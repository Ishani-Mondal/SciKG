{"title": [], "abstractContent": [{"text": "Clustering is crucial for many NLP tasks and applications.", "labels": [], "entities": []}, {"text": "However, evaluating the results of a clustering algorithm is hard.", "labels": [], "entities": []}, {"text": "In this paper we focus on the evaluation setting in which a gold standard solution is available.", "labels": [], "entities": []}, {"text": "We discuss two existing information theory based measures , V and VI, and show that they are both hard to use when comparing the performance of different algorithms and different datasets.", "labels": [], "entities": []}, {"text": "The V measure favors solutions having a large number of clusters, while the range of scores given by VI depends on the size of the dataset.", "labels": [], "entities": []}, {"text": "We present anew measure, NVI, which normalizes VI to address the latter problem.", "labels": [], "entities": [{"text": "VI", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9730100035667419}]}, {"text": "We demonstrate the superiority of NVI in a large experiment involving an important NLP application , grammar induction, using real corpus data in English, German and Chinese.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7552559673786163}]}], "introductionContent": [{"text": "Clustering is a major technique in machine learning and its application areas.", "labels": [], "entities": []}, {"text": "It lies at the heart of unsupervised learning, which has great potential advantages over supervised learning.", "labels": [], "entities": []}, {"text": "This is especially true for NLP, due to the high efforts and costs incurred by the human annotations required for training supervised algorithms.", "labels": [], "entities": []}, {"text": "Recent NLP problems addressed by clustering include POS induction, word sense disambiguation (), semantic role labeling (), pitch accent type disambiguation () and grammar induction).", "labels": [], "entities": [{"text": "POS induction", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.8984627723693848}, {"text": "word sense disambiguation", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.7071441411972046}, {"text": "semantic role labeling", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.6990780830383301}, {"text": "pitch accent type disambiguation", "start_pos": 124, "end_pos": 156, "type": "TASK", "confidence": 0.5971041619777679}, {"text": "grammar induction", "start_pos": 164, "end_pos": 181, "type": "TASK", "confidence": 0.7577574849128723}]}, {"text": "Evaluation of clustering results is a challenging task.", "labels": [], "entities": [{"text": "Evaluation of clustering", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6208826700846354}]}, {"text": "In this paper we address the external measures setting, where a correct assignment of elements to classes is available and is used for evaluating the quality of another assignment of the elements into clusters.", "labels": [], "entities": []}, {"text": "Many NLP works have used external clustering evaluation measures (see.", "labels": [], "entities": []}, {"text": "Recently, two measures have been proposed that avoid many of the weaknesses of previous measures and exhibit several attractive properties (see Sections 2 and 3): the VI measure and the V measure (.", "labels": [], "entities": []}, {"text": "However, each of these has a serious drawback.", "labels": [], "entities": []}, {"text": "The possible values of VI lie in, where N is the size of the clustered dataset.", "labels": [], "entities": [{"text": "VI", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.871496319770813}]}, {"text": "Hence it has limited use when comparing performance on different datasets.", "labels": [], "entities": []}, {"text": "V measure values lie in regardless of the dataset, but the measure strongly favors a clustering having many small clusters.", "labels": [], "entities": []}, {"text": "In addition, V does not have many of the attractive properties of This paper has two contributions.", "labels": [], "entities": []}, {"text": "First, we propose the NVI measure, a normalization of VI which guarantees that the score of clusterings that VI considers good lies in, regardless of dataset size.", "labels": [], "entities": []}, {"text": "Most of VI's attractive properties are retained by NVI.", "labels": [], "entities": [{"text": "VI", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.7938873171806335}, {"text": "NVI", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.9762091040611267}]}, {"text": "Second, we compare the behavior of V, VI and NVI in various situations to the desired behavior and to each other.", "labels": [], "entities": []}, {"text": "In particular, we show that V gives high scores to clusterings with a large number of clusters even when they are of low quality.", "labels": [], "entities": []}, {"text": "We demonstrate this both in a synthetic example (Section 5) and in the evaluation (in three languages) of a difficult NLP problem, labeled parse tree induc-tion (Section 6).", "labels": [], "entities": []}, {"text": "We show that in both cases, NVI constitutes a better clustering evaluation measure.", "labels": [], "entities": []}], "datasetContent": [{"text": "A large number of clustering quality measures have been proposed.", "labels": [], "entities": []}, {"text": "Here we briefly survey the three main types, mapping based measures, counting pairs measures and information theory based measures.", "labels": [], "entities": []}, {"text": "We first review some terminology.", "labels": [], "entities": []}, {"text": "Ina homogeneous clustering, every cluster contains only elements from a single class.", "labels": [], "entities": []}, {"text": "Ina complete clustering, all elements of each class are assigned to the same cluster.", "labels": [], "entities": []}, {"text": "The perfect solution is the fully homogeneous and complete clustering.", "labels": [], "entities": []}, {"text": "We will illustrate the behavior of some measures using three extreme cases: the single cluster case, in which all data elements are put in the same single cluster; the singletons case, in which each data element is put in a cluster of its own; and the no knowledge case, in which the class distribution within each cluster is identical to the class distribution in the entire dataset.", "labels": [], "entities": []}, {"text": "If the single cluster solution is not the perfect one, the no knowledge solution is the worst possible solution.", "labels": [], "entities": []}, {"text": "Throughout the paper, the number of data elements to be clustered is denoted by N. Mapping based measures are based on a postprocessing step in which each cluster is mapped to a class.", "labels": [], "entities": []}, {"text": "Among these are: L,), misclassification index (MI) (), H, clustering F-measure () and micro-averaged precision and recall.", "labels": [], "entities": [{"text": "misclassification index (MI)", "start_pos": 22, "end_pos": 50, "type": "METRIC", "confidence": 0.9312661767005921}, {"text": "H", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.9778082370758057}, {"text": "F-measure", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.5910367965698242}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9274003505706787}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.996965229511261}]}, {"text": "As noted in, these measures evaluate not only the quality of the proposed clustering but also of the mapping scheme.", "labels": [], "entities": []}, {"text": "Different mapping schemes can lead to different quality scores for the same clustering.", "labels": [], "entities": []}, {"text": "Moreover, even when the mapping scheme is fixed, it can lead to not evaluating the entire membership of a cluster and not evaluating every cluster.", "labels": [], "entities": []}, {"text": "Counting pairs measures are based on a combinatorial approach which examines the number of pairs of data elements that are clustered similarly in the reference and proposed clustering.", "labels": [], "entities": []}, {"text": "Among these are Rand Index, Adjusted Rand Index, \u0393 statistic, Jaccard (, Fowlkes-Mallows ( and Mirkin.", "labels": [], "entities": [{"text": "Rand Index", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.7204174399375916}, {"text": "Adjusted Rand Index", "start_pos": 28, "end_pos": 47, "type": "METRIC", "confidence": 0.8757644097010294}, {"text": "Jaccard", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9233987927436829}, {"text": "Fowlkes-Mallows", "start_pos": 73, "end_pos": 88, "type": "METRIC", "confidence": 0.6544255614280701}]}, {"text": "Meila (2007) described a number of problems with such measures.", "labels": [], "entities": []}, {"text": "The most acute one is that their values are unbounded, making it hard to interpret their results.", "labels": [], "entities": []}, {"text": "The problem can be solved by transformations adjusting their values to lie in, but the adjusted measures suffer from severe distributional problems, again limiting their usability in practice.", "labels": [], "entities": []}, {"text": "Information-theoretic (IT) based measures are those addressed in this work.", "labels": [], "entities": []}, {"text": "The measures in this family suffer neither from the problems associated with mappings, since they evaluate the entire membership of each cluster and not just a mapped portion, nor from the distributional problems of the counting pairs measures.", "labels": [], "entities": []}, {"text": "define Purity and Entropy as follows: where q is the number of classes, k the number of clusters, n r cluster r's size, and n i r is the number of elements in class i assigned to cluster r.", "labels": [], "entities": [{"text": "Purity and Entropy", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.6372904578844706}]}, {"text": "Both measures are good measures for homogeneity (Purity increases and Entropy decreases when homogeneity increases).", "labels": [], "entities": [{"text": "Purity", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9728052616119385}, {"text": "Entropy", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9981942772865295}]}, {"text": "However, they do not evaluate completeness at all.", "labels": [], "entities": []}, {"text": "The singletons solution is thus considered optimal even if in fact it is of very low quality.", "labels": [], "entities": []}, {"text": "proposed the Q measure, the sum of a homogeneity term H(C|K) and a model cost term calculated using a coding theory argument: where C are the correct classes, K are the induced clusters and h(k) is the number of elements in cluster k.", "labels": [], "entities": []}, {"text": "Dom also presented a normalized version of the Q measure (called Q 2 ) whose range is (0, 1] and gives higher scores to clusterings that are preferable.", "labels": [], "entities": []}, {"text": "As noted by, the Q measure does not explicitly address the completeness of the suggested clustering.", "labels": [], "entities": []}, {"text": "Due to the cost term, if two clusterings have the same H(C|K) value, the model prefers the one with the lower number of clusters, but the trade-off between homogeneity and completeness is not explicitly addressed.", "labels": [], "entities": []}, {"text": "In the next section we describe the V and VI mea-sures, which are IT measures that explicitly assess both the homogeneity and completeness of the clustering solution.", "labels": [], "entities": []}, {"text": "BCubed () is an attractive measure that addresses both completeness and homogeneity.", "labels": [], "entities": [{"text": "BCubed", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6185063719749451}]}, {"text": "It does not explicitly use IT concepts and avoids mapping.", "labels": [], "entities": []}, {"text": "In this paper we focus on V and VI; a detailed comparison with BCubed is out of our scope here and will be done in future work.", "labels": [], "entities": [{"text": "BCubed", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.7088434100151062}]}, {"text": "Several recent NLP papers used clustering techniques and evaluation measures.", "labels": [], "entities": []}, {"text": "Examples include (, using VI, Rand index and clustering F-score for evaluating coreference resolution;, using VI, V, greedy 1-to-1 and many-to-1 mapping for evaluating unsupervised POS induction;, using clustering F-score, the adjusted Rand index, V, VI and Q 2 for document clustering; and (, using greedy 1-to-1 and many-to-1 mappings for evaluating labeled parse tree induction.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.9139768481254578}, {"text": "document clustering", "start_pos": 266, "end_pos": 285, "type": "TASK", "confidence": 0.7120417654514313}, {"text": "labeled parse tree induction", "start_pos": 352, "end_pos": 380, "type": "TASK", "confidence": 0.6122221872210503}]}, {"text": "Schulte im used clustering to induce semantic verb classes and extensively discussed non-IT based clustering evaluation measures.", "labels": [], "entities": []}, {"text": "presented a comparison of clustering evaluation measures (IT based and others).", "labels": [], "entities": []}, {"text": "While their analysis is extensive, their experiments were confined to artificial data.", "labels": [], "entities": []}, {"text": "In this work, we experiment with a complex NLP application using large real datasets.", "labels": [], "entities": []}, {"text": "In this section we analyse the behavior of V, VI, NVI and NVIK using a highly non-trivial NLP application with large real datasets, the unsupervised labeled parse tree induction (LTI) algorithm of.", "labels": [], "entities": [{"text": "labeled parse tree induction (LTI)", "start_pos": 149, "end_pos": 183, "type": "TASK", "confidence": 0.6860413338456836}]}, {"text": "We focus on the labeling that the algorithm finds for parsing constituents, which is a clustering of constituents.", "labels": [], "entities": [{"text": "parsing constituents", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.9069423973560333}]}, {"text": "We show that V gives about the same score to a labeling that uses thousands of labels and to labelings in which the number of labels (dozens) is identical or smaller than the number of labels in the reference evaluation set (an annotated corpus).", "labels": [], "entities": []}, {"text": "Contrary to V, both NVI and VI give much better scores to the solutions having a smaller number of labels.", "labels": [], "entities": []}, {"text": "It could be argued that the total number of 'real' labels in the data is indeed large (e.g., because every verb exhibits its own syntactic patterns) and that a small number of labels is just an arbitrary decision of the corpus annotators.", "labels": [], "entities": []}, {"text": "However, most linguistic theories agree that there is a prototypical level of generalization that uses concepts such as Noun Phrase and Verb Phrase, a level which consists of at most dozens of labels and is strongly manifested by real language data.", "labels": [], "entities": []}, {"text": "Under these accepted assumptions, the scoring behavior of V is unreasonable.: The number of elements (constituents) covered by the clusters (labels) produced by the MDL+SC (T or P labels) and MDL clusterings.", "labels": [], "entities": []}, {"text": "L is the total number of labels.", "labels": [], "entities": []}, {"text": "Shown are the number of clusters having one element, less than 10 elements, less than 100 elements, and more than 100 elements.", "labels": [], "entities": []}, {"text": "It is evident that MDL induces a sparse clustering with many clusters that annotate very few constituents.", "labels": [], "entities": []}, {"text": "The LTI algorithm has three stages: bracketing, initial labeling, and label clustering.", "labels": [], "entities": [{"text": "bracketing", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.9598407745361328}, {"text": "label clustering", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.7158614099025726}]}, {"text": "Bracketing is done from raw text using the unsupervised incremental parser of.", "labels": [], "entities": [{"text": "Bracketing", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8163186311721802}]}, {"text": "Initial labeling is done using the BMM model, which aims at minimizing the grammar description length (MDL).", "labels": [], "entities": [{"text": "grammar description length (MDL)", "start_pos": 75, "end_pos": 107, "type": "METRIC", "confidence": 0.7637530118227005}]}, {"text": "Finally, labels are clustered to a desired number of labels using the k-means algorithm with syntactic features extracted from the initially labeled trees.", "labels": [], "entities": []}, {"text": "We refer to this stage as MDL+SC (for 'syntactic clustering').", "labels": [], "entities": []}, {"text": "Using a mapping-based evaluation with two different mapping functions, the LTI algorithm was shown to outperform previous work on unsupervised labeled parse tree induction.", "labels": [], "entities": [{"text": "parse tree induction", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.6228734155495962}]}, {"text": "The MDL clustering step induces several thousand labels for corpora of several tens of thousands of constituents.", "labels": [], "entities": [{"text": "MDL clustering", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6552972197532654}]}, {"text": "The role of the SC step is to generalize these labels using syntactic features.", "labels": [], "entities": []}, {"text": "There are two versions of the SC step.", "labels": [], "entities": []}, {"text": "In one, the number of clusters is identical to the number of labels in the gold standard annotation of the experimental corpus.", "labels": [], "entities": []}, {"text": "This set of labels is called T (for target) labels.", "labels": [], "entities": []}, {"text": "In the other SC version, the number of labels is the minimum number of labels required to annotate more than 95% of the constituents in the gold standard annotation of the corpus.", "labels": [], "entities": []}, {"text": "This set of labels is called P (for prominent) labels.", "labels": [], "entities": []}, {"text": "Since constituent labels follow the Zipfian distribution, P is much smaller than T . In this paper we run the LTI algorithm and evaluate its labeling quality using V, VI, NVI and NVIK.", "labels": [], "entities": []}, {"text": "In each corpus, we used the sentences of length at most 10, 4 numbering 7422 (WSJ10), 7542 (NEGRA10) and 4626 (CTB10).", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.8157633543014526}, {"text": "NEGRA10", "start_pos": 92, "end_pos": 99, "type": "DATASET", "confidence": 0.926545262336731}]}, {"text": "The characteristics of the induced clusterings are shown in . The table demonstrates the fact that MDL labeling, while perhaps capturing the salient level of generalization of the data in its leading clusters, is extremely noisy.", "labels": [], "entities": [{"text": "MDL labeling", "start_pos": 99, "end_pos": 111, "type": "TASK", "confidence": 0.7947060465812683}]}, {"text": "For WSJ10, for example, 2282 of the 2916 unique labels annotate only one constituent, and 2774 labels label less than 10 constituents.", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.9120330214500427}]}, {"text": "These 2774 labels annotate 14.4% of compared constituents, and the 2864 labels that annotate less than 100 constituents each, cover 30.7% of the compared constituents (these percentages are not shown in the table).", "labels": [], "entities": []}, {"text": "In other words, MDL is not a solution in which almost all of the mass is concentrated in the few leading clusters; its tail occupies a large percentage of its mass.", "labels": [], "entities": []}, {"text": "MDL patterns for NEGRA10 and CTB10 are very similar.", "labels": [], "entities": [{"text": "MDL", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8856859803199768}, {"text": "NEGRA10", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.8232086300849915}, {"text": "CTB10", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.8950902819633484}]}, {"text": "For MDL+SC with T or P labels, most of the induced labels annotate 100 constituents or more.", "labels": [], "entities": []}, {"text": "We thus expect MDL+SC to provide better clustering than MDL; a good clustering evaluation measure should reflect this expectation.", "labels": [], "entities": []}, {"text": "shows V, VI, NVI and NVIK scores for MDL and MDL+SC (with T or P labels).", "labels": [], "entities": []}, {"text": "For all three corpora, V values are almost identical for the MDL and the MDL+SC schemes.", "labels": [], "entities": []}, {"text": "This is in contrast to VI and NVI values that strongly prefer the MDL+SC clusterings, fitting our expectations (recall that for these measures, the lower the score, the better the clustering).", "labels": [], "entities": [{"text": "VI", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9809536933898926}]}, {"text": "Moreover, VI and NVI prefer MDL+SC with P labels, which again accords with our expectations, since P labels were defined as those that are more salient in the data (see above).", "labels": [], "entities": [{"text": "NVI", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.8697177767753601}]}, {"text": "The patterns of NVI and VI are identical, since NV I = VI H(C) and H(C) is independent of the induced clustering.", "labels": [], "entities": []}, {"text": "However, the numbers given by NVI are easier to interpret than those given by VI.", "labels": [], "entities": [{"text": "NVI", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.9104132652282715}]}, {"text": "The latter are basically meaningless, conveying nothing about clustering quality.", "labels": [], "entities": []}, {"text": "The former are quite close to 1, telling us that clustering quality is not that good but not horrible either.", "labels": [], "entities": []}, {"text": "This makes sense, because the overall quality of the labeling induction algorithm is indeed not that high: using oneto-one mapping (the more forgiving mapping), the accuracy of the labels induced by MDL+SC is only 45-72%.", "labels": [], "entities": [{"text": "labeling induction", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9095825254917145}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9990605711936951}]}, {"text": "NVIK, the normalization of VI with H(K), is worse even than V.", "labels": [], "entities": [{"text": "NVIK", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.501542329788208}]}, {"text": "This measure (which also gives lower scores to better clusterings) prefers the MDL over MDL+SC labels.", "labels": [], "entities": []}, {"text": "This is a further justification of our decision to define NVI by normalizing VI by H(C) rather than by H(K).: Class (H(C)) and cluster (H(K)) entropy for MDL and MDL+SC with T or P labels.", "labels": [], "entities": []}, {"text": "H(C) is cluster independent.", "labels": [], "entities": []}, {"text": "H(K) increases with the number of clusters.", "labels": [], "entities": [{"text": "H(K)", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9168119728565216}]}, {"text": "shows the H(C) and H(K) values in the experiment.", "labels": [], "entities": [{"text": "H(K)", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.8690979778766632}]}, {"text": "While H(C) is independent of the induced clustering and is thus constant fora given annotated corpus, H(K) monotonically increases with the number of induced clusters.", "labels": [], "entities": []}, {"text": "Since both NVIK and the completeness term of V are normalized by H(K), these measures prefer clusterings with a large number of clusters even when many of these clusters provide useless information.", "labels": [], "entities": [{"text": "NVIK", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.7615318298339844}]}], "tableCaptions": [{"text": " Table 1: The clustering matrix of solution R (top), and  the scores given to it and to the singletons solution by the  four measures (bottom). Although solution R is superior,  the score given by V to the singletons solution is much  higher. NVI exhibits the most preferable behavior (recall  that higher V values are better, as opposed to the other  three measures).", "labels": [], "entities": []}, {"text": " Table 2: The number of elements (constituents) covered by the clusters (labels) produced by the MDL+SC (T or P  labels) and MDL clusterings. L is the total number of labels. Shown are the number of clusters having one element,  less than 10 elements, less than 100 elements, and more than 100 elements. It is evident that MDL induces a sparse  clustering with many clusters that annotate very few constituents.", "labels": [], "entities": []}, {"text": " Table 3: V, VI, NVI and NVIK values for MDL and MDL+SC with T or P labels. V gives the three clusterings  very similar scores. NVIK prefers MDL labeling. NVI and VI both show the expected qualitative behavior, favoring  MDL+SC clustering with P labels. The most preferable scores are those of NVI, whose numbers are also the easiest  to interpret.", "labels": [], "entities": []}, {"text": " Table 4: Class (H(C)) and cluster (H(K)) entropy for  MDL and MDL+SC with T or P labels. H(C) is cluster  independent. H(K) increases with the number of clus- ters.", "labels": [], "entities": []}]}