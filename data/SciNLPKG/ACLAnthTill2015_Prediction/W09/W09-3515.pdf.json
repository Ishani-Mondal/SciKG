{"title": [{"text": "Combining a Two-step Conditional Random Field Model and a Joint Source Channel Model for Machine Transliteration", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes our system for \"NEWS 2009 Machine Transliteration Shared Task\" (NEWS 2009).", "labels": [], "entities": [{"text": "NEWS 2009 Machine Transliteration Shared Task\" (NEWS 2009)", "start_pos": 37, "end_pos": 95, "type": "TASK", "confidence": 0.6912035860798575}]}, {"text": "We only participated in the standard run, which is a direct orthographical mapping (DOP) between two languages without using any intermediate phonemic mapping.", "labels": [], "entities": []}, {"text": "We propose anew two-step conditional random field (CRF) model for DOP machine transliteration, in which the first CRF segments a source word into chunks and the second CRF maps the chunks to a word in the target language.", "labels": [], "entities": [{"text": "DOP machine transliteration", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.8959528605143229}]}, {"text": "The two-step CRF model obtains a slightly lower top-1 accuracy when compared to a state-of-the-art n-gram joint source-channel model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9897650480270386}]}, {"text": "The combination of the CRF model with the joint source-channel leads to improvements in all the tasks.", "labels": [], "entities": []}, {"text": "The official result of our system in the NEWS 2009 shared task confirms the effectiveness of our system; where we achieved 0.627 top-1 accuracy for Japanese transliterated to Japanese Kanji(JJ), 0.713 for English-to-Chinese(E2C) and 0.510 for English-to-Japanese Katakana(E2J) .", "labels": [], "entities": [{"text": "NEWS 2009 shared task", "start_pos": 41, "end_pos": 62, "type": "DATASET", "confidence": 0.9208609312772751}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9771943688392639}]}], "introductionContent": [{"text": "With the increasing demand for machine translation, the out-of-vocabulary (OOV) problem caused by named entities is becoming more serious.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7443506419658661}]}, {"text": "The translation of named entities from an alphabetic language (like English, French and Spanish) to a non-alphabetic language (like Chinese and Japanese) is usually performed through transliteration, which tries to preserve the pronunciation in the source language.", "labels": [], "entities": [{"text": "translation of named entities from an alphabetic language (like English, French and Spanish)", "start_pos": 4, "end_pos": 96, "type": "TASK", "confidence": 0.7072551436722279}]}, {"text": "For example, in Japanese, foreign words imported from other languages are usually written in a special syllabary called Katakana; in Chinese, foreign words accepted to Chinese are always written by Chinese characters; examples are given in.", "labels": [], "entities": []}, {"text": "An intuitive transliteration method is to first convert a source word into phonemes, then find the corresponding phonemes in the target language, and finally convert to the target language's writing system).", "labels": [], "entities": []}, {"text": "One major limitation of this method is that the named entities are usually OOVs with diverse origins and this makes the grapheme-to-phoneme conversion very difficult.", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion", "start_pos": 120, "end_pos": 150, "type": "TASK", "confidence": 0.7168442606925964}]}, {"text": "DOP is gaining more attention in the transliteration research community which is also the standard evaluation of NEWS 2009.", "labels": [], "entities": [{"text": "DOP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.44719842076301575}, {"text": "NEWS 2009", "start_pos": 113, "end_pos": 122, "type": "DATASET", "confidence": 0.9508506953716278}]}, {"text": "The source channel and joint source-channel models () have been proposed for DOP, which try to model P (T |S) and P (T, S) respectively, where T and S denotes the words in the target and source languages.", "labels": [], "entities": []}, {"text": "() modified the joint source-channel model to incorporate different context information into the model for the Indian languages.", "labels": [], "entities": []}, {"text": "Here we propose a two-step CRF model for transliteration, and the idea is to make use of the discriminative ability of CRF.", "labels": [], "entities": []}, {"text": "For example, in E2C transliteration, the first step is to segment an English name into alphabet chunks and after this step the number of Chinese characters is decided.", "labels": [], "entities": []}, {"text": "The second step is to perform a context-dependent mapping from each English chunk into one Chinese character.", "labels": [], "entities": []}, {"text": "shows that this method is applicable to many other transliteration tasks including E2C and E2J.", "labels": [], "entities": []}, {"text": "Our CRF method and the n-gram joint sourcechannel model use different information in predicting the corresponding Chinese characters and therefore in combination better results are expected.", "labels": [], "entities": []}, {"text": "We interpolate the two models linearly and use this as our final system for NEWS 2009.", "labels": [], "entities": [{"text": "NEWS 2009", "start_pos": 76, "end_pos": 85, "type": "DATASET", "confidence": 0.9306309819221497}]}, {"text": "The rest of the paper is organized as follows: Section 2 introduces our system in detail including the alignment and decoding modules, Section 3 explains our experiments and finally Section 4 describes conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the training and development sets of NEWS 2009 data in our experiments as detailed in   The results are listed in.", "labels": [], "entities": [{"text": "NEWS 2009 data", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9659988085428873}]}, {"text": "For E2C task the top-1 accuracy of the joint source-channel model is 70.3% and 67.3% for the two-step CRF model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9965788722038269}]}, {"text": "After combining the two results together the top-1 accuracy increases to 71.5% corresponding to a 1.2% absolute improvement over the stateof-the-art joint source-channel model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9941615462303162}]}, {"text": "Similarly, we get 1.8% absolute improvement for E2J task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. For E2C  task the top-1 accuracy of the joint source-channel  model is 70.3% and 67.3% for the two-step CRF  model. After combining the two results together  the top-1 accuracy increases to 71.5% correspond- ing to a 1.2% absolute improvement over the state- of-the-art joint source-channel model. Similarly,  we get 1.8% absolute improvement for E2J task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9973238706588745}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9847770929336548}]}]}