{"title": [{"text": "Evaluating the pairwise string alignment of pronunciations", "labels": [], "entities": [{"text": "pairwise string alignment of pronunciations", "start_pos": 15, "end_pos": 58, "type": "TASK", "confidence": 0.7335740447044372}]}], "abstractContent": [{"text": "Pairwise string alignment (PSA) is an important general technique for obtaining a measure of similarity between two strings, used e.g., in dialectology, historical linguistics , transliteration, and in evaluating name distinctiveness.", "labels": [], "entities": [{"text": "Pairwise string alignment (PSA)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7610754370689392}, {"text": "evaluating name distinctiveness", "start_pos": 202, "end_pos": 233, "type": "TASK", "confidence": 0.6564077933629354}]}, {"text": "The current study focuses on evaluating different PSA methods at the alignment level instead of via the distances it induces.", "labels": [], "entities": [{"text": "PSA", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9750291705131531}]}, {"text": "About 3.5 million pairwise alignments of Bulgarian phonetic dialect data are used to compare four algorithms with a manually corrected gold standard.", "labels": [], "entities": [{"text": "Bulgarian phonetic dialect data", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.5454713404178619}]}, {"text": "The algorithms evaluated include three variants of the Levenshtein algorithm as well as the Pair Hidden Markov Model.", "labels": [], "entities": []}, {"text": "Our results show that while all algorithms perform very well and align around 95% of all alignments correctly, there are specific qualitative differences in the (mis)alignments of the different algorithms .", "labels": [], "entities": []}], "introductionContent": [{"text": "Our cultural heritage is not only accessible through museums, libraries, archives and their digital portals, it is alive and well in the varied cultural habits practiced today by the various peoples of the world.", "labels": [], "entities": []}, {"text": "To research and understand this cultural heritage we require instruments which are sensitive to its signals, and, in particular sensitive to signals of common provenance.", "labels": [], "entities": []}, {"text": "The present paper focuses on speech habits which even today bear signals of common provenance in the various dialects of the world's languages, and which have also been recorded and preserved in major archives of folk culture internationally.", "labels": [], "entities": []}, {"text": "We present work in a research line which seeks to develop digital instruments capable of detecting common provenance among pronunciation habits, focusing in this paper on the issue of evaluating the quality of these instruments.", "labels": [], "entities": [{"text": "detecting common provenance among pronunciation habits", "start_pos": 89, "end_pos": 143, "type": "TASK", "confidence": 0.8036778767903646}]}, {"text": "Pairwise string alignment (PSA) methods, like the popular Levenshtein algorithm which uses insertions (alignments of a segment against a gap), deletions (alignments of a gap against a segment) and substitutions (alignments of two segments) often form the basis of determining the distance between two strings.", "labels": [], "entities": [{"text": "Pairwise string alignment (PSA)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8069846133391062}]}, {"text": "Since there are many alignment algorithms and specific settings for each algorithm influencing the distance between two strings, evaluation is very important in determining the effectiveness of the distance methods.", "labels": [], "entities": []}, {"text": "Determining the distance (or similarity) between two phonetic strings is an important aspect of dialectometry, and alignment quality is important in applications in which string alignment is a goal in itself, for example, determining if two words are likely to be cognate, detecting confusable drug names, or determining whether a string is the transliteration of the same name from another writing system.", "labels": [], "entities": [{"text": "detecting confusable drug names", "start_pos": 273, "end_pos": 304, "type": "TASK", "confidence": 0.8350218832492828}]}, {"text": "In this paper we evaluate string distance measures on the basis of data from dialectology.", "labels": [], "entities": []}, {"text": "We therefore explain a bit more of the intended use of the pronunciation distance measure.", "labels": [], "entities": [{"text": "pronunciation distance measure", "start_pos": 59, "end_pos": 89, "type": "METRIC", "confidence": 0.7985259691874186}]}, {"text": "Dialect atlases normally contain a large number of pronunciations of the same word in various places throughout a language area.", "labels": [], "entities": [{"text": "Dialect atlases", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8250097632408142}]}, {"text": "All pairs of pronunciations of corresponding words are compared in order to obtain a measure of the aggregate linguistic distance between dialectal varieties.", "labels": [], "entities": []}, {"text": "It is clear that the quality of the measurement is of crucial importance.", "labels": [], "entities": []}, {"text": "Almost all evaluation methods in dialectometry focus on the aggregate results and ignore the individual word-pair distances and individual alignments on which the distances are based.", "labels": [], "entities": []}, {"text": "The focus on the aggregate distance of 100 or so word pairs effectively hides many differences between methods.", "labels": [], "entities": []}, {"text": "For example, find no significant differences in the degrees to which several pairwise string distance measures correlate with perceptual distances when examined at an aggregate level.  and  also report almost no difference between different PSA algorithms at the aggregate level.", "labels": [], "entities": []}, {"text": "It is important to be able to evaluate the different techniques more sensitively, which is why this paper examines alignment quality at the segment level.", "labels": [], "entities": []}, {"text": "applies a PSA algorithm to align words in different languages in order to detect cognates automatically.", "labels": [], "entities": []}, {"text": "Exceptionally, he does provide an evaluation of the string alignments generated by different algorithms.", "labels": [], "entities": []}, {"text": "But he restricts his examination to a set of only 82 gold standard pairwise alignments and he only distinguishes correct and incorrect alignments and does not look at misaligned phones.", "labels": [], "entities": []}, {"text": "In the current study we introduce and evaluate several alignment algorithms more extensively at the alignment level.", "labels": [], "entities": []}, {"text": "The algorithms we evaluate include the Levenshtein algorithm (with syllabicity constraint), which is one of the most popular alignment methods and has successfully been used in determining pronunciation differences in phonetic strings).", "labels": [], "entities": []}, {"text": "In addition we look at two adaptations of the Levenshtein algorithm.", "labels": [], "entities": []}, {"text": "The first adaptation includes the swap-operation (, while the second adaptation includes phonetic segment distances, which are generated by applying an iterative pointwise mutual information (PMI) procedure).", "labels": [], "entities": []}, {"text": "Finally we include alignments generated with the Pair Hidden Markov Model (PHMM) as introduced to language studies by.", "labels": [], "entities": []}, {"text": "They reported that the Pair Hidden Markov Model outperformed ALINE, the best performing algorithm at the alignment level in the aforementioned study of.", "labels": [], "entities": [{"text": "ALINE", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9378083944320679}]}, {"text": "The PHMM has also successfully been used in dialectology by .", "labels": [], "entities": [{"text": "PHMM", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.7137003540992737}]}], "datasetContent": [{"text": "The dataset used in this study consists of 152 words collected from 197 sites equally distributed over Bulgaria.", "labels": [], "entities": []}, {"text": "The transcribed word pronunciations include diacritics and suprasegmentals (e.g., intonation).", "labels": [], "entities": []}, {"text": "The total number of different phonetic types (or segments) is 98.", "labels": [], "entities": []}, {"text": "The gold standard pairwise alignment was automatically generated from a manually corrected gold standard set of N multiple alignments (see Proki\u00b4c ) in the following way: \u2022 Every individual string (including gaps) in the multiple alignment is aligned with every other string of the same word.", "labels": [], "entities": []}, {"text": "With 152 words and 197 sites and in some cases more than one pronunciations per site fora certain word, the total number of pairwise alignments is about 3.5 million.", "labels": [], "entities": []}, {"text": "\u2022 If a resulting pairwise alignment contains a gap in both strings at the same position (a gap-gap alignment), these gaps are removed from the pairwise alignment.", "labels": [], "entities": []}, {"text": "We justify this, reasoning that no alignment algorithm maybe expected to detect parallel deletions in a single pair of words.", "labels": [], "entities": []}, {"text": "There is no evidence for this in the single pair.", "labels": [], "entities": []}, {"text": "To make this clear, consider the multiple alignment of three Bulgarian dialectal variants of the word 'I' (as in 'I am'): j \"A s \"A z i j \"A Using the procedure above, the three generated pairwise alignments are: j \"A s j \"A s \"A z i \"A z i j \"A j \"A  As described in section 2, we use the generated pairwise alignments from a gold standard of multiple alignments for evaluation.", "labels": [], "entities": []}, {"text": "In addition, we look at the performance of a baseline of pairwise alignments, which is constructed by aligning the strings according to the Hamming distance (i.e. only allowing substitutions and no insertions or deletions;.", "labels": [], "entities": []}, {"text": "The evaluation procedure consists of comparing the alignments of the previously discussed algorithms including the baseline with the alignments of the gold standard.", "labels": [], "entities": []}, {"text": "For the comparison we use the standard Levenshtein algorithm without any restrictions.", "labels": [], "entities": []}, {"text": "The evaluation proceeds as follows: 1.", "labels": [], "entities": []}, {"text": "The pairwise alignments of the four algorithms, the baseline and the gold standard are generated and standardized (see section 4.1).", "labels": [], "entities": []}, {"text": "When multiple equal-scoring alignments are generated by an algorithm, only one (i.e. the final) alignment is selected.", "labels": [], "entities": []}, {"text": "2. In each alignment, we convert each pair of aligned segments to a single token, so that every alignment of two strings is converted to a single string of segment pairs.", "labels": [], "entities": []}, {"text": "3. For every algorithm these transformed strings are aligned with the transformed strings of the gold standard using the standard Levenshtein algorithm.", "labels": [], "entities": []}, {"text": "4. The Levenshtein distances for all these strings are summed up resulting in the total distance between every alignment algorithm and the gold standard.", "labels": [], "entities": []}, {"text": "Only if individual segments match completely the segment distance is 0, otherwise it is 1.", "labels": [], "entities": []}, {"text": "To illustrate this procedure, consider the following gold standard alignment of and, two Bulgarian dialectal variants of the word 'wolf': Every aligned segment pair is converted to a single token by adding the symbol '/' between the segments and using the symbol '-' to indicate a gap.", "labels": [], "entities": []}, {"text": "This yields the following transformed string: v/v l/\"7 \"7/l k/k Suppose another algorithm generates the following alignment (not detecting the swap): The transformed string for this alignment is: To evaluate this alignment, we align this string to the transformed string of the gold standard and obtain a Levenshtein distance of 3: By repeating this procedure for all alignments and summing up all distances, we obtain total distances between the gold standard and every alignment algorithm.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 447, "end_pos": 460, "type": "DATASET", "confidence": 0.8600074052810669}]}, {"text": "Algorithms which generate highquality alignments will have a low distance from the gold standard, while the distance will be higher for algorithms which generate low-quality alignments.", "labels": [], "entities": []}, {"text": "Using the procedure described in section 4, we calculated the distances between the gold standard and the alignment algorithms.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 84, "end_pos": 97, "type": "DATASET", "confidence": 0.9106015264987946}, {"text": "alignment", "start_pos": 106, "end_pos": 115, "type": "TASK", "confidence": 0.9622094035148621}]}, {"text": "Besides reporting the total number of misaligned tokens, we also divided this number by the total number of aligned segments in the gold standard (about 16 million) to get an idea of the error rate.", "labels": [], "entities": []}, {"text": "Note that the error rate is 0 in the perfect case, but might rise to nearly 2 in the worst case, which is an alignment consisting of only insertions and deletions and therefore up to twice as long as the alignments in the gold standard.", "labels": [], "entities": [{"text": "error rate", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.984440416097641}]}, {"text": "Finally, we also report the total number of alignments (word pairs) which are not exactly equal to the alignments of the gold standard.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We can clearly see that all algorithms beat the baseline and align about 95% of all string pairs correctly.", "labels": [], "entities": []}, {"text": "While the Levenshtein PMI algorithm aligns most strings perfectly, it misaligns slightly more individual segments than the PHMM and the Levenshtein algorithm with the swap operation (i.e. it makes more segment alignment errors per word pair).", "labels": [], "entities": [{"text": "PHMM", "start_pos": 123, "end_pos": 127, "type": "DATASET", "confidence": 0.9284167885780334}]}, {"text": "The VC-sensitive Levenshtein algorithm in general performs slightly worse than the other three algorithms.", "labels": [], "entities": []}], "tableCaptions": []}