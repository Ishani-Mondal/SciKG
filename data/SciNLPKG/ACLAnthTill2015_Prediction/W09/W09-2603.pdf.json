{"title": [{"text": "Mining of Parsed Data to Derive Deverbal Argument Structure", "labels": [], "entities": []}], "abstractContent": [{"text": "The availability of large parsed corpora and improved computing resources now make it possible to extract vast amounts of lexical data.", "labels": [], "entities": []}, {"text": "We describe the process of extracting structured data and several methods of deriving argument structure mappings for deverbal nouns that significantly improves upon non-lexicalized rule-based methods.", "labels": [], "entities": [{"text": "deriving argument structure mappings", "start_pos": 77, "end_pos": 113, "type": "TASK", "confidence": 0.6275876015424728}]}, {"text": "For atypical model, the F-measure of performance improves from a baseline of about 0.72 to 0.81.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9993500113487244}]}], "introductionContent": [{"text": "There is a long-standing division in natural language processing between symbolic, rule-based approaches and data-driven, statistical ones.", "labels": [], "entities": []}, {"text": "Rulebased, human-curated approaches are thought to be more accurate for linguistic constructions explicitly covered by the rules.", "labels": [], "entities": []}, {"text": "However, such approaches often have trouble scaling up to a wider range of phenomena or different genres of text.", "labels": [], "entities": []}, {"text": "There have been repeated moves towards hybridized approaches, in which rules created with human linguistic intuitions are supplemented by automatically derived corpus data).", "labels": [], "entities": []}, {"text": "Unstructured corpus data for English can easily be found on the Internet.", "labels": [], "entities": []}, {"text": "Large corpora of text annotated with part of speech information are also available (such as the British National Corpus).", "labels": [], "entities": [{"text": "British National Corpus)", "start_pos": 96, "end_pos": 120, "type": "DATASET", "confidence": 0.9197619259357452}]}, {"text": "However, it is much harder to find widely available, large corpora annotated for syntactic or semantic structure.", "labels": [], "entities": [{"text": "syntactic or semantic structure", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.6093253642320633}]}, {"text": "The Penn Treebank () has until recently been the only such corpus, covering 4.5M words in a single genre of financial reporting.", "labels": [], "entities": [{"text": "Penn Treebank ()", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9899813930193583}]}, {"text": "At the same time, the accuracy and speed of syntactic parsers has been improving greatly, so that in recent years it has become possible to automatically create parsed corpora of reasonable quality, using much larger amounts of text with greater genre variation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.999371349811554}]}, {"text": "For many NLP tasks, having more training data greatly improves the quality of the resulting models (), even if the training data are not perfect.", "labels": [], "entities": []}, {"text": "We have access to the entire English-language text of Wikipedia (about 2M pages) that was parsed using the XLE parser (), as well as an architecture for distributed datamining within this corpus, called Oceanography.", "labels": [], "entities": []}, {"text": "Using the parsed corpus, we extract a large volume of dependency relations and derive lexical models that significantly improve a rule-based system for determining the underlying argument structure of deverbal noun constructions.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of the current and experimental argument mappings, we extracted a random set of 1000 sentences from the parsed Wikipedia corpus in which a deverbal noun had a single possessive argument.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 139, "end_pos": 155, "type": "DATASET", "confidence": 0.8733421862125397}]}, {"text": "Each sentence was manually annotated with the verb role mapping between the deverbal and the possessive arguments.", "labels": [], "entities": []}, {"text": "The distribution of annotations is summarized in.", "labels": [], "entities": []}, {"text": "For possessive arguments, the prevalent role was subject, and for 'of' arguments it was object.", "labels": [], "entities": []}, {"text": "The defaults will correctly assign the majority of arguments roles.: Evaluation Role Judgements, with defaults in bold  The base system against which we compare these models uses the output of the parser, identifies deverbal nouns and their arguments, and applies the heuristics described in Section 2.1 to obtain verb roles.", "labels": [], "entities": [{"text": "Evaluation Role Judgements", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.6254502832889557}]}, {"text": "Recall that possessive arguments of transitive deverbals map to the subject role, and 'of' arguments map to object.", "labels": [], "entities": []}, {"text": "Also recall that these rules apply only to eventive deverbals; mapping rules for known agentive and patient-like deverbals remain as before.", "labels": [], "entities": []}, {"text": "In the evaluation, the experimental models take precedence: if the model predicts an outcome, it is used.", "labels": [], "entities": []}, {"text": "The default system behavior is used as a fallback when the model does not have sufficient evidence to make a prediction.", "labels": [], "entities": []}, {"text": "This stacking of models allows the use of corpus evidence when available, and generalized defaults otherwise.", "labels": [], "entities": []}, {"text": "For the animacy model, we used our full system to detect whether the argument of a deverbal was animate (more precisely, human).", "labels": [], "entities": []}, {"text": "In addition to the animate pronouns used to generate the model, we also considered person names, as well as common nouns that had the hypernym 'person' in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 155, "end_pos": 162, "type": "DATASET", "confidence": 0.9568617343902588}]}, {"text": "If the argument was animate and the model had a prediction, that was used.", "labels": [], "entities": []}, {"text": "If no prediction was available for animate arguments, then the inanimate prediction was used.", "labels": [], "entities": []}, {"text": "Failing that, the prediction falls back to the general defaults.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. For possessive arguments, the preva- lent role was subject, and for 'of' arguments it was  object.", "labels": [], "entities": []}, {"text": " Table 1: Evaluation Role Judgements, with de- faults in bold", "labels": [], "entities": [{"text": "Evaluation Role Judgements", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7022962768872579}]}, {"text": " Table 5: Performance on deverbal nouns with one  possessive argument", "labels": [], "entities": []}, {"text": " Table 6: Performance on deverbal nouns with one  'of' argument", "labels": [], "entities": []}]}