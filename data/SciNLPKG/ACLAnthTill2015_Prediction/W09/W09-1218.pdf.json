{"title": [{"text": "Multilingual Syntactic-Semantic Dependency Parsing with Three-Stage Approximate Max-Margin Linear Models", "labels": [], "entities": [{"text": "Multilingual Syntactic-Semantic Dependency Parsing", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.483951136469841}]}], "abstractContent": [{"text": "This paper describes a system for syntactic-semantic dependency parsing for multiple languages.", "labels": [], "entities": [{"text": "syntactic-semantic dependency parsing", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.6888004541397095}]}, {"text": "The system consists of three parts: a state-of-the-art higher-order projective dependency parser for syntactic dependency parsing , a predicate classifier, and an argument classifier for semantic dependency parsing.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 101, "end_pos": 129, "type": "TASK", "confidence": 0.688611368338267}, {"text": "semantic dependency parsing", "start_pos": 187, "end_pos": 214, "type": "TASK", "confidence": 0.639275312423706}]}, {"text": "For semantic dependency parsing, we explore use of global features.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.7632350325584412}]}, {"text": "All components are trained with an approximate max-margin learning algorithm.", "labels": [], "entities": []}, {"text": "In the closed challenge of the CoNLL-2009 Shared Task (Haji\u010d et al., 2009), our system achieved the 3rd best performances for En-glish and Czech, and the 4th best performance for Japanese.", "labels": [], "entities": [{"text": "CoNLL-2009 Shared Task (Haji\u010d et al., 2009)", "start_pos": 31, "end_pos": 74, "type": "DATASET", "confidence": 0.8059049606323242}]}], "introductionContent": [{"text": "In recent years, joint inference of syntactic and semantic dependencies has attracted attention in NLP communities.", "labels": [], "entities": []}, {"text": "Ideally, we would like to choose the most plausible syntactic-semantic structure among all possible structures in that syntactic dependencies and semantic dependencies are correlated.", "labels": [], "entities": []}, {"text": "However, solving this problem is too difficult because the search space of the problem is extremely large.", "labels": [], "entities": []}, {"text": "Therefore we focus on improving performance for each subproblem: dependency parsing and semantic role labeling.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.8646149933338165}, {"text": "semantic role labeling", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7082961797714233}]}, {"text": "In the past few years, research investigating higher-order dependency parsing algorithms has found its superiority to first-order parsing algorithms.", "labels": [], "entities": [{"text": "higher-order dependency parsing", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6131579478581747}]}, {"text": "To reap the benefits of these advances, we use a higher-order projective dependency parsing algorithm which is an extension of the span-based parsing algorithm, for syntactic dependency parsing.", "labels": [], "entities": [{"text": "projective dependency parsing", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.6805858810742696}, {"text": "syntactic dependency parsing", "start_pos": 165, "end_pos": 193, "type": "TASK", "confidence": 0.7133422692616781}]}, {"text": "In terms of semantic role labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.6286995609601339}]}, {"text": "Previous research dealt with such information using re-ranking (.", "labels": [], "entities": []}, {"text": "We explore a different approach to deal with such information using global features.", "labels": [], "entities": []}, {"text": "Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling ( and dependency parsing) with a great deal of success.", "labels": [], "entities": [{"text": "structured prediction problem", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.7927305301030477}, {"text": "sequential labeling", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7462731599807739}, {"text": "dependency parsing", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7524082660675049}]}, {"text": "We attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.853575199842453}]}, {"text": "We present an approximate max-margin learning algorithm for argument classifiers with global features.", "labels": [], "entities": []}], "datasetContent": [{"text": "In terms of the argument classifier, since N-best generation time account fora substantial proportion of the training time (in this work N = 100), chang-   ing N affects the training and evaluation times significantly.", "labels": [], "entities": []}, {"text": "All modules of our system are implemented in Java.", "labels": [], "entities": []}, {"text": "The required memory spaces shown in and 5 are calculated by subtracting free memory size from the total memory size of the Java VM.", "labels": [], "entities": []}, {"text": "Note that we observed that the value fluctuated drastically while measuring memory usage, so the value may not indicate precise memory requirements of our system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Scores of our system.", "labels": [], "entities": [{"text": "Scores", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9798974394798279}]}, {"text": " Table 3: Effect of global features (semantic labeled F1).  \u2206P and \u2206R denote the differentials of labeled precision  and labeled recall between F L and F L +F G respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.8960527181625366}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.7109299898147583}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.7246419191360474}]}, {"text": " Table 4: Training, evaluation time and memory require- ments of the second-order dependency parsers. The 'iter'  column denote the number of iterations of the model  used for the evaluations. Catalan, Czech and English  are trained on Xeon 3.0GHz, Chinese and Japanese are  trained on Xeon 2.66GHz, German and Spanish are  trained on Opteron 2.3GHz machines.", "labels": [], "entities": [{"text": "memory", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9859778881072998}]}, {"text": " Table 5: Training, evaluation time and memory require- ments of the global argument classifiers. The classifiers  are all trained on Opteron 2.3GHz machines.", "labels": [], "entities": [{"text": "memory", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.995973527431488}]}]}