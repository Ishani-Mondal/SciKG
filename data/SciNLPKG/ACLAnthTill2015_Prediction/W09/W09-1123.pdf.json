{"title": [{"text": "Improving Text Classification by a Sense Spectrum Approach to Term Expansion", "labels": [], "entities": [{"text": "Improving Text Classification", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9125444491704305}, {"text": "Term Expansion", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.6888142228126526}]}], "abstractContent": [{"text": "Experimenting with different mathematical objects for text representation is an important step of building text classification models.", "labels": [], "entities": [{"text": "text representation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.809716135263443}, {"text": "text classification", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.713528960943222}]}, {"text": "In order to be efficient, such objects of a formal model, like vectors, have to reasonably reproduce language-related phenomena such as word meaning inherent in index terms.", "labels": [], "entities": []}, {"text": "We introduce an algorithm for sense-based semantic ordering of index terms which approximates Cruse's description of a sense spectrum.", "labels": [], "entities": [{"text": "sense-based semantic ordering of index terms", "start_pos": 30, "end_pos": 74, "type": "TASK", "confidence": 0.7531046122312546}]}, {"text": "Following semantic ordering, text classification by support vector machines can benefit from semantic smoothing kernels that regard semantic relations among index terms while computing document similarity.", "labels": [], "entities": [{"text": "text classification", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7404960542917252}]}, {"text": "Adding expansion terms to the vector representation can also improve effectiveness.", "labels": [], "entities": []}, {"text": "This paper proposes anew kernel which discounts less important expansion terms based on lexical re-latedness.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generally, building an automated text classification system consists of two key subtasks.", "labels": [], "entities": [{"text": "text classification system", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.7633416851361593}]}, {"text": "The first task is text representation which converts the content of documents into compact format so that they can be further processed by the text classifiers.", "labels": [], "entities": [{"text": "text representation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7445798218250275}]}, {"text": "Another task is to learn the model of a text classifier which is used to classify the unlabeled documents.", "labels": [], "entities": []}, {"text": "This paper proposes a substantially new model for text representation to improve effectiveness of text classification by semantic ordering.", "labels": [], "entities": [{"text": "text representation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7838704288005829}, {"text": "text classification", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7170241326093674}]}, {"text": "Our motivation for the research presented here came from) who demonstrated the viability of database searching by visible light using a quantum algorithm, albeit on meaningless items.", "labels": [], "entities": [{"text": "database searching", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.809288740158081}]}, {"text": "The question was, what kind of document representation would be necessary to extend their in-principle results to include semantics, one that has been leading us to test both periodic and nonperiodic functions for this purpose.", "labels": [], "entities": []}, {"text": "Since representation and retrieval by colors was implied in their method, we speculated that the following components could be useful in a rephrased model: (a) a metaphorically presented spectral expression of lexical semantic phenomena, (b) a ranked onedimensional condensate of multidimensional sense structure, and (c) representation of documents and queries by functions in L 2 space with a similarity measure.", "labels": [], "entities": []}, {"text": "Our anticipation was that by matching these components, anew model could demonstrate new capacities in general, and contribute to computing meaning by waves in particular.", "labels": [], "entities": []}, {"text": "Semantic ordering (component b) is an approximation of what) referred to as a sense spectrum, i.e. a series of points -called local senses and constituting lexical units -, in a one-dimensional semantic continuum (component a).", "labels": [], "entities": []}, {"text": "Apart from differentiating between the conceptual content of the same word in terms of its senses in word pairs, i.e. their semantic relatedness, it also compresses the result in spectral form.", "labels": [], "entities": []}, {"text": "The scalar values of this spectrum have the double potential of being a condensed measure for semantic weighting, and, tentatively, they can play the role of mass in experiments where gravity is called in as a metaphor for text categorization and information retrieval.", "labels": [], "entities": [{"text": "semantic weighting", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7821846008300781}, {"text": "information retrieval", "start_pos": 247, "end_pos": 268, "type": "TASK", "confidence": 0.7819039821624756}]}, {"text": "183 This paper addresses text categorization by means of non-periodical functions only.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.8011125326156616}]}, {"text": "In support of Cruse's point, recently it has been demonstrated by measurements that sense classification errors made by their maximum entropy based word sense disambiguation system were partly remedied once instead of a fine-grained view, a more coarse-grained view of senses was adopted ().", "labels": [], "entities": [{"text": "sense classification", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.6449532359838486}]}, {"text": "Improvement of sense classification accuracy linked with \"zooming out\" in terms of observation granularity indicates, in our eyes, the \"fluid\", perhaps spectral nature of sense inasmuch as it is impossible to precisely distinguish between the borderlines and some fuzziness is implied both in the phenomenon and its perception.", "labels": [], "entities": [{"text": "sense classification", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.6572147607803345}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9454493522644043}]}, {"text": "We approach our problem in three steps: (1) whether distributional semantics alone is enough for the representation of word meaning, (2) whether semantic relatedness between word pairs can be expressed in an ordered form while preserving lexical field structure, and if (3) the uniqueness of entries in such an order can be expressed by functions rather than scalars such as distance.", "labels": [], "entities": []}, {"text": "As we will show, this line of thought leads to performance improvement in text classification by using kernel-based feature weighting.", "labels": [], "entities": [{"text": "text classification", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.813702255487442}]}, {"text": "Since the early days of the vector space model, it has been debated whether it is a proper carrier of meaning of texts (, arguing if distributional similarity is an adequate proxy for lexical semantic relatedness).", "labels": [], "entities": []}, {"text": "We argue for the need to enrich distributional semantics-based text representation by other components because with the statistical, i.e. devoid of word semantics approaches there is generally noway to improve both precision and recall at the same time, increasing one is done at the expense of the other.", "labels": [], "entities": [{"text": "distributional semantics-based text representation", "start_pos": 32, "end_pos": 82, "type": "TASK", "confidence": 0.6380336731672287}, {"text": "precision", "start_pos": 215, "end_pos": 224, "type": "METRIC", "confidence": 0.9986127614974976}, {"text": "recall", "start_pos": 229, "end_pos": 235, "type": "METRIC", "confidence": 0.9952730536460876}]}, {"text": "For example, casting a wider net of search terms to improve recall of relevant items will also bring in an even greater proportion of irrelevant items, lowering precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.994358479976654}, {"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9987539052963257}]}, {"text": "In the meantime, practical approaches have been proliferating, especially with developments in kernel methods in the last decade).", "labels": [], "entities": []}, {"text": "Some researchers suggested a more general mathematical framework to accommodate the needs that the vector space model cannot satisfy (van).", "labels": [], "entities": []}, {"text": "This paper explores the opportunities of this representation in the domain of text classification by introducing it as anew nonlinear semantic kernel.", "labels": [], "entities": [{"text": "text classification", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7269209921360016}]}, {"text": "Another aspect of the same problem is term expansion for document classification and retrieval.", "labels": [], "entities": [{"text": "term expansion", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7069768905639648}, {"text": "document classification", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7466232180595398}]}, {"text": "By automatically selecting expansion terms fora text classification system to expand a document vector by adding terms that are related to the terms already in the document, performance can be improved (.", "labels": [], "entities": []}, {"text": "Such new terms can either be statistically related to the original terms or chosen from lexical resources such as thesauri, controlled vocabularies, ontologies and the like.", "labels": [], "entities": []}, {"text": "However, in doing so the fundamental question often overlooked is whether the expansion terms extracted are equally related to the document and are useful for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.8395695090293884}]}, {"text": "In what follows we propose a form of term expansion with decreasing importance of those terms that are less related, as contrasted with rigid term expansion.", "labels": [], "entities": [{"text": "term expansion", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.6775899976491928}, {"text": "rigid term expansion", "start_pos": 136, "end_pos": 156, "type": "TASK", "confidence": 0.7003008325894674}]}, {"text": "This can be carried out by a combination of semantic ordering and using function space for classification.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 overviews text classification by support vector machines, expanding on traditional text similarity measures (Section 2.1), semantic smoothing kernels (Section 2.2), term expansion strategies (Section 2.3), and finally introduces our semantic kernels in the L 2 space (Section 2.4).", "labels": [], "entities": [{"text": "text classification", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7733174860477448}]}, {"text": "Section 3 discusses experimental results and Section 4 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The most widely used benchmark corpus is the Reuters-21578 collection.", "labels": [], "entities": [{"text": "Reuters-21578 collection", "start_pos": 45, "end_pos": 69, "type": "DATASET", "confidence": 0.9766559302806854}]}, {"text": "For benchmarking purposes, the ModApte split was adopted.", "labels": [], "entities": [{"text": "ModApte split", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9122731387615204}]}, {"text": "9603 documents were used as the training set and 3299 as the test set in the experiments.", "labels": [], "entities": []}, {"text": "Only those ninety text categories which had at least one positive example in the training set were included in the benchmark.", "labels": [], "entities": []}, {"text": "Another benchmark data corpus we used was the 20 188 Newsgroups corpus, which is a collection of approximate 20,000 newsgroup documents nearly evenly divided among 20 discussion groups and each document is labeled as one of the 20 categories corresponding to the name of the newsgroup that the document was posted to.", "labels": [], "entities": [{"text": "20 188 Newsgroups corpus", "start_pos": 46, "end_pos": 70, "type": "DATASET", "confidence": 0.6550392508506775}]}, {"text": "In preparing the index terms, we restricted the vocabulary to the terms of WordNet 3.0 in order to be able to calculate the similarity score between any two terms.", "labels": [], "entities": [{"text": "WordNet 3.0", "start_pos": 75, "end_pos": 86, "type": "DATASET", "confidence": 0.9481419324874878}, {"text": "similarity score", "start_pos": 124, "end_pos": 140, "type": "METRIC", "confidence": 0.9643305242061615}]}, {"text": "Stop words were removed in advance.", "labels": [], "entities": []}, {"text": "Multiple word expressions were used to fully utilize WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9679903388023376}]}, {"text": "We used the built-in stemmer of WordNet, which is able to distinguish between different partsof-speeches if the form of the word is unambiguous.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.9550597667694092}]}, {"text": "For example, {accommodates, accommodated, accommodation} was stemmed to {accommodate, accommodate, accommodation}.", "labels": [], "entities": []}, {"text": "We used term frequency as term weighting.", "labels": [], "entities": []}, {"text": "Prior to the semantic ordering, terms were assumed to be in alphabetic order.", "labels": [], "entities": []}, {"text": "Measuring the Jiang-Conrath distance between adjacent terms, the average distance was 1.68 on the Reuters corpus.", "labels": [], "entities": [{"text": "Reuters corpus", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.9762574434280396}]}, {"text": "Note that the Jiang-Conrath distance was normalized to the interval.", "labels": [], "entities": []}, {"text": "There were few terms with zero or little distance between them.", "labels": [], "entities": []}, {"text": "This is due to terms which are related and start with the same word or stem.", "labels": [], "entities": []}, {"text": "For example, account, account executive, account for, accountable.", "labels": [], "entities": []}, {"text": "The same average distance after reordering the terms with the proposed algorithm and the JiangConrath distance was 0.56 on the same corpus.", "labels": [], "entities": [{"text": "JiangConrath distance", "start_pos": 89, "end_pos": 110, "type": "METRIC", "confidence": 0.6172227561473846}]}, {"text": "About one third of the terms had very little distance between each other.", "labels": [], "entities": []}, {"text": "Nevertheless, over 10 % of the total terms still had the maximum distance.", "labels": [], "entities": [{"text": "distance", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.8904837369918823}]}, {"text": "This is due to the non-optimal nature of the proposed termordering algorithm.", "labels": [], "entities": []}, {"text": "These terms add noise to the classification.", "labels": [], "entities": []}, {"text": "The noisy terms occur typically at the two sides of the scale, that is, the leftmost terms and the rightmost terms.", "labels": [], "entities": []}, {"text": "While it is easy to find close terms in the beginning, as the algorithm proceeds, fewer terms remain in the pool to be chosen.", "labels": [], "entities": []}, {"text": "For instance, brand, brand name, trade name, label are in the 33rd, 34th, 35th and 36th position on the left side counting from the seed respectively, while windy, widespread, willingly, whatsoever, worried, worthwhile close the left side, apparently sharing little in common.", "labels": [], "entities": []}, {"text": "The noise can be reduced by the appropriate choice of the parameter bin exp(\u2212bx 2 ), so that the impact of adjacent but distantly related terms can be minimized.", "labels": [], "entities": []}, {"text": "shows the results on the two benchmark corpora with the baseline linear kernel.", "labels": [], "entities": []}, {"text": "Precision and recall with regard to a class ck , the F 1 score shown is their average.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9995775818824768}, {"text": "F 1 score", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9876919786135355}]}, {"text": "For all the kernels, the results with the best parameter settings are shown.", "labels": [], "entities": []}, {"text": "Polynomial kernels were benchmarked between degrees 2 and 5.", "labels": [], "entities": []}, {"text": "L 2 kernels were benchmarked with width b between 1 and 8, the performance peaking at 4 in all cases.", "labels": [], "entities": [{"text": "width b", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9637424349784851}]}, {"text": "The model is able to outperform the baseline kernels, and the differences in micro-averaged results are statistically significant.", "labels": [], "entities": []}, {"text": "In all cases of the L 2 kernel, the increase of F 1 was due the increase in both precision and recall.", "labels": [], "entities": [{"text": "F 1", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9944368600845337}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.999681830406189}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9983794689178467}]}], "tableCaptions": [{"text": " Table 1: Micro-and macro-average F 1 results", "labels": [], "entities": [{"text": "Micro-and macro-average F 1", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.7321306020021439}]}]}