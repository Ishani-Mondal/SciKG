{"title": [{"text": "A Two-tier User Simulation Model for Reinforcement Learning of Adaptive Referring Expression Generation Policies", "labels": [], "entities": [{"text": "Reinforcement Learning of Adaptive Referring Expression Generation Policies", "start_pos": 37, "end_pos": 112, "type": "TASK", "confidence": 0.8224727362394333}]}], "abstractContent": [{"text": "We present anew two-tier user simulation model for learning adaptive referring expression generation (REG) policies for spoken dialogue systems using reinforcement learning.", "labels": [], "entities": [{"text": "learning adaptive referring expression generation (REG)", "start_pos": 51, "end_pos": 106, "type": "TASK", "confidence": 0.7289612032473087}]}, {"text": "Current user simulation models that are used for dialogue policy learning do not simulate users with different levels of domain expertise and are not responsive to referring expressions used by the system.", "labels": [], "entities": [{"text": "dialogue policy learning", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.9414904713630676}]}, {"text": "The two-tier model displays these features, that are crucial to learning an adaptive REG policy.", "labels": [], "entities": []}, {"text": "We also show that the two-tier model simulates real user behaviour more closely than other baseline models, using the dialogue similarity measure based on Kullback-Leibler divergence.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present anew user simulation model for learning adaptive referring expression generation (REG) policies for spoken dialogue systems using reinforcement learning methods.", "labels": [], "entities": [{"text": "learning adaptive referring expression generation (REG)", "start_pos": 42, "end_pos": 97, "type": "TASK", "confidence": 0.7289560623466969}]}, {"text": "An adaptive REG policy equips a dialogue system to dynamically modify its utterances in order to adapt to user's domain knowledge level.", "labels": [], "entities": []}, {"text": "For instance, to refer to domain objects, the system might use simple descriptive expressions with novices and technical jargon with experts.", "labels": [], "entities": []}, {"text": "Such adaptations help grounding between the dialogue partners.", "labels": [], "entities": []}, {"text": "Since the user's knowledge level is unknown, the system must be able to adapt dynamically during the conversation.", "labels": [], "entities": []}, {"text": "Handcoding such a policy could be extremely difficult.) have shown that such policies can be learned using simulation based reinforcement learning (RL) methods.", "labels": [], "entities": []}, {"text": "The quality of such learned policies is directly dependent on the performance of the user simulations used to train them.", "labels": [], "entities": []}, {"text": "So far, only hand-coded user simulations have been employed.", "labels": [], "entities": []}, {"text": "In contrast, we now present a data driven two-tier user simulation model trained on dialogue data collected from real users.", "labels": [], "entities": []}, {"text": "We also show that the two-tier model simulates real users more faithfully than other data driven baseline n-gram models ().", "labels": [], "entities": []}, {"text": "In section 2 we briefly discuss other work related to user simulations for dialogue policy learning using RL.", "labels": [], "entities": [{"text": "dialogue policy learning", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.8953875700632731}]}, {"text": "In section 3 we describe the data used to build the simulation.", "labels": [], "entities": []}, {"text": "Section 4 describes the simulation models in detail.", "labels": [], "entities": []}, {"text": "In section 5 and 6 we present the evaluation metrics used and the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "While there are many proposed measures to rank user simulation models with respect to real user data (, we use the Dialogue Similarity measure based on Kullback-Leibler (KL) () divergence to measure how similar the probability distributions of the simulation models are to the original real human data.", "labels": [], "entities": []}, {"text": "We consider the Advanced N-gram model to be a realistic model of the real human dialogue corpus, as it takes into account all context variables and is reasonably smoothed to account for unobserved user responses.", "labels": [], "entities": []}, {"text": "Therefore, we compare the probability distributions of all the other models to The results show that the two-tier model is much closer (0.078, 0.018) to the Advanced Ngram model than the other models.", "labels": [], "entities": []}, {"text": "This is due to the fact that the bigram and trigram models don't take into account factors like the user's knowledge, the strategy used, and the dialogue history.", "labels": [], "entities": []}, {"text": "By effectively dividing the RE processing and the environment interaction, the two-tier simulation model is not only realistic in observed contexts but also usable in unobserved contexts (unlike the Advanced N-gram model).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dialogue Similarity with Modified  Witten-Bell discounting w.r.t Advanced N-gram  model", "labels": [], "entities": []}]}