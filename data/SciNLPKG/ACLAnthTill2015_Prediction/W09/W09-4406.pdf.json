{"title": [], "abstractContent": [{"text": "In this paper we report on the performance of different learning algorithms and different sampling technique applied to a definition extraction task, using data sets in different language.", "labels": [], "entities": [{"text": "definition extraction task", "start_pos": 122, "end_pos": 148, "type": "TASK", "confidence": 0.9203169544537863}]}, {"text": "We compare our results with those obtained by hand-crafted rules to extract definitions.", "labels": [], "entities": []}, {"text": "When Definition Extraction is handled with machine learning algorithms, two different issues arise.", "labels": [], "entities": [{"text": "Definition Extraction", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.9470934867858887}]}, {"text": "On the one hand, inmost cases the data set used to extract definitions is unbalanced, and this means that it is necessary to deal with this characteristic with specific techniques.", "labels": [], "entities": []}, {"text": "On the other hand it is possible to use the same methods to extract definitions from documents in different corpus, making the classifier language independent.", "labels": [], "entities": []}], "introductionContent": [{"text": "According to Aristotle, the formal structure of a definition should resemble an equation with the definiendum (what is to be defined) on the left hand side and the definiens (the part which is doing the defining) on the right hand side.", "labels": [], "entities": []}, {"text": "The definiens should consist of two parts: the genus (the nearest superior concept) and the differentiae specificae (the distinguishing characteristics).", "labels": [], "entities": []}, {"text": "In this way, definitions would adequately capture the concept to be defined.", "labels": [], "entities": []}, {"text": "In Hebenstreit, two more types of definition are pointed out.", "labels": [], "entities": [{"text": "Hebenstreit", "start_pos": 3, "end_pos": 14, "type": "DATASET", "confidence": 0.8871130347251892}]}, {"text": "Firstly, the definition by enumeration of the concept species on the same level of abstraction (extensional definition), e.g. a chess piece is a king, a queen, a bishop, a knight, a rook or a pawn.", "labels": [], "entities": []}, {"text": "Secondly, the definition by enumeration of the parts of the concept (partitive definition), e.g. the solar system is made of the planets Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto.", "labels": [], "entities": []}, {"text": "Barnbrook identifies 16 different types of definitions analysing dictionary entries.", "labels": [], "entities": []}, {"text": "In spite of the richness of this classification, in automatic definition extraction application only the simplest type is taken in consideration, that is a sentence composed by a subject, a copular verb and a predicative phrase.", "labels": [], "entities": [{"text": "definition extraction", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7475095391273499}]}, {"text": "In this paper a definition is a sentence containing an expression (the definiendum) and its definition (the definiens) connected by the verb \"to be\".", "labels": [], "entities": []}, {"text": "Two different approaches are possible when dealing with automatic definition extraction.", "labels": [], "entities": [{"text": "automatic definition extraction", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.6775139570236206}]}, {"text": "The first one consists in building a system of rules, based on lexical and syntactic clues.", "labels": [], "entities": []}, {"text": "The second one is to consider the task as a classification problem, where for each sentence in the corpus it is possible to assign the correct class.", "labels": [], "entities": []}, {"text": "The problem of the first approach is that it is language dependent, and in case of a large use of lexical clues, the performance on different corpus get worst.", "labels": [], "entities": []}, {"text": "In the case of classification approach one of the main issue to be dealt with is the sparseness of definitions in a corpus.", "labels": [], "entities": []}, {"text": "It is a matter of fact that the number of definition bearing sentences is much lesser than the number of sentences that are not definitions.", "labels": [], "entities": []}, {"text": "This configuration gives rise to an imbalanced data set, which may present different degrees of imbalance, depending on the corpus used.", "labels": [], "entities": []}, {"text": "For corpus composed mostly by encyclopedic documents it is likely to get a balanced data set.", "labels": [], "entities": []}, {"text": "For example used a balanced corpus where the definition-bearing sentences represent 59% of the whole corpus, while using a corpus consisting of encyclopedic text and web documents reports that only 18% of the sentences were definitions.", "labels": [], "entities": []}, {"text": "In this work we deal with the problem of imbalanced data sets in definition extraction tasks in a language independent way.", "labels": [], "entities": [{"text": "definition extraction tasks", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.8969982266426086}]}, {"text": "We show not only that sampling techniques can improve the performance of classifiers but also that this improvement is language independent.", "labels": [], "entities": []}, {"text": "Other researches using learning algorithms relay strongly on lexical and syntactic components as features to describe the data set.", "labels": [], "entities": []}, {"text": "These kinds of features are not only language dependent but also domain dependent, and as we want our classifier to be as general as possible we select the most basic features, that is n-grams of part of speech (POS).", "labels": [], "entities": []}, {"text": "This makes the present approach viable for all those languages that are not equipped with rich lexical resources as learning data or in a situation where the domain is too specific to benefit from such resources, and moves away from previous works that use features such as words, word lemmas, position of the sentence in the document he document, etc.", "labels": [], "entities": []}, {"text": "In this paper we apply the same techniques we applied to a Portuguese Corpus in a previous experiment to a corpus in Dutch and compare results.", "labels": [], "entities": [{"text": "Portuguese Corpus", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.8314679265022278}]}, {"text": "Our task handles several aspects that are common to different machine learning tasks in NLP application: small amounts of data, inherent ambiguity (definition detection is sometimes a matter of judgment), noisy data (human annotators make mistakes), imbalanced class distribution, this last aspect being the main issue addressed in this paper.", "labels": [], "entities": [{"text": "definition detection", "start_pos": 148, "end_pos": 168, "type": "TASK", "confidence": 0.7089419960975647}]}], "datasetContent": [{"text": "One of the most used metric is the Error Rate, defined as 1.0-(True Positive+True Negative)/(True PositiveFalse Positive+False Negative+True Negative).", "labels": [], "entities": [{"text": "Error Rate", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9859069585800171}]}, {"text": "However using this metric implies that the class distribution is known and fixed, an assumption that does not hold in real world applications as the one proposed here.", "labels": [], "entities": []}, {"text": "Moreover, Error Rate is biased to favor the majority class, making it a bad choice when evaluating the effects of class distribution.", "labels": [], "entities": [{"text": "Error Rate", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9850175678730011}]}, {"text": "Other aspect against the use of Error Rate is that it considers different classification errors as equally important, and in domains such medical diagnosis, the error of diagnosing a sick patience as healthy is a fatal error while the contrary is considered a much less serious error.", "labels": [], "entities": [{"text": "Error Rate", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9768684506416321}]}, {"text": "This means that a metric such as Error Rate is sensitive to class imbalance.", "labels": [], "entities": [{"text": "Error Rate", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9877490699291229}]}, {"text": "It is possible to derive metrics that are not sensitive to the skew of the data.", "labels": [], "entities": []}, {"text": "In particular, four metrics are proposed in: A good classifier should try to minimize FN and FP rates, and maximize TN and TP rates.", "labels": [], "entities": [{"text": "FN and FP rates", "start_pos": 86, "end_pos": 101, "type": "METRIC", "confidence": 0.7873803377151489}, {"text": "TN and TP rates", "start_pos": 116, "end_pos": 131, "type": "METRIC", "confidence": 0.6853435337543488}]}, {"text": "Unfortunately, there is a tradeoff between these two metrics, and in order to analyze this relationship ROC graphs are used.", "labels": [], "entities": []}, {"text": "ROC graphs are two-dimensional graphs where TP rate is plotted on the Y axis and FP rate is plotted on the X axis.", "labels": [], "entities": [{"text": "TP rate", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9478140771389008}, {"text": "FP rate", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.98943230509758}]}, {"text": "ROC graphs are consistent fora given problem even if the distribution of positive and negative instances is highly skewed.", "labels": [], "entities": []}, {"text": "It is important to notice that the lower left point (0, 0) represents the strategy of never issuing a positive classification: such a classifier produces no false positive errors but also gains no true positives.", "labels": [], "entities": []}, {"text": "The opposite strategy, of unconditionally issuing positive classifications, is represented by the upper right point.", "labels": [], "entities": [{"text": "issuing positive classifications", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.6729545195897421}]}, {"text": "In order to compare classifiers, it is possible to reduce a ROC curve to a scalar value representing the performance of the classifier.", "labels": [], "entities": [{"text": "ROC curve", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9333480596542358}]}, {"text": "Area Under the ROC (AUC) is a portion of the area of the unit square.", "labels": [], "entities": [{"text": "Area Under the ROC (AUC)", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.595535472035408}]}, {"text": "Its value will always be between 0 and 1.", "labels": [], "entities": []}, {"text": "However, because random guessing produces the diagonal line between(0,0) and(1,1), which has an area of 0.5, no realistic classier should have an AUC less than 0.5.", "labels": [], "entities": [{"text": "AUC", "start_pos": 146, "end_pos": 149, "type": "METRIC", "confidence": 0.9555199146270752}]}, {"text": "The AUC is equivalent to the Wilcoxon test of ranks and it is also related to Gini coefficient (for an exhaustive description of ROC and AUC in assessing machine learning algorithms see) . In this work, we will use the AUC measure in order to assess the performance of classifiers.", "labels": [], "entities": [{"text": "AUC", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8010282516479492}, {"text": "Gini coefficient", "start_pos": 78, "end_pos": 94, "type": "METRIC", "confidence": 0.9650701880455017}, {"text": "ROC", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.8950272798538208}, {"text": "AUC measure", "start_pos": 219, "end_pos": 230, "type": "METRIC", "confidence": 0.8861694931983948}]}, {"text": "Furthermore, for each classifier, we present also the F-measure in order to compare our results to previous works in this area.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9924370646476746}]}, {"text": "F-measure is a combination of Recall and Precision metrics: F \u2212 measure = 2 * P recision * Recall (P recision+Recall)", "labels": [], "entities": [{"text": "F \u2212 measure", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9285291830698649}]}], "tableCaptions": [{"text": " Table 1: Results using k-NN algorithm with k=1", "labels": [], "entities": []}, {"text": " Table 2: Results using k-NN algorithm with k=3", "labels": [], "entities": []}, {"text": " Table 3: Results using C4.5 algorithm", "labels": [], "entities": []}, {"text": " Table 4: Results using Random Forest algorithm", "labels": [], "entities": []}, {"text": " Table 5: Results using SVM algorithm", "labels": [], "entities": []}, {"text": " Table 6: Results using Na\u00a8\u0131veNa\u00a8\u0131ve Bayes", "labels": [], "entities": [{"text": "\u00a8\u0131veNa\u00a8\u0131ve Bayes", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.7451445281505584}]}]}