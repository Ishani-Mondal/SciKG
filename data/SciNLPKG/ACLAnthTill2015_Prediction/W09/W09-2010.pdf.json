{"title": [{"text": "An Unsupervised Model for Text Message Normalization", "labels": [], "entities": [{"text": "Text Message Normalization", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.7151506145795187}]}], "abstractContent": [{"text": "Cell phone text messaging users express themselves briefly and colloquially using a variety of creative forms.", "labels": [], "entities": []}, {"text": "We analyze a sample of creative , non-standard text message word forms to determine frequent word formation processes in texting language.", "labels": [], "entities": []}, {"text": "Drawing on these observations, we construct an unsupervised noisy-channel model for text message normal-ization.", "labels": [], "entities": []}, {"text": "On a test set of 303 text message forms that differ from their standard form, our model achieves 59% accuracy, which is on par with the best supervised results reported on this dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.999627947807312}]}], "introductionContent": [], "datasetContent": [{"text": "We use the data provided by which consists of texting forms-extracted from a collection of 900 text messages-and their manually determined standard forms.", "labels": [], "entities": []}, {"text": "Our development data-used for model development and discussed in Section 2-consists of the 400 texting form types that are not in Choudhury et al.'s held-out test set, and that are not the same as one of their standard forms.", "labels": [], "entities": [{"text": "model development", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7078771740198135}]}, {"text": "The test data consists of 1213 texting forms and their corresponding standard forms.", "labels": [], "entities": []}, {"text": "A subset of 303 of these texting forms differ from their standard form.", "labels": [], "entities": []}, {"text": "This subset is the focus of this study, but we also report results on the full dataset.", "labels": [], "entities": []}, {"text": "To evaluate our system, we consider three accuracy metrics: in-top-1, in-top-10, and in-top-20.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9992378950119019}]}, {"text": "Intop-n considers the system correct if a correct standard form is in then most probable standard forms.", "labels": [], "entities": []}, {"text": "The in-top-1 accuracy shows how well the system determines the correct standard form; the in-top-10  and in-top-20 accuracies maybe indicative of the usefulness of the output of our system in other tasks which could exploit a ranked list of standard forms, such as machine translation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9847914576530457}, {"text": "machine translation", "start_pos": 265, "end_pos": 284, "type": "TASK", "confidence": 0.8003469705581665}]}], "tableCaptions": [{"text": " Table 3: % in-top-1, in-top-10, and in-top-20 accuracy  on test data using both estimates for P (wf ). The results  reported by Choudhury et al. (2007) are also shown.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.997631311416626}, {"text": "P", "start_pos": 95, "end_pos": 96, "type": "METRIC", "confidence": 0.986250638961792}]}]}