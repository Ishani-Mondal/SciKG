{"title": [{"text": "Integrating High Precision Rules with Statistical Sequence Classifiers for Accuracy and Speed", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9980097413063049}]}], "abstractContent": [{"text": "Integrating rules and statistical systems is a challenge often faced by natural language processing system builders.", "labels": [], "entities": []}, {"text": "A common sub-class is integrating high precision rules with a Markov statistical sequence classifier.", "labels": [], "entities": []}, {"text": "In this paper we suggest that using such rules to constrain the sequence classifier decoder results in superior accuracy and efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9988262057304382}]}, {"text": "Ina case study of a named entity tagging system, we provide evidence that this method of combination does prove efficient than other methods.", "labels": [], "entities": [{"text": "named entity tagging", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7325119376182556}]}, {"text": "The accuracy was the same.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997536540031433}]}], "introductionContent": [{"text": "Sequence classification lies at the core of several natural language processing applications, such as named entity extraction, Asian language segmentation, Germanic language noun decompounding, and event identification.", "labels": [], "entities": [{"text": "Sequence classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9639713764190674}, {"text": "named entity extraction", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.6683360934257507}, {"text": "Asian language segmentation", "start_pos": 127, "end_pos": 154, "type": "TASK", "confidence": 0.6749082108338674}, {"text": "Germanic language noun decompounding", "start_pos": 156, "end_pos": 192, "type": "TASK", "confidence": 0.594245582818985}, {"text": "event identification", "start_pos": 198, "end_pos": 218, "type": "TASK", "confidence": 0.817915290594101}]}, {"text": "Statistical models with a Markov dependency have been successful employed to perform these tasks, e.g., hidden Markov models (HMMs) and conditional random fields (CRFs)().", "labels": [], "entities": []}, {"text": "These statistical systems employ a Viterbi decoder at runtime to efficiently calculate the most likely label sequence based on the observed sequence and model.", "labels": [], "entities": []}, {"text": "Statistical machine translation systems make use of similar decoders.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6315237383047739}]}, {"text": "In many situations it is beneficial, and sometimes required, for these systems to respect constraints from high precision rules.", "labels": [], "entities": []}, {"text": "And thus when building working sequence labeling systems, researchers/software engineers are often faced with the task of combining these two approaches.", "labels": [], "entities": [{"text": "working sequence labeling", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.5812528232733408}]}, {"text": "In this paper we argue fora particular method of combining statistical models with Markov dependencies and high precision rules.", "labels": [], "entities": []}, {"text": "We outline a number of ways to do this and then argue that guiding the decoder of the statistical system has many advantages over other methods of combination.", "labels": [], "entities": []}, {"text": "But first, does the problem of combining multiple approaches really happen?", "labels": [], "entities": []}, {"text": "In our experience the need arises in the following way: a statistical approach with a Markov component is chosen because it has the best precision/recall characteristics and has reasonable speed.", "labels": [], "entities": [{"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9987661838531494}, {"text": "recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9223626852035522}]}, {"text": "However, a number of rules arise for varied reasons.", "labels": [], "entities": []}, {"text": "For example, the customer provides domain knowledge not present in the training data or a particular output characteristic is more important that accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9980831146240234}]}, {"text": "Consider the following fictitious but plausible situation: A named entity tagging system is built using a CRF.", "labels": [], "entities": [{"text": "named entity tagging", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.6795314351717631}]}, {"text": "The customer then provides a number of company names that cannot be missed, i.e., false negatives for these companies are catastrophic but false positives can be tolerated.", "labels": [], "entities": []}, {"text": "In addition, it is known that, unlike in the training data, the runtime data will have a company name immediately before every ticker symbol.", "labels": [], "entities": []}, {"text": "The question facing the builder of the system is how to combine the CRF with rules based on the must-find company list and the company-name-before-every-ticker-symbol fact.", "labels": [], "entities": []}, {"text": "Similar situations arise for the other sequence tagging situations mentioned above and for machine translation.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.7074523121118546}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7793987393379211}]}, {"text": "We suspect that even for non-language applications, such as gene sequence labeling, similar situations arise.", "labels": [], "entities": [{"text": "gene sequence labeling", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6170584658781687}]}, {"text": "In the next section we will discuss a number of methods for combining statistical systems and high precision rules and argue for guiding the decoder of the statistical model.", "labels": [], "entities": []}, {"text": "Then in section 3, we describe an implementation of the approach and give evidence that the speed benefits are substantial.", "labels": [], "entities": [{"text": "speed", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.9859435558319092}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Experiment Results  Database Methods  Precision Recall F1  CoNLL  Baseline  84.38  83.02  83.69  Post-corr  85.87  84.86  85.36  Constr-viti 85.98  85.55  85.76  TF  Baseline  88.39  82.42  85.30  Post-corr  87.69  88.30  87.99  Constr-viti 88.02  88.54  88.28  MUC  Baseline  92.22  88.72  90.43  Post-Corr  91.28  88.87  90.06  Constr-viti 90.86  89.37  90.11  (a)Precision and Recall", "labels": [], "entities": [{"text": "Precision Recall F1  CoNLL  Baseline  84.38  83.02  83.69  Post-corr  85.87  84.86  85.36  Constr-viti 85.98  85.55  85.76  TF  Baseline  88.39  82.42  85.30  Post-corr  87.69  88.30  87.99  Constr-viti 88.02  88.54  88.28", "start_pos": 48, "end_pos": 270, "type": "TASK", "confidence": 0.7860155732467257}, {"text": "MUC  Baseline  92.22  88.72  90.43  Post-Corr  91.28  88.87  90.06  Constr-viti 90.86  89.37  90.11", "start_pos": 272, "end_pos": 371, "type": "DATASET", "confidence": 0.6273038937495306}, {"text": "Recall", "start_pos": 390, "end_pos": 396, "type": "TASK", "confidence": 0.4254797101020813}]}]}