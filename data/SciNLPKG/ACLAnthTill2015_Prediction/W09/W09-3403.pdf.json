{"title": [], "abstractContent": [{"text": "Lexicon is in important resource in any kind of language processing application.", "labels": [], "entities": []}, {"text": "Corpus-based lexica have several advantages over other traditional approaches.", "labels": [], "entities": []}, {"text": "The lexicon developed for Sinhala was based on the text obtained from a corpus of 10 million words drawn from diverse genres.", "labels": [], "entities": []}, {"text": "The words extracted from the corpus have been labeled with parts of speech categories defined according to a novel classification proposed for Sinhala.", "labels": [], "entities": []}, {"text": "The lexicon reports 80% coverage over unrestricted text obtained from online sources.", "labels": [], "entities": [{"text": "coverage", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9903368949890137}]}, {"text": "The lexicon has been implemented in Lexical Mark up Framework .", "labels": [], "entities": []}], "introductionContent": [{"text": "The availability of lexical resources is central to many natural language processing tasks as words play a crucial role in defining higher level constructions such as phrases, clauses and sentences of any language.", "labels": [], "entities": []}, {"text": "The most generic and basic lexical resource for such work is a lexicon, preferably with part of speech annotation and information about possible word forms.", "labels": [], "entities": []}, {"text": "The latter is important especially for morphologically rich languages such as Sinhala.", "labels": [], "entities": []}, {"text": "This kind of resource is extremely useful for part of speech tagging, grammar development and parsing, machine translations, speech processing applications, among others.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7962989211082458}, {"text": "grammar development and parsing", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.7554110586643219}, {"text": "machine translations", "start_pos": 103, "end_pos": 123, "type": "TASK", "confidence": 0.7613778114318848}]}, {"text": "As new knowledge is created, new concepts are introduced to the language in terms of words.", "labels": [], "entities": []}, {"text": "Non-corpus-based lexicon development approaches are not capable of acquiring these new words into lexica due to their inherent limitations such as reliance on introspection and linguistic exposure of the human compiler(s).", "labels": [], "entities": []}, {"text": "Therefore it is essential to adopt less expensive (less time consuming, labor intensive and robust) alternative strategies to develop wide-coverage lexica for less studied languages.", "labels": [], "entities": []}, {"text": "This paper presents a lexicon for Sinhala which has nearly 35,000 entries based on the text drawn from the UCSC Text Corpus of Contemporary Sinhala consisting of 10 million words from diverse genres.", "labels": [], "entities": [{"text": "UCSC Text Corpus of Contemporary Sinhala", "start_pos": 107, "end_pos": 147, "type": "DATASET", "confidence": 0.9501910507678986}]}, {"text": "The corpus-based approach taken in this work can overcome the limitations that traditional approaches suffering from such as less reliance on less expert knowledge, the ability to capture modern usage based on recently introduced words and wide coverage.", "labels": [], "entities": []}, {"text": "The lexical entries defined in this approach are classified according to a novel classification in order to fulfill the requirements of language processing tasks.", "labels": [], "entities": []}, {"text": "The broad classes defined are significantly different from those described in traditional Sinhala grammar.", "labels": [], "entities": []}, {"text": "For declensional classes such as Nouns and Verbs, further subdivisions have been proposed based on their morpho-phonemic features.", "labels": [], "entities": []}, {"text": "Each of the subdivision classes is associated with a set of rules that can be used to generate all possible morphological forms of that group.", "labels": [], "entities": []}, {"text": "This has made a significant contribution to improve the coverage of the lexicon as fora given lexical entry it is hard to guarantee that all possible forms exist in the original corpus.", "labels": [], "entities": []}, {"text": "However, the rules defined in each class guarantee recognize such unseen forms in the test data set.", "labels": [], "entities": []}, {"text": "In addition, a comprehensive set of function words has been defined based on some of the indeclinable classes such as Post-positions, Particles, Determiners, Conjunctions and Interjections.", "labels": [], "entities": []}, {"text": "The lexicon also consists of the most commonly used named entities such as person and city names.", "labels": [], "entities": []}, {"text": "Syllabified phonetic transcriptions of the lexical entries are also incorporated in order to make this resource useful in speech processing applications.", "labels": [], "entities": []}, {"text": "These characteristics are essential in building effective practical natural language processing applications.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first attempt to build a wide coverage lexicon for Sinhala from a computational linguistic perspective reported in the literature.", "labels": [], "entities": []}, {"text": "The rest of the paper describes the work carried out in detail.", "labels": [], "entities": []}, {"text": "Section 2 gives a detailed description of the data acquisition stage, the part of speech categories and the subdivisions based on morphology and the phonetic transcription with syllabification.", "labels": [], "entities": [{"text": "data acquisition", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.72318035364151}]}, {"text": "The implementation details of the lexicon and schemas defined for lexical entries using Lexical Mark up Framework (LMF) is given in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 comments on the results of the experiments conducted to measure the coverage of the lexicon.", "labels": [], "entities": []}, {"text": "Finally, Section 5 discusses the issues and limitations of the current work with insights for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Distribution of Corpus Text  across Genres", "labels": [], "entities": [{"text": "Distribution of Corpus Text", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8614068478345871}]}, {"text": " Table 2. Part of Speech Categories  and their Frequencies", "labels": [], "entities": []}, {"text": " Table 7. Coverage Reported for each  Genre on Un-cleaned and Cleaned Data Sets", "labels": [], "entities": []}, {"text": " Table 9. Different Error Types Distributed  across Three Genres Reported on  Distinct Wordlist (DW) and Full Text (FT)", "labels": [], "entities": []}]}