{"title": [{"text": "Exploring Two Biomedical Text Genres for Disease Recognition", "labels": [], "entities": [{"text": "Disease Recognition", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.713941678404808}]}], "abstractContent": [{"text": "In the framework of contextual information retrieval in the biomedical domain, this paper reports on the automatic detection of disease concepts in two genres of biomedical text: sentences from the literature and PubMed user queries.", "labels": [], "entities": [{"text": "contextual information retrieval", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.6711620489756266}, {"text": "automatic detection of disease concepts", "start_pos": 105, "end_pos": 144, "type": "TASK", "confidence": 0.806624972820282}]}, {"text": "A statistical model and a Natural Language Processing algorithm for disease recognition were applied on both corpora.", "labels": [], "entities": [{"text": "disease recognition", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.703296422958374}]}, {"text": "While both methods show good performance (F=77% vs. F=76%) on the sentence corpus, results on the query corpus indicate that the statistical model is more robust (F=74% vs. F=70%).", "labels": [], "entities": [{"text": "F", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9922542572021484}, {"text": "F", "start_pos": 163, "end_pos": 164, "type": "METRIC", "confidence": 0.9616619348526001}]}], "introductionContent": [{"text": "Contextual Information Retrieval (IR) is making use of additional information or assumptions about the users' needs beyond the obvious intent of the query.", "labels": [], "entities": [{"text": "Contextual Information Retrieval (IR)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7967297534147898}]}, {"text": "IR systems need to go beyond the task of providing generally relevant information by assisting users in finding information that is relevant to them and their specific needs at the time of the search.", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9795547127723694}]}, {"text": "A practical example of a Google contextual IR feature is when the search engine returns a map showing restaurant locations to a user entering a query such as \"Paris restaurants.\"", "labels": [], "entities": []}, {"text": "The contextual aspects of a user's search were defined for example by who discussed integrating the cognitive, affective, and situational levels of human computer interaction in IR systems.", "labels": [], "entities": []}, {"text": "Other research efforts studied users' search behavior based on their level of domain knowledge () or aimed at modeling users' interests and search habits ().", "labels": [], "entities": []}, {"text": "Information about the search context maybe sought explicitly from the user through profiling or relevance feedback).", "labels": [], "entities": []}, {"text": "Recent work also exploited query log analysis and basic computer environment information (), which involve no explicit interaction with the user.", "labels": [], "entities": [{"text": "query log analysis", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.6941909591356913}]}, {"text": "In adaptive information retrieval, context information is inferred based on query analysis and collection characteristics.", "labels": [], "entities": [{"text": "adaptive information retrieval", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.618837962547938}]}, {"text": "In the biomedical domain, a need for contextual information retrieval was identified in particular for clinical queries submitted to PubMed).", "labels": [], "entities": [{"text": "contextual information retrieval", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.6170274217923483}, {"text": "PubMed", "start_pos": 133, "end_pos": 139, "type": "DATASET", "confidence": 0.9213923215866089}]}, {"text": "Building on the idea that a specific type of document is required for searches with a \"clinical\" context, the PubMed Clinical Queries portal was developed (.", "labels": [], "entities": [{"text": "PubMed Clinical Queries portal", "start_pos": 110, "end_pos": 140, "type": "DATASET", "confidence": 0.856694370508194}]}, {"text": "A perhaps more prominent contextual feature of PubMed is the \"citation sensor\", which identifies queries classified by Rose and Levinson as reflecting a \"Navigational\" or \"Obtain resource\" goal.", "labels": [], "entities": []}, {"text": "For example, the citation sensor will identify and retrieve a specific citation if the user enters the article title as the query.", "labels": [], "entities": []}, {"text": "The analysis of Entrez logs shows that MEDLINE is the most popular database among the 30 or so databases maintained by the National Center for Biotechnology Information (NCBI) as it receives most of Entrez traffic.", "labels": [], "entities": [{"text": "Entrez logs", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.7953848838806152}, {"text": "MEDLINE", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.6043822765350342}]}, {"text": "This suggests that there is a need to complement the information retrieved from MEDLINE by giving contextual access to other NCBI resources re-levant to users' queries, such as Entrez Gene, Clinical Q&A or BookShelf.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.8534362316131592}, {"text": "Clinical Q&A", "start_pos": 190, "end_pos": 202, "type": "DATASET", "confidence": 0.8234652578830719}, {"text": "BookShelf", "start_pos": 206, "end_pos": 215, "type": "DATASET", "confidence": 0.7625265717506409}]}, {"text": "In addition, the NLM estimated that about 1/3 of PubMed users are not biomedical professionals.", "labels": [], "entities": []}, {"text": "In this light, providing an access point to consumer information such as the Genetics Home Reference might also be useful.", "labels": [], "entities": [{"text": "Genetics Home Reference", "start_pos": 77, "end_pos": 100, "type": "DATASET", "confidence": 0.8297714392344157}]}, {"text": "To achieve this, the sensor project was recently launched with the goal of recognizing a variety of biomedical concepts (e.g. gene, protein and drug names) in PubMed queries.", "labels": [], "entities": []}, {"text": "These high-level concepts will help characterize users' search context in order to provide them with information related to their need beyond PubMed.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 142, "end_pos": 148, "type": "DATASET", "confidence": 0.9385191202163696}]}, {"text": "For instance, if a user query contains the drug name \"Lipitor\", it will be recognized by the drug sensor and additional information on this drug from Clinical Q&A will be shown in the sidebar in addition to default PubMed results.", "labels": [], "entities": []}, {"text": "Since disease names are common in PubMed queries, the goal of this work is to investigate and benchmark computational techniques for automatic disease name recognition as an aid to implementing PubMed search contexts.", "labels": [], "entities": [{"text": "automatic disease name recognition", "start_pos": 133, "end_pos": 167, "type": "TASK", "confidence": 0.6546643450856209}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Agreement on disease mention annotations  (partial match allowed) -average is 73.10%", "labels": [], "entities": [{"text": "disease mention annotations", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.6674039165178934}, {"text": "average", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.8374723792076111}]}, {"text": " Table 5: Precision (P), Recall (R) and F-measure of the  Priority Model on the training set for different values of  the probability threshold.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9433419704437256}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9644419997930527}, {"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9985111355781555}]}, {"text": " Table 6: performance of the Priority Model on the train- ing set for threshold .3 depending on whether mappings  to Findings are used in the \"adjustments\"", "labels": [], "entities": []}, {"text": " Table 7: Performance of MetaMap on the training set", "labels": [], "entities": []}, {"text": " Table 8: Precision (P), Recall (R) and F-measure of the  Priority Model and MetaMap on the test set", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9433828145265579}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9606233090162277}, {"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9961305856704712}]}, {"text": " Table 9: performance of the Priority Model on the train- ing set for threshold .3 depending on whether mappings  to Findings are used in the \"adjustments\"", "labels": [], "entities": []}, {"text": " Table 10: performance of MetaMap on the training set", "labels": [], "entities": []}, {"text": " Table 11: Precision (P), Recall (R) and F-measure of  the Priority Model and MetaMap on the test set", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 11, "end_pos": 24, "type": "METRIC", "confidence": 0.9454580545425415}, {"text": "Recall (R)", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.961207315325737}, {"text": "F-measure", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9960346817970276}]}]}