{"title": [{"text": "A Discriminative Approach to Tree Alignment", "labels": [], "entities": [{"text": "Tree Alignment", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.7975818514823914}]}], "abstractContent": [{"text": "In this paper we propose a discriminative framework for automatic tree alignment.", "labels": [], "entities": [{"text": "automatic tree alignment", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.6278676788012186}]}, {"text": "We use a rich feature set and a log-linear model trained on small amounts of hand-aligned training data.", "labels": [], "entities": []}, {"text": "We include contextual features and link dependencies to improve the results even further.", "labels": [], "entities": []}, {"text": "We achieve an overall F-score of almost 80% which is significantly better than other scores reported for this task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9996134638786316}]}], "introductionContent": [{"text": "A parallel treebank consists of a collection of sentence pairs that have been grammatically tagged, syntactically annotated and aligned on sub-sentential level.", "labels": [], "entities": []}, {"text": "Large parallel treebanks are much sought after in present-day NLP applications but have been, until recently, only been built by hand and therefore tended to be small and expensive to create.", "labels": [], "entities": []}, {"text": "Some areas of application for parallel treebanks are: \u2022 knowledge source for transfer-rule induction \u2022 training for data-driven machine translation \u2022 reference for phrase-alignment \u2022 knowledge source for corpus-based translation studies \u2022 knowledge source for studies in contrastive linguistics As for ourselves, we are interested in applying tree alignment in the context of a syntax-based machine translation (MT) approach.", "labels": [], "entities": [{"text": "transfer-rule induction", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.8110317885875702}, {"text": "machine translation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7619360089302063}, {"text": "tree alignment", "start_pos": 343, "end_pos": 357, "type": "TASK", "confidence": 0.7271367460489273}, {"text": "syntax-based machine translation (MT)", "start_pos": 378, "end_pos": 415, "type": "TASK", "confidence": 0.8444785376389822}]}, {"text": "Since well-aligned treebanks will play a substantial role in our MT model, finding an optimal solution to the problem of tree alignment is very important.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9805686473846436}, {"text": "tree alignment", "start_pos": 121, "end_pos": 135, "type": "TASK", "confidence": 0.7230171859264374}]}, {"text": "In the next section, we provide a brief background of recent findings on the topic before presenting our own approach thereafter.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran a number of experiments using a pre-aligned treebank and various settings including features as described above.", "labels": [], "entities": []}, {"text": "In the following, we will first briefly describe the data used for training and testing.", "labels": [], "entities": []}, {"text": "Thereafter evaluation measures are defined and results of our experiments are summarized.", "labels": [], "entities": []}, {"text": "For evaluation we use the standard measures of precision, recall and F-scores.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9997640252113342}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9994601607322693}, {"text": "F-scores", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9951051473617554}]}, {"text": "Due to the distinction between good and fuzzy alignments we compute values similar to word alignment evaluation scores in which \"sure\" and \"possible\" links are considered: S refers hereto the good alignments in the gold standard and P refers to the possible alignments which includes both, good and fuzzy.", "labels": [], "entities": []}, {"text": "A are the links proposed by the system and \u03b1 is used to define the balance between precision and recall in the F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9993706345558167}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9987910389900208}, {"text": "F-score", "start_pos": 111, "end_pos": 118, "type": "METRIC", "confidence": 0.9559414386749268}]}, {"text": "We will only use a balanced F-score with \u03b1 = 0.5.", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.997820258140564}]}, {"text": "We also omit alignment error rates due to the discussion about this measure in the word alignment literature.", "labels": [], "entities": [{"text": "alignment error rates", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.7182023127873739}, {"text": "word alignment", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.6631829887628555}]}, {"text": "Note that the proportion of fuzzy links seems reasonable and we do not expect severe consequences on our evaluation as discussed in for word alignment experiments with unbalanced gold standards.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 136, "end_pos": 150, "type": "TASK", "confidence": 0.7605128586292267}]}], "tableCaptions": [{"text": " Table 1: Results for different feature sets.", "labels": [], "entities": []}, {"text": " Table 2: Results for different node types (all features)  including recall scores for different link types.", "labels": [], "entities": [{"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9989998936653137}]}]}