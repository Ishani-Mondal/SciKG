{"title": [{"text": "The TALP-UPC phrase-based translation system for EACL-WMT 2009", "labels": [], "entities": [{"text": "TALP-UPC phrase-based translation", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.5942376255989075}, {"text": "EACL-WMT", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8042508959770203}]}], "abstractContent": [{"text": "This study presents the TALP-UPC submission to the EACL Fourth Worskhop on Statistical Machine Translation 2009 evaluation campaign.", "labels": [], "entities": [{"text": "EACL Fourth Worskhop on Statistical Machine Translation 2009 evaluation", "start_pos": 51, "end_pos": 122, "type": "TASK", "confidence": 0.6410626073678335}]}, {"text": "It outlines the architecture and configuration of the 2009 phrase-based statistical machine translation (SMT) system, putting emphasis on the major novelty of this year: combination of SMT systems implementing different word reordering algorithms.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 59, "end_pos": 109, "type": "TASK", "confidence": 0.7049138673714229}]}, {"text": "Traditionally, we have concentrated on the Spanish-to-English and English-to-Spanish News Commentary translation tasks.", "labels": [], "entities": [{"text": "English-to-Spanish News Commentary translation", "start_pos": 66, "end_pos": 112, "type": "TASK", "confidence": 0.5714986994862556}]}], "introductionContent": [], "datasetContent": [{"text": "We followed the evaluation baseline instructions to train the MOSES-based translation system.", "labels": [], "entities": [{"text": "MOSES-based translation", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.7888261377811432}]}, {"text": "In some experiments we used MBR decoding () with the smoothed BLEU score as a similarity criteria, that allowed gaining 0.2 BLEU points comparing to the standard procedure of outputting the translation with the highest probability (HP).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9668304026126862}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.99759441614151}, {"text": "HP)", "start_pos": 232, "end_pos": 235, "type": "METRIC", "confidence": 0.9390946328639984}]}, {"text": "We applied the Moses implementation of this algorithm to the list 1 http://www.statmt.org/wmt09/baseline.html of 200 best translations generated by the TALP-UPC system.", "labels": [], "entities": []}, {"text": "The results obtained over the official 2009 Test dataset can be found in: MBR versus MERT decoding.", "labels": [], "entities": [{"text": "2009 Test dataset", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.8536455432573954}, {"text": "MBR", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.935012936592102}, {"text": "MERT", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.8181295394897461}]}, {"text": "The \"recase\" script provided within the baseline was supplemented with and additional module, which restore the original case for unknown words (many of them are proper names and loosing of case information leads to a significant performance degradation).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Perplexity results obtained on the Dev  2009 corpus and the monolingual LMs.", "labels": [], "entities": [{"text": "Dev  2009 corpus", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.959829310576121}]}, {"text": " Table 2: MBR versus MERT decoding.", "labels": [], "entities": [{"text": "MBR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5381144285202026}, {"text": "MERT decoding", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.6022373735904694}]}, {"text": " Table 3: BLEU and NIST scores for preliminary  official test dataset 2009 (primary submission)  with 500 sentences excluded.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9972044825553894}, {"text": "NIST", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.8765636682510376}, {"text": "preliminary  official test dataset 2009", "start_pos": 35, "end_pos": 74, "type": "DATASET", "confidence": 0.6733499884605407}]}]}