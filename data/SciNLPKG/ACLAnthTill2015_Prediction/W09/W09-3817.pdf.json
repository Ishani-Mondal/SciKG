{"title": [{"text": "Capturing Consistency between Intra-clause and Inter-clause Relations in Knowledge-rich Dependency and Case Structure Analysis", "labels": [], "entities": [{"text": "Case Structure Analysis", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.7167657415072123}]}], "abstractContent": [{"text": "We present a method for dependency and case structure analysis that captures the consistency between intra-clause relations (i.e., case structures or predicate-argument structures) and inter-clause relations.", "labels": [], "entities": [{"text": "dependency and case structure analysis", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.675901347398758}]}, {"text": "We assess intra-clause relations on the basis of case frames and inter-clause relations on the basis of transition knowledge between case frames.", "labels": [], "entities": []}, {"text": "Both knowledge bases are automatically acquired from a massive amount of parses of a Web corpus.", "labels": [], "entities": []}, {"text": "The significance of this study is that the proposed method selects the best dependency and case structure that are consistent within each clause and between clauses.", "labels": [], "entities": []}, {"text": "We confirm that this method contributes to the improvement of dependency parsing of Japanese.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8297716975212097}]}], "introductionContent": [{"text": "The approaches of dependency parsing basically assess the likelihood of a dependency relation between two words or phrases and subsequently collect all the assessments for these pairs as the dependency parse of the sentence.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8464294672012329}]}, {"text": "To improve dependency parsing, it is important to consider as broad a context as possible, rather than a word/phrase pair.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.8198501467704773}]}, {"text": "In the recent evaluation workshops (shared tasks) of multilingual dependency parsing, transition-based and graph-based methods achieved good performance by incorporating rich context.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.6117819746335348}]}, {"text": "Transition-based dependency parsers consider the words following the word under consideration as features of machine learning ().", "labels": [], "entities": [{"text": "Transition-based dependency parsers", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6432831088701884}]}, {"text": "Graph-based dependency parsers consider sibling and grandparent nodes, i.e., second-order and higher-order features.", "labels": [], "entities": []}, {"text": "It is desirable to consider a wider-range phrase, clause, or a whole sentence, but it is difficult to judge whether the structure of such a wide-range expression is linguistically correct.", "labels": [], "entities": []}, {"text": "One of the reasons for this is the scarcity of the knowledge required to make such a judgment.", "labels": [], "entities": []}, {"text": "When we use the Penn Treebank (, which is one of the largest corpora among the available analyzed corpora, as training data, even bi-lexical dependencies cannot be learned sufficiently.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 16, "end_pos": 29, "type": "DATASET", "confidence": 0.9946379959583282}]}, {"text": "To circumvent such scarcity, for instance, proposed the use of word classes induced by clustering words in a large raw corpus.", "labels": [], "entities": []}, {"text": "They succeeded in improving the accuracy of a higher-order dependency parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9994248151779175}]}, {"text": "On the other hand, some researchers have proposed other approaches where linguistic units such as predicate-argument structures (also known as case structures and logical forms) are considered instead of arbitrary nodes such as sibling nodes.", "labels": [], "entities": []}, {"text": "To solve the problem of knowledge scarcity, they learned knowledge of such predicate-argument structures from a very large number of automatically analyzed corpora ().", "labels": [], "entities": [{"text": "knowledge scarcity", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7292148619890213}]}, {"text": "While used only cooccurrence statistics of verbal arguments, Kawahara and Kurohashi (2006b) assessed predicateargument structures by checking case frames, which are semantic frames that are automatically compiled for each predicate sense from a large raw corpus.", "labels": [], "entities": []}, {"text": "These methods outperformed the accuracy of supervised dependency parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9972102046012878}]}, {"text": "In such linguistically-motivated approaches, well-formedness within a clause was considered, but coherence between clauses was not considered.", "labels": [], "entities": []}, {"text": "Even if intra-clause relations (i.e., a predicate-argument structure within a clause) are: Possible dependency and case structures of sentence (1).", "labels": [], "entities": []}, {"text": "optimized, they might not be optimum when looking at clause pairs or sequences.", "labels": [], "entities": []}, {"text": "To improve the accuracy of dependency parsing, we propose a method for dependency and case structure analysis that considers the consistency between intraclause and inter-clause relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9981445074081421}, {"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8525962829589844}, {"text": "case structure analysis", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.6893526613712311}]}, {"text": "This method analyzes intra-clause relations on the basis of case frames and inter-clause relations on the basis of transition knowledge between case frames.", "labels": [], "entities": []}, {"text": "These two knowledge sources are automatically acquired from a massive amount of parses of a Web corpus.", "labels": [], "entities": []}, {"text": "The contributions of this paper are two-fold.", "labels": [], "entities": []}, {"text": "First, we acquire transition knowledge not between verbs or verb phrases but between case frames, which are semantically disambiguated representations.", "labels": [], "entities": []}, {"text": "Second, we incorporate the transition knowledge into dependency and case structure analysis to capture the consistency between intra-clause and inter-clause relations.", "labels": [], "entities": [{"text": "case structure analysis", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7112427055835724}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 illustrates our idea.", "labels": [], "entities": []}, {"text": "Section 3 describes a method for acquiring the transition knowledge.", "labels": [], "entities": []}, {"text": "Section 4 explains the proposed method of incorporating the acquired transition knowledge into a probabilistic model of dependency and case structure analysis.", "labels": [], "entities": [{"text": "case structure analysis", "start_pos": 135, "end_pos": 158, "type": "TASK", "confidence": 0.7956541180610657}]}, {"text": "Section 5 reports experimental results.", "labels": [], "entities": []}, {"text": "Section 6 gives the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "To obtain the case frames and the transition knowledge between case frames, we first built a Japanese Web corpus by using the method of.", "labels": [], "entities": [{"text": "Japanese Web corpus", "start_pos": 93, "end_pos": 112, "type": "DATASET", "confidence": 0.8696521520614624}]}, {"text": "We first crawled 100 million Japanese Web pages, and then, we extracted and unduplicated Japanese sentences from the Web pages.", "labels": [], "entities": []}, {"text": "Consequently, we developed a Web corpus consisting of 1.6 billion Japanese sentences.", "labels": [], "entities": []}, {"text": "Using the procedure of case frame construction presented in Section 3.1.1, we constructed case frames from the whole Web corpus.", "labels": [], "entities": [{"text": "case frame construction", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.7246368130048116}]}, {"text": "They consisted of 43,000 predicates, and the average number of case frames fora predicate was 22.2.", "labels": [], "entities": []}, {"text": "Then, we acquired the transition knowledge between case frames using 500 million sentences of the Web corpus.", "labels": [], "entities": [{"text": "Web corpus", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.7873565852642059}]}, {"text": "The resulting knowledge consisted of 108 million unique case frame pairs.", "labels": [], "entities": []}, {"text": "Table 2 lists some examples of the acquired transition knowledge.", "labels": [], "entities": []}, {"text": "In the acquired transition knowledge, we can find various kinds of relation such as entailment, cause-effect and temporal relations.", "labels": [], "entities": []}, {"text": "Let us compare this result with the results of previous studies.", "labels": [], "entities": []}, {"text": "For example, obtained 29,165 verb pairs for several semantic relations in VerbOcean.", "labels": [], "entities": [{"text": "VerbOcean", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.9338069558143616}]}, {"text": "The transition knowledge acquired in this study is several thousand times larger than that in VerbOcean.", "labels": [], "entities": [{"text": "VerbOcean", "start_pos": 94, "end_pos": 103, "type": "DATASET", "confidence": 0.9254646897315979}]}, {"text": "It is very difficult to make a meaningful comparison, but it can be seen that we have succeeded in acquiring generic transition knowledge on a large scale.", "labels": [], "entities": []}, {"text": "We evaluated the dependency structures that were output by our new dependency parser.", "labels": [], "entities": []}, {"text": "The case frames used in these experiments are the same as those described in Section 3.3, which were automatically constructed from 1.6 billion Japanese sentences obtained from the Web.", "labels": [], "entities": []}, {"text": "In this study, the parameters related to unlexical types were calculated from the Kyoto University Text Corpus, which is a small tagged corpus of newspaper articles, and lexical parameters were obtained from a large Web corpus.", "labels": [], "entities": [{"text": "Kyoto University Text Corpus", "start_pos": 82, "end_pos": 110, "type": "DATASET", "confidence": 0.968441054224968}]}, {"text": "To evaluate the effectiveness of our model, our experiments were conducted using sentences obtained from the Web.", "labels": [], "entities": []}, {"text": "As a test corpus, we used 759 Web sentences 2 , which were manually annotated using the same criteria as those in the case of the Kyoto University Text Corpus.", "labels": [], "entities": [{"text": "Kyoto University Text Corpus", "start_pos": 130, "end_pos": 158, "type": "DATASET", "confidence": 0.927994892001152}]}, {"text": "We also used the Kyoto University Text Corpus as a development corpus to optimize some smoothing parameters.", "labels": [], "entities": [{"text": "Kyoto University Text Corpus", "start_pos": 17, "end_pos": 45, "type": "DATASET", "confidence": 0.9785301983356476}]}, {"text": "The system input was automatically tagged using the JUMAN morphological analyzer 3 . We used two baseline systems for the purposes of comparison: a rule-based dependency parser ( and the probabilistic generative model of dependency and case structure analysis . We use the above-mentioned case frames also in the latter baseline parser, which also requires automatically constructed case frames.", "labels": [], "entities": [{"text": "case structure analysis", "start_pos": 236, "end_pos": 259, "type": "TASK", "confidence": 0.6812717417875925}]}, {"text": "We evaluated the obtained dependency structures in terms of phrase-based dependency accuracythe proportion of correct dependencies out of all dependencies . lists the dependency accuracies.", "labels": [], "entities": [{"text": "accuracythe", "start_pos": 84, "end_pos": 95, "type": "METRIC", "confidence": 0.908416211605072}]}, {"text": "In this table, \"syn\" represents the rule-based dependency parser, \"syn+case\" represents the probabilistic parser of syntactic and case structure) 6 , and \"syn+case+cons\" represents our proposed model.", "labels": [], "entities": []}, {"text": "In the table, the dependency accuracies are classified into four categories on the basis of the phrase classes (VP: verb phrase and NP: noun phrase) of a dependent and its head.", "labels": [], "entities": []}, {"text": "The parser \"syn+case+cons\" significantly outperformed the two baselines for \"all\" (McNemar's test; p < 0.05).", "labels": [], "entities": []}, {"text": "In particular, the accuracy of the intra-clause (predicate-argument) relations (\"NP\u2192VP\") was improved by 1.5% from \"syn\" and by 0.4% from \"syn+case.\"", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9994844198226929}]}, {"text": "These im-3 http://nlp.kuee.kyoto-u.ac.jp/ nl-resource/juman-e.html 4 http://nlp.kuee.kyoto-u.ac.jp/ nl-resource/knp-e.html Since Japanese is head-final, the second to last phrase unambiguously depends on the last phrase.", "labels": [], "entities": []}, {"text": "However, we include such dependencies into our evaluation as inmost of previous studies.", "labels": [], "entities": []}, {"text": "The accuracy described in is different from that of this paper due to the different evaluation measure excluding the unambiguous dependencies of the second last phrases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995085000991821}]}, {"text": "7 VP includes not only verbs but also adjectives and nouns with copula.", "labels": [], "entities": []}, {"text": "provements are due to the incorporation of the transition knowledge into syntactic/case structure analysis.", "labels": [], "entities": [{"text": "syntactic/case structure analysis", "start_pos": 73, "end_pos": 106, "type": "TASK", "confidence": 0.6951288521289826}]}, {"text": "In order to compare our results with a state-ofthe-art discriminative dependency parser, we input the test corpus into an SVM-based Japanese dependency parser, CaboCha 8 (), which was trained using the Kyoto University Text Corpus.", "labels": [], "entities": [{"text": "Kyoto University Text Corpus", "start_pos": 202, "end_pos": 230, "type": "DATASET", "confidence": 0.9133032709360123}]}, {"text": "Its dependency accuracy was 88.6%, which is close to that of \"syn.\"", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9575716257095337}]}, {"text": "This low accuracy is attributed to the lack of knowledge of both intra-clause and inter-clause relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9991694688796997}]}, {"text": "Another cause of the low accuracy is the out-of-domain training corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9992658495903015}]}, {"text": "In other words, the parser was trained on a newspaper corpus, while the test corpus was obtained from the Web because a tagged Web corpus that is large enough to train a supervised parser is not available.", "labels": [], "entities": []}], "tableCaptions": []}