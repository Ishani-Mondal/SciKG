{"title": [], "abstractContent": [{"text": "This paper describes the multilingual semantic role labeling system of Computational Linguistics Group, Trinity College Dublin, for the CoNLL-2009 SRLonly closed shared task.", "labels": [], "entities": [{"text": "multilingual semantic role labeling", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.6244187876582146}, {"text": "Computational Linguistics Group, Trinity College Dublin", "start_pos": 71, "end_pos": 126, "type": "DATASET", "confidence": 0.6454307096345084}, {"text": "CoNLL-2009 SRLonly closed shared task", "start_pos": 136, "end_pos": 173, "type": "DATASET", "confidence": 0.7697005271911621}]}, {"text": "The system consists of two cascaded components: one for disambiguating predicate word sense, and the other for identifying and classifying arguments.", "labels": [], "entities": [{"text": "disambiguating predicate word sense", "start_pos": 56, "end_pos": 91, "type": "TASK", "confidence": 0.6042251512408257}]}, {"text": "Supervised learning techniques are utilized in these two components.", "labels": [], "entities": []}, {"text": "As each language has its unique characteristics , different parameters and strategies have to betaken for different languages, either for providing functions required by a language or for meeting the tight deadline.", "labels": [], "entities": []}, {"text": "The system obtained labeled F1 69.26 averaging over seven languages (Catalan, Chinese, Czech, English, German, Japanese, and Spanish), which ranks the system fourth among the seven systems participating the SRLonly closed track.", "labels": [], "entities": [{"text": "F1 69.26", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.8747565150260925}, {"text": "SRLonly closed track", "start_pos": 207, "end_pos": 227, "type": "DATASET", "confidence": 0.8954263726870219}]}], "introductionContent": [{"text": "Semantic role labeling, which aims at computationally identifying and labeling arguments of predicate words, has become a leading research problem in computational linguistics with the advent of various supporting resources (e.g. corpora and lexicons) (.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7383750875790914}, {"text": "computationally identifying and labeling arguments of predicate words", "start_pos": 38, "end_pos": 107, "type": "TASK", "confidence": 0.6816907860338688}]}, {"text": "Word semantic dependencies derived by semantic role labeling are assumed to facilitate automated interpretation of natural language texts.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.6857057412465414}, {"text": "automated interpretation of natural language texts", "start_pos": 87, "end_pos": 137, "type": "TASK", "confidence": 0.7992001871267954}]}, {"text": "Moreover, techniques for automatic annotation of semantic dependencies can also play an important role in adding metadata to corpora for the purposes of machine translation and speech processing.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.7717714011669159}]}, {"text": "We are currently investigating such techniques as part of our research into integrated language technology in the Center for Next Generation Localization (CNGL, http://www.cngl.ie).", "labels": [], "entities": []}, {"text": "The multilingual nature of the CoNLL-2009 shared task on syntactic and semantic dependency analysis, which includes Catalan, Chinese, Czech, English, German, Japanese, and Spanish (), makes it a good testbed for our research.", "labels": [], "entities": [{"text": "syntactic and semantic dependency analysis", "start_pos": 57, "end_pos": 99, "type": "TASK", "confidence": 0.566880851984024}]}, {"text": "We decided to participate in the CoNLL-2009 shared task at the beginning of March, signed the agreement forgetting the training data on March 2 nd , 2009, and obtained all the training data (especially the part from LDC) on March 4 th , 2009.", "labels": [], "entities": [{"text": "LDC", "start_pos": 216, "end_pos": 219, "type": "DATASET", "confidence": 0.9036598801612854}]}, {"text": "Due to the tight time constraints of the task, we chose to use existing packages to implement our system.", "labels": [], "entities": []}, {"text": "These time constraints also meant that we had to resort to less computationally intensive methods to meet the deadline, especially for some large datasets (such as the Czech data).", "labels": [], "entities": [{"text": "Czech data)", "start_pos": 168, "end_pos": 179, "type": "DATASET", "confidence": 0.9080247282981873}]}, {"text": "In spite of these difficulties and resource limitations, we are proud to be among the 21 teams who successfully submitted the results . As anew participant, our goals in attending the CoNLL-2009 SRLonly shared task were to gain more thorough knowledge of this line of research and its state-of-the-art, and to explore how well a system quickly assembled with existing packages can fare at this hard semantic analysis problem.", "labels": [], "entities": [{"text": "CoNLL-2009 SRLonly shared task", "start_pos": 184, "end_pos": 214, "type": "DATASET", "confidence": 0.7511666864156723}]}, {"text": "Following the successful approaches taken by the participants of the CoNLL-2008 shared task ( ) on monolingual syntactic and semantic dependency analysis, we designed and implemented our CoNLL-2009 SRLonly system with pipeline architecture.", "labels": [], "entities": [{"text": "monolingual syntactic and semantic dependency analysis", "start_pos": 99, "end_pos": 153, "type": "TASK", "confidence": 0.5937257707118988}]}, {"text": "Two main components are cascaded in this system: one is for disambiguating predicate word sense 2 , and the other for identifying and classifying arguments for 1 According to our correspondence with Dr. Jan Haji\u010d, totally 31 teams among 60 registered ones signed and got the evaluation data.", "labels": [], "entities": []}, {"text": "As predicate words are marked in the CoNLL-2009 datasets, we don't need to identify predicate words.", "labels": [], "entities": [{"text": "CoNLL-2009 datasets", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.9823372662067413}]}, {"text": "Different supervised learning techniques are utilized in these two components.", "labels": [], "entities": []}, {"text": "For predicate word sense disambiguation (WSD), we have experimented with three algorithms: SVM, kNN, and Na\u00efve Bayes.", "labels": [], "entities": [{"text": "predicate word sense disambiguation (WSD)", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.8546927911894662}]}, {"text": "Based on experimental results on the development datasets, we chose SVM and kNN to produce our submitted official results.", "labels": [], "entities": [{"text": "SVM", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.8728404641151428}]}, {"text": "For argument identification and classification, we used a maximum entropy classifier for all the seven datasets.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.8136713802814484}]}, {"text": "As each language has its unique characteristics and peculiarities within the dataset, different parameters and strategies have to betaken for different languages (as detailed below), either for providing functions required by a language or for meeting the tight deadline.", "labels": [], "entities": []}, {"text": "Our official submission obtained 69.26 labeled F1 averaging over the seven languages, which ranks our system fourth among the seven systems in the SRLonly closed track.", "labels": [], "entities": [{"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9897837042808533}, {"text": "SRLonly closed track", "start_pos": 147, "end_pos": 167, "type": "DATASET", "confidence": 0.8823991020520529}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the first component of our system for predicate word sense disambiguation.", "labels": [], "entities": [{"text": "predicate word sense disambiguation", "start_pos": 58, "end_pos": 93, "type": "TASK", "confidence": 0.8062256574630737}]}, {"text": "Section 3 explains how our system detects and classifies arguments with respect to a predicate word.", "labels": [], "entities": []}, {"text": "We present experiments in Section 4, and conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The datasets of the CoNLL-2009 shared task contain seven languages: Catalan (CA), Chinese (CN), Czech (CZ), English (EG), German (GE), Japanese (JP), and Spanish (SP.", "labels": [], "entities": []}, {"text": "Statistical information of the seven language datasets (training and development).", "labels": [], "entities": []}, {"text": "shows some statistical information of both training and development data for each language.", "labels": [], "entities": []}, {"text": "The total size of the uncompressed original data without lexicons is about 345MB.", "labels": [], "entities": []}, {"text": "The Czech dataset is the largest one containing 43,955 sentences and 469,754 predicate words, while the Japanese dataset the smallest one.", "labels": [], "entities": [{"text": "Czech dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9212004840373993}, {"text": "Japanese dataset", "start_pos": 104, "end_pos": 120, "type": "DATASET", "confidence": 0.7771632373332977}]}, {"text": "On average, 10.69 predicate words appear in a Czech sentence, while only 0.47 predicate words exist in a German sentence.", "labels": [], "entities": []}, {"text": "The most popular sense tag in the Czech datasets is \"=\", which means the PRED field has the same value as the PLEMMA field or the FORM field.", "labels": [], "entities": [{"text": "Czech datasets", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.8826094269752502}]}, {"text": "About 81% of Czech predicate words take this value.", "labels": [], "entities": []}, {"text": "F1 is used as the main evaluation metric in the CoNLL-2009 shared task.", "labels": [], "entities": [{"text": "F1", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9893177151679993}, {"text": "CoNLL-2009 shared task", "start_pos": 48, "end_pos": 70, "type": "DATASET", "confidence": 0.7798108061154684}]}, {"text": "As to the SRLonly track, a joint semantic labeled F1, which considers predicate word sense disambiguation and argument labeling equally, is used to rank systems..", "labels": [], "entities": [{"text": "SRLonly track", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.723578929901123}, {"text": "F1", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.992017388343811}, {"text": "predicate word sense disambiguation", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.6022970005869865}]}, {"text": "Results of our system after fixing a minor bug.", "labels": [], "entities": []}, {"text": "After submitting the official results, we found and fixed a minor bug in the implementation of the second component.", "labels": [], "entities": []}, {"text": "presents the results of our system after fixing this bug.", "labels": [], "entities": []}, {"text": "The overall performance doesn't change much.", "labels": [], "entities": []}, {"text": "We further analyzed the bottlenecks by checking the performance of different components.", "labels": [], "entities": []}, {"text": "At the predicate WSD part, our system works reasonable with labeled F1 86.9, but the performance on the Czech data is lower than that of a baseline system that constantly chooses the most popular sense tag.", "labels": [], "entities": [{"text": "F1 86.9", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.937353640794754}, {"text": "Czech data", "start_pos": 104, "end_pos": 114, "type": "DATASET", "confidence": 0.9435741007328033}]}, {"text": "If we use this baseline solution, we can get predicate WSD F1 78.66, which further increases the overall labeled F1 on the Czech data to 61.68 from 57.57 and the overall labeled F1 over the seven languages to 70.05 from 69.47.", "labels": [], "entities": [{"text": "predicate WSD F1 78.66", "start_pos": 45, "end_pos": 67, "type": "METRIC", "confidence": 0.7030255347490311}, {"text": "F1", "start_pos": 113, "end_pos": 115, "type": "METRIC", "confidence": 0.7541370987892151}, {"text": "Czech data", "start_pos": 123, "end_pos": 133, "type": "DATASET", "confidence": 0.9083845019340515}, {"text": "F1", "start_pos": 178, "end_pos": 180, "type": "METRIC", "confidence": 0.9269819259643555}]}, {"text": "From table 3, we can see our system performs relatively poorly for argument identification and classification (57.24 vs. 86.9).", "labels": [], "entities": [{"text": "argument identification and classification", "start_pos": 67, "end_pos": 109, "type": "TASK", "confidence": 0.7622751444578171}]}, {"text": "The system seems too conservative for argument identification, which makes the recall very lower.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.905245304107666}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9994377493858337}]}, {"text": "We explored some strategies for improving the performance of the second component, e.g. separating argument identification and argument classification, and using feature selection (with DF threshold) techniques, but none of them helps much.", "labels": [], "entities": [{"text": "separating argument identification", "start_pos": 88, "end_pos": 122, "type": "TASK", "confidence": 0.8964518109957377}, {"text": "argument classification", "start_pos": 127, "end_pos": 150, "type": "TASK", "confidence": 0.7203915268182755}]}, {"text": "We are thinking the features currently used may not be effective enough, which deserves further study.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Statistical information of the seven language  datasets (training and development).", "labels": [], "entities": []}, {"text": " Table 2. Official results of our system.", "labels": [], "entities": []}, {"text": " Table 3. Results of our system after fixing a minor bug.", "labels": [], "entities": []}]}