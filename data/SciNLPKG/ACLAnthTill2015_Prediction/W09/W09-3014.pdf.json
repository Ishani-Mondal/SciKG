{"title": [{"text": "Schema and Variation: Digitizing Printed Dictionaries", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we show how to exploit typographical and textual features of raw text for creating a fine-grain XML Schema Markup with special focus on capturing linguistic variation in dictionaries.", "labels": [], "entities": []}, {"text": "We use declarative programming techniques and context-free grammars implemented in PROLOG.", "labels": [], "entities": [{"text": "PROLOG", "start_pos": 83, "end_pos": 89, "type": "DATASET", "confidence": 0.8424669504165649}]}], "introductionContent": [{"text": "In 1996, Cambridge University Press proudly presented an outstanding milestone in electronic publishing: Samuel Johnson: A Dictionary of the English Language on CD-ROM, edited by Anne McDermott; containing the First Edition 1755 and the significantly revised Fourth Edition 1773.", "labels": [], "entities": [{"text": "Cambridge University Press", "start_pos": 9, "end_pos": 35, "type": "DATASET", "confidence": 0.8621209661165873}, {"text": "Samuel Johnson: A Dictionary of the English Language", "start_pos": 105, "end_pos": 157, "type": "DATASET", "confidence": 0.6751724614037408}, {"text": "First Edition 1755", "start_pos": 210, "end_pos": 228, "type": "DATASET", "confidence": 0.696236809094747}]}, {"text": "\"The Dictionary is not only the first great work of English lexicography but also a literary and historical resource of immense value, and this electronic edition has been prepared to the highest standards by a team of scholars at the University of Birmingham.\"", "labels": [], "entities": [{"text": "The Dictionary", "start_pos": 1, "end_pos": 15, "type": "DATASET", "confidence": 0.9630514681339264}]}, {"text": "The announcement highlighted all the key characteristics of electronic texts: accessability, completeness, use of multi-media environment, searchability and highest standards applied by scholars, i.e. philological reliability and precision, wrapped in leading edge technology.", "labels": [], "entities": [{"text": "precision", "start_pos": 230, "end_pos": 239, "type": "METRIC", "confidence": 0.9976315498352051}]}, {"text": "Today, more than a decade and at least one electronic product life-cycle later, the CD is still on sale -as far as we could find out unchanged -and has not lost anything of its former value.", "labels": [], "entities": []}, {"text": "In the context of digitizing the cultural heritage there is even a strong and growing demand for digitizing research tools like dictionaries (cf., e.g., Gallica Digital Library Charter/Chapter: Time period covered).", "labels": [], "entities": [{"text": "Gallica Digital Library Charter/Chapter", "start_pos": 153, "end_pos": 192, "type": "DATASET", "confidence": 0.9329819679260254}]}, {"text": "But, in the field of electronic text editing, requirements grow rapidly and standards develop fast.", "labels": [], "entities": [{"text": "electronic text editing", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.6178869903087616}]}, {"text": "The users of electronic texts today want to search not only for words, phrases, headwords, quotations, and authors of sources.", "labels": [], "entities": []}, {"text": "They would like to get access to and search for variant forms, grammatical categories, usage indicators and the structuring of the description of word senses, etc., not only in single dictionaries, but -perhaps using a grid environment -in fully connected dictionary networks (cf. the dictionary search, possible within the Trier Dictionary Net and as a TextGrid feature).", "labels": [], "entities": [{"text": "Trier Dictionary Net", "start_pos": 324, "end_pos": 344, "type": "DATASET", "confidence": 0.9168727993965149}]}, {"text": "In the context of these new user scenarios, possibly grid-based, usable for collabortive research and secured safely in longterm archive structures, we try to put fine-grain encoding ideas into practise using Joachim Heinrich Campe's dictionary of the German Language as testbed.", "labels": [], "entities": [{"text": "Joachim Heinrich Campe's dictionary of the German Language", "start_pos": 209, "end_pos": 267, "type": "DATASET", "confidence": 0.7848077880011665}]}, {"text": "This is one of the reasons why TEXTGRID (2009), the first grid project in German eHumanities, funded by the Federal Ministry of Education and Research, chose the Campe Dictionary (1811): 6 volumes with altogether about 6.000 pages and about 140.000 entries, published between 1807 and 1813 as one testbed for their TEXTGRID Lab, a Virtual Research Library.", "labels": [], "entities": [{"text": "Campe Dictionary (1811)", "start_pos": 162, "end_pos": 185, "type": "DATASET", "confidence": 0.8926364541053772}]}, {"text": "It entails a grid-enabled workbench that will process, analyse, annotate, edit and publish text data for academic research and TEXTGRIDRep, a grid repository for long-term storage.", "labels": [], "entities": [{"text": "TEXTGRIDRep", "start_pos": 127, "end_pos": 138, "type": "METRIC", "confidence": 0.8755677342414856}]}, {"text": "Electronic dictionaries are used in a wide field of new research areas such as the growing community of eHumanities.", "labels": [], "entities": []}, {"text": "One of the main projects for the German humanities is the community project TEXTGRID, which aims to develop a platform for the collaborative editing, annotation, analysis and publication of texts.", "labels": [], "entities": [{"text": "TEXTGRID", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.8799746036529541}]}, {"text": "According to the TEI Consortium (2009), large text corpora from different epochs have to be parsed and annotated for performing further analysis, such as building a metalemma list for the project interdependencies between language and genomes.", "labels": [], "entities": [{"text": "TEI Consortium (2009)", "start_pos": 17, "end_pos": 38, "type": "DATASET", "confidence": 0.9032315254211426}]}, {"text": "In general, there are the following important prerequisites for state of the art text encoding in the Humanities.", "labels": [], "entities": [{"text": "text encoding", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.6944933533668518}]}, {"text": "The encoding should use international standards, especially XML and related standards, e.g., TEI P5 with XML Schema.", "labels": [], "entities": []}, {"text": "Also the combination of text and image is necessay.", "labels": [], "entities": []}, {"text": "The text capture should aim at reference quality for the encoded text.", "labels": [], "entities": [{"text": "text capture", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.7537818551063538}]}, {"text": "A fine-grain encoding preserving lexicographical and textual variation without blurring (distorting) the content modelling of XML elements is helpful.", "labels": [], "entities": []}, {"text": "Finally, a TEI schema (Relax NG) that is flexible enough to encode variation in lexicographical and textual structures without loosening the grip of the constraints is necessary to define clear cut element content.", "labels": [], "entities": []}, {"text": "In this paper, we present an annotation workflow using declarative programming techniques for fine-grain text markup, and we apply it for retro-digitizing a printed version of the Campe Dictionary.", "labels": [], "entities": [{"text": "Campe Dictionary", "start_pos": 180, "end_pos": 196, "type": "DATASET", "confidence": 0.7005335688591003}]}, {"text": "Our parsing and annotation toolkit is based on SWI-PROLOG and the XML query and transformation language FN-QUERY, which is implemented in SWI-PROLOG.", "labels": [], "entities": [{"text": "FN-QUERY", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.7237432599067688}]}, {"text": "Using PROLOG technology for parsing and annotating is common in natural language processing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9693729281425476}]}, {"text": "It has, e.g., been used within the Jean Paul project at the Berlin-Brandenburg Academy of Sciences (), where XML transformations based on FNQUERY turned out to be easier to write than XSLT transformations.", "labels": [], "entities": []}, {"text": "A frequently applied method in PROLOG programming is to find the proper level of abstraction and to write suitable macros for frequently occurring patterns in the code; PROLOG even allows to design dedicated special-purpose languages.", "labels": [], "entities": []}, {"text": "Definite clause grammars have been developed as an abstraction for parsing; this has, e.g., been very successful for parsing controlled natural languages ().", "labels": [], "entities": [{"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9743008017539978}, {"text": "parsing controlled natural languages", "start_pos": 117, "end_pos": 153, "type": "TASK", "confidence": 0.8368383944034576}]}, {"text": "The rest of this paper is organized as follows: In Section 2, we sketch the worklflow for capturing text from the printed text corpus and the semi-automatic error correction to produce a source file for our parsing and annotation toolkit.", "labels": [], "entities": []}, {"text": "Section 3 gives an overview of the structure of the different entries in the dictionary; we will explain this structure with the lemma \"Der Aal\", and we will examplify the variation of entries.", "labels": [], "entities": [{"text": "Aal", "start_pos": 140, "end_pos": 143, "type": "METRIC", "confidence": 0.6243744492530823}]}, {"text": "The next section shows the annotation of the different lemma variants and the parsing of nouns and verbs.", "labels": [], "entities": []}, {"text": "In Section 5, we describe the parsing and annotation of the sense block with citations and references, punctuation, linebreaks and hyphenation.", "labels": [], "entities": []}, {"text": "The last section gives a conclusion of our work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}