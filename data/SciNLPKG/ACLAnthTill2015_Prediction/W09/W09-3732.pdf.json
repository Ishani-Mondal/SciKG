{"title": [{"text": "A Study of a Segmentation Technique for Dialogue Act Assignation *", "labels": [], "entities": [{"text": "Dialogue Act Assignation", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.7372125387191772}]}], "abstractContent": [], "introductionContent": [{"text": "A dialogue system is usually defined as a computer system that interacts with a human user to achieve a task using dialogue.", "labels": [], "entities": []}, {"text": "In these systems, the computer must know the meaning and intention of the user input, in order to give the appropriate answer.", "labels": [], "entities": []}, {"text": "The user turns must be interpreted by the system, taking only into account the essential information, i.e, their semantics for the dialogue process and the task to be accomplished.", "labels": [], "entities": []}, {"text": "This information is usually represented by labels called Dialogue Acts (DA) which label different segments of the turn known as utterances.", "labels": [], "entities": []}, {"text": "The DA labels usually take into account the semantics of the utterance with respect to the dialogue process, but they can include semantic information related to the task the dialogue is about.", "labels": [], "entities": []}, {"text": "Therefore, the correct assignation of DA to a user turn is crucial to the correct behaviour of the dialogue system.", "labels": [], "entities": []}, {"text": "Several models have been proposed to perform this assignation.", "labels": [], "entities": [{"text": "assignation", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.965060293674469}]}, {"text": "In the recent years, probabilistic models have gained importance in this task.", "labels": [], "entities": []}, {"text": "In the assignation task, these models are applied on non-annotated dialogues.", "labels": [], "entities": [{"text": "assignation task", "start_pos": 7, "end_pos": 23, "type": "TASK", "confidence": 0.9274650812149048}]}, {"text": "Most of the previous work done on the assignation of DA is performed on user turns segmented into utterances, although the availability of the segmentation is not usual in the dialogue corpora nor in areal dialogue system.", "labels": [], "entities": [{"text": "assignation of DA", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.90535968542099}]}, {"text": "The proposed assignation models can be easily adapted to the lack of segmentation into utterances.", "labels": [], "entities": []}, {"text": "In this article, we present a model based on Hidden Markov Model (HMM) and N-grams that can be applied to segmented and unsegmented turns.", "labels": [], "entities": []}, {"text": "The results show that the lack of segmentation causes many errors in the assignation of DA.", "labels": [], "entities": [{"text": "assignation of DA", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.8510116537412008}]}, {"text": "Therefore, we propose another model based on N-grams (NGT model) that segments a user turn into utterances previously to the DA assignation.", "labels": [], "entities": [{"text": "DA assignation", "start_pos": 125, "end_pos": 139, "type": "TASK", "confidence": 0.6617168933153152}]}], "datasetContent": [{"text": "In this section, we compare the performance of the HMM-based model when using the correct segmentation into utterances, the NGT segmentation and when no segmentation of the turns is given.", "labels": [], "entities": [{"text": "NGT segmentation", "start_pos": 124, "end_pos": 140, "type": "TASK", "confidence": 0.7139103412628174}]}, {"text": "The experiments were performed on the SwitchBoard corpus and on the Dihana corpus (with the two and three-level labels).", "labels": [], "entities": [{"text": "SwitchBoard corpus", "start_pos": 38, "end_pos": 56, "type": "DATASET", "confidence": 0.9414569139480591}, {"text": "Dihana corpus", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.9707367718219757}]}, {"text": "All the experiments were performed using a crossvalidation approach.", "labels": [], "entities": []}, {"text": "Some simplifications were performed on the corpora before training the models and performing the experiments.", "labels": [], "entities": []}, {"text": "The HMM model is trained for each DA label from the utterances of the training dialogues annotated with the corresponding label.", "labels": [], "entities": []}, {"text": "The N-gram model is trained from the sequences of DA labels in the training dialogues.", "labels": [], "entities": []}, {"text": "In the NGT model, the training dialogues were re-labelled to obtain the sequences of words with the attached utterance boundaries.", "labels": [], "entities": [{"text": "NGT", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.9014096856117249}]}, {"text": "From these sequences, different N-grams were inferred with N values from 2 to 5.", "labels": [], "entities": []}, {"text": "These N-grams were used to obtain the segmentation of the turns in the test dialogues into utterances.", "labels": [], "entities": []}, {"text": "The decoding step was performed using the Viterbi algorithm.", "labels": [], "entities": []}, {"text": "In the case of the segmented dialogues, the segmentation was fixed to that provided in the manual annotation or by NGT.", "labels": [], "entities": [{"text": "NGT", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.9824076294898987}]}, {"text": "In the case of the unsegmented turns, the search was performed on the complete turn and the optimal DA assignation provided the segmentation as a by-product.", "labels": [], "entities": [{"text": "DA assignation", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.5995446741580963}]}, {"text": "We can compute the accuracy of the segmentation given by the NGT model and the HMM-based model from the reference segmentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9995113611221313}, {"text": "segmentation", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.9638052582740784}, {"text": "NGT", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.923151433467865}]}, {"text": "These results are presented in, along with the error in the number of utterances (for bigram).", "labels": [], "entities": []}, {"text": "In general, the NGT model provides a more accurate segmentation of the dialogue turns.", "labels": [], "entities": [{"text": "NGT", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.8758808970451355}]}, {"text": "The reduction of the segmentation errors is quite significant, with relative reductions of more than a 20%.", "labels": [], "entities": [{"text": "segmentation errors", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8108530044555664}]}, {"text": "This is in general true for the estimation of the correct number of utterances (except for Dihana 2-levels).", "labels": [], "entities": []}, {"text": "With these results, we can expect that the decoding of the HMM-based model using the NGT segmentation would be of higher quality than the decodings on the unsegmented turns.", "labels": [], "entities": [{"text": "NGT segmentation", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.8097600340843201}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The evaluation is done with two measures: complete turn DA error (all the labels must be coincident) and DAER (like WER for speech recognition systems but at the DA level).", "labels": [], "entities": [{"text": "complete turn DA error", "start_pos": 42, "end_pos": 64, "type": "METRIC", "confidence": 0.9029093533754349}, {"text": "DAER", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9981396198272705}, {"text": "WER", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.7661595344543457}]}, {"text": "As was expected, the number of erroneously labelled turns increases with the unsegmented approach for both measures.", "labels": [], "entities": []}, {"text": "This relative increase is lower in the simpler dialogue corpora than in the more complex corpora.", "labels": [], "entities": []}, {"text": "The results for the NGT model are with a bigram, and they show that in the case of the SwitchBoard corpus, the quality of the DA assignation is quite better, but in the rest of cases the improvement is not significant or even negative (Dihana 2-level).", "labels": [], "entities": [{"text": "SwitchBoard corpus", "start_pos": 87, "end_pos": 105, "type": "DATASET", "confidence": 0.8295722007751465}, {"text": "DA assignation", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.7568977773189545}]}, {"text": "The results show that the clearest source of errors in DA assignation that the NGT model can produce is due to the split of the turn into a wrong number of utterances.", "labels": [], "entities": [{"text": "DA assignation", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.954542875289917}, {"text": "NGT", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.8620997071266174}]}, {"text": "This clearly induces an erroneous assignment of the DA sequence to the turn, as the number of labels will be different to the reference and, consequently, the turn will be counted as erroneous.", "labels": [], "entities": []}, {"text": "Even in the case of DAER error, this fact is present: for Dihana 2-levels, the unsegmented labelling provides a lower error rate than the NGT-segmented one.", "labels": [], "entities": [{"text": "error rate", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.936294674873352}]}, {"text": "This is sound with the error in the number of segments that provide the HMM-based and the NGT model.", "labels": [], "entities": []}, {"text": "Therefore, we can see a clear correlation between the assignation of an incorrect number of utterances and the error rates in DA assignation when using NGT-segmented turns or unsegmented turns.", "labels": [], "entities": [{"text": "assignation of an incorrect number of utterances", "start_pos": 54, "end_pos": 102, "type": "TASK", "confidence": 0.7420686398233686}, {"text": "DA assignation", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.8252312242984772}]}, {"text": "Consequently, we can conclude that segmenting into the correct number of utterances is critical to obtain a correct assignation of DA.", "labels": [], "entities": [{"text": "segmenting into the correct number of utterances", "start_pos": 35, "end_pos": 83, "type": "TASK", "confidence": 0.7177745274135044}, {"text": "assignation of DA", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.547830601533254}]}, {"text": "The DAER rate presented in confirms that considering only the turns with an incorrect segmentation but a correct number of utterances, many of them present a correct assignation of DA.", "labels": [], "entities": [{"text": "DAER", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9900193214416504}, {"text": "DA", "start_pos": 181, "end_pos": 183, "type": "METRIC", "confidence": 0.8816059231758118}]}, {"text": "The main conclusion we can extract from these experiments and results is that a correct hypothesis on the number of utterances of a dialogue turn is needed to obtain a correct assignation of DA to that turn, and that the accuracy of the segmentation is not so important.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.9991040825843811}]}, {"text": "Following these conclusions, future work will be directed to the obtainment of models that, given a dialogue turn, provide its number of utterances.", "labels": [], "entities": []}, {"text": "This hypothesis on the number of utterances can be used to restrict the exploration of possible segmentations in both the presented models and it can help to obtain better results.", "labels": [], "entities": []}, {"text": "Other work can be done to improve the models or the use of other segmentation models.", "labels": [], "entities": []}, {"text": "This can help us to obtain more general conclusions on the importance of segmentation for the DA assignation task.", "labels": [], "entities": [{"text": "DA assignation task", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.9439671039581299}]}], "tableCaptions": [{"text": " Table 1: Segmentation errors for complete turn with the NGT and HMM- based model, and errors in the number of estimated utterances for bigrams.  Best results for each corpus are shown in boldface.", "labels": [], "entities": [{"text": "NGT", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.9520977735519409}]}, {"text": " Table 2: Errors for complete turn DA assignation and DAER results (for  bigrams) with different segmentation conditions. Best results for each corpus  are shown in boldface.", "labels": [], "entities": [{"text": "Errors", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.963469386100769}, {"text": "DA assignation", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7222762852907181}, {"text": "DAER", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9313571453094482}]}]}