{"title": [{"text": "Annotating Spoken Dialogs: from Speech Segments to Dialog Acts and Frame Semantics", "labels": [], "entities": [{"text": "Speech Segments", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7098284214735031}]}], "abstractContent": [{"text": "We are interested in extracting semantic structures from spoken utterances generated within conversational systems.", "labels": [], "entities": [{"text": "extracting semantic structures from spoken utterances generated within conversational systems", "start_pos": 21, "end_pos": 114, "type": "TASK", "confidence": 0.8820006430149079}]}, {"text": "Current Spoken Language Understanding systems rely either on handwritten semantic grammars or on flat attribute-value sequence labeling.", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 8, "end_pos": 37, "type": "TASK", "confidence": 0.8344875772794088}]}, {"text": "While the former approach is known to be limited in coverage and robustness, the latter lacks detailed relations amongst attribute-value pairs.", "labels": [], "entities": [{"text": "coverage", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9752948880195618}]}, {"text": "In this paper, we describe and analyze the human annotation process of rich semantic structures in order to train semantic statistical parsers.", "labels": [], "entities": []}, {"text": "We have annotated spoken conversations from both a human-machine and a human-human spoken dialog corpus.", "labels": [], "entities": []}, {"text": "Given a sentence of the transcribed corpora, domain concepts and other linguistic features are annotated, ranging from e.g. part-of-speech tagging and constituent chunking, to more advanced annotations , such as syntactic, dialog act and predicate argument structure.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.7315934002399445}]}, {"text": "In particular , the two latter annotation layers appear to be promising for the design of complex dialog systems.", "labels": [], "entities": []}, {"text": "Statistics and mutual information estimates amongst such features are reported and compared across corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken language understanding (SLU) addresses the problem of extracting and annotating the meaning structure from spoken utterances in the context of human dialogs.", "labels": [], "entities": [{"text": "Spoken language understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8983201682567596}, {"text": "extracting and annotating the meaning structure from spoken utterances", "start_pos": 61, "end_pos": 131, "type": "TASK", "confidence": 0.6683235665162405}]}, {"text": "In spoken dialog systems (SDS) most used models of SLU are based on the identification of slots (en- * This work was partially funded by the European Commission projects LUNA (contract 33549) and ADAMACH (contract 022593).", "labels": [], "entities": []}, {"text": "tities) within one or more frames (frame-slot semantics) that is defined by the application.", "labels": [], "entities": []}, {"text": "While this model is simple and clearly insufficient to cope with interpretation and reasoning, it has supported the first generation of spoken dialog systems.", "labels": [], "entities": [{"text": "interpretation and reasoning", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.7414870659510294}]}, {"text": "Such dialog systems are thus limited by the ability to parse semantic features such as predicates and to perform logical computation in the context of a specific dialog act).", "labels": [], "entities": []}, {"text": "This limitation is reflected in the type of human-machine interactions which are mostly directed at querying the user for specific slots (e.g. \"What is the departure city?\") or implementing simple dialog acts (e.g. confirmation).", "labels": [], "entities": [{"text": "confirmation)", "start_pos": 215, "end_pos": 228, "type": "TASK", "confidence": 0.8903268277645111}]}, {"text": "We believe that an important step in overcoming such limitation relies on the study of models of human-human dialogs at different levels of representation: lexical, syntactic, semantic and discourse.", "labels": [], "entities": []}, {"text": "In this paper, we present our results in addressing the above issues in the context of the LUNA research project for next-generation spoken dialog interfaces).", "labels": [], "entities": []}, {"text": "We propose models for different levels of annotation of the LUNA spoken dialog corpus, including attributevalue, predicate argument structures and dialog acts.", "labels": [], "entities": [{"text": "LUNA spoken dialog corpus", "start_pos": 60, "end_pos": 85, "type": "DATASET", "confidence": 0.8452181816101074}]}, {"text": "We describe the tools and the adaptation of off-the-shelf resources to carryout annotation of the predicate argument structures (PAS) of spoken utterances.", "labels": [], "entities": [{"text": "predicate argument structures (PAS) of spoken utterances", "start_pos": 98, "end_pos": 154, "type": "TASK", "confidence": 0.6882059607240889}]}, {"text": "We present a quantitative analysis of such semantic structures for both human-machine and human-human conversations.", "labels": [], "entities": []}, {"text": "To the best of our knowledge this is the first (human-machine and human-human) SDS corpus denoting a multilayer approach to the annotation of lexical, semantic and dialog features, which allows us to investigate statistical relations between the layers such as shallow semantic and discourse features used by humans or machines.", "labels": [], "entities": []}, {"text": "In the following sections we describe the corpus, as well as a quantitative analysis and statistical correlations between annotation layers.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Dialog acts ranked by frequency in the  human-machine (HM) corpus", "labels": [], "entities": []}, {"text": " Table 3: Dialog acts ranked by frequency in the  human-human (HH) corpus", "labels": [], "entities": []}, {"text": " Table 5: Dialog turn and frame statistics for the  human-machine (HM) resp. human-human (HH)  corpus", "labels": [], "entities": []}, {"text": " Table 6: The 10 most frequent frames in the HM  corpus (* =newly introduced)", "labels": [], "entities": [{"text": "HM  corpus", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.8069180846214294}]}, {"text": " Table 7: The 10 most frequent frames in the HH  corpus (* =newly introduced)", "labels": [], "entities": [{"text": "HH  corpus", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.9610028564929962}]}, {"text": " Table 8: The 5 most frequent frame bigrams", "labels": [], "entities": []}, {"text": " Table 9: The 5 most frequent frame trigrams", "labels": [], "entities": []}]}