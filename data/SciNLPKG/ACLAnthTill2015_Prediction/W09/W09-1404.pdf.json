{"title": [], "abstractContent": [{"text": "We describe a biological event detection method implemented for the BioNLP 2009 Shared Task 1.", "labels": [], "entities": [{"text": "biological event detection", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.6353288491566976}, {"text": "BioNLP 2009 Shared Task 1", "start_pos": 68, "end_pos": 93, "type": "DATASET", "confidence": 0.8916048526763916}]}, {"text": "The method relies entirely on the chunk and syntactic dependency relations provided by a general NLP pipeline which was not adapted in anyway for the purposes of the shared task.", "labels": [], "entities": []}, {"text": "The method maps the syntactic relations to event structures while being guided by the probabilities of the syntactic features of events which were automatically learned from the training data.", "labels": [], "entities": []}, {"text": "Our method achieved a recall of 26% and a precision of 44% in the official test run, under \"strict equal-ity\" of events.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9993725419044495}, {"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.999357283115387}]}], "introductionContent": [{"text": "This paper describes the adaptation of an existing text mining system to the BioNLP shared task.", "labels": [], "entities": [{"text": "text mining", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.7336498200893402}, {"text": "BioNLP shared task", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.6611983378728231}]}, {"text": "The system has been originally created for participation in the BioCreative 1 protein-protein interaction task () and further developed for an internal project based on the IntAct dataset of protein interactions ().", "labels": [], "entities": [{"text": "BioCreative 1 protein-protein interaction task", "start_pos": 64, "end_pos": 110, "type": "TASK", "confidence": 0.7106707692146301}, {"text": "IntAct dataset", "start_pos": 173, "end_pos": 187, "type": "DATASET", "confidence": 0.8875603675842285}]}, {"text": "We decided to participate only in Task 1 of the BioNLP shared task, mainly because of lack of time and resources.", "labels": [], "entities": [{"text": "BioNLP shared task", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.5652010838190714}]}, {"text": "Our event annotation method relied on various preprocessing steps and an existing state of the art dependency parser, which provided the input to the event annotator.", "labels": [], "entities": []}, {"text": "As all the linguistic processing was performed by the preprocessor and the parser, the ideas implemented for the event annotator could remain simple while still producing reasonable results.", "labels": [], "entities": []}, {"text": "Thus, the event annotator performed a straightforward rewriting of syntactic structures to event structures, guided by the information on the syntactic nature of events that we obtained from the training data.", "labels": [], "entities": []}, {"text": "In this sense our system can be used as a reference fora comparison to other systems that rely completely on a dependency parser delivered analysis that is rewritten into event structures using knowledge gained from the training data.", "labels": [], "entities": []}, {"text": "Our system consists of a preprocessing phase that uses a pipeline of NLP tools, described in section 2 of this paper.", "labels": [], "entities": []}, {"text": "Linguistic resources are learned automatically from the preprocessed training data (section 3).", "labels": [], "entities": []}, {"text": "A Prolog-implemented event generator is applied directly to the preprocessing results and is guided by the relative frequencies of syntactic features provided in the resources (section 4).", "labels": [], "entities": []}, {"text": "This is followed by a postprocessing step that removes some unlikely event structures, makes sure that all events that violate the well-formedness rules are filtered out, and finally serializes the event structures into the requested output format.", "labels": [], "entities": []}, {"text": "In section 5 we present an illustrative example of the events generated by this approach and discuss some implications of the event model adopted in the shared task.", "labels": [], "entities": []}, {"text": "In section 6, we describe the evaluation that we performed during the training period, the final official results on the test data, and some alternative evaluations performed in parallel to the official one.", "labels": [], "entities": []}, {"text": "In section 7 we draw conclusions and describe future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We mainly trained and evaluated using the \"strict equality\" evaluation criteria as our reference.", "labels": [], "entities": []}, {"text": "The results on the development data are shown in table 2.", "labels": [], "entities": []}, {"text": "With more relaxed equality definitions, the results were always a few percentage points better.", "labels": [], "entities": []}, {"text": "Our results in the official testrun are shown in table 3.", "labels": [], "entities": []}, {"text": "Good results for some event structures (notably Phosphorylation) are due to the simple textual representation of these events.", "labels": [], "entities": []}, {"text": "For example, Phosphorylation is always triggered by a form or derivation of 'phosphorylate', and these forms rarely trigger any other types of events.", "labels": [], "entities": []}, {"text": "Furthermore, according to the parsed training data, the probability of a Phosphorylation-event, given a syntactic domination relation between a Phosphorylation-trigger and a protein is 0.92.", "labels": [], "entities": []}, {"text": "Also, 56% of these domination paths are either chunk-internal or over a single modpp dependency relation, making them easy to detect.", "labels": [], "entities": []}, {"text": "In parallel to the approach used in our official submission we considered some variants, aimed at maximizing either recall or precision, as well as an alternative approach based on machine learning.", "labels": [], "entities": [{"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9984604120254517}, {"text": "precision", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9864227175712585}]}, {"text": "A high recall baseline method, which generates all possible event structures in a given sentence, achieves 81% recall on simple events, with precision dropping to 11%.", "labels": [], "entities": [{"text": "recall", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.997601330280304}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9975104331970215}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.999448835849762}]}, {"text": "One of the reasons why this method does not reach 100% recall is the fact that it only annotates event candidates with single-token triggers that have been seen in the training data.", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9718782901763916}]}, {"text": "The filter described in section 4.3 has a major effect on precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9981991648674011}]}, {"text": "If it is removed, precision drops by 11%, while the gain in recall is only 3% -recall 35.10%, precision 37.88%, F-score 36.44%.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9998047947883606}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9996846914291382}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9985533356666565}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9991752505302429}, {"text": "F-score", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9966855645179749}]}, {"text": "Instead, if we keep w 1 but set w 2 = w 3 = 0 in formula 3, precision increases to 56%, while recall drops to 27%.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9998027682304382}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9997019171714783}]}, {"text": "Increasing the probability thresholds to further improve precision results in the precision of 60% but this remains the ceiling in our experiments.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.999285876750946}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9996229410171509}]}, {"text": "Additionally, we performed separate experiments with a machine-learning approach which considers a more varied set of features, including surface information and syntax coming from an ensemble of parsers.", "labels": [], "entities": []}, {"text": "However, the limited time and resources available to us during the competition did not allow us to go beyond the results achieved using the approach described in detail in this paper.", "labels": [], "entities": []}, {"text": "Since our best score on the development data was 27% (about 10% inferior to our consolidated approach), we opted for not considering this approach in our official submission.", "labels": [], "entities": []}, {"text": "The fact that this approach was based on a decomposition of events into their arguments led us to realize some fundamental limitations in the official evaluation measures.", "labels": [], "entities": []}, {"text": "In particular, none of the originally implemented measures would give credit to the partial recognition of an event (i.e. correct trigger word and at least one correct argument, but not all).", "labels": [], "entities": []}, {"text": "We contend that such partial recognition can be   useful in a practical annotation task, and yet the official scores doubly punish such an outcome (once as a FP and once as a FN).", "labels": [], "entities": [{"text": "FP", "start_pos": 158, "end_pos": 160, "type": "METRIC", "confidence": 0.8884164094924927}]}, {"text": "This is a problem already observed in previous evaluation challenges, however we believe that a simple solution in this case consists in decomposing the events (for evaluation purposes) in their constituent roles and arguments.", "labels": [], "entities": []}, {"text": "In other words, each event is given as much \"weight\" as its number of roles.", "labels": [], "entities": []}, {"text": "The correct recognition of an event with two roles would therefore lead to two TP, but its partial recognition (one argument) would still lead to one TP, which we think is a more fair evaluation in case of partial recognition.", "labels": [], "entities": [{"text": "TP", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9132320284843445}, {"text": "TP", "start_pos": 150, "end_pos": 152, "type": "METRIC", "confidence": 0.97700035572052}]}, {"text": "Our suggestion was later implemented by the organizers as an additional scoring criteria.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on the development data of 150 abstracts, measured using \"strict equality\".", "labels": [], "entities": []}, {"text": " Table 3: Results on the test data of 260 abstracts, measured using \"strict equality\", as reported by the BioNLP 2009  online evaluation system.", "labels": [], "entities": [{"text": "BioNLP 2009  online evaluation system", "start_pos": 106, "end_pos": 143, "type": "DATASET", "confidence": 0.9496220469474792}]}]}