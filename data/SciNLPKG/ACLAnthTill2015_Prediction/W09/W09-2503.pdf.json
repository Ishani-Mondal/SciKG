{"title": [{"text": "Sub-sentential Paraphrasing by Contextual Pivot Translation", "labels": [], "entities": [{"text": "Sub-sentential Paraphrasing by Contextual Pivot Translation", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.5971715946992239}]}], "abstractContent": [{"text": "The ability to generate or to recognize paraphrases is key to the vast majority of NLP applications.", "labels": [], "entities": []}, {"text": "As correctly exploiting context during translation has been shown to be successful, using context information for paraphrasing could also lead to improved performance.", "labels": [], "entities": []}, {"text": "In this article , we adopt the pivot approach based on parallel multilingual corpora proposed by (Bannard and Callison-Burch, 2005), which finds short paraphrases by finding appropriate pivot phrases in one or several auxiliary languages and back-translating these pivot phrases into the original language.", "labels": [], "entities": []}, {"text": "We show how context can be exploited both when attempting to find pivot phrases, and when looking for the most appropriate paraphrase in the original sub-sentential \"envelope\".", "labels": [], "entities": []}, {"text": "This framework allows the use of paraphrasing units ranging from words to large sub-sentential fragments for which context information from the sentence can be successfully exploited.", "labels": [], "entities": []}, {"text": "We report experiments on a text revision task, and show that in these experiments our contextual sub-sentential paraphrasing system outperforms a strong baseline system .", "labels": [], "entities": [{"text": "text revision task", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8623896439870199}]}], "introductionContent": [{"text": "The ability to generate or to recognize paraphrases is key to the vast majority of NLP applications.", "labels": [], "entities": []}, {"text": "Most current research efforts on paraphrase generation attempt to push the limits of their respective methods and resources without recourse to deep meaning interpretation, an admitedly long-term research objective.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.9576401710510254}, {"text": "deep meaning interpretation", "start_pos": 144, "end_pos": 171, "type": "TASK", "confidence": 0.7111866076787313}]}, {"text": "A step towards meaning-aware paraphrasing can be done by appropriate use of the context in which a paraphrasing occurrence occurs.", "labels": [], "entities": []}, {"text": "At the lowest level, deciding automatically when a word can be substituted with a synonym is a complex issue.", "labels": [], "entities": []}, {"text": "When attempting paraphrasing on a higher level, such as arbitrary phrases or full sentences (), a first issue concerns the acquisition of elementary units, which in the general case do not exist in predefined dictionaries.", "labels": [], "entities": []}, {"text": "Some paraphrasing strategy must then follow, which may consider the context of a substitution to guide the selection of appropriate units.", "labels": [], "entities": []}, {"text": "An important limitation to this family of works is the scarcity of corpora that can be used as reliable supervised training data.", "labels": [], "entities": []}, {"text": "Indeed, strictly parallel sentence pairs, for instance, are not naturally produced inhuman activities.", "labels": [], "entities": []}, {"text": "As a consequence, works on paraphrasing have recourse to costly human evaluation procedures, and an objective of automatic evaluation metrics is to rely on as little gold standard data as possible . A text revision task is an application of paraphrase generation where context maybe used in an effective way.", "labels": [], "entities": [{"text": "text revision task", "start_pos": 201, "end_pos": 219, "type": "TASK", "confidence": 0.8058956662813822}, {"text": "paraphrase generation", "start_pos": 241, "end_pos": 262, "type": "TASK", "confidence": 0.872605711221695}]}, {"text": "When a local change is made to a text, it occurs within a textual \"envelope\" within which a paraphrase should fit.", "labels": [], "entities": []}, {"text": "In particular, if the original sentence was grammatical, the substituted sentence should remain grammatical and convey essentially the same meaning.", "labels": [], "entities": []}, {"text": "The manner in which such a context can be exploited depends of course on the type of automatic paraphrasing technique used.", "labels": [], "entities": []}, {"text": "In this article, we adopt the pivot approach based on parallel multilingual corpora proposed by), which finds short paraphrases by finding appropriate pivot phrases in one or several auxiliary languages and back-translating these pivot phrases into the original language.", "labels": [], "entities": []}, {"text": "We show how context can be exploited both when attempting to find pivot phrases, and when looking for the most appropriate paraphrase in the original sub-sentential envelope.", "labels": [], "entities": []}, {"text": "This framework allows the use of paraphrasing units ranging from words to large subsentential fragments for which context information from the sentence can be successfully exploited.", "labels": [], "entities": []}, {"text": "This article is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we briefly review related work in paraphrasing and context-aware Machine Translation.", "labels": [], "entities": [{"text": "context-aware Machine Translation", "start_pos": 65, "end_pos": 98, "type": "TASK", "confidence": 0.5790983637173971}]}, {"text": "We describe the main characteristics of our approach to subsentential paraphrasing in section 3.", "labels": [], "entities": []}, {"text": "We then describe an evaluation protocol for evaluating our proposal and report the results of a human evaluation in section 4.", "labels": [], "entities": []}, {"text": "We finally conclude and present our future work in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have conducted experiments motivated by a text revision task that we report in this section by describing our baseline and context-aware subsentential paraphrasing systems and the results of a small-scale manual evaluation.", "labels": [], "entities": [{"text": "text revision task", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8406950632731119}]}, {"text": "A native speaker was asked to study a held-out test file of Europarl data in French and to identify at most one fragment per sentence that would be a good candidate for revision and for which the annotator could think of reasonable paraphrases that did not involve changes to the envelope.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 60, "end_pos": 73, "type": "DATASET", "confidence": 0.9765769839286804}, {"text": "revision", "start_pos": 169, "end_pos": 177, "type": "TASK", "confidence": 0.9413872957229614}]}, {"text": "Candidate fragments were accepted if they were not found in the French\u2192English translation table.", "labels": [], "entities": []}, {"text": "This step resulted in a corpus of 151 sentences with as many test fragments, with sizes ranging from 2 to 12 words, an average size of 5.38 words and a median size of 4 words.", "labels": [], "entities": []}, {"text": "Two native speakers, including the previous annotator, were asked to evaluate all paraphrased sentences on grammaticality and meaning.", "labels": [], "entities": []}, {"text": "Contrary to previous works, we decided to use a smaller evaluation scale with only 3 values, as using more values tend to result in low interannotator agreement: \u2022 2: indicates that the paraphrase is perfect or almost perfect; \u2022 1: indicates that the paraphrase could become grammatical with one minor change, or that its meaning is almost clear; \u2022 0: indicates that more than one minor change is required to make the paraphrase grammatical or understandable.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Contrastive results. The notation S cont < S bas stands for cases in which S cont is found to be  worse than S bas by both judges; S cont \u2264 S bas for cases where S cont was found to be worse by one judge  while the other found the two systems equivalent; similarly for other cases. '?' stands for cases where  judges disagreed.", "labels": [], "entities": []}, {"text": " Table 3: Absolute results for manual evaluation. '+' indicates that both judges agree on a positive  judgement (score 1 or 2), '-' that both judges agree on a negative judgment (score 0), and '?' that judges  disagreed. 'System' judgments include judgments for both Grammar and Meaning.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9731608033180237}]}]}