{"title": [{"text": "Improving Phrase-Based Translation via Word Alignments from Stochastic Inversion Transduction Grammars", "labels": [], "entities": [{"text": "Improving Phrase-Based Translation", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.885486920674642}, {"text": "Word Alignments from Stochastic Inversion Transduction Grammars", "start_pos": 39, "end_pos": 102, "type": "TASK", "confidence": 0.713058705840792}]}], "abstractContent": [{"text": "We argue that learning word alignments through a compositionally-structured, joint process yields higher phrase-based translation accuracy than the conventional heuris-tic of intersecting conditional models.", "labels": [], "entities": [{"text": "learning word alignments", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.6348602771759033}, {"text": "phrase-based translation", "start_pos": 105, "end_pos": 129, "type": "TASK", "confidence": 0.6027795672416687}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.8686791658401489}]}, {"text": "Flawed word alignments can lead to flawed phrase translations that damage translation accuracy.", "labels": [], "entities": [{"text": "Flawed word alignments", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.675152192513148}, {"text": "phrase translations", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7452267408370972}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.8544149994850159}]}, {"text": "Yet the IBM word alignments usually used today are known to be flawed, in large part because IBM models (1) model reordering by allowing unrestricted movement of words, rather than constrained movement of compositional units, and therefore must (2) attempt to compensate via directed, asymmetric distortion and fertility models.", "labels": [], "entities": [{"text": "IBM word alignments", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.5568065543969473}]}, {"text": "The conventional heuris-tics for attempting to recover from the resulting alignment errors involve estimating two directed models in opposite directions and then intersecting their alignments-to makeup for the fact that, in reality, word alignment is an inherently joint relation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 233, "end_pos": 247, "type": "TASK", "confidence": 0.7162804007530212}]}, {"text": "A natural alternative is provided by Inversion Transduction Grammars, which estimate the joint word alignment relation directly, eliminating the need for any of the conventional heuristics.", "labels": [], "entities": [{"text": "Inversion Transduction Grammars", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.7741696437199911}]}, {"text": "We show that this alignment ultimately produces superior translation accuracy on BLEU, NIST, and METEOR metrics over three distinct language pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9338449835777283}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9938099980354309}, {"text": "NIST", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.8716062903404236}, {"text": "METEOR", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.8859719038009644}]}], "introductionContent": [{"text": "In this paper we argue that word alignments learned through a compositionally-structured, joint process are able to significantly improve the training of phrase-based translation systems, leading to higher translation accuracy than the conventional heuristic of intersecting conditional models.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7057279348373413}, {"text": "phrase-based translation", "start_pos": 154, "end_pos": 178, "type": "TASK", "confidence": 0.6665975749492645}, {"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.9306213855743408}]}, {"text": "Today, statistical machine translation (SMT) systems perform at state-of-the-art levels; their ability to weigh different translation hypotheses against each other to find an optimal solution has proven to be a great asset.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.8001987387736639}]}, {"text": "What sets various SMT systems apart are the models employed to determine what to consider optimal.", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.994046688079834}]}, {"text": "The most common systems today consist of phrase-based models, where chunks of texts are substituted and rearranged to produce the output sentence.", "labels": [], "entities": []}, {"text": "Our premise is that certain flawed word alignments can lead to flawed phrase translations that in turn damage translation accuracy, since word alignment is the basis for learning phrase translations in phrase-based SMT systems.", "labels": [], "entities": [{"text": "phrase translations", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.7255275547504425}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9528205990791321}, {"text": "word alignment", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.7150862365961075}, {"text": "learning phrase translations", "start_pos": 170, "end_pos": 198, "type": "TASK", "confidence": 0.6653387049833933}, {"text": "SMT", "start_pos": 215, "end_pos": 218, "type": "TASK", "confidence": 0.8565202951431274}]}, {"text": "A critical part of such systems is the word-level translation model, which is estimated from aligned data.", "labels": [], "entities": [{"text": "word-level translation", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7258275747299194}]}, {"text": "Currently, the standard way of computing a word alignment is to estimate a function linking words in one of the languages to words in the other.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.6989210247993469}]}, {"text": "Functions can only define many-to-one relations, but word alignment is a many-to-many relation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7620705366134644}]}, {"text": "The solution is to combine two functions, one in each direction, and harmonize them by means of some heuristic.", "labels": [], "entities": []}, {"text": "After that, phrases can be extracted from the word alignments.", "labels": [], "entities": []}, {"text": "The problem is that the starting point for word alignments is usually the IBM models, which are known to produce flawed alignments, in large part because they (1) model reordering by allowing unrestricted movement of words, rather than constrained movement of compositional units, and therefore must (2) attempt to compensate via directed, asymmetric distortion and fertility models.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.7671911120414734}, {"text": "IBM models", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9315981864929199}]}, {"text": "The conventional heuristics for attempting to recover from the resulting alignment errors is to estimate two directed models in opposite directions and then intersect their alignments -to makeup for the fact that, in reality, word alignment is an inherently joint relation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 226, "end_pos": 240, "type": "TASK", "confidence": 0.7082443237304688}]}, {"text": "It is unfortunate that such a critical stage in the training process of an SMT system relies on inaccurate heuristics, which have been largely motivated by historical implementation factors, rather than principles explaining language phenomena.", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9917405843734741}]}, {"text": "Inversion Transduction Grammar (ITG) models provide a natural, alternative approach, by estimating the joint word alignment relation directly, eliminating the need for any of the conventional heuristics.", "labels": [], "entities": [{"text": "Inversion Transduction Grammar (ITG)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8109266608953476}]}, {"text": "A transduction grammar is a grammar that generates sentences in two languages (L 0 and L 1 ) simultaneously; i.e., one start symbol expands into two strings, as for example in(b).", "labels": [], "entities": []}, {"text": "A transduction grammar explains two languages simultaneously.", "labels": [], "entities": []}, {"text": "ITGs model a class of transductions (sets of sentence translations) with expressive power and computational complexity falling between (a) finite-state transducers or FSTs and (b) syntax-directed transduction grammars 1 or SDTGs.", "labels": [], "entities": [{"text": "transductions (sets of sentence translations)", "start_pos": 22, "end_pos": 67, "type": "TASK", "confidence": 0.660641074180603}]}, {"text": "An ITG produces both a common structural form fora sentence pairs, as well as relating the wordsaligning them.", "labels": [], "entities": []}, {"text": "This could actually work as the joint word alignment that is usually constructed by heuristic function combination.", "labels": [], "entities": [{"text": "joint word alignment", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.6874654293060303}]}, {"text": "Yet despite the substantial body of literature on word alignment, ITG based models, and phrasebased SMT, the existing work has not assessed the potential for improving phrase-based translation quality by using joint ITG based word alignments to replace the error-prone conditional IBM model based word alignments and associated heuristics for intersecting bidirectional IBM alignments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.7873341143131256}, {"text": "phrasebased SMT", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.5600401163101196}, {"text": "phrase-based translation", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.7282368838787079}]}, {"text": "On one hand, word alignment work is usually evaluated not on actual translation quality, but rather on artificial metrics like alignment error rate, which relies on a manually annotated gold standard word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.8385704159736633}, {"text": "alignment error rate", "start_pos": 127, "end_pos": 147, "type": "METRIC", "confidence": 0.6174570123354594}]}, {"text": "There are some indications that ITG produces better alignment then the standard method.", "labels": [], "entities": [{"text": "ITG", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.6620909571647644}]}, {"text": "There is, however, little inherent utility in alignments -their value is determined by the SMT systems one can build from them.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9836781024932861}]}, {"text": "In fact, recent Which \"synchronous CFGs\" are essentially identical to. studies have discredited the earlier assumption that lower AER is correlated with improved translation quality -the opposite can very well occur).", "labels": [], "entities": [{"text": "AER", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.9981655478477478}]}, {"text": "Therefore it is essential to evaluate the quality of the word alignment not in terms of AER, but rather in terms of actual translation quality in a system built from it.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.7094699591398239}, {"text": "AER", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.99748694896698}]}, {"text": "On the other hand, ITG models have been employed to improve translation quality as measured by), but still without directly addressing the problem of dependence on inaccurate IBM alignments.", "labels": [], "entities": []}, {"text": "construct an ITG from word alignments computed by the conventional IBM model, which does little to alleviate the problems.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.7000685632228851}]}, {"text": "use an ITG to structure a prior distribution to a phrase extraction system, which is an altogether different approach.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7679825723171234}]}, {"text": "douse ITG to build word alignments, but blur the lines by still mixing in the conventional IBM method, and focus on phrase extraction.", "labels": [], "entities": [{"text": "ITG", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.9160935282707214}, {"text": "word alignments", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.7522282600402832}, {"text": "phrase extraction", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.8392098546028137}]}, {"text": "The present work clearly demonstrates, for the first time to our knowledge, that replacing the widely-used heuristic of intersecting IBM word alignments from two directed conditional models instead with a single ITG alignment from a joint model produces superior translation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 275, "end_pos": 283, "type": "METRIC", "confidence": 0.769914448261261}]}, {"text": "The experiments are performed on three distinct language pairs: German-English, Spanish-English, and French-English.", "labels": [], "entities": []}, {"text": "Translation accuracy is reported in terms of BLEU, NIST, and METEOR metrics.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9261664152145386}, {"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9432029128074646}, {"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9984034895896912}, {"text": "NIST", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.8485314249992371}, {"text": "METEOR", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9824913144111633}]}], "datasetContent": [{"text": "We trained a total of nine systems (three tasks and three different alignments), which we evaluated with three different measures: BLEU), NIST, and METEOR.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9992784857749939}, {"text": "NIST", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.7486021518707275}, {"text": "METEOR", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.9369715452194214}]}, {"text": "shows a sentence pair as it was aligned with the two different models.", "labels": [], "entities": []}, {"text": "shows the GIZA++ alignment in both directions, and the intersection between them, whereas Figure 2(b) shows the SBITG alignment with its common structure.", "labels": [], "entities": [{"text": "GIZA++ alignment", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.7642447153727213}, {"text": "SBITG alignment", "start_pos": 112, "end_pos": 127, "type": "DATASET", "confidence": 0.7120742946863174}]}, {"text": "The asymmetric reordering mechanism of the IBM models is simply unable to relate the two halves to one another.", "labels": [], "entities": []}, {"text": "The segment zur kenntnis genommen could certainly be said to mean note, but as a verb, and not as a noun, which is the current usage of the word.", "labels": [], "entities": []}, {"text": "This is an inherent problem of the asymmetry of the IBM models, which is rectified by simultaneous alignment.", "labels": [], "entities": []}, {"text": "Again,(a) was aligned with GIZA++ and(b) with the SITG model.", "labels": [], "entities": [{"text": "GIZA++", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.8741582036018372}]}, {"text": "This shows a case with perhaps even more structured reordering, where a notion of constituency is definitely needed to get it right.", "labels": [], "entities": []}, {"text": "SITG handles constituency, and gets this issue right.", "labels": [], "entities": [{"text": "SITG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7097622752189636}]}, {"text": "The IBM models do not, resulting in the error of aligning either to aufgerufen.", "labels": [], "entities": []}, {"text": "As mentioned before, the GDFA heuristic is applied after the word alignment process, and it does fix some of these problems.", "labels": [], "entities": [{"text": "word alignment process", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.8021615544954935}]}, {"text": "Therefore we opted to evaluate this, not on alignments, but rather on translation quality of phrase based SMT systems derived from the alignments.", "labels": [], "entities": [{"text": "SMT", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.8146896958351135}]}, {"text": "Our empirical results confirm that SBITG alignments do indeed lead to better translation quality, as shown in.", "labels": [], "entities": [{"text": "SBITG", "start_pos": 35, "end_pos": 40, "type": "TASK", "confidence": 0.952518880367279}]}, {"text": "We also tried the intersect combination heuristic, and depending on language pair and evaluation metric, the GDFA and intersect heuristics come out on top.", "labels": [], "entities": []}, {"text": "The ITG approach is, however, consistently better than either of the heuristics applied to GIZA++ output.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of training data.", "labels": [], "entities": []}, {"text": " Table 2: Results. The best result on each task/metric combination is in bold digits.  (The identical results for SBITG on Spanish-English and French-English are not typos.)", "labels": [], "entities": []}]}