{"title": [{"text": "Exploring ways beyond the simple supervised learning approach for biological event extraction", "labels": [], "entities": []}], "abstractContent": [{"text": "Our paper presents the comparison of a machine-learnt and a manually constructed expert-rule-based biological event extraction system and some preliminary experiments to apply a negation and speculation detection system to further classify the extracted events.", "labels": [], "entities": [{"text": "expert-rule-based biological event extraction", "start_pos": 81, "end_pos": 126, "type": "TASK", "confidence": 0.6265865117311478}, {"text": "negation and speculation detection", "start_pos": 178, "end_pos": 212, "type": "TASK", "confidence": 0.7612812519073486}]}, {"text": "We report results on the BioNLP'09 Shared Task on Event Extraction evaluation datasets, and also on an external dataset for negation and speculation detection.", "labels": [], "entities": [{"text": "BioNLP'09 Shared Task on Event Extraction evaluation datasets", "start_pos": 25, "end_pos": 86, "type": "DATASET", "confidence": 0.6833228021860123}, {"text": "negation and speculation detection", "start_pos": 124, "end_pos": 158, "type": "TASK", "confidence": 0.6986365392804146}]}], "introductionContent": [{"text": "When we consider the sizes of publicly available biomedical scientific literature databases for researchers, valuable biological knowledge is accessible today in enormous amounts.", "labels": [], "entities": []}, {"text": "The efficient processing of these large text collections is becoming an increasingly important issue in Natural Language Processing.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.6807255148887634}]}, {"text": "For a survey on techniques used in biological Information Extraction, see.", "labels": [], "entities": [{"text": "biological Information Extraction", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.6962479948997498}]}, {"text": "The BioNLP'09 Shared Task () involved the recognition of bio-molecular events in scientific abstracts.", "labels": [], "entities": [{"text": "recognition of bio-molecular events in scientific abstracts", "start_pos": 42, "end_pos": 101, "type": "TASK", "confidence": 0.816341085093362}]}, {"text": "In this paper we describe our systems submitted to the event detection and characterization (Task1) and the recognition of negations and speculations (Task3) subtasks.", "labels": [], "entities": [{"text": "event detection and characterization", "start_pos": 55, "end_pos": 91, "type": "TASK", "confidence": 0.7838627398014069}]}, {"text": "Our experiments can be regarded as case studies on i) how to define a framework fora hybrid human-machine biological information extraction system, ii) how the linguistic scopes of negation/speculation keywords relate to biological event annotations.", "labels": [], "entities": [{"text": "human-machine biological information extraction", "start_pos": 92, "end_pos": 139, "type": "TASK", "confidence": 0.757961630821228}, {"text": "negation/speculation keywords", "start_pos": 181, "end_pos": 210, "type": "TASK", "confidence": 0.8035189509391785}]}, {"text": "* On leave from RGAI of Hungarian Acad.", "labels": [], "entities": [{"text": "RGAI", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.8211513757705688}, {"text": "Hungarian Acad.", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.9263765215873718}]}], "datasetContent": [{"text": "First we evaluated our negation and speculation keyword/non-keyword classification models on the BioScope corpus by 5-fold cross-validation.", "labels": [], "entities": [{"text": "negation and speculation keyword/non-keyword classification", "start_pos": 23, "end_pos": 82, "type": "TASK", "confidence": 0.5766588492052895}, {"text": "BioScope corpus", "start_pos": 97, "end_pos": 112, "type": "DATASET", "confidence": 0.949324756860733}]}, {"text": "We trained models for 15 negation and 41 speculative keywords.", "labels": [], "entities": []}, {"text": "We considered different word forms of the same lemma to be different keywords because they maybe used in a different meaning/context.", "labels": [], "entities": []}, {"text": "For instance, different keyword/non-keyword decision rules must be used for appear, appears and appeared.", "labels": [], "entities": []}, {"text": "We trained a C4.5 decision tree using word uni-and bigram features and POS codes to discriminate keyword/non-keyword uses and compared the results with the most frequent class (MFC) baseline.", "labels": [], "entities": []}, {"text": "Overall, our context-based classification method outperformed the baseline algorithm by 3.7% (giving an error reduction of 46%) and 3.1% (giving an error reduction of 27%) on the negation and speculation keywords, respectively.", "labels": [], "entities": [{"text": "context-based classification", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.6712944209575653}, {"text": "error reduction", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.9225607216358185}]}, {"text": "The learnt models were typically very small decision trees i.e. they represented very simple rules indicating collocations (like 'hypothesis is a keyword if and only if followed by that, etc.).", "labels": [], "entities": []}, {"text": "More complex rules (e.g. 'clear is a keyword if and only if not is in \u00b13 environment') were learnt just in a few cases.", "labels": [], "entities": []}, {"text": "Our second set of experiments focused on Task3 of the shared task (.", "labels": [], "entities": []}, {"text": "As the official evaluation process of Task3 was built upon the detected events of Task1, it did not provide any useful feedback about our negation and speculation detection approach.", "labels": [], "entities": [{"text": "negation and speculation detection", "start_pos": 138, "end_pos": 172, "type": "TASK", "confidence": 0.7880704551935196}]}, {"text": "Thus instead of our Task1 output, we evaluated our model on the gold standard Task1 annotation of the training and the development datasets.", "labels": [], "entities": []}, {"text": "The statistical parts of the system were learnt on the BioScope corpus, thus the train set was kept blind as well.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9783479571342468}]}, {"text": "summarises the results obtained by the explicit negation, speculation and by the full speculation (both explicit and implicit keywords) detection methods.", "labels": [], "entities": []}, {"text": "Analysing the errors of the system, we found that most of the false positives came from the different approaches of the BioScope and the Genia annotations (see below fora detailed discussion).", "labels": [], "entities": [{"text": "BioScope", "start_pos": 120, "end_pos": 128, "type": "DATASET", "confidence": 0.8040333986282349}]}, {"text": "Most of the false negative predictions were a consequence of the incompleteness of our keyword list.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of rule based-system compared to the  statistical and combined systems (R/P/fscore)  All Event  Gene exp.  Phosph.  stat.  16 / 31 / 21 36 / 41 / 38 73 / 37 / 49  rule  5 / 80 / 10  20 / 85 / 33 17 / 58 / 26  hybrid 22 / 37 / 27 56 / 51 / 54 81 / 40 / 53", "labels": [], "entities": []}, {"text": " Table 3: Negation and speculation detection results", "labels": [], "entities": [{"text": "Negation and speculation detection", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.898019328713417}]}]}