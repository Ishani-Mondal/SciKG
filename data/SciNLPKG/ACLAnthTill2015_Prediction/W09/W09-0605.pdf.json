{"title": [{"text": "Probabilistic Approaches for Modeling Text Structure and their application to Text-to-Text Generation", "labels": [], "entities": [{"text": "Modeling Text Structure", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.823479970296224}, {"text": "Text-to-Text Generation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7200983762741089}]}], "abstractContent": [{"text": "Text-to-text generation aims to produce a coherent text by extracting, combining and rewriting information given in input texts.", "labels": [], "entities": [{"text": "Text-to-text generation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7595745325088501}]}, {"text": "Examples of its applications include summarization, answer fusion in question-answering and text simplification.", "labels": [], "entities": [{"text": "summarization", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.9900760054588318}, {"text": "answer fusion", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.866006463766098}, {"text": "text simplification", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.7806797623634338}]}, {"text": "At first glance, text-to-text generation seems a much easier task than the traditional generation setup where the input consists of a non-linguistic representation.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.7214697897434235}]}, {"text": "Research in summarization over the last decade proved that the opposite is true-texts generated by these methods rarely match the quality of those written by humans.", "labels": [], "entities": []}, {"text": "One of the key reasons is the lack of coherence in the generated text.", "labels": [], "entities": []}, {"text": "In contrast to the traditional setup in concept-to-text generation, these applications do not have access to semantic representations and domain-specific communication knowledge.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.785987377166748}]}, {"text": "Therefore, traditional approaches for content selection cannot be employed in text-to-text applications.", "labels": [], "entities": [{"text": "content selection", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7824772298336029}]}, {"text": "These considerations motivate the development of novel approaches for document organization that can exclusively rely on information available in textual input.", "labels": [], "entities": [{"text": "document organization", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.6690844595432281}]}, {"text": "In this talk, I will present models of document structure that can be effectively used to guide content selection in text-to-text generation.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.7126057595014572}]}, {"text": "First, I will focus on unsupervised learning of domain-specific content models.", "labels": [], "entities": []}, {"text": "These models capture the topics addressed in a text, and the order in which these topics appear; they are close in their functionality to the content planners traditionally used in concept-to-text generation.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 181, "end_pos": 207, "type": "TASK", "confidence": 0.7600311934947968}]}, {"text": "I will present an effective method for learning content models from unannotated domain-specific documents, utilizing hierarchical Bayesian methods.", "labels": [], "entities": []}, {"text": "Incorporation of these models into information ordering and summarization applications yields substantial improvement over previously proposed methods.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.8430152237415314}, {"text": "summarization", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.7029819488525391}]}, {"text": "Next, I will present a method for assessing the coherence of a generated text.", "labels": [], "entities": []}, {"text": "The key premise of our work is that the distribution of entities in coherent texts exhibits certain regularities.", "labels": [], "entities": []}, {"text": "The models I will be presenting operate over an automatically-computed representation that reflects distributional, syntactic, and referential information about discourse entities.", "labels": [], "entities": []}, {"text": "This representation allows us to induce the properties of coherent texts from a given corpus, without recourse to manual annotation or a predefined knowledge base.", "labels": [], "entities": []}, {"text": "I will show how these models can be effectively integrated in text-to-text applications such as summarization and answer fusion.", "labels": [], "entities": [{"text": "summarization", "start_pos": 96, "end_pos": 109, "type": "TASK", "confidence": 0.9891913533210754}, {"text": "answer fusion", "start_pos": 114, "end_pos": 127, "type": "TASK", "confidence": 0.8905925154685974}]}, {"text": "This is joint work with Branavan, Harr Chen, Mirella Lapata and Lillian Lee.", "labels": [], "entities": [{"text": "Branavan", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8655876517295837}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}