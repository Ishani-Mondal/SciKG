{"title": [{"text": "The University of Maryland Statistical Machine Translation System for the Fourth Workshop on Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6007294158140818}, {"text": "Machine Translation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.737643301486969}]}], "abstractContent": [{"text": "This paper describes the techniques we explored to improve the translation of news text in the German-English and Hungarian-English tracks of the WMT09 shared translation task.", "labels": [], "entities": [{"text": "translation of news text", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.899405226111412}, {"text": "WMT09 shared translation task", "start_pos": 146, "end_pos": 175, "type": "TASK", "confidence": 0.7587655484676361}]}, {"text": "Beginning with a convention hierarchical phrase-based system , we found benefits for using word seg-mentation lattices as input, explicit generation of beginning and end of sentence markers, minimum Bayes risk decoding, and incorporation of a feature scoring the alignment of function words in the hypothesized translation.", "labels": [], "entities": []}, {"text": "We also explored the use of monolingual paraphrases to improve coverage, as well as co-training to improve the quality of the segmentation lattices used, but these did not lead to improvements .", "labels": [], "entities": []}], "introductionContent": [{"text": "For the shared translation task of the Fourth Workshop on Machine Translation (WMT09), we focused on two tasks: German to English and Hungarian to English translation.", "labels": [], "entities": [{"text": "Fourth Workshop on Machine Translation (WMT09)", "start_pos": 39, "end_pos": 85, "type": "TASK", "confidence": 0.6592132933437824}, {"text": "Hungarian to English translation", "start_pos": 134, "end_pos": 166, "type": "TASK", "confidence": 0.5941408276557922}]}, {"text": "Despite belonging to different language families, German and Hungarian have three features in common that complicate translation into English: 1.", "labels": [], "entities": [{"text": "translation", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.9696584343910217}]}, {"text": "productive compounding (especially of nouns), 2.", "labels": [], "entities": [{"text": "productive compounding", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7043573260307312}]}, {"text": "rich inflectional morphology, 3.", "labels": [], "entities": []}, {"text": "widespread mid-to long-range word order differences with respect to English.", "labels": [], "entities": []}, {"text": "Since these phenomena are poorly addressed with conventional approaches to statistical machine translation, we chose to work primarily toward mitigating their negative effects when constructing our systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.6542574763298035}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the baseline model, Section 3 describes the various strategies we employed to address the challenges just listed, and Section 4 summarizes the final translation system.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the official evaluation criterion for WMT09 is human sentence ranking, we chose to minimize a linear combination of two common evaluation metrics, BLEU and TER (), during system development and tuning: Although we are not aware of any work demonstrating that this combination of metrics correlates better than either individually in sentence ranking, Yaser Al-Onaizan (personal communication) reports that it correlates well with the human evaluation metric HTER.", "labels": [], "entities": [{"text": "WMT09", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.516864001750946}, {"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9991126656532288}, {"text": "TER", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.9920915365219116}]}, {"text": "In this paper, we report uncased TER and BLEU individually.", "labels": [], "entities": [{"text": "TER", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.975760817527771}, {"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9949585795402527}]}, {"text": "This section describes the experimental variants explored.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Impact of modeling sentence boundaries.", "labels": [], "entities": []}, {"text": " Table 3: Impact of alignment dominance feature.", "labels": [], "entities": [{"text": "alignment dominance", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.8134948909282684}]}]}