{"title": [{"text": "Multilingual Dependency Learning: Exploiting Rich Features for Tagging Syntactic and Semantic Dependencies", "labels": [], "entities": [{"text": "Tagging Syntactic and Semantic Dependencies", "start_pos": 63, "end_pos": 106, "type": "TASK", "confidence": 0.8552937746047974}]}], "abstractContent": [{"text": "This paper describes our system about multilingual syntactic and semantic dependency parsing for our participation in the joint task of CoNLL-2009 shared tasks.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.6728529334068298}]}, {"text": "Our system uses rich features and incorporates various integration technologies.", "labels": [], "entities": []}, {"text": "The system is evaluated on in-domain and out-of-domain evaluation data of closed challenge of joint task.", "labels": [], "entities": []}, {"text": "For in-domain evaluation, our system ranks the second for the average macro labeled F1 of all seven languages, 82.52% (only about 0.1% worse than the best system), and the first for English with macro labeled F1 87.69%.", "labels": [], "entities": [{"text": "F1", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.88663649559021}]}, {"text": "And for out-of-domain evaluation, our system also achieves the second for average score of all three languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the system of National Institute of Information and Communications Technology (NICT) and City University of Hong Kong (CityU) for the joint learning task of CoNLL-2009 shared task . The system is basically a pipeline of syntactic parser and semantic parser.", "labels": [], "entities": []}, {"text": "We use a syntactic parser that uses very rich features and integrates graph-and transition-based methods.", "labels": [], "entities": []}, {"text": "As for the semantic parser, a group of well selected feature templates are used with n-best syntactic features.", "labels": [], "entities": []}, {"text": "Our thanks give to the following corpus providers,;) and ().", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents the technical details of our syntactic dependency parsing.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6850240727265676}]}, {"text": "Section 3 describes the details of the semantic dependency parsing.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.701624353726705}]}, {"text": "Section 4 shows the evaluation results.", "labels": [], "entities": []}, {"text": "Section 5 looks into a few issues concerning our forthcoming work for this shared task, and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two tracks (closed and open challenges) are provided for joint task of CoNLL2009 shared task.", "labels": [], "entities": [{"text": "CoNLL2009", "start_pos": 71, "end_pos": 80, "type": "DATASET", "confidence": 0.8100675940513611}]}, {"text": "We participated in the closed challenge and evaluated our system on the in-domain and out-of-domain evaluation data.: The effect of rich features for syntactic dependency parsing", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 150, "end_pos": 178, "type": "TASK", "confidence": 0.7039209206899008}]}], "tableCaptions": [{"text": " Table 3: Feature template sets:n-best vs. non-n-best", "labels": [], "entities": []}, {"text": " Table 6: The official results of our submission for out-of- domain task(%)", "labels": [], "entities": []}, {"text": " Table 7: The effect of rich features for syntactic depen- dency parsing", "labels": [], "entities": [{"text": "syntactic depen- dency parsing", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6431540369987487}]}, {"text": " Table 5: The official results of our joint submission (%)", "labels": [], "entities": []}, {"text": " Table 8: The performance in development set (semantic  labeled F1) vs. training corpus size", "labels": [], "entities": [{"text": "F1", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9715069532394409}]}, {"text": " Table 9: Our system's rank within the joint task according to three main measures", "labels": [], "entities": []}, {"text": " Table 10: The performance differences between our system and the best one within the joint task according to three  main measures", "labels": [], "entities": []}]}