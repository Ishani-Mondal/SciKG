{"title": [{"text": "Using Web Selectors for the Disambiguation of All Words", "labels": [], "entities": [{"text": "Disambiguation of All Words", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.7876571267843246}]}], "abstractContent": [{"text": "This research examines a word sense dis-ambiguation method using selectors acquired from the Web.", "labels": [], "entities": [{"text": "word sense dis-ambiguation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.6837741235891978}]}, {"text": "Selectors describe words which may take the place of another given word within its local context.", "labels": [], "entities": []}, {"text": "Work in using Web selectors for noun sense disambiguation is generalized into the disambiguation of verbs, adverbs , and adjectives as well.", "labels": [], "entities": [{"text": "noun sense disambiguation", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.7868461608886719}]}, {"text": "Additionally, this work incorporates previously ignored adverb context selectors and explores the effectiveness of each type of context selector according to its part of speech.", "labels": [], "entities": []}, {"text": "Overall results for verb, adjective, and adverb disambigua-tion are well above a random baseline and slightly below the most frequent sense base-line, a point which noun sense disambigua-tion overcomes.", "labels": [], "entities": []}, {"text": "Our experiments find that, for noun and verb sense disambiguation tasks, each type of context selector may assist target selectors in disambiguation.", "labels": [], "entities": [{"text": "noun and verb sense disambiguation tasks", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.6711423794428507}]}, {"text": "Finally, these experiments also help to draw insights about the future direction of similar research.", "labels": [], "entities": []}], "introductionContent": [{"text": "The great amount of text on the Web has emerged as an unprecedented electronic source of natural language.", "labels": [], "entities": []}, {"text": "Recently, word sense disambiguation systems have fostered the size of the Web in order to supplant the issue of limited annotated data availability for supervised systems).", "labels": [], "entities": []}, {"text": "Some unsupervised or minimally supervised methods use the Web more directly in disambiguation algorithms that do not use a training set for the specific target words.", "labels": [], "entities": []}, {"text": "One such minimally supervised method uses selectors acquired from the Web for noun sense disambiguation by comparing the selectors of a given sentence to a target noun within the sentence (.", "labels": [], "entities": [{"text": "noun sense disambiguation", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.8188069264094034}]}, {"text": "Although this work found strong results, many aspects of the use of selectors was left unexplored.", "labels": [], "entities": [{"text": "selectors", "start_pos": 68, "end_pos": 77, "type": "TASK", "confidence": 0.9602036476135254}]}, {"text": "For one, the method was only applied to noun sense disambiguation, focusing on the welldeveloped noun hypernym hierarchy within WordNet (.", "labels": [], "entities": [{"text": "noun sense disambiguation", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7914069692293803}, {"text": "WordNet", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.9641482830047607}]}, {"text": "Additionally, the role of different types of selectors was not extensively explored, and adverb selectors were not used at all.", "labels": [], "entities": []}, {"text": "We seek to address those issues.", "labels": [], "entities": []}, {"text": "In this paper, we extend our method of using selectors from the Web for noun sense disambiguation into a more robust method of disambiguating words of all parts of speech.", "labels": [], "entities": [{"text": "noun sense disambiguation", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.7612767616907755}]}, {"text": "After a brief background on selectors and related work, we explain the acquisition and empirical application of selectors from nouns, verbs, adjectives, pronouns/proper nouns, and adverbs.", "labels": [], "entities": []}, {"text": "Finally, results are presented from the SemEval-2007 coarse grained all-words task (, and we explore the influence of various types of selectors on the algorithm in order to draw insight for future improvement of Web-based methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are run over the SemEval2007 Task 7: coarse-grained English all-words.", "labels": [], "entities": [{"text": "SemEval2007 Task 7", "start_pos": 33, "end_pos": 51, "type": "DATASET", "confidence": 0.6295244097709656}]}, {"text": "The sense inventory was created by mapping senses in WordNet 2.1 to the Oxford Dictionary of English ().", "labels": [], "entities": [{"text": "Oxford Dictionary of English", "start_pos": 72, "end_pos": 100, "type": "DATASET", "confidence": 0.9350786954164505}]}, {"text": "The corpus was composed of five documents with differing domains resulting in 2269 annotated word instances.", "labels": [], "entities": []}, {"text": "Our system runs on finegrained WordNet senses, but evaluation is done by checking if the predicted fine-grained sense maps to the correct coarse-grained sense.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.9217177033424377}]}, {"text": "Many issues associated with fine-grained annotation, such as those brought up in () are avoided through the use of this corpus.", "labels": [], "entities": []}, {"text": "First, we apply the generalized Web selector algorithm in a straight-forward manner to the entire task.", "labels": [], "entities": []}, {"text": "Then, we delve into analyzing the acquired selectors and the influence of each type of context selector in order to gain insights into future related work., NUS-PT = (, and SSI = a task organizer's system (Navigli and Velardi, 2005)).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results as F1 Values of our system, WS,  compared with baselines: random, BL Rand ; most fre- quent sense, BL M F S ; median system performance at Se- mEval07, MED.", "labels": [], "entities": [{"text": "F1", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.9947683811187744}, {"text": "BL Rand", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9131849408149719}, {"text": "BL M F S", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9346026182174683}, {"text": "MED", "start_pos": 170, "end_pos": 173, "type": "METRIC", "confidence": 0.9622023701667786}]}, {"text": " Table 3: Results as F1 Values of top performing systems  for the SemEval07 Task07 (UPV = (", "labels": [], "entities": [{"text": "F1", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.9965296387672424}, {"text": "SemEval07 Task07", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.5852364748716354}]}, {"text": " Table  3. Our overall results were just below that of the top  system not utilizing training data, (UPV-WSD", "labels": [], "entities": [{"text": "UPV-WSD", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9097545146942139}]}, {"text": " Table 4. We see that adjective disambiguation  was the furthest above our median point of refer- ence, and noun disambiguation results were above  the MFS baseline. On the other hand, our adverb  disambiguation results appear weakest compared to  the baselines. Note that we previously reported a  noun sense disambiguation F1 value of 80.20% on  the same corpus (", "labels": [], "entities": [{"text": "adjective disambiguation", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.7251165360212326}, {"text": "noun disambiguation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.6859101057052612}, {"text": "MFS baseline", "start_pos": 152, "end_pos": 164, "type": "DATASET", "confidence": 0.8197427690029144}, {"text": "noun sense disambiguation F1 value", "start_pos": 299, "end_pos": 333, "type": "TASK", "confidence": 0.6622793078422546}]}, {"text": " Table 5: Various statistics on the acquired selectors for  the SemEval07 Task 7 broken down by part of speech.  Row descriptions are in the text.", "labels": [], "entities": [{"text": "SemEval07 Task 7", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7573256293932596}]}, {"text": " Table 6: Precision when disambiguating with target se- lectors only. All instances contain target selectors and  multiple senses in WordNet. (insts. = number of in- stances disambiguated.)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.991241455078125}, {"text": "WordNet", "start_pos": 133, "end_pos": 140, "type": "DATASET", "confidence": 0.9783274531364441}]}, {"text": " Table 7: Instance occurrences used for disambiguation  when experimenting with all types of context selectors  (listed as columns). The rows represent the four parts of  speech disambiguated.", "labels": [], "entities": []}]}