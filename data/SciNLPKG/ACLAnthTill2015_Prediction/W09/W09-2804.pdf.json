{"title": [{"text": "Optimization-based Content Selection for Opinion Summarization", "labels": [], "entities": [{"text": "Optimization-based Content Selection", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7483094731966654}, {"text": "Summarization", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.8022657036781311}]}], "abstractContent": [{"text": "We introduce a content selection method for opinion summarization based on a well-studied, formal mathematical model, the p-median clustering problem from facility location theory.", "labels": [], "entities": [{"text": "opinion summarization", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.656421348452568}]}, {"text": "Our method replaces a series of local, myopic steps to content selection with a global solution, and is designed to allow content and realization decisions to be naturally integrated.", "labels": [], "entities": []}, {"text": "We evaluate and compare our method against an existing heuristic-based method on content selection, using human selections as a gold standard.", "labels": [], "entities": [{"text": "content selection", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7529222965240479}]}, {"text": "We find that the algorithms perform similarly, suggesting that our content selection method is robust enough to support integration with other aspects of summarization.", "labels": [], "entities": [{"text": "content selection", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.7389606535434723}, {"text": "summarization", "start_pos": 154, "end_pos": 167, "type": "TASK", "confidence": 0.9783420562744141}]}], "introductionContent": [{"text": "It is now possible to find a large amount of information on people's opinions on almost every subject online.", "labels": [], "entities": []}, {"text": "The ability to analyze such information is critical in complex, high-stakes decision making processes.", "labels": [], "entities": [{"text": "decision making", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.8043473362922668}]}, {"text": "At the individual level, someone wishing to buy a laptop may read customer reviews from others who have purchased and used the product.", "labels": [], "entities": []}, {"text": "At the corporate level, customer feedback on a newly launched product may help to identify weaknesses and features that are in need of improvement).", "labels": [], "entities": []}, {"text": "Effective summarization systems are thus needed to convey people's opinions to users.", "labels": [], "entities": []}, {"text": "A challenging problem in implementing this approach in a particular domain is to devise a content selection strategy that identifies what key information should be presented.", "labels": [], "entities": []}, {"text": "In general, content selection is a critical task at the core of both summarization and NLG and it represents a promising area for cross-fertilization.", "labels": [], "entities": [{"text": "content selection", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.807561993598938}, {"text": "summarization", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.9723010659217834}]}, {"text": "Existing NLG systems tend to approach content selection by defining a heuristic based on several relevant factors, and maximizing this heuristic function.", "labels": [], "entities": [{"text": "content selection", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7752334773540497}]}, {"text": "ILEX (Intelligent Labelling Explorer) is a system for generating labels for sets of objects defined in a database, such as for museum artifacts (O').", "labels": [], "entities": []}, {"text": "Its content selection strategy involves computing a heuristic relevance score for knowledge elements, and returning the items with the highest scores.", "labels": [], "entities": [{"text": "content selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7102891653776169}]}, {"text": "In GEA (Generator of Evaluative Arguments), evaluative arguments are generated to describe an entity as positive or negative).", "labels": [], "entities": []}, {"text": "An entity is decomposed into a hierarchy of features, and a relevance score is independently calculated for each feature, based on the preferences of the user and the value of that feature for the product.", "labels": [], "entities": [{"text": "relevance score", "start_pos": 60, "end_pos": 75, "type": "METRIC", "confidence": 0.9316215813159943}]}, {"text": "Content selection involves selecting the most relevant features for the current user.", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7542817890644073}]}, {"text": "There is also work in sentiment analysis relying on optimization or clustering-based approaches.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9806182980537415}]}, {"text": "frame the problem of detecting subjective sentences as finding the minimum cut in a graph representation of the sentences.", "labels": [], "entities": []}, {"text": "They produce compressed versions of movie reviews using just the subjective sentences, which retain the polarity information of the review.", "labels": [], "entities": []}, {"text": "use a heuristic approach to cluster sentences drawn from car reviews, grouping sentences that share common terms, especially those salient in the domain such as 'drive' or 'handling'.", "labels": [], "entities": []}, {"text": "The resulting clusters are displayed by a Treemap visualization.", "labels": [], "entities": []}, {"text": "Our work is most similar to the content selection method of the multimedia conversation system RIA (Responsive Information Architect) ().", "labels": [], "entities": [{"text": "content selection", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.6937083750963211}]}, {"text": "In RIA, content selection involves selecting dimensions (such as price in the real estate domain) in response to a query such that the desirability of the dimensions selected for the query is maximized while respect-ing time and space constraints.", "labels": [], "entities": [{"text": "RIA", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9803286790847778}, {"text": "content selection", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.6828954815864563}]}, {"text": "The maximization of desirability is implemented as an optimization problem similar to a knapsack problem.", "labels": [], "entities": []}, {"text": "RIA's content selection method performs similarly to expert human designers, but the evaluation is limited in scale (two designers, each annotating two series of queries to the system), and no heuristic alternative is compared against it.", "labels": [], "entities": [{"text": "content selection", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.6445839107036591}]}, {"text": "Our work also frames content selection as a formal optimization problem, but we apply this model to the domain of opinion summarization.", "labels": [], "entities": [{"text": "content selection", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.8054541647434235}, {"text": "opinion summarization", "start_pos": 114, "end_pos": 135, "type": "TASK", "confidence": 0.6975729167461395}]}, {"text": "A key advantage of formulating a content selection strategy as a p-median optimization problem is that the resulting framework can be extended to select other characteristics of the summary at the same time as the information content, such as the realization strategy with which the content is expressed.", "labels": [], "entities": []}, {"text": "The p-median clustering works as a module separate from its interpretation as the solution to a content selection problem, so we can freely modify the conversion process from the selection problem to the clustering problem.", "labels": [], "entities": []}, {"text": "Work in NLG and summarization has shown that content and realization decisions (including media allocation) are often dependent on each other, which should be reflected in the summarization process.", "labels": [], "entities": [{"text": "summarization", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.990959644317627}]}, {"text": "For example, in multi-modal summarization, complex information can be more effectively conveyed by combining graphics and text).", "labels": [], "entities": []}, {"text": "While graphics can present large amounts of data compactly and support the discovery of trends and relationships, text is much more effective at explaining key points about the data.", "labels": [], "entities": []}, {"text": "In another case specific to opinion summarization, the controversiality of the opinions in a corpus was found to correlate with the type of text summary, with abstractive summarization being preferred when the controversiality is high.", "labels": [], "entities": [{"text": "opinion summarization", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.6964665949344635}]}, {"text": "We first test whether our optimization-based approach can achieve reasonable performance on content selection alone.", "labels": [], "entities": []}, {"text": "As a contribution of this paper, we compare our optimization-based approach to a previously proposed heuristic method.", "labels": [], "entities": []}, {"text": "Because our approach replaces a set of myopic decisions with an extensively studied procedure (the p-median problem) that is able to find a global solution, we hypothesized our approach would produce better selections.", "labels": [], "entities": []}, {"text": "The results of our study indicate that our optimization-based content selection strategy performs about as well as the heuristic method.", "labels": [], "entities": [{"text": "optimization-based content selection", "start_pos": 43, "end_pos": 79, "type": "TASK", "confidence": 0.6500471631685892}]}, {"text": "These results suggest that our framework is robust enough for integrating other aspects of summarization with content selection.", "labels": [], "entities": [{"text": "summarization", "start_pos": 91, "end_pos": 104, "type": "TASK", "confidence": 0.9833784699440002}, {"text": "content selection", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.6884677410125732}]}], "datasetContent": [{"text": "Using this human gold standard, we can now compare the greedy heuristic and the p-median strategies.", "labels": [], "entities": []}, {"text": "We report the agreement between the human and machine selections in terms of kappa and aversion of the Pyramid method.", "labels": [], "entities": [{"text": "aversion", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9829615950584412}]}, {"text": "The Pyramid method is a summarization evaluation scheme built upon the observation that human summaries can be equally informative despite being divergent in content ().", "labels": [], "entities": [{"text": "summarization evaluation", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.9157446622848511}]}, {"text": "In the Pyramid method, Summary Content Units (SCUs) in a set of human-written model summaries are manually identified and annotated.", "labels": [], "entities": []}, {"text": "These SCUs are placed into a pyramid with different tiers, corresponding to the number of model (i.e. human) summaries in which each SCU appears.", "labels": [], "entities": []}, {"text": "A summary to be evaluated is similarly annotated by SCUs and is scored by the scores of its SCUs, which are the tier of the pyramid in which the SCU appears.", "labels": [], "entities": []}, {"text": "The Pyramid score is defined as the sum of the weights of the SCUs in the evaluated summary divided by the maximum score achievable with this number of SCUs, if we were to take SCUs starting from the highest tier of the pyramid.", "labels": [], "entities": []}, {"text": "Thus, a summary scores highly if its SCUs are found in many of the model summaries.", "labels": [], "entities": []}, {"text": "We use UDFs rather than text passages as SCUs, since UDFs are the basic units of content in our selections.", "labels": [], "entities": []}, {"text": "Moderate inter-annotator agreement between human feature selections shows that our data fits the assumption of the Pyramid method (i.e. diversity of human annotations); the Fleiss' kappa (1971) scores for the human selections ranged from 0.2984 to 0.6151, with a mean of 0.4456 among all 33 sets which were evaluated.", "labels": [], "entities": []}, {"text": "A kappa value above 0.6 is generally taken to indicate substantial agreement.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics on the 36 generated data sets.  At depth 1, 134 of the 407 features in total across  the trees were barren. The generated tree hierar- chies were quite flat, with a maximum depth of 2.", "labels": [], "entities": []}, {"text": " Table 3: Cohen's kappa for heuristic greedy and  p-median methods against human selections. Two  versions of the measure of importance were tested,  one using squared P/S scores, the other using ab- solute values.", "labels": [], "entities": []}]}