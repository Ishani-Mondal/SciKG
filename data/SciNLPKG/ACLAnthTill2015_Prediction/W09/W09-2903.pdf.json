{"title": [{"text": "Verb Noun Construction MWE Token Supervised Classification", "labels": [], "entities": [{"text": "Verb Noun Construction MWE Token Supervised Classification", "start_pos": 0, "end_pos": 58, "type": "DATASET", "confidence": 0.933102718421391}]}], "abstractContent": [{"text": "We address the problem of classifying multi-word expression tokens in running text.", "labels": [], "entities": [{"text": "classifying multi-word expression tokens", "start_pos": 26, "end_pos": 66, "type": "TASK", "confidence": 0.8021167665719986}]}, {"text": "We focus our study on Verb-Noun Constructions (VNC) that vary in their idiomaticity depending on context.", "labels": [], "entities": [{"text": "Verb-Noun Constructions (VNC)", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.7070115268230438}]}, {"text": "VNC tokens are classified as either idiomatic or literal.", "labels": [], "entities": []}, {"text": "We present a supervised learning approach to the problem.", "labels": [], "entities": []}, {"text": "We experiment with different features.", "labels": [], "entities": []}, {"text": "Our approach yields the best results to date on MWE classification combining different linguistically motivated features, the overall performance yields an F-measure of 84.58% corresponding to an F-measure of 89.96% for idiomaticity identification and classification and 62.03% for literal identification and classification.", "labels": [], "entities": [{"text": "MWE classification", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.9612683951854706}, {"text": "F-measure", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9979755282402039}, {"text": "F-measure", "start_pos": 196, "end_pos": 205, "type": "METRIC", "confidence": 0.9954792261123657}, {"text": "idiomaticity identification and classification", "start_pos": 220, "end_pos": 266, "type": "TASK", "confidence": 0.7348458468914032}, {"text": "literal identification and classification", "start_pos": 282, "end_pos": 323, "type": "TASK", "confidence": 0.8115182518959045}]}], "introductionContent": [{"text": "In the literature in general a multiword expression (MWE) refers to a multiword unit or a collocation of words that co-occur together statistically more than chance.", "labels": [], "entities": [{"text": "multiword expression (MWE)", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.7097550868988037}]}, {"text": "A MWE is a cover term for different types of collocations which vary in their transparency and fixedness.", "labels": [], "entities": []}, {"text": "MWEs are pervasive in natural language, especially in web based texts and speech genres.", "labels": [], "entities": []}, {"text": "Identifying MWEs and understanding their meaning is essential to language understanding, hence they are of crucial importance for any Natural Language Processing (NLP) applications that aim at handling robust language meaning and use.", "labels": [], "entities": [{"text": "Identifying MWEs", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7363211810588837}, {"text": "language understanding", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.739631712436676}]}, {"text": "In fact, the seminal paper () refers to this problem as a key issue for the development of high-quality NLP applications.", "labels": [], "entities": []}, {"text": "For our purposes, a MWE is defined as a collocation of words that refers to a single concept, for example -kick the bucket, spill the beans, make a decision, etc.", "labels": [], "entities": []}, {"text": "An MWE typically has an idiosyncratic meaning that is more or different from the meaning of its component words.", "labels": [], "entities": []}, {"text": "An MWE meaning is transparent, i.e. predictable, in as much as the component words in the expression relay the meaning portended by the speaker compositionally.", "labels": [], "entities": [{"text": "MWE meaning", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.8693969547748566}]}, {"text": "Accordingly, MWEs vary in their degree of meaning compositionality; compositionality is correlated with the level of idiomaticity.", "labels": [], "entities": []}, {"text": "An MWE is compositional if the meaning of an MWE as a unit can be predicted from the meaning of its component words such as in make a decision meaning to decide.", "labels": [], "entities": []}, {"text": "If we conceive of idiomaticity as being a continuum, the more idiomatic an expression, the less transparent and the more non-compositional it is.", "labels": [], "entities": []}, {"text": "Some MWEs are more predictable than others, for instance, kick the bucket, when used idiomatically to mean to die, has nothing in common with the literal meaning of either kick or bucket, however, make a decision is very clearly related to to decide.", "labels": [], "entities": []}, {"text": "Both of these expressions are considered MWEs but have varying degrees of compositionality and predictability.", "labels": [], "entities": []}, {"text": "Both of these expressions belong to a class of idiomatic MWEs known as verb noun constructions (VNC).", "labels": [], "entities": []}, {"text": "The first VNC kick the bucket is a nondecomposable VNC MWE, the latter make a decision is a decomposable VNC MWE.", "labels": [], "entities": []}, {"text": "These types of constructions are the object of our study.", "labels": [], "entities": []}, {"text": "To date, most research has addressed the problem of MWE type classification for VNC expressions in English, not token classification.", "labels": [], "entities": [{"text": "MWE type classification", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.9261890848477682}, {"text": "token classification", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.8202986419200897}]}, {"text": "For example: he spilt the beans on the kitchen counter is most likely a literal usage.", "labels": [], "entities": []}, {"text": "This is given away by the use of the prepositional phrase on the kitchen counter, as it is plausable that beans could have literally been spilt on a location such as a kitchen counter.", "labels": [], "entities": []}, {"text": "Most previous research would classify spilt the beans as idiomatic irrespective of contextual usage.", "labels": [], "entities": []}, {"text": "Ina recent study by) of 53 idiom MWE types used in different contexts, the authors concluded that almost half of them had clear literal meaning and over 40% of their usages in text were actually literal.", "labels": [], "entities": []}, {"text": "Thus, it would be important for an NLP application such as machine translation, for example, when given anew VNC MWE token, to be able to determine whether it is used idiomatically or not as it could potentially have detrimental effects on the quality of the translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7680845260620117}]}, {"text": "In this paper, we address the problem of MWE classification for verb-noun (VNC) token constructions in running text.", "labels": [], "entities": [{"text": "MWE classification", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.987138956785202}]}, {"text": "We investigate the binary classification of an unseen VNC token expression as being either Idiomatic (IDM) or Literal (LIT).", "labels": [], "entities": []}, {"text": "An IDM expression is certainly an MWE, however, the converse is not necessarily true.", "labels": [], "entities": []}, {"text": "To date most approaches to the problem of idiomaticity classification on the token level have been unsupervised.", "labels": [], "entities": [{"text": "idiomaticity classification", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.873604416847229}]}, {"text": "In this study we carryout a supervised learning investigation using support vector machines that uses some of the features which have been shown to help in unsupervised approaches to the problem.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: In Section 2 we describe our understanding of the various classes of MWEs in general.", "labels": [], "entities": []}, {"text": "Section 3 is a summary of previous related research.", "labels": [], "entities": []}, {"text": "Section 4 describes our approach.", "labels": [], "entities": []}, {"text": "In Section 5 we present the details of our experiments.", "labels": [], "entities": []}, {"text": "We discuss the results in Section 6.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use F \u03b2=1 (F-measure) as the harmonic mean between (P)recision and (R)ecall, as well as accuracy to report the results.", "labels": [], "entities": [{"text": "F \u03b2", "start_pos": 7, "end_pos": 10, "type": "METRIC", "confidence": 0.9497103095054626}, {"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9208350777626038}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9997778534889221}]}, {"text": "We report the results separately for the two classes IDM and LIT averaged over the 5 folds of the TEST data set.", "labels": [], "entities": [{"text": "LIT", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.8815775513648987}, {"text": "TEST data set", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.9488814870516459}]}], "tableCaptions": [{"text": " Table 1: Results in %s of varying context window size", "labels": [], "entities": []}, {"text": " Table 2: Final results in %s averaged over 5 folds of test data using different features and their combina- tions", "labels": [], "entities": []}]}