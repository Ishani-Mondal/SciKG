{"title": [{"text": "Generation of Referring Expression with an Individual Imprint", "labels": [], "entities": []}], "abstractContent": [{"text": "A major outcome of the last Shared Tasks for Referring Expressions Generation was that each human prefers distinct properties , syntax and lexical units for building referring expressions.", "labels": [], "entities": []}, {"text": "One of the reasons for this seems to be that entities might be identified faster since the conversation partner has already some knowledge about how his conversation partner builds referring expressions.", "labels": [], "entities": []}, {"text": "Therefore, artificial referring expressions should provide such individual preferences as well so that they become human like.", "labels": [], "entities": []}, {"text": "With this contribution to the shared task, we follow this idea again.", "labels": [], "entities": []}, {"text": "For the development set, we got a very good DICE score of 0.88 for the furniture domain and of 0.79 for the people domain.", "labels": [], "entities": [{"text": "DICE score", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9825581908226013}]}], "introductionContent": [{"text": "We expect that the test set does not provide the information to which human a referring expression belongs.", "labels": [], "entities": []}, {"text": "Therefore, we implemented a fallback strategy in order to get still acceptable DICE scores.", "labels": [], "entities": []}, {"text": "In such cases, we select among all sets the set of referring expressions which is most similar to all others.", "labels": [], "entities": []}, {"text": "We compute the similarity between two sets as the average DICE score between all referring expression of two sets.", "labels": [], "entities": [{"text": "similarity", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.967104434967041}, {"text": "DICE score", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9183025062084198}]}, {"text": "The basis for our algorithm is an extended full brevity implementation, cf. ().", "labels": [], "entities": []}, {"text": "IS-FP uses also the nearest neighbor technique like the IS-FBN algorithm that was introduced by.", "labels": [], "entities": [{"text": "IS-FP", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8957811594009399}]}, {"text": "With the nearest neighbor technique, IS-FP selects the expressions which are most similar to the referring expressions of the same human and a human that builds referring expressions similar or in the case that the human is unknown it uses the most similar one to all others referring expressions.", "labels": [], "entities": []}, {"text": "The similarity is computed as the average of all DICE scores between all combinations of the available trails for two humans.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9944370985031128}, {"text": "DICE", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9078854322433472}]}, {"text": "From the result of the nearest neighbor evaluation, FP selects the shortest and if still more than one expressions remain then it computes the similarity among them and chooses the most typical and finally, if still alternatives remain, it selects one with the attributes having the highest frequency.", "labels": [], "entities": []}, {"text": "shows the results for IS-FP trained on the training set and applied to the development set.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for the IS-FP algorithm", "labels": [], "entities": []}, {"text": " Table 2: Results for the TUNA-REG Task", "labels": [], "entities": [{"text": "TUNA-REG Task", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.6717792451381683}]}]}