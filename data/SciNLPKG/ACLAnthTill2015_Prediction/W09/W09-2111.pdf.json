{"title": [{"text": "User Input and Interactions on Microsoft Research ESL Assistant", "labels": [], "entities": [{"text": "Microsoft Research ESL Assistant", "start_pos": 31, "end_pos": 63, "type": "DATASET", "confidence": 0.9023116230964661}]}], "abstractContent": [{"text": "ESL Assistant is a prototype web-based writing assistance tool that is being developed for English Language Learners.", "labels": [], "entities": []}, {"text": "The system fo-cuses on types of errors that are typically made by non-native writers of American Eng-lish.", "labels": [], "entities": []}, {"text": "A freely-available prototype was deployed in June 2008.", "labels": [], "entities": []}, {"text": "User data from this system are manually evaluated to identify writing domain and measure system accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9895167946815491}]}, {"text": "Combining the user log data with the evaluated rewrite suggestions enables us to determine how effectively English language learners are using the system, across rule types and across writing domains.", "labels": [], "entities": []}, {"text": "We find that repeat users typically make informed choices and can distinguish correct suggestions from incorrect.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much current research in grammatical error detection and correction is focused on writing by English Language Learners (ELL).", "labels": [], "entities": [{"text": "grammatical error detection and correction", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.6986352562904358}]}, {"text": "The Microsoft Research ESL Assistant is a web-based proofreading tool designed primarily for ELLs who are native speakers of East-Asian languages.", "labels": [], "entities": [{"text": "Microsoft Research ESL Assistant", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.7825518846511841}]}, {"text": "Initial system development was informed by pre-existing ELL error corpora, which were used both to identify common ELL mistakes and to evaluate system performance.", "labels": [], "entities": []}, {"text": "These corpora, however, were created from data collected under arguably artificial classroom or examination conditions, leaving unresolved the more practical question as to whether the ESL Assistant can actually help a person who produced the text to improve their English language writing skills in course of more realistic everyday writing tasks.", "labels": [], "entities": []}, {"text": "In June of 2008, a prototype version of this system was made freely available as a web service", "labels": [], "entities": []}], "datasetContent": [{"text": "We are manually evaluating the rewrite suggestions that ESL Assistant generated in order to determine both system accuracy and whether user acceptances led to an improvement in their writing.", "labels": [], "entities": [{"text": "ESL Assistant generated", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.8505846261978149}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9899134635925293}]}, {"text": "These categories are shown in.", "labels": [], "entities": []}, {"text": "Note that results reported for non-native text look very different from those reported for native text (discussed in Section 3) because of the neutral categories which do not appear in the evaluation of native text.", "labels": [], "entities": []}, {"text": "Systems reporting 87% accuracy on native text cannot achieve anything near that on 2 These are anonymized to protect user privacy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9955278038978577}]}, {"text": "non-native ELL text because almost one third of the flags fall into a neutral category.", "labels": [], "entities": []}, {"text": "In 51% of the 39,944 frequent user sentences, the system generated at least one grammatical error flag, fora total of 17,832 flags.", "labels": [], "entities": []}, {"text": "Thirteen percent of the time, the user ignored the flags.", "labels": [], "entities": []}, {"text": "The remaining 87% of the flags were inspected by the user, and of those, the user looked at the suggested rewrites without taking further action 31% of the time.", "labels": [], "entities": []}, {"text": "For 28% of the flags, the user hovered over a suggestion to trigger a parallel web search but did not accept the proposed rewrite.", "labels": [], "entities": []}, {"text": "Nevertheless, 41% of inspected rewrites were accepted, causing the original string in the text to be revised.", "labels": [], "entities": []}, {"text": "Overall, the users inspected about 15.5K suggested rewrites to accept about 6.4K.", "labels": [], "entities": []}, {"text": "A significant number of users appear to be inspecting the suggested revisions and making deliberate choices to accept or not accept.", "labels": [], "entities": []}, {"text": "The next question is: Are users making the right choices?", "labels": [], "entities": []}, {"text": "To help answer this question, 34% of the user sessions have been manually evaluated for system accuracy -a total of approximately 5.1K grammatical error flags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9892807602882385}]}, {"text": "For each error category and for the three major writing domains, we:  Subcategory: Description  When all of the modules are evaluated across the three major writing domains, shown in, the same pattern of user discrimination between good and bad flags holds.", "labels": [], "entities": []}, {"text": "This is most evident in the technical writing domain, where the overall rate of good suggestions improved 13.2% after accepting the suggestion and the false positive rate dropped 15.1% after the decision.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 151, "end_pos": 170, "type": "METRIC", "confidence": 0.915632406870524}]}, {"text": "It is least marked for the essay/nontechnical writing domain.", "labels": [], "entities": []}, {"text": "Here the overall good flag rate increased by only .3% while the false positive rate dropped 1.6%.", "labels": [], "entities": [{"text": "good flag rate", "start_pos": 17, "end_pos": 31, "type": "METRIC", "confidence": 0.7834711074829102}, {"text": "false positive rate", "start_pos": 64, "end_pos": 83, "type": "METRIC", "confidence": 0.9494714339574178}]}, {"text": "Again, all of the differences in false positive rates are statistically significant in Wilcoxon's signed-ranks test.", "labels": [], "entities": [{"text": "false positive rates", "start_pos": 33, "end_pos": 53, "type": "METRIC", "confidence": 0.8856748541196188}, {"text": "Wilcoxon's signed-ranks test", "start_pos": 87, "end_pos": 115, "type": "DATASET", "confidence": 0.7878215610980988}]}, {"text": "These findings are consistent with those for the machine learned articles and prepositions modules in the email domain (Chodorow et al, under review).", "labels": [], "entities": []}, {"text": "A probable explanation for the differences seen across the domains is that those users who are proofreading non-technical writing are, as a whole, less proficient in English than the users who are writing in the other domains.", "labels": [], "entities": []}, {"text": "Users who are proofreading technical writing are typically writing a dissertation or paper in English and therefore tend to relatively fluent in the language.", "labels": [], "entities": []}, {"text": "The email domain comprises people who are confident enough in their English language skills to communicate with colleagues and friends by email in English.", "labels": [], "entities": []}, {"text": "With the essay/non-technical writers, it often is not clear who the intended audience is.", "labels": [], "entities": []}, {"text": "If there is any indication of audience, it is often an instructor.", "labels": [], "entities": []}, {"text": "Users in this domain appear to be the least English-", "labels": [], "entities": []}], "tableCaptions": []}