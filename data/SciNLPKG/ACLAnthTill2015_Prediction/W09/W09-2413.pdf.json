{"title": [{"text": "SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation", "labels": [], "entities": [{"text": "SemEval-2010 Task", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8520393371582031}, {"text": "Cross-lingual Word Sense Disambiguation", "start_pos": 21, "end_pos": 60, "type": "TASK", "confidence": 0.7357998490333557}]}], "abstractContent": [{"text": "We propose a multilingual unsupervised Word Sense Disambiguation (WSD) task fora sample of English nouns.", "labels": [], "entities": [{"text": "multilingual unsupervised Word Sense Disambiguation (WSD) task", "start_pos": 13, "end_pos": 75, "type": "TASK", "confidence": 0.7460746963818868}]}, {"text": "Instead of providing manually sense-tagged examples for each sense of a polysemous noun, our sense inventory is built upon the basis of the Europarl parallel corpus.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 140, "end_pos": 164, "type": "DATASET", "confidence": 0.9651189645131429}]}, {"text": "The multilingual setup involves the translations of a given English polyse-mous noun in five supported languages, viz.", "labels": [], "entities": []}, {"text": "Dutch, French, German, Spanish and Italian.", "labels": [], "entities": []}, {"text": "The task targets the following goals: (a) the manual creation of a multilingual sense inventory fora lexical sample of English nouns and (b) the evaluation of systems on their ability to disambiguate new occurrences of the selected polysemous nouns.", "labels": [], "entities": []}, {"text": "For the creation of the hand-tagged gold standard, all translations of a given polysemous English noun are retrieved in the five languages and clustered by meaning.", "labels": [], "entities": []}, {"text": "Systems can participate in 5 bilingual evaluation subtasks (English-Dutch, English-Ger-man, etc.) and in a multilingual subtask covering all language pairs.", "labels": [], "entities": []}, {"text": "As WSD from cross-lingual evidence is gaining popularity, we believe it is important to create a multilingual gold standard and run cross-lingual WSD benchmark tests.", "labels": [], "entities": [{"text": "WSD", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9849761128425598}, {"text": "WSD", "start_pos": 146, "end_pos": 149, "type": "TASK", "confidence": 0.8397665023803711}]}], "introductionContent": [{"text": "The Word Sense Disambiguation (WSD) task, which consists in selecting the correct sense of a given word in a given context, has been widely studied in computational linguistics.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD) task", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.8231834556375232}]}, {"text": "For a recent overview of WSD algorithms, resources and applications, we refer to and.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9803001880645752}]}, {"text": "Semantic evaluation competitions such as Senseval and its successor Semeval revealed that supervised approaches to WSD usually achieve better results than unsupervised methods).", "labels": [], "entities": [{"text": "WSD", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9740738272666931}]}, {"text": "The former use machine learning techniques to induce a classifier from manually sense-tagged data, where each occurrence of a polysemous word gets assigned a sense label from a predefined sense inventory such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 212, "end_pos": 219, "type": "DATASET", "confidence": 0.9622480273246765}]}, {"text": "These supervised methods, however, heavily rely on large sensetagged corpora which are very time consuming and expensive to build.", "labels": [], "entities": []}, {"text": "This phenomenon, well known as the knowledge acquisition bottleneck (, explains the modest use and success of supervised WSD in real applications.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7478510439395905}, {"text": "WSD", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9262739419937134}]}, {"text": "Although WSD has longtime been studied as a stand-alone NLP task, there is a growing feeling in the WSD community that WSD should preferably be integrated in real applications such as Machine Translation or multilingual information retrieval ().", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 184, "end_pos": 203, "type": "TASK", "confidence": 0.8494767844676971}, {"text": "multilingual information retrieval", "start_pos": 207, "end_pos": 241, "type": "TASK", "confidence": 0.6051826973756155}]}, {"text": "Several studies have demonstrated that for instance Statistical Machine Translation (SMT) benefits from incorporating a dedicated WSD module (.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.8426147699356079}]}, {"text": "Using translations from a corpus instead of human-defined sense labels is one way of facilitating the integration of WSD in multilingual applications.", "labels": [], "entities": [{"text": "WSD", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9597042798995972}]}, {"text": "It also implic-itly deals with the granularity problem as finer sense distinctions are only relevant as far as they are lexicalized in the translations.", "labels": [], "entities": []}, {"text": "Furthermore, this type of corpus-based approach is languageindependent, which makes it a valid alternative for languages lacking sufficient sense inventories and sense-tagged corpora, although one could argue that the lack of parallel corpora for certain language pairs might be problematic as well.", "labels": [], "entities": []}, {"text": "The methodology to deduce word senses from parallel corpora starts from the hypothesis that the different sense distinctions of a polysemous word are often lexicalized cross-linguistically.", "labels": [], "entities": [{"text": "deduce word senses from parallel corpora", "start_pos": 19, "end_pos": 59, "type": "TASK", "confidence": 0.7800512810548147}]}, {"text": "For instance, if we query the English noun \"bill\" in the English-Dutch Europarl, the following top four translations are retrieved: \"rekening\" (Eng.: \"invoice\") (198 occurrences), \"kosten\" (Eng.: \"costs\") (100 occ.), \"Bill\" (96 occ.) and \"wetsvoorstel\" (Eng.: \"piece of legislation\") (77 occ.).", "labels": [], "entities": []}, {"text": "If we make the simplifying assumption for our example that (i) these are the only Dutch translations of our focus word and that (ii) all sense distinctions of \"bill\" are lexicalized in Dutch, we can infer that the English noun \"bill\" has at most four different senses.", "labels": [], "entities": []}, {"text": "These different senses in turn can be grouped in case of synonymy.", "labels": [], "entities": []}, {"text": "In the Dutch-French Europarl, for example, both \"rekening\" and \"kosten\", are translated by the French \"frais\", which might indicate that both Dutch words are synonymous.", "labels": [], "entities": []}, {"text": "Several WSD studies are based on the idea of cross-lingual evidence.", "labels": [], "entities": [{"text": "WSD", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9728032350540161}]}, {"text": "use a bilingual parallel corpus for the automatic creation of a sense-tagged data set, where target words in the source language are tagged with their translation of the word in the target language.", "labels": [], "entities": []}, {"text": "present an unsupervised approach to WSD that exploits translational correspondences in parallel corpora that were artificially created by applying commercial MT systems on a sense-tagged English corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9540637135505676}]}, {"text": "use a multilingual parallel corpus (containing seven languages from four language families) and show that sense distinctions derived from translation equivalents are at least as reliable as those made by human annotators.", "labels": [], "entities": []}, {"text": "Moreover, some studies present multilingual WSD systems that attain state-of-the-art performance in all-words disambiguation ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.95695561170578}]}, {"text": "The proposed Cross-lingual Word Sense Disambiguation task differs from earlier work (e.g.) through its independence from an externally defined sense set.", "labels": [], "entities": [{"text": "Cross-lingual Word Sense Disambiguation task", "start_pos": 13, "end_pos": 57, "type": "TASK", "confidence": 0.8006180942058563}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present a detailed description of the cross-lingual WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.8521928191184998}]}, {"text": "It introduces the parallel corpus we used, informs on the development and test data and discusses the annotation procedure.", "labels": [], "entities": []}, {"text": "Section 3 gives an overview of the different scoring strategies that will be applied.", "labels": [], "entities": []}, {"text": "Section 4 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "As stated before, systems can participate in two tasks, i.e. systems can either participate in one or more bilingual evaluation tasks or they can participate in the multilingual evaluation task incorporating the five supported languages.", "labels": [], "entities": []}, {"text": "The evaluation of the multilingual evaluation task is simply the average of the system scores on the five bilingual evaluation tasks.", "labels": [], "entities": []}, {"text": "For the evaluation of the participating systems we will use an evaluation scheme which is inspired by the English lexical substitution task in.", "labels": [], "entities": []}, {"text": "The evaluation will be performed using precision and recall (P and R in the equations that follow).", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9996206760406494}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9992579817771912}]}, {"text": "We perform both a best result evaluation and a more relaxed evaluation for the top five results.", "labels": [], "entities": []}, {"text": "Let H be the set of annotators, T be the set of test items and hi be the set of responses for an item i \u2208 T for annotator h \u2208 H.", "labels": [], "entities": []}, {"text": "Let Abe the set of items from T where the system provides at least one answer and a i : i \u2208 Abe the set of guesses from the system for item i.", "labels": [], "entities": []}, {"text": "For each i, we calculate the multiset union (H i ) for all hi for all h \u2208 H and for each unique type (res) in H i that has an associated frequency (f req res ).", "labels": [], "entities": []}, {"text": "In the formula of, the associated frequency (f req res ) is equal to the number of times an item appears in H i . As we define our answer clusters by consensus, this frequency would always be \"1\".", "labels": [], "entities": [{"text": "associated frequency (f req res )", "start_pos": 23, "end_pos": 56, "type": "METRIC", "confidence": 0.7197433880397252}]}, {"text": "In order to overcome this, we ask our human annotators to indicate their top 3 translations, which enables us to also obtain meaningful associated frequencies (f req res ) (\"1\" in case the translation is not chosen by any annotator, \"2\" in case a translation is picked by 1 annotator, \"3\" if picked by two annotators and \"4\" if chosen by all three annotators).", "labels": [], "entities": []}, {"text": "Best result evaluation For the best result evaluation, systems can propose as many guesses as the system believes are correct, but the resulting score is divided by the number of guesses.", "labels": [], "entities": []}, {"text": "In this way, systems that output a lot of guesses are not favoured.", "labels": [], "entities": []}, {"text": "Relaxed evaluation For the more relaxed evaluation, systems can propose up to five guesses.", "labels": [], "entities": []}, {"text": "For this evaluation, the resulting score is not divided by the number of guesses.", "labels": [], "entities": []}], "tableCaptions": []}