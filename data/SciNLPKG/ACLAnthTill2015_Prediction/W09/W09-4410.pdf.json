{"title": [], "abstractContent": [{"text": "In this paper a combination of linguistic and structural information is used for the extraction of Dutch definitions.", "labels": [], "entities": [{"text": "extraction of Dutch definitions", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.8274964839220047}]}, {"text": "The corpus used is a collection of Dutch texts on computing and elearn-ing containing 603 definitions.", "labels": [], "entities": []}, {"text": "The extraction process consists of two steps.", "labels": [], "entities": []}, {"text": "In the first step a parser using a grammar defined on the basis of the patterns observed in the definitions is applied on the complete corpus.", "labels": [], "entities": []}, {"text": "Machine learning is thereafter applied to improve the results obtained with the grammar.", "labels": [], "entities": []}, {"text": "The experiments show that using a combination of linguistic (n-grams, type of article, type of noun) and structural information (layout, position) is a promising approach to the definition extraction task.", "labels": [], "entities": [{"text": "definition extraction task", "start_pos": 178, "end_pos": 204, "type": "TASK", "confidence": 0.9568431576093038}]}], "introductionContent": [{"text": "Definition extraction is a relevant task in different areas.", "labels": [], "entities": [{"text": "Definition extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9163065850734711}]}, {"text": "Most times it is used in the domain of question answering to answer 'What-is'-questions, but it is also used for dictionary building, ontology development and glossary creation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7624171078205109}, {"text": "dictionary building", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.8403490781784058}, {"text": "ontology development", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.8033753931522369}, {"text": "glossary creation", "start_pos": 159, "end_pos": 176, "type": "TASK", "confidence": 0.739904522895813}]}, {"text": "The context in which we apply definition extraction is the automatic creation of glossaries within elearning.", "labels": [], "entities": [{"text": "definition extraction", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8613958656787872}]}, {"text": "Glossaries can play an important role within this domain since they support the learner in decoding the learning object he is confronted with and in understanding the central concepts which are being conveyed in the learning material.", "labels": [], "entities": []}, {"text": "The glossary creation context provides its own requirements to the task.", "labels": [], "entities": []}, {"text": "The most relevant one is constituted by the corpus of learning objects which includes a variety of text genres (such as manuals, scientific texts, descriptive documents) and also a variety of writing styles that pose areal challenge to computational techniques for automatic identification and extraction of definitions together with the headwords.", "labels": [], "entities": [{"text": "automatic identification and extraction of definitions", "start_pos": 265, "end_pos": 319, "type": "TASK", "confidence": 0.6961705933014551}]}, {"text": "Our texts are not as structured as those employed for the extraction of definitions in questionanswering tasks which most times include encyclopedias and Wikipedia.", "labels": [], "entities": []}, {"text": "Furthermore, some of our learning objects are relatively small in size, thus our approach has not only to favor precision but also recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.998673677444458}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9948828220367432}]}, {"text": "That is, we want to make sure that as many as possible definitions present in a text are proposed to the user for the creation of the relevant glossary.", "labels": [], "entities": []}, {"text": "Therefore, the extraction of definitions cannot be limited to sentences consisting of a subject, a copular verb and a predicative phrase, as is often the casein question-answering tasks, but a much richer typology of patterns needs to be identified than in current research on definition extraction.", "labels": [], "entities": [{"text": "extraction of definitions", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.8163142601648966}, {"text": "definition extraction", "start_pos": 277, "end_pos": 298, "type": "TASK", "confidence": 0.802953451871872}]}, {"text": "Different approaches for the extraction of definitions can be distinguished.", "labels": [], "entities": [{"text": "extraction of definitions", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.8594069083531698}]}, {"text": "We use a sequential combination of a rule-based approach and machine learning to extract them.", "labels": [], "entities": []}, {"text": "As a first step a grammar is used to match sentences with a definition pattern and thereafter, machine learning techniques are applied to filter out those sentences that -although they have a definition pattern -do not qualify as definitions.", "labels": [], "entities": []}, {"text": "Our work has several innovative aspects compared to other work in this area.", "labels": [], "entities": []}, {"text": "First, we address less common definition types in addition to 'to be' definitions.", "labels": [], "entities": []}, {"text": "Second, we apply a machine learning algorithm designed specifically to deal with imbalanced datasets, which seems to be more appropriate for us because we have data sets in which the proportion of 'yes'-cases is extremely low.", "labels": [], "entities": []}, {"text": "The third innovative aspect on which this paper focuses has to do with the combination of different types of information for the extraction of definitions.", "labels": [], "entities": [{"text": "extraction of definitions", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.8532682855923971}]}, {"text": "Not only linguistic information (n-grams, type of article, type of noun) has been used, but also experiments with structural and textual information have been carried out (position, layout).", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces relevant work in definition extraction, focusing on the work done within the glossary creation context.", "labels": [], "entities": [{"text": "definition extraction", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.970808744430542}]}, {"text": "Section 3 describes the data used in the experiments and the definition categories we distinguish.", "labels": [], "entities": []}, {"text": "In section 4 the way in which grammars have been applied to extract definitions and the results obtained with them are discussed.", "labels": [], "entities": []}, {"text": "Section 5 talks about the machine learning approach, covering issues such as the classifier, the features and the experiments.", "labels": [], "entities": []}, {"text": "Section 6 reports and discusses the results obtained in the experiments.", "labels": [], "entities": []}, {"text": "Section 7 provides conclusions and presents some future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Examples for each of the definition types", "labels": [], "entities": []}, {"text": " Table 2: Results with the grammar", "labels": [], "entities": []}, {"text": " Table 3: Proportions of article types used in definien- dum of is-definitions", "labels": [], "entities": []}, {"text": " Table 4: Proportions of article types used at start of  definiens in is-definitions", "labels": [], "entities": []}, {"text": " Table 6: Final results after applying grammar and machine learning", "labels": [], "entities": []}]}