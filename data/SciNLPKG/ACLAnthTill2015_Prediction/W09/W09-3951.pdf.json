{"title": [{"text": "Unsupervised Classification of Dialogue Acts using a Dirichlet Process Mixture Model", "labels": [], "entities": [{"text": "Unsupervised Classification of Dialogue Acts", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7219977915287018}]}], "abstractContent": [{"text": "In recent years Dialogue Acts have become a popular means of modelling the communicative intentions of human and machine utterances in many modern dialogue systems.", "labels": [], "entities": []}, {"text": "Many of these systems rely heavily on the availability of dialogue corpora that have been annotated with Dialogue Act labels.", "labels": [], "entities": []}, {"text": "The manual annotation of dialogue corpora is both tedious and expensive.", "labels": [], "entities": []}, {"text": "Consequently, there is a growing interest in unsupervised systems that are capable of automating the annotation process.", "labels": [], "entities": []}, {"text": "This paper investigates the use of a Dirichlet Process Mixture Model as a means of clustering dialogue utterances in an unsupervised manner.", "labels": [], "entities": [{"text": "clustering dialogue utterances", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.8669251600901285}]}, {"text": "These clusters can then be analysed in terms of the possible Dialogue Acts that they might represent.", "labels": [], "entities": []}, {"text": "The results presented here are from the application of the Dirichlet Process Mixture Model to the Dihana corpus.", "labels": [], "entities": [{"text": "Dihana corpus", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.8485365509986877}]}], "introductionContent": [{"text": "Dialogue Acts (DAs) are an important contribution from discourse theory to the design of dialogue systems.", "labels": [], "entities": []}, {"text": "These linguistics abstractions are based on the illocutionary force of speech acts and try to capture and model the communicative intention of human or machine utterances.", "labels": [], "entities": []}, {"text": "In recent years, several dialogue systems have made use of DAs for modelling discourse phenomena in either the Dialogue Manager (, Automatic Speech Recogniser () or the Automatic Speech Synthesiser (.", "labels": [], "entities": []}, {"text": "Additionally, they have been used also in other tasks such as summarisation, ().", "labels": [], "entities": [{"text": "summarisation", "start_pos": 62, "end_pos": 75, "type": "TASK", "confidence": 0.994070827960968}]}, {"text": "Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks.", "labels": [], "entities": [{"text": "DA classification of dialogue turns", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.7384521007537842}]}, {"text": "Many machine learning approaches have been used to automatically label DAs.", "labels": [], "entities": []}, {"text": "They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (, Neural Networks () or Graphical Models ().", "labels": [], "entities": []}, {"text": "Relatively few approaches to DA classification have been based on unsupervised learning methods.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.9915890991687775}]}, {"text": "Some promising results were reported by Anderach et al ( who applied Kohonen Self Organising Maps (SOMs) to the problem of DA classification.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.9641794860363007}]}, {"text": "Although the SOM is nonparametric in the sense that it doesn't require that the number of clusters to be found in the data be a parameter of the SOM that is specified before clustering begins, it's capacity to detect clusters is limited to the size of the two-dimensional lattice onto which the clusters are projected, and the size of this lattice is determined prior to clustering.", "labels": [], "entities": [{"text": "SOM", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9286661744117737}]}, {"text": "This paper investigates the use of an unsupervised, nonparametric Bayesian approach to automatic DA labelling: namely the Dirichlet Process Mixture Model (DPMM).", "labels": [], "entities": [{"text": "DA labelling", "start_pos": 97, "end_pos": 109, "type": "TASK", "confidence": 0.9067592620849609}]}, {"text": "Specifically, the paper reports results from applying the Chinese Restaurant Process (CRP), a popular approach to DPMMs, to the automatic labelling of DAs in the Dihana corpus.", "labels": [], "entities": [{"text": "Dihana corpus", "start_pos": 162, "end_pos": 175, "type": "DATASET", "confidence": 0.8719663619995117}]}, {"text": "The Dihana corpus (J.M.) has previously been used for the same task but with a supervised learning approach.", "labels": [], "entities": [{"text": "Dihana corpus (J.M.)", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.8530832231044769}]}, {"text": "The results reported here indicate that, treating each utterance as a bag of words, the CRP is capable of automatically clus-tering most utterances according to speaker, level 1 and in some cases level 2 DA annotations (see below).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Clusters that have specialised on level 1  and level 2 annotations.", "labels": [], "entities": []}]}