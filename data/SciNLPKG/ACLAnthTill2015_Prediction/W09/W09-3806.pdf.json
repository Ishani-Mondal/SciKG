{"title": [{"text": "Predictive Text Entry using Syntax and Semantics", "labels": [], "entities": [{"text": "Predictive Text Entry", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.880157987276713}]}], "abstractContent": [{"text": "Most cellular telephones use numeric key-pads, where texting is supported by dictionaries and frequency models.", "labels": [], "entities": []}, {"text": "Given a key sequence, the entry system recognizes the matching words and proposes a rank-ordered list of candidates.", "labels": [], "entities": []}, {"text": "The ranking quality is instrumental to an effective entry.", "labels": [], "entities": []}, {"text": "This paper describes anew method to enhance entry that combines syntax and language models.", "labels": [], "entities": []}, {"text": "We first investigate components to improve the ranking step: language models and semantic relatedness.", "labels": [], "entities": []}, {"text": "We then introduce a novel syntactic model to capture the word context, optimize ranking, and then reduce the number of keystrokes per character (KSPC) needed to write a text.", "labels": [], "entities": [{"text": "KSPC)", "start_pos": 145, "end_pos": 150, "type": "METRIC", "confidence": 0.9011421203613281}]}, {"text": "We finally combine this model with the other components and we discuss the results.", "labels": [], "entities": []}, {"text": "We show that our syntax-based model reaches an error reduction in KSPC of 12.4% on a Swedish corpus over a base-line using word frequencies.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 47, "end_pos": 62, "type": "METRIC", "confidence": 0.9641889929771423}, {"text": "KSPC", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.6364324688911438}]}, {"text": "We also show that bigrams are superior to all the other models.", "labels": [], "entities": []}, {"text": "However, bigrams have a memory footprint that is unfit for most devices.", "labels": [], "entities": []}, {"text": "Nonetheless, bigrams can be further improved by the addition of syntactic models with an error reduction that reaches 29.4%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 89, "end_pos": 104, "type": "METRIC", "confidence": 0.9828353524208069}]}], "introductionContent": [{"text": "The 12-key input is the most common keypad layout on cellular telephones.", "labels": [], "entities": []}, {"text": "It divides the alphabet into eight lists of characters and each list is mapped onto one key as shown in.", "labels": [], "entities": []}, {"text": "Since three or four characters are assigned to a key, a single key press is ambiguous.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our dependency parser separately from the rest of the application and shows the results.", "labels": [], "entities": []}, {"text": "We optimized our parameter selection for the unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 45, "end_pos": 77, "type": "METRIC", "confidence": 0.7986421485741934}]}, {"text": "This explains the relatively high difference with the labeled attachment score (LAS): about -8.6.", "labels": [], "entities": [{"text": "labeled attachment score (LAS)", "start_pos": 54, "end_pos": 84, "type": "METRIC", "confidence": 0.8584862152735392}]}, {"text": "also shows the highest scores obtained on the same Talbanken corpus of Swedish text) in the CoNLL-X evaluation (): 89.58 for unlabeled attachments) and 84.58 for labeled attachments ( ).", "labels": [], "entities": [{"text": "Talbanken corpus of Swedish text", "start_pos": 51, "end_pos": 83, "type": "DATASET", "confidence": 0.9464672088623047}, {"text": "CoNLL-X evaluation", "start_pos": 92, "end_pos": 110, "type": "DATASET", "confidence": 0.720700204372406}]}, {"text": "CoNLL-X systems were optimized for the LAS category.", "labels": [], "entities": [{"text": "CoNLL-X", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8971906900405884}, {"text": "LAS", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9235101938247681}]}, {"text": "The figures we reached were about 1.10% below those reported in CONLL-X for the UAS category.", "labels": [], "entities": [{"text": "CONLL-X", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9173598289489746}, {"text": "UAS", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.6487622857093811}]}, {"text": "However our results are not directly comparable as the parsers or the classifiers in CONLL-X have either a higher complexity or are more timeconsuming.", "labels": [], "entities": [{"text": "CONLL-X", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.864915132522583}]}, {"text": "We chose linear classifiers over kernel machines as it was essential to our application to run on mobile devices with limited resources in both CPU power and memory size.: Parse results on the Swedish Talbanken corpus obtained for this paper as well as the best reported results in CONLL-X on the same corpus ().", "labels": [], "entities": [{"text": "Parse", "start_pos": 172, "end_pos": 177, "type": "METRIC", "confidence": 0.9919430017471313}, {"text": "Swedish Talbanken corpus", "start_pos": 193, "end_pos": 217, "type": "DATASET", "confidence": 0.8395981987317404}, {"text": "CONLL-X", "start_pos": 282, "end_pos": 289, "type": "DATASET", "confidence": 0.8826967477798462}]}, {"text": "We parsed the corpus and we divided it randomly into a training set (80%), a development set (10%), and a test set (10%).", "labels": [], "entities": []}, {"text": "The training set was used to gather statistics on word n-grams, POS n-grams, collocations, lemma frequencies, dependent/head relations.", "labels": [], "entities": []}, {"text": "We discarded hapaxes: relations and sequences occurring only once.", "labels": [], "entities": []}, {"text": "We used lemmas instead of stems in the semantic relatedness score, SemR, because stemming is less appropriate in Swedish than in English.", "labels": [], "entities": []}, {"text": "We used the development set to find optimal weights for the scoring functions, resulting in the lowest KSPC.", "labels": [], "entities": [{"text": "KSPC", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.8270792961120605}]}, {"text": "We ran an exhaustive search using all possible linear combinations with increments of 0.1, except for two functions, where this was too coarse.", "labels": [], "entities": []}, {"text": "We applied the resulting linear combinations of scoring functions to the test set.", "labels": [], "entities": []}, {"text": "We first compared the frequency-based disambiguation acting as a baseline to linear combinations involving or not involving syntax, but always excluding bigrams.", "labels": [], "entities": []}, {"text": "shows the most significant combinations.", "labels": [], "entities": []}, {"text": "We then compared a set of other combinations with the bigram model.", "labels": [], "entities": []}, {"text": "They are shown in Table 6.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Parse results on the Swedish Talbanken  corpus obtained for this paper as well as the best  reported results in CONLL-X on the same corpus  (", "labels": [], "entities": [{"text": "Parse", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9866513013839722}, {"text": "Swedish Talbanken  corpus", "start_pos": 31, "end_pos": 56, "type": "DATASET", "confidence": 0.8901967803637186}, {"text": "CONLL-X", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.8273307085037231}]}, {"text": " Table 4: The different combinations of scoring models using frequency-based disambiguation as a base- line. The DepSyn weight triples corresponds to (\u03bb 1 , \u03bb 2 , \u03bb 3 ) in Sect. 5.", "labels": [], "entities": []}, {"text": " Table 5: Results for the disambiguation based on word frequencies together with the semantic and syn- tactic models.", "labels": [], "entities": []}, {"text": " Table 6: The different combinations of scoring models using bigram-based disambiguation as baseline.  In addition to the DepSyn weights, this table also shows the language model interpolation weights, \u03b2 1  and \u03b2 2 described in Sect. 2.2.", "labels": [], "entities": []}, {"text": " Table 7: Results for the disambiguation based on bigrams plus the semantic and syntactical models. The  error reduction rate is relative to the word frequency baseline.", "labels": [], "entities": [{"text": "error reduction rate", "start_pos": 105, "end_pos": 125, "type": "METRIC", "confidence": 0.9471858143806458}]}]}