{"title": [{"text": "Grammar Error Detection with Best Approximated Parse", "labels": [], "entities": [{"text": "Grammar Error Detection", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.560575544834137}, {"text": "Approximated Parse", "start_pos": 34, "end_pos": 52, "type": "METRIC", "confidence": 0.9025932848453522}]}], "abstractContent": [{"text": "In this paper, we propose that grammar error detection be disambiguated in generating the connected parse(s) of optimal merit for the full input utterance, in overcoming the cheapest error.", "labels": [], "entities": [{"text": "grammar error detection", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.6027843852837881}]}, {"text": "The detected er-ror(s) are described as violated grammatical constraints in a framework for Model-Theoretic Syntax (MTS).", "labels": [], "entities": [{"text": "Model-Theoretic Syntax (MTS)", "start_pos": 92, "end_pos": 120, "type": "TASK", "confidence": 0.7161660075187684}]}, {"text": "We present a parsing algorithm for MTS, which only relies on a grammar of well-formedness, in that the process does not require any extra-grammatical resources, additional rules for constraint relaxation or error handling, or any recovery process.", "labels": [], "entities": [{"text": "MTS", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9799240231513977}, {"text": "constraint relaxation or error handling", "start_pos": 182, "end_pos": 221, "type": "TASK", "confidence": 0.6694064021110535}]}], "introductionContent": [{"text": "Grammar error detection is a crucial part of NLP applications such as Grammar Checking or Computer-Assisted Language Learning (CALL).", "labels": [], "entities": [{"text": "Grammar error detection", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6906013786792755}, {"text": "Grammar Checking", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.8001577258110046}]}, {"text": "The problem is made highly ambiguous depending on which context is used for interpreting, and thus pinpointing, the error.", "labels": [], "entities": []}, {"text": "For example, a phrase may look perfectly fine when isolated (e.g. brief interview), but is erroneous in a specific context (e.g. in *The judge grants brief interview to this plaintiff, or in *The judges brief interview this plaintiff ).", "labels": [], "entities": []}, {"text": "Robust partial parsing is often not enough to precisely desambiguate those cases.", "labels": [], "entities": [{"text": "Robust partial parsing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7706839243570963}]}, {"text": "The solution we prescribe is to point out the error(s) as a set of violated (atomic) constraints of minimal cost, along with the structural context used for measuring that cost.", "labels": [], "entities": []}, {"text": "Given an ungrammatical input string, the aim is then to provide an approximated rooted parse tree for it, along with a description of all the grammatical constraints it violates.", "labels": [], "entities": []}, {"text": "For example, illustrates an approximated parse for an ill-formed sentence in French, and the error being detected in that context.", "labels": [], "entities": []}, {"text": "Property Grammar) provides an elegant framework for that purpose.", "labels": [], "entities": [{"text": "Property Grammar", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6590259522199631}]}, {"text": "Most of the relevant approaches to robust knowledge-based parsing addresses the problem as a recovery process.", "labels": [], "entities": [{"text": "robust knowledge-based parsing", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.555991013844808}]}, {"text": "More specifically, we observe three families of approaches in that respect: those relying on grammar mal-rules in order to specify how to correctly parse what ought to be ungrammatical (; those relying on constraint relaxation according to specified relaxation rules; and those relying on constraint relaxation with no relaxation rules, along with a recovery process based on weighted parsing).", "labels": [], "entities": []}, {"text": "The first two are actually quite similar, in that, through their use of extra-grammatical rules, they both extend the grammar's coverage with a set of ought-to-beungrammatical utterances.", "labels": [], "entities": []}, {"text": "The main drawback of those approaches is that when faced with unexpected input at best their outcome remains unknown, at worst the parsing process fails.", "labels": [], "entities": [{"text": "parsing", "start_pos": 131, "end_pos": 138, "type": "TASK", "confidence": 0.9842895865440369}]}, {"text": "With robust weighted parsing, on the other hand, that problem does not occur.", "labels": [], "entities": []}, {"text": "The recovery process consists of filtering out structures with respect to their weights or the weights of the constraints being relaxed.", "labels": [], "entities": []}, {"text": "However, these strategies usually cannot discriminate between grammatical and ungrammatical sentences.", "labels": [], "entities": []}, {"text": "The reason for that comes from the fact that grammaticality is disconnected from grammar consistency: since the grammar contains contradicting (universal) constraints, no conclusion can be drawn with regard to the grammaticality of a syntactic structure, which violates part of the constraint system.", "labels": [], "entities": []}, {"text": "The same problem occurs with Optimality Theory.", "labels": [], "entities": [{"text": "Optimality Theory", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.891831248998642}]}, {"text": "Ina different fashion, Fouvry weighs unification constraints according to \"how much information it contains\".", "labels": [], "entities": []}, {"text": "However, relaxation only seems possible for those unification constraints: error patterns such as word order, co-occurrence, uniqueness, mutual exclusion, . .", "labels": [], "entities": []}, {"text": "The same restriction is observed in, though to a much smaller extent in terms of unrelaxable constraints.", "labels": [], "entities": []}, {"text": "What we would like is (i) to detect any type of errors, and present them as conditions of wellformedness being violated in solely relying on the knowledge of a grammar of well-formedness-as opposed to an error grammar or mal-rules, and (ii) to present, along-side the violated constraints, an approximated parse for the full sentence, which may explain which errors have been found and overcome.", "labels": [], "entities": []}, {"text": "We propose here a parsing algorithm which meets these requirements.", "labels": [], "entities": [{"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9803916215896606}]}], "datasetContent": [{"text": "In order to measure Numbat's ability to (i) detect errors in an ungrammatical sentence, and (ii) build the best approximated parse for it, Numbat should, ideally, be evaluated on a corpus of both wellformed and ill-formed utterances annotated with spannnig phrase structures.", "labels": [], "entities": []}, {"text": "Unfortunately, such a Gold Standard is not available to us.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.9283724725246429}]}, {"text": "The development of adequate resources is central to future works.", "labels": [], "entities": []}, {"text": "In order to (partially) overcome that problem we have carried out two distinct evaluations: one aims to measure Numbat's performance on grammatical sentences, and the other one on ungrammatical sentences.", "labels": [], "entities": []}, {"text": "Evaluation 1, whose results are reported in, follows the protocol devised for the EASY evaluation campaign of parsers of French (, with a subset of the campaign's corpus.", "labels": [], "entities": []}, {"text": "For comparison, reports the performance measured under the same circumstances for two other parsers: a shallow one) also based on PG, and a stochastic one ().", "labels": [], "entities": []}, {"text": "The grammar used for that evaluation was developed by   a corpus of unannotated ungrammatical sentences ( ), where each of the ungrammatical sentences (amounting to 94% of the corpus) matches a controlled error pattern.", "labels": [], "entities": []}, {"text": "Five expert annotators were asked whether the solution trees were possible and acceptable syntactic parses for their corresponding sentence.", "labels": [], "entities": []}, {"text": "Specific instructions were given to make sure that the judgement does not hold on the grammatical acceptability of the surface sentence as such, but actually on the parse associated with it.", "labels": [], "entities": []}, {"text": "For that evaluation VanRullen's grammar was completed with nested categories (since the EASY annotation scheme only has chunks).", "labels": [], "entities": []}, {"text": "Given the nature of the material to be assessed here, the Precision and Recall measurements had to be modified.", "labels": [], "entities": [{"text": "Precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9939984083175659}, {"text": "Recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.964424192905426}]}, {"text": "The total number of input sentences is interpreted as the number of predictions; the number of COMPLETE structures is interpreted as the number of observations; and the number of structures evaluated as CORRECT by human judges is interpreted as the number of correct solutions.", "labels": [], "entities": []}, {"text": "Hence the following formulations and scores: Precision=CORRECT/COMPLETE=0.74; Recall=CORRECT/Total=0.68; F=0.71.", "labels": [], "entities": [{"text": "Precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9986357092857361}, {"text": "CORRECT", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.9883028864860535}, {"text": "COMPLETE", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.6296688318252563}, {"text": "Recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9989577531814575}, {"text": "CORRECT/Total", "start_pos": 85, "end_pos": 98, "type": "METRIC", "confidence": 0.835468570391337}, {"text": "F", "start_pos": 105, "end_pos": 106, "type": "METRIC", "confidence": 0.9968998432159424}]}, {"text": "92% of the corpus is analysed with a complete structure; 74% of these complete parses were judged as syntactically correct.", "labels": [], "entities": []}, {"text": "The Recall score indicates that the correct parses represent 68% of the corpus.", "labels": [], "entities": [{"text": "Recall score", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.930277019739151}]}, {"text": "In spite of alack of areal baseline, these scores compare with those of grammatical parsers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: EASY scores of Numbat (Eval. 1)", "labels": [], "entities": [{"text": "EASY", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9928130507469177}, {"text": "Eval. 1", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.8944642543792725}]}, {"text": " Table 3: Comparative EASY scores", "labels": [], "entities": [{"text": "EASY", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.7805559039115906}]}]}