{"title": [{"text": "Participant Subjectivity and Involvement as a Basis for Discourse Segmentation", "labels": [], "entities": [{"text": "Discourse Segmentation", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.70323845744133}]}], "abstractContent": [{"text": "We propose a framework for analyzing episodic conversational activities in terms of expressed relationships between the participants and utterance content.", "labels": [], "entities": []}, {"text": "We test the hypothesis that linguistic features which express such properties, e.g. tense, aspect, and person deixis, area useful basis for automatic intentional discourse seg-mentation.", "labels": [], "entities": []}, {"text": "We present a novel algorithm and test our hypothesis on a set of intentionally segmented conversational monologues.", "labels": [], "entities": []}, {"text": "Our algorithm performs better than a simple baseline and as well as or better than well-known lexical-semantic segmentation methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper concerns the analysis of conversations in terms of communicative activities.", "labels": [], "entities": []}, {"text": "Examples of the kinds of activities we are interested in include relating a personal experience, making a group decision, committing to future action, and giving instructions.", "labels": [], "entities": []}, {"text": "The reason we are interested in these kinds of events is that they are part of participants' common-sense notion of the goals and accomplishments of a dialogue.", "labels": [], "entities": []}, {"text": "They are part of participants' subjective experience of what happened and show up in summaries of conversations such as meeting minutes.", "labels": [], "entities": []}, {"text": "We therefore consider them an ideal target for the practical, common-sense description of conversations.", "labels": [], "entities": []}, {"text": "Activities like these commonly occur as cohesive episodes of multiple turns within a conversation.", "labels": [], "entities": []}, {"text": "They represent an intermediate level of dialogue structure -greater than a single speech act but still small enough to have a potentially well-defined singular purpose.", "labels": [], "entities": []}, {"text": "They have a temporal granularity of anywhere from a few seconds to several minutes.", "labels": [], "entities": [{"text": "temporal granularity", "start_pos": 12, "end_pos": 32, "type": "METRIC", "confidence": 0.936452329158783}]}, {"text": "Ultimately, it would be useful to use descriptions of such activities in automatic summarization technologies for conversational genres.", "labels": [], "entities": []}, {"text": "This would provide an activity-oriented summary describing what 'happened' that would complement one based on information content or what the conversation was 'about'.", "labels": [], "entities": []}, {"text": "Part of our research goal is thus to identify a set of discourse features for segmenting, classifying, and describing conversations in this way.", "labels": [], "entities": [{"text": "segmenting, classifying, and describing conversations", "start_pos": 78, "end_pos": 131, "type": "TASK", "confidence": 0.7421871083123344}]}], "datasetContent": [{"text": "The analysis described in the previous sections suggests that participant-relational features correlate with the intentional structure of discourse.", "labels": [], "entities": []}, {"text": "In this section we describe an experiment which tests the hypothesis that a small set of such features, i.e., tense, aspect, and first-and second-person pronouns, area useful basis for intentional segmentation.", "labels": [], "entities": []}, {"text": "Our experiment compares the performance of our novel algorithm (which we call NM09) with a naive baseline and a well-known alternative method -P&L's co-reference based NP algorithm.", "labels": [], "entities": []}, {"text": "To our knowledge, P&L is the only existing publication describing algorithms designed specifically for intentional segmentation of dialogue.", "labels": [], "entities": [{"text": "intentional segmentation of dialogue", "start_pos": 103, "end_pos": 139, "type": "TASK", "confidence": 0.743582010269165}]}, {"text": "Their NP algorithm exploits annotations of direct and inferred relations between noun phrases in adjacent units.", "labels": [], "entities": []}, {"text": "Inspired by Centering theory (, these annotations are used in a computational account of discourse focus to measure coherence.", "labels": [], "entities": []}, {"text": "Although adding pause-based features improved results slightly, the NP method was the clear winner amongst those using a single feature type and produced very good results.", "labels": [], "entities": []}, {"text": "The NP algorithm requires co-reference annotations as input, so to create a fully-automatic version (NP-AUTO) we have employed a state-ofthe-art co-reference resolution system () to generate the required input.", "labels": [], "entities": []}, {"text": "We also include results based on P&L's original human co-reference annotations (NP-HUMAN).", "labels": [], "entities": [{"text": "P&L's original human co-reference annotations (NP-HUMAN)", "start_pos": 33, "end_pos": 89, "type": "DATASET", "confidence": 0.8621257597749884}]}, {"text": "For reference, we include a baseline that randomly assigns boundaries at the same mean frequency as the gold-standard annotations, i.e., a sequence drawn from the Bernoulli distribution with success probability p = 0.169 (this probability determines the value of the target segment length parameter l in our own algorithm).", "labels": [], "entities": []}, {"text": "As a top-line reference, we calculate the mean of the seven annotators' scores with respect to the three-annotator gold standard.", "labels": [], "entities": []}, {"text": "For evaluation we employ two types of measure.", "labels": [], "entities": []}, {"text": "On one hand, we use P (k)) as an error measure designed to accommodate near-miss boundary assignments.", "labels": [], "entities": []}, {"text": "It is useful because it estimates the probability that two randomly drawn points will be assigned incorrectly to either the same or different segments.", "labels": [], "entities": []}, {"text": "On the other hand, we use Cohen's Kappa (\u03ba) to evaluate the precise placement of boundaries such that each potential boundary site is considered a binary classification.", "labels": [], "entities": []}, {"text": "While \u03ba is typically used to evaluate inter-annotator agreement, it is a useful measure of classification accuracy in our experiment for two reasons.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8659591674804688}]}, {"text": "First, it accounts for the strong class bias in our data.", "labels": [], "entities": []}, {"text": "Second, it allows a direct and intuitive comparison with our inter-annotator top-line reference.", "labels": [], "entities": []}, {"text": "We also provide results for the commonly-used IR measures F 1 , recall, and precision.", "labels": [], "entities": [{"text": "IR", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.9079872369766235}, {"text": "F 1", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9684184789657593}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9994993209838867}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9994168281555176}]}, {"text": "These are useful for comparing with previous results in the literature and provide a more widely-understood measure of the accuracy of the results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9987279772758484}]}, {"text": "Precision and recall are also helpful in revealing the effects of any classification bias the algorithms may have.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9839993119239807}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9994713664054871}]}, {"text": "The results are calculated for 18 of the 20 narratives, as manual feature development involved the use of two randomly selected narratives as development data.", "labels": [], "entities": []}, {"text": "The one exception is NP-HUMAN, which is evaluated on the 10 narratives for which there are manual co-reference annotations.", "labels": [], "entities": [{"text": "NP-HUMAN", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.853297770023346}]}, {"text": "We have extended the above experiment to compare the results of our novel algorithm with existing topic segmentation methods.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7186654806137085}]}, {"text": "We employ Choi's implementations of C99) and TEXTTILING as examples of wellknown topic-oriented methods.", "labels": [], "entities": [{"text": "TEXTTILING", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9746080040931702}]}, {"text": "While we acknowledge that there are newer algorithms which improve upon this work, these were selected for being well studied and easy to apply out-of-thebox.", "labels": [], "entities": []}, {"text": "Our method and evaluation is the same as in the previous experiment.", "labels": [], "entities": []}, {"text": "The mean results for the 18 narratives are shown in, with the human and baseline score reproduced from the previous table.", "labels": [], "entities": []}, {"text": "All three automatic algorithms are superior to the random baseline in terms of P (k), \u03ba, and F 1 (p\u22640.05).", "labels": [], "entities": [{"text": "F 1", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9904301464557648}]}, {"text": "The only statistically significant difference (p\u22640.05) between the three automatic methods is between and TEXTTILING in terms of F 1 . The observed difference between NM09 and TEXTTIL-ING in terms of \u03ba is only moderately significant (p\u22640.08).", "labels": [], "entities": [{"text": "TEXTTILING", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.993297278881073}, {"text": "F 1", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.97630774974823}, {"text": "NM09", "start_pos": 167, "end_pos": 171, "type": "DATASET", "confidence": 0.9560185670852661}]}, {"text": "The observed differences between between NM09 and C99 are minimally significant (p\u22640.24) .", "labels": [], "entities": [{"text": "NM09", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.9238978624343872}]}], "tableCaptions": [{"text": " Table 1: Mean results for the 18 test narratives.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9914775490760803}]}, {"text": " Table 2: Results comparing our method to topic- oriented segmentation methods.", "labels": [], "entities": [{"text": "topic- oriented segmentation", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6259292140603065}]}]}