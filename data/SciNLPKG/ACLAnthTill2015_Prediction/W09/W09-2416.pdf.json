{"title": [{"text": "SemEval-2010 Task 9: The Interpretation of Noun Compounds Using Paraphrasing Verbs and Prepositions", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a brief overview of the main challenges in understanding the semantics of noun compounds and consider some known methods.", "labels": [], "entities": [{"text": "understanding the semantics of noun compounds", "start_pos": 54, "end_pos": 99, "type": "TASK", "confidence": 0.7391334672768911}]}, {"text": "We introduce anew task to be part of SemEval-2010: the interpretation of noun compounds using paraphrasing verbs and prepositions.", "labels": [], "entities": []}, {"text": "The task is meant to provide a standard testbed for future research on noun compound semantics.", "labels": [], "entities": [{"text": "noun compound semantics", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.8318870464960734}]}, {"text": "It should also promote paraphrase-based approaches to the problem, which can benefit many NLP applications.", "labels": [], "entities": []}], "introductionContent": [{"text": "Noun compounds (NCs) -sequences of two or more nouns acting as a single noun, 1 e.g., colon cancer tumor suppressor protein -are abundant in English and pose a major challenge to the automatic analysis of written text.", "labels": [], "entities": [{"text": "automatic analysis of written text", "start_pos": 183, "end_pos": 217, "type": "TASK", "confidence": 0.6939927279949188}]}, {"text": "calculated that 3.9% and 2.6% of the tokens in the Reuters corpus and the British National Corpus (BNC), respectively, are part of a noun compound.", "labels": [], "entities": [{"text": "Reuters corpus", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.9694762825965881}, {"text": "British National Corpus (BNC)", "start_pos": 74, "end_pos": 103, "type": "DATASET", "confidence": 0.9548009037971497}]}, {"text": "Compounding is also an extremely productive process in English.", "labels": [], "entities": []}, {"text": "The frequency spectrum of compound types follows a Zipfian or power-law distribution, so in practice many compound tokens encountered belong to a \"long tail\" of low-frequency types.", "labels": [], "entities": []}, {"text": "For example, over half of the two-noun NC types in the BNC occur just once (.", "labels": [], "entities": [{"text": "BNC", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.7980182766914368}]}, {"text": "Even for relatively frequent NCs that occur tenor more times in the BNC, static English dictionaries give only 27% coverage (.", "labels": [], "entities": [{"text": "BNC", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.958123505115509}]}, {"text": "Taken together, We follow the definition in. the factors of high frequency and high productivity mean that achieving robust NC interpretation is an important goal for broad-coverage semantic processing.", "labels": [], "entities": [{"text": "NC interpretation", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.8605303466320038}, {"text": "broad-coverage semantic processing", "start_pos": 167, "end_pos": 201, "type": "TASK", "confidence": 0.8000933527946472}]}, {"text": "NCs provide a concise means of evoking a relationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information.", "labels": [], "entities": []}, {"text": "Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered.", "labels": [], "entities": []}, {"text": "The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community.", "labels": [], "entities": [{"text": "NC interpretation", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.8423838317394257}]}, {"text": "Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8764675557613373}, {"text": "Machine Translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.8748349547386169}, {"text": "Information Retrieval", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.8376700282096863}, {"text": "Information Extraction", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.809529572725296}]}, {"text": "For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same concept when used in the same document.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 221, "end_pos": 243, "type": "TASK", "confidence": 0.7431711256504059}]}, {"text": "Similarly, a machine translation system facing the unknown NC WTO Geneva headquarters might benefit from the ability to paraphrase it as Geneva headquarters of the WTO or as WTO headquarters located in Geneva.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.6955263912677765}, {"text": "NC WTO Geneva headquarters", "start_pos": 59, "end_pos": 85, "type": "DATASET", "confidence": 0.9202913492918015}]}, {"text": "Given a query like can-cer treatment, an information retrieval system could use suitable paraphrasing verbs like relieve and prevent for page ranking and query refinement.", "labels": [], "entities": [{"text": "page ranking", "start_pos": 137, "end_pos": 149, "type": "TASK", "confidence": 0.6673164665699005}, {"text": "query refinement", "start_pos": 154, "end_pos": 170, "type": "TASK", "confidence": 0.7705977261066437}]}, {"text": "In this paper, we introduce anew task, which will be part of the SemEval-2010 competition: NC interpretation using paraphrasing verbs and prepositions.", "labels": [], "entities": [{"text": "NC interpretation", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.8847399950027466}]}, {"text": "The task is intended to provide a standard testbed for future research on noun compound semantics.", "labels": [], "entities": [{"text": "noun compound semantics", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.8300447463989258}]}, {"text": "We also hope that it will promote paraphrase-based approaches to the problem, which can benefit many NLP applications.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: Section 2 presents a brief overview of the existing approaches to NC semantic interpretation and introduces the one we will adopt for SemEval-2010 Task 9; Section 3 provides a general description of the task, the data collection, and the evaluation methodology; Section 4 offers a conclusion.", "labels": [], "entities": [{"text": "NC semantic interpretation", "start_pos": 118, "end_pos": 144, "type": "TASK", "confidence": 0.8231897552808126}, {"text": "SemEval-2010 Task 9", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7920854489008585}]}], "datasetContent": [{"text": "As trial/development data, we will release the previously collected paraphrase sets for the Levi-250 dataset (after further review and cleaning).", "labels": [], "entities": [{"text": "Levi-250 dataset", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.9834400415420532}]}, {"text": "This dataset consists of 250 noun-noun compounds, each paraphrased by 25-30 human subjects.", "labels": [], "entities": []}, {"text": "The test data will consist of approximately 300 NCs, each accompanied by a set of paraphrasing verbs and prepositions.", "labels": [], "entities": []}, {"text": "Following the methodology of Nakov (2008b), we will use the Amazon Mechanical Turk Web service 4 to recruit human subjects.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk Web service 4", "start_pos": 60, "end_pos": 96, "type": "DATASET", "confidence": 0.8862031300862631}]}, {"text": "This service offers an inexpensive way to recruit subjects for tasks that require human intelligence, and provides an API which allows a computer program to easily run tasks and collate the responses from human subjects.", "labels": [], "entities": []}, {"text": "The Mechanical Turk is becoming a popular means to elicit and collect linguistic intuitions for NLP research; see for an overview and a discussion of issues that arise.", "labels": [], "entities": []}, {"text": "We intend to recruit 100 annotators for each NC, and we will require each annotator to paraphrase at least five NCs.", "labels": [], "entities": []}, {"text": "Annotators will be given clear instructions and will be asked to produce one or more paraphrases fora given NC.", "labels": [], "entities": []}, {"text": "To help us filter out subjects with an insufficient grasp of English or an insufficient interest in the task, annotators will be asked to complete a short and simple multiplechoice pretest on NC comprehension before proceeding to the paraphrasing step.", "labels": [], "entities": []}, {"text": "We will manually check the trial/development data and the test data.", "labels": [], "entities": []}, {"text": "Depending on the quality of the paraphrases, we may decide to drop the least frequent verbs.", "labels": [], "entities": []}, {"text": "All data will be released under the Creative Commons Attribution 3.0 Unported license 5 .  Single-NC Scores.", "labels": [], "entities": []}, {"text": "For each NC, we will compare human scores (our gold standard) with those proposed by each participating system.", "labels": [], "entities": []}, {"text": "We have con-sidered three scores: (1) Pearson's correlation, (2) cosine similarity, and (3) Spearman's rank correlation.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 38, "end_pos": 59, "type": "METRIC", "confidence": 0.9655229051907858}, {"text": "cosine similarity", "start_pos": 65, "end_pos": 82, "type": "METRIC", "confidence": 0.8182186186313629}, {"text": "Spearman's rank correlation", "start_pos": 92, "end_pos": 119, "type": "METRIC", "confidence": 0.6183341294527054}]}, {"text": "Pearson's correlation coefficient is a standard measure of the correlation strength between two distributions; it can be calculated as follows: (1) where X = (x 1 , . .", "labels": [], "entities": [{"text": "Pearson's correlation coefficient", "start_pos": 0, "end_pos": 33, "type": "METRIC", "confidence": 0.6164611354470253}]}, {"text": ", x n ) and Y = (y 1 , . .", "labels": [], "entities": [{"text": "Y", "start_pos": 12, "end_pos": 13, "type": "METRIC", "confidence": 0.9486417770385742}]}, {"text": ", y n ) are vectors of numerical scores for each paraphrase provided by the humans and the competing systems, respectively, n is the number of paraphrases to score, and E(X) is the expectation of X.", "labels": [], "entities": [{"text": "E(X)", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.8988911658525467}]}, {"text": "Cosine correlation coefficient is another popular alternative and was used by; it can be seen as an uncentered version of Pearson's correlation coefficient: Spearman's rank correlation coefficient is suitable for comparing rankings of sets of items; it is a special case of Pearson's correlation, derived by considering rank indices (1,2,.", "labels": [], "entities": [{"text": "Cosine correlation coefficient", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.7823400100072225}, {"text": "rank correlation coefficient", "start_pos": 168, "end_pos": 196, "type": "METRIC", "confidence": 0.733528862396876}]}, {"text": ") as item scores . It is defined as follows: One problem with using Spearman's rank coefficient for the current task is the assumption that swapping any two ranks has the same effect.", "labels": [], "entities": []}, {"text": "The often-skewed nature of paraphrase frequency distributions means that swapping some ranks is intuitively less \"wrong\" than swapping others.", "labels": [], "entities": []}, {"text": "However, Spearman's coefficient treats both alterations identically since it only looks at ranks; thus, we do not plan to use it for official evaluation, though it maybe useful for post-hoc analysis.", "labels": [], "entities": []}, {"text": "A participating system's final score will be the average of the scores it achieves overall test examples.", "labels": [], "entities": []}, {"text": "We will provide an automatic evaluation tool that participants can use when training/tuning/testing their systems.", "labels": [], "entities": []}, {"text": "We will use the same tool for the official evaluation.", "labels": [], "entities": []}], "tableCaptions": []}