{"title": [{"text": "Comparing learners for Boolean partitions: implications for morphological paradigms *", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, I show that a problem of learning a morphological paradigm is similar to a problem of learning a partition of the space of Boolean functions.", "labels": [], "entities": []}, {"text": "I describe several learners that solve this problem in different ways, and compare their basic properties.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lately, there has been a lot of work on acquiring paradigms as part of the word-segmentation problem).", "labels": [], "entities": []}, {"text": "However, the problem of learning the distribution of affixes within paradigms as a function of their semantic (or syntactic) features is much less explored to my knowledge.", "labels": [], "entities": []}, {"text": "This problem can be described as follows: suppose that the segmentation has already been established.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 59, "end_pos": 71, "type": "TASK", "confidence": 0.9766253232955933}]}, {"text": "Can we now predict what affixes should appear in what contexts, whereby a 'context' I mean something quite general: some specification of semantic (and/or syntactic) features of the utterance.", "labels": [], "entities": []}, {"text": "For example, one might say that the nominal suffixz in English (as in apple-z) occurs in contexts that involve plural or possesive nouns whose stems end in a voiced segment.", "labels": [], "entities": []}, {"text": "In this paper, I show that the problem of learning the distribution of morphemes in contexts specified over some finite number of features is roughly equivalent to the problem of learning Boolean partitions of DNF formulas.", "labels": [], "entities": []}, {"text": "Given this insight, one can easily extend standard DNFlearners to morphological paradigm learners.", "labels": [], "entities": []}, {"text": "I show how this can be done on an example of the classical k-DNF learner.", "labels": [], "entities": []}, {"text": "This insight also allows us to bridge the paradigmlearning problem with other similar problems in * This paper ows a great deal to the input from Ed Stabler.", "labels": [], "entities": []}, {"text": "As usual, all the errors and shortcomings are entirely mine.", "labels": [], "entities": [{"text": "errors", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9760278463363647}]}, {"text": "the domain of cognitive science for which DNF's have been used, e.g., concept learning.", "labels": [], "entities": [{"text": "concept learning", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.8511464595794678}]}, {"text": "I also describe two other learners proposed specifically for learning morphological paradigms.", "labels": [], "entities": []}, {"text": "The first of these learners, proposed by me, was designed to capture certain empirical facts about syncretism and free variation in typological data.", "labels": [], "entities": []}, {"text": "The second learner, proposed by David Adger, was designed as a possible explanation of another empirical fact -uneven frequencies of free variants in paradigms).", "labels": [], "entities": []}, {"text": "In the last section, I compare the learners on some simple examples and comment on their merits and the key differences among the algorithms.", "labels": [], "entities": []}, {"text": "I also draw connections to other work, and discuss directions for further empirical tests of these proposals.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}