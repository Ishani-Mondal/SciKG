{"title": [{"text": "A Hybrid Approach to English-Korean Name Transliteration", "labels": [], "entities": [{"text": "English-Korean Name Transliteration", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.5923483471075693}]}], "abstractContent": [{"text": "This paper presents a hybrid approach to English-Korean name transliteration.", "labels": [], "entities": [{"text": "English-Korean name transliteration", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.5937539537747701}]}, {"text": "The base system is built on MOSES with enabled factored translation features.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.8631654977798462}]}, {"text": "We expand the base system by combining with various transliteration methods including a Web-based n-best re-ranking, a dictionary-based method, and a rule-based method.", "labels": [], "entities": []}, {"text": "Our standard run and best non-standard run achieve 45.1 and 78.5, respectively , in top-1 accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9897599816322327}]}, {"text": "Experimental results show that expanding training data size significantly contributes to the performance.", "labels": [], "entities": []}, {"text": "Also we discover that the Web-based re-ranking method can be successfully applied to the English-Korean transliteration.", "labels": [], "entities": []}], "introductionContent": [{"text": "Often, named entities such as person names or place names from foreign origin do not appear in the dictionary, and such out of vocabulary words area common source of errors in processing natural languages.", "labels": [], "entities": []}, {"text": "For example, in statistical machine translation (SMT), if anew word occurs in the input source sentence, the decoder will at best drop the unknown word or directly copy the source word to the target sentence.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.7951589127381643}]}, {"text": "Transliteration, a method of mapping phonemes or graphemes of source language into those of target language, can be used in this casein order to identify a possible translation of the word.", "labels": [], "entities": []}, {"text": "The approaches to automatic transliteration between English and Korean can be performed through the following ways: First, in learning how to write the names of foreign origin, we can refer to a transliteration standard which is established by the government or some official linguistic organizations.", "labels": [], "entities": []}, {"text": "No matter where the standard comes from, the basic principle of the standard is based on the correct pronunciation of foreign words.", "labels": [], "entities": []}, {"text": "Second, since constructing such rules are very costly in terms of time and money, we can rely on a statistical method such as SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9773349761962891}]}, {"text": "We believe that the rule-based method can guarantee to increase accuracy for known cases, and the statistical method can be robust to handle various exceptions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9978031516075134}]}, {"text": "In this paper, we present a variety of techniques for English-Korean name transliteration.", "labels": [], "entities": [{"text": "English-Korean name transliteration", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.6084880630175272}]}, {"text": "First, we use a phrase-base SMT model with some factored translation features for the transliteration task.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.8308466076850891}]}, {"text": "Second, we expand the base system by applying Web-based n-best re-ranking of the results.", "labels": [], "entities": []}, {"text": "Third, we apply a pronouncing dictionary-based method to the base system which utilizes the pronunciation symbols which is motivated by linguistic knowledge.", "labels": [], "entities": []}, {"text": "Finally, we introduce a phonicsbased method which is originally designed for teaching speakers of English to read and write that language.", "labels": [], "entities": []}], "datasetContent": [{"text": "We participate in both standard and non-standard tracks for English-Korean name transliteration in NEWS 2009 Machine Transliteration Shared Task (.", "labels": [], "entities": [{"text": "English-Korean name transliteration", "start_pos": 60, "end_pos": 95, "type": "TASK", "confidence": 0.609894593556722}, {"text": "NEWS 2009 Machine Transliteration Shared Task", "start_pos": 99, "end_pos": 144, "type": "DATASET", "confidence": 0.8061703046162924}]}, {"text": "Experimenting on the development data, we determine the best performing parameters for MOSES as follows.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 87, "end_pos": 92, "type": "TASK", "confidence": 0.48442479968070984}]}, {"text": "\u2022 With above parameter setup, the results are produced from the following five different systems.", "labels": [], "entities": []}, {"text": "\u2022 Baseline System (BS): For the standard task, we use only given official training data 3 to construct translation model and language model for our base system.", "labels": [], "entities": []}, {"text": "\u2022 Expanded Resource (ER): For all four nonstandard tasks, we use the examples of writing foreign names as additional training data.", "labels": [], "entities": []}, {"text": "The examples are provided from the National Institute of the Korean Language 4 . The data originally consists of around 27,000 person names and around 7,000 place names including non-Ascii characters for English side words as well as duplicate entries.", "labels": [], "entities": [{"text": "National Institute of the Korean Language 4", "start_pos": 35, "end_pos": 78, "type": "DATASET", "confidence": 0.9467908058847699}]}, {"text": "We preprocess the data in order to use 13,194 dis-tinct pairs of English names and Korean transliteration.", "labels": [], "entities": []}, {"text": "\u2022 Web-based Re-ranking (WR): We re-rank the result of ER by applying the method described in section 2.2.", "labels": [], "entities": [{"text": "Re-ranking (WR)", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.7005834579467773}]}, {"text": "\u2022 Pronouncing Dictionary-based Method (PD): The re-ranking of WR by combining with the method described in section 2.3.", "labels": [], "entities": []}, {"text": "\u2022 Phonics-based Method (PB): The re-ranking of WR by combining with the method described in section 2.4.", "labels": [], "entities": []}, {"text": "The last two methods re-rank the WR method by applying pronouncing dictionary-based method and Phonics-based method.", "labels": [], "entities": [{"text": "WR", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.8146551251411438}]}, {"text": "We restrict that the pronouncing dictionary-based method and Phonics-based method can produce only one output, and use the outputs of the two methods to rerank (again) the result of Web-based re-ranking.", "labels": [], "entities": []}, {"text": "When re-ranking the results, we heuristically combined the outputs of PD or PB with the n-best result of WR.", "labels": [], "entities": [{"text": "PD", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9680624604225159}, {"text": "WR", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9348923563957214}]}, {"text": "If the outputs of the two methods exist in the result of WR, we add some positive scores to the original scores of WR.", "labels": [], "entities": [{"text": "WR", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.6892174482345581}]}, {"text": "Otherwise, we inserted the result into fixed position of the rank.", "labels": [], "entities": []}, {"text": "The fixed position of rank is empirically decided using development set.", "labels": [], "entities": []}, {"text": "We inserted the output of PD and PB at second rank and at sixth rank, respectively.", "labels": [], "entities": [{"text": "PD", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9962477087974548}, {"text": "PB", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.8876093029975891}]}, {"text": "shows our experimental results of the five systems on the test data.", "labels": [], "entities": []}, {"text": "We found that the use of additional training data (ER) and web-based reranking (WR) have a strong effect on transliteration performance.", "labels": [], "entities": [{"text": "reranking (WR)", "start_pos": 69, "end_pos": 83, "type": "METRIC", "confidence": 0.6730057373642921}]}, {"text": "However, the integration of the PD or PB with WB proves not to significantly contribute the performance.", "labels": [], "entities": [{"text": "WB", "start_pos": 46, "end_pos": 48, "type": "DATASET", "confidence": 0.7463253140449524}]}, {"text": "To find more elaborate integration of those results will be one of our future work.", "labels": [], "entities": []}, {"text": "The M AP sys value of the three re-ranking methods WR, PD, and PB are relatively higher than other methods because we filter out some candidates in n-best by their Web frequencies.", "labels": [], "entities": [{"text": "M AP sys", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9368723432223002}, {"text": "WR", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9220895171165466}, {"text": "PD", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.792766809463501}]}, {"text": "In addition to the standard evaluation measures, we include the Mean F dec to measure the Levenshtein distance between reference and the output of the decoder (decomposed result).", "labels": [], "entities": [{"text": "Mean F dec", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9361552596092224}]}], "tableCaptions": [{"text": " Table 1: Experimental Results (EnKo)", "labels": [], "entities": [{"text": "EnKo)", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.9170534014701843}]}]}