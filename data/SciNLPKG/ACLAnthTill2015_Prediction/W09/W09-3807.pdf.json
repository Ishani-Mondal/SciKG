{"title": [{"text": "Parsing Formal Languages using Natural Language Parsing Techniques", "labels": [], "entities": []}], "abstractContent": [{"text": "Program analysis tools used in software maintenance must be robust and ought to be accurate.", "labels": [], "entities": [{"text": "Program analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7114769667387009}, {"text": "software maintenance", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.6858653128147125}]}, {"text": "Many data-driven parsing approaches developed for natural languages are robust and have quite high accuracy when applied to parsing of software.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9983892440795898}, {"text": "parsing of software", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.8817863066991171}]}, {"text": "We show this for the programming languages Java, C/C++, and Python.", "labels": [], "entities": []}, {"text": "Further studies indicate that post-processing can almost completely remove the remaining errors.", "labels": [], "entities": []}, {"text": "Finally, the training data for instantiating the generic data-driven parser can be generated automatically for formal languages, as opposed to the manually development of treebanks for natural languages.", "labels": [], "entities": []}, {"text": "Hence, our approach could improve the robust-ness of software maintenance tools, probably without showing a significant negative effect on their accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9963782429695129}]}], "introductionContent": [{"text": "Software engineering, especially software maintenance, is supported by numerous program analysis tools.", "labels": [], "entities": [{"text": "Software engineering", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7453759610652924}, {"text": "software maintenance", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7876541614532471}]}, {"text": "Maintenance tasks include program comprehension (understanding unknown code for fixing bugs or further development), quality assessment (judging code, e.g., in code reviews), and reverse-engineering (reifying the design documents forgiven source code).", "labels": [], "entities": []}, {"text": "To extract information from the programs, the tools first parse the program code and produce an abstract syntax tree (AST) for further analysis and abstraction.", "labels": [], "entities": []}, {"text": "As long as the program conforms to the syntax of a programming language, classical parsing techniques known from the field of compiler construction maybe applied.", "labels": [], "entities": [{"text": "compiler construction", "start_pos": 126, "end_pos": 147, "type": "TASK", "confidence": 0.7308813631534576}]}, {"text": "This, however, cannot be assumed in general, as the programs to analyze can be incomplete, erroneous, or conform to a (yet unknown) dialect or version of the language.", "labels": [], "entities": []}, {"text": "Despite error stabilization, classical parsers then lose a lot of information or simply breakdown.", "labels": [], "entities": []}, {"text": "This is unsatisfactory for tools supporting maintenance.", "labels": [], "entities": []}, {"text": "Therefore, quite some effort has gone into the development of robust parsers of programs for these tools (cf. our related work section 5).", "labels": [], "entities": []}, {"text": "This effort, however, has to be repeated for every programming language.", "labels": [], "entities": []}, {"text": "The development of robust parsers is of special interest for languages like C/C++ due to their numerous dialects in use.", "labels": [], "entities": []}, {"text": "Also, tools for languages frequently coming in new versions, like Java, benefit from robust parsing.", "labels": [], "entities": []}, {"text": "Finally, there are languages like HTML where existing browsers are forgiving if documents do not adhere to the formal standard with the consequence that there exist many formally erroneous documents.", "labels": [], "entities": []}, {"text": "In such cases, robust parsing is even a prerequisite for tool-supported maintenance.", "labels": [], "entities": []}, {"text": "The accuracy of parsing is a secondary goal in the context of software maintenance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999038577079773}, {"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9689903855323792}, {"text": "software maintenance", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7240766882896423}]}, {"text": "Tasks like program comprehension, quality assessment, and reverse-engineering are fuzzy by their nature.", "labels": [], "entities": []}, {"text": "There is no well-defined notion of correctnessrather an empirical answer to the question: Did it help the software engineers in fulfilling their tasks?", "labels": [], "entities": []}, {"text": "Moreover, the information provided to the engineers abstracts anyway from the concrete program syntax and semantics, i.e., inaccuracies in the input may disappear in the output.", "labels": [], "entities": []}, {"text": "Finally, program analyses are often heuristics themselves, approximating computationally hard problems like pattern matching and optimal clustering.", "labels": [], "entities": [{"text": "pattern matching", "start_pos": 108, "end_pos": 124, "type": "TASK", "confidence": 0.7869691252708435}]}, {"text": "The natural language processing (NLP) community has for many years developed parsing technology that is both completely robust and highly accurate.", "labels": [], "entities": [{"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.9661794900894165}]}, {"text": "The present approach applies this technology to programming languages.", "labels": [], "entities": []}, {"text": "It is robust in the sense that, for each program, the parser always gives a meaningful model even for slightly incorrect and incomplete programs.", "labels": [], "entities": []}, {"text": "The approach is, however, not accurate to 100%, i.e., even correct programs may lead to slightly incorrect models.", "labels": [], "entities": []}, {"text": "As we will show, it is quite accurate when applied to programming languages.", "labels": [], "entities": []}, {"text": "The data-driven dependency parsing approach applied here only needs correct examples of the source and the expected analysis model.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.6906155496835709}]}, {"text": "Then it automatically trains and adapts a generic parser.", "labels": [], "entities": []}, {"text": "As we will show, training data for adapting to anew programming language can even be generated automatically.", "labels": [], "entities": []}, {"text": "Hence, the effort for creating a parser fora new programming language is quite small.", "labels": [], "entities": []}, {"text": "The basic idea -applying natural language parsing to programming languages -has been presented to the program maintenance community before (.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7614553570747375}]}, {"text": "This paper contributes with experimental results on 1.", "labels": [], "entities": []}, {"text": "data-driven dependency parsing of the programming languages C/C++, Java, and Python, 2.", "labels": [], "entities": [{"text": "data-driven dependency parsing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5973154505093893}]}, {"text": "transformations between dependency structure and phrase structure adapted to programming languages, 3.", "labels": [], "entities": []}, {"text": "generic parser model selection and its effect on parsing accuracy.", "labels": [], "entities": [{"text": "generic parser model selection", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6670982837677002}, {"text": "parsing", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.9710582494735718}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.8589830994606018}]}, {"text": "Section 2 gives an introduction to the parsing technology applied here.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.9865542650222778}]}, {"text": "In section 3, the preparation of the training examples necessary is described, while section 4 presents the experimental results.", "labels": [], "entities": []}, {"text": "Section 5 discusses related work in information extraction for software maintenance.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.756973147392273}, {"text": "software maintenance", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.7096259742975235}]}, {"text": "We end with conclusions and future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We will in this section present parsing experiments and evaluate the accuracy of the syntax trees produced by the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9992639422416687}]}, {"text": "As mentioned in section 2, the parsing algorithm is robust in the sense that it always produces a syntactic analysis no matter the input, but it can commit errors even for correct input.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9656770825386047}]}, {"text": "This section investigates the accuracy for correct input, when varying feature set, head-finding rules and language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9993425011634827}]}, {"text": "We begin with the experimental setup.", "labels": [], "entities": []}, {"text": "The open-source software MaltParser (maltparser.org) ( ) is used in the experiments.", "labels": [], "entities": []}, {"text": "It contains an implementation of the parsing algorithm, as well as an implementation of the conversion strategy from syntax trees to dependency trees and back, presented in subsections 3.3 and 3.4.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.9689520001411438}]}, {"text": "It comes with the machine learner LIBSVM), producing the most accurate results for parsing natural languages compared to other evaluated machine learners ( ).", "labels": [], "entities": [{"text": "parsing natural languages", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.894163191318512}]}, {"text": "The source files of the following projects have been converted into dependency trees: \u2022 For Java: Recoder 0.83 (, using all source files in the directory \"src\" (having 400 source files with 92k LOC and 335k tokens).", "labels": [], "entities": []}, {"text": "\u2022 For C/C++: Elsa 2005.08.22b, where 1389 source files were used, including the 978 C/C++ benchmark files in the distribution (thus comprising 1389 source files with 265k LOC and 691k tokens).", "labels": [], "entities": [{"text": "Elsa 2005.08.22b", "start_pos": 13, "end_pos": 29, "type": "DATASET", "confidence": 0.9324086308479309}]}, {"text": "\u2022 For Python: Natural Language Toolkit 0.9.5 (, where all source files in the directory \"nltk\" were used (having 160 source files with 65k LOC and 280k tokens).", "labels": [], "entities": []}, {"text": "To construct the syntax tree for the source code file of Recoder, we have used Recoder.", "labels": [], "entities": [{"text": "Recoder", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.898719847202301}, {"text": "Recoder", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.9463115334510803}]}, {"text": "It creates an abstract syntax tree fora source file, but we are currently interested in the concrete syntax tree with all the original tokens.", "labels": [], "entities": []}, {"text": "In this first conversion step, the tokens of the syntax trees are thus retained.", "labels": [], "entities": []}, {"text": "For example, the syntax trees in are generated by Recoder.", "labels": [], "entities": [{"text": "Recoder", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9307504296302795}]}], "tableCaptions": [{"text": " Table 1: F-score for various parser models and  head-finding rules for Java, where FR = FREQ, LE  = LEFT and RI = RIGHT.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.995130181312561}, {"text": "FR", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.9972198009490967}, {"text": "FREQ", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.8634822368621826}, {"text": "LE  = LEFT", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.7098587155342102}, {"text": "RI", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9243978261947632}, {"text": "RIGHT", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.6413800716400146}]}, {"text": " Table 2: Attachment score for Java and the lexical  feature set, where CO = convertible and NC = non- convertible dependency trees.", "labels": [], "entities": []}, {"text": " Table 3: F-score for various parser models and  head-finding rules LEFT for Python and C/C++.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9960193037986755}, {"text": "LEFT", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9841992855072021}]}, {"text": " Table 4: Confusion matrix for Java using non- convertible dependency trees with LEFT, ordered  by descending frequency.", "labels": [], "entities": [{"text": "LEFT", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9851112961769104}]}]}