{"title": [{"text": "Bottom-up Named Entity Recognition using a Two-stage Machine Learning Method", "labels": [], "entities": [{"text": "Entity Recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.6464390009641647}]}], "abstractContent": [{"text": "This paper proposes Japanese bottom-up named entity recognition using a two-stage machine learning method.", "labels": [], "entities": [{"text": "Japanese bottom-up named entity recognition", "start_pos": 20, "end_pos": 63, "type": "TASK", "confidence": 0.6641090750694275}]}, {"text": "Most work has formalized Named Entity Recognition as a sequential labeling problem, in which only local information is utilized for the label estimation, and thus along named entity consisting of several morphemes tends to be wrongly recognized.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7009938955307007}]}, {"text": "Our proposed method regards a compound noun (chunk) as a labeling unit, and first estimates the labels of all the chunks in a phrasal unit (bunsetsu) using a machine learning method.", "labels": [], "entities": []}, {"text": "Then, the best label assignment in the bunsetsu is determined from bottom up as the CKY parsing algorithm using a machine learning method.", "labels": [], "entities": [{"text": "CKY parsing", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.7820216715335846}]}, {"text": "We conducted an experimental on CRL NE data, and achieved an F measure of 89.79, which is higher than previous work.", "labels": [], "entities": [{"text": "CRL NE data", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8533397316932678}, {"text": "F measure", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9941340386867523}]}], "introductionContent": [{"text": "Named Entity Recognition (NER) is a task of recognizing named entities such as person names, organization names, and location.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8006232132514318}]}, {"text": "It is used for several NLP applications such as Information Extraction (IE) and Question Answering (QA).", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.8355586767196655}, {"text": "Question Answering (QA)", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.8903664708137512}]}, {"text": "Most work uses machine learning methods such as Support Vector Machines (SVMs) and Conditional Random Field (CRF) () using a hand-annotated corpus;.", "labels": [], "entities": []}, {"text": "In general, NER is formalized as a sequential labeling problem.", "labels": [], "entities": [{"text": "NER", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9791238307952881}]}, {"text": "For example, regarding a morpheme as a basic unit, it is first labeled as S-PERSON, B-PERSON, I-PERSON, E-PERSON, S-ORGANIZATION, etc.", "labels": [], "entities": []}, {"text": "Then, considering the labeling results of morphemes, the best NE label sequence is recognized.", "labels": [], "entities": []}, {"text": "When the label of each morpheme is estimated, only local information around the morpheme (e.g., the morpheme, the two preceding morphemes, and the two following morphemes) is utilized.", "labels": [], "entities": []}, {"text": "Therefore, along named entity consisting of several morphemes tends to be wrongly recognized.", "labels": [], "entities": []}, {"text": "Let us consider the example sentences shown in In sentence (1), the label of \"Kazama\" can be recognized to be S-PERSON (PERSON consisting of one morpheme) by utilizing the surrounding information such as the suffix \"san\" (Mr.) and the verb \"kikoku shita\" (return home).", "labels": [], "entities": []}, {"text": "On the other hand, in sentence (2), when the label of \"shinyou\" (credit) is recognized to be B-ORGANIZATION (the beginning of ORGA-NIZATION), only information from \"hatsudou\" (invoke) to \"kyusai\" (relief) can be utilized, and thus the information of the morpheme \"ginkou\" (bank) that is apart from \"shinyou\" by three morphemes cannot be utilized.", "labels": [], "entities": [{"text": "B-ORGANIZATION", "start_pos": 93, "end_pos": 107, "type": "METRIC", "confidence": 0.9863795638084412}, {"text": "ORGA-NIZATION", "start_pos": 126, "end_pos": 139, "type": "METRIC", "confidence": 0.8197291493415833}]}, {"text": "To cope with this problem,) and utilized information of the head of bunsetsu 1 . In their methods, when the label of \"shinyou\" is recognized, the information of the morpheme \"ginkou\" can be utilized.", "labels": [], "entities": []}, {"text": "However, these methods do notwork when the morpheme that we want to refer to is not ahead of bunsetsu as in sentence.", "labels": [], "entities": []}, {"text": "In this example, when \"gaikoku\" (foreign) is recognized to be B-ARTIFACT (the beginning of ARTIFACT), we want to refer to \"hou\" (law), not \"ihan\" (violation), which is the head of the bunsetsu.", "labels": [], "entities": [{"text": "B-ARTIFACT", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.968034565448761}]}, {"text": "This paper proposes Japanese bottom-up named 'on suspicion of the private document falsification and the violation of the foreigner registration law': Example sentences.", "labels": [], "entities": []}, {"text": "entity recognition using a two-stage machine learning method.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8054479360580444}]}, {"text": "Different from previous work, this method regards a compound noun as a labeling unit (we call it chunk, hereafter), and estimates the labels of all the chunks in the bunsetsu using a machine learning method.", "labels": [], "entities": []}, {"text": "In sentence (3), all the chunks in the second bunsetsu (i.e., \"gaikoku\", \"gaikoku-jin\", \u00b7 \u00b7 \u00b7, \"gaikoku-jintouroku-hou-ihan \", \u00b7 \u00b7 \u00b7, \"ihan\") are labeled, and in the case that the chunk \"gaikoku-jin-tourokuhou\" is labeled, the information about \"hou\" (law) is utilized in a natural manner.", "labels": [], "entities": []}, {"text": "Then, in the bunsetsu, the best label assignment is determined.", "labels": [], "entities": []}, {"text": "For example, among the combination of \"gaikoku-jintouroku-hou\" (ARTIFACT) and \"ihan\" (OTHER), the combination of \"gaikoku-jin\" (PERSON) and \"touroku-hou-ihan\" (OTHER), etc., the best label assignment, \"gaikoku-jin-touroku-hou\" (AR-TIFACT) and \"ihan\" (OTHER), is chosen based on a machine learning method.", "labels": [], "entities": [{"text": "OTHER", "start_pos": 251, "end_pos": 256, "type": "METRIC", "confidence": 0.8711792230606079}]}, {"text": "In this determination of the best label assignment, as the CKY parsing algorithm, the label assignment is determined by bottom-up dynamic programming.", "labels": [], "entities": [{"text": "CKY parsing", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.7857978940010071}]}, {"text": "We conducted an experimental on CRL NE data, and achieved an F measure of 89.79, which is higher than previous work.", "labels": [], "entities": [{"text": "CRL NE data", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8533397316932678}, {"text": "F measure", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9941340386867523}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work of NER, especially focusing on sequential labeling based method.", "labels": [], "entities": [{"text": "NER", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9290898442268372}]}, {"text": "Section 3 describes an overview of our proposed method.", "labels": [], "entities": []}, {"text": "Section 4 presents two machine learning models, and Section 5 describes an analysis algorithm.", "labels": [], "entities": []}, {"text": "Section 6 gives an experimental result.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate the effectiveness of our proposed method, we conducted an experiment on CRL NE data.", "labels": [], "entities": [{"text": "CRL NE data", "start_pos": 87, "end_pos": 98, "type": "DATASET", "confidence": 0.8611261049906412}]}, {"text": "In this data, 10,718 sentences in 1,174 news articles are annotated with eight NEs.", "labels": [], "entities": []}, {"text": "The expression to which it is difficult to annotate manually is labeled as OPTIONAL, and was not used for both: Experimental result.", "labels": [], "entities": [{"text": "OPTIONAL", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9903468489646912}]}, {"text": "(d) and (e).", "labels": [], "entities": []}, {"text": "Then, the label comparison model is learned from the obtained features.", "labels": [], "entities": []}, {"text": "After that, the analysis in the part (a) is performed by using both the label estimation model 1 and the label comparison model.", "labels": [], "entities": []}, {"text": "In this experiment, a Japanese morphological analyzer, JUMAN 9 , and a Japanese parser, KNP 10 were adopted.", "labels": [], "entities": [{"text": "JUMAN 9", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.6622851490974426}]}, {"text": "The two SVM models were learned with polynomial kernel of degree 2, and \u03b2 in the sigmoid function was set to be 1.", "labels": [], "entities": []}, {"text": "An Fmeasure in all NE classes is 89.79.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 3, "end_pos": 11, "type": "METRIC", "confidence": 0.9941603541374207}]}, {"text": "presents the comparison with previous work, and our method outperformed previous work.", "labels": [], "entities": []}, {"text": "Among previous work, acquired huge amount of categoryinstance pairs (e.g., \"political party -New party DAICHI\",\"company-TOYOTA\") by some patterns from a large Web corpus, and Sasano et al. utilized the analysis result of corefer resolution as a feature for the model learning.", "labels": [], "entities": [{"text": "corefer resolution", "start_pos": 221, "end_pos": 239, "type": "TASK", "confidence": 0.8432963192462921}]}, {"text": "Therefore, in our method, by incorporating these knowledge and/or such analysis result, the performance would be improved.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Features for the label estimation model.", "labels": [], "entities": [{"text": "label estimation", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7140748798847198}]}, {"text": " Table 4: Comparison with previous work. (All work was evaluated on CRL NE data using cross valida- tion.)", "labels": [], "entities": [{"text": "CRL NE data", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.8761279980341593}]}]}