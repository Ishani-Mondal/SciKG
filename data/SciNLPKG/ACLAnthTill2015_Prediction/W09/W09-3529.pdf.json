{"title": [{"text": "Maximum N-gram HMM-based Name Transliteration: Experiment in NEWS 2009 on English-Chinese Corpus", "labels": [], "entities": [{"text": "HMM-based Name Transliteration", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.7730644941329956}, {"text": "NEWS 2009", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.8773985803127289}]}], "abstractContent": [{"text": "We propose an English-Chinese name transli-teration system using a maximum N-gram Hidden Markov Model.", "labels": [], "entities": []}, {"text": "To handle special challenges with alphabet-based and character-based language pair, we apply a two-phase transliteration model by building two HMM models, one between English and Chinese Pi-nyin and another between Chinese Pinyin and Chinese characters.", "labels": [], "entities": []}, {"text": "Our model improves traditional HMM by assigning the longest prior translation sequence of syllables the largest weight.", "labels": [], "entities": [{"text": "HMM", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9639695882797241}]}, {"text": "In our non-standard runs, we use a Web-mining module to boost the performance by adding online popularity information of candidate translations.", "labels": [], "entities": []}, {"text": "The entire model does not rely on any dictionaries and the probability tables are derived merely from training corpus.", "labels": [], "entities": []}, {"text": "In participation of NEWS 2009 experiment, our model achieved 0.462 Top-1 accuracy and 0.764 Mean F-score.", "labels": [], "entities": [{"text": "NEWS 2009 experiment", "start_pos": 20, "end_pos": 40, "type": "DATASET", "confidence": 0.9480164051055908}, {"text": "Top-1", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.8899226188659668}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.8163045048713684}, {"text": "Mean", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9977173805236816}, {"text": "F-score", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.7017619609832764}]}], "introductionContent": [{"text": "It is in general difficult for human to translate unfamiliar personal names, place names and names of organizations ().", "labels": [], "entities": [{"text": "translate unfamiliar personal names, place names and names of organizations", "start_pos": 40, "end_pos": 115, "type": "TASK", "confidence": 0.8060845732688904}]}, {"text": "One reason is the variability in name translation.", "labels": [], "entities": [{"text": "name translation", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.8734919726848602}]}, {"text": "In many situations, there is more than one correct translation for the same name.", "labels": [], "entities": []}, {"text": "In some languages, such as Arabic, it can go up to as many as forty (.", "labels": [], "entities": [{"text": "it", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9882323145866394}]}, {"text": "Even professional translators find it difficult to identify all variations.", "labels": [], "entities": []}, {"text": "For example, when translating \"Phelps\" into Chinese, there are at least 5 different ways to translate this name: \"\u8d39\u5c14\u666e\u65af,\" \"\u83f2\u5c14\u666e\u65af,\" \"\u5f17\u5c14\u666e\u65af,\" \"\u83f2\u5c14\u666e\u601d,\" and \"\u83f2\u5c14\u666e\u4e1d,\" with some more popular than others.", "labels": [], "entities": [{"text": "translating \"Phelps\"", "start_pos": 18, "end_pos": 38, "type": "TASK", "confidence": 0.8773466348648071}]}, {"text": "The variability in translation implies the complexity in name translation that can hardly be addressed in typical machine translation systems.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9694030284881592}, {"text": "name translation", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.8226528167724609}, {"text": "machine translation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.7525634765625}]}, {"text": "Machine translation systems are often black boxes where only one translation is provided, which do not offer a solution to variability issue.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8041530251502991}]}, {"text": "The accuracy of a machine translation system, whether statistical or example-based, largely depends on sentence context information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9990466237068176}, {"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7065388709306717}]}, {"text": "This context information is often not available with name translation.", "labels": [], "entities": [{"text": "name translation", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.837242841720581}]}, {"text": "Furthermore, emerging names are difficult to capture in regular machine translation systems if they have not been included in training corpus or translation dictionary.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7200902253389359}]}, {"text": "Thus, being able to translate proper names not only has its own application area, it will also enhance the performance of current machine translation systems.", "labels": [], "entities": [{"text": "translate proper names", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.8642603357632955}, {"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7225332111120224}]}, {"text": "In our previous English-Arabic name transliteration work (, we proposed a framework for name transliteration using a 2-gram and a 3-gram Hidden Markov Model (HMM).", "labels": [], "entities": [{"text": "name transliteration", "start_pos": 88, "end_pos": 108, "type": "TASK", "confidence": 0.7200055569410324}]}, {"text": "In this research, we extend our 2-gram and 3-gram HMM to an N-gram HMM where N is the maximum number of prior translation mapping sequence that can be identified in the training corpus.", "labels": [], "entities": []}, {"text": "In our non-standard runs, we also integrated a Web mining module.", "labels": [], "entities": [{"text": "Web mining", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.6856662631034851}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work; Section 3 describes our algorithm; Section 4 discusses implementation and evaluation results are provided in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Named Entity Workshop (NEWS) 2009 Machine Transliteration Shared Task provided a training corpus with 31,961 pairs of English and Chinese name translations and 2,896 testing cases.", "labels": [], "entities": [{"text": "Named Entity Workshop (NEWS) 2009 Machine Transliteration Shared Task", "start_pos": 0, "end_pos": 69, "type": "DATASET", "confidence": 0.5968720371072943}]}, {"text": "We submitted one standard run with Maximum Ngram HMM (N-HMM) setting, and two nonstandard runs with 3-gram HMM (3-HMM), and Maximum N-gram HMM + Web mining (N-HMM+W).", "labels": [], "entities": []}, {"text": "There are two other runs that we submitted which contains error in the results and they are not discussed here.", "labels": [], "entities": []}, {"text": "We present our evaluation results in.", "labels": [], "entities": []}, {"text": "It is confirmed that Web-mining module boosted the performance of N-gram HMM in all measure except for MAP . However, the boosting effect is small (1.3%).", "labels": [], "entities": []}, {"text": "To our surprise, 3-gram HMM outperformed Maximum N-gram HMM slightly (3% in MAP ).", "labels": [], "entities": []}, {"text": "Our best Top-1 accuracy is 0.462, and best Mean F-score is 0.764 both achieved by N-gram HMM with Web mining module.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9445842504501343}, {"text": "Mean", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9970601201057434}, {"text": "F-score", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.7389278411865234}]}, {"text": "We believe this slightly lower performance of Maximum N-gram HMM can be improved with some tuning of weight parameters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation Results with Top-10 Candidates", "labels": [], "entities": []}]}