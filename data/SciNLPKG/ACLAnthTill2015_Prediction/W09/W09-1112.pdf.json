{"title": [{"text": "Minimally Supervised Model of Early Language Acquisition", "labels": [], "entities": [{"text": "Early Language Acquisition", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.6383882264296213}]}], "abstractContent": [{"text": "Theories of human language acquisition assume that learning to understand sentences is a partially-supervised task (at best).", "labels": [], "entities": [{"text": "human language acquisition", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.6593401630719503}]}, {"text": "Instead of using 'gold-standard' feedback, we train a simplified \"Baby\" Semantic Role Labeling system by combining world knowledge and simple grammatical constraints to form a potentially noisy training signal.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.5764958957831064}]}, {"text": "This combination of knowledge sources is vital for learning ; a training signal derived from a single component leads the learner astray.", "labels": [], "entities": []}, {"text": "When this largely unsupervised training approach is applied to a corpus of child directed speech, the BabySRL learns shallow structural cues that allow it to mimic striking behaviors found in experiments with children and begin to correctly identify agents in a sentence.", "labels": [], "entities": [{"text": "BabySRL", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.8870552182197571}]}], "introductionContent": [{"text": "Sentence comprehension involves assigning semantic roles to sentence constituents, determining who does what to whom.", "labels": [], "entities": [{"text": "Sentence comprehension", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9636700749397278}]}, {"text": "How do young children begin learning to interpret sentences?", "labels": [], "entities": []}, {"text": "The structuremapping view of early verb and syntax acquisition proposes that children treat the number of nouns in the sentence as a cue to its semantic predicateargument structure, and represent language experience in an abstract format that promotes generalization to new verbs ).", "labels": [], "entities": [{"text": "early verb and syntax acquisition", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.6175298392772675}]}, {"text": "Theories of human language acquisition assume that learning to understand sentences is naturally a partially-supervised task: the fit of the learner's predicted meaning with the referential context and background knowledge provides corrective feedback (e.g.,).", "labels": [], "entities": [{"text": "human language acquisition", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.6831492086251577}]}, {"text": "But this feedback must be noisy; referential scenes provide ambiguous information about the semantic roles of sentence participants.", "labels": [], "entities": []}, {"text": "For example, the same participant could be construed as an agent who 'fled' or as a patient who is 'chased'.", "labels": [], "entities": []}, {"text": "In this paper, we address this problem by designing a Semantic Role Labeling system (SRL), equipped with shallow representations of sentence structure motivated by the structure-mapping account, that learns with no gold-standard feedback at all.", "labels": [], "entities": [{"text": "Semantic Role Labeling system (SRL)", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.70267796090671}]}, {"text": "Instead, the SRL provides its own internallygenerated feedback based on a combination of world knowledge and linguistic constraints.", "labels": [], "entities": [{"text": "SRL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8643223643302917}]}, {"text": "As a simple stand-in for world knowledge, we assume that the learner has animacy information for some set of nouns, and uses this knowledge to determine their likely roles.", "labels": [], "entities": []}, {"text": "In terms of linguistic constraints, the learner uses simple knowledge about the possible arguments verbs can appear with.", "labels": [], "entities": []}, {"text": "This approach has two goals.", "labels": [], "entities": []}, {"text": "The first is to inform theories of language learning by investigating the utility of the proposed internally-generated feedback as one component of the human learner's tools.", "labels": [], "entities": [{"text": "language learning", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7038543075323105}]}, {"text": "Second, from an NLP and Machine Learning perspective we propose to inject information into a supervised learning algorithm through a channel other than labeled training data.", "labels": [], "entities": []}, {"text": "From both perspectives, our key question is whether the algorithm can use these internally labeled examples to extract general patterns that can be applied to new cases.", "labels": [], "entities": []}, {"text": "By building a model that uses shallow representations of sentences and minimal feedback, but that mimics features of language development in children, we can explore the nature of initial representations of syntactic structure.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments use internally-generated feedback to train simple, abstract structural features: the NPattern features that proved useful with goldstandard training in.", "labels": [], "entities": []}, {"text": "Section 3.1 tests the system on agent-identification in held-out sentences from the corpus, and demonstrates that the animacy-based feedback is useful, yielding SRL performance comparable to that of a system trained with 1000 sentences of gold-standard feedback.", "labels": [], "entities": [{"text": "SRL", "start_pos": 161, "end_pos": 164, "type": "TASK", "confidence": 0.7409743070602417}]}, {"text": "Section 3.2 presents the critical novelverb test data, demonstrating that this system replicates key findings of () with no gold standard feedback.", "labels": [], "entities": []}, {"text": "Using only noisy internallygenerated feedback, the BabySRL learned that the first of two nouns is an agent, and generalized this knowledge to sentences with novel verbs.", "labels": [], "entities": [{"text": "BabySRL", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9256193041801453}]}, {"text": "(+NPattern) when tested on a held-out section of the Sarah Childes corpus section 84-90, recorded at child ages 3;11-4;1 years.", "labels": [], "entities": [{"text": "NPattern)", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9461120069026947}, {"text": "Sarah Childes corpus section 84-90", "start_pos": 53, "end_pos": 87, "type": "DATASET", "confidence": 0.858188247680664}]}, {"text": "Agent identification based on lexical features is quite accurate given animacy feedback alone (Feedback 1).", "labels": [], "entities": [{"text": "Agent identification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7518309056758881}]}, {"text": "As expected, because many agents are animate, the animacy tagging heuristic itself is useful.", "labels": [], "entities": [{"text": "animacy tagging heuristic", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.7678293685118357}]}, {"text": "As linguistic constraints are added via non-A0 inference (Feedback 2), performance increases for both the lexical baseline and NPattern feature-set, because the system experiences more non-A0 training examples.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 reports for the varying feedback schemes,  the A0 F1 performance for a system with either lex- ical baseline feature (Words) or structural features", "labels": [], "entities": [{"text": "A0 F1", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.7327267527580261}]}, {"text": " Table 2: Percentage of sentences interpreted as agent first (%A0-A1) by the BabySRL when trained on unlabeled data  with the 3 internally-generated feedback schemes described in the text. Two different two-noun sentence structures  were used ('A gorps B', 'A and B gorp'), along with two different methods of sampling the nouns (Full Distribution,  Animate Nouns) to create test sets with 100 sentences each.", "labels": [], "entities": [{"text": "BabySRL", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.965457022190094}]}]}