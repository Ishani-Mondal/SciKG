{"title": [{"text": "Extracting Complex Biological Events with Rich Graph-Based Feature Sets", "labels": [], "entities": [{"text": "Extracting Complex Biological Events", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8704537451267242}]}], "abstractContent": [{"text": "We describe a system for extracting complex events among genes and proteins from biomedical literature, developed in context of the BioNLP'09 Shared Task on Event Extraction.", "labels": [], "entities": [{"text": "BioNLP'09 Shared Task on Event Extraction", "start_pos": 132, "end_pos": 173, "type": "TASK", "confidence": 0.5426606237888336}]}, {"text": "For each event, its text trigger, class, and arguments are extracted.", "labels": [], "entities": []}, {"text": "In contrast to the prevailing approaches in the domain, events can be arguments of other events, resulting in a nested structure that better captures the underlying biological statements.", "labels": [], "entities": []}, {"text": "We divide the task into independent steps which we approach as machine learning problems.", "labels": [], "entities": []}, {"text": "We define a wide array of features and in particular make extensive use of dependency parse graphs.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 75, "end_pos": 91, "type": "TASK", "confidence": 0.6850046664476395}]}, {"text": "A rule-based post-processing step is used to refine the output in accordance with the restrictions of the extraction task.", "labels": [], "entities": []}, {"text": "In the shared task evaluation, the system achieved an F-score of 51.95% on the primary task, the best performance among the participants.", "labels": [], "entities": [{"text": "F-score", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.999652624130249}]}], "introductionContent": [{"text": "In this paper, we present the best-performing system in the primary task of the BioNLP'09 Shared Task on Event Extraction (.", "labels": [], "entities": [{"text": "BioNLP'09 Shared Task on Event Extraction", "start_pos": 80, "end_pos": 121, "type": "TASK", "confidence": 0.5050871620575587}]}, {"text": "The purpose of this shared task was to competitively evaluate information extraction systems targeting complex events in the biomedical domain.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.765942394733429}]}, {"text": "Such an evaluation helps to establish the relative merits of competing approaches, allowing direct comparability of results in a controlled setting.", "labels": [], "entities": []}, {"text": "The shared task was the first competitive evaluation of its kind in the BioNLP field as the extraction of complex events became possible only recently with the introduction of corpora containing the necessary annotation: the GENIA event corpus () and the BioInfer corpus ().", "labels": [], "entities": [{"text": "GENIA event corpus", "start_pos": 225, "end_pos": 243, "type": "DATASET", "confidence": 0.9020004272460938}, {"text": "BioInfer corpus", "start_pos": 255, "end_pos": 270, "type": "DATASET", "confidence": 0.9331485629081726}]}, {"text": "The objective of the primary task (Task 1) was to detect biologically relevant events such as protein binding and phosphorylation, given only annotation of named entities.", "labels": [], "entities": []}, {"text": "For each event, its class, trigger expression in the text, and arguments need to be extracted.", "labels": [], "entities": []}, {"text": "The task follows the recent movement in BioNLP towards the extraction of semantically typed, complex events the arguments of which can also be other events.", "labels": [], "entities": []}, {"text": "This results in a nested structure that captures the underlying biological statements more accurately compared to the prevailing approach of merely detecting binary interactions of pairs of biological entities.", "labels": [], "entities": []}, {"text": "Our system is characterized by heavy reliance on efficient, state-of-the-art machine learning techniques and a wide array of features derived from a full dependency analysis of each sentence.", "labels": [], "entities": []}, {"text": "The system is a pipeline of three major processing steps: trigger recognition, argument detection and semantic post-processing.", "labels": [], "entities": [{"text": "trigger recognition", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7307702302932739}, {"text": "argument detection", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7574009299278259}]}, {"text": "By separating trigger recognition from argument detection, we can use methods familiar from named entity recognition to tag words as event triggers.", "labels": [], "entities": [{"text": "trigger recognition", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7210378497838974}, {"text": "argument detection", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6812541335821152}, {"text": "named entity recognition", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.7730008959770203}]}, {"text": "Event argument detection then becomes the task of predicting for each triggertrigger or trigger-named entity pair whether it corresponds to an actual instantiation of an event argument.", "labels": [], "entities": [{"text": "Event argument detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7157788872718811}]}, {"text": "Both steps can thus be approached as classification tasks.", "labels": [], "entities": []}, {"text": "In contrast, semantic post-processing is rule-based, directly implementing argument type constraints following from the definition of the task.", "labels": [], "entities": []}, {"text": "In the following sections, we present the implementation of the three stages of our information extraction system in detail, and provide insights into why we chose the approach we did.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.8414579927921295}]}, {"text": "We also discuss alternate directions we followed but that did not improve performance.", "labels": [], "entities": []}, {"text": "Finally, we analyze the overall performance of our system in the shared task as well as evaluate its components individually.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Per-class performance in terms of Recall, Preci- sion, and F-score on the test set (3182 events) using ap- proximate span and recursive matching, the primary eval- uation criterion of Task 1.", "labels": [], "entities": [{"text": "Recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9980666041374207}, {"text": "Preci- sion", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.9502736131350199}, {"text": "F-score", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.9983950257301331}]}, {"text": " Table 2: Performance of our system on the test set (3182  events) with respect to other evaluation measures in the  shared task.", "labels": [], "entities": []}, {"text": " Table 3: Effect of the trigger detector (Trig), edge detec- tor (Edge), and post-processing (PP) on performance on  the development set (1789 events). The \u2206F column in- dicates the effect of replacing the predictions (pred) of  a component with the corresponding gold standard data  (GS), i.e. the maximal possible performance gain obtain- able from further development of that component.", "labels": [], "entities": [{"text": "post-processing (PP)", "start_pos": 77, "end_pos": 97, "type": "METRIC", "confidence": 0.7231591194868088}]}]}