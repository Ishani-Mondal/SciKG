{"title": [{"text": "Exploiting Comparable Corpora with TER and TERp", "labels": [], "entities": [{"text": "TER", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.7870117425918579}, {"text": "TERp", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.7695284485816956}]}], "abstractContent": [{"text": "In this paper we present an extension of a successful simple and effective method for extracting parallel sentences from comparable corpora and we apply it to an Arabic/English NIST system.", "labels": [], "entities": []}, {"text": "We experiment with anew TERp filter, along with WER and TER filters.", "labels": [], "entities": [{"text": "TERp filter", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.9453835487365723}, {"text": "WER", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9622328281402588}, {"text": "TER", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9879446029663086}]}, {"text": "We also report a comparison of our approach with that of (Munteanu and Marcu, 2005) using exactly the same corpora and show performance gain by using much lesser data.", "labels": [], "entities": []}, {"text": "Our approach employs an SMT system built from small amounts of parallel texts to translate the source side of the non-parallel corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9887004494667053}]}, {"text": "The target side texts are used, along with other corpora, in the language model of this SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9935699701309204}]}, {"text": "We then use information retrieval techniques and simple filters to create parallel data from a comparable news corpora.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7516880929470062}]}, {"text": "We evaluate the quality of the extracted data by showing that it significantly improves the performance of an SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.9928939938545227}]}], "introductionContent": [{"text": "Parallel corpora, a requisite resource for Statistical Machine Translation (SMT) as well as many other natural language processing applications, remain a sparse resource due to the huge expense (human as well as monetary) required for their creation.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 43, "end_pos": 80, "type": "TASK", "confidence": 0.8671162525812784}]}, {"text": "A parallel corpus, also called bitext, consists in bilingual texts aligned at the sentence level.", "labels": [], "entities": []}, {"text": "SMT systems use parallel texts as training material and monolingual corpora for target language modeling.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9819120168685913}, {"text": "target language modeling", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.634740541378657}]}, {"text": "Though enough monolingual data is available for most language pairs, it is the parallel corpus that is a sparse resource.", "labels": [], "entities": []}, {"text": "The performance of an SMT system heavily depends on the parallel corpus used for training.", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9940388202667236}]}, {"text": "Generally, more bitexts lead to better performance.", "labels": [], "entities": [{"text": "bitexts", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.9729649424552917}]}, {"text": "The existing resources of parallel corpora cover a few language pairs and mostly come from one domain (proceedings of the Canadian or European Parliament, or of the United Nations).", "labels": [], "entities": []}, {"text": "The language jargon used in such corpora is not very well suited for everyday life translations or translations of some other domain, thus a dire need arises for more parallel corpora well suited for everyday life and domain adapted translations.", "labels": [], "entities": [{"text": "everyday life translations or translations", "start_pos": 69, "end_pos": 111, "type": "TASK", "confidence": 0.7187240600585938}]}, {"text": "One option to increase this scarce resource could be to produce more human translations, but this is a very expensive option, in terms of both time and money.", "labels": [], "entities": []}, {"text": "Crowd sourcing could be another option, but this has its own costs and thus is not very practical for all cases.", "labels": [], "entities": [{"text": "Crowd sourcing", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7679277658462524}]}, {"text": "The worldwide web can also be crawled for potential \"parallel sentences\", but most of the found bilingual texts are not direct translations of each other and not very easy to align.", "labels": [], "entities": []}, {"text": "In recent works less expensive but very productive methods of creating such sentence aligned bilingual corpora were proposed.", "labels": [], "entities": []}, {"text": "These are based on generating \"parallel\" texts from already available \"almost parallel\" or \"not much parallel\" texts.", "labels": [], "entities": []}, {"text": "The term \"comparable corpus\" is often used to define such texts.", "labels": [], "entities": []}, {"text": "A comparable corpus is a collection of texts composed independently in the respective languages and combined on the basis of similarity of content (.", "labels": [], "entities": []}, {"text": "The raw material for comparable documents is often easy to obtain but the alignment of individual documents is a challenging task.", "labels": [], "entities": []}, {"text": "Potential sources of comparable corpora are multilingual news reporting agencies like AFP, Xinhua, Al-Jazeera, BBC etc, or multilingual encyclopedias like Wikipedia, Encarta etc.", "labels": [], "entities": []}, {"text": "Such comparable corpora are widely available from LDC, in particular the Gigaword corpora, or over the WEB for many languages and domains, e.g. Wikipedia.", "labels": [], "entities": [{"text": "WEB", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.9452438354492188}]}, {"text": "They often contain many sentences that are reasonable translations of each other.", "labels": [], "entities": []}, {"text": "Reliable identification of these pairs would enable the automatic creation of large and diverse parallel corpora.", "labels": [], "entities": []}, {"text": "The ease of availability of these comparable corpora and the potential for parallel corpus as well as dictionary creation has sparked an interest in trying to make maximum use of these comparable resources, some of these works include dictionary learning and identifying word translations, named entity recognition), word sense disambiguation, improving SMT performance using extracted parallel sentences (,.", "labels": [], "entities": [{"text": "dictionary creation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7371329963207245}, {"text": "identifying word translations", "start_pos": 259, "end_pos": 288, "type": "TASK", "confidence": 0.6519462962945303}, {"text": "named entity recognition", "start_pos": 290, "end_pos": 314, "type": "TASK", "confidence": 0.6157452166080475}, {"text": "word sense disambiguation", "start_pos": 317, "end_pos": 342, "type": "TASK", "confidence": 0.7706471880276998}, {"text": "SMT", "start_pos": 354, "end_pos": 357, "type": "TASK", "confidence": 0.9968944787979126}]}, {"text": "There has been considerable amount of work on bilingual comparable corpora to learn word translations as well as discovering parallel sentences.", "labels": [], "entities": [{"text": "learn word translations", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.6546455721060435}]}, {"text": "use an approach based on dynamic programming to identify potential parallel sentences in title pairs.", "labels": [], "entities": []}, {"text": "Longest common sub sequence, edit operations and match-based score functions are subsequently used to determine confidence scores.", "labels": [], "entities": []}, {"text": "propose their STRAND web-mining based system and show that their approach is able to find large numbers of similar document pairs.", "labels": [], "entities": []}, {"text": "Works aimed at discovering parallel sentences include (, who use cross-language information retrieval techniques and dynamic programming to extract sentences from an English-Japanese comparable corpus.", "labels": [], "entities": []}, {"text": "They identify similar article pairs, and then, treating these pairs as parallel texts, align their sentences on a sentence pair similarity score and use DP to find the least-cost alignment over the document pair.", "labels": [], "entities": [{"text": "DP", "start_pos": 153, "end_pos": 155, "type": "METRIC", "confidence": 0.9387192130088806}]}, {"text": "approach the problem by using a cosine similarity measure to match foreign and English documents.", "labels": [], "entities": []}, {"text": "They work on \"very non-parallel corpora\".", "labels": [], "entities": []}, {"text": "They then generate all possible sentence pairs and select the best ones based on a threshold on cosine similarity scores.", "labels": [], "entities": []}, {"text": "Using the extracted sentences they learn a dictionary and iterate over with more sentence pairs.", "labels": [], "entities": []}, {"text": "Recent work by uses a bilingual lexicon to translate some of the words of the source sentence.", "labels": [], "entities": []}, {"text": "These translations are then used to query the database to find matching translations using information retrieval (IR) techniques.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 91, "end_pos": 117, "type": "TASK", "confidence": 0.7681543111801148}]}, {"text": "Candidate sentences are determined based on word overlap and the decision whether a sentence pair is parallel or not is performed by a maximum entropy classifier trained on parallel sentences.", "labels": [], "entities": []}, {"text": "Bootstrapping is used and the size of the learned bilingual dictionary is increased over iterations to get better results.", "labels": [], "entities": []}, {"text": "Our technique is similar to that of (Munteanu and Marcu, 2005) but we bypass the need of the bilingual dictionary by using proper SMT translations and instead of a maximum entropy classifier we use simple measures like the word error rate (WER) and the translation edit rate (TER) to decide whether sentences are parallel or not.", "labels": [], "entities": [{"text": "SMT translations", "start_pos": 130, "end_pos": 146, "type": "TASK", "confidence": 0.9360291063785553}, {"text": "word error rate (WER)", "start_pos": 223, "end_pos": 244, "type": "METRIC", "confidence": 0.881053626537323}, {"text": "translation edit rate (TER)", "start_pos": 253, "end_pos": 280, "type": "METRIC", "confidence": 0.8326959908008575}]}, {"text": "We also report an extension of our work by experimenting with an additional filter TERp, and building a named entity noun dictionary using the unknown words from the SMT (section 5.2).", "labels": [], "entities": [{"text": "TERp", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9294370412826538}, {"text": "SMT", "start_pos": 166, "end_pos": 169, "type": "TASK", "confidence": 0.5141554474830627}]}, {"text": "TERp has been tried encouraged by the outperformance of TER in our previous study on French-English.", "labels": [], "entities": [{"text": "TERp", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7674276828765869}, {"text": "TER", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9353392720222473}]}, {"text": "We have applied our technique on a different language pair Arabic-English, versus French-English that we reported the technique earlier on.", "labels": [], "entities": []}, {"text": "Our use of full SMT sentences, gives us an added advantage of being able to detect one of the major errors of these approaches, also identified by), i.e, the cases where the initial sentences are identical but the retrieved sentence has a tail of extra words at sentence end.", "labels": [], "entities": [{"text": "SMT sentences", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.9324169754981995}]}, {"text": "We discuss this problem as detailed in section 5.1.", "labels": [], "entities": []}, {"text": "We apply our technique to create a parallel corpus for the Arabic/English language pair.", "labels": [], "entities": []}, {"text": "We show that we achieve significant improvements in the BLEU score by adding our extracted corpus to the already available human-translated corpora.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9750155806541443}]}, {"text": "We also perform a comparison of the data extracted by our approach and that by) and report the results in Section 5.3.", "labels": [], "entities": [{"text": "Section 5.3", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.9112097322940826}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section we first describe the baseline SMT system trained on human-provided translations only.", "labels": [], "entities": [{"text": "SMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9858574867248535}]}, {"text": "We then proceed by explaining our parallel sentence selection scheme and the post-processing.", "labels": [], "entities": []}, {"text": "Section 5 summarizes our experimental results and the paper concludes with a discussion and perspectives of this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our main goal was to be able to create an additional parallel corpus to improve machine translation quality, especially for the domains where we have lessor no parallel data available.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7832752168178558}]}, {"text": "In this section we report the results of adding these extracted parallel sentences to the already available humantranslated parallel sentences.", "labels": [], "entities": []}, {"text": "We conducted a range of experiments by adding our extracted corpus to various combinations of already available human-translated parallel corpora.", "labels": [], "entities": []}, {"text": "For our experiments on effect on SMT quality we use only the XIN extracted corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9969835877418518}, {"text": "XIN extracted corpus", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.8377944827079773}]}, {"text": "We experimented with WER, TER and TERp as filters to select the best scoring sentences.", "labels": [], "entities": [{"text": "WER", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9675677418708801}, {"text": "TER", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9658529758453369}, {"text": "TERp", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.969436526298523}]}, {"text": "shows some of the scores obtained based on BLEU scores on the Dev and test data as a function of the size of the added extracted corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9977445602416992}, {"text": "Dev and test data", "start_pos": 62, "end_pos": 79, "type": "DATASET", "confidence": 0.8655826300382614}]}, {"text": "The name of the bitext indicates the filter threshold used, for example, TER-50 means sentences selected based on TER filter threshold of 50.", "labels": [], "entities": [{"text": "TER-50", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9815708994865417}, {"text": "TER filter threshold", "start_pos": 114, "end_pos": 134, "type": "METRIC", "confidence": 0.9226447939872742}]}, {"text": "Generally, sentences selected based on TER filter showed better BLEU scores on NIST06 than their WER and TERp counter parts up to almost 21M words.", "labels": [], "entities": [{"text": "TER", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9343140721321106}, {"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9995658993721008}, {"text": "NIST06", "start_pos": 79, "end_pos": 85, "type": "DATASET", "confidence": 0.9657333493232727}, {"text": "WER", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9502129554748535}, {"text": "TERp", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9215487837791443}]}, {"text": "Also for the same filter threshold TERp selected longer sentences, followed by TER and then WER, this fact is evident from table 2, where for the filter threshold of 60, TERp and TER select 20.8M and 17.3 words respectively, whereas WER selects 14.5M words.", "labels": [], "entities": [{"text": "TER", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9866898059844971}, {"text": "WER", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.977495551109314}]}, {"text": "shows the trend obtained in function of the number of words added.", "labels": [], "entities": []}, {"text": "These experiments were performed by adding our extracted sentences to only 5.8M words of human-provided translations.", "labels": [], "entities": []}, {"text": "Our best results are obtained when 11.5M of our extracted parallel sentences based on TER filter are added to 5.8M of News wire and gale parallel corpora.", "labels": [], "entities": [{"text": "TER", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.8795015811920166}]}, {"text": "We gain an improvement of Arabic words for training baseline TER TERp WER: BLEU scores on the NIST06 (Dev, top) and NIST08 (test, bottom) data using an WER,TER or TERp filter as a function of the number of extracted Arabic words added.", "labels": [], "entities": [{"text": "TER TERp WER", "start_pos": 61, "end_pos": 73, "type": "METRIC", "confidence": 0.6570261120796204}, {"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.889289915561676}, {"text": "NIST06", "start_pos": 94, "end_pos": 100, "type": "DATASET", "confidence": 0.9579315185546875}, {"text": "NIST08", "start_pos": 116, "end_pos": 122, "type": "DATASET", "confidence": 0.9500645399093628}, {"text": "TERp", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.9347143769264221}]}, {"text": "An interesting thing to notice in figure 2 is that no filter was able to clearly outperform the others, which is contradictory to our experiments with the French-English language pair, where the TER filter clearly outperformed the WER filter.", "labels": [], "entities": [{"text": "TER", "start_pos": 195, "end_pos": 198, "type": "METRIC", "confidence": 0.9794501066207886}]}, {"text": "WER is worse than TER but less evident here than for our previous experiments for the French-English language pair.", "labels": [], "entities": [{"text": "WER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9819580316543579}, {"text": "TER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9966652989387512}]}, {"text": "This performance gain by using the TER filter for FrenchEnglish was our main motivation for trying TERp.", "labels": [], "entities": [{"text": "TER", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9043758511543274}, {"text": "FrenchEnglish", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.9641348719596863}, {"text": "TERp", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.594269335269928}]}, {"text": "We expected TERp to get better results compared to WER and TER, but TER filter seems the better one among the three filters.", "labels": [], "entities": [{"text": "TERp", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9327719807624817}, {"text": "WER", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9197150468826294}, {"text": "TER", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9889233112335205}, {"text": "TER filter", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.967458575963974}]}, {"text": "Note that all conditions in all the experiments were identical.", "labels": [], "entities": []}, {"text": "This gives a strong hint of language pair dependency, making the decision of suitability of a particular filter dependent on the language pair in consideration.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of BLEU scores for the best  systems selected based on various thresholds of  WER, TER and TERp filters", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8804765939712524}, {"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9920516014099121}, {"text": "WER", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9907842874526978}, {"text": "TER", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9470865726470947}, {"text": "TERp", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9449200630187988}]}]}