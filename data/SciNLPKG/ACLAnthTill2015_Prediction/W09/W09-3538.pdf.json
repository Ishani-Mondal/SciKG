{"title": [{"text": "Czech Named Entity Corpus and SVM-based Recognizer", "labels": [], "entities": [{"text": "Czech Named Entity Corpus", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.8972074389457703}]}], "abstractContent": [{"text": "This paper deals with recognition of named entities in Czech texts.", "labels": [], "entities": [{"text": "recognition of named entities in Czech texts", "start_pos": 22, "end_pos": 66, "type": "TASK", "confidence": 0.8678980554853167}]}, {"text": "We present a recently released corpus of Czech sentences with manually annotated named entities , in which a rich two-level classification scheme was used.", "labels": [], "entities": []}, {"text": "There are around 6000 sentences in the corpus with roughly 33000 marked named entity instances.", "labels": [], "entities": []}, {"text": "We use the data for training and evaluating a named entity recognizer based on Support Vector Machine classification technique.", "labels": [], "entities": [{"text": "Support Vector Machine classification", "start_pos": 79, "end_pos": 116, "type": "TASK", "confidence": 0.5169364735484123}]}, {"text": "The presented recognizer outperforms the results previously reported for NE recognition in Czech.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.9856268167495728}]}], "introductionContent": [{"text": "After the series of Message Understanding Conferences (MUC;), processing of named entities (NEs) became a well established discipline within the NLP domain, usually motivated by the needs of Information Extraction, Question Answering, or Machine Translation.", "labels": [], "entities": [{"text": "Message Understanding Conferences (MUC", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.7758010566234589}, {"text": "processing of named entities (NEs)", "start_pos": 62, "end_pos": 96, "type": "TASK", "confidence": 0.8084097334316799}, {"text": "Information Extraction", "start_pos": 191, "end_pos": 213, "type": "TASK", "confidence": 0.7875149846076965}, {"text": "Question Answering", "start_pos": 215, "end_pos": 233, "type": "TASK", "confidence": 0.8258484601974487}, {"text": "Machine Translation", "start_pos": 238, "end_pos": 257, "type": "TASK", "confidence": 0.7711161673069}]}, {"text": "For English, one can find literature about attempts at rule-based solutions for the NE task as well as machine-learning approaches, be they dependent on the existence of labeled data (such as CoNLL-2003 shared task data), unsupervised (using redundancy in NE expressions and their contexts, see e.g. () or a combination of both (such as (), in which labeled data are used as a source of seed for an unsupervised procedure exploiting huge unlabeled data).", "labels": [], "entities": [{"text": "CoNLL-2003 shared task data", "start_pos": 192, "end_pos": 219, "type": "DATASET", "confidence": 0.8698093444108963}]}, {"text": "A survey of research on named entity recognition is available in.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.7187981208165487}]}, {"text": "There has been considerably less research done in the NE field in Czech, as discussed in).", "labels": [], "entities": [{"text": "NE field", "start_pos": 54, "end_pos": 62, "type": "TASK", "confidence": 0.9223329126834869}]}, {"text": "Therefore we focus on it in this paper, which is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we present a recently released corpus of Czech sentences with manually annotated instances of named entities, in which a rich classification scheme is used.", "labels": [], "entities": []}, {"text": "In Section 3 we describe anew NE recognizer developed for Czech, based on the Support Vector Machine (SVM) classification technique.", "labels": [], "entities": [{"text": "NE recognizer", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.8506120145320892}, {"text": "Support Vector Machine (SVM) classification", "start_pos": 78, "end_pos": 121, "type": "TASK", "confidence": 0.5517178305557796}]}, {"text": "Evaluation of such approach is presented in Section 4.", "labels": [], "entities": []}, {"text": "The summary is given in Section 5.", "labels": [], "entities": [{"text": "summary", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9398006796836853}]}], "datasetContent": [{"text": "We use the following standard quantities for evaluating performance of the presented classifier: \u2022 precision -the number of correctly predicted NEs divided by the number of all predicted NEs, \u2022 recall -the number of correctly predicted NEs divided by the number of all NEs in the data, \u2022 f-score -harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9986380934715271}, {"text": "recall", "start_pos": 194, "end_pos": 200, "type": "METRIC", "confidence": 0.9986775517463684}, {"text": "f-score -harmonic mean", "start_pos": 288, "end_pos": 310, "type": "METRIC", "confidence": 0.9268182218074799}, {"text": "precision", "start_pos": 314, "end_pos": 323, "type": "METRIC", "confidence": 0.9322434663772583}, {"text": "recall", "start_pos": 328, "end_pos": 334, "type": "METRIC", "confidence": 0.9983711838722229}]}, {"text": "In our opinion, simpler quantities such as accuracy (the percentage of correctly marked words) are not suitable for this task, since the number of NE instances to be found is not known in advance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9991883635520935}]}], "tableCaptions": [{"text": " Table 1: Division of the annotated corpus into  training, development test, and evaluation test sets.", "labels": [], "entities": []}, {"text": " Table 2: Occurrences of NE instances of different  length in the annotated corpus.", "labels": [], "entities": []}, {"text": " Table 3: Distribution of several most frequent NE  types in the annotated corpus.", "labels": [], "entities": []}, {"text": " Table 4: Summary of the SVM classifier performance (P=precision, R=recall, F=f-measure). Recogni- tion of NEs of different length is evaluated separately. The other dimension corresponds to the gradually  released correctness requirements.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9884077906608582}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9485682249069214}, {"text": "Recogni- tion", "start_pos": 90, "end_pos": 103, "type": "METRIC", "confidence": 0.9523679614067078}]}]}