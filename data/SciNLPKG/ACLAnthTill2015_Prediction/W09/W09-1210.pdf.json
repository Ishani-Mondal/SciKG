{"title": [{"text": "Efficient Parsing of Syntactic and Semantic Dependency Structures", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe our system for the 2009 CoNLL shared task for joint parsing of syntactic and semantic dependency structures of multiple languages.", "labels": [], "entities": [{"text": "joint parsing of syntactic and semantic dependency structures of multiple languages", "start_pos": 73, "end_pos": 156, "type": "TASK", "confidence": 0.7579961473291571}]}, {"text": "Our system combines and implements efficient parsing techniques to get a high accuracy as well as very good parsing and training time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9770306348800659}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9992806315422058}, {"text": "parsing", "start_pos": 108, "end_pos": 115, "type": "TASK", "confidence": 0.9680778980255127}]}, {"text": "For the applications of syntactic and semantic parsing, the parsing time and memory footprint are very important.", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6427903696894646}]}, {"text": "We think that also the development of systems can profit from this since one can perform more experiments in the given time.", "labels": [], "entities": []}, {"text": "For the subtask of syntactic dependency parsing, we could reach the second place with an accuracy in average of 85.68 which is only 0.09 points behind the first ranked system.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.7270487546920776}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9995933175086975}]}, {"text": "For this task, our system has the highest accuracy for English with 89.88, German with 87.48 and the out-of-domain data in average with 78.79.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.999401330947876}]}, {"text": "The semantic role labeler works not as well as our parser and we reached therefore the fourth place (ranked by the macro F1 score) in the joint task for syntactic and semantic dependency parsing.", "labels": [], "entities": [{"text": "semantic role labeler", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6309032638867696}, {"text": "macro F1 score", "start_pos": 115, "end_pos": 129, "type": "METRIC", "confidence": 0.7137272556622823}, {"text": "syntactic and semantic dependency parsing", "start_pos": 153, "end_pos": 194, "type": "TASK", "confidence": 0.6131065547466278}]}], "introductionContent": [{"text": "Depedendency parsing and semantic role labeling improved in the last years significantly.", "labels": [], "entities": [{"text": "Depedendency parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8332652151584625}, {"text": "semantic role labeling", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7174486120541891}]}, {"text": "One of the reasons are CoNLL shared tasks for syntactic dependency parsing in the years) and the CoNLL shared task for joint parsing of syntactic and semantic dependencies in the year 2008 and of cause this shared task in 2009, cf. ().", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6900272965431213}, {"text": "joint parsing of syntactic and semantic dependencies", "start_pos": 119, "end_pos": 171, "type": "TASK", "confidence": 0.7245176945413861}]}, {"text": "The CoNLL Shared Task 2009 is to parse syntactic and semantic dependencies of seven languages.", "labels": [], "entities": [{"text": "CoNLL Shared Task 2009", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7500184625387192}, {"text": "parse syntactic and semantic dependencies", "start_pos": 33, "end_pos": 74, "type": "TASK", "confidence": 0.8078393936157227}]}, {"text": "Therefore, training and development data inform of annotated corpora for Catalan, Chinese, Czech, English, German, Japanese and Spanish is provided, cf. (;).", "labels": [], "entities": []}, {"text": "There are two main approaches to dependency parsing: Maximum Spanning Tree (MST) based dependency parsing and Transition based dependency parsing, cf.).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.8124867677688599}, {"text": "dependency parsing", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.709385558962822}, {"text": "Transition based dependency parsing", "start_pos": 110, "end_pos": 145, "type": "TASK", "confidence": 0.5894961282610893}]}, {"text": "Our system uses the first approach since we saw better chance to improve the parsing speed and additionally, the MST had so far slightly better parsing results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.9786757826805115}, {"text": "MST", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.5933496952056885}, {"text": "parsing", "start_pos": 144, "end_pos": 151, "type": "TASK", "confidence": 0.9627834558486938}]}, {"text": "For the task of semantic role labeling, we adopted a pipeline architecture where we used for each step the same learning technique (SVM) since we opted for the possibility to build asynchronous combined parser with one score function.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.7347497344017029}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Performance Comparison. For the baseline sys- tem (1), we used the system of McDonald and Pereira  (2006) on a MacPro 2.8 Ghz as well for our implementa- tion (2). For system (3), we use a computer with Intel i7  3.2 Ghz which is faster than the MacPro. For all systems,  we use 10 training iterations for the SVM Mira.", "labels": [], "entities": [{"text": "SVM Mira", "start_pos": 320, "end_pos": 328, "type": "DATASET", "confidence": 0.8720751106739044}]}, {"text": " Table 4: Syntactic and Semantic Scores. @ indicate values that are the highest scores of all systems.", "labels": [], "entities": []}]}