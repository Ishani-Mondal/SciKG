{"title": [{"text": "The effect of correcting grammatical errors on parse probabilities", "labels": [], "entities": []}], "abstractContent": [{"text": "We parse the sentences in three parallel error corpora using a generative, probabilis-tic parser and compare the parse probabilities of the most likely analyses for each grammatical sentence and its closely related ungrammatical counterpart.", "labels": [], "entities": []}], "introductionContent": [{"text": "The syntactic analysis of a sentence provided by a parser is used to guide the interpretation process required, to varying extents, by applications such as question-answering, sentiment analysis and machine translation.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 176, "end_pos": 194, "type": "TASK", "confidence": 0.9718956053256989}, {"text": "machine translation", "start_pos": 199, "end_pos": 218, "type": "TASK", "confidence": 0.8184724152088165}]}, {"text": "In theory, however, parsing also provides a grammaticality judgement as shown in.", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.969502866268158}]}, {"text": "Whether or not a sentence is grammatical is determined by its parsability with a grammar of the language in question.", "labels": [], "entities": []}, {"text": "The use of parsing to determine whether a sentence is grammatical has faded into the background as hand-written grammars aiming to describe only the grammatical sequences in a language have been largely supplanted by treebankderived grammars.", "labels": [], "entities": []}, {"text": "Grammars read from treebanks tend to overgenerate.", "labels": [], "entities": []}, {"text": "This overgeneration is unproblematic if a probabilistic model is used to rank analyses and if the parser is not being used to provide a grammaticality judgement.", "labels": [], "entities": []}, {"text": "The combination of grammar size, probabilistic parse selection and smoothing techniques results in high robustness to errors and broad language coverage, desirable properties in applications requiring a syntactic analysis of any input, regardless of noise.", "labels": [], "entities": []}, {"text": "However, for applications which rely on a parser's ability to distinguish grammatical sequences from ungrammatical ones, e.g. grammar checkers, overgenerating grammars are perhaps less useful as they fail to reject ungrammatical strings.", "labels": [], "entities": []}, {"text": "A naive solution might be to assume that the probability assigned to a parse tree by its probabilistic model could be leveraged in someway to: Grammaticality and formal languages determine the sentence's grammaticality.", "labels": [], "entities": []}, {"text": "In this paper, we explore one aspect of this question by using three parallel error corpora to determine the effect of common English grammatical errors on the parse probability of the most likely parse tree returned by a generative probabilistic parser.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of this experiment is to find out to what extent ungrammatical sentences behave differently from correct sentences as regards their parse probabilities.", "labels": [], "entities": []}, {"text": "There are two types of corpora we study: two parallel error corpora that consist of authentic ungrammatical sentences and manual corrections, and a parallel error corpus that consists of authentic grammatical sentences and automatically induced errors.", "labels": [], "entities": []}, {"text": "Using parallel corpora allows us to compare pairs of sentences that have the same or very similar lexical content and differ only with respect to their grammaticality.", "labels": [], "entities": []}, {"text": "A corpus with automatically induced errors is included because such a corpus is much larger and controlled error insertion allows us to examine directly the effect of a particular error type.", "labels": [], "entities": []}, {"text": "The first parallel error corpus contains 1,132 sentence pairs each comprising an ungrammatical sentence and a correction).", "labels": [], "entities": []}, {"text": "The sentences are taken from written texts and contain either one or two grammatical errors.", "labels": [], "entities": []}, {"text": "The errors include those made by native English speakers.", "labels": [], "entities": []}, {"text": "We call this the Foster corpus.", "labels": [], "entities": [{"text": "Foster corpus", "start_pos": 17, "end_pos": 30, "type": "DATASET", "confidence": 0.9472995698451996}]}, {"text": "The second corpus is a learner corpus.", "labels": [], "entities": []}, {"text": "It contains transcribed spoken utterances produced by learners of English of varying L1s and levels of experience in a classroom setting.", "labels": [], "entities": []}, {"text": "manually corrected 500 sentences of the transcribed utterances, producing a parallel error corpus which we call Gonzaga 500.", "labels": [], "entities": [{"text": "Gonzaga 500", "start_pos": 112, "end_pos": 123, "type": "DATASET", "confidence": 0.8361694812774658}]}, {"text": "The third parallel corpus contains 199,600 sentences taken from the British National Corpus and ungrammatical sentences produced by introducing errors of the following five types into the original BNC sentences: errors involving an extra word, errors involving a missing word, realword spelling errors, agreement errors and errors involving an incorrect verbal inflection.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 68, "end_pos": 91, "type": "DATASET", "confidence": 0.951851487159729}]}, {"text": "All sentence pairs in the three parallel corpora are parsed using the June 2006 version of the first-stage parser of Charniak and Johnson (2005), a lexicalised, generative, probabilistic parser achieving competitive performance on Wall Street Journal text.", "labels": [], "entities": [{"text": "Wall Street Journal text", "start_pos": 231, "end_pos": 255, "type": "DATASET", "confidence": 0.9758361726999283}]}, {"text": "We compare the probability of the highest ranked tree for the grammatical sentence in the pair to the probability of the highest ranked tree for the ungrammatical sentence.", "labels": [], "entities": []}, {"text": "shows the results for the Foster corpus.", "labels": [], "entities": [{"text": "Foster corpus", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.965469628572464}]}, {"text": "For ranges of 4 points on the logarithmic scale, the bars depict how many sentence pairs have a probability ratio within the respective range.", "labels": [], "entities": []}, {"text": "For example, there are 48 pairs (5th bar from left) for which the correction has a parse probability which is between 8 and 12 points lower than the parse probability of its erroneous original, or, in other words, for which the probability ratio is between e \u221212 and e \u22128 . 853 pairs show a higher probability for the correction vs. 279 pairs which do not.", "labels": [], "entities": []}, {"text": "Since the probability of a tree is the product of its rule probabilities, sentence length is a factor.", "labels": [], "entities": []}, {"text": "If we focus on corrections that do not change the sentence length, the ratio sharpens to 414 vs. 90 pairs.", "labels": [], "entities": [{"text": "sharpens", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.8530968427658081}]}, {"text": "Ungrammatical sentences do often receive lower parse probabilities than their corrections.", "labels": [], "entities": []}, {"text": "shows the results for the Gonzaga 500.", "labels": [], "entities": [{"text": "Gonzaga 500", "start_pos": 26, "end_pos": 37, "type": "DATASET", "confidence": 0.9442020952701569}]}, {"text": "Here we see a picture similar to the Foster corpus although the peak for the range from e 0 = 1 toe 4 \u2248 54.6 is more pronounced.", "labels": [], "entities": [{"text": "Foster corpus", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.9279354214668274}]}, {"text": "This time there are more cases where the parse probability drops despite a sentence being shortened and vice versa.", "labels": [], "entities": [{"text": "parse probability", "start_pos": 41, "end_pos": 58, "type": "METRIC", "confidence": 0.8465740978717804}]}, {"text": "Overall, 348 sentence pairs show an increased parse probability, 152 do not.", "labels": [], "entities": [{"text": "parse probability", "start_pos": 46, "end_pos": 63, "type": "METRIC", "confidence": 0.773624062538147}]}, {"text": "For sentences that stay the same length the ratio is 154 to 34, or 4.53:1, for this corpus which is almost identical to the Foster corpus (4.60:1).", "labels": [], "entities": [{"text": "Foster corpus", "start_pos": 124, "end_pos": 137, "type": "DATASET", "confidence": 0.9257628321647644}]}], "tableCaptions": []}