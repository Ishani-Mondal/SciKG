{"title": [{"text": "On bootstrapping of linguistic features for bootstrapping grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "We discuss a cue-based grammar induction approach based on a parallel theory of grammar.", "labels": [], "entities": [{"text": "cue-based grammar induction", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.6339745819568634}]}, {"text": "Our model is based on the hypotheses of interdependency between linguistic levels (of representation) and in-ductability of specific structural properties at a particular level, with consequences for the induction of structural properties at other linguistic levels.", "labels": [], "entities": []}, {"text": "We present the results of three different cue-learning experiments and settings, covering the induction of phonological, morphological, and syntactic properties, and discuss potential consequences for our general grammar induction model.", "labels": [], "entities": [{"text": "general grammar induction", "start_pos": 205, "end_pos": 230, "type": "TASK", "confidence": 0.629791776339213}]}], "introductionContent": [{"text": "We assume that individual linguistic levels of natural languages differ with respect to their formal complexity.", "labels": [], "entities": []}, {"text": "In particular, the assumption is that structural properties of linguistic levels like phonology or morphology can be characterized fully by Regular grammars, and if not, at least a large subset can.", "labels": [], "entities": []}, {"text": "Structural properties of natural language syntax on the other hand might be characterized by Mildly context-free grammars, whereat least a large subset could be characterized by Regular and Context-free grammars.", "labels": [], "entities": []}, {"text": "Ignoring for the time being extra-linguistic conditions and cues for linguistic properties, and independent of the complexity of specific linguistic levels for particular languages, we assume that specific properties atone particular linguistic level correlate with properties at another level.", "labels": [], "entities": []}, {"text": "In natural languages certain phonological processes might be triggered at morphological boundaries only, e.g. (, or prosodic properties correlate with syntactic phrase boundaries and semantic properties, e.g..", "labels": [], "entities": []}, {"text": "Similarly, lexical properties, as for example stress patterns and morphological structure tend to be specific to certain word types (e.g. substantives, but not function words).", "labels": [], "entities": []}, {"text": "i.e. correlate with the lexical morpho-syntactic properties used in grammars of syntax.", "labels": [], "entities": []}, {"text": "Other more informal correlations that are discussed in linguistics, that rather lack a formal model or explanation, are for example the relation between morphological richness and the freedom of word order in syntax.", "labels": [], "entities": []}, {"text": "Thus, it seems that specific regularities and grammatical properties atone linguistic level might provide cues for structural properties at another level.", "labels": [], "entities": []}, {"text": "We expect such correlations to be language specific, given that languages qualitatively significantly differ at least at the phonetic, phonological and morphological level, and at least quantitatively also at the syntactic level.", "labels": [], "entities": []}, {"text": "Thus in our model of grammar induction, we favor the view expressed e.g. in) that complex grammars are bootstrapped (or grow) from less complex grammars.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7490121722221375}]}, {"text": "On the other hand, the intuition that structural or inherent properties at different linguistic levels correlate, i.e. they seem to be used as cues in processing and acquisition, might require a parallel model of language learning or grammar induction, as for example suggested in or the Competition Model.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 234, "end_pos": 251, "type": "TASK", "confidence": 0.7017791271209717}]}, {"text": "In general, we start with the observation that natural languages are learnable.", "labels": [], "entities": []}, {"text": "In principle, the study of how this might be modeled, and what the minimal assumptions about the grammar properties and the induction algorithm could be, could start top-down, by assuming maximal knowledge of the target grammar, and subsequently eliminating elements that are obviously learnable in an unsupervised way, or fallout as side-effects.", "labels": [], "entities": []}, {"text": "Alternatively, a bottom-up approach could start with the question about how much supervision has to be added to an unsupervised model in order to converge to a concise grammar.", "labels": [], "entities": []}, {"text": "Here we favor the bottom-up approach, and ask how simple properties of grammar can be learned in an unsupervised way, and how cues could be identified that allow for the induction of higher level properties of the target grammar, or other linguistic levels, by for example favoring some structural hypotheses over others.", "labels": [], "entities": []}, {"text": "In this article we will discuss in detail several experiments of morphological cue induction for lexical classification) and) using Vector Space Models for category induction and subsequent rule formation.", "labels": [], "entities": [{"text": "morphological cue induction", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.701369563738505}, {"text": "lexical classification", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.7728840112686157}, {"text": "category induction", "start_pos": 156, "end_pos": 174, "type": "TASK", "confidence": 0.740441769361496}, {"text": "rule formation", "start_pos": 190, "end_pos": 204, "type": "TASK", "confidence": 0.7300389409065247}]}, {"text": "Furthermore, we discuss structural cohesion measured via Entropy-based statistics on the basis of distributional properties for unsupervised syntactic structure induction) from raw text, and compare the results with syntactic corpora like the Penn Treebank.", "labels": [], "entities": [{"text": "syntactic structure induction", "start_pos": 141, "end_pos": 170, "type": "TASK", "confidence": 0.706170936425527}, {"text": "Penn Treebank", "start_pos": 243, "end_pos": 256, "type": "DATASET", "confidence": 0.9947597682476044}]}, {"text": "We expand these results with recent experiments in the domain of unsupervised induction of phonotactic regularities and phonological structure ( \u00b4 Cavar and\u00b4Cavar and\u00b4 and\u00b4Cavar, 2009), providing cues for morphological structure induction and syntactic phrasing.", "labels": [], "entities": [{"text": "morphological structure induction", "start_pos": 205, "end_pos": 238, "type": "TASK", "confidence": 0.6530952354272207}]}], "datasetContent": [], "tableCaptions": []}