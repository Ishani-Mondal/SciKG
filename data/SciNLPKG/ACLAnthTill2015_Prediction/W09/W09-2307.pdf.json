{"title": [{"text": "Discriminative Reordering with Chinese Grammatical Relations Features", "labels": [], "entities": [{"text": "Discriminative Reordering with Chinese Grammatical Relations", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.631424700220426}]}], "abstractContent": [{"text": "The prevalence in Chinese of grammatical structures that translate into English in different word orders is an important cause of translation difficulty.", "labels": [], "entities": [{"text": "translation", "start_pos": 130, "end_pos": 141, "type": "TASK", "confidence": 0.9659214019775391}]}, {"text": "While previous work has used phrase-structure parses to deal with such ordering problems, we introduce a richer set of Chinese grammatical relations that describes more semantically abstract relations between words.", "labels": [], "entities": [{"text": "phrase-structure parses", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.7385918200016022}]}, {"text": "Using these Chinese grammatical relations , we improve a phrase orientation clas-sifier (introduced by Zens and Ney (2006)) that decides the ordering of two phrases when translated into English by adding path features designed over the Chinese typed dependencies.", "labels": [], "entities": []}, {"text": "We then apply the log probability of the phrase orientation classifier as an extra feature in a phrase-based MT system, and get significant BLEU point gains on three test sets: MT02 (+0.59), MT03 (+1.00) and MT05 (+0.77).", "labels": [], "entities": [{"text": "phrase orientation classifier", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.7958391408125559}, {"text": "MT", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.9137278199195862}, {"text": "BLEU point", "start_pos": 140, "end_pos": 150, "type": "METRIC", "confidence": 0.9741006791591644}, {"text": "MT02", "start_pos": 177, "end_pos": 181, "type": "DATASET", "confidence": 0.8560576438903809}, {"text": "MT03", "start_pos": 191, "end_pos": 195, "type": "DATASET", "confidence": 0.8658370971679688}, {"text": "MT05", "start_pos": 208, "end_pos": 212, "type": "DATASET", "confidence": 0.9065253734588623}]}, {"text": "Our Chinese grammatical relations are also likely to be useful for other NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Structural differences between Chinese and English area major factor in the difficulty of machine translation from Chinese to English.", "labels": [], "entities": [{"text": "machine translation from Chinese to English", "start_pos": 90, "end_pos": 133, "type": "TASK", "confidence": 0.8278263807296753}]}, {"text": "The wide variety of such Chinese-English differences include the ordering of head nouns and relative clauses, and the ordering of prepositional phrases and the heads they modify.", "labels": [], "entities": []}, {"text": "Previous studies have shown that using syntactic structures from the source side can help MT performance on these constructions.", "labels": [], "entities": [{"text": "MT", "start_pos": 90, "end_pos": 92, "type": "TASK", "confidence": 0.996321439743042}]}, {"text": "Most of the previous syntactic MT work has used phrase structure parses in various ways, either by doing syntaxdirected translation to directly translate parse trees into strings in the target language), or by using source-side parses to preprocess the source sentences (.", "labels": [], "entities": [{"text": "syntactic MT", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.5727289319038391}, {"text": "phrase structure parses", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.6696636180082957}]}, {"text": "One intuition for using syntax is to capture different Chinese structures that might have the same meaning and hence the same translation in English.", "labels": [], "entities": []}, {"text": "But it turns out that phrase structure (and linear order) are not sufficient to capture this meaning relation.", "labels": [], "entities": []}, {"text": "Two sentences with the same meaning can have different phrase structures and linear orders.", "labels": [], "entities": []}, {"text": "In the example in, sentences (a) and (b) have the same meaning, but different linear orders and different phrase structure parses.", "labels": [], "entities": [{"text": "phrase structure parses", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.6401899953683218}]}, {"text": "The translation of sentence (a) is: \"In the past three years these municipalities have collectively put together investment in fixed assets in the amount of 12 billion yuan.\"", "labels": [], "entities": []}, {"text": "In sentence (b), \"in the past three years\" has moved its position.", "labels": [], "entities": []}, {"text": "The temporal adverbial \" \" (in the past three years) has different linear positions in the sentences.", "labels": [], "entities": []}, {"text": "The phrase structures are different too: in (a) the LCP is immediately under IP while in (b) it is under VP.", "labels": [], "entities": []}, {"text": "We propose to use typed dependency parses instead of phrase structure parses.", "labels": [], "entities": [{"text": "typed dependency parses", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.6314665774504343}, {"text": "phrase structure parses", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.7269014219443003}]}, {"text": "Typed dependency parses give information about grammatical relations between words, instead of constituency information.", "labels": [], "entities": [{"text": "Typed dependency parses", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6254225671291351}]}, {"text": "They capture syntactic relations, such as nsubj (nominal subject) and dobj (direct object) , but also encode semantic information such as in the loc (localizer) relation.", "labels": [], "entities": []}, {"text": "For the example in, if we look at the sentence structure from the typed dependency parse (bottom of), \" \" is connected to the main verb (finish) by a loc (localizer) relation, and the structure is the same for sentences (a) and (b).", "labels": [], "entities": []}, {"text": "This suggests that this kind of semantic and syntactic representation could have more benefit than phrase structure parses.", "labels": [], "entities": [{"text": "phrase structure parses", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.7446252107620239}]}, {"text": "Our Chinese typed dependencies are automatically extracted from phrase structure parses.", "labels": [], "entities": [{"text": "phrase structure parses", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.6928979158401489}]}, {"text": "In English, this kind of typed dependencies has been introduced by and.", "labels": [], "entities": []}, {"text": "Using typed dependencies, it is easier to readout relations between words, and thus the typed dependencies have been used in meaning extraction tasks.", "labels": [], "entities": [{"text": "meaning extraction", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.7964587807655334}]}, {"text": "We design features over the Chinese typed dependencies and use them in a phrase-based MT system when deciding whether one chunk of Chinese words (MT system statistical phrase) should appear before or after another.", "labels": [], "entities": [{"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9117797613143921}]}, {"text": "To achieve this, we train a discriminative phrase orientation classifier following the work by, and we use the grammatical relations between words as extra features to build the classifier.", "labels": [], "entities": []}, {"text": "We then apply the phrase orientation classifier as a feature in a phrasebased MT system to help reordering.", "labels": [], "entities": [{"text": "phrase orientation classifier", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.820241908232371}]}], "datasetContent": [{"text": "We use various Chinese-English parallel corpora 1 for both training the phrase orientation classifier, and for extracting statistical phrases for the phrase-based MT system.", "labels": [], "entities": [{"text": "phrase orientation classifier", "start_pos": 72, "end_pos": 101, "type": "TASK", "confidence": 0.8162185947100321}, {"text": "MT", "start_pos": 163, "end_pos": 165, "type": "TASK", "confidence": 0.865976095199585}]}, {"text": "The parallel data contains 1, 560, 071 sentence pairs from various parallel corpora.", "labels": [], "entities": []}, {"text": "There are 12, 259, 997 words on the English side.", "labels": [], "entities": [{"text": "English side", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.9176509380340576}]}, {"text": "Chinese word segmentation is done by the Stanford Chinese segmenter (.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5690516829490662}]}, {"text": "After segmentation, there are 11,061,792 words on the Chinese side.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 6, "end_pos": 18, "type": "TASK", "confidence": 0.9766531586647034}]}, {"text": "The alignment is done by the Berkeley word aligner () and then we symmetrized the word alignment using the grow-diag heuristic.", "labels": [], "entities": []}, {"text": "For the phrase orientation classifier experiments, we extracted labeled examples using the parallel data and the alignment as in.", "labels": [], "entities": [{"text": "phrase orientation classifier", "start_pos": 8, "end_pos": 37, "type": "TASK", "confidence": 0.861514945824941}]}, {"text": "We extracted 9, 194, 193 total valid examples: 86.09% of them are ordered and the other 13.91% are reversed.", "labels": [], "entities": []}, {"text": "To evaluate the classifier performance, we split these examples into training, dev and test set (8 : 1 : 1).", "labels": [], "entities": []}, {"text": "The phrase orientation classifier used in MT experiments is trained with all of the available labeled examples.", "labels": [], "entities": [{"text": "phrase orientation classifier", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.7504047950108846}, {"text": "MT", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.9930619597434998}]}, {"text": "Our MT experiments use a re-implementation of Moses () called Phrasal, which provides an easier API for adding features.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9320590496063232}]}, {"text": "We use a 5-gram language model trained on the Xinhua and AFP sections of the Gigaword corpus (LDC2007T40) and also the English side of all the LDC parallel data permissible under the NIST08 rules.", "labels": [], "entities": [{"text": "AFP", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.8546214699745178}, {"text": "Gigaword corpus", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.8920702040195465}, {"text": "NIST08", "start_pos": 183, "end_pos": 189, "type": "DATASET", "confidence": 0.9596299529075623}]}, {"text": "Documents of Gigaword released during the epochs of MT02, MT03, MT05, and MT06 were removed.", "labels": [], "entities": [{"text": "MT02", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9732263684272766}, {"text": "MT03", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.8785545825958252}, {"text": "MT05", "start_pos": 64, "end_pos": 68, "type": "DATASET", "confidence": 0.8828916549682617}, {"text": "MT06", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.9551499485969543}]}, {"text": "For features in MT experiments, we incorporate Moses' standard eight features as well as the lexicalized reordering features.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9894326329231262}]}, {"text": "To have a more comparable setting with (), we also have a baseline experiment with only the standard eight features.", "labels": [], "entities": []}, {"text": "Parameter tuning is done with Minimum Error Rate Training (MERT).", "labels": [], "entities": [{"text": "Parameter tuning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.721862256526947}, {"text": "Minimum Error Rate Training (MERT)", "start_pos": 30, "end_pos": 64, "type": "METRIC", "confidence": 0.9222412364823478}]}, {"text": "The tuning set for MERT is the NIST MT06 data set, which includes 1664 sentences.", "labels": [], "entities": [{"text": "MERT", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.9514577388763428}, {"text": "NIST MT06 data set", "start_pos": 31, "end_pos": 49, "type": "DATASET", "confidence": 0.9222688376903534}]}, {"text": "We evaluate the result with MT02 (878 sentences), MT03 (919 sen-1 LDC2002E18, LDC2003E07, LDC2003E14, LDC2005E83, LDC2005T06, LDC2006E26, LDC2006E85, LDC2002L27 and LDC2005T34. tences), and MT05 (1082 sentences).", "labels": [], "entities": [{"text": "MT02", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.7576501965522766}, {"text": "MT03", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.8915386199951172}, {"text": "MT05", "start_pos": 190, "end_pos": 194, "type": "DATASET", "confidence": 0.8290043473243713}]}, {"text": "The basic source word features described in Section 2 are referred to as Src, and the target word features as Tgt.", "labels": [], "entities": []}, {"text": "The feature set that used in their MT experiments is Src+Tgt.", "labels": [], "entities": [{"text": "MT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9850442409515381}]}, {"text": "In addition to that, we also experimented with source word features Src2 which are similar to Src, but take a window of 3 around j instead of j.", "labels": [], "entities": []}, {"text": "In we can see that adding the Src2 features increased the total number of features by almost 50%, but also improved the performance.", "labels": [], "entities": []}, {"text": "The PATH features add fewer total number of features than the lexical features, but still provide a 10% error reduction and 1.63 on the macro-F1 on the dev set.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.9750215411186218}]}, {"text": "We use the best feature sets from the feature engineering in and test it on the test set.", "labels": [], "entities": []}, {"text": "We get 94.28% accuracy and 87.17 macro-F1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9997970461845398}]}, {"text": "The overall improvement of accuracy over the baseline is 8.19 absolute points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9996793270111084}]}, {"text": "In the MT setting, we use the log probability from the phrase orientation classifier as an extra feature.", "labels": [], "entities": [{"text": "MT", "start_pos": 7, "end_pos": 9, "type": "TASK", "confidence": 0.9678246974945068}]}, {"text": "The weight of this discriminative reordering feature is also tuned by MERT, along with other Moses features.", "labels": [], "entities": [{"text": "MERT", "start_pos": 70, "end_pos": 74, "type": "DATASET", "confidence": 0.5477896332740784}]}, {"text": "In order to understand how much the PATH features add value to the MT experiments, we trained two phrase orientation classifiers with different features: one with the Src+Src2+Tgt feature set, and the other one with Src+Src2+Tgt+PATH.", "labels": [], "entities": [{"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9707024693489075}]}, {"text": "The results are listed in   lines.", "labels": [], "entities": []}, {"text": "If we use the discriminative reordering model without PATH features and only with word features, we still get improvement over the Moses8Features baseline, but the MT performance is not significantly different from Baseline which uses lexicalized reordering features.", "labels": [], "entities": [{"text": "Moses8Features baseline", "start_pos": 131, "end_pos": 154, "type": "DATASET", "confidence": 0.9328688383102417}, {"text": "MT", "start_pos": 164, "end_pos": 166, "type": "TASK", "confidence": 0.8573453426361084}]}, {"text": "we see that using the Src+Src2+Tgt+PATH features significantly outperforms both baselines.", "labels": [], "entities": [{"text": "PATH", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.8638710975646973}]}, {"text": "Also, if we compare between Src+Src2+Tgt and Src+Src2+Tgt+PATH, the differences are also statistically significant, which shows the effectiveness of the path features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The percentage of typed dependencies in files  1-325 in Chinese (CTB6) and English (English-Chinese  Translation Treebank)", "labels": [], "entities": [{"text": "English-Chinese  Translation Treebank", "start_pos": 94, "end_pos": 131, "type": "DATASET", "confidence": 0.6074415345986685}]}, {"text": " Table 2: Chinese grammatical relations and examples. The counts are from files 1-325 in CTB6.", "labels": [], "entities": [{"text": "Chinese grammatical relations", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.6909310619036356}, {"text": "CTB6", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.9644686579704285}]}, {"text": " Table 3: Feature engineering of the phrase orientation  classifier. Accuracy is defined as (#correctly labeled ex- amples) divided by (#all examples). The macro-F is an  average of the accuracies of the two classes.", "labels": [], "entities": [{"text": "phrase orientation  classifier", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.7472588419914246}, {"text": "Accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9987075328826904}]}, {"text": " Table 4: MT experiments of different settings on various NIST MT evaluation datasets. All differences marked in bold  are significant at the level of 0.05 with the approximate randomization test in (Riezler and Maxwell, 2005).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9908757209777832}, {"text": "NIST MT evaluation datasets", "start_pos": 58, "end_pos": 85, "type": "DATASET", "confidence": 0.6922020018100739}]}]}