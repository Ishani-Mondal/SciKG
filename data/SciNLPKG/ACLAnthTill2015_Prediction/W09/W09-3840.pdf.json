{"title": [], "abstractContent": [{"text": "We propose a generic method to perform lexical disambiguation in lexicalized grammatical formalisms.", "labels": [], "entities": [{"text": "lexical disambiguation", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.6949193179607391}]}, {"text": "It relies on dependency constraints between words.", "labels": [], "entities": []}, {"text": "The soundness of the method is due to invariant properties of the parsing in a given grammar that can be computed statically from the grammar.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this work, we propose a method of lexical disambiguation based on the notion of dependencies.", "labels": [], "entities": [{"text": "lexical disambiguation", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.6877570152282715}]}, {"text": "In modern linguistics, LucienTesn\u00ec ere developed a formal and sophisticated theory with.", "labels": [], "entities": []}, {"text": "Nowadays, many current grammatical formalisms rely more or less explicitly on the notion of dependencies between words.", "labels": [], "entities": []}, {"text": "The most straightforward examples are formalisms in the Dependency Grammars family but it is also true of the phrase structure based formalisms which consider that words introduce incomplete syntactic structures which must be completed by other words.", "labels": [], "entities": [{"text": "Dependency Grammars family", "start_pos": 56, "end_pos": 82, "type": "DATASET", "confidence": 0.6623868544896444}]}, {"text": "This idea is at the core of Categorial Grammars (CG) and all its trends such as Abstract Categorial Grammars (ACG) () or Combinatory Categorial Grammars (CCG), being mostly encoded in their type system.", "labels": [], "entities": []}, {"text": "Dependencies in CG were studied in and for CCG in.", "labels": [], "entities": []}, {"text": "Other formalisms can be viewed as modeling and using dependencies, such as Tree Adjoining Grammars (TAG) with their substitution and adjunction operations.", "labels": [], "entities": []}, {"text": "Dependencies for TAG were studied in.", "labels": [], "entities": [{"text": "TAG", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.4928322434425354}]}, {"text": "More recently, showed that it is also possible to extract a dependency structure from a syntactic analysis in Interaction Grammars (IG).", "labels": [], "entities": [{"text": "Interaction Grammars (IG)", "start_pos": 110, "end_pos": 135, "type": "TASK", "confidence": 0.6665171802043914}]}, {"text": "Another much more recent concept of polarity can be used in grammatical formalisms to express that words introduce incomplete syntactic structures.", "labels": [], "entities": []}, {"text": "IG directly use polarities to describe these structures but it is also possible to use polarities in other formalisms in order to make explicit the more or less implicit notion of incomplete structures: for instance, in CG or in TAG; Gardent and).", "labels": [], "entities": []}, {"text": "On this regard, exhibited a direct link between polarities and dependencies.", "labels": [], "entities": []}, {"text": "This encourages us to say that in many respects dependencies and polarities are two sides of the same coin.", "labels": [], "entities": []}, {"text": "The aim of this paper is to show that dependencies can be used to express constraints on the taggings of a sentence and hence these dependency constraints can be used to partially disambiguate the words of a sentence.", "labels": [], "entities": []}, {"text": "We will see that, in practice, using the link between dependencies and polarities, these dependency constraints can be computed directly from polarized structures.", "labels": [], "entities": []}, {"text": "Exploiting the dependencies encoded in lexical entries to perform disambiguation is the intuition behind supertagging (), a method introduced for LTAG and successfully applied since then to CCG) and HPSG ().", "labels": [], "entities": [{"text": "HPSG", "start_pos": 199, "end_pos": 203, "type": "DATASET", "confidence": 0.9117459654808044}]}, {"text": "These approaches select the most likely lexical entry (entries) for each word, based on Hidden Markov Models or Maximum Entropy Models.", "labels": [], "entities": []}, {"text": "Like the work done by, our method is not based on statistics nor heuristics, but on a necessary condition of the deep parsing.", "labels": [], "entities": []}, {"text": "Consequently, we accept to have more than one lexical tagging fora sentence, as long as we can ensure to have the good ones (when they exist!).", "labels": [], "entities": []}, {"text": "This property is particulary useful to ensure that the deep parsing will not fail because of an error at the disambiguation step.", "labels": [], "entities": []}, {"text": "In wide-coverage lexicalized grammars, a word typically has about 10 corresponding lexical descriptions, which implies that fora short sentence of 10 words, we get 10 10 possible taggings.", "labels": [], "entities": []}, {"text": "It is not reasonable to treat them individually.", "labels": [], "entities": []}, {"text": "To avoid this, it is convenient to use an automaton to represent the set of all paths.", "labels": [], "entities": []}, {"text": "This automaton has linear size with regard to the initial lexical ambiguity.", "labels": [], "entities": []}, {"text": "The idea of using automata is not new.", "labels": [], "entities": []}, {"text": "In particular, methods based on Hidden Markov Models (HMM) use such a technique for part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.7484435141086578}]}, {"text": "Using automata, we benefit from dynamic programming procedures, and consequently from an exponential temporal and space speedup.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}