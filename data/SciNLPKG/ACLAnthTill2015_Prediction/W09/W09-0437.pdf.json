{"title": [{"text": "A Systematic Analysis of Translation Model Search Spaces", "labels": [], "entities": [{"text": "Systematic Analysis of Translation Model Search Spaces", "start_pos": 2, "end_pos": 56, "type": "TASK", "confidence": 0.6947273910045624}]}], "abstractContent": [{"text": "Translation systems are complex, and most metrics do little to pinpoint causes of error or isolate system differences.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9431110620498657}]}, {"text": "We use a simple technique to discover induction errors, which occur when good translations are absent from model search spaces.", "labels": [], "entities": []}, {"text": "Our results show that a common pruning heuristic drastically increases induction error, and also strongly suggest that the search spaces of phrase-based and hierarchical phrase-based models are highly overlapping despite the well known structural differences.", "labels": [], "entities": [{"text": "error", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.5236322283744812}]}], "introductionContent": [{"text": "Most empirical work in translation analyzes models and algorithms using BLEU () and related metrics.", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9784412384033203}, {"text": "BLEU", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9963827133178711}]}, {"text": "Though such metrics are useful as sanity checks in iterative system development, they are less useful as analytical tools.", "labels": [], "entities": []}, {"text": "The performance of a translation system depends on the complex interaction of several different components.", "labels": [], "entities": []}, {"text": "Since metrics assess only output, they fail to inform us about the consequences of these interactions, and thus provide no insight into the errors made by a system, or into the design tradeoffs of competing systems.", "labels": [], "entities": []}, {"text": "In this work, we show that it is possible to obtain such insights by analyzing translation system components in isolation.", "labels": [], "entities": []}, {"text": "We focus on model search spaces ( \u00a72), posing a very simple question: Given a model and a sentence pair, does the search space contain the sentence pair?", "labels": [], "entities": []}, {"text": "Applying this method to the analysis and comparison of FrenchEnglish translation using both phrase-based and hierarchical phrase-based systems yields surprising results, which we analyze quantitatively and qualitatively.", "labels": [], "entities": [{"text": "comparison of FrenchEnglish translation", "start_pos": 41, "end_pos": 80, "type": "TASK", "confidence": 0.6627683043479919}]}, {"text": "\u2022 First, we analyze the induction error of a model, a measure on the completeness of the search space.", "labels": [], "entities": [{"text": "induction error", "start_pos": 24, "end_pos": 39, "type": "METRIC", "confidence": 0.8429771959781647}]}, {"text": "We find that low weight phrase translations typically discarded by heuristic pruning nearly triples the number of reference sentences that can be exactly reconstructed by either model ( \u00a73).", "labels": [], "entities": [{"text": "phrase translations", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7656453549861908}]}, {"text": "\u2022 Second, we find that the high-probability regions in the search spaces of phrase-based and hierarchical systems are nearly identical ( \u00a74).", "labels": [], "entities": []}, {"text": "This means that reported differences between the models are due to their rankings of competing hypotheses, rather than structural differences of the derivations they produce.", "labels": [], "entities": []}], "datasetContent": [{"text": "We analyse rulesets in isolation, removing the influence of the parametrization and heuristics as much as possible for each system as follows: First, we disabled beam search to avoid pruning based on parametrization weights.", "labels": [], "entities": []}, {"text": "Second, we require our decoders to generate the reference via disallowing reference-incompatible hypothesis or chart entries.", "labels": [], "entities": []}, {"text": "This leaves only some search restrictions such as the distortion limit for the phrase-based system for which we controlled, or the maximum number of source words involved in a rule application for the hierarchical system.", "labels": [], "entities": []}, {"text": "Our phrase-based system is Moses (.", "labels": [], "entities": []}, {"text": "We set its stack size to 10 5 , disabled the beam threshold, and varied the translation option limit tol.", "labels": [], "entities": []}, {"text": "Forced translation was implemented by who ensures that hypothesis area prefix of the reference to be generated.", "labels": [], "entities": []}, {"text": "Our hierarchical system is Hiero, modified to construct rules from a small sample of occurrences of each source phrase in training as described by.", "labels": [], "entities": []}, {"text": "The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (10 50 ) to prevent pruning.", "labels": [], "entities": []}, {"text": "Forced translation was implemented by discarding rules and chart entries which do not match the reference.", "labels": [], "entities": [{"text": "translation", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.9471327662467957}]}, {"text": "We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible.", "labels": [], "entities": []}, {"text": "Each system was trained on French-English Europarl (, version 3 (40M words).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.6390092372894287}]}, {"text": "The corpus was aligned with GIZA++ ( and symmetrized with the grow-diag-finaland heuristic (.", "labels": [], "entities": []}, {"text": "A trigram language model with modified Kneser-Ney discounting and interpolation was used as produced by the SRILM toolkit).", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 108, "end_pos": 121, "type": "DATASET", "confidence": 0.8617215156555176}]}, {"text": "Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training and tested on the WMT08 test data.", "labels": [], "entities": [{"text": "WMT08 French-English development data", "start_pos": 30, "end_pos": 67, "type": "DATASET", "confidence": 0.9400446563959122}, {"text": "WMT08 test data", "start_pos": 137, "end_pos": 152, "type": "DATASET", "confidence": 0.986801008383433}]}, {"text": "Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con- straint.", "labels": [], "entities": []}, {"text": "showed that under certain conditions, this constraint could have significant impact on system performance.", "labels": [], "entities": []}, {"text": "The maximum phrase lengths for both the hierarchical and phrase-based system were set to 7.", "labels": [], "entities": []}, {"text": "The distortion limit (dl) for the phrase-based system was set to 6 unless otherwise mentioned.", "labels": [], "entities": [{"text": "distortion limit (dl)", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.9751730680465698}]}, {"text": "All other settings were left at their default values as described by and.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Translation system components and their  associated error types.", "labels": [], "entities": [{"text": "Translation system", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.915838211774826}]}, {"text": " Table 2: Ruleset size expressed as percentage of  available rules when varying the limit of transla- tion options tol per English span and percentage  of French spans with up to tol translations.", "labels": [], "entities": []}, {"text": " Table 3: French spans with more than 1000 trans- lation options.", "labels": [], "entities": [{"text": "trans- lation", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.6657419999440511}]}, {"text": " Table 4: Example translations which could be generated with tol = 50 but not with tol = 20. For each  translation the source (S), reference (R) and the unconstrained output (O) are shown. Bold phrases mark  translation options which were not available under tol = 20.", "labels": [], "entities": []}, {"text": " Table 5: Mutual reachability performance for  French-English (fr-en), German-English (de-en)  and Enlgish-German (en-de). P \u2192 H denotes how  many hierarchical (H) high scoring outputs can be  reached by the phrase-based (P) system. The sub- scripts nt (non-tight) and t (tight) denote the use  of rules with unaligned words or not.", "labels": [], "entities": []}, {"text": " Table 6: Performance for phrase-based and hier- archical systems in BLEU for French-English (fr- en), German-English (de-en) and English-German  (en-de).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.8462859392166138}]}]}