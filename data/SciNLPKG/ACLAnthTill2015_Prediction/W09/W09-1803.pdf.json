{"title": [{"text": "Bounding and Comparing Methods for Correlation Clustering Beyond ILP", "labels": [], "entities": []}], "abstractContent": [{"text": "We evaluate several heuristic solvers for correlation clustering, the NP-hard problem of partitioning a dataset given pairwise affinities between all points.", "labels": [], "entities": [{"text": "correlation clustering", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.9366759359836578}]}, {"text": "We experiment on two practical tasks, document clustering and chat dis-entanglement, to which ILP does not scale.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7932201027870178}]}, {"text": "On these datasets, we show that the clustering objective often, but not always, correlates with external metrics, and that local search always improves over greedy solutions.", "labels": [], "entities": []}, {"text": "We use semi-definite programming (SDP) to provide a tighter bound, showing that simple algorithms are already close to optimality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Correlation clustering is a powerful technique for discovering structure in data.", "labels": [], "entities": [{"text": "Correlation clustering", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.798178493976593}]}, {"text": "It operates on the pairwise relationships between datapoints, partitioning the graph to minimize the number of unrelated pairs that are clustered together, plus the number of related pairs that are separated.", "labels": [], "entities": []}, {"text": "Unfortunately, this minimization problem is NP-hard (.", "labels": [], "entities": []}, {"text": "Practical work has adopted one of three strategies for solving it.", "labels": [], "entities": []}, {"text": "For a few specific tasks, one can restrict the problem so that it is efficiently solvable.", "labels": [], "entities": []}, {"text": "In most cases, however, this is impossible.", "labels": [], "entities": []}, {"text": "Integer linear programming (ILP) can be used to solve the general problem optimally, but only when the number of data points is small.", "labels": [], "entities": []}, {"text": "Beyond a few hundred points, the only available solutions are heuristic or approximate.", "labels": [], "entities": []}, {"text": "In this paper, we evaluate a variety of solutions for correlation clustering on two realistic NLP tasks, text topic clustering and chat disentanglement, where typical datasets are too large for ILP to find a solution.", "labels": [], "entities": [{"text": "correlation clustering", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9013693332672119}, {"text": "text topic clustering", "start_pos": 105, "end_pos": 126, "type": "TASK", "confidence": 0.7347810467084249}, {"text": "chat disentanglement", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.772426038980484}]}, {"text": "We show, as in previous work on consensus clustering, that local search can improve the solutions found by commonly-used methods.", "labels": [], "entities": [{"text": "consensus clustering", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8762973845005035}]}, {"text": "We investigate the relationship between the clustering objective and external evaluation metrics such as F-score and one-toone overlap, showing that optimizing the objective is usually a reasonable aim, but that other measurements like number of clusters found should sometimes be used to reject pathological solutions.", "labels": [], "entities": [{"text": "F-score", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.9953558444976807}]}, {"text": "We prove that the best heuristics are quite close to optimal, using the first implementation of the semidefinite programming (SDP) relaxation to provide tighter bounds.", "labels": [], "entities": []}, {"text": "The specific algorithms we investigate are, of course, only a subset of the large number of possible solutions, or even of those proposed in the literature.", "labels": [], "entities": []}, {"text": "We chose to test a few common, efficient algorithms that are easily implemented.", "labels": [], "entities": []}, {"text": "Our use of a good bounding strategy means that we do not need to perform an exhaustive comparison; we will show that, though the methods we describe are not perfect, the remaining improvements possible with any algorithm are relatively small.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Score of the solution with best objective for each  solver, averaged over newsgroups training sets, sorted by  objective.", "labels": [], "entities": [{"text": "Score", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9647732377052307}]}, {"text": " Table 3: Score of the solution with best objective found  by each solver on the chat test dataset, averaged over 6  annotations, sorted by objective.", "labels": [], "entities": [{"text": "chat test dataset", "start_pos": 81, "end_pos": 98, "type": "DATASET", "confidence": 0.7255714138348898}]}, {"text": " Table 4: Average number of clusters found (using addi- tive weights) for chat test data.", "labels": [], "entities": []}, {"text": " Table 5: Kendall's tau correlation between objective and  metric values for the chat test set, for all solutions and top  10% of solutions.", "labels": [], "entities": [{"text": "chat test set", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.7678312063217163}]}]}