{"title": [{"text": "Multilingual Dependency-based Syntactic and Semantic Parsing", "labels": [], "entities": [{"text": "Multilingual Dependency-based Syntactic and Semantic Parsing", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.5371706386407217}]}], "abstractContent": [{"text": "Our CoNLL 2009 Shared Task system includes three cascaded components: syntactic parsing, predicate classification, and semantic role labeling.", "labels": [], "entities": [{"text": "CoNLL 2009 Shared Task system", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.8667045116424561}, {"text": "syntactic parsing", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7063669115304947}, {"text": "predicate classification", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.8096617162227631}, {"text": "semantic role labeling", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.640015572309494}]}, {"text": "A pseudo-projective high-order graph-based model is used in our syntactic dependency parser.", "labels": [], "entities": [{"text": "syntactic dependency parser", "start_pos": 64, "end_pos": 91, "type": "TASK", "confidence": 0.6465220352013906}]}, {"text": "A support vector machine (SVM) model is used to classify predicate senses.", "labels": [], "entities": []}, {"text": "Semantic role labeling is achieved using maximum entropy (MaxEnt) model based semantic role classification and integer linear programming (ILP) based post inference.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6609517832597097}, {"text": "semantic role classification", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.6721968750158945}]}, {"text": "Finally , we win the first place in the joint task, including both the closed and open challenges.", "labels": [], "entities": []}, {"text": "1 System Architecture Our CoNLL 2009 Shared Task (Haji\u010d et al., 2009): multilingual syntactic and semantic dependencies system includes three cascaded components: syntactic parsing, predicate classification, and semantic role labeling.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.702054500579834}, {"text": "predicate classification", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.8119391798973083}, {"text": "semantic role labeling", "start_pos": 212, "end_pos": 234, "type": "TASK", "confidence": 0.6487423976262411}]}, {"text": "2 Syntactic Dependency Parsing We extend our CoNLL 2008 graph-based model (Che et al., 2008) in four ways: 1.", "labels": [], "entities": [{"text": "Syntactic Dependency Parsing", "start_pos": 2, "end_pos": 30, "type": "TASK", "confidence": 0.7068371772766113}, {"text": "CoNLL 2008 graph-based model", "start_pos": 45, "end_pos": 73, "type": "DATASET", "confidence": 0.9120410084724426}]}, {"text": "We use bigram features to choose multiple possible syntactic labels for one arc, and decide the optimal label during decoding.", "labels": [], "entities": []}, {"text": "2. We extend the model with sibling features (Mc-Donald, 2006).", "labels": [], "entities": [{"text": "Mc-Donald, 2006)", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.8647815585136414}]}, {"text": "3. We extend the model with grandchildren features.", "labels": [], "entities": []}, {"text": "Rather than only using the left-most and right-most grandchildren as Carreras (2007) and Johans-son and Nugues (2008) did, we use all left and right grandchildren in our model.", "labels": [], "entities": []}, {"text": "4. We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We participate in the CoNLL 2009 shared task with all 7 languages:, Chinese (Palmer and Xue, 2009),), English (, German (), Japanese (), and Spanish (.", "labels": [], "entities": [{"text": "CoNLL 2009 shared task", "start_pos": 22, "end_pos": 44, "type": "DATASET", "confidence": 0.8312172740697861}]}, {"text": "Besides the closed challenge, we also submitted the open challenge results.", "labels": [], "entities": []}, {"text": "Our open challenge strategy is very simple.", "labels": [], "entities": []}, {"text": "We add the SRL development data of each language into their training data.", "labels": [], "entities": [{"text": "SRL development", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.8440593481063843}]}, {"text": "The purpose is to examine the effect of the additional data, especially for out-of-domain (ood) data.", "labels": [], "entities": []}, {"text": "Three machines (with 2.5GHz Xeon CPU and 16G memory) were used to train our models.", "labels": [], "entities": []}, {"text": "During the peak time, Amazon's EC2 (Elastic Compute Cloud) 3 was used, too.", "labels": [], "entities": [{"text": "Amazon's EC2 (Elastic Compute Cloud) 3", "start_pos": 22, "end_pos": 60, "type": "DATASET", "confidence": 0.9135373830795288}]}, {"text": "Our system requires 15G memory at most and the longest training time is about 36 hours.", "labels": [], "entities": []}, {"text": "During training the predicate classification (PC) and the semantic role labeling (SRL) models, golden syntactic dependency parsing results are used.", "labels": [], "entities": [{"text": "predicate classification (PC)", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.8258509397506714}, {"text": "semantic role labeling (SRL)", "start_pos": 58, "end_pos": 86, "type": "TASK", "confidence": 0.785822590192159}, {"text": "golden syntactic dependency parsing", "start_pos": 95, "end_pos": 130, "type": "TASK", "confidence": 0.6863958686590195}]}, {"text": "Previous experiments show that the PC and SRL test results based on golden parse trees are slightly worse than that based on cross trained parse trees.", "labels": [], "entities": []}, {"text": "It is, however, a pity that we have no enough time and machines to do cross training for so many languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Final system results", "labels": [], "entities": []}]}