{"title": [{"text": "Multilingual Dependency Learning: A Huge Feature Engineering Method to Semantic Dependency Parsing *", "labels": [], "entities": [{"text": "Semantic Dependency Parsing", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.6235739489396414}]}], "abstractContent": [{"text": "This paper describes our system about multilingual semantic dependency parsing (SR-Lonly) for our participation in the shared task of CoNLL-2009.", "labels": [], "entities": [{"text": "multilingual semantic dependency parsing", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.6343580931425095}, {"text": "CoNLL-2009", "start_pos": 134, "end_pos": 144, "type": "DATASET", "confidence": 0.8415313959121704}]}, {"text": "We illustrate that semantic dependency parsing can be transformed into a word-pair classification problem and implemented as a single-stage machine learning system.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.7149335145950317}, {"text": "word-pair classification", "start_pos": 73, "end_pos": 97, "type": "TASK", "confidence": 0.7295389473438263}]}, {"text": "For each input corpus, a large scale feature engineering is conducted to select the best fit feature template set incorporated with a proper argument pruning strategy.", "labels": [], "entities": []}, {"text": "The system achieved the top average score in the closed challenge: 80.47% semantic labeled F1 for the average score.", "labels": [], "entities": [{"text": "F1", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.8426820039749146}]}], "introductionContent": [{"text": "The syntactic and semantic dependency parsing in multiple languages introduced by the shared task of is an extension of the CoNLL-2008 shared task.", "labels": [], "entities": [{"text": "syntactic and semantic dependency parsing", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.6296248316764832}]}, {"text": "Seven languages, English plus Catalan, Chinese, Czech, German, Japanese and Spanish, are involved;).", "labels": [], "entities": []}, {"text": "This paper presents our research for participation in the semantic-only (SRLonly) challenge of the CoNLL-2009 shared task, with a * This study is partially supported by CERG grant 9040861 (CityU 1318/03H), CityU Strategic Research Grant 7002037, Projects 60673041 and 60873041 under the National Natural Science Foundation of China and Project 2006AA01Z147 under the \"863\" National High-Tech Research and Development of China.", "labels": [], "entities": [{"text": "CERG grant 9040861 (CityU 1318/03H", "start_pos": 169, "end_pos": 203, "type": "DATASET", "confidence": 0.8328371942043304}, {"text": "CityU Strategic Research Grant 7002037", "start_pos": 206, "end_pos": 244, "type": "DATASET", "confidence": 0.8868377566337585}]}, {"text": "highlight on our strategy to select features from a large candidate set for maximum entropy learning.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our evaluation is carried out on two computational servers, (1) LEGA, a 64-bit ubuntu Linux installed server with double dual-core AMD Opteron processors of 2.8GHz and 24GB memory.", "labels": [], "entities": [{"text": "LEGA", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.7454357743263245}]}, {"text": "This server was also used for our previous participation in CoNLL-2008 shared task.", "labels": [], "entities": [{"text": "CoNLL-2008 shared task", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6839825510978699}]}, {"text": "(2) MEGA, a 64-bit ubuntu Linux installed server with six quad-core Intel Xeon processors of 2.33GHz and 128GB memory.", "labels": [], "entities": [{"text": "MEGA", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.6822549104690552}]}, {"text": "Altogether nearly 60,000 machine learning routines were run to select the best fit feature template sets for all seven languages within two months.", "labels": [], "entities": []}, {"text": "Both LEGA and MEGA were used for this task.", "labels": [], "entities": [{"text": "LEGA", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.8459807634353638}, {"text": "MEGA", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.635526716709137}]}, {"text": "However, training and test for the final submission of Chinese, Czech and English run in MEGA, and the rest in LEGA.", "labels": [], "entities": [{"text": "MEGA", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.9334030747413635}, {"text": "LEGA", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.8408510088920593}]}, {"text": "As we used multiple thread training and multiple routines run at the same time, the exact time cost for either training or testis hard to estimate.", "labels": [], "entities": []}, {"text": "Here we just report the actual time and memory cost in for reference.", "labels": [], "entities": [{"text": "memory", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.8554767370223999}]}, {"text": "The official evaluation results of our system are in.", "labels": [], "entities": []}, {"text": "Numbers in bold in the table stand for the best performances for the specific languages.", "labels": [], "entities": []}, {"text": "The results in development sets are also given.", "labels": [], "entities": []}, {"text": "The first row of the table reports the results using golden input features.", "labels": [], "entities": []}, {"text": "Two facts as the following suggest that our system does output robust and stable results.", "labels": [], "entities": []}, {"text": "The first is that two results for development and test sets in the same language are quite close.", "labels": [], "entities": []}, {"text": "The second is about out-ofdomain (OOD) task.", "labels": [], "entities": []}, {"text": "Though for each OOD task, we just used the same model trained from the respective language and did nothing to strengthen it, this does not hinder our system to obtain top results in Czech and English OOD tasks.", "labels": [], "entities": [{"text": "OOD task", "start_pos": 16, "end_pos": 24, "type": "TASK", "confidence": 0.8285557925701141}]}, {"text": "In addition, the feature template sets from automatical selection procedure in this task were used for the joint task of this shared task, and also output top results according to the average score of semantic labeled F1 (", "labels": [], "entities": [{"text": "F1", "start_pos": 218, "end_pos": 220, "type": "METRIC", "confidence": 0.9324997067451477}]}], "tableCaptions": [{"text": " Table 1: Notations of FEATs", "labels": [], "entities": [{"text": "FEATs", "start_pos": 23, "end_pos": 28, "type": "TASK", "confidence": 0.2814180850982666}]}, {"text": " Table 2: Feature template set: argument classifier", "labels": [], "entities": []}, {"text": " Table 3: Feature template set: sense classifier", "labels": [], "entities": []}, {"text": " Table 6: Semantic labeled F1", "labels": [], "entities": []}]}