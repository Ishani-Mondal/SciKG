{"title": [{"text": "Accurate Argumentative Zoning with Maximum Entropy models", "labels": [], "entities": [{"text": "Accurate", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.955269992351532}]}], "abstractContent": [{"text": "We present a maximum entropy classifier that significantly improves the accuracy of Argumentative Zoning in scientific literature.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9993396401405334}, {"text": "Argumentative Zoning", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7187286913394928}]}, {"text": "We examine the features used to achieve this result and experiment with Argumentative Zoning as a sequence tagging task, decoded with Viterbi using up to four previous classification decisions.", "labels": [], "entities": [{"text": "sequence tagging task", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.7534680167833964}]}, {"text": "The result is a 23% F-score increase on the Computational Linguistics conference papers marked up by Teufel (1999).", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9994624257087708}, {"text": "Computational Linguistics conference papers", "start_pos": 44, "end_pos": 87, "type": "DATASET", "confidence": 0.7209778130054474}]}, {"text": "Finally, we demonstrate the performance of our system in different scientific domains by applying it to a corpus of Astronomy journal articles annotated using a modified Argumentative Zoning scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of generating automatic summarizations of one or more texts is a central problem in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "generating automatic summarizations of one or more texts", "start_pos": 12, "end_pos": 68, "type": "TASK", "confidence": 0.6955420821905136}, {"text": "Natural Language Processing (NLP)", "start_pos": 93, "end_pos": 126, "type": "TASK", "confidence": 0.7280443807442983}]}, {"text": "Summarization is a fundamental component for future information retrieval and question answering systems, incorporating both natural language understanding and natural language generation.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9620181918144226}, {"text": "information retrieval", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.7158751785755157}, {"text": "question answering", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8105892241001129}, {"text": "natural language generation", "start_pos": 160, "end_pos": 187, "type": "TASK", "confidence": 0.6595391233762106}]}, {"text": "Comprehension-based summarization, e.g. and, is the most ambitious model of automatic summarization, requiring a complete understanding of the text.", "labels": [], "entities": [{"text": "Comprehension-based summarization", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6687037944793701}, {"text": "summarization", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.7627851366996765}]}, {"text": "Due to the failure of rule-based NLP and knowledge representation, other less knowledge-intensive methods now dominate.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.7554627060890198}]}, {"text": "Sentence extraction, e.g. and, selects a small number of abstract worthy sentences from a larger text.", "labels": [], "entities": [{"text": "Sentence extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9124694764614105}]}, {"text": "The resulting sentences form a collection of excerpt sentences meant to capture the essence of the text.", "labels": [], "entities": []}, {"text": "The next stage is information fusion () which attempts to combine the excerpts into a more cohesive text.", "labels": [], "entities": [{"text": "information fusion", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.864677906036377}]}, {"text": "These methods can create inflexible and incoherent extracts that result in under-informative results ( ).", "labels": [], "entities": []}, {"text": "Argumentative Zoning) attempts to solve this problem by representing the structure of a text using a rhetorically-based schema.", "labels": [], "entities": [{"text": "Argumentative Zoning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6321482062339783}]}, {"text": "Sentences are classified into one of a small number of nonhierarchical argumentative roles, which can then be used in both the sentence extraction and text generation/fusion phase of automatic summarization.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.7439218163490295}, {"text": "text generation/fusion", "start_pos": 151, "end_pos": 173, "type": "TASK", "confidence": 0.8021049275994301}]}, {"text": "Argumentative Zoning can enable tailored summarizations depending on the needs of the user, e.g. a layperson versus a domain expert.", "labels": [], "entities": [{"text": "Argumentative Zoning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6582569628953934}]}, {"text": "The first experiments in Argumentative Zoning used Na\u00a8\u0131veNa\u00a8\u0131ve Bayes (NB) classifiers () which assume conditional independence of the features.", "labels": [], "entities": [{"text": "Argumentative Zoning", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7512410581111908}]}, {"text": "However, this assumption is rarely true for the kinds of rich feature representations we want to use for most NLP tasks.", "labels": [], "entities": []}, {"text": "Maximum entropy (ME) models have become popular in NLP because they can incorporate evidence from the complex, diverse and overlapping features needed to represent language.", "labels": [], "entities": []}, {"text": "Some example applications include part-of-speech (POS) tagging, parsing), language modelling, and text categorisation ().", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.6214803278446197}, {"text": "language modelling", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7755114138126373}, {"text": "text categorisation", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7572351694107056}]}, {"text": "We have developed an Argumentative Zoning (zone) classifier using a ME model.", "labels": [], "entities": [{"text": "Argumentative Zoning (zone) classifier", "start_pos": 21, "end_pos": 59, "type": "TASK", "confidence": 0.5148432950178782}]}, {"text": "We compare our zone classifier to a reimplementation of's NB classifier and features on their original Computational Linguistics corpus.", "labels": [], "entities": [{"text": "NB classifier", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9121068120002747}, {"text": "Computational Linguistics corpus", "start_pos": 103, "end_pos": 135, "type": "DATASET", "confidence": 0.6153320670127869}]}, {"text": "Like Teufel (1999), we model zone classification as a sequence tagging task.", "labels": [], "entities": [{"text": "zone classification", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7169582843780518}, {"text": "sequence tagging task", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7583406964937845}]}, {"text": "Our zone classifier achieves an F-score of 96.88%, a 20% improvement.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9997186064720154}]}, {"text": "We also show how Argumentative Zoning can be applied to other domains by evaluating our system on a corpus of Astronomy journal articles, achieving an F-measure of 97.9%.", "labels": [], "entities": [{"text": "Argumentative Zoning", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7776578366756439}, {"text": "F-measure", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9995089769363403}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Teufel and Moens (2002)'s and our NB  performance on CMP-LG", "labels": [], "entities": [{"text": "CMP-LG", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.8527445793151855}]}, {"text": " Table 4: History features on the CMP-LG corpus  with ME model of unigram/bigram features only", "labels": [], "entities": [{"text": "CMP-LG corpus", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.8894001543521881}]}, {"text": " Table 5: Subtractive analysis CMP-LG ME model", "labels": [], "entities": [{"text": "Subtractive analysis CMP-LG ME", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8702868968248367}]}, {"text": " Table 7: Final CMP-LG ME performance", "labels": [], "entities": []}, {"text": " Table 8: Subtractive analysis ASTRO ME model", "labels": [], "entities": [{"text": "Subtractive analysis ASTRO ME", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7677289992570877}]}, {"text": " Table 9: Final ASTRO ME model performance", "labels": [], "entities": [{"text": "ASTRO ME", "start_pos": 16, "end_pos": 24, "type": "TASK", "confidence": 0.6341353058815002}]}, {"text": " Table 10: Comparing CMP-LG and ASTRO directly  on the basic annotation scheme", "labels": [], "entities": [{"text": "ASTRO", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.6165475249290466}]}]}