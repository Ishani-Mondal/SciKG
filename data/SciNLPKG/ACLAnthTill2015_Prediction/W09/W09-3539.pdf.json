{"title": [{"text": "Voted NER System using Appropriate Unlabeled Data", "labels": [], "entities": [{"text": "Appropriate", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.9536733627319336}]}], "abstractContent": [{"text": "This paper reports a voted Named Entity Recognition (NER) system with the use of appropriate unlabeled data.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.7685320874055227}]}, {"text": "The proposed method is based on the classifiers such as Maximum En-tropy (ME), Conditional Random Field (CRF) and Support Vector Machine (SVM) and has been tested for Bengali.", "labels": [], "entities": [{"text": "Maximum En-tropy (ME)", "start_pos": 56, "end_pos": 77, "type": "METRIC", "confidence": 0.8444260478019714}]}, {"text": "The system makes use of the language independent features in the form of different contextual and orthographic word level features along with the language dependent features extracted from the Part of Speech (POS) tagger and gazetteers.", "labels": [], "entities": []}, {"text": "Context patterns generated from the unlabeled data using an active learning method have been used as the features in each of the classifiers.", "labels": [], "entities": []}, {"text": "A semi-supervised method has been used to describe the measures to automatically select effective documents and sentences from unla-beled data.", "labels": [], "entities": []}, {"text": "Finally, the models have been combined together into a final system by weighted voting technique.", "labels": [], "entities": []}, {"text": "Experimental results show the effectiveness of the proposed approach with the overall Recall, Precision, and F-Score values of 93.81%, 92.18% and 92.98%, respectively.", "labels": [], "entities": [{"text": "Recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9994736313819885}, {"text": "Precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.990216851234436}, {"text": "F-Score", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.9997443556785583}]}, {"text": "We have shown how the language dependent features can improve the system performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entity Recognition (NER) is an important tool in almost all Natural Language Processing (NLP) application areas.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7682081510623296}]}, {"text": "Machine learning (ML) approaches are more popularly used in NER because these are easily trainable, adoptable to different domains and languages as well as their maintenance are also less expensive.", "labels": [], "entities": [{"text": "Machine learning (ML)", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7987212777137757}, {"text": "NER", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.8813526630401611}]}, {"text": "Some of the very effective ML approaches used in NER are ME), CRF () and SVM ().", "labels": [], "entities": [{"text": "ML", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9746617674827576}, {"text": "NER", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.968569278717041}, {"text": "ME", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9003503322601318}]}, {"text": "In the earlier work (, it has been shown that combination of several ML models yields better performance than any single ML model.", "labels": [], "entities": []}, {"text": "One drawback of the ML techniques to NLP tasks is the requirement of a large amount of annotated data to achieve a reasonable performance.", "labels": [], "entities": [{"text": "ML", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.9754255414009094}]}, {"text": "Indian languages are resource-constrained and the manual preparation of NE annotated data is both time consuming and cost intensive.", "labels": [], "entities": []}, {"text": "It is important to decide how the system should effectively select unlabeled data and how the size and relevance of data impact the performance.", "labels": [], "entities": []}, {"text": "India is a multilingual country with great cultural diversities.", "labels": [], "entities": []}, {"text": "Named Entity (NE) identification in Indian languages in general and Bengali in particular is difficult and challenging as: 1.", "labels": [], "entities": [{"text": "Named Entity (NE) identification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6214401026566824}]}, {"text": "Unlike English and most of the European languages, Bengali lacks capitalization information, which plays a very important role in identifying NEs.", "labels": [], "entities": [{"text": "identifying NEs", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.8014346063137054}]}, {"text": "2. Indian person names are generally found in the dictionary as common nouns with some specific meanings.", "labels": [], "entities": []}, {"text": "For example, kabitA is a person name and can also be found in the dictionary as a common noun with the meaning 'poem'.", "labels": [], "entities": []}, {"text": "3. Bengali is an inflectional language providing one of the richest and most challenging sets of linguistic and statistical features resulting in long and complex wordforms. are not yet available in the required measure.", "labels": [], "entities": []}, {"text": "6. Although Indian languages have a very old and rich literary history, technological developments are of recent origin.", "labels": [], "entities": []}, {"text": "7. Web sources for name lists are available in English, but such lists are not available in Bengali.", "labels": [], "entities": []}, {"text": "This necessitates the use of transliteration for creating such lists.", "labels": [], "entities": []}, {"text": "A HMM based NER system for Bengali has been reported in, where additional contextual information has been considered during emission probabilities and NE suffixes are used for handling the unknown words.", "labels": [], "entities": []}, {"text": "More recently, the works in the area of Bengali NER can be found in, and Ekbal and Bandyopadhyay (2008b) with the CRF, and SVM approach, respectively.", "labels": [], "entities": [{"text": "Bengali NER", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.43569737672805786}]}, {"text": "Other than Bengali, the works on Hindi can be found in with with a hybrid feature set based ME approach.", "labels": [], "entities": []}, {"text": "Various works of NER involving Indian languages are reported in IJCNLP-08 NER Shared Task on South and South East Asian Languages (NERSSEAL) 1 using various techniques.", "labels": [], "entities": [{"text": "NER", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9670360088348389}, {"text": "IJCNLP-08 NER Shared Task on South and South East Asian Languages (NERSSEAL) 1", "start_pos": 64, "end_pos": 142, "type": "DATASET", "confidence": 0.6069844822088878}]}], "datasetContent": [{"text": "Out of 200K wordforms, 150K wordforms along with the IJCNLP-08 shared task data has been used for training the models.", "labels": [], "entities": [{"text": "IJCNLP-08 shared task data", "start_pos": 53, "end_pos": 79, "type": "DATASET", "confidence": 0.8526895344257355}]}, {"text": "Out of 200K wordforms, 50K wordforms have been used as the development data.", "labels": [], "entities": []}, {"text": "The system has been tested with a gold standard test set of 35K wordforms.", "labels": [], "entities": []}, {"text": "Each of the models has been evaluated in two different ways, being guided by language independent features (language independent system denoted as LI) and being guided by language independent as well as language dependent features (language dependent system denoted as LD).", "labels": [], "entities": []}, {"text": "A number of experiments have been carried out in order to identify the best-suited set of language independent features for NER in each of models.", "labels": [], "entities": []}, {"text": "Evaluation results of the development set for the NER models are presented in in terms of percentages of Recall (R), Precision (P) and F-Score (FS).", "labels": [], "entities": [{"text": "NER", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9536800384521484}, {"text": "Recall (R)", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9652315378189087}, {"text": "Precision (P)", "start_pos": 117, "end_pos": 130, "type": "METRIC", "confidence": 0.9577100425958633}, {"text": "F-Score (FS)", "start_pos": 135, "end_pos": 147, "type": "METRIC", "confidence": 0.9630374610424042}]}, {"text": "The ME based system has demonstrated the F-Score value of 74.67% for the context word window of size three, i.e., previous one word, current word and the next word, prefixes and suffixes of length up to three characters of only the current word, dynamic NE tag of the previous word, first word, infrequent word, length and the various digit features.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9983298182487488}, {"text": "length", "start_pos": 312, "end_pos": 318, "type": "METRIC", "confidence": 0.9635135531425476}]}, {"text": "The CRF based system yielded the highest F-Score value of 76.97% for context window of size five, i.e., two preceding, current and two succeeding words along with the other set of features as in the ME model.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9981871247291565}]}, {"text": "Both the SVM based systems have demonstrated the best performance for the context window of size seven, i.e., three preceding, current and two succeeding words, dynamic NE information of the previous two words along with the other set of features as in the ME and CRF based systems.", "labels": [], "entities": []}, {"text": "In SVM models, we have conducted experiments with the different polynomial kernel functions and observed the highest FScore value with degree 2.", "labels": [], "entities": [{"text": "FScore", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9933752417564392}]}, {"text": "It has been also observed that pairwise multiclass decision method performs better than the one vs rest method.", "labels": [], "entities": []}, {"text": "For all the models, context words and prefixes and/or suffixes have been found to be the most effective features..", "labels": [], "entities": []}, {"text": "Results on the development set for the language independent supervised models  Evaluation results of the systems that include the POS information and other language dependent features are presented in the.", "labels": [], "entities": []}, {"text": "During the experiments, it has been observed that all the language dependent features are not equally important.", "labels": [], "entities": []}, {"text": "POS information is the most effective followed by NE suffixes, person prefix words, designations, organization clue words and location clue words.", "labels": [], "entities": []}, {"text": "show that the language dependent features can improve the overall performance of the systems significantly..", "labels": [], "entities": []}, {"text": "Results on the development set for the language dependent supervised models", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Results on the development set for  the language independent supervised models", "labels": [], "entities": []}, {"text": " Table 2. Results on the development set for the  language dependent supervised models", "labels": [], "entities": []}, {"text": " Table 3. Clearly, it is  evident from the results of", "labels": [], "entities": []}, {"text": " Table 3. Results on the development set by in- cluding context features", "labels": [], "entities": []}, {"text": " Table 4. Results on the test set", "labels": [], "entities": []}, {"text": " Table 6. Results of the 10-fold cross validation  tests  Statistical ANOVA tests (Anderson", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.8803104162216187}, {"text": "Anderson", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8251595497131348}]}, {"text": " Table 7. After selection of the appropriate  unlabeled data, all the models have been  retrained by including the unlabeled documents.  Results have been presented in", "labels": [], "entities": []}, {"text": " Table 7. Incremental improvement of perform- ance", "labels": [], "entities": [{"text": "Incremental", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9239861965179443}, {"text": "perform- ance", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9288288752237955}]}, {"text": " Table 8. Results after unlabeled data selection", "labels": [], "entities": []}, {"text": " Table 9. Results of the voted system", "labels": [], "entities": []}]}