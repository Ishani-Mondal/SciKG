{"title": [{"text": "MATREX: The DCU MT System for WMT 2009", "labels": [], "entities": [{"text": "MATREX", "start_pos": 0, "end_pos": 6, "type": "TASK", "confidence": 0.8236510157585144}, {"text": "WMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8457910418510437}]}], "abstractContent": [{"text": "In this paper, we describe the machine translation system in the evaluation campaign of the Fourth Workshop on Statistical Machine Translation at EACL 2009.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.808931976556778}, {"text": "Statistical Machine Translation at EACL 2009", "start_pos": 111, "end_pos": 155, "type": "TASK", "confidence": 0.7087733199199041}]}, {"text": "We describe the modular design of our multi-engine MT system with particular focus on the components used in this participation.", "labels": [], "entities": [{"text": "MT", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9194749593734741}]}, {"text": "We participated in the translation task for the following translation directions: French-English and English-French, in which we employed our multi-engine architecture to translate.", "labels": [], "entities": [{"text": "translation task", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.9016668200492859}]}, {"text": "We also participated in the system combination task which was carried out by the MBR de-coder and Confusion Network decoder.", "labels": [], "entities": [{"text": "MBR de-coder", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.9560177624225616}]}, {"text": "We report results on the provided development and test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we present a multi-engine MT system developed at DCU, MATREX (Machine Translation using Examples).", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9705902934074402}, {"text": "Machine Translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7479782104492188}]}, {"text": "This system exploits EBMT, SMT and system combination techniques to build a cascaded translation framework.", "labels": [], "entities": [{"text": "SMT", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9760273098945618}]}, {"text": "We participated in both the French-English and English-French News tasks.", "labels": [], "entities": []}, {"text": "In these two tasks, we employ three individual MT system which are 1) Baseline: phrase-based system (PB); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker ().", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9710082411766052}]}, {"text": "3) HPB: atypical hierarchical phrase-based system.", "labels": [], "entities": []}, {"text": "Meanwhile, we also use a word-level combination framework ( to combine the multiple translation hypotheses and employ anew rescoring model to generate the final result.", "labels": [], "entities": []}, {"text": "For the system combination task, we first use the minimum Bayes-risk (MBR) () decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) ().", "labels": [], "entities": [{"text": "minimum Bayes-risk (MBR)", "start_pos": 50, "end_pos": 74, "type": "METRIC", "confidence": 0.7818543791770936}]}, {"text": "We then build the CN using the TER metric), and finally search and generate the translation.", "labels": [], "entities": [{"text": "TER", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9671674370765686}]}, {"text": "The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task.", "labels": [], "entities": []}, {"text": "In Section 3, we outline the complete system setup for the shared task and provide results on the development and test sets.", "labels": [], "entities": []}, {"text": "Section 4 is our conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The following section describes the system and experimental setup for the French-English and English-French translation tasks.", "labels": [], "entities": []}, {"text": "The system output is evaluated with respect to BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9684100151062012}]}, {"text": "In, we used devset2009-b to tune the various parameters in our three single systems and devset2009-a for testing.", "labels": [], "entities": []}, {"text": "In terms of the Europarl data, we can see that the three systems we used achieved similar performance on the test set for both translation directions, with the Baseline-E system yielding slightly better results than the other two.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 16, "end_pos": 29, "type": "DATASET", "confidence": 0.9916132092475891}]}], "tableCaptions": [{"text": " Table 1: Statistics of Parallel Data", "labels": [], "entities": []}, {"text": " Table 2. We  configured these two LMs for Baseline and EBMT  systems while HPB only used the large one.", "labels": [], "entities": [{"text": "HPB", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.9706711173057556}]}, {"text": " Table 2: Statistics of Monolingual Data", "labels": [], "entities": []}, {"text": " Table 3: Statistics of MT Systems", "labels": [], "entities": [{"text": "MT", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.943070650100708}]}, {"text": " Table 4: Experimental Results on Devset2009-a", "labels": [], "entities": [{"text": "Devset2009-a", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.5581308007240295}]}]}