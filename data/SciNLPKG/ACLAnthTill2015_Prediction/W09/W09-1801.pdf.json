{"title": [{"text": "Summarization with a Joint Model for Sentence Extraction and Compression", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9757956862449646}, {"text": "Sentence Extraction", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.9459626376628876}]}], "abstractContent": [{"text": "Text summarization is one of the oldest problems in natural language processing.", "labels": [], "entities": [{"text": "Text summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7892629206180573}, {"text": "natural language processing", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.6418546338876089}]}, {"text": "Popular approaches rely on extracting relevant sentences from the original documents.", "labels": [], "entities": []}, {"text": "As aside effect, sentences that are too long but partly relevant are doomed to either not appear in the final summary, or prevent inclusion of other relevant sentences.", "labels": [], "entities": []}, {"text": "Sentence compression is a recent framework that aims to select the shortest subsequence of words that yields an informative and grammatical sentence.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9142237603664398}]}, {"text": "This work proposes a one-step approach for document summarization that jointly performs sentence extraction and compression by solving an integer linear program.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7565916478633881}, {"text": "sentence extraction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7547049522399902}]}, {"text": "We report favorable experimental results on newswire data.", "labels": [], "entities": [{"text": "newswire data", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.9216409921646118}]}], "introductionContent": [{"text": "Automatic text summarization dates back to the 1950s and 1960s.", "labels": [], "entities": [{"text": "Automatic text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5863918960094452}]}, {"text": "Today, the proliferation of digital information makes research on summarization technologies more important than ever before.", "labels": [], "entities": [{"text": "summarization", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.9910560846328735}]}, {"text": "In the last two decades, machine learning techniques have been employed in extractive summarization of single documents () and multiple documents).", "labels": [], "entities": [{"text": "extractive summarization of single documents", "start_pos": 75, "end_pos": 119, "type": "TASK", "confidence": 0.8423651695251465}]}, {"text": "Most of this work aims only to extract relevant sentences from the original documents and present them as the summary; this simplification of the problem yields scalable solutions.", "labels": [], "entities": []}, {"text": "Some attention has been devoted by the NLP community to the related problem of sentence compression): given along sentence, how to maximally compress it into a grammatical sentence that still preserves all the relevant information?", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.7226430624723434}]}, {"text": "While sentence compression is a promising framework with applications, for example, in headline generation (, little work has been done to include it as a module in document summarization systems.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 6, "end_pos": 26, "type": "TASK", "confidence": 0.8428595662117004}, {"text": "headline generation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.804986834526062}, {"text": "document summarization", "start_pos": 165, "end_pos": 187, "type": "TASK", "confidence": 0.6616464853286743}]}, {"text": "Most existing approaches (with some exceptions, like the vine-growth model of) use a two-stage architecture, either by first extracting a certain number of salient sentences and then feeding them into a sentence compressor, or by first compressing all sentences and extracting later.", "labels": [], "entities": []}, {"text": "However, regardless of which operation is performed first-compression or extraction-two-step \"pipeline\" approaches may fail to find overall-optimal solutions; often the summaries are not better that the ones produced by extractive summarization.", "labels": [], "entities": []}, {"text": "On the other hand, a pilot study carried out by suggests that summarization systems that perform sentence compression have the potential to beat pure extractive systems if they model cross-sentence effects.", "labels": [], "entities": [{"text": "summarization", "start_pos": 62, "end_pos": 75, "type": "TASK", "confidence": 0.9758201837539673}, {"text": "sentence compression", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.7203423827886581}]}, {"text": "In this work, we address this issue by merging the tasks of sentence extraction and sentence compression into a global optimization problem.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7616650462150574}, {"text": "sentence compression", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7368744909763336}]}, {"text": "A careful design of the objective function encourages \"sparse solutions,\" i.e., solutions that involve only a small number of sentences whose compressions are to be included in the summary.", "labels": [], "entities": []}, {"text": "Our contributions are: \u2022 We cast joint sentence extraction and compression as an integer linear program (ILP); \u2022 We provide anew formulation of sentence compression using dependency parsing information that only requires a linear number of variables, and combine it with a bigram model; \u2022 We show how the full model can be trained in a max-margin framework.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7230860590934753}, {"text": "sentence compression", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.7265637814998627}, {"text": "dependency parsing information", "start_pos": 171, "end_pos": 201, "type": "TASK", "confidence": 0.7783175309499105}]}, {"text": "Since a dataset of summaries comprised of extracted, compressed sentences is unavailable, we present a procedure that trains the compression and extraction models separately and tunes a parameter to interpolate the 1 two models.", "labels": [], "entities": []}, {"text": "The compression model and the full system are compared with state-of-the-art baselines in standard newswire datasets.", "labels": [], "entities": [{"text": "newswire datasets", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.812870979309082}]}, {"text": "This paper is organized as follows: \u00a72-3 provide an overview of our two building blocks, sentence extraction and sentence compression.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.7913593053817749}, {"text": "sentence compression", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.7478076219558716}]}, {"text": "\u00a74 describes our method to perform one-step sentence compression and extraction.", "labels": [], "entities": [{"text": "sentence compression and extraction", "start_pos": 44, "end_pos": 79, "type": "TASK", "confidence": 0.7218212857842445}]}, {"text": "\u00a75 shows experiments in newswire data.", "labels": [], "entities": []}, {"text": "Finally, \u00a76 concludes the paper and suggests future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments, two datasets were used: The DUC 2002 dataset.", "labels": [], "entities": [{"text": "DUC 2002 dataset", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.9836741089820862}]}, {"text": "This is a collection of newswire articles, comprised of 59 document clusters.", "labels": [], "entities": []}, {"text": "Each document within the collections (out of a total of 567 documents) has one or two manually created abstracts with approximately 100 words.", "labels": [], "entities": []}, {"text": "5 Clarke's dataset for sentence compression.", "labels": [], "entities": [{"text": "Clarke's dataset", "start_pos": 2, "end_pos": 18, "type": "DATASET", "confidence": 0.9413849115371704}, {"text": "sentence compression", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7879071533679962}]}, {"text": "This is the dataset used by.", "labels": [], "entities": []}, {"text": "It contains manually created compressions of 82 newspaper articles (1,433 sentences) from the British National Corpus and the American News Text corpus.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 94, "end_pos": 117, "type": "DATASET", "confidence": 0.9470261931419373}, {"text": "American News Text corpus", "start_pos": 126, "end_pos": 151, "type": "DATASET", "confidence": 0.935965359210968}]}, {"text": "The compression ratio associated with the reference compressed sentences in this dataset is 69.06%.", "labels": [], "entities": []}, {"text": "In the rightmost column, the statistically indistinguishable best results are emboldened, based on a paired t-test applied to the sequence of F 1 measures (p < 0.01).", "labels": [], "entities": [{"text": "F 1 measures", "start_pos": 142, "end_pos": 154, "type": "METRIC", "confidence": 0.9260859886805216}]}, {"text": "sentences, calculated on unigrams.", "labels": [], "entities": []}, {"text": "To evaluate the full system, we used Rouge-N (), a popular n-gram recallbased automatic evaluation measure.", "labels": [], "entities": [{"text": "recallbased", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.9382237792015076}]}, {"text": "This score compares the summary produced by a system with one or more valid reference summaries.", "labels": [], "entities": []}, {"text": "All our experiments were conducted on a PC with a Intel dual-core processor with 2.66 GHz and 2 Gb RAM memory.", "labels": [], "entities": [{"text": "RAM", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9627771377563477}]}, {"text": "We used ILOG CPLEX, a commercial integer programming solver.", "labels": [], "entities": [{"text": "ILOG CPLEX", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.893857330083847}, {"text": "integer programming solver", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.646973043680191}]}, {"text": "The interface with CPLEX was coded in Java.", "labels": [], "entities": [{"text": "CPLEX", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.8930907249450684}]}], "tableCaptions": [{"text": " Table 1: Results for sentence compression in the Clarke's test dataset (441 sentences) for our implementation of the  baseline systems (HedgeTrimmer and the system described in", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.7302073091268539}, {"text": "Clarke's test dataset", "start_pos": 50, "end_pos": 71, "type": "DATASET", "confidence": 0.9402448534965515}, {"text": "HedgeTrimmer", "start_pos": 137, "end_pos": 149, "type": "DATASET", "confidence": 0.9211118221282959}]}, {"text": " Table 2: Results for sentence extraction in the DUC2002  dataset (140 documents). Bold indicates the best results  with statistical significance, according to a paired t-test  (p < 0.01); Rouge-2 scores of all systems except Pipeline  are indistinguishable according to the same test, with p >  0.05.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7925347685813904}, {"text": "DUC2002  dataset", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.9846496284008026}]}]}