{"title": [], "abstractContent": [{"text": "In this paper we present our experiments with active learning to improve the performance of our probabilistic anaphora resolution system.", "labels": [], "entities": [{"text": "probabilistic anaphora resolution", "start_pos": 96, "end_pos": 129, "type": "TASK", "confidence": 0.6757594048976898}]}, {"text": "We have adopted entropy-based uncertainty measures to select new instances to be added to our training data.", "labels": [], "entities": []}, {"text": "The actively selected instances, however, were not more successful in improving the performance of the system than the same amount of randomly selected instances.", "labels": [], "entities": []}, {"text": "The uncertainty measures we used behave differently from each other when selecting new instances, but none of them achieved remarkable performance.", "labels": [], "entities": []}, {"text": "Further studies on active sample selection for anaphora resolution are necessary.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7799349725246429}]}], "introductionContent": [{"text": "Anaphora is the relation between two linguistic expressions in the discourse where the reader is referred back to the first of them when reading the second later in the text.", "labels": [], "entities": []}, {"text": "Anaphora resolution can be understood as the process of identifying an anaphoric relation between two expressions in the text and consequently linking the two of them, one being the anaphor and the other being the antecedent.", "labels": [], "entities": [{"text": "Anaphora resolution", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8055934607982635}]}, {"text": "Manually annotating corpora with anaphoric links in order to use it as training or test data fora corpus-based anaphora resolution system is a particulary difficult and time consuming task, given the complex nature of the phenomenon.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.8008259236812592}]}, {"text": "We have developed a probabilistic model for resolution of non-pronominal anaphora and aim to improve its performance by acquiring incrementally and selectively more training data using active learning.", "labels": [], "entities": [{"text": "resolution of non-pronominal anaphora", "start_pos": 44, "end_pos": 81, "type": "TASK", "confidence": 0.8499992787837982}]}, {"text": "We have adopted an uncertainty-based active learning approach in order to do that, and it uses our probabilistic model as the base classifier.", "labels": [], "entities": []}, {"text": "The uncertainty-based approach has been applied to, for instance, named-entity recognition by who report at least 80% reduction in annotation costs, parsing by who reports 67% savings, and parse selection by who report 60% savings.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.7643865942955017}, {"text": "parsing", "start_pos": 149, "end_pos": 156, "type": "TASK", "confidence": 0.9834995269775391}, {"text": "parse selection", "start_pos": 189, "end_pos": 204, "type": "TASK", "confidence": 0.9818065464496613}]}, {"text": "We are not aware of any work that has applied active learning to anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7846485376358032}]}, {"text": "For calculating the uncertainty of an anaphora resolution model, we feel the need to combine the information about the confindence of the model for the classification of each antecedent candidate associated to a given anaphor.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7396964579820633}]}, {"text": "We have tested three entropy-based uncertainty measures in order to select the instances to be added to the training data.", "labels": [], "entities": []}, {"text": "Our training corpus is composed of five fulllength scientific articles from the biomedical domain.", "labels": [], "entities": []}, {"text": "We have used this corpus to simulate active learning: we have divided our training data into two parts, one for the initial training and the other for active learning (simulating unlabelled data), and have compared the classifier performance when trained on a sample selected by active learning to its performance when trained on the same amount of randomly selected instances.", "labels": [], "entities": []}, {"text": "In the next section we describe our probabilistic model for anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7954893410205841}]}, {"text": "In Section 3 we detail our training corpus.", "labels": [], "entities": []}, {"text": "we describe the strategy we have adopted to select the samples to take part in the active learning, and in Section 5 1 we describe our experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "Initially, our training data was divided in 10-folds for cross-validation evaluation of our probabilistic model for anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7833258807659149}]}, {"text": "For the active learning experiments we kept the same folds, using one for the initial training, eight for the active learning phase, and the remaining one for testing.", "labels": [], "entities": []}, {"text": "We have experimented with 10 different initialtraining/active-learning/testing splits, selected randomly from all combinations of the 10 folds, and the results in this section correspond to the average of the results from the different data splits.", "labels": [], "entities": []}, {"text": "A fold contains the positive and negative samples derived from about 270 anaphors, it contains about 7000 candidate-anaphor pairs (an average of about 26 antecedent candidates per anaphor).", "labels": [], "entities": []}, {"text": "The anaphors that are part of each fold were randomly selected.", "labels": [], "entities": []}, {"text": "The purpose of our experiments is to check whether the samples selected by using the entropybased measures described above, when added to our training data, can improve the performance of the model more than in the case of adding the same amount of randomly selected samples.", "labels": [], "entities": []}, {"text": "For that, we computed (1) the performance of our model using one fold of training data, (2) the performance of the model over 10 iterations of active learning using each of the uncertainty measures above, and (3) the performance of the model over 10 iterations adding the same amount of randomly selected instances as for active learning.", "labels": [], "entities": []}, {"text": "At each active learning iteration, when using LE(A, a) we selected the 1500 candidate-anaphor pairs for which uncertainty was the highest, and when using GE1(A) and GE2(A) we selected the 50 anaphors for which the model was most uncertain and generated the positive and negative instances that were associated to the anaphors.", "labels": [], "entities": []}, {"text": "We expected (2), entropy-based sample selection, to achieve better performance than (3), random sample selection, however this has not happened.", "labels": [], "entities": [{"text": "entropy-based sample selection", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.616735190153122}]}, {"text": "The graphs in compare the precision, recall and F-measure scores for and along the 10 iterations for each class of anaphoric relation.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9995892643928528}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9976316690444946}, {"text": "F-measure", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9878756999969482}]}, {"text": "The lines corresponding to random sampling plot the results of the experiments done in the same way as for GE1(A) and GE2(A), that is, where 50 anaphors are selected at each iteration, although we also tested random sampling in the LE(A, a) fashion, selecting 1500 candidate-anaphor pairs.", "labels": [], "entities": []}, {"text": "We observe that none of the uncertainty measures that we tested have performed consistently better than random sampling.", "labels": [], "entities": []}, {"text": "LE(A, a) presents the most dramatic results, it worsens the general performance of the model for all classes, although it causes a considerable increase in precision for coreferent and set-member cases.", "labels": [], "entities": [{"text": "LE", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.944341242313385}, {"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9990861415863037}]}, {"text": "GE1(A) and GE2(A) have a less clear pattern, but it is possible to notice that GE1(A) tends to bring improvements in precision while GE2(A) causes the opposite, improvements in recall and drops in precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9989839196205139}, {"text": "recall", "start_pos": 177, "end_pos": 183, "type": "METRIC", "confidence": 0.9994943141937256}, {"text": "precision", "start_pos": 197, "end_pos": 206, "type": "METRIC", "confidence": 0.9983054399490356}]}], "tableCaptions": [{"text": " Table 3: Training instances, according to anaphoric class", "labels": [], "entities": []}, {"text": " Table 4: Performance of the probabilistic model", "labels": [], "entities": []}]}