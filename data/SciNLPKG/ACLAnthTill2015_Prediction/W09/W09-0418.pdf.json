{"title": [{"text": "NICT@WMT09: Model Adaptation and Transliteration for Spanish-English SMT", "labels": [], "entities": [{"text": "NICT@WMT09", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8425779342651367}, {"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.6904692053794861}]}], "abstractContent": [{"text": "This paper describes the NICT statistical machine translation (SMT) system used for the WMT 2009 Shared Task (WMT09) evaluation.", "labels": [], "entities": [{"text": "NICT statistical machine translation (SMT)", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.7248851997511727}, {"text": "WMT 2009 Shared Task (WMT09) evaluation", "start_pos": 88, "end_pos": 127, "type": "TASK", "confidence": 0.5628147199749947}]}, {"text": "We participated in the Spanish-English translation task.", "labels": [], "entities": [{"text": "Spanish-English translation task", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.756962239742279}]}, {"text": "The focus of this year's participation was to investigate model adaptation and transliter-ation techniques in order to improve the translation quality of the baseline phrase-based SMT system.", "labels": [], "entities": [{"text": "model adaptation", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.734157919883728}, {"text": "SMT", "start_pos": 180, "end_pos": 183, "type": "TASK", "confidence": 0.8659968376159668}]}], "introductionContent": [{"text": "This paper describes the NICT statistical machine translation (SMT) system used for the shared task of the Fourth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "NICT statistical machine translation (SMT)", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.7269841730594635}, {"text": "Statistical Machine Translation", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.6549614369869232}]}, {"text": "We participated in the SpanishEnglish translation task under the Constrained Condition.", "labels": [], "entities": [{"text": "SpanishEnglish translation task", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.7943368951479594}]}, {"text": "For the training of the SMT engines, we used two parallel Spanish-English corpora provided by the organizers: the Europarl (EP) corpus (, which consists of 1.4M parallel sentences extracted from the proceedings of the European Parliament, and the News Commentary (NC) corpus, which consists of 74K parallel sentences taken from major news outlets like BBC, Der Spiegel, and Le Monde.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.992921769618988}, {"text": "Europarl (EP) corpus", "start_pos": 114, "end_pos": 134, "type": "DATASET", "confidence": 0.8947256565093994}]}, {"text": "In order to adapt SMT systems to a specific domain, recent research focuses on model adaptation techniques that adjust their parameters based on information about the evaluation domain).", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9934137463569641}]}, {"text": "Statistical models can be trained on in-domain and out-of-domain data sets and combined at run-time using probabilistic weighting between domain-specific statistical models.", "labels": [], "entities": []}, {"text": "As the official WMT09 evaluation testset consists of documents taken from the news domain, we applied statistical model adaptation techniques to combine translation models (tm), language models (lm) and distortion models (dm) trained on (a) the in-domain NC corpus and (b) the out-of-domain EP corpus (cf. Section 2).", "labels": [], "entities": [{"text": "WMT09 evaluation testset", "start_pos": 16, "end_pos": 40, "type": "DATASET", "confidence": 0.7815979719161987}, {"text": "NC corpus", "start_pos": 255, "end_pos": 264, "type": "DATASET", "confidence": 0.8762760162353516}, {"text": "EP corpus", "start_pos": 291, "end_pos": 300, "type": "DATASET", "confidence": 0.7969792783260345}]}, {"text": "One major problem in the given translation task was the large amount of out-of-vocabulary (OOV) words, i.e., source language words that do not occur in the training corpus.", "labels": [], "entities": [{"text": "translation task", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.9011145830154419}]}, {"text": "For unknown words, no translation entry is available in the statistical translation model (phrase.", "labels": [], "entities": []}, {"text": "As a result, these OOV words cannot be translated.", "labels": [], "entities": []}, {"text": "Dealing with languages with a rich morphology like Spanish and having a limited amount of bilingual resources make this problem even more severe.", "labels": [], "entities": []}, {"text": "There have been several efforts in dealing with OOV words to improve translation quality.", "labels": [], "entities": []}, {"text": "In addition to parallel text corpora, external bilingual dictionaries can be exploited to reduce the OOV problem (.", "labels": [], "entities": [{"text": "OOV", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.8221867680549622}]}, {"text": "However, these approaches depend on the coverage of the utilized external dictionaries.", "labels": [], "entities": []}, {"text": "Data sparseness problems due to inflectional variations were previously addressed by applying word transformations using stemming or lemmatization ().", "labels": [], "entities": []}, {"text": "A tight integration of morphosyntactic information into the translation model was proposed by) where lemma and morphological information are translated separately, and this information is combined on the output side to generate the translation.", "labels": [], "entities": []}, {"text": "However, these approaches still suffer from the data sparseness problem, since lemmata and inflectional forms never seen in the training corpus cannot be translated.", "labels": [], "entities": []}, {"text": "In order to generate translations for unknown words, previous approaches focused on transliteration methods, where a sequence of characters is mapped from one writing system into another.", "labels": [], "entities": []}, {"text": "For example, in order to translate names and technical terms,) introduced a probabilistic model that replaces Japanese katakana 1 words with phonetically equivalent English words.", "labels": [], "entities": [{"text": "translate names and technical terms", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.8361310720443725}]}, {"text": "More recently,) proposed a transliteration method that is based directly on techniques developed for phrasebased SMT, and transforms a character sequence from one language into another in a subwordlevel, character-based manner.", "labels": [], "entities": [{"text": "phrasebased SMT", "start_pos": 101, "end_pos": 116, "type": "TASK", "confidence": 0.5490388423204422}]}, {"text": "We extend this approach by exploiting the phrase-table of the baseline SMT system to train a phrase-based transliteration model that generates English translations of Spanish OOV words as described in Section 3.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9506708979606628}]}, {"text": "The effects of the proposed techniques are investigated in detail in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The effects of model adaptation and transliteration techniques were evaluated using the SpanishEnglish language resources summarized in Table 1.", "labels": [], "entities": [{"text": "SpanishEnglish language resources", "start_pos": 88, "end_pos": 121, "type": "DATASET", "confidence": 0.9311008453369141}]}, {"text": "In addition, the characteristics of this year's testset are given in.", "labels": [], "entities": []}, {"text": "The sentence length is given as the average number of words per sentence.", "labels": [], "entities": []}, {"text": "The OOV word figures give the percentage of words in the evaluation data set that do not appear in the NC/EP training data.", "labels": [], "entities": [{"text": "OOV", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8994074463844299}, {"text": "evaluation data set", "start_pos": 57, "end_pos": 76, "type": "DATASET", "confidence": 0.7906718452771505}, {"text": "NC/EP training data", "start_pos": 103, "end_pos": 122, "type": "DATASET", "confidence": 0.9214252948760986}]}, {"text": "In order to get an idea how difficult the translation task maybe, we also calculated the language perplexity of the respective evaluation data sets according to 5-gram target language models trained on the NC/EP data sets.", "labels": [], "entities": [{"text": "translation", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.9751107692718506}, {"text": "NC/EP data sets", "start_pos": 206, "end_pos": 221, "type": "DATASET", "confidence": 0.9573463559150696}]}, {"text": "Concerning the development sets, the newsdev2009 data taken from the same news sources as the evaluation set of the shared task was used for the tuning of the SMT engines, and the devtest2006 data taken from the EP corpus was used for system parameter optimization.", "labels": [], "entities": [{"text": "newsdev2009 data", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.9078328907489777}, {"text": "SMT", "start_pos": 159, "end_pos": 162, "type": "TASK", "confidence": 0.9783766269683838}, {"text": "EP corpus", "start_pos": 212, "end_pos": 221, "type": "DATASET", "confidence": 0.9033622443675995}, {"text": "system parameter optimization", "start_pos": 235, "end_pos": 264, "type": "TASK", "confidence": 0.7633880774180094}]}, {"text": "For the evaluation of the proposed methods, we used the testsets of the Second Workshop on SMT (nc-test2007 for NC and test2007 for EP).", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.96499103307724}]}, {"text": "All data sets were casesensitive with punctuation marks tokenized.", "labels": [], "entities": []}, {"text": "The numbers in indicate that the characteristics of this year's testset differ largely from testsets of previous evaluation campaigns.", "labels": [], "entities": []}, {"text": "The NC devset (2,438/1,378 OOVs) contains twice as many untranslatable Spanish words as the NC evalset (1,168/73 OOVs) and the EP devset (912/63 OOVs).", "labels": [], "entities": []}, {"text": "In addition, the high language perplexity figures for this year's testset show that the translation quality output for both baseline systems is expected to be much lower than those for the EP evaluation data sets.", "labels": [], "entities": [{"text": "EP evaluation data sets", "start_pos": 189, "end_pos": 212, "type": "DATASET", "confidence": 0.7107049450278282}]}, {"text": "In this paper, translation quality is evaluated according to (1) the BLEU metrics which calculates the geometric mean of ngram precision by the system output with respect to reference translations (), and (2) the METEOR metrics that calculates unigram overlaps between translations (Banerjee and).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9971941709518433}, {"text": "ngram precision", "start_pos": 121, "end_pos": 136, "type": "METRIC", "confidence": 0.6500438749790192}, {"text": "METEOR", "start_pos": 213, "end_pos": 219, "type": "METRIC", "confidence": 0.9442076683044434}]}, {"text": "Scores of both metrics range between 0 (worst) and 1 (best) and are displayed in percent figures.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Effects of Model Adaptation", "labels": [], "entities": []}, {"text": " Table 6: Effects of Transliteration", "labels": [], "entities": [{"text": "Transliteration", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.6322463750839233}]}, {"text": " Table 7: Testset 2009 Performance", "labels": [], "entities": [{"text": "Testset 2009", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.9753723740577698}]}]}