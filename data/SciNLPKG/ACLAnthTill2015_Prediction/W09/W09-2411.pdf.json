{"title": [{"text": "SemEval-2010 Task 1: Coreference Resolution in Multiple Languages", "labels": [], "entities": [{"text": "SemEval-2010 Task", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.848513275384903}, {"text": "Coreference Resolution", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.9745443165302277}]}], "abstractContent": [{"text": "This paper presents the task 'Coreference Resolution in Multiple Languages' to be run in SemEval-2010 (5th International Workshop on Semantic Evaluations).", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.9409832954406738}, {"text": "SemEval-2010 (5th International Workshop on Semantic Evaluations)", "start_pos": 89, "end_pos": 154, "type": "TASK", "confidence": 0.7660675512419807}]}, {"text": "This task aims to evaluate and compare automatic coreference resolution systems for three different languages (Catalan, English, and Spanish) by means of two alternative evaluation metrics, thus providing an insight into (i) the portabil-ity of coreference resolution systems across languages, and (ii) the effect of different scoring metrics on ranking the output of the participant systems.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.8578515946865082}, {"text": "coreference resolution", "start_pos": 245, "end_pos": 267, "type": "TASK", "confidence": 0.8822808861732483}]}], "introductionContent": [{"text": "Coreference information has been shown to be beneficial in many NLP applications such as Information Extraction, Text Summarization (, Question Answering, and Machine Translation.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.8056823909282684}, {"text": "Text Summarization", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.8492904901504517}, {"text": "Question Answering", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.8430156111717224}, {"text": "Machine Translation", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.8651194274425507}]}, {"text": "In these systems, there is a need to identify the different pieces of information that refer to the same discourse entity in order to produce coherent and fluent summaries, disambiguate the references to an entity, and solve anaphoric pronouns.", "labels": [], "entities": []}, {"text": "Coreference is an inherently complex phenomenon.", "labels": [], "entities": []}, {"text": "Some of the limitations of the traditional rulebased approaches could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.", "labels": [], "entities": []}, {"text": "This task will promote the development of linguistic resources -annotated corpora 1 -and machine-learning techniques oriented to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.9515618085861206}]}, {"text": "In particular, we aim to evaluate and compare coreference resolution systems in a multilingual context, including Catalan, English, and Spanish languages, and by means of two different evaluation metrics.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.9200003445148468}]}, {"text": "By setting up a multilingual scenario, we can explore to what extent it is possible to implement a general system that is portable to the three languages, how much language-specific tuning is necessary, and the significant differences between Romance languages and English, as well as those between two closely related languages such as Spanish and Catalan.", "labels": [], "entities": []}, {"text": "Besides, we expect to gain some useful insight into the development of multilingual NLP applications.", "labels": [], "entities": []}, {"text": "As far as the evaluation is concerned, by employing B-cubed ( and CEAF () algorithms we can consider both the advantages and drawbacks of using one or the other scoring metric.", "labels": [], "entities": [{"text": "B-cubed", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9533953070640564}, {"text": "CEAF", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.8709383010864258}]}, {"text": "For comparison purposes, the MUC score will also be reported.", "labels": [], "entities": [{"text": "MUC score", "start_pos": 29, "end_pos": 38, "type": "DATASET", "confidence": 0.5383273661136627}]}, {"text": "Among others, we are interested in the following questions: Which evaluation metric provides a more accurate picture of the accuracy of the system performance?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9965481162071228}]}, {"text": "Is there a strong correlation between them?", "labels": [], "entities": []}, {"text": "Can statistical systems be optimized under both metrics at the same time?", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the overall task.", "labels": [], "entities": []}, {"text": "The corpora and the annotation scheme are presented in Section 3.", "labels": [], "entities": []}, {"text": "Conclusions and final remarks are given in Section 4.", "labels": [], "entities": [{"text": "Conclusions", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9658850431442261}]}], "datasetContent": [], "tableCaptions": []}