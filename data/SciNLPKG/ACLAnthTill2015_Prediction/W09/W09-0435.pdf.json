{"title": [{"text": "A POS-Based Model for Long-Range Reorderings in SMT", "labels": [], "entities": [{"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8911184668540955}]}], "abstractContent": [{"text": "In this paper we describe anew approach to model long-range word reorderings in statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.7831966082255045}]}, {"text": "Until now, most SMT approaches are only able to model local reorderings.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9932767152786255}]}, {"text": "But even the word order of related languages like German and English can be very different.", "labels": [], "entities": []}, {"text": "In recent years approaches that reorder the source sentence in a preprocessing step to better match target sentences according to POS(Part-of-Speech)-based rules have been applied successfully.", "labels": [], "entities": []}, {"text": "We enhance this approach to model long-range reorder-ings by introducing discontinuous rules.", "labels": [], "entities": []}, {"text": "We tested this new approach on a German-English translation task and could significantly improve the translation quality, by up to 0.8 BLEU points, compared to a system which already uses continuous POS-based rules to model short-range reorder-ings.", "labels": [], "entities": [{"text": "German-English translation task", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6611780822277069}, {"text": "BLEU", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.9993376135826111}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) is currently the most promising approach to machine translation of large vocabulary tasks.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8578502734502157}, {"text": "machine translation of large vocabulary tasks", "start_pos": 82, "end_pos": 127, "type": "TASK", "confidence": 0.8501768459876379}]}, {"text": "The approach was first presented by and has since been used in many translation systems (,,), ( . Stateof-the-art SMT systems often use translation models based on phrases to describe translation correspondences and word reordering between two languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.7857548594474792}]}, {"text": "The reordering of words is one of the main difficulties in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7770085036754608}]}, {"text": "Phrase-based translation models by themselves have only limited capability to model different word orders in the source and target language, by capturing local reorderings within phrase pairs.", "labels": [], "entities": [{"text": "Phrase-based translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8725093901157379}]}, {"text": "In addition, the decoder can reorder phrases, subject to constraints such as confining reorderings to a relatively small window.", "labels": [], "entities": []}, {"text": "In combination with a distance-based distortion model, some short-range reorderings can be handled.", "labels": [], "entities": []}, {"text": "But for many language pairs this is not sufficient, and several authors have proposed additional reordering models as described in Section 2.", "labels": [], "entities": []}, {"text": "In this work we present anew method that explicitly handles longrange word reorderings by applying discontinuous, POS-based reordering rules.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: In the next section we present related work that was carried out in this area.", "labels": [], "entities": []}, {"text": "Afterwards, we describe the problem of long-range reordering.", "labels": [], "entities": []}, {"text": "In Section 4 the existing framework for reordering will be introduced.", "labels": [], "entities": []}, {"text": "Section 5 describes the extraction of rules modeling long-range reorderings, and in the following section the integration into the framework will be explained.", "labels": [], "entities": []}, {"text": "Finally, the model will be evaluated in Section 7, and a conclusion is given in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed the experiments on the translation task of the WMT'08 evaluation.", "labels": [], "entities": [{"text": "translation task", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.9246208965778351}, {"text": "WMT'08 evaluation", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.7509960532188416}]}, {"text": "Most of the experiments were done on the German-English task, but in the end also some results on German-French and English-German are shown.", "labels": [], "entities": []}, {"text": "The systems were trained on the European Parliament Proceedings (EPPS) and the News Commentary corpus.", "labels": [], "entities": [{"text": "European Parliament Proceedings (EPPS)", "start_pos": 32, "end_pos": 70, "type": "DATASET", "confidence": 0.906368245681127}, {"text": "News Commentary corpus", "start_pos": 79, "end_pos": 101, "type": "DATASET", "confidence": 0.8646220366160074}]}, {"text": "For the German-French task we used the intersection of the parallel corpora from the GermanEnglish and English-French task.", "labels": [], "entities": []}, {"text": "The data was preprocessed and we applied compound splitting to the German corpus for the tasks translating from German.", "labels": [], "entities": []}, {"text": "Afterwards, the word alignment was generated with the GIZA++-Toolkit and the alignments of the two directions were combined using the grow-diag-final-and heuristic.", "labels": [], "entities": [{"text": "GIZA++-Toolkit", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.775126059850057}]}, {"text": "Then the phrase tables were created where we performed additional smoothing of the relative frequencies ().", "labels": [], "entities": []}, {"text": "Furthermore, the phrase table applied in the news task was adapted to this domain.", "labels": [], "entities": []}, {"text": "In addition, a 4-gram language model was trained on both corpora.", "labels": [], "entities": []}, {"text": "The rules were extracted using the POS tags generated by the TreeTagger (.", "labels": [], "entities": []}, {"text": "In the end a beam-search decoder as described in was used to optimize the weights using the MER-training on the development sets provided for the different task by the workshop.", "labels": [], "entities": [{"text": "MER-training", "start_pos": 92, "end_pos": 104, "type": "METRIC", "confidence": 0.6366143226623535}]}, {"text": "The systems were tested on the test2007 set for the EPPS task and on the nc-test2007 testset for the news task.", "labels": [], "entities": [{"text": "EPPS", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.8381578326225281}]}, {"text": "For test set translations the statistical significance of the results was tested using the bootstrap technique as described in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation of different Lattice sizes  generated by changing the short-range threshold  \u03b8 short and long-range threshold \u03b8 long", "labels": [], "entities": []}, {"text": " Table 2: Number of long-range reordering rules of  different types used to create the lattices", "labels": [], "entities": []}, {"text": " Table 3: Translation results for the German- English task using different rule types (BLEU)", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9670955538749695}, {"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9973932504653931}]}, {"text": " Table 4: Summary of translation results for the  German-English tasks (BLEU)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9910284876823425}]}, {"text": " Table 5: Translation results for the German- French translation task (BLEU)", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.962906539440155}, {"text": "German- French translation task", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.622611278295517}, {"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.8421505689620972}]}, {"text": " Table 6: Translation results for the English- German translation task (BLEU)", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9595749378204346}, {"text": "English- German translation task", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.6704700112342834}, {"text": "BLEU", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.8700183033943176}]}]}