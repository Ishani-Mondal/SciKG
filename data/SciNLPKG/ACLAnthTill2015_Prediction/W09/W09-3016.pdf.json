{"title": [], "abstractContent": [{"text": "NLP systems that deal with large collections of text require significant computational resources, both in terms of space and processing time.", "labels": [], "entities": []}, {"text": "Moreover, these systems typically add new layers of linguistic information with references to another layer.", "labels": [], "entities": []}, {"text": "The spreading of these layered annotations across different files makes them more difficult to process and access the data.", "labels": [], "entities": []}, {"text": "As the amount of input increases, so does the difficulty to process it.", "labels": [], "entities": []}, {"text": "One approach is to use distributed parallel computing for solving these larger problems and save time.", "labels": [], "entities": []}, {"text": "We propose a framework that simplifies the integration of independently existing NLP tools to build language-independent NLP systems capable of creating layered annotations.", "labels": [], "entities": []}, {"text": "Moreover, it allows the development of scalable NLP systems, that executes NLP tools in parallel, while offering an easy-to-use programming environment and a transparent handling of distributed computing problems.", "labels": [], "entities": []}, {"text": "With this framework the execution time was decreased to 40 times less than the original one on a cluster with 80 cores.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic information can be automatically created by NLP systems.", "labels": [], "entities": []}, {"text": "These systems are composed by several NLP tools that are typically executed in a pipeline, where each tool performs a processing step.", "labels": [], "entities": []}, {"text": "Therefore, each tool uses the results produced by the previous processing steps and produces new linguistic information that can be later used by other tools.", "labels": [], "entities": []}, {"text": "The addition of new layers of linguistic information (layered annotations) by NLP tools makes the processing and access to data difficult due to the spreading of the layered annotations across different files.", "labels": [], "entities": []}, {"text": "Moreover, whenever these tools are integrated, several problems related with information flow between them may arise.", "labels": [], "entities": []}, {"text": "A given tool may need an annotation previously produced by another tool but some of the information in annotation can be lost in conversions between the different tool data formats, because the expressiveness of each format maybe different and not completely convertible into other formats.", "labels": [], "entities": []}, {"text": "Besides tool integration problems, there is also another problem related with the data-intensive nature of NLP and the computation power needed to produce the linguistic information.", "labels": [], "entities": [{"text": "tool integration", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.7323452830314636}]}, {"text": "The wealth of annotations has increased the amount of data to process.", "labels": [], "entities": []}, {"text": "Therefore, the processing of this linguistic information is a computation-heavy process and some algorithms continue to take along time (hours or days) to produce their results.", "labels": [], "entities": []}, {"text": "This kind of processing can benefit from distributed parallel computing but it may create other problems, such as fault tolerance to machine failures.", "labels": [], "entities": []}, {"text": "Because some NLP algorithms can take longtime to produce their results, it is important to automatically recover from these failures, in order not to lose the results of computations already performed.", "labels": [], "entities": []}, {"text": "Task scheduling is also a problem due to data-intensive nature of NLP.", "labels": [], "entities": [{"text": "Task scheduling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7601528167724609}]}, {"text": "Data-driven scheduling (based on data location) improves performance because it reduces bandwidth usage.", "labels": [], "entities": [{"text": "Data-driven scheduling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6660360395908356}]}, {"text": "Our framework aims to simplify the integration of independently developed NLP tools, while providing an easy-to-use programming environment, and transparent handling of distributed computing problems, such as fault tolerance and task scheduling, when executing the NLP tools in parallel.", "labels": [], "entities": [{"text": "fault tolerance", "start_pos": 209, "end_pos": 224, "type": "TASK", "confidence": 0.7110775858163834}, {"text": "task scheduling", "start_pos": 229, "end_pos": 244, "type": "TASK", "confidence": 0.6648296266794205}]}, {"text": "Moreover, NLP systems built on top of the framework are language-independent and produce layered annotations.", "labels": [], "entities": []}, {"text": "We also measured the gains that can be achieved with the parallel execution of NLP tools and the merging of the layered annotations.", "labels": [], "entities": []}, {"text": "Section 2 discusses related work, Section 3 present the framework's architecture and a detailed description of its components, Section 4 shows the integrated tools, Section 5 explains how the information produced by tools is merged, and Section 6 presents the achieved results.", "labels": [], "entities": []}, {"text": "Finally, Section 7 presents concluding remarks.) is one of the most used framework for building NLP systems.", "labels": [], "entities": []}, {"text": "However, it does not provide a controller for parallel execution, it only supports the execution of applications on different machines over data shared on the server ().", "labels": [], "entities": []}, {"text": "However, this solution cannot be applied in a large-scale distributed environment because the shared repository becomes a bottleneck in computation due to the accesses from all the machines making computations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Serial processing time of the Stanford  POS Tagger", "labels": [], "entities": [{"text": "Stanford  POS Tagger", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.797057310740153}]}, {"text": " Table 2: Stanford POS tagger output compression  evaluation with a fixed number of 64 mappers and  64 reducers.", "labels": [], "entities": [{"text": "POS tagger output compression", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.6657602190971375}]}]}