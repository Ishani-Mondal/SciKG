{"title": [{"text": "Train the Machine with What It Can Learn \u2212 Corpus Selection for SMT", "labels": [], "entities": [{"text": "Corpus Selection", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.8656686544418335}, {"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9447629451751709}]}], "abstractContent": [{"text": "Statistical machine translation relies heavily on available parallel corpora, but SMT may not have the ability or intelligence to make full use of the training set.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.6643708646297455}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9903267025947571}]}, {"text": "Instead of collecting more and more parallel training corpora , this paper aims to improve SMT performance by exploiting the full potential of existing parallel corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9970118999481201}]}, {"text": "We first identify literally translated sentence pairs via lexical and grammatical compatibility, and then use these data to train SMT models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 130, "end_pos": 133, "type": "TASK", "confidence": 0.9926039576530457}]}, {"text": "One experiment indicates that larger training corpora do not always lead to higher decoding performance when the added data are not literal translations.", "labels": [], "entities": []}, {"text": "And another experiment shows that properly enlarging the contribution of literal translation can improve SMT performance significantly.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7840403914451599}, {"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9962421655654907}]}], "introductionContent": [], "datasetContent": [{"text": "This experiment was designed to check whether it is true that larger training corpora always lead to better SMT decoding performance.", "labels": [], "entities": [{"text": "SMT decoding", "start_pos": 108, "end_pos": 120, "type": "TASK", "confidence": 0.9262641370296478}]}, {"text": "We randomly segmented the 400,000 free translation sentence pairs into 4 subsets, with each of them including 100,000 pairs.", "labels": [], "entities": []}, {"text": "A baseline SMT model was trained with the 200,000 literal translation sentence pairs, and then 4 other SMT models were trained on extended corpora, of which each later used corpus includes one more subset than the previous one.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9835941195487976}, {"text": "SMT", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9681793451309204}]}, {"text": "The decoding performances in terms of BLEU and NIST scores of all 5 models are listed in the second and third column of, and the last column gives the numbers of out-of-vocabulary (OOV) words of each model on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9976840019226074}, {"text": "NIST", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.7582849264144897}]}, {"text": "Curves in    A comparison between the different models' BLEU and NIST scores shows that a larger training data set does not necessarily lead to better SMT decoding performance.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9963552951812744}, {"text": "NIST", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.8243899345397949}, {"text": "SMT decoding", "start_pos": 151, "end_pos": 163, "type": "TASK", "confidence": 0.9079591035842896}]}, {"text": "Based on the literal translation data, when more and more free translation data are added to the training set, the performance measures of the relevant SMT models fall at first, then rise, and at finally fall again.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7288012802600861}, {"text": "SMT", "start_pos": 152, "end_pos": 155, "type": "TASK", "confidence": 0.9840747117996216}]}, {"text": "Furthermore, according to our manual analysis of the decoding results, free translation data have actually harmed the SMT model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.9953126907348633}]}, {"text": "It is just because the much smaller numbers of OOV words have made up for the impairment that the performance measures have risen for two times.", "labels": [], "entities": []}, {"text": "They, however, will fall when the decrease in OOV words fails to make it up.", "labels": [], "entities": [{"text": "OOV", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.852183997631073}]}, {"text": "This experiment was designed to exploit both the contribution of literal translation and the advantage of a large vocabulary from a larger corpus.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.8237277269363403}]}, {"text": "To achieve such a goal, minor modifications need to be made towards the training corpus and the module of GIZA++.", "labels": [], "entities": []}, {"text": "We start with an SMT training data set X, which includes n bilingual sentence pairs, i.e. the input vector X = {x 1 , x 2 , x 3 , \u2026, xi , \u2026, x n-1 , x n }.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.905309796333313}]}, {"text": "During the original training process, every sentence pair xi contributes in the same way to the estimation of parameters in the translation model since the corpus has not been weighted.", "labels": [], "entities": []}, {"text": "Now we tried to adjust the contribution of xi according to our previous decision whether it is literal translation or free translation.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7286405861377716}]}, {"text": "If we set the weight vector to be W = {w 1 , w 2 , w 3 , \u2026, w i , \u2026, w n-1 , w n } T , the weighted corpus would become X' = WX = {w 1 x 1 , w 2 x 2 , w 3 x 3 , \u2026, w ix i , \u2026, w n-1 x n-1 , w n x n }, where Hereby \u03bb is an empirical weighting parameter in the range of 0<= \u03bb <=1.", "labels": [], "entities": []}, {"text": "The module of GIZA++ was modified to ensure that the weights imposed on sentence pairs could be effectively transmitted to smaller translation units.", "labels": [], "entities": []}, {"text": "GIZA++ builds word alignments by means of counting occurrences of word pairs in the training corpus.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7249315232038498}]}, {"text": "Given a possibly translatable Chinese-English word pair D = <c, e>, the number N of its occurrences in our original training corpus X can be calculated by summing up its occurrence number N xi in each sentence pair, i.e. We trained five SMT models of different weights on the previously mentioned corpora of free and literal translations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 237, "end_pos": 240, "type": "TASK", "confidence": 0.9872455596923828}]}, {"text": "lists both the training parameters and relevant decoding performances of the five models.", "labels": [], "entities": []}, {"text": "show the trajectories of BLEU and NIST scores in accordance with the weight variable.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9973300695419312}, {"text": "NIST", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.803313136100769}]}, {"text": "We can see that the SMT model achieved the best performance when \u03bb was set to be 0.67.", "labels": [], "entities": [{"text": "SMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9902051687240601}]}, {"text": "Among the five models, that of \u03bb = 0.5 is the baseline since here all sentence pairs contributed in the same way.", "labels": [], "entities": []}, {"text": "Those of \u03bb = 0 and 1 are two special cases designed to explore the isolated contribution of free and literal translation corpora in a contrastive way.", "labels": [], "entities": []}, {"text": "Hereby the two models of \u03bb = 0.67 and 0.8 are the central part of our experiment.", "labels": [], "entities": []}, {"text": "According to the performance trajectories it seems that a reasonable increase in the contribution of the corpus of literal translations effectively improves the decoding performance of the SMT system since the BLEU scores with \u03bb = 0.67 and 0.8 are higher than that of the baseline which are 0.0121 and 0.0105, and of the NIST scores which are 0.", "labels": [], "entities": [{"text": "SMT", "start_pos": 189, "end_pos": 192, "type": "TASK", "confidence": 0.9923241138458252}, {"text": "BLEU", "start_pos": 210, "end_pos": 214, "type": "METRIC", "confidence": 0.9982611536979675}, {"text": "NIST", "start_pos": 321, "end_pos": 325, "type": "DATASET", "confidence": 0.9630852341651917}]}, {"text": "Our further analysis of the translation results and the related evaluation scores with different weight parameters showed that there exists some potential for literal translations to be used to improve SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 202, "end_pos": 205, "type": "TASK", "confidence": 0.9975816011428833}]}, {"text": "Our analysis indicates that two facts caused most of the out-of-vocabulary words (see).", "labels": [], "entities": []}, {"text": "First, some OOV words never occurred in the training corpus; second, most others had been pruned off due to their much lower frequencies.", "labels": [], "entities": []}, {"text": "Training corpora for \u03bb = 0.67 and 0.8 have the same size of as that for \u03bb = 0.5, but they resulted in much more OOV words than those for \u03bb = 0.5 because the lower weight had decreased some related alignment probabilities very much.", "labels": [], "entities": []}, {"text": "It seems that the large OOV increase must have counteracted the potential improvement to a certain degree although it did not have a devastating effects in these two cases.", "labels": [], "entities": [{"text": "OOV", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9959249496459961}]}, {"text": "Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase.", "labels": [], "entities": [{"text": "SMT", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.9951136708259583}, {"text": "OOV", "start_pos": 208, "end_pos": 211, "type": "METRIC", "confidence": 0.9812657237052917}]}], "tableCaptions": [{"text": " Table 2: SMT performance with extended corpora", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9949310421943665}]}, {"text": " Table 3: SMT performances with weighted corpora", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9943625926971436}]}]}