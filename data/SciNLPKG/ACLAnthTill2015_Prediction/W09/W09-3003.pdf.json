{"title": [{"text": "Assessing the benefits of partial automatic pre-labeling for frame-semantic annotation", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present the results of an experiment in which we assess the usefulness of partial semi-automatic annotation for frame labeling.", "labels": [], "entities": [{"text": "frame labeling", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.7865153849124908}]}, {"text": "While we found no conclusive evidence that it can speedup human annotation, automatic pre-annotation does increase its overall quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistically annotated resources play a crucial role in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.6524181663990021}]}, {"text": "Many recent advances in areas such as part-of-speech tagging, parsing, co-reference resolution, and semantic role labeling have only been possible because of the creation of manually annotated corpora, which then serve as training data for machine-learning based NLP tools.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7240491509437561}, {"text": "parsing", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.9616979956626892}, {"text": "co-reference resolution", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.6904391348361969}, {"text": "semantic role labeling", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.6278530061244965}]}, {"text": "However, human annotation of linguistic categories is time-consuming and expensive.", "labels": [], "entities": [{"text": "human annotation of linguistic categories", "start_pos": 9, "end_pos": 50, "type": "TASK", "confidence": 0.7785586953163147}]}, {"text": "While this is already a problem for major languages like English, it is an even bigger problem for lessused languages.", "labels": [], "entities": []}, {"text": "This data acquisition bottleneck is a well-known problem and there have been numerous efforts to address it on the algorithmic side.", "labels": [], "entities": [{"text": "data acquisition", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.7311121821403503}]}, {"text": "Examples include the development of weakly supervised learning methods such as co-training and active learning.", "labels": [], "entities": []}, {"text": "However, addressing only the algorithmic side is not always possible and not always desirable in all scenarios.", "labels": [], "entities": []}, {"text": "First, some machine learning solutions are not as generally applicable or widely re-usable as one might think.", "labels": [], "entities": []}, {"text": "It has been shown, for example, that co-training does notwork well for problems which cannot easily be factorized into two independent views.", "labels": [], "entities": []}, {"text": "Some active learning studies suggest both that the utility of the selected examples strongly depends on the model used for classification and that the example pool selected for one model can turnout to be sub-optimal when another model is trained on it at a later stage ().", "labels": [], "entities": []}, {"text": "Furthermore, there area number of scenarios for which there is simply no alternative to high-quality, manually annotated data; for example, if the annotated corpus is used for empirical research in linguistics.", "labels": [], "entities": []}, {"text": "In this paper, we look at this problem from the data creation side.", "labels": [], "entities": [{"text": "data creation", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.7081760615110397}]}, {"text": "Specifically we explore whether a semi-automatic annotation set-up in which a human expert corrects the output of an automatic system can help to speedup the annotation process without sacrificing annotation quality.", "labels": [], "entities": []}, {"text": "For our study, we explore the task of framesemantic argument structure annotation ().", "labels": [], "entities": [{"text": "framesemantic argument structure annotation", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.6422048062086105}]}, {"text": "We chose this particular task because it is a rather complex -and therefore time-consuming -undertaking, and it involves making a number of different but interdependent annotation decisions for each instance to be labeled (e.g. frame assignment and labeling of frame elements, see Section 3.1).", "labels": [], "entities": [{"text": "frame assignment", "start_pos": 228, "end_pos": 244, "type": "TASK", "confidence": 0.7314883470535278}]}, {"text": "Semi-automatic support would thus be of real benefit.", "labels": [], "entities": []}, {"text": "More specifically, we explore the usefulness of automatic pre-annotation for the first step in the annotation process, namely frame assignment (word sense disambiguation).", "labels": [], "entities": [{"text": "frame assignment", "start_pos": 126, "end_pos": 142, "type": "TASK", "confidence": 0.7217094004154205}, {"text": "word sense disambiguation", "start_pos": 144, "end_pos": 169, "type": "TASK", "confidence": 0.5985301633675894}]}, {"text": "Since the available inventory of frame elements is dependent on the chosen frame, this step is crucial for the whole annotation process.", "labels": [], "entities": []}, {"text": "Furthermore, semi-automatic annotation is more feasible for the frame labeling sub-task.", "labels": [], "entities": [{"text": "frame labeling", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.7312918305397034}]}, {"text": "Most automatic semantic role labeling systems (ASRL), including ours, tend to perform much better on frame assignment than on frame role labeling and correcting an erroneously chosen frame typically also requires fewer physical operations from the annotator than correcting a number of wrongly assigned frame elements.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.6533321539560953}, {"text": "frame assignment", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7051742374897003}, {"text": "frame role labeling", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.6258645057678223}]}, {"text": "We aim to answer three research questions in our study: First, we explore whether pre-annotation of frame labels can indeed speedup the annotation process.", "labels": [], "entities": []}, {"text": "This question is important because frame assignment, in terms of physical operations of the annotator, is a relatively minor effort compared to frame role assignment and because checking a preannotated frame still involves all the usual mental operations that annotation from scratch does.", "labels": [], "entities": [{"text": "frame assignment", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.8264894485473633}, {"text": "frame role assignment", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.6083021263281504}]}, {"text": "Our second major question is whether annotation quality would remain acceptably high.", "labels": [], "entities": []}, {"text": "Here the concern is that annotators might tend to simply go along with the pre-annotation, which would lead to an overall lower annotation quality than they could produce by annotating from scratch.", "labels": [], "entities": []}, {"text": "1 Depending on the purpose for which the annotations are to be used, trading off accuracy for speed mayor may not be acceptable.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9991746544837952}, {"text": "speed mayor", "start_pos": 94, "end_pos": 105, "type": "METRIC", "confidence": 0.9483739137649536}]}, {"text": "Our third research question concerns the required quality of pre-annotation for it to have any positive effect.", "labels": [], "entities": []}, {"text": "If the quality is too low, the annotation process might actually be slowed down because annotations by the automatic system would have to be deleted before the new correct one could be made.", "labels": [], "entities": []}, {"text": "In fact, annotators might ignore the pre-annotations completely.", "labels": [], "entities": []}, {"text": "To determine the effect of the pre-annotation quality, we not only compared a null condition of providing no prior annotation to one where we did, but we in fact compared the null condition to two different quality levels of pre-annotation, one that reflects the performance of a state-of-the-art ASRL system and an enhanced one that we artificially produced from the gold standard.", "labels": [], "entities": []}], "datasetContent": [{"text": "The annotation scheme we use is that of FrameNet (FN), a lexicographic project that produces a database of frame-semantic descriptions of English vocabulary.", "labels": [], "entities": []}, {"text": "Frames are representations of prototypical events or states and their participants in the sense of.", "labels": [], "entities": []}, {"text": "In the FN database, both frames and their participant roles are arranged in various hierarchical relations (most prominently, the is-a relation).", "labels": [], "entities": [{"text": "FN database", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.826816201210022}]}, {"text": "FrameNet links these descriptions of frames with the words and multi-words (lexical units, LUs) that evoke these conceptual structures.", "labels": [], "entities": []}, {"text": "It also docu-ments all the ways in which the semantic roles (frame elements, FEs) can be realized as syntactic arguments of each frame-evoking word by labeling corpus attestations.", "labels": [], "entities": [{"text": "FEs", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9497892260551453}]}, {"text": "As a small example, consider the Collaboration frame, evoked in English by lexical units such as collaborate.v, conspire.v, collaborator.n and others.", "labels": [], "entities": []}, {"text": "The core set of frame-specific roles that apply include Partner 1 , Partner 2 , Partners and Undertaking.", "labels": [], "entities": []}, {"text": "A labeled example sentence is [The two researchers P artners ] COLLAB-ORATED [on many papers U ndertaking ].", "labels": [], "entities": [{"text": "COLLAB-ORATED", "start_pos": 63, "end_pos": 76, "type": "METRIC", "confidence": 0.9922797679901123}]}, {"text": "FrameNet uses two modes of annotation: fulltext, where the goal is to exhaustively annotate the running text of a document with all the different frames and roles that occur, and lexicographic, where only instances of particular target words used in particular frames are labeled.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8829076290130615}]}], "tableCaptions": [{"text": " Table 3: Results for frame assignment: precision,  recall, f-score (F), time (t) (frame and role as- signment), pre-annotation (p): Non, Enhanced,  Shalmaneser", "labels": [], "entities": [{"text": "frame assignment", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7054244428873062}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9995452761650085}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9991247057914734}, {"text": "f-score (F)", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9121561646461487}]}, {"text": " Table 4: Average f-score for the 6 annotators", "labels": [], "entities": [{"text": "Average f-score", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8818608522415161}]}, {"text": " Table 5: Baselines for automatic pre-annotation  (Shalmaneser) and enhanced pre-annotation", "labels": [], "entities": []}, {"text": " Table 6: Average f-scores for the 6 annotators", "labels": [], "entities": []}]}