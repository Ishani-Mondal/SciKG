{"title": [{"text": "The effect of linguistic devices in information presentation messages on comprehension and recall", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we examine the effect of linguistic devices on recall and comprehension in information presentation using both recall and eye-tracking data.", "labels": [], "entities": [{"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9948062300682068}, {"text": "information presentation", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.7180168926715851}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9940724968910217}]}, {"text": "In addition , the results were validated via an experiment using Amazon's Mechanical Turk micro-task environment.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk micro-task environment", "start_pos": 65, "end_pos": 112, "type": "DATASET", "confidence": 0.8710824052492777}]}], "introductionContent": [{"text": "In this paper, we present two experiments designed to examine the impact of linguistic devices, such as discourse cues and connectives, on comprehension and recall in information presentation for natural language generation (NLG) as used in spoken dialogue systems (SDS).", "labels": [], "entities": [{"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9469012022018433}, {"text": "natural language generation (NLG)", "start_pos": 196, "end_pos": 229, "type": "TASK", "confidence": 0.8349571228027344}]}, {"text": "Spoken dialogue systems have traditionally used simple templates to present options (e.g., flights, restaurants) and their attributes to users).", "labels": [], "entities": []}, {"text": "Recently, however, researchers have proposed approaches to information presentation that use linguistic devices (e.g., but, however, moreover, only, just, also etc.) in order to highlight specific properties of and relations between items presented to the user, e.g. associations () and contrasts.", "labels": [], "entities": [{"text": "information presentation", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.7276641875505447}]}, {"text": "Previous research indicates that linguistic devices such as connectives facilitate comprehension (see, fora review).", "labels": [], "entities": []}, {"text": "However, to our knowledge, no empirical validation has been performed to test whether using linguistic devices has an effect on comprehension and recall of the information presentated.", "labels": [], "entities": [{"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9918617010116577}]}], "datasetContent": [{"text": "In order to test whether there are differences in recall, we performed a within-participants reading experiment comparing recall for experiment material presented with or without linguistic devices 1 A total of 24 participants, native English speakers and mostly students of the University of Edinburgh, were paid to participate in the study.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.997306227684021}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9944173097610474}]}, {"text": "They were naive to the purpose of the experiment but were told that they were about to be presented with a number of consumer products and that they were supposed to answer questions about these.", "labels": [], "entities": []}, {"text": "Each participant read 14 short texts describing consumer products from 14 domains, see for examples.", "labels": [], "entities": []}, {"text": "The texts are the type of presentation typically produced by spoken dialogue systems designed to help users select an entity from a set of available options.", "labels": [], "entities": []}, {"text": "Participants' eye-movements during reading were recorded as described in section 3.", "labels": [], "entities": []}, {"text": "There were two types of messages, one containing linguistic devices to point out similari-ties and differences among the options, and one without these linguistic markers.", "labels": [], "entities": []}, {"text": "Each participant read seven texts of each type, alternating between types.", "labels": [], "entities": []}, {"text": "Ordering of both the domains and the text type was controlled for.", "labels": [], "entities": []}, {"text": "We took particular care to add discourse devices without modifying the propositions in any other way.", "labels": [], "entities": []}, {"text": "After each message, the participant had to answer three questions testing different levels of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9976462721824646}]}, {"text": "Examples of each type of question are given in.", "labels": [], "entities": []}, {"text": "In each trial, participants read a text presented for up to 45 seconds on the screen.", "labels": [], "entities": []}, {"text": "Users could press Enter on the keyboard when they were finished reading.", "labels": [], "entities": []}, {"text": "They were then presented with the questions, which they had to answer one after the other.", "labels": [], "entities": []}, {"text": "After a question was presented, the participant pressed Enter to be prompted to type in an answer.", "labels": [], "entities": []}, {"text": "We carried out a web-based user study on Amazon's Mechanical Turk 3 (MT) platform both in order to verify the results obtained in the previous recall experiment and in order to test whether results obtained from casual website users are comparable to those obtained from laboratory participants who focus exclusively on performing the experiment in the lab.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk 3 (MT) platform", "start_pos": 41, "end_pos": 81, "type": "DATASET", "confidence": 0.7833887272410922}]}, {"text": "We recruited native English speakers online to carryout the same experiment previously conducted in the lab.", "labels": [], "entities": []}, {"text": "MT is a webbased micro-task platform that allows researchers and developers to put small tasks requiring human intelligence on the web.", "labels": [], "entities": []}, {"text": "Deploying MT is advantageous because it attracts many visitors due to its affiliation with the well established Amazon website and thus eases recruitment of new participants especially from outside the usual student population.", "labels": [], "entities": [{"text": "Deploying MT", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.718736320734024}]}, {"text": "In addition, conducting experiments online significantly reduces the effort involved in data collection for the experimenter.", "labels": [], "entities": []}, {"text": "Moreover, the website allows for convenient payment for both participants and the experimenter.", "labels": [], "entities": []}, {"text": "For these reasons, MT has recently been used in a number of language experiments (e.g.,).", "labels": [], "entities": [{"text": "MT", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9820020198822021}]}, {"text": "In order to resemble the interface that was used in the previous experiment as closely as possible in terms of the general \"look and feel\", a web-based interface was implemented using Adobe's Flash format.", "labels": [], "entities": []}, {"text": "We chose the widely used Flash format because it can be integrated into the MT environment easily and allows for tighter user control in comparison with standard HTML pages.", "labels": [], "entities": []}, {"text": "For example, we made it impossible for users to reread the presented information once they read the corresponding question.", "labels": [], "entities": []}, {"text": "With standard HMTL users would have been able to use their browser's back button to do just that.", "labels": [], "entities": []}, {"text": "The experiment was then made available to the users on Amazon's MT website.", "labels": [], "entities": [{"text": "Amazon's MT website", "start_pos": 55, "end_pos": 74, "type": "DATASET", "confidence": 0.7979662269353867}]}, {"text": "The procedure was otherwise exactly the same as in experiment 1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2.2). In particular, answers to compari- son questions were correctly recalled significantly  more often when linguistic markers were present.", "labels": [], "entities": []}, {"text": " Table 1: Eye-tracking data per IA (first pass reading times, remaining time reading times, number of  passes, regressions out and in) for messages with and without discourse cues", "labels": [], "entities": [{"text": "IA", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.6261839270591736}]}]}