{"title": [{"text": "Cross-lingual Adaptation as a Baseline: Adapting Maximum Entropy Models to Bulgarian", "labels": [], "entities": [{"text": "Cross-lingual Adaptation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7146033346652985}]}], "abstractContent": [{"text": "We describe our efforts in adapting five basic natural language processing components to Bulgar-ian: sentence splitter, tokenizer, part-of-speech tagger, chunker, and syntactic parser.", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7243078649044037}]}, {"text": "The components were originally developed for English within OpenNLP, an open source maximum en-tropy based machine learning toolkit, and were retrained based on manually annotated training data from the BulTreeBank.", "labels": [], "entities": [{"text": "BulTreeBank", "start_pos": 203, "end_pos": 214, "type": "DATASET", "confidence": 0.9695286154747009}]}, {"text": "The evaluation results show an F1 score of 92.54% for the sentence splitter, 98.49% for the tokenizer, 94.43% for the part-of-speech tagger, 84.60% for the chun-ker, and 77.56% for the syntactic parser, which should be interpreted as baseline for Bulgarian.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9871308207511902}, {"text": "sentence splitter", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7110653817653656}]}], "introductionContent": [{"text": "Nowadays, the dominant approach in natural language processing (nlp) is to acquire linguistic knowledge using machine learning methods.", "labels": [], "entities": [{"text": "natural language processing (nlp)", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7761104007562002}]}, {"text": "Other approaches, e.g., using manual rules, have proven to be both timeconsuming and error-prone.", "labels": [], "entities": []}, {"text": "Still, using machine learning has one major limitation: it requires manually annotated corpora as training data, which can be quite costly to create.", "labels": [], "entities": []}, {"text": "Fortunately, for Bulgarian such a rich resource already exists -the BulTreeBank 1 , an HPSGbased Syntactic Treebank with rich annotations at various linguistic levels.", "labels": [], "entities": [{"text": "BulTreeBank 1", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.7109927833080292}, {"text": "HPSGbased Syntactic Treebank", "start_pos": 87, "end_pos": 115, "type": "DATASET", "confidence": 0.8766964673995972}]}, {"text": "The existence of such a resource makes it possible to adapt to Bulgarian various nlp tools that have been originally developed for other languages, e.g., English, and that have been trained on similar kinds of resources, e.g., the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 231, "end_pos": 244, "type": "DATASET", "confidence": 0.9953214228153229}]}, {"text": "In this paper, we further stipulate that language adaption should be no harder than domain adaptation.", "labels": [], "entities": [{"text": "language adaption", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7756945490837097}, {"text": "domain adaptation", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7070586085319519}]}, {"text": "Similarly to, we experiment with the OpenNLP tools 2 since they are open source and contain several platform-independent Java implementations of important nlp components.", "labels": [], "entities": [{"text": "OpenNLP tools", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.9078056216239929}]}, {"text": "Moreover, these tools are based on a single machine learning algorithm, maximum entropy (me), as implemented in the OpenNLP MaxEnt 3 Java package.", "labels": [], "entities": [{"text": "maximum entropy (me)", "start_pos": 72, "end_pos": 92, "type": "METRIC", "confidence": 0.7648008227348327}, {"text": "OpenNLP MaxEnt 3 Java package", "start_pos": 116, "end_pos": 145, "type": "DATASET", "confidence": 0.8627324342727661}]}, {"text": "In our experiments below, we focus on five basic components from the OpenNLP tools: sentence detection, tokenization, part-of-speech (pos) tagging, chunking, and parsing.", "labels": [], "entities": [{"text": "sentence detection", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8107222020626068}, {"text": "tokenization", "start_pos": 104, "end_pos": 116, "type": "TASK", "confidence": 0.9710681438446045}, {"text": "part-of-speech (pos) tagging", "start_pos": 118, "end_pos": 146, "type": "TASK", "confidence": 0.6022668778896332}]}, {"text": "Maximum entropy models search fora distribution (|) that is consistent with the empirical observations about a particular feature (, ), computed from a set of training examples = {, }, e.g., a sentence and its labeling ; see for details.", "labels": [], "entities": []}, {"text": "From all such distributions, the one with the highest entropy is chosen.", "labels": [], "entities": []}, {"text": "It can be shown that the resulting distribution will have the following form: The features used in the OpenNLP framework combine heterogeneous contextual information such as words around the end of a sentence for the English sentence splitter, or word, character -grams and partof-speech tag alone and in various combinations for the English chunker.", "labels": [], "entities": [{"text": "English sentence splitter", "start_pos": 217, "end_pos": 242, "type": "TASK", "confidence": 0.5915757218996683}]}, {"text": "These features are based on the publications of Sha and Pereira for the chunker, and on the dissertation of Ratnaparkhi for the POS tagger and the syntactic parser.", "labels": [], "entities": [{"text": "chunker", "start_pos": 72, "end_pos": 79, "type": "TASK", "confidence": 0.9404176473617554}]}, {"text": "The remainder of this paper is organized as follows: Section 2 describes the process of converting the BulTreeBank XML data to Penn Treebank-style bracketing, Section 3 describes the experiments and discusses the results, and Section 4 concludes and suggests directions for future work.", "labels": [], "entities": [{"text": "BulTreeBank XML data", "start_pos": 103, "end_pos": 123, "type": "DATASET", "confidence": 0.9173432191212972}, {"text": "Penn Treebank-style", "start_pos": 127, "end_pos": 146, "type": "DATASET", "confidence": 0.9587609767913818}]}], "datasetContent": [{"text": "In our experiments, we used the training and the testing sections of the BulTreeBank without further modifications in order to retrain for Bulgarian the sentence splitter, the tokenizer, the POS tagger, the chunker (shallow parser), and the syntactic parser from the OpenNLP tools.", "labels": [], "entities": [{"text": "BulTreeBank", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.836759626865387}, {"text": "sentence splitter", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.7188204228878021}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The sentence splitter achieved an F 1 score of 92.54%.", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.789376437664032}, {"text": "F 1 score", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9919092456499735}]}, {"text": "The false positives constituted most of the errors and appeared in complicated sentences rather than at abbreviations of organization names as we expected.", "labels": [], "entities": []}, {"text": "For example, the following chunk was recognized as a sentence: \u041a\u043e \u0438 \u0431\u0435\u0448\u0435 \u0442\u043e\u0437\u0438 \u0447\u043e\u0432\u0435\u043a?, \u0431\u0438 \u0437\u0430\u043f\u0438\u0442\u0430\u043b \u0442\u043e \u0438.", "labels": [], "entities": []}, {"text": "Who was that guy?, he would ask.", "labels": [], "entities": []}], "tableCaptions": []}