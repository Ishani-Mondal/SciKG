{"title": [{"text": "An Integrated Approach to Robust Processing of Situated Spoken Dialogue", "labels": [], "entities": [{"text": "Robust Processing of Situated Spoken Dialogue", "start_pos": 26, "end_pos": 71, "type": "TASK", "confidence": 0.8951842486858368}]}], "abstractContent": [{"text": "Spoken dialogue is notoriously hard to process with standard NLP technologies.", "labels": [], "entities": [{"text": "Spoken dialogue", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9390542507171631}]}, {"text": "Natural spoken dialogue is replete with disfluent, partial, elided or ungrammatical utterances, all of which are very hard to accommodate in a dialogue system.", "labels": [], "entities": []}, {"text": "Furthermore , speech recognition is known to be a highly error-prone task, especially for complex, open-ended discourse domains.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.8484865725040436}]}, {"text": "The combination of these two problems-ill-formed and/or misrecognised speech inputs-raises a major challenge to the development of robust dialogue systems.", "labels": [], "entities": []}, {"text": "We present an integrated approach for addressing these two issues, based on a in-cremental parser for Combinatory Categorial Grammar.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar", "start_pos": 102, "end_pos": 132, "type": "TASK", "confidence": 0.5884494582811991}]}, {"text": "The parser takes word lattices as input and is able to handle ill-formed and misrecognised utterances by selectively relaxing its set of grammatical rules.", "labels": [], "entities": []}, {"text": "The choice of the most relevant interpretation is then realised via a discriminative model augmented with con-textual information.", "labels": [], "entities": []}, {"text": "The approach is fully implemented in a dialogue system for autonomous robots.", "labels": [], "entities": []}, {"text": "Evaluation results on a Wizard of Oz test suite demonstrate very significant improvements inaccuracy and robustness compared to the baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialogue is often considered to be one of the most natural means of interaction between a human and a robot.", "labels": [], "entities": [{"text": "Spoken dialogue", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9083556532859802}]}, {"text": "It is, however, notoriously hard to process with standard language processing technologies.", "labels": [], "entities": []}, {"text": "Dialogue utterances are often incomplete or ungrammatical, and may contain numerous disfluencies like fillers (err, uh, mm), repetitions, self-corrections, etc.", "labels": [], "entities": []}, {"text": "Rather than getting crisp-and-clear commands such as \"Put the red ball inside the box!\", it is more likely the robot will hear such kind of utterance: \"right, now, could you, uh, put the red ball, yeah, inside the ba/ box!\".", "labels": [], "entities": [{"text": "crisp-and-clear", "start_pos": 20, "end_pos": 35, "type": "METRIC", "confidence": 0.9871081709861755}]}, {"text": "This is natural behaviour in human-human interaction) and can also be observed in several domain-specific corpora for human-robot interaction ().", "labels": [], "entities": []}, {"text": "Moreover, even in the (rare) case where the utterance is perfectly well-formed and does not contain any kind of disfluencies, the dialogue system still needs to accomodate the various speech recognition errors thay may arise.", "labels": [], "entities": []}, {"text": "This problem is particularly acute for robots operating in realworld noisy environments and deal with utterances pertaining to complex, open-ended domains.", "labels": [], "entities": []}, {"text": "The paper presents anew approach to address these two difficult issues.", "labels": [], "entities": []}, {"text": "Our starting point is the work done by Zettlemoyer and Collins on parsing using relaxed CCG grammars) (ZC07).", "labels": [], "entities": [{"text": "ZC07)", "start_pos": 103, "end_pos": 108, "type": "DATASET", "confidence": 0.924354761838913}]}, {"text": "In order to account for natural spoken language phenomena (more flexible word order, missing words, etc.), they augment their grammar framework with a small set of non-standard combinatory rules, leading to a relaxation of the grammatical constraints.", "labels": [], "entities": []}, {"text": "A discriminative model over the parses is coupled with the parser, and is responsible for selecting the most likely interpretation(s) among the possible ones.", "labels": [], "entities": []}, {"text": "In this paper, we extend their approach in two important ways.", "labels": [], "entities": []}, {"text": "First, ZC07 focused on the treatment of ill-formed input, and ignored the speech recognition issues.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.8066139221191406}]}, {"text": "Our system, to the contrary, is able to deal with both ill-formed and misrecognized input, in an integrated fashion.", "labels": [], "entities": []}, {"text": "This is done by augmenting the set of non-standard combinators with new rules specifically tailored to deal with speech recognition errors.", "labels": [], "entities": [{"text": "speech recognition errors", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.7999338110287985}]}, {"text": "Second, the only features used by ZC07 are syntactic features (see 3.4 for details).", "labels": [], "entities": [{"text": "ZC07", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.8680174350738525}]}, {"text": "We significantly extend the range of features included in the discriminative model, by incorporating not only syntactic, but also acoustic, semantic and contextual information into the model.", "labels": [], "entities": []}, {"text": "An overview of the paper is as follows.", "labels": [], "entities": []}, {"text": "We first describe in Section 2 the cognitive architecture in which our system has been integrated.", "labels": [], "entities": []}, {"text": "We then discuss the approach in detail in Section 3.", "labels": [], "entities": []}, {"text": "Finally, we present in Section 4 the quantitative evaluations on a WOZ test suite, and conclude.", "labels": [], "entities": [{"text": "WOZ test suite", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.877556840578715}]}], "datasetContent": [{"text": "We performed a quantitative evaluation of our approach, using its implementation in a fully integrated system (cf. Section 2).", "labels": [], "entities": []}, {"text": "To setup the experiments for the evaluation, we have gathered a corpus of human-robot spoken dialogue for our task-domain, which we segmented and annotated manually with their expected semantic interpretation.", "labels": [], "entities": []}, {"text": "The data set contains 195 individual utterances along with their complete logical forms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Exact-match accuracy results (in percents).", "labels": [], "entities": [{"text": "Exact-match", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9871147871017456}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9294330477714539}]}, {"text": " Table 2: Partial-match accuracy results (in percents).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9793756604194641}]}, {"text": " Table 3: Word error rate (in percents).", "labels": [], "entities": [{"text": "Word error rate", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8095881144205729}]}]}