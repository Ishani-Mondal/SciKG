{"title": [{"text": "Analysis and Development of Urdu POS Tagged Corpus", "labels": [], "entities": [{"text": "Urdu POS Tagged Corpus", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.7912594825029373}]}], "abstractContent": [{"text": "In this paper, two corpora of Urdu (with 110K and 120K words) tagged with different POS tagsets are used to train TnT and Tree taggers.", "labels": [], "entities": []}, {"text": "Error analysis of both taggers is done to identify frequent confusions in tagging.", "labels": [], "entities": []}, {"text": "Based on the analysis of tagging, and syntactic structure of Urdu, a more refined tagset is derived.", "labels": [], "entities": []}, {"text": "The existing tagged corpora are tagged with the new tagset to develop a single corpus of 230K words and the TnT tagger is retrained.", "labels": [], "entities": []}, {"text": "The results show improvement in tagging accuracy for individual corpora to 94.2% and also for the merged corpus to 91%.", "labels": [], "entities": [{"text": "tagging", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9321497082710266}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9796702861785889}]}, {"text": "Implications of these results are discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "There is increasing amount of work on computational modeling of Urdu language.", "labels": [], "entities": []}, {"text": "As various groups work on the language, diversity in analysis is also developed.", "labels": [], "entities": []}, {"text": "In this context, there has been some work on Urdu part of speech (POS) tagging, which has caused multiple tagsets to appear.", "labels": [], "entities": [{"text": "Urdu part of speech (POS) tagging", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.6508989222347736}]}, {"text": "Thus, there is also need to converge these efforts.", "labels": [], "entities": []}, {"text": "Current work compares the existing tagsets of Urdu being used for tagging corpora in an attempt to look at the differences, and understand the reasons for the variation.", "labels": [], "entities": [{"text": "tagging corpora", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.8894335627555847}]}, {"text": "The work then undertakes experiments to develop a common tagset, which is syntactically and computationally coherent.", "labels": [], "entities": []}, {"text": "The aim is to make a robust tagset and then to port the differently tagged Urdu corpora onto the same tagset.", "labels": [], "entities": []}, {"text": "As Urdu already has very few annotated corpora, this will help consolidating them for better modeling.", "labels": [], "entities": []}, {"text": "The next sections present the existing tagsets and accuracies of the POS taggers reported using them.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present baseline experiment and the methodology used for the analysis for updating the tagset.", "labels": [], "entities": []}, {"text": "Section 6 describes the proposed tagset.", "labels": [], "entities": []}, {"text": "Section 7 reports experiments comparing the new tagset with existing ones.", "labels": [], "entities": []}, {"text": "Section 8 discusses the results achieved and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpora annotated with the different tagsets are acquired from CRULP.", "labels": [], "entities": [{"text": "CRULP", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.9757737517356873}]}, {"text": "The corpus originally tagged with T1 tagset is referred to as C1 (news from non-business domain) and the corpus initially annotated with T2 tagset is referred to as C2 (news from business domain), subsequently in the current work.", "labels": [], "entities": []}, {"text": "Both C1 and C2 are taken and cleaned.", "labels": [], "entities": []}, {"text": "The data is re-counted and approximately 100,000 words are separated for training and rest are kept for testing.", "labels": [], "entities": []}, {"text": "The details of data are given in  After designing anew tagset, a series of experiments are conducted to investigate the proposed changes.", "labels": [], "entities": []}, {"text": "The rationale of the sequence of experiments has been discussed in Section 5 above, however the reasoning for each experiment is also given below.", "labels": [], "entities": []}, {"text": "As T2 tags have much more semantic and phrasal information, and C2 tagged with T2 shows lower accuracy than T1 on C1, therefore further experiments are conducted to compare the performance of T1 and T3 only.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9986780285835266}]}, {"text": "Comparisons on C2 with T3 may also be drawn.", "labels": [], "entities": []}, {"text": "As baseline estimation shows that T1 on C1 outperforms T2 on C2, the first experiment is to compare the performance of T3 on C1.", "labels": [], "entities": []}, {"text": "In this experiment C1 is semi-automatically tagged with T3.", "labels": [], "entities": []}, {"text": "TnT tagger is then trained and tested.", "labels": [], "entities": [{"text": "TnT tagger", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7057268172502518}]}, {"text": "T3 gives 93.44% accuracy, which is slightly better than the results already obtained for T1 (93.01%).", "labels": [], "entities": [{"text": "T3", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7923378944396973}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9997422099113464}]}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "Now to test the effect of change in domain of the corpus, the performance T1 and T3 on C2 is compared in this experiment.", "labels": [], "entities": []}, {"text": "C2 is manually tagged with T3, then trained and tested using TnT tagger.", "labels": [], "entities": []}, {"text": "The results obtained with T3 are 91.98%, which are significantly better than the results already obtained for T2 on C2 (88.13%).", "labels": [], "entities": []}, {"text": "C2 is also semi-automatically re-tagged with T1.", "labels": [], "entities": []}, {"text": "T1 shows better performance (91.31%) than T2 (88.13%).", "labels": [], "entities": []}, {"text": "However, the accuracy of using T3 (on C2) is still slightly higher.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9997143149375916}]}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "Due to the change in open class set there maybe a difference of performance on unknown words, therefore in this experiment, all the unknown words of test set are also included in the vocabulary.", "labels": [], "entities": []}, {"text": "This experiment again involves T3 and T1 with C2.", "labels": [], "entities": []}, {"text": "Combined lexica are built using testing and training parts of the corpus, to eliminate the factor of unknown words.", "labels": [], "entities": []}, {"text": "This experiment also shows that T3 performs better than T1, as shown in.", "labels": [], "entities": []}, {"text": "Finally both corpora (C1 and C2) were combined, forming a training set of 203,882 words and a test set of 29,851 words.", "labels": [], "entities": []}, {"text": "The lexica are generated only from the training set.", "labels": [], "entities": []}, {"text": "Then TnT tagger is trained separately for both T1 and T3 tagsets and the accuracies are compared.", "labels": [], "entities": [{"text": "TnT tagger", "start_pos": 5, "end_pos": 15, "type": "TASK", "confidence": 0.6805771887302399}]}, {"text": "The results show that T3 gives better tagging accuracy, as shown in.", "labels": [], "entities": [{"text": "T3", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.7789978981018066}, {"text": "tagging", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.95050048828125}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9824252724647522}]}, {"text": "Partial confusion matrices for both the tagsets are given in The error analysis shows that the accuracy drops for both tagsets when trained on multidomain corpus, which is expected.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9994043111801147}]}, {"text": "The highest error count is for the confusion between noun and adjective.", "labels": [], "entities": [{"text": "error count", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9815089106559753}]}, {"text": "There is also confusion between proper and common nouns.", "labels": [], "entities": []}, {"text": "T3 also gives significant confusion between personal pronouns and demonstratives, as they represent the same lexical entries.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Number of tokens in Urdu corpora", "labels": [], "entities": []}, {"text": " Table 2. Number of sentences in Urdu corpora", "labels": [], "entities": []}, {"text": " Table 3. Results of both tagsets on their respec- tive corpora with TnT and Tree taggers", "labels": [], "entities": []}, {"text": " Table 4. Summary of experiments conducted", "labels": [], "entities": []}, {"text": " Table 5. Major misclassifications in C2 with T2  tagset using Tree tagger", "labels": [], "entities": []}, {"text": " Table 6. Major misclassifications in C2 with T2  tagset using TnT-tagger", "labels": [], "entities": []}, {"text": " Table 7. Accuracies of T3 and T1 on C1", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9986779093742371}]}, {"text": " Table 8. Accuracies of T3 on C1, and accura- cies of T3 and T1 on C2", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9994445443153381}, {"text": "accura", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9944080114364624}]}, {"text": " Table 9. Accuracies of T3 and T1 with ALL  known words in test data", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9980891346931458}]}, {"text": " Table 10. Accuracies of T3 and T1 using  combined C1 and C2 corpora", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9940245747566223}]}]}