{"title": [{"text": "Comparison of Classification and Ranking Approaches to Pronominal Anaphora Resolution in Czech *", "labels": [], "entities": [{"text": "Pronominal Anaphora Resolution", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7145305871963501}]}], "abstractContent": [{"text": "In this paper we compare two Machine Learning approaches to the task of pronominal anaphora resolution: a conventional classification system based on C5.0 decision trees, and a novel perceptron-based ranker.", "labels": [], "entities": [{"text": "pronominal anaphora resolution", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.7219667037328085}]}, {"text": "We use coref-erence links annotated in the Prague Dependency Treebank 2.0 for training and evaluation purposes.", "labels": [], "entities": [{"text": "Prague Dependency Treebank 2.0", "start_pos": 43, "end_pos": 73, "type": "DATASET", "confidence": 0.9506460428237915}]}, {"text": "The perceptron system achieves f-score 79.43% on recognizing coreference of personal and possessive pronouns, which clearly outperforms the classifier and which is the best result reported on this data set so far.", "labels": [], "entities": [{"text": "f-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9935004115104675}]}], "introductionContent": [{"text": "Anaphora Resolution (AR) is a well established task in Natural Language Processing).", "labels": [], "entities": [{"text": "Anaphora Resolution (AR)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8236338675022126}]}, {"text": "Classification techniques (e.g., single candidate model aimed at answering: \"Is there a coreference link between the anaphor and this antecedent candidate, or not?\") are very often used for the task, e.g. in and.", "labels": [], "entities": []}, {"text": "However, as argued already in, better results are achieved when the candidates can compete in a pairwise fashion.", "labels": [], "entities": []}, {"text": "It can be explained by the fact that in this approach (called twin-candidate model), more information is available for the decision making.", "labels": [], "entities": [{"text": "decision making", "start_pos": 123, "end_pos": 138, "type": "TASK", "confidence": 0.8426736891269684}]}, {"text": "If we proceed further along this direction, we come to the ranking approach described in, in which the entire candidate set is considered at once and * The work on this project was supported by the grants MSM 0021620838, GAAV\u010cRGAAV\u02c7GAAV\u010cR 1ET101120503 and 1ET201120505, M \u02c7 SMT\u010cRSMT\u02c7SMT\u010cR LC536, and which leads to further significant shift in performance, more recently documented in Denis and Baldridge.", "labels": [], "entities": [{"text": "MSM 0021620838", "start_pos": 205, "end_pos": 219, "type": "DATASET", "confidence": 0.8057549893856049}, {"text": "M \u02c7 SMT\u010cRSMT\u02c7SMT\u010cR LC536", "start_pos": 270, "end_pos": 294, "type": "METRIC", "confidence": 0.6905530244112015}]}, {"text": "In this paper we deal with supervised approaches to pronominal anaphora in Czech.", "labels": [], "entities": []}, {"text": "For training and evaluation purposes, we use coreferences links annotated in the Prague Dependency Treebank,).", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 81, "end_pos": 107, "type": "DATASET", "confidence": 0.9655846754709879}]}, {"text": "We limit ourselves only to textual coreference (see Section 2) and to personal and possessive pronouns.", "labels": [], "entities": [{"text": "textual coreference", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.6327272802591324}]}, {"text": "We make use of a rich set of features available thanks to the complex annotation scenario of the treebank.", "labels": [], "entities": []}, {"text": "We experiment with two of the above mentioned techniques for AR: a classifier and a ranker.", "labels": [], "entities": []}, {"text": "The former is based on a top-down induction of decision trees.", "labels": [], "entities": []}, {"text": "The latter uses a simple scoring function whose optimal weight vector is estimated using perceptron learning inspired by.", "labels": [], "entities": []}, {"text": "We try to provide both implementations with as similar input information as possible in order to be able to compare their performance for the given task.", "labels": [], "entities": []}, {"text": "Performance of the presented systems can be compared with several already published works, namely with a rule-based system described in Ku\u010dov\u00e1 and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y (2005), some of the \"classical\" algorithms implemented in N\u011bm\u010d\u00edk (2006), a system based on decision trees (), and a rule-based system evaluated in Ngu . y and\u017dabokrtsk\u00b4y and\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y.", "labels": [], "entities": [{"text": "Ngu . y", "start_pos": 336, "end_pos": 343, "type": "DATASET", "confidence": 0.8892710407574972}]}, {"text": "To illustrate the real complexity of the task, we also provide performance evaluation of a baseline solution.", "labels": [], "entities": []}, {"text": "The most important result claimed in this paper is that, to the best of our knowledge, the presented ranker system outperforms all the previously published systems evaluated on the PDT data.", "labels": [], "entities": [{"text": "PDT data", "start_pos": 181, "end_pos": 189, "type": "DATASET", "confidence": 0.799873948097229}]}, {"text": "Moreover, the performance of our ranker (fscore 79.43%) for Czech data is not far from the performance of the state-of-the-art system for English described in Denis and Baldridge (2008) (fscore for 3rd person pronouns 82.2 %).", "labels": [], "entities": [{"text": "Czech data", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.7879795730113983}]}, {"text": "A side product of this work lies in bringing empirical evidence -for a different language and different data set -for the claim of that the ranking approach is more appropriate for the task of AR than the classification approach.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "The data with manually annotated links we use are described in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 outlines preprocessing the data for training and evaluation purposes.", "labels": [], "entities": []}, {"text": "The classifier-based and ranker-based systems are described in Section 4 and Section 5 respectively.", "labels": [], "entities": []}, {"text": "Section 6 summarizes the achieved results by evaluating both approaches using the test data.", "labels": [], "entities": []}, {"text": "Conclusions and final remarks follow in Section 7.) is a large collection of linguistically annotated data and documentation, based on the theoretical framework of Functional Generative Description (FGD; introduced by and later elaborated, e.g. in by).", "labels": [], "entities": [{"text": "Functional Generative Description (FGD", "start_pos": 164, "end_pos": 202, "type": "TASK", "confidence": 0.6558009028434754}]}, {"text": "The PDT 2.0 data are Czech newspaper texts selected from the Czech National Corpus 4 (CNC).", "labels": [], "entities": [{"text": "PDT 2.0 data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8519388635953268}, {"text": "Czech newspaper texts selected from the Czech National Corpus 4 (CNC)", "start_pos": 21, "end_pos": 90, "type": "DATASET", "confidence": 0.8269937978341029}]}, {"text": "The PDT 2.0 has a three-level structure.", "labels": [], "entities": [{"text": "PDT 2.0", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9406029284000397}]}, {"text": "On the lowest morphological level, a lemma and a positional morphological tag are added to each token.", "labels": [], "entities": []}, {"text": "The middle analytical level represents each sentence as a surface-syntactic dependency tree.", "labels": [], "entities": []}, {"text": "On the highest tectogrammatical level, each sentence is represented as a complex deep-syntactic depen-dency tree, see Mikulov\u00e1 and others (2005) for details.", "labels": [], "entities": []}, {"text": "This level includes also annotation of coreferential links.", "labels": [], "entities": []}, {"text": "The PDT 2.0 contains 3,168 newspaper texts (49,431 sentences) annotated on the tectogrammatical level.", "labels": [], "entities": [{"text": "PDT 2.0", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9384897649288177}]}, {"text": "Coreference has been annotated manually in all this data.", "labels": [], "entities": []}, {"text": "Following the FGD, there are two types of coreference distinguished: grammatical coreference and textual coreference.", "labels": [], "entities": [{"text": "FGD", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.9369845390319824}]}, {"text": "The main difference between the two coreference types is that the antecedent in grammatical coreference can be identified using grammatical rules and sentence syntactic structure, whereas the antecedent in textual coreference cannot.", "labels": [], "entities": []}, {"text": "The further division of grammatical and textual coreference is based on types of anaphors: Grammatical anaphors: relative pronouns, reflexive pronouns, reciprocity pronouns, restored (surface-unexpressed) \"subjects\" of infinitive verbs below verbs of control, Textual anaphors: personal and possessive pronouns, demonstrative pronouns.", "labels": [], "entities": []}, {"text": "The data in the PDT 2.0 are divided into three groups: training set (80%), development test set (10%), and evaluation test set (10%).", "labels": [], "entities": [{"text": "PDT 2.0", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.7201366126537323}]}, {"text": "The training and development test set can be freely exploited, while the evaluation test data should serve only for the very final evaluation of developed tools.", "labels": [], "entities": []}, {"text": "shows the distribution of each anaphor type.", "labels": [], "entities": []}, {"text": "The total number of coreference links in the PDT 2.0 data is 45,174.", "labels": [], "entities": [{"text": "PDT 2.0 data", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.9591095447540283}]}, {"text": "Personal pronouns including those zero ones and possessive pronouns form 37.4% of all anaphors in the entire corpus.", "labels": [], "entities": []}, {"text": "An example tectogrammatical tree with depicted coreference links (arrows) is presented in.", "labels": [], "entities": []}, {"text": "For the sake of simplicity, only three node attributes are displayed below the nodes: tectogrammatical lemma, functor, and semantic part of speech (tectogrammatical nodes themselves are complex data structures and around twenty attributes might be stored with them).", "labels": [], "entities": []}, {"text": "Tectogrammatical lemma is a canonical word form or an artificial value of a newly created node on the tectogrammatical level.", "labels": [], "entities": []}, {"text": "E.g. the (artificial) tectogrammatical lemma #PersPron stands for personal (and possessive) pronouns, be they expressed on the surface (i.e., present in the original sentence) or restored during the annotation of the tectogrammatical tree structure (zero pronouns).", "labels": [], "entities": []}, {"text": "Functor captures the deep-syntactic dependency relation between anode and its governor in the tectogrammatical tree.", "labels": [], "entities": []}, {"text": "According to FGD, functors are divided into actants (ACT -actor, PATpatient, ADDR -addressee, etc.) and free modifiers (LOC -location, BEN -benefactor, RHEM -rhematizer, TWHEN -temporal modifier, APP -appurtenance, etc.).", "labels": [], "entities": [{"text": "FGD", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.9072333574295044}, {"text": "BEN", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.9899041056632996}]}, {"text": "Semantic parts of speech correspond to basic onomasiological categories (substance, feature, factor, event).", "labels": [], "entities": []}, {"text": "The main semantic POS distinguished in PDT 2.0 are: semantic nouns, semantic adjectives, semantic adverbs and semantic verbs (for example, personal and possessive pronouns belong to semantic nouns).", "labels": [], "entities": []}], "datasetContent": [{"text": "Scores for all three systems (baseline, clasifier with and without fallback, ranker) are given in Table 3.", "labels": [], "entities": []}, {"text": "Our baseline system based on the combination of three rules (BASE 3+2+1) reports results superior to the ones of the rule-based system described in Ku\u010dov\u00e1 and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y (2005).", "labels": [], "entities": [{"text": "BASE", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9809895157814026}]}, {"text": "Ku\u010dov\u00e1 and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y proposed a set of filters for personal pronominal anaphora resolution.", "labels": [], "entities": [{"text": "personal pronominal anaphora resolution", "start_pos": 83, "end_pos": 122, "type": "TASK", "confidence": 0.6717438772320747}]}, {"text": "The list of candidates was built from the preceding and the same sentence as the personal pronoun.", "labels": [], "entities": []}, {"text": "After applying each filter, improbable candidates were cutoff.", "labels": [], "entities": []}, {"text": "If there was more than one candidate left at the end, the nearest one to the anaphor was chosen as its antecedent.", "labels": [], "entities": []}, {"text": "The reported final success rate was 60.4 % (counted simply as the number of correctly predicted links divided by the number of pronoun anaphors in the test data section).", "labels": [], "entities": []}, {"text": "An interesting point of the classifier-based system lies in the comparison with the rule-based: Precision (P), Recall (R) and F-measure (F) results for the presented AR systems.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 96, "end_pos": 109, "type": "METRIC", "confidence": 0.9484944641590118}, {"text": "Recall (R)", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9476298540830612}, {"text": "F-measure (F)", "start_pos": 126, "end_pos": 139, "type": "METRIC", "confidence": 0.9395760297775269}]}, {"text": "system of Ngu . y and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y (2007).", "labels": [], "entities": [{"text": "Ngu . y and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y (2007)", "start_pos": 10, "end_pos": 70, "type": "DATASET", "confidence": 0.9281972391264779}]}, {"text": "Without the rule-based fallback (CLASS), the classifier falls behind the Ngu . y and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y's system (74.2%), while including the fallback (CLASS+3+2+1) it gives better results.", "labels": [], "entities": [{"text": "Ngu . y and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y's", "start_pos": 73, "end_pos": 128, "type": "DATASET", "confidence": 0.9465705156326294}]}, {"text": "Overall, the ranker-based system (RANK) significantly outperforms all other AR systems for Czech with the f-score of 79.43%.", "labels": [], "entities": [{"text": "ranker-based system (RANK)", "start_pos": 13, "end_pos": 39, "type": "METRIC", "confidence": 0.9259461045265198}, {"text": "f-score", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.9968234300613403}]}, {"text": "Comparing with the model for third person pronouns of, which reports the f-score of 82.2%, our ranker is not so far behind.", "labels": [], "entities": [{"text": "f-score", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.9590712785720825}]}, {"text": "It is important to say that our system relies on manually annotated information 20 and we solve the task of anaphora resolution for third person pronouns on the tectogrammatical level of the PDT 2.0.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7433783411979675}, {"text": "PDT 2.0", "start_pos": 191, "end_pos": 198, "type": "DATASET", "confidence": 0.8440134823322296}]}, {"text": "That means these pronouns are not only those expressed on the surface, but also artificially added (reconstructed) into the structure according to the principles of FGD.", "labels": [], "entities": [{"text": "FGD", "start_pos": 165, "end_pos": 168, "type": "DATASET", "confidence": 0.8965046405792236}]}], "tableCaptions": [{"text": " Table 1: Distribution of the different anaphor  types in the PDT 2.0.", "labels": [], "entities": [{"text": "PDT 2.0", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.8925416767597198}]}, {"text": " Table 3: Precision (P), Recall (R) and F-measure  (F) results for the presented AR systems.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9422470778226852}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.959668830037117}, {"text": "F-measure  (F)", "start_pos": 40, "end_pos": 54, "type": "METRIC", "confidence": 0.9643752127885818}]}]}