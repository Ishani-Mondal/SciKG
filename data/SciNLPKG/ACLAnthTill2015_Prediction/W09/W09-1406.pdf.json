{"title": [{"text": "A Markov Logic Approach to Bio-Molecular Event Extraction", "labels": [], "entities": [{"text": "Bio-Molecular Event Extraction", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.7110775510470072}]}], "abstractContent": [{"text": "In this paper we describe our entry to the BioNLP 2009 Shared Task regarding bio-molecular event extraction.", "labels": [], "entities": [{"text": "BioNLP 2009 Shared Task", "start_pos": 43, "end_pos": 66, "type": "DATASET", "confidence": 0.7413273602724075}, {"text": "bio-molecular event extraction", "start_pos": 77, "end_pos": 107, "type": "TASK", "confidence": 0.604597270488739}]}, {"text": "Our work can be described by three design decisions: (1) instead of building a pipeline using local classier technology, we design and learn a joint probabilistic model over events in a sentence; (2) instead of developing spe-cic inference and learning algorithms for our joint model, we apply Markov Logic, a general purpose Statistical Relation Learning language, for this task; (3) we represent events as relational structures over the tokens of a sentence, as opposed to structures that explicitly mention abstract event entities.", "labels": [], "entities": [{"text": "Statistical Relation Learning language", "start_pos": 326, "end_pos": 364, "type": "TASK", "confidence": 0.7983606606721878}]}, {"text": "Our results are competitive: we achieve the 4th best scores for task 1 (in close range to the 3rd place) and the best results for task 2 with a 13 percent point margin.", "labels": [], "entities": []}, {"text": "1 Introduction The continuing rapid development of the Inter-net makes it very easy to quickly access large amounts of data online.", "labels": [], "entities": [{"text": "Inter-net", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.9209012389183044}]}, {"text": "However, it is impossible fora single human to read and comprehend a signicant fraction of the available information.", "labels": [], "entities": []}, {"text": "Genomics is not an exception, with databases such as MEDLINE storing avast amount of biomedical knowledge.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.8667495250701904}]}, {"text": "A possible way to overcome this is information extraction (IE) based on natural language processing (NLP) techniques.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.8746818780899048}]}, {"text": "One specic IE sub-task concerns the extraction of molecular events that are mentioned in biomedical literature.", "labels": [], "entities": [{"text": "IE", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9802470207214355}]}, {"text": "In order to drive forward research in this domain, the BioNLP Shared task 2009 (Kim et al., 2009) concerned the extraction of such events from text.", "labels": [], "entities": [{"text": "BioNLP Shared task 2009", "start_pos": 55, "end_pos": 78, "type": "DATASET", "confidence": 0.6075632572174072}]}, {"text": "In the course of the shared task the organizers provided a training/development set of abstracts for biomedical papers, annotated with the mentioned events.", "labels": [], "entities": []}, {"text": "Participants were required to use this data in order to engineer a event predictor which was then evaluated on unseen test data.", "labels": [], "entities": []}, {"text": "The shared task covered three sub-tasks.", "labels": [], "entities": []}, {"text": "The rst task concerned the extraction of events along with their clue words and their main arguments.", "labels": [], "entities": [{"text": "extraction of events", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8789191842079163}]}, {"text": "Figure 1 shows atypical example.", "labels": [], "entities": []}, {"text": "The second task was an extension of the rst one, requiring participants to not only predict the core arguments of each event, but also the cellular locations the event is associated within the text.", "labels": [], "entities": []}, {"text": "The events in this task were similar in nature to those in gure 1, but would also contain arguments that are neither events nor proteins but cellular location terms.", "labels": [], "entities": []}, {"text": "In contrast to the protein terms, cellular location terms were not given as input and had to be predicted, too.", "labels": [], "entities": []}, {"text": "Finally, for task 3 participants were asked to extract negations and speculations regarding events.", "labels": [], "entities": []}, {"text": "However, in our work we only tackled Task 1 and Task 2, and hence we omit further details on Task 3 for brevity.", "labels": [], "entities": []}, {"text": "Our approach to biomedical event extraction is inspired by recent work on Semantic Role Labelling (Meza-Ruiz and Riedel, 2009; Riedel and Meza-Ruiz, 2008) and can be characterized by three decisions that we will illustrate in the following.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6845611532529196}, {"text": "Semantic Role Labelling", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7015967965126038}]}, {"text": "First, we do not build a pipelined system that rst predicts event clues and cellular locations, and then relations between these; in-41 stead, we design and learn a joint discrimina-tive model of the complete event structure fora given sentence.", "labels": [], "entities": []}, {"text": "This allows us to incorporate global correlations between decisions in a prin-cipled fashion.", "labels": [], "entities": []}, {"text": "For example, we know that any event that has arguments which itself are events (such as the positive regulation event in gure 1) has to be a regulation event.", "labels": [], "entities": []}, {"text": "This means that when we make the decision about the type of an event (e.g., in the rst step of a classica-tion pipeline) independently from the decisions about its arguments and their type, we run the risk of violating this constraint.", "labels": [], "entities": []}, {"text": "However, in a joint model this can be easily avoided.", "labels": [], "entities": []}, {"text": "Our second design choice is the following: instead of designing and implementing specic inference and training methods for our structured model, we use Markov Logic, a Statistical Re-lational Learning language, and dene our global model declaratively.", "labels": [], "entities": []}, {"text": "This simplied the implementation of our system signicantly, and allowed us to construct a very competitive event extractor in three person-months.", "labels": [], "entities": []}, {"text": "For example, the above observation is captured by the simple formula: eventT ype (e, t) \u2227 role (e, a, r) \u2227 event (a) \u21d2 regT ype (t) (1) Finally, we represent event structures as rela-tional structures over tokens of a sentence, as opposed to structures that explicitly mention abstract event entities (compare gure 1 and 2).", "labels": [], "entities": []}, {"text": "The reason is as follows.", "labels": [], "entities": []}, {"text": "Markov Logic, for now,", "labels": [], "entities": [{"text": "Markov Logic", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8144596517086029}]}], "introductionContent": [{"text": "The continuing rapid development of the Internet makes it very easy to quickly access large amounts of data online.", "labels": [], "entities": []}, {"text": "However, it is impossible fora single human to read and comprehend a signicant fraction of the available information.", "labels": [], "entities": []}, {"text": "Genomics is not an exception, with databases such as MEDLINE storing avast amount of biomedical knowledge. were not given as input and had to be predicted, too.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.8760180473327637}]}, {"text": "Finally, for task 3 participants were asked to extract negations and speculations regarding events.", "labels": [], "entities": []}, {"text": "However, in our work we only tackled eventT ype (e, t) \u2227 role (e, a, r) \u2227 event (a) \u21d2 regT ype (t) Finally, we represent event structures as relational structures over tokens of a sentence, as opposed to structures that explicitly mention abstract event entities (compare gure 1 and 2).", "labels": [], "entities": []}, {"text": "The reason is as follows.", "labels": [], "entities": []}, {"text": "Markov Logic, for now, is tailored to link prediction problems where we may make inferences about the existence of relations between given entities.", "labels": [], "entities": [{"text": "Markov Logic", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7309072017669678}, {"text": "link prediction", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8220980763435364}]}, {"text": "However, when the identity and number of objects of our domain is unknown, things become more complicated.", "labels": [], "entities": []}, {"text": "By mapping to relational structure over grounded text, we also show a direct connection to recent formulations of Semantic Role Labelling which maybe helpful in the future.", "labels": [], "entities": [{"text": "Semantic Role Labelling", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.790854811668396}]}, {"text": "The remainder of this paper is organized as follows: we will rst present the preprocessing steps we perform (section 2), then the conversion to a link prediction problem (section 3).", "labels": [], "entities": [{"text": "link prediction", "start_pos": 146, "end_pos": 161, "type": "TASK", "confidence": 0.7657303512096405}]}, {"text": "Subsequently, we will describe Markov Logic (section 4) and our Markov Logic Network for event ex- Figure 1: Example gold annotation for task 1 of the shared task.", "labels": [], "entities": []}, {"text": "traction (section 5).", "labels": [], "entities": []}, {"text": "Finally, we present our results (in section 6) and conclude (section 7).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: (R)ecall, (P)recision, and (F)-Score for task  1 and 2 in terms of event types.", "labels": [], "entities": [{"text": "recision", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.883934736251831}, {"text": "F)-Score", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.6649354894955953}]}]}