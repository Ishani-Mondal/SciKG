{"title": [{"text": "Automatic Scoring of Children's Read-Aloud Text Passages and Word Lists", "labels": [], "entities": [{"text": "Automatic Scoring of Children's Read-Aloud Text Passages and Word Lists", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.7493701712651686}]}], "abstractContent": [{"text": "Assessment of reading proficiency is typically done by asking subjects to read a text passage silently and then answer questions related to the text.", "labels": [], "entities": [{"text": "reading proficiency", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7345817983150482}]}, {"text": "An alternate approach, measuring reading-aloud proficiency, has been shown to correlate well with the aforementioned common method and is used as a paradigm in this paper.", "labels": [], "entities": []}, {"text": "We describe a system that is able to automatically score two types of children's read speech samples (text passages and word lists), using automatic speech recognition and the target criterion \"correctly read words per minute\".", "labels": [], "entities": []}, {"text": "Its performance is dependent on the datatype (passages vs. word lists) as well as on the relative difficulty of passages or words for individual readers.", "labels": [], "entities": []}, {"text": "Pearson correlations with human assigned scores are around 0.86 for passages and around 0.80 for word lists.", "labels": [], "entities": []}], "introductionContent": [{"text": "It has long been noted that a substantial number of U.S. students in the 10-14 years age group have deficiencies in their reading competence).", "labels": [], "entities": []}, {"text": "With the enactment of the No Child Left Behind Act (2002), interest and focus on objectively assessing and improving this unsatisfactory situation has come to the forefront.", "labels": [], "entities": []}, {"text": "While assessment of reading is usually done posthoc with measures of reading comprehension, direct reading assessment is also often performed using a different method, oral (read-aloud) reading.", "labels": [], "entities": []}, {"text": "In this paradigm, students read texts aloud and their proficiency in terms of speed, fluency, pronunciation, intonation etc.", "labels": [], "entities": [{"text": "speed", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.9830533862113953}]}, {"text": "can be monitored directly while reading is in progress.", "labels": [], "entities": []}, {"text": "In the reading research literature, oral reading has been one of the best diagnostic and predictive measures of foundational reading weaknesses and of overall reading ability (e.g.,).", "labels": [], "entities": []}, {"text": "An association between low reading comprehension and slow, inaccurate reading rate has been confirmed repeatedly in middle school populations (e.g.,).", "labels": [], "entities": []}, {"text": "Correlations consistently fall in the 0.65-0.7 range for predicting untimed passage reading comprehension test outcomes (.", "labels": [], "entities": [{"text": "predicting untimed passage reading comprehension test", "start_pos": 57, "end_pos": 110, "type": "TASK", "confidence": 0.8055573999881744}]}, {"text": "In this paper, we investigate the feasibility of large-scale, automatic assessment of read-aloud speech of middle school students with a reasonable degree of accuracy (these students typically attend grades 6-8 and their age is in the 10-14 years range).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9980813264846802}]}, {"text": "If possible, this would improve the utility of oral reading as a large-scale, school-based assessment technique, making it more efficient by saving costs and time of human annotations and grading of reading errors.", "labels": [], "entities": []}, {"text": "The most widely used measure of oral reading proficiency is \"correctly read words per minute\" (cwpm) (.", "labels": [], "entities": [{"text": "correctly read words per minute\" (cwpm)", "start_pos": 61, "end_pos": 100, "type": "METRIC", "confidence": 0.7877616220050387}]}, {"text": "To obtain this measure, students' read speech samples are first recorded, then the reading time is determined, and finally a human rater has to listen to the recording and note all reading errors and sum them up.", "labels": [], "entities": []}, {"text": "Reading errors are categorized into word substitutions, deletions etc.", "labels": [], "entities": [{"text": "word substitutions", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6692235171794891}]}, {"text": "We have several sets of digitally recorded readaloud samples from middle school students available which were not collected for use with automatic speech recognition (ASR) but which were scored by hand.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 137, "end_pos": 171, "type": "TASK", "confidence": 0.7909772495428721}]}, {"text": "Our approach here is to pass the children's speech samples through an automatic speech recognizer and then to align its output word hypotheses with the original text that was read by the student.", "labels": [], "entities": []}, {"text": "From this alignment and from the reading time, an estimate for the above mentioned measure of cwpm can then be computed.", "labels": [], "entities": []}, {"text": "If the automatically computed cwpm measures are close enough to those obtained by human hand-scoring, this process maybe employed in real world settings eventually to save much time and money.", "labels": [], "entities": []}, {"text": "Recognizing children's speech, however, has been shown to be substantially harder than adult speech (), which is partly due to children's higher degree of variability in different dimensions of language such as pronunciation or grammar.", "labels": [], "entities": [{"text": "Recognizing children's speech", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8459206521511078}]}, {"text": "In our data, there was also a substantial number of non-native speakers of English, presenting additional challenges.", "labels": [], "entities": []}, {"text": "We used targeted training and adaptation of our ASR systems to achieve reasonable word accuracies.", "labels": [], "entities": [{"text": "ASR", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.983017086982727}]}, {"text": "While for text passages, the word accuracy on unseen speakers was about 72%, it was only about 50% for word lists, which was due in part to a higher percentage of non-native speakers in this data set, to the fact that various sources of noise often prevented the recognizer from correctly locating the spoken words in the signal, and also due to our choice of a uniform language model since conventional n-gram models did notwork on this data with many silences and noises between words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8994342088699341}]}, {"text": "The remainder of this paper is organized as follows: in Section 2 we review related work, followed by a description of our data in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 provides a brief description of our speech recognizer as well as the experimental setup.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.705652117729187}]}, {"text": "Section 5 provides the results of our experiments, followed by a discussion in Section 6 and conclusions and future work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The ASR system's acoustic model (AM) was trained using portions of the OGI and CMU Kids' corpora as well as a randomly selected sub-set of our own passage and word list data sets described in the previous section.", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9515542387962341}, {"text": "OGI and CMU Kids' corpora", "start_pos": 71, "end_pos": 96, "type": "DATASET", "confidence": 0.8395654678344726}]}, {"text": "About 90% of each data set (Set1, Set2, Set3) was used for that purpose.", "labels": [], "entities": []}, {"text": "Since the size of our own data set was too small for AM training, we had to augment it with the two mentioned corpora (OGI, CMU Kids), although they were not a perfect match in age range and accent.", "labels": [], "entities": [{"text": "AM training", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.9355187714099884}, {"text": "OGI, CMU Kids", "start_pos": 119, "end_pos": 132, "type": "DATASET", "confidence": 0.6424842327833176}]}, {"text": "All recordings were first converted and downsampled to 11 kHz, mono, 16 bit resolution, PCM format.", "labels": [], "entities": []}, {"text": "There was no speaker overlap between training and test sets.", "labels": [], "entities": []}, {"text": "For the language model (LM), two different models were created: for passages, we built an interpolated trigram LM where 90% of the weight is assigned to a LM trained only on the 4 passages from the training set (Set1, Set2) and 10% to a generic LM using the Linguistic Data Consortium (LDC) Broadcast News corpus (LDC, 1997).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC) Broadcast News corpus (LDC, 1997)", "start_pos": 258, "end_pos": 324, "type": "DATASET", "confidence": 0.812082439661026}]}, {"text": "The dictionary contains all words from the transcribed passages in the training set, augmented with the 1,000 most frequent words from the Broadcast News corpus.", "labels": [], "entities": [{"text": "Broadcast News corpus", "start_pos": 139, "end_pos": 160, "type": "DATASET", "confidence": 0.9271366198857626}]}, {"text": "That way, the LM is not too restrictive and allows the recognizer to hypothesize some reading mistakes not already encountered in the human transcriptions of the training set.", "labels": [], "entities": []}, {"text": "For the word lists, a trigram LM was found to be not working well since the words were spoken in isolation with sometimes significant pauses in between and automatic removal of these silences proved too hard given other confounding factors such as microphone, speaker, or background noise.", "labels": [], "entities": [{"text": "trigram LM", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.7071215510368347}]}, {"text": "Therefore it was decided to implement a grammar LM for the word list decoder where all possible words are present in a network that allows them to occur at anytime and in any sequence, allowing for silence and/or noises in between words.", "labels": [], "entities": []}, {"text": "This model with uniform priors, however, has the disadvantage of not including any words not present in the word list training set, such as common mispronunciations and is therefore more restrictive than the LM for text passages.", "labels": [], "entities": []}, {"text": "One could make the argument of using forced alignment instead of a statistical LM to determine reading errors.", "labels": [], "entities": []}, {"text": "In fact, this approach is typically used when assessing the pronunciation of read speech.", "labels": [], "entities": [{"text": "assessing the pronunciation of read speech", "start_pos": 46, "end_pos": 88, "type": "TASK", "confidence": 0.7075920800367991}]}, {"text": "However, in our case, the interest is more in determining how many words were read correctly in the sequence of the text (and how fast they were read) as opposed to details in pronunciation.", "labels": [], "entities": []}, {"text": "Further, even if we had confidence scores attached to words in forced alignment, deciding on which of the words obtained low confidence due to poor pronunciation or due to substitution would not bean easy decision.", "labels": [], "entities": []}, {"text": "Finally, word deletions and insertions, if too frequent, might prevent the forced alignment algorithm from terminating.", "labels": [], "entities": []}, {"text": "After training was complete, we tested the recognizer on the held-out passage and word list data.", "labels": [], "entities": []}, {"text": "After recognizing, we computed our target measure of \"correct words per minute\" (cwpm) according to the following formula (W= all words in a text, S= substitutions, D= deletions, T= reading time in minutes), performing a string alignment between the recognizer hypothesis and the passage or word list to be read: The reason that insertions are not considered here is that they contribute to an increase in reading time and therefore can be considered to be accounted for already in the formula.", "labels": [], "entities": []}, {"text": "Next, we performed an experiment that looks at whether automatic scoring of read-aloud speech allows for accurate predictions of student placements in broad cohorts of reading proficiency.", "labels": [], "entities": []}, {"text": "We then also look more closely at typical errors made by human readers and the speech recognizer.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.6754535585641861}]}, {"text": "All these experiments are described and discussed in the following section.", "labels": [], "entities": []}, {"text": "describes the set-up of the experiments.", "labels": [], "entities": []}, {"text": "Note that Passage4 (Set2) was included only in the training but not in the evaluation set since this set was very small.", "labels": [], "entities": [{"text": "Passage4", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.6207329630851746}]}, {"text": "As mentioned in the previous section, most speakers from the passage sets read more than one passage and a few speakers from the word lists set read more than one word list.", "labels": [], "entities": []}, {"text": "To followup on the encouraging results with basic and rank correlation, we conducted an experiment to explore the question of practical importance whether the automatic system can assign students to reading proficiency cohorts automatically.", "labels": [], "entities": [{"text": "basic and rank correlation", "start_pos": 44, "end_pos": 70, "type": "METRIC", "confidence": 0.7863747477531433}]}, {"text": "For better comparison, we selected those 27 students from 37 total who read all 3 passages (Set 1) and grouped them into three cohorts of 9 students each, based on their human generated cwpm score for all passages combined: (a) proficient (cwpm>190), (b) intermediate, and (c) low proficient (cwpm<135).", "labels": [], "entities": []}, {"text": "We then had the automatic system predict each student's cohort based on the cwpm computed from ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.5532777905464172}]}, {"text": "Since ASR-based cwpm values are consistently lower than human annotator based cwpm values, the automatic cohort assignment is not based on the cwpm values but rather on their ranking.", "labels": [], "entities": [{"text": "ASR-based cwpm", "start_pos": 6, "end_pos": 20, "type": "TASK", "confidence": 0.7877521812915802}]}, {"text": "The outcome of this experiment is very encouraging in that there were no cohort prediction errors by the automatic system.", "labels": [], "entities": []}, {"text": "While the precise ranking differs, the system is very well able to predict overall cohort placement of students based on cwpm.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Text passages and word lists data sets.", "labels": [], "entities": []}, {"text": " Table 3. ASR experiment results (word accuracies in percent)", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8064885139465332}, {"text": "word accuracies", "start_pos": 34, "end_pos": 49, "type": "METRIC", "confidence": 0.8571467399597168}]}, {"text": " Table 4. CWPM results for passages and word  lists. All correlations are significant at p<0.01.  *For word lists, we use \"cw\" (correct words, nu- merator of Equation", "labels": [], "entities": []}, {"text": " Table 5. Word error statistics on TRANS-TRUE  and HYPO-TRANS alignments for both evaluation  data sets.", "labels": [], "entities": []}, {"text": " Table 6. Top 5 most frequent confusion pairs for  passages and word list evaluation sets in two dif- ferent alignments. For passages, substitutions  among closed class words such as determiners or  prepositions are omitted.", "labels": [], "entities": []}, {"text": " Table 7. Statistics on matched errors: percentage of  students' reading errors (substitutions and dele- tions) that were also correctly identified by the  ASR system.", "labels": [], "entities": [{"text": "reading errors (substitutions and dele- tions", "start_pos": 65, "end_pos": 110, "type": "METRIC", "confidence": 0.7640404514968395}, {"text": "ASR", "start_pos": 156, "end_pos": 159, "type": "TASK", "confidence": 0.8666701912879944}]}]}