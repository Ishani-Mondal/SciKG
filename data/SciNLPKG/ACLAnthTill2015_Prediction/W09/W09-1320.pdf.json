{"title": [{"text": "Towards Retrieving Relevant Information for Answering Clinical Comparison Questions", "labels": [], "entities": [{"text": "Retrieving Relevant Information", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.9110531012217203}, {"text": "Answering Clinical Comparison Questions", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.9138646870851517}]}], "abstractContent": [{"text": "This paper introduces the task of automatically answering clinical comparison questions using MEDLINE \u00ae abstracts.", "labels": [], "entities": [{"text": "automatically answering clinical comparison questions", "start_pos": 34, "end_pos": 87, "type": "TASK", "confidence": 0.7083211302757263}, {"text": "MEDLINE \u00ae abstracts", "start_pos": 94, "end_pos": 113, "type": "DATASET", "confidence": 0.8120378653208414}]}, {"text": "In the beginning, clinical comparison questions and the main challenges in recognising and extracting their components are described.", "labels": [], "entities": []}, {"text": "Then, different strategies for retrieving MEDLINE \u00ae abstracts are shown.", "labels": [], "entities": [{"text": "retrieving MEDLINE \u00ae abstracts", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.6008539572358131}]}, {"text": "Finally, the results of an initial experiment judging the relevance of MEDLINE \u00ae abstracts retrieved by searching for the components of twelve comparison questions will be shown and discussed.", "labels": [], "entities": [{"text": "MEDLINE \u00ae abstracts", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.6636404097080231}]}], "introductionContent": [{"text": "Clinicians wishing to practice evidence-based medicine need to keep up with avast amount of ever changing research to be able to use the current best evidence in individual patient care.", "labels": [], "entities": []}, {"text": "This can be difficult for time-pressed clinicians, although methods such as systematic reviews, evidence summaries and clinical guidelines can help to translate research into practice.", "labels": [], "entities": []}, {"text": "Ina survey commissioned by Doctors.net.uk, 97% of doctors and nurses said that they would find a Question Answering (QA) Service useful, where they can ask questions in their own words.", "labels": [], "entities": [{"text": "Doctors.net.uk", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.9172695279121399}, {"text": "Question Answering (QA)", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.8287995278835296}]}, {"text": "Studies have also shown that clinicians often want answers to particular questions, rather than getting information on broad topics.", "labels": [], "entities": []}, {"text": "A type of question that clinicians commonly want answered are comparison questions.", "labels": [], "entities": []}, {"text": "Ina corpus of clinical questions collected from the National Library of Health (NLH) Question Answering Service (http://www.clinicalanswers.nhs.uk), approximately 16% of the 4580 questions concern comparisons of different drugs, different treatment methods or different interventions as in (1).", "labels": [], "entities": [{"text": "National Library of Health (NLH) Question Answering Service", "start_pos": 52, "end_pos": 111, "type": "DATASET", "confidence": 0.9209704220294952}]}, {"text": "(1) Have any studies directly compared the effects of Pioglitazone and Rosiglitazone on the liver?", "labels": [], "entities": []}, {"text": "Despite the frequency of comparison questions in the clinical domain, there are no clinical QA methods specially designed to answer them.", "labels": [], "entities": []}, {"text": "This paper introduces the task of answering clinical comparison questions, focusing initially on questions involving comparisons between drugs.", "labels": [], "entities": [{"text": "answering clinical comparison questions", "start_pos": 34, "end_pos": 73, "type": "TASK", "confidence": 0.8777637034654617}]}, {"text": "Section 2 presents an overview of comparative structures and Section 3, relevant previous work on clinical question answering and the computational extraction of comparisons.", "labels": [], "entities": [{"text": "clinical question answering", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.599379152059555}, {"text": "computational extraction of comparisons", "start_pos": 134, "end_pos": 173, "type": "TASK", "confidence": 0.7999813258647919}]}, {"text": "Section 4 discusses strategies for retrieving MEDLINE \u00ae abstracts involving comparisons.", "labels": [], "entities": [{"text": "retrieving MEDLINE \u00ae abstracts", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.6491179913282394}]}, {"text": "Section 5 presents the results of an initial experiment judging the relevance of MEDLINE \u00ae abstracts, which are then discussed in Section 6.", "labels": [], "entities": [{"text": "MEDLINE \u00ae abstracts", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.6246404349803925}]}], "datasetContent": [], "tableCaptions": []}