{"title": [{"text": "Using a maximum entropy-based tagger to improve a very fast vine parser", "labels": [], "entities": []}], "abstractContent": [{"text": "In this short paper, an off-the-shelf maximum entropy-based POS-tagger is used as a partial parser to improve the accuracy of an extremely fast linear time dependency parser that provides state-of-the-art results in multilingual unlabeled POS sequence parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9986938834190369}, {"text": "POS sequence parsing", "start_pos": 239, "end_pos": 259, "type": "TASK", "confidence": 0.589418371518453}]}], "introductionContent": [{"text": "The dependency parsing literature has grown in all directions the past 10 years or so.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8861561417579651}]}, {"text": "Dependency parsing is used in a wide variety of applications, and many different parsing techniques have been proposed.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8838931322097778}]}, {"text": "Two dependency parsers have become more popular than the rest, namely MSTParser () and MaltParser (.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.9162378311157227}]}, {"text": "MSTParser is slightly more accurate than MaltParser on most languages, especially when dependencies are long and non-projective, but MaltParser is theoretically more efficient as it runs in linear time.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9139426350593567}]}, {"text": "Both are relatively slow in terms of training (hours, sometimes days), and relatively big models are queried in parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 112, "end_pos": 119, "type": "TASK", "confidence": 0.9648145437240601}]}, {"text": "MSTParser and MaltParser can be optimized for speed in various ways, 1 but the many applications of dependency parsers today may turn model size into a serious problem.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9361365437507629}]}, {"text": "MSTParser typically takes about a minute to parse a small standard test suite, say 2-300 sentences; the stand-alone version of MaltParser may take 5-8 minutes.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9198895692825317}]}, {"text": "Such parsing times are problematic in, say, a machine translation system where for each sentence pair multiple Recent work has optimized MaltParser considerably for speed.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7217151373624802}]}, {"text": "speedup the MaltParser by a factor of 30 by simplifying the decision function for the classifiers.", "labels": [], "entities": []}, {"text": "Parsing is still considerably slower than with our vine parser, i.e. a test suite is parsed in about 15-20 seconds, whereas our vine parser parses a test suite in less than two seconds.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.576551079750061}]}, {"text": "target sentences are parsed (.", "labels": [], "entities": []}, {"text": "Since training takes hours or days, researchers are also more reluctant to experiment with new features, and it is very likely that the features typically used in parsing are suboptimal in, say, machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 195, "end_pos": 214, "type": "TASK", "confidence": 0.6864978224039078}]}, {"text": "Conceptually simpler dependency parsers are also easier to understand, which makes debugging, cross-domain adaption or cross-language adaptation a lot easier.", "labels": [], "entities": [{"text": "cross-language adaptation", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.8061088919639587}]}, {"text": "Finally, state-of-the-art dependency parsers may in fact be outperformed by simpler systems on non-standard test languages with, say, richer morphology or more flexible word order.", "labels": [], "entities": []}, {"text": "Vine parsing is a parsing strategy that guarantees fast parsing and smaller models, but the accuracy of dependency-based vine parsers has been non-competitive).", "labels": [], "entities": [{"text": "Vine parsing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7163094580173492}, {"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9739431142807007}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9979726672172546}, {"text": "dependency-based vine parsers", "start_pos": 104, "end_pos": 133, "type": "TASK", "confidence": 0.6973557670911154}]}, {"text": "This paper shows how the accuracy of dependency-based vine parsers can be improved by 1-5% across six very different languages with a very small cost in training time and practically no cost in parsing time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9989264607429504}, {"text": "dependency-based vine parsers", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.6236373881498972}, {"text": "parsing", "start_pos": 194, "end_pos": 201, "type": "TASK", "confidence": 0.974622368812561}]}, {"text": "The main idea in our experiments is to use a maximum entropy-based part-of-speech (POS) tagger to identify roots and tokens whose heads are immediately left or right of them.", "labels": [], "entities": []}, {"text": "These are tasks that a tagger can solve.", "labels": [], "entities": []}, {"text": "You simply read off a tagged text from the training, resp.", "labels": [], "entities": []}, {"text": "test, section of a treebank and replace all tags of roots, i.e. tokens whose syntactic head is an artificial root node, with anew tag ROOT.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.988495945930481}]}, {"text": "You then train on the training section and apply your tagger on the test section.", "labels": [], "entities": []}, {"text": "The decisions made by the tagger are then, subsequently, used as hard constraints by your parser.", "labels": [], "entities": []}, {"text": "When the parser then tries to find root nodes, for instance, it is forced to use the roots assigned by the tagger.", "labels": [], "entities": []}, {"text": "This strategy is meaningful if the tagger has better precision for roots than the parser.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9983499050140381}]}, {"text": "If it has better recall than the parser, the parser maybe forced to select roots only from the set of potential roots assigned by the tagger.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9981569647789001}]}, {"text": "In our experiments, only the first strategy was used (since the tagger's precision was typically better than its recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9942029118537903}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9990420937538147}]}, {"text": "The dependency parser used in our experiments is very simple.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.797772616147995}]}, {"text": "It is based on the Chu-LiuEdmonds algorithm, which is also used in the MSTParser (), but it is informed only by a simple MLE training procedure and omits cycle contraction in parsing.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 71, "end_pos": 80, "type": "DATASET", "confidence": 0.87198805809021}]}, {"text": "This means that it produces cyclic graphs.", "labels": [], "entities": []}, {"text": "In the context of poor training, insisting on acyclic output graphs often compromises accuracy by > 10%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.999212384223938}]}, {"text": "On top of this parser, which is super fast but often does not even outperform a simple structural baseline, hard and soft constraints on dependency length are learned discriminatively.", "labels": [], "entities": []}, {"text": "The speed of the parser allows us to repeatedly parse a tuning section to optimize these constraints.", "labels": [], "entities": []}, {"text": "In particular, the tuning section (about 7500 tokens) is parsed a fixed number of times for each POS/CPOS tag to find the optimal dependency length constraint when that tag is the tag of the head or dependent word.", "labels": [], "entities": [{"text": "POS/CPOS tag", "start_pos": 97, "end_pos": 109, "type": "DATASET", "confidence": 0.6270969361066818}]}, {"text": "In general, this discriminative training procedure takes about 10 minutes for an average-sized treebank.", "labels": [], "entities": []}, {"text": "The parser only produces unlabeled dependency graphs and is still underdevelopment.", "labels": [], "entities": []}, {"text": "While accuracy is below state-of-the-art results, our improved parser significantly outperforms a default version of the MaltParser that is restricted to POS tags only, on 5/6 languages (p \u2264 0.05), and it significantly outperforms the baseline vine parser on all languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9995453953742981}]}], "datasetContent": [{"text": "The Python/C++ implementation of the maximum entropy-based part-of-speech (POS) tagger first described in that comes with the maximum entropy library in was used to identify arcs to the root node and to tokens immediately left or right of the dependent.", "labels": [], "entities": []}, {"text": "This was done by first extracting a tagged text from each treebank with dependents of the root node assigned a special tag ROOT.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9737699031829834}]}, {"text": "Similarly, tagged texts were extracted in which dependents of their immediate left, resp.", "labels": [], "entities": []}, {"text": "right neighbors, were assigned a special tag.", "labels": [], "entities": []}, {"text": "Our tagger was trained on the texts extracted from the training sections of the treebanks and evaluated on the texts extracted from the test sections.", "labels": [], "entities": []}, {"text": "The number of gold standard, resp.", "labels": [], "entities": []}, {"text": "predicted, ROOT/LEFT/RIGHT tags are presented in.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9844604134559631}, {"text": "LEFT", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.7431141138076782}, {"text": "RIGHT", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.6426933407783508}]}, {"text": "Precision and f-score are also computed.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9953058362007141}, {"text": "f-score", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9681656360626221}]}, {"text": "Note that since our parser uses information from our tagger as hard constraints, i.e. it disregards arcs to the root node or immediate neighbors not predicted by our tagger, precision is really what is important, not f-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9989269375801086}]}, {"text": "Or more precisely, precision indicates if our tagger is of any help to us, and f-score tells us to what extent it maybe of help.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9995371103286743}]}], "tableCaptions": []}