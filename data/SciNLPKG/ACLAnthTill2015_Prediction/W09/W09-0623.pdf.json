{"title": [{"text": "Investigating Content Selection for Language Generation using Machine Learning", "labels": [], "entities": [{"text": "Investigating Content Selection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8325392603874207}, {"text": "Language Generation", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.709839940071106}]}], "abstractContent": [{"text": "The content selection component of a natural language generation system decides which information should be communicated in its output.", "labels": [], "entities": []}, {"text": "We use information from reports on the game of cricket.", "labels": [], "entities": []}, {"text": "We first describe a simple factoid-to-text alignment algorithm then treat content selection as a collective classification problem and demonstrate that simple 'group-ing' of statistics at various levels of granu-larity yields substantially improved results over a probabilistic baseline.", "labels": [], "entities": [{"text": "factoid-to-text alignment", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8290723860263824}, {"text": "content selection", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7157999128103256}]}, {"text": "We additionally show that holding back of specific types of input data, and linking database structures with commonality further increase performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Content selection is the task executed by a natural language generation (NLG) system of deciding, given a knowledge-base, which subset of the information available should be conveyed in the generated document.", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7904199063777924}, {"text": "natural language generation (NLG)", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.8035427331924438}]}, {"text": "Consider the task of generating a cricket match report, given the scorecard for that match.", "labels": [], "entities": []}, {"text": "Such a scorecard would typically contain a large number of statistics pertaining to the game as a whole as well as individual players (e.g. see).", "labels": [], "entities": []}, {"text": "Our aim is to identify which statistics should be selected by the NLG system.", "labels": [], "entities": [{"text": "NLG system", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.9285832047462463}]}, {"text": "Much work has been done in the field of content selection, in a diverse range of domains e.g. weather forecasts.", "labels": [], "entities": [{"text": "content selection", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7378953397274017}, {"text": "weather forecasts", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7308236360549927}]}, {"text": "Approaches are usually domain specific and predominantly based on structured tables of well-defined input data.", "labels": [], "entities": []}, {"text": "attempted a statistical approach to content selection using a substantial corpus of biographical summaries paired with selected content, where they extracted rules and patterns linking the two.", "labels": [], "entities": [{"text": "content selection", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7475290894508362}]}, {"text": "They then used machine learning to ascertain what was relevant.", "labels": [], "entities": []}, {"text": "extended this approach but applying it to a sports domain (American football), similarly viewing content selection as a classification task and additionally taking account of contextual dependencies between data, and found that this improved results compared to a content-agnostic baseline.", "labels": [], "entities": []}, {"text": "We aim throughout to extend and improve upon Barzilay and Lapata's methods.", "labels": [], "entities": []}, {"text": "We emphasise that content selection through statistical machine learning is a relatively new area -approaches prior to Duboue and McKeown's are, in principle, much less portable -and as such there is not an enormous body of work to build upon.", "labels": [], "entities": [{"text": "content selection", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.7506263554096222}]}, {"text": "This work offers a novel algorithm for data-totext alignment, presents anew 'grouping' method for sharing knowledge across similar but distinct learning instances and shows that holding back certain data from the machine learner, and reintroducing it later on can improve results.", "labels": [], "entities": [{"text": "data-totext alignment", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7382058799266815}]}], "datasetContent": [{"text": "The output of our program is the original text with all aligned figures and strings (factoids) replaced with their corresponding tag attributes.", "labels": [], "entities": []}, {"text": "We can see an extract from an aligned report in where we show the aligned factoids in bold, and their corresponding tag attributes in italics.", "labels": [], "entities": []}, {"text": "We also note at this point that much of commentary shown does not in fact appear in the scorecard, and therefore additional knowledge sources would typically be required to generate a full match report -this is beyond the scope of our paper, but attempts to deal with this problem in the domain of basketball using revision-based techniques for including additional content.", "labels": [], "entities": []}, {"text": "We asked a domain expert to evaluate five of our aligned match reports -he did this by creating his own 'gold standard' for each report, a list of aligned tags.", "labels": [], "entities": []}, {"text": "Compared to our automatically aligned tags, we obtained 79.0% average precision, 75.8% average recall and a mean F of 77.0%.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9373424053192139}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9499286413192749}, {"text": "F", "start_pos": 113, "end_pos": 114, "type": "METRIC", "confidence": 0.9913191199302673}]}, {"text": "It is not clear what constitutes a suitable baseline so we considered multiple options.", "labels": [], "entities": []}, {"text": "The issue of ambiguous reference baselines is not specific to the cricket domain, as there is no standardized baseline approach across the prior literature.", "labels": [], "entities": []}, {"text": "We employ ten-fold cross validation throughout.", "labels": [], "entities": []}, {"text": "The main difficulty we encountered arose when we came to assessing the Precision and Recall figures as we have yet to decide on what level we are considering the output of our system to be correct.", "labels": [], "entities": [{"text": "Precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9563724994659424}, {"text": "Recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.7096216678619385}]}, {"text": "We see three possibilities for the level: Category We could simply count the 'votes' predicted on a per category basis (as described in sections 3.1 and 5.1), and evaluate categories based on the number of votes given for each.", "labels": [], "entities": []}, {"text": "We would expect this to generate very good results as we are effectively overgrouping, once on a group basis (grouping together all attributes) and once on a category basis (unifying all groups within a category), but the output would be so general and trivial (effectively stating something to the effect that \"a match report should contain information about batting, bowling and team statistics\") that it would be of no use in an NLG system.", "labels": [], "entities": []}, {"text": "Groups Here we compare which 'groups' were verbalised within each category, and which were predicted to be verbalised (as we did for the Majority Baseline of Section 5.1).", "labels": [], "entities": []}, {"text": "Our implicit grouping means that we do not have to necessarily return the correct statistic pertaining to a group since each group acts as a basket for the statistics contained within it, and is susceptible to 'false positives'.", "labels": [], "entities": []}, {"text": "This method is most similar to B&L's.", "labels": [], "entities": [{"text": "B&L's", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.9335881471633911}]}, {"text": "Tags Since we are trying to establish which tag attributes should be included rather than which groups are likely to contain verbalised tag attributes, we could say that even the above method is too liberal in its definition of correctness.", "labels": [], "entities": []}, {"text": "Thus we also evaluate our groups on the basis of their component parts, i.e., if a particular group of tag attributes is estimated to be verbalised by BoosTexter, then we include all attributes from that group.", "labels": [], "entities": [{"text": "BoosTexter", "start_pos": 151, "end_pos": 161, "type": "DATASET", "confidence": 0.9316664338111877}]}], "tableCaptions": [{"text": " Table 1: Number of attributes per category with  percent verbalised (Verb)", "labels": [], "entities": [{"text": "Verb)", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9102305471897125}]}, {"text": " Table 2: Majority Baseline, B maj", "labels": [], "entities": [{"text": "B", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9763076305389404}]}, {"text": " Table 3: Probabilistic Baseline, B prob", "labels": [], "entities": []}, {"text": " Table 4: No-Player Probabilistic Baseline, B nops", "labels": [], "entities": []}, {"text": " Table 5: Categorized Groups with Best value for  T = 25.", "labels": [], "entities": []}, {"text": " Table 6: Categorized Tags Results", "labels": [], "entities": [{"text": "Categorized Tags", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7022824287414551}]}, {"text": " Table 7: Unassisted Boosting (UB), No Players  (NP) and Enhanced Categorization (EC). Best val- ues for T = 2250, 250 and 20 respectively.", "labels": [], "entities": [{"text": "Unassisted Boosting (UB)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.9147365689277649}, {"text": "Enhanced Categorization (EC)", "start_pos": 57, "end_pos": 85, "type": "METRIC", "confidence": 0.9446576952934265}, {"text": "val- ues", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9636686245600382}, {"text": "T", "start_pos": 105, "end_pos": 106, "type": "METRIC", "confidence": 0.9821880459785461}]}]}