{"title": [{"text": "A Japanese corpus of referring expressions used in a situated collaboration task", "labels": [], "entities": []}], "abstractContent": [{"text": "In order to pursue research on generating referring expressions in a situated collaboration task, we setup a data-collection experiment based on the Tangram puzzle.", "labels": [], "entities": []}, {"text": "For a pair of participants we recorded every utterance in synchronisation with the current state of the puzzle as well as all operations by the participants.", "labels": [], "entities": []}, {"text": "Referring expressions were annotated with their ref-erents in order to build a referring expression corpus in Japanese.", "labels": [], "entities": []}, {"text": "We provide preliminary results on the analysis of the corpus from various standpoints, focussing on action-mentioning expressions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Referring expressions area linguistic device to refer to a certain object, enabling smooth collaboration between humans and agents where physical operations are involved.", "labels": [], "entities": []}, {"text": "Previous research often either selectively focussed only on a limited number of expression-types or setup overly controlled experiments.", "labels": [], "entities": []}, {"text": "In contrast, we intend to work towards analysing the whole breadth of referring expressions in a situated domain.", "labels": [], "entities": []}, {"text": "For this purpose we created a corpus (in Japanese) and analysed it from various standpoints.", "labels": [], "entities": []}, {"text": "From very early on in referring expression research, there has been some interest in the collaborative aspect of the reference process.", "labels": [], "entities": [{"text": "referring expression research", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.915933092435201}]}, {"text": "This has more recently developed into creating situated corpora in order to analyse the referring expressions occurring in situated collaborative tasks.", "labels": [], "entities": []}, {"text": "The COCONUT corpus (Di) is collected from keyboard-input dialogues between two participants who are collaboratively working on a simple 2-D design task (buying and arranging furniture for two rooms).", "labels": [], "entities": [{"text": "COCONUT corpus (Di) is collected from keyboard-input dialogues between two participants who are collaboratively working on a simple 2-D design task (buying and arranging furniture for two rooms)", "start_pos": 4, "end_pos": 198, "type": "Description", "confidence": 0.7932194788008928}]}, {"text": "In contrast, the QUAKE corpus ( ) -as well as the more recent SCARE corpus (, which is an extension of QUAKE -is based on an interaction captured in a 3-D virtual reality (VR) world where two participants collaboratively carryout a treasure hunting task.", "labels": [], "entities": [{"text": "QUAKE corpus", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.872014582157135}, {"text": "SCARE corpus", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.7733558118343353}, {"text": "treasure hunting task", "start_pos": 232, "end_pos": 253, "type": "TASK", "confidence": 0.736383299032847}]}, {"text": "There has been ongoing work to exploit these two resources for research on different aspects of referring expressions (Pamela W..", "labels": [], "entities": []}, {"text": "However, while these resources have inspired new research into different aspects of referring expressions, at the same time they have clear limitations.", "labels": [], "entities": []}, {"text": "The COCONUT corpus is collected from dialogues in which participants refer to symbollike objects in a 2-D world.", "labels": [], "entities": [{"text": "COCONUT corpus", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8803814947605133}]}, {"text": "It thus resembles the more recent (non-collaborative) TUNAcorpus) in tending to encourage very simple types of expressions.", "labels": [], "entities": []}, {"text": "Furthermore, limiting participants' interaction to keyboard input makes the dialogue less natural.", "labels": [], "entities": []}, {"text": "While the QUAKE corpus deals with a more complex domain (3-D virtual world), the participating subjects were only able to carryout limited kinds of actions (pushing buttons, picking up or dropping objects) as compared with the complexity of the three-dimensional target domain.", "labels": [], "entities": [{"text": "QUAKE corpus", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.7942858040332794}]}, {"text": "In contrast to these two corpora, we setup a comparatively simple collaborative task (Tangram Puzzle) allowing participants to freely communicate via speech and to perform actions various enough to accomplish the given task, e.g. picking, moving, turning and rotating pieces.", "labels": [], "entities": []}, {"text": "All utterances by participants were recorded in synchronisation with operations on objects and the object arrangement.", "labels": [], "entities": []}, {"text": "The utterances were transcribed and all referring expressions found were annotated together with their referents.", "labels": [], "entities": []}, {"text": "Thus, this corpus allows us to study in detail human-human interaction, particularly referring expressions in a situated setting.", "labels": [], "entities": []}, {"text": "In what follows, we first describe details of the building of the corpus and then provide results of our preliminary analysis.", "labels": [], "entities": []}, {"text": "This analysis reveals a novel type of referring expression mentioning an action on objects, which we call actionmentioning expressions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We recruited 12 Japanese graduate students (4 females, 8 males) and split them into 6 pairs.", "labels": [], "entities": []}, {"text": "Each pair was instructed to solve the Tangram puzzle (an ancient Chinese geometrical puzzle) cooperatively.", "labels": [], "entities": []}, {"text": "The goal of Tangram is to construct a given shape by arranging seven pieces of simple figures as shown in.", "labels": [], "entities": []}, {"text": "In order to record detailed information of the interaction (position of pieces, participants' actions), we implemented a Tangram simulator in which the pieces on the computer display can be moved, rotated and flipped with simple mouse operations.", "labels": [], "entities": []}, {"text": "shows the simulator interface in which the left shows the goal shape area and the right the working area.", "labels": [], "entities": []}, {"text": "We assigned two different roles to participants, a solver and an operator; the solver thinks of the arrangement of the pieces to make the goal shape and gives instructions to the operator, while the operator manipulates the pieces with the mouse according to the solver's instructions.", "labels": [], "entities": []}, {"text": "A solver and an operator sit side by side in front of their own computer display.", "labels": [], "entities": [{"text": "solver", "start_pos": 2, "end_pos": 8, "type": "TASK", "confidence": 0.9792278409004211}]}, {"text": "Both participants share the same working area of the simulator.", "labels": [], "entities": []}, {"text": "The operator can manipulate the pieces, but cannot seethe goal shape.", "labels": [], "entities": []}, {"text": "In contrast, the solver sees the goal shape but cannot move pieces.", "labels": [], "entities": [{"text": "solver", "start_pos": 17, "end_pos": 23, "type": "TASK", "confidence": 0.981717050075531}]}, {"text": "A shield screen was set between the participants in order to prevent them from peeking at their partner's display.", "labels": [], "entities": []}, {"text": "In this asymmetrical interaction, we can expect many referring expressions during the interaction.", "labels": [], "entities": []}, {"text": "Each pair is assigned four exercises and the participants exchanged roles after two exercises.", "labels": [], "entities": []}, {"text": "We set a time limit of 15 minutes for an exercise.", "labels": [], "entities": []}, {"text": "Utterances by the participants are recorded separately in stereo through headset microphones in synchronisation with the position of the pieces and the mouse actions.", "labels": [], "entities": []}, {"text": "In total, we collected 24 dialogues of about four hours.", "labels": [], "entities": []}, {"text": "The average length of a dialogue was 10 minutes 43 seconds.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features of referring expressions", "labels": [], "entities": []}]}