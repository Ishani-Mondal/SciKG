{"title": [{"text": "Proceedings of CLIAWS3, Third International", "labels": [], "entities": [{"text": "CLIAWS3", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.8626824617385864}]}], "abstractContent": [{"text": "For many languages, the size of Wikipedia is an order of magnitude smaller than the En-glish Wikipedia.", "labels": [], "entities": [{"text": "En-glish Wikipedia", "start_pos": 84, "end_pos": 102, "type": "DATASET", "confidence": 0.805718183517456}]}, {"text": "We present a method for cross-lingual alignment of template and in-fobox attributes in Wikipedia.", "labels": [], "entities": []}, {"text": "The alignment is used to add and complete templates and infoboxes in one language with information derived from Wikipedia in another language.", "labels": [], "entities": []}, {"text": "We show that alignment between English and Dutch Wikipedia is accurate and that the result can be used to expand the number of template attribute-value pairs in Dutch Wikipedia by 50%.", "labels": [], "entities": []}, {"text": "Furthermore, the alignment provides valuable information for normalization of template and attribute names and can be used to detect potential inconsistencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the more interesting aspects of Wikipedia is that it has grown into a multilingual resource, with Wikipedia's for many languages, and systematic (cross-language) links between the information in different language versions.", "labels": [], "entities": []}, {"text": "Eventhough English has the largest Wikipedia for any given language, the amount of information present in Wikipedia exceeds that of any single Wikipedia.", "labels": [], "entities": [{"text": "Eventhough English", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.9528518319129944}, {"text": "Wikipedia", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9571747779846191}]}, {"text": "One of the reasons for this is that each language version of Wikipedia has its own cultural and regional bias.", "labels": [], "entities": []}, {"text": "It is likely, for instance, that information about the Netherlands is better represented in Dutch Wikipedia than in other Wikipedia's.", "labels": [], "entities": []}, {"text": "Some indication that this is indeed the case comes from the fact a Google search for 'Pim Fortuyn' in the Dutch Wikipedia gives 498 hits, whereas the English Wikipedia gives only 292 hits.", "labels": [], "entities": []}, {"text": "Also, 21,697 pages in Dutch Wikipedia fall in a category matching 'Nederlands(e)', whereas only 9,494 pages in English Wikipedia fall in a category matching 'Dutch'.", "labels": [], "entities": [{"text": "Nederlands(e)'", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.8481334447860718}]}, {"text": "This indicates that, apart from the obvious fact that smaller Wikipedia's can be expanded with information found in the larger Wikipedia's, it is also true that even the larger Wikipedia's can be supplemented with information harvested from smaller Wikipedia's.", "labels": [], "entities": []}, {"text": "Wikipedia infoboxes are tabular summaries of the most relevant facts contained in an article.", "labels": [], "entities": [{"text": "Wikipedia infoboxes", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.9467224776744843}]}, {"text": "They represent an important source of information for general users of the encyclopedia.", "labels": [], "entities": []}, {"text": "Infoboxes (see) encode facts using attributes and values, and therefore are easy to collect and process automatically.", "labels": [], "entities": []}, {"text": "For this reason, they are extremely valuable for systems that harvest information from Wikipedia automatically, such as DbPedia (.", "labels": [], "entities": [{"text": "DbPedia", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.9647876024246216}]}, {"text": "However, as note, infoboxes are missing for many pages, and not all infoboxes are complete.", "labels": [], "entities": []}, {"text": "This is particularly true for Wikipedia's in languages other than English.", "labels": [], "entities": []}, {"text": "Infoboxes area subclass of Wikipedia templates, which are used by authors of Wikipedia pages to express information in a systematic way, and to ensure that formatting of this information is consistent across Wikipedia.", "labels": [], "entities": []}, {"text": "Templates exist for referring to multimedia content, external websites, news stories, scientific sources, other on-line repositories (such as the Internet Movie Database (IMDB), medical classification systems (ICD9 and ICD10), coordinates on Google Maps, etc.", "labels": [], "entities": [{"text": "ICD9", "start_pos": 210, "end_pos": 214, "type": "DATASET", "confidence": 0.8610368967056274}, {"text": "ICD10", "start_pos": 219, "end_pos": 224, "type": "DATASET", "confidence": 0.6243209838867188}]}, {"text": "Although we are primarily interested in infoboxes, in the experiments below we take We plan to use information mined from Wikipedia for Question Answering and related tasks.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.7991098165512085}]}, {"text": "In 2007 and 2008, the CLEF question answering track 1 used Wikipedia as text collection.", "labels": [], "entities": [{"text": "CLEF question answering track 1", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.6905330419540405}]}, {"text": "While the usual approach to open domain question answering relies on information retrieval for selecting relevant text snippets, and natural language processing techniques for answer extraction, an alternative stream of research has focussed on the potential of on-line data-sets for question answering ().", "labels": [], "entities": [{"text": "open domain question answering", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.5984543114900589}, {"text": "answer extraction", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.7751969993114471}, {"text": "question answering", "start_pos": 284, "end_pos": 302, "type": "TASK", "confidence": 0.875878244638443}]}, {"text": "In it is suggested that information harvested from infoboxes can be used for question answering in CLEF.", "labels": [], "entities": [{"text": "question answering", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.848539799451828}, {"text": "CLEF", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8579060435295105}]}, {"text": "For instance, the answer to questions such as How high is the Matterhorn?, Where was Piet Mondriaan born?, and What is the area of the country Suriname?", "labels": [], "entities": [{"text": "Matterhorn", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.9492489695549011}]}, {"text": "can in principle be found in infoboxes.", "labels": [], "entities": []}, {"text": "However, in practice the number of questions that is answered by their Dutch QA-system by means information from infoboxes is small.", "labels": [], "entities": [{"text": "Dutch QA-system", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.8365994989871979}]}, {"text": "One reason for this is the lack of coverage of infoboxes in Dutch Wikipedia.", "labels": [], "entities": []}, {"text": "1 http://clef-qa.itc.it In the recent GIKICLEF task 2 systems have to find Wikipedia pages in a number of languages which match descriptions such as Which Australian mountains are higher than 2000 m?, French bridges which were in construction between 1980 and 1990, and African capitals with a population of two million inhabitants or more.", "labels": [], "entities": []}, {"text": "The emphasis in this task is lesson answer extraction from text (as in QA) and more on accurate interpretation of (geographical) facts known about an entity.", "labels": [], "entities": [{"text": "lesson answer extraction from text", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.7617200613021851}, {"text": "accurate interpretation of (geographical) facts known about an entity", "start_pos": 87, "end_pos": 156, "type": "TASK", "confidence": 0.6900692040270026}]}, {"text": "GIKICLEF is closely related to the entity ranking task for Wikipedia, as organized by INEX.", "labels": [], "entities": [{"text": "GIKICLEF", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6939486861228943}, {"text": "INEX", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.9250351190567017}]}, {"text": "We believe systems participating in tasks like this could profit from large collections of entity,attribute,value triples harvested from Wikipedia templates.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for automatically expanding the amount of information present in the form of templates.", "labels": [], "entities": []}, {"text": "In our experiments, we used English and Dutch Wikipedia as sources.", "labels": [], "entities": []}, {"text": "Given a page in English, and a matching page in Dutch, we first find all English-Dutch attribute-value tuples which have a matching value.", "labels": [], "entities": []}, {"text": "Based on the frequency with which attributes match, we create a bidirectional, intersective, alignment of EnglishDutch attribute pairs.", "labels": [], "entities": []}, {"text": "Finally, we use the set of aligned attributes to expand the number of attributevalue pairs in Dutch Wikipedia with information obtained from matching English pages.", "labels": [], "entities": []}, {"text": "We also show that aligned attributes can be used to normalize attribute names and to detect formatting issues and potential inconsistencies in attribute values.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics for the version of Dutch and English  Wikipedia used in the experiment.", "labels": [], "entities": []}, {"text": " Table 2: Dutch template\u223cattribute pairs matching En- glish cite web\u223ctitle. Counts refer to the number of pages  with a matching value.", "labels": [], "entities": [{"text": "Dutch template\u223cattribute pairs matching En- glish cite web\u223ctitle", "start_pos": 10, "end_pos": 74, "type": "DATASET", "confidence": 0.5603191623320947}]}]}