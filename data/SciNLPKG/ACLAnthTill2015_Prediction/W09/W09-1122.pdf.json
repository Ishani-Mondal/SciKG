{"title": [{"text": "Lexical Patterns or Dependency Patterns: Which Is Better for Hypernym Extraction?", "labels": [], "entities": [{"text": "Hypernym Extraction", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7205362766981125}]}], "abstractContent": [{"text": "We compare two different types of extraction patterns for automatically deriving semantic information from text: lexical patterns, built from words and word class information, and dependency patterns with syntactic information obtained from a full parser.", "labels": [], "entities": []}, {"text": "We are particularly interested in whether the richer linguistic information provided by a parser allows fora better performance of subsequent information extraction work.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.736976146697998}]}, {"text": "We evaluate automatic extraction of hypernym information from text and conclude that the application of dependency patterns does not lead to substantially higher precision and recall scores than using lexical patterns.", "labels": [], "entities": [{"text": "automatic extraction of hypernym information from text", "start_pos": 12, "end_pos": 66, "type": "TASK", "confidence": 0.8241590346608844}, {"text": "precision", "start_pos": 162, "end_pos": 171, "type": "METRIC", "confidence": 0.9988698363304138}, {"text": "recall scores", "start_pos": 176, "end_pos": 189, "type": "METRIC", "confidence": 0.9763378202915192}]}], "introductionContent": [{"text": "For almost a decade, automatic sentence parsing systems with a reasonable performance (90+% constituent precision/recall) have been available for English.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.6685359925031662}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.7488144636154175}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.8581599593162537}]}, {"text": "In recent years there has been an increase in linguistic applications which use parsing as a preprocessing step, e.g. and.", "labels": [], "entities": []}, {"text": "One of the boosts for these new applications was the increasing power of desktop computers, which allows for an easier access to the computing-intensive parsing results.", "labels": [], "entities": []}, {"text": "Another is the increased popularity of dependency parsing of which the results can easily be incorporated into followup systems.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8514009416103363}]}, {"text": "Although there is a consensus about the fact that the richness of the dependency structures should, in principle, enable better performance than lexical information or shallow parsing results, it is not clear if these better results can also be obtained in practice.", "labels": [], "entities": []}, {"text": "A performance of 90% precision and recall at constituent level still leaves an average of one error in a medium-length sentence often words.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9994375109672546}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9993694424629211}]}, {"text": "These errors could degrade the performance of any approach which relies heavily on parser output.", "labels": [], "entities": []}, {"text": "The question of whether to include a full parser as a preprocessor for natural language processing task, has led to a heated discussion between the two authors of the paper.", "labels": [], "entities": [{"text": "natural language processing task", "start_pos": 71, "end_pos": 103, "type": "TASK", "confidence": 0.696846216917038}]}, {"text": "One of us argues that full parsers are slow and make too many errors, and relies on shallow techniques like part-of-speech tagging for preprocessing.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.6978434771299362}]}, {"text": "The other points at the decreasing costs of computing and improvements in the reliability of parsers, and recommends dependency parsers as preprocessing tools.", "labels": [], "entities": []}, {"text": "While no automatic text preprocessing method is free of errors, it is indeed true that approaches other than full parsing, like for example shallow parsing, offer useful information at a considerably cheaper processing cost.", "labels": [], "entities": [{"text": "shallow parsing", "start_pos": 140, "end_pos": 155, "type": "TASK", "confidence": 0.5721166878938675}]}, {"text": "The choice between using a heavy full parser or alight shallow language analyzer is one that developers of language processing systems frequently have to make.", "labels": [], "entities": []}, {"text": "The expected performance boost of parsed data could bean important motivation for choosing for full syntactic analysis.", "labels": [], "entities": [{"text": "full syntactic analysis", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.5967005689938863}]}, {"text": "However, we do not know how big the difference between the two methods will be.", "labels": [], "entities": []}, {"text": "In order to find this out, we designed an experiment in which we compared the effects of preprocessing with and without using information generated by a full parser.", "labels": [], "entities": []}, {"text": "In this paper, we compare two text preprocessing approaches fora single language processing task.", "labels": [], "entities": []}, {"text": "The first of the two methods is shallow lin-guistic processing, a robust and fast text analysis method which only uses information from words, like lemma information and part-of-speech classes.", "labels": [], "entities": []}, {"text": "The second method is dependency parsing which includes information about the syntactic relations between words.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.857872486114502}]}, {"text": "The natural language processing task which we will use for assessing the usability of the two processing methods is automatic extraction of hypernym information from text.", "labels": [], "entities": [{"text": "automatic extraction of hypernym information from text", "start_pos": 116, "end_pos": 170, "type": "TASK", "confidence": 0.7601068786212376}]}, {"text": "The language of the text documents is Dutch.", "labels": [], "entities": []}, {"text": "We expect that the findings of this study would have been similar if any other Germanic language (including English) was used.", "labels": [], "entities": []}, {"text": "The contribution of this paper is a thorough and fair comparison of the involved preprocessing techniques.", "labels": [], "entities": []}, {"text": "There have been earlier studies of hypernym extraction with either lexical or dependency extraction patterns.", "labels": [], "entities": [{"text": "hypernym extraction", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8002805113792419}]}, {"text": "However, these studies applied the techniques to a variety of different data sets and used different evaluation techniques.", "labels": [], "entities": []}, {"text": "We will apply the two methods to the same data, evaluate the results in a consistent manner and examine the differences.", "labels": [], "entities": []}, {"text": "After this introduction, we will describe the task, the preprocessing methods and the evaluation setting in more detail.", "labels": [], "entities": []}, {"text": "In the third section, we will show how our experiments were setup and present the results.", "labels": [], "entities": []}, {"text": "Section four contains a detailed discussion of the two methods and their effect on the extraction task.", "labels": [], "entities": [{"text": "extraction task", "start_pos": 87, "end_pos": 102, "type": "TASK", "confidence": 0.8921312689781189}]}, {"text": "In the final section of the paper, we will present some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "For parameter optimization we need an automatic evaluation procedure, since repeated manual checks of results generated by different versions of the learner require too much time.", "labels": [], "entities": [{"text": "parameter optimization", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7277175486087799}]}, {"text": "We have adopted the evaluation method of: compare the generated hypernyms with hypernyms present in a lexical resource, in our case the Dutch part of.", "labels": [], "entities": []}, {"text": "This choice results in two restrictions.", "labels": [], "entities": []}, {"text": "First, we will only consider pairs of known words (words that are present in the lexical resource) for evaluation.", "labels": [], "entities": []}, {"text": "We have no information about other words so we make no assumptions about them.", "labels": [], "entities": []}, {"text": "Second, if two words appear in the lexical resource but not in the hypernym relation of that same resource then we will assume that they are unrelated.", "labels": [], "entities": []}, {"text": "In other words, we assume the hypernymy relation specified in the lexical resource as complete (like in the work of).", "labels": [], "entities": []}, {"text": "We use standard evaluation scores.", "labels": [], "entities": []}, {"text": "We will compute precision and recall for the candidate hypernyms, as well as the related F \u03b2=1 rate, the harmonic mean between precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9993780851364136}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9992941617965698}, {"text": "F \u03b2=1 rate", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9830427527427673}, {"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9958221912384033}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9858054518699646}]}, {"text": "Precision will be computed against all chosen candidate hypernyms.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9717459082603455}]}, {"text": "However, recall will only be computed against the positive noun pairs which occur in the phrases selected by the examined method.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9989925026893616}]}, {"text": "The different preprocessing methods may cause different numbers of positive pairs to be selected.", "labels": [], "entities": []}, {"text": "Only these pairs will be used for computing recall scores.", "labels": [], "entities": [{"text": "recall scores", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.9724865257740021}]}, {"text": "For this reason we will report the selected number of positive target pairs in the result tables as well .  We have applied the extraction techniques to two different Dutch corpora.", "labels": [], "entities": []}, {"text": "The first is a collection of texts from the news domain.", "labels": [], "entities": []}, {"text": "It consists of texts from five different Dutch news papers from the Twente News Corpus collection.", "labels": [], "entities": [{"text": "Twente News Corpus collection", "start_pos": 68, "end_pos": 97, "type": "DATASET", "confidence": 0.8852655440568924}]}, {"text": "Two versions of this corpus exist.", "labels": [], "entities": []}, {"text": "We have worked with the version which contains the years 1997-2005 (26 million sentences and 450 million tokens).", "labels": [], "entities": []}, {"text": "The second corpus is the Dutch Wikipedia.", "labels": [], "entities": [{"text": "Dutch Wikipedia", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9274671375751495}]}, {"text": "Here we used aversion of October 2006 (5 million sentences and 58 million words).", "labels": [], "entities": [{"text": "aversion", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9972334504127502}]}, {"text": "Syntactic preprocessing of the material was done with the Alpino parser, the best available parser for Dutch with a labeled dependency accuracy of 89%).", "labels": [], "entities": [{"text": "labeled dependency accuracy", "start_pos": 116, "end_pos": 143, "type": "METRIC", "confidence": 0.6686474680900574}]}, {"text": "Rather than performing the parsing task ourselves, we have relied on an available parsed treebank which included the text corpora that we wanted to use).", "labels": [], "entities": [{"text": "parsing", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.966429591178894}]}, {"text": "The parser also performs part-of-speech tagging and lemmatization, tasks which are useful for the lexical preprocessing methods.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6953470706939697}]}, {"text": "However, taking future real-time applications in mind, we did not want the lexical processing to be dependent on the parser.", "labels": [], "entities": []}, {"text": "Therefore we have developed an in-house part-ofspeech tagger and lemmatizer based on the material created in the Corpus Spoken Dutch project).", "labels": [], "entities": [{"text": "Corpus Spoken Dutch project", "start_pos": 113, "end_pos": 140, "type": "DATASET", "confidence": 0.7237983196973801}]}, {"text": "The tagger achieved an accuracy of 96% on test data from the same project while the lemmatizer achieved 98%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9996331930160522}]}, {"text": "We used the Dutch part of EuroWordNet as the gold standard lexical resource, both for training and testing.", "labels": [], "entities": [{"text": "Dutch part of EuroWordNet", "start_pos": 12, "end_pos": 37, "type": "DATASET", "confidence": 0.841370016336441}]}, {"text": "In the lexicon, many nouns have different senses.", "labels": [], "entities": []}, {"text": "This can cause problems for the pattern extraction process.", "labels": [], "entities": [{"text": "pattern extraction", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8688681423664093}]}, {"text": "For example, if a noun N 1 with sense X is related to another noun N 2 then the appearance of N 1 with sense Y with N 2 in the text maybe completely accidental and say nothing about the relation between the two words.", "labels": [], "entities": []}, {"text": "In that case it would be wrong to regard the context of the two words as an interesting extraction pattern.", "labels": [], "entities": []}, {"text": "There are several ways to deal with this problem.", "labels": [], "entities": []}, {"text": "One is to automatically assign senses to words.", "labels": [], "entities": []}, {"text": "However we do not have a reliable sense tagger for Dutch at our disposal.", "labels": [], "entities": []}, {"text": "Another method was proposed by: assume that every word bears its most frequent sense.", "labels": [], "entities": []}, {"text": "But this is also information which we lack for Dutch: our lexical resource does not contain frequency information for word senses.", "labels": [], "entities": []}, {"text": "We have chosen the approach suggested by : remove all nouns with multiple senses from the data set and use only the monosemous words for finding good extraction patterns.", "labels": [], "entities": []}, {"text": "This restriction is only imposed in the training phase.", "labels": [], "entities": []}, {"text": "We consider both monosemous words and polysemous words in the evaluation process.", "labels": [], "entities": []}, {"text": "We imposed two additional restrictions on the lexical resource.", "labels": [], "entities": []}, {"text": "First, we removed the top noun of the hypernymy hierarchy (iets) from the list of valid hypernyms.", "labels": [], "entities": []}, {"text": "This word is a valid hypernym of any other noun.", "labels": [], "entities": []}, {"text": "It is not an interesting suggestion for the extraction procedure to put forward.", "labels": [], "entities": []}, {"text": "Second, we restricted the extraction procedure to propose only known hypernyms as candidate hypernyms.", "labels": [], "entities": []}, {"text": "Nouns that appeared in the lexical resources only as hy- ponyms (leaf nodes of the hypernymy tree) were never proposed as candidate hypernyms.", "labels": [], "entities": []}, {"text": "This made sense for our evaluation procedure which is only aimed at finding known hypernym-hyponym pairs.", "labels": [], "entities": []}, {"text": "We performed two hypernym extraction experiments, one which used lexical extraction patterns and one which used dependency patterns 2 . The results from the experiments can be found in.", "labels": [], "entities": [{"text": "hypernym extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7581713199615479}]}, {"text": "The newspaper F-scores obtained with lexical patterns are similar to those reported for English (.0) but the dependency patterns perform worse.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.652148425579071}]}, {"text": "Both approaches perform well on Wikipedia data, most likely because of the more repeated sentence structures and the presence of many definition sentences.", "labels": [], "entities": [{"text": "Wikipedia data", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.8533483445644379}]}, {"text": "For newspaper data, lexical patterns outperform dependency patterns both for precision and F \u03b2=1 . For Wikipedia data the differences are smaller and in fact the dependency pat-terns obtain the best F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9994450211524963}, {"text": "F \u03b2", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9888489842414856}, {"text": "Wikipedia data", "start_pos": 103, "end_pos": 117, "type": "DATASET", "confidence": 0.8860736191272736}, {"text": "F-score", "start_pos": 199, "end_pos": 206, "type": "METRIC", "confidence": 0.9900292754173279}]}, {"text": "For all data sets, the dependency patterns suggest more related pairs than the lexical patterns (column Targets).", "labels": [], "entities": []}, {"text": "The differences between the two pattern types are significant (p < 0.05) for all evaluation measures for Newspapers and for positive targets and recall for Wikipedia.", "labels": [], "entities": [{"text": "Newspapers", "start_pos": 105, "end_pos": 115, "type": "DATASET", "confidence": 0.9086199402809143}, {"text": "recall", "start_pos": 145, "end_pos": 151, "type": "METRIC", "confidence": 0.9994487166404724}, {"text": "Wikipedia", "start_pos": 156, "end_pos": 165, "type": "DATASET", "confidence": 0.9547138810157776}]}], "tableCaptions": [{"text": " Table 1: Hypernym extraction scores for the five news- papers in the Twente News Corpus (AD, NRC, Parool,  Trouw and Volkskrant) and for the Dutch Wikipedia.  The Targets column shows the number of unique posi- tive word pairs in each data set. The Dutch Wikipedia  contains about as much data as one of the newspaper sec- tions.", "labels": [], "entities": [{"text": "Hypernym extraction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.765722006559372}, {"text": "Twente News Corpus (AD, NRC", "start_pos": 70, "end_pos": 97, "type": "DATASET", "confidence": 0.7403158119746617}, {"text": "Dutch Wikipedia", "start_pos": 142, "end_pos": 157, "type": "DATASET", "confidence": 0.804709255695343}]}, {"text": " Table 2: Best performing extraction patterns according to  F-scores.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9873605370521545}]}]}