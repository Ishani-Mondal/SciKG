{"title": [{"text": "Investigation of Unsupervised Pattern Learning Techniques for Bootstrap Construction of a Medical Treatment Lexicon", "labels": [], "entities": []}], "abstractContent": [{"text": "Dictionaries of biomedical concepts (e.g. diseases , medical treatments) are critical source of background knowledge for systems doing biomedical information retrieval, extraction, and automated discovery.", "labels": [], "entities": [{"text": "Dictionaries of biomedical concepts (e.g. diseases , medical treatments)", "start_pos": 0, "end_pos": 72, "type": "TASK", "confidence": 0.7307631156661294}, {"text": "biomedical information retrieval, extraction", "start_pos": 135, "end_pos": 179, "type": "TASK", "confidence": 0.7007619976997376}, {"text": "automated discovery", "start_pos": 185, "end_pos": 204, "type": "TASK", "confidence": 0.7449621558189392}]}, {"text": "However, the rapid pace of biomedical research and the lack of constraints on usage ensure that such dictionaries are incomplete.", "labels": [], "entities": []}, {"text": "Focusing on medical treatment concepts (e.g. drugs, medical procedures and medical devices), we have developed an unsupervised, iterative pattern learning approach for constructing a comprehensive dictionary of medical treatment terms from randomized clinical trial (RCT) abstracts.", "labels": [], "entities": []}, {"text": "We have investigated different methods of seeding, either with a seed pattern or seed instances (terms), and have compared different ranking methods for ranking extracted context patterns and instances.", "labels": [], "entities": []}, {"text": "When used to identify treatment concepts from 100 randomly chosen, manually annotated RCT abstracts, our medical treatment dictionary shows better performance (precision:0.40, recall: 0.92 and F-measure: 0.54) over the most widely used manually created medical treatment terminology (precision: 0.41, recall: 0.52 and F-measure: 0.42).", "labels": [], "entities": [{"text": "precision", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9986792206764221}, {"text": "recall", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.998532772064209}, {"text": "F-measure", "start_pos": 193, "end_pos": 202, "type": "METRIC", "confidence": 0.9787944555282593}, {"text": "precision", "start_pos": 284, "end_pos": 293, "type": "METRIC", "confidence": 0.9961814880371094}, {"text": "recall", "start_pos": 301, "end_pos": 307, "type": "METRIC", "confidence": 0.9985357522964478}, {"text": "F-measure", "start_pos": 318, "end_pos": 327, "type": "METRIC", "confidence": 0.9712977409362793}]}], "introductionContent": [{"text": "Dictionary based natural language processing systems have been widely used in recognizing medical concepts from free text.", "labels": [], "entities": [{"text": "recognizing medical concepts from free text", "start_pos": 78, "end_pos": 121, "type": "TASK", "confidence": 0.8831786513328552}]}, {"text": "For example, the MetaMap program is used to map medical text to concepts from the most widely used biomedical terminology, the Unified Medical Language System (UMLS) Metathesaurus.", "labels": [], "entities": []}, {"text": "It identifies various forms of UMLS concepts in text and returns them as a ranked list using a five-step process: identifying simple noun phrases (NP's), generating variants of each phrase, finding matched phrases, assigning scores to matched phrases and composing mappings.", "labels": [], "entities": []}, {"text": "However, its performance largely depends on the quality of the underlying UMLS Metathesaurus and its manually created rules and variants.", "labels": [], "entities": [{"text": "UMLS Metathesaurus", "start_pos": 74, "end_pos": 92, "type": "DATASET", "confidence": 0.8868454694747925}]}, {"text": "One study has shown that, of the medical concepts identified by human subjects, more than 40% were not in UMLS.", "labels": [], "entities": []}, {"text": "Other examples of mapping text to controlled biomedical terminologies include ( and).", "labels": [], "entities": []}, {"text": "Many other systems make heavy use of biomedical terminologies directly such as the work of Blaschke, et al.) and).", "labels": [], "entities": []}, {"text": "Biomedical terminology is highly dynamic, both because biomedical research is itself highly dynamic, but also because there are essentially no constraints on the use of new terminological variants, making the terms used in free text quite different from the canonical forms listed in controlled terminologies.", "labels": [], "entities": []}, {"text": "To contrast UMLS with actual text mentions, there are 150 different chemotherapy concepts in UMLS.", "labels": [], "entities": []}, {"text": "The majority of these terms derive from the diseases they are used to treat.", "labels": [], "entities": []}, {"text": "For example cancer chemotherapy, AIDS chemotherapy, brain disorder chemotherapy, and alcoholism chemotherapy.", "labels": [], "entities": []}, {"text": "On the other hand, we have identified more than 1,000 different chemotherapy types mentioned in RCT (Randomized Clinical Trial) report abstracts, with most of the names derived from the chemicals contained in the chemotherapy regimen, such as platinum-based chemotherapy or fluorouracil-based chemotherapy.", "labels": [], "entities": [{"text": "RCT (Randomized Clinical Trial) report abstracts", "start_pos": 96, "end_pos": 144, "type": "DATASET", "confidence": 0.5480695590376854}]}, {"text": "There is little overlap between the chemotherapy terms in UMLS and the ones used in RCT abstracts.", "labels": [], "entities": []}, {"text": "Even for simple drug names as 5-fluorouracil and tamoxifen, there are many clinically distinct and important variants of these drugs which are absent in UMLS as distinct terms/concepts, such as intralesional 5-fluorouracil, topical 5-fluorouracil, intrahepatic arterial 5-Fluorouracil, adjuvant sequential tamoxifen, and neoadjuvant tamoxifen.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 153, "end_pos": 157, "type": "DATASET", "confidence": 0.8243966102600098}]}, {"text": "There has been considerable work on expanding the coverage of biomedical dictionaries through morphological variants, but these approaches require an initial term dictionary with reasonable extensive coverage.", "labels": [], "entities": []}, {"text": "Examples include the approaches developed by), Tsuruoka and Tsujii (, and Mukherjea and colleagues).", "labels": [], "entities": []}, {"text": "An important shortcoming with static, human derived terminologies that cannot easily be addressed by looking for variants of existing terms is the fact that continual developments in medical therapies constantly gives rise to new terms.", "labels": [], "entities": []}, {"text": "Examples include, Apomab, Bapineuzumab, Bavituximab, Etaracizumab, and Figitumumab.", "labels": [], "entities": [{"text": "Apomab", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.873422384262085}]}, {"text": "These all represent anew generation of targeted biological agents currently in clinical trials none of which appear in UMLS.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.9452252984046936}]}, {"text": "Clearly we need to develop techniques to deal with this dynamic terminology landscape.", "labels": [], "entities": []}, {"text": "MEDLINE is the most extensive and authoritative source of biomedical information.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9263861179351807}]}, {"text": "Large quantities of biomedical text are available in MEDLINE's collection of RCT reports with over 500,000 abstracts available.", "labels": [], "entities": [{"text": "MEDLINE's collection of RCT reports", "start_pos": 53, "end_pos": 88, "type": "DATASET", "confidence": 0.9425071775913239}]}, {"text": "RCT reports area critical resource for information about diseases, their treatments, and treatment efficacy.", "labels": [], "entities": [{"text": "RCT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8391638398170471}]}, {"text": "These reports have the advantage of being highly redundant (a disease or treatment name is often reported in multiple RCT abstracts), medically related, coherent in writing style, trustworthy and freely available.", "labels": [], "entities": []}, {"text": "In our recent study, we have developed and evaluated an automated, unsupervised, iterative pattern learning approach for constructing a comprehensive disease dictionary from RCT abstracts.", "labels": [], "entities": []}, {"text": "When used to identify disease concepts from 100 manually annotated clinical abstracts, the disease dictionary shows significant performance improvement (F1 increased by 35-88%) over UMLS and other disease terminologies.", "labels": [], "entities": [{"text": "F1", "start_pos": 153, "end_pos": 155, "type": "METRIC", "confidence": 0.9996067881584167}]}, {"text": "It remained to be demonstrated that these bootstrapping techniques are indeed rapidly retargetable and can be extended to other situations, and so we have extended our scope to investigate medical treatment names in addition to disease terms in this work.", "labels": [], "entities": []}, {"text": "Our approach is inspired by the framework adopted in several bootstrapping systems for learning term dictionaries, including, (?), and).", "labels": [], "entities": []}, {"text": "These approaches are based on a set of surface patterns, which are matched to the text collection and used to find instance-concept relations.", "labels": [], "entities": []}, {"text": "Similar systems include that of Snow and colleagues, which integrates syntactic dependency structure into pattern representation and has been applied to the task of learning instance-of relations, and the approach developed of which focussed on learning text context patterns to identify mentions of point mutations.", "labels": [], "entities": []}, {"text": "All iterative learning systems suffer from the inevitable problem of spurious patterns and instances introduced in the iterative process.", "labels": [], "entities": []}, {"text": "To analyze different approaches to addressing this issue, we have compared three different approaches to ranking extracted patterns and three different approaches to ranking extracted instances.", "labels": [], "entities": []}, {"text": "Because such systems also depend on an initial seeding with either a seed pattern or term instance, an important question is whether these different starting points lead to different results.", "labels": [], "entities": []}, {"text": "We investigated this issue by starting from each point separately and compared the final results.", "labels": [], "entities": []}, {"text": "the publicly available information retrieval library, Lucene, to create an index on sentences and their corresponding parse trees.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.9571036696434021}]}, {"text": "For evaluation and comparison, 241,793 treatment terms with treatment related semantics types from UMLS were used.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8940287232398987}]}], "datasetContent": [{"text": "An important question is how accurate the Stanford Parser is at identifying the relevant term boundaries.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.9531701803207397}]}, {"text": "We used manually curated treatment names from UMLS to measure the accuracy of the Stanford Parser in identifying treatment noun phrases.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.9046592116355896}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9993213415145874}]}, {"text": "With NP count(treatment) defined as number of times that the Stanford Parser identifies a treatment as noun phrase or part of a noun phrase in the data and count(treatment) as number of times the treatment appears in the data.", "labels": [], "entities": [{"text": "NP count(treatment)", "start_pos": 5, "end_pos": 24, "type": "METRIC", "confidence": 0.8691148877143859}, {"text": "Stanford Parser", "start_pos": 61, "end_pos": 76, "type": "DATASET", "confidence": 0.931817889213562}, {"text": "count", "start_pos": 156, "end_pos": 161, "type": "METRIC", "confidence": 0.9676151275634766}]}, {"text": "Our dictionary derived from using \"treated with\" as the seed pattern with two bootstrapping itera-  tions consists of 1,768,320 candidate instances and 78,037 patterns, each with an accompanying confidence score.", "labels": [], "entities": []}, {"text": "The top 20 patterns are associated with more than 90% of the instances.", "labels": [], "entities": []}, {"text": "We evaluated the quality of the dictionary by using it to identify treatment concepts in 100 randomly selected abstracts where treatment names were manually annotated.", "labels": [], "entities": []}, {"text": "There were an average of three treatment names per test abstract.", "labels": [], "entities": []}, {"text": "shows the precision, recall and F1 values when instances are ranked by the best pattern based ranking method (ScoreC).", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9996528625488281}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9987162351608276}, {"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9992357492446899}]}, {"text": "The precision, recall and F1 values at each cut-off (percentage of all instances) were averaged across the 100 abstracts.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995597004890442}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9988237023353577}, {"text": "F1", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9985346794128418}]}, {"text": "The precision, recall and F1 of the UMLS Metathesaurus in identifying treatment names from the test dataset are 0.41, 0.52 and 0.42 respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996659755706787}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9996102452278137}, {"text": "F1", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.999693751335144}, {"text": "UMLS Metathesaurus", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.8813205361366272}]}, {"text": "The performance using UMLS on this task is consistent with a previous study.", "labels": [], "entities": []}, {"text": "The low precision may due to the fact that UMLS often tags irrelevant names as treatment related names.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9993734955787659}]}, {"text": "For example, common, non-specific terms such as drug, agent, treatment and procedure appear in the dictionary derived from UMLS.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 123, "end_pos": 127, "type": "DATASET", "confidence": 0.9375035166740417}]}, {"text": "However, we chose not to edit the lexicon derived from UMLS as it is unclear how to do so in a systematic matter without essentially creating anew version of UMLS, and we are interested in studying methods that do not rely on any human involvement (our Discussion describes the possible inclusion of human judgments).", "labels": [], "entities": []}, {"text": "Also, the low recall of UMLS is not surprising given the fact that the names specified in UMLS are often not the terms authors use in writing.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9993698000907898}]}, {"text": "The performance of our dictionary (precision: 0.40, recall: 0.92, F1: 0.54) is a dramatic improvement over using UMLS.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9990571141242981}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9993336796760559}, {"text": "F1", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9987841248512268}]}, {"text": "Our recall is high since all the terms are learned from the literature directly and exemplify the manner in which authors write RCT reports.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9996750354766846}]}, {"text": "However, the precision of our dictionary is still low (see Discussion).", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9995784163475037}]}, {"text": "Even though the Stanford Parser is trained on nonmedical data, it is highly accurate in identifying treatments as noun phrases or parts of a noun phrase with accuracy of 0.95.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.8824115693569183}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9994339346885681}]}, {"text": "The reason maybe that medical treatments are indeed often noun phrases or parts of a noun phrase in RCT reports, and there are strong syntactical signals for their phrasal roles in the sentences.", "labels": [], "entities": []}, {"text": "For example, treatments are often either the object of a preposition (e.g. efficacy of fluorouracil and treated with fluorouracil) or the subject of a sentence (e.g. fluorouracil is effective in treating colon cancer).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: : The ratio of overlap in the top ranking patterns  discovered by different seed types", "labels": [], "entities": [{"text": "overlap", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.8758114576339722}]}, {"text": " Table 4: Precision, recall and F1 at 4 cutoff values", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9971451163291931}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9996168613433838}, {"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.999438464641571}]}]}