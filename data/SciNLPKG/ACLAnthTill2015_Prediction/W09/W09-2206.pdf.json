{"title": [{"text": "Latent Dirichlet Allocation with Topic-in-Set Knowledge *", "labels": [], "entities": []}], "abstractContent": [{"text": "Latent Dirichlet Allocation is an unsupervised graphical model which can discover latent topics in unlabeled data.", "labels": [], "entities": []}, {"text": "We propose a mechanism for adding partial supervision, called topic-inset knowledge, to latent topic mod-eling.", "labels": [], "entities": []}, {"text": "This type of supervision can be used to encourage the recovery of topics which are more relevant to user modeling goals than the topics which would be recovered otherwise.", "labels": [], "entities": []}, {"text": "Preliminary experiments on text datasets are presented to demonstrate the potential effectiveness of this method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Latent topic models such as Latent Dirichlet Allocation (LDA) () have emerged as a useful family of graphical models with many interesting applications in natural language processing.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.5562477807203928}]}, {"text": "One of the key virtues of LDA is its status as a fully generative probabilistic model, allowing principled extensions and variations capable of expressing rich problem domain structure.", "labels": [], "entities": []}, {"text": "LDA is an unsupervised learning model.", "labels": [], "entities": []}, {"text": "This work aims to add supervised information in the form of latent topic assignments to LDA.", "labels": [], "entities": []}, {"text": "Traditionally, topic assignments have been denoted by the variable z in LDA, and we will call such supervised information \"z-labels.\"", "labels": [], "entities": []}, {"text": "In particular, a z-label is the knowl- * We would like to acknowledge the assistance of Brandi Gancarz with the biological annotations.", "labels": [], "entities": []}, {"text": "This work is supported in part by the Wisconsin Alumni Research Foundation.", "labels": [], "entities": [{"text": "Wisconsin Alumni Research Foundation", "start_pos": 38, "end_pos": 74, "type": "DATASET", "confidence": 0.938916340470314}]}, {"text": "edge that the topic assignment fora given word position is within a subset of topics.", "labels": [], "entities": []}, {"text": "As such, this work is a combination of unsupervised model and supervised knowledge, and falls into the category similar to constrained clustering ( and semi-supervised dimensionality reduction ().", "labels": [], "entities": [{"text": "semi-supervised dimensionality reduction", "start_pos": 152, "end_pos": 192, "type": "TASK", "confidence": 0.7084362308184305}]}], "datasetContent": [{"text": "We now present preliminary experimental results to demonstrate some interesting applications for topicin-set knowledge.", "labels": [], "entities": []}, {"text": "Unless otherwise specified, symmetric hyperparameters \u03b1 = .5 and \u03b2 = .1 were used and all MCMC chains were run for 2000 samples before estimating \u03c6 and \u03b8 from the final sample, as in ( ).", "labels": [], "entities": [{"text": "\u03c6", "start_pos": 146, "end_pos": 147, "type": "METRIC", "confidence": 0.9099845290184021}]}], "tableCaptions": []}