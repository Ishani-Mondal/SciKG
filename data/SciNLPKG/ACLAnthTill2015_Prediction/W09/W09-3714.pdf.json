{"title": [{"text": "An extended model of natural logic", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation.", "labels": [], "entities": [{"text": "natural language inference", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6938120325406393}]}, {"text": "We extend past work in natural logic, which has focused on semantic containment and monotonicity, by incorporating both semantic exclusion and implicativity.", "labels": [], "entities": [{"text": "semantic containment", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.722698301076889}]}, {"text": "Our model decomposes an inference problem into a sequence of atomic edits linking premise to hypothesis ; predicts a lexical semantic relation for each edit; propagates these relations upward through a semantic composition tree according to properties of intermediate nodes; and joins the resulting semantic relations across the edit sequence.", "labels": [], "entities": []}, {"text": "A computational implementation of the model achieves 70% accuracy and 89% precision on the FraCaS test suite.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9995563626289368}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9996378421783447}, {"text": "FraCaS test suite", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.9789994955062866}]}, {"text": "Moreover, including this model as a component in an existing system yields significant performance gains on the Recognizing Textual Entailment challenge.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 112, "end_pos": 142, "type": "TASK", "confidence": 0.6809742450714111}]}], "introductionContent": [{"text": "Natural language inference (NLI) is the problem of determining whether a natural language hypothesis h can reasonably be inferred from a given premise p.", "labels": [], "entities": [{"text": "Natural language inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8139947752157847}]}, {"text": "For example: (1) p: Every firm polled saw costs grow more than expected, even after adjusting for inflation.", "labels": [], "entities": []}, {"text": "h: Every big company in the poll reported cost increases.", "labels": [], "entities": []}, {"text": "A capacity for open-domain NLI is clearly necessary for full natural language understanding, and NLI can also enable more immediate applications, such as semantic search and question answering.", "labels": [], "entities": [{"text": "semantic search", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.7663456797599792}, {"text": "question answering", "start_pos": 174, "end_pos": 192, "type": "TASK", "confidence": 0.9188171625137329}]}, {"text": "Consequently, NLI has been the focus of intense research effort in recent years, centered around the annual Recognizing Textual Entailment (RTE) competition (6).", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE) competition", "start_pos": 108, "end_pos": 156, "type": "TASK", "confidence": 0.7116458117961884}]}, {"text": "For a semanticist, the most obvious approach to NLI relies on full semantic interpretation: first, translate p and h into some formal meaning representation, such as first-order logic (FOL), and then apply automated reasoning tools to determine inferential validity.", "labels": [], "entities": []}, {"text": "While the formal approach can succeed in restricted domains, it struggles with open-domain NLI tasks such as RTE.", "labels": [], "entities": []}, {"text": "For example, the FOL-based system of (1) was able to find a proof for less than 4% of the problems in the RTE1 test set.", "labels": [], "entities": [{"text": "FOL-based", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.7697373032569885}, {"text": "RTE1 test set", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.9334609905878702}]}, {"text": "The difficulty is plain: truly natural language is fiendishly complex.", "labels": [], "entities": []}, {"text": "The formal approach faces countless thorny problems: idioms, ellipsis, paraphrase, ambiguity, vagueness, lexical semantics, the impact of pragmatics, and soon.", "labels": [], "entities": []}, {"text": "Consider fora moment the difficulty of fully and accurately translating (1) to a formal meaning representation.", "labels": [], "entities": []}, {"text": "Yet (1) also demonstrates that full semantic interpretation is often not necessary to determining inferential validity.", "labels": [], "entities": []}, {"text": "To date, the most successful NLI systems have relied on surface representations and approximate measures of lexical and syntactic similarity to ascertain whether p subsumes h.", "labels": [], "entities": []}, {"text": "However, these approaches face a different problem: they lack the precision needed to properly handle such commonplace phenomena as negation, antonymy, downward-monotone quantifiers, non-factive contexts, and the like.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9915624260902405}]}, {"text": "For example, if every were replaced by some or most throughout (1), the lexical and syntactic similarity of h top would be unaffected, yet the inference would be rendered invalid.", "labels": [], "entities": []}, {"text": "In this paper, we explore a middle way, by developing a model of what (11) called natural logic, which characterizes valid patterns of inference in terms of syntactic forms which are as close as possible to surface forms.", "labels": [], "entities": []}, {"text": "For example, the natural logic approach might sanction (1) by observing that: in ordinary upward monotone contexts, deleting modifiers preserves truth; in downward monotone contexts, inserting modifiers preserves truth; and every is downward monotone in its restrictor NP.", "labels": [], "entities": []}, {"text": "Natural logic thus achieves the semantic precision needed to handle inferences like (1), while sidestepping the difficulties of full semantic interpretation.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9102500677108765}]}, {"text": "The natural logic approach has a very long history, 1 originating in the syllogisms of Aristotle and continuing through the medieval scholastics and the work of Leibniz.", "labels": [], "entities": []}, {"text": "It was revived in recent times by and (17), whose monotonicity calculus explains inferences involving semantic containment and inversions of monotonicity, even when nested, as in Nobody can enter without a valid passport |= Nobody can enter without a passport.", "labels": [], "entities": []}, {"text": "However, because the monotonicity calculus lacks any representation of semantic exclusion, it fails to license many simple inferences, such as Stimpy is a cat |= Stimpy is not a poodle.", "labels": [], "entities": []}, {"text": "Another model which arguably belongs to the natural logic tradition (though not presented as such) was developed by (15) to explain inferences involving implicatives and factives, even when negated or nested, as in Ed did not forget to force Dave to leave |= Dave left.", "labels": [], "entities": []}, {"text": "While the model bears some resemblance to the monotonicity calculus, it does not incorporate semantic containment or explain interactions between implicatives and monotonicity, and thus fails to license inferences such as John refused to dance |= John didn't tango.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew model of natural logic which extends the monotonicity calculus to incorporate semantic exclusion, and partly unifies it with Nairn et al.'s account of implicatives.", "labels": [], "entities": []}, {"text": "We first define an inventory of basic semantic relations which includes representations of both containment and exclusion (section 2).", "labels": [], "entities": []}, {"text": "We then describe a general method for establishing the semantic relation between a premise p and a hypothesis h.", "labels": [], "entities": []}, {"text": "Given a sequence of atomic edits which transforms pinto h, we determine the lexical semantic relation generated by each edit (section 4); project each lexical semantic relation into anatomic semantic relation, according to properties of the context in which the edit occurs (section 5); and join atomic semantic relations across the edit sequence (section 3).", "labels": [], "entities": []}, {"text": "We have previously presented an implemented system based on this model; here we offer a detailed account of its theoretical foundations.", "labels": [], "entities": []}], "datasetContent": [{"text": "The model of natural logic described here has been implemented in software as the NatLog system.", "labels": [], "entities": []}, {"text": "In previous work, we have presented a description and evaluation of NatLog; this section summarizes the main results.", "labels": [], "entities": []}, {"text": "Natlog faces three primary challenges: 1.", "labels": [], "entities": []}, {"text": "Finding an appropriate sequence of atomic edits connecting premise and hypothesis.", "labels": [], "entities": []}, {"text": "NatLog does not address this problem directly, but relies instead on edit sequences from other sources.", "labels": [], "entities": [{"text": "NatLog", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9182791709899902}]}, {"text": "We have investigated this problem separately in (12).", "labels": [], "entities": []}, {"text": "2. Determining the lexical semantic relation for each edit.", "labels": [], "entities": []}, {"text": "NatLog learns to predict lexical semantic relations by using machine learning techniques and exploiting a variety of manually and automatically constructed sources of information on lexical relations.", "labels": [], "entities": [{"text": "predict lexical semantic relations", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.7602766454219818}]}, {"text": "3. Computing the projection of each lexical semantic relation.", "labels": [], "entities": []}, {"text": "NatLog identifies expressions with non-default projectivity and computes the likely extent of their arguments in a syntactic parse using hand-crafted tree patterns.", "labels": [], "entities": []}, {"text": "We have evaluated NatLog on two different test suites.", "labels": [], "entities": [{"text": "NatLog", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.8232428431510925}]}, {"text": "The first is the FraCaS test suite (5), which contains 346 NLI problems, divided into nine sections, each focused on a specific category of semantic phenomena.", "labels": [], "entities": [{"text": "FraCaS test suite", "start_pos": 17, "end_pos": 34, "type": "DATASET", "confidence": 0.9351059794425964}]}, {"text": "The goal is three-way entailment classification, as described in section 2.", "labels": [], "entities": [{"text": "entailment classification", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.8155603408813477}]}, {"text": "On this task, NatLog achieves an average accuracy of 70%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9902240633964539}]}, {"text": "In the section concerning quantifiers, which is both the largest and the most amenable to natural logic, the system answers all problems but one correctly.", "labels": [], "entities": []}, {"text": "Unsurprisingly, performance is mediocre in four sections concerning semantic phenomena (e.g., ellipsis) not relevant to natural logic and not modeled by the system.", "labels": [], "entities": []}, {"text": "But in the other five sections (representing about 60% of the problems), NatLog achieves accuracy of 87%.", "labels": [], "entities": [{"text": "NatLog", "start_pos": 73, "end_pos": 79, "type": "DATASET", "confidence": 0.8752127885818481}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9996401071548462}]}, {"text": "What's more, precision is uniformly high, averaging 89% overall sections.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999534010887146}]}, {"text": "Thus, even outside its areas of expertise, the system rarely predicts entailment when none exists.", "labels": [], "entities": [{"text": "predicts entailment", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8615448176860809}]}, {"text": "The RTE3 test suite (8) differs from FraCaS in several important ways: the goal is binary entailment classification; the problems have much longer premises and are more \"natural\"; and the problems employ a diversity of types of inference-including paraphrase, temporal reasoning, and relation extraction-which NatLog is not designed to address.", "labels": [], "entities": [{"text": "RTE3 test suite", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8952587048212687}, {"text": "FraCaS", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.9383593797683716}, {"text": "binary entailment classification", "start_pos": 83, "end_pos": 115, "type": "TASK", "confidence": 0.725391685962677}, {"text": "relation extraction-which NatLog", "start_pos": 284, "end_pos": 316, "type": "TASK", "confidence": 0.7764546871185303}]}, {"text": "Consequently, the NatLog system by itself achieves mediocre accuracy (59%) on RTE3 problems.", "labels": [], "entities": [{"text": "NatLog", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.9028093218803406}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9994321465492249}]}, {"text": "However, its precision is comparatively high, which suggests a strategy of hybridizing with a broad-coverage RTE system.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9995112419128418}]}, {"text": "We were able to show that adding NatLog as a component in the Stanford RTE system (3) led to accuracy gains of 4%.", "labels": [], "entities": [{"text": "Stanford RTE system", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.9279313683509827}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9994010925292969}]}], "tableCaptions": []}