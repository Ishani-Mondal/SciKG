{"title": [], "abstractContent": [{"text": "In this paper, a terminological framework, both theoretical and methodological, backed by empirical data, is proposed in order to highlight the particular questions to which attention should be paid when conceiving an evaluation scheme for definition extraction (DE) in terminology.", "labels": [], "entities": [{"text": "definition extraction (DE)", "start_pos": 240, "end_pos": 266, "type": "TASK", "confidence": 0.8602744579315186}]}, {"text": "The premise is that not just any information is relevant to defining a given concept in a given expert domain.", "labels": [], "entities": []}, {"text": "Therefore, evaluation guidelines applicable to DE should integrate some understanding of what is relevant for terminographic definitions and in which cases.", "labels": [], "entities": [{"text": "DE", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9561218023300171}]}, {"text": "This, in turn, requires some understanding of the mechanisms of feature selection.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7882100641727448}]}, {"text": "An explanatory hypothesis of feature relevance is then put forward and one of its aspects examined, to see to what extent the example considered may serve as a relevance referential.", "labels": [], "entities": []}, {"text": "To conclude, a few methodological proposals for automating the application of relevance tests are discussed.", "labels": [], "entities": []}, {"text": "The overall objective is to explore ways of empirically testing broader theoretical hypotheses and principles that should orient the conception of general guidelines to evaluate DE for terminographic purposes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Definition extraction (DE) evaluation in terminology maybe seen as a task aimed at enhancing precision and reducing the noise generated, for example, by limited extraction algorithms, i.e. as a task consisting in separating information on a concept from other information (for example, on another concept).", "labels": [], "entities": [{"text": "Definition extraction (DE) evaluation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.9039946595827738}, {"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9968786239624023}]}, {"text": "Thus considered, the task of evaluation would consist in assessing whether all the information about a concept (i.e. all the conceptual contexts in which it occurs) has been retrieved, and whether no extraneous or spurious information has been retrieved.", "labels": [], "entities": []}, {"text": "Assuming that this conceptual context retrieval issue is settled and that we already have all the textual contexts relating to a concept we want to define, there is still another aspect to be evaluated: is it the case that all the information extracted on a given concept in a given specialized corpus is relevant to the definition of that concept in that expert domain.", "labels": [], "entities": [{"text": "conceptual context retrieval", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.6883753538131714}]}, {"text": "One could argue that since the corpus from which the information is extracted is a specialized one, all the extracted information on a concept is at least potentially defining.", "labels": [], "entities": []}, {"text": "However, as we shall see, this is not always the case.", "labels": [], "entities": []}, {"text": "How may it be possible, then, to decide what is (or may be) relevant to the definition of a concept and what is not?", "labels": [], "entities": []}, {"text": "What is addressed here is, therefore, a more fundamental kind of evaluation concerning the relevance of the extracted information for terminographic definition writing.", "labels": [], "entities": [{"text": "terminographic definition writing", "start_pos": 134, "end_pos": 167, "type": "TASK", "confidence": 0.6872216065724691}]}, {"text": "In that perspective, we shall first show that what is extracted is not necessarily a definition, basing our argument on terminological and terminographic frameworks as well as on an empirical study.", "labels": [], "entities": []}, {"text": "This background implies several questions which ought to be considered when designing an evaluation scheme applicable to extracted information and its use for terminographic definitions.", "labels": [], "entities": []}, {"text": "Some hypotheses concerning the elements against which the extracted information maybe evaluated are proposed and examined, as are methodological approaches to answering the questions thus raised, therefore providing empirical grounds for an evaluation.", "labels": [], "entities": []}, {"text": "The main focus of this paper is therefore highlighting various factors that should be considered in evaluating the relevance of extracted information.", "labels": [], "entities": []}], "datasetContent": [{"text": "The last paragraph raises several questions pertinent to the design of schemes for the evaluation of information extraction for definitions in a terminological context.", "labels": [], "entities": [{"text": "evaluation of information extraction for definitions", "start_pos": 87, "end_pos": 139, "type": "TASK", "confidence": 0.7013621628284454}]}, {"text": "Now that a tentative (and partial) solution to the problem of selecting relevant features amongst a set of potentially relevant features has been examined, some equally tentative methods for automating the evaluation of information extracted from a corpus for use in constructing terminological definitions maybe considered.", "labels": [], "entities": []}, {"text": "The methodologies proposed should be tested in order to see whether they can in fact be automated or if the evaluation process needs to be carried out by a human expert.", "labels": [], "entities": []}, {"text": "In any case, it should be noted that this empirical endeavor is a task whose accomplishment relies on linguistic factors.", "labels": [], "entities": []}, {"text": "Therefore, to be applicable, each method should be associated with a set of linguistic features specifically devised for each language.", "labels": [], "entities": []}, {"text": "Considering that the relevance referentials examined are the coverage of a feature and the nature of the extension's object set, two methodological questions should be addressed: 1.", "labels": [], "entities": []}, {"text": "How to account for feature coverage automatically, i.e. the number of objects in the extension?", "labels": [], "entities": []}, {"text": "2. How to account for the extension's nature automatically, i.e. the homogeneity or heterogeneity of the set of objects?", "labels": [], "entities": []}, {"text": "As far as feature coverage is concerned, we suggest identifying and testing linguistic patterns that could be matched with the three types of feature coverage.", "labels": [], "entities": [{"text": "feature coverage", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.790162056684494}]}, {"text": "Thus, universal features might be searched out by looking for nomological expressions like \"all N[.", "labels": [], "entities": []}, {"text": "]\" or \"always found in[.", "labels": [], "entities": []}, {"text": "]\"; stereotypical features might be identified by looking for generalizing expressions like \"generally[.", "labels": [], "entities": []}, {"text": "]\" as suggested by Pearson (where more patterns are proposed that may serve to determine the one or the other type of feature coverage or another), or expressions like \"measuring between [.", "labels": [], "entities": []}, {"text": "]\", which express features that allow for some variation in the properties of the extension's objects 9 ; and, finally, singular features might be found by identifying referential expressions, such as proper names.", "labels": [], "entities": []}, {"text": "In order to identify multiple object sets, one could look, following Carlson, for expressions like \"are widespread\", which only apply to kind predicates, thus exclude single object extensions.", "labels": [], "entities": []}, {"text": "With respect to identifying the nature of the multiple object extension, an expression identified as a genus byway of a linguistic marker, for example, and followed by a disjunction would be a sign of a heterogenous set.", "labels": [], "entities": []}, {"text": "However, this kind of judgement may prove difficult to automate.", "labels": [], "entities": []}, {"text": "Expressions like \"for example\" followed by an enumeration may also indicate the heterogeneity of the extension.", "labels": [], "entities": []}, {"text": "Indeed, in some cases, it is difficult even fora human annotator to determine whether the set is homogenous or heterogenous.", "labels": [], "entities": []}, {"text": "These methodological questions should be further examined in order to determine to what extent this particular hypothesis maybe used as a reliable feature relevance referential, and to see if its evaluation is easily automated or if evaluation needs to be performed by a human judge, who may apply a wider range of tests to asses the relevance of a feature -of extracted information-with respect to the extension, while considering the exemplified attributes and values.", "labels": [], "entities": []}, {"text": "She might not only rely on linguistic markers, but also use linguistic tests that require making more complex inferences, not to mention make use of tests that are based on her understanding and interpretation of the information in the extracted text, or on her background knowledge of the world.", "labels": [], "entities": []}], "tableCaptions": []}