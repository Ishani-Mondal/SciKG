{"title": [{"text": "Using Search Engine to Construct a Scalable Corpus for Vietnamese Lexical Development for Word Segmentation", "labels": [], "entities": [{"text": "Vietnamese Lexical Development", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.6657159129778544}, {"text": "Word Segmentation", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7167534381151199}]}], "abstractContent": [{"text": "As the web content becomes more accessible to the Vietnamese community across the globe, there is a need to process Vietnamese query texts properly to find relevant information.", "labels": [], "entities": []}, {"text": "The recent deployment of a Vietnamese translation tool on a well-known search engine justifies its importance in gaining popularity with the World Wide Web.", "labels": [], "entities": [{"text": "Vietnamese translation tool", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.6948120296001434}]}, {"text": "There are still problems in the translation and retrieval of Vietnamese language as its word recognition is not fully addressed.", "labels": [], "entities": [{"text": "translation and retrieval of Vietnamese language", "start_pos": 32, "end_pos": 80, "type": "TASK", "confidence": 0.7619396448135376}, {"text": "word recognition", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7145648151636124}]}, {"text": "In this paper we introduce a semi-supervised approach in building a general scalable web corpus for Vietnamese using search engine to facilitate the word segmentation process.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.7171002179384232}]}, {"text": "Moreover, we also propose a segmentation algorithm which recognizes effectively Out-Of-Vocabulary (OOV) words.", "labels": [], "entities": []}, {"text": "The result indicates that our solution is scalable and can be applied for real time translation program and other linguistic applications.", "labels": [], "entities": [{"text": "real time translation program", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.6686545461416245}]}, {"text": "This work is here is a continuation of the work of Nguyen D.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Vietnamese language as a minority language is gaining popularity including content and audience.", "labels": [], "entities": []}, {"text": "It is important to emphasize a need for natural language such as search engines or translation tools to process the data correctly.", "labels": [], "entities": []}, {"text": "With this emphasis, we need to have away to improve and automate the training process as well as expanding its training data.", "labels": [], "entities": []}, {"text": "Previous works in constructing segmentation systems for the Vietnamese language relied on single source of information such as newspapers or electronic dictionaries (Le H., Le T.).", "labels": [], "entities": []}, {"text": "Mono-source corpora would work best within their domain, and might notwork well externally per.", "labels": [], "entities": []}, {"text": "described the dictionary based approach as problematic due to the lack of consistency and completeness.", "labels": [], "entities": [{"text": "consistency", "start_pos": 74, "end_pos": 85, "type": "METRIC", "confidence": 0.9909852743148804}]}, {"text": "This speaks to the need of standardizations between dictionaries, concrete grammar theories, and being up-to-date with the arrival of new words.", "labels": [], "entities": []}, {"text": "In the work of Nguyen C., corpus training was done manually by linguists.", "labels": [], "entities": [{"text": "corpus training", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8838895559310913}]}, {"text": "This was very time-consuming and costly.", "labels": [], "entities": []}, {"text": "Because the task is performed only once, a corpus will go stale and will get out-of-date., in a comparison with major Vietnamese segmentation approaches, concluded that the handling of unknown compound words is a much greater source of segmenting errors and underscored that future effort should be geared at prioritizing towards the automatic detection of new compounds.", "labels": [], "entities": []}, {"text": "In this paper, we first present the main issues with the Vietnamese word segmentation problem.", "labels": [], "entities": [{"text": "Vietnamese word segmentation problem", "start_pos": 57, "end_pos": 93, "type": "TASK", "confidence": 0.6491426303982735}]}, {"text": "We describe the two approaches in obtaining raw text from the Web.", "labels": [], "entities": []}, {"text": "Then, we present our approach in building a large web corpus fora word segmentation function and compare our result against a sophisticated algorithm built on a human trained corpus.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7506869733333588}]}, {"text": "Finally, we provide our conclusion and offer suggestions for future research directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "With no restriction, there were 167,735 searches performed using the Yahoo!", "labels": [], "entities": []}, {"text": "We bootstrapped the initial core lexicons from Ho's Word List (2004) and built up to gather lexical statistics and discovered new OOV words.", "labels": [], "entities": [{"text": "Ho's Word List (2004)", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.8849297591618129}]}, {"text": "The corpus syllables classifications and their occurrences are shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5. Performance Results Comparison", "labels": [], "entities": [{"text": "Comparison", "start_pos": 30, "end_pos": 40, "type": "TASK", "confidence": 0.4030766785144806}]}]}