{"title": [{"text": "SemEval-2010 Task 7: Argument Selection and Coercion", "labels": [], "entities": [{"text": "Argument Selection", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.6978964656591415}]}], "abstractContent": [{"text": "In this paper, we describe the Argument Selection and Coercion task, currently in development for the SemEval-2 evaluation exercise scheduled for 2010.", "labels": [], "entities": [{"text": "Argument Selection", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7354373037815094}, {"text": "SemEval-2 evaluation exercise", "start_pos": 102, "end_pos": 131, "type": "TASK", "confidence": 0.8648732304573059}]}, {"text": "This task involves characterizing the type of compositional operation that exists between a predicate and the arguments it selects.", "labels": [], "entities": [{"text": "characterizing the type of compositional operation", "start_pos": 19, "end_pos": 69, "type": "TASK", "confidence": 0.6289520015319189}]}, {"text": "Specifically, the goal is to identify whether the type that a verb selects is satisfied directly by the argument, or whether the argument must change type to satisfy the verb typing.", "labels": [], "entities": []}, {"text": "We discuss the problem in detail and describe the data preparation for the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, a number of annotation schemes that encode semantic information have been developed and used to produce data sets for training machine learning algorithms.", "labels": [], "entities": []}, {"text": "Semantic markup schemes that have focused on annotating entity types and, more generally, word senses, have been extended to include semantic relationships between sentence elements, such as the semantic role (or label) assigned to the argument by the predicate.", "labels": [], "entities": []}, {"text": "In this task, we take this one step further, in that this task attempts to capture the \"compositional history\" of the argument selection relative to the predicate.", "labels": [], "entities": []}, {"text": "In particular, this task attempts to identify the operations of type adjustment induced by a predicate over its arguments when they do not match its selectional properties.", "labels": [], "entities": []}, {"text": "The task is defined as follows: for each argument of a predicate, identify whether the entity in that argument position satisfies the type expected by the predicate.", "labels": [], "entities": []}, {"text": "If not, then one needs to identify how the entity in that position satisfies the typing expected by the predicate; that is, to identify the source and target types in a type-shifting (or coercion) operation.", "labels": [], "entities": []}, {"text": "Consider the example below, where the verb report normally selects fora human in subject position as in (1).", "labels": [], "entities": []}, {"text": "Notice, however, that through a metonymic interpretation, this constraint can be violated as demonstrated in (1).", "labels": [], "entities": []}, {"text": "John reported in late from Washington. b. Washington reported in late.", "labels": [], "entities": []}, {"text": "Neither the surface annotation of entity extents and types, nor assigning semantic roles associated with the predicate would reflect in this case a crucial point: namely, that in order for the typing requirements of the predicate to be satisfied, what has been referred to a type coercion or a metonymy) has taken place.", "labels": [], "entities": []}, {"text": "The SemEval Metonymy task) was a good attempt to annotate such metonymic relations over a larger data set.", "labels": [], "entities": [{"text": "SemEval Metonymy task", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8344058593114217}]}, {"text": "This task involved two types with their metonymic variants: (2) i.", "labels": [], "entities": []}, {"text": "Categories for Locations: literal, place-for-people, place-for-event, place-for-product; ii.", "labels": [], "entities": []}, {"text": "Categories for Organizations: literal, organizationfor-members, organization-for-event, organization-forproduct, organization-for-facility.", "labels": [], "entities": []}, {"text": "One of the limitations of this approach, however, is that, while appropriate for these specialized metonymy relations, the annotation specification and resulting corpus are not an informative guide for extending the annotation of argument selection more broadly.", "labels": [], "entities": []}, {"text": "In fact, the metonymy example in (1) is an instance of a much more pervasive phenomenon of type shifting and coercion in argument selection.", "labels": [], "entities": [{"text": "type shifting", "start_pos": 91, "end_pos": 104, "type": "TASK", "confidence": 0.773057609796524}, {"text": "argument selection", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.6953580975532532}]}, {"text": "For example, in (3) below, the sense annotation for the verb enjoy should arguably assign similar values to both (3a) and (3b).", "labels": [], "entities": []}, {"text": "The consequence of this, however, is that, undercurrent sense and role annotation strategies, the mapping to a syntactic realization fora given sense is made more complex, and is in fact, perplexing fora clustering or learning algorithm operating over subcategorization types for the verb.", "labels": [], "entities": []}], "datasetContent": [{"text": "Precision and recall will be used as evaluation metrics.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9898961782455444}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9988489151000977}]}, {"text": "A scoring program will be supplied for participants.", "labels": [], "entities": []}, {"text": "Two subtasks will be evaluated separately: (1) identifying the compositional operation (i.e. selection vs. coercion) and (2) identifying the source and target argument type, for each relevant argument.", "labels": [], "entities": []}, {"text": "Both subtasks require sense disambiguation which will not be evaluated separately.", "labels": [], "entities": []}, {"text": "Since type-shifting is by its nature a relatively rare event, the distribution between different types of compositional operations in the data set will be necessarily skewed.", "labels": [], "entities": []}, {"text": "One of the standard sampling methods for handling class imbalance is downsizing, where the number of instances of the major class in the training set is artificially reduced.", "labels": [], "entities": []}, {"text": "Another possible alternative is to assign higher error costs to misclassification of minor class instances ().", "labels": [], "entities": []}], "tableCaptions": []}