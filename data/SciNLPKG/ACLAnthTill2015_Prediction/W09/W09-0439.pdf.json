{"title": [], "abstractContent": [{"text": "The most commonly used method for training feature weights in statistical machine translation (SMT) systems is Och's minimum error rate training (MERT) procedure.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.7748662034670512}, {"text": "minimum error rate training (MERT", "start_pos": 117, "end_pos": 150, "type": "METRIC", "confidence": 0.7650815745194753}]}, {"text": "A well-known problem with Och's procedure is that it tends to be sensitive to small changes in the system, particularly when the number of features is large.", "labels": [], "entities": []}, {"text": "In this paper, we quantify the stability of Och's procedure by supplying different random seeds to a core component of the procedure (Powell's algorithm).", "labels": [], "entities": []}, {"text": "We show that for systems with many features, there is extensive variation in outcomes, both on the development data and on the test data.", "labels": [], "entities": []}, {"text": "We analyze the causes of this variation and propose modifications to the MERT procedure that improve stability while helping performance on test data.", "labels": [], "entities": [{"text": "MERT", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.533409059047699}, {"text": "stability", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9556930065155029}]}], "introductionContent": [{"text": "Most recent approaches in SMT, eg, use a log-linear model to combine probabilistic features.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9966082572937012}]}, {"text": "Minimum ErrorRate Training (MERT) aims to find the set of loglinear weights that yields the best translation performance on a development corpus according to some metric such as BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.9504697322845459}]}, {"text": "This is an essential step in SMT training that can significantly improve performance on a test corpus compared to setting weights by hand.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9183272421360016}]}, {"text": "MERT is a difficult problem, however, because calculating BLEU as a function of log-linear weights requires decoding, which is an expensive operation.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.5647454261779785}, {"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.997778594493866}]}, {"text": "Moreover, because this function is not differentiable, efficient gradient-based optimization algorithms cannot be used.", "labels": [], "entities": []}, {"text": "Och's procedure is the most widely-used version of MERT for SMT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 51, "end_pos": 55, "type": "TASK", "confidence": 0.7362903356552124}, {"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9802855253219604}]}, {"text": "To reduce computational cost, it relies on the key technique of optimizing weights over n-best lists of translation hypotheses rather than overall possible hypotheses.", "labels": [], "entities": []}, {"text": "This allows the most probable hypothesis under a given set of weights-and the corresponding BLEU score-to be found by enumerating n-best entries rather than decoding.", "labels": [], "entities": [{"text": "BLEU score-to", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.9793123602867126}]}, {"text": "Some variant on Powell's algorithm) is typically used to maximize BLEU in this setting.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9856522083282471}]}, {"text": "The n-best lists are constructed by alternating decoding and BLEU maximization operations: decoding adds new hypotheses to the current lists, then BLEU is maximized over the lists to find new best weights for the subsequent decoding step, etc.", "labels": [], "entities": [{"text": "BLEU maximization", "start_pos": 61, "end_pos": 78, "type": "METRIC", "confidence": 0.9769035577774048}, {"text": "BLEU", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9978724718093872}]}, {"text": "This process continues until no new hypotheses are found.", "labels": [], "entities": []}, {"text": "Och's procedure works well in practice, usually converging after 10-20 calls to the decoder, far fewer than would be required to maximize BLEU directly with a general-purpose optimization algorithm.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.9920116066932678}]}, {"text": "However, it tends to be sensitive to small changes in the system, particularly for large feature sets.", "labels": [], "entities": []}, {"text": "This is a well-known problem with Och's procedure.", "labels": [], "entities": []}, {"text": "It makes it difficult to assess the contribution of features, because the measured gain in performance due to anew feature can depend heavily on the setting of some apparently unrelated parameter such as the size of n-best list used.", "labels": [], "entities": []}, {"text": "Features with the potential for statistically significant gains maybe rejected because Och's procedure failed to find good weights for them.", "labels": [], "entities": []}, {"text": "In this paper we attempt to quantify the stability of Och's procedure under different conditions by measuring the variation in test-set scores across different random seeds used with Powell's algorithm.", "labels": [], "entities": []}, {"text": "We show that there is extensive variation for large feature sets, and that it is due to two main factors: the occasional failure of Och's procedure to find a good maximum on the development set, and the failure of some maxima to generalize to the test set.", "labels": [], "entities": []}, {"text": "We analyze the causes of each of these problems, and propose solutions for improving the stability of the overall procedure.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments described here were carried outwith a standard phrase-based SMT system (Koehn It can also choose to optimize linear combinations of weights in order to avoid ridges that are not aligned with the original coordinates, which can be done just as easily..", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.8855624198913574}]}, {"text": "We used two separate log-linear models for MERT: \u2022 large: 16 phrase-table features, 2 4-gram language model features, 1 distortion feature, and 1 word-count feature (20 features in total).", "labels": [], "entities": [{"text": "MERT", "start_pos": 43, "end_pos": 47, "type": "TASK", "confidence": 0.9412641525268555}]}, {"text": "\u2022 small: 2 phrase-table features, 1 4-gram language model feature, 1 distortion feature, and 1 word-count feature (5 features in total).", "labels": [], "entities": []}, {"text": "The phrase-table features for the large model were derived as follows.", "labels": [], "entities": []}, {"text": "Globally-trained HMM and IBM2 models were each used to extract phrases from UN and non-UN portions of the training corpora (see below).", "labels": [], "entities": []}, {"text": "This produced four separate phrase tables, each of which was used to generate both relative-frequency and \"lexical\" conditional phrase-pair probabilities in both directions (target given source and vice versa).", "labels": [], "entities": []}, {"text": "The two language model features in the large log-linear model were trained on the UN and non-UN corpora.", "labels": [], "entities": []}, {"text": "Phrase-: Test-set BLEU score variation with 10 different random seeds, for small (S) and large (L) models on dev sets 1 and 2.", "labels": [], "entities": [{"text": "BLEU score variation", "start_pos": 18, "end_pos": 38, "type": "METRIC", "confidence": 0.9464537302652994}]}, {"text": "The avg column gives the average BLEU score over the 10 runs; \u2206 gives the difference between the maximum and minimum scores, and S is the standard deviation. and NIST 2005 corpora were used for testing.", "labels": [], "entities": [{"text": "avg", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9863751530647278}, {"text": "BLEU score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9806297123432159}, {"text": "NIST 2005 corpora", "start_pos": 162, "end_pos": 179, "type": "DATASET", "confidence": 0.9828500747680664}]}, {"text": "Table 1 summarizes the sizes of the devtest corpora, all of which have four reference translations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Development and test corpora.", "labels": [], "entities": []}, {"text": " Table 2: Test-set BLEU score variation with 10  different random seeds, for small (S) and large (L)  models on dev sets 1 and 2. The avg column gives  the average BLEU score over the 10 runs; \u2206 gives  the difference between the maximum and mini- mum scores, and S is the standard deviation.", "labels": [], "entities": [{"text": "BLEU score variation", "start_pos": 19, "end_pos": 39, "type": "METRIC", "confidence": 0.9328753153483073}, {"text": "BLEU score", "start_pos": 164, "end_pos": 174, "type": "METRIC", "confidence": 0.9791860580444336}]}, {"text": " Table 3: Pearson (\u03c1) and Spearman rank (r) cor- relation between dev-set and test-set BLEU scores  for the large log-linear model. The final column  shows nist04/nist06 correlation.", "labels": [], "entities": [{"text": "Pearson (\u03c1)", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9719306081533432}, {"text": "Spearman rank (r) cor- relation", "start_pos": 26, "end_pos": 57, "type": "METRIC", "confidence": 0.8966518640518188}, {"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9886345863342285}, {"text": "correlation", "start_pos": 170, "end_pos": 181, "type": "METRIC", "confidence": 0.6906819939613342}]}, {"text": " Table 4: Performance of various strategies for im- proving maximization on the dev corpora: base- line is the baseline used in section 5; re-seed is  random generator re-seeding; history is accumu- lation of previous best weights as starting point;  and sel a,b,m is the final, weight selection, strat- egy described in section 6, parameterized by a, b,  and m. Strategies are applied cumulatively, as in- dicated by the + signs.", "labels": [], "entities": [{"text": "im- proving maximization", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6299991831183434}]}, {"text": " Table 5: Performance of various MERT tech- niques on the test corpora. (+) sel 5,9,3 is the same  configuration as +sel 5,9,3 in table 4; + reg 10  uses regularized BLEU within this procedure.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 166, "end_pos": 170, "type": "METRIC", "confidence": 0.9833483099937439}]}]}