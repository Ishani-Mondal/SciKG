{"title": [{"text": "Empirical lower bounds on alignment error rates in syntax-based machine translation", "labels": [], "entities": [{"text": "syntax-based machine translation", "start_pos": 51, "end_pos": 83, "type": "TASK", "confidence": 0.6732504566510519}]}], "abstractContent": [{"text": "The empirical adequacy of synchronous context-free grammars of rank two (2-SCFGs) (Satta and Peserico, 2005), used in syntax-based machine translation systems such as Wu (1997), Zhang et al.", "labels": [], "entities": []}, {"text": "(2006) and Chi-ang (2007), in terms of what alignments they induce, has been discussed in Wu (1997) and Wellington et al.", "labels": [], "entities": []}, {"text": "(2006), but with a one-sided focus on so-called \"inside-out alignments\".", "labels": [], "entities": []}, {"text": "Other alignment configurations that cannot be induced by 2-SCFGs are identified in this paper , and their frequencies across a wide collection of hand-aligned parallel corpora are examined.", "labels": [], "entities": []}, {"text": "Empirical lower bounds on two measures of alignment error rate, i.e. the one introduced in Och and Ney (2000) and one where only complete translation units are considered , are derived for 2-SCFGs and related formalisms.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 42, "end_pos": 62, "type": "METRIC", "confidence": 0.703061709801356}]}], "introductionContent": [{"text": "Syntax-based approaches to machine translation typically use synchronous grammars to recognize or produce translation equivalents.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.754292219877243}]}, {"text": "The synchronous * This work was done while the first author was a Senior Researcher at the Dpt. of Linguistics, University of Potsdam, supported by the German Research Foundation in the Emmy Noether project Ptolemaios on grammar learning from parallel corpora; and while he was a Postdoctoral Researcher at the ISV Computational Linguistics Group, Copenhagen Business School, supported by the Danish Research Foundation in the project Efficient syntax-and semantics-based machine translation.", "labels": [], "entities": [{"text": "Efficient syntax-and semantics-based machine translation", "start_pos": 435, "end_pos": 491, "type": "TASK", "confidence": 0.5555007040500641}]}, {"text": "The second author is supported by the German Research Foundation in the Emmy Noether project Ptolemaios on grammar learning from parallel corpora.", "labels": [], "entities": [{"text": "grammar learning from parallel corpora", "start_pos": 107, "end_pos": 145, "type": "TASK", "confidence": 0.7369194209575654}]}, {"text": "production rules are typically learned from alignment structures or from alignment structures and derivation trees for the source string).", "labels": [], "entities": []}, {"text": "They are also used for inducing alignments.", "labels": [], "entities": []}, {"text": "It is for all three reasons, i.e. translation, induction from alignment structures and induction of alignment structures, important that the synchronous grammars are expressive enough to induce all the alignment structures found in hand-aligned gold standard parallel corpora ().", "labels": [], "entities": []}, {"text": "Such alignments are supposed to reflect the structure of translations, typically contain fewer errors and are used to evaluate automatically induced alignments.", "labels": [], "entities": []}, {"text": "In this paper it is shown that the synchronous grammars used in, and are not expressive enough to do that.", "labels": [], "entities": []}, {"text": "The synchronous grammars used in these systems are, formally, synchronous context-free grammars of rank two (2-SCFGs), or equivalently (normal form) inversion transduction grammars (ITGs).", "labels": [], "entities": []}, {"text": "The notion of rank is defined as the maximum number of constituents aligned by a production rule, i.e. the maximum number of distinct indeces.", "labels": [], "entities": []}, {"text": "Our results will be extended to slight extensions of 2-SCFGs, incl.", "labels": [], "entities": []}, {"text": "the extension of ITGs proposed by, synchronous tree substitution grammars of rank two (2-STSGs), i.e. where tree pairs include at most two linked pairs of nonterminals, and synchronous tree-adjoining grammars of rank two (2-STAGs).", "labels": [], "entities": []}, {"text": "The overall frequency of alignment structures that cannot be induced by these approaches is examined across a wide collection of hand-aligned parallel corpora.", "labels": [], "entities": []}, {"text": "Empirical lower bounds on the coverage of the systems are derived from our results.", "labels": [], "entities": []}, {"text": "Our notion of an alignment structure is standard.", "labels": [], "entities": [{"text": "alignment structure", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9001986682415009}]}, {"text": "Words can be aligned to multiple words.", "labels": [], "entities": []}, {"text": "Maximally connected subgraphs are called translation units.", "labels": [], "entities": []}, {"text": "There is one more choice to make in the context of many-to-many alignments, namely whether the alignment relation is such that if w i |w \u2032 k and w i |w \u2032 l , resp., are aligned, and w j |w \u2032 k are aligned too, then w j |w \u2032 l are also aligned.", "labels": [], "entities": []}, {"text": "If so, the alignment structure is divided into complete translation units.", "labels": [], "entities": []}, {"text": "Such alignment structures are therefore called complete; in, alignment structures with this property are said to be closed under transitivity.", "labels": [], "entities": []}, {"text": "An alignment structure is simply written as a sequence of alignments, e.g. or, alternatively, as sequences of (possibly discontinuous) translation units, e.g. w i w j |w \u2032 kw \u2032 l . A translation unit induced by asynchronous grammar is a set of terminals that are recognized or generated simultaneously.", "labels": [], "entities": []}, {"text": "Consequently, synchronous grammars can only induce complete alignment structures (by transitivity of simultaneity).", "labels": [], "entities": []}, {"text": "Syntax-based approaches to machine translations are commonly evaluated in terms of their alignment error rate (AER) on one or more parallel corpora).", "labels": [], "entities": [{"text": "machine translations", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.6904377341270447}, {"text": "alignment error rate (AER)", "start_pos": 89, "end_pos": 115, "type": "METRIC", "confidence": 0.9384183386961619}]}, {"text": "The AER, in the case where all alignments are sure alignments, is where GA are the gold standard alignments, and SA the alignments produced by the system.", "labels": [], "entities": [{"text": "AER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9986627101898193}]}, {"text": "AER has been criticized by.", "labels": [], "entities": [{"text": "AER", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5485990643501282}]}, {"text": "They show that AER does not penalize unequal precision and recall when a distinction between sure and possible alignments is made.", "labels": [], "entities": [{"text": "AER", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9945030212402344}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9891235828399658}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9985643029212952}]}, {"text": "Since no such distinction is assumed below, the classical definition is used.", "labels": [], "entities": []}, {"text": "We introduce also the notion of translation unit error rate (TUER), which is defined as where GU are the translation units in the gold standard, and S U the translation units produced by the system.", "labels": [], "entities": [{"text": "translation unit error rate (TUER)", "start_pos": 32, "end_pos": 66, "type": "METRIC", "confidence": 0.8186112897736686}, {"text": "GU", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.9493722915649414}]}, {"text": "In other words, what is measured is a system's ability to predict translation units relative to the Gold standard, not just its ability to predict alignments.", "labels": [], "entities": [{"text": "Gold standard", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.8687345683574677}]}, {"text": "If the system only gets part of a translation unit right, it is not rewarded.", "labels": [], "entities": []}, {"text": "In the context of many-to-many alignments, this measure may tell us more about translation quality than AER.", "labels": [], "entities": [{"text": "translation", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.9536908268928528}, {"text": "AER", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9942019581794739}]}, {"text": "Consider, for instance, the small children's book discourse in Danish: ( Say (1-4) and the English translations area parallel corpus on which we would like to evaluate an aligner or a statistical machine translation system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 184, "end_pos": 215, "type": "TASK", "confidence": 0.6473388572533926}]}, {"text": "Say also that the test corpus has been aligned.", "labels": [], "entities": []}, {"text": "Let the first three sentences be our training data and (4) our test data.", "labels": [], "entities": []}, {"text": "Note that the words laegger . .", "labels": [], "entities": []}, {"text": "sammen form a discontinuous translation unit ('add').", "labels": [], "entities": []}, {"text": "Say our aligner aligned only sammen and add, but not laegger and add.", "labels": [], "entities": []}, {"text": "This would mean that the alignments or translations of add would most likely be associated with the following probabilities: .66 which again means that our system is likely to arrive at the wrong alignment or translation in (4).", "labels": [], "entities": []}, {"text": "Nevertheless these alignments are rewarded in AER.", "labels": [], "entities": [{"text": "AER", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.8782129287719727}]}, {"text": "TUER, on the other hand, reflects the intuition that unless you get the entire translation unit it's better to get nothing at all.", "labels": [], "entities": [{"text": "TUER", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.4623633325099945}]}, {"text": "The hand-aligned parallel corpora in our experiments come from the Copenhagen Dependency Treebank, for five different language pairs, the German-English parallel corpus used in, and the six parallel corpora of the first 100 sentences of Europarl () for different language pairs documented in.", "labels": [], "entities": [{"text": "Copenhagen Dependency Treebank", "start_pos": 67, "end_pos": 97, "type": "DATASET", "confidence": 0.9548855821291605}, {"text": "Europarl", "start_pos": 237, "end_pos": 245, "type": "DATASET", "confidence": 0.969928503036499}]}, {"text": "Consequently, our experiments include a total of 12 parallel corpora.", "labels": [], "entities": []}, {"text": "The biggest parallel corpus consists of 4,729 sentence pairs; the smallest of 61 sentence pairs.", "labels": [], "entities": []}, {"text": "The average size is 541 sentence pairs.", "labels": [], "entities": []}, {"text": "The six parallel corpora documented in use sure and possible alignments; in our experiments, as already mentioned, the two types of alignments are treated alike.", "labels": [], "entities": []}, {"text": "3 The annotations of the parallel corpora differ in format and consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9900716543197632}]}, {"text": "In fact the empirical lower bounds obtained below are lower bounds in two senses: (i) they are lower bounds on TUERs because TUERs maybe significantly higher than the empirical lower bounds found here, and (ii) they are lower bounds in the sense that there maybe hidden instances of the configurations in question in the parallel corpora.", "labels": [], "entities": []}, {"text": "Most seriously, our search algorithms only sort alignments, but not their elements; instead they assume that their elements are listed in chronological order.", "labels": [], "entities": []}, {"text": "Sometimes, but rarely, this is not the case.", "labels": [], "entities": []}, {"text": "Consider, for instance, file 1497, line 12 in the Danish-Spanish parallel corpus in the Copenhagen Dependency Treebank: <align out=\"a56\" type=\"\" in=\"b30+b32+b8\" outsign=\"af\" insign=\"del de de\"/> This is a translation unit.", "labels": [], "entities": [{"text": "Danish-Spanish parallel corpus in the Copenhagen Dependency Treebank", "start_pos": 50, "end_pos": 118, "type": "DATASET", "confidence": 0.8439305573701859}]}, {"text": "The word in position 56 in the source string is aligned to the words in positions 8, 30 and 32 in the target string, but note that the target string words do not appear in chronological order.", "labels": [], "entities": []}, {"text": "In some cases our algorithms take care of this; they do not, however, in general search all possible combinations of words and alignments, but rely on the linear order Sect.", "labels": [], "entities": []}, {"text": "2 discusses the frequency of inside-out alignments in our hand-aligned corpora, whereas Sect.", "labels": [], "entities": []}, {"text": "3 is about complex translation units.", "labels": [], "entities": []}, {"text": "4 briefly introduces formalisms for syntax-based machine translation, but some prior knowledge is assumed.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.6832205802202225}]}, {"text": "5 brings the three sections together and presents lower bounds on the coverage of the systems discussed in Sect.", "labels": [], "entities": []}, {"text": "4, obtained by inspection of the results in Sect.", "labels": [], "entities": []}, {"text": "6 compares our results to related work, in particular Zens and Ney (2003).", "labels": [], "entities": []}, {"text": "identified so-called inside-out alignments, two alignment configurations that cannot be induced by binary synchronous context-free grammars; these alignment configurations, while infrequent in language pairs such as English-French (), have been argued to be frequent in other language pairs, incl.", "labels": [], "entities": []}, {"text": "English-Chinese () and English-Spanish ().", "labels": [], "entities": []}, {"text": "While our main focus is on configurations that involve discontinuous translation units, the frequencies of inside-out alignments in our parallel corpora are also reported.", "labels": [], "entities": []}, {"text": "Recall that inside-out alignments are of the form (or upside-down):.", "labels": [], "entities": []}, {"text": "Note that there is some variation across the corpora.", "labels": [], "entities": []}, {"text": "The fact that there are no inside-out alignments in corpora 2-4 maybe because annotators of these corpora have been very conservative, i.e. there are many unaligned nodes; the first corpus, which is also part of the Danish Dependency Treebank, also has very few inside-out alignments.", "labels": [], "entities": [{"text": "Danish Dependency Treebank", "start_pos": 216, "end_pos": 242, "type": "DATASET", "confidence": 0.955059548219045}]}, {"text": "It is not entirely clear to us if this has to do with the languages in question or the annotation guide lines (cf. Danish-Spanish).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}