{"title": [{"text": "Combining MDL Transliteration Training with Discriminative Modeling", "labels": [], "entities": [{"text": "Combining MDL Transliteration", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.654867043097814}]}], "abstractContent": [{"text": "We present a transliteration system that introduces minimum description length training for transliteration and combines it with discriminative modeling.", "labels": [], "entities": []}, {"text": "We apply the proposed approach to translitera-tion from English to 8 non-Latin scripts, with promising results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent research in transliteration and translation showed utility of increasing the n-gram size in transliteration models and phrase tables ().", "labels": [], "entities": []}, {"text": "Yet most learning algorithms for training n-gram transliteration models place restrictions on the size of n-gram due to tractability and overfitting issues, and, in the case of machine translation, construct the phrase table after training the model, in an ad-hoc manner.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 177, "end_pos": 196, "type": "TASK", "confidence": 0.7096377462148666}]}, {"text": "In this paper, we present a minimum description length (MDL) approach for learning transliteration models comprising n-grams of unrestricted size.", "labels": [], "entities": []}, {"text": "Given a bilingual dictionary of transliterated data we seek to derive a transliteration model so that the combined size of the data and the model is minimized.", "labels": [], "entities": []}, {"text": "Use of discriminative modeling for transliteration and translation is another promising direction allowing incorporation of arbitrary features in the transliteration process (.", "labels": [], "entities": [{"text": "translation", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.8359622955322266}]}, {"text": "Here we propose to use the transliteration model derived via MDL training as a starting point and learn the model weights in the discriminative manner.", "labels": [], "entities": []}, {"text": "The discriminative approach also provides a natural way to integrate the language modeling component into the transliteration decoding process.", "labels": [], "entities": []}, {"text": "We experimentally evaluate the proposed approach on the standard datasets for the task of transliterating from English to 8 non-Latin scripts", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the standard data for transliterating from English into 8 non-Latin scripts: Chinese (); Korean, Japanese (Kanji), and Japanese (Katakana) (;.", "labels": [], "entities": []}, {"text": "The data is provided as part of the Named Entities Workshop 2009 Machine Transliteration Shared Task (.", "labels": [], "entities": [{"text": "Named Entities Workshop 2009 Machine Transliteration Shared Task", "start_pos": 36, "end_pos": 100, "type": "TASK", "confidence": 0.6591457799077034}]}, {"text": "For all 8 datasets, we report scores on the standard tests sets provided as part of the evaluation.", "labels": [], "entities": []}, {"text": "Details of the evaluation methodology are presented in ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: MDL Data and Model Compression  showing initial data size, final combined data and  model size, the compression ratio, and the number  of n-gram pairs in the final model.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results for transliteration  from English to 8 non-Latin scripts comparing  performance of generative (T1) and corresponding  discriminative (T2) models.", "labels": [], "entities": []}]}