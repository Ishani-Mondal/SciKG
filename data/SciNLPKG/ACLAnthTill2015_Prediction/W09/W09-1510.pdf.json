{"title": [], "abstractContent": [{"text": "We describe the design and implementation of a system for data exploration over dependency parses and derived semantic representations in a large-scale NLP-based search system at powerset.com.", "labels": [], "entities": []}, {"text": "Because of the distributed nature of the document repository and the processing infrastructure, and also the complex representations of the corpus data, standard text analysis tools such as grep or awk or language modeling toolkits are not applicable.", "labels": [], "entities": []}, {"text": "This paper explores the challenges of extracting statistical information and of building language models in such a distributed NLP environment , and introduces a corpus analysis system , Oceanography, that simplifies the writing of analysis code and transparently takes advantage of existing distributed processing infrastructure.", "labels": [], "entities": []}], "introductionContent": [{"text": "In computational linguistics we deal with large corpora and vast amounts of data from which we would like to extract useful information.", "labels": [], "entities": []}, {"text": "The size of the text resources, derived linguistic analyses, and the complexity of their representations is often a stumbling block on the way to understanding the statistical and linguistic behavior within the corpus.", "labels": [], "entities": []}, {"text": "Simple software tools suffice for small or simple analysis problems, or for building models of easily represented relations.", "labels": [], "entities": []}, {"text": "However, as the size of data, the intricacy of relations to be analyzed, and the complexity of the representation grow, so too does the technical difficulty of conducting the analysis.", "labels": [], "entities": []}, {"text": "Software is our given means of escape from this escalation of complexity.", "labels": [], "entities": []}, {"text": "However, as \"computational linguists,\" we often find ourselves spending more time and attention building software to perform the required computations than we do on understanding the linguistics.", "labels": [], "entities": []}, {"text": "Even once a suitable set of NLP tools (e.g. taggers, chunkers, parsers, etc.) has been chosen, analysis software, in the CL world, often consists of \"throw away\" scripts.", "labels": [], "entities": []}, {"text": "Small, ad hoc programs are often the norm, often with no assurance (via strict design or testing) of correctness or completeness.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}