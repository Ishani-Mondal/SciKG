{"title": [], "abstractContent": [{"text": "This paper describes our contribution to the semantic role labeling task (SRL-only) of the CoNLL-2009 shared task in the closed challenge (Haji\u010d et al., 2009).", "labels": [], "entities": [{"text": "semantic role labeling task (SRL-only)", "start_pos": 45, "end_pos": 83, "type": "TASK", "confidence": 0.6752379025731768}]}, {"text": "Our system consists of a pipeline of independent, local clas-sifiers that identify the predicate sense, the arguments of the predicates, and the argument labels.", "labels": [], "entities": []}, {"text": "Using these local models, we carried out abeam search to generate a pool of candidates.", "labels": [], "entities": []}, {"text": "We then reranked the candidates using a joint learning approach that combines the local models and proposition features.", "labels": [], "entities": []}, {"text": "To address the multilingual nature of the data, we implemented a feature selection procedure that systematically explored the feature space, yielding significant gains over a standard set of features.", "labels": [], "entities": []}, {"text": "Our system achieved the second best semantic score overall with an average labeled semantic F1 of 80.31.", "labels": [], "entities": [{"text": "labeled semantic F1", "start_pos": 75, "end_pos": 94, "type": "METRIC", "confidence": 0.5325306057929993}]}, {"text": "It obtained the best F1 score on the Chinese and German data and the second best one on English.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.98173788189888}]}], "introductionContent": [{"text": "In this paper, we describe a three-stage analysis approach that uses the output of a dependency parser and identifies the arguments of the predicates in a sentence.", "labels": [], "entities": []}, {"text": "The first stage consists of a pipeline of independent classifiers.", "labels": [], "entities": []}, {"text": "We carried out the predicate disambiguation with a set of greedy classifiers, where we applied one classifier per predicate lemma.", "labels": [], "entities": [{"text": "predicate disambiguation", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.9559855163097382}]}, {"text": "We then used abeam search to identify the arguments of each predicate and to label them, yielding a pool of candidate propositions.", "labels": [], "entities": []}, {"text": "The second stage consists of a reranker that we applied to the candidates using the local models and proposition features.", "labels": [], "entities": []}, {"text": "We combined the score of the greedy classifiers and the reranker in a third stage to select the best candidate proposition.", "labels": [], "entities": []}, {"text": "We evaluated our semantic parser on a set of seven languages provided by the organizers of the CoNLL-2009 shared task: Catalan and Spanish,),), English (), German (), and Japanese ().", "labels": [], "entities": []}, {"text": "Our system achieved an average labeled semantic F1 of 80.31, which corresponded to the second best semantic score overall.", "labels": [], "entities": [{"text": "labeled semantic F1", "start_pos": 31, "end_pos": 50, "type": "METRIC", "confidence": 0.5459580620129904}]}, {"text": "After the official evaluation was completed, we discovered a fault in the training procedure of the reranker for Spanish.", "labels": [], "entities": []}, {"text": "The revised average labeled semantic F1 after correction was 80.80.", "labels": [], "entities": [{"text": "semantic F1", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.5011389702558517}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Summary of submitted results: closed challenge,  semantic F1. * denotes the post-evaluation results ob- tained for Spanish after a bug fix.", "labels": [], "entities": [{"text": "F1", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.7465468049049377}]}, {"text": " Table 4: Improvement of reranker. * denotes the post- evaluation results obtained for Spanish after a bug fix.", "labels": [], "entities": []}, {"text": " Table 5: Summary of training and parsing times on an Apple Mac Pro, 3.2 GHz.", "labels": [], "entities": []}]}