{"title": [{"text": "An Analysis of Bootstrapping for the Recognition of Temporal Expressions", "labels": [], "entities": [{"text": "Recognition of Temporal Expressions", "start_pos": 37, "end_pos": 72, "type": "TASK", "confidence": 0.8862871825695038}]}], "abstractContent": [{"text": "We present a semi-supervised (bootstrapping) approach to the extraction of time expression mentions in large unlabelled corpora.", "labels": [], "entities": []}, {"text": "Because the only supervision is in the form of seed examples, it becomes necessary to resort to heuristics to rank and filter out spurious patterns and candidate time expressions.", "labels": [], "entities": []}, {"text": "The application of bootstrapping to time expression recognition is, to the best of our knowledge , novel.", "labels": [], "entities": [{"text": "time expression recognition", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.7600100835164388}]}, {"text": "In this paper, we describe one such architecture for bootstrapping Information Extraction (IE) patterns-suited to the extraction of entities, as opposed to events or relations-and summarize our experimental findings.", "labels": [], "entities": [{"text": "bootstrapping Information Extraction (IE) patterns-suited", "start_pos": 53, "end_pos": 110, "type": "TASK", "confidence": 0.789302796125412}]}, {"text": "These point out to the fact that a pattern set with a good increase in recall with respect to the seeds is achievable within our framework while, on the other side, the decrease in precision in successive iterations is succesfully controlled through the use of ranking and selection heuristics.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9988366961479187}, {"text": "precision", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.9980130195617676}]}, {"text": "Experiments are still underway to achieve the best use of these heuristics and other parameters of the boot-strapping algorithm.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of time expression recognition refers to the identification in free-format natural language text of the occurrences of expressions that denote time.", "labels": [], "entities": [{"text": "time expression recognition", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6354482471942902}]}, {"text": "This problem is a subpart of a task called TERN (Temporal Expression Recognition and Normalization), where temporal expressions are first identified in text and then its intended temporal meaning is represented in a canonical format.", "labels": [], "entities": [{"text": "TERN", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.98451828956604}, {"text": "Temporal Expression Recognition and Normalization)", "start_pos": 49, "end_pos": 99, "type": "TASK", "confidence": 0.7895591904719671}]}, {"text": "TERN was first proposed as an independent task in the 2004 edition of the ACE conferences . The most widely used standard for the annotation of temporal expressions is TIMEX).", "labels": [], "entities": [{"text": "TERN", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8227620720863342}, {"text": "ACE conferences", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.904096394777298}, {"text": "TIMEX", "start_pos": 168, "end_pos": 173, "type": "METRIC", "confidence": 0.8354471921920776}]}, {"text": "The most common approach to temporal expression recognition in the past has been the use of hand-made grammars to capture the expressions (see) for examples), which can then be easily expanded with additional attributes for the normalization task, based on computing distance and direction (past or future) with respect to a reference time.", "labels": [], "entities": [{"text": "temporal expression recognition", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6667937835057577}]}, {"text": "This approach achieves an F 1 -measure of approximately 85% for recognition and normalization.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9901503622531891}, {"text": "recognition", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.8858071565628052}]}, {"text": "The use of machine learning techniquesmainly statistical-for this task is a more recent development, either alongside the traditional handgrammar approach to learn to distinguish specific difficult cases), or on its own ().", "labels": [], "entities": []}, {"text": "The latter apply SVMs to the recognition task alone, using the output of several human-made taggers as additional features for the classifier, and report an F 1 -measure of 87.8%.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 157, "end_pos": 169, "type": "METRIC", "confidence": 0.991448312997818}]}, {"text": "Bootstrapping techniques have been used for such diverse NLP problems as: word sense disambiguation, named entity classification), IE pattern acquisition), document classification (), fact extraction from the web) and hyponymy relation extraction (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.6835757891337076}, {"text": "named entity classification", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.648126095533371}, {"text": "IE pattern acquisition", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.9076396624247233}, {"text": "document classification", "start_pos": 156, "end_pos": 179, "type": "TASK", "confidence": 0.8059438765048981}, {"text": "fact extraction from the web", "start_pos": 184, "end_pos": 212, "type": "TASK", "confidence": 0.8235084772109985}, {"text": "hyponymy relation extraction", "start_pos": 218, "end_pos": 246, "type": "TASK", "confidence": 0.6606265604496002}]}, {"text": "( used bootstrapping to train decision list classifiers to disambiguate between two senses of a word, achieving impressive classification accuracy.) applied bootstrapping to extract rules for named entity (NE) classification, seeding the sytem with a few handcrafted rules.", "labels": [], "entities": [{"text": "accuracy.", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9703232049942017}, {"text": "named entity (NE) classification", "start_pos": 192, "end_pos": 224, "type": "TASK", "confidence": 0.6765962342421213}]}, {"text": "Their main innovation was to split training in two alternate stages: during one step, only contextual rules are sought; during the second step, the new contextual rules are used to tag further NEs and these are used to produce new spelling rules.", "labels": [], "entities": []}, {"text": "Bootstrapping approaches are employed in, (),, and) in order to find IE patterns for domain-specific event extraction.) employ a bootstrapping process to extract general facts from the Web, viewed as two-term relationships (e.g could bean instance of a \"born in year\" relationship).", "labels": [], "entities": [{"text": "domain-specific event extraction.", "start_pos": 85, "end_pos": 118, "type": "TASK", "confidence": 0.6862495541572571}]}, {"text": "() used bootstrapping co-trained with an EM classifier in order to perform topic classification of documents based on the presence of certain learned syntactic-semantic patterns.", "labels": [], "entities": [{"text": "topic classification of documents", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.8067043051123619}]}, {"text": "In (, bootstrapping is applied to finding new members of certain class of objects (i.e. an \"is-a\" relationship), by providing a member of the required class as seed and using a \"such as\" type of textual pattern to locate new instances.", "labels": [], "entities": []}, {"text": "The recognition of temporal expressions is crucial for many applications in NLP, among them: IE, Question Answering (QA) and Automatic Summarization (for the temporal ordering of events).", "labels": [], "entities": [{"text": "recognition of temporal expressions", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.7737157046794891}, {"text": "IE", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.9031313061714172}, {"text": "Question Answering (QA)", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.8576070189476013}, {"text": "Automatic Summarization", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.7102176249027252}]}, {"text": "Work on slightly supervised approaches such as bootstrapping is justified by the large availability of unlabelled corpora, as opposed to tagged ones, from which to learn models for recognition.", "labels": [], "entities": []}, {"text": "illustrates the building blocks of the algorithm and their interactions, along with input and output data.", "labels": [], "entities": []}], "datasetContent": [{"text": "As unsupervised data for our experiments, we use the NW (newswire) category of LDC's ACE 2005 Unsupervised Data Pool, containing 456 Mbytes of data in 204K documents fora total of over 82 million tokens.", "labels": [], "entities": [{"text": "LDC's ACE 2005 Unsupervised Data Pool", "start_pos": 79, "end_pos": 116, "type": "DATASET", "confidence": 0.9027760965483529}]}, {"text": "Simultaneously, we use a much smaller labelled corpus (where the correct time expressions are tagged) to measure the precision, recall and F 1 -measure of the pattern set learned by the bootstrapping process.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9995431900024414}, {"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9992697834968567}, {"text": "F 1 -measure", "start_pos": 139, "end_pos": 151, "type": "METRIC", "confidence": 0.9891686886548996}]}, {"text": "This is the ACE 2005 corpus, containing 550 documents with 257K tokens and approx. 4650 time expression mentions.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.9815683762232462}]}, {"text": "The labelled corpus is split in two halves: one half is used to obtain the initial seed examples from among the time expressions found therein; the other half is used for evaluation.", "labels": [], "entities": []}, {"text": "We are requiring that a pattern captures the target time expression mention exactly (no misalignment allowed at the boundaries), in order to count it as a precision or recall hit.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9992076754570007}, {"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.9740059971809387}]}, {"text": "We will also be interested in measuring the gain in recall, that is, the difference between the recall in the best iteration and the initial recall given by the seeds.", "labels": [], "entities": [{"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9986771941184998}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9872041344642639}]}, {"text": "Also important is the number of iterations after which the bootstrapping process converges.", "labels": [], "entities": []}, {"text": "In the case where the same F 1 -measure mark is achieved in two experimental settings, earlier convergence of the algorithm will be prefered.", "labels": [], "entities": [{"text": "F 1 -measure mark", "start_pos": 27, "end_pos": 44, "type": "METRIC", "confidence": 0.9265712141990662}]}, {"text": "Otherwise, better F 1 and gain in recall are the primary goals.", "labels": [], "entities": [{"text": "F 1", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9955810606479645}, {"text": "gain in", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9161126613616943}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.8813118934631348}]}, {"text": "In order to start with a set of seeds with high precision, we select them automatically, imposing that a seed time expression must have precision above a certain value (understood as the percentage, of all the appearances of the sequence of tokens in the supervised corpus, those in which it is tagged as a correct time expression).", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9619067311286926}, {"text": "precision", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9864532351493835}]}, {"text": "In the experiments presented below, this threshold for precision of the seeds is 90% -in the half of the supervised corpus reserved for extraction of seeds-.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9990308284759521}]}, {"text": "From those that pass this filter, the ones that appear with greater frequency are selected.", "labels": [], "entities": []}, {"text": "For time expressions that have an identical digit pattern (e.g. two dates \"@@ December\" or two years \"@@@@\", where @ stands for any digit), only one seed is taken.", "labels": [], "entities": []}, {"text": "This approach simulates the human domain expert, which typically is the first step in bootstrapping IE models Unless specifically stated otherwise, all the experiments presented below share the following default settings: \u2022 Only the first 2.36 Mbytes of the unsupervised corpus are used (10 Mbytes after tokenization and feature extraction), that is 0.5% of the available data.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 321, "end_pos": 339, "type": "TASK", "confidence": 0.6715650260448456}]}, {"text": "This is to keep the execution time of experiments low, where multiple experiments need to be run to optimize a certain parameter.", "labels": [], "entities": []}, {"text": "\u2022 We use the Collins and Singer strategy (see section 4.1) with a precision threshold of 0.50 for sub-score combination in pattern selection.", "labels": [], "entities": [{"text": "precision threshold", "start_pos": 66, "end_pos": 85, "type": "METRIC", "confidence": 0.9752334356307983}, {"text": "pattern selection", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.7382815182209015}]}, {"text": "This strategy favours patterns with slightly higher precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.997450053691864}]}, {"text": "\u2022 The maximum length of prefix and postfix is 1 and 0 elements, respectively.", "labels": [], "entities": []}, {"text": "\u2022 100 seed examples are used (out of a maximum of 605 available).", "labels": [], "entities": []}, {"text": "\u2022 In the ranking of examples, the \u03bb i weights for the three sub-scores for infixes are 0.5 for the \"similarity-based score\", 0.25 for \"phrasecompleteness\" and 0.25 for \"context-based score\".", "labels": [], "entities": []}, {"text": "\u2022 In the selection of examples, the maximum number of new infixes accepted per iteration is 200, with a maximum of 50 different contexts per infix.", "labels": [], "entities": []}, {"text": "In the selection of patterns, the maximum number of new accepted patterns per iteration is 5000 (although this number is never reached due to the analysis of subsumptions).", "labels": [], "entities": []}, {"text": "\u2022 In the selection of patterns, multisets are used for computing the instance set of a pattern for the frequency-based score and normal sets for the precision score (determined experimentally).", "labels": [], "entities": [{"text": "precision score", "start_pos": 149, "end_pos": 164, "type": "METRIC", "confidence": 0.9808966815471649}]}, {"text": "\u2022 The POS tag type of generalization (pattern element) has been deactivated, that is, neither all-POS patterns, nor patterns that are combinations of POS PEs with another are generated.", "labels": [], "entities": []}, {"text": "After an analysis of errors, it was observed that POS generalizations (because of the fact that they are not lexicalized like, for instance, the syntactic PEs with a given headword) give rise to a considerable number of precision errors.", "labels": [], "entities": [{"text": "precision", "start_pos": 220, "end_pos": 229, "type": "METRIC", "confidence": 0.9979221224784851}]}, {"text": "\u2022 All patterns are generated with COMPLETE-PHRASE modifier automatically attached.", "labels": [], "entities": []}, {"text": "It was determined experimentally that it was best to use this heuristic in all cases (see section 3).", "labels": [], "entities": []}], "tableCaptions": []}