{"title": [{"text": "Anchor Text Extraction for Academic Search", "labels": [], "entities": [{"text": "Anchor Text Extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7907576560974121}]}], "abstractContent": [], "introductionContent": [{"text": "Anchor text is apiece of clickable text that links to a target Web page.", "labels": [], "entities": []}, {"text": "In general Web search, anchor text plays an extremely important role in improving the search quality.", "labels": [], "entities": []}, {"text": "The main reason for this is that anchor text actually aggregates the opinion (which is more comprehensive, accurate, and objective) of a potentially large number of people fora Web page.", "labels": [], "entities": []}, {"text": "* This work was performed when Fei Xing and Mingjie Zhu were interns at Microsoft Research Asia.", "labels": [], "entities": [{"text": "Microsoft Research Asia", "start_pos": 72, "end_pos": 95, "type": "DATASET", "confidence": 0.8353207310040792}]}, {"text": "In recent years, academic search () has become an important supplement to general web search for retrieving research articles.", "labels": [], "entities": []}, {"text": "Several academic search systems (including Google Scholar \u2020 , Citeseer \u2021 , DBLP \u00a7 , Libra ** , ArnetMiner \u2020 \u2020 , etc.) have been deployed.", "labels": [], "entities": []}, {"text": "In order to improve the results quality of an academic search system, we may consider exploiting the techniques which are demonstrated to be quite useful and critical in general Web search.", "labels": [], "entities": []}, {"text": "In this paper, we study the possibility of extracting anchor text for research papers and using them to improve the search performance of an academic search system.", "labels": [], "entities": []}, {"text": "The basic search unit inmost academic search systems is a research paper.", "labels": [], "entities": []}, {"text": "Borrowing the concepts of URL and anchor-text in general Web search, we may need to assign a pseudo-URL for one research paper as its identifier and to define the pseudo-anchor text for it by the contextual description when this paper is referenced (or mentioned).", "labels": [], "entities": []}, {"text": "The pseudo-URL of a research paper could be the combination of its title, authors and publication information.", "labels": [], "entities": []}, {"text": "shows an excerpt where one paper cites a couple of other papers.", "labels": [], "entities": []}, {"text": "The grayed text can be treated as the pseudo-anchor text of the papers being referenced.", "labels": [], "entities": []}, {"text": "Once the pseudo-anchor text of research papers is acquired, it can be indexed and utilized to help ranking, just as in general web search.", "labels": [], "entities": []}, {"text": "However it remains a challenging task to correctly identify and extract these pseudo-URLs and pseudo-anchor texts.", "labels": [], "entities": []}, {"text": "First, unlike the situation in general web search where one unique URL is assigned to each web page as a natural identifier, the information of research papers need to be extracted from web pages or PDF files.", "labels": [], "entities": []}, {"text": "As a result, in constructing pseudo-URLs for research papers, we may face the problem of extraction errors, typos, and the case of one research paper having different expressions in different places.", "labels": [], "entities": []}, {"text": "Second, in general Web search, anchor text is always explicitly specified by HTML tags (<a> and </a>).", "labels": [], "entities": []}, {"text": "It is however much harder to perform anchor text extraction for research papers.", "labels": [], "entities": [{"text": "anchor text extraction", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7995012799898783}]}, {"text": "For example, human knowledge maybe required in to accurately identify the description of every cited paper.", "labels": [], "entities": [{"text": "identify the description of every cited paper", "start_pos": 61, "end_pos": 106, "type": "TASK", "confidence": 0.6725120288985116}]}, {"text": "To address the above challenges, we propose an approach for extracting and utilizing pseudoanchor text information in academic search to improve the search results quality.", "labels": [], "entities": []}, {"text": "Our approach is composed of three phases.", "labels": [], "entities": []}, {"text": "In the first phase, each time a paper is cited in another paper, we construct a tentative pseudo-URL for the cited paper and extract a candidate anchor block for it.", "labels": [], "entities": []}, {"text": "The tentative pseudo-URL and the candidate anchor block are allowed to be inaccurate.", "labels": [], "entities": []}, {"text": "In the second phase, we merge the tentative pseudoURLs that should represent the same paper.", "labels": [], "entities": []}, {"text": "All candidate anchor blocks belong to the same paper are grouped accordingly in this phase.", "labels": [], "entities": []}, {"text": "In the third phase, the final pseudo-anchor text of each paper is generated from all its candidate blocks, by adopting a SVM-based machine learning methodology.", "labels": [], "entities": []}, {"text": "We conduct experiments upon a dataset containing 0.9 million research papers.", "labels": [], "entities": []}, {"text": "The experimental results show that lots of useful anchor text can be successfully extracted and accumulated using our approach, and the ultimate search performance is dramatically improved when anchor information is indexed and used for paper ranking.", "labels": [], "entities": [{"text": "paper ranking", "start_pos": 237, "end_pos": 250, "type": "TASK", "confidence": 0.6879023313522339}]}, {"text": "The remaining part of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe in detail our approach for pseudo-anchor text extraction and accumulation.", "labels": [], "entities": [{"text": "pseudo-anchor text extraction", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.6213352978229523}]}, {"text": "Experimental results are reported in Section 3.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 4 and finally conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experimental dataset contains 0.9 million papers crawled from the web.", "labels": [], "entities": []}, {"text": "All the papers are processed according to the process in (b).", "labels": [], "entities": []}, {"text": "We randomly select 300 queries from the query log of Libra (libra.msra.cn) and retrieve the results in our indexing and ranking system with/without the pseudo-anchors generated by our approach.", "labels": [], "entities": [{"text": "Libra", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.9233456254005432}]}, {"text": "Then the volunteer researchers and students in our group are involved to judge the search results.", "labels": [], "entities": []}, {"text": "The top 30 results of different ranking algorithms for each query are labeled and assigned a relevance value from 1 (meaning 'poor match') to 5 (meaning 'perfect match').", "labels": [], "entities": []}, {"text": "The search results quality is measured by NDCG).", "labels": [], "entities": [{"text": "NDCG", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.877833366394043}]}, {"text": "shows the performance comparison between the results of two baseline paper ranking algorithms and the results of including pseudoanchor text in ranking.", "labels": [], "entities": []}, {"text": "The \"Base\" algorithm considers the title, abstract, full-text and static-rank (which is a function of the citation count) of a paper.", "labels": [], "entities": []}, {"text": "Ina bit more detail, for each paper, we adopt the BM25 formula () over its title, abstract, and full-text respectively.", "labels": [], "entities": [{"text": "BM25", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.5424330830574036}]}, {"text": "And then the resulting score is linearly combined with the static-rank to get its final score.", "labels": [], "entities": []}, {"text": "The static-rank is computed as follows,  We conduct experiments to test the effectiveness and efficiency of the multiple-feature-stringhashing algorithm presented in Section 2.2.", "labels": [], "entities": []}, {"text": "The duplication detection quality of this algorithm is determined by the appropriate selection of fea-  We take all the papers extracted from PDF files as input to run the algorithm.", "labels": [], "entities": [{"text": "duplication detection", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8400636911392212}]}, {"text": "Identical TPURLs are first eliminated (therefore their candidate anchor blocks are merged) by utilizing a hash table.", "labels": [], "entities": []}, {"text": "This pre-process step results in about 1.46 million distinct TP-URLs.", "labels": [], "entities": []}, {"text": "The number is larger than our collection size (0.9 million), because some cited papers are not in our paper collection.", "labels": [], "entities": []}, {"text": "We tested four kinds of feature strings all of which are generated from paper title: unigrams, bigrams, trigrams, and 4-grams.", "labels": [], "entities": []}, {"text": "shows the slot size distribution corresponding to each kind of feature strings.", "labels": [], "entities": []}, {"text": "The performance comparison among different feature strings and slot size thresholds is shown in.", "labels": [], "entities": []}, {"text": "It seems that bigrams achieve a good trade-off between accuracy and performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9991726279258728}]}], "tableCaptions": [{"text": " Table 2. Statistical significance tests (t-test over  nDCG@3)", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.686697393655777}]}, {"text": " Table 3. Performance compassion using binary judg- ment measures", "labels": [], "entities": []}, {"text": " Table 4. Slot distribution with different feature strings", "labels": [], "entities": []}, {"text": " Table 5. It seems  that bigrams achieve a good trade-off between  accuracy and performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9993069171905518}]}, {"text": " Table 5. Performance comparison between different  feature strings and slot size thresholds", "labels": [], "entities": []}]}