{"title": [{"text": "Graph Connectivity Measures for Unsupervised Parameter Tuning of Graph-Based Sense Induction Systems", "labels": [], "entities": [{"text": "Graph Connectivity Measures", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.608405073483785}, {"text": "Parameter Tuning of Graph-Based Sense Induction", "start_pos": 45, "end_pos": 92, "type": "TASK", "confidence": 0.5840080926815668}]}], "abstractContent": [{"text": "Word Sense Induction (WSI) is the task of identifying the different senses (uses) of a target word in a given text.", "labels": [], "entities": [{"text": "Word Sense Induction (WSI)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7717690567175547}, {"text": "identifying the different senses (uses) of a target word in a given text", "start_pos": 42, "end_pos": 114, "type": "TASK", "confidence": 0.6266629894574484}]}, {"text": "This paper focuses on the unsupervised estimation of the free parameters of a graph-based WSI method, and explores the use of eight Graph Connectiv-ity Measures (GCM) that assess the degree of connectivity in a graph.", "labels": [], "entities": []}, {"text": "Given a target word and a set of parameters, GCM evaluate the connectivity of the produced clusters, which correspond to subgraphs of the initial (unclus-tered) graph.", "labels": [], "entities": []}, {"text": "Each parameter setting is assigned a score according to one of the GCM and the highest scoring setting is then selected.", "labels": [], "entities": [{"text": "GCM", "start_pos": 67, "end_pos": 70, "type": "DATASET", "confidence": 0.9171115159988403}]}, {"text": "Our evaluation on the nouns of SemEval-2007 WSI task (SWSI) shows that: (1) all GCM estimate a set of parameters which significantly outperform the worst performing parameter setting in both SWSI evaluation schemes, (2) all GCM estimate a set of parameters which outperform the Most Frequent Sense (MFS) baseline by a statistically significant amount in the supervised evaluation scheme, and (3) two of the measures estimate a set of parameters that performs closely to a set of parameters estimated in supervised manner.", "labels": [], "entities": [{"text": "nouns of SemEval-2007 WSI task (SWSI)", "start_pos": 22, "end_pos": 59, "type": "DATASET", "confidence": 0.5774606727063656}]}], "introductionContent": [{"text": "Using word senses instead of word forms is essential in many applications such as information retrieval (IR) and machine translation (MT) ().", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 82, "end_pos": 108, "type": "TASK", "confidence": 0.845542824268341}, {"text": "machine translation (MT)", "start_pos": 113, "end_pos": 137, "type": "TASK", "confidence": 0.8415391683578491}]}, {"text": "Word senses area prerequisite for word sense disambiguation (WSD) algorithms.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.7810187538464864}]}, {"text": "However, they are usually represented as a fixed-list of definitions of a manually constructed lexical database.", "labels": [], "entities": []}, {"text": "The fixed-list of senses paradigm has several disadvantages.", "labels": [], "entities": []}, {"text": "Firstly, lexical databases often contain general definitions and miss many domain specific senses ().", "labels": [], "entities": []}, {"text": "Secondly, they suffer from the lack of explicit semantic and topical relations between concepts).", "labels": [], "entities": []}, {"text": "Thirdly, they often do not reflect the exact content of the context in which the target word appears.", "labels": [], "entities": []}, {"text": "WSI aims to overcome these limitations of handconstructed lexicons.", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8533796668052673}]}, {"text": "Most WSI systems are based on the vector-space model that represents each context of a target word as a vector of features (e.g. frequency of cooccurring words).", "labels": [], "entities": [{"text": "WSI", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9638193249702454}]}, {"text": "Vectors are clustered and the resulting clusters are taken to represent the induced senses.", "labels": [], "entities": []}, {"text": "Recently, graph-based methods have been employed to WSI.", "labels": [], "entities": [{"text": "WSI", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9515776634216309}]}, {"text": "Typically, graph-based approaches represent each word co-occurring with the target word, within a pre-specified window, as a vertex.", "labels": [], "entities": []}, {"text": "Two vertices are connected via an edge if they co-occur in one or more contexts of the target word.", "labels": [], "entities": []}, {"text": "This cooccurrence graph is then clustered employing different graph clustering algorithms to induce the senses.", "labels": [], "entities": []}, {"text": "Each cluster (induced sense) consists of words expected to be topically related to the particular sense.", "labels": [], "entities": []}, {"text": "As a result, graph-based approaches assume that each context word is related to one and only one sense of the target one.", "labels": [], "entities": []}, {"text": "Recently, argued that this assumption might not be always valid, since a context word maybe related to more than one senses of the target one.", "labels": [], "entities": []}, {"text": "As a result, they pro-36 posed the use of a graph-based model for WSI, in which each vertex of the graph corresponds to a collocation (word-pair) that co-occurs with the target word, while edges are drawn based on the cooccurrence frequency of their associated collocations.", "labels": [], "entities": [{"text": "WSI", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.7770388126373291}]}, {"text": "Clustering of this collocational graph would produce clusters, which consist of a set of collocations.", "labels": [], "entities": []}, {"text": "The intuition is that the produced clusters will be less sense-conflating than those produced by other graph-based approaches, since collocations provide strong and consistent clues to the senses of a target word.", "labels": [], "entities": []}, {"text": "The collocational graph-based approach as well as the majority of state-of-the-art WSI systems estimate their parameters either empirically or by employing supervised techniques.", "labels": [], "entities": []}, {"text": "The SemEval-2007 WSI task (SWSI) participating systems UOY and UBC-AS used labeled data for parameter estimation, while the authors of I2R, UPV SI and UMND2 have empirically chosen values for their parameters.", "labels": [], "entities": [{"text": "SemEval-2007 WSI task (SWSI)", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6774756411711375}, {"text": "UOY", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.9410672783851624}]}, {"text": "This issue imposes limits on the unsupervised nature of these algorithms, as well as on their performance on different datasets.", "labels": [], "entities": []}, {"text": "More specifically, when applying an unsupervised WSI system on different datasets, one cannot be sure that the same set of parameters is appropriate for all datasets ().", "labels": [], "entities": []}, {"text": "In most cases, anew parameter tuning might be necessary.", "labels": [], "entities": []}, {"text": "Unsupervised estimation of free parameters may enhance the unsupervised nature of systems, making them applicable to any dataset, even if there are no tagged data available.", "labels": [], "entities": []}, {"text": "In this paper, we focus on estimating the free parameters of the collocational graph-based WSI method () using eight graph connectivity measures (GCM).", "labels": [], "entities": []}, {"text": "Given a parameter setting and the associated induced clustering solution, each induced cluster corresponds to a subgraph of the original unclustered graph.", "labels": [], "entities": []}, {"text": "A graph connectivity measure GCM i scores each cluster by evaluating the degree of connectivity of its corresponding subgraph.", "labels": [], "entities": []}, {"text": "Each clustering solution is then assigned the average of the scores of its clusters.", "labels": [], "entities": []}, {"text": "Finally, the highest scoring solution is selected.", "labels": [], "entities": []}, {"text": "Our evaluation on the nouns of SWSI shows that GCM improve the worst performing parameter setting by large margins in both SWSI evaluation schemes, although they are below the best performing parameter setting.", "labels": [], "entities": []}, {"text": "Moreover, the evaluation in a WSD setting shows that all GCM estimate a set of parameters which are above the Most Frequent Sense (MFS) baseline by a statistically significant amount.", "labels": [], "entities": [{"text": "WSD", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.957991361618042}, {"text": "Most Frequent Sense (MFS) baseline", "start_pos": 110, "end_pos": 144, "type": "METRIC", "confidence": 0.8796422481536865}]}, {"text": "Finally our results show that two of the measures, i.e. average degree and weighted average degree, estimate a set of parameters that performs closely to a set of parameters estimated in a supervised manner.", "labels": [], "entities": [{"text": "weighted average degree", "start_pos": 75, "end_pos": 98, "type": "METRIC", "confidence": 0.7408523758252462}]}, {"text": "All of these findings, suggest that GCM are able to identify useful differences regarding the quality of the induced clusters for different parameter combinations, in effect being useful for unsupervised parameter estimation.", "labels": [], "entities": []}], "datasetContent": [{"text": "The collocational WSI approach was evaluated under the framework and corpus of).", "labels": [], "entities": [{"text": "WSI", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8951542973518372}]}, {"text": "The corpus consists of text of the Wall Street Journal corpus, and is hand-tagged with OntoNotes senses).", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 35, "end_pos": 61, "type": "DATASET", "confidence": 0.9787755310535431}]}, {"text": "The evaluation focuses on all 35 nouns of SWSI.", "labels": [], "entities": []}, {"text": "SWSI task employs two evaluation schemes.", "labels": [], "entities": [{"text": "SWSI task", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.7793944776058197}]}, {"text": "In unsupervised evaluation, the results are treated as clusters of contexts and gold standard (GS) senses as classes.", "labels": [], "entities": []}, {"text": "Ina perfect clustering solution, each induced cluster contains the same contexts as one of the classes (Homogeneity), and each class contains the same contexts as one of the clusters (Completeness).", "labels": [], "entities": []}, {"text": "F-Score is used to assess the overall quality of clustering.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.946359395980835}]}, {"text": "Entropy and purity are also used, complementarily.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9722594618797302}, {"text": "purity", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9921080470085144}]}, {"text": "F-Score is a better measure than entropy or purity, since F-Score measures both homogeneity and completeness, while entropy and purity measure only the former.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9069226384162903}, {"text": "purity", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9742757678031921}, {"text": "F-Score", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9380099773406982}]}, {"text": "In the second scheme, supervised evaluation, the training corpus is used to map the induced clusters to GS senses.", "labels": [], "entities": []}, {"text": "The testing corpus is then used to measure WSD performance, Sup.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9673495888710022}]}, {"text": "The graph-based collocational WSI method is referred as Col-Sm (where \"Col\" stands for the \"col- locational WSI\" approach and \"Sm\" for its version using \"smoothing\").", "labels": [], "entities": []}, {"text": "Col-Bl (where \"Bl\" stands for \"baseline\") refers to the same system without smoothing.", "labels": [], "entities": [{"text": "Bl", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.9487395286560059}]}, {"text": "The parameters of Col-Sm were originally estimated by cross-validation on the training set of SWSI.", "labels": [], "entities": [{"text": "SWSI", "start_pos": 94, "end_pos": 98, "type": "DATASET", "confidence": 0.6080693602561951}]}, {"text": "Out of 72 parameter combinations, the setting with the highest F-Score was chosen and applied to all 35 nouns of the test set.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9980438947677612}]}, {"text": "This is referred as Col-Sm-org (where \"org\" stands for \"original\") in. shows all values for each parameter, and the chosen values, under supervised parameter estimation 2 . Col-Bl-org) induces senses as Col-Sm-org does, but without smoothing.", "labels": [], "entities": []}, {"text": "In table 4, Col-Sm-w (respectively Col-Bl-w) refers to the evaluation of Col-Sm (Col-Bl), following the same technique for parameter estimation as in for each target word separately (\"w\" stands for \"word\").", "labels": [], "entities": []}, {"text": "Given that GCM are applied for each target word separately, these baselines will allow to seethe performance of GCM compared to a supervised setting.", "labels": [], "entities": []}, {"text": "The 1c1inst baseline assigns each instance to a distinct cluster, while the 1c1w baseline groups all instances of a target word into a single cluster.", "labels": [], "entities": []}, {"text": "1c1w is equivalent to MFS in this setting.", "labels": [], "entities": [{"text": "MFS", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.7755959033966064}]}, {"text": "The fifth column of table 4 shows the average number of clusters.", "labels": [], "entities": []}, {"text": "The SWSI participant systems UOY and UBC-AS used labeled data for parameter estimation.", "labels": [], "entities": [{"text": "UOY", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.9118624925613403}, {"text": "UBC-AS", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.8935655951499939}]}, {"text": "The authors of I2R, UPV SI and UMND2 have empirically chosen values for their parameters.", "labels": [], "entities": [{"text": "UMND2", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.8127421140670776}]}, {"text": "The next subsection presents the evaluation of GCM as well as the results of SWSI systems.", "labels": [], "entities": [{"text": "GCM", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.6223423480987549}, {"text": "SWSI", "start_pos": 77, "end_pos": 81, "type": "TASK", "confidence": 0.9215842485427856}]}, {"text": "Initially, we provide a brief discussion on the differences between the two evaluation schemes of SWSI that will allow fora better understanding of GCM performance.", "labels": [], "entities": [{"text": "SWSI", "start_pos": 98, "end_pos": 102, "type": "TASK", "confidence": 0.891999363899231}]}], "tableCaptions": [{"text": " Table 2: Computations of graph connectivity measures  and relevant quantities on the example graph (", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of WSI systems and baselines.", "labels": [], "entities": [{"text": "WSI", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9061670899391174}]}, {"text": " Table 5: Upper and lower performance bounds for sys- tems Col-Sm and Col-Bl.", "labels": [], "entities": []}, {"text": " Table 6: Unsupervised & supervised evaluation of the collocational WSI approach using graph connectivity measures.", "labels": [], "entities": [{"text": "WSI", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9277664422988892}]}]}