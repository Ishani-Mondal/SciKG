{"title": [{"text": "Meeting TempEval-2: Shallow Approach for Temporal Tagger", "labels": [], "entities": [{"text": "Temporal Tagger", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.788494735956192}]}], "abstractContent": [{"text": "Temporal expressions are one of the important structures in natural language.", "labels": [], "entities": [{"text": "Temporal expressions", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8870295584201813}]}, {"text": "In order to understand text, temporal expressions have to be identified and normalized by providing ISO-based values.", "labels": [], "entities": []}, {"text": "In this paper we present a shallow approach for automatic recognition of temporal expressions based on a supervised machine learning approach trained on an annotated corpus for temporal information, namely TimeBank.", "labels": [], "entities": [{"text": "automatic recognition of temporal expressions", "start_pos": 48, "end_pos": 93, "type": "TASK", "confidence": 0.7709421396255494}, {"text": "TimeBank", "start_pos": 206, "end_pos": 214, "type": "DATASET", "confidence": 0.9272076487541199}]}, {"text": "Our experiments demonstrate a performance level comparable to a rule-based implementation and achieve the scores of 0.872, 0.836 and 0.852 for precision, recall and F1-measure for the detection task respectively, and 0.866, 0.796, 0.828 when an exact match is required.", "labels": [], "entities": [{"text": "precision", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.9993859529495239}, {"text": "recall", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.9986520409584045}, {"text": "F1-measure", "start_pos": 165, "end_pos": 175, "type": "METRIC", "confidence": 0.997093677520752}]}], "introductionContent": [{"text": "The task of recognizing temporal expressions (sometimes also referred as time expressions or simply TIMEX) was first introduced in the Message Understanding Conference (MUC) in 1995.", "labels": [], "entities": [{"text": "Message Understanding Conference (MUC) in 1995", "start_pos": 135, "end_pos": 181, "type": "TASK", "confidence": 0.8576632402837276}]}, {"text": "Temporal expressions were treated as apart of the Named Entity Recognition (NER) task, in which capitalized tokens in text were labeled with one of the predefined semantic labels, such as Date, Time, Person, Organization, Location, Percentage, and Money.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) task", "start_pos": 50, "end_pos": 85, "type": "TASK", "confidence": 0.83504171030862}]}, {"text": "As the types of temporal entities identified in this way were too restricted and provided little further information, the Automated Content Extraction (ACE) launched a competition campaign for Temporal Expression Recognition and Normalization).", "labels": [], "entities": [{"text": "Automated Content Extraction (ACE)", "start_pos": 122, "end_pos": 156, "type": "TASK", "confidence": 0.7535435458024343}, {"text": "Temporal Expression Recognition and Normalization", "start_pos": 193, "end_pos": 242, "type": "TASK", "confidence": 0.7556221663951874}]}, {"text": "The tasks were to identify temporal expressions in free text and normalize them providing an ISO-based date-time value.", "labels": [], "entities": []}, {"text": "Later evaluations of ACE in and 2007 unfortunately did not set new challenges for temporal expression recognition and thus the participation interest in this particular task decreased.", "labels": [], "entities": [{"text": "temporal expression recognition", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.7562089363733927}]}, {"text": "TempEval-2 is a successor of TempEval-2007 and will take place in 2010.", "labels": [], "entities": [{"text": "TempEval-2", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9446178674697876}]}, {"text": "The new evaluation initiative sets new challenges for temporal text analysis.", "labels": [], "entities": [{"text": "temporal text analysis", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7795538703600565}]}, {"text": "While TempEval-2007 was solely focused on recognition of temporal links, the TempEval-2 tasks aim at an all-around temporal processing with separate evaluations for recognition of temporal expressions and events, for the estimation of temporal relations between events and times in the same sentence, between events and document creation time, between two events in consecutive sentences and between two events, where one of them syntactically dominates the other ().", "labels": [], "entities": []}, {"text": "These evaluations became possible with anew freely available corpus with annotated temporal information, TimeBank (, and an annotation schema, called TimeML ().", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 105, "end_pos": 113, "type": "DATASET", "confidence": 0.8648739457130432}]}, {"text": "For us all the tasks of TempEval-2 seem to be interesting.", "labels": [], "entities": []}, {"text": "In this paper we make the first step towards a comprehensive temporal analysis and address the problem of temporal expression recognition as it is set in TempEval-2.", "labels": [], "entities": [{"text": "temporal expression recognition", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.6831496159235636}]}, {"text": "Despite a number of previous implementations mainly done in the context of the ACE TERN competition, very few, and exclusively rule-based methods were reported for temporal taggers on TimeBank developed by using the TimeML annotation scheme.", "labels": [], "entities": [{"text": "ACE TERN competition", "start_pos": 79, "end_pos": 99, "type": "DATASET", "confidence": 0.8453278342882792}, {"text": "temporal taggers", "start_pos": 164, "end_pos": 180, "type": "TASK", "confidence": 0.6886007636785507}]}, {"text": "As a main result of the deep analysis of relevant work (Section 2), we decided to employ a machine learning approach for constituent-based classifications with generic syntactic and lexical features.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: in Section 2 we provide the details of relevant work done in this field along with corpora and annotations schemes used; Section 3 describes the approach; experimental setup, results and error analysis are provided in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 gives an outlook for further improvements and research.", "labels": [], "entities": []}], "datasetContent": [{"text": "With the start of the ACE TERN competition in 2004, two major evaluation conditions were proposed: Recognition+Normalization (full task) and Recognition only).", "labels": [], "entities": [{"text": "ACE TERN competition", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.5513690908749899}]}, {"text": "Detection (Recognition): Detection is a preliminary task towards the full TERN task, in which temporally relevant expressions have to be found.", "labels": [], "entities": [{"text": "Detection (Recognition)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6263546347618103}, {"text": "TERN", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.7761659622192383}]}, {"text": "The scoring is very generous and implies a minimal overlap in the extent of the reference and the system output tags.", "labels": [], "entities": []}, {"text": "As long as there is at least one overlapping character, the tags will be aligned.", "labels": [], "entities": []}, {"text": "Any alignment of the system output tags are scored as a correct detection.", "labels": [], "entities": []}, {"text": "Sloopy span: Spans usually refer to strict match of both boundaries (the extent) of a temporal expression (see Exact Match).", "labels": [], "entities": []}, {"text": "\"Sloopy\" admits recognized temporal expressions as long as their right boundary is the same as in the corresponding TimeBank's extents).", "labels": [], "entities": []}, {"text": "The motivation was to assess the correctness of temporal expressions recognized in TimeBank, which was reported as inconsistent with respect to some left boundary items, such as determiners and pre-determiners.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8843714594841003}]}, {"text": "Exact Match (Bracketing or Extent Recognition): Exact match measures the ability to correctly identify the extent of the TIMEX.", "labels": [], "entities": [{"text": "Exact Match (Bracketing or Extent Recognition)", "start_pos": 0, "end_pos": 46, "type": "METRIC", "confidence": 0.7604890167713165}]}, {"text": "The extent of the reference and the system output tags must match exactly the system output tag to be scored as correct.", "labels": [], "entities": []}, {"text": "To date, there are two annotated corpora used for temporal evaluations, the ACE TERN corpus and TimeBank ().", "labels": [], "entities": [{"text": "ACE TERN corpus", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.7486627896626791}, {"text": "TimeBank", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.7358620166778564}]}, {"text": "In this section we provide a brief description of the temporal corpora and annotation standards, which can substantially influence recognition results.", "labels": [], "entities": [{"text": "recognition", "start_pos": 131, "end_pos": 142, "type": "TASK", "confidence": 0.9488573670387268}]}, {"text": "Most of the implementations referred as the state-of-the-art were developed in the scope of the ACE TERN 2004.", "labels": [], "entities": [{"text": "ACE TERN 2004", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.8938177029291788}]}, {"text": "For evaluations, a training corpus of 862 documents with about 306 thousand words was provided.", "labels": [], "entities": []}, {"text": "Each document represents a news article formatted in XML, in which TIMEX2 tags denote temporal expressions.", "labels": [], "entities": []}, {"text": "The total number of temporal expressions for training is 8047 TIMEX2 tags with an average of 10.5 per document.", "labels": [], "entities": [{"text": "TIMEX2", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9615433216094971}]}, {"text": "The test set comprises 192 documents with 1828 TIMEX2 tags.", "labels": [], "entities": [{"text": "TIMEX2", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.8440315127372742}]}, {"text": "The annotation of temporal expressions in the ACE corpus was done with respect to the TIDES annotation guidelines ).", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.9579898118972778}]}, {"text": "The TIDES standard specifies so-called markable expressions, whose syntactic head must bean appropriate lexical trigger, e.g. \"minute\", \"afternoon\", \"Monday\", \"8:00\", \"future\" etc.", "labels": [], "entities": []}, {"text": "When tagged, the full extent of the tag must correspond to one of the grammatical categories: nouns (NN, NNP), noun phrases (NP), adjectives (JJ), adjective phrases (ADJP), adverbs (RB) and adverb phrases (ADVP).", "labels": [], "entities": []}, {"text": "According to this, all pre-and postmodifiers as well as dependent clauses are also included to the TIMEX2 extent, e.g. \"five days after he came back\", \"nearly four decades of experience\".", "labels": [], "entities": [{"text": "TIMEX2", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9703468680381775}]}, {"text": "Such abroad extent for annotations is of course necessary for correct normalization, but on the other hand, introduces difficulties for exact match.", "labels": [], "entities": []}, {"text": "Another important characteristic of the TIDES standard are the nested temporal expressions as for example: <TIMEX2>The<TIMEX2 VAL = \"1994\">1994 </TIMEX2> baseball season </TIMEX2> The most recent annotation language for temporal expressions, TimeML (, with an underlying corpus TimeBank (), opens up new possibilities for processing temporal information in text.", "labels": [], "entities": [{"text": "TIMEX2 VAL", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.7253981232643127}]}, {"text": "Besides the specification for temporal expressions, i.e. TIMEX3, which is to a large extent inherited from TIDES, TimeML provides a means to capture temporal semantics by annotations with suitably defined attributes for fine-grained specification of analytical detail).", "labels": [], "entities": []}, {"text": "The annotation schema establishes new entity and relation marking tags along with numerous attributes for them.", "labels": [], "entities": []}, {"text": "This advancement influenced the extent for event-based temporal expression, in which dependent clauses are no longer included into TIMEX3 tags.", "labels": [], "entities": [{"text": "event-based temporal expression", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.5943586925665537}]}, {"text": "The TimeBank corpus includes 186 documents with 68.5 thousand words and 1423 TIMEX3 tags.", "labels": [], "entities": [{"text": "TimeBank corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9698653817176819}]}, {"text": "After processing the TimeBank corpus of 183 documents we had 2612 parsed sentences with 1224 temporal expressions in them.", "labels": [], "entities": [{"text": "TimeBank corpus of 183 documents", "start_pos": 21, "end_pos": 53, "type": "DATASET", "confidence": 0.9661328673362732}]}, {"text": "2612 sentences resulted in 49656 phrase candidates.", "labels": [], "entities": []}, {"text": "We separated the data in order to perform 10-fold cross validation, train the classifier and test it on an unseen dataset.", "labels": [], "entities": []}, {"text": "The evaluations were conducted with respect to the TERN 2004 evaluation plan) and described in Section 2.1.", "labels": [], "entities": [{"text": "TERN 2004 evaluation plan", "start_pos": 51, "end_pos": 76, "type": "DATASET", "confidence": 0.9512975811958313}]}, {"text": "After running experiments the classifier demonstrated the performance in detection of TIMEX3 tags with a minimal overlap of one character with precision, recall and F1-measure at 0.872, 0.836 and 0.852 respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.9996395111083984}, {"text": "recall", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.9996241331100464}, {"text": "F1-measure", "start_pos": 165, "end_pos": 175, "type": "METRIC", "confidence": 0.9990935325622559}]}, {"text": "Since the candidate phrases provided by the parser do not always exactly align annotated temporal expressions, the results for the exact match experiments are constrained by an estimated upper-bound recall of 0.919.", "labels": [], "entities": [{"text": "recall", "start_pos": 199, "end_pos": 205, "type": "METRIC", "confidence": 0.9720520377159119}]}, {"text": "The experiments on exact match demonstrated a small decline of performance level and received scores of 0.866, 0.796 and 0.828 for precision, recall and F1-measure respectively.", "labels": [], "entities": [{"text": "performance level", "start_pos": 63, "end_pos": 80, "type": "METRIC", "confidence": 0.9252806007862091}, {"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9997145533561707}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9991421699523926}, {"text": "F1-measure", "start_pos": 153, "end_pos": 163, "type": "METRIC", "confidence": 0.9989029169082642}]}, {"text": "Putting the received figures in context, we can say that with a very few shallow features and a standard machine learning algorithm the recognizer of temporal expressions performed at a comparable operational level to the rule-based approach of) and outperformed it inexact match.", "labels": [], "entities": []}, {"text": "A comparative performance summary is presented in.", "labels": [], "entities": []}, {"text": "Sometimes it is very hard even for humans to identify the use of obvious temporal triggers in a specific context.", "labels": [], "entities": []}, {"text": "As a result, many occurrences of such triggers remained unannotated for which TIMEX3 identification could not be properly carried out.", "labels": [], "entities": [{"text": "TIMEX3 identification", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7805929780006409}]}, {"text": "Apart of obvious incorrect parses, inexact alignment between temporal expressions and candidate phrases was caused by annotations that occurred at the middle of a phrase, for example \"eight-years-long\", \"overnight\", \"yesterday's\".", "labels": [], "entities": []}, {"text": "In total there are 99 TIMEX3 tags (or 8.1%) misaligned with the parser output, which resulted in 53 (or 4.3%) undetected TIMEX3s.", "labels": [], "entities": []}, {"text": "Definite and indefinite articles are unsystematically left out or included into TIMEX3 extent, which may introduce an additional bias in classification.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. All the results were obtained on  the ACE TERN dataset.", "labels": [], "entities": [{"text": "ACE TERN dataset", "start_pos": 48, "end_pos": 64, "type": "DATASET", "confidence": 0.8283734122912089}]}, {"text": " Table 1. Performance of Machine Learning Ap- proaches with B-I-O Encoding", "labels": [], "entities": []}, {"text": " Table 2. Comparative Performance Summary", "labels": [], "entities": [{"text": "Comparative Performance Summary", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.7796627283096313}]}]}