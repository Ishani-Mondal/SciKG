{"title": [{"text": "A Learning Approach to Shallow Parsing*", "labels": [], "entities": []}], "abstractContent": [{"text": "A SNoW based learning approach to shallow parsing tasks is presented and studied experimentally.", "labels": [], "entities": [{"text": "shallow parsing tasks", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.6434878905614217}]}, {"text": "The approach learns to identify syntactic patterns by combining simple predictors to produce a coherent inference.", "labels": [], "entities": []}, {"text": "Two instantiations of this approach are studied and experimental results for Noun-Phrases (NP) and Subject-Verb (SV) phrases that compare favorably with the best published results are presented.", "labels": [], "entities": []}, {"text": "In doing that, we compare two ways of mod-eling the problem of learning to recognize patterns and suggest that shallow parsing patterns are better learned using open/close predictors than using inside/outside predictors.", "labels": [], "entities": []}], "introductionContent": [{"text": "Shallow parsing is studied as an alternative to full-sentence parsers.", "labels": [], "entities": [{"text": "Shallow parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7802348136901855}]}, {"text": "Rather than producing a complete analysis of sentences, the alternative is to perform only partial analysis of the syntactic structures in a text.", "labels": [], "entities": []}, {"text": "Shallow parsing information such as NPs and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.8717043995857239}, {"text": "text summarization", "start_pos": 183, "end_pos": 201, "type": "TASK", "confidence": 0.7810748815536499}]}, {"text": "A lot of the work on shallow parsing over the past years has concentrated on manual construction of rules.", "labels": [], "entities": [{"text": "shallow parsing", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7576702237129211}]}, {"text": "The observation that shallow syntactic information can be extracted using local information -by examining the pattern itself, its nearby context and the local part-of-speech information -has motivated the use of learning methods to recognize these patterns).", "labels": [], "entities": []}, {"text": "* Research supported by NSF grants IIS-9801638 and SBR-9873450.", "labels": [], "entities": [{"text": "IIS-9801638", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.531776487827301}, {"text": "SBR-9873450", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.5492734313011169}]}, {"text": "t Research supported by NSF grant CCR-9502540.", "labels": [], "entities": [{"text": "NSF grant CCR-9502540", "start_pos": 24, "end_pos": 45, "type": "DATASET", "confidence": 0.8402042190233866}]}, {"text": "This paper presents a general learning approach for identifying syntactic patterns, based on the SNoW learning architecture).", "labels": [], "entities": []}, {"text": "The SNoW learning architecture is a sparse network of linear ftmctions over a predefined or incrementally learned feature space.", "labels": [], "entities": []}, {"text": "SNoW is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large -of which NLP is a principal example.", "labels": [], "entities": []}, {"text": "Preliminary versions of it have already been used successfully on several tasks in natural language processing).", "labels": [], "entities": []}, {"text": "In particular, SNoW's sparse architecture supports well chaining and combining predictors to produce a coherent inference.", "labels": [], "entities": []}, {"text": "This property of the architecture is the base for the learning approach studied herein the context of shallow parsing.", "labels": [], "entities": []}, {"text": "Shallow parsing tasks often involve the identification of syntactic phrases or of words that participate in a syntactic relationship.", "labels": [], "entities": [{"text": "Shallow parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7564287483692169}]}, {"text": "Computationally, each decision of this sort involves multiple predictions that interact in someway.", "labels": [], "entities": []}, {"text": "For example, in identifying a phrase, one can identify the beginning and end of the phrase while also making sure they are coherent.", "labels": [], "entities": []}, {"text": "Our computational paradigm suggests using a SNoW based predictor as a building block that learns to perform each of the required predictions, and writing a simple program that activates these predictors with the appropriate input, aggregates their output and controls the interaction between the predictors.", "labels": [], "entities": []}, {"text": "Two instantiations of this paradigm are studied and evaluated on two different shallow parsing tasksidentifying base NPs and SV phrases.", "labels": [], "entities": [{"text": "shallow parsing tasksidentifying base NPs and SV phrases", "start_pos": 79, "end_pos": 135, "type": "TASK", "confidence": 0.7500279396772385}]}, {"text": "The first instantiation of this para4igm uses predictors to decide whether each word belongs to the in-I terior of a phrase or not, and then groups the words into phrases.", "labels": [], "entities": []}, {"text": "The second instantiation finds the borders of phrases (beginning and end) and then pairs !them in an \"optimal\" way into different phrases.", "labels": [], "entities": []}, {"text": "These problems formulations are similar to those studied in and), respectively.", "labels": [], "entities": []}, {"text": "The experimental results presented using the SNoW based approach compare favorably with previously published results, both for NPs and SV phrases.", "labels": [], "entities": []}, {"text": "As important, we present a few experiments that shed light on some of the issues involved in using learned predictors that interact to produce the desired inference.", "labels": [], "entities": []}, {"text": "In particular, we exhibit the contribution of chaining: features that are generated as the output of one of the predictors contribute to the performance of another predictor that uses them as its input.", "labels": [], "entities": []}, {"text": "Also, the comparison between the two instantiations 0f the learning paradigm -the Inside/Outside and the Open/Close -shows the advantages of the Open/Close model over the Inside/Outside, especially for the task of identifying long sequences.", "labels": [], "entities": []}, {"text": "The contribtition of this work is in improving the state of the art in learning to perform shallow parsing tasks, developing a better understanding for how to model these tasks as learning problems and in further studying the SNoW based computational paradigm that, we believe, can be used in many other related tasks in NLP.", "labels": [], "entities": [{"text": "learning to perform shallow parsing tasks", "start_pos": 71, "end_pos": 112, "type": "TASK", "confidence": 0.7472917934258779}]}, {"text": "The rest of this paper is organized as follows: The SNoW architecture is presented in Sec.", "labels": [], "entities": []}, {"text": "3 presents the shallow parsing tasks studled and provides details on the computational approach.", "labels": [], "entities": []}, {"text": "4 describes the data used and the experimental approach, and Sec.", "labels": [], "entities": []}, {"text": "5 presents and discusses the experimental results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sizes of the training and test data sets for NP Patterns.", "labels": [], "entities": [{"text": "NP Patterns", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.6863445043563843}]}, {"text": " Table 2: Sizes of the training and test data sets for SV Patterns.", "labels": [], "entities": [{"text": "SV Patterns", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.8660515248775482}]}, {"text": " Table 3: Results for NP detection using Inside/Outside method.", "labels": [], "entities": [{"text": "NP detection", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.9849480986595154}]}, {"text": " Table 4: Results for SV Phrase and NP detection using Open/Close method.", "labels": [], "entities": [{"text": "SV Phrase", "start_pos": 22, "end_pos": 31, "type": "TASK", "confidence": 0.7215253412723541}, {"text": "NP detection", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.8477542102336884}]}, {"text": " Table 5: Accuracy of close bracket predictor when using features created on local information alone  versus using additional features created from the open bracket candidate. Overall performance and  performance on positive examples only is shown.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9833605289459229}]}, {"text": " Table 6: Comparison of Inside/Outside and Open/Close on SV patterns of varying lengths.", "labels": [], "entities": []}, {"text": " Table 8: Comparison of Results for SV. In the accuracy column, O indicates the accuracy of the  Open predictor and C indicates the accuracy of the Close predictor.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9995044469833374}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9990779161453247}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9991263747215271}]}]}