{"title": [{"text": "Applying Extrasentential Context To Maximum Entropy Based Tagging With A Large Semantic And Syntactic Tagset", "labels": [], "entities": [{"text": "Applying", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9244950413703918}]}], "abstractContent": [{"text": "Experiments are presented which measure the perplexity reduction derived from incorporating into the predictive model utilised in a standard tag-n-gram part-of-speech tagger, contextual information from previous sentences of a document.", "labels": [], "entities": []}, {"text": "The tagset employed is the roughly-3000-tag ATR General English Tagset, whose tags are both syntactic and semantic in nature.", "labels": [], "entities": [{"text": "ATR General English Tagset", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.8275510221719742}]}, {"text": "The kind of extrasentential information provided to the tagger is semantic, and consists in the occurrence or non-occurrence, within the past 6 sentences of the document being tagged, of words tagged with particular tags from the tagset, and of boolean combinations of such conditions.", "labels": [], "entities": []}, {"text": "In some cases, these conditions are combined with the requirement that the word being tagged belong to a particular set of words thought most likely to benefit from the extrasentential information they are being conjoined with.", "labels": [], "entities": []}, {"text": "The baseline model utilized is a maximum entropy-based tag-n-gram tagging model, embodying a standard tag-n-gram approach to tagging: i.e. constraints for tag trigrams, bigrams, and and the word-tag occurrence frequency of the specific word being tagged, form the basis of prediction.", "labels": [], "entities": []}, {"text": "Added into to this baseline tagging model is the extrasentential semantic information just indicated.", "labels": [], "entities": []}, {"text": "The performance of the tagging model with and without the added contextual knowledge is contrasted, training from the 850,000-word ATR General English Treebank, and testing on the accompanying 53,000-word test tree-bank.", "labels": [], "entities": [{"text": "ATR General English Treebank", "start_pos": 131, "end_pos": 159, "type": "DATASET", "confidence": 0.8908651769161224}]}, {"text": "Results are that a significant reduction in testset perplexity is achieved via the added semantic extrasentential information of the richer model.", "labels": [], "entities": []}, {"text": "The model with both long-range tag triggers and more complex linguistic constraints achieved a perplexity reduction of 21.4%.", "labels": [], "entities": [{"text": "perplexity reduction", "start_pos": 95, "end_pos": 115, "type": "METRIC", "confidence": 0.9565337896347046}]}], "introductionContent": [{"text": "It appears intuitively that information from earlier sentences in a document ought to help reduce uncertMnty as to a word's correct partof-speech tag.", "labels": [], "entities": []}, {"text": "This is especially so fora large semantic and syntactic tagset such as the roughly-3000-tag ATR General English Tagset (.", "labels": [], "entities": [{"text": "ATR General English Tagset", "start_pos": 92, "end_pos": 118, "type": "DATASET", "confidence": 0.7285869866609573}]}, {"text": "And in fact, ) demonstrate a significant \"tag trigger-pair\" effect.", "labels": [], "entities": []}, {"text": "That is, given that certain \"triggering\" tags have already occurred in a document, the probability of occurrence of specific \"triggered\" tags is raised significantly--with respect to the unigram tag probability model., taken from ), provides examples of the tag trigger-pair effect.", "labels": [], "entities": []}, {"text": "Yet, it is one thing to show that extrasentential context yields again in information with respect to a unigram tag probability model.", "labels": [], "entities": []}, {"text": "But it is another thing to demonstrate that extrasentential context supports an improvement in perplexity vis-a-vis a part-of-speech tagging model which employs state-of-the-art techniques: such as, for instance, the tagging model of a maximum entropy tag-n-grambased tagger.", "labels": [], "entities": []}, {"text": "The present paper undertakes just such a demonstration.", "labels": [], "entities": []}, {"text": "Both the model underlying a standard tag-n-gram-based tagger, and the same model augmented with extrasentential contextual information, are trMned on the 850,000-word ATR General English Treebank (, and then tested on the accompanying 53,000-word test treebank.", "labels": [], "entities": [{"text": "ATR General English Treebank", "start_pos": 167, "end_pos": 195, "type": "DATASET", "confidence": 0.8973342180252075}]}, {"text": "Performance differences are measured, with the result that semantic information from previous sentences within a document is shown to help significantly in improving the perplexity of tagging In what follows, Section 2 provides a basic overview of the tagging approach used (a maximum entropy tagging model employing constraints equivalent to those of the standard hidden Markov model).", "labels": [], "entities": []}, {"text": "Section 3 discusses and offers examples of the sorts of extrasententiallybased semantic constraints that were added to the basic tagging model.", "labels": [], "entities": []}, {"text": "Section 4 describes the experiments we performed.", "labels": [], "entities": []}, {"text": "Section 5 details our experimental results.", "labels": [], "entities": []}, {"text": "Section 6 glances at projected future research, and concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "The performance of each the tagging models is measured on a 53,000-word test treebank handlabelled to an accuracy of over 97%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.999290943145752}]}, {"text": "We measure the model performance in terms of the perplexity of the tag being predicted.", "labels": [], "entities": []}, {"text": "This measurement gives an indication of how useful the features we supply could be to an n-gram tagger when it consults its model to obtain a probablity distribution over the tagset fora particular word.", "labels": [], "entities": []}, {"text": "Since our intention is to gauge the usefulness of long-range context, we measure the performance improvement with respect to correctly (very accurately) labelled context.", "labels": [], "entities": []}, {"text": "We chose to do this to isolate the effect of the correct markup of the history on tagging performance (i.e. to measure the performance gain in the absence of noise from the tagging process itself).", "labels": [], "entities": []}, {"text": "Earlier experiments using predicted tags in the history showed that at current levels of tagging accuracy for this tagset, these predicted tags yielded very little benefit to a tagging model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9653352499008179}]}, {"text": "However, removing the noise from these tags showed clearly that improvement was possible from this information.", "labels": [], "entities": []}, {"text": "As a consequence, we chose to investigate in the absence of noise, so that we could seethe utility of exploiting the history when labelled with syntactic/semantic tags.", "labels": [], "entities": []}, {"text": "The resulting measure is an idealization of a component of areal tagging process, and is a measure of the usefulness of knowing the tags in the history.", "labels": [], "entities": []}, {"text": "In order to make the comparisons between models fair, we use correctly-labelled history in the n-gram components of our models as well as for the long-range triggers.", "labels": [], "entities": []}, {"text": "As a consequence of this, no search is nescessary.", "labels": [], "entities": []}, {"text": "The number of possible triggers is obviously very large and needs to be limited for reasons of", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Selected Tag Trigger-Pairs, ATR General-English Treebank", "labels": [], "entities": [{"text": "ATR General-English Treebank", "start_pos": 38, "end_pos": 66, "type": "DATASET", "confidence": 0.8791780869166056}]}, {"text": " Table 2: Vocabulary sizes and number of trig- gers used", "labels": [], "entities": []}, {"text": " Table 3: The 5 triggers for tag NNIPERSON with the highest MI", "labels": [], "entities": [{"text": "MI", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.983787477016449}]}, {"text": " Table 4: Perplexity of the four models", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9773769974708557}]}]}