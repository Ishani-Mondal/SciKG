{"title": [{"text": "Exploiting Diversity in Natural Language Processing: Combining Parsers", "labels": [], "entities": [{"text": "Exploiting Diversity in Natural Language Processing", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.6605409731467565}]}], "abstractContent": [{"text": "Three state-of-the-art statistical parsers are combined to produce more accurate parses, as well as new bounds on achievable Treebank parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.878493070602417}]}, {"text": "Two general approaches are presented and two combination techniques are described for each approach.", "labels": [], "entities": []}, {"text": "Both parametric and non-parametric models are explored, i The resulting parsers surpass the best previously published performance results for the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 146, "end_pos": 159, "type": "DATASET", "confidence": 0.9949013888835907}]}], "introductionContent": [{"text": "The natural language processing community is in the strong position of having many available approaches to solving some of its most fundamental problems.", "labels": [], "entities": []}, {"text": "The machine learning community has been in a similar situation and has studied the combination of multiple classifiers.", "labels": [], "entities": []}, {"text": "Their theoretical I finding is simply stated: classification error rate decreases toward the noise rate exponentially in the number of independent, accurate classifiers.", "labels": [], "entities": [{"text": "classification error rate", "start_pos": 46, "end_pos": 71, "type": "METRIC", "confidence": 0.7798041303952535}]}, {"text": "The theory has also been validated empirically.", "labels": [], "entities": []}, {"text": "Recently, combination techniques have been investigated for part of speech tagging with positive results).", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7761935889720917}]}, {"text": "In both cases the investigators were able to achieve significant improvements over the previous best tagging results.", "labels": [], "entities": []}, {"text": "Similar advances have been made in machine translation, speech recognition (Fiscus, 1997) and named entity recognition ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.783814936876297}, {"text": "speech recognition", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8185577094554901}, {"text": "named entity recognition", "start_pos": 94, "end_pos": 118, "type": "TASK", "confidence": 0.7577055096626282}]}, {"text": "The corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by, and.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.5862302333116531}]}, {"text": "These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal corpus", "start_pos": 72, "end_pos": 112, "type": "DATASET", "confidence": 0.9795939028263092}]}, {"text": "We used these three parsers to explore parser combination techniques.", "labels": [], "entities": []}], "datasetContent": [{"text": "The three parsers were trained and tuned by their creators on various sections of the WSJ portion of the Penn Treebank, leaving only sections 22 and 23 completely untouched during the development of any of the parsers, i We used section 23 as the development set for our combining techniques, and section 22 only for final testing.", "labels": [], "entities": [{"text": "WSJ portion of the Penn Treebank", "start_pos": 86, "end_pos": 118, "type": "DATASET", "confidence": 0.9308153092861176}]}, {"text": "The development set contalned 44088 constituents in 2416 sentences and the test set contained 30691 constituents in 1699 sentences.", "labels": [], "entities": []}, {"text": "A sentence was withheld from section 22 because its exireme length was troublesome fora couple of the parsers) The standard measures for evaluating Penn Treebank parsing performance are precision and recall of the predicted Constituents.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 148, "end_pos": 161, "type": "DATASET", "confidence": 0.9809756577014923}, {"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9994103908538818}, {"text": "recall", "start_pos": 200, "end_pos": 206, "type": "METRIC", "confidence": 0.9993696808815002}]}, {"text": "Each parse is converted into a set of constituents represented as a tuples: 1The sentence: in question was more than 100 words in length and included nested quotes and parenthetical expressions.", "labels": [], "entities": []}, {"text": "(label, start, end).", "labels": [], "entities": []}, {"text": "The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.", "labels": [], "entities": [{"text": "Penn Treebank parse", "start_pos": 57, "end_pos": 76, "type": "DATASET", "confidence": 0.9800143837928772}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9996163845062256}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9988110065460205}]}, {"text": "Precision is the portion of hypothesized constituents that are correct and recall is the portion of the Treebank constituents that are hypothesized.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9873194694519043}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9989111423492432}]}, {"text": "For our experiments we also report the mean of precision and recall, which we denote by (P + R)/2 and F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9962936043739319}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9994938373565674}, {"text": "F-measure", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9828081727027893}]}, {"text": "F-measure is the harmonic mean of precision and recall, 2PR/(P + R).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9742807745933533}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9989606142044067}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9975826740264893}, {"text": "2PR", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9690006971359253}]}, {"text": "It is closer to the smaller value of precision and recall when there is a large skew in their values.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9993849992752075}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9987238049507141}]}, {"text": "We performed three experiments to evaluate our techniques.", "labels": [], "entities": []}, {"text": "The first shows how constituent features and context do not help in deciding which parser to trust.", "labels": [], "entities": []}, {"text": "We then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9658452272415161}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9671019911766052}]}, {"text": "Finally we show the combining techniques degrade very little when a poor parser is added to the set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Bayes Switching Parser Usage", "labels": [], "entities": [{"text": "Bayes Switching Parser Usage", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.5774226039648056}]}, {"text": " Table 1: Isolated Constituent Precision By Constituent Label", "labels": [], "entities": [{"text": "Isolated Constituent Precision", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.7347966829935709}]}, {"text": " Table 2: Summary of Development Set Performance", "labels": [], "entities": []}, {"text": " Table 3: Test Set Results", "labels": [], "entities": []}]}