{"title": [{"text": "Automatically Merging Lexicons that have Incompatible Part-of-Speech Categories", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew method to automatically merge lexicons that employ different incompatible POS categories.", "labels": [], "entities": []}, {"text": "Such incompatibilities have hindered efforts to combine lexicons to maximize coverage with reasonable human effort.", "labels": [], "entities": []}, {"text": "Given an \"original lexicon\", our method is able to merge lexemes from an \"additional lexicon\" into the original lexicon , converting lexemes from the additional lexicon with about 89% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 184, "end_pos": 193, "type": "METRIC", "confidence": 0.9970402121543884}]}, {"text": "This level of precision is achieved with the aid of a device we introduce called an anti-lexicon, which neatly summarizes all the essential information we need about the co-occurrence of tags and lemmas.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9990791082382202}]}, {"text": "Our model is intuitive, fast, easy to implement, and does not require heavy computational resources nor training corpus.", "labels": [], "entities": []}, {"text": "lemma I tag apple INN boy NN calculate VB Example entries in Brill lexicon 1 Motivation We present anew, accurate method to automatically merge lexicons that contain incompatible POS categories.", "labels": [], "entities": []}, {"text": "In this paper, we look specifically at the problem that different lexicons employ their own part-of-speech (POS) tagsets that are incompatible with each other, owing to their different linguistic backgrounds, application domains, and/or lexical acquisition methods.", "labels": [], "entities": []}, {"text": "Consider the way that lemmas are typically marked with POS information in machine-readable lexicons.", "labels": [], "entities": []}, {"text": "For example, here area few entries from the lexicon in Brill's tagger (Brill, 1994) and the Moby lexicon (Ward, 1996), showing simple pairs of lemmas and POS tags:", "labels": [], "entities": [{"text": "Brill's tagger (Brill, 1994)", "start_pos": 55, "end_pos": 83, "type": "DATASET", "confidence": 0.8129871636629105}, {"text": "Moby lexicon (Ward, 1996)", "start_pos": 92, "end_pos": 117, "type": "DATASET", "confidence": 0.9385896580559867}]}], "introductionContent": [], "datasetContent": [{"text": "5.1 Setup We tested the above method in a set of experiments using four commonly-used machine-readable dictionaries.", "labels": [], "entities": []}, {"text": "They are Brill's lexicon, the Moby lexicon, the Collins lexicon, the Oxford machine-readable dictionary, with characteristics as summarized in new set of training lexicons in each task.", "labels": [], "entities": [{"text": "Brill's lexicon", "start_pos": 9, "end_pos": 24, "type": "DATASET", "confidence": 0.8977133433024088}, {"text": "Moby lexicon", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9701479077339172}, {"text": "Collins lexicon", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.9891453385353088}, {"text": "Oxford machine-readable dictionary", "start_pos": 69, "end_pos": 103, "type": "DATASET", "confidence": 0.8756802876790365}]}, {"text": "Note that the trimmed down Brill lexicon in the \"Brill-to-Collins\" task is not the same as the trimmed down Brill lexicon in \"Brill-to-Moby\".", "labels": [], "entities": [{"text": "Brill", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9511163234710693}]}, {"text": "In order to evaluate the accuracy of our methods, we asked a linguist to manually create twelve \"gold standard\" sets of POS mapping rules, TO, one for each of the twelve pairwise lexicons on the semantics between the POS tag only.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9984490871429443}, {"text": "TO", "start_pos": 139, "end_pos": 141, "type": "METRIC", "confidence": 0.991141676902771}]}, {"text": "We then ran the experiments to automatically generate two sets of POS mapping tables, with one under the complete world assumption and another using an anti-lexicon in each merging task.", "labels": [], "entities": []}, {"text": "We evaluated precision and recall on POS mapping rules as follows:    by the fact that machine readable lexicons usually do not contain full lexeme coverage.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999437153339386}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9993718266487122}, {"text": "POS mapping", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.7610823512077332}]}, {"text": "This means our \"complete lexicon assumption\" which says that we can interpret entries not being in the lexicon as \"negative examples\" is not correct.", "labels": [], "entities": []}, {"text": "In the anti-lexicon model, the precision greatly improves, with some experiments even achieving 100% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9996330738067627}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9967369437217712}]}, {"text": "Unfortunately, the recall suffers sharply.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9981154203414917}]}, {"text": "After automatically constructing the POS mapping tables from training, we proceeded to merge lexicons in each testing task using the lexicon merging algorithm described above, and evaluated the accuracy of the merged lexicons as follow.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9987469911575317}]}, {"text": "In each merging task, we randomly selected 100 lexemes from the additional lexicon.", "labels": [], "entities": []}, {"text": "Given these 100 lexemes, a linguist first manually constructs a set of correctly converted lexemes, which will be used as the \"gold standard\" set of lexemes, T~ n.", "labels": [], "entities": []}, {"text": "Similar to the evaluation criteria outlined for POS mappings, we define the precision and recall on lexicon merging as the following: where \u2022 E L is the set of lexemes generated by the lexicon insertor.", "labels": [], "entities": [{"text": "POS mappings", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.753553032875061}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9995352029800415}, {"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9990543723106384}]}, {"text": "\u2022 E L' is the subset of E L that contains all lexemes in ~n.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of English monolingual  lexicons", "labels": [], "entities": [{"text": "Summary of English monolingual  lexicons", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.7989422798156738}]}, {"text": " Table 2: Summary of original POS tagsets in lexicons", "labels": [], "entities": []}, {"text": " Table 3: Size of trimmed lexicons after lexicon intersection", "labels": [], "entities": []}, {"text": " Table 4: Results for POS mapping rule learning", "labels": [], "entities": [{"text": "POS mapping rule learning", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.8835816532373428}]}, {"text": " Table 5: Results for lexicon merging", "labels": [], "entities": []}, {"text": " Table 6: Lexicon merging results using  gold standard POS mapping rules", "labels": [], "entities": []}, {"text": " Table 7: Average precision on lexicon merging using different sire-thresholds 7 and anti- thresholds A", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.980732262134552}, {"text": "anti- thresholds", "start_pos": 85, "end_pos": 101, "type": "METRIC", "confidence": 0.9624322851498922}]}]}