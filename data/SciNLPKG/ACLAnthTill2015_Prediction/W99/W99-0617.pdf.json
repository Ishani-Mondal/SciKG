{"title": [{"text": "POS Tags and Decision Trees for Language Modeling", "labels": [], "entities": [{"text": "POS Tags", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.5548938512802124}, {"text": "Language Modeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7216895520687103}]}], "abstractContent": [{"text": "Language models for speech recognition concentrate solely on recognizing the words that were spoken.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7808062732219696}]}, {"text": "In this paper, we advocate redefining the speech recognition problem so that its goal is to find both the best sequence of words and their POS tags, and thus incorporate POS tagging.", "labels": [], "entities": [{"text": "speech recognition problem", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.8267002105712891}, {"text": "POS tagging", "start_pos": 170, "end_pos": 181, "type": "TASK", "confidence": 0.7514061331748962}]}, {"text": "To use POS tags effectively, we use clustering and decision tree algorithms, which allow generalizations between POS tags and words to be effectively used in estimating the probability distributions.", "labels": [], "entities": []}, {"text": "We show that our POS model gives, a reduction in word error rate and perplexity for the Trains corpus in comparison to word and class-based approaches.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 49, "end_pos": 64, "type": "METRIC", "confidence": 0.7087811430295309}, {"text": "Trains corpus", "start_pos": 88, "end_pos": 101, "type": "DATASET", "confidence": 0.9229196906089783}]}, {"text": "By using the Wall Street Journal corpus, we show that this approach scales up when more training data is available.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 13, "end_pos": 39, "type": "DATASET", "confidence": 0.9769384264945984}]}], "introductionContent": [{"text": "For recognizing spontaneous speech, the acoustic signal is to weak to narrow down the number of word candidates.", "labels": [], "entities": [{"text": "recognizing spontaneous speech", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.8760112325350443}]}, {"text": "Hence, recognizers employ a language model to take into account the likelihood of word seqiaences.", "labels": [], "entities": []}, {"text": "To do this, the recognition problem is Cast as finding the most likely word sequence l?g given the acoustic signal A.", "labels": [], "entities": []}, {"text": "The last line involves two probabilities that need to be estimated--the first due to the acoustic model Pr(AIW ) and the second due to the language model Pr(W).", "labels": [], "entities": []}, {"text": "The language model probability can be expressed as follows, where we rewrite the sequence W explicitly as the sequence of N words Wi,N. To estimate the probability distribution Pr(WilWl, i-a), a training corpus is used to determine the relative frequencies.", "labels": [], "entities": []}, {"text": "Due to sparseness of data, one must define equivalence classes amongst the contexts W~,i-1, which can be done by limiting the context to an n-gram language model.", "labels": [], "entities": []}, {"text": "One can also mix in smaller size language models when there is not enough data to support the larger context by using either interpolated estimation) or a backoff approach.", "labels": [], "entities": []}, {"text": "A way of measuring the effectiveness of the estimated probability distribution is to measure the perplexity that it assigns to a test corpus (.", "labels": [], "entities": []}, {"text": "Perplexity is an estimate of how well the language model is able to predict the next word of a test corpus in terms of the number of alternatives that need to be considered at each point.", "labels": [], "entities": []}, {"text": "The perplexity of a test set Wi,N is calculated as 2 H, where H is the entropy, defined as follows.", "labels": [], "entities": []}, {"text": "1 N n -N Y~l\u00b0g2tSr(wilw~i-1)3) i=1", "labels": [], "entities": []}], "datasetContent": [{"text": "To make the best use of the limited size of the Trains corpus, we used a six-fold crossvalidation procedure: each sixth of the data was tested using the rest of the data for training.", "labels": [], "entities": [{"text": "Trains corpus", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.9741992950439453}]}, {"text": "This was done for both acoustic and language models.", "labels": [], "entities": []}, {"text": "Dialogs for each pair of speakers were distributed as evenly between the six partitions in order to minimize the new speaker problem.", "labels": [], "entities": []}, {"text": "For our perplexity results, we ran the experiments on the hand-collected transcripts.", "labels": [], "entities": []}, {"text": "Changes in speaker are marked in the word transcription with the token <turn>.", "labels": [], "entities": []}, {"text": "Contractions, such as \"that'll\" and \"gonna\", are treated as separate words: \"that\" and '\"11\" for the first example, and \"going\" and \"ta\" for the second.", "labels": [], "entities": []}, {"text": "All word fragments were changed to the token <fragment>.", "labels": [], "entities": []}, {"text": "In searching for the best sequence of POS tags for the transcribed words, we follow the technique proposed by and only keep a small number of alternative paths by pruning the low probability paths after processing each word.", "labels": [], "entities": []}, {"text": "For our speech recognition results, we used OGI's large vocabulary speech recognizer), using acoustic models trained from the Trains corpus.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7986007034778595}, {"text": "OGI", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.890701413154602}, {"text": "large vocabulary speech recognizer", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.511408619582653}, {"text": "Trains corpus", "start_pos": 126, "end_pos": 139, "type": "DATASET", "confidence": 0.888230174779892}]}, {"text": "We ran the decoder in a single pass using crossword acoustic modeling and a trigram wordbased backoff model built with the CMU toolkit.", "labels": [], "entities": []}, {"text": "For the first pass, contracted words were treated as single tokens in order to improve acoustic recognition of them.", "labels": [], "entities": []}, {"text": "The result of the first pass was a word graph, which we rescored in a second pass using our other trigram language models.", "labels": [], "entities": []}], "tableCaptions": []}