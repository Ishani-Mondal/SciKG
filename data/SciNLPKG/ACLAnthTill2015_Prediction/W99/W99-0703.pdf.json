{"title": [], "abstractContent": [{"text": "This paper presents a semi-automatic technique for developing broad-coverage finite-state morphological analyzers for any language.", "labels": [], "entities": [{"text": "broad-coverage finite-state morphological analyzers", "start_pos": 62, "end_pos": 113, "type": "TASK", "confidence": 0.6090172529220581}]}, {"text": "It consists of three components-elicitation of linguistic information from humans, a machine learning bootstrapping scheme and a testing environment.", "labels": [], "entities": []}, {"text": "The three components are applied iteratively until a threshold of output quality is attained.", "labels": [], "entities": []}, {"text": "The initial application of this technique is for morphology of low-density languages in the context of the Expedition project at NMSU CRL.", "labels": [], "entities": [{"text": "NMSU CRL", "start_pos": 129, "end_pos": 137, "type": "DATASET", "confidence": 0.9118291437625885}]}, {"text": "This elicit-build-test technique compiles lexical and inflectional information elicited from a human into a finite state transducer lexicon and combines this with a sequence of morphographemic rewrite rules that is induced using transformation-based learning from the elicited examples.", "labels": [], "entities": []}, {"text": "The resulting morphological analyzer is then tested against a test suite, and any corrections are fed back into the learning procedure that builds an improved analyzer.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Expedition project is devoted to fast \"ramp-up\" of machine translation systems from less studied, so-called \"low-density\" languages into English.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7015336900949478}]}, {"text": "One of the components that must be acquired and built during this process is a morphological analyzer for the source low-density language.", "labels": [], "entities": []}, {"text": "Since we expect that the source language informant will not be well-versed in computational linguistics in general or in recent approaches to building morphological analyzers (e.g.,,,,) and the operation of state-of-the-art finite state tools (e.g.,,,) in particular, the generation of the morphological analyzer component has to be accomplished almost semi-automatically.", "labels": [], "entities": []}, {"text": "The user must be guided through a knowledge elicitation procedure for the knowledge required for the morphological analyzer.", "labels": [], "entities": []}, {"text": "This is accomplished using the elicitation component of Expedition, the Boas system.", "labels": [], "entities": [{"text": "Expedition", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.8909270167350769}, {"text": "Boas system", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.8812826573848724}]}, {"text": "As this task is not easy, we expect that the development of the morphological analyzer will bean iterative process, whereby the human informant will revise and/or refine the information previously elicited based on the feedback from a test runs of the nascent analyzer.", "labels": [], "entities": []}, {"text": "The work reported in this paper describes the use of machine learning in the process of building and refining morphological analyzers.", "labels": [], "entities": []}, {"text": "The main use of machine learning in our current approach is in the automatic learning of formal rewrite or replace rules for morphographemic changes from the examples, provided by the informant.", "labels": [], "entities": []}, {"text": "This subtask of accounting for such phenomena is perhaps one of the more complicated aspects of building an analyzer and by automating it we expect to gain a certain improvement in productivity.", "labels": [], "entities": []}, {"text": "There have been a number of studies on inducing morphographemic rules from a list of inflected words and a root word list.", "labels": [], "entities": []}, {"text": "Johnson presents a scheme for inducing phonological rules from surface data, mainly in the context of studying certain aspects of language acquisition.", "labels": [], "entities": []}, {"text": "The premise is that languages have a finite number of alternations to be handled by morphographemic rules and a fixed number of contexts in which they appear; so if there is enough data, phonological rewrite rules can be generated to account for the data.", "labels": [], "entities": []}, {"text": "Rules are ordered by some notion of \"'surfaciness\", and at each stage the nmst surfacy rule --the rule with the most transparent context is selected.", "labels": [], "entities": []}, {"text": "describe an approach for inducing rules of English word formation from a given corpus of root forms and the corresponding inflected forms.", "labels": [], "entities": [{"text": "English word formation", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.6514124472935995}]}, {"text": "The procedure described there generates a sequence of transformation rules, leach specifying how to perform a particular inflection.", "labels": [], "entities": []}, {"text": "More recently, Theron and Cloete have pre1Not in the sense it is used in transformation-based learning.", "labels": [], "entities": []}, {"text": "sented a scheme for obtaining two-level morphology rules from a set of aligned segmented and surface pairs.", "labels": [], "entities": []}, {"text": "They use the notion of string edit sequences assuming that only insertions and deletions are applied to a root form to get the inflected form.", "labels": [], "entities": []}, {"text": "They determine the root form associated with an inflected form (and consequently the suffixes and prefixes) by exhaustively matching against all root words.", "labels": [], "entities": []}, {"text": "The motivation is that \"real\" suffixes and prefixes will appear often enough in the corpus of inflected forms, so that, once frequently occurring suffixes and prefixes are identified, one can then determine the segmentation fora given inflected word by choosing the segmentation with the most frequently occurring affix segments and considering the remainder to be the root.", "labels": [], "entities": []}, {"text": "While this procedure seems to be reasonable fora small root word list, the potential for \"noisy\" or incorrect alignments is quite high when the corpus of inflected forms is large and the procedure is not given any prior knowledge of possible segmentations.", "labels": [], "entities": []}, {"text": "As a result, selecting the \"correct\" segmentation automatically becomes quite nontrivial.", "labels": [], "entities": []}, {"text": "An additional complication is that allomorphs show up as distinct affixes and their counts in segmentations are not accumulated, which might lead to actual segmentations being missed due to fragmentation.", "labels": [], "entities": []}, {"text": "The rule induction is not via a learning scheme: aligned pairs are compressed into a special data structure and traversals over this data structure generate morphographemic rules.", "labels": [], "entities": [{"text": "rule induction", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6981139481067657}]}, {"text": "Theron and Cloete have experimented with pluralization in Afrikaans, and the resulting system has shown about 94% accuracy on unseen words.", "labels": [], "entities": [{"text": "pluralization", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.9610396027565002}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9991588592529297}]}, {"text": "Goldsmith has used an unsupervised learning method based on the minimum description length principle to learn the \"morphology\" of a number of languages.", "labels": [], "entities": []}, {"text": "What is learned is a set of \"root\" words and affixes, and common inflectional pattern classes.", "labels": [], "entities": []}, {"text": "The system requires just a corpus of words in a language.", "labels": [], "entities": []}, {"text": "In the absence of any root word list to use as a scaffolding, the shortest forms that appear frequently are assumed to be roots, and observed surface forms are then either generated by concatenative affixation of suffixes or by rewrite rules.", "labels": [], "entities": []}, {"text": "2 Since the system has no notion of what the roots and their part of speech values really are, and what morphological information is encoded by the affixes, these need to be retrofitted manually by a human (if one is building a morphological analyzer) who would have to weed through a large number of noisy rules.", "labels": [], "entities": []}, {"text": "We feel that this approach, while quite novel, can be used to build real-world morphological analyzers only after substantial modifications are made.", "labels": [], "entities": []}, {"text": "ZSome of which may\" not make sense, but are necessaryto account for the data: for instance a rule like insert a word final y after the root \"eas\". is used to generate easy.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}