{"title": [{"text": "Learning Discourse Relations with Active Data Selection", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents anew approach to identifying discourse relations, which makes use of a particular sampling method called committee-based sampling (CBS).", "labels": [], "entities": []}, {"text": "In the committee-based sampling, multiple learning models are generated to measure the utility of an input example in classification; if it is judged as not useful, then the example will be ignored.", "labels": [], "entities": []}, {"text": "The method has the effect of reducing the amount of data required for training.", "labels": [], "entities": []}, {"text": "In the paper, we extend CBS for decision tree classifiers.", "labels": [], "entities": [{"text": "CBS", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9298051595687866}, {"text": "decision tree classifiers", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.6941289901733398}]}, {"text": "With an additional extension called error feedback, it is found that the method achieves an increased accuracy as well as a substantial reduction in the amount of data for training classifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9991136193275452}]}], "introductionContent": [{"text": "The success of corpus-based approaches to discourse ultimately depends on whether one is able to acquire a large volume of data annotated for discourse-level information.", "labels": [], "entities": []}, {"text": "However, to acquire merely a few hundred texts annotated for discourse information is often impossible due to the enormity of the haman labor required.", "labels": [], "entities": []}, {"text": "This paper presents a novel method for reducing the amount of data for training a decision tree classifier, while not compromising the accuracy.", "labels": [], "entities": [{"text": "decision tree classifier", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.6331052184104919}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9985311031341553}]}, {"text": "While there has been some work exploring the use of machine leaning techniques for discourse and dialogue), to our knowledge, no computational research on discourse or dialogue so far has addressed the problem of reducing or minimizing the amount of data for training a learning algorithm.", "labels": [], "entities": []}, {"text": "A particular method proposed here is built on the committee-based sampling, initially proposed for probabilistic classifiers by, where an example is selected from the corpus according to its utility in improving statistics.", "labels": [], "entities": []}, {"text": "We extend the method for decision tree classifiers using a statistical technique called bootstrapping.", "labels": [], "entities": [{"text": "decision tree classifiers", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.7226534287134806}]}, {"text": "With an additional extension, which we call error .feedback, it is found that the method achieves an increased accuracy as well as a significant reduction of training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9993478655815125}]}, {"text": "The method proposed here should be of use in domains other than discourse, where a decision tree strategy is found applicable.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our method, we carried out experiments, using a corpus of news articles from a Japanese economics daily.", "labels": [], "entities": []}, {"text": "The corpus had 477 articles, randomly selected from issues that were published durilig the year.", "labels": [], "entities": []}, {"text": "Each sentence in the articles was tagged with one of the discourse relations at the subclass level (i.e. CONSEQUEN-TIAL, ANTITHESIS, etc.).", "labels": [], "entities": [{"text": "ANTITHESIS", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.8434064984321594}]}, {"text": "However, in evaluation experiments, we translated a subclass relation into a corresponding major class relation (SE-QUENCE/ELABORATION) for reasons discussed earlier.", "labels": [], "entities": [{"text": "SE-QUENCE", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9863114953041077}, {"text": "ELABORATION", "start_pos": 123, "end_pos": 134, "type": "METRIC", "confidence": 0.7050791382789612}]}, {"text": "Furthermore , we explicitly asked coders not to tag a paragraph initial sentence fora discourse relation, for we found that coders rarely agree on their :classifications.", "labels": [], "entities": []}, {"text": "Paragraph-initial sentences were dropped ffrom the evaluation corpus.", "labels": [], "entities": []}, {"text": "This had left us with 5221 sentences, of which 56% are labeled as SEQUENCE and 44% ELABORATION.", "labels": [], "entities": [{"text": "SEQUENCE", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9677837491035461}, {"text": "ELABORATION", "start_pos": 83, "end_pos": 94, "type": "METRIC", "confidence": 0.9969698786735535}]}, {"text": "To find out effects of the committee-based sampling method (CBS), we ran the C4.5 (Release 5) decision tree algorithm with CBS turned on and off) and measured the performance by the 10-fold cross validation, in which the corpus is divided evenly into 10 blocks of data and 9 blocks are used for training and the remaining one block is held out for testing.", "labels": [], "entities": []}, {"text": "On each validation fold, CBS starts with a set of about 512 samples from the set of training blocks and sequentially examines samples from the rest of the training set for possible labeling.", "labels": [], "entities": []}, {"text": "If a sample is selected, then a decision tree will be trained on the sample together with the data acquired so far, and tested on the held-out data.", "labels": [], "entities": []}, {"text": "Performance scores (error rates) are averaged over 10 folds to give a summary figure fora particular learning strategy.", "labels": [], "entities": [{"text": "error rates)", "start_pos": 20, "end_pos": 32, "type": "METRIC", "confidence": 0.8887317180633545}]}, {"text": "Throughout the experiments, we assume that k = 10 and g = 1, i.e., 10 committee members and the entropy gain of 1.", "labels": [], "entities": []}, {"text": "shows the result of using CBS fora decision tree.", "labels": [], "entities": [{"text": "CBS fora decision tree", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.9079577475786209}]}, {"text": "Though the performance fluctuates erratically, we see a general tendency that the CBS method fares better than a decision tree classifier alone.", "labels": [], "entities": []}, {"text": "In fact differences between C4.5/CBS and C4.5 alone proved statistically significant (t = 7.06, df = 90, p < .01).", "labels": [], "entities": []}, {"text": "While there seems to be a tendency for performance to improve with an increase in the amount of training data, either with or without CBS, it is apparent that an increase in the training data has non-linear effects on performance, which makes an interesting contrast with probabilistic classifiers like HMM, whose performance improves linearly as the training data grow.", "labels": [], "entities": []}, {"text": "The reason has to do with the structural complexity of the decision tree model: it is possible that small changes in the INFO value lead to a drastic restructuring of a decision tree.", "labels": [], "entities": []}, {"text": "In the face of this, we made a small change to the way CBS works.", "labels": [], "entities": []}, {"text": "The idea, which we calla sampling with error feedback, is to remove harmful examples from the training data and only use those with positive effects on performance.", "labels": [], "entities": []}, {"text": "It forces the sampling mechanism to return to status quo ante when it finds that an example selected degrades performance.", "labels": [], "entities": []}, {"text": "More precisely, this would be put as follows: St is a training set at time t.", "labels": [], "entities": []}, {"text": "C s denotes a classifter built from the training set S.", "labels": [], "entities": []}, {"text": "E(C s) is an error rate of a classifier C s.", "labels": [], "entities": [{"text": "E(C s) is an error rate", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.8157938321431478}]}, {"text": "Thus if there is an increase or no reduction in the error rate after adding an example e to the training set, a classifter goes back to the state before the change.", "labels": [], "entities": []}, {"text": "As shows, the error feedback produced a drastic reduction in the error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9786396920681}]}, {"text": "At 900, the committee-based method with the error feedback reduced the error rate by as much as 23%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9919584691524506}]}, {"text": "compares performance of three sampling methods, random sampling, the committee-based sampling with 100 bootstrap replicates (i.e., K = 100) and that with 500 bootstrap replicates.", "labels": [], "entities": []}, {"text": "In the random sampling method, a sample is selected randomly from the data and added to the training data.", "labels": [], "entities": []}, {"text": "compares a random sampling approach with CBS with 500 bootstrap replicates.", "labels": [], "entities": []}, {"text": "Both used the error feedback mechanism.", "labels": [], "entities": []}, {"text": "Differences, though they seem small, turned out to be statistically significant (t = 4.51, df = 90, p < .01), which demonstrates the significance of C4.5/CBS approach.", "labels": [], "entities": []}, {"text": "Furthermore, demonstrates that the number of bootstrap replicates affects performance (t = 8.87, df = 90, p < .01).", "labels": [], "entities": []}, {"text": "CBS with 500 bootstraps performs consistently better than that with 100 bootstrap replicates.", "labels": [], "entities": [{"text": "CBS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9142270088195801}]}, {"text": "This might mean that in the current setup, 100 replicates are not enough to simulate the true distribution of P(M I S).", "labels": [], "entities": []}, {"text": "Note that CBS with 500 replicates achieves the error rate of 33.40 with only 1008 training samples, which amount to one fourth of the training data C4.5 alone required to reach 44.64.", "labels": [], "entities": [{"text": "error rate", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9929595589637756}]}, {"text": "While a direct comparison with other learning schemes in discourse such as a transformation method () is not feasible, if's approach is indeed comparable to C5.0, as discussed in, then the present method might be able to reduce the Training Data 1000 amount of training data without hurting performance.", "labels": [], "entities": [{"text": "Training Data 1000 amount of training data", "start_pos": 232, "end_pos": 274, "type": "DATASET", "confidence": 0.8593850561550685}]}], "tableCaptions": []}