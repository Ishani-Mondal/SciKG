{"title": [{"text": "Unsupervised Models for Named Entity Classification", "labels": [], "entities": [{"text": "Named Entity Classification", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.7149026989936829}]}], "abstractContent": [{"text": "This paper discusses the use of unlabeled examples for the problem of named entity classification.", "labels": [], "entities": [{"text": "named entity classification", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.6646861632664999}]}, {"text": "A large number of rules is needed for coverage of the domain, suggesting that a fairly large number of labeled examples should be required to train a classi-fier.", "labels": [], "entities": []}, {"text": "However, we show that the use of unlabeled data can reduce the requirements for supervision to just 7 simple \"seed\" rules.", "labels": [], "entities": []}, {"text": "The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context inwhich it appears are sufficient to determine its type.", "labels": [], "entities": []}, {"text": "The first method uses a similar algorithm to that of (Yarowsky 95), with modifications motivated by (Blum and Mitchell 98).", "labels": [], "entities": []}, {"text": "The second algorithm extends ideas from boosting algorithms, designed for supervised learning tasks, to the framework suggested by (Blum and Mitchell 98).", "labels": [], "entities": []}], "introductionContent": [{"text": "Many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.", "labels": [], "entities": []}, {"text": "Recent results (e.g.,) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.", "labels": [], "entities": []}, {"text": "This paper discusses the use of unlabeled examples for the problem of named entity classification.", "labels": [], "entities": [{"text": "named entity classification", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.6646861632664999}]}, {"text": "The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location.", "labels": [], "entities": []}, {"text": "For example, a good classifier would identify Mrs. Frank as a person, Steptoe & Johnson as a company, and Honduras as a location.", "labels": [], "entities": [{"text": "Steptoe & Johnson", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.9043084581693014}]}, {"text": "The approach uses both spelling and contextual rules.", "labels": [], "entities": []}, {"text": "A spelling rule might be a simple look-up for the string (e.g., a rule that Honduras is a location) or a rule that looks at words within a string (e.g., a rule that any string containing Mr. is a person).", "labels": [], "entities": []}, {"text": "A contextual rule considers words surrounding the string in the sentence in which it appears (e.g., a rule that any proper name modified by an appositive whose head is president is a person).", "labels": [], "entities": []}, {"text": "The task can be considered to be one component of the MUC (MUC-6, 1995) named entity task (the other task is that of segmentation, i.e., pulling possible people, places and locations from text before sending them to the classifier).", "labels": [], "entities": [{"text": "MUC (MUC-6, 1995) named entity task", "start_pos": 54, "end_pos": 89, "type": "DATASET", "confidence": 0.8710378011067709}]}, {"text": "Supervised methods have been applied quite successfully to the full MUC named-entity task (Bikel et el. 97).", "labels": [], "entities": [{"text": "MUC named-entity task", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.8022376298904419}]}, {"text": "At first glance, the problem seems quite complex: a large number of rules is needed to cover the domain, suggesting that a large number of labeled examples is required to train an accurate classifier.", "labels": [], "entities": []}, {"text": "But we will show that the use of unlabeled data can drastically reduce the need for supervision.", "labels": [], "entities": []}, {"text": "Given around 90,000 unlabeled examples, the methods described in this paper classify names with over 91% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9976480603218079}]}, {"text": "The only supervision is in the form of 7 seed rules (namely, that New York, California and U.S. are locations; that any name containing Mr. is a person; that any name containing Incorporated is an organization; and that LB.M. and Microsoft are organizations).", "labels": [], "entities": []}, {"text": "The key to the methods we describe is redundancy in the unlabeled data.", "labels": [], "entities": []}, {"text": "In many cases, inspection of either the spelling or context alone is sufficient to classify an example.", "labels": [], "entities": []}, {"text": "For example, in .., says Mr. Cooper, a vice president of ..", "labels": [], "entities": []}, {"text": "both a spelling feature (that the string contains Mr.) and a contextual feature (that president modifies the string) are strong indications that Mr. Cooper is of type Person.", "labels": [], "entities": []}, {"text": "Even if an example like this is not labeled, it can be interpreted as a \"hint\" that Mr. and president imply the same category.", "labels": [], "entities": []}, {"text": "The unlabeled data gives many such \"hints\" that two features should predict the same label, and these hints turnout to be surprisingly useful when building a classifier.", "labels": [], "entities": []}, {"text": "The first method builds on results from (Yarowsky 95) and (Blum and I Mitchell 98).", "labels": [], "entities": []}, {"text": "(Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7361393421888351}]}, {"text": "Unfortunately, Yarowsky's method is not well understood from a theoretical viewpoint: we would like to formalize the notion of redundancy in unlabeled data, and setup the learning task as optimization of some appropriate objective function.", "labels": [], "entities": []}, {"text": "(Blum and Mitchell 98) offer a promising formulation of redundancy, also prove some results about how the use of unlabeled examples can help classification, and suggest an objective function when training :with unlabeled examples.", "labels": [], "entities": [{"text": "classification", "start_pos": 141, "end_pos": 155, "type": "TASK", "confidence": 0.9807064533233643}]}, {"text": "Our first algorithm is similar to Yarowsky's, but with some important modifications motivated by (Blum and Mitchell 98).", "labels": [], "entities": []}, {"text": "The algorithm can be viewed as heuristically optimizing an objective function suggested by; empirically it is shown to be quite successful in optimizing this criteflon.", "labels": [], "entities": []}, {"text": "The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).", "labels": [], "entities": []}, {"text": "The AdaBoost algorithm was developed for supervised learning.", "labels": [], "entities": []}, {"text": "AdaBoost finds a weighted combination of simple (weak) classifiers, where the w'eights are chosen to minimize a function that bounds the classification error on a set of training examples.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9044504761695862}]}, {"text": "Roughly speaking, the new algorithm presented in this paper performs a similar search, but instead minimizes abound on the number of (unlabeled) examples on which two classifiers disagree.", "labels": [], "entities": []}, {"text": "The algorithm builds two classifiers iteratively: each iteration involves minimization of a continuously differential function which bounds the number of examples on which the two classifiers disagree.", "labels": [], "entities": []}], "datasetContent": [{"text": "1,000 of these were picked at random, and labeled by hand to produce a test set.", "labels": [], "entities": []}, {"text": "We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.", "labels": [], "entities": []}, {"text": "The numbers falling into the location, person, organi z at ion categories were 186, 289 and 402 respectively.", "labels": [], "entities": []}, {"text": "123 examples fell into the noise category.", "labels": [], "entities": []}, {"text": "Of these cases, 38 were temporal expressions (either a day of the week or month of the year).", "labels": [], "entities": []}, {"text": "We excluded these from the evaluation as they can be easily identified with a list of days/months.", "labels": [], "entities": []}, {"text": "This left 962 examples, of which 85 were noise.", "labels": [], "entities": []}, {"text": "Taking Arc to be the number of examples an algorithm classified correctly (where all gold standard items labeled no i s e were counted as being incorrect), we calculated two measures of accuracy:  .,,.,,,~.-\" Coverage:train ----* ....", "labels": [], "entities": [{"text": "Arc", "start_pos": 7, "end_pos": 10, "type": "METRIC", "confidence": 0.9315621256828308}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9992702603340149}]}, {"text": ".~ : Agreements:train .....", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracy for different learning methods.  The baseline method tags all entities as the most fre- quent class type (organization).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9894683957099915}]}]}