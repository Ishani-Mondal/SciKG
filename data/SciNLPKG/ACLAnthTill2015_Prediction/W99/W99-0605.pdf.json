{"title": [{"text": "Cross-Language Information Retrieval for Technical Documents", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6862716277440389}]}], "abstractContent": [{"text": "This paper proposes a Japanese/English cross-language information retrieval (CLIR) system targeting technical documents.", "labels": [], "entities": [{"text": "Japanese/English cross-language information retrieval (CLIR)", "start_pos": 22, "end_pos": 82, "type": "TASK", "confidence": 0.6470994386408064}]}, {"text": "Our system first translates a given query containing technical terms into the target language, and then retrieves documents relevant to the translated query.", "labels": [], "entities": []}, {"text": "The translation of technical terms is still problematic in that technical terms are often compound words, and thus new terms can be progressively created simply by combining existing base words.", "labels": [], "entities": [{"text": "translation of technical terms", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.8737498819828033}]}, {"text": "In addition, Japanese often represents loanwords based on its phono-gram.", "labels": [], "entities": []}, {"text": "Consequently, existing dictionaries find it difficult to achieve sufficient coverage.", "labels": [], "entities": []}, {"text": "To counter the first problem, we use a compound word translation method, which uses a bilingual dictionary for base words and collocational statistics to resolve translation ambiguity.", "labels": [], "entities": [{"text": "compound word translation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6663309435049692}]}, {"text": "For the second problem, we propose a translitera-tion method, which identifies phonetic equivalents in the target language.", "labels": [], "entities": []}, {"text": "We also show the effectiveness of our system using a test collection for CLIR.", "labels": [], "entities": [{"text": "CLIR", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.7781676650047302}]}], "introductionContent": [{"text": "Cross-language information retrieval (CLIR), where the user presents queries in one language to retrieve documents in another language, has recently been one of the major topics within the information retrieval community.", "labels": [], "entities": [{"text": "Cross-language information retrieval (CLIR)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8355982402960459}, {"text": "information retrieval", "start_pos": 189, "end_pos": 210, "type": "TASK", "confidence": 0.7240705341100693}]}, {"text": "One strong motivation for CLIR is the growing number of documents in various languages accessible via the Internet.", "labels": [], "entities": []}, {"text": "Since queries and documents are in different languages, CLIR requires a translation phase along with the usual monolingual retrieval phase.", "labels": [], "entities": []}, {"text": "For this purpose, existing CLIR systems adopt various techniques explored in natural language processing (NLP) research.", "labels": [], "entities": [{"text": "natural language processing (NLP) research", "start_pos": 77, "end_pos": 119, "type": "TASK", "confidence": 0.7568878020559039}]}, {"text": "In brief, bilingual dictionaries, corpora, thesauri and machine translation (MT) systems are used to translate queries or/and documents.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.8236923098564148}]}, {"text": "In this paper, we propose a Japanese/English CLIR system for technical documents, focusing on translation of technical terms.", "labels": [], "entities": [{"text": "translation of technical terms", "start_pos": 94, "end_pos": 124, "type": "TASK", "confidence": 0.8719545602798462}]}, {"text": "Our purpose also includes integration of different components within one framework.", "labels": [], "entities": []}, {"text": "Our research is partly motivated by the \"NACSIS\" test collection for IR systems ( ) 1 , which consists of Japanese queries and Japanese/English abstracts extracted from technical papers (we will elaborate on the NAC-SIS collection in Section 4).", "labels": [], "entities": [{"text": "NACSIS\" test collection", "start_pos": 41, "end_pos": 64, "type": "DATASET", "confidence": 0.8664564490318298}, {"text": "IR", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.8869656324386597}, {"text": "NAC-SIS collection", "start_pos": 212, "end_pos": 230, "type": "DATASET", "confidence": 0.9431535303592682}]}, {"text": "Using this collection, we investigate the effectiveness of each component as well as the overall performance of the system.", "labels": [], "entities": []}, {"text": "As with MT systems, existing CLIR systems still find it difficult to translate technical terms and proper nouns, which are often unlisted in general dictionaries.", "labels": [], "entities": [{"text": "MT", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.9819469451904297}, {"text": "translate technical terms and proper nouns", "start_pos": 69, "end_pos": 111, "type": "TASK", "confidence": 0.7764997283617655}]}, {"text": "Since most CLIR systems target newspaper articles, which are comprised mainly of general words, the problem related to unlisted words has been less explored than other CLIR subtopics (such as resolution of translation ambiguity).", "labels": [], "entities": [{"text": "resolution of translation ambiguity", "start_pos": 192, "end_pos": 227, "type": "TASK", "confidence": 0.9046714454889297}]}, {"text": "However,, for example, used a subset of the TREC collection related to health topics, and showed that combination of general and domain specific (i.e., medical) dictionaries improves the CLIR performance obtained with only a general dictionary.", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.7708806097507477}]}, {"text": "This result shows the potential contribution of technical term translation to CLIR.", "labels": [], "entities": [{"text": "technical term translation", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.640284945567449}, {"text": "CLIR", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.6582834720611572}]}, {"text": "At the same time, note that even domain specific dictionaries lhttp ://www. rd. nacs is. ac. j p/-nt cadm/index-en, html do not exhaustively list possible technical terms.", "labels": [], "entities": []}, {"text": "We classify problems associated with technical term translation as given below: (1) technical terms are often compound word~ which can be progressively created simply by combining multiple existing morphemes (\"base words\"), and therefore it is not entirely satisfactory to exhaustively enumerate newly emerging terms in dictionaries, (2) Asian languages often represent loanwords based on their special phonograms (primarily for technical terms and proper nouns), which creates new base words progressively (in the case of Japanese, the phonogram is called katakana).", "labels": [], "entities": [{"text": "technical term translation", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.6658495863278707}]}, {"text": "To counter problem (1), we use the compound word translation method we proposed), which selects appropriate translations based on the probability of occurrence of each combination of base words in the target language.", "labels": [], "entities": [{"text": "compound word translation", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6870072682698568}]}, {"text": "For problem (2), we use \"transliteration\". and proposed English-Chinese transliteration methods relying on the property of the Chinese phonetic system, which cannot be directly applied to transliteration between English and Japanese.", "labels": [], "entities": []}, {"text": "proposed a Japanese-English transliteration method based on the mapping probability between English and Japanese katakana sounds.", "labels": [], "entities": []}, {"text": "However, since their method needs large-scale phoneme inventories, we propose a simpler approach using surface mapping between English and katakana characters, rather than sounds.", "labels": [], "entities": []}, {"text": "Section 2 overviews our CLIR system, and Section 3 elaborates on the translation module focusing on compound word translation and transliteration.", "labels": [], "entities": [{"text": "compound word translation", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.647262175877889}]}, {"text": "Section 4 then evaluates the effectiveness of our CLIR system byway of the standardized IR evaluation method used in TREC programs.", "labels": [], "entities": [{"text": "IR evaluation", "start_pos": 88, "end_pos": 101, "type": "TASK", "confidence": 0.870736837387085}]}], "datasetContent": [{"text": "This section investigates the performance of our CLIR system based on the TREC-type evaluation methodology: the system outputs 1,000 top documents, and TREC evaluation software is used to calculate the recall-precision trade-off and ll-point average precision.", "labels": [], "entities": [{"text": "recall-precision", "start_pos": 202, "end_pos": 218, "type": "METRIC", "confidence": 0.9974684715270996}, {"text": "ll-point average precision", "start_pos": 233, "end_pos": 259, "type": "METRIC", "confidence": 0.8462811509768168}]}, {"text": "For the purpose of our evaluation, we used the NACSIS test collection ( . This collection consists of 21 Japanese queri~'s and approximately 330,000 documents (in el-ther a confl)ination of English and Japanese or either of the languages individually), collected fi'om technical papers published by 65 Japanese associations tbr various fields.", "labels": [], "entities": [{"text": "NACSIS test collection", "start_pos": 47, "end_pos": 69, "type": "DATASET", "confidence": 0.976799488067627}]}, {"text": "Each document consists of the document ID, title, name(s) of author(s), name/date of conference, hosting organization, abstract and keywords, from which titles, abstracts and keywords were used for our evaluation.", "labels": [], "entities": []}, {"text": "We used as target documents approximately 187,000 entries where abstracts are in both English and Japanese.", "labels": [], "entities": []}, {"text": "Each query consists of the title of the topic, description, narrative and list of synonyms, from which we used only the description.", "labels": [], "entities": []}, {"text": "Roughly speaking, most topics are related to electronic, information and control engineering.", "labels": [], "entities": [{"text": "information and control engineering", "start_pos": 57, "end_pos": 92, "type": "TASK", "confidence": 0.676718182861805}]}, {"text": "shows example descriptions (translated into English by one of the authors).", "labels": [], "entities": []}, {"text": "Relevance assessment was performed based on one of the three ranks of relevance, i.e., \"relevant\", \"partially relevant\" and \"irrelevant\".", "labels": [], "entities": [{"text": "Relevance assessment", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7298510074615479}]}, {"text": "In our evaluation, relevant documents refer to both \"relevant\" and \"partially relevant\" documents 5.", "labels": [], "entities": []}, {"text": "(3) randomly selected k translations derived from our bilingual dictionary are used (\"random\"), (4) k-best translations through compound word translation are used (\"C\\\u00a5T\").", "labels": [], "entities": []}, {"text": "For system \"EDR\", compound words unlisted in the EDR dictionary were manuMly segmented so that substrings (shorter compound words or base words) can be translated.", "labels": [], "entities": [{"text": "EDR dictionary", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.9395104646682739}]}, {"text": "For both systems \"random\" and \"CWT\", we arbitrarily set k = 3. and show the recallprecision curve and l 1-point average precision for each method, respectively.", "labels": [], "entities": [{"text": "recallprecision curve", "start_pos": 76, "end_pos": 97, "type": "METRIC", "confidence": 0.9812412858009338}, {"text": "l 1-point average precision", "start_pos": 102, "end_pos": 129, "type": "METRIC", "confidence": 0.5972753688693047}]}, {"text": "In these, \"J-J\" refers to the result obtained by the JapaneseJapanese IR system, which uses as documents Japanese titles/abstracts/keywords comparable to English fields in the NACSIS collection.", "labels": [], "entities": [{"text": "NACSIS collection", "start_pos": 176, "end_pos": 193, "type": "DATASET", "confidence": 0.9363795518875122}]}, {"text": "This can be seen as the upper bound for CLIR performance 6.", "labels": [], "entities": []}, {"text": "Looking at these results, we can conclude that the dictionary production and probabilistic translation methods we proposed are effective for CLIR.", "labels": [], "entities": [{"text": "dictionary production", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.8001904487609863}]}, {"text": "In the NACSIS collection, three queries contain katakana (base) words unlisted in our bilingual dictionary: Those words are \"ma-i-nin-gu (mining)\" and \"ko-ro-ke-i-sho-n (collocation)\".", "labels": [], "entities": [{"text": "NACSIS collection", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.947458952665329}]}, {"text": "However, to emphasize the effectiveness of transliteration, we compared the following extreme cases: (1) a control, in which every katakana word is discarded from queries (\"control\"), (2) a case where transliteration is applied to every katakana word and top 10 candidates are used (\"translit\").", "labels": [], "entities": []}, {"text": "Both cases use system \"CWT\" in Section 4.1.", "labels": [], "entities": []}, {"text": "In the case of \"translit\", we do not use katakana entries listed in the base word dictionary.", "labels": [], "entities": []}, {"text": "show the recall-precision curve and ll-point average precision for each case, respectively.", "labels": [], "entities": [{"text": "recall-precision curve", "start_pos": 9, "end_pos": 31, "type": "METRIC", "confidence": 0.983076810836792}, {"text": "ll-point average precision", "start_pos": 36, "end_pos": 62, "type": "METRIC", "confidence": 0.917236864566803}]}, {"text": "In these, results for \"CWT\" correspond to those in and, respectively.", "labels": [], "entities": []}, {"text": "We can conclude that our transliteration method significantly improves the baseline perfomlance (i.e., \"control\"), and comparable to word-based translation ill terms of CLIR performance.", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.6656968891620636}]}, {"text": "An interesting observation is that the use of transliteration is robust against typos in documents, because a number of similar strings are used as query terms.", "labels": [], "entities": []}, {"text": "For example, our transliteration method produced the following strings for \"ri-da-ku-sho-n (reduction)\": riduction, redction, redaction, reduction.", "labels": [], "entities": []}, {"text": "All of these words are effective for retrieval, because they are contained in the target documents.", "labels": [], "entities": []}, {"text": "We compared our system (\"CWT+translit\") with the Japanese-Japanese IR system, where (unlike the evaluation in Section 4.2) transliteration was applied only to \"ma-i-ni-n-gu (mining)\" and \"ko-ro-ke-i-sho-n (collocation)\".", "labels": [], "entities": []}, {"text": "show the recall-precision curve and l 1-point average precision for each system, respectively, from which one can see that our CLIR system is quite comparable with the monolingual IR system in performance.", "labels": [], "entities": [{"text": "recall-precision curve", "start_pos": 9, "end_pos": 31, "type": "METRIC", "confidence": 0.9764216542243958}, {"text": "l 1-point average precision", "start_pos": 36, "end_pos": 63, "type": "METRIC", "confidence": 0.7292284816503525}]}, {"text": "In addition, from to 7, one can see that the monolingual system generally performs better at lower re(:all while the CLIR system pertbrms b(,It(,r at higher recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9948717355728149}]}, {"text": "For further investigation, let us discuss similar (~xperim(mtal results reported by, where a bilingual dictionary produced ti'om Japanese/English keyword pairs in the NACSIS documents is used for query translation.", "labels": [], "entities": [{"text": "NACSIS documents", "start_pos": 167, "end_pos": 183, "type": "DATASET", "confidence": 0.9540871679782867}, {"text": "query translation", "start_pos": 196, "end_pos": 213, "type": "TASK", "confidence": 0.7894609570503235}]}, {"text": "Their evaluation method is almost the same as pertbrmed in our experinmnts.", "labels": [], "entities": []}, {"text": "One difference is that they use the \"OpenText\" search engine 7, and thus the performance tbr Jal)anese-Japanese IR is higher than obtained in out\" evaluation.", "labels": [], "entities": []}, {"text": "However, the performance of their Japanese-English CLIR systems, which is roughly 50-60% of that for their JapaneseJapanese IR system, is comparable with our CLIR system performance.", "labels": [], "entities": []}, {"text": "It is expected that using a more sophisticated search engine, our CLIR system will achieve a higher performance than that obtained by Kando and Aizawa.", "labels": [], "entities": []}, {"text": "In this paper, we proposed a Japanese/English cross-language information retrieval system, targeting technical documents.", "labels": [], "entities": [{"text": "Japanese/English cross-language information retrieval", "start_pos": 29, "end_pos": 82, "type": "TASK", "confidence": 0.4857233117024104}]}, {"text": "We combined a query translation module, which performs 7Devcloped by OpenText Corp.", "labels": [], "entities": [{"text": "query translation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7191351354122162}]}, {"text": "compound wor(1 translation and transliteration, with an existing monolingual retrieval method.", "labels": [], "entities": []}, {"text": "Our experimental results showed that compound word translation and transliteration methods individually improve on the baseline performance, and when used together the improvement is even greater.", "labels": [], "entities": [{"text": "compound word translation", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.6231918931007385}]}, {"text": "Future work will inelude the application of automatic word alignment methods to enhance the dictionary.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7115211486816406}]}], "tableCaptions": [{"text": " Table 2: Comparison of average precision for  evaluation of compound word translation", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.8902031779289246}, {"text": "compound word translation", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.6632715264956156}]}, {"text": " Table 3: Comparison of average precision for  evaluation of transliteration", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.8588310480117798}, {"text": "transliteration", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.5470038652420044}]}, {"text": " Table 4: Comparison of average precision tbr  evaluation of overall l)erfbrmance", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9428843259811401}]}]}