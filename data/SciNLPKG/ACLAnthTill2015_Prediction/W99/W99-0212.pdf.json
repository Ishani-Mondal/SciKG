{"title": [], "abstractContent": [{"text": "We present a system which retrieves answers to queries based on coreference relationships between entities and events in the query and documents.", "labels": [], "entities": []}, {"text": "An evaluation of this system is given which demonstrates that the the amount of information that the user must process on average , tQ find an answer to their query, is reduced by an order of magnitude.", "labels": [], "entities": []}], "introductionContent": [{"text": "Search engines have become ubiquitous as a means for accessing information.", "labels": [], "entities": []}, {"text": "When a ranking of documents is returned by a search engine the information retrieval task is usually not complete.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7605179846286774}]}, {"text": "The document, as a unit of information, is often too large for many users information needs and finding information within the set of returned documents poses a burden of its own.", "labels": [], "entities": []}, {"text": "Here we examine a technique for extracting sentences from documents which attempts to satisfy the users information needs by providing an answer to the query presented.", "labels": [], "entities": []}, {"text": "The system does this by modeling coreference relationships between entities and events in the query and documents.", "labels": [], "entities": []}, {"text": "An evaluation of this system is given which demonstrates that it performs better than using a standard tf. idf weighting and that the amount of information that the user must process on average, to find an answer to their query, is reduced by an order of magnitude over document ranking alone.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the evaluation of the system ten queries were selected from a collection of actual queries presented to an online search engine.", "labels": [], "entities": []}, {"text": "Queries were selected based on their expressing the users information need clearly, their being likely answered in a single sentence, and non-dubious intent.", "labels": [], "entities": []}, {"text": "The queries used in this evaluation are as follows: \u2022 Why has the dollar weakened against the yen?", "labels": [], "entities": []}, {"text": "\u2022 What was the first manned Apollo mission to circle the moon?", "labels": [], "entities": []}, {"text": "\u2022 What virus was spread in the U.S. in 1968?", "labels": [], "entities": []}, {"text": "\u2022 Where were the 1968 Summer Olympics held?", "labels": [], "entities": []}, {"text": "\u2022 Who wrote \"The Once and Future King\"?", "labels": [], "entities": []}, {"text": "\u2022 What did Mark McGwire say about child abuse?", "labels": [], "entities": [{"text": "McGwire say", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.8232407569885254}]}, {"text": "\u2022 What are the symptoms of Chronic Fatigue Syndrome?", "labels": [], "entities": [{"text": "Chronic Fatigue Syndrome", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.7108274102210999}]}, {"text": "\u2022 What kind of tanks does Israel have?", "labels": [], "entities": []}, {"text": "\u2022 What is the lifespan of a white tailed deer?", "labels": [], "entities": []}, {"text": "\u2022 Who was the first president of Turkey?", "labels": [], "entities": []}, {"text": "The information requested by the query was then searched for from a data source which was considered likely to contain the answer.", "labels": [], "entities": []}, {"text": "Sources for these experiments include Britannica Online, CNN, and the Web at large.", "labels": [], "entities": [{"text": "Britannica Online", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.9388814866542816}]}, {"text": "Once a promising set of documents were retrieved, the top ten were annotated for instances of the answer to the query.", "labels": [], "entities": []}, {"text": "The system was then asked to process the ten documents and present a ranked listing of sentences.", "labels": [], "entities": []}, {"text": "System performance is presented below as the top ranked sentence which contained an answer to the question.", "labels": [], "entities": []}, {"text": "A question mark is used to indicate that an answer did not appear in the top ten ranked sentences.", "labels": [], "entities": []}], "tableCaptions": []}