{"title": [], "abstractContent": [{"text": "We present a memory-based learning (MBL) approach to shallow parsing in which POS tagging, chunking, and identification of syntactic relations are formulated as memory-based modules.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.8141684234142303}, {"text": "identification of syntactic relations", "start_pos": 105, "end_pos": 142, "type": "TASK", "confidence": 0.8215008825063705}]}, {"text": "The experiments reported in this paper show competitive results, the F~=l for the Wall Street Journal (WSJ) treebank is: 93.8% for NP chunking, 94.7% for VP chunking, 77.1% for subject detection and 79.0% for object detection.", "labels": [], "entities": [{"text": "F~=l", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9688426454861959}, {"text": "Wall Street Journal (WSJ) treebank", "start_pos": 82, "end_pos": 116, "type": "DATASET", "confidence": 0.9494430507932391}, {"text": "NP chunking", "start_pos": 131, "end_pos": 142, "type": "TASK", "confidence": 0.7880488634109497}, {"text": "VP chunking", "start_pos": 154, "end_pos": 165, "type": "TASK", "confidence": 0.6892141997814178}, {"text": "subject detection", "start_pos": 177, "end_pos": 194, "type": "TASK", "confidence": 0.757720410823822}, {"text": "object detection", "start_pos": 209, "end_pos": 225, "type": "TASK", "confidence": 0.8131937086582184}]}], "introductionContent": [{"text": "Recently, there has been an increased interest in approaches to automatically learning to recognize shallow linguistic patterns in text.", "labels": [], "entities": []}, {"text": "Shallow parsing is an important component of most text analysis systems in applications such as information extraction and summary generation.", "labels": [], "entities": [{"text": "Shallow parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7655994594097137}, {"text": "text analysis", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.7503784000873566}, {"text": "information extraction", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.8462806940078735}, {"text": "summary generation", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8692483901977539}]}, {"text": "It includes discovering the main constituents of sentences (NPs, VPs, PPs) and their heads, and determining syntactic relationships like subject, object, adjunct relations between verbs and heads of other constituents.", "labels": [], "entities": []}, {"text": "Memory-Based Learning (MBL) shares with other statistical and learning techniques the advantages of avoiding the need for manual definition of patterns (common practice is to use hand-crafted regular expressions), and of being reusable for different corpora and sublanguages.", "labels": [], "entities": [{"text": "Memory-Based Learning (MBL)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6219287276268005}]}, {"text": "The unique property of memory-based approaches which sets them apart from other learning methods is the fact that they are lazy learners: they keep all training data available for extrapolation.", "labels": [], "entities": []}, {"text": "All other statistical and machine learning methods are eager (or greedy) learners: They abstract knowledge structures or probability distributions from the training data, forget the individual training instances, and extrapolate from the induced structures.", "labels": [], "entities": []}, {"text": "Lazy learning techniques have been shown to achieve higher accuracy than eager methods for many language processing tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9980300068855286}]}, {"text": "A reason for this is tile intricate interaction between regularities, subregularities and exceptions inmost language data. and the related problem for learners of distinguishing noise from exceptions.", "labels": [], "entities": []}, {"text": "Eager learning techniques abstract from what they consider noise (hapaxes, low-frequency events, non-typical events) whereas lazy learning techniques keep all data available, including exceptions which may sometimes be productive.", "labels": [], "entities": []}, {"text": "For a detailed analysis of this issue, see.", "labels": [], "entities": []}, {"text": "Moreover, the automatic feature weighting in the similarity metric of a memory-based learner makes the approach well-suited for domains with large numbers of features from heterogeneous sources, as it embodies a smoothing-by-similarity method when data is sparse.", "labels": [], "entities": []}, {"text": "In this paper, we will provide a empirical evaluation of tile MBL approach to syntactic analysis on a number of shallow pattern learning tasks: NP chunking, \\'P clmnking, and the assignment of subject-verb and object-verb relations.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.7957858443260193}, {"text": "NP chunking", "start_pos": 144, "end_pos": 155, "type": "TASK", "confidence": 0.7866982817649841}, {"text": "assignment of subject-verb and object-verb relations", "start_pos": 179, "end_pos": 231, "type": "TASK", "confidence": 0.8130413790543874}]}, {"text": "The approach is evaluated by cross-validation on the WSJ treebank corpus.", "labels": [], "entities": [{"text": "WSJ treebank corpus", "start_pos": 53, "end_pos": 72, "type": "DATASET", "confidence": 0.9914249579111735}]}, {"text": "We compare the approach qualitatively and as far as possible quantitatively with other approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out two series of experiments.", "labels": [], "entities": []}, {"text": "In the first we evaluated a memory-based NP and VP chunker, in the second we used this chunker for memory-based subject/object detection.", "labels": [], "entities": [{"text": "memory-based subject/object detection", "start_pos": 99, "end_pos": 136, "type": "TASK", "confidence": 0.6141943991184234}]}, {"text": "To evaluate the performance of our trained memorybased classifiers, we will use four measures: accuracy (the percentage of correctly predicted output classes), precision (the percentage of predicted chunks or subject-or object-verb pairs that is correct), recall (the percentage of chunks or subjector object-verb pairs to be predicted that is found), and F,~ [C.J.van, which is given by (~2+1) v,.ec rec with ;3 = 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9991322159767151}, {"text": "precision", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9993721842765808}, {"text": "recall", "start_pos": 256, "end_pos": 262, "type": "METRIC", "confidence": 0.9992932081222534}, {"text": "F", "start_pos": 356, "end_pos": 357, "type": "METRIC", "confidence": 0.9992960691452026}]}, {"text": "See below for an example.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overview of the NP/VP chunking scores of 25-fold cross-validation on the  of two words and POS right and one left, and of using IGTREE with the same  computed with IGTrtEE using only the focus POS tag or the focus word", "labels": [], "entities": [{"text": "NP/VP chunking", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.5114227309823036}, {"text": "IGTREE", "start_pos": 138, "end_pos": 144, "type": "DATASET", "confidence": 0.7449202537536621}, {"text": "IGTrtEE", "start_pos": 174, "end_pos": 181, "type": "DATASET", "confidence": 0.9062687158584595}]}, {"text": " Table 2: Some sample instances for the subject/object detection task. The second row shows the relative weight of  the features (truncated and multiplied by 100; from one of the 10 cross-validation experiments). Thus the order of  importance of the features is: 2, 1, 11, 9, 13, 10, 8, 12, 7, 6, 3, 4, 5.", "labels": [], "entities": [{"text": "object detection task", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7840858201185862}]}, {"text": " Table 3: Results of the 10-fold cross validation experiment on the subject-verb/object-verb relations data\u2022 We", "labels": [], "entities": []}, {"text": " Table 4: Comparison of MBL aad MBSL on  carried out with a context of five words and", "labels": [], "entities": [{"text": "MBL aad MBSL", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.5616326530774435}]}, {"text": " Table 5: Comparison of MBL and MBSL on subject/object detection as formulated by Argamon et al.", "labels": [], "entities": [{"text": "subject/object detection", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.6314216628670692}]}]}