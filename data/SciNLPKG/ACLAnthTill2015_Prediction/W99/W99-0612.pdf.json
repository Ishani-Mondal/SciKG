{"title": [{"text": "Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence", "labels": [], "entities": [{"text": "Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence", "start_pos": 0, "end_pos": 93, "type": "TASK", "confidence": 0.7284096539020538}]}], "abstractContent": [{"text": "Identifying and classifying personal, geographic, institutional or other names in a text is an important task for numerous applications.", "labels": [], "entities": [{"text": "Identifying and classifying personal, geographic, institutional or other names in a text", "start_pos": 0, "end_pos": 88, "type": "TASK", "confidence": 0.8189849938665118}]}, {"text": "This paper describes and evaluates a language-independent boot-strapping algorithm based on iterative learning and re-estimation of contextual and mOrphological patterns captured in hierarchically smoothed trie models.", "labels": [], "entities": []}, {"text": "The algorithm learns from unannotated text and achieves competitive performance when trained on a very short labelled name list with no other required language-specific information, tokenizers or tools.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ability to determine the named entities in a text has been established as an important task for several natural language processing areas, including information retrieval, machine translation, information extraction and language understanding.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 153, "end_pos": 174, "type": "TASK", "confidence": 0.7945812940597534}, {"text": "machine translation", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.78347247838974}, {"text": "information extraction", "start_pos": 197, "end_pos": 219, "type": "TASK", "confidence": 0.8459755480289459}, {"text": "language understanding", "start_pos": 224, "end_pos": 246, "type": "TASK", "confidence": 0.7308483421802521}]}, {"text": "For the 1995 Message Understanding Conference (MUC-6), a separate named entity recognition task was developed and the best systems achieved impressive accuracy (with an F-measure approaching 95%).", "labels": [], "entities": [{"text": "1995 Message Understanding Conference (MUC-6)", "start_pos": 8, "end_pos": 53, "type": "TASK", "confidence": 0.7241439138139997}, {"text": "entity recognition task", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.789293090502421}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.999226450920105}, {"text": "F-measure", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9990074038505554}]}, {"text": "What should be underlined here is that these systems were trained fora specific domain and a particular langnage (English), typically making use of hand-coded rules, taggers, parsers and semantic lexicons.", "labels": [], "entities": []}, {"text": "Indeed, most named entity recognizers that have been published either use tagged text, perform syntactical and morphological analysis or use semantic information for contextual clues.", "labels": [], "entities": []}, {"text": "Even the systems that do not make use of extensive knowledge about a particular language, such as Nominator (), still typically use large data files containing lists of names, exceptions, personal and organizational identifiers.", "labels": [], "entities": []}, {"text": "Our aim has been to build a maximally langnageindependent system for both named-entity identification and classification, using minimal information about the source language.", "labels": [], "entities": [{"text": "named-entity identification and classification", "start_pos": 74, "end_pos": 120, "type": "TASK", "confidence": 0.6513665467500687}]}, {"text": "The applicability of AI-style algorithms and supervised methods is limited in the multilingual case because of the cost of knowledge databases and manually annotated corpora.", "labels": [], "entities": []}, {"text": "Therefore, a much more suitable approach is to consider an EM-style bootstrapping algorithm.", "labels": [], "entities": []}, {"text": "In terms of world knowledge, the simplest and most relevant resource for this task is a database of known names.", "labels": [], "entities": []}, {"text": "For each entity class to be recognized and tagged, it is assumed that the user can provide a shortlist (order of one hundred) of unambiguous examples (seeds).", "labels": [], "entities": []}, {"text": "Of course the more examples provided, the better the results, but what we try to prove is that even with minimal knowledge good results can be achieved.", "labels": [], "entities": []}, {"text": "Additionally some basic particularities of the language should be known: capitalization (if it exists and is relevant -some languages do not make use of capitalization; in others, such as German, the capitalization is not of great help), allowable word separators (if they exist), and a few frequent exceptions (like the pronoun \"/\" in English).", "labels": [], "entities": []}, {"text": "Although such information can be utilised if present, it is not required, and no other assumptions are made in the general model.", "labels": [], "entities": []}], "datasetContent": [{"text": "The results shown in were obtained fora Romanian text having 12320 words, from which 438 were entities, using a training seed set of 300 names (115 first names, 125 last names, and 60 city/country names).", "labels": [], "entities": []}, {"text": "The baseline measures and default system (a) are as described above.", "labels": [], "entities": []}, {"text": "In configuration (b), the based parameters of the system have been optimized for Romanian, using greedy search on an independent development test (devtest) set, yielding a slight increase in F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.99638831615448}]}, {"text": "Configuration (c) used the default parameters, but the more conservative \"dominant\" criterion was utilized, clearly favoring precision at the expense of recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9990684390068054}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9987200498580933}]}, {"text": "Configuration (d), which is relevant for the ENAMEX task, represents the performance of the system when classes \"first name\" and \"last name\" are combined into \"person\" (whenever two or more such entities are adjacent, we consider the whole group as a \"person\" entity).", "labels": [], "entities": [{"text": "Configuration (d)", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.9307811558246613}]}, {"text": "Configuration (e) shows contrastive performance when using standard continuous EM smoothing on the same data and data structures.", "labels": [], "entities": []}, {"text": "source shows system performance for 5 fairly diverse languages: Romanian, English, Greek, Turkish and Hindi.", "labels": [], "entities": []}, {"text": "The initial 4 rows provide some basic details on the training data available for each language.", "labels": [], "entities": []}, {"text": "Note that when annotators were generating the lists of 150-300 seed words, they had access to a development test from which to extract samples, but they were not constrained to this text and could add additional ones from memory.", "labels": [], "entities": []}, {"text": "Furthermore, it was quite unpredictable how many contexts would actually be found fora given word in the development texts, as some appeared several times and many did not appear at all.", "labels": [], "entities": []}, {"text": "Thus the total number of contextual matches for the seed words was quite variable, from 113-249, and difficult to control.", "labels": [], "entities": []}, {"text": "It is also the case that not all additional contexts bring comparable new benefit, as many secondary instances of the same word in a given related document collection tend to have similar or identical surrounding contexts to the first instance (e.g. \"Mayor of XXX\" or \"XXX said\"), so in general it is quite difficult to control the actual training information content just by the number of raw seed word types that are annotated.", "labels": [], "entities": [{"text": "Mayor of XXX\"", "start_pos": 251, "end_pos": 264, "type": "DATASET", "confidence": 0.9055154919624329}]}, {"text": "For each of these languages, 5 levels of information sources are evaluated.", "labels": [], "entities": []}, {"text": "The baseline case is as previously described for.", "labels": [], "entities": []}, {"text": "The context-only case restricts system training to the two (left and right) contextual tries, ignoring the prefix/suffix morphological information.", "labels": [], "entities": []}, {"text": "The morphology only case, in contrast, restricts the system to only the two (prefix and suffix) morphological models.", "labels": [], "entities": []}, {"text": "These can be estimated from the 3 training wordlists (150-300 words total), but without an independent source of information (e.g. context) via which bootstrapping can iterate, there is no available path by which these  The second graph shows that F-measure performance also increases roughly logrithmically with the total length of the seed wordlists in the range 40-300.", "labels": [], "entities": []}, {"text": "This increase is due entirely to improved recall, which doubles over this small range.", "labels": [], "entities": [{"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9997844099998474}]}, {"text": "This trend sug2Note again that this baseline is more competitive than typical, as it not only assigns the majority tag (\"last name\"), but when there is an exact match with the training wordlist (e.g. \"deepak\"), a common occurrence given repeated highfrequency names in the Hindi data, the training classification is used as the baseline answer gests that there is considerable benefit to be gained by additional human annotation, or seed wordlist acquisition from existing online lexicons.", "labels": [], "entities": []}, {"text": "However, relative to case of raw text acquisition, such additional annotations tend to be much costlier, and there is a clear cost-benefit tradeoff to further investment in annotation.", "labels": [], "entities": [{"text": "raw text acquisition", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.7025877237319946}]}, {"text": "In summary, however, these evaluation results are satisfying in that they (a) show clear and consistent trends across several diverse languages, (b) show clear trends for improvement as training resources grow, and (c) show that comparable (and robust) classification results can be achieved on this diversity of languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Comparison of the performance of basic estimation methods on Romaninan", "labels": [], "entities": [{"text": "Romaninan", "start_pos": 71, "end_pos": 80, "type": "DATASET", "confidence": 0.9054591059684753}]}, {"text": " Table 4: Comparison of performance", "labels": [], "entities": []}]}