{"title": [{"text": "PP-Attachment: A Committee Machine Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we use various methods for multiple neural network combination in tasks of prepo-sitional phrase attachment.", "labels": [], "entities": [{"text": "prepo-sitional phrase attachment", "start_pos": 89, "end_pos": 121, "type": "TASK", "confidence": 0.5671952267487844}]}, {"text": "Experiments with aggregation functions such as unweighted and weighted average, OWA operator, Choquet integral and stacked generalization demonstrate that combining multiple networks improve the estimation of each individual neural network.", "labels": [], "entities": [{"text": "OWA operator", "start_pos": 80, "end_pos": 92, "type": "METRIC", "confidence": 0.9473166167736053}]}, {"text": "Using the Ratnaparkhi data set (the complete training set and the complete test set) we obtained an accuracy score of 86.08%.", "labels": [], "entities": [{"text": "Ratnaparkhi data set", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.9463107585906982}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.999764621257782}]}, {"text": "In spite of the high cost in computational time of neural net training, the response time in test mode is faster than others methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Structural ambiguity is one of the most serious problems that Natural Language Processing (NLP) systems face.", "labels": [], "entities": []}, {"text": "This ambiguity takes place because the syntactic information alone does not suffice to make an assignment decision.", "labels": [], "entities": []}, {"text": "Constructions such as Prepositional Phrase (PP), coordination, or relative clauses are affected.", "labels": [], "entities": [{"text": "Prepositional Phrase (PP)", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7021040380001068}]}, {"text": "An exhaustive study about the information needed to deal with this particular structural ambiguity has not been carried out as of yet; nevertheless, in the current literature we can find several proposals.", "labels": [], "entities": []}, {"text": "\u2022 In certain cases, it seems that the information needed to solve the attachment comes from the general context.", "labels": [], "entities": []}, {"text": "(1.a) John has a telescope.", "labels": [], "entities": []}, {"text": "(1.b) He saw the girl with the telescope.", "labels": [], "entities": []}, {"text": "In this particular case, a correct attachment would require a model representing the situation in which the different entities are involved.", "labels": [], "entities": []}, {"text": "If this were true for all of the cases, determining PP assignment would require highly complex computation.", "labels": [], "entities": [{"text": "PP assignment", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.8471314013004303}]}, {"text": "\u2022 In some other cases, the information determining the PP attachment seems to be local.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.866235613822937}]}, {"text": "Some works,, suggested several strategies that based their decision-making on the relationships existing between predicates and argumentswhat called selectional restrictions.", "labels": [], "entities": []}, {"text": "Cases belonging to this group seem to be easier to handle computationally than the former ones.", "labels": [], "entities": []}, {"text": "Regarding these different cases we can speak of two kinds of disambiguation mechanisms.", "labels": [], "entities": []}, {"text": "One that can be called a low level mechanism which uses mainly information regarding selectional restrictions between predicates and arguments.", "labels": [], "entities": []}, {"text": "This mechanism uses a local context in order to solve syntactic disambiguation: that which is constituted by the predicate and its arguments.", "labels": [], "entities": []}, {"text": "The second mechanism uses higher level information such as situation models.", "labels": [], "entities": []}, {"text": "If the low level mechanism does not solve the ambiguity, the high level mechanism, which would be activated later, should be able to do it.", "labels": [], "entities": []}, {"text": "There are empirical data that seem to support the fact that human beings use these two mechanisms both for word sense disambiguation and syntactic disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.6997585197289785}, {"text": "syntactic disambiguation", "start_pos": 137, "end_pos": 161, "type": "TASK", "confidence": 0.7398737668991089}]}, {"text": "For a review see].", "labels": [], "entities": []}], "datasetContent": [{"text": "In this problem we had a high level of noise: on one hand the inadequate senses of each word in the 4-tuple.", "labels": [], "entities": []}, {"text": "Words in English have a high number of senses thus, in the input, the level of noise (inadequate sense) can reach 5 times that of signal (correct sense).", "labels": [], "entities": []}, {"text": "In addition, the Ratnaparkhi data set contains many errors, some of them due to errors originating from the Penn Treebank I. This level of noise deteriorates the generalizing capacity of the neural network.", "labels": [], "entities": [{"text": "Ratnaparkhi data set", "start_pos": 17, "end_pos": 37, "type": "DATASET", "confidence": 0.9670117298762003}, {"text": "Penn Treebank I.", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9891862869262695}]}, {"text": "There are many methods that permit a neural network to improve its capacity of generalization.", "labels": [], "entities": []}, {"text": "For reasons of complexity, the size of the network that we are using places restrictions on the selection of the method.", "labels": [], "entities": []}, {"text": "Of the methods that we are testing, committee machines allow us to improve results the most easily.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test and accuracy results", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9957242012023926}]}, {"text": " Table 2: Results obtained with Backed-Off, 0,  50 and 100 hidden units and time in seconds to  disambiguate 3,097 4-tuples.", "labels": [], "entities": []}, {"text": " Table 3: Results Committee machines. 50 hidden  layers", "labels": [], "entities": []}, {"text": " Table 4: Results Committee machines. 100 hidden  layers", "labels": [], "entities": []}, {"text": " Table 5: Results Committee machines in 60th  epoch. 100 hidden layers", "labels": [], "entities": []}, {"text": " Table 7: Results Choquet integral.", "labels": [], "entities": []}]}