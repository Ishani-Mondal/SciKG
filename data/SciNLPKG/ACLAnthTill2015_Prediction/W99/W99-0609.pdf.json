{"title": [{"text": "Determining the specificity of nouns from text", "labels": [], "entities": [{"text": "Determining the specificity of nouns", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7645106613636017}]}], "abstractContent": [{"text": "In this work, we use a large text corpus to order nouns by their level of specificity.", "labels": [], "entities": []}, {"text": "This semantic information can for most nouns be determined with over 80% accuracy using simple statistics from a text corpus without using any additional sources of semantic knowledge.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9979985356330872}]}, {"text": "This kind of semantic information can be used to help in automatically constructing or augmenting a lexical database such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 125, "end_pos": 132, "type": "DATASET", "confidence": 0.9435975551605225}]}], "introductionContent": [{"text": "Large lexical databases such as) are in common research use.", "labels": [], "entities": []}, {"text": "However, there are circumstances, particularly involving domainspecific text, where WordNet does not have sufficient coverage.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.9385401606559753}]}, {"text": "Various automatic methods have been proposed to automatically build lexical resources or augment existing resources.", "labels": [], "entities": []}, {"text": "(See, e.g.,,,, and.)", "labels": [], "entities": []}, {"text": "In this paper, we describe a method which can be used to assist in this problem.", "labels": [], "entities": []}, {"text": "We present here away to determine the relative specificity of nouns; that is, which nouns are more specific (or more general) than others, using only a large text corpus and no additional sources of semantic knowledge.", "labels": [], "entities": []}, {"text": "By gathering simple statistics, we are able to decide which of two nouns is more specific to over 80% accuracy for nouns at \"basic level\" or below (see, e.g.,), and about 59% accuracy for nouns above basic level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9979528188705444}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9987152814865112}]}, {"text": "It should be noted that specificity by itself is not enough information from which to construct a noun hierarchy.", "labels": [], "entities": []}, {"text": "This project is meant to provide a tool to support other methods.", "labels": [], "entities": []}, {"text": "See Caraballo (1999) fora detailed description of a method to construct such a hierarchy.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of these measures, we used the hypernym data in WordNet (1998) as our gold standard.", "labels": [], "entities": [{"text": "hypernym data in WordNet (1998)", "start_pos": 59, "end_pos": 90, "type": "DATASET", "confidence": 0.8135842595781598}]}, {"text": "(A word X is considered a hypernym of a word Y if native speakers accept the sentence \"Y is a (kind of) X.\")'We constructed three small hierarchies of nouns and looked at how often our measures found the proper relationships between the hypernym/hyponym pairs in these hierarchies.", "labels": [], "entities": []}, {"text": "To select the words for our three hierarchies, we wanted to use sets of words for which there would be enough information in the Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 129, "end_pos": 155, "type": "DATASET", "confidence": 0.9758067727088928}]}, {"text": "We chose three clusters produced by a program similar to except that it is based on a generative probability model and tries to classify all nouns rather than just those in pre-selected clusters.", "labels": [], "entities": []}, {"text": "(All data sets are given in the Appendix.)", "labels": [], "entities": [{"text": "Appendix", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.6236205697059631}]}, {"text": "The clusters we selected represented vehicles (car, truck, boat, ...), food (bread, pizza, wine, ...), and occupations (journalist, engineer, biochemist, ...).", "labels": [], "entities": []}, {"text": "From the clustered data we removed proper nouns and words that were not really in our target categories.", "labels": [], "entities": []}, {"text": "We then looked up the remaining words in WordNet, and added their single-word hypernyms to the categories in the correct hierarchical structure.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9734337329864502}]}, {"text": "(Many WordNet categories are described by multiple words, e.g., \"motorized vehicle\", and these were omitted for obvious reasons.)", "labels": [], "entities": []}, {"text": "For each of these three hierarchies, we looked at each hypernym/hyponym pair within the hierarchy and determined whether each specificity measure placed the words in the proper order.", "labels": [], "entities": []}, {"text": "The percentage each specificity measure placed correctly are presented in.", "labels": [], "entities": []}, {"text": "Clearly the better measures are performing much better than a random-guess algorithm which would give 50% performance.", "labels": [], "entities": []}, {"text": "Among In these evaluations, it became clear that a single bad node high in the hierarchy could have a large effect on the results.", "labels": [], "entities": []}, {"text": "For example, in the \"occupations\" hierarchy, the root node is \"person,\" however, this is not a very frequent word in the Wall Street Journal corpus and rates as fairly specific across all of our measures.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 121, "end_pos": 147, "type": "DATASET", "confidence": 0.9675101488828659}]}, {"text": "Since this node has eight children, a single bad value at this node can cause eight errors.", "labels": [], "entities": []}, {"text": "We therefore considered another evaluation measure: for each internal node in the tree, we evaluated whether each specificity measure rated this word as more general than all of its descendants.", "labels": [], "entities": []}, {"text": "(This is somewhat akin to the idea of edit distance. If we sufficiently increased the generality measure for each node marked incorrect in this system, the hierarchy would match WordNet's exactly.)", "labels": [], "entities": [{"text": "WordNet", "start_pos": 178, "end_pos": 185, "type": "DATASET", "confidence": 0.9465623497962952}]}, {"text": "The results for this evaluation are presented in.", "labels": [], "entities": []}, {"text": "Although this is a harsher measure, it isolates the effect of individual difficult internal nodes.", "labels": [], "entities": []}, {"text": "Although the numbers are lower in  correct relationship to all of their descen-2, the same measures as in relatively well.", "labels": [], "entities": []}, {"text": "However, here Hmod has the best performance both on average and on two of three data sets, while the freq measure does a bit less well, now performing at about the level of Hi0 rather than Hs0.", "labels": [], "entities": [{"text": "freq measure", "start_pos": 101, "end_pos": 113, "type": "METRIC", "confidence": 0.959748387336731}]}, {"text": "The fact that some of the numbers in are below 50% should not be alarming, as the average number of descendants of an internal node is over 5, implying that random chance would give performance well below the 50% level on this measure.", "labels": [], "entities": []}, {"text": "Some of these results are negatively affected by word-sense problems.", "labels": [], "entities": []}, {"text": "Some of the words added from the WordNet data are much more common in the Wall Street Journal data fora different word sense than the one we are trying to evaluate.", "labels": [], "entities": [{"text": "WordNet data", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.9821709096431732}, {"text": "Wall Street Journal data", "start_pos": 74, "end_pos": 98, "type": "DATASET", "confidence": 0.9774678945541382}]}, {"text": "For example, the word \"performer\" is in the occupations hierarchy, but in the Wall Street Journal this word generally refers to stocks or funds (as \"good performers\", for example) rather than to people.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 78, "end_pos": 97, "type": "DATASET", "confidence": 0.9483115871747335}]}, {"text": "Since it was our goal not to use any outside sources of semantic knowledge these words were included in the evaluations.", "labels": [], "entities": []}, {"text": "However, if we eliminate those words, the results are as shown in.", "labels": [], "entities": []}, {"text": "It is possible that using some kind of automatic word:sense disambiguation while gathering the statistics would help reduce this problem.", "labels": [], "entities": []}, {"text": "This is also an area for future work.", "labels": [], "entities": []}, {"text": "However, it should be noted that on the evaluation measures in, as in the first two tables, the best results are obtained with Hmod, Hso and freq.", "labels": [], "entities": [{"text": "freq", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9842797517776489}]}, {"text": "The above results are primarily for nouns at \"basic level\" and below, which includes the vast majority of nouns.", "labels": [], "entities": []}, {"text": "We also considered a data set at basic level and above, with \"entity\" at its root.: Percentage of internal nodes with the correct relationship to all descendants when words with the wrong predominant sense are removed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Percentage of parent-child relationships which  sure.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.963230311870575}]}, {"text": " Table 2: Percentage of internal nodes  dants.", "labels": [], "entities": []}, {"text": " Table 3:  dominant sense are removed.", "labels": [], "entities": []}, {"text": " Table 4: Percentage of internal nodes with the correct relationship to all descendants when  words with the wrong predominant sense are removed.", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of the various specificity measures on a test set of more general nouns.", "labels": [], "entities": []}]}