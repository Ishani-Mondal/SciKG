{"title": [{"text": "The Structure of Shared Forests in Ambiguous Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "The Context-Free backbone of some natural language ana-lyzers produces all possible CF parses as some kind of shared forest, from which a singletree is to be chosen by a disam-biguation process that maybe based on the finer features of the language.", "labels": [], "entities": []}, {"text": "We study the structure of these forests with respect to optimality of sharing, and in relation with the parsing schema used to produce them.", "labels": [], "entities": []}, {"text": "In addition to a theoretical and experimental framework for studying these issues, the main results presented are:-sophistication in chart parsing schemata (e.g. use of look-ahead) may reduce time and space efficiency instead of improving it,-there is a shared forest structure with at most cubic size for any CF grammar,-when O(n 3) complexity is required, the shape of a shared forest is dependent on the parsing schema used.", "labels": [], "entities": [{"text": "chart parsing schemata", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.8162482579549154}]}, {"text": "Though analyzed on CF grammars for simplicity, these results extend to more complex formalisms such as unification based grammars.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several natural language parser start with & pure Conte~zt.", "labels": [], "entities": []}, {"text": "Free (CF) backbone that makes a first sketch of the structure of the analyzed sentence, before it is handed to a more elaborate analyzer (possibly a coroutine), that takes into account the finer grammatical structure to filter out undesirable parses (see for example).", "labels": [], "entities": []}, {"text": "In, Shieber surveys existing variants to this approach before giving his own tunable approach based on restrictions that ~ split up the infinite nonterminal domain into a finite set of equivalence classes that can be used for parsing\".", "labels": [], "entities": []}, {"text": "The basic motivation for this approach is to benefit from the CF parsing technology whose development over 30 years has lead to powerful and ei~cient parsers.", "labels": [], "entities": [{"text": "CF parsing", "start_pos": 62, "end_pos": 72, "type": "TASK", "confidence": 0.6517172008752823}]}, {"text": "A parser that takes into account only an approximation of the grammatical features will often find ambiguities it cannot resolve in the analyzed sentences I.", "labels": [], "entities": []}, {"text": "A natural solution *Address: INRIA, B.P. 105, 78153 Le Chesn~y, France.", "labels": [], "entities": [{"text": "INRIA", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.928825318813324}, {"text": "B.P. 105, 78153 Le Chesn~y", "start_pos": 36, "end_pos": 62, "type": "DATASET", "confidence": 0.8072248175740242}]}, {"text": "The work reported here was partially supported by the Eureka Software Factory project.", "labels": [], "entities": [{"text": "Eureka Software Factory project", "start_pos": 54, "end_pos": 85, "type": "DATASET", "confidence": 0.9409062266349792}]}, {"text": "1 Ambiguity may also have a semantical origin.\" is then to produce all possible parses, according to the CF backbone, and then select among them on the basis of the complete features information.", "labels": [], "entities": [{"text": "CF backbone", "start_pos": 105, "end_pos": 116, "type": "DATASET", "confidence": 0.8708160817623138}]}, {"text": "One hitch is that the number of parses maybe exponential in the size of the input sentence, or even infuite for cyclic grammars or incomplete sentences.", "labels": [], "entities": []}, {"text": "However chart parsing techniques have been developed that produce an encoding of all possible parses as a data structure with a size polynomial in the length of the input sentence.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.7385077178478241}]}, {"text": "These techniques are all based on a dynamic programming paradigm.", "labels": [], "entities": []}, {"text": "The kind of structure they produce to represent all parses of the analyzed sentence is an essential characteristic of these algorithm.", "labels": [], "entities": []}, {"text": "Some of the published algorithms produce only a chart as described by Kay in, which only associates nonterminal categories to segments of the analyzed sentence, and which thus still requires non-trivial proceasing to extract parse-trees.", "labels": [], "entities": []}, {"text": "The worst size complexity of such a chart is only a square function of the size of the input 2.", "labels": [], "entities": []}, {"text": "However, practical parsing algorithms will often produce a more complex structure that explicitly relates the instances of nonterminals associated with sentence fragments to their constituents, possibly in several ways in case of ambiguity, with a sharing of some common subtrees between the distinct ambiguous parses ~ One advantage of this structure is that the chart retains only these constituents that can actually participate in a parse.", "labels": [], "entities": []}, {"text": "Furthermore it makes the extraction of parse-trees a trivial matter.", "labels": [], "entities": []}, {"text": "A drawback is that this structure maybe cubic in the length of the parsed sentence, and more generally polynomial' for some proposed algorithms.", "labels": [], "entities": []}, {"text": "However, these algorithms are rather well behaved in practice, and this complexity is not a problem.", "labels": [], "entities": []}, {"text": "In this paper we shall call shared forests such data struc-2 We do not consider CF reco~zers that have asymptotically the lowest complexity, but are only of theoretical interest here.", "labels": [], "entities": []}, {"text": "3 There are several other published implementation of chart parsers, hut they often do not give much detail on the output of the parsing process, or even side-step the problem ~1. together.", "labels": [], "entities": []}, {"text": "We do not consider here the well .formed s~bs~ring fablea of Shell which falls somewhere in between in our classificgtlon.", "labels": [], "entities": [{"text": "Shell", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.9374591112136841}]}, {"text": "They do not use pointers and parse-trees are only \"indirectly\" visible, but maybe extracted rather simply in linear time.", "labels": [], "entities": []}, {"text": "\u2022 The table may contain useless constituents.", "labels": [], "entities": []}, {"text": "4 Space cubic algorithms often require the lan~tage grammar to be in Chomsky Normal Form, and some authors have incorrectly conjectured tha~ cubic complexity cannot he obtained otherwise.", "labels": [], "entities": []}, {"text": "tures used to represent simultaneously all parse trees fora given sentence.", "labels": [], "entities": []}, {"text": "Several question\u2022 maybe asked in relation with shared forests: \u2022 How to construct them during the parsing process?", "labels": [], "entities": [{"text": "parsing process", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.9053052067756653}]}, {"text": "\u2022 Can the cubic complexity be attained without modifying the grammar (e.g. into Chomsky Normal Form)?", "labels": [], "entities": []}, {"text": "s What is the appropriate data structure to improve sharing and reduce time and space complexity?", "labels": [], "entities": []}, {"text": "\u2022 How good is the sharing of tree fragments between ambiguous parses, and how can it be improved?", "labels": [], "entities": [{"text": "sharing of tree fragments between ambiguous parses", "start_pos": 18, "end_pos": 68, "type": "TASK", "confidence": 0.7331620369638715}]}, {"text": "\u2022 Is there a relation between the coding of parse-trees in the shared forest and the parsing schema used?", "labels": [], "entities": []}, {"text": "\u2022 How well formalized is their definition snd construction?", "labels": [], "entities": []}, {"text": "These questions are of importance in practical systems because the answers impact both the performance and the implementation techniques.", "labels": [], "entities": []}, {"text": "For example good sharing may allow a better factorization of the computation that filters parse trees with the secondary features of the language.", "labels": [], "entities": []}, {"text": "The representation needed for good sharing or low space complexity maybe incompatible with the needs of other components of the system.", "labels": [], "entities": []}, {"text": "These components may also make assumptions about this representation that are incompatible with some parsing schemata.", "labels": [], "entities": []}, {"text": "The issue of formalization is of course related to the formal tractability of correctness proof for algorithms using shared forests.", "labels": [], "entities": []}, {"text": "In section 2 we describe a uniform theoretical framework in which various parsing strategies are expressed and compared with respect to the above questions.", "labels": [], "entities": []}, {"text": "This approach has been implemented into a system intended for the experimental study and comparison of parsing strategies.", "labels": [], "entities": [{"text": "comparison of parsing", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.6342146794001261}]}, {"text": "This system is described in section 3.", "labels": [], "entities": []}, {"text": "Section 4 contain~ a detailed example produced with our implementation which illustrates both the working of the system and the underlying theory.", "labels": [], "entities": []}], "datasetContent": [{"text": "The ideas presented above have been implemented in an experimental system called Tin (after the woodman of OZ).", "labels": [], "entities": [{"text": "Tin (after the woodman of OZ", "start_pos": 81, "end_pos": 109, "type": "DATASET", "confidence": 0.7106590058122363}]}, {"text": "The intent is to provide a uniform f~amework for the construction and experimentation of chart parsers, somewhat as systems like MCHART, but with a more systematic theoretical foundation.", "labels": [], "entities": []}, {"text": "The kernel of the system is a virtual parsing machine with a stack and a set of primitive commands corresponding essentially to the operation of a practical Push-Down Transducer.", "labels": [], "entities": []}, {"text": "These commands include for example: push (resp. pop) to push a symbol on the stack (reap.", "labels": [], "entities": []}, {"text": "pop one), check~indow to compare the look-ahead symbol(s) to some given symbol, chsckstack to branch depending on the top of the sta~k, scan to read an input word, outpu$ to output a rule number (or a terminal symbol), goto for unconditional jumps, and a few others.", "labels": [], "entities": []}, {"text": "However theae commands are never used directly to program parsers.", "labels": [], "entities": []}, {"text": "They are used as machine instructions for compilers that compile grammatical definitions into Tin code according to some parsing schema.", "labels": [], "entities": []}, {"text": "A characteristic of these commands is that they may all be marked as non-determlnistic.", "labels": [], "entities": []}, {"text": "The intuitive interpretation is that there is a non-deterministic choice between a command thus marked and another command whose address in the virtual machine code is then specified.", "labels": [], "entities": []}, {"text": "However execution of the virtual machine code is done by an all-paths interpreter that follows the dynamic programming strategy described in section 2.1 and appendix A.", "labels": [], "entities": []}, {"text": "The Tin interpreter is used in two different ways: 1.", "labels": [], "entities": [{"text": "Tin interpreter", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8894748687744141}]}, {"text": "to study the effectiveness for chart parsing of known parsing schemata designed for deterministic parsing.", "labels": [], "entities": [{"text": "chart parsing of known parsing schemata", "start_pos": 31, "end_pos": 70, "type": "TASK", "confidence": 0.7037795881430308}, {"text": "deterministic parsing", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.648658812046051}]}, {"text": "We have only considered formally defined parsing schemata, corresponding to established PDA construction techniques that we use to mechanically translate CF grammars into Tin code.", "labels": [], "entities": [{"text": "PDA construction", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7731373310089111}]}, {"text": "(e.g. LALR(1) and LALR(2), weak precedence, LL(0) top-down (recursive descent), LR(0), LR(1) ...).", "labels": [], "entities": []}, {"text": "2. to study the computational behavior of the generated code, and the optimization techniques that could be used on the Tin code --and more generally chart parser code --with respect to code size, execution speed and better sharing in the parse forest.", "labels": [], "entities": []}, {"text": "Experimenting with several compilation schemata has shown that sophistication may have a negative effect on the ej~iciency of all-path parsin911 . Sophisticated PDT construction techniques tend to multiply the number of special cases, thereby increasing the code size of the chart parser.", "labels": [], "entities": [{"text": "PDT construction", "start_pos": 161, "end_pos": 177, "type": "TASK", "confidence": 0.9005759358406067}]}, {"text": "Sometimes it also prevents sharing of locally identical subcomputations because of differences in context analysis.", "labels": [], "entities": []}, {"text": "This in turn may result in lesser sharing in the parse forest and sometimes longer computation, as in example $BBL in appendix C, but of course it does not change the set of parsetrees encoded in the forest 12.", "labels": [], "entities": [{"text": "BBL", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9726395010948181}]}, {"text": "Experimentally, weak precedence gives slightly better sharing than LALR(1) parsing.", "labels": [], "entities": [{"text": "LALR(1) parsing", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.5417802333831787}]}, {"text": "The latter is often v/ewed as more efficient, whereas it only has a larger deterministic domain.", "labels": [], "entities": []}, {"text": "One essential guideline to achieve better sharing (and often also reduced computation time) is to try to recognize every grammar rule in only one place of the generated chart parser code, even at the cost of increasing non-determinism.", "labels": [], "entities": []}, {"text": "Thus simpler schemata such as precedence, LL(0) (and probably LR(0) I~) produce the best sharing.", "labels": [], "entities": []}, {"text": "However, since they correspond to a smaller deterministic domain within the CF grammar realm, they may sometimes be computationally less efficient because they produce a larger number of useless items (Le. edges) that correspond to dead-end computational paths.", "labels": [], "entities": []}, {"text": "Slight sophistication (e.g. LALR(1) used by Tomita in, or LR(1) ) may slightly improve computational performance by detecting earlier dead-end computations.", "labels": [], "entities": []}, {"text": "This may however beat the expense of the forest sharing quality.", "labels": [], "entities": []}, {"text": "More sophistication (say LR(2)) is usually losing on both accounts as explained earlier.", "labels": [], "entities": [{"text": "LR", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9278870224952698}]}, {"text": "The duplication of computational pgths due to distinct context analysis overweights the 11 We mean here the sophistication of the CF parser construction technique rather than the sophistication of the language features chopin to be used by this parser.", "labels": [], "entities": [{"text": "CF parser construction", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.6430645287036896}]}, {"text": "l~ This negative behavior of some techniques originally intended to preserve determlni~n had beam remarked and analyzed in a special case by Bouckaert, Pirotte and Shelling.", "labels": [], "entities": []}, {"text": "However we believe their result to be weaker than ours, since it seems to rely on the fact that they directly interpret ~'anuuars rather than first compile them.", "labels": [], "entities": []}, {"text": "Hence each interpretive step include in some sense compilation steps, which are more expensive when look-ahead is increased.", "labels": [], "entities": []}, {"text": "Their paper presents several examples that run less efficiently when look-ahead is increased.", "labels": [], "entities": []}, {"text": "For all these examples, this behavior disappears in our compiled setting.", "labels": [], "entities": []}, {"text": "However the grammar SBBL in appendix C shows a loss of eltlciency with increased look-ahead that is due exclusively to loss of sharing caused by irrelevant contextual distinctions.", "labels": [], "entities": []}, {"text": "This effect is particularly visible when parsing incomplete sentences.", "labels": [], "entities": [{"text": "parsing incomplete sentences", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.8834547400474548}]}, {"text": "Eiticiency loss with increased look-ahead is mainly due to state splitting.", "labels": [], "entities": []}, {"text": "This should favor LALR techniques ova-LR ones. is Our resnlts do not take into account a newly found optimization of PDT interpretation that applies to all and only to bottomup PDTs.", "labels": [], "entities": [{"text": "PDT interpretation", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.8722007870674133}]}, {"text": "This should make simple bottom-up schemes competitive for sharing quality, and even increase their computational ei~ciency.", "labels": [], "entities": []}, {"text": "However it should not change qualitatively the relative performances of bottom-up parsers, and n~y emphasize even more the phenomenon that reduces efficiency when look-ahead in-benefits of early elimination of dead-end paths.", "labels": [], "entities": []}, {"text": "But there can be no absolute rule: ff a grammar is aclose\" to the LR(2) domain, an LR(2) schema is likely to give the best result for most parsed sentences.", "labels": [], "entities": []}, {"text": "Sophisticated schemata correspond also to larger parsers, which maybe critical in some natural language applications with very large grammars.", "labels": [], "entities": []}, {"text": "The choice of a parsing schema depends in fine on the grammar used, on the corpus (or kind) of sentences to be analyzed, and on a balance between computational and sharing efficiency.", "labels": [], "entities": []}, {"text": "It is best decided on an experimental basis with a system such as ours.", "labels": [], "entities": []}, {"text": "Furthermore, we do not believe that any firm conclusion limited to CF grammars would be of real practical usefulness.", "labels": [], "entities": []}, {"text": "The real purpose of the work presented is to get a qualitative insight in phenomena which are best exhibited in the simpler framework of CF parsing.", "labels": [], "entities": [{"text": "CF parsing", "start_pos": 137, "end_pos": 147, "type": "TASK", "confidence": 0.8270204365253448}]}, {"text": "This insight should help us with more complex formalisms (cf. section 5) for which the phenomena might be less easily evidenced.", "labels": [], "entities": []}, {"text": "Note that the evidence gained contradicts the common belid that parsing schemata with a large deterministic domain (see for example the remarks on LR parsing in) are more effective than simpler ones.", "labels": [], "entities": [{"text": "LR parsing", "start_pos": 147, "end_pos": 157, "type": "TASK", "confidence": 0.7149556577205658}]}, {"text": "Most experiments in this area were based on incomparable implementations, while our uniform framework gives us a common theoretical yardstick.", "labels": [], "entities": []}, {"text": "This appc~dlx gives some of the experimental data gathered to c~npa~ compilation achemata~ For each grammar, the first table gives the size of the PDTs oht~dned by compiling it accordlnZ to several compilation schematL This size corresponds to the number of instructions genca'ated for the PDT, which is roughly the n,mher of possible PDT states.", "labels": [], "entities": [{"text": "accordlnZ", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.8998647928237915}]}, {"text": "The second table gives two figures far each schema and for sevm-al input sentences.", "labels": [], "entities": []}, {"text": "The first figure is the number of items computed to parse that sentence with the given schema: it maybe read as the number of computation steps and is thus \u2022 measure of computational ei~ciency.", "labels": [], "entities": []}, {"text": "The second figure is the n,,ml~er of items r~n~in;ng after simp/ification of the output grarnm~, it is thus an indicator of shsx~g quality.", "labels": [], "entities": []}, {"text": "Sharing is better when this second figure is low.", "labels": [], "entities": [{"text": "Sharing", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9237024784088135}]}, {"text": "In these tables, columns beaded with LR/LALR stands for the LR(0), LR(1), LALR(1) and LALR(2) cases (which often give the same results), unlesa one of these cases has its own expl;clt column.", "labels": [], "entities": []}, {"text": "Tests were run on the GRE, NSE, UBDA and RR gramman of: they did not exhibit the loss of eRiciency with incre~md look-ahead that was reported for the bottom-up look-ahead of.", "labels": [], "entities": [{"text": "GRE", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.7344092130661011}, {"text": "NSE", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.9029938578605652}, {"text": "UBDA", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.8548839092254639}, {"text": "RR gramman", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.7992429435253143}, {"text": "eRiciency", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9802126884460449}]}, {"text": "We believe the results presented here axe consistent and give an accurate comparison of performances of the parsers considered, despite some implementation departure from the strict theoretical model required by performance considerations.", "labels": [], "entities": []}, {"text": "A tint version of our LL compiler &,ave results that were inconsistent with the results of the bottom-up parsers.", "labels": [], "entities": []}, {"text": "This was ,, due to & weakness in that LL(0) compiler which was then corrected.", "labels": [], "entities": [{"text": "LL(0) compiler", "start_pos": 38, "end_pos": 52, "type": "DATASET", "confidence": 0.8800401091575623}]}, {"text": "We consider this experience to be a conflrm~ion of the nsefuln~ of our uniform framework.", "labels": [], "entities": []}, {"text": "It must be stressed that these ~re prellmi~L~-y experiments.", "labels": [], "entities": []}, {"text": "On the basis of thdr.", "labels": [], "entities": []}, {"text": "~,dysis, we intend anew set of experiments that will better exhibit the phenomena discussed in the paper.", "labels": [], "entities": [{"text": "dysis", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.8687994480133057}]}, {"text": "In particular we wish to study variants of the schen~ta and dynamic progr~nming interpretation that give the best p,~dble sharing.", "labels": [], "entities": []}], "tableCaptions": []}