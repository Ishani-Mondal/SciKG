{"title": [{"text": "SOME CHART-BASED TECHNIQUES FOR PARSING ILL-FORMED INPUT", "labels": [], "entities": [{"text": "SOME CHART-BASED TECHNIQUES FOR PARSING ILL-FORMED INPUT", "start_pos": 0, "end_pos": 56, "type": "METRIC", "confidence": 0.5942402737481254}]}], "abstractContent": [{"text": "We argue for the usefulness of an active chart as the basis of a system that searches for the globally most plausible explanation of failure to syntactically parse a given input.", "labels": [], "entities": []}, {"text": "We suggest semantics-free, grammar-independent techniques for parsing inputs displaying simple kinds of ill-formedness and discuss the search issues involved.", "labels": [], "entities": []}, {"text": "THE PROBLEM Although the ultimate solution to the problem of processing ill-formed input must take into account semantic and pragmatic factors, nevertheless it is important to understand the limits of recovery strategies that age based entirely on syntax and which are independent of any particular grammar.", "labels": [], "entities": []}, {"text": "The aim of Otis work is therefore to explore purely syntactic and granmmr-independent techniques to enable a to recover from simple kinds of iil-formedness in rex.", "labels": [], "entities": []}, {"text": "Accordingly, we present a generalised parsing strategy based on an active chart which is capable of diagnosing simple \u00a2nvrs (unknown/mi.uq~elled words, omitted words, extra noise words) in sentences (from languages described by context free phrase slructur\u00a2 grammars without e-productions).", "labels": [], "entities": []}, {"text": "This strategy has the advantage that the recovery process can run after a standard (active chart) parser has terminated unsuccessfully, without causing existing work to be reputed or the original parser to be slowed down in anyway, and that, unlike previous systems, it allows the full syntactic context to be exploited in the determination of a \"best\" parse for an ill-formed sentence.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "To see whether the ideas of this paper make sense in practice, we have performed some very preliminaw experiments, with an inefficient implementation of the chart parser and a small CF-PSG (84 rules and 34 word lexicon, 18 of whose entries indicate category ambiguity) fora fragment of English.", "labels": [], "entities": []}, {"text": "We generated random sentences (30 of each length considered) from the grammar and then introduced random ocxunences of specific types of errors into these sentences.", "labels": [], "entities": []}, {"text": "The errors considered were none (i.e. leaving the correct sentence as it was), deleting a word, adding a word (either a completely unknown word or a word with an entry in the lexicon) and substituting a completely unknown word for one word of the sentence.", "labels": [], "entities": []}, {"text": "For each length of original sentence, the re,~ts were averaged over the 30 sentences randomly generated.", "labels": [], "entities": []}, {"text": "We collected the following statistics (see for the results): BU cyc/e$ -the number of cycles taken (see below) to exhaust the chart in the initial (standard) bottom-up parsing phase.", "labels": [], "entities": [{"text": "BU cyc/e$", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9214392900466919}]}, {"text": "#$olns -the number of different \"solutions\" found.", "labels": [], "entities": [{"text": "olns", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9519230723381042}]}, {"text": "A \"solution\" was deemed to be a description of a possible set of errors which has a minimal penalty score and if corrected would enable a complete parse to be constructed.", "labels": [], "entities": []}, {"text": "Possible errors were adding an extra word, deleting a word and substituting a word for an instance of a given lexical category.", "labels": [], "entities": []}, {"text": "The penalty associated with a given set of errors was the number of em3~ in the set.", "labels": [], "entities": []}, {"text": "First -the number of cycles of generalised top-down parsing required to find the first solution.", "labels": [], "entities": []}, {"text": "Last -the number of cycles of generalised topdown parsing required to find the last solution.", "labels": [], "entities": [{"text": "generalised topdown parsing", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.4804813067118327}]}, {"text": "TD cyc/es -the number of cycles of generalised top-down parsing required to exhaust all possibilities of sets of errors with the same penalty as the first solution found.", "labels": [], "entities": []}, {"text": "It was important to have an implementationindependent measure of the amount of work done by the parser, and for this we used the concept of a \"cycle\" of the chart parser.", "labels": [], "entities": []}, {"text": "A \"cycle\" in this context represents the activity of the parser in removing one item from the agenda, adding the relevant edge to the chart and adding to the agenda any new edges that are suggested by the rules as a result of the new addition.", "labels": [], "entities": []}, {"text": "For instance, in conventional top-down chart parsing a cycle might consist of removing the edge <S from 0 to 6 needs [NP VI'] from 0 to 6> from the front of the agenda, adding this to the chart and then adding new edges to the agenda, as follows.", "labels": [], "entities": [{"text": "top-down chart parsing", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7041707833607992}]}, {"text": "Ftrst of all, for each edge of the form <NP from 0 to a needs 0> in the chart the fundamental rule determines that <S from 0 to 6 needs from ct to 6> should be added.", "labels": [], "entities": []}, {"text": "Secondly, for each rule NP -.., 7 in the grammar the top-down rule determines that <NP from 0 to * needs y from 0 to *> should be added.", "labels": [], "entities": []}, {"text": "With generalised top-down parsing, there are more rules to be considered, but the idea is the same.", "labels": [], "entities": []}, {"text": "Actually, for the top-down rule our implementation schedules a whole collection of single additions (\"apply the top down rule to edge a\") as a single item on the agenda.", "labels": [], "entities": []}, {"text": "When such a request reaches the front of the queue, the actual new edges are then computed and themselves added to the agenda.", "labels": [], "entities": []}, {"text": "The result of this strategy is to make the agenda smaller but more structured, at the cost of some extra cycles.", "labels": [], "entities": []}, {"text": "The preliminary results show that, for small sentences and only one error, enumerating all the possible minimum-penalty errors takes no worse than 10 times as long as parsing the correct sentences.", "labels": [], "entities": []}, {"text": "Finding the first minimal-penalty error can also be quite fast.", "labels": [], "entities": []}, {"text": "There is, however, a great variability between the types of error.", "labels": [], "entities": []}, {"text": "Errors involving completely unknown words can be diagnosed reasonably quickly because the presence of an unknown word allows the estimation of penalty scores to be quite accurate (the system still has to workout whether the word can bean addition and for what categories it can substitute for an instance of, however).", "labels": [], "entities": [{"text": "estimation of penalty scores", "start_pos": 129, "end_pos": 157, "type": "METRIC", "confidence": 0.7736870497465134}]}, {"text": "We have not yet considered multiple errors in a sentence, and we can expect the behaviour to worsten dramatically as the number of errors increases.", "labels": [], "entities": []}, {"text": "Although does not show this, there is also a great deal of variability between sentences of the same length with the same kind of introduced error.", "labels": [], "entities": []}, {"text": "It is noticeable that errors towards the end of a sentence are harder to diagnose than those at the start.", "labels": [], "entities": []}, {"text": "This reflects the leRfight orientation of the parsing rules -an attempt to find phrases starting to the right of an error will have a PBG score at least one more than the estimated PB, whereas an attempt m find phrases in an open-ended portion of the chart starting before an error may have a PBG score the same as the PB (as the error may occur within the phrases to be found).", "labels": [], "entities": [{"text": "PBG", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9917444586753845}, {"text": "PBG", "start_pos": 293, "end_pos": 296, "type": "METRIC", "confidence": 0.9577499628067017}]}, {"text": "Thus more parsing attempts will be relegated to the lower parts of the agenda in the first case than in the second.", "labels": [], "entities": [{"text": "parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9813794493675232}]}, {"text": "One disturbing fact about the statistics is that the number of minimal-penalty solutions maybe quite large.", "labels": [], "entities": []}, {"text": "For instance, the ill-formed sentence: who has John seen on that had was formed by adding the extra word \"had\" to the sentence \"who has John seen on that\".", "labels": [], "entities": []}, {"text": "Our parser found three other possible single errors to account for the sentence.", "labels": [], "entities": []}, {"text": "The word \"on\" could have been an added word, the word \"on\" could have been a substitution fora complementiser and there could have been a missing NP after \"on\".", "labels": [], "entities": []}, {"text": "This large number of solutions could bean artefact of our particular gramram\" and lexicon; certainly it is unclear how one should choose between possible solutions in a grammar-independent way.", "labels": [], "entities": []}, {"text": "Ina few cases, the introduction of a random error actually produced a grammatical sentence -this occurred, for instance, twice with sentences of length 5 given one random A__dded word.", "labels": [], "entities": []}, {"text": "At this stage, we cannot claim that our experiments have done anything more than indicate a certain concreteness to the ideas and point to a number of unresolved problems.", "labels": [], "entities": []}, {"text": "It remains to be seen how the performance will scale up fora realistic grammar and parser.", "labels": [], "entities": []}, {"text": "There area number of detailed issues to resolve before a really practical implementation of the above ideas can be produced.", "labels": [], "entities": []}, {"text": "The indexing strategy of the chart needs to be altered to take into account the new parsing rules, and remaining problems of duplication of effort need to be addressed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 84, "end_pos": 91, "type": "TASK", "confidence": 0.9706172347068787}]}, {"text": "For instance, the generalised version of the fundamental rule allows an active edge to combine with a set of inactive edges satisfying its needs in any order.", "labels": [], "entities": []}, {"text": "The scoring of errors is another ar~ which should be better investigated.", "labels": [], "entities": [{"text": "ar", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9694804549217224}]}, {"text": "Where extra words are introduced accidentally into a text, in practice they are perhaps unlikely to be words that are already in the lexicon.", "labels": [], "entities": []}, {"text": "Thus when we gave our system sentences with known words added, this may not have been a fair test.", "labels": [], "entities": []}, {"text": "Perhaps the scoring system should prefer added words to be words outside the lexicon, substituted words to substitute for words in open categories, deleted words to be non-content words, and soon.", "labels": [], "entities": []}, {"text": "Perhaps also the confidence of the system about possible substitutions could take into account whether a standard spelling corrector can rewrite the acnmi word to a known word of the hypothesised category.", "labels": [], "entities": []}, {"text": "A more sophisticated error scoring strategy could improve the system's behaviour considerably for real examples (it might of course make less difference for random examples like the ones in our experiments).", "labels": [], "entities": [{"text": "error scoring", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.6322908252477646}]}, {"text": "Finally the behaviour of the approach with realistic grammars written in more expressive notations needs to be established.", "labels": [], "entities": []}, {"text": "At present, we are investigating whether any of the current ideas can be used in conjunction with Allport's (1988) \"interesting corner\" parser.", "labels": [], "entities": [{"text": "Allport's (1988) \"interesting corner\" parser", "start_pos": 98, "end_pos": 142, "type": "DATASET", "confidence": 0.8514559030532837}]}], "tableCaptions": [{"text": " Table 1: Preliminary experimental results", "labels": [], "entities": []}]}