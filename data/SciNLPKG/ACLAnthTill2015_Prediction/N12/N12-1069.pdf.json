{"title": [{"text": "Concavity and Initialization for Unsupervised Dependency Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate models for unsupervised learning with concave log-likelihood functions.", "labels": [], "entities": []}, {"text": "We begin with the most well-known example, IBM Model 1 for word alignment (Brown et al., 1993) and analyze its properties, discussing why other models for unsupervised learning are so seldom concave.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.7797968685626984}]}, {"text": "We then present concave models for dependency grammar induction and validate them experimentally.", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.8435250918070475}]}, {"text": "We find our concave models to be effective initializers for the dependency model of Klein and Manning (2004) and show that we can encode linguistic knowledge in them for improved performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "In NLP, unsupervised learning typically implies optimization of a \"bumpy\" objective function riddled with local maxima.", "labels": [], "entities": []}, {"text": "However, one exception is IBM Model 1 ( for word alignment, which is the only model commonly used for unsupervised learning in NLP that has a concave loglikelihood function.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.8200255632400513}]}, {"text": "1 For other models, such as those used in unsupervised part-of-speech tagging and grammar induction, and indeed for more sophisticated word alignment models, the log-likelihood function maximized by EM is non-concave.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.7240333557128906}, {"text": "grammar induction", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.74543297290802}, {"text": "word alignment", "start_pos": 135, "end_pos": 149, "type": "TASK", "confidence": 0.7732917964458466}]}, {"text": "As a result, researchers are obligated to consider initialization in addition to model design (.", "labels": [], "entities": [{"text": "initialization", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.9710222482681274}]}, {"text": "For example, consider the dependency grammar induction results shown in when training the It is not strictly concave ( widely used dependency model with valence (DMV;).", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.8285203178723654}]}, {"text": "Using uniform distributions for initialization (UNIF) results in an accuracy of 17.6% on the test set, well below the baseline of attaching each word to its right neighbor (ATTACHRIGHT, 31.7%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9995015859603882}, {"text": "ATTACHRIGHT", "start_pos": 173, "end_pos": 184, "type": "METRIC", "confidence": 0.9645956754684448}]}, {"text": "Furthermore, when using a set of 50 random initializers (RAND), the standard deviation of the accuracy is an alarming 8.3%.", "labels": [], "entities": [{"text": "standard deviation", "start_pos": 68, "end_pos": 86, "type": "METRIC", "confidence": 0.9418312311172485}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9995507597923279}]}, {"text": "In light of this sensitivity to initialization, it is compelling to consider unsupervised models with concave log-likelihood functions, which may provide stable, data-supported initializers for more complex models.", "labels": [], "entities": [{"text": "initialization", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.9878849387168884}]}, {"text": "In this paper, we explore the issues involved with such an expedition and elucidate the limitations of such models for unsupervised NLP.", "labels": [], "entities": []}, {"text": "We then present simple concave models for dependency grammar induction that are easy to implement and offer efficient optimization.", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.8258093396822611}]}, {"text": "We also show how linguistic knowledge can be encoded without sacrificing concavity.", "labels": [], "entities": []}, {"text": "Using our models to initialize the DMV, we find that they lead to an improvement in average accuracy across 18 languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9659329652786255}]}], "datasetContent": [{"text": "We ran experiments to determine how well our concave grammar induction models CCV1 and CCV2 can perform on their own and when used as initializers for the DMV ().", "labels": [], "entities": [{"text": "DMV", "start_pos": 155, "end_pos": 158, "type": "DATASET", "confidence": 0.8827921748161316}]}, {"text": "The DMV is a generative model of POS tag sequences and projective dependency trees over them.", "labels": [], "entities": []}, {"text": "It is the foundation of most state-of-the-art unsupervised grammar induction models (several of which are listed in Tab. 1).", "labels": [], "entities": []}, {"text": "The model includes multinomial distributions for generating each POS tag given its parent and the direction of generation: where e i is the parent POS tag and e j the child tag, these distributions take the form c(e j | e i , sign(j \u2212 i)), analogous to the distributions used in our concave models.", "labels": [], "entities": []}, {"text": "The DMV also has multinomial distributions for deciding whether to stop or continue generating children in each direction considering whether any children have already been generated in that direction.", "labels": [], "entities": [{"text": "DMV", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8976327776908875}]}, {"text": "The majority of researchers use the original initializer from, denoted here K&M.", "labels": [], "entities": []}, {"text": "K&M is a deterministic harmonic initializer that sets parent-child token affinities inversely 2 This is similar to the rule used by Mare\u010dek and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y (2011) with empirical success.", "labels": [], "entities": []}, {"text": "3 As verbs, we take all tags that map to V in the universal tag mappings from.", "labels": [], "entities": []}, {"text": "Thus, to apply this constraint to anew language, one would have to produce a similar tag mapping or identify verb tags through manual inspection.", "labels": [], "entities": []}, {"text": "proportional to their distances, then normalizes to obtain probability distributions.", "labels": [], "entities": []}, {"text": "K&M is often described as corresponding to an initial E step for an unspecified model that favors short attachments.", "labels": [], "entities": [{"text": "K&M", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5798598329226176}]}, {"text": "Procedure We run EM for our concave models for 100 iterations.", "labels": [], "entities": [{"text": "EM", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.7389176487922668}]}, {"text": "We evaluate the learned models directly as parsers on the test data and also use them to initialize the DMV.", "labels": [], "entities": []}, {"text": "When using them directly as parsers, we use dynamic programming to ensure that a valid tree is recovered.", "labels": [], "entities": []}, {"text": "When using the concave models as initializers for the DMV, we copy the c parameters over directly since they appear in both models.", "labels": [], "entities": []}, {"text": "We do not have the stop/continue parameters in our concave models, so we simply initialize them uniformly for the DMV.", "labels": [], "entities": []}, {"text": "We train each DMV for 200 iterations and use minimum Bayes risk decoding with the final model on the test data.", "labels": [], "entities": []}, {"text": "We use several initializers for training the DMV, including the uniform initializer (UNIF), K&M, and our trained concave models CCV1 and CCV2.", "labels": [], "entities": [{"text": "UNIF", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.6333926916122437}]}, {"text": "We follow standard practice in removing punctuation and using short sentences (\u2264 10 or \u2264 20 words) for training.", "labels": [], "entities": []}, {"text": "For all experiments, we train on separate data from that used for testing and use gold POS tags for both training and testing.", "labels": [], "entities": []}, {"text": "We report accuracy on (i) test set sentences \u2264 10 words and (ii) all sentences from the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994397759437561}]}, {"text": "Results Results for English are shown in Tab.", "labels": [], "entities": [{"text": "English", "start_pos": 20, "end_pos": 27, "type": "DATASET", "confidence": 0.9502562880516052}, {"text": "Tab.", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.9745306372642517}]}, {"text": "1. We train on \u00a72-21 and test on \u00a723 in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.9936357140541077}]}, {"text": "The constraint on sentence roots helps a great deal, as CCV2 by itself is competitive with the DMV when testing on short sentences.", "labels": [], "entities": []}, {"text": "The true benefit of the concave models, however, appears when using them as initializers.", "labels": [], "entities": []}, {"text": "The DMV initialized with CCV2 achieves a substantial improvement overall others.", "labels": [], "entities": []}, {"text": "When training on sentences of length \u2264 20 words (bold), the performance even rivals that of several more sophisticated models shown in the table, despite only using the DMV with a different initializer.", "labels": [], "entities": []}, {"text": "2 shows results for 18 languages.", "labels": [], "entities": []}, {"text": "On average, CCV2 performs best and CCV1 does at least as well as K&M.", "labels": [], "entities": [{"text": "K&M", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.7073966066042582}]}, {"text": "This shows that a simple, concave model can be as effective as a state-of-the-art handdesigned initializer (K&M), and that concave models can encode linguistic knowledge to further improve performance.", "labels": [], "entities": []}, {"text": "In some cases, we did not use official CoNLL test sets but instead took the training data and reserved the first 80% of the sentences for training, the next 10% for development, and the final 10% as our test set; dataset details are omitted for space but are the same as those given by Cohen (2011).", "labels": [], "entities": [{"text": "CoNLL test sets", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9375595450401306}]}, {"text": "Average log-likelihoods (micro-averaged across sentences) achieved by EM training are shown in the final column of Tab.", "labels": [], "entities": [{"text": "Tab", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.9213584065437317}]}, {"text": "2. CCV2 leads to substantiallyhigher likelihoods than the other initializers, suggesting that the verb-root constraint is helping EM to find better local optima.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Test set attachment accuracies for 18 languages; first number in each cell is accuracy for sentences \u2264 10  words and second is for all sentences. For training, sentences \u2264 10 words from each treebank were used. In order,  languages are Basque, Bulgarian, Catalan, Chinese, Czech, Danish, Dutch, English, German, Greek, Hungarian,  Italian, Japanese, Portuguese, Slovenian, Spanish, Swedish, and Turkish.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9993026256561279}]}]}