{"title": [{"text": "Intrinsic and Extrinsic Evaluation of an Automatic User Disengagement Detector for an Uncertainty-Adaptive Spoken Dialogue System", "labels": [], "entities": [{"text": "User Disengagement Detector", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.7319357792536417}]}], "abstractContent": [{"text": "We present a model for detecting user disengagement during spoken dialogue interactions.", "labels": [], "entities": [{"text": "detecting user disengagement during spoken dialogue interactions", "start_pos": 23, "end_pos": 87, "type": "TASK", "confidence": 0.8262630786214556}]}, {"text": "Intrinsic evaluation of our model (i.e., with respect to a gold standard) yields results on par with prior work.", "labels": [], "entities": []}, {"text": "However, since our goal is immediate implementation in a system that already detects and adapts to user uncertainty , we go further than prior work and present an extrinsic evaluation of our model (i.e., with respect to the real-world task).", "labels": [], "entities": []}, {"text": "Correlation analyses show crucially that our automatic disengagement labels correlate with system performance in the same way as the gold standard (manual) labels, while regression analyses show that detecting user disengagement adds value over and above detecting only user uncertainty when modeling performance.", "labels": [], "entities": []}, {"text": "Our results suggest that automatically detecting and adapting to user disengagement has the potential to significantly improve performance even in the presence of noise, when compared with only adapting to one affective state or ignoring affect entirely.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialogue systems that can detect and adapt to user affect 1 are fast becoming reality (; Lee * Now at Univ. Toronto: jdrummond@cs.toronto.edu We use affect for emotions and attitudes that affect how users communicate.", "labels": [], "entities": []}, {"text": "Other speech researchers also combine concepts of emotion, arousal, and attitudes where emotion is not full-blown and).", "labels": [], "entities": []}, {"text": "The benefits are clear: affect-adaptive systems have been shown to increase task success) or improve other system performance metrics such as user satisfaction ().", "labels": [], "entities": []}, {"text": "However, to date most affective systems researchers have focused either only on affect detection, or only on detecting and adapting to a single affective state.", "labels": [], "entities": [{"text": "affect detection", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.7449465990066528}]}, {"text": "The next step is thus to develop and evaluate spoken dialogue systems that detect and respond to multiple affective states.", "labels": [], "entities": []}, {"text": "We previously showed that detecting and responding to user uncertainty during spoken dialogue computer tutoring significantly improves task success).", "labels": [], "entities": [{"text": "detecting and responding to user uncertainty during spoken dialogue computer tutoring", "start_pos": 26, "end_pos": 111, "type": "TASK", "confidence": 0.5975890430537137}]}, {"text": "We are now taking the next step: incorporating automatic detection and adaptation to user disengagement as well, with the goal of further improving task success.", "labels": [], "entities": []}, {"text": "We targeted user uncertainty and disengagement because manual annotation showed them to be the two most common user affective states in our system and both are negatively correlated with task success).", "labels": [], "entities": []}, {"text": "Thus, we hypothesize that providing appropriate responses to these states would reduce their frequency, consequently improving task success.", "labels": [], "entities": [{"text": "frequency", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9740766882896423}]}, {"text": "Although we address these user states in the tutoring domain, spoken dialogue researchers across domains and applications have investigated the automatic detection of both user uncertainty (e.g. () and user disengagement (e.g.,), to improve system performance.", "labels": [], "entities": []}, {"text": "The detection of user disengagement in particular has received substantial attention in recent years, due to growing awareness of its potential for negatively impacting commercial applications (.", "labels": [], "entities": [{"text": "detection of user disengagement", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.8106389790773392}]}, {"text": "In this paper we present a model for automatically detecting user disengagement during spoken dialogue interactions.", "labels": [], "entities": [{"text": "automatically detecting user disengagement during spoken dialogue interactions", "start_pos": 37, "end_pos": 115, "type": "TASK", "confidence": 0.7438510805368423}]}, {"text": "Intrinsic evaluation of our model yields results on par with those of prior work.", "labels": [], "entities": []}, {"text": "However, we argue that while intrinsic evaluations are necessary, they aren't sufficient when immediate implementation is the goal, because there is no a priori way to know when the model's performance is acceptable to use in a working system.", "labels": [], "entities": []}, {"text": "This problem is particularly relevant to affect detection because it is such a difficult task, where no one achieves nearperfect results.", "labels": [], "entities": [{"text": "affect detection", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.8458221256732941}]}, {"text": "We argue that for such tasks some extrinsic evaluation is also necessary, to show that the automatic labels are useful and/or area reasonable substitute fora gold standard before undertaking a labor-intensive and time-consuming evaluation with real users.", "labels": [], "entities": []}, {"text": "Here we use correlational analyses to show that our automatic disengagement labels are related to system performance in the same way as the gold standard (manual) labels.", "labels": [], "entities": []}, {"text": "We further show through regression analyses that detecting user disengagement adds value over and above detecting only user uncertainty when modeling performance.", "labels": [], "entities": [{"text": "detecting user disengagement", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.7181174059708914}]}, {"text": "These results provide strong evidence that enhancing a spoken dialogue system to detect and adapt to multiple affective states (specifically, user disengagement and uncertainty) has the potential to significantly improve performance even in the presence of noise due to automatic detection, when compared with only adapting to one affective state or ignoring affect entirely.", "labels": [], "entities": [{"text": "user disengagement", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.6900501400232315}]}], "datasetContent": [{"text": "Our final DISE model was produced by running the J48 algorithm over our entire corpus.", "labels": [], "entities": []}, {"text": "The resulting decision tree contains 141 nodes and 75 leaves.", "labels": [], "entities": []}, {"text": "Inspection of the tree reveals that all of the feature types in (acoustic-prosodic, lexical/dialogue, user identifier) are used as decision nodes in the tree, although not all variations on these types were used.", "labels": [], "entities": []}, {"text": "The upper-level nodes of the tree are usually considered to be more informative features as compared to lower-level nodes, since they are queried for more leaves.", "labels": [], "entities": []}, {"text": "The upper level of the DISE model consists entirely of temporal, lexical, pitch and energy features as well as question name and depth and incorrect runs, while features such as gender, turn number, and dialogue name appear only near the leaves, and pretest score and turn (in)correctness don't appear at all.", "labels": [], "entities": []}, {"text": "The amount of pausing prior to the start of the user turn is the most important feature for determining disengagement, with pauses shorter than a quarter second being labeled DISE, suggesting that fast answers area strong signal of disengagement in our system.", "labels": [], "entities": [{"text": "DISE", "start_pos": 175, "end_pos": 179, "type": "METRIC", "confidence": 0.9736810326576233}]}, {"text": "Users who answer quickly may do so without taking the time to think it through; the more engaged user, in contrast, takes more time to prepare an answer.", "labels": [], "entities": []}, {"text": "Three lexical items from the student turns, \"friction\", \"light\", and \"greater\", are the next most important features in the tree, suggesting that particular concepts and question types can be typically associated with user disengagement in a system.", "labels": [], "entities": []}, {"text": "For example, open-ended system questions may lead users to disengage due to frustration from not knowing when their answer is complete.", "labels": [], "entities": []}, {"text": "One common casein ITSPOKE involves asking users to name all the forces on an object; some users don't know how many to list, so they start listing random forces, such as \"friction.\"", "labels": [], "entities": []}, {"text": "On the other hand, multiple choice questions can also lead users to disengage; they begin with a reasonable chance of being correct and thus don't take the time to think through their answer.", "labels": [], "entities": []}, {"text": "One common casein ITSPOKE involves asking users to determine which of two objects has the greater or lesser force, acceleration, and velocity.", "labels": [], "entities": [{"text": "acceleration", "start_pos": 115, "end_pos": 127, "type": "METRIC", "confidence": 0.979572594165802}]}, {"text": "While our feature set is highly generalizable to other domains, it is an empirical question as to whether the feature values we found maximally effective for predicting disengagement also generalize to other domains.", "labels": [], "entities": [{"text": "predicting disengagement", "start_pos": 158, "end_pos": 182, "type": "TASK", "confidence": 0.8416200876235962}]}, {"text": "Intuition is often unreliable, and it has been widely shown in affect prediction that the answer can depend on domain, dataset, and learning algorithm employed.", "labels": [], "entities": [{"text": "Intuition", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9569615125656128}]}, {"text": "Moreover, there are many types of spoken dialogue systems with different styles and no single type can represent the entire field.", "labels": [], "entities": []}, {"text": "That said, it is also important to note that there are lessons to be learned from the features selected for one particular domain, in terms of the take-home message for other domains.", "labels": [], "entities": []}, {"text": "For example, the fact that \"prior pause\" is selected as a strong signal of disengagement in ITSPOKE dialogues may indicate that the feature itself (regardless of its selected value) could be transferred to different domains, alone or in the demonstrated combinations with the other selected features.", "labels": [], "entities": []}, {"text": "Next we use extrinsic evaluation to confirm that our final DISE model is both useful and a reasonable substitute for our gold standard manual DISE labels.", "labels": [], "entities": []}, {"text": "With respect to showing the utility of detecting DISE, we use a correlational analysis to show that the gold standard (manual) DISE values are significantly predictive of two different measures of system performance.", "labels": [], "entities": [{"text": "detecting DISE", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.6843954920768738}]}, {"text": "12 With respect to showing the adequacy of our current level of detection performance for the learned DISE model, we demonstrate that after replacing the manual DISE labels with the automatic DISE labels when running our correlations, the automatic labels are related to performance in the same way as the gold standard labels.", "labels": [], "entities": []}, {"text": "Thus for both our automatically detected DISE labels (auto) and our gold standard DISE labels (manual), we first computed the total number of occurrences for each student, and then computed a bivariate Pearson's correlation between this total and two different metrics of performance: learning gain (LG) and user satisfaction (US).", "labels": [], "entities": [{"text": "learning gain (LG)", "start_pos": 285, "end_pos": 303, "type": "METRIC", "confidence": 0.8550995588302612}, {"text": "user satisfaction (US)", "start_pos": 308, "end_pos": 330, "type": "METRIC", "confidence": 0.7123026609420776}]}, {"text": "In the tutoring domain, learning is the primary performance metric and as is common in this domain we compute it as normalized learning gain ((posttest score-pretest score)/(1- pretest score)).", "labels": [], "entities": [{"text": "posttest score-pretest score)/(1- pretest score", "start_pos": 143, "end_pos": 190, "type": "METRIC", "confidence": 0.9169024154543877}]}, {"text": "In spoken dialogue systems, user satisfaction is the primary performance metric and as is common in this domain we compute it by totaling over the user satisfaction survey scores.", "labels": [], "entities": []}, {"text": "13 shows first the mean and standard deviation for the DISE label overall students, the Pearson's Correlation coefficient (R) and its significance (p).", "labels": [], "entities": [{"text": "DISE label overall students", "start_pos": 55, "end_pos": 82, "type": "DATASET", "confidence": 0.8612448275089264}, {"text": "Pearson's Correlation coefficient (R)", "start_pos": 88, "end_pos": 125, "type": "METRIC", "confidence": 0.936636711869921}, {"text": "significance (p)", "start_pos": 134, "end_pos": 150, "type": "METRIC", "confidence": 0.9093467444181442}]}, {"text": "As shown, both our manual and automatic DISE labels are significantly related to performance, regardless of whether we measure it as user satisfaction or learning gain.", "labels": [], "entities": []}, {"text": "14 Moreover, in both cases the correlations are nearly identical between the manual and automatic labels.", "labels": [], "entities": []}, {"text": "These results indicate that the detected DISE values area useful substitute for the gold standard, and suggest that redesigning IT-SPOKE to recognize and respond to DISE can significantly improve system performance.", "labels": [], "entities": []}, {"text": "Because we are adding our disengagement detector to a spoken dialogue system that already detects and adapts to user uncertainty, we argue that it is also necessary to evaluate whether greater performance benefits are likely to be obtained by adapting to a second state.", "labels": [], "entities": []}, {"text": "In other words, given how difficult it is to effectively detect and adapt to one user affective state, is performance likely to improve by detecting and adapting to multiple affective states?", "labels": [], "entities": []}, {"text": "To answer this question, we performed a multiple linear regression analysis aimed at quantifying the relative usefulness of the automatically detected Identical results were obtained by using an average instead of a total, and only slightly weaker results were obtained when normalizing the DISE totals as the percentages of total turns.", "labels": [], "entities": [{"text": "DISE totals", "start_pos": 291, "end_pos": 302, "type": "DATASET", "confidence": 0.8138701617717743}]}, {"text": "We previously found a related correlation between different DISE and learning measures, during the analysis of our DISE annotation scheme).", "labels": [], "entities": []}, {"text": "In particular, we showed a significant partial correlation between the percentage of manual DISE labels and posttest controlled for pretest score.", "labels": [], "entities": [{"text": "posttest controlled for pretest score", "start_pos": 108, "end_pos": 145, "type": "METRIC", "confidence": 0.844703984260559}]}, {"text": "disengagement and uncertainty labels when predicting our system performance metrics.", "labels": [], "entities": []}, {"text": "We ran four stepwise linear regressions.", "labels": [], "entities": []}, {"text": "The first regression predicted learning gain, and gave the model two possible inputs: the total number of automatic DISE labels and UNC labels per user.", "labels": [], "entities": []}, {"text": "We then ran the same regression again, this time predicting user satisfaction.", "labels": [], "entities": []}, {"text": "For comparison, we ran the same two regressions using the manual DISE and UNC labels.", "labels": [], "entities": [{"text": "DISE", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.5327474474906921}, {"text": "UNC labels", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.7962086498737335}]}, {"text": "As the trained regression models in show, when predicting learning gain, selecting both automatically detected affective state metrics as inputs significantly increases the model's predictive power as compared to only selecting one.", "labels": [], "entities": []}, {"text": "The (standardized) feature weights indicate relative predictive power in accounting for the variance in learning gain.", "labels": [], "entities": []}, {"text": "As shown, both automatic affect metrics have the same weight in the final model.", "labels": [], "entities": []}, {"text": "This result suggests that adapting to our automatically detected disengagement and uncertainty labels can further improve learning over and above adapting to uncertainty alone.", "labels": [], "entities": []}, {"text": "Although the final model's predictive power is low (R 2 =0.15), our interest here is only in investigating whether the two affective states are more useful in combination than in isolation for predicting performance.", "labels": [], "entities": [{"text": "R", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.9558427929878235}]}, {"text": "In similar types of stepwise regressions on prior ITSPOKE corpora, we've shown that more complete models of system performance incorporating many predictors of learning (i.e. affective states in conjunction with other dialogue features) can yield R 2 values of over .5).", "labels": [], "entities": [{"text": "R 2", "start_pos": 247, "end_pos": 250, "type": "METRIC", "confidence": 0.9521475732326508}]}, {"text": "16 Using the stepwise method, Automatic DISE was the first feature selected, and Automatic UNC the second.", "labels": [], "entities": [{"text": "Automatic DISE", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.6113509237766266}]}, {"text": "However, note that a model consisting of only the Automatic UNC metric also yields significantly worse predictive power than selecting both affective state metrics.", "labels": [], "entities": [{"text": "UNC metric", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.7386320233345032}]}, {"text": "Further note that almost identical models were produced using percentages rather than totals.", "labels": [], "entities": []}, {"text": "16 R 2 is the standard reported metric for linear regressions.", "labels": [], "entities": []}, {"text": "However, for consistency with Table 3, note that the two models in yield R values of -.", "labels": [], "entities": []}, {"text": "Learning Gain = -.31 * Total Automatic DISE (R 2 =.09, p=.009) Learning Gain = -.24 * Total Automatic DISE -.24 * Total Automatic UNC (R 2 =.15, p=.004) Interestingly, for the regression models of learning gain that used manual affect metrics, only the DISE metric was selected as an input.", "labels": [], "entities": [{"text": "UNC", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.5217527747154236}]}, {"text": "This indicates that the automatic affective state labels are useful in combination for predicting performance in away that is not reflected in their gold standard counterparts.", "labels": [], "entities": []}, {"text": "Detecting multiple affective states might thus be one way to compensate for the noise that is introduced in a fully-automated affective spoken dialogue system.", "labels": [], "entities": [{"text": "Detecting multiple affective states", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8266594707965851}]}, {"text": "Similarly, only the DISE metric was selected for inclusion in the regression model of user satisfaction, regardless of whether manual or automatic labels were used.", "labels": [], "entities": []}, {"text": "A separate correlation analysis showed that user uncertainty is not significantly correlated with user satisfaction in our system, though we previously found that multiple uncertainty-related metrics do significantly correlate with learning ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 2008 ITSPOKE Corpus Description (N=7216)  Turn Label  Total Percent  Disengaged  1170 16.21%  Correct  5330 73.86%  Uncertain  1483 20.55%  Uncertain+Disengaged 373  5.17%", "labels": [], "entities": [{"text": "2008 ITSPOKE Corpus Description", "start_pos": 10, "end_pos": 41, "type": "DATASET", "confidence": 0.8282833471894264}, {"text": "Turn Label  Total Percent  Disengaged  1170", "start_pos": 52, "end_pos": 95, "type": "METRIC", "confidence": 0.7456742922465006}, {"text": "Correct", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.5505971312522888}]}, {"text": " Table 2: Results of 10-fold Cross-Validation Experiment with J48 Decision Tree Algorithm Detecting the Binary DISE  Label in the 2008 ITSPOKE Corpus (N=7216 user turns)  Algorithm  Accuracy UA Precision UA Recall UA Fmeasure CC  MLE  Decision Tree  83.1%  68.9%  68.7%  68.8%  0.52 0.25  Majority Label 83.8%  41.9%  50.0%  45.6%  - 0.27", "labels": [], "entities": [{"text": "J48 Decision Tree", "start_pos": 62, "end_pos": 79, "type": "DATASET", "confidence": 0.8684307932853699}, {"text": "ITSPOKE Corpus", "start_pos": 135, "end_pos": 149, "type": "DATASET", "confidence": 0.8308128416538239}, {"text": "Accuracy UA Precision UA Recall UA Fmeasure CC", "start_pos": 182, "end_pos": 228, "type": "METRIC", "confidence": 0.8082935661077499}]}, {"text": " Table 3: Correlations between Disengagement and both Satisfaction and Learning in ITSPOKE Corpus (N=72 users)", "labels": [], "entities": [{"text": "ITSPOKE Corpus", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.8997207283973694}]}]}