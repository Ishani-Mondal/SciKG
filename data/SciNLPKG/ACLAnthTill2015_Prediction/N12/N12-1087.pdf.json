{"title": [], "abstractContent": [{"text": "We present a general framework containing a graded spectrum of Expectation Maximization (EM) algorithms called Unified Expectation Maximization (UEM.)", "labels": [], "entities": [{"text": "Expectation Maximization (EM)", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.8407539010047913}, {"text": "Unified Expectation Maximization (UEM", "start_pos": 111, "end_pos": 148, "type": "TASK", "confidence": 0.7222513377666473}]}, {"text": "UEM is parameterized by a single parameter and covers existing algorithms like standard EM and hard EM, constrained versions of EM such as Constraint-Driven Learning (Chang et al., 2007) and Posterior Regularization (Ganchev et al., 2010), along with a range of new EM algorithms.", "labels": [], "entities": [{"text": "Posterior Regularization (Ganchev et al., 2010)", "start_pos": 191, "end_pos": 238, "type": "TASK", "confidence": 0.7916201816664802}]}, {"text": "For the constrained inference step in UEM we present an efficient dual projected gradient ascent algorithm which generalizes several dual decomposition and Lagrange relaxation algorithms popularized recently in the NLP literature (Ganchev et al., 2008; Koo et al., 2010; Rush and Collins, 2011).", "labels": [], "entities": []}, {"text": "UEM is as efficient and easy to implement as standard EM.", "labels": [], "entities": [{"text": "UEM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.875206470489502}]}, {"text": "Furthermore , experiments on POS tagging, information extraction, and word-alignment show that often the best performing algorithm in the UEM family is anew algorithm that wasn't available earlier, exhibiting the benefits of the UEM framework.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.8153782188892365}, {"text": "information extraction", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.8578163385391235}]}], "introductionContent": [{"text": "Expectation Maximization (EM) is inarguably the most widely used algorithm for unsupervised and semi-supervised learning.", "labels": [], "entities": [{"text": "Expectation Maximization (EM)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8011772453784942}]}, {"text": "Many successful applications of unsupervised and semi-supervised learning in NLP use EM including text classification), machine translation (, and parsing ().", "labels": [], "entities": [{"text": "text classification", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7928299307823181}, {"text": "machine translation", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.8151313662528992}]}, {"text": "Recently, EM algorithms which incorporate constraints on structured output spaces have been proposed (.", "labels": [], "entities": []}, {"text": "Several variations of EM (e.g. hard EM) exist in the literature and choosing a suitable variation is often very task-specific.", "labels": [], "entities": []}, {"text": "Some works have shown that for certain tasks, hard EM is more suitable than regular EM (.", "labels": [], "entities": []}, {"text": "The same issue continues in the presence of constraints where Posterior Regularization (PR) ( corresponds to EM while Constraint-Driven Learning (CoDL)) corresponds to hard EM.", "labels": [], "entities": []}, {"text": "The problem of choosing between EM and hard EM (or between PR and CoDL) remains elusive, along with the possibility of simple and better alternatives, to practitioners.", "labels": [], "entities": []}, {"text": "Unfortunately, little study has been done to understand the relationships between these variations in the NLP community.", "labels": [], "entities": []}, {"text": "In this paper, we approach various EM-based techniques from a novel perspective.", "labels": [], "entities": []}, {"text": "We believe that \"EM or Hard-EM?\" and \"PR or CoDL?\" are not the right questions to ask.", "labels": [], "entities": [{"text": "PR or CoDL?\"", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.4948279336094856}]}, {"text": "Instead, we present a unified framework for EM, Unified EM (UEM), that covers many EM variations including the constrained cases along with a continuum of new ones.", "labels": [], "entities": []}, {"text": "UEM allows us to compare and investigate the properties of EM in a systematic way and helps find better alternatives.", "labels": [], "entities": [{"text": "UEM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.729275643825531}]}, {"text": "The contributions of this paper are as follows: 1.", "labels": [], "entities": []}, {"text": "We propose a general framework called Unified Expectation Maximization (UEM) that presents a continuous spectrum of EM algorithms parameterized by a simple temperaturelike tuning parameter.", "labels": [], "entities": [{"text": "Unified Expectation Maximization (UEM)", "start_pos": 38, "end_pos": 76, "type": "TASK", "confidence": 0.7747242550055186}]}, {"text": "The framework covers both constrained and unconstrained EM algorithms.", "labels": [], "entities": []}, {"text": "UEM thus connects EM, hard EM, PR, and CoDL so that the relation between different algorithms can be better understood.", "labels": [], "entities": [{"text": "UEM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8165304064750671}]}, {"text": "It also enables us to find new EM algorithms.", "labels": [], "entities": []}, {"text": "a dual projected subgradient ascent algorithm that generalizes several dual decomposition and Lagrange relaxation algorithms introduced recently in NLP ().", "labels": [], "entities": []}, {"text": "3. We provide away to implement a family of EM algorithms and choose the appropriate one, given the data and problem setting, rather than a single EM variation.", "labels": [], "entities": []}, {"text": "We conduct experiments on unsupervised POS tagging, unsupervised word-alignment, and semi-supervised information extraction and show that choosing the right UEM variation outperforms existing EM algorithms by a significant margin.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.7702079713344574}, {"text": "information extraction", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.7489135265350342}]}], "datasetContent": [{"text": "Our experiments are designed to explore tuning \u03b3 in the UEM framework as away to obtain gains over EM and hard EM in the constrained and unconstrained cases.", "labels": [], "entities": []}, {"text": "We conduct experiments on POStagging, word-alignment, and information extraction; we inject constraints in the latter two.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.8122464716434479}]}, {"text": "In all the cases we use our unified inference step to implement general UEM and the special cases of existing EM algorithms.", "labels": [], "entities": []}, {"text": "Since both of our constrained problems involve large scale constrained inference during the E-step, we use UEM 0 (with a Lagrange relaxation based E-step) as a proxy for ILP-based CoDL . As we vary \u03b3 over, we circumvent much of the debate over EM vs hard EM ( by exploring the space of EM algorithms in a \"continuous\" way.", "labels": [], "entities": []}, {"text": "Furthermore, we also study the relation between quality of model initialization and the value of \u03b3 in the case of POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 114, "end_pos": 125, "type": "TASK", "confidence": 0.7620401084423065}]}, {"text": "This is inspired by a general \"research wisdom\" that hard EM is a better choice than EM with a good initialization point whereas the opposite is true with an \"uninformed\" initialization.", "labels": [], "entities": []}, {"text": "Unsupervised POS Tagging We conduct experiments on unsupervised POS learning experiment with the tagging dictionary assumption.", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.6297411471605301}]}, {"text": "We use a standard subset of Penn Treebank containing 24,115 tokens () with the tagging dictionary derived from the entire Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9948521256446838}, {"text": "Penn Treebank", "start_pos": 122, "end_pos": 135, "type": "DATASET", "confidence": 0.995961606502533}]}, {"text": "We run UEM with a first order (bigram) HMM model . We consider initialization points of varying quality and observe the performance for \u03b3 \u2208.", "labels": [], "entities": []}, {"text": "Different initialization points are constructed as follows.", "labels": [], "entities": []}, {"text": "The \"posterior uniform\" initialization is created by spreading the probability uniformly overall possible tags for each token.", "labels": [], "entities": []}, {"text": "Our EM model on ( showed that a first order HMM model performs much better than a second order HMM model on unsupervised POS tagging).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 121, "end_pos": 132, "type": "TASK", "confidence": 0.6405896246433258}]}, {"text": "The posterior uniform initialization does not use any labeled examples.", "labels": [], "entities": []}, {"text": "As the no. of labeled examples used to create the initial HMM model increases, the quality of the initial model improves.", "labels": [], "entities": []}, {"text": "The results show that the value of the best \u03b3 is sensitive to the initialization point and EM (\u03b3 = 1) and hard EM (\u03b3 = 0) are often not the best choice.", "labels": [], "entities": [{"text": "EM", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.9761958122253418}]}, {"text": "this dataset obtains 84.9% accuracy on all tokens and 72.3% accuracy on ambiguous tokens, which is competitive with results reported in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9984342455863953}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9988719820976257}]}, {"text": "To construct better initialization points, we train a supervised HMM tagger on holdout labeled data.", "labels": [], "entities": [{"text": "HMM tagger", "start_pos": 65, "end_pos": 75, "type": "TASK", "confidence": 0.8859174251556396}]}, {"text": "The quality of the initialization points is varied by varying the size of the labeled data over {5, 10, 20, 40, 80}.", "labels": [], "entities": []}, {"text": "Those initialization points are then fed into different UEM algorithms.", "labels": [], "entities": []}, {"text": "Results For a particular \u03b3, we report the performance of UEM \u03b3 w.r.t.", "labels": [], "entities": [{"text": "UEM", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.6863211393356323}]}, {"text": "EM (\u03b3 = 1.0) as given by where Acc represents the accuracy as evaluated on the ambiguous words of the given data.", "labels": [], "entities": [{"text": "EM", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9727885723114014}, {"text": "Acc", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9975296854972839}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9994922876358032}]}, {"text": "Note that rel(\u03b3) 0, implies performance better or worse than EM.", "labels": [], "entities": [{"text": "rel(\u03b3) 0", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9531933069229126}, {"text": "EM", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.6005758047103882}]}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "Note that when we use the \"posterior uniform\" initialization, EM wins by a significant margin.", "labels": [], "entities": []}, {"text": "Surprisingly, with the initialization point constructed with merely 5 or 10 examples, EM is not the best algorithm anymore.", "labels": [], "entities": []}, {"text": "The best result for most cases is obtained at \u03b3 somewhere between 0 (hard EM) and 1 (EM).", "labels": [], "entities": []}, {"text": "Furthermore, the results not only indicate that a measure of \"hardness\" of EM i.e. the best value of \u03b3, is closely related to the quality of the initialization point but also elicit a more fine-grained relationship between initialization and UEM.", "labels": [], "entities": [{"text": "EM", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9607688188552856}, {"text": "UEM", "start_pos": 242, "end_pos": 245, "type": "METRIC", "confidence": 0.6670997738838196}]}, {"text": "This experiment agrees with, which shows that EM performs poorly in the semisupervised setting.", "labels": [], "entities": [{"text": "EM", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.8234481811523438}]}, {"text": "In (, the authors show that hard EM (Viterbi EM) works better than standard EM.", "labels": [], "entities": []}, {"text": "We extend these results by showing that this issue can be overcome with the UEM framework by picking appropriate \u03b3 based on the amount of available labeled data.", "labels": [], "entities": [{"text": "UEM framework", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.8098810315132141}]}], "tableCaptions": [{"text": " Table 2: AER (Alignment Error Rate) comparisons  for French-English (above) and Spanish-English (below)  alignment for various data sizes. For French-English set- ting, tuned \u03b3 for all data-sizes is either 0.5 or 0.6. For  Spanish-English, tuned \u03b3 for all data-sizes is 0.7.", "labels": [], "entities": [{"text": "AER (Alignment Error Rate)", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.8216246863206228}]}]}