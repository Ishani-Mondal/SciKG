{"title": [{"text": "Autonomous Self-Assessment of Autocorrections: Exploring Text Message Dialogues", "labels": [], "entities": [{"text": "Exploring Text Message Dialogues", "start_pos": 47, "end_pos": 79, "type": "TASK", "confidence": 0.6195889636874199}]}], "abstractContent": [{"text": "Text input aids such as automatic correction systems play an increasingly important role in facilitating fast text entry and efficient communication between text message users.", "labels": [], "entities": [{"text": "text entry", "start_pos": 110, "end_pos": 120, "type": "TASK", "confidence": 0.7295044660568237}]}, {"text": "Although these tools are beneficial when they work correctly, they can cause significant communication problems when they fail.", "labels": [], "entities": []}, {"text": "To improve its autocorrection performance, it is important for the system to have the capability to assess its own performance and learn from its mistakes.", "labels": [], "entities": []}, {"text": "To address this, this paper presents a novel task of self-assessment of autocorrection performance based on interactions between text message users.", "labels": [], "entities": []}, {"text": "As part of this investigation, we collected a dataset of au-tocorrection mistakes from true text message users and experimented with a rich set of features in our self-assessment task.", "labels": [], "entities": []}, {"text": "Our experimental results indicate that there are salient cues from the text message discourse that allow systems to assess their own behaviors with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9847721457481384}]}], "introductionContent": [{"text": "The use of SMS text messaging is widespread and growing.", "labels": [], "entities": [{"text": "SMS text messaging", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.651558925708135}]}, {"text": "Users of text messaging often rely on small mobile devices with limited user interfaces to communicate with each other.", "labels": [], "entities": [{"text": "text messaging", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7566169202327728}]}, {"text": "To support efficient communication between users, many tools to aid text input such as automatic completion (autocompletion) and automatic correction (autocorrection) have become available.", "labels": [], "entities": []}, {"text": "When they work correctly, these tools allow users to maintain clear communication while potentially increasing the rate at which they input their message, improving efficiency in communication.", "labels": [], "entities": []}, {"text": "However, when these tools make a mistake, they can cause problematic situations.", "labels": [], "entities": []}, {"text": "Consider the following example: A 1 : Euthanasia doing tonight?", "labels": [], "entities": [{"text": "A", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9429275393486023}]}, {"text": "B 1 : Euthanasia?!", "labels": [], "entities": [{"text": "Euthanasia?", "start_pos": 6, "end_pos": 17, "type": "TASK", "confidence": 0.8196745812892914}]}, {"text": "A 2 : I typed whatcha and stupid autotype.", "labels": [], "entities": []}, {"text": "In this example, the automatic correction system on person A's phone interpreted his attempt to write the word whatcha as an attempt to write euthanasia (due to the keyboard adjacency of thew and e keys, etc.).", "labels": [], "entities": []}, {"text": "This completely changed the meaning of the message, which confused person B.", "labels": [], "entities": []}, {"text": "Although this instance was eventually discovered and corrected, the natural flow of conversation was interrupted and the participants were forced to make extra effort to clarify this confusion.", "labels": [], "entities": []}, {"text": "This example indicates that the cost of a mistake in autocorrection is potentially high.", "labels": [], "entities": []}, {"text": "This is exacerbated by the fact that users will often fail to notice these mistakes in a timely manner, due to their focus being on the keyboard () and the quick and casual conversation style of text messaging.", "labels": [], "entities": []}, {"text": "Because of this, autocorrection systems must have high accuracy to be useful for text messaging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9981825351715088}, {"text": "text messaging", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.8275228142738342}]}, {"text": "This example also indicates that, when an autocorrection mistake happens (i.e., mistaken correction of euthanasia), it often causes confusion which requires dialogue participants to use the follow-up dialogue to clarify the intent.", "labels": [], "entities": [{"text": "mistaken correction of euthanasia)", "start_pos": 80, "end_pos": 114, "type": "TASK", "confidence": 0.7959565758705139}]}, {"text": "What this suggests is that the discourse between text message users may provide important information for autocorrection sys-tems to assess whether an attempted correction is indeed what the user intended to type.", "labels": [], "entities": []}, {"text": "Self-assessment of its correction performance will allow an autocorrection system to detect correction mistakes, learn from such mistakes, and potentially improve its correction performance for future operations.", "labels": [], "entities": []}, {"text": "For instance, if a system is able to identify that its current autocorrection policy results in too many mistakes it may choose to adopt a more cautious correction policy in the future.", "labels": [], "entities": []}, {"text": "Additionally, if it is able to discover not only that a mistake has taken place but what the ideal action should have been, it will be able to use this data to learn a more refined policy for future attempts.", "labels": [], "entities": []}, {"text": "Motivated by this observation, this paper investigates the novel task of self-assessment of autocorrection performance based on interactions between dialogue participants.", "labels": [], "entities": []}, {"text": "In particular, we formulate this task as the automatic identification of correction mistakes and their corresponding intended words based on the discourse.", "labels": [], "entities": [{"text": "automatic identification of correction mistakes", "start_pos": 45, "end_pos": 92, "type": "TASK", "confidence": 0.6563198626041412}]}, {"text": "For instance, in the previous example, the system should automatically detect that the attempted correction \"euthanasia\" is a mistake and the true term (i.e., intended word) should have been \"whatcha\".", "labels": [], "entities": []}, {"text": "To support our investigation, we collected a dataset of autocorrection mistakes from true text message users.", "labels": [], "entities": []}, {"text": "We further experimented with a rich set of features in our self-assessment task.", "labels": [], "entities": []}, {"text": "Our experimental results indicate that there are salient cues from the text message discourse that potentially allow systems to assess their own behavior with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9851040244102478}]}, {"text": "In the sections that follow, we first introduce and give an analysis of our dataset.", "labels": [], "entities": []}, {"text": "We then highlight the two interrelated problems that must be solved for system self-assessment, and outline and evaluate our approach to each of these problems.", "labels": [], "entities": []}, {"text": "Finally, we examine the results of applying the system assessment procedure end-to-end and discuss potential applications of autocorrection self-assessment.", "labels": [], "entities": []}], "datasetContent": [{"text": "To find the most likely intended term fora correction mistake, we rank every candidate word in W and predict that the top ranked word is the intended term.", "labels": [], "entities": []}, {"text": "We used the ranking mode of SVMlight to train our ranker.", "labels": [], "entities": [{"text": "SVMlight", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.8109946250915527}]}, {"text": "By thresholding our results to only trust predictions in which the ranker reported a high ranking value for the top term, we were able to examine the precision at different recall levels.", "labels": [], "entities": [{"text": "precision", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.9986036419868469}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9969109892845154}]}, {"text": "That is, if the top ranked term does not meet the threshold, we simply do not predict an intended term for that instance, hurting recall but hopefully improving precision by removing instances that we are not confident about.", "labels": [], "entities": [{"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9988784193992615}, {"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9986684322357178}]}, {"text": "This thresholding process may also allow the ranker to exclude instances in which the intended term does not appear in the dialogue, which are hopefully ranked lower than other cases.", "labels": [], "entities": []}, {"text": "As before, evaluation was done via leave-one-out cross validation.", "labels": [], "entities": []}, {"text": "As a method of comparison we report a baseline that selects the word with the smallest edit distance as the intended term.", "labels": [], "entities": []}, {"text": "As shown, using the entire feature set results in consistently above baseline performance.", "labels": [], "entities": []}, {"text": "As before, we are more concerned with the precision of our predictions than the recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9977578520774841}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9944165945053101}]}, {"text": "It is difficult to assess the appropriate precision-recall tradeoff without an in-depth study of autocorrection usage by text messagers.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 42, "end_pos": 58, "type": "METRIC", "confidence": 0.9943869113922119}]}, {"text": "However, a few observations can be made from the precision-recall curve.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 49, "end_pos": 65, "type": "METRIC", "confidence": 0.9983311295509338}]}, {"text": "Most critically, we can observe that the model is able to predict the intended term for an erroneous correction with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.9863459467887878}]}, {"text": "Additionally, the precision stays relatively stable as recall increases, suffering a comparatively small drop in precision for an increase in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9995439648628235}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9988687634468079}, {"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9995471835136414}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9982104301452637}]}, {"text": "At its highest achieved recall values of 0.892, it maintains high precision at 0.869.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9996048808097839}, {"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.999337375164032}]}, {"text": "Feature ablation results are also reported in.", "labels": [], "entities": []}, {"text": "The most critical feature source was word similarity; without the similarity feature the performance is consistently worse than all other runs, even falling below baseline performance at high recall levels.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.6371482014656067}, {"text": "recall", "start_pos": 192, "end_pos": 198, "type": "METRIC", "confidence": 0.9937809109687805}]}, {"text": "This is not suprising, as the system's incorrect guess must beat least reasonably similar to the intended term, or the system would be unlikely to make this mistake.", "labels": [], "entities": []}, {"text": "Although not as substantial as the similarity feature, the contextual and punctuation features were also shown to have a significant effect on overall performance.", "labels": [], "entities": []}, {"text": "Conversely, removing word form or pattern features did not cause a significant change in performance (not shown in to enhance readability).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature ablation results for identifying autocor- rection mistakes", "labels": [], "entities": []}]}