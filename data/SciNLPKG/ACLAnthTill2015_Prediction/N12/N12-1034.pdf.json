{"title": [{"text": "Using paraphrases for improving first story detection in news and Twitter", "labels": [], "entities": [{"text": "first story detection in news and Twitter", "start_pos": 32, "end_pos": 73, "type": "TASK", "confidence": 0.7698707112244197}]}], "abstractContent": [{"text": "First story detection (FSD) involves identifying first stories about events from a continuous stream of documents.", "labels": [], "entities": [{"text": "First story detection (FSD)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8455293476581573}]}, {"text": "A major problem in this task is the high degree of lexical variation in documents which makes it very difficult to detect stories that talk about the same event but expressed using different words.", "labels": [], "entities": []}, {"text": "We suggest using paraphrases to alleviate this problem, making this the first work to use paraphrases for FSD.", "labels": [], "entities": [{"text": "FSD", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.8042579889297485}]}, {"text": "We show a novel way of integrating paraphrases with locality sensitive hashing (LSH) in order to obtain an efficient FSD system that can scale to very large datasets.", "labels": [], "entities": [{"text": "FSD", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.8742648363113403}]}, {"text": "Our system achieves state-of-the-art results on the first story detection task, beating both the best supervised and unsupervised systems.", "labels": [], "entities": [{"text": "story detection task", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.8434459567070007}]}, {"text": "To test our approach on large data, we construct a corpus of events for Twitter, consisting of 50 million documents, and show that paraphrasing is also beneficial in this domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "First story detection (FSD), sometimes also called new event detection (NED), is the task of detecting the first story about anew event from a stream of documents.", "labels": [], "entities": [{"text": "First story detection (FSD)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8056637744108835}, {"text": "new event detection (NED)", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.8169252574443817}, {"text": "detecting the first story about anew event from a stream of documents", "start_pos": 93, "end_pos": 162, "type": "TASK", "confidence": 0.8417683839797974}]}, {"text": "It began as one of the tasks in Topic Detection and Tracking (TDT)) where the overall goal of the project was to improve technologies related to event-based information organization tasks.", "labels": [], "entities": [{"text": "Topic Detection and Tracking (TDT))", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.867730941091265}]}, {"text": "Of the five TDT tasks, first story detection is considered the most difficult one (.", "labels": [], "entities": [{"text": "TDT tasks", "start_pos": 12, "end_pos": 21, "type": "TASK", "confidence": 0.9053818881511688}, {"text": "first story detection", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.66329292456309}]}, {"text": "A good FSD system would be very useful for business or intelligence analysts where timely discovery of events is crucial.", "labels": [], "entities": [{"text": "FSD", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.8803552985191345}]}, {"text": "With the significant increase in the amount of information being produced and consumed everyday, a crucial requirement fora modern FSD system to be useful is efficiency.", "labels": [], "entities": [{"text": "FSD", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.8870038986206055}]}, {"text": "This means that the system should be able to work in a streaming setting where documents are constantly coming in at a high rate, while still producing good results.", "labels": [], "entities": []}, {"text": "While previous work has addressed the efficiency) aspect, there has been little work on improving FSD performance in the past few years.", "labels": [], "entities": [{"text": "FSD", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.973921537399292}]}, {"text": "A major obstacle is the high degree of lexical variation in documents that cover the same event.", "labels": [], "entities": []}, {"text": "Here we address this problem, while keeping in mind the efficiency constraints.", "labels": [], "entities": []}, {"text": "The problem of lexical variation plagues many IR and NLP tasks, and one way it has been addressed in the past is through the use of paraphrases.", "labels": [], "entities": [{"text": "IR and NLP tasks", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7938812375068665}]}, {"text": "Paraphrases are alternative ways of expressing the same meaning in the same language.", "labels": [], "entities": []}, {"text": "For example, the phrase he got married can be paraphrased as he tied the knot.", "labels": [], "entities": []}, {"text": "Paraphrases were already shown to help in a number of tasks: for machine translation to translate unknown phrases by translating their paraphrases), for query expansion in information retrieval), or for improving question answering (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7587155103683472}, {"text": "query expansion", "start_pos": 153, "end_pos": 168, "type": "TASK", "confidence": 0.7816219925880432}, {"text": "question answering", "start_pos": 213, "end_pos": 231, "type": "TASK", "confidence": 0.863364964723587}]}, {"text": "A much more detailed discussion on the use of paraphrases and ways to extract them is given in.", "labels": [], "entities": []}, {"text": "Here, we present the first work to use paraphrases for improving first story detection.", "labels": [], "entities": [{"text": "first story detection", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.8396658102671305}]}, {"text": "Using paraphrases, we are able to detect that some documents previously thought to be about new events are actually paraphrases of the documents already seen.", "labels": [], "entities": []}, {"text": "Our approach is simple and we show a novel way of integrating paraphrases with locality sensitive hashing (LSH)).", "labels": [], "entities": []}, {"text": "This way we obtain a very efficient FSD system with all the benefits of using paraphrases, while avoiding computationally expensive topic modeling approaches such as.", "labels": [], "entities": [{"text": "FSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9495893716812134}]}, {"text": "First story detection was introduced as a task before the popularization of social media.", "labels": [], "entities": [{"text": "First story detection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7020817995071411}]}, {"text": "Event detection in social media, especially Twitter is a very good fit: we cover a much larger set of events than would be possible by using newswire, and the stories are reported in real time, often much sooner than in news.", "labels": [], "entities": [{"text": "Event detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7971579134464264}]}, {"text": "Of course, social media carries additional problems not found in traditional media: we have to deal with huge amounts of data, the data is very noisy (both due to spam and due to spelling and grammar errors), and in the case of Twitter, documents are extremely short.", "labels": [], "entities": []}, {"text": "There has been little effort in solving these problems for FSD.", "labels": [], "entities": [{"text": "FSD", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9738430380821228}]}, {"text": "Arguably the main reason for this is the lack of a TDT-style corpus for Twitter that researchers could use to test their approaches.", "labels": [], "entities": []}, {"text": "Here we build such a corpus and use it to measure the performance of TDT systems on Twitter.", "labels": [], "entities": []}, {"text": "Our main contributions are: i) we create a first corpus of events on Twitter, ii) we show how to use paraphrases in FSD, and how to combine it with LSH to handle high-volume streams, iii) our unsupervised system that uses paraphrases achieves the highest reported results on the TDT5 corpus, beating both the supervised and unsupervised state of the art, while still keeping a constant per-document time complexity, and iv) we show that paraphrases also help in Twitter, although less than in TDT.", "labels": [], "entities": [{"text": "TDT5 corpus", "start_pos": 279, "end_pos": 290, "type": "DATASET", "confidence": 0.9394186735153198}, {"text": "TDT", "start_pos": 493, "end_pos": 496, "type": "DATASET", "confidence": 0.9374880194664001}]}], "datasetContent": [{"text": "In the official TDT evaluation, each FSD system is required to assign a score between 0 and 1 to every document upon its arrival.", "labels": [], "entities": []}, {"text": "Lower scores correspond to old stories, and vice versa.", "labels": [], "entities": []}, {"text": "Evaluation is then carried out by first sorting all stories according to their scores and then performing a threshold sweep.", "labels": [], "entities": []}, {"text": "For each value of the threshold, stories with a score above the threshold are considered new, and all others are considered old.", "labels": [], "entities": []}, {"text": "Therefore, for each threshold value, one can compute the probability of a false alarm, i.e., probability of declaring a story new when it is actually not, and the miss probability, i.e., probability of declaring anew story old (missing anew story).", "labels": [], "entities": [{"text": "miss probability", "start_pos": 163, "end_pos": 179, "type": "METRIC", "confidence": 0.9854220449924469}]}, {"text": "Using the false alarm and the miss rate, the cost C det is defined as follows: where C miss and C FA are costs of miss and false alarm (0.02 and 0.98, respectively), P miss and P FA are the miss and false alarm rate, and P target and P non\u2212target are the prior target and non-target probabilities.", "labels": [], "entities": []}, {"text": "Different FSD systems are compared on the minimal cost C min , which is the minimal value of C det overall threshold values.", "labels": [], "entities": []}, {"text": "This means that in FSD evaluation, a lower value of C min indicates a better system.", "labels": [], "entities": [{"text": "FSD evaluation", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.7984901964664459}]}], "tableCaptions": [{"text": " Table 1: TDT FSD results for different systems, lower is  better. The number next to UMass system indicates the  number of features kept for each document (selected ac- cording to their TFIDF). All paraphrasing systems work  with full documents. Results for the best supervised sys- tem were taken from Kumaran and Allan (2005).", "labels": [], "entities": [{"text": "TDT FSD", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.5607902109622955}, {"text": "TFIDF", "start_pos": 187, "end_pos": 192, "type": "METRIC", "confidence": 0.9040902853012085}]}, {"text": " Table 2. Numbers next to precision", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.8945800065994263}]}, {"text": " Table 3: Twitter FSD results for different systems, lower  is better. The baseline system is that of (Petrovi\u00b4cPetrovi\u00b4c et al.,  2010).", "labels": [], "entities": [{"text": "FSD", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.6893248558044434}]}, {"text": " Table 4: Coverage of different resources.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9341145157814026}]}]}