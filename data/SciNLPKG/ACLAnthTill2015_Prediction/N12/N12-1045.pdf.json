{"title": [{"text": "A Hierarchical Dirichlet Process Model for Joint Part-of-Speech and Morphology Induction", "labels": [], "entities": [{"text": "Joint Part-of-Speech and Morphology Induction", "start_pos": 43, "end_pos": 88, "type": "TASK", "confidence": 0.6030047178268433}]}], "abstractContent": [{"text": "In this paper we present a fully unsupervised nonparametric Bayesian model that jointly induces POS tags and morphological segmen-tations.", "labels": [], "entities": []}, {"text": "The model is essentially an infinite HMM that infers the number of states from data.", "labels": [], "entities": []}, {"text": "Incorporating segmentation into the same model provides the morphological features to the system and eliminates the need to find them during preprocessing step.", "labels": [], "entities": []}, {"text": "We show that learning both tasks jointly actually leads to better results than learning either task with gold standard data from the other task provided.", "labels": [], "entities": []}, {"text": "The evaluation on multilingual data shows that the model produces state-of-the-art results on POS induction.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.8231925666332245}]}], "introductionContent": [{"text": "Nonparametric Bayesian modeling has recently become very popular in natural language processing (NLP), mostly because of its ability to provide priors that are especially suitable for tasks in NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 68, "end_pos": 101, "type": "TASK", "confidence": 0.7405738433202108}]}, {"text": "Using nonparametric priors enables to treat the size of the model as a random variable with its value to be induced during inference which makes its use very appealing in models that need to decide upon the number of states.", "labels": [], "entities": []}, {"text": "The task of unsupervised parts-of-speech (POS) tagging has been under research in numerous papers, for overview see ().", "labels": [], "entities": [{"text": "parts-of-speech (POS) tagging", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.6046149730682373}]}, {"text": "Most of the POS induction models use the structure of hidden Markov model (HMM)) that requires the knowledge about the number of hidden states (corresponding to the number of tags) in advance.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.888627827167511}]}, {"text": "According to our considerations, supplying this information is not desirable for two opposing reasons: 1) it injects into the system apiece of knowledge which in a truly unsupervised setting would be unavailable; and 2) the number of POS tags used is somewhat arbitrary anyway because there is no common consensus of what should be the true number of tags in each language and therefore it seems unreasonable to constrain the model with such a number instead of learning it from the data.", "labels": [], "entities": []}, {"text": "Unsupervised morphology learning is another popular task that has been extensively studied by many authors.", "labels": [], "entities": [{"text": "Unsupervised morphology learning", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6303412715593973}]}, {"text": "Here we are interested in learning concatenative morphology of words, meaning the substrings of the word corresponding to morphemes that, when concatenated, will give the lexical representation of the word type.", "labels": [], "entities": []}, {"text": "For the rest of the paper we will refer to this task as (morphological) segmentation.", "labels": [], "entities": []}, {"text": "Several unsupervised POS induction systems make use of morphological features) and this approach has been empirically proved to be helpful (.", "labels": [], "entities": []}, {"text": "Ina similar fashion one could think that knowing POS tags could be useful for learning morphological segmentations and in this paper we will study this hypothesis.", "labels": [], "entities": [{"text": "learning morphological segmentations", "start_pos": 78, "end_pos": 114, "type": "TASK", "confidence": 0.7478776971499125}]}, {"text": "In this paper we will build a model that combines POS induction and morphological segmentation into one learning problem.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9233218729496002}]}, {"text": "We will show that the unsupervised learning of both of these tasks in the same model will lead to better results than learning both tasks separately with the gold standard data of the other task provided.", "labels": [], "entities": []}, {"text": "We will also demonstrate that our model produces state-of-the-art results on POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.7770945727825165}]}, {"text": "As opposed to the compared methods, our model also induces the number of tags from data.", "labels": [], "entities": []}, {"text": "In the following, section 2 gives the overview of the Dirichlet Processes, section 3 describes the model setup followed by the description of inference procedures in section 4, experimental results are presented in section 5, section 6 summarizes the previous work and last section concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test the POS induction part of the model on all languages in the Multext-East corpora as well as on the free corpora from CONLL-X Shared Task 1 for Dutch, Danish, Swedish and Portuguese.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.8483389317989349}, {"text": "Multext-East corpora", "start_pos": 68, "end_pos": 88, "type": "DATASET", "confidence": 0.9578000903129578}]}, {"text": "The evaluation of morphological segmentations is based on the Morpho Challenge gold segmented wordlists for English, Finnish and Turkish 2 . We gathered the sentences from Europarl corpus 3 for English and Finnish, and use the Turkish text data from the Morpho Challenge 2009 4 . Estonian gold standard segmentations have been obtained from the Estonian morphologically annotated corpus . We report three accuracy measures for tagging: greedy one-to-one mapping (1-1)), many-to-one mapping (m-1) and Vmeasure (V-m).", "labels": [], "entities": [{"text": "Morpho Challenge gold segmented wordlists", "start_pos": 62, "end_pos": 103, "type": "DATASET", "confidence": 0.8768826603889466}, {"text": "Europarl corpus 3", "start_pos": 172, "end_pos": 189, "type": "DATASET", "confidence": 0.9686995347340902}, {"text": "Morpho Challenge 2009 4", "start_pos": 254, "end_pos": 277, "type": "DATASET", "confidence": 0.8018827587366104}, {"text": "accuracy", "start_pos": 405, "end_pos": 413, "type": "METRIC", "confidence": 0.9980362057685852}, {"text": "Vmeasure (V-m)", "start_pos": 500, "end_pos": 514, "type": "METRIC", "confidence": 0.899589478969574}]}, {"text": "Segmentation is evaluated on the basis of standard F-score which is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.995473325252533}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9994820952415466}, {"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.9968292117118835}]}, {"text": "For each experiment, we made five runs with random initializations and report the results of the median.", "labels": [], "entities": []}, {"text": "The sampler was run 200 iterations for burnin, after which we collected 5 samples, letting the sampler to run for another 200 iterations between each two sample.", "labels": [], "entities": []}, {"text": "We start with 15 segmenting iterations during each Gibbs iteration to enable the segmentation sampler to burnin to the current tagging state, and gradually reduce this number to one.", "labels": [], "entities": []}, {"text": "Segmentation likelihood term for tagging is calculated on the basis of the last segment only because this setting gave the best results in preliminary experiments and it also makes the whole computation less expensive.", "labels": [], "entities": [{"text": "Segmentation likelihood term", "start_pos": 0, "end_pos": 28, "type": "METRIC", "confidence": 0.787237306435903}, {"text": "tagging", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.9758014678955078}]}, {"text": "The first set of experiments was conducted to test the model tagging accuracy on different languages mentioned above.", "labels": [], "entities": [{"text": "model tagging", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.5486752688884735}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.7872865796089172}]}, {"text": "The results obtained were in general slightly lower than the current state-of-the-art and the number of tags learned was generally bigger than the number of gold standard tags.", "labels": [], "entities": []}, {"text": "We observed that different components making up the corpus logarithmic probability have different magnitudes.", "labels": [], "entities": []}, {"text": "In particular, we found that the emission probability component in log-scale is roughly four times smaller than the transition probability.", "labels": [], "entities": []}, {"text": "This observation motivated introducing the likelihood scaling heuristic into the model to scale the emission probability up.", "labels": [], "entities": []}, {"text": "We tried a couple of different scaling factors on Multext-East English corpus and then set its value to 4 for all languages for the rest of the experiments.", "labels": [], "entities": [{"text": "Multext-East English corpus", "start_pos": 50, "end_pos": 77, "type": "DATASET", "confidence": 0.9802523652712504}]}, {"text": "This improved the tagging results consistently across all languages.", "labels": [], "entities": [{"text": "tagging", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9677668809890747}]}, {"text": "POS induction results are given in.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6637692451477051}]}, {"text": "When comparing these results with the recently published results on the same corpora we can see that our results compare favorably with the state-of-the-art, resulting with the best published results in many occasions.", "labels": [], "entities": []}, {"text": "The number of tag clusters learned by the model corresponds surprisingly well to the number of true coarse-grained gold standard tags across all languages.", "labels": [], "entities": []}, {"text": "There are two things to note here: 1) the tag distributions learned are influenced by the likelihood scaling heuristic and more experiments are needed in order to fully understand the characteristics and influence of this heuristic; 2) as the model is learning the coarse-grained tagset consistently in all languages, it might as well be that the POS tags are not as dependent on the morphology as we assumed, especially in inflectional languages with many derivational and inflectional suffixes, because otherwise the model should have learned a more fine-grained tagset.", "labels": [], "entities": []}, {"text": "Segmentation results are presented in.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.8054636716842651}]}, {"text": "For each language, we report the lexicon-based precision, recall and F-measure, the number of word types in the corpus and and number of word types with gold segmentation available.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9980192184448242}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9994459748268127}, {"text": "F-measure", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9983920454978943}]}, {"text": "The reported standard deviations show that the segmentations obtained are stable across different runs which is probably due to the blocked sampler.", "labels": [], "entities": []}, {"text": "We give the segmentation results both with and without likelihood scaling heuristic and denote that while the emission likelihood scaling improves the tagging accuracy, it actually degrades the segmentation results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.94822758436203}]}, {"text": "It can also be seen that in general precision score is better but for Estonian recall is higher.", "labels": [], "entities": [{"text": "precision score", "start_pos": 36, "end_pos": 51, "type": "METRIC", "confidence": 0.9585596323013306}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.965064287185669}]}, {"text": "This can be explained by the characteristics of the evaluation data sets.", "labels": [], "entities": []}, {"text": "For English, Finnish and Turkish we use the Morpho Challenge wordlists where the gold standard segmentations are fine-grained, separating both inflectional and derivational morphemes.", "labels": [], "entities": [{"text": "Morpho Challenge wordlists", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.9198843042055765}]}, {"text": "Especially derivational morphemes are hard to learn with pure data-driven methods with no knowledge about semantics and thus it can result in undersegmentation.", "labels": [], "entities": []}, {"text": "On the other hand, Estonian corpus separates only inflectional morphemes which thus leads to higher recall.", "labels": [], "entities": [{"text": "Estonian corpus", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9208947718143463}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.997527539730072}]}, {"text": "Some difference can also come from the fact that the sets of gold-segmented word types for other languages are much smaller than in Esto- nian and thus it would be interesting to see whether and how the results would change if the evaluation could be done on all word types in the corpus for other languages as well.", "labels": [], "entities": []}, {"text": "In general, undersegmentation is more acceptable than oversegmentation, especially when the aim is to use the resulting segmentations in some NLP application.", "labels": [], "entities": []}, {"text": "Next, we studied the convergence characteristics of our model.", "labels": [], "entities": []}, {"text": "For these experiments we made five runs with random initializations on Estonian corpus and let the sampler run up to 1100 iterations.", "labels": [], "entities": [{"text": "Estonian corpus", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.9715588688850403}]}, {"text": "Samples were taken after each ten iterations.", "labels": [], "entities": []}, {"text": "shows the log-likelihood of the samples plotted against iteration number.", "labels": [], "entities": []}, {"text": "Dark lines show the averages over five runs and gray lines in the background are the likelihoods of real samples showing also the variance.", "labels": [], "entities": []}, {"text": "We first calculated the full likelihood of the samples (the solid line) that showed a quick improvement during the first few iterations and then stabilized by continuing with only slow improvements overtime.", "labels": [], "entities": []}, {"text": "We then divided the full likelihood into two factors in order to seethe contribution of both tagging and segmentation parts separately.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 105, "end_pos": 117, "type": "TASK", "confidence": 0.8388392329216003}]}, {"text": "The results are quite surprising.", "labels": [], "entities": []}, {"text": "It turned out that the random tagging initializations are very good in terms of probability and as a matter of fact much better than the data can support and thus the tagging likelihood drops quite significantly after the first iteration and then continues with very slow improvements.", "labels": [], "entities": [{"text": "tagging initializations", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7913077771663666}]}, {"text": "The matters are totally different with segmentations where the initial random segmentations result in a low likelihood that improves heavily: Tagging results for different languages.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 142, "end_pos": 149, "type": "TASK", "confidence": 0.9783479571342468}]}, {"text": "For each language we report median one-to-one (1-1), many-to-one (m-1) and V-measure (V-m) together with standard deviation from five runs where median is taken over V-measure.  with the first few iterations and then stabilizes but still continues to improve overtime.", "labels": [], "entities": [{"text": "overtime", "start_pos": 259, "end_pos": 267, "type": "METRIC", "confidence": 0.9723402857780457}]}, {"text": "The explanation for this kind of model behaviour needs further studies and we leave it for future work.", "labels": [], "entities": []}, {"text": "plots the V-measure against the tagging factor of the log-likelihood for all samples.", "labels": [], "entities": [{"text": "V-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9665740132331848}]}, {"text": "It can be seen that the lower V-measure values are more spread out in terms of likelihood.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.9558082222938538}]}, {"text": "These points correspond to the early samples of the runs.", "labels": [], "entities": []}, {"text": "The samples taken later during the runs are on the right in the figure and the positive correlation between the V-measure and likelihood values can be seen.", "labels": [], "entities": [{"text": "V-measure", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9420050978660583}, {"text": "likelihood", "start_pos": 126, "end_pos": 136, "type": "METRIC", "confidence": 0.9191316962242126}]}, {"text": "Next we studied whether the morphological seg-  mentations and POS tags help each other in the learning process.", "labels": [], "entities": []}, {"text": "For that we conducted two semisupervised experiments on Estonian corpus.", "labels": [], "entities": [{"text": "Estonian corpus", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9544568955898285}]}, {"text": "First we provided gold standard segmentations to the model and let it only learn the tags.", "labels": [], "entities": []}, {"text": "Then, we gave the model gold standard POS tags and only learned the segmentations.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "We also added the results from joint unusupervised learning for easier comparison.", "labels": [], "entities": []}, {"text": "Unfortunately we cannot repeat this experiment on other languages to see whether the results are stable across different languages because to our knowledge there is no other free corpus with both gold standard POS tags and morphological segmentations available.", "labels": [], "entities": []}, {"text": "From the results it can be seen that the unsupervised learning results for both tagging and segmentation are better than the results obtained from semisupervised learning.", "labels": [], "entities": [{"text": "tagging", "start_pos": 80, "end_pos": 87, "type": "TASK", "confidence": 0.9578788876533508}]}, {"text": "This is surprising because one would assume that providing gold standard data would lead to better results.", "labels": [], "entities": []}, {"text": "On the other hand, these results are encouraging, showing that learning two dependent tasks in a joint model by unsupervised manner can be as good or even better than learning the same tasks separately and providing the gold standard data as features.", "labels": [], "entities": []}, {"text": "Finally, we learned the morphological segmentations with the state-of-the-art morphology induction system Morfessor baseline) and report the best results in the last row of.", "labels": [], "entities": []}, {"text": "Apparently, our joint model cannot beat Morfessor in morphological segmentation and when 6 http://www.cis.hut.fi/projects/morpho/ using the emission likelihood scaling that influences the tagging results favorably, the segmentation results get even worse.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.7046320736408234}]}, {"text": "Altough the semisupervised experiments showed that there are dependencies between tags and segmentations, the conducted experiments do not reveal of how to use these dependencies for helping the POS tags to learn better morphological segmentations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Tagging results for different languages. For each language we report median one-to-one (1-1), many-to-one  (m-1) and V-measure (V-m) together with standard deviation from five runs where median is taken over V-measure.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9728004336357117}]}, {"text": " Table 2: Segmentation results on different languages. Results are calculated based on word types. For each language  we report precision, recall and F1 measure, number of word types in the corpus and number of word types with gold  standard segmentation available. For each language we report the segmentation result without and with emission  likelihood scaling (without LLS and with LLS respectively).", "labels": [], "entities": [{"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.999651312828064}, {"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9995397329330444}, {"text": "F1 measure", "start_pos": 150, "end_pos": 160, "type": "METRIC", "confidence": 0.9840201139450073}, {"text": "emission  likelihood scaling", "start_pos": 335, "end_pos": 363, "type": "METRIC", "confidence": 0.8942988316218058}]}, {"text": " Table 3: Tagging and segmentation results on Estonian  Multext-East corpus (Learned seg and Learned tag) com- pared to the semisupervised setting where segmentations  are fixed to gold standard (Fixed seg) and tags are fixed  to gold standard (Fixed tag). Finally the segmentatation  results from Morfessor system for comparison are pre- sented.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9544451832771301}, {"text": "Estonian  Multext-East corpus", "start_pos": 46, "end_pos": 75, "type": "DATASET", "confidence": 0.864470918973287}, {"text": "Morfessor system", "start_pos": 298, "end_pos": 314, "type": "DATASET", "confidence": 0.9247508943080902}]}, {"text": " Table 3. Apparently, our joint model cannot beat  Morfessor in morphological segmentation and when", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.743608832359314}]}]}