{"title": [], "abstractContent": [{"text": "This paper reports on an implementation of a multimodal grammar of speech and co-speech gesture within the LKB/PET grammar engineering environment.", "labels": [], "entities": [{"text": "LKB/PET grammar engineering", "start_pos": 107, "end_pos": 134, "type": "DATASET", "confidence": 0.7858469367027283}]}, {"text": "The implementation extends the English Resource Grammar (ERG, Flickinger (2000)) with HPSG types and rules that capture the form of the linguistic signal, the form of the gestural signal and their relative timing to constrain the meaning of the multimodal action.", "labels": [], "entities": [{"text": "English Resource Grammar (ERG, Flickinger (2000))", "start_pos": 31, "end_pos": 80, "type": "DATASET", "confidence": 0.8121377408504487}]}, {"text": "The grammar yields a single parse tree that integrates the spoken and gestural modality thereby drawing on standard semantic composition techniques to derive the multimodal meaning representation.", "labels": [], "entities": []}, {"text": "Using the current machinery, the main challenge for the grammar engineer is the non-linear input: the modalities can overlap temporally.", "labels": [], "entities": []}, {"text": "We capture this by identical speech and gesture token edges.", "labels": [], "entities": []}, {"text": "Further, the semantic contribution of gestures is encoded by lexical rules transforming a speech phrase into a mul-timodal entity of conjoined spoken and gestu-ral semantics.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our aim is to regiment the form-meaning mapping of multimodal actions consisting of speech and cospeech gestures.", "labels": [], "entities": []}, {"text": "The language of study is English, and the gestures of interest are depicting-the hand depicts the referent-and deictic-the hand points at the referent's spatial coordinates.", "labels": [], "entities": []}, {"text": "Motivation for encoding the form-meaning mapping in the grammar stems from the fact that form effects judgments of multimodal grammaticality: e.g., in (1) 1 the gesture performance along with The speech item where the gesture is performed is marked by underlining, and the accented item is given in uppercase.", "labels": [], "entities": []}, {"text": "the unaccented \"called\" in a single prosodic phrase seems ill-formed despite the gesture depicting an aspect of the referent-the act of calling.", "labels": [], "entities": []}, {"text": "(1) * Your MOTHER called . .", "labels": [], "entities": [{"text": "MOTHER", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9893353581428528}]}, {"text": "This intuitive judgment is inline with the empirical findings of who observed that prosody influences the perception of temporally misaligned speech-and-gesture signals as ill-formed.", "labels": [], "entities": []}, {"text": "Further, Alahverdzhieva and Lascarides (2010) established empirically that the gesture performance can be predicted from the prosodic prominence in speech and that gestures not overlapping subject NPs cannot be semantically related with that subject NP.", "labels": [], "entities": []}, {"text": "The fact that speech-and-gesture integration is informed by the form of the linguistic signal suggests formalising the integration within the grammar.", "labels": [], "entities": [{"text": "speech-and-gesture integration", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.6937921643257141}]}, {"text": "Alternatively, integrating the gestural contribution by discourse update would involve pragmatic reasoning accessing information about linguistic form, disrupting the transition between syntax/semantics and pragmatics.", "labels": [], "entities": []}, {"text": "The work is set within HPSG -a constraint-based grammar framework with the different types and rules organised in a hierarchy.", "labels": [], "entities": []}, {"text": "The semantic information, derived in parallel with syntax, is expressed in Minimal Recursion Semantics (MRS) which supports a high level of underspecifiability ().", "labels": [], "entities": []}, {"text": "This is useful for computing gesture meaning since even through discourse processing not all semantic information resolves to a specific interpretation.", "labels": [], "entities": [{"text": "computing gesture meaning", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.643736352523168}]}, {"text": "The rest of the paper is structured as follows: \u00a72 provides theoretical background, \u00a73 details the implementation and \u00a74 discusses the evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation was performed against a test suite designed in analogy to the traditional phenomenonbased test-suites (: manuallycrafted to ensure coverage of well-formed and illformed data, but inspired by an examination of natural data.", "labels": [], "entities": []}, {"text": "We systematically tested syntactic phenomena (intransitivity, transitivity, complex NPs, coordination, negation and modification) over well-formed and ill-formed examples where the ill-formed items were derived by means of the following operations: prosodic permutation (varying the prosodic markedness, e.g., from (4a) we derive (4b) to reflect intuitions of native speakers); gesture variation (testing distinct gesture types) and temporal permutation (moving the gestural performance over the distinct speech items).", "labels": [], "entities": []}, {"text": "The test set contained 471 multimodal items (72% well-formed) covering the full range of prosodic (prosodic markedness and unmarkedness) and gesture (the span of depicting/deictic gesture and its temporal relation to the prosodically marked elements) permutations.", "labels": [], "entities": []}, {"text": "The gestural vocabulary was limited since a larger gesture lexicon has no effects on the performance.", "labels": [], "entities": []}, {"text": "To test the grammar, we used the [incr tsdb()] 2 competence and performance tool which enables batch processing of test items and which creates a coverage profile of the test set (see).", "labels": [], "entities": []}, {"text": "The values are as follows: the left column separates the items per aggregation criterion (the length of test items); the next column shows the number of test items per aggregate; then we have the number of grammatical items; average length of test item; average number of lexical items; average number of distinct analyses and total coverage.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Coverage Profile of Test Items generated by [incr tsdb()]", "labels": [], "entities": []}]}