{"title": [{"text": "Translation-Based Projection for Multilingual Coreference Resolution", "labels": [], "entities": [{"text": "Multilingual Coreference Resolution", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.7368110517660776}]}], "abstractContent": [{"text": "To build a coreference resolver fora new language, the typical approach is to first coreference-annotate documents from this target language and then train a resolver on these annotated documents using supervised learning techniques.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.8029093444347382}]}, {"text": "However, the high cost associated with manually coreference-annotating documents needed by a supervised approach makes it difficult to deploy coreference technologies across a large number of natural languages.", "labels": [], "entities": []}, {"text": "To alleviate this corpus annotation bottleneck, we examine a translation-based projection approach to multilingual corefer-ence resolution.", "labels": [], "entities": [{"text": "multilingual corefer-ence resolution", "start_pos": 102, "end_pos": 138, "type": "TASK", "confidence": 0.5881804426511129}]}, {"text": "Experimental results on two target languages demonstrate the promise of our approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Noun phrase (NP) coreference resolution is the task of determining which NPs (or mentions) refer to each real-world entity in a document.", "labels": [], "entities": [{"text": "Noun phrase (NP) coreference resolution", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6351288173879895}]}, {"text": "Recent years have witnessed a surge of interest in multilingual coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.788578987121582}]}, {"text": "For instance, the ACE 2004/2005 evaluations and SemEval-2010 Shared Task 1 have both involved coreference resolution in multiple languages.", "labels": [], "entities": [{"text": "ACE 2004/2005 evaluations", "start_pos": 18, "end_pos": 43, "type": "DATASET", "confidence": 0.8706812858581543}, {"text": "coreference resolution", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.9357447624206543}]}, {"text": "As evidenced by the participants in these evaluations, the most common approach to building a resolver fora new language is supervised, which involves training a resolver on coreference-annotated documents from the target language.", "labels": [], "entities": []}, {"text": "Although supervised approaches work reasonably well, they present a challenge to deploying coreference technologies across a large number of natural languages.", "labels": [], "entities": []}, {"text": "Specifically, for each new language of interest, one has to hire native speakers of the language to go through the labor-intensive, timeconsuming process of hand-annotating a potentially large number of documents with coreference annotation before a supervised resolver can be trained.", "labels": [], "entities": []}, {"text": "One may argue that a potential solution to this corpus annotation bottleneck is to employ an unsupervised or heuristic approach to coreference resolution, especially in light of the fact that they have recently started to rival their supervised counterparts.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.9676211476325989}]}, {"text": "However, by adopting these approaches, we are simply replacing the corpus annotation bottleneck by another, possibly equally serious, bottleneck, the knowledge acquisition bottleneck.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 150, "end_pos": 171, "type": "TASK", "confidence": 0.7529117166996002}]}, {"text": "Specifically, in these approaches, one has to employ knowledge of the target language to design coreference rules (e.g.,,,) or sophisticated generative models (e.g.,,) to combine the available knowledge sources.", "labels": [], "entities": []}, {"text": "One could argue that designing coreference rules and generative models may not be as timeconsuming as annotating a large coreference corpus.", "labels": [], "entities": []}, {"text": "This maybe true fora well-studied language like English, where we can easily compose a rule that disallows coreference between two mentions if they disagree in number and gender, for instance.", "labels": [], "entities": [{"text": "coreference between two mentions", "start_pos": 107, "end_pos": 139, "type": "TASK", "confidence": 0.8532750606536865}]}, {"text": "However, computing these features may not be as simple as we hope fora language like Chinese: the lack of morphology complicates the determination of number information, and the fact that most Chinese first names are used by both genders makes gender determination difficult.", "labels": [], "entities": [{"text": "gender determination", "start_pos": 244, "end_pos": 264, "type": "TASK", "confidence": 0.6575804948806763}]}, {"text": "The difficulty in accurately computing features translates to difficulties in composing coreference rules: for example, the aforementioned rule involving gender and number agreement, as well as rules that implement traditional linguistic constraints on coreference, may no longer be accurate and desirable to have if the features involved cannot be accurately computed.", "labels": [], "entities": []}, {"text": "Consequently, we believe that research in multilingual coreference resolution will continue to be dominated by supervised approaches.", "labels": [], "entities": [{"text": "multilingual coreference resolution", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.6740960876146952}]}, {"text": "Given the high cost of annotating data with coreference chains, it is crucial to explore methods for obtaining annotated data in a cost-effective manner.", "labels": [], "entities": []}, {"text": "Motivated in part by this observation, we examine one such method that has recently shown promise fora variety of NLP tasks, translation-based projection, which is composed of three steps.", "labels": [], "entities": [{"text": "translation-based projection", "start_pos": 125, "end_pos": 153, "type": "TASK", "confidence": 0.9370042383670807}]}, {"text": "To coreference annotate a text in the target language, we (1) machine-translate it to a resource-rich language (henceforth the source language); (2) automatically produce the desired linguistic annotations (which in our case are coreference annotations) on the translated text using the linguistic tool developed for the source language (which in our case is a coreference resolver) ; and (3) project the annotations from the source language to the target language.", "labels": [], "entities": []}, {"text": "Unlike supervised approaches, this projection approach does not require any coreference-annotated data from the target language.", "labels": [], "entities": []}, {"text": "Equally importantly, unlike its unsupervised counterparts, this approach does not require that we have any linguistic knowledge of the target language.", "labels": [], "entities": []}, {"text": "In fact, we have no knowledge of the target languages we employ in our evaluation.", "labels": [], "entities": []}, {"text": "One of our goals is to examine the feasibility of building a coreference resolver fora language for which we have no coreference-annotated data and no linguistic knowledge of the language.", "labels": [], "entities": []}, {"text": "Recall that we view projection as an approach for alleviating the corpus annotation bottleneck, not as a solution to the multilingual coreference resolution problem.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.735622376203537}]}, {"text": "In fact, though rarely emphasized in previous work on applying projection, we note that projection alone cannot be used to solve multilingual NLP problems, including coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 166, "end_pos": 188, "type": "TASK", "confidence": 0.96232870221138}]}, {"text": "The reason is that every language has its own idiosyncrasies with respect to linguistic properties, and projection simply cannot produce annotations capturing those properties that are specific to the target language.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to explore the extent to which projection, which does not require that we have any knowledge of the target language, can push the limits of multilingual coreference resolution.", "labels": [], "entities": [{"text": "multilingual coreference resolution", "start_pos": 166, "end_pos": 201, "type": "TASK", "confidence": 0.6687839130560557}]}, {"text": "If our results indicate that projection is a promising approach, then the automatic coreference annotations it produces can be used to augment the manual annotations that capture the properties specific to the target language, thus alleviating the corpus annotation bottleneck.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our MT-based projection approach for each of the three settings described in Section 3.", "labels": [], "entities": [{"text": "MT-based projection", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.9677440822124481}]}, {"text": "We use the Spanish and Italian data sets from the SemEval-2010 shared task on Coreference Resolution in Multiple Languages.", "labels": [], "entities": [{"text": "Coreference Resolution in Multiple Languages", "start_pos": 78, "end_pos": 122, "type": "TASK", "confidence": 0.86708505153656}]}, {"text": "11 Each data set is composed of a training set and a test set.", "labels": [], "entities": []}, {"text": "Statistics of these data sets are shown in The data sets can be downloaded from http://stel.", "labels": [], "entities": []}, {"text": "ub.edu/semeval2010-coref/datasets.", "labels": [], "entities": []}, {"text": "11 Note, however, that our approach is equally applicable to other languages evaluated in the shared task., and BLANC (Recasens and Hovy, 2011), which were downloaded from the shared task website (see Footnote 10).", "labels": [], "entities": [{"text": "BLANC", "start_pos": 112, "end_pos": 117, "type": "METRIC", "confidence": 0.9903948903083801}]}], "tableCaptions": [{"text": " Table 1. As we can see, each  feature is either relational, capturing the relation be- tween m j and m k , or non-relational, capturing the  linguistic property of m k . The possible values of  a relational feature (except LEXICAL) are C (com- patible), I (incompatible), and NA (the comparison cannot be made due to missing data). For a non- relational feature, we refer the reader to the data sets  for the list of possible values.", "labels": [], "entities": [{"text": "LEXICAL", "start_pos": 224, "end_pos": 231, "type": "METRIC", "confidence": 0.9457679390907288}]}, {"text": " Table 2: Statistics of the data sets.", "labels": [], "entities": []}, {"text": " Table 3: Results for Spanish", "labels": [], "entities": []}, {"text": " Table 4: Results for Italian", "labels": [], "entities": [{"text": "Italian", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.7203482985496521}]}]}