{"title": [], "abstractContent": [{"text": "We present an active learning method for coreference resolution that is novel in three respects.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.9728540480136871}]}, {"text": "(i) It uses bootstrapped neighborhood pooling, which ensures a class-balanced pool even though gold labels are not available.", "labels": [], "entities": []}, {"text": "(ii) It employs neighborhood selection, a selection strategy that ensures coverage of both positive and negative links for selected markables.", "labels": [], "entities": []}, {"text": "(iii) It is based on a query-by-committee selection strategy in contrast to earlier uncertainty sampling work.", "labels": [], "entities": []}, {"text": "Experiments show that this new method outperforms random sampling in terms of both annotation effort and peak performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution (CR) -the task of determining if two expressions in natural language text refer to the same real-world entity -is an important NLP task.", "labels": [], "entities": [{"text": "Coreference resolution (CR)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.938458263874054}]}, {"text": "One popular approach to CR is supervised classification.", "labels": [], "entities": [{"text": "CR", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9816988706588745}, {"text": "supervised classification", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.6842461973428726}]}, {"text": "This approach needs manually labeled training data that is expensive to create.", "labels": [], "entities": []}, {"text": "Active learning (AL) is a technique that can reduce this cost by setting up an interactive training/annotation loop that selects and annotates training examples that are maximally useful for the classifier that is being trained.", "labels": [], "entities": [{"text": "Active learning (AL)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7434736549854278}]}, {"text": "However, while AL has been proven successful for many other NLP tasks, such as partof-speech tagging (, parsing (), text classification () and named entity recognition (), AL has not been successfully applied to coreference resolution so far.", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.8214657306671143}, {"text": "parsing", "start_pos": 104, "end_pos": 111, "type": "TASK", "confidence": 0.963094174861908}, {"text": "text classification", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7721869349479675}, {"text": "named entity recognition", "start_pos": 143, "end_pos": 167, "type": "TASK", "confidence": 0.6748332778612772}, {"text": "coreference resolution", "start_pos": 212, "end_pos": 234, "type": "TASK", "confidence": 0.9726965129375458}]}, {"text": "In this paper, we present a novel approach to AL for CR based on query-by-committee sampling and bootstrapping and show that it performs better than a number of baselines.", "labels": [], "entities": [{"text": "CR", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.8422180414199829}]}], "datasetContent": [{"text": "We use the mention-pair CR system SUCRE ().", "labels": [], "entities": []}, {"text": "The link classifier is a decision tree and the clustering algorithm a variant of best-first clustering).", "labels": [], "entities": []}, {"text": "SUCRE results were competitive in SEMEVAL 2010).", "labels": [], "entities": [{"text": "SUCRE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.5004448890686035}, {"text": "SEMEVAL 2010", "start_pos": 34, "end_pos": 46, "type": "TASK", "confidence": 0.5954829454421997}]}, {"text": "We implemented N-pool bootstrapping and selection methods on top of the AL framework of.", "labels": [], "entities": []}, {"text": "We use the English part of the SemEval-2010 CR task data set, a subset of OntoNotes 2.0 ().", "labels": [], "entities": [{"text": "SemEval-2010 CR task data set", "start_pos": 31, "end_pos": 60, "type": "DATASET", "confidence": 0.7855814754962921}]}, {"text": "Training and test set sizes are about 96,000 and 24,000 words.", "labels": [], "entities": []}, {"text": "Since we focus on the coreference resolution subtask, we use the true mention boundaries for the markables.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8550556004047394}]}, {"text": "The pool for example selection is created by pairing every markable with every preceding markable within a window of 100 markables.", "labels": [], "entities": []}, {"text": "This yields a pool of 1.7 million links, of which only 1.5% are labeled as coreferent.", "labels": [], "entities": []}, {"text": "This drastic class imbalance necessitates our bootstrapped class-balancing.", "labels": [], "entities": []}, {"text": "We run two baseline experiments for comparison: (i) random selection on the entire pool, without any class balancing, and (ii) random selection from a gold-label-based N-pool.", "labels": [], "entities": []}, {"text": "We chose to use gold neighborhood information for the baseline to remove the influence of badly predicted neighbor- hoods and focus on the performance of random sampling.", "labels": [], "entities": []}, {"text": "Hence, this is a very strong random baseline.", "labels": [], "entities": []}, {"text": "The performance with bootstrapped neighborhoods would likely be lower.", "labels": [], "entities": []}, {"text": "We run 10 runs of each experiment, starting from 10 different seed sets.", "labels": [], "entities": []}, {"text": "These seed sets contained 200 links, drawn randomly from the entire pool, for random sampling; and 20 neighborhoods for neighborhood selection, with a comparable number of links.", "labels": [], "entities": []}, {"text": "We verified that each seed set contained instances of both classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of different methods. All measures are F 1 measures.", "labels": [], "entities": [{"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9868987500667572}]}]}