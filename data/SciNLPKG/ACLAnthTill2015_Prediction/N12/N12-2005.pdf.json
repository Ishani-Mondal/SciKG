{"title": [{"text": "Unified Extraction of Health Condition Descriptions", "labels": [], "entities": [{"text": "Unified Extraction of Health Condition Descriptions", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7504569639762243}]}], "abstractContent": [{"text": "This paper discusses a method for identifying diabetes symptoms and conditions in free text electronic health records in Bulgarian.", "labels": [], "entities": [{"text": "identifying diabetes symptoms", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.839015543460846}]}, {"text": "The main challenge is to automatically recognise phrases and paraphrases for which no \"canon-ical forms\" exist in any dictionary.", "labels": [], "entities": []}, {"text": "The focus is on extracting blood sugar level and body weight change which are some of the dominant factors when diagnosing diabetes.", "labels": [], "entities": []}, {"text": "A combined machine-learning and rule-based approach is applied.", "labels": [], "entities": []}, {"text": "The experiment is performed on 2031 sentences of diabetes case history.", "labels": [], "entities": []}, {"text": "The F-measure varies between 60 and 96% in the separate processing phases.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9987862706184387}]}], "introductionContent": [{"text": "Electronic Health Records (EHRs) area rich source of information regarding patient's health condition and treatment overtime but they often exist as free text only.", "labels": [], "entities": []}, {"text": "Currently great efforts are put into structuring such data and making them available for further automatic processing, the so-called secondary use of EHRs.", "labels": [], "entities": []}, {"text": "Following this line of work in this paper we present a pilot study for extracting condition descriptions from EHRs in Bulgarian with the help of NLP techniques thus making a step toward the structuring of the free text.", "labels": [], "entities": [{"text": "extracting condition descriptions from EHRs in Bulgarian", "start_pos": 71, "end_pos": 127, "type": "TASK", "confidence": 0.725371275629316}]}, {"text": "The specificity of the EHRs as a combination of biomedical terminology in an underresourced language and a source of valuable health-care data makes them attractive for various medical and language research tasks.", "labels": [], "entities": []}, {"text": "We present an algorithm which comprises machine learning (ML) techniques and rule-based analysis to automatically identify phrases and paraphrases, for which no \"canonical forms\" exist in any dictionary, with minimal effort.", "labels": [], "entities": []}, {"text": "We analyse anonymous EHRs of patients diagnosed with diabetes.", "labels": [], "entities": []}, {"text": "We focus on extracting the levels of blood sugar and body weight change (examples are given in table 1) which are some of the dominant factors when diagnosing diabetes but we believe this approach can extend to recognise also other symptoms or medication expressions which have similar record structure.", "labels": [], "entities": []}, {"text": "We extract information which is on one hand very important for the professionals and on the other hand not directly observable in a collection of unstructured documents because of its composite meaning.", "labels": [], "entities": []}, {"text": "In Bulgarian EHRs laboratory data is sometimes present inline in the text only and means for extracting such information from the plain text message are often needed.", "labels": [], "entities": [{"text": "Bulgarian EHRs laboratory data", "start_pos": 3, "end_pos": 33, "type": "DATASET", "confidence": 0.6736234053969383}]}, {"text": "The paper is structured as follows: section 2 presents related studies, section 4 describes the method, and section 3 the experiments.", "labels": [], "entities": []}, {"text": "The results are given in section 5 and the conclusion in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Source Data This work is done on free text EHRs of diabetic patients submitted by the Endocrinology Hospital of the Medical University in Sofia.", "labels": [], "entities": []}, {"text": "The health conditions are written in the case history which describes the diabetes development, complications, their corresponding treatment, etc.", "labels": [], "entities": []}, {"text": "Symptom descriptions are written within a single sentence (sometimes other symptoms are described in the same sentence too) as shown in table 1.", "labels": [], "entities": []}, {"text": "Our training corpus is a subset of anamnesis sen- tences regarding only symptom descriptions.", "labels": [], "entities": []}, {"text": "It is annotated with symptom type on sentence level and with symptom description on token level.", "labels": [], "entities": []}, {"text": "These are excerpts from from 100 epicrises.", "labels": [], "entities": []}, {"text": "All sentences are marked with class \"bs\" (blood sugar), \"bwc\" (body weight change) or another symptom.", "labels": [], "entities": [{"text": "class \"bs\" (blood sugar), \"bwc\" (body weight change)", "start_pos": 30, "end_pos": 82, "type": "METRIC", "confidence": 0.8218475825646344}]}, {"text": "The sentences that describe more symptoms have more than one label.", "labels": [], "entities": []}, {"text": "These data was used for learning the rules and the vocabularies.", "labels": [], "entities": []}, {"text": "The experimental/test dataset consists of 2031 anamnesis sentences annotated with symptoms.", "labels": [], "entities": []}, {"text": "The documents are manually sentence split and automatically tokenized.", "labels": [], "entities": []}, {"text": "To overcome the inflexion and gain a wider coverage of the rules we also use stemmed forms.", "labels": [], "entities": []}, {"text": "Vocabularies The algorithm relies on a set of specific vocabularies manually built from the annotated training set.", "labels": [], "entities": []}, {"text": "We build a Focal Term Vocabulary which contains words and phrases signalling the presence of the health condition description (e.g. \"glycemic control\", \"hypoglycemia\" etc.).", "labels": [], "entities": []}, {"text": "It is used for defining the condition in phase 2.", "labels": [], "entities": []}, {"text": "All single words which appear in this vocabulary except for the stop words form the so called Key Term Vocabulary used in the phase 1 classification task.", "labels": [], "entities": [{"text": "phase 1 classification task", "start_pos": 126, "end_pos": 153, "type": "TASK", "confidence": 0.6979470700025558}]}, {"text": "There are two vocabularies containing border terms: one with rightmost context border expressions (Right Border Vocabulary); and one with left border expressions (Left Border Vocabulary).", "labels": [], "entities": []}, {"text": "These are conjunctions and phrases separating the blood sugar level description from another observation preceding it.", "labels": [], "entities": []}, {"text": "Both vocabularies are sorted in descending order by the probability of occurrence associated with each expression as border term.", "labels": [], "entities": []}, {"text": "A Vocabulary of Negation Expressions is also compiled as well as a Vocabulary of Condition Statuses (e.g. \"good\", \"bad\", \"increased\" etc.).", "labels": [], "entities": []}, {"text": "Results from the separate phases of rule-based analysis are shown in table 6.", "labels": [], "entities": [{"text": "rule-based analysis", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.809910237789154}]}, {"text": "At phase 2 the tokens available in the training set are completely recognised; there is a group of tokens which are not available in the training set, but during the phase 1 processing fall into the scope of the expression of interest.", "labels": [], "entities": []}, {"text": "These ones are included to the condition description without having assigned any status class.", "labels": [], "entities": []}, {"text": "Tokens may not be identified for two reasons -they are not available in the training set or they are misplaced (e.g. the target adjective is following the focal expression instead of preceding it, as it happens in all training set examples).", "labels": [], "entities": []}, {"text": "45% of the attributes expressing blood sugar status are recognised and 78.1% espressing body weight.", "labels": [], "entities": []}, {"text": "Although the recall for blood sugar seems to below at this phase, the result is actually good because during the error analysis we found out that 60% of the tokens which were not identified were equivalent.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9994885921478271}]}, {"text": "At phase 3 the main problem for value recognition were the alphanumerical expressions of lab test values which occur comparatively rare and have a wide range of spelling variants (and errors).", "labels": [], "entities": [{"text": "value recognition", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.876142293214798}]}, {"text": "Thus few extraction errors have high influence on the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9987578392028809}]}, {"text": "This problem can be easily overcome by pregenerating a list of alphanumeric expressions and their variations.", "labels": [], "entities": []}, {"text": "The negation at phase 4 was recognised with high accuracy.", "labels": [], "entities": [{"text": "negation", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9838719964027405}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9983571171760559}]}, {"text": "At phase 5 all scope problems for blood sugar related expressions are resolved successfully except for one.", "labels": [], "entities": []}, {"text": "The interval describing the value of the blood sugar was written as \"ot 12 mmol/l do 14 mmol/l\" (from 12 mmol/l to 14 mmol/l) instead of \"from 12 to 14 mmol/l\" like all such examples in the training set.", "labels": [], "entities": [{"text": "ot 12 mmol", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9371494650840759}]}, {"text": "This lead to wrongly recognised right border and only partial recognition of the blood sugar level value.", "labels": [], "entities": [{"text": "blood sugar level value", "start_pos": 81, "end_pos": 104, "type": "METRIC", "confidence": 0.7502992153167725}]}, {"text": "However this issue could be easily overcome by extending the recognition rules with additional \"cosmetic\" clauses for processing of alphanumeric values as suggested above.", "labels": [], "entities": []}, {"text": "It would be helpful for recognition of any symptom to add new lexical alternations and paraphrases in addtion to the stemmed forms in the regex.", "labels": [], "entities": []}, {"text": "Our approach is completely driven by the training set analysis because our goal is to see how far do we get on that base.", "labels": [], "entities": []}, {"text": "The extension of the rules as shown on helped identifying blood sugar descriptions twice.", "labels": [], "entities": [{"text": "identifying blood sugar descriptions", "start_pos": 46, "end_pos": 82, "type": "TASK", "confidence": 0.8689443916082382}]}, {"text": "We believe that such extensions in feature will have higher impact on a larger scale experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Level 1 evaluation. ML vs Rule-based best per- formance.", "labels": [], "entities": [{"text": "ML", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.8257961273193359}]}, {"text": " Table 6: Rule performance by level", "labels": [], "entities": [{"text": "Rule", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9738494753837585}]}]}