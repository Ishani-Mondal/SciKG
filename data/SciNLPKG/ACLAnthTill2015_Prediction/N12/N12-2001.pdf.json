{"title": [{"text": "Finding the Right Supervisor: Expert-Finding in a University Domain", "labels": [], "entities": []}], "abstractContent": [{"text": "Effective knowledge management is a key factor in the development and success of any organisation.", "labels": [], "entities": [{"text": "Effective knowledge management", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6035399834314982}]}, {"text": "Many different methods have been devised to address this need.", "labels": [], "entities": []}, {"text": "Applying these methods to identify the experts within an organisation has attracted a lot of attention.", "labels": [], "entities": []}, {"text": "We look atone such problem that arises within universities on a daily basis but has attracted little attention in the literature, namely the problem of a searcher who is trying to identify a potential PhD supervisor, or, from the perspective of the university's research office, to allocate a PhD application to a suitable supervisor.", "labels": [], "entities": []}, {"text": "We reduce this problem to identifying a ranked list of experts fora given query (representing a research area).", "labels": [], "entities": []}, {"text": "We report on experiments to find experts in a university domain using two different methods to extract a ranked list of candidates: a database-driven method and a data-driven method.", "labels": [], "entities": []}, {"text": "The first one is based on a fixed list of experts (e.g. all members of academic staff) while the second method is based on automatic Named-Entity Recognition (NER).", "labels": [], "entities": [{"text": "Named-Entity Recognition (NER)", "start_pos": 133, "end_pos": 163, "type": "TASK", "confidence": 0.7766367375850678}]}, {"text": "We use a graded weighting based on proximity between query and candidate name to rank the list of candidates.", "labels": [], "entities": []}, {"text": "As a baseline, we use a system that ranks candidates simply based on frequency of occurrence within the top documents .", "labels": [], "entities": []}], "introductionContent": [{"text": "The knowledge and expertise of individuals are significant resources for organisation.", "labels": [], "entities": []}, {"text": "Managing this intangible resource effectively and efficiently constitutes an essential and very important task.", "labels": [], "entities": []}, {"text": "Approaching experts is the primary and most direct way of utilising their knowledge ().", "labels": [], "entities": [{"text": "Approaching experts", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7362092435359955}]}, {"text": "Therefore, it is important to have a means of locating the right experts within organisations.", "labels": [], "entities": []}, {"text": "The expert-finding task can be categorised as an information retrieval task similar to a web search, but where the results are people rather than documents.", "labels": [], "entities": []}, {"text": "An expert-finding system allows users to input a query, and it returns a ranked list of experts.", "labels": [], "entities": []}, {"text": "Here we look at a university context.", "labels": [], "entities": []}, {"text": "We start with a real-world problem which is to identify a list of experts within an academic environment, e.g. a university intranet.", "labels": [], "entities": []}, {"text": "The research reported here is based on an empirical study of a simple but effective method in which a system that applies the concept of expert-finding has been designed and implemented.", "labels": [], "entities": []}, {"text": "The proposed system will contribute to provide an expert-search service to all of the university's stakeholders.", "labels": [], "entities": []}, {"text": "Expert-finding systems require two main resources in order to function: a list of candidates and a collection of data from which the evidence of expertise can be extracted.", "labels": [], "entities": []}, {"text": "We present two approaches to address this problem, a database-driven and a data-driven method using NER.", "labels": [], "entities": []}, {"text": "The main difference between the two methods is the way in which the candidates' list is constructed.", "labels": [], "entities": []}, {"text": "In the database method, the candidates are simply selected from a known list of experts, e.g. the university's academic staff.", "labels": [], "entities": []}, {"text": "In the NER method, the candidates are extracted automatically from the pages returned by an underlying search engine.", "labels": [], "entities": []}, {"text": "This method promises to be more useful for finding experts from a wider (and possibly more up-to-date) range of candidates.", "labels": [], "entities": []}, {"text": "Both methods apply the same ranking function(s), as will be discussed below.", "labels": [], "entities": []}, {"text": "This paper will survey related work in Section 2 and introduce the expert-finding task in a university domain in Section 3.", "labels": [], "entities": []}, {"text": "The process of ranking experts will be discussed in Section 4.", "labels": [], "entities": []}, {"text": "The evaluation will be described in Section 4, followed by a discussion of the experiment's results in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "As with any IR system, evaluation can be difficult.", "labels": [], "entities": [{"text": "IR", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.9832060933113098}]}, {"text": "In the given context one might argue that precision is more important than recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9988079071044922}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.996947705745697}]}, {"text": "In any case, recall can be difficult to measure precisely.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9987326264381409}]}, {"text": "To address these issues we approximate a gold standard as follows.", "labels": [], "entities": []}, {"text": "We selected one school within the university for which a page of research topics with corresponding academics exists In this experiment we take this mapping as a complete set of correct matches.", "labels": [], "entities": []}, {"text": "In this page, there are 371 topics (i.e. potential queries) divided among 28 more general research topics.", "labels": [], "entities": []}, {"text": "Each topic/query is associated with one or more of the school's academic staff.", "labels": [], "entities": []}, {"text": "It is presumed that those names belong to experts on the corresponding topics.", "labels": [], "entities": []}, {"text": "illustrates some general topics with the number of (sub)topic they contain.", "labels": [], "entities": []}, {"text": "The measure used to test the system is recall at the following values {3, 5, 7, 10, 15, 20}.", "labels": [], "entities": [{"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.999491810798645}]}, {"text": "We also measure Mean Average Precision at rank 20 (MAP@20).", "labels": [], "entities": [{"text": "Mean Average", "start_pos": 16, "end_pos": 28, "type": "METRIC", "confidence": 0.8984581232070923}, {"text": "Precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.49842336773872375}, {"text": "MAP", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.987139880657196}]}, {"text": "shows the system results where BL is the baseline result.", "labels": [], "entities": [{"text": "BL", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9969894289970398}]}, {"text": "There are two main findings.", "labels": [], "entities": []}, {"text": "First of all, the database-driven approach outperforms the data-driven approach.", "labels": [], "entities": []}, {"text": "Secondly, our approach which applies a grading of results based on proximity between queries and potential expert names significantly outperforms the baseline approach that only considers frequency, that is true for both formulae we apply when ranking the results (using paired t-tests applied to MAP with p<0.0001).", "labels": [], "entities": []}, {"text": "However, the differences between cm1 and cm2 tend not to be significantly different.", "labels": [], "entities": []}, {"text": "It is perhaps important to mention that our data is fairly clean.", "labels": [], "entities": []}, {"text": "More noise would make the creation of relational database more difficult.", "labels": [], "entities": []}, {"text": "In that case the data-driven approach may become more appropriate.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 list some  of the topics.", "labels": [], "entities": []}]}