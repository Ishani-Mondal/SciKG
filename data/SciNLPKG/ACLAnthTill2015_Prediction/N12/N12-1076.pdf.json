{"title": [{"text": "A comparison of models of word meaning in context", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper compares a number of recently proposed models for computing context sensitive word similarity.", "labels": [], "entities": [{"text": "computing context sensitive word similarity", "start_pos": 61, "end_pos": 104, "type": "TASK", "confidence": 0.6887770891189575}]}, {"text": "We clarify the connections between these models, simplify their formulation and evaluate them in a unified setting.", "labels": [], "entities": []}, {"text": "We show that the models are essentially equivalent if syntactic information is ignored, and that the substantial performance differences previously reported disappear to a large extent when these simplified variants are evaluated under identical conditions.", "labels": [], "entities": []}, {"text": "Furthermore, our reformulation allows for the design of a straightforward and fast implementation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The computation of semantic similarity scores between words is an important sub-task fora variety of NLP applications.", "labels": [], "entities": []}, {"text": "One standard approach is to exploit the so-called distributional hypothesis that similar words tend to appear in similar contexts: Word meaning is represented by the contexts in which a word occurs, and semantic similarity is computed by comparing these contexts in a high-dimensional vector space.", "labels": [], "entities": []}, {"text": "Such distributional models of word meaning are attractive because they are simple, have wide coverage, and can be easily acquired in an unsupervised way.", "labels": [], "entities": [{"text": "word meaning", "start_pos": 30, "end_pos": 42, "type": "TASK", "confidence": 0.7235947847366333}]}, {"text": "Ambiguity, however, is a fundamental problem: when encountering a word in context, we want a distributional representation which reflects its meaning in this specific context.", "labels": [], "entities": []}, {"text": "For instance, while buy and acquire are similar when we consider them in isolation, they do not convey the same meaning when acquire occurs in students acquire knowledge.", "labels": [], "entities": []}, {"text": "This is particularly difficult for vector space models which compute a single type vector summing up overall occurrences of a word.", "labels": [], "entities": []}, {"text": "This vector mixes all of a word's usages and makes no distinctions between its-potentially very diverse-senses.", "labels": [], "entities": []}, {"text": "Several proposals have been made in the recent literature to address this problem.", "labels": [], "entities": []}, {"text": "Type-based methods combine the (type) vector of the target with the vectors of the surrounding context words to obtain a disambiguated representation.", "labels": [], "entities": []}, {"text": "In recent work, this has been proposed by, and, which differ in the choice of input vector representation and in the combination operation they propose.", "labels": [], "entities": []}, {"text": "A different approach has been taken by, and, who make use of token vectors for individual occurrences of a word, rather than using the already mixed type vectors.", "labels": [], "entities": []}, {"text": "Generally speaking, these methods \"select\" a set of token vectors of the target, which are similar to the current context, and use only these to obtain a disambiguated representation.", "labels": [], "entities": []}, {"text": "Yet another approach has been taken by, \u00d3 and, who propose to use latent variable models.", "labels": [], "entities": []}, {"text": "Conceptually, this comes close to token-based models, however their approach is more unitary as they attempt to recover a hidden layer which best explains the observation data.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the first group of approaches and investigate the precise differences between the three models of Erk and Pad\u00f3 and Thater et al., out of which) achieves state of the art results on a standard data set.", "labels": [], "entities": []}, {"text": "Despite the fact that these models exploit similar intuitions, both their formal presentations and the results obtained vary to a great extent.", "labels": [], "entities": []}, {"text": "The answer given in this paper is surprising: the three models are essentially equivalent if syntactic information is ignored; in a syntactic space the three methods implement only slightly different intuitions.", "labels": [], "entities": []}, {"text": "We clarify these connections, simplify the syntactic variants originally proposed and reduce them to straightforward matrix operations, and evaluate them in a unified experimental setting.", "labels": [], "entities": []}, {"text": "We obtain significantly better results than originally reported in the literature.", "labels": [], "entities": []}, {"text": "Our reformulation also also supports efficient implementations for these methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have just shown that EP08, TFP10 and TFP11 are essentially equivalent to each other if syntactic information is ignored, hence it is a bit surprising that performance results reported in the literature vary to such a great extent.", "labels": [], "entities": []}, {"text": "In this section we consider syntactic variants of these methods and we show that performance differences previously reported can only partly be explained by the different ways syntactic information is used: when we simplify these models and evaluate them under identical conditions, the differences between them disappear to a large extent.", "labels": [], "entities": []}, {"text": "To evaluate the three models, we reimplemented them using matrix operations similar to the ones used in Section 3, where we made few simplifications to the TFP10 and EP08 models: we follow TFP11 and we use component-wise multiplication to combine the target with one context word, and add the resulting composed vectors when given more context words . Furthermore for TFP10, we change the 1 Note that some of the parameters in the EP08 method (omit-) is reported only on a subset of the data -this subset is however judged by the authors to be \"easier\" than the entire data; all other methods are tested on the entire dataset.", "labels": [], "entities": [{"text": "TFP11", "start_pos": 189, "end_pos": 194, "type": "DATASET", "confidence": 0.8896802067756653}]}, {"text": "treatment of syntax in the line of the much simpler proposal of TFP11.", "labels": [], "entities": [{"text": "TFP11", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.8885997533798218}]}, {"text": "Specifically: where V is a I \u00d7 J syntactic input matrix, i.e. the columns are (word, relation) pairs.", "labels": [], "entities": []}, {"text": "For simplification, the columns of V are reordered such that syntactic relations form continuous regions.", "labels": [], "entities": []}, {"text": "Lr is a lifting map similar to that of Equation as it maps I-into Jdimensional vectors: the resulting vector is equal to the original one in the column region of relation r, while everything else is 0.", "labels": [], "entities": []}, {"text": "In the above equations we use the standard Matlab notation, V w,: denoting a row vector in matrix V . We evaluate these models on a paraphrase ranking task, using the SemEval 2007 Lexical Substitution Task (LST) dataset: the models are given a target word in context plus a list of potential synonyms (substitution candidates) ranging overall senses of the target word.", "labels": [], "entities": [{"text": "SemEval 2007 Lexical Substitution Task (LST) dataset", "start_pos": 167, "end_pos": 219, "type": "DATASET", "confidence": 0.6885435150729285}]}, {"text": "The models have to decide to what extent each substitution candidate is a synonym of the target in the given context.", "labels": [], "entities": []}, {"text": "We omit the precise description of the evaluation setting here, as we follow the methodology described in.", "labels": [], "entities": []}, {"text": "Results are shown in, where the first column gives the GAP (Generalized Average Precision) score of the model and the second column gives the difference to the result reported in the literature.", "labels": [], "entities": [{"text": "GAP (Generalized Average Precision) score", "start_pos": 55, "end_pos": 96, "type": "METRIC", "confidence": 0.8708032539912632}]}, {"text": "TFP10 and EP08 perform much better than the original proposals, as we obtain very significant gains of 4 and 14 GAP points.", "labels": [], "entities": [{"text": "TFP10", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7999739050865173}, {"text": "EP08", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.8567511439323425}, {"text": "GAP", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.9952250719070435}]}, {"text": "ted in the brief presentation in Section 2), which are difficult to tune), disappear this way.", "labels": [], "entities": []}, {"text": "We can observe that the differences between the three methods, when simplified and tested in an unified setting, largely disappear.", "labels": [], "entities": []}, {"text": "This is to be expected as all three methods implement very similar, all motivated intuitions: TFP11 reweights the vector of the target acquire with the second order vector of the context knowledge, i.e. with the vector of similarities of knowledge to all other words in the vocabulary.", "labels": [], "entities": []}, {"text": "TFP10 takes a complementary approach: it reweights the vector of knowledge with the second order vector of acquire.", "labels": [], "entities": [{"text": "TFP10", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8527695536613464}]}, {"text": "In both these methods, anything outside the object (object \u22121 respectively) region of the space, is set to 0.", "labels": [], "entities": []}, {"text": "The variant of EP08 that we implement is very similar to TFP11, however it compares knowledge to all other words in the vocabulary only using occurrences as objects while TFP11 takes all syntactic relations into account.", "labels": [], "entities": []}, {"text": "Note that TFP10 and TFP11 operate on complementary syntactic regions of the vectors.", "labels": [], "entities": []}, {"text": "For this reason the two models can be trivially combined.", "labels": [], "entities": []}, {"text": "The combined model (TFP10+11) achieves even better results: the difference to TFP11 is small, however statistically significant at level p < 0.05.", "labels": [], "entities": [{"text": "TFP11", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.5620223879814148}]}, {"text": "Straightforward implementations of the three models are computationally expensive, as they all use \"second order\" vectors to implement contextualization of a target word.", "labels": [], "entities": []}, {"text": "Our reformulation in terms of matrix operations allows for efficient implementations, which take advantage of the sparsity of the input matrix V : contextualization of a target word runs in O(nnz(V )), where nnz is the number of non-zero entries.", "labels": [], "entities": []}, {"text": "Note that ranking not only a small set of predefined substitution candidates, as in the experiment above, but also ranking the entire vocabulary runs in O(nnz(V )).", "labels": [], "entities": [{"text": "O", "start_pos": 153, "end_pos": 154, "type": "METRIC", "confidence": 0.9836322069168091}]}, {"text": "On this task, this overall running time is in fact identical to that of simpler methods such as those of.", "labels": [], "entities": []}, {"text": "In our experiments, we use GigaWord to extract a syntactic input matrix V of size \u2248 2M \u00d7 7M.", "labels": [], "entities": []}, {"text": "V is only 4.5 \u00d7 10 \u221206 dense.", "labels": [], "entities": []}, {"text": "Note that because of the simple operations involved, we do not need to compute or store the entire VV T matrix, which is much denser than V (we have estimated order of 10 10 entries).", "labels": [], "entities": []}, {"text": "The sparsity of V allows for very efficient computations in practice: the best single model, TFP11, runs in less than 0.2s/0.4s per LST instance, for ranking the candidate list/entire vocabulary in a Python implementation using scipy.sparse, on a standard 1GHz processor.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: GAP scores LST data.", "labels": [], "entities": [{"text": "GAP scores LST data", "start_pos": 10, "end_pos": 29, "type": "DATASET", "confidence": 0.639531172811985}]}]}