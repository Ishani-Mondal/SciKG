{"title": [{"text": "Fine-Grained Focus for Pinpointing Positive Implicit Meaning from Negated Statements", "labels": [], "entities": [{"text": "Pinpointing Positive Implicit Meaning from Negated Statements", "start_pos": 23, "end_pos": 84, "type": "TASK", "confidence": 0.8571493285042899}]}], "abstractContent": [{"text": "Negated statements often carry positive implicit meaning.", "labels": [], "entities": []}, {"text": "Regardless of the semantic representation one adopts, pinpointing the positive concepts within a negated statement is needed in order to encode the statement's meaning.", "labels": [], "entities": []}, {"text": "In this paper, novel ideas to reveal positive implicit meaning using focus of negation are presented.", "labels": [], "entities": []}, {"text": "The concept of granular-ity of focus is introduced and justified.", "labels": [], "entities": []}, {"text": "New annotation and features to detect fine-grained focus are discussed and results reported.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic representation of text is an important step towards text understanding.", "labels": [], "entities": [{"text": "Semantic representation of text", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8530278503894806}, {"text": "text understanding", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.8106747567653656}]}, {"text": "Current approaches are based on relatively shallow representations and ignore pervasive linguistic phenomena such as negation and metaphor.", "labels": [], "entities": []}, {"text": "Despite these weaknesses, shallow representations have been proven useful for several tasks, e.g., coreference resolution (, machine translation (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.954732209444046}, {"text": "machine translation", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.8071139752864838}]}, {"text": "Consider statement (1) The company won't ship the new product to the United States until next year.", "labels": [], "entities": []}, {"text": "Existing approaches to represent the meaning of either indicate that the verb ship is negated or disregard the negation altogether.", "labels": [], "entities": []}, {"text": "Only doing so one can aim at representing the actual meaning of (1): The company will ship the new product to the United States during next year.", "labels": [], "entities": []}, {"text": "Note that the verb ship, and its AGENT, THEME and LOCATION (i.e., The company, the new product and to the United States) are positive, as well as the temporal anchor next year.", "labels": [], "entities": [{"text": "AGENT", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9981350898742676}, {"text": "THEME", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9975408315658569}, {"text": "LOCATION", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9942219853401184}]}, {"text": "Regardless of the semantic representation one favors (logic forms, predicate calculus, semantic relations, semantic frames, etc.), we argue that pinpointing the numerous words that contribute to implicit positive meanings within a negated statement is a required subtask to obtain it.", "labels": [], "entities": []}, {"text": "This paper aims at extracting specific positive implicit meaning from negated statements.", "labels": [], "entities": [{"text": "extracting specific positive implicit meaning from negated statements", "start_pos": 19, "end_pos": 88, "type": "TASK", "confidence": 0.7502625808119774}]}, {"text": "The main contributions are: (1) interpretation of negation using fine-grained focus; (2) fine-grained focus of negation annotation over a subset of PropBank; (3) feature set to detect fine-grained focus of negation; and (4) model to retrieve precise positive implicit meaning from negated statements.", "labels": [], "entities": [{"text": "interpretation of negation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.8054305911064148}, {"text": "PropBank", "start_pos": 148, "end_pos": 156, "type": "DATASET", "confidence": 0.9648950099945068}]}], "datasetContent": [{"text": "We have carried our experiments using Yamcha (), a generic, customizable, and open source text chunker 1 implemented using TinySVM 2 . Following Yamcha's design, we distinguish between static and dynamic features.", "labels": [], "entities": []}, {"text": "Static features are the ones depicted in fora fixed size window.", "labels": [], "entities": []}, {"text": "Dynamic features are the predicted classes fora fixed set of previous instances.", "labels": [], "entities": []}, {"text": "Whereas values for static features are considered correct, values for dynamic features are predictions of previous instances and therefore may contain errors.", "labels": [], "entities": []}, {"text": "Varying window size effectively varies the number of features considered, the larger the window the more local context is taken into account.", "labels": [], "entities": []}, {"text": "Window sizes are defined using ranges between instances.", "labels": [], "entities": []}, {"text": "The instance to be predicted has index '0', the previous one '\u22121', the next one '1', and soon.", "labels": [], "entities": [{"text": "index '0", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9439809719721476}]}, {"text": "The range [i..j] indicates we take into account from the ith to the jth instances to predict the current instance.", "labels": [], "entities": []}, {"text": "Ranges for dynamic features can only contain instances preceding the current one.", "labels": [], "entities": []}, {"text": "The best performing system was obtained using a window including the current and two previous instances, and taking into account dynamic features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Syntactic nodes for coarse-grained focus.", "labels": [], "entities": []}, {"text": " Table 1. In a first round,  they were asked to select as fine-grained focus the  words within the coarse-grained focus that they be-", "labels": [], "entities": []}, {"text": " Table 3: Examples of annotation (and relevant context) exemplifying the annotation guidelines.", "labels": [], "entities": []}, {"text": " Table 4: Numeric analysis: average number of words  in fine-grained focus, percentage of negations in which  coarse and fine-grained focus are the same and average  ratio of words in fine versus coarse-grained focus.", "labels": [], "entities": []}, {"text": " Table 5: Precision, recall and f-measure of baselines.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9980050921440125}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9992144107818604}, {"text": "f-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9883179068565369}]}, {"text": " Table 6: Feature set used to predict fine-grained focus of negation. If a feature is especially useful for a particular  syntactic node, we indicate so between parenthesis in the right hand side of column 1 (otherwise it is useful for all).", "labels": [], "entities": []}, {"text": " Table 8: Detailed results per phrase using the best win- dow size of features (in bold in Table 7).", "labels": [], "entities": []}]}