{"title": [], "abstractContent": [{"text": "The accuracy of many natural language processing tasks can be improved by a reranking step, which involves selecting a single output from a list of candidate outputs generated by a baseline system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9986922144889832}]}, {"text": "We propose a novel family of reranking algorithms based on learning separate low-dimensional embeddings of the task's input and output spaces.", "labels": [], "entities": []}, {"text": "This embedding is learned in such away that prediction becomes a low-dimensional nearest-neighbor search, which can be done computationally efficiently.", "labels": [], "entities": [{"text": "prediction", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.9710084199905396}]}, {"text": "A key quality of our approach is that feature engineering can be done separately on the input and output spaces; the relationship between inputs and outputs is learned automatically.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.760401040315628}]}, {"text": "Experiments on part-of-speech tagging task in four languages show significant improvements over a baseline decoder and existing reranking approaches.", "labels": [], "entities": [{"text": "part-of-speech tagging task", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7799201607704163}]}], "introductionContent": [{"text": "Mapping inputs to outputs lies at the heart of many Natural Language Processing applications.", "labels": [], "entities": [{"text": "Mapping inputs to outputs", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8589487075805664}]}, {"text": "For example, given a sentence as input: part-of-speech (POS) tagging involves finding the appropriate POS tag sequence); parsing involves finding the appropriate tree structure () and statistical machine translation (SMT) involves finding correct target language translation).", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.672562575340271}, {"text": "statistical machine translation (SMT)", "start_pos": 184, "end_pos": 221, "type": "TASK", "confidence": 0.8099709153175354}]}, {"text": "The accuracy achieved on such tasks can often be improved significantly with the help of a discriminative reranking step).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993895292282104}]}, {"text": "For the POS tagging, reranking is relative less explored due to the already higher accuracies in English, but it is shown to improve accuracies in other languages such as Chinese (.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.6811639666557312}, {"text": "reranking", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.8127491474151611}, {"text": "accuracies", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9694971442222595}, {"text": "accuracies", "start_pos": 133, "end_pos": 143, "type": "METRIC", "confidence": 0.9862319827079773}]}, {"text": "In this paper, we propose a novel approach to discriminative reranking and show its effectiveness in POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 101, "end_pos": 112, "type": "TASK", "confidence": 0.9103110432624817}]}, {"text": "Reranking allows us to use arbitrary features defined jointly on input and output spaces that are often difficult to incorporate into the baseline decoder due to the computational tractability issues.", "labels": [], "entities": []}, {"text": "The effectiveness of reranking depends on the joint features defined over both input and output spaces.", "labels": [], "entities": []}, {"text": "This has led the community to spend substantial efforts in defining joint features for reranking).", "labels": [], "entities": []}, {"text": "Unfortunately, developing joint features over the input and output space can be challenging, especially in problems for which the exact mapping between the input and the output is unclear (for instance, in automatic caption generation for images, semantic parsing or non-literal translation).", "labels": [], "entities": [{"text": "automatic caption generation", "start_pos": 206, "end_pos": 234, "type": "TASK", "confidence": 0.6683685978253683}, {"text": "semantic parsing", "start_pos": 247, "end_pos": 263, "type": "TASK", "confidence": 0.712200790643692}]}, {"text": "In contrast to prior work, our approach uses features defined separately within the input and output spaces, and learns a mapping function that can map an object from one space into the other.", "labels": [], "entities": []}, {"text": "Since our approach requires within-space features, it makes the feature engineering relatively easy.", "labels": [], "entities": []}, {"text": "For clarity, we will discuss our approach in the context of POS tagging, though of course it generalizes to any reranking problem.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.8360290825366974}]}, {"text": "At test time, in POS tagging, we receive a sentence and a list of candidate output POS sequences as input.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.9327594041824341}]}, {"text": "We run a feature extractor on the input sentence to obtain a representation x \u2208 Rd 1 ; we run an independent", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report POS tagging experiments on four languages: English, Chinese, French and Swedish.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.8621935248374939}]}, {"text": "The data in all these languages is obtained from the CoNLL 2006 shared task on multilingual dependency parsing ().", "labels": [], "entities": [{"text": "CoNLL 2006 shared task", "start_pos": 53, "end_pos": 75, "type": "DATASET", "confidence": 0.9097016155719757}, {"text": "multilingual dependency parsing", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.5253822505474091}]}, {"text": "We only consider the word and its fine grained POS tag (columns 2 and 5 respectively) and ignore the dependency links in the data.", "labels": [], "entities": []}, {"text": "shows the data statistics in each of these languages.", "labels": [], "entities": []}, {"text": "We use a second order Hidden Markov Model () based tagger as a baseline tagger in our experiments.", "labels": [], "entities": []}, {"text": "This model uses trigram transition and emission probabilities and is shown to achieve good accuracies in English and other languages (.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9924762845039368}]}, {"text": "We refer to this as the baseline tagger in the rest of this paper and is used to produce n-best list for each candidate sentence.", "labels": [], "entities": []}, {"text": "The n-best list for training data is produced using multifold cross-validation like Collins and and.", "labels": [], "entities": []}, {"text": "The first block of shows the accuracies of the top-ranked tag sequence (according to the Viterbi decoding score) and the oracle accuracies on the 10-best list.", "labels": [], "entities": []}, {"text": "As expected the accuracies on English and French are high and are on par with the state-of-the-art systems.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.9922767281532288}]}, {"text": "From the oracle scores, it is clear that though there is a chance for improvement using reranking, the scope for improvement in English is less compared to the 5 point improvement reported for parsing).", "labels": [], "entities": []}, {"text": "This indicates the difficulty of the reranking problem for POS tagging in wellresourced languages.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.8784625828266144}]}], "tableCaptions": [{"text": " Table 2: Accuracy of the baseline HMM tagger and different reranking approaches. For comparison purposes, we also  showed the results of Collins and", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9887710213661194}, {"text": "HMM tagger", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.79396191239357}]}, {"text": " Table 3: Accuracies without combining with Viterbi de- coding score.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9990726709365845}, {"text": "Viterbi de- coding score", "start_pos": 44, "end_pos": 68, "type": "METRIC", "confidence": 0.6844216585159302}]}]}