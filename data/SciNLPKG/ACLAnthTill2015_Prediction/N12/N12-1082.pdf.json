{"title": [{"text": "On The Feasibility of Open Domain Referring Expression Generation Using Large Scale Folksonomies", "labels": [], "entities": [{"text": "Open Domain Referring Expression Generation", "start_pos": 22, "end_pos": 65, "type": "TASK", "confidence": 0.7493462085723877}]}], "abstractContent": [{"text": "Generating referring expressions has received considerable attention in Natural Language Generation.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.654241144657135}]}, {"text": "In recent years we start seeing deployments of referring expression generators moving away from limited domains with custom-made ontologies.", "labels": [], "entities": []}, {"text": "In this work, we explore the feasibility of using large scale noisy ontologies (folksonomies) for open domain referring expression generation, an important task for summarization by re-generation.", "labels": [], "entities": [{"text": "open domain referring expression generation", "start_pos": 98, "end_pos": 141, "type": "TASK", "confidence": 0.5988199353218079}, {"text": "summarization", "start_pos": 165, "end_pos": 178, "type": "TASK", "confidence": 0.990471363067627}]}, {"text": "Our experiments on a fully annotated anaphora resolution training set and a larger, volunteer-submitted news corpus show that existing algorithms are efficient enough to deal with large scale ontologies but need to be extended to deal with undefined values and some measure for information salience.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7712965309619904}, {"text": "information salience", "start_pos": 278, "end_pos": 298, "type": "TASK", "confidence": 0.7209725677967072}]}], "introductionContent": [{"text": "Given an entity 1 (the referent) and a set of competing entities (the set of distractors), the task of referring expression generation (REG) involves creating a mention to the referent so that, in the eyes of the reader, it is clearly distinguishable from any other entity in the set of distractors.", "labels": [], "entities": [{"text": "referring expression generation (REG)", "start_pos": 103, "end_pos": 140, "type": "TASK", "confidence": 0.7848987778027853}]}, {"text": "Ina traditional generation pipeline, referring expression generation happens at the sentence planning level.", "labels": [], "entities": []}, {"text": "As a result, its output is not a textual nugget but a description employed later on by the surface realizer.", "labels": [], "entities": []}, {"text": "In this paper, we consider the output of the REG system to * To whom correspondence should be addressed.", "labels": [], "entities": []}, {"text": "Email: pablo.duboue@gmail.com.", "labels": [], "entities": []}, {"text": "1 Or set of entities, but not in this work.", "labels": [], "entities": []}, {"text": "be Definite Descriptions (DD) consisting of a set of positive triples and a set of negative triples, enumerating referent-related properties.", "labels": [], "entities": []}, {"text": "Since the seminal work by, REG has received a lot of attention in the Natural Language Generation (NLG) community.", "labels": [], "entities": [{"text": "REG", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9422985911369324}, {"text": "Natural Language Generation (NLG)", "start_pos": 70, "end_pos": 103, "type": "TASK", "confidence": 0.7692418297131857}]}, {"text": "However, most of the early work on REG has been on traditional NLG systems, using custom-tailored ontologies.", "labels": [], "entities": [{"text": "REG", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9735594987869263}]}, {"text": "In recent years () there has been a shift towards what we term \"Open Domain Referring Expression Generation,\" (OD REG), that is, a REG task where the properties come from a folksonomy, a large-scale volunteer-built ontology.", "labels": [], "entities": [{"text": "Open Domain Referring Expression Generation", "start_pos": 64, "end_pos": 107, "type": "TASK", "confidence": 0.6720903754234314}]}, {"text": "In particular, we are interested in changing anaphoric references for entities appearing in sentences drafted from different documents, as done in multi-document summarization).", "labels": [], "entities": []}, {"text": "For example, consider the following summary excerpt 2 as produced by Newsblaster): Thousands of cheering, flag-waving Palestinians gave Palestinian Authority President Mahmoud Abbas an enthusiastic welcome in Ramallah on Sunday, as he told them triumphantly that a \"Palestinian spring\" had been born following his speech to the United Nations last week.", "labels": [], "entities": [{"text": "Newsblaster", "start_pos": 69, "end_pos": 80, "type": "DATASET", "confidence": 0.974888801574707}]}, {"text": "The president pressed Israel, in unusually frank terms, to reach a final peace agreement with the Palestinians, citing the boundaries in place on the eve of the June 1967 Arab-Israeli War as the starting point for ne-gotiation about borders.", "labels": [], "entities": []}, {"text": "Here the second sentence refers to U.S. president Barack Obama and a referring expression of the form \"U.S. president\" should have been used.", "labels": [], "entities": []}, {"text": "Such expressions depend on the set of distractors present in the text, a requirement that highlights the dynamic nature of the problem.", "labels": [], "entities": []}, {"text": "Our experiments extracted thousands of complex cases (such as distinguishing one musician from a set of five) which we used to test existing algorithms against a folksonomy, dbPedia).", "labels": [], "entities": []}, {"text": "This folksonomy contains 1.7M triples (for its English version) and has been curated from Wikipedia.", "labels": [], "entities": []}, {"text": "We performed two experiments: first we employed sets of distractors derived from a set of documents annotated with anaphora resolution information ().", "labels": [], "entities": []}, {"text": "We found that roughly half of the entities annotated in the documents were present in the folksonomy, which speaks of the feasibility of using a folksonomy for OD REG, given the fact that Wikipedia has strict notability requirements for adding information.", "labels": [], "entities": [{"text": "OD REG", "start_pos": 160, "end_pos": 166, "type": "TASK", "confidence": 0.7282929122447968}]}, {"text": "In the second experiment, we obtained sets of distractors from Wikinews, 7 a service where volunteers submit news articles interspersed with Wikipedia links.", "labels": [], "entities": [{"text": "Wikinews, 7", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.8586499492327372}]}, {"text": "We leveraged said links to assemble 40k referring expression tasks.", "labels": [], "entities": []}, {"text": "For algorithms, we employed Dale and Reiter (1995), and Full Brevity (FB)).", "labels": [], "entities": [{"text": "Full Brevity (FB))", "start_pos": 56, "end_pos": 74, "type": "METRIC", "confidence": 0.8724801898002624}]}, {"text": "Our results show that the first two algorithms produce results in a majority of the referring expression tasks, with the Dale and Reiter algorithm being the most efficient and resilient of the three.", "labels": [], "entities": []}, {"text": "The results, however, are of mixed quality and more research is needed to overcome two problems we have identified in our experiments: dealing with undefined information in the folksonomy and the need to incorporate a rough user model in the form of information salience.", "labels": [], "entities": []}, {"text": "In the next section we briefly summarize the three algorithms we employed in our experiments.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the data employed.", "labels": [], "entities": []}, {"text": "Section 4 contains the results of our experiments and subsequent analysis.", "labels": [], "entities": []}, {"text": "We conclude discussing future work.", "labels": [], "entities": []}, {"text": "Obama prods Mideast allies to embrace reform, make peace (Washington Post, 10/07/2011, 371 words).", "labels": [], "entities": [{"text": "Washington Post, 10/07/2011", "start_pos": 58, "end_pos": 85, "type": "DATASET", "confidence": 0.9623556137084961}]}, {"text": "5 http://dbpedia.org 6 http://wikipedia.org 7 http://wikinews.org", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}