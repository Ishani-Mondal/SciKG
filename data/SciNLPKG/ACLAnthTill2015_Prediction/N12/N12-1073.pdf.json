{"title": [], "abstractContent": [{"text": "Sentiment analysis of citations in scientific papers and articles is anew and interesting problem which can open up many exciting new applications in bibliographic search and biblio-metrics.", "labels": [], "entities": [{"text": "Sentiment analysis of citations in scientific papers and articles", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.9238327874077691}]}, {"text": "Current work on citation sentiment detection focuses on only the citation sentence.", "labels": [], "entities": [{"text": "citation sentiment detection", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.963984489440918}]}, {"text": "In this paper, we address the problem of context-enhanced citation sentiment detection.", "labels": [], "entities": [{"text": "context-enhanced citation sentiment detection", "start_pos": 41, "end_pos": 86, "type": "TASK", "confidence": 0.7056511864066124}]}, {"text": "We present anew citation sentiment corpus which has been annotated to take the dominant sentiment in the entire citation context into account.", "labels": [], "entities": []}, {"text": "We believe that this gold standard is closer to the truth than annotation that looks only at the citation sentence itself.", "labels": [], "entities": []}, {"text": "We then explore the effect of context windows of different lengths on the performance of a state-of-the-art citation sentiment detection system when using this context-enhanced gold standard definition.", "labels": [], "entities": [{"text": "citation sentiment detection", "start_pos": 108, "end_pos": 136, "type": "TASK", "confidence": 0.7793412804603577}]}], "introductionContent": [{"text": "Sentiment analysis of citations in scientific papers and articles is anew and interesting problem.", "labels": [], "entities": [{"text": "Sentiment analysis of citations in scientific papers and articles", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.9316356579462687}]}, {"text": "It can open up many exciting new applications in bibliographic search and in bibliometrics, i.e., the automatic evaluation of the influence and impact of individuals and journals via citations.", "labels": [], "entities": [{"text": "bibliographic search", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7552997171878815}]}, {"text": "Automatic detection of citation sentiment can also be used as a first step to scientific summarisation (Abu-Jbara and Radev, 2011).", "labels": [], "entities": [{"text": "detection of citation sentiment", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6637851074337959}, {"text": "scientific summarisation", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.5345968455076218}]}, {"text": "Alternatively, it can help researchers during search, e.g., by identifying problems with a particular approach, or by helping to recognise unaddressed issues and possible gaps in the current research.", "labels": [], "entities": []}, {"text": "However, there is a problem with the expression of sentiment in scientific text.", "labels": [], "entities": []}, {"text": "Conventionally, the writing style in scientific writing is meant to be objective.", "labels": [], "entities": []}, {"text": "Any personal bias by authors has to be hedged.", "labels": [], "entities": []}, {"text": "Negative sentiment is politically particularly dangerous, and some authors have documented the strategy of prefacing the intended criticism by slightly disingenuous praise.", "labels": [], "entities": [{"text": "Negative sentiment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9087220430374146}]}, {"text": "This makes the problem of identifying such opinions particularly challenging.", "labels": [], "entities": []}, {"text": "This non-local expression of sentiment has been observed in other genres as well ()..", "labels": [], "entities": []}, {"text": "While the first sentence praises some aspects of the cited paper, the remaining sentences list its shortcomings.", "labels": [], "entities": []}, {"text": "It is clear that criticism is the intended sentiment, but if we define our gold standard only by looking at the citation sentence, we lose a significant amount of sentiment hidden in the text.", "labels": [], "entities": []}, {"text": "Given that most citations are neutral), this makes it evermore important to recover what explicit sentiment there is from the context of the citation.", "labels": [], "entities": []}, {"text": "However, the dominant assumption in current citation identification methods () is that the sentiment present in the citation sentence represents the true sentiment of the author towards the cited paper.", "labels": [], "entities": [{"text": "citation identification", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.8389801383018494}]}, {"text": "This is due to the difficulty of determining the relevant context, whereas it is substantially easier to identify the citation sentence.", "labels": [], "entities": []}, {"text": "In our example above, however, such an approach would lead to the wrong prediction of praise or neutral sentiment.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of contextenhanced citation sentiment detection.", "labels": [], "entities": [{"text": "contextenhanced citation sentiment detection", "start_pos": 41, "end_pos": 85, "type": "TASK", "confidence": 0.7647150456905365}]}, {"text": "We present anew citation sentiment corpus where each citation has been annotated according to the dominant sentiment in the corresponding citation context.", "labels": [], "entities": []}, {"text": "We claim that this corpus is closer to the truth than annotation that considers only the citation sentence itself.", "labels": [], "entities": []}, {"text": "We show that it increases citation sentiment coverage, particularly for negative sentiment.", "labels": [], "entities": [{"text": "citation sentiment", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7181884944438934}, {"text": "coverage", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.5398409366607666}]}, {"text": "Using this gold standard, we explore the effect of assuming context windows of different but fixed lengths on the performance of a state-of-the-art citation sentiment detection system where the sentiment of citation is considered in the entire context of the citation and more than one single sentiment can be assigned.", "labels": [], "entities": [{"text": "citation sentiment detection", "start_pos": 148, "end_pos": 176, "type": "TASK", "confidence": 0.6999199390411377}]}, {"text": "Previous approaches neither detect citation sentiment and context simultaneously nor use as large a corpus as we do.", "labels": [], "entities": [{"text": "citation sentiment", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8378072679042816}]}], "datasetContent": [{"text": "We represent each citation as a feature set in a Support Vector Machine (SVM)) framework and use n-grams of length 1 to 3 as well as dependency triplets as features.", "labels": [], "entities": []}, {"text": "The dependency triplets are constructed by merging the relation, governor and dependent in a single string, for instance, the relation nsubj(failed, method) is represented as nsubj failed method . This setup has been shown to produce good results earlier as well (; Athar, 2011).", "labels": [], "entities": []}, {"text": "The first set of experiments focuses on simultaneous detection of sentiment and context sentences.", "labels": [], "entities": [{"text": "detection of sentiment and context sentences", "start_pos": 53, "end_pos": 97, "type": "TASK", "confidence": 0.7242532620827357}]}, {"text": "For this purpose, we use the four-class annotated corpus described earlier.", "labels": [], "entities": []}, {"text": "While the original annotations were performed fora window of length 4, we also experiment with asymmetrical windows of l sentences preceding the citation and r sentences succeeding it.", "labels": [], "entities": []}, {"text": "The detailed results are given in.", "labels": [], "entities": []}, {"text": "Because of the skewed class distribution, we use both the F macro and F micro scores with 10-fold cross-validation.", "labels": [], "entities": [{"text": "F micro scores", "start_pos": 70, "end_pos": 84, "type": "METRIC", "confidence": 0.901535153388977}]}, {"text": "The baseline score, shown in bold, is obtained with no context window and is comparable to the results reported by.", "labels": [], "entities": [{"text": "baseline score", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9317584037780762}]}, {"text": "However, we can observe that the F scores decrease as more context is introduced.", "labels": [], "entities": [{"text": "F scores", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.98241326212883}]}, {"text": "This maybe attributed to the increase in the vocabulary size of the n-grams and a consequent reduction in the discriminating power of the decision boundaries.", "labels": [], "entities": []}, {"text": "These results show that the task of jointly detecting sentiment and context is a hard problem.", "labels": [], "entities": [{"text": "detecting sentiment and context", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.8295547068119049}]}, {"text": "For our second set of experiments, we use the three-class annotation scheme.", "labels": [], "entities": []}, {"text": "We merge the text of the sentences in the context windows as well as their dependency triplets to obtain the features.", "labels": [], "entities": []}, {"text": "The results are reported in with best results in bold.", "labels": [], "entities": []}, {"text": "Although these results are not better than the context-less baseline, the reason might be data sparsity since existing work on citation sentiment analysis uses more data.", "labels": [], "entities": [{"text": "citation sentiment analysis", "start_pos": 127, "end_pos": 154, "type": "TASK", "confidence": 0.8954755067825317}]}], "tableCaptions": [{"text": " Table 1: Distribution of classes.", "labels": [], "entities": [{"text": "Distribution", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9732896089553833}]}, {"text": " Table 2: Results for joint context and sentiment de- tection.", "labels": [], "entities": [{"text": "sentiment de- tection", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.6457516551017761}]}, {"text": " Table 3: Results using different context windows.", "labels": [], "entities": []}]}