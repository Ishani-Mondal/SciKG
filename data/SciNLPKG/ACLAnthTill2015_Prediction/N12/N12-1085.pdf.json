{"title": [{"text": "Grammatical structures for word-level sentiment detection", "labels": [], "entities": [{"text": "word-level sentiment", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.7286693155765533}]}], "abstractContent": [{"text": "Existing work in fine-grained sentiment analysis focuses on sentences and phrases but ignores the contribution of individual words and their grammatical connections.", "labels": [], "entities": [{"text": "fine-grained sentiment analysis", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7497956951459249}]}, {"text": "This is because of alack of both (1) annotated data at the word level and (2) algorithms that can leverage syntactic information in a principled way.", "labels": [], "entities": []}, {"text": "We address the first need by annotating articles from the information technology business press via crowdsourcing to provide training and testing data.", "labels": [], "entities": []}, {"text": "To address the second need, we propose a suffix-tree data structure to represent syntactic relationships between opinion targets and words in a sentence that are opinion-bearing.", "labels": [], "entities": []}, {"text": "We show that a factor graph derived from this data structure acquires these relationships with a small number of word-level features.", "labels": [], "entities": []}, {"text": "We demonstrate that our supervised model performs better than baselines that ignore syntactic features and constraints.", "labels": [], "entities": []}], "introductionContent": [{"text": "The terms \"sentiment analysis\" and \"opinion mining\" cover a wide body of research on and development of systems that can automatically infer emotional states from text (after we use the two names interchangeably).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9673569202423096}, {"text": "opinion mining", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.7248620092868805}]}, {"text": "Sentiment analysis plays a large role in business, politics, and is itself a vibrant research area.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9541404545307159}]}, {"text": "Effective sentiment analysis for texts such as newswire depends on the ability to extract who (source) is saying what (target).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8689331412315369}]}, {"text": "Fine-grained sentiment analysis requires identifying the sources and targets directly relevant to sentiment bearing expressions (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.8669382929801941}]}, {"text": "For example, consider the following sentence from a major information technology (IT) business journal: Lloyd Hession, chief security officer at BT Radianz in New York, said that virtualization also opens up a slew of potential network access control issues.", "labels": [], "entities": [{"text": "BT Radianz in New York", "start_pos": 145, "end_pos": 167, "type": "DATASET", "confidence": 0.9192500829696655}]}, {"text": "There are three entities in the sentence that have the capacity to express an opinion: Lloyd Hession, BT Radianz, and New York.", "labels": [], "entities": [{"text": "Lloyd Hession", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.7941208481788635}, {"text": "BT Radianz", "start_pos": 102, "end_pos": 112, "type": "DATASET", "confidence": 0.8698028326034546}]}, {"text": "These are potential opinion sources.", "labels": [], "entities": []}, {"text": "There are also a number of mentioned concepts that could serve as the topic of an opinion in the sentence, or target.", "labels": [], "entities": []}, {"text": "These include all the sources, but also \"virtualization\", \"network access control\", \"network\", and soon.", "labels": [], "entities": []}, {"text": "The challenging task is to discriminate between these mentions and choose the ones that are relevant to the user.", "labels": [], "entities": []}, {"text": "Furthermore, such a system must also indicate the content of the opinion itself.", "labels": [], "entities": []}, {"text": "This means that we are actually searching for all triples {source, target, opinion} in this sentence) and throughout each document in the corpus.", "labels": [], "entities": []}, {"text": "In this case, we want to identify that Lloyd Hession is the source of an opinion, \"slew of network issues,\" about a target, virtualization.", "labels": [], "entities": []}, {"text": "Providing such fine-grained annotations would enrich information extraction, question answering, and corpus exploration applications by letting users see who is saying what with what opinion ().", "labels": [], "entities": [{"text": "information extraction", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7344760298728943}, {"text": "question answering", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.8933099806308746}, {"text": "corpus exploration", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7744760513305664}]}, {"text": "We motivate the need fora grammatically-focused approach to fine-grained opinion mining and situate it within the context of existing work in Section 2.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.7180838882923126}]}, {"text": "We propose a supervised technique for learning opiniontarget relations from dependency graphs in away that preserves syntactic coherence and semantic compositionality.", "labels": [], "entities": []}, {"text": "In addition to being theoretically sound -a lacuna identified in many sentiment systems -such approaches improve downstream sentiment tasks.", "labels": [], "entities": []}, {"text": "There are multiple types of downstream tasks that potentially require the retrieval of {source, target, opinion} relations on a sentence-by-sentence basis.", "labels": [], "entities": []}, {"text": "An increasingly significant application area is in the use of large corpora in social science.", "labels": [], "entities": []}, {"text": "This area of research requires the exploration and aggregation of data about the relationships between discourses, organizations, and people.", "labels": [], "entities": []}, {"text": "For example, the IT business press data that we use in this work belongs to a larger research program ( of exploring industry opinion leadership.", "labels": [], "entities": []}, {"text": "IT business press text is one type of text in which many entities and opinions can appear intermingled with one another in a small amount of text.", "labels": [], "entities": []}, {"text": "Another application for fine-grained sentiment relation retrieval of this type is paraphrasing, where attribution of which opinion belongs to which entities maybe important for producing useful and accurate output, since source and target identification errors can change the entire meaning of an output text.", "labels": [], "entities": [{"text": "sentiment relation retrieval", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.7974695761998495}, {"text": "paraphrasing", "start_pos": 82, "end_pos": 94, "type": "TASK", "confidence": 0.9527603387832642}]}, {"text": "Unlike previous approaches that ignore syntax, we use a sentence's syntactic structure to build a probabilistic model that encodes whether a word is opinion bearing as a latent variable.", "labels": [], "entities": []}, {"text": "We build a data structure we calla \"syntactic relatedness trie\" (Section 3) that serves as the skeleton fora graphical model over the sentiment relevance of words (Section 4).", "labels": [], "entities": []}, {"text": "This approach allows us to learn features that predict opinion bearing constructions from grammatical structures.", "labels": [], "entities": []}, {"text": "Because of a dearth of resources for this fine-grained task, we also develop new crowdsourcing techniques for labeling word-level, syntactically informed sen-1 Alm (2011) recently argued that work on sentiment analysis needs to de-emphasize the goal of building systems that are \"high-performing\" by traditional measures, because the field risks sacrificing \"opportunities that may lead to a more thorough understanding of language uses and users\" in relation to subjective phenomena.", "labels": [], "entities": [{"text": "labeling word-level, syntactically informed sen-1 Alm", "start_pos": 110, "end_pos": 163, "type": "TASK", "confidence": 0.7668816447257996}, {"text": "sentiment analysis", "start_pos": 200, "end_pos": 218, "type": "TASK", "confidence": 0.9348111748695374}]}, {"text": "The work we present in this paper therefore focuses on extracting meaningful features as an investment in future work that directly improves retrieval performance.", "labels": [], "entities": []}, {"text": "timent (Section 5).", "labels": [], "entities": []}, {"text": "We use inference techniques to uncover grammatical patterns that connect opinionexpressing words and target entities (Section 6) performing better than using syntactically uninformed methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "During the training phase, we evaluate the quality of a candidate labeling based on label accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.7717397212982178}]}, {"text": "We need to identify both flow nodes and inert nodes in order to distinguish between relevant and irrelevant subcomponents.", "labels": [], "entities": []}, {"text": "We thus also employ precision and recall as performance metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9994400143623352}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9985939860343933}]}, {"text": "An example of how this works can be seen by comparing figure 2(b) to, viewing the former as the gold standard and the latter as a hypothetical system output.", "labels": [], "entities": []}, {"text": "If we run the evaluation over that single SRT and treat flow as the positive class, we find that 3 true positives, 1 false positive, 2 false negatives, and no true negatives.", "labels": [], "entities": []}, {"text": "There are 6 labels in total.", "labels": [], "entities": []}, {"text": "That yields 0.50 accuracy, 0.75 precision, 0.60 recall, and 0.67 F-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.998119056224823}, {"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9975308775901794}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9964435696601868}, {"text": "F-measure", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9970506429672241}]}, {"text": "We run every experiment (training a model and testing on held-out data) 10 times and take the mean average and range of all measures.", "labels": [], "entities": [{"text": "range", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9473569393157959}]}, {"text": "F-measure is calculated for each run and averaged post hoc.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9933366775512695}]}, {"text": "Our baseline system is the initial setting of the labels for the sampler: uniform random assignment of flow labels, respecting the invariant.", "labels": [], "entities": []}, {"text": "This leads to a large class imbalance in favor of inert as any switch to inert converts all nodes downstream from the root to convert to inert, while a switch to flow causes only one ancestor branch to convert to flow.", "labels": [], "entities": []}, {"text": "Our next systems involve combinations of our SRT factors with the observed linguistic features.", "labels": [], "entities": [{"text": "SRT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9051258563995361}]}, {"text": "All our experiments include the factor g that pertains only to the features of the node.", "labels": [], "entities": []}, {"text": "Then we add factor f -the parent-node \"bigram\" features-and finally factor h, the variable-length node-child features.", "labels": [], "entities": []}, {"text": "We also experiment with including and excluding combinations of POS, role, and word features.", "labels": [], "entities": []}, {"text": "We also explored models that only made local decisions, ignoring the consistency constraints over sentiment flows.", "labels": [], "entities": []}, {"text": "Although such models cannot be used in techniques such as Nakagawa et al.'s polarity classifier, they function as a baseline and inform whether syntactic constraints help performance.", "labels": [], "entities": []}, {"text": "We ran the inferencer for 200 iterations to train a model with a particular factor-feature combination.", "labels": [], "entities": []}, {"text": "We use the learned model to predict the labels on the held-out testing data by running the inference algorithm (sampling labels only) for 50 iterations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance using different feature combinations, including some without enforcing the invariant.  Mean averages and standard deviation for 10 runs.", "labels": [], "entities": [{"text": "Mean averages", "start_pos": 109, "end_pos": 122, "type": "METRIC", "confidence": 0.9778832495212555}, {"text": "standard deviation", "start_pos": 127, "end_pos": 145, "type": "METRIC", "confidence": 0.9506894946098328}]}]}