{"title": [{"text": "Comparing HMMs and Bayesian Networks for Surface Realisation", "labels": [], "entities": [{"text": "Surface Realisation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7191523313522339}]}], "abstractContent": [{"text": "Natural Language Generation (NLG) systems often use a pipeline architecture for sequential decision making.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7570293744405111}]}, {"text": "Recent studies however have shown that treating NLG decisions jointly rather than in isolation can improve the overall performance of systems.", "labels": [], "entities": []}, {"text": "We present a joint learning framework based on Hierarchical Reinforcement Learning (HRL) which uses graphical models for surface realisation.", "labels": [], "entities": []}, {"text": "Our focus will be on a comparison of Bayesian Networks and HMMs in terms of user satisfaction and naturalness.", "labels": [], "entities": []}, {"text": "While the former perform best in isolation, the latter present a scal-able alternative within joint systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "NLG systems have traditionally used a pipeline architecture which divides the generation process into three distinct stages.", "labels": [], "entities": []}, {"text": "Content selection chooses 'what to say' and constructs a semantic form.", "labels": [], "entities": []}, {"text": "Utterance planning organises the message into submessages and surface realisation maps the semantics onto words.", "labels": [], "entities": [{"text": "Utterance planning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8846691250801086}]}, {"text": "Recently, a number of studies have pointed out that many decisions made at these distinct stages require interrelated, rather than isolated, optimisations).", "labels": [], "entities": []}, {"text": "The key feature of a joint architecture is that decisions of all three NLG stages share information and can be made in an interrelated fashion.", "labels": [], "entities": []}, {"text": "We present a joint NLG framework based on Hierarchical RL and focus, in particular, on the surface realisation component of joint NLG systems.", "labels": [], "entities": [{"text": "Hierarchical RL", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.5820602774620056}]}, {"text": "We compare the user satisfaction and naturalness of surface realisation using Hidden Markov Models (HMMs) and Bayesian Networks (BNs) which both have been suggested as generation spaces-spaces of surface form variants fora semantic conceptwithin joint NLG systems and in isolation).", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare instructions generated with the HMMs and BNs according to their user satisfaction and their naturalness.", "labels": [], "entities": []}, {"text": "The learn-1 This is key to the joint treatment of content selection and surface realisation: if an utterance is not informative in terms of content, it will receive bad rewards, even with good surface realisation choices (and vice versa).", "labels": [], "entities": [{"text": "surface realisation", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7503173053264618}]}, {"text": "ing agent is trained using the reward function Reward = U ser satisfaction \u00d7 P (w 0 . .", "labels": [], "entities": [{"text": "Reward", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9658355116844177}, {"text": "U ser satisfaction \u00d7 P", "start_pos": 56, "end_pos": 78, "type": "METRIC", "confidence": 0.660998272895813}]}, {"text": "w n ) \u00d7 CAS.", "labels": [], "entities": [{"text": "CAS", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.9950438737869263}]}, {"text": "2 U ser satisfaction is a function of task success and the number of user turns based on the PARADISE framework 3 ( and CAS refers to the proportion of repetition and variation in surface forms.", "labels": [], "entities": [{"text": "PARADISE framework 3", "start_pos": 93, "end_pos": 113, "type": "DATASET", "confidence": 0.8138847549756368}, {"text": "CAS", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.9717128872871399}]}, {"text": "Our focus in this short paper is on P (w 0 . .", "labels": [], "entities": [{"text": "P", "start_pos": 36, "end_pos": 37, "type": "METRIC", "confidence": 0.9642465114593506}]}, {"text": "w n ) which rewards the agent for having generated a surface form sequence w 0 . .", "labels": [], "entities": []}, {"text": "w n . In HMMs, this corresponds to the forward probability-obtained from the Forward algorithm-of observing the sequence in the data.", "labels": [], "entities": []}, {"text": "In BNs, P (w 0 . .", "labels": [], "entities": []}, {"text": "w n ) corresponds to P (Y j = v x |pa(Y j ) = v y ), the posterior probability given the chosen values v x and v y of random variables and their dependencies.", "labels": [], "entities": []}, {"text": "We assign a reward of \u22121 for each action to prevent loops.", "labels": [], "entities": []}, {"text": "User satisfaction Our trained policies learn the same content selection and utterance planning behaviour reported by).", "labels": [], "entities": [{"text": "content selection and utterance planning", "start_pos": 54, "end_pos": 94, "type": "TASK", "confidence": 0.6973594903945923}]}, {"text": "These policies contribute to the user satisfaction of instructions.", "labels": [], "entities": []}, {"text": "BNs and HMMs however differ in their surface realisation choices.", "labels": [], "entities": [{"text": "BNs", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8113464713096619}]}, {"text": "shows the performance in terms of average rewards overtime for both models within the joint learning framework and in isolation.", "labels": [], "entities": []}, {"text": "For ease of comparison, a learning curve using a greedy policy is also shown.", "labels": [], "entities": []}, {"text": "It always chooses the most likely surface form according to the human corpus without taking other tradeoffs into account.", "labels": [], "entities": []}, {"text": "Within the joint framework, both BNs and HMMs learn to generate context-sensitive surface forms that balance the tradeoffs of the most likely sequence (according to the human corpus) and the one that best corresponds to the user's information need (e.g., using nick names of rooms for familiar users).", "labels": [], "entities": []}, {"text": "The BNs reach an average reward 5 of \u221211.53 and outperform the HMMs (average \u221211.64) only marginally by less than one percent.", "labels": [], "entities": [{"text": "BNs", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8048341870307922}, {"text": "reward 5", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9490079879760742}]}, {"text": "BNs and HMMs improve the greedy baseline by 6% (p < 0.0001, r = 0.90).", "labels": [], "entities": [{"text": "BNs", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7659416794776917}]}, {"text": "While BNs reach the same performance in isolation of the joint framework, the performance of HMMs deteriorates significantly to an average reward of \u221212.12.", "labels": [], "entities": []}, {"text": "This corresponds to a drop of 5% (p < 0.0001, r = 0.79) and is nearly as low as the greedy baseline.", "labels": [], "entities": []}, {"text": "HMMs thus reach a comparable performance to BNs as a result of the joint learning architecture: the HRL agent will discover the nonoptimal behaviour that is caused by the HMM's lack of context-awareness (due to their independence assumptions) and learn to balance this drawback by learning a more comprehensive policy itself.", "labels": [], "entities": []}, {"text": "For the more context-aware BNs this is not necessary.", "labels": [], "entities": []}, {"text": "Naturalness We compare the instructions generated with HMMs and BNs regarding their humanlikeness based on the Kullback-Leibler (KL) divergence.", "labels": [], "entities": []}, {"text": "It computes the difference between two probability distributions.", "labels": [], "entities": []}, {"text": "For evidence of its usefulness for measuring naturalness, cf. .", "labels": [], "entities": []}, {"text": "We compare human instructions (based on strings) drawn from the corpus against strings generated by the HMMs and BNs to see how similar both are to human authors.", "labels": [], "entities": []}, {"text": "Splitting the human instructions in half and comparing them to each other indicates how similar human authors are to each other.", "labels": [], "entities": []}, {"text": "It yields a KL score of 1.77 as a gold standard (the lower the better).", "labels": [], "entities": [{"text": "KL score", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9742042422294617}, {"text": "gold standard", "start_pos": 34, "end_pos": 47, "type": "METRIC", "confidence": 0.9207788109779358}]}, {"text": "BNs compared with human data obtain a score of 2.83 and HMMs of 2.80.", "labels": [], "entities": [{"text": "HMMs", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9914813041687012}]}, {"text": "The difference in The average rewards of agents have negative values due to the negative reward of \u22121 the agent receives for each action.", "labels": [], "entities": []}, {"text": "terms of similarity with humans for HMMs and BNs in a joint NLG model is not significant.", "labels": [], "entities": []}], "tableCaptions": []}