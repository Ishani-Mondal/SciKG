{"title": [{"text": "NOMIT: Automatic Titling by Nominalizing", "labels": [], "entities": [{"text": "NOMIT", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.8492974042892456}, {"text": "Automatic Titling", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.5746548473834991}]}], "abstractContent": [{"text": "The important mass of textual documents is in perpetual growth and requires strong applications to automatically process information.", "labels": [], "entities": []}, {"text": "Automatic titling is an essential task for several applications: 'No Subject' e-mails ti-tling, text generation, summarization, and so forth.", "labels": [], "entities": [{"text": "Automatic titling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6392025351524353}, {"text": "text generation", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.7850789725780487}, {"text": "summarization", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9741222262382507}]}, {"text": "This study presents an original approach consisting in titling journalistic articles by nominalizing.", "labels": [], "entities": []}, {"text": "In particular, morphological and semantic processing are employed to obtain a nominalized form which has to respect titles characteristics (in particular, relevance and catchiness).", "labels": [], "entities": []}, {"text": "The evaluation of the approach , described in the paper, indicates that titles stemming from this method are informative and/or catchy.", "labels": [], "entities": []}], "introductionContent": [{"text": "A title establishes a link between a reader and a text.", "labels": [], "entities": []}, {"text": "It has two main functions.", "labels": [], "entities": []}, {"text": "First of all, a title can be informative (it conveys relevant information about the text content and aim), and second, it can be catchy or incentive.", "labels": [], "entities": []}, {"text": "A heading is said to be catchy when it succeeds in capturing the reader's attention on an aspect of the announced event, in a ingenious, metaphoric, enigmatic, or shocking way.", "labels": [], "entities": []}, {"text": "From a syntactic point of view, a title can be a word, a phrase, an expression, a sentence, that designates a paper or one of its parts, by giving its subject.", "labels": [], "entities": []}, {"text": "Titles are used within applications such as automatic generation of contents, or summarization.", "labels": [], "entities": [{"text": "automatic generation of contents", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.7811041325330734}, {"text": "summarization", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.9870975613594055}]}, {"text": "So, it is interesting to automate the process that produces relevant titles by extracting them from texts, and supplying other applications with such data, while avoiding any human intervention: Direct applications (as automatic titling of \"no object\" e-mails) are thus possible.", "labels": [], "entities": []}, {"text": "The point is that several titles can be relevant fora same text: This constitutes the main difficulty of automatic titling.", "labels": [], "entities": []}, {"text": "Some writers prefer informative titles, whereas others prefer catchy ones.", "labels": [], "entities": []}, {"text": "Others juggle with both criteria according to the context and the type of the publication.", "labels": [], "entities": []}, {"text": "So, evaluation of automatic titling is a complex step requiring a human intervention.", "labels": [], "entities": []}, {"text": "Indeed, how can titles relevance be estimated ? How an automatic title can be compared to a human-written (\"real\") title, knowing that both can have a very different morphosyntactic structure?", "labels": [], "entities": []}, {"text": "Automatic titling is a full process, possessing its own functions.", "labels": [], "entities": [{"text": "Automatic titling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.68669793009758}]}, {"text": "It has to be sharply differentiated from summarization and indexation tasks.", "labels": [], "entities": [{"text": "summarization", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.9834871888160706}]}, {"text": "Its purpose is to propose title(s) that have to be short, informative and/or catchy, and keep a coherent syntactic structure.", "labels": [], "entities": []}, {"text": "NLP 1 methods will be exploited in order to abide by language morphosyntactic and semantic constraints in titling.", "labels": [], "entities": []}, {"text": "In this paper, we describe an approach of automatic titling relying on nominalization, i.e. rules transforming a verb phrase into a noun phrase (e.g. \"the president left\" is nominalized into \" President's Departure\").", "labels": [], "entities": []}, {"text": "This study raises two crucial questions: (1) Determining sentences and phrases containing relevant information (2) Nominalizing a chosen item and using it as a title.", "labels": [], "entities": [{"text": "Determining sentences and phrases containing relevant information", "start_pos": 45, "end_pos": 110, "type": "TASK", "confidence": 0.8670646037374224}, {"text": "Nominalizing a chosen item", "start_pos": 115, "end_pos": 141, "type": "TASK", "confidence": 0.8880026936531067}]}, {"text": "Example: From the following pair of sentences \"The disappointing perfor-1 Natural Language Processing mance, on Sunday October 9th, of S\u00e9gol\u00e8ne Royal, amazed the French citizens.", "labels": [], "entities": [{"text": "Sunday October 9th, of S\u00e9gol\u00e8ne Royal", "start_pos": 112, "end_pos": 149, "type": "DATASET", "confidence": 0.9428865143230983}]}, {"text": "For months, they defended their candidate on the Web.\", containing the relevant information about an article in the French press in 2007, the idea is to built the following title: \"S\u00e9gol\u00e8ne Royal: Surprise of the French citizens\".", "labels": [], "entities": []}, {"text": "In fact, other titles could apply such as \"S\u00e9gol\u00e8ne Royal's Disappointing Performance\" or \"Surprising the French Citizens\", but notice that both are less informative, since they drop apart of the information.", "labels": [], "entities": [{"text": "S\u00e9gol\u00e8ne Royal's Disappointing Performance\"", "start_pos": 43, "end_pos": 86, "type": "TASK", "confidence": 0.8347076773643494}, {"text": "Surprising the French Citizens\"", "start_pos": 91, "end_pos": 122, "type": "TASK", "confidence": 0.6416549801826477}]}, {"text": "This article is organized as such: The following section briefly positions automatic titling in its research environment and describes previous work (section 2).", "labels": [], "entities": []}, {"text": "The next one describes NOMIT, our approach of automatic titling by nominalization, which consists in three successive steps: Extracting candidate headings from the document (section 3.1), processing them linguistically (section 3.2), and last, selecting one among the produced headings, which will play the role of the system heading suggestion (section 3.3).", "labels": [], "entities": [{"text": "NOMIT", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.4888361990451813}]}, {"text": "Finally, the results of NOMIT evaluation are presented and discussed (section 4).", "labels": [], "entities": [{"text": "NOMIT", "start_pos": 24, "end_pos": 29, "type": "TASK", "confidence": 0.8920050263404846}]}], "datasetContent": [{"text": "Evaluation of titles is a difficult and boring task.", "labels": [], "entities": [{"text": "Evaluation of titles", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9133045872052511}]}, {"text": "That is why we setup an online evaluation to share the amount of work.", "labels": [], "entities": []}, {"text": "A call for participation was submitted in the French community of researchers (informatics, linguistics).", "labels": [], "entities": []}, {"text": "Even if we do not know the information relative to every annotator (nationality, age, etc.), we think that a great majority of these annotators have a rather good level in French, to judge titles (this is confirmed by the well-writing of the collected definitions for \"relevance\" and \"catchiness\").", "labels": [], "entities": []}, {"text": "NOMIT has been evaluated according to two protocols.", "labels": [], "entities": [{"text": "NOMIT", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.5448712706565857}]}, {"text": "The first one consisted in a quantitative evaluation, stemming from an on-line user evaluation . 103 people have participated to this evaluation.", "labels": [], "entities": []}, {"text": "The second was an evaluation performed by 3 judges.", "labels": [], "entities": []}, {"text": "This last one enables to compute the agreement inter-judges on the various criteria of the evaluation process.", "labels": [], "entities": []}, {"text": "In both cases, the French daily paper Le Monde is used, thus avoiding any connection to the subjectivity of recent news personal analysis.", "labels": [], "entities": [{"text": "French daily paper Le Monde", "start_pos": 19, "end_pos": 46, "type": "DATASET", "confidence": 0.8493083119392395}]}], "tableCaptions": [{"text": " Table 1: Evaluation Results for POSTIT, CATIT,  NOMIT, and RT (Real Titles).", "labels": [], "entities": [{"text": "POSTIT", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.6928012371063232}, {"text": "NOMIT", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.6786166429519653}, {"text": "RT", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.6858891248703003}]}, {"text": " Table 2: Contingency Matrix for NOMIT (relevance).", "labels": [], "entities": [{"text": "NOMIT", "start_pos": 33, "end_pos": 38, "type": "TASK", "confidence": 0.4639827311038971}]}, {"text": " Table 3: Contingency Matrix for NOMIT (catchiness).", "labels": [], "entities": [{"text": "NOMIT", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.4919402301311493}, {"text": "catchiness", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.7983773350715637}]}, {"text": " Table 4: Kappa average for relevance and catchiness of  titles obtained with NOMIT.", "labels": [], "entities": [{"text": "Kappa average", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9400164783000946}, {"text": "relevance", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.985878586769104}, {"text": "catchiness", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9639599323272705}, {"text": "NOMIT", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.6575579047203064}]}]}