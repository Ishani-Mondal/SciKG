{"title": [], "abstractContent": [{"text": "Arabic Dialects present many challenges for machine translation, not least of which is the lack of data resources.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.8034774959087372}]}, {"text": "We use crowdsourc-ing to cheaply and quickly build Levantine-English and Egyptian-English parallel corpora , consisting of 1.1M words and 380k words, respectively.", "labels": [], "entities": []}, {"text": "The dialectal sentences are selected from a large corpus of Arabic web text, and translated using Amazon's Mechanical Turk.", "labels": [], "entities": []}, {"text": "We use this data to build Dialec-tal Arabic MT systems, and find that small amounts of dialectal data have a dramatic impact on translation quality.", "labels": [], "entities": [{"text": "Dialec-tal Arabic MT", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.4976630012194316}, {"text": "translation", "start_pos": 128, "end_pos": 139, "type": "TASK", "confidence": 0.9598508477210999}]}, {"text": "When translating Egyptian and Levantine test sets, our Dialec-tal Arabic MT system performs 6.3 and 7.0 BLEU points higher than a Modern Standard Arabic MT system trained on a 150M-word Arabic-English parallel corpus.", "labels": [], "entities": [{"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.6551913022994995}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9991698265075684}]}], "introductionContent": [{"text": "The Arabic language is a well-known example of diglossia, where the formal variety of the language, which is taught in schools and used in written communication and formal speech (religion, politics, etc.) differs significantly in its grammatical properties from the informal varieties that are acquired natively, which are used mostly for verbal communication.", "labels": [], "entities": []}, {"text": "The spoken varieties of the Arabic language (which we refer to collectively as Dialectal Arabic) differ widely among themselves, depending on the geographic distribution and the socio-economic conditions of the speakers, and they diverge from the formal variety known as Modern Standard Arabic (MSA) ().", "labels": [], "entities": []}, {"text": "Significant differences in the phonology, morphology, lexicon and even syntax render some of these varieties mutually incomprehensible.", "labels": [], "entities": []}, {"text": "The use of Dialectal Arabic has traditionally been confined to informal personal speech, while writing has been done almost exclusively using MSA (or its ancestor Classical Arabic).", "labels": [], "entities": []}, {"text": "This situation is quickly changing, however, with the rapid proliferation of social media in the Arabic-speaking part of the world, where much of the communication is composed in dialect.", "labels": [], "entities": []}, {"text": "The focus of the Arabic NLP research community, which has been mostly on MSA, is turning towards dealing with informal communication, with the introduction of the DARPA BOLT program.", "labels": [], "entities": [{"text": "Arabic NLP research community", "start_pos": 17, "end_pos": 46, "type": "DATASET", "confidence": 0.6282855123281479}, {"text": "BOLT", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.6778256297111511}]}, {"text": "This new focus presents new challenges, the most obvious of which is the lack of dialectal linguistic resources.", "labels": [], "entities": []}, {"text": "Dialectal text, which is usually user-generated, is also noisy, and the lack of standardized orthography means that users often improvise spelling.", "labels": [], "entities": []}, {"text": "Dialectal data also includes a wider range of topics than formal data genres, such as newswire, due to its informal nature.", "labels": [], "entities": []}, {"text": "These challenges require innovative solutions if NLP applications are to deal with Dialectal Arabic effectively.", "labels": [], "entities": [{"text": "Dialectal Arabic", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.7320884466171265}]}, {"text": "In this paper: \u2022 We describe a process for cheaply and quickly developing parallel corpora for LevantineEnglish and Egyptian-English using Amazon's Mechanical Turk crowdsourcing service ( \u00a73).", "labels": [], "entities": []}, {"text": "\u2022 We use the data to perform a variety of machine translation experiments showing the impact of morphological analysis, the limited value of adding MSA parallel data, the usefulness of cross-dialect training, and the effects of translating from dialect to MSA to English ( \u00a74).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.703269824385643}]}, {"text": "We find that collecting dialect translations has a low cost ($0.03/word) and that relatively small amounts of data has a dramatic impact on translation quality.", "labels": [], "entities": []}, {"text": "When trained on 1.5M words of dialectal data, our system performs 6.3 to 7.0 BLEU points higher than when it is trained on 100 times more MSA data from a mismatching domain.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9994974136352539}]}], "datasetContent": [{"text": "We performed a set of experiments to contrast systems trained using our dialectal parallel corpus with systems trained on a (much larger) MSA-English parallel corpus.", "labels": [], "entities": []}, {"text": "All experiments use the same methods for training, decoding and parameter tuning, and we only varied the corpora used for training, tuning and testing.", "labels": [], "entities": []}, {"text": "The MT system we used is based on a phrase-based hierarchical model similar to that of.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9712271094322205}]}, {"text": "We used GIZA++ to align sentences and extract hierarchical rules.", "labels": [], "entities": []}, {"text": "The decoder used a log-linear model that combines the scores of multiple feature scores, including translation probabilities, smoothed lexical probabilities, a dependency tree language model, in addition to a trigram English language model.", "labels": [], "entities": []}, {"text": "Additionally, we used 50,000 sparse, binary-valued source and target features based on.", "labels": [], "entities": []}, {"text": "The English language model was trained on 7 billion words from the Gigaword and from a web crawl.", "labels": [], "entities": [{"text": "Gigaword", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9666234850883484}]}, {"text": "The feature weights were tuned to maximize the BLEU score on a tuning set using the Expected-BLEU optimization procedure.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9811708033084869}]}, {"text": "The Dialectal Arabic side of our corpus consisted of 1.5M words (1.1M Levantine and 380k Egyptian).", "labels": [], "entities": []}, {"text": "gives statistics about the various train/tune/test splits we used in our experiments.", "labels": [], "entities": []}, {"text": "Since the Egyptian set was so small, we split it only to training/test sets, opting not to have a tuning set.", "labels": [], "entities": [{"text": "Egyptian set", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.808365672826767}]}, {"text": "The MSA training data we used consisted of ArabicEnglish corpora totaling 150M tokens (Arabic side).", "labels": [], "entities": [{"text": "MSA training data", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.6666886707146963}]}, {"text": "The MSA train/tune/test sets were constructed for the DARPA GALE program.", "labels": [], "entities": [{"text": "MSA train/tune/test sets", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.8788754684584481}, {"text": "DARPA GALE", "start_pos": 54, "end_pos": 64, "type": "TASK", "confidence": 0.5208458751440048}]}, {"text": "We report translation quality in terms of BLEU  --: A comparison of translation quality of Egyptian, Levantine, and MSA web text, using various training corpora.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9966862797737122}]}, {"text": "The highest BLEU scores are achieved using the full set of dialectal data (which combines Levantine and Egyptian), since the Egyptian alone is sparse.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9986164569854736}]}, {"text": "For Levantine, adding Egyptian has no effect.", "labels": [], "entities": []}, {"text": "In both cases, adding MSA to the dialectal data results in marginally worse translations. score.", "labels": [], "entities": []}, {"text": "In addition, we also report the OOV rate of the test set relative to the training corpus in each experimental setups.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9886248111724854}]}], "tableCaptions": [{"text": " Table 2: Statistics about the training/tuning/test datasets  used in our experiments. The token counts are calculated  before MADA segmentation.", "labels": [], "entities": [{"text": "MADA segmentation", "start_pos": 127, "end_pos": 144, "type": "TASK", "confidence": 0.7039117962121964}]}, {"text": " Table 3: Comparison of the effect of morphological segmentation when translating MSA web text and Dialectal  Arabic web text. The morphological segmentation uniformly improves translation quality, but the improvements are  more dramatic for MSA than for Dialectal Arabic when comparing similarly-sized training corpora.", "labels": [], "entities": []}, {"text": " Table 4: A comparison of translation quality of Egyptian, Levantine, and MSA web text, using various training corpora.", "labels": [], "entities": []}, {"text": " Table 6: Results on a truly independent test set, consisting of data harvested from Egyptian Facebook pages that are  entirely distinct from the our dialectal training set. The improvements over the MSA baseline are still considerable:  +2.9 BLEU points when no Facebook data is available for tuning and +2.7 with a Facebook tuning set.", "labels": [], "entities": [{"text": "MSA baseline", "start_pos": 200, "end_pos": 212, "type": "DATASET", "confidence": 0.7043387442827225}, {"text": "BLEU", "start_pos": 243, "end_pos": 247, "type": "METRIC", "confidence": 0.9978306889533997}]}, {"text": " Table 7: A comparison of the effectiveness of performing Levantine-to-MSA mapping before translating into English,  versus translating directly from Levantine into English. The mapping from Levantine to MSA was done manually, so it  is an optimistic estimate of what might be done automatically. Although initially helpful to the MSA baseline system,  the usefulness of pivoting through MSA drops as more dialectal data is added, eventually hurting performance.", "labels": [], "entities": [{"text": "Levantine-to-MSA mapping", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.7225858271121979}]}]}