{"title": [{"text": "Training Dependency Parser Using Light Feedback", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce lightly supervised learning for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8933064937591553}]}, {"text": "In this paradigm, the algorithm is initiated with a parser, such as one that was built based on a very limited amount of fully annotated training data.", "labels": [], "entities": []}, {"text": "Then, the algorithm iterates over unlabeled sentences and asks only fora single bit of feedback, rather than a full parse tree.", "labels": [], "entities": []}, {"text": "Specifically, given an example the algorithm outputs two possible parse trees and receives only a single bit indicating which of the two alternatives has more correct edges.", "labels": [], "entities": []}, {"text": "There is no direct information about the correctness of any edge.", "labels": [], "entities": []}, {"text": "We show on dependency parsing tasks in 14 languages that with only 1% of fully labeled data, and light-feedback on the remaining 99% of the training data, our algorithm achieves, on average , only 5% lower performance than when training with fully annotated training set.", "labels": [], "entities": [{"text": "dependency parsing tasks", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.8313128550847372}]}, {"text": "We also evaluate the algorithm in different feedback settings and show its robustness to noise.", "labels": [], "entities": []}], "introductionContent": [{"text": "Supervised learning is a dominant paradigm in machine learning in which a prediction model is built based on examples, each of which is composed of inputs and a corresponding full annotation.", "labels": [], "entities": [{"text": "Supervised learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9076888561248779}]}, {"text": "In the task of parsing, examples are composed of sentences in some language and associated with full parse trees.", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9642927050590515}]}, {"text": "These parse trees are often generated by human annotators.", "labels": [], "entities": []}, {"text": "The annotation process is complex, slow and prone to mistakes as for each sentence a full correct feedback is required.", "labels": [], "entities": []}, {"text": "We describe light-feedback learning which suits learning problems with complex or structured output, like parsing.", "labels": [], "entities": []}, {"text": "After building an initial classifier, our algorithm reduces the work of the annotator from a full annotation of the input sentence to a single bit of information.", "labels": [], "entities": []}, {"text": "Specifically, it provides the annotator with two alternative parses of the input sentence and asks for the single bit indicating which of the alternatives is better.", "labels": [], "entities": []}, {"text": "In 95% of the sentences both alternatives are identical except fora single word.", "labels": [], "entities": []}, {"text": "Thus, the work of the annotator boils down to deciding for some specific word in the sentence which of two possible words should be that word's head.", "labels": [], "entities": []}, {"text": "We show empirically, through simulation, that using only 1% of the training set with full annotation, and the remaining 99% with light annotation, our algorithm achieves an average accuracy of about 80%, only 5% less than a parser built with full annotated training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9992498755455017}]}, {"text": "These results are averaged over 14 languages.", "labels": [], "entities": []}, {"text": "With additional simple relaxations, our algorithm achieves average accuracy of 82.5%, not far from the performance of an algorithm observing full annotation of the data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.997101366519928}]}, {"text": "We also evaluate our algorithm under few noise settings, showing that it is resistant to noise, with a decrease of only 1.5% inaccuracy under about 10% feedback noise.", "labels": [], "entities": []}, {"text": "We defer a discussion of related work to the end of the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the light feedback model using 14 languages: English (the Penn Tree Bank) and the remaining 13 were used in CoNLL 2006 shared task 1 . The number of training sentences in the training datasets is ranging is between about 1.5\u221257K, with an average of about 14K sentences and 50K\u2212700K words.", "labels": [], "entities": [{"text": "Penn Tree Bank", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.9957955876986185}, {"text": "CoNLL 2006 shared task 1", "start_pos": 121, "end_pos": 145, "type": "DATASET", "confidence": 0.9268058180809021}]}, {"text": "The test sets contain an average of \u223c 590 sentences and \u223c10K words for all datasets.", "labels": [], "entities": []}, {"text": "The average number of words per sentence vary from 6 in Chinese to 37 in Arabic.", "labels": [], "entities": []}, {"text": "Experimental Setup For each of the languages we split the data into two parts of relative fraction of p and 1 \u2212 p for p = 10%, 5% and 1% and performed training in two stages.", "labels": [], "entities": []}, {"text": "First, we used the smaller set to build a parser using standard supervised learning procedure.", "labels": [], "entities": []}, {"text": "Specifically, we used MSTParser and ran the MIRA online learning algorithm for 5 iterations.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.9156793355941772}, {"text": "MIRA online learning algorithm", "start_pos": 44, "end_pos": 74, "type": "DATASET", "confidence": 0.6700975149869919}]}, {"text": "This process yielded our initial parser.", "labels": [], "entities": []}, {"text": "Second, the larger portion, which is the remaining of the training set, was used to improve the initial parser using the light feedback algorithm described above.", "labels": [], "entities": []}, {"text": "Our algorithm iterates over the sentences of the larger subset and each sentence was parsed by the current parser (parameterized by w) and asked fora preference between two specific parses for that sentence.", "labels": [], "entities": []}, {"text": "Given this feedback, the algorithm updated its model and proceeded for the next sentence.", "labels": [], "entities": []}, {"text": "The true parse of these sentences was only used to simulate light feedback and it was never provided to the algorithm.", "labels": [], "entities": []}, {"text": "The performance of all the trained parsers was evaluated on a fixed test set.", "labels": [], "entities": []}, {"text": "We performed five iterations of the larger subset during the light feedback training.", "labels": [], "entities": []}], "tableCaptions": []}