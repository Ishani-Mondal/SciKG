{"title": [{"text": "Intra-Speaker Topic Modeling for Improved Multi-Party Meeting Summarization with Integrated Random Walk", "labels": [], "entities": [{"text": "Intra-Speaker Topic Modeling", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6551514565944672}]}], "abstractContent": [{"text": "This paper proposes an improved approach to extrac-tive summarization of spoken multi-party interaction , in which integrated random walk is performed on a graph constructed on topical/ lexical relations.", "labels": [], "entities": [{"text": "extrac-tive summarization of spoken multi-party interaction", "start_pos": 44, "end_pos": 103, "type": "TASK", "confidence": 0.7569517989953359}]}, {"text": "Each utterance is represented as anode of the graph, and the edges' weights are computed from the topical similarity between the utterances, evaluated using probabilistic latent semantic analysis (PLSA), and from word overlap.", "labels": [], "entities": []}, {"text": "We model intra-speaker topics by partially sharing the topics from the same speaker in the graph.", "labels": [], "entities": []}, {"text": "In this paper, we perform experiments on automatically and manually generated transcripts.", "labels": [], "entities": []}, {"text": "For automatic transcripts, our results show that intra-speaker topic sharing and integrating topical/ lexical relations can help include the important utterances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speech summarization is an active and important topic of research (, because multimedia/ spoken documents are more difficult to browse than text or image content.", "labels": [], "entities": [{"text": "Speech summarization", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7077802568674088}]}, {"text": "While earlier work was focused primarily on broadcast news content, recent effort has been increasingly directed to new domains such as lectures () and multi-party interaction (.", "labels": [], "entities": []}, {"text": "We describe experiments on multi-party interaction found in meeting recordings, performing extractive summarization (  on transcripts generated by automatic speech recognition (ASR) and human annotators.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.5298076122999191}, {"text": "automatic speech recognition (ASR)", "start_pos": 147, "end_pos": 181, "type": "TASK", "confidence": 0.7874180873235067}]}, {"text": "Graph-based methods for computing lexical centrality as importance to extract summaries () have been investigated in the context of text summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.7451069056987762}]}, {"text": "Some works focus on maximizing coverage of summaries using the objective function.", "labels": [], "entities": []}, {"text": "Speech summarization carries intrinsic difficulties due to the presence of recognition errors, spontaneous speech effect, and lack of segmentation.", "labels": [], "entities": [{"text": "Speech summarization", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6649814248085022}]}, {"text": "A general approach has been found very successful), in which each utterance in the document d, U = t 1 t 2 ...t i ...t n , represented as a sequence of terms ti , is given an importance score: where s(t i , d), l(t i ), c(t i ), g(t i ) are respectively some statistical measure (such as TF-IDF), linguistic measure (e.g., different part-of-speech tags are given different weights), confidence score and N-gram score for the term ti , and b(U ) is calculated from the grammatical structure of the utterance U , and \u03bb 1 , \u03bb 2 , \u03bb 3 , \u03bb 4 and \u03bb 5 are weighting parameters.", "labels": [], "entities": [{"text": "confidence score", "start_pos": 383, "end_pos": 399, "type": "METRIC", "confidence": 0.973667323589325}]}, {"text": "For each document, the utterances to be used in the summary are then selected based on this score.", "labels": [], "entities": []}, {"text": "In recent work, Chen (2011) proposed a graphical structure to rescore I(U, d), which can model the topical coherence between utterances using random walk within documents.", "labels": [], "entities": []}, {"text": "Similarly, we now use a graph-based approach to consider the importance of terms and the similarity between utterances, where topical and lexical similarity are integrated in the graph, so that utterances topically or lexically similar to more important utterances are given higher scores.", "labels": [], "entities": []}, {"text": "Using topical similarity can compensate the negative effects of recognition errors on similarity evaluated on word overlap to some extent.", "labels": [], "entities": []}, {"text": "In addition, this paper proposes an approach of modeling intraspeaker topics in the graph to improve meeting summarization () using information from multiparty interaction, which is not available in lectures or broadcast news.", "labels": [], "entities": [{"text": "meeting summarization", "start_pos": 101, "end_pos": 122, "type": "TASK", "confidence": 0.5522757321596146}]}], "datasetContent": [{"text": "Automated evaluation utilizes the standard DUC evaluation metric ROUGE) which represents recall over various n-grams statistics from a systemgenerated summary against a set of human generated peer summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.8443792462348938}, {"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9967071413993835}]}, {"text": "F-measures for ROUGE-1 (unigram) and ROUGE-L (longest common subsequence) can be evaluated in exactly the same way, which are used in the following results.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9250783920288086}, {"text": "ROUGE-1", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.8131382465362549}, {"text": "ROUGE-L", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.848289430141449}]}, {"text": "shows the performance achieved by all proposed approaches.", "labels": [], "entities": []}, {"text": "In these experiments, the damping factor, (1 \u2212 \u03b1 \u2212 \u03b2) in (8), is empirically set to 0.1.", "labels": [], "entities": []}, {"text": "Row (a) is the baseline, which use LTE-based statistical measure to compute the importance of utterances I(U, d).", "labels": [], "entities": [{"text": "Row", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9206173419952393}]}, {"text": "Row (b) is the result only considering lexical similarity; row (c) only uses topical similarity.", "labels": [], "entities": []}, {"text": "Row (d) are the results additionally including speaker information such as TopicSim (U i , U j ).", "labels": [], "entities": []}, {"text": "Row (e) is the result performed by integrated random walk (with \u03b1 = 0 and \u03b2 = 0) using parameters that have been optimized on the dev set.", "labels": [], "entities": [{"text": "Row (e)", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9351448863744736}]}], "tableCaptions": [{"text": " Table 1: Maximum relative improvement (RI) with respect to the baseline for all proposed approaches (%).", "labels": [], "entities": [{"text": "relative improvement (RI)", "start_pos": 18, "end_pos": 43, "type": "METRIC", "confidence": 0.9153970599174499}]}]}