{"title": [], "abstractContent": [{"text": "We present an approach to automatically recover hidden attributes of scientific articles, such as whether the author is a native English speaker, whether the author is a male or a female , and whether the paper was published in a conference or workshop proceedings.", "labels": [], "entities": []}, {"text": "We train classifiers to predict these attributes in computational linguistics papers.", "labels": [], "entities": []}, {"text": "The classi-fiers perform well in this challenging domain, identifying non-native writing with 95% accuracy (over a baseline of 67%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.999135434627533}]}, {"text": "We show the benefits of using syntactic features in stylom-etry; syntax leads to significant improvements over bag-of-words models on all three tasks, achieving 10% to 25% relative error reduction.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 172, "end_pos": 196, "type": "METRIC", "confidence": 0.7202377716700236}]}, {"text": "We give a detailed analysis of which words and syntax most predict a particular attribute, and we show a strong correlation between our predictions and a paper's number of citations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Stylometry aims to recover useful attributes of documents from the style of their writing.", "labels": [], "entities": []}, {"text": "In some domains, statistical techniques have successfully deduced author identities, gender ( , native language (), and even whether an author has dementia ().", "labels": [], "entities": []}, {"text": "Stylometric analysis is important to marketers, analysts and social scientists because it provides demographic data directly from raw text.", "labels": [], "entities": [{"text": "Stylometric analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.937815397977829}]}, {"text": "There has been growing interest in applying stylometry in Web 2.0 applications, e.g., detecting the ethnicity of Twitter users), or whether a person is writing deceptive online reviews).", "labels": [], "entities": []}, {"text": "We evaluate stylometric techniques in the novel domain of scientific writing.", "labels": [], "entities": []}, {"text": "Science is a difficult domain; authors are compelled, often explicitly by reviewers/submission guidelines, to comply with normative practices in spelling and grammar.", "labels": [], "entities": []}, {"text": "Moreover, topical clues are less salient than in domains like social media.", "labels": [], "entities": []}, {"text": "Yet science is more than just a good challenge for stylometry; it is an important area in itself.", "labels": [], "entities": []}, {"text": "Systems for scientific stylometry would give sociologists new tools for analyzing academic communities, and new ways to resolve the nature of collaboration in specific articles).", "labels": [], "entities": []}, {"text": "Authors might also use these tools, e.g. to help ensure a consistent style in multi-authored papers (.", "labels": [], "entities": []}, {"text": "Our work includes: New Stylometric Tasks: We predict whether a paper is written: (1) by a native or non-native English speaker, (2) by a male or female, and (3) in the style of a conference or a workshop paper.", "labels": [], "entities": []}, {"text": "The latter is a novel stylometric and bibliometric prediction.", "labels": [], "entities": [{"text": "bibliometric prediction", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.5987307131290436}]}, {"text": "New Stylometric Features: We show the value of syntactic features for stylometry.", "labels": [], "entities": []}, {"text": "Among others, we describe tree substitution grammar fragments, which have not previously been used in stylometry.", "labels": [], "entities": []}, {"text": "TSG fragments are interpretable, efficient, and particularly effective for detecting non-native writing.", "labels": [], "entities": []}, {"text": "While recent studies have mostly evaluated single prediction tasks, we compare different strategies across different tasks on a common dataset and with a common infrastructure.", "labels": [], "entities": []}, {"text": "In addition to contrasting different feature types, we also compare different al., 2011), or whether someone is writing deceptive online reviews).", "labels": [], "entities": []}, {"text": "We evaluate stylometric techniques in the novel domain of scientific writing.", "labels": [], "entities": []}, {"text": "Science is a difficult domain; authors are encouraged, often explicitly by reviewers/submission-guidelines, to comply with normative practices in style, spelling and grammar.", "labels": [], "entities": []}, {"text": "Moreover, topical clues are less salient than in domains like social media.", "labels": [], "entities": []}, {"text": "Success in this challenging domain can bring us closer to correctly analyzing the huge volumes of online text that are currently unmarked for useful author attributes such as gender and native-language.", "labels": [], "entities": []}, {"text": "Yet science is more than just a good steppingstone for stylometry; it is an important area in itself.", "labels": [], "entities": []}, {"text": "Systems for scientific stylometry would give sociologists new tools for analyzing academic communities, and new ways to resolve the nature of collaboration in specific articles).", "labels": [], "entities": []}, {"text": "Authors might also use these tools, e.g., to help ensure a consistent style in multi-authored papers, or to determine sections of a paper needing revision.", "labels": [], "entities": []}, {"text": "The contributions of our paper include: New Stylometric Tasks: We predict whether a paper is written: (1) by a native or non-native speaker, (2) by a male or female, and (3) in the style of a conference or workshop paper.", "labels": [], "entities": []}, {"text": "The latter is a fully novel stylometric and bibliometric prediction.", "labels": [], "entities": []}, {"text": "New Stylometric Features: We show the value of syntactic features for stylometry.", "labels": [], "entities": []}, {"text": "Among others, we describe tree substitution grammar fragments, which have not previously been used in stylometry.", "labels": [], "entities": []}, {"text": "TSG fragments are interpretable, efficient, and particularly effective for detecting non-native writing.", "labels": [], "entities": []}, {"text": "While recent studies have mostly evaluated single prediction tasks, we compare different strategies across different tasks on a common dataset and with a common infrastructure.", "labels": [], "entities": []}, {"text": "In addition to contrasting different feature types, we compare different training strategies, exploring ways to make use of training instances with label uncertainty.", "labels": [], "entities": []}, {"text": "We also provide a detailed analysis that is interesting from a sociolinguistic standpoint.", "labels": [], "entities": []}, {"text": "Precisely what words distinguish non-native writing?", "labels": [], "entities": []}, {"text": "How does the syntax of female authors differ from males?", "labels": [], "entities": []}, {"text": "What are the hallmarks of top-tier papers?", "labels": [], "entities": []}, {"text": "Finally, we identify some strong correlations between our predictions and a paper's citation count, even when controlling for paper venue and origin.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use papers from the ACL Anthology Network (, Release 2011) and exploit its manually-curated meta-data such as normalized author names, affiliations (including country, available up to 2009), and citation counts.", "labels": [], "entities": [{"text": "ACL Anthology Network (, Release 2011)", "start_pos": 23, "end_pos": 61, "type": "DATASET", "confidence": 0.87724868953228}]}, {"text": "We convert each PDF to text 1 but remove text before the Abstract (to anonymize) and after the Acknowledgments/References headings.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9276142716407776}]}, {"text": "We split the text into sentences 2 and filter any documents with fewer than 100 (this removes some short/demo papers, malconverted PDFs, etc.", "labels": [], "entities": []}, {"text": "-about 23% of the 13K papers with affiliation information).", "labels": [], "entities": []}, {"text": "In case the text was garbled, we then filtered the first 3 lines from every file and any line with an '@' symbol (which might be part of an affiliation).", "labels": [], "entities": []}, {"text": "We remove footers like Proceedings of ...,  We take the minority class as the positive class: NES for NativeL, top-tier for Venue and female for Gender, and calculate the precision/recall of these classes.", "labels": [], "entities": [{"text": "precision", "start_pos": 171, "end_pos": 180, "type": "METRIC", "confidence": 0.9994825124740601}, {"text": "recall", "start_pos": 181, "end_pos": 187, "type": "METRIC", "confidence": 0.9754177331924438}]}, {"text": "We tune three hyperparameters for F1-score on development data: (1) the SVM regularization parameter, (2) the threshold for classifying an instance as positive (using the signed hyperplanedistance as the score), and (3) for transductive training ( \u00a75), the fraction of unlabeled data to label as positive.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9890572428703308}]}, {"text": "Statistical significance on held-out test data is assessed with McNemar's test, p<0.05.", "labels": [], "entities": [{"text": "significance", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.8133437037467957}, {"text": "McNemar's test", "start_pos": 64, "end_pos": 78, "type": "METRIC", "confidence": 0.7146827181180319}]}, {"text": "For F1-score, we use the following reasonable Baseline: we label all instances with the label of the minority class (achieving 100% recall but low precision).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.997519314289093}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9908416271209717}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9986305236816406}]}, {"text": "For NativeL, we also created a special test corpus of 273 papers written by first-time ACL authors.", "labels": [], "entities": []}, {"text": "This set closely aligns with the system's potential use as a tool to help new authors compose papers.", "labels": [], "entities": []}, {"text": "Two (native-speaking) annotators manually annotated each paper for whether it was primarily written by a native or non-native speaker (considering both content and author names/affiliations).", "labels": [], "entities": []}, {"text": "The annotators agreed on 90% of decisions, with an inter-annotator kappa of 66%.", "labels": [], "entities": []}, {"text": "We divided the papers into a test set and a development set.", "labels": [], "entities": []}, {"text": "We applied our Bow+Style+Syntax system exactly as trained above, except we tuned its hyperparameters on the new development data.", "labels": [], "entities": []}, {"text": "The system performed quite well on this set, reaching 68% F1 over a baseline of only 27%.", "labels": [], "entities": [{"text": "F1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9998273849487305}]}, {"text": "Moreover, the system also reached 90% accuracy, matching the level of human agreement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9995753169059753}]}], "tableCaptions": [{"text": " Table 1: Number of documents for each task", "labels": [], "entities": []}, {"text": " Table 2: F1 scores for Bow+Style+Syntax system on de- velopment data: The best training strategy and the best  syntactic features depend on the task.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9996645450592041}]}]}