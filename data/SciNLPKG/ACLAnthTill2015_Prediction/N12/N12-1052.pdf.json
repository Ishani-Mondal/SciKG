{"title": [{"text": "Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure", "labels": [], "entities": [{"text": "Direct Transfer of Linguistic Structure", "start_pos": 32, "end_pos": 71, "type": "TASK", "confidence": 0.701791626214981}]}], "abstractContent": [{"text": "It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure.", "labels": [], "entities": [{"text": "prediction of linguistic structure", "start_pos": 128, "end_pos": 162, "type": "TASK", "confidence": 0.689511314034462}]}, {"text": "While previous work has focused primarily on English, we extend these results to other languages along two dimensions.", "labels": [], "entities": []}, {"text": "First, we show that these results hold true fora number of languages across families.", "labels": [], "entities": []}, {"text": "Second, and more interestingly, we provide an algorithm for inducing cross-lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross-lingual structure prediction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9986333250999451}, {"text": "cross-lingual structure prediction", "start_pos": 184, "end_pos": 218, "type": "TASK", "confidence": 0.6752937436103821}]}, {"text": "Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%.", "labels": [], "entities": []}, {"text": "When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%.", "labels": [], "entities": [{"text": "direct transfer of named-entity recognizers", "start_pos": 33, "end_pos": 76, "type": "TASK", "confidence": 0.5631028831005096}]}], "introductionContent": [{"text": "The ability to predict the linguistic structure of sentences or documents is central to the field of natural language processing (NLP).", "labels": [], "entities": [{"text": "predict the linguistic structure of sentences or documents", "start_pos": 15, "end_pos": 73, "type": "TASK", "confidence": 0.852240726351738}, {"text": "natural language processing (NLP)", "start_pos": 101, "end_pos": 134, "type": "TASK", "confidence": 0.822046955426534}]}, {"text": "Structures such as named-entity tag sequences () or sentiment relations are inherently useful in data mining, information retrieval and other user-facing technologies.", "labels": [], "entities": [{"text": "data mining", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.7271176725625992}, {"text": "information retrieval", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.7848988473415375}]}, {"text": "More fundamental structures such as part-of-speech tag sequences) or syntactic parse trees), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005;).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 194, "end_pos": 213, "type": "TASK", "confidence": 0.841810405254364}]}, {"text": "Currently, supervised data-driven methods dominate the literature on linguistic structure prediction.", "labels": [], "entities": [{"text": "linguistic structure prediction", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.7425532142321268}]}, {"text": "Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources.", "labels": [], "entities": []}, {"text": "Notable exceptions include the CoNLL shared tasks and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by.", "labels": [], "entities": []}, {"text": "While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9799466729164124}]}, {"text": "This fact has given rise to a large body of research on unsupervised (), semi-supervised () and transfer () systems for prediction of linguistic structure.", "labels": [], "entities": [{"text": "prediction of linguistic structure", "start_pos": 120, "end_pos": 154, "type": "TASK", "confidence": 0.8483802974224091}]}, {"text": "These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age.", "labels": [], "entities": []}, {"text": "Unsupervised methods are appealing in that they are often inherently language independent.", "labels": [], "entities": []}, {"text": "This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages).", "labels": [], "entities": []}, {"text": "However, the performance for most languages is still well below that of supervised systems and recent work has established that the performance is also below simple methods of linguistic transfer . In this study we focus on semi-supervised and linguistic-transfer methods for multilingual structure prediction.", "labels": [], "entities": [{"text": "linguistic transfer", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.7406657338142395}, {"text": "multilingual structure prediction", "start_pos": 276, "end_pos": 309, "type": "TASK", "confidence": 0.7064113219579061}]}, {"text": "In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 1.", "labels": [], "entities": [{"text": "structure prediction", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.7453424334526062}]}, {"text": "Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure.", "labels": [], "entities": []}, {"text": "Previous studies on this approach have typically focused only on a small set of languages and tasks).", "labels": [], "entities": []}, {"text": "Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.8408902585506439}, {"text": "named-entity recognition (NER)", "start_pos": 103, "end_pos": 133, "type": "TASK", "confidence": 0.8429328858852386}]}, {"text": "This is the first study with such abroad view on this subject, in terms of language diversity.", "labels": [], "entities": []}, {"text": "2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages.", "labels": [], "entities": [{"text": "Cross-lingual word cluster", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.6151575346787771}, {"text": "transferring linguistic structure from English", "start_pos": 43, "end_pos": 89, "type": "TASK", "confidence": 0.8567562580108643}]}, {"text": "We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages.", "labels": [], "entities": []}, {"text": "This is achieved by means of a probabilistic model overlarge amounts of monolingual data in two languages, coupled with parallel data through which cross-lingual word-cluster constraints are enforced.", "labels": [], "entities": []}, {"text": "We show that by augmenting the delexicalized direct transfer system of McDonald et al.", "labels": [], "entities": []}, {"text": "(2011) with cross-lingual cluster features, we are able to reduce its error by up to 13% relative.", "labels": [], "entities": [{"text": "error", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9844121336936951}]}, {"text": "Further, we show that by applying the same method to direct-transfer NER, we achieve a relative error reduction of 26%.", "labels": [], "entities": [{"text": "NER", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.7680452466011047}, {"text": "error reduction", "start_pos": 96, "end_pos": 111, "type": "METRIC", "confidence": 0.925559014081955}]}, {"text": "By incorporating cross-lingual cluster features in a linguistic transfer system, we are for the first time combining SSL and cross-lingual transfer.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before moving onto the multilingual setting, we conduct a set of monolingual experiments where we evaluate the use of the monolingual word clusters just described as features for dependency parsing and NER.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.8255724012851715}]}, {"text": "In the parsing experiments, we study the following thirteen languages: 1 Danish (DA), German (DE), Greek (EL), English (EN), Spanish (ES), French (FR), Italian (IT), Korean (KO), Dutch (NL), Portugese (PT), Russian (RU), Swedish (SV) and Chinese (ZH) -representing the Chinese, Germanic, Hellenic, Romance, Slavic, Altaic and Korean genera.", "labels": [], "entities": [{"text": "parsing", "start_pos": 7, "end_pos": 14, "type": "TASK", "confidence": 0.9647385478019714}]}, {"text": "In the NER experiments, we study three Germanic languages: German (DE), English (EN) and Dutch (NL); and one Romance language: Spanish (ES).", "labels": [], "entities": [{"text": "NER", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9043316841125488}]}, {"text": "Details of the labeled and unlabeled data sets used are given in Appendix A. For all experiments we fixed the number of clusters to 256 as this performed well on held-out data.", "labels": [], "entities": [{"text": "Appendix A.", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9542633891105652}]}, {"text": "Furthermore, we only clustered the 1 million most frequent word types in each language for both efficiency and sparsity reasons.", "labels": [], "entities": []}, {"text": "For languages in which our unlabeled data did not have at least 1 million types, we considered all types.", "labels": [], "entities": []}, {"text": "In our first set of experiments on using cross-lingual cluster features, we evaluate direct transfer of our EN parser, trained on Stanford style dependencies), to the the ten non-EN Indo-European languages listed in Section 3.", "labels": [], "entities": []}, {"text": "We exclude KO and ZH as initial experiments proved direct transfer a poor technique when transferring parsers between such diverse languages.", "labels": [], "entities": []}, {"text": "We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of, which only has features derived from universal part-of-speech tags, projected from English with the method of , to the same model when adding features derived from cross-lingual clusters.", "labels": [], "entities": []}, {"text": "In both cases the feature models are the same as those used in Section 3.1, except that they are delexicalized by removing all lexical word-identity features.", "labels": [], "entities": []}, {"text": "We evaluate both the PRO-JECTED CLUSTERS and the X-LINGUAL CLUSTERS.", "labels": [], "entities": [{"text": "PRO-JECTED CLUSTERS", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.34659697115421295}]}, {"text": "For these experiments we train the perceptron for only five epochs in order to prevent over-fitting, which is an acute problem due to the divergence between the training and testing data sets in this setting.", "labels": [], "entities": []}, {"text": "Furthermore, in accordance to standard practices we only evaluate unlabeled attachment score (UAS) due to the fact that each treebank uses a different -possibly non-overlapping -label set.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 66, "end_pos": 98, "type": "METRIC", "confidence": 0.7949129988749822}]}, {"text": "In our second set of experiments, we evaluate direct transfer of a NER system trained on EN to DE, ES and NL.", "labels": [], "entities": [{"text": "NER", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8871185183525085}, {"text": "DE", "start_pos": 95, "end_pos": 97, "type": "DATASET", "confidence": 0.6084175705909729}]}, {"text": "We use the same feature models as in the monolingual case, with the exception that we use universal part-of-speech tags for all languages and we remove the capitalization feature when transferring from EN to DE.", "labels": [], "entities": []}, {"text": "Capitalization is both a prevalent and highly predictive feature of named-entities in EN, while in DE, capitalization is even more prevalent, but has very low predictive power.", "labels": [], "entities": []}, {"text": "Interestingly, while delexicalization has shown to be important for direct transfer of dependency-parsers ), we noticed in preliminary experiments that it substantially degrades performance for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 194, "end_pos": 197, "type": "TASK", "confidence": 0.9568816423416138}]}, {"text": "We hypothesize that this is because word features are predictive of common proper names and that these are often translated directly across languages, at least in the case of newswire text.", "labels": [], "entities": []}, {"text": "As for the transfer parser, when training the source NER model, we regularize the model more heavily by setting \u03c3 = 0.1.", "labels": [], "entities": []}, {"text": "Appendix A contains the details of the training, testing, unlabeled and parallel/aligned data sets.", "labels": [], "entities": []}, {"text": "lists the results of the transfer experiments for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.9118106067180634}]}, {"text": "The baseline results are comparable to those in McDonald et al.", "labels": [], "entities": []}, {"text": "(2011) and thus also significantly outperform the results of recent unsupervised approaches.", "labels": [], "entities": []}, {"text": "Importantly, crosslingual cluster features are helpful across the board and give a relative error reduction ranging from 3% for DA to 13% for PT, with an average reduction of 6%, in terms of unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "error reduction", "start_pos": 92, "end_pos": 107, "type": "METRIC", "confidence": 0.9641532003879547}, {"text": "PT", "start_pos": 142, "end_pos": 144, "type": "METRIC", "confidence": 0.9874978065490723}, {"text": "unlabeled attachment score (UAS)", "start_pos": 191, "end_pos": 223, "type": "METRIC", "confidence": 0.8246218860149384}]}, {"text": "This shows the utility of cross-lingual cluster features for syntactic transfer.", "labels": [], "entities": [{"text": "syntactic transfer", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.8487792611122131}]}, {"text": "However, X-LINGUAL CLUSTERS provides roughly the same performance as PROJECTED CLUSTERS suggesting that even simple methods of cross-lingual clustering are sufficient for direct transfer dependency parsing.", "labels": [], "entities": [{"text": "direct transfer dependency parsing", "start_pos": 171, "end_pos": 205, "type": "TASK", "confidence": 0.6026755198836327}]}], "tableCaptions": [{"text": " Table 3: Supervised parsing results measured with labeled attachment score (LAS) on the test set. All results are  statistically significant at p < 0.05, except FR and NL.", "labels": [], "entities": [{"text": "labeled attachment score (LAS)", "start_pos": 51, "end_pos": 81, "type": "METRIC", "confidence": 0.9041251639525095}, {"text": "FR", "start_pos": 162, "end_pos": 164, "type": "METRIC", "confidence": 0.9943743944168091}, {"text": "NL", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9669495224952698}]}, {"text": " Table 4: Supervised NER results measured with F 1 -score  on the CoNLL 2002/2003 development and test sets.", "labels": [], "entities": [{"text": "NER", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9129104614257812}, {"text": "F 1 -score", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9823070168495178}, {"text": "CoNLL 2002/2003 development and test sets", "start_pos": 66, "end_pos": 107, "type": "DATASET", "confidence": 0.957717128098011}]}, {"text": " Table 4. Introducing word cluster features for  NER reduces relative errors on the test set by 21%  (39% on the development set) on average. Broken  down per language, reductions on the test set vary  from substantial for NL (30%) and EN (26%), down  to more modest for DE (17%) and ES (12%). The  addition of cluster features most markedly improve", "labels": [], "entities": []}, {"text": " Table 5: Direct transfer dependency parsing from English. Results measured by unlabeled attachment score (UAS).  ONLY SUBJECT/OBJECT RELATIONS -UAS measured only over words marked as subject/object in the evaluation data.", "labels": [], "entities": [{"text": "Direct transfer dependency parsing", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.6782352328300476}, {"text": "unlabeled attachment score (UAS)", "start_pos": 79, "end_pos": 111, "type": "METRIC", "confidence": 0.7856358190377554}, {"text": "ONLY SUBJECT/OBJECT RELATIONS -UAS", "start_pos": 114, "end_pos": 148, "type": "METRIC", "confidence": 0.77425502879279}]}, {"text": " Table 6. While the perfor- mance of the transfer systems is very poor when no  word clusters are used, adding cross-lingual word  clusters give substantial improvements across all lan- guages. The simple PROJECTED CLUSTERS work  well, but the X-LINGUAL CLUSTERS provide even  larger improvements. On average the latter reduce", "labels": [], "entities": []}]}