{"title": [{"text": "Minimum-Risk Training of Approximate CRF-Based NLP Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "Conditional Random Fields (CRFs) area popular formalism for structured prediction in NLP.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.7378990352153778}]}, {"text": "It is well known how to train CRFs with certain topologies that admit exact inference, such as linear-chain CRFs.", "labels": [], "entities": []}, {"text": "Some NLP phenomena , however, suggest CRFs with more complex topologies.", "labels": [], "entities": []}, {"text": "Should such models be used, considering that they make exact inference intractable?", "labels": [], "entities": []}, {"text": "(2011) recently argued for training parameters to minimize the task-specific loss of whatever approximate inference and decoding methods will be used attest time.", "labels": [], "entities": []}, {"text": "We apply their method to three NLP problems, showing that (i) using more complex CRFs leads to improved performance, and that (ii) minimum-risk training learns more accurate models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conditional Random Fields (CRFs) ( are often used to model dependencies among linguistic variables.", "labels": [], "entities": []}, {"text": "CRF-based models have improved the state of the art in a number of natural language processing (NLP) tasks ranging from partof-speech tagging to information extraction and sentiment analysis ().", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.7960087358951569}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.8123091757297516}, {"text": "sentiment analysis", "start_pos": 172, "end_pos": 190, "type": "TASK", "confidence": 0.9220532178878784}]}, {"text": "Robust and theoretically sound training procedures have been developed for CRFs when the model can be used with exact inference and decoding.", "labels": [], "entities": [{"text": "CRFs", "start_pos": 75, "end_pos": 79, "type": "TASK", "confidence": 0.9512301683425903}]}, {"text": "However, some NLP problems seem to call for higher-treewidth graphical models in which exact inference is expensive or intractable.", "labels": [], "entities": []}, {"text": "These \"loopy\" CRFs have cyclic connections among the output and/or latent variables.", "labels": [], "entities": []}, {"text": "Alas, standard learning procedures assume exact inference: they do not compensate for approximations that will be used attest time, and can go surprisingly awry if approximate inference is used at training time (.", "labels": [], "entities": []}, {"text": "While NLP research has been consistently evolving toward more richly structured models, one may hesitate to add dependencies to a graphical model if there is a danger that this will end up hurting performance through approximations.", "labels": [], "entities": []}, {"text": "In this paper we illustrate how to address this problem, even for extremely interconnected models in which every pair of output variables is connected.", "labels": [], "entities": []}, {"text": "showed that if approximate inference will be used attest time, it maybe beneficial to use a learning procedure that does not converge to the true model but to one that performs well under the approximations.", "labels": [], "entities": []}, {"text": "argue for minimizing a certain non-convex training objective, namely the empirical risk of the entire system comprising the CRF together with whatever approximate inference and decoding procedures will be used attest time.", "labels": [], "entities": []}, {"text": "They regard this entire system as simply a complex decision rule, analogous to a neural network, and show how to use back-propagation to tune its parameters to locally minimize the empirical risk (i.e., the average task-specific loss on training data).", "labels": [], "entities": []}, {"text": "show that on certain synthetic-data problems, this frequentist training regimen significantly reduced test-data loss compared to approximate maximum likelihood estimation (MLE).", "labels": [], "entities": [{"text": "approximate maximum likelihood estimation (MLE", "start_pos": 129, "end_pos": 175, "type": "METRIC", "confidence": 0.7491101721922556}]}, {"text": "However, this method has not been evaluated on real-world problems until now.", "labels": [], "entities": []}, {"text": "We will refer to the  approach as \"ERMA\"-Empirical Risk Minimization under Approximations.", "labels": [], "entities": [{"text": "ERMA\"-Empirical Risk Minimization", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.48847238123416903}]}, {"text": "ERMA is attractive for NLP because the freedom to use arbitrarily structured graphical models makes it possible to include latent linguistic variables, predict complex structures such as parses, and do collective prediction in relational domains).", "labels": [], "entities": []}, {"text": "In training, ERMA considers not only the approximation method but also the task-specific loss function.", "labels": [], "entities": [{"text": "ERMA", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.9254875183105469}]}, {"text": "This means that ERMA is careful to use the additional variables and dependencies only in ways that help training set performance.", "labels": [], "entities": []}, {"text": "(Overfitting on the enlarged parameter set should be avoided through regularization.)", "labels": [], "entities": []}, {"text": "We have developed a simple syntax for specifying CRFs with complex structures, and a software package (available from http://www.clsp.", "labels": [], "entities": [{"text": "specifying CRFs", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.6923182606697083}]}, {"text": "jhu.edu/ \u02dc ves/software.html) that allows ERMA training of these CRFs for several popular loss functions (e.g., accuracy, mean-squared error, F-measure).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9988471269607544}, {"text": "mean-squared error", "start_pos": 122, "end_pos": 140, "type": "METRIC", "confidence": 0.8813921809196472}, {"text": "F-measure", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9849338531494141}]}, {"text": "In this paper, we use these tools to revisit three previously studied NLP applications that can be modeled naturally with approximate CRFs (we will use approximate CRFs to refer to CRFbased systems that are used with approximations in inference or decoding).", "labels": [], "entities": []}, {"text": "We show that (i) natural language can be modeled more effectively with CRFs that are not restricted to a linear structure and (ii) that ERMA training represents an improvement over previous learning methods.", "labels": [], "entities": []}, {"text": "The first application, predicting congressional votes, has not been previously modeled with CRFs.", "labels": [], "entities": [{"text": "predicting congressional votes", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.8941692113876343}]}, {"text": "By using a more principled probabilistic approach, we are able to improve the state-of-the-art accuracy from 71.2% to 78.2% when training to maximize the approximate log-likelihood of the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9974837303161621}]}, {"text": "By switching to ERMA training, we improve this result further to 85.1%.", "labels": [], "entities": []}, {"text": "The second application, information extraction from seminar announcements, has been modeled previously with skip-chain CRFs).", "labels": [], "entities": [{"text": "information extraction from seminar announcements", "start_pos": 24, "end_pos": 73, "type": "TASK", "confidence": 0.8696346879005432}]}, {"text": "The skip-chain CRF introduces loops and requires approximate inference, which motivates minimum risk training.", "labels": [], "entities": []}, {"text": "Our results show that ERMA training improves Fmeasures from 89.5 to 90.9 (compared to 87.1 for the model without skip-chains).", "labels": [], "entities": [{"text": "Fmeasures", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9987382292747498}]}, {"text": "Finally, for our third application, we perform collective multi-label text classification.", "labels": [], "entities": [{"text": "multi-label text classification", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.5754012068112692}]}, {"text": "We follow previous work and use a fully connected CRF to model all pairwise dependencies between labels.", "labels": [], "entities": []}, {"text": "We observe similar trends for this task: switching from a maximum entropy model that does not model label dependencies to a loopy CRF leads to an improvement in F-measure from 81.6 to 84.0, and using ERMA leads to additional improvement (84.7).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9965217113494873}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results. The top of the table lists the loss function used for each problem and the score for the best exact  baseline. The bottom lists results for the full models used with loopy BP. Models are tested with either sum-product  BP (sumprod) or max-product BP (maxprod) and trained with MLE or the minimum risk criterion. Min-risk training  runs are either annealed (maxprod), which matches max-product test, or not (sumprod), which matches sum-product  test; grey cells in the table indicate matched training and test settings. In each column, we boldface the best result as  well as all results that are not significantly worse (paired permutation test, p < 0.05).", "labels": [], "entities": [{"text": "MLE", "start_pos": 296, "end_pos": 299, "type": "METRIC", "confidence": 0.9950355291366577}]}]}