{"title": [{"text": "Towards Using EEG to Improve ASR Accuracy", "labels": [], "entities": [{"text": "ASR", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.6802007555961609}, {"text": "Accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.7500952482223511}]}], "abstractContent": [{"text": "We report on a pilot experiment to improve the performance of an automatic speech recognizer (ASR) by using a single-channel EEG signal to classify the speaker's mental state as reading easy or hard text.", "labels": [], "entities": [{"text": "automatic speech recognizer (ASR)", "start_pos": 65, "end_pos": 98, "type": "TASK", "confidence": 0.8095323443412781}]}, {"text": "We use a previously published method (Mostow et al., 2011) to train the EEG classifier.", "labels": [], "entities": [{"text": "EEG classifier", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.6071335673332214}]}, {"text": "We use its prob-abilistic output to control weighted interpolation of separate language models for easy and difficult reading.", "labels": [], "entities": []}, {"text": "The EEG-adapted ASR achieves higher accuracy than two baselines.", "labels": [], "entities": [{"text": "EEG-adapted ASR", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.5077967941761017}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9988812804222107}]}, {"text": "We analyze how its performance depends on EEG classification accuracy.", "labels": [], "entities": [{"text": "EEG classification", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7174535989761353}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.7025087475776672}]}, {"text": "This pilot result is a step towards improving ASR more generally by using EEG to distinguish mental states.", "labels": [], "entities": [{"text": "ASR", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9948871731758118}]}], "introductionContent": [{"text": "Humans use speech to communicate what's on their mind.", "labels": [], "entities": []}, {"text": "However, until now, automatic speech recognizers (ASR) and dialogue systems have had no direct way to take into account what is going on in a speaker's mind.", "labels": [], "entities": [{"text": "automatic speech recognizers (ASR)", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.7867312033971151}]}, {"text": "Some work has attempted to infer cognitive states from volume and speaking rate to adapt language modeling ( or from query click logs) to detect domains.", "labels": [], "entities": []}, {"text": "A new way to address this limitation is to infer mental states from electroencephalogram (EEG) signals.", "labels": [], "entities": []}, {"text": "EEG is a voltage signal that can be measured on the surface of the scalp, arising from large areas of coordinated neural activity.", "labels": [], "entities": [{"text": "EEG", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.6134961247444153}]}, {"text": "This neural activity varies as a function of development, mental state, and cognitive activity, and EEG can measurably detect such variation.", "labels": [], "entities": []}, {"text": "Recently, a few companies have scaled back medical grade EEG technology to create portable EEG headsets that are commercially available and simple to use.", "labels": [], "entities": []}, {"text": "The NeuroSky MindSet, for example, is an audio headset equipped with a single-channel EEG sensor.", "labels": [], "entities": [{"text": "NeuroSky MindSet", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.7715573608875275}]}, {"text": "It measures the voltage between an electrode that rests on the forehead and electrodes in contact with the ear.", "labels": [], "entities": []}, {"text": "Unlike the multi-channel electrode nets worn in labs, the sensor requires no gel or saline for recording, and requires no expertise to wear.", "labels": [], "entities": []}, {"text": "Even with the limitations of recording from only a single sensor and working with untrained users, Furthermore, used its output signal to distinguish easy from difficult reading, achieving above-chance accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.9940186738967896}]}, {"text": "Here we build on that work by using the output of such classifiers to adapt language models for ASR and thereby improve recognition accuracy.", "labels": [], "entities": [{"text": "ASR", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9821593165397644}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9174483418464661}]}, {"text": "The most similar work is use of electromyographic (EMG) signals generated by human articulatory muscles in producing speech.", "labels": [], "entities": []}, {"text": "They showed that augmenting acoustic features with these EMG features can achieve rudimentary silent speech detection.", "labels": [], "entities": [{"text": "silent speech detection", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.6431402365366617}]}, {"text": "used electrocorticographic (ECoG) recordings from nonprimary auditory cortex in the human superior temporal gyrus to reconstruct acoustic information in speech sounds.", "labels": [], "entities": []}, {"text": "Our work differs from these efforts in that we use a consumer-grade single-channel EEG sensor measuring frontal lobe activities, and that we use the detected mental state just to help improve ASR performance rather than to dictate or reconstruct speech, which are much harder tasks.", "labels": [], "entities": [{"text": "ASR", "start_pos": 192, "end_pos": 195, "type": "TASK", "confidence": 0.9937865734100342}]}, {"text": "Section 2 describes how to use machine learning to distinguish mental states associated with easy and difficult readings.", "labels": [], "entities": []}, {"text": "Section 3 describes how we use EEG classifier output to adapt ASR language models.", "labels": [], "entities": [{"text": "ASR language", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.9151412546634674}]}, {"text": "Section 4 uses an oracle simulation to show how increasing EEG classifier accuracy will affect ASR accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9193817377090454}, {"text": "ASR", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.9879043698310852}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.8670525550842285}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: ASR performance of proposed approaches using EEG-based classification of mental states.", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.953414261341095}, {"text": "EEG-based classification of mental states", "start_pos": 55, "end_pos": 96, "type": "TASK", "confidence": 0.8080126762390136}]}]}