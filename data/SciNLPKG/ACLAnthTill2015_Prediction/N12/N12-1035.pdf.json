{"title": [{"text": "Insertion and Deletion Models for Statistical Machine Translation", "labels": [], "entities": [{"text": "Insertion and Deletion", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8460275530815125}, {"text": "Statistical Machine Translation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.8561002413431803}]}], "abstractContent": [{"text": "We investigate insertion and deletion models for hierarchical phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "insertion and deletion", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.8245833516120911}, {"text": "phrase-based statistical machine translation", "start_pos": 62, "end_pos": 106, "type": "TASK", "confidence": 0.5799824222922325}]}, {"text": "Insertion and deletion models are designed as a means to avoid the omission of content words in the hypotheses.", "labels": [], "entities": [{"text": "Insertion and deletion", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6151531239350637}]}, {"text": "In our case, they are implemented as phrase-level feature functions which count the number of inserted or deleted words.", "labels": [], "entities": []}, {"text": "An English word is considered inserted or deleted based on lexical probabilities with the words on the foreign language side of the phrase.", "labels": [], "entities": []}, {"text": "Related techniques have been employed before by Och et al.", "labels": [], "entities": []}, {"text": "(2003) in an n-best reranking framework and by Mauser et al.", "labels": [], "entities": []}, {"text": "(2006) and Zens (2008) in a standard phrase-based translation system.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.6911681592464447}]}, {"text": "We propose novel thresholding methods in this work and study insertion and deletion features which are based on two different types of lexicon models.", "labels": [], "entities": []}, {"text": "We give an extensive experimental evaluation of all these variants on the NIST Chinese\u2192English translation task.", "labels": [], "entities": [{"text": "NIST Chinese\u2192English translation task", "start_pos": 74, "end_pos": 111, "type": "TASK", "confidence": 0.8018929362297058}]}, {"text": "1 Insertion and Deletion Models In hierarchical phrase-based translation (Chiang, 2005), we deal with rules X \u2192 \u03b1, \u03b2, \u223c where \u03b1, \u03b2 is a bilingual phrase pair that may contain symbols from a non-terminal set, i.e. \u03b1 \u2208 (N \u222a V F) + and \u03b2 \u2208 (N \u222aV E) + , where VF and V E are the source and target vocabulary, respectively, and N is a non-terminal set which is shared by source and target.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6340267658233643}]}, {"text": "The left-hand side of the rule is a non-terminal symbol X \u2208 N , and the \u223c relation denotes a one-to-one correspondence between the non-terminals in \u03b1 and in \u03b2.", "labels": [], "entities": []}, {"text": "Let J \u03b1 denote the number of terminal symbols in \u03b1 and I \u03b2 the number of terminal symbols in \u03b2.", "labels": [], "entities": []}, {"text": "Indexing \u03b1 with j, i.e. the symbol \u03b1 j , 1 \u2264 j \u2264 J \u03b1 , denotes the j-th terminal symbol on the source side of the phrase pair \u03b1, \u03b2, and analogous with \u03b2 i , 1 \u2264 i \u2264 I \u03b2 , on the target side.", "labels": [], "entities": []}, {"text": "With these notational conventions, we now define our insertion and deletion models, each in both source-to-target and target-to-source direction.", "labels": [], "entities": []}, {"text": "We give phrase-level scoring functions for the four features.", "labels": [], "entities": []}, {"text": "In our implementation, the feature values are precomputed and written to the phrase table.", "labels": [], "entities": []}, {"text": "The features are then incorporated directly into the log-linear model combination of the decoder.", "labels": [], "entities": []}, {"text": "Our insertion model in source-to-target direction t s2tIns (\u00b7) counts the number of inserted words on the target side \u03b2 of a hierarchical rule with respect to the source side \u03b1 of the rule: t s2tIns (\u03b1, \u03b2) = I \u03b2 i=1 J\u03b1 j=1 p(\u03b2 i |\u03b1 j) < \u03c4 \u03b1 j (1) Here, [\u00b7] denotes a true or false statement: The result is 1 if the condition is true and 0 if the condition is false.", "labels": [], "entities": []}, {"text": "The model considers an occurrence of a target word e an insertion iff no source word f exists within the phrase where the lexical translation probability p(e|f) is greater than a corresponding threshold \u03c4 f.", "labels": [], "entities": []}, {"text": "We employ lexical translation probabilities from two different types of lexicon models, a model which is extracted from word-aligned training data and-given the word alignment matrix-relies on pure relative frequencies, and the IBM model 1 lexicon (cf. Section 2).", "labels": [], "entities": [{"text": "IBM model 1 lexicon", "start_pos": 228, "end_pos": 247, "type": "DATASET", "confidence": 0.9098811894655228}]}, {"text": "For \u03c4 f , previous authors have used a fixed heuristic value which was equal for all 347", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We present empirical results obtained with the different insertion and deletion model variants on the Chinese\u2192English 2008 NIST task.", "labels": [], "entities": [{"text": "Chinese\u2192English 2008 NIST task", "start_pos": 102, "end_pos": 132, "type": "DATASET", "confidence": 0.7606084843476614}]}, {"text": "To setup our systems, we employ the open source statistical machine translation toolkit Jane (, which is freely available for non-commercial use.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.6198887626330057}, {"text": "Jane", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.7842478156089783}]}, {"text": "Jane provides efficient C++ implementations for hierarchical phrase extraction, optimization of log-linear feature weights, and parsing-based decoding algorithms.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7446970194578171}]}, {"text": "In our experiments, we use the cube pruning algorithm to carryout the search.", "labels": [], "entities": []}, {"text": "We work with a parallel training corpus of 3.0M Chinese-English sentence pairs (77.5M Chinese / 81.0M English running words).", "labels": [], "entities": []}, {"text": "The counts for the RF lexicon models are computed from a symmetrized word alignment, the IBM-1 models are produced with GIZA++.", "labels": [], "entities": [{"text": "IBM-1", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.8908454775810242}]}, {"text": "When extracting phrases, we apply several restrictions, in particular a maximum length of 10 on source and target side for lexical phrases, a length limit of five (including non-terminal symbols) for hierarchical phrases, and no more than two gaps per phrase.", "labels": [], "entities": []}, {"text": "The models integrated into the baseline are: phrase translation probabilities and RF lexical translation probabilities on phrase level, each for both translation directions, length penalties on word and phrase level, binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, source-to-target and target-to-source phrase length ratios, four binary features marking phrases that have been seen more than one, two, three or five times, respectively, and an n-gram language model.", "labels": [], "entities": [{"text": "phrase translation probabilities", "start_pos": 45, "end_pos": 77, "type": "TASK", "confidence": 0.7878689368565878}]}, {"text": "The language model is a 4-gram with modified Kneser-Ney smoothing which was trained with the SRILM toolkit) on a large collection of English data including the target side of the parallel corpus and the LDC Gigaword v3.", "labels": [], "entities": []}, {"text": "Model weights are optimized against BLEU) with standard Minimum Error Rate Training, performance is measured with BLEU and TER).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9984245300292969}, {"text": "Minimum Error Rate Training", "start_pos": 56, "end_pos": 83, "type": "METRIC", "confidence": 0.9046474397182465}, {"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9989759922027588}, {"text": "TER", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.994445264339447}]}, {"text": "We employ MT06 as development set, MT08 is used as unseen test set.", "labels": [], "entities": [{"text": "MT06", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.8897069096565247}, {"text": "MT08", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.9034480452537537}]}, {"text": "The empirical evaluation of all our setups is presented in.", "labels": [], "entities": []}, {"text": "With the best model variant, we obtain a significant improvement (90% confidence) of +1.0 points BLEU over the baseline on MT08.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9996825456619263}, {"text": "MT08", "start_pos": 123, "end_pos": 127, "type": "DATASET", "confidence": 0.9537485837936401}]}, {"text": "A consistent trend towards one of the variants cannot be observed.", "labels": [], "entities": []}, {"text": "The results on the test set with RF lexicons or IBM-1, insertion or deletion models, and (in most of the cases) with all of the thresholding methods are roughly at the same level.", "labels": [], "entities": [{"text": "IBM-1", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.8001691699028015}]}, {"text": "For comparison we also give a result with an unaligned word count model (+0.4 BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9982782602310181}]}, {"text": "(2011) recently reported substantial improvements over typical hierarchical baseline setups by just including phrase-level IBM-1 scores.", "labels": [], "entities": []}, {"text": "When we add the IBM-1 models directly, our baseline is outperformed by +1.7 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9982561469078064}]}, {"text": "We tried to get improvements with insertion and deletion models over this setup again, but the positive effect was largely diminished.", "labels": [], "entities": [{"text": "insertion", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9220636487007141}]}, {"text": "In one of our strongest setups, which includes discriminative word lexicon models (DWL), triplet lexicon models and a discriminative reordering model (discrim.", "labels": [], "entities": []}, {"text": "RO) , insertion models still yield a minimal gain, though.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results for the NIST Chinese\u2192English translation task (truecase). s2t denotes source-to-target  scoring, t2s target-to-source scoring. Bold font indicates results that are significantly better than the baseline (p < .1).", "labels": [], "entities": [{"text": "NIST Chinese\u2192English translation task", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.7079546252886454}]}]}