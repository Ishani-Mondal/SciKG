{"title": [{"text": "Ebiquity: Paraphrase and Semantic Similarity in Twitter using Skipgram", "labels": [], "entities": [{"text": "Skipgram", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9113110303878784}]}], "abstractContent": [{"text": "We describe the system we developed to participate in SemEval 2015 Task 1, Paraphrase and Semantic Similarity in Twitter.", "labels": [], "entities": [{"text": "SemEval 2015 Task 1", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.859213724732399}]}, {"text": "We create similarity vectors from two-skip trigrams of prepro-cessed tweets and measure their semantic similarity using our UMBC-STS system.", "labels": [], "entities": [{"text": "UMBC-STS", "start_pos": 124, "end_pos": 132, "type": "DATASET", "confidence": 0.9325844049453735}]}, {"text": "The best result is ranked eleventh out of eighteen teams with F1 score of 0.599.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9844731092453003}]}], "introductionContent": [{"text": "In this task, participants were given pairs of text sequences from Twitter trends and produced a binary judgment for each stating whether or not they are paraphrases (e.g., semantically the same) and optionally a graded score (0.0 to 1.0) measuring their degree of semantic equivalence.", "labels": [], "entities": []}, {"text": "For example, for the trending topic \"A Walk to Remember\" (a film released in 2002), the pair A Walk to Remember is the definition of true love\" and \"A Walk to Remember is on and Im in town and Im upset\" might be judged as not paraphrases with score 0.2 whereas the pair \"A Walk to Remember is the definition of true love\" and \"A Walk to Remember is the cutest thing\" could be judged as paraphrases with a score of 0.6.", "labels": [], "entities": [{"text": "A Walk to Remember\" (a film released in 2002)", "start_pos": 37, "end_pos": 82, "type": "TASK", "confidence": 0.7034925520420074}]}, {"text": "Many methods have been proposed to solve the paraphrase detection problem.", "labels": [], "entities": [{"text": "paraphrase detection problem", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.961027463277181}]}, {"text": "Early approaches were often based on lexical matching techniques, e.g., word n-gram overlap ( or predicate argument tuple matching).", "labels": [], "entities": [{"text": "word n-gram overlap", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.5822718739509583}, {"text": "predicate argument tuple matching", "start_pos": 97, "end_pos": 130, "type": "TASK", "confidence": 0.60697390884161}]}, {"text": "Some other approaches that go beyond simple lexical matching have also been developed.", "labels": [], "entities": []}, {"text": "For example,) estimated semantic similarity of sentence pairs with word-to-word similarity measures and a word specificity measure.", "labels": [], "entities": []}, {"text": "() uses text canonicalization to transfer texts of similar meaning into the same surface text with a higher probability than those with different meaning.", "labels": [], "entities": []}, {"text": "Many of these approaches adopt distributional semantic models, but limited to a word level.", "labels": [], "entities": []}, {"text": "To extend distributional semantic models beyond words, several researchers have learned phrase or sentence representation by composing the representation of individual words).", "labels": [], "entities": [{"text": "phrase or sentence representation", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.6079492643475533}]}, {"text": "An alternative approach by) represents phrases and sentences with fixed matrices consisting of pooled word and phrase pairwise similarities.", "labels": [], "entities": []}, {"text": "() learns representation of sentences directly by predicting context without composition of words.", "labels": [], "entities": []}, {"text": "In our work, we judge that two sentences are paraphrases if they have high degree of semantic similarity.", "labels": [], "entities": []}, {"text": "We use the UMBC-Semantic Textual Similarity system , which provides high accurate semantic similarity measurement.", "labels": [], "entities": [{"text": "UMBC-Semantic Textual Similarity", "start_pos": 11, "end_pos": 43, "type": "TASK", "confidence": 0.735635002454122}, {"text": "accurate semantic similarity measurement", "start_pos": 73, "end_pos": 113, "type": "METRIC", "confidence": 0.7732842341065407}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the task and the details of our method.", "labels": [], "entities": []}, {"text": "Section 3 presents our re-sults and a brief discussion.", "labels": [], "entities": []}, {"text": "The last section offers conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 shows the  statistical results for each feature ablation run.", "labels": [], "entities": []}, {"text": " Table 2. Performance of system on development data.", "labels": [], "entities": []}]}