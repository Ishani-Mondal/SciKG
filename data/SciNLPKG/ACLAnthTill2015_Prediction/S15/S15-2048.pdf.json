{"title": [{"text": "VectorSLU: A Continuous Word Vector Approach to Answer Selection in Community Question Answering Systems", "labels": [], "entities": [{"text": "Answer Selection in Community Question Answering", "start_pos": 48, "end_pos": 96, "type": "TASK", "confidence": 0.7144916206598282}]}], "abstractContent": [{"text": "Continuous word and phrase vectors have proven useful in a number of NLP tasks.", "labels": [], "entities": []}, {"text": "Here we describe our experience using them as a source of features for the SemEval-2015 task 3, consisting of two community question answering subtasks: Answer Selection for categorizing answers as potential, good, and bad with regards to their corresponding questions; and YES/NO inference for predicting a yes, no, or unsure response to a YES/NO question using all of its good answers.", "labels": [], "entities": [{"text": "SemEval-2015 task 3", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8118629256884257}, {"text": "predicting a yes, no, or unsure response to a YES/NO question", "start_pos": 295, "end_pos": 356, "type": "TASK", "confidence": 0.7722985903422038}]}, {"text": "Our system ranked 6th and 1st in the English answer selection and YES/NO inference subtasks respectively, and 2nd in the Arabic answer selection subtask.", "labels": [], "entities": [{"text": "YES", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9505407810211182}]}], "introductionContent": [{"text": "Continuous word and phrase vectors, in which similar words and phrases are associated with similar vectors, have been useful in many NLP tasks.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of continuous vector representations for Community question answering (CQA), we focused on using simple features derived from vector similarity as input to a multi-class linear SVM classifier.", "labels": [], "entities": [{"text": "Community question answering (CQA)", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.7801355471213659}]}, {"text": "Our approach is language independent and was evaluated on both English and Arabic.", "labels": [], "entities": []}, {"text": "Most of the vectors we use are domain-independent.", "labels": [], "entities": []}, {"text": "CQA services provide forums for users to ask or answer questions on any topic, resulting in high variance answer quality.", "labels": [], "entities": [{"text": "CQA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9142124652862549}]}, {"text": "Searching for good answers among the many responses can be time-consuming for participants.", "labels": [], "entities": []}, {"text": "This is illustrated by the following example of a question and subsequent answers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach on the answer selection and YES/NO answer inference tasks.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.8774998188018799}, {"text": "YES", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9978594183921814}]}, {"text": "We use the CQA datasets provided by the Semeval 2015 task that contain 2600 training and 300 development questions and their corresponding answers (a total number of 16,541 training and 1,645 development answers).", "labels": [], "entities": [{"text": "CQA datasets provided by the Semeval 2015 task", "start_pos": 11, "end_pos": 57, "type": "DATASET", "confidence": 0.7323226444423199}]}, {"text": "About 10% of these questions are of the YES/NO type.", "labels": [], "entities": [{"text": "YES/NO type", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.7808176726102829}]}, {"text": "We combined the training and development datasets for training purposes.", "labels": [], "entities": []}, {"text": "The test dataset includes 329 questions and 1976 answers.", "labels": [], "entities": []}, {"text": "About 9% of the test questions are bipolar.", "labels": [], "entities": []}, {"text": "We also evaluate our performance on the Arabic answer selection task.", "labels": [], "entities": [{"text": "Arabic answer selection task", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.7921140938997269}]}, {"text": "The dataset contains 1300 training questions, 200 development questions, and 200 test questions.", "labels": [], "entities": []}, {"text": "This dataset does not include YES/NO questions.", "labels": [], "entities": [{"text": "YES", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.869266152381897}, {"text": "NO", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.6466432213783264}]}, {"text": "English answer selection Our approach for the answer selection task in English ranked 6th out of 12 submissions and its results are shown in.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.7542080879211426}, {"text": "answer selection task", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.9448733727137247}]}, {"text": "VectorSLU-Primary shows the results when we include all the features listed in    the rank-based and text-based features.", "labels": [], "entities": []}, {"text": "Interestingly, VectorSLU-Contrastive leads to a better performance than VectorSLU-Primary.", "labels": [], "entities": []}, {"text": "The lower performance of VectorSLU-Primary could be due to the high overlap between text-based features in different classes that can clearly mislead classifiers.", "labels": [], "entities": []}, {"text": "For example, A1, A2 and A3 (see Section 1) all have a considerable word overlap with their question, while only A2 is a good answer.", "labels": [], "entities": [{"text": "A1", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9845204949378967}, {"text": "A2", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.9029616117477417}]}, {"text": "The last two rows of the table are respectively related to the best performance among all submissions and the majority class baseline that always predicts good.", "labels": [], "entities": []}, {"text": "Arabic answer selection Our approach for answer selection in Arabic ranked 2nd out of 4 submissions.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 7, "end_pos": 23, "type": "TASK", "confidence": 0.7912188768386841}, {"text": "answer selection", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.9651125371456146}]}, {"text": "In these experiments, we employ all features listed in except for yes/no/probably-based features, since the Arabic task does not include YES/NO answer inference.", "labels": [], "entities": [{"text": "YES", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.9107032418251038}]}, {"text": "Vectors were trained from the Arabic Gigaword (Linguistic Data Consortium, 2011).", "labels": [], "entities": [{"text": "Arabic Gigaword (Linguistic Data Consortium, 2011)", "start_pos": 30, "end_pos": 80, "type": "DATASET", "confidence": 0.9397784339057075}]}, {"text": "We found lemma vectors to work better than token vectors.", "labels": [], "entities": []}, {"text": "We computed ranking scores with SVM Rank for both VectorSLU-contrastive and VectorSLUPrimary.", "labels": [], "entities": []}, {"text": "In the case of VectorSLU-contrastive, we used these scores to predict labels according to the following heuristic: the top scoring answer is labeled as direct, the second scoring answer as related, and all other answers as irrelevant.", "labels": [], "entities": []}, {"text": "This decision mechanism is based on the distribution in the training and development data, and proved to work well on the test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for the English answer selection task.", "labels": [], "entities": [{"text": "English answer selection task", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.8018620610237122}]}, {"text": " Table 3: Results for the Arabic answer selection task.", "labels": [], "entities": [{"text": "Arabic answer selection task", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.8035513013601303}]}]}