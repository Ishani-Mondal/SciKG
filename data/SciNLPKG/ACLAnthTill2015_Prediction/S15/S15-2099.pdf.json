{"title": [{"text": "UNIBA: Sentiment Analysis of English Tweets Combining Micro-blogging, Lexicon and Semantic Features", "labels": [], "entities": [{"text": "UNIBA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.945866584777832}, {"text": "Sentiment Analysis of English Tweets", "start_pos": 7, "end_pos": 43, "type": "TASK", "confidence": 0.881926667690277}]}], "abstractContent": [{"text": "This paper describes the UNIBA team participation in the Sentiment Analysis in Twitter task (Task 10) at SemEval-2015.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter task (Task 10) at SemEval-2015", "start_pos": 57, "end_pos": 117, "type": "TASK", "confidence": 0.8010917035016146}]}, {"text": "We propose a supervised approach relying on keyword, lexicon and micro-blogging features as well as representation of tweets in a word space.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is the study of the subjectivity and polarity (positive vs. negative) of a text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.920317530632019}]}, {"text": "With the worldwide diffusion of social media, a huge amount of textual data has been made available, thus attracting the interest of researchers in this domain ().", "labels": [], "entities": []}, {"text": "Sentiment analysis on such informal texts poses new challenges due to the presence of slang, misspelled words and micro-blogging features such as hashtags or links and traditional approaches may not be successfully exploited in this domain.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9470891058444977}]}, {"text": "Previous research has successfully exploited approaches based on lexical and micro-blogging features.", "labels": [], "entities": []}, {"text": "In this study, we investigate a supervised approach including three kinds of features based on keywords and micro-blogging properties of tweets, sentiment lexicons and semantics.", "labels": [], "entities": []}, {"text": "Rather than using word-sense disambiguation (), we represent tweets in a distributional semantic model (DSM) (, which is able to learn the context of usage of words analysing cooccurrences in large corpora.", "labels": [], "entities": []}, {"text": "This paper describes our participation at the SemEval 2015 Sentiment Analysis in Twitter task.", "labels": [], "entities": [{"text": "SemEval 2015 Sentiment Analysis in Twitter task", "start_pos": 46, "end_pos": 93, "type": "TASK", "confidence": 0.9177818042891366}]}, {"text": "We discuss methods and results of our experimental study for the overall polarity classification of tweets (message level subtask B).", "labels": [], "entities": [{"text": "overall polarity classification of tweets", "start_pos": 65, "end_pos": 106, "type": "TASK", "confidence": 0.7759282171726227}]}, {"text": "The Sentiment Analysis task focuses on English tweets.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.9393516977628072}]}, {"text": "Data provided for training are annotated according to the overall polarity of each tweet (i.e., 'negative', 'positive' or 'neutral').", "labels": [], "entities": []}, {"text": "The system evaluation is performed on different test sets.", "labels": [], "entities": []}, {"text": "In particular, the rank of the systems is calculated on the offical Twitter 2015 test set.", "labels": [], "entities": [{"text": "Twitter 2015 test set", "start_pos": 68, "end_pos": 89, "type": "DATASET", "confidence": 0.8264995366334915}]}, {"text": "Further evaluation is performed on a progress set including test instances from the previous edition of the task, to allow comparision with previous studies).", "labels": [], "entities": []}, {"text": "We build a supervised system based on our sentiment classifier for Italian tweets, which ranked 1st in both the polarity and subjectivity tasks at Evalita 2014 ().", "labels": [], "entities": [{"text": "Evalita 2014", "start_pos": 147, "end_pos": 159, "type": "DATASET", "confidence": 0.8767513036727905}]}, {"text": "The paper is structured as follows: we introduce our system and report the details about features in Section 2.", "labels": [], "entities": []}, {"text": "We describe the evaluation and the system setup in Section 3.", "labels": [], "entities": []}, {"text": "We conclude by reporting results and discussion in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The message level subtask (subtask B) is designed for evaluating systems on their ability to predict the overall polarity of a given tweet, with respect to three classes: positive, negative, and neutral.", "labels": [], "entities": []}, {"text": "Organizers provided 8,006 manually annotated tweets as training data.", "labels": [], "entities": []}, {"text": "We use the training set 8 to extract the features described in Section 2.", "labels": [], "entities": []}, {"text": "Details on our system setup are reported in Section 3.1.", "labels": [], "entities": []}, {"text": "As test set, organizers provided a collection of 2,390 manually annotated tweets (Official 2015 test set).", "labels": [], "entities": [{"text": "Official 2015 test set)", "start_pos": 82, "end_pos": 105, "type": "DATASET", "confidence": 0.9069191455841065}]}, {"text": "Further data from different sources 8 Further development data provided by the organizers are not used for training tweets overall) are included in the progress test set and are provided to allow comparison with systems participating in previous editions.", "labels": [], "entities": [{"text": "progress test set", "start_pos": 152, "end_pos": 169, "type": "DATASET", "confidence": 0.7302981019020081}]}, {"text": "Systems are compared against the gold standard of the official test set in terms of macro average F measure calculated over the positive and negative classes.", "labels": [], "entities": [{"text": "official test set", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.7770113746325175}, {"text": "macro average F measure", "start_pos": 84, "end_pos": 107, "type": "METRIC", "confidence": 0.8429546803236008}]}, {"text": "For the sake of completeness, we report also weighted F measure considering all the three categories in the classification task (see Section 4).", "labels": [], "entities": [{"text": "F measure", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9743002951145172}]}], "tableCaptions": [{"text": " Table 4: System results for all feature settings and all classes on the official test set Twitter 2015.", "labels": [], "entities": [{"text": "official test set Twitter 2015", "start_pos": 73, "end_pos": 103, "type": "DATASET", "confidence": 0.8608155131340027}]}]}