{"title": [{"text": "NTNU: An Unsupervised Knowledge Approach for Taxonomy Extrac- tion", "labels": [], "entities": [{"text": "NTNU", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9325613975524902}, {"text": "Taxonomy Extrac- tion", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.5406818389892578}]}], "abstractContent": [{"text": "Taxonomy structures are important tools in the science of classification of things or concepts, including the principles that underlie such classification.", "labels": [], "entities": []}, {"text": "This paper presents an approach to the problem of taxonomy construction from texts focusing on the hyponym-hypernym relation between two terms.", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.8899987637996674}]}, {"text": "Given a set of terms in a particular domain, the approach in this study uses Wikipedia and WordNet as knowledge sources and applies the information extraction methods to analyze and establish the hyponym-hypernym relationship between two terms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.8675811290740967}]}, {"text": "Our system is ranked fourth among the participating systems in SemEval-2015 task 17.", "labels": [], "entities": [{"text": "SemEval-2015 task 17", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.7710201342900594}]}], "introductionContent": [{"text": "Taxonomies are essential tools for many Natural Language Processing (NLP) applications and the backbone of many structured knowledge resources.", "labels": [], "entities": []}, {"text": "Taxonomies specific to a domain are becoming indispensable to a growing number of applications.", "labels": [], "entities": []}, {"text": "Several stateof-the-art approaches already exist to extract taxonomies to characterize the domains of interest from the corpus using the information extraction techniques.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.720706969499588}]}, {"text": "Recently, attention has been devoted to inducing the taxonomy from a set of keyword phrases instead of from a text corpus (.", "labels": [], "entities": []}, {"text": "Such approaches enrich the set of keyword phrases by aggregating search results for each keyword phrase into a text corpus to overcome the lack of explicit relationships between keyword phrases from which the taxonomy can be induced.", "labels": [], "entities": []}, {"text": "This approach faces a key challenge of extracting explicit relationships among keyword phrases.", "labels": [], "entities": [{"text": "extracting explicit relationships among keyword phrases", "start_pos": 39, "end_pos": 94, "type": "TASK", "confidence": 0.8211075663566589}]}, {"text": "However, semantic relatedness between concepts in a domain is an important clue to extracting their taxonomy relationships.", "labels": [], "entities": []}, {"text": "An important contribution in relation to this is reported by that present an explicit semantic analysis using the natural concepts and propose a uniform method of computing relatedness of both individual concept and arbitrarily long text fragments.", "labels": [], "entities": []}, {"text": "Lexical databases such as WordNet encode relations between words such as synonymy and hypernymy.", "labels": [], "entities": []}, {"text": "Quite a few metrics have been defined that compute relatedness using various properties of the underlying graph structures of these resources.", "labels": [], "entities": []}, {"text": "The obvious drawback of this approach is that the creation of lexical resources requires the lexicographic expertise as well as a lot of time and effort, and consequently such resources cover only a small fragment of the language lexicon.", "labels": [], "entities": []}, {"text": "Specifically, such the resources contain few proper names, neologisms, slang, and domain-specific technical terms.", "labels": [], "entities": []}, {"text": "Furthermore, these resources have strong lexical orientation and mainly contain information about individual words but little world knowledge in general.", "labels": [], "entities": []}, {"text": "With the advent of new information sources, many new methods and ideas are developed for the large scale information extraction taking advantages of huge amounts of unstructured available resources.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.7105902582406998}]}, {"text": "propose a novel method for acquisition of knowledge for taxonomies of concepts from the raw Wikipedia text.", "labels": [], "entities": []}, {"text": "Their approach uses the learning process to derive concept hierarchies from WordNet and maps them to Wikipedia pages for extraction of appropriate knowledge.", "labels": [], "entities": []}, {"text": "Most state-of-the-art approaches for the domain-specific taxonomy induction use the text corpus as its input and some information extraction methods to extract ontological relationships from the text corpus, and finally apply the relationships to build the taxonomy.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.715478703379631}]}, {"text": "Other automatic approaches to taxonomy construction from texts include a statistical method to compare the syntactic context of terms for taxonomic relations identification.", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8878206014633179}, {"text": "taxonomic relations identification", "start_pos": 138, "end_pos": 172, "type": "TASK", "confidence": 0.7400966286659241}]}, {"text": "There have been a number of handcrafted, well-structured taxonomies publicly available online, including WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9799036383628845}]}, {"text": "However, such taxonomies are also not perfect since human experts are liable to miss some relevant terms.", "labels": [], "entities": []}, {"text": "In this study, we consider the challenging problem of deriving taxonomies of a set of concepts under a specific domain of interest.", "labels": [], "entities": []}, {"text": "Consider for illustration, the domain vehicle containing concepts such as car, bicycle, Toyota, automobile, bus, Toyota_cambire, cruiser and Motorcycle.", "labels": [], "entities": []}, {"text": "Establishing hyponym-hypernym relationships among concepts is a difficult task if no other information is provided.", "labels": [], "entities": [{"text": "Establishing hyponym-hypernym relationships among concepts", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.8202984213829041}]}, {"text": "We propose an approach to the taxonomy extraction task in) with the following contributions: \uf0b7 To derive the statistical information about individual concepts in a given domain, the study uses WordNet and Wikipedia to find the definition for the concept.", "labels": [], "entities": [{"text": "taxonomy extraction task", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.8696066737174988}, {"text": "WordNet", "start_pos": 193, "end_pos": 200, "type": "DATASET", "confidence": 0.9674177765846252}]}, {"text": "\uf0b7 Using the definitions of concepts, the statistical information derived from these definitions is used to determine concept relationships and to represent the concepts in a domain with a Bayesian Rose Tree (BRT).", "labels": [], "entities": []}, {"text": "\uf0b7 The study finally extracts taxonomies for domain concepts using the BRT tree and WordNet type binary relations.", "labels": [], "entities": [{"text": "BRT tree", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.6892735958099365}]}, {"text": "Bayesian hierarchical clustering algorithm (BRT) is used to cluster concepts having hyponym-hypernym relationships).", "labels": [], "entities": []}, {"text": "presents our level approach to constructing the taxonomy for the domain concepts.", "labels": [], "entities": []}, {"text": "In, resources WordNet and Wikipedia are first used to help the extraction of the definitions of the concepts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.9638761281967163}, {"text": "Wikipedia", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.9048900008201599}]}, {"text": "Then, information extracted from WordNet sense and Wikipedia categories are utilized to build the concept binary trees.", "labels": [], "entities": [{"text": "WordNet sense", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.9110175371170044}]}, {"text": "With the concept binary trees, the system can construct the BRT tree and furthermore generate the relationships in the taxonomy for the concepts.", "labels": [], "entities": []}, {"text": "Details in each step are described in the following sections.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system is ranked fourth among the comparative evaluation final ranking of the task participant.", "labels": [], "entities": []}, {"text": "The table below shows the performance of participants' system based on average precision (Avg. P), recall (Avg. R), and average F-score measure (Avg. F) for the taxonomy extraction.", "labels": [], "entities": [{"text": "average precision (Avg. P)", "start_pos": 71, "end_pos": 97, "type": "METRIC", "confidence": 0.8200114270051321}, {"text": "recall (Avg. R)", "start_pos": 99, "end_pos": 114, "type": "METRIC", "confidence": 0.9460221648216247}, {"text": "F-score measure (Avg. F)", "start_pos": 128, "end_pos": 152, "type": "METRIC", "confidence": 0.9354916314284006}, {"text": "taxonomy extraction", "start_pos": 161, "end_pos": 180, "type": "TASK", "confidence": 0.8557494580745697}]}, {"text": "The evaluation tool measures a systemgenerated taxonomy against the gold standard taxonomy by comparing the following items: 4 \uf0b7 The overall structure of the taxonomy against a gold standard, with an approach used for comparing hierarchical clusters.", "labels": [], "entities": []}, {"text": "\uf0b7 Manual quality assessment of novel edges.", "labels": [], "entities": []}, {"text": "In comparison against the gold standard data, the system's average performance under certain domain terms (chemical (CH), equipment (EQ), food and science (SC) domains) with respect to vertices in common, edge coverage and ratio of novel edges are shown in the  In the table, the feature \"vertices in coverage\" represent the ratio of number of vertices in common with the gold standard taxonomy to the number of the gold standard vertices.", "labels": [], "entities": []}, {"text": "The feature \"edge coverage\" is the fraction of number of edges in common with the gold standard over the number of edges in the gold standard.", "labels": [], "entities": []}, {"text": "The ration of the product of the number of taxonomy edges and the number of edges in common with the gold standard to the number of gold standard edges is represented by \"Ratio of Novel edges\" in the result in.", "labels": [], "entities": []}, {"text": "From, it can be observed that, the system has the best and the worst performance in taxonomies for the science and equipment domains respectively.", "labels": [], "entities": []}, {"text": "The bases of these differences in the system's performance are its precision for individual domain against its gold standard.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9995108842849731}]}, {"text": "For instance, from 452 vertices for the gold standard science domain from the taxonomy of fields and their subfields, the system was able to extract 338 vertices.", "labels": [], "entities": []}, {"text": "Furthermore, the system's cumulative measure of the similarity against the gold standard is affected by the precision rate.", "labels": [], "entities": [{"text": "similarity", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9754260182380676}, {"text": "precision rate", "start_pos": 108, "end_pos": 122, "type": "METRIC", "confidence": 0.9829241335391998}]}, {"text": "For instance, in the worst performance for the gold standard domain of material handling equipment combined with IS-A relations from, our system has a precision of 1.61% as shown in the evaluation result while SC has good results in edge and vertex retrieval due to the good cumulative results.", "labels": [], "entities": [{"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9985530972480774}]}], "tableCaptions": [{"text": " Table 1. Comparative evaluation results for SemEval- 2015 Task 17, showing our system result in bold let- ters.", "labels": [], "entities": [{"text": "SemEval- 2015 Task 17", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.7941534757614136}]}, {"text": " Table 2. System's comparison against gold standard  data.", "labels": [], "entities": [{"text": "gold standard  data", "start_pos": 38, "end_pos": 57, "type": "DATASET", "confidence": 0.7393415371576945}]}]}