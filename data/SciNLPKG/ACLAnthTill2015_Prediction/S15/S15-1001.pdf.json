{"title": [{"text": "Neural Networks for Integrating Compositional and Non-compositional Sentiment in Sentiment Composition", "labels": [], "entities": [{"text": "Integrating Compositional and Non-compositional Sentiment in Sentiment Composition", "start_pos": 20, "end_pos": 102, "type": "TASK", "confidence": 0.6361899711191654}]}], "abstractContent": [{"text": "This paper proposes neural networks for integrating compositional and non-compositional sentiment in the process of sentiment composition , a type of semantic composition that optimizes a sentiment objective.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.7849125266075134}]}, {"text": "We enable individual composition operations in a recursive process to possess the capability of choosing and merging information from these two types of sources.", "labels": [], "entities": []}, {"text": "We propose our models in neural network frameworks with structures, in which the merging parameters can be learned in a principled way to optimize a well-defined objective.", "labels": [], "entities": []}, {"text": "We conduct experiments on the Stan-ford Sentiment Treebank and show that the proposed models achieve better results over the model that lacks this ability.", "labels": [], "entities": [{"text": "Stan-ford Sentiment Treebank", "start_pos": 30, "end_pos": 58, "type": "DATASET", "confidence": 0.7918267051378886}]}], "introductionContent": [{"text": "Automatically determining the sentiment of a phrase, a sentence, or even a longer piece of text is still a challenging problem.", "labels": [], "entities": [{"text": "determining the sentiment of a phrase, a sentence", "start_pos": 14, "end_pos": 63, "type": "TASK", "confidence": 0.8865924212667677}]}, {"text": "Data sparseness encountered in such tasks often requires to factorize the problem to consider smaller pieces of component words or phrases, for which much research has been performed on bag-of-words or bag-of-phrases models ().", "labels": [], "entities": []}, {"text": "More recent work has started to model sentiment composition, a type of semantic composition that optimizes a sentiment objective.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.9127781987190247}]}, {"text": "In general, the composition process is critical in the formation of the sentiment of a span of text, which has not been well modeled yet and there is still scope for future work.", "labels": [], "entities": []}, {"text": "Compositionality, or non-compositionality, of the senses of text spans is important for language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7203680276870728}]}, {"text": "Sentiment, as one of the major semantic differential categories (, faces the problem as well.", "labels": [], "entities": []}, {"text": "For example, the phrase must see or must try in a movie or restaurant review often indicates a positive sentiment, which, however, maybe hard to learn from the component words.", "labels": [], "entities": []}, {"text": "More extreme examples, e.g., slangs like bad ass, are not rare in social media text.", "labels": [], "entities": []}, {"text": "This particular example can actually convey a very positive sentiment even though its component words are very negative.", "labels": [], "entities": []}, {"text": "In brief, a sentiment composition framework that can consider both compositional and non-compositional sentiment is theoretically interesting.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7927509844303131}]}, {"text": "From a more pragmatical viewpoint, if one is able to reliably learn the sentiment of a text span (e.g., an ngram) holistically, it would be desirable that a composition model has the ability to decide the sources of knowledge it trusts more: the composition from the component words, the noncompositional source, or a soft combination of them.", "labels": [], "entities": []}, {"text": "In such a situation, whether the text span is actually composable maybe blur or may not be a concern.", "labels": [], "entities": [{"text": "blur", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9962605834007263}]}, {"text": "In general, the composition of sentiment is a rather complicated process.", "labels": [], "entities": [{"text": "composition of sentiment", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7775605718294779}]}, {"text": "As a glimpse of evidence, the effect of negation words on changing sentiment of their scopes appears to be a complicated function ().", "labels": [], "entities": []}, {"text": "The recently proposed neural networks) are promising, for their capability of modeling complicated functions) in 1 general, handling data sparseness by learning lowdimensional embeddings at each layer of composition, and providing a framework to optimize the composition process in principled way.", "labels": [], "entities": []}, {"text": "This paper proposes neural networks for integrating compositional and non-compositional sentiment in the process of sentiment composition.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.7992808818817139}]}, {"text": "To achieve this, we enable individual composition operations in a recursive process to possess the capability of choosing and merging information from these two types of sources.", "labels": [], "entities": []}, {"text": "We propose our models in neural network frameworks with structures, in which the merging parameters can be learned in a principled way to optimize a welldefined objective.", "labels": [], "entities": []}, {"text": "We conduct experiments on the Stanford Sentiment Treebank and show that the proposed models achieve better results over the model that does not consider this property.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank", "start_pos": 30, "end_pos": 57, "type": "DATASET", "confidence": 0.9209480484326681}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Model performances (accuracies) on predicting 5-category sentiment at the sentence (root) level and phrase- level on Stanford Sentiment Treebank. The numbers in the bold font are the best performances achieved on the two  tasks. Both results are statistically significantly better (p < 0.05) than the corresponding RNTN results.", "labels": [], "entities": [{"text": "predicting 5-category sentiment", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.8193988998730978}, {"text": "Stanford Sentiment Treebank", "start_pos": 127, "end_pos": 154, "type": "DATASET", "confidence": 0.9155645171801249}]}]}