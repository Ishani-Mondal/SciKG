{"title": [{"text": "SWASH: A Naive Bayes Classifier for Tweet Sentiment Identification", "labels": [], "entities": [{"text": "Naive Bayes Classifier", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.8505442341168722}, {"text": "Tweet Sentiment Identification", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.8780850370724996}]}], "abstractContent": [{"text": "This paper describes a sentiment classification system designed for SemEval-2015, Task 10, Subtask B. The system employs a constrained , supervised text categorization approach.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.9401282072067261}]}, {"text": "Firstly, since thorough preprocess-ing of tweet data was shown to be effective in previous SemEval sentiment classification tasks, various preprocessessing steps were introduced to enhance the quality of lexical information.", "labels": [], "entities": [{"text": "SemEval sentiment classification tasks", "start_pos": 91, "end_pos": 129, "type": "TASK", "confidence": 0.9460930675268173}]}, {"text": "Secondly, a Naive Bayes classi-fier is used to detect tweet sentiment.", "labels": [], "entities": [{"text": "detect tweet sentiment", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.5985763768355051}]}, {"text": "The classifier is trained only on the training data provided by the task organizers.", "labels": [], "entities": []}, {"text": "The system makes use of external human-generated lists of positive and negative words at several steps throughout classification.", "labels": [], "entities": []}, {"text": "The system produced an overall F-score of 59.26 on the official test set.", "labels": [], "entities": [{"text": "F-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9995312690734863}]}], "introductionContent": [{"text": "Over the past few years, an increasing number of people have begun to express their opinion through social networks and microblogging services.", "labels": [], "entities": []}, {"text": "Twitter, as one of the most popular of these social networks, has become a major platform for social communication, allowing its users to send and read short messages called 'tweets'.", "labels": [], "entities": []}, {"text": "Tweets have become important in a variety of tasks, including the prediction of election results (O').", "labels": [], "entities": [{"text": "prediction of election results (O')", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.783514312335423}]}, {"text": "The emergence of online expressions of opinion has attracted interest in sentiment analysis of tweets in both academia and industry.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.8862355053424835}]}, {"text": "Sentiment analysis, also known as opinion mining, focuses on computational treatments of sentiments (emotions, attitudes, opinions) in natural language text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9164002537727356}, {"text": "opinion mining", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.7479372918605804}, {"text": "computational treatments of sentiments (emotions, attitudes, opinions) in natural language text", "start_pos": 61, "end_pos": 156, "type": "TASK", "confidence": 0.6791866064071655}]}, {"text": "In this paper we describe our submission to Task 10, subtask B: Message Polarity Classification.", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.7731291254361471}]}, {"text": "The task is defined as: 'Given a message, classify whether the message is of positive, negative, or neutral sentiment.", "labels": [], "entities": []}, {"text": "For a message conveying both a positive and negative sentiment, whichever is the stronger sentiment should be chosen' (.", "labels": [], "entities": []}, {"text": "This paper describes a system which utilizes a Naive Bayes classifier to determine the sentiment of tweets.", "labels": [], "entities": []}, {"text": "This paper describes the resources used, the system details, including preprocessing steps taken, feature extraction and classifier implemented, and the test runs and end results.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.6846152544021606}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Changes in F1-score obtained by each prepro- cessing step (taken individually, not cumulatively) using  5-fold cross validation on the provided training set.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9993459582328796}]}, {"text": " Table 2: F-scores for individual sentiments and over- all score, produced using 5-fold cross validation on  SemEval-2015 training data.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9986488223075867}, {"text": "SemEval-2015 training data", "start_pos": 109, "end_pos": 135, "type": "DATASET", "confidence": 0.8318328857421875}]}, {"text": " Table 3: Two parameters empirically determined using  crossvalidation. In Laplace smoothing, \u03bb is the additive  constant for unknown words. The 'positive' and 'nega- tive' features introduced by the sentiment lexicon were  given five times the weight of the token unigrams.", "labels": [], "entities": []}, {"text": " Table 4: Performance on the official 2015 test data as well  as on the progress data sets.", "labels": [], "entities": [{"text": "official 2015 test data", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.67923304438591}, {"text": "progress data sets", "start_pos": 72, "end_pos": 90, "type": "DATASET", "confidence": 0.8929889798164368}]}]}