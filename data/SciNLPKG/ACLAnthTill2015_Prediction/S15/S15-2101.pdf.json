{"title": [{"text": "Swiss-Chocolate: Combining Flipout Regularization and Random Forests with Artificially Built Subsystems to Boost Text-Classification for Sentiment", "labels": [], "entities": [{"text": "Swiss-Chocolate", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9406360387802124}, {"text": "Flipout Regularization", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.64023058116436}, {"text": "Sentiment", "start_pos": 137, "end_pos": 146, "type": "TASK", "confidence": 0.8187998533248901}]}], "abstractContent": [{"text": "We describe a classifier for predicting message-level sentiment of English micro-blog messages from Twitter.", "labels": [], "entities": [{"text": "predicting message-level sentiment of English micro-blog messages", "start_pos": 29, "end_pos": 94, "type": "TASK", "confidence": 0.801482515675681}]}, {"text": "This paper describes our submission to the SemEval-2015 competition (Task 10).", "labels": [], "entities": [{"text": "SemEval-2015 competition", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.8840609192848206}]}, {"text": "Our approach is to combine several variants of our previous year's SVM system into one meta-classifier, which was then trained using a random forest.", "labels": [], "entities": []}, {"text": "The main idea is that the meta-classifier allows the combination of the strengths and overcome some of the weaknesses of the artificially-built individual classifiers, and adds additional non-linearity.", "labels": [], "entities": []}, {"text": "We were also able to improve the linear classifiers by using anew regularization technique we call flipout.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the availability of huge amounts of user generated text online, the interest in automatic sentiment analysis of text has greatly increased recently in both academia and industry.", "labels": [], "entities": [{"text": "automatic sentiment analysis of text", "start_pos": 85, "end_pos": 121, "type": "TASK", "confidence": 0.7875496208667755}]}, {"text": "The goal is to classify a tweet (on the full message level) into the three classes positive, negative, and neutral.", "labels": [], "entities": []}, {"text": "In this paper, we describe our approach using a modified SVM based classifier on short text as in Twitter messages.", "labels": [], "entities": []}, {"text": "Our system has participated in the SemEval-2015  Our Results in the Competition.", "labels": [], "entities": []}, {"text": "Our system was ranked 8th out of 40 participants, with an F1-score of 62.61 on the Twitter-2015 test set.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9993011951446533}, {"text": "Twitter-2015 test set", "start_pos": 83, "end_pos": 104, "type": "DATASET", "confidence": 0.8067341645558676}]}, {"text": "The 2015 winning team obtained an average F1-score of 64.84.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9989896416664124}]}, {"text": "The detailed rankings of our approach were: 4th rank on the LiveJournal data; 6th on the SMS data (2013); 10th on for full details and all results.", "labels": [], "entities": [{"text": "LiveJournal data", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9919775724411011}, {"text": "SMS data (2013)", "start_pos": 89, "end_pos": 104, "type": "DATASET", "confidence": 0.9059386730194092}]}, {"text": "In the competition, tweets for training and development were provided as tweet IDs.", "labels": [], "entities": []}, {"text": "A fraction (10-15%) of the tweets were no longer available on Twitter, which made results of the competition not fully comparable.", "labels": [], "entities": []}, {"text": "For testing, in addition to last year's data (tweets, SMS, LiveJournal), new tweets were provided.", "labels": [], "entities": []}, {"text": "An overview of the data that we were able to download is given in.", "labels": [], "entities": []}, {"text": "Our system is based on two main ideas.", "labels": [], "entities": []}, {"text": "First, we propose anew regularization technique called flipout, which post-processes a trained classifier model for better generalization performance.", "labels": [], "entities": []}, {"text": "Details of this are given in Section 2.", "labels": [], "entities": []}, {"text": "Second, we combine multiple classifiers with a metaclassifier, to yield better performance than each single sub-classifier ).", "labels": [], "entities": []}, {"text": "To achieve this, we extended our existing system ().", "labels": [], "entities": []}, {"text": "The result is simple: a large collection of features used in a linear SVM classifier.", "labels": [], "entities": []}, {"text": "We replicated that system with several dif-ferent choices of features and parameters.", "labels": [], "entities": []}, {"text": "The output of all those artificially built classifiers is then feed as input to a random forest classifier, which generated final classification results, and gave our system additional non-linear output capabilities.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overview of the data we found available for  training, development and testing.  Dataset  Total Posit. Negat. Neutr.  Train (Tweets)  8224 3058 1210 3956  Dev (Tweets)  1417  494  286  637  Test: Twitter2015  2390 1038  365  987  Test: Twitter2014  1853  982  202  669  Test: Twitter2013  3813 1572  601 1640  Test: SMS2013  2093  492  394 1207  Test: Tw2014Sarcasm  86  33  40  13  Test: LiveJournal2014 1142  427  304  411", "labels": [], "entities": []}, {"text": " Table 2: Results of our subsystems and final system.", "labels": [], "entities": []}]}