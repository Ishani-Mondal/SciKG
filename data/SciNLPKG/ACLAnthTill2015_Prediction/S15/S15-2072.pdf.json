{"title": [{"text": "CUAB: Supervised Learning of Disorders and their Attributes Using Relations", "labels": [], "entities": [{"text": "CUAB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9554939270019531}, {"text": "Supervised Learning of Disorders and their Attributes", "start_pos": 6, "end_pos": 59, "type": "TASK", "confidence": 0.7757449405533927}]}], "abstractContent": [{"text": "We implemented an end-to-end system for disorder identification and slot filling.", "labels": [], "entities": [{"text": "disorder identification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.8130182921886444}, {"text": "slot filling", "start_pos": 68, "end_pos": 80, "type": "TASK", "confidence": 0.9309626817703247}]}, {"text": "For identifying spans for both disorders and their attributes , we used a linear chain conditional random field (CRF) approach coupled with cTAKES for pre-processing.", "labels": [], "entities": []}, {"text": "For combining disjoint disorder spans, finding relations between attributes and disorders, and attribute normalization, we used l2-regularized l2-loss linear support vector machine (SVM) classification.", "labels": [], "entities": [{"text": "l2-regularized l2-loss linear support vector machine (SVM) classification", "start_pos": 128, "end_pos": 201, "type": "TASK", "confidence": 0.692845219373703}]}, {"text": "Disorder CUIs were identified using a back-off approach to YTEX lookup (CUAB1) or NLM UTS API (CUAB2) if the target text was not found in the training data.", "labels": [], "entities": []}, {"text": "Our best system utilized UMLS semantic type features for disorder/attribute span identification and the NLM UTS API for normalization.", "labels": [], "entities": [{"text": "disorder/attribute span identification", "start_pos": 57, "end_pos": 95, "type": "TASK", "confidence": 0.6113961040973663}]}, {"text": "It was ranked 12th in Task 1 (disorder identification) and 6th in Task 2b (disorder identification and slot filling) with a weighted F Measure of 0.711.", "labels": [], "entities": [{"text": "disorder identification)", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.771491934855779}, {"text": "disorder identification", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.6685092598199844}, {"text": "slot filling", "start_pos": 103, "end_pos": 115, "type": "TASK", "confidence": 0.7467191815376282}, {"text": "F Measure", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9248569011688232}]}], "introductionContent": [{"text": "One of the core problems in the field of clinical text processing is the identification and normalization of medical disorders.", "labels": [], "entities": [{"text": "clinical text processing", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.6260445415973663}, {"text": "identification and normalization of medical disorders", "start_pos": 73, "end_pos": 126, "type": "TASK", "confidence": 0.7739921808242798}]}, {"text": "A secondary problem is the identification of attributes for the identified disorders such as their severity or body location.", "labels": [], "entities": []}, {"text": "Attribute identification and normalization helps to better describe the disorder context, allowing fora better determination of the appropriateness of the discovered disorder for the task at hand.", "labels": [], "entities": [{"text": "Attribute identification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6557333171367645}]}, {"text": "SemEval-2015 Task 14 addresses these problems as separate tasks, assessing end to end systems capable of identifying both disorders and attributes from unlabeled clinical text.", "labels": [], "entities": []}, {"text": "The first task requires participants to identify discontinuous disorder spans in clinical text and normalize them to a UMLS Concept Unique Identifier (CUI) that is both within the disorder Semantic Group and present in SNOMED CT.", "labels": [], "entities": [{"text": "SNOMED CT", "start_pos": 219, "end_pos": 228, "type": "TASK", "confidence": 0.6563629508018494}]}, {"text": "The second task requires identification of disorder CUIs as well as 8 additional attributes associated with each disorder as shown in on the shared task page 1 . For each attribute, the span offset of the lexical cue must also be identified, which maybe discontinuous.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance on disorder identification and normalization (Task 1), including rank among the 39 competing  systems (Rank), true positives (TP), false positives (FP), false negatives (FN), precision (P), recall (R) and F-measure  (F). Task ranking was only given for strict scoring.", "labels": [], "entities": [{"text": "disorder identification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7213283777236938}, {"text": "true positives (TP), false positives (FP), false negatives (FN)", "start_pos": 132, "end_pos": 195, "type": "METRIC", "confidence": 0.7126490053008584}, {"text": "precision (P)", "start_pos": 197, "end_pos": 210, "type": "METRIC", "confidence": 0.9465248733758926}, {"text": "recall (R)", "start_pos": 212, "end_pos": 222, "type": "METRIC", "confidence": 0.939804807305336}, {"text": "F-measure  (F)", "start_pos": 227, "end_pos": 241, "type": "METRIC", "confidence": 0.9582557082176208}]}, {"text": " Table 4: Performance on disorder identification, normalization and slot-filling (Task 2b), including rank among the  23 competing systems (Rank), true positives (TP), false positives (FP), false negatives (FN), precision (P), recall (R),  F-measure (F), accuracy (A), weighted accuracy (WA).", "labels": [], "entities": [{"text": "disorder identification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7285536229610443}, {"text": "true positives (TP), false positives (FP)", "start_pos": 147, "end_pos": 188, "type": "METRIC", "confidence": 0.7027878788384524}, {"text": "precision (P)", "start_pos": 212, "end_pos": 225, "type": "METRIC", "confidence": 0.9426927715539932}, {"text": "recall (R)", "start_pos": 227, "end_pos": 237, "type": "METRIC", "confidence": 0.936757817864418}, {"text": "F-measure (F)", "start_pos": 240, "end_pos": 253, "type": "METRIC", "confidence": 0.9468201398849487}, {"text": "accuracy (A)", "start_pos": 255, "end_pos": 267, "type": "METRIC", "confidence": 0.9582580327987671}, {"text": "weighted accuracy (WA)", "start_pos": 269, "end_pos": 291, "type": "METRIC", "confidence": 0.8913480043411255}]}, {"text": " Table 5: Weighted accuracy by attribute type on slot-filling", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9729385375976562}]}]}