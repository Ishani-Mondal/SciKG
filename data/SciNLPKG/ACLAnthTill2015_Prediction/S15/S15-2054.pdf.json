{"title": [{"text": "BLCUNLP: Corpus Pattern Analysis for Verbs Based on Dependency Chain", "labels": [], "entities": [{"text": "BLCUNLP", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9262628555297852}, {"text": "Corpus Pattern Analysis", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.8393935759862264}]}], "abstractContent": [{"text": "We implemented a syntactic and semantic tagging system for SemEval 2015 Task 15: Corpus Pattern Analysis.", "labels": [], "entities": [{"text": "SemEval 2015 Task 15", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.8528241962194443}, {"text": "Corpus Pattern Analysis", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.7971406777699789}]}, {"text": "For syntactic tagging, we present a Dependency Chain Search Algorithm that is found to be effective at identifying structurally distant subjects and objects.", "labels": [], "entities": [{"text": "syntactic tagging", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7157662808895111}]}, {"text": "Other syntactic labels are identified using rules defined over dependency parse structures and the output of a verb classification module.", "labels": [], "entities": [{"text": "verb classification module", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.7726859649022421}]}, {"text": "Semantic tagging is performed using a simple lexical mapping table combined with post-processing rules written over phrase structure constituent types and named entity information.", "labels": [], "entities": [{"text": "Semantic tagging", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.847180038690567}]}, {"text": "The final score of our system is 0.530 F1, ranking second in this task.", "labels": [], "entities": [{"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9942618608474731}]}], "introductionContent": [{"text": "Corpus Pattern Analysis (CPA) is an important language analysis technique, which attempts to describe the patterns of word usage in text.", "labels": [], "entities": [{"text": "Corpus Pattern Analysis (CPA)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8236141155163447}, {"text": "language analysis", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7297769486904144}]}, {"text": "In this paper, we present the system we developed for SemEval-2015 Task 15: CPA, Subtask1: CPA parsing.", "labels": [], "entities": [{"text": "SemEval-2015 Task 15", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.8244976997375488}, {"text": "CPA parsing", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.6011521071195602}]}, {"text": "The system operates in two stages: syntactic tagging and semantic tagging.", "labels": [], "entities": [{"text": "syntactic tagging", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.685235857963562}, {"text": "semantic tagging", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.6985045075416565}]}, {"text": "We first search for the syntactic roles of a verb's arguments in a sentence.", "labels": [], "entities": []}, {"text": "We use the following tag set for the syntactic roles: \"subj\" is for subject, \"obj\" is for object, \"iobj\" is for indirect object, \"advprep\" is for adverbial preposition or other adverbial/verbal link, \"acomp\" is for adverbial or verb complement, and \"scomp\" is for noun or adjective complement.", "labels": [], "entities": []}, {"text": "For example, take a sentence whose core verb is \"plan\": \"Mr Eigen plans to wage his war diplomatically\".", "labels": [], "entities": []}, {"text": "The correct tagging of syntactic Due to time constraints, we put more effort into improving the accuracy of syntactic tagging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9990485310554504}, {"text": "syntactic tagging", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7352978587150574}]}, {"text": "We rely on simpler techniques for semantic tagging.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.8326288461685181}]}, {"text": "For syntactic tagging, we use Stanford CoreNLP to extract linguistic attributes, deduce dependency chains through dependency relations and to classify verbs.", "labels": [], "entities": [{"text": "syntactic tagging", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7339364886283875}, {"text": "Stanford CoreNLP", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.9141819477081299}]}, {"text": "When performing semantic tagging, we use a data driven mapping of words to their most frequent semantic tag in the task's training data in conjunction with a small number of postprocessing rules.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7339359223842621}]}], "datasetContent": [{"text": "Our syntactic and semantic tagging results from the official evaluation are shown in.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.6730083376169205}]}, {"text": "During the official evaluation, we failed to upload the \"undertake\" file, which lead to a comparatively lower score on this task.", "labels": [], "entities": []}, {"text": "The final overall F-score of our system is 0.53, ranking second on the task, with the baseline system achieving 0.624.", "labels": [], "entities": [{"text": "F-score", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.996581494808197}]}, {"text": "This F-score is calculated by averaging the F-scores achieved on syntactic and semantic tagging.", "labels": [], "entities": [{"text": "F-score", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.996574878692627}, {"text": "F-scores", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9936809539794922}, {"text": "syntactic and semantic tagging", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.6572638675570488}]}, {"text": "On the evaluation data, if we ignore the \"undertake\" file that we failed to upload, the average F-score of syntactic tagging increases to 0.732, and the combined overall score increases to 0.619.", "labels": [], "entities": [{"text": "F-score", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.998766303062439}]}, {"text": "Similar to our work, the baseline methods are also rule based, but we observe that our rules underperform the baseline.", "labels": [], "entities": []}, {"text": "We believe this is because we used a simpler rule set that we spent less time refining for the semantic task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Syntactic and semantic tagging results.", "labels": [], "entities": [{"text": "Syntactic and semantic tagging", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.6824981942772865}]}]}