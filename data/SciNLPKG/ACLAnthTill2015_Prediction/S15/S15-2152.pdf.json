{"title": [{"text": "INRIASAC: Simple Hypernym Extraction Methods", "labels": [], "entities": [{"text": "INRIASAC", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7458409070968628}, {"text": "Hypernym Extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.6574607789516449}]}], "abstractContent": [{"text": "For information retrieval, it is useful to classify documents using a hierarchy of terms from a domain.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7953576147556305}]}, {"text": "One problem is that, for many domains , hierarchies of terms are not available.", "labels": [], "entities": []}, {"text": "The task 17 of SemEval 2015 addresses the problem of structuring a set of terms from a given domain into a taxonomy without manual intervention.", "labels": [], "entities": []}, {"text": "Here we present some simple taxonomy structuring techniques, such as term overlap and document and sentence co-occurrence in large quantities of text (English Wikipedia) to produce hypernym pairs for the eight domain lists supplied by the task organizers.", "labels": [], "entities": [{"text": "term overlap", "start_pos": 69, "end_pos": 81, "type": "TASK", "confidence": 0.6512802243232727}, {"text": "English Wikipedia)", "start_pos": 151, "end_pos": 169, "type": "DATASET", "confidence": 0.9385084311167399}]}, {"text": "Our submission ranked first in this 2015 benchmark, which suggests that overly complicated methods might need to be adapted to individual domains.", "labels": [], "entities": []}, {"text": "We describe our generic techniques and present an initial evaluation of results.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes two simple hypernym extraction methods, given a list of domain terms and a large amount of text divided into documents.", "labels": [], "entities": [{"text": "hypernym extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7648209035396576}]}, {"text": "Task 17 of the 2015 Semeval campaign consists in structuring a flat list of preidentified domain terms into a list of hypernym pairs.", "labels": [], "entities": []}, {"text": "Task organizers provide two lists of terms for each of four domains: equipment, food, chemical, science, one extracted from WordNet and one from an unknown source.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 124, "end_pos": 131, "type": "DATASET", "confidence": 0.975006639957428}]}, {"text": "Participants in the task were allowed to use any resource (except existing taxonomies) to automatically transform the lists of terms into lists of pairs of terms, the first term being a hyponym of the more general second term.", "labels": [], "entities": []}, {"text": "For example, if the words airship and blimp were included in the lists of terms fora domain, the system was expected to return lines such as: The task organizers provided training data from the domains of Artificial Intelligence, vehicles and plants, different from the test domains.", "labels": [], "entities": []}, {"text": "The training data consisted in term lists (for plants), and term lists and lists of hypernyms (for AI and for vehicles).", "labels": [], "entities": []}, {"text": "We examined these files to get an understanding of the task but did not exploit them.", "labels": [], "entities": []}, {"text": "We used the English text of Wikipedia (downloaded from http://dumps.wikimedia.org on August 13, 2014) as our only resource for discovering these relations.", "labels": [], "entities": []}, {"text": "We extracted only the text of each article, ignoring titles, section headings, categories, infoboxes, or other meta-information present in the article.", "labels": [], "entities": []}, {"text": "We recognized task terms in these articles and gathered statistics on document and sentence co-occurrence between domain terms, as well as term frequency.", "labels": [], "entities": []}, {"text": "To recognize hypernyms, we used term inclusion (explained in section 3.1 below) and co-occurrence statistics (see section 3.2) to decide whether two terms were possibly in a hypernym relation, and document frequency to chose which term was the hypernym.", "labels": [], "entities": []}, {"text": "Our submission ranked first in the SemEval 2015 task 17 benchmark.", "labels": [], "entities": [{"text": "SemEval 2015 task 17", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.8251150548458099}]}], "datasetContent": [{"text": "Each participant in Task 17 of SemEval 2015 was allowed to submit one run for each of the 8 domains (see for the names of the domains, and the number of hypernym pairs we submitted.", "labels": [], "entities": []}, {"text": "Suffix and prefix subterms account for 10% to 36% of the hypernyms we produced.", "labels": [], "entities": []}, {"text": "The cooccurence technique produced the most hypernym candidates).", "labels": [], "entities": []}, {"text": "The task organizers evaluated the submissions of the six participating teams, using automated and manual methods, and published their evaluation three weeks after the submission deadline.", "labels": [], "entities": []}, {"text": "Our team placed first in the official ranking of the six teams.", "labels": [], "entities": []}, {"text": "The evaluation criteria, which were not published before the submission, combined the presences of cycles in the hypernyms submitted, the Fowlkes & Mallows measure of the overlap between the submitted hierarchy and the gold standard hierarchy, the F-score ranking, the number of domains submitted (not all teams returned results for all domains), and a manual precision ranking (for hypernyms not present in the gold standard).", "labels": [], "entities": [{"text": "F-score ranking", "start_pos": 248, "end_pos": 263, "type": "METRIC", "confidence": 0.9757155478000641}, {"text": "precision", "start_pos": 360, "end_pos": 369, "type": "METRIC", "confidence": 0.9788651466369629}]}, {"text": "The gold standards used by the task organizers came from published taxonomies, or from subtrees of WordNet (prefixed as WN_ above).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9617630839347839}]}, {"text": "A quick evaluation of how well our simple hypernym extraction techniques fared on each gold standard is shown in.", "labels": [], "entities": [{"text": "hypernym extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7700012624263763}]}, {"text": "As shows, most of the correct answers found come from the sentence and document cooccurrence method described in section 3.2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Number of prefix and suffix hypernyms pro- duced, compared to the total number of hypernyms re- turned for each domain.", "labels": [], "entities": []}, {"text": " Table 2. Number of gold standard relations to find in  the last column. Columns 2, 3 and 4 are the number of  gold standard relations found by each technique. \"un- ion\" is the union of columns 2, 3 and 4. Since the co- occurrence technique can find relations that have been  found by the suffix and prefix techniques.", "labels": [], "entities": []}, {"text": " Table 3. Percentage of correct answers found by each  method.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9782592058181763}]}]}