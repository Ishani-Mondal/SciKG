{"title": [{"text": "Lsislif: CRF and Logistic Regression for Opinion Target Extraction and Sentiment Polarity Analysis", "labels": [], "entities": [{"text": "Sentiment Polarity Analysis", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.8630032738049825}]}], "abstractContent": [{"text": "This paper describes our contribution in Opinion Target Extraction OTE and Sentiment Polarity sub tasks of SemEval 2015 ABSA task.", "labels": [], "entities": [{"text": "Opinion Target Extraction OTE", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.6135954931378365}, {"text": "SemEval 2015 ABSA task", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.7179133743047714}]}, {"text": "A CRF model with IOB notation has been adopted for OTE with several groups of features including syntactic, lexical, semantic, sentiment lexicon features.", "labels": [], "entities": []}, {"text": "Our submission for OTE is ranked fifth over twenty submissions.", "labels": [], "entities": [{"text": "OTE", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.7795796990394592}]}, {"text": "A Logistic Regression model with a weighting schema of positive and negative labels have been used for sentiment polarity; several groups of features (lexical, syntactic , semantic, lexicon and Z score) are extracted.", "labels": [], "entities": [{"text": "sentiment polarity", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.9059275984764099}, {"text": "Z score", "start_pos": 194, "end_pos": 201, "type": "METRIC", "confidence": 0.9076999723911285}]}, {"text": "Our submission for Sentiment Polarity is ranked third over ten submissions on the restaurant data set, third over thirteen on the laptops data set, but the first over eleven on the hotel data set that is out-of-domain set.", "labels": [], "entities": [{"text": "Sentiment Polarity", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.9254090487957001}, {"text": "restaurant data set", "start_pos": 82, "end_pos": 101, "type": "DATASET", "confidence": 0.77755073706309}, {"text": "laptops data set", "start_pos": 130, "end_pos": 146, "type": "DATASET", "confidence": 0.760804812113444}, {"text": "hotel data set", "start_pos": 181, "end_pos": 195, "type": "DATASET", "confidence": 0.819385806719462}]}], "introductionContent": [{"text": "Sentiment Analysis (SA) has become more and more interesting since the year 2000, many techniques in Natural Language Processing have been used to understand the expressed sentiment on an entity.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9115148067474366}]}, {"text": "Many levels of granularity have been also distinguished: Document Level SA considers the whole document is about an entity and classifies whether the expressed sentiment is positive, negative or neutral; Sentence Level SA determines the sentiment of each sentence, some papers have focused on Clause Level SA, but they are still not enough; Entity or Aspect-Based SA performs finer-grained analysis in which all entities and their aspects should be extracted and the sentiment towards them should also be determined.", "labels": [], "entities": []}, {"text": "Aspect-Based SA task consists of several subproblems, the document is about many entities which could be for example a restaurant, a laptop, a printer.", "labels": [], "entities": []}, {"text": "Users may refer to an entity by different writings, but normally there are not a lot of variations to indicate the same entity, each entity has many aspects which could be its parts or attributes.", "labels": [], "entities": []}, {"text": "Some aspects could be another entity such as screen of laptop, but most work did not take this case into account.", "labels": [], "entities": []}, {"text": "Therefore, we could define the opinion by the quintuple (Liu, 2012) (ei, aij, sijkl, hk, tl) where ei is the entity i, aij are the aspects of the entity i, sijkl is the expressed sentiment on the aspect at the time tl , hk the holder which created the document or the text.", "labels": [], "entities": []}, {"text": "This definition does not take into account that the entity has aspects that could have also other aspects which leads to an aspect hierarchy, in order to avoid this information loss, few work has handled this issue, they proposed to represent the aspect as a tree of aspect terms.", "labels": [], "entities": []}, {"text": "In this paper, we focus on Opinion Target Extraction (OTE) and Sentiment Polarity towards a target or a category.", "labels": [], "entities": [{"text": "Opinion Target Extraction (OTE)", "start_pos": 27, "end_pos": 58, "type": "METRIC", "confidence": 0.8069303035736084}]}, {"text": "The description of each subtask is provided by ABSA organizers (.", "labels": [], "entities": [{"text": "ABSA organizers", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.8314079940319061}]}, {"text": "For OTE or aspect term extraction, a CRF model is proposed with IOB annotation and several groups of features including syntactic, lexical, semantic, sentiment lexicon features.", "labels": [], "entities": [{"text": "OTE or aspect term extraction", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.6204002976417542}]}, {"text": "For aspect term polarity detection, a logistic regression classifier is trained with weighting schema for positive and negative labels and several groups of features are extracted includ-ing lexical, syntactic, semantic, lexicon and Z score features.", "labels": [], "entities": [{"text": "aspect term polarity detection", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.8098333477973938}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines existing work in aspect extraction and polarity detection.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.8642463982105255}, {"text": "polarity detection", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.848501443862915}]}, {"text": "Section 3 describes our system for aspect term extraction.", "labels": [], "entities": [{"text": "aspect term extraction", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7781647642453512}]}, {"text": "Aspect term polarity detection is presented in Section 4.", "labels": [], "entities": [{"text": "Aspect term polarity detection", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6249173730611801}]}, {"text": "Section 6 shows the conclusion and the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In addition to the restaurant data set presented in tabel 1, two other data sets statistics are presented in table 3 (Laptops data which consists of training and testing data sets while the Hotel test set is out of domain set that was provided to test our model on new domain without having training data).", "labels": [], "entities": [{"text": "restaurant data set", "start_pos": 19, "end_pos": 38, "type": "DATASET", "confidence": 0.7678628265857697}, {"text": "Hotel test set", "start_pos": 190, "end_pos": 204, "type": "DATASET", "confidence": 0.8639224767684937}]}, {"text": "We trained a L1-regularized Logistic regression classifier implemented in LIBLINEAR, which has given good results in several papers ()).", "labels": [], "entities": []}, {"text": "The classifier is trained on the training data set using the previous features with the three polarities (positive, negative, and neutral) as labels.", "labels": [], "entities": []}, {"text": "A weighting schema is adapted for each class, we use the weighting option -wi which enables a use of different cost parameter C for different classes.", "labels": [], "entities": []}, {"text": "Since the training data is unbalanced, this weighting schema adjusts the probability of each label.", "labels": [], "entities": []}, {"text": "Thus, we tuned the classifier in adjusting the cost parameter C of Logistic Regression, weight wpos of positive class and weight wneg of negative class.", "labels": [], "entities": []}, {"text": "We used the 1/10 of training data set for tuning the three parameters in the two data sets, all combinations of C in range 0.1 to to 4 by step 0.1, wpos in range 1 to 8 by step 0.1, wneg in range 1 to 8 by step 0.1 are tested.", "labels": [], "entities": [{"text": "training data set", "start_pos": 20, "end_pos": 37, "type": "DATASET", "confidence": 0.7561647593975067}]}, {"text": "The combination C=0.3, textitwpos=1.2, wneg=1.9 have been chosen for the restaurant set and C=0.2 wpos=2.1 wneg=1.9 for the laptops set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Training and testing data sets for restaurant  OTE slot.", "labels": [], "entities": [{"text": "OTE slot", "start_pos": 57, "end_pos": 65, "type": "TASK", "confidence": 0.7523018717765808}]}, {"text": " Table 2 shows our system and the baseline  results.", "labels": [], "entities": []}, {"text": " Table 3. Data set statistics for Hotel and Laptops  Reviews.", "labels": [], "entities": [{"text": "Hotel and Laptops  Reviews", "start_pos": 34, "end_pos": 60, "type": "DATASET", "confidence": 0.7621291428804398}]}, {"text": " Table 4. Results of sentiment polarity in Restaurant,  laptops, hotels reviews.", "labels": [], "entities": []}]}