{"title": [{"text": "GPLSIUA: Combining Temporal Information and Topic Modeling for Cross-Document Event Ordering", "labels": [], "entities": [{"text": "GPLSIUA", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9130769968032837}, {"text": "Cross-Document Event Ordering", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.6509190499782562}]}], "abstractContent": [{"text": "Building unified timelines from a collection of written news articles requires cross-document event coreference resolution and temporal relation extraction.", "labels": [], "entities": [{"text": "cross-document event coreference resolution", "start_pos": 79, "end_pos": 122, "type": "TASK", "confidence": 0.7188450172543526}, {"text": "temporal relation extraction", "start_pos": 127, "end_pos": 155, "type": "TASK", "confidence": 0.6179492175579071}]}, {"text": "In this paper we present an approach event coreference resolution according to: a) similar temporal information, and b) similar semantic arguments.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.8337539434432983}]}, {"text": "Temporal information is detected using an automatic temporal information system (TIPSem), while semantic information is represented by means of LDA Topic Modeling.", "labels": [], "entities": []}, {"text": "The evaluation of our approach shows that it obtains the highest Micro-average F-score results in the SemEval-2015 Task 4: \"TimeLine: Cross-Document Event Ordering\" (25.36% for TrackB, 23.15% for SubtrackB), with an improvement of up to 6% in comparison to the other systems.", "labels": [], "entities": [{"text": "Micro-average", "start_pos": 65, "end_pos": 78, "type": "METRIC", "confidence": 0.9091024994850159}, {"text": "F-score", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.7832642197608948}, {"text": "Cross-Document Event Ordering", "start_pos": 134, "end_pos": 163, "type": "TASK", "confidence": 0.6365758081277212}]}, {"text": "However , our experiment also showed some drawbacks in the Topic Modeling approach that degrades performance of the system.", "labels": [], "entities": [{"text": "Topic Modeling", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.8719007670879364}]}], "introductionContent": [{"text": "Since access to knowledge is crucial in any domain, connecting and time-ordering the information extracted from different documents is a very important task.", "labels": [], "entities": []}, {"text": "The goal of this paper is therefore to build ordered timelines fora set of events related to a target entity.", "labels": [], "entities": []}, {"text": "In doing so, our approach is dealing with two problems: a) cross-document event coreference resolution and b) cross-document temporal relation extraction.", "labels": [], "entities": [{"text": "cross-document event coreference resolution", "start_pos": 59, "end_pos": 102, "type": "TASK", "confidence": 0.7594484463334084}, {"text": "cross-document temporal relation extraction", "start_pos": 110, "end_pos": 153, "type": "TASK", "confidence": 0.7405737042427063}]}, {"text": "In order to arrange event mentions in a timeline it is necessary to know which event mentions co-refer to the same event or fact and occur at the same moment.", "labels": [], "entities": []}, {"text": "Our approach attempts to formalize the idea that two or more event mentions co-refer if they have not only temporal compatibility (the events occur at the same time) but also semantic compatibility (the event mentions refers to the same facts, location, entities, etc.).", "labels": [], "entities": []}, {"text": "Of a set of event mentions in one or more texts, our proposal groups together the event mentions that (i) have the same or a similar temporal reference, (ii) have the same or a similar event headword, and (iii) whose main arguments refer to the same or similar topics.", "labels": [], "entities": []}, {"text": "In order to evaluate the system, we have participated in the SemEval-2015 Task 4 \"TimeLine: Cross-Document Event Ordering\".", "labels": [], "entities": [{"text": "Cross-Document Event Ordering", "start_pos": 92, "end_pos": 121, "type": "TASK", "confidence": 0.6518483658631643}]}, {"text": "In the following sections we will present the theoretical background to our approach (section 2) and the main technical aspects (sections 3 and 4).", "labels": [], "entities": []}, {"text": "Then we will present the results obtained (section 5) and some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "SemEval-2015 Task 4 consists on building timelines from written news in English in which a target entity is involved.", "labels": [], "entities": []}, {"text": "The input data provided by the organizers is therefore a set of documents and a set of target entities related to those documents.", "labels": [], "entities": []}, {"text": "Two different tracks are proposed in the task, along with their subtracks: \u2022 Track A: This consists of using raw texts as input and obtaining full timelines.", "labels": [], "entities": []}, {"text": "Subtrack A has the same input data, but the output will be the timeLines of only ordered events (no assignment of time anchors).", "labels": [], "entities": []}, {"text": "\u2022 Track B: This consists of using texts with manual annotation of events mentions as input data.", "labels": [], "entities": []}, {"text": "Subtrack B has the same input data but the output will be timeLines of only ordered events.", "labels": [], "entities": []}, {"text": "In the Semeval-2015 Task 4 competition we have participated in Track B and Subtrack B. The results for the Micro-average F-score measure obtained by our approach in the competition are shown in.", "labels": [], "entities": [{"text": "Semeval-2015 Task 4 competition", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.6327587515115738}, {"text": "Micro-average F-score measure", "start_pos": 107, "end_pos": 136, "type": "METRIC", "confidence": 0.8338205615679423}]}, {"text": "Although the Micro-FScore results are not very high, the results obtained by our approach are the highest in all of the corpus evaluated by the organizers.", "labels": [], "entities": []}, {"text": "Our approach obtained an improvement of 7% compared with the other participant in Track B and a 6.48% in Subtrack B.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for GPLSIUA Approach.", "labels": [], "entities": [{"text": "GPLSIUA", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.5771887302398682}, {"text": "Approach", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.611565351486206}]}]}