{"title": [{"text": "Distributional semantics for ontology verification *", "labels": [], "entities": [{"text": "ontology verification", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8159806132316589}]}], "abstractContent": [{"text": "As they grow in size, OWL ontologies tend to comprise intuitively incompatible statements, even when they remain logically consistent.", "labels": [], "entities": []}, {"text": "This is true in particular of lightweight on-tologies, especially the ones which aggregate knowledge from different sources.", "labels": [], "entities": []}, {"text": "The article investigates how distributional semantics can help detect and repair violation of commonsense in consistent ontologies, based on the identification of consequences which are unlikely to hold if the rest of the ontology does.", "labels": [], "entities": []}, {"text": "A score evaluating the plausibility fora consequence to hold with regard to distributional evidence is defined, as well as several methods in order to decide which statements should be preferably amended or discarded.", "labels": [], "entities": []}, {"text": "A conclusive evaluation is also provided, which consists in extending an input ontology with randomly generated statements, before trying to discard them automatically.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ontology learning from texts deals with the automated extraction of knowledge from linguistic evidence.", "labels": [], "entities": [{"text": "Ontology learning from texts", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8623023629188538}, {"text": "automated extraction of knowledge from linguistic evidence", "start_pos": 44, "end_pos": 102, "type": "TASK", "confidence": 0.8212706276348659}]}, {"text": "This article investigates a slightly different problem, which is how Natural Language Processing may provide hints for the identification of statements of an input ontology which are unlikely to hold if the rest of it does.", "labels": [], "entities": []}, {"text": "As a minimal example, consider the following set \u2206 of statements, from DBpedia (, and assume that \u2206 is a subset of a larger set of statements K (for instance DBpedia itself, or some subset of it) : There is a clear violation of commonsense in \u2206 : the individual CEO must be both a key person of Caixa Bank, and the occupation of another individual, who is himself a key person of some company.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9695748090744019}, {"text": "DBpedia", "start_pos": 158, "end_pos": 165, "type": "DATASET", "confidence": 0.928095817565918}, {"text": "Caixa Bank", "start_pos": 295, "end_pos": 305, "type": "DATASET", "confidence": 0.8755207657814026}]}, {"text": "Detecting such cases within (larger) sets of logical statements is of particular interest in OWL, which facilitates the aggregation of knowledge from multiple sources with overlapping signatures, yielding datasets in which several incompatible understandings of a same individual or predicate may coexist.", "labels": [], "entities": []}, {"text": "This easily leads to undesired inferences, even when the dataset is logically consistent.", "labels": [], "entities": []}, {"text": "But as the example illustrates, the problem may also occur within a single knowledge base, especially if it has been built semi-automatically, and/or is issued from a collaborative effort.", "labels": [], "entities": []}, {"text": "Another problem of interest consists in deciding which statement(s) should be preferably discarded or amended in order to get rid of the nonsense.", "labels": [], "entities": []}, {"text": "In example 1, without further information, it would be intuitively relevant to discard or modify either (1) or (2).", "labels": [], "entities": []}, {"text": "Unfortunately though, \u2206 alone does not give any indication of which of the two should be preferably discarded.", "labels": [], "entities": []}, {"text": "But the whole input ontology K \u2283 \u2206 may.", "labels": [], "entities": []}, {"text": "To keep the example simple, let us assume that Peter Munk, CEO and occupation do not appear in K \\ \u2206.", "labels": [], "entities": [{"text": "Peter Munk", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.72345170378685}]}, {"text": "Then a reasonable assumption is that the overall understanding of keyPerson within K should be the decisive factor.", "labels": [], "entities": []}, {"text": "If it generally ranges over person functions (i.e. if inmost instances of the relation according to K, the second argument is a person function), then it is to be understood as \"has as a key person someone whose function is\", and (2) should be preferably discarded.", "labels": [], "entities": []}, {"text": "Alternatively, if keyPerson generally ranges over human beings, then (1) should be preferably discarded.", "labels": [], "entities": []}, {"text": "The article investigates the use of linguistic evidence to solve both of these problems : identifying violations of commonsense, and selecting the statement(s) to be preferably amended or discarded.", "labels": [], "entities": []}, {"text": "This maybe viewed as a small paradigm shift, in that it questions an assumption commonly made in the knowledge extraction literature, namely that manually crafted knowledge strictly prevails over the one obtained from linguistic sources.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.7294808626174927}]}, {"text": "By default, the case of a consistent 2 input ontology K will be studied, but section 6 discusses the application of the approach to an inconsistent K as well.", "labels": [], "entities": []}, {"text": "As a concrete contribution, section 5 evaluates the adaptation of relatively simple techniques issued from named entity classification/ontology population, and based on distributional semantics.", "labels": [], "entities": [{"text": "named entity classification", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6382695039113363}]}, {"text": "To illustrate how this works, let us assume that the only other appearance of keyPerson within K is the following OWL statement : Then K |= \u03c8 1 = Person(CEO), and K |= \u03c8 2 = Person(Peter Munk).", "labels": [], "entities": []}, {"text": "Assume also that there are other instances of Person according to K, and that most of them are actually human beings (like Peter Munk).", "labels": [], "entities": []}, {"text": "Then \u03c8 1 is an undesirable consequence of K, whereas \u03c8 2 on the other hand reinforces it.", "labels": [], "entities": []}, {"text": "Distributional semantics characterizes a word (or possibly a multi word unit) by some algebraic representation of the linguistic contexts with which it is observed.", "labels": [], "entities": [{"text": "Distributional semantics characterizes a word", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8278434991836547}]}, {"text": "These representations have already been used for ontology population, for instance by, the main intuition being that individuals denoted by linguistic terms with similar contexts tend to instantiate the same classes.", "labels": [], "entities": []}, {"text": "The underlying linguistic phenomenon is known as selectional preference, i.e. the fact that some contexts tend to selector rule out certain categories of individuals : e.g. the context \"X was born in\" tends to select a human being, whereas \"X was launched\" tends to rule it out.", "labels": [], "entities": []}, {"text": "Back to the example, one can expect the similarity between the distributional representation of the term \"C.E.O\" and other terms denoting instances of Person according to K to be relatively low, hindering the plausibility of \u03c8 1 with regard to K.", "labels": [], "entities": []}, {"text": "In other words, \u03c8 1 should stand as an outlier among consequences of K, and therefore is probably undesirable.", "labels": [], "entities": []}, {"text": "Conversely, the similarity between \"Peter Munk\" and terms denoting other instances of Person should be relatively high.", "labels": [], "entities": [{"text": "similarity", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.9900380373001099}]}, {"text": "For simplicity, suppose that (1), (2), (3) and (4) are the only 4 statements of K which are candidate for removal.", "labels": [], "entities": []}, {"text": "Then in order to give up the belief in \u03c8 1 while preserving \u03c8 2 , it is necessary to discard (1), and retain (2) and (4).", "labels": [], "entities": []}, {"text": "It is also sufficient to discard (1), i.e. discarding (3) as well would result in an unnecessary information loss.", "labels": [], "entities": []}, {"text": "So in this case, the evidence provided by distributional semantics should suggest the removal of (1), or at least its modification, which is also intuitively the correct solution.", "labels": [], "entities": []}, {"text": "Section 4 formalizes this approach, by defining a score which estimates the plausibility of some consequences a subbases \u0393 of K, given distributional evidence.", "labels": [], "entities": []}, {"text": "Section 5 then provides an original evaluation of this strategy, based on the prior extension of a small OWL ontology with randomly generated statements.", "labels": [], "entities": []}, {"text": "The approach is evaluated for both problems, i.e. the identification of undesired consequences and statements.", "labels": [], "entities": []}, {"text": "Performances of several forms of distributional representations are also compared.", "labels": [], "entities": []}, {"text": "Section 6 discusses immediate applications, in particular for (consistent and inconsistent) ontology debugging.", "labels": [], "entities": [{"text": "ontology debugging", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7160644233226776}]}, {"text": "Finally, section 7 considers possible extensions of this framework, as well as their limitations.", "labels": [], "entities": []}, {"text": "Section 2 is a brief overview of related works in the fields of ontology learning and debugging, whereas section 3 introduces notational conventions, and lists some preliminary requirements to be met by the input K.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset used for this evaluation is a fragment of the fisheries ontology from the NEON project.", "labels": [], "entities": [{"text": "NEON project", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.7963488101959229}]}, {"text": "It has been automatically built out of 10 randomly selected named individuals, applying a module extraction procedure, followed by a trimming algorithm.", "labels": [], "entities": []}, {"text": "The fragment contains 1038 (logical) statements, and involves 71 named individuals (mostly geographical or administrative entities), the least expressive underlying DL being SI.", "labels": [], "entities": []}, {"text": "The linguistic input is a small corpus of approximately 6300 web pages, retrieved with a search engine, using the labels of named individuals of F as queries.", "labels": [], "entities": []}, {"text": "The HTML documents were cleaned with the BootCat library ().", "labels": [], "entities": [{"text": "BootCat library", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9619115591049194}]}, {"text": "The construction of the distributional representations of the named individuals of F was basic, the use of more elaborate methods (SVD,.", "labels": [], "entities": []}, {"text": ") being left for future work.", "labels": [], "entities": []}, {"text": "The approach presented in this article remains generic enough to be applied to most existing distributional frameworks, the only requirement being a real-valued similarity measure.", "labels": [], "entities": []}, {"text": "Two different forms of linguistic contexts were alternatively tested.", "labels": [], "entities": []}, {"text": "The first option considers as a context any n-gram (2 \u2264 n \u2264 5) without punctuation mark which immediately precedes or follows a term t denoting an individual of F . The other option is a more customized one, extracting sequences of lemmatized words (lemmaPOS in what follows) surrounding t, in a shifting window of 3 to 5 tokens + the size oft, ignoring certain categories of word.", "labels": [], "entities": []}, {"text": "Part-of-speech tagging was performed thanks to the Stanford Parser (, with a pre-trained model for English.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7964976727962494}, {"text": "Stanford Parser", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.8989935219287872}]}, {"text": "If Cont designates the set of contexts observed with at least 2 individuals, then an individual was rep-7 http://www.neon-project.org/nw/Ontologies resented by the vector of its respective frequencies with each context c \u2208 Cont.", "labels": [], "entities": []}, {"text": "Different possibilities were compared to weight these frequencies.", "labels": [], "entities": []}, {"text": "The pointwise mutual information (PMI) was used in a standard way for n-grams and lemmaPOS contexts (with possible negative resulting frequencies set to 0).", "labels": [], "entities": []}, {"text": "Following (), the self-information self(c) was also used for n-grams, defined by self(c) = \u2212 log p(c), the probability p(c) being estimated thanks to the Microsoft Web N-gram Services.", "labels": [], "entities": []}, {"text": "A combined weighting by PMI and self-information was also tested for n-grams.", "labels": [], "entities": []}, {"text": "These alternative settings are represented by capital letters in tables 1 and 2 : LP for lemmaPOS with PMI, and NP, NS and NPS for n-grams with PMI, self-information and both respectively.", "labels": [], "entities": []}, {"text": "The ontology F has been extended for the sake of the evaluation, with statements randomly generated out of its signature.", "labels": [], "entities": []}, {"text": "The underlying assumption is that adding such statements to F is very likely to generate violations of commonsense (although nothing prevents in theory the generation of plausible statements too).", "labels": [], "entities": []}, {"text": "The goal for the evaluation was then to automatically retrieve proper consequences of each extension of F on the one hand, and the random statements themselves on the other hand.", "labels": [], "entities": []}, {"text": "To prevent any misunderstanding, it should be emphasized that this is not a realistic application case.", "labels": [], "entities": []}, {"text": "The input ontology was selected for its quality, and degraded through random statement generation, allowing an arguably artificial, but also very objective evaluation procedure (the only bias may come from randomly generated statements which are actually plausible).", "labels": [], "entities": []}, {"text": "By contrast, using anon modified input dataset, and evaluating whether or not the axioms/consequences spotted by the algorithm are actually erroneous is a complex and subjective task, with a possibly low inter-annotator agreement.", "labels": [], "entities": []}, {"text": "The generation procedure randomly selects a statement \u03c6 \u2208 F , and yields a statement \u03c6 with the same syntactic structure as \u03c6, but in which individuals and predicates have been replaced by random individuals and predicates appearing in F . For instance, if \u03c6 = \u2200xy(A(x) \u2227 r(x, y) \u2192 \u00acB(y)), then \u03c6 = \u2200xy(C(x) \u2227 s(x, y) \u2192 \u00acD(y)), with C and D (resp. s) randomly chosen among classes (resp.", "labels": [], "entities": []}, {"text": "binary predicates) of the signature of F . 100 randomly generated statements \u03c6 1 , . were added independently to F , yielding 100 input ontologies K 1 , . .", "labels": [], "entities": []}, {"text": ", K 100 , such that each K i was consistent, and that there was at least one consequence of the form A(e) or \u00acA(e) entailed by K i but not by F , withe sharing at least one linguistic context with some other individual of F . All 100 input ontologies are available online.", "labels": [], "entities": []}, {"text": "The first part of the evaluation was performed as follows.", "labels": [], "entities": []}, {"text": "For each K i and each \u03c8 \u2208 \u03a8 K i , the plausibility sc K i (\u03c8) was computed as in definitions 4.1/4.2, and \u03a8 K i was ordered by increasing plausibility.", "labels": [], "entities": []}, {"text": "Within \u03a8 K i are consequences which were not initially entailed by F , but have been obtained after the extension of F with the random statement \u03c6 i . So in a sense, these consequences are randomly generated too, and therefore one may expect many of them to convey absurd information (for instance Architect(Belgium)), or at least to be outliers (like Person(CEO) in ex 1) within , and if sc K i (\u03c8) is actually lower than for most other formulas of \u03a8 K i , this would indicate that the plausibility score, as formulated in definitions 4.1/4.2, is actually a good estimator.", "labels": [], "entities": []}, {"text": "In order to evaluate this, column \"rank\" in table 1 gives the average ranking (for all 100 ontologies) within \u03a8 K i of the formula \u03c8 i \u2208 \u03a8 rand with lowest score.", "labels": [], "entities": []}, {"text": "The lower this ranking, the more efficient the plausibility score is at detecting outlier consequences.", "labels": [], "entities": []}, {"text": "Column \"pVal\" gives the probability (ttest) for the cumulated rankings of all formulas in all \u03a8 rand K i to be as low as the observed ones, if all consequences in all \u03a8 K i had been randomly ordered.", "labels": [], "entities": []}, {"text": "Results are convincing, with a significant p-value for all four settings.", "labels": [], "entities": []}, {"text": "For most ontologies (75/100), there was only one formula in \u03a8 rand . A closer look at the data revealed that, for the best setting (LP), inmost of theses cases (57/75), the only formula in \u03a8 rand K i was also the one with lowest plausibility in \u03a8 K i , over 216.1 on average, i.e. the only randomly generated consequence was also the least plausible one according to linguistic evidence.", "labels": [], "entities": []}, {"text": "This is very encouraging, especially considering the relatively small number of named individuals (71) in F , i.e. the fact that the support to evaluate the plausibility of a consequence \u03c8 \u2208 \u03a8 K i was limited.", "labels": [], "entities": []}, {"text": "On the other hand, performances were generally poor when the cardinality of \u03a8 rand , which maybe explained by the fact that support sets for some classes of F were significantly modified after the extension of F with \u03c6 i . As for the settings, unsurprisingly, the two most beneficial (but unfortunately incompatible) factors were the use of lemmatized contexts on the one hand (LP), and the queries over the Web N-gram corpus on the other hand (NS and NPS) The second part of the evaluation focused on the retrieval of the random statements \u03c6 1 , .., \u03c6 100 , for the LP setting only, because it gave the best results in the previous experiment.", "labels": [], "entities": []}, {"text": "For each extended base K i , all immediate subbases \u0393 i,1 , .., \u0393 i,|F |+1 of K i were generated, i.e. each \u0393 i,j was such that K i = \u0393 i,j \u222a {\u03c6 j } for some statement \u03c6 j of K i . The different \u0393 i,j were ordered by decreasing compliance score comp(\u0393 i,j ) (resp.", "labels": [], "entities": [{"text": "compliance score comp", "start_pos": 228, "end_pos": 249, "type": "METRIC", "confidence": 0.9082679748535156}]}, {"text": "comp K i (\u0393 i,j )), or by decreasing lexicographic ordering lex (resp.", "labels": [], "entities": []}, {"text": "Intuitively, this yields a ranking on K i where the least reliable statements wrt linguistic evidence should appear first : if \u03c6 j \u2208 K i , and if the subbase of K i obtained by discarding \u03c6 j (i.e. \u0393 i,j ) has a higher linguistic compliance score than K i , then discarding \u0393 i,j can be viewed as an improvement over K i . And if \u0393 i,j is among the best ranked subbases of K i , then \u03c6 j is among the least reliable statements of K i wrt distributional evidence.", "labels": [], "entities": []}, {"text": "For instance, in example 1, one may expect the subbase K \\ (1) to have a maximal linguistic compliance score among immediate subbases of K (or to be rank  maximal wrt the lexicographic ordering), such that (1) is the best candidate for removal.", "labels": [], "entities": [{"text": "maximal linguistic compliance score", "start_pos": 73, "end_pos": 108, "type": "METRIC", "confidence": 0.6375453993678093}]}, {"text": "So back to the test data, if K i = F \u222a {\u03c6 i }, i.e. if \u03c6 i is, among the |F +1| statements of K i , the one which has been randomly generated, and if \u0393 i,i = K i \\ \u03c6 i is among the best ranked immediate subbases of K i , this would indicate that the linguistic compliance score in definitions 4.3 (resp.", "labels": [], "entities": []}, {"text": "4.4), or the corresponding lexicographic ordering lex (resp.", "labels": [], "entities": []}, {"text": "lex K i ) is actually a good estimator of faulty statements.", "labels": [], "entities": []}, {"text": "An additional precaution was taken in order to avoid artificially good results.", "labels": [], "entities": []}, {"text": "For most statements \u03c6 j \u2208 K i , discarding \u03c6 j did not have any impact on the set \u03a8 \u0393 i,j of consequences to be evaluated, i.e. \u03a8 \u0393 i,j = \u03a8 K i , and therefore comp(\u0393 i,j ) = comp(K i ).", "labels": [], "entities": []}, {"text": "Let \u2206 i \u2286 K i be the set of statements whose removal did have an impact instead (on average, there were 79.3 statements in \u2206 i ).", "labels": [], "entities": []}, {"text": "Then the compliance of a subbase \u0393 i,j of K i was evaluated only if \u03c6 j \u2208 \u2206 i , i.e. only if the removal of \u03c6 j made a difference.", "labels": [], "entities": []}, {"text": "K i was also added to this set of evaluated subbases, yielding a ranking of 79.03 + 1 = 80.03 bases on average.", "labels": [], "entities": []}, {"text": "Column \"rank\" in table 2 gives the average ranking of \u0393 i,i , i.e. the base obtained after the removal of the randomly generated statement \u03c6 i . Both lexicographic orderings outperformed the compliance scores (i.e. the mean of plausibility scores), and the best configuration was the fourth presented in section 4.2, using sc K i (\u03c8) as a plausibility score instead of sc \u0393 i,j (\u03c8).", "labels": [], "entities": []}], "tableCaptions": []}