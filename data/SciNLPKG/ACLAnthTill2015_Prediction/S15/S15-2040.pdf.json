{"title": [{"text": "Al-Bayan: A Knowledge-based System for Arabic Answer Selection", "labels": [], "entities": [{"text": "Arabic Answer Selection", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.8228951891263326}]}], "abstractContent": [{"text": "This paper describes Al-Bayan team participation in SemEval-2015 Task 3, Subtask A. Task 3 targets semantic solutions for answer selection in community question answering systems.", "labels": [], "entities": [{"text": "SemEval-2015 Task 3", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.845449169476827}, {"text": "answer selection in community question answering", "start_pos": 122, "end_pos": 170, "type": "TASK", "confidence": 0.6764904260635376}]}, {"text": "We propose a knowledge-based solution for answer selection of Arabic questions, specialized for Islamic sciences.", "labels": [], "entities": [{"text": "answer selection of Arabic questions", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.8787497997283935}]}, {"text": "We build a Semantic Interpreter to evaluate the semantic similarity between Arabic question and answers using our Quranic ontology of concepts.", "labels": [], "entities": []}, {"text": "Using supervised learning, we classify the candidate answers according to their relevance to the users questions.", "labels": [], "entities": []}, {"text": "Results show that our system achieves 74.53% accuracy which is comparable to the other participating systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9993483424186707}]}], "introductionContent": [{"text": "With the increase of the popularity of community question answering (CQA) systems, answer selection became more challenging.", "labels": [], "entities": [{"text": "community question answering (CQA)", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.7970669269561768}, {"text": "answer selection", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.9825165569782257}]}, {"text": "CQA systems are often open for public to answer any questions with no restriction or review from field experts.", "labels": [], "entities": []}, {"text": "This highlights the importance of developing systems that automatically detects the most relevant answers from the irrelevant ones.", "labels": [], "entities": []}, {"text": "These systems might be open-domain or closed-domain, causing a tradeoff between accuracy and generality.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9991528987884521}]}, {"text": "SemEval-2015 task 3 targets semantically oriented solutions for answer selection in community question answering data.", "labels": [], "entities": [{"text": "answer selection in community question answering data", "start_pos": 64, "end_pos": 117, "type": "TASK", "confidence": 0.8589785865374974}]}, {"text": "We focus on Subtask A for the Arabic language which provides questions and several community answers from the Fatwa website . The Fatwa is a question about the Islamic religion.", "labels": [], "entities": []}, {"text": "goal is to classify each answer as: Direct, Related or Irrelevant.", "labels": [], "entities": []}, {"text": "In this paper, we propose a knowledge-based answer selection system for Arabic.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7576543390750885}]}, {"text": "We use our Quranic ontology, enriched with Quran verses and Tafseer books, to convert each question and its candidate answers into weighted vectors of ontology concepts.", "labels": [], "entities": []}, {"text": "We use these vectors to compute a semantic similarity score between the question and each candidate answer.", "labels": [], "entities": [{"text": "semantic similarity score", "start_pos": 34, "end_pos": 59, "type": "METRIC", "confidence": 0.6551223496596018}]}, {"text": "We also compute a keyword matching score and feed the two scores into a decision tree classifier which predicts how much the answer is related to the question.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 shows some of the related work to the system.", "labels": [], "entities": []}, {"text": "Section 3 shows the details of the system architecture.", "labels": [], "entities": []}, {"text": "In Section 4, we show the results of the task evaluation.", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our learning linguistic system by applying it on Fatwa questions/answers selection with a supervised learning framework.", "labels": [], "entities": [{"text": "Fatwa questions/answers selection", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.7380632281303405}]}, {"text": "We train our classifier on the provided benchmark dataset in SemEval2015.", "labels": [], "entities": []}, {"text": "The used data is from Fatwa website . Each question in the dataset is provided with five different answers.", "labels": [], "entities": [{"text": "Fatwa website", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.9767941534519196}]}, {"text": "Each answer is labeled as Direct, Related, or Irrelevant.", "labels": [], "entities": []}, {"text": "The distribution of the dataset we use is given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The confusion matrix, and precision,recall and F-measure of the SemEval 2015 testset.", "labels": [], "entities": [{"text": "precision,recall", "start_pos": 36, "end_pos": 52, "type": "METRIC", "confidence": 0.9996297359466553}, {"text": "F-measure", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.999053418636322}, {"text": "SemEval 2015 testset", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.7802911003430685}]}, {"text": " Table 2: Statistics of the training and testing data.", "labels": [], "entities": []}]}