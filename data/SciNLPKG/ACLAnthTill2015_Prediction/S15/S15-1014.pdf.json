{"title": [{"text": "Towards Semantic Language Classification: Inducing and Clustering Semantic Association Networks from Europarl", "labels": [], "entities": [{"text": "Semantic Language Classification", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.8040704528490702}, {"text": "Europarl", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.9598835110664368}]}], "abstractContent": [{"text": "We induce semantic association networks from translation relations in parallel corpora.", "labels": [], "entities": []}, {"text": "The resulting semantic spaces are encoded in a single reference language, which ensures cross-language comparability.", "labels": [], "entities": []}, {"text": "As our main contribution, we cluster the obtained (cross-lingually comparable) lexical semantic spaces.", "labels": [], "entities": []}, {"text": "We find that, in our sample of languages, lexical semantic spaces largely coincide with genealogical relations.", "labels": [], "entities": []}, {"text": "To our knowledge, this constitutes the first large-scale quantitative lexical semantic typology that is completely unsupervised, bottom-up, and data-driven.", "labels": [], "entities": []}, {"text": "Our results maybe important for the decision which multilingual resources to integrate in a semantic evaluation task.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has been a recent surge of interest in integrating multilingual resources in natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 83, "end_pos": 116, "type": "TASK", "confidence": 0.7491771280765533}]}, {"text": "For example, show that jointly considering morphological segmentations across languages improves performance compared to the monolingual baseline. and demonstrate that string transduction can benefit from supplemental information provided in other languages.", "labels": [], "entities": [{"text": "string transduction", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.7577714920043945}]}, {"text": "Analogously, in lexical semantics, Navigli and Ponzetto (2012) explore semantic relations from Wikipedia in different languages to induce a huge integrated lexical semantic network.", "labels": [], "entities": []}, {"text": "In this paper, we also focus on multilingual resources in lexical semantics.", "labels": [], "entities": []}, {"text": "But rather than integrating them, we investigate their (dis-)similarities.", "labels": [], "entities": []}, {"text": "More precisely, we cluster (classify) languages based on their semantic relations between lexical units.", "labels": [], "entities": []}, {"text": "The outcome of our classification may have direct consequences for approaches that integrate diverse multilingual resources.", "labels": [], "entities": []}, {"text": "For example, from a linguistic point of view, it might be argued that integrating very heterogeneous/dissimilar semantic resources is harmful, e.g., in a monolingual semantic similarity task, because semantically unrelated languages might contribute semantic relations unavailable in the language for which semantic similarity is computed.", "labels": [], "entities": []}, {"text": "Alternatively, from a statistical point of view, it might be argued that integrating heterogeneous/dissimilar resources is beneficial due to their higher degree of uncorrelatedness.", "labels": [], "entities": []}, {"text": "In any case, either of these implications necessitates knowledge of a typology of lexical semantics.", "labels": [], "entities": []}, {"text": "In order to address this question, we provide a translation-based model of lexical semantic spaces.", "labels": [], "entities": []}, {"text": "Our approach is to generate association networks in which the weight of a link between two words depends on their degree of partial synonymy.", "labels": [], "entities": []}, {"text": "To measure synonymy, we rely on translation data that is input to a statistical alignment toolkit.", "labels": [], "entities": [{"text": "statistical alignment", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.6687221825122833}]}, {"text": "We define the degree of synonymy of two words to be proportional to the number of common translations in a reference language, weighted by the probability of translation.", "labels": [], "entities": []}, {"text": "By pivoting on the reference language, we represent semantic associations among words in different languages by means of the synonymy relations of their translations in the same target language.", "labels": [], "entities": []}, {"text": "This approach ensures cross-language comparability of semantic spaces: Greek and Bulgarian are compared, for example, by means of the synonymy relations that are retained when translating them into the same pivot language (e.g., English).", "labels": [], "entities": []}, {"text": "This approach does not only address proximities of pairs of words shared among languages (e.g., and BEEF, MOUTH and DOOR, CHILD and FRUIT -cf.).", "labels": [], "entities": [{"text": "BEEF", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9971107244491577}, {"text": "MOUTH", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9145154356956482}, {"text": "DOOR", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.4774356186389923}, {"text": "FRUIT", "start_pos": 132, "end_pos": 137, "type": "METRIC", "confidence": 0.9459231495857239}]}, {"text": "By averaging over word pairs, it also allows for calculating semantic distances between pairs of languages.", "labels": [], "entities": []}, {"text": "The Sapir-Whorf Hypothesis (SWH)) already predicts that semantic relations are not universal.", "labels": [], "entities": []}, {"text": "Though we are agnostic about the assumptions underlying the SWH, it nevertheless gives an evaluation criterion for our experiment: if the SWH is true, we expect a clustering of translation-based semantic spaces along the genealogical relationships of the languages involved.", "labels": [], "entities": []}, {"text": "However, genealogy is certainly not the sole principle potentially underlying a typology of lexical semantics.", "labels": [], "entities": []}, {"text": "For example, finds that French is semantically closer to Basque, a putatively non-Indoeuropean language, than to German.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, a large-scale quantitative typological analysis of lexical semantics is lacking thus far and we intend to make first steps towards this target.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines related work.", "labels": [], "entities": []}, {"text": "Section 3 presents our formal model and Section 4 details our experiments on clustering semantic spaces across selected languages of the European Union.", "labels": [], "entities": [{"text": "clustering semantic spaces", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.85043865442276}]}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method by means of the Europarl corpus (.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9954367280006409}]}, {"text": "Europarl documents the proceedings of the European parliament in the 21 official languages of the European Union.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9417223930358887}]}, {"text": "This provides us with sentence-aligned multi-texts in which each tuple of sentences expresses the same underlying meaning.", "labels": [], "entities": []}, {"text": "Using GIZA++, this allows us to estimate the conditional translation probabilities P [A|B] for any two words A, B from any two languages in the Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 144, "end_pos": 159, "type": "DATASET", "confidence": 0.9926213026046753}]}, {"text": "In our experiment, we focus on the approx. 400,000 sentences for which translations in all 21 languages are available.", "labels": [], "entities": []}, {"text": "To process this data, we set all words of all sentences to lower-case.", "labels": [], "entities": []}, {"text": "Ideally, we would have lemmatized all texts, but did not do so because of the unavailability of lemmatizers for some of the languages.", "labels": [], "entities": []}, {"text": "Therefore, we decided to lemmatize only words in the reference language and kept full-forms for all source languages.", "labels": [], "entities": []}, {"text": "We choose Ina tuple of sentences, one sentence is the source of which all the other sentences are translations.", "labels": [], "entities": []}, {"text": "Lemmatization tools and models are taken from the TreeTagger ( homepage www.cis.", "labels": [], "entities": []}, {"text": "uni-muenchen.de/ \u02dc schmid/tools/TreeTagger English as the reference language.", "labels": [], "entities": []}, {"text": "In all languages, we omitted all words whose corpus frequency is less than 50 and excluded the 100 most frequent (mostly function) words.", "labels": [], "entities": []}, {"text": "In the reference language, we also ignored all words whose characters do not belong to the standard English character set.", "labels": [], "entities": []}, {"text": "shows subgraphs centered around the seed word WOMAN in five network versions of English.", "labels": [], "entities": []}, {"text": "All subgraphs are constructed using the Europarl data.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 40, "end_pos": 53, "type": "DATASET", "confidence": 0.9954015612602234}]}, {"text": "Apparently, the network versions of English diverge from each other.", "labels": [], "entities": []}, {"text": "For instance, the semantic association between WOMAN and WIFE appears to be strongest in the French and in the Spanish version of English, while in the Finnish version there does not even exist a link between these nodes.", "labels": [], "entities": []}, {"text": "In contrast, the weight of the link between WOMAN and LESBIAN is highest in the Czech version of English, while that between WOMAN and GIRL is strongest in the Finnish version.", "labels": [], "entities": [{"text": "weight", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9565276503562927}, {"text": "LESBIAN", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.8133185505867004}]}, {"text": "All in all, the wiring and the thickness of links clearly differ across language networks, indicating that the languages differ in terms of semantic relations of their translations.", "labels": [], "entities": []}, {"text": "shows network statistics of the graphs Gk . All network versions of English consist of exactly 5,021 English (lemmatized) words.", "labels": [], "entities": []}, {"text": "The networks show a high cluster value, indicating that neighbors of a word are probably interlinked (i.e., semantically related) (cf.).", "labels": [], "entities": []}, {"text": "Average path lengths and diameters are low, that is, distances between words are short, as is typically observed for semantic networks (cf.).", "labels": [], "entities": []}, {"text": "The density of the networks (measured by the ratio of existing links and the upper bound of theoretically possible links) varies substantially for the language networks.", "labels": [], "entities": []}, {"text": "For instance, in the Hungarian network version of English, only 2.56% of the possible links are realized, while in the Dutch version, 8.45% are present.", "labels": [], "entities": []}, {"text": "This observation may hint at the 'degree of analyticity' of a language: the more word forms per lemma there are in a language, the less likely they are linked by means of Eq.", "labels": [], "entities": []}, {"text": "Due to the limited availability of lemmatizers, not all languages could have served as a reference language.", "labels": [], "entities": []}, {"text": "Although we posit that the choice of reference language has no (or minimal) impact upon the resulting language classification as outlined below, this would need to be experimentally verified in follow-up work.", "labels": [], "entities": []}, {"text": "The threshold of 50 serves to reduce computational effort.", "labels": [], "entities": []}, {"text": "Note that since the density of a network may have substantial impact on random surfer processes as applied by us, and since analyticity is a morphological rather than a semantic phenomenon, it maybe possible that the classification results reported below are in fact due to syntagmatic relations -in contrast to our hypothesis about their semantic, paradigmatic nature.", "labels": [], "entities": []}, {"text": "We address this issue below.", "labels": [], "entities": []}, {"text": "Semantic similarity Before proceeding to our main task, the clustering of semantic spaces, we measure how strongly our semantic association networks capture semantics.", "labels": [], "entities": []}, {"text": "To this end, we compute the correlation coefficient between the semantic similarity scores of the word pairs in the WordSimilarity-353 () English word relatedness dataset and the similarity scores, for the same word pairs, obtained by our method.", "labels": [], "entities": [{"text": "WordSimilarity-353 () English word relatedness dataset", "start_pos": 116, "end_pos": 170, "type": "DATASET", "confidence": 0.8475759426752726}]}, {"text": "The WordSimilarity-353 dataset consists of 353 word pairs annotated by the average of 13 human experts, each on a scale from 0 (unrelated) to 10 (very closely related or identical).", "labels": [], "entities": [{"text": "WordSimilarity-353 dataset", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.9671762585639954}]}, {"text": "We evaluated only on those word pairs for which each word in the pair is contained in our set of 5,021 English words, which amounted to 172 word pairs.", "labels": [], "entities": []}, {"text": "To be more precise on the computation of semantic relatedness, for each word pair (u, v) in the WordSimilarity-353 dataset, we computed the semantic similarity of the word pair in the language L k version of English by considering the cosine similarity of u k and v k , that is, by means of the semantic meanings of u and v generated by the random surfer process on network Gk . Doing so for each language L k gives 20 different correlation coefficients, one for each network version of English, shown in: Sample Pearson correlation coefficients between human gold standard and our approach for different network versions of English.", "labels": [], "entities": [{"text": "WordSimilarity-353 dataset", "start_pos": 96, "end_pos": 122, "type": "DATASET", "confidence": 0.9904128909111023}, {"text": "Sample Pearson correlation", "start_pos": 506, "end_pos": 532, "type": "METRIC", "confidence": 0.6801696618398031}]}, {"text": "We first note that the correlation coefficients differ between network versions of English, where the Italian version exhibits the highest correlation with the (English) human reference, and the Lithuanian version the lowest.", "labels": [], "entities": [{"text": "correlation", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.9653605818748474}]}, {"text": "Note that Hassan and Mihalcea (2009) obtain a correlation coefficient of 0.55 on the whole WordSimilarity-353 dataset, which is considerably higher than our best score of 0.34.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 46, "end_pos": 69, "type": "METRIC", "confidence": 0.9718997180461884}, {"text": "WordSimilarity-353 dataset", "start_pos": 91, "end_pos": 117, "type": "DATASET", "confidence": 0.9805774986743927}]}, {"text": "However, first note that our networks, which consist of 5,021 lexical units, are quite small compared to the data sizes that other studies rely on, which makes a comparison highly unfair.", "labels": [], "entities": []}, {"text": "Secondly, one has to see that we compute the semantic relatedness of English words from the semantic point of view of two languages: the reference language and the respective source language (e.g., the Italian version of English), which, by our very postulate, differs from the semantics of the reference language.", "labels": [], "entities": []}, {"text": "According to, the semantics of English is apparently better represented by the semantics of Italian, Portuguese, Spanish, Romanian, and Dutch, than, e.g., by the one of Bulgarian, Hungarian, Estonian, and Lithuanian -at least subject to the translations provided by the Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 270, "end_pos": 285, "type": "DATASET", "confidence": 0.9866810441017151}]}, {"text": "Clustering of semantic spaces Finally, we cluster semantic spaces by comparing the network versions of the English reference language.", "labels": [], "entities": []}, {"text": "To determine the semantic distance between two languages L k and L j , we plugin each pair of languages in Eq.", "labels": [], "entities": []}, {"text": "(3) -with S(v k , v j ) as vector distance -thus obtaining asymmetric 20 \u00d7 20 distance matrix. and 5 show the results when feeding this distance matrix as input to k-means clustering (a centroid based clustering approach) and to hierarchical clustering using default parameters.", "labels": [], "entities": []}, {"text": "As can be seen, both clustering methods arrange the languages on the basis of their semantic spaces along genealogical relationships.", "labels": [], "entities": []}, {"text": "For instance, both clustering algorithms group Danish, Swedish, Dutch and German (Germanic), Portuguese, Spanish, French, Italian, Romanian (Romance), Bulgarian, Czech, Polish, Slovak, Slovene (Slavic), Finnish, Hungarian, Estonian (Finno-Ugric), and Latvian, Lithuanian (Baltic).", "labels": [], "entities": []}, {"text": "Greek, which is genealogically isolated in our selection of languages, is in our classification associated with the Romance languages, but constitutes an outlier in this group.", "labels": [], "entities": []}, {"text": "All in all, the clustering appears highly non-random and almost a To address the question of whether morphological principles are the driving force behind the clustering of the semantic spaces generated here, we lemmatized the reference language English and all source languages L k for which lemmatizers were freely available in order to conduct the same classification procedure.", "labels": [], "entities": []}, {"text": "This included 10 languages: Bulgarian, Dutch, Estonian, Finnish, French, German, Italian, Polish, Slovak, and Spanish.", "labels": [], "entities": []}, {"text": "This procedure leads to an assimilation of density values in the graphs Gk as shown in: for the 10 languages, the relative standard deviation in network density decreases by about 23%.", "labels": [], "entities": []}, {"text": "However, the optimal groupings of the languages do not change in that k-means clustering determines the five groups Spanish, French, Italian; Bulgarian, Slovak, Polish; German, Dutch; Finnish; Estonian, irrespective of whether the named ten languages are lemmatized or not.", "labels": [], "entities": []}, {"text": "Integrated networks Lastly, we address the derivative question raised in the introduction, viz., whether the integration of heterogeneous/dissimilar multilingual resources maybe harmful or beneficial.", "labels": [], "entities": []}, {"text": "To this end, we consider integrated networks G in which the weight of a link (\u03b1, \u03b2) \u2208 E (S) is given as the average (arithmetic mean) link weight of all link weights in the networks fora selection of languages S.", "labels": [], "entities": []}, {"text": "Using our optimal number of k = 5 clusters (and the clusters themselves) derived above, we thus let S range over the union of all the languages in the 2 k \u22121 possible subsets of clusters.", "labels": [], "entities": []}, {"text": "For each so resulting network G (S) , we determine semantic similarity between any pair of words exactly as above and then compute correlation with the WordSimilarity-353 dataset.", "labels": [], "entities": [{"text": "WordSimilarity-353 dataset", "start_pos": 152, "end_pos": 178, "type": "DATASET", "confidence": 0.9841628074645996}]}, {"text": "The numbers appear to support the hypothesis that, in the given monolingual semantic similarity task for English, integrating semantically similar languages (and, putatively, languages whose semantic similarity to English itself is closer) leads to better results than integrating heterogeneous languages.", "labels": [], "entities": []}, {"text": "For example, the average network consisting of the Romance languages has a roughly 2% higher correlation than the network consisting of all languages.", "labels": [], "entities": [{"text": "correlation", "start_pos": 93, "end_pos": 104, "type": "METRIC", "confidence": 0.9608016014099121}]}, {"text": "Interestingly, however, the very best combination result is achieved when we integrate the Romance, Germanic and the three non-Indoeuropean languages Finnish, Hungarian and Estonian.: Sample Pearson correlation coefficients between human gold standard and our approach for different integrated network versions.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 191, "end_pos": 210, "type": "METRIC", "confidence": 0.7993826568126678}]}, {"text": "Language cluster abbreviations: Romance (it, fr, pt, es, ro, el), Germanic (sv, nl, de, da), Slavic (bg, cz, pl, sk, sl), Baltic (lv, lt), Finno-Ugric (fi, hu, et).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of nodes, cluster value (CV), geodesic", "labels": [], "entities": [{"text": "cluster value (CV)", "start_pos": 27, "end_pos": 45, "type": "METRIC", "confidence": 0.8020872950553894}]}, {"text": " Table 1: for the 10 languages, the relative  standard deviation in network density decreases by  about 23%. However, the optimal groupings of the  languages do not change in that k-means clustering  determines the five groups Spanish, French, Italian;  Bulgarian, Slovak, Polish; German, Dutch; Finnish;  Estonian, irrespective of whether the named ten lan- guages are lemmatized or not. 11  Integrated networks Lastly, we address the  derivative question raised in the introduction, viz., whether the integration of heterogeneous/dissimilar  multilingual resources may be harmful or beneficial.  To this end, we consider integrated networks G", "labels": [], "entities": []}, {"text": " Table 3. The numbers  appear to support the hypothesis that, in the given  monolingual semantic similarity task for English,  integrating semantically similar languages (and, pu- tatively, languages whose semantic similarity to En- glish itself is closer) leads to better results than in- tegrating heterogeneous languages. For example,  the average network consisting of the Romance lan- guages has a roughly 2% higher correlation than  the network consisting of all languages. Interest- ingly, however, the very best combination result is  achieved when we integrate the Romance, Germanic  and the three non-Indoeuropean languages Finnish,  Hungarian and Estonian.", "labels": [], "entities": []}, {"text": " Table 3: Sample Pearson correlation coefficients be- tween human gold standard and our approach for  different integrated network versions. Language  cluster abbreviations: Romance (it, fr, pt, es, ro, el),  Germanic (sv, nl, de, da), Slavic (bg, cz, pl, sk, sl),  Baltic (lv, lt), Finno-Ugric (fi, hu, et).", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 17, "end_pos": 36, "type": "METRIC", "confidence": 0.7852049767971039}]}]}