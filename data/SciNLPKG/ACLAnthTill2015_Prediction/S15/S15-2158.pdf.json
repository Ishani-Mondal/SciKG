{"title": [{"text": "TALN-UPF: Taxonomy Learning Exploiting CRF-Based Hypernym Extraction on Encyclopedic Definitions", "labels": [], "entities": [{"text": "Taxonomy Learning Exploiting CRF-Based Hypernym Extraction on Encyclopedic Definitions", "start_pos": 10, "end_pos": 96, "type": "TASK", "confidence": 0.7616162565019395}]}], "abstractContent": [{"text": "This paper describes the system submitted by the TALN-UPF team to SEMEVAL Task 17 (Taxonomy Extraction Evaluation).", "labels": [], "entities": [{"text": "SEMEVAL Task 17", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.5265238483746847}, {"text": "Taxonomy Extraction Evaluation)", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.8265264853835106}]}, {"text": "We present a method for automatically learning a taxonomy from a flat terminology, which benefits from a definition corpus obtained by querying the BabelNet semantic network.", "labels": [], "entities": []}, {"text": "Then, we combine a machine-learning algorithm for term-hypernym extraction with linguistically-motivated heuristics for hyper-nym decomposition.", "labels": [], "entities": [{"text": "term-hypernym extraction", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.7147504538297653}, {"text": "hyper-nym decomposition", "start_pos": 120, "end_pos": 143, "type": "TASK", "confidence": 0.7162445336580276}]}, {"text": "Our approach performs well in terms of vertex coverage and newly added vertices, while it shows room for improvement in terms of graph topology, edge coverage and precision of novel edges.", "labels": [], "entities": [{"text": "precision", "start_pos": 163, "end_pos": 172, "type": "METRIC", "confidence": 0.9973281621932983}]}], "introductionContent": [{"text": "Learning semantic relations out of flat terminologies is an appealing task due to its potential application in tasks like Question Answering (), automatic glossary construction (), Ontology Learning (Navigli et al., 2011) or Textual Entailment ().", "labels": [], "entities": [{"text": "Learning semantic relations out of flat terminologies", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.7860355802944728}, {"text": "Question Answering", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.8367668986320496}, {"text": "automatic glossary construction", "start_pos": 145, "end_pos": 176, "type": "TASK", "confidence": 0.6082814633846283}, {"text": "Textual Entailment", "start_pos": 225, "end_pos": 243, "type": "TASK", "confidence": 0.728620320558548}]}, {"text": "Today, in the context of massive webenabled data, hypernym (is-a) relations are the focus of much research, as they constitute the backbone of ontologies).", "labels": [], "entities": []}, {"text": "However, one challenge remains open in the automatic construction of knowledge bases that exploit this type of relation.", "labels": [], "entities": []}, {"text": "It is unfeasible to have up-to-date semantic resources for each domain, as they are limited in scope and domain, and their manual construction is knowledge intensive and time consuming).", "labels": [], "entities": []}, {"text": "Given this rationale, Task 17 () in the SEMEVAL 2015 set of shared tasks focuses on Taxonomy Extraction Evaluation, i.e. the construction of a taxonomy out of a flat set of terms belonging to one of the four domains of choice (food, chemical, equipment and science).", "labels": [], "entities": [{"text": "SEMEVAL 2015 set", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.6761372288068136}, {"text": "Taxonomy Extraction Evaluation", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.871150016784668}]}, {"text": "These terms have to be hierarchically organized, and new terms are allowed to be included in the taxonomy.", "labels": [], "entities": []}, {"text": "As for evaluation, for each domain, two taxonomies were used as gold standard: One created by domain experts; and one derived from the WordNet taxonomy rooted at the domain node, e.g. food . Finally, evaluation is carried out from two standpoints: (1) The taxonomy topology and the rate of replicated nodes and edges are taken into account when compared to a gold standard taxonomy; and (2) Human experts validated as corrector incorrect a subset of the newly added edges.", "labels": [], "entities": [{"text": "WordNet taxonomy", "start_pos": 135, "end_pos": 151, "type": "DATASET", "confidence": 0.9579395651817322}]}, {"text": "In this paper we describe our contribution to this shared task.", "labels": [], "entities": []}, {"text": "Our approach relies on a set of definitional sentences for each term, from which term\u2192hypernym relations are extracted using a machine-learning classifier.", "labels": [], "entities": []}, {"text": "Ina second step, linguistically-motivated rules are applied in order to (1) extract a hypernym candidate when the confidence of the classifier was below a threshold, and (2) decompose multiword hypernyms in more general concepts (e.g. from coca-cola\u2192carbonated soft drink to carbonated soft drink\u2192soft drink and soft drink\u2192drink).", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows: Section 3 describes the modules of our approach, Section 4 presents and discusses the evaluation procedure as well as results, and finally Section 5 analyzes the performance of our system as well as the difficulties encountered, and suggests potential avenues for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation is carried out considering the structural properties of the taxonomy, as well as its quality when compared to gold-standard (see).", "labels": [], "entities": []}, {"text": "These gold taxonomies can be either the subgraphs rooted atone relevant WordNet term (chemical, food, equipment or science), or taxonomies manually crafted by domain experts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.9283428192138672}]}, {"text": "These results suggest that the approach described in this paper can be safely followed to construct a taxonomy from a flat terminology as input, provided major issues like domain-specificity or WSD are addressed.", "labels": [], "entities": [{"text": "WSD", "start_pos": 194, "end_pos": 197, "type": "TASK", "confidence": 0.5449092984199524}]}, {"text": "Our approach strongly depends of available definitions of terms in Wikipedia, which was not the casein very specific domains (such as the chemical terminology).", "labels": [], "entities": []}, {"text": "On the other hand, however, the hypernym extraction pass worked well and thus we are encouraged to work in this direction, stressing the importance of an appropriate domain dataset from which definitional knowledge can be extracted.", "labels": [], "entities": [{"text": "hypernym extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.678400382399559}]}, {"text": "In order to compare the system and reference taxonomies, the evaluation consists in computing node and edge coverage by taking into account the number of nodes and edges in common and the sizes of the taxonomies.", "labels": [], "entities": []}, {"text": "In addition, the results of a structural metric are also provided, such metric being the Fowlkes&Mallows measure, a method for comparing hierarchical clusters.", "labels": [], "entities": [{"text": "Fowlkes&Mallows measure", "start_pos": 89, "end_pos": 112, "type": "DATASET", "confidence": 0.6426418647170067}]}, {"text": "The results show poor performance of our system in inferring relations among concepts at deeper levels in the taxonomy.", "labels": [], "entities": []}, {"text": "One of the reasons this might be due to is the fact that the lexicalization of a term does not necessarily have to be exact between a BabelNet synset and an associated Wikipedia definition.", "labels": [], "entities": []}, {"text": "Regarding the manual evaluation of the quality of newly acquired edges, our system is unsurprisingly weak (P=10.2%) 5 due to the inherent term ambiguity which makes our system retrieve noisy definitions at each step.", "labels": [], "entities": []}, {"text": "We hypothesize that our results might be higher in the chemical domain, since terminology would be less prone to be polysemous.", "labels": [], "entities": []}, {"text": "However, this domain was not considered for this evaluation measure.", "labels": [], "entities": []}, {"text": "These negative results together with the good performance of the hypernym-extraction module stress the need to retrieve valid domain specific definitional sentences for our approach to work well.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of the results obtained with our approach in the structural evaluation in terms of vertex coverage  (VC), edge coverage (EC), ratio of novel edges (RNE), cumulative Fowlkes and Mallows Measure (F&M), whether  the taxonomy contains cycles (Cycles), and Precision, Recall and F-Score against gold standard taxonomies.", "labels": [], "entities": [{"text": "vertex coverage  (VC)", "start_pos": 101, "end_pos": 122, "type": "METRIC", "confidence": 0.7789302825927734}, {"text": "edge coverage (EC)", "start_pos": 124, "end_pos": 142, "type": "METRIC", "confidence": 0.9317361831665039}, {"text": "ratio of novel edges (RNE)", "start_pos": 144, "end_pos": 170, "type": "METRIC", "confidence": 0.7467119140284402}, {"text": "cumulative Fowlkes and Mallows Measure (F&M)", "start_pos": 172, "end_pos": 216, "type": "METRIC", "confidence": 0.8601133346557617}, {"text": "Precision", "start_pos": 270, "end_pos": 279, "type": "METRIC", "confidence": 0.9978094696998596}, {"text": "Recall", "start_pos": 281, "end_pos": 287, "type": "METRIC", "confidence": 0.9736554026603699}, {"text": "F-Score", "start_pos": 292, "end_pos": 299, "type": "METRIC", "confidence": 0.9936747550964355}]}]}