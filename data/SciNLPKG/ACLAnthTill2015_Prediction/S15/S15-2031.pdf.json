{"title": [{"text": "Samsung: Align-and-Differentiate Approach to Semantic Textual Similarity", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.5928122500578562}]}], "abstractContent": [{"text": "This paper describes our Align-and-Differentiate approach to the SemEval 2015 Task 2 competition for English Semantic Textual Similarity (STS) systems.", "labels": [], "entities": [{"text": "SemEval 2015 Task 2 competition", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.9092749238014222}, {"text": "English Semantic Textual Similarity (STS)", "start_pos": 101, "end_pos": 142, "type": "TASK", "confidence": 0.6562960275581905}]}, {"text": "Our submission achieved the top place on two of the five evaluation datasets.", "labels": [], "entities": []}, {"text": "Our team placed 3rd among 28 participating teams, and our three runs ranked 4th, 6th and 7th among the 73 runs submitted by the 28 teams.", "labels": [], "entities": []}, {"text": "Our approach improves upon the UMBC PairingWords system by semantically differentiating distributionally similar terms.", "labels": [], "entities": []}, {"text": "This novel addition improves results by 2.5 points on the Pearson correlation measure.", "labels": [], "entities": [{"text": "Pearson correlation measure", "start_pos": 58, "end_pos": 85, "type": "METRIC", "confidence": 0.8679014841715494}]}], "introductionContent": [{"text": "Since its inception in 2012, the annual Semantic Textual Similarity (STS) task has attracted and increasing amount of interest in the NLP community.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 40, "end_pos": 78, "type": "TASK", "confidence": 0.8151636804853167}]}, {"text": "The task is to measure the semantic similarity between two sentences using a scale ranging from 0 to.", "labels": [], "entities": []}, {"text": "In this task, 0 means unrelated and 5 means complete semantic equivalence.", "labels": [], "entities": []}, {"text": "For example, the sentence \"China's new PM rejects US hacking claims\" is semantically equivalent to the sentence \"China Premier Li rejects 'groundless' US hacking accusations\" even though there are many word level differences between the two sentences.", "labels": [], "entities": []}, {"text": "Improvements in the STS task can advance or benefit many research areas, such as paraphrase recognition), automatic machine translation evaluation), ontology mapping and schema matching, Twitter search (), image retrieval by captions () and information retrieval in general.", "labels": [], "entities": [{"text": "STS task", "start_pos": 20, "end_pos": 28, "type": "TASK", "confidence": 0.88371741771698}, {"text": "paraphrase recognition", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.8401983976364136}, {"text": "machine translation evaluation", "start_pos": 116, "end_pos": 146, "type": "TASK", "confidence": 0.7783477604389191}, {"text": "ontology mapping and schema matching", "start_pos": 149, "end_pos": 185, "type": "TASK", "confidence": 0.8025528192520142}, {"text": "image retrieval by captions", "start_pos": 206, "end_pos": 233, "type": "TASK", "confidence": 0.8315987139940262}, {"text": "information retrieval", "start_pos": 241, "end_pos": 262, "type": "TASK", "confidence": 0.8691883683204651}]}, {"text": "Measuring semantic similarity is difficult because it is relatively easy to express the same idea in very different ways.", "labels": [], "entities": []}, {"text": "Both word choice and word order can have a great impact on the semantics of a sentence, or not at all.", "labels": [], "entities": [{"text": "word choice", "start_pos": 5, "end_pos": 16, "type": "TASK", "confidence": 0.751840740442276}, {"text": "word order", "start_pos": 21, "end_pos": 31, "type": "TASK", "confidence": 0.6843055337667465}]}, {"text": "For example, the sentences \"A woman is playing piano on the street\" and \"A lady is playing violin on the street\" have a semantic similarity score of only 2, because pianos are not violins so the two events in the sentences must be different.", "labels": [], "entities": [{"text": "semantic similarity score", "start_pos": 120, "end_pos": 145, "type": "METRIC", "confidence": 0.6861570477485657}]}, {"text": "This is problematic because common solutions, such as bag-of-words representations, parse trees, and word alignments measure word choice and word order.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 101, "end_pos": 116, "type": "TASK", "confidence": 0.7109001725912094}]}, {"text": "We improve upon existing word choice approaches with better measures to semantically differentiate distributionally similar terms, and by using these measures to also improve the word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 179, "end_pos": 193, "type": "TASK", "confidence": 0.7095166444778442}]}, {"text": "Our solution is an Align-and-Differentiate approach, in which we greedily align words between sentences, before penalizing non-matching words in the differentiate-phase.", "labels": [], "entities": []}, {"text": "Our system improves upon the successful UMBC PairingWords system by about 2 points of Pearson's Correlation measure.", "labels": [], "entities": [{"text": "UMBC", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.8210743069648743}, {"text": "Pearson's Correlation measure", "start_pos": 86, "end_pos": 115, "type": "METRIC", "confidence": 0.5940828919410706}]}, {"text": "The success of the PairingWords system is largely due to their high-quality distributional word similarity model 1 described in ().", "labels": [], "entities": []}, {"text": "The distributional similarity model can tell that \"woman\" and \"lady\" in the above example are highly similar, which is usually correct, but it also says that \"pi-ano\" and \"violin\" are very similar, which in many contexts is incorrect.", "labels": [], "entities": []}, {"text": "While distributional similarity measures can be criticized for producing high similarity scores for antonyms and contrasting words, we find that this property is actually advantageous when performing word alignment between two sentences.", "labels": [], "entities": [{"text": "word alignment between two sentences", "start_pos": 200, "end_pos": 236, "type": "TASK", "confidence": 0.8219348847866058}]}, {"text": "We take advantage of this property by first aligning with distributional similarity, and then differentiate by penalizing alignments of words that are semantically disjoint.", "labels": [], "entities": []}, {"text": "This technique to first align and then differentiate is our key improvement.", "labels": [], "entities": []}, {"text": "The remainder of the paper proceeds as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly revisits the UMBC PairingWords system.", "labels": [], "entities": [{"text": "UMBC PairingWords system", "start_pos": 31, "end_pos": 55, "type": "DATASET", "confidence": 0.8904586434364319}]}, {"text": "Section 3 presents our new Align-andDifferentiate approach.", "labels": [], "entities": []}, {"text": "Section 4 presents and discusses our results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Pearson correlation and STS 2015 Competition  Rank of our three runs on test sets.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7271278202533722}, {"text": "STS 2015 Competition  Rank", "start_pos": 34, "end_pos": 60, "type": "METRIC", "confidence": 0.7917712777853012}]}, {"text": " Table 2: Our approach improves results by 2.5% in Pear- son's correlation.", "labels": [], "entities": [{"text": "Pear- son's correlation", "start_pos": 51, "end_pos": 74, "type": "METRIC", "confidence": 0.6097836792469025}]}]}