{"title": [{"text": "IOA: Improving SVM Based Sentiment Classification Through Post Processing", "labels": [], "entities": [{"text": "IOA", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7706427574157715}, {"text": "SVM Based Sentiment Classification", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.8406057357788086}]}], "abstractContent": [{"text": "This paper describes our systems for expression-level and message-level sentiment analysis-two subtasks of SemEval-2015 Task 10 on sentiment analysis in Twitter.", "labels": [], "entities": [{"text": "message-level sentiment analysis-two", "start_pos": 58, "end_pos": 94, "type": "TASK", "confidence": 0.7111397981643677}, {"text": "SemEval-2015 Task 10 on sentiment analysis", "start_pos": 107, "end_pos": 149, "type": "TASK", "confidence": 0.7358095099528631}]}, {"text": "First we built two baseline systems for the two sub-tasks using SVM with a variety of features.", "labels": [], "entities": []}, {"text": "Then we improved the systems through model iteration and probability-output weighting respectively.", "labels": [], "entities": []}, {"text": "Our submissions are ranked the 3rd and 2nd among eleven teams on the 2015 test set and progress test set in subtask A and the 7th and 4th among 40 teams on the two test sets respectively in subtask B.", "labels": [], "entities": [{"text": "2015 test set", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.856690506140391}]}], "introductionContent": [{"text": "Recently sentiment analysis has become one of the most popular research topics in the natural language processing community, mainly due to the exponential growth of social media data replete with subjective information.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.9548154473304749}, {"text": "natural language processing", "start_pos": 86, "end_pos": 113, "type": "TASK", "confidence": 0.6473465363184611}]}, {"text": "The once neglected topic has spurred immense interests from both academia and industry.", "labels": [], "entities": []}, {"text": "Many approaches have been proposed for sentiment analysis in customer reviews, blogs and microblogs (for good reviews, see).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.9636784195899963}]}, {"text": "These approaches can be roughly divided into two categories.", "labels": [], "entities": []}, {"text": "One is knowledge intensive or rule-based approaches, e.g.,.", "labels": [], "entities": []}, {"text": "Such approaches can achieve reasonably good results when tailored fora specific domain but their maintainability and cross domain portability is usually weak.", "labels": [], "entities": []}, {"text": "The other is data intensive or machine learning-based, which learns to analyse sentiment from data.", "labels": [], "entities": []}, {"text": "It is currently the most predominant approach, including supervised learning, deep learning etc.", "labels": [], "entities": []}, {"text": "Sentiment analysis is often taken as a classification task.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9679407179355621}]}, {"text": "Widely used classifiers include Support Vector Machines (SVM), Maximum Entropy Models (MaxEnt), and naive Bayes classifiers.", "labels": [], "entities": []}, {"text": "Common features include word/character n-grams and sentiment lexicons, among others.", "labels": [], "entities": []}, {"text": "Key research issues for learning approaches include feature engineering, model selection, ensemble learning, etc.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8240469694137573}, {"text": "model selection", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.7626109421253204}]}, {"text": "SemEval 2015 task10 () is a sequel to the two tasks on sentiment analysis in Twitter in the past two years ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.9001111686229706}]}, {"text": "They have provided freely available, annotated corpus as a common testbed and significantly promoted sentiment analysis in tweetlike short and informal texts.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.9504954218864441}]}, {"text": "The same metric, i.e., the average F 1 score of positive and negative classes, is used for measuring performances.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9823382695515951}]}, {"text": "But this year there are some changes.", "labels": [], "entities": []}, {"text": "Besides the classical expression-level (A) and message-level (B) subtasks, another three subtasks are added, i.e., subtask C -topic-based message polarity classification, subtask D -detecting trends towards a topic, and subtask E -determining strength of association of twitter terms with positive sentiment.", "labels": [], "entities": [{"text": "topic-based message polarity classification", "start_pos": 126, "end_pos": 169, "type": "TASK", "confidence": 0.68875502794981}]}, {"text": "The organisers make no distinction between constrained and unconstrained systems, which means participants could utilise any other data.", "labels": [], "entities": []}, {"text": "But it has to be described in the submission form.", "labels": [], "entities": []}, {"text": "We submitted systems only for the expressionlevel and message-level subtasks.", "labels": [], "entities": []}, {"text": "In this paper, we provide some details behind the systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "The official evaluation metric of the task is the average F 1 score of the positive and the negative classes.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9889156023661295}]}, {"text": "After the base training (Section 2.4), we got the base results in, \"baseline\" columns.", "labels": [], "entities": []}, {"text": "Then we focused on improving systems for both subtasks.", "labels": [], "entities": []}, {"text": "And the improved (or not) results are shown in the \"submitted\" columns.", "labels": [], "entities": []}, {"text": "For subtask A, we made iteration stop at i = 2.", "labels": [], "entities": []}, {"text": "The reason why there is little improvement is: (1) After each iteration, the number of new data added to the training data for retraining anew model is rather small.", "labels": [], "entities": []}, {"text": "(2) Once the classifier puts a high confidence on a label, this instance is very likely to be similar to existing instances, which means the added instances would not contribute very much to classification.", "labels": [], "entities": []}, {"text": "In the experiments after submission, we tried to interchange the improvement method between the subtasks, but they showed a little decrease on both subtasks.", "labels": [], "entities": []}, {"text": "When the model iteration approach was used in subtask B, we did not receive expected improvement.", "labels": [], "entities": []}, {"text": "This maybe because that the performance for subtask B is lower than that for subtask A, which may result in the wrong samples added into the training data.", "labels": [], "entities": []}, {"text": "When the probability-output weighting approach was used on subtask A, we only got limited improvement in the F 1 score.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.9691480199495951}]}], "tableCaptions": [{"text": " Table 1: Statistics of all the datasets. The last row  of Progress2015-test data is composed of all the pre- vious test data sets.", "labels": [], "entities": [{"text": "Progress2015-test data", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.9747779071331024}]}, {"text": " Table 3: The parameters for different test data. I is the maximum number of iteration. w pos and w neg are  weight parameters.", "labels": [], "entities": []}, {"text": " Table 4: The overall results.", "labels": [], "entities": []}, {"text": " Table 5: The results for subtask A under different threshold p . Numbers in bold are the submitted results.", "labels": [], "entities": []}]}