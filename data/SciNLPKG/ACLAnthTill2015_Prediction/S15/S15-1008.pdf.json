{"title": [{"text": "Learning Structures of Negations from Flat Annotations", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel method to learn negation expressions in a specialized (medical) domain.", "labels": [], "entities": [{"text": "negation expressions", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.820024311542511}]}, {"text": "In our corpus, negations are annotated as 'flat' text spans.", "labels": [], "entities": []}, {"text": "This allows for some infelicities in the markup of the ground truth, making it less than perfectly aligned with the underlying syntactic structure.", "labels": [], "entities": []}, {"text": "Nonetheless, the negations thus captured are correct in intent, and thus potentially valuable.", "labels": [], "entities": []}, {"text": "We succeed in training a model for detecting the negated predicates corresponding to the annotated negations , by re-mapping the corpus to anchor its 'flat' annotation spans into the predicate argument structure.", "labels": [], "entities": []}, {"text": "Our key idea-re-mapping the negation instance spans to more uniform syntactic nodes-makes it possible to re-frame the learning task as a simpler one, and to leverage an imperfect resource in away which enables us to learn a high performance model.", "labels": [], "entities": []}, {"text": "We achieve high accuracy for negation detection overall, 87%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9996625185012817}, {"text": "negation detection", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9938496947288513}]}, {"text": "Our re-mapping scheme can be constructively applied to existing flatly annotated resources for other tasks where syntactic context is vital.", "labels": [], "entities": []}], "introductionContent": [{"text": "Accounting for extra-propositional aspects of meaning in text is a very active NLP research area in recent years, exploring different aspects of meaning such as factivity, uncertainty/hedging (, committed belief, and modalities ().", "labels": [], "entities": []}, {"text": "Among these, negation detection has generated special interest because of demonstrated needs for negation detection capability in practical applications such as information retrieval (), information extraction (, sentiment analysis, and relation detection.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9885920882225037}, {"text": "negation detection", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.9230795204639435}, {"text": "information retrieval", "start_pos": 161, "end_pos": 182, "type": "TASK", "confidence": 0.788603812456131}, {"text": "information extraction", "start_pos": 187, "end_pos": 209, "type": "TASK", "confidence": 0.8389739394187927}, {"text": "sentiment analysis", "start_pos": 213, "end_pos": 231, "type": "TASK", "confidence": 0.9360343217849731}, {"text": "relation detection", "start_pos": 237, "end_pos": 255, "type": "TASK", "confidence": 0.9664179086685181}]}, {"text": "Accurately detecting negations is especially important in systems processing medical/clinical text.", "labels": [], "entities": [{"text": "Accurately detecting negations", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6344420810540518}]}, {"text": "Consider the segment \"Mild hyperinflation without focal pneumonia\", taken from a patient's clinical record.", "labels": [], "entities": [{"text": "Mild hyperinflation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.8641742765903473}]}, {"text": "It indicates the absence of focal pneumonia in the patient.", "labels": [], "entities": [{"text": "focal pneumonia", "start_pos": 28, "end_pos": 43, "type": "METRIC", "confidence": 0.8212423324584961}]}, {"text": "Not capturing this extra-propositional aspect of negation concerning focal pneumonia will lead to wrong-and harmful-inferences in downstream processing, e.g. by a clinical decision support system.", "labels": [], "entities": [{"text": "negation concerning focal pneumonia", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.7609706819057465}]}, {"text": "The need for sophisticated negation detection capabilities in clinical text is even more urgent given the broadening spectrum of applications in this domain: clinical question answering (), clinical decision support, medical information extraction (, medical entity relation mining (, patient history tracking (), etc.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.9682714641094208}, {"text": "clinical question answering", "start_pos": 158, "end_pos": 185, "type": "TASK", "confidence": 0.5858237942059835}, {"text": "medical information extraction", "start_pos": 217, "end_pos": 247, "type": "TASK", "confidence": 0.6696295241514841}, {"text": "medical entity relation mining", "start_pos": 251, "end_pos": 281, "type": "TASK", "confidence": 0.590132586658001}, {"text": "patient history tracking", "start_pos": 285, "end_pos": 309, "type": "TASK", "confidence": 0.6307362020015717}]}, {"text": "Our motivation for detecting negations in medical texts also stems from practical concerns of an operational medical question answering (QA) system).", "labels": [], "entities": [{"text": "detecting negations in medical texts", "start_pos": 19, "end_pos": 55, "type": "TASK", "confidence": 0.8906679153442383}, {"text": "operational medical question answering (QA)", "start_pos": 97, "end_pos": 140, "type": "TASK", "confidence": 0.7943031787872314}]}, {"text": "Most recent approaches to negation detection adopt supervised machine learning techniques to learn the phraseology of negation-containing expressions.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9923849701881409}]}, {"text": "They often follow a two step processdetection of negation cues (\"no\", \"without\", . . .), followed by detection of their associated scopes.", "labels": [], "entities": []}, {"text": "Cue detection is a relatively simple task, since the set of cue words is not large.", "labels": [], "entities": [{"text": "Cue detection", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9400479197502136}]}, {"text": "Determining the scope of a negation cue, on the other hand, is more challenging.", "labels": [], "entities": [{"text": "negation cue", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.8828504085540771}]}, {"text": "Negation constructs do not necessarily apply to entire sentences: in the earlier example, Mild hyperinflation is not negated.", "labels": [], "entities": []}, {"text": "The scope detection task is to identify the part(s) of the sentence that come under the scope of a negation cue.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8363601267337799}]}, {"text": "Scope detection is crucial for interpreting negations, and to that end, the BioScope corpus () was released, with annotations of both negation cues and their associated scopes.", "labels": [], "entities": [{"text": "Scope detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9334474205970764}, {"text": "interpreting negations", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.888931006193161}, {"text": "BioScope corpus", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.9165670871734619}]}, {"text": "The fact that these scopes are represented only as text-spans is a drawback of BioScope.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.7343915700912476}]}, {"text": "Without being anchored to a syntactic analysis of the sentences in which they occur, BioScope's scope annotations suffer from a variety of inconsistencies of mark-up.", "labels": [], "entities": []}, {"text": "They also may, and occasionally do, fail to align with the underlying syntactic structures).", "labels": [], "entities": []}, {"text": "Such inconsistencies make it hard fora system to learn the actual syntactic patterns connecting negation cues and their scopes-which are, after all, the real object of negation interpretation.", "labels": [], "entities": [{"text": "negation interpretation", "start_pos": 168, "end_pos": 191, "type": "TASK", "confidence": 0.9175286293029785}]}, {"text": "The insight that we develop in this paper is that a scope span can be associated with one or more nodes in the syntactic analysis of a negated expression, and that these will be further connected-in a systematic way-to the negation cue node.", "labels": [], "entities": []}, {"text": "Mapping loosely and/or inconsistently bounded spans to unique syntactic nodes (and configurations thereof) reduces the noise inherent in BioScope.", "labels": [], "entities": []}, {"text": "The learning task for scope detection would now be the easier one of learning negation scoping patterns from syntactic representations.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.9637088775634766}, {"text": "learning negation scoping patterns from syntactic representations", "start_pos": 69, "end_pos": 134, "type": "TASK", "confidence": 0.7536429251943316}]}, {"text": "To elaborate on this, we look at BioScope's issues in some detail (Section 3.1).", "labels": [], "entities": [{"text": "BioScope", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.8311562538146973}]}, {"text": "Our intent here, however, is not to offer a review or criticism of the corpus, nor to suggest how to correct those issues.", "labels": [], "entities": []}, {"text": "Given that we do want to use BioScope (we motivate our choice of BioScope separately in Section 2), we propose anew method for learning how to detect negated constructs which are rooted in syntactic structure elements, and therefore directly usable by downstream components, many of which typically assume awareness of syntax.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.8071503639221191}]}, {"text": "Our method is to re-map BioScope's scope span annotations onto the syntactic space and then to use those annotations' corresponding node structure(s) to train a system to automatically detect negated syntactic nodes.", "labels": [], "entities": []}, {"text": "As outlined earlier, due to the re-mapping, many syntactic inconsistencies would not be seen by the learner, which now is trained on cleaner data and consequently, faces a simpler learning problem.", "labels": [], "entities": []}, {"text": "We verify that our re-mapping process identifies the correct negated syntactic node with high accuracy (93%); this validates the approach we propose here.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9984203577041626}]}, {"text": "Our supervised learning system, trained using re-mapped scope nodes to detect them automatically, obtains an overall accuracy of 87%, using automatically tagged cues.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9995824694633484}]}, {"text": "In the light of state-ofthe-art performance figures, ours is a novel, constructive and pragmatic approach which allows us to leverage effectively an important resource, despite its representational imperfections, and to utilize the essential 'nuggets' it captures and exposes-namely the expressions of negated predicates.", "labels": [], "entities": []}, {"text": "This strategy can also be applied to other tasks where syntactic context is important but resources are annotated by text spans only (e.g. hedge detection).", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 139, "end_pos": 154, "type": "TASK", "confidence": 0.7882853150367737}]}, {"text": "The rest of the paper is grounded in discussion of related work, and of BioScope and its annotations (Section 2), highlighting some relevant details of the issues with these (Section 3).", "labels": [], "entities": [{"text": "BioScope", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.6518350839614868}]}, {"text": "We then outline the syntactic framework we use in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 presents our re-mapping of BioScope, and Section 6 offers experiments and results.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.7616516351699829}]}, {"text": "In Section 7, we compare our performance with previously published studies.", "labels": [], "entities": []}, {"text": "Section 8 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The most commonly used metric to evaluate negation scope span detection is Percentage of Correct Scopes (PCS).", "labels": [], "entities": [{"text": "negation scope span detection", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.9241989552974701}, {"text": "Percentage of Correct Scopes (PCS)", "start_pos": 75, "end_pos": 109, "type": "METRIC", "confidence": 0.9178752558571952}]}, {"text": "PCS measures the percentage of exact matches between predicted and actual scope spans.", "labels": [], "entities": []}, {"text": "Since our task is different-negated predicate detection as opposed to negated span detectionwe report the Percentage of Correct Scope Predicates (PCSP) obtained in our experiments.", "labels": [], "entities": [{"text": "predicate detection", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7472777366638184}, {"text": "negated span detectionwe", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.650621364514033}]}, {"text": "Models built from the composite training corpus comprising training corpora of all three genres (see Section 3) perform better than models built separately over each sub-corpus.", "labels": [], "entities": []}, {"text": "We report results separately for each sub-corpus, as well as for the entire corpus, and compare them with a strong baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of our CuePredicate detection on Dev and Test sets", "labels": [], "entities": [{"text": "CuePredicate detection", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.7545384466648102}]}, {"text": " Table 2: Percentage of Correct NegatedPredicate (PCSP) on Dev and Test sets", "labels": [], "entities": []}, {"text": " Table 3: PCS measures from previous BioScope span detection approaches and our end-to-end system.  Col. 1-3: end-to-end systems", "labels": [], "entities": [{"text": "BioScope span detection", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.6893997589747111}]}]}