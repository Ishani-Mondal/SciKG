{"title": [{"text": "Multi-Level Alignments As An Extensible Representation Basis for Textual Entailment Algorithms", "labels": [], "entities": [{"text": "Multi-Level Alignments", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7503971457481384}, {"text": "Textual Entailment Algorithms", "start_pos": 65, "end_pos": 94, "type": "TASK", "confidence": 0.7963219881057739}]}], "abstractContent": [], "introductionContent": [{"text": "A key challenge of Natural Language Processing is to determine what conclusions can be drawn from a natural language text, a task known as Textual Entailment (TE,.", "labels": [], "entities": []}, {"text": "The ability to recognize TE helps dealing with surface variability in tasks like Question Answering (), Intelligent Tutoring (), or Text Exploration (.", "labels": [], "entities": [{"text": "recognize TE", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.6333362460136414}, {"text": "Question Answering", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8187859654426575}, {"text": "Text Exploration", "start_pos": 132, "end_pos": 148, "type": "TASK", "confidence": 0.8480420708656311}]}, {"text": "Open source implementations a number of TE algorithms have become available over the last years, including BIUTEE ( and EDITS (, which has made it much easier for end users to utilize TE engines.", "labels": [], "entities": [{"text": "BIUTEE", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9827693700790405}]}, {"text": "At the same time, the situation is still more difficult for researchers and developers.", "labels": [], "entities": []}, {"text": "Even though recently a common platform for TE has been proposed) that standardizes important aspects like annotation types, preprocessing, and knowledge resources, it largely ignores the algorithmic level.", "labels": [], "entities": [{"text": "TE", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9644062519073486}]}, {"text": "In fact, TE algorithms themselves are generally not designed to be extensible or interoperable.", "labels": [], "entities": [{"text": "TE", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.973233163356781}]}, {"text": "Therefore, changes to the algorithms -like adding support fora new language or for new analysis aspect -are often very involved, if not impossible.", "labels": [], "entities": []}, {"text": "This often forces the next generation of TE researchers to develop and implement their own core algorithms from scratch.", "labels": [], "entities": [{"text": "TE", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.8755165934562683}]}, {"text": "In this paper, we address this problem by proposing a schema for TE algorithms that revolves around a central representation layer called multi-level alignment geared towards encoding the relevant information for deciding entailment.", "labels": [], "entities": [{"text": "TE algorithms", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.9091097712516785}]}, {"text": "The use of multi-level alignments encourages a modular, extensible development of TE algorithms that can be partitioned into \"alignment producers\" and \"alignment consumers\".", "labels": [], "entities": []}, {"text": "This enables for future researchers and developers to change analysis components or add new ones in a straightforward manner.", "labels": [], "entities": []}, {"text": "We also present evaluation results fora very simple TE algorithm based on multi-level alignments for English, German and Italian.", "labels": [], "entities": [{"text": "TE", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.5361151099205017}]}, {"text": "It utilizes a minimal set of analyzers and four basic language-independent features.", "labels": [], "entities": []}, {"text": "It can thus be regarded as a baseline of the performance achievable with this approach.", "labels": [], "entities": []}, {"text": "The results can already compete with the best open-source engines available for each of the languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "RTE-3 was the third instance of the yearly benchmarking workshops of the Textual Entailment community ().", "labels": [], "entities": [{"text": "RTE-3", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8744500279426575}]}, {"text": "The English dataset created for RTE-3 consists of 800 training and 800 testing T-H pairs.", "labels": [], "entities": [{"text": "RTE-3", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.6486148834228516}]}, {"text": "Later, the RTE-3 dataset was translated into both German and Italian ().", "labels": [], "entities": [{"text": "RTE-3 dataset", "start_pos": 11, "end_pos": 24, "type": "DATASET", "confidence": 0.9194041192531586}]}, {"text": "It is the only Textual Entailment dataset in multiple languages with the same content.", "labels": [], "entities": [{"text": "Textual Entailment dataset", "start_pos": 15, "end_pos": 41, "type": "DATASET", "confidence": 0.722466508547465}]}, {"text": "The task is binary TE recognition, with baseline of 50% accuracy (balanced classes).", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.8432824909687042}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9990972280502319}]}, {"text": "We trained and tested our Multi-Level Alignment approach (MultiAlign) on the RTE-3 dataset separately for each language.", "labels": [], "entities": [{"text": "RTE-3 dataset", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.9027592837810516}]}, {"text": "We compare against the other RTE systems from the platform by, namely BIUTEE (, EDITS (, and TIE (.", "labels": [], "entities": [{"text": "BIUTEE", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9917746186256409}, {"text": "EDITS", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.6974951028823853}, {"text": "TIE", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.8160868883132935}]}, {"text": "Each system is configured with its best known configurations.", "labels": [], "entities": []}, {"text": "The pilot system supports all three languages, while others support one (BIUTEE) or two languages (EDITS, TIE).", "labels": [], "entities": [{"text": "BIUTEE", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9949761629104614}, {"text": "TIE", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.7656468749046326}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The pilot system performs well in all three languages.", "labels": [], "entities": []}, {"text": "It ties with BIU-TEE on English and it outperforms TIE and EDITS in their respective results on German and Italian.", "labels": [], "entities": [{"text": "BIU-TEE", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9773396849632263}, {"text": "TIE", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8918552994728088}, {"text": "EDITS", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.8407558798789978}]}, {"text": "This is particularly notable since all three systems have gone through several years of development, while MultiAlign is only a pilot implementation.", "labels": [], "entities": []}, {"text": "We perform the second evaluation on real-world application data from two application datasets: an entailment graph dataset (for English and Italian), and an e-mail categorization dataset (for German).", "labels": [], "entities": []}, {"text": "Entailment graph building is the task of constructing graphs that hierarchically structure the statements from a collection for the application of Text Exploration.", "labels": [], "entities": [{"text": "Entailment graph building", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7971153259277344}, {"text": "Text Exploration", "start_pos": 147, "end_pos": 163, "type": "TASK", "confidence": 0.7448843121528625}]}, {"text": "In TE-based e-mail categorization, the goal is to assign the right category to an email with TE, using the email as T and a category description as H.", "labels": [], "entities": [{"text": "TE-based e-mail categorization", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.8243607481320699}]}, {"text": "(   respective first step, the binary decision of entailment for individual T-H pairs.", "labels": [], "entities": []}, {"text": "This task corresponds to RTE-3, and the main difference to Evaluation 1 is that these pairs come from real-world interactions and were produced by native speakers.", "labels": [], "entities": [{"text": "RTE-3", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.6271374225616455}]}, {"text": "All T-H pairs are sampled from application gold data which were manually constructed on the basis of anonymized customer interactions (  for German; for English and Italian 2 ).", "labels": [], "entities": []}, {"text": "The sets are fairly large (5300 pairs for English, 1700 for Italian, 1274 for German), and were sampled to be balanced.", "labels": [], "entities": []}, {"text": "We report F 1 for comparability with non-balanced setups (our random baseline is F 1 =50).", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9789921343326569}]}, {"text": "MultiAlign system beats EDITS for Italian (+4), and ties with TIE for German.", "labels": [], "entities": [{"text": "EDITS", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.923218309879303}, {"text": "TIE", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.7931951284408569}]}, {"text": "On English, BIUTEE still outperforms MultiAlign (-2).", "labels": [], "entities": [{"text": "BIUTEE", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9942160248756409}]}, {"text": "Thus, MultiAlign also performs acceptably on real-world data.", "labels": [], "entities": []}, {"text": "In sum, we find that MultiAlign is already competitive with state-of-the-art open-source TE engines on three languages.", "labels": [], "entities": []}, {"text": "MultiAlign is not only much less complex, but it is also a single system covering all three languages, without any language-specific optimizations.", "labels": [], "entities": []}, {"text": "We interpret this as a positive sign for the future of the Multi-Level Alignment approach.", "labels": [], "entities": [{"text": "Multi-Level Alignment", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7548862993717194}]}, {"text": "The platform also supports visualization of individual Text-Hypothesis pairs, showing the alignments that were created by the system as well as the features computed on the basis of the alignments.", "labels": [], "entities": []}, {"text": "The visualization was built on the basis of the BRAT library.", "labels": [], "entities": [{"text": "BRAT library", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.7263733744621277}]}, {"text": "3 shows an example for the Text The judges made an assessment of Peter's credibility and the Hypothesis The judges assessed if Peter was credible.", "labels": [], "entities": []}, {"text": "The top line shows the final prediction, Entailment, and the confidence (75%).", "labels": [], "entities": [{"text": "prediction", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.7218907475471497}, {"text": "Entailment", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9953023195266724}, {"text": "confidence", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9966772794723511}]}, {"text": "The main part shows the Text and the Hypothesis below each other, connected The three features currently used by the English system are are shown below.", "labels": [], "entities": []}, {"text": "As can be seen, they aggregate very simple statistics about the alignments: 5 of 7 tokens in the hypothesis are covered, 4 out of 5 content words, and the one proper name is also aligned.", "labels": [], "entities": []}, {"text": "This situation motivates nicely the use of those features: a relatively low alignment coverage on all tokens is still compatible with entailment as long as the crucial tokens are aligned.", "labels": [], "entities": []}, {"text": "This visualization enables end users to quickly take in the justification behind the system's decision.", "labels": [], "entities": []}, {"text": "Developers can inspect alignments and features for plausibility and detect possible bugs and assess the limitations of aligners and their underlying resources.", "labels": [], "entities": []}, {"text": "For example, the current example shows a wrong link produced by the VerbOcean resource between the noun judges in the Text and the verb assessed in the Hypothesis.", "labels": [], "entities": []}, {"text": "The reason is that the noun judges is mistaken for an inflected form of the verb to judge which indeed stands in a Stronger-than relationship to to assess.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy evaluation on the RTE3 dataset", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985713958740234}, {"text": "RTE3 dataset", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.9365414679050446}]}, {"text": " Table 1. The pilot system  performs well in all three languages. It ties with BIU- TEE on English and it outperforms TIE and EDITS in  their respective results on German and Italian. This  is particularly notable since all three systems have  gone through several years of development, while  MultiAlign is only a pilot implementation.", "labels": [], "entities": [{"text": "BIU- TEE", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9612173835436503}, {"text": "TIE", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.9537235498428345}]}, {"text": " Table 2: F 1 evaluation on application data", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9563886225223541}]}]}