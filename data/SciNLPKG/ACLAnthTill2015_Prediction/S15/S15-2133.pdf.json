{"title": [{"text": "SPINOZA VU: An NLP Pipeline for Cross Document TimeLines", "labels": [], "entities": [{"text": "VU", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.4977753162384033}, {"text": "Cross Document TimeLines", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.7332481543223063}]}], "abstractContent": [{"text": "This paper describes the system SPINOZA VU developed for the SemEval 2015 Task 4: Cross Document TimeLines.", "labels": [], "entities": [{"text": "SemEval 2015 Task 4: Cross Document TimeLines", "start_pos": 61, "end_pos": 106, "type": "TASK", "confidence": 0.7952091917395592}]}, {"text": "The system integrates output from the News-Reader Natural Language Processing pipeline and is designed following an entity based model.", "labels": [], "entities": []}, {"text": "The poor performance of the submitted runs are mainly a consequence of error propagation.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.6655981987714767}]}, {"text": "Nevertheless, the error analysis has shown that the interpretation module behind the system performs correctly.", "labels": [], "entities": []}, {"text": "An out of competition version of the system has fixed some errors and obtained competitive results.", "labels": [], "entities": []}, {"text": "Therefore, we consider the system an important step towards a more complex task such as storyline extraction.", "labels": [], "entities": [{"text": "storyline extraction", "start_pos": 88, "end_pos": 108, "type": "TASK", "confidence": 0.8952922224998474}]}], "introductionContent": [{"text": "This paper reports on a system (SPINOZA VU) for timeline extraction developed at the CLTL Lab of the VU Amsterdam in the context of the SemEval 2015 Task 4: Cross Document TimeLines.", "labels": [], "entities": [{"text": "timeline extraction", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.803333193063736}, {"text": "CLTL Lab of the VU Amsterdam", "start_pos": 85, "end_pos": 113, "type": "DATASET", "confidence": 0.8109530011812845}, {"text": "SemEval 2015 Task 4: Cross Document TimeLines", "start_pos": 136, "end_pos": 181, "type": "TASK", "confidence": 0.7557391040027142}]}, {"text": "In this task, a timeline is defined as a set of chronologically anchored and ordered events extracted from a corpus spanning over a (large) period of time with respect to a target entity.", "labels": [], "entities": []}, {"text": "Cross-document timeline extraction benefits from previous works and evaluation campaigns in Temporal Processing, such as the TempEval evaluation campaigns () and aims at promoting research in temporal processing by tackling the following issues: cross-document and cross-temporal event detection and ordering; event coreference (indocument and cross-document); and entity-based temporal processing.", "labels": [], "entities": [{"text": "Cross-document timeline extraction", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7910675009091696}, {"text": "Temporal Processing", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.862084299325943}, {"text": "cross-temporal event detection and ordering", "start_pos": 265, "end_pos": 308, "type": "TASK", "confidence": 0.7183736383914947}, {"text": "entity-based temporal processing", "start_pos": 365, "end_pos": 397, "type": "TASK", "confidence": 0.6036874254544576}]}, {"text": "The SPINOZA VU system is based on the NewsReader (NWR) NLP pipeline (, which has been developed within the context of the NWR project 1 and provides multi-layer annotations over raw texts from tokenization up to temporal relations.", "labels": [], "entities": [{"text": "NewsReader (NWR) NLP pipeline", "start_pos": 38, "end_pos": 67, "type": "DATASET", "confidence": 0.8879809478918711}]}, {"text": "The goal of the NWR project is to build structured event indexes from large volumes of news data addressing the same research issues as the task.", "labels": [], "entities": []}, {"text": "Within this framework, we are developing a storyline module which aims at providing more structured representation of events and their relations.", "labels": [], "entities": []}, {"text": "Timeline extraction from raw text qualifies as the first component of this new module.", "labels": [], "entities": [{"text": "Timeline extraction from raw text", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8289457082748413}]}, {"text": "This is why we participated in Track A and Subtrack A of the task, timeline extraction from raw text.", "labels": [], "entities": [{"text": "timeline extraction from raw text", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.809813129901886}]}, {"text": "Participating in Track B would require a full re-engineering of the NWR pipeline and of our system.", "labels": [], "entities": [{"text": "NWR pipeline", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.9640310406684875}]}, {"text": "The remainder of the paper is structured as follows: Section 2 provides an overview of the model implemented in the two versions of our system.", "labels": [], "entities": []}, {"text": "Section 3 presents the results and error analysis, and Section 4 puts forward some conclusions.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 35, "end_pos": 49, "type": "METRIC", "confidence": 0.9328802824020386}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: System Results (micro F1 score) for the Se- mEval 2015 Task 4 Task A -Main Track.", "labels": [], "entities": [{"text": "F1 score)", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9243840972582499}, {"text": "Se- mEval 2015 Task 4 Task A", "start_pos": 50, "end_pos": 78, "type": "DATASET", "confidence": 0.7834967374801636}]}, {"text": " Table 2: System Results (micro F1 score) for the Se- mEval 2015 Task 4 Task A -Subtrack.", "labels": [], "entities": [{"text": "F1 score)", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9174034198125204}, {"text": "Se- mEval 2015 Task 4 Task A -Subtrack", "start_pos": 50, "end_pos": 88, "type": "DATASET", "confidence": 0.7925931453704834}]}]}