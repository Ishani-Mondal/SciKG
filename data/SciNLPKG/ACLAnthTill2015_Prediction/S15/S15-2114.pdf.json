{"title": [{"text": "KELabTeam: A Statistical Approach on Figurative Language Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "KELabTeam", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.78936767578125}, {"text": "Figurative Language Sentiment Analysis", "start_pos": 37, "end_pos": 75, "type": "TASK", "confidence": 0.8086100369691849}]}], "abstractContent": [{"text": "In this paper, we propose anew statistical method for sentiment analysis of figurative language within short texts collected from Twitter (called tweets) as apart of SemEval-2015 Task 11.", "labels": [], "entities": [{"text": "sentiment analysis of figurative language within short texts collected from Twitter", "start_pos": 54, "end_pos": 137, "type": "TASK", "confidence": 0.8856460181149569}, {"text": "SemEval-2015 Task 11", "start_pos": 166, "end_pos": 186, "type": "TASK", "confidence": 0.7141136725743612}]}, {"text": "Particularly, the proposed model focuses on classifying the tweets into three categories (i.e., sarcastic, ironic, and metaphorical tweet) by extracting two main features (i.e., term features and emotion patterns).", "labels": [], "entities": []}, {"text": "Our experiments have been conducted with two datasets, which are Trial set (1000 tweets) and Test set (4000 tweets).", "labels": [], "entities": []}, {"text": "Performance is evaluated by cosine similarity to gold annotations.", "labels": [], "entities": []}, {"text": "Using this evaluation methodology , the proposed method achieves 0.74 on the Trial set.", "labels": [], "entities": [{"text": "Trial set", "start_pos": 77, "end_pos": 86, "type": "DATASET", "confidence": 0.90470752120018}]}, {"text": "On the Test set, we achieve 0.90 on sarcastic tweets and 0.89 on ironic tweets.", "labels": [], "entities": [{"text": "Test set", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.8539713323116302}]}], "introductionContent": [{"text": "Sentiment analysis in computer science is a difficult task which aims to identify the emotion from a given data source.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9513806700706482}]}, {"text": "The goal of sentiment analysis is to dissect a given document and determine whether its opinion represent positive, negative, or neutral.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.9363645911216736}]}, {"text": "There have been many studies (which use lexiconbased methods and machine learning-based methods) to extract and identify the sentiment).", "labels": [], "entities": []}, {"text": "In case of figurative language, the task becomes more challenging because the document can have secondary or extended meanings.", "labels": [], "entities": []}, {"text": "Hence, exactly finding the truth meaning of figurative language is an interesting problem for researchers due to its importance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The test data comprises 4000 tweets with both figurative and non-figurative tweets with 70% of them are sarcasm, irony, or metaphor; and 30% of the data are other.", "labels": [], "entities": []}, {"text": "We evaluate the test with: i) Contentbased Approach Module, ii) Emotion Pattern-based Approach Module, and iii) Combined Module.", "labels": [], "entities": []}, {"text": "FLASA Model works well with figurative tweets.", "labels": [], "entities": [{"text": "FLASA Model", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8546334207057953}]}, {"text": "Using cosine similarity to gold annotations to evaluate the system, the highest performance that we got is 0.90 with irony type, and the next is sarcastic type with 0.89.", "labels": [], "entities": []}, {"text": "With metaphor type, we achieve 0.34 with annotated tweets.", "labels": [], "entities": []}, {"text": "About non-figurative tweets, the performance is still low due to the tweets in the Training set.", "labels": [], "entities": [{"text": "Training set", "start_pos": 83, "end_pos": 95, "type": "DATASET", "confidence": 0.9088715016841888}]}, {"text": "The root cause is that there are no nonfigurative tweets in the Training set.", "labels": [], "entities": [{"text": "Training set", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.933048814535141}]}, {"text": "If we add more non-figurative tweets to the Training set in order to learn, the result will be improved.", "labels": [], "entities": [{"text": "Training set", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.8019046187400818}]}, {"text": "shows the performance that we got from testing our approach on the Test set.", "labels": [], "entities": [{"text": "Test set", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9255886077880859}]}], "tableCaptions": []}