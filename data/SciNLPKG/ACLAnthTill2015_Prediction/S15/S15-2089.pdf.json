{"title": [{"text": "GTI: An Unsupervised Approach for Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.9610454142093658}]}], "abstractContent": [{"text": "This paper presents the approach of the GTI Research Group to SemEval-2015 task 10 on Sentiment Analysis in Twitter, or more specifically , subtasks A (Contextual Polarity Disam-biguation) and B (Message Polarity Classification).", "labels": [], "entities": [{"text": "GTI Research", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.8593247830867767}, {"text": "SemEval-2015 task 10", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7419987519582113}, {"text": "Sentiment Analysis", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8770251870155334}, {"text": "Message Polarity Classification)", "start_pos": 196, "end_pos": 228, "type": "TASK", "confidence": 0.7338119372725487}]}, {"text": "We followed an unsupervised dependency parsing-based approach using a sentiment lexicon, created by means of an automatic polarity expansion algorithm and Natural Language Processing techniques.", "labels": [], "entities": [{"text": "dependency parsing-based", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.7358372211456299}]}, {"text": "These techniques involve the use of linguistic peculiarities , such as the detection of polarity conflicts or adversative/concessive subordinate clauses.", "labels": [], "entities": []}, {"text": "The results obtained confirm the competitive and robust performance of the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The domain of sentiment analysis has received increasing attention in recent years (, particularly due to the growth of the Internet and content generated by users of social networks and other platforms.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9263909757137299}]}, {"text": "Some of these, such as Twitter, allow people to express their opinions using colloquial, compact language.", "labels": [], "entities": []}, {"text": "The result is anew form of expression that may in the long term become a source of extremely valuable information.", "labels": [], "entities": []}, {"text": "An increasing number of companies are now focusing their marketing campaigns on online comments, sentiments, and opinions of brands from clients or potential clients, and some are even trying to predict the acceptance and rejection of certain products using this information ().", "labels": [], "entities": []}, {"text": "Even though the approaches used for this purpose are numerous and varied, they can be broadly divided into two categories: supervised machine-learning and unsupervised semantic-based approaches.", "labels": [], "entities": []}, {"text": "The former are often classifiers built from features of a \"bag of words\" representation (.", "labels": [], "entities": []}, {"text": "In other words, they consist of automatically analyzing n-grams in search of recurrent combinations of opinion words.", "labels": [], "entities": []}, {"text": "The latter aim at capturing and modeling linguistic knowledge through the use of dictionaries) containing words that are tagged with their semantic orientation.", "labels": [], "entities": []}, {"text": "These methods detect the words present in a text using different strategies involving lexics, syntax or semantics () and then aggregate their values.", "labels": [], "entities": []}, {"text": "Such methods usually combine two or more levels of analysis.", "labels": [], "entities": []}, {"text": "In recent years, work on sentiment classification using different types of texts has shown that specialized methods are required.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.9723757207393646}]}, {"text": "For example, emotions are not conveyed in the same manner in newspaper articles as in blogs, reviews, forums or other types of user-generated content.", "labels": [], "entities": []}, {"text": "Dealing with sentiment in Twitter, thus, requires an analysis of the characteristics of tweets and the design of adapted methods.", "labels": [], "entities": []}, {"text": "This paper presents a method for sentiment analysis in English that uses dependency parsing to determine the polarity of tweets, using a previously created sentiment lexicon and considering the special structure and linguistic content of these postings.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9314754605293274}, {"text": "dependency parsing", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7242583632469177}]}, {"text": "The remainder of this article is structured as follows: Section 2 provides a brief description of the task and some of its subtasks.", "labels": [], "entities": []}, {"text": "Section 3 presents in detail the system proposed for the performance of these tasks, and Section 4 shows the results obtained and discusses them.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes the main findings and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the experiments we conducted for both subtasks.", "labels": [], "entities": []}, {"text": "These experiments were carried out using the datasets provided by the SemEval-2015 task organizers.", "labels": [], "entities": [{"text": "SemEval-2015 task organizers", "start_pos": 70, "end_pos": 98, "type": "DATASET", "confidence": 0.6837494770685831}]}, {"text": "These datasets are composed of texts extracted from Twitter (including sarcastic tweets), LiveJournal and phone text messages.", "labels": [], "entities": []}, {"text": "The performance of each system is measured by means of the F-score, calculated as shown in Equation 1, where F P stands for the F-score estimated only for positive results.", "labels": [], "entities": [{"text": "F-score", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9971821308135986}, {"text": "Equation", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9754344820976257}, {"text": "F P", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.964244931936264}, {"text": "F-score", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.9762865900993347}]}, {"text": "In this case, this value is computed as shown in Equation 2, where PP represents the precision and RP the recall, both for positive results.", "labels": [], "entities": [{"text": "Equation", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.8702566027641296}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.999446451663971}, {"text": "RP", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.9776715040206909}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9976466298103333}]}, {"text": "The same is calculated for negative results, denominated F N . presents the overall score for subtasks A and B, in Twitter2015 Test, as well as precision, recall and F-measure values for positive (P), negative (N) and neutral (NEU) results.: Results of our approach for subtasks A and B.", "labels": [], "entities": [{"text": "Twitter2015 Test", "start_pos": 115, "end_pos": 131, "type": "DATASET", "confidence": 0.961879312992096}, {"text": "precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9995606541633606}, {"text": "recall", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9985551238059998}, {"text": "F-measure", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.9781585931777954}]}, {"text": "The approach previously described was applied on both datasets (A and B) in the same way using the  As can be seen, all our results are adjusted, so we can state that our system has no bias for one particular result, but performs quite well for all three types of answers.", "labels": [], "entities": []}, {"text": "However, as can be seen in subtask A, the performance measures for neutral tweets are notably lower than those obtained for positive and negative tweets.", "labels": [], "entities": []}, {"text": "This can be explained by the content of the dataset provided, which contained 1006 negative and 1896 positive tweets, but just 190 neutral tweets, which is an insufficient sample for producing reliable estimates on precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 215, "end_pos": 224, "type": "METRIC", "confidence": 0.9931108951568604}]}, {"text": "The same problem happened for progress test A, where the proportions of tweets are similarly unbalanced.", "labels": [], "entities": []}, {"text": "Detailed scores for progress tests of subtasks A and B are shown in.", "labels": [], "entities": []}, {"text": "In general, we can say that our system is quite stable, as it generates similar results for the different kinds of texts under evaluation.", "labels": [], "entities": []}, {"text": "Also of note are the high percentages obtained for sarcastic tweets, which ranked in the first position in subtask A and in the tenth (test dataset) and sixth positions (progress dataset) in subtask B (as shown in).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of our approach for subtasks A and B.", "labels": [], "entities": []}, {"text": " Table 2: Performance of our approach on the progress test A and B.", "labels": [], "entities": []}, {"text": " Table 3: Position of our approach for each test and task,  according to results provided on January 1, 2015.", "labels": [], "entities": []}]}