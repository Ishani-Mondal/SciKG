{"title": [{"text": "Turku: Semantic Dependency Parsing as a Sequence Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents the University of Turku entry to the SemEval-2015 task on Broad-Coverage Semantic Dependency Parsing.", "labels": [], "entities": [{"text": "SemEval-2015 task", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.91419917345047}, {"text": "Broad-Coverage Semantic Dependency Parsing", "start_pos": 78, "end_pos": 120, "type": "TASK", "confidence": 0.5832064524292946}]}, {"text": "The system uses an existing transition-based parser as a sequence classifier to jointly predict all arguments of one candidate predicate at a time.", "labels": [], "entities": []}, {"text": "Compared to our 2014 entry, the 2015 system gains about 3pp in terms of F-score fora fraction of the development time.", "labels": [], "entities": [{"text": "F-score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9987932443618774}]}, {"text": "Depending on the subtask, the difference between our entry and the winning system ranges between 1 and 5pp.", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval-2015 task on Broad-Coverage Semantic Dependency Parsing is a continuation to the semantic parsing shared task organized for the first time in 2014.", "labels": [], "entities": [{"text": "Broad-Coverage Semantic Dependency Parsing", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.5913134813308716}, {"text": "semantic parsing shared task", "start_pos": 93, "end_pos": 121, "type": "TASK", "confidence": 0.8399112075567245}]}, {"text": "The objective of the shared task is to produce a rich semantic analysis fora given sentence in three distinct annotation formats.", "labels": [], "entities": []}, {"text": "In contrast to the 2014 task, this year predicate disambiguation and two additional languages are included: Czech data from the Prague Czech-English Dependency) and Chinese data from the Penn Chinese Treebank ().", "labels": [], "entities": [{"text": "predicate disambiguation", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.7957372963428497}, {"text": "Prague Czech-English Dependency", "start_pos": 128, "end_pos": 159, "type": "DATASET", "confidence": 0.8534218668937683}, {"text": "Penn Chinese Treebank", "start_pos": 187, "end_pos": 208, "type": "DATASET", "confidence": 0.9420289794603983}]}, {"text": "For English and Czech also out-of-domain test data is provided in order to test the generalization ability of the systems.", "labels": [], "entities": []}, {"text": "The semantic parsing task includes three different tracks.", "labels": [], "entities": [{"text": "semantic parsing task", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.832737147808075}]}, {"text": "In the closed track the systems must be trained using only the official training data, whereas in the open track all additional sources of information are allowed.", "labels": [], "entities": []}, {"text": "Together with the training data the organizers provided also syntactic dependency parses produced in the Stanford Dependencies scheme) with the dependency parser of.", "labels": [], "entities": []}, {"text": "In addition to the closed and open tracks, also a gold track is included, where gold standard dependency parses are given for both training and test data.", "labels": [], "entities": []}, {"text": "This paper describes our system used to take part in the open and gold tracks of the shared task.", "labels": [], "entities": []}, {"text": "The system is a sequence classifier built on top of an existing dependency parser.", "labels": [], "entities": []}, {"text": "The main idea behind the implementation is to turn the task of predicting all arguments fora single predicate to a sequence classification problem, but still process each predicate independently.", "labels": [], "entities": [{"text": "sequence classification", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.6772487014532089}]}, {"text": "Predicting one predicate at a time feels very natural when working with data annotated in PropBank style ( , and since our main objective is to develop an SRL system optimized for Finnish PropBank), we did not want to merely follow the main methods from last year.", "labels": [], "entities": [{"text": "Finnish PropBank", "start_pos": 180, "end_pos": 196, "type": "DATASET", "confidence": 0.6806398332118988}]}, {"text": "Our system also requires syntactic analyses of the data, which is why we participated only on the tasks which allow their use (open and gold tracks).", "labels": [], "entities": []}, {"text": "The system will be described in detail in Section 3.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: English open track (in-domain & out-of-domain)  results in terms of precision (P), recall (R), labeled F- score (F) and unlabeled F-score (UF).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 78, "end_pos": 91, "type": "METRIC", "confidence": 0.9638255834579468}, {"text": "recall (R)", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9664644747972488}, {"text": "F- score (F)", "start_pos": 113, "end_pos": 125, "type": "METRIC", "confidence": 0.9528348743915558}, {"text": "F-score (UF)", "start_pos": 140, "end_pos": 152, "type": "METRIC", "confidence": 0.9347722977399826}]}, {"text": " Table 2: Results for Czech and Chinese data in the open  track. The Czech data is in PSD format and includes  both in-domain (ID) and out-of-domain (OOD) test sets,  whereas the Chinese data is in PAS format and has only  in-domain test set.", "labels": [], "entities": [{"text": "Czech data", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.8023781180381775}]}, {"text": " Table 3: English gold track (in-domain & out-of-domain)  results in terms of labeled F-score when using Stanford  Dependencies (SD) and DeepBank (DB) style syntactic  annotations.", "labels": [], "entities": [{"text": "English gold track", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.6548829972743988}, {"text": "F-score", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9156461358070374}]}]}