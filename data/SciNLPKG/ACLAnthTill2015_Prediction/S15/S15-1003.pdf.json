{"title": [{"text": "A Hybrid Distributional and Knowledge-based Model of Lexical Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "A range of approaches to the representation of lexical semantics have been explored within Computational Linguistics.", "labels": [], "entities": [{"text": "representation of lexical semantics", "start_pos": 29, "end_pos": 64, "type": "TASK", "confidence": 0.7968324720859528}]}, {"text": "Two of the most popular are distributional and knowledge-based models.", "labels": [], "entities": []}, {"text": "This paper proposes hybrid models of lexical semantics that combine the advantages of these two approaches.", "labels": [], "entities": []}, {"text": "Our models provide robust representations of synonymous words derived from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.9492434859275818}]}, {"text": "We also make use of WordNet's hierarcy to refine the synset vectors.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 20, "end_pos": 27, "type": "DATASET", "confidence": 0.9630569219589233}]}, {"text": "The models are evaluated on two widely explored tasks involving lexical semantics: lexical similarity and Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.6842144926389059}]}, {"text": "The hybrid models are found to perform better than standard distributional models and have the additional benefit of modelling polysemy.", "labels": [], "entities": []}], "introductionContent": [{"text": "The representation of lexical semantics is a core problem in Computational Linguistics and a variety of approaches have been developed.", "labels": [], "entities": [{"text": "representation of lexical semantics", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.8625178635120392}, {"text": "Computational Linguistics", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.8435513377189636}]}, {"text": "Two of the most widely explored have been knowledge-based and distributional semantics.", "labels": [], "entities": []}, {"text": "Knowledge-based approaches make use of some external information source which defines the set of possible meanings for each lexical item.", "labels": [], "entities": []}, {"text": "The most widely used information source is WordNet), although other resources, such as Machine Readable Dictionaries, thesaurii and ontologies have also been used (see).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9570621848106384}]}, {"text": "One advantage of these resources is that they represent the various possible meanings of lexical items which makes it straightforward to identify ones that are ambiguous.", "labels": [], "entities": []}, {"text": "For example, these resources would include multiple meanings for the word ball including the 'event' and 'sports equipment' senses.", "labels": [], "entities": []}, {"text": "However, the fact that there are multiple meanings associated with ambiguous lexical items can also be problematic since it may not be straightforward to identify which one is being used for an instance of an ambiguous word in text.", "labels": [], "entities": []}, {"text": "This issue has lead to significant exploration of the problem of Word Sense Disambiguation ().", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.6850606600443522}]}, {"text": "More recently distributional semantics has become a popular approach to representing lexical semantics).", "labels": [], "entities": []}, {"text": "These approaches are based on the premise that the semantics of lexical items can be modelled by their context.", "labels": [], "entities": []}, {"text": "Distributional semantic models have the advantages of being robust and straightforward to create from unannotated corpora.", "labels": [], "entities": []}, {"text": "However, problems can arise when they are used to represent the semantics of polysemous words.", "labels": [], "entities": []}, {"text": "Distributional semantic models are generally constructed by examining the context of lexical items in unannotated corpora.", "labels": [], "entities": []}, {"text": "But for ambiguous words, like ball, it is not clear if a particular instance of the word in a corpus refers to the 'event', 'sports equipment' or another sense which can lead to the distributional semantic model becoming a mixture of different meanings without representing any of the meanings individually.", "labels": [], "entities": []}, {"text": "This paper proposes models that merge elements of distributional and knowledge-based approaches to lexical semantics and combines advantages of both techniques.", "labels": [], "entities": []}, {"text": "A standard distributional semantic model 20 is created from an unannotated corpus and then refined using WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9703154563903809}]}, {"text": "The resulting models can be viewed as enhanced distributional models that have been refined using the information from WordNet to reduce the problems caused by ambiguous terms when models are created.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.9703336358070374}]}, {"text": "Alternatively, it can be used as aversion of the WordNet hierarchy in which distributional semantic models are attached to synsets.", "labels": [], "entities": []}, {"text": "Thereby creating aversion of WordNet for which the appropriate synsets can be identified more easily for ambiguous lexical items that occur in text.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9614874720573425}]}, {"text": "We evaluate our models on two standard tasks: lexical similarity and word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.7283398111661276}]}, {"text": "Results show that the proposed hybrid models perform consistently better than traditional distributional semantic models.", "labels": [], "entities": []}, {"text": "The reminder of the paper is organised as follows.", "labels": [], "entities": [{"text": "reminder of the paper", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.7011625915765762}]}, {"text": "Section 2 describes our hybrid models which combine information from WordNet and a standard distributional semantic model.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9483806490898132}]}, {"text": "These models are augmented using Latent Semantic Analysis and Canonical Correlation Analysis.", "labels": [], "entities": [{"text": "Canonical Correlation Analysis", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.7039001782735189}]}, {"text": "Sections 3 and 4 describe evaluation of the models on the word similarity and word sense disambiguation tasks.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.7168693145116171}]}, {"text": "Related work is presented in Section 5 and conclusions in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Performance is measured as the correlation between the similarity scores returned by each proposed method and the human judgements.", "labels": [], "entities": [{"text": "similarity scores returned", "start_pos": 55, "end_pos": 81, "type": "METRIC", "confidence": 0.9372626145680746}]}, {"text": "This is the standard approach to evaluate word and text similarity tasks, e.g. (. Our experiments use Spearman's correlation coefficient.", "labels": [], "entities": [{"text": "word and text similarity tasks", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6377137184143067}]}, {"text": "kicked in games') and 'ball.n.04' ('the people assembled at a lavish formal dance') is 'ball'.", "labels": [], "entities": []}, {"text": "In this case, the synset vector in H and the lemma vector in Dare identical and still polysemous.", "labels": [], "entities": []}, {"text": "This problem does not hold in H p and therefore the correlations are higher for that semantic space but still lower than those obtained for D.", "labels": [], "entities": []}, {"text": "Applying LSA on H and H p improves results but correlations are still lower than those obtained using D 2 . On the other hand, the joint space learned by applying CCA, H * , produces consistently better similarity estimates than D while outperforms all the other models in the majority of the data sets.", "labels": [], "entities": [{"text": "similarity", "start_pos": 203, "end_pos": 213, "type": "METRIC", "confidence": 0.9515326619148254}]}, {"text": "That confirms our main assumption than incorporating information obtained from a large corpus and a knowledge-base improves word vector representations.", "labels": [], "entities": [{"text": "word vector representations", "start_pos": 124, "end_pos": 151, "type": "TASK", "confidence": 0.7248347600301107}]}, {"text": "shows the Spearman's correlation of similarity scores generated by each model and human judgements of similarity across various data sets by taking the average pairwise similarity score of two words' synsets.", "labels": [], "entities": []}, {"text": "Results show that using the average rather than the maximum system similarity improves results for almost all data sets.", "labels": [], "entities": []}, {"text": "For example, the best 2 Note that  found that applying SVD to D did not improve performance over using the full space.", "labels": [], "entities": []}, {"text": "Word sense disambiguation systems are evaluated by computing precision and recall.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6636107265949249}, {"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9987136125564575}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9971410036087036}]}, {"text": "Precision measures the proportion of disambiguated words that have been correctly assigned with a sense.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9782965183258057}]}, {"text": "Recall measures the proportion of words disambiguated correctly out of all words available for disambiguation.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9271194934844971}]}, {"text": "shows the results obtained by using our hybrid models on the two word sense disambiguation data sets.", "labels": [], "entities": [{"text": "word sense disambiguation data sets", "start_pos": 65, "end_pos": 100, "type": "TASK", "confidence": 0.7063769459724426}]}, {"text": "The full Synset Rank model H p is consistently better method in terms of precision and recall in both data sets.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9993941783905029}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9995781779289246}]}, {"text": "On the other hand, it is somewhat surprising that dimensionality reduction and integration of semantic spaces do not help in improving performance.", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.7147705554962158}]}, {"text": "That is the\u02dcHthe\u02dc the\u02dcH p and H * p models achieve lower precision and recall than the fuller H p .", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9993759989738464}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9995067119598389}]}], "tableCaptions": [{"text": " Table 1: Spearman's correlation on various data sets. Maximum similarity between pairs of synsets.", "labels": [], "entities": [{"text": "Spearman's correlation", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.6209776600201925}, {"text": "similarity", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.5868268013000488}]}, {"text": " Table 2: Spearman's correlation on various data sets. Average pairwise similarity between pairs of synsets.", "labels": [], "entities": [{"text": "Spearman's correlation", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.6429584821065267}]}, {"text": " Table 3: Results obtained by hybrid models on SenseEval-2 and SenseEval-3 data sets (nouns only).", "labels": [], "entities": [{"text": "SenseEval-3 data sets", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.9094908237457275}]}]}