{"title": [{"text": "Lisbon: Evaluating TurboSemanticParser on Multiple Languages and Out-of-Domain Data", "labels": [], "entities": [{"text": "Lisbon", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9332131147384644}]}], "abstractContent": [{"text": "As part of the SemEval-2015 shared task on Broad-Coverage Semantic Dependency Parsing , we evaluate the performace of our last year's system (TurboSemanticParser) on multiple languages and out-of-domain data.", "labels": [], "entities": [{"text": "SemEval-2015 shared task", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.8400226434071859}, {"text": "Broad-Coverage Semantic Dependency Parsing", "start_pos": 43, "end_pos": 85, "type": "TASK", "confidence": 0.6553588882088661}]}, {"text": "Our system is characterized by a feature-rich linear model, that includes scores for first and second-order dependencies (arcs, siblings, grandparents and co-parents).", "labels": [], "entities": []}, {"text": "For decoding this second-order model, we solve a linear relaxation of that problem using alternating directions dual decomposition (AD 3).", "labels": [], "entities": []}, {"text": "The experiments have shown that, even though the parser's performance in Chinese and Czech attains around 80% (not too far from English performance), domain shift is a serious issue, suggesting domain adaptation as an interesting avenue for future research.", "labels": [], "entities": [{"text": "domain shift", "start_pos": 150, "end_pos": 162, "type": "TASK", "confidence": 0.7611245512962341}, {"text": "domain adaptation", "start_pos": 194, "end_pos": 211, "type": "TASK", "confidence": 0.7510988712310791}]}], "introductionContent": [{"text": "The last years have witnessed a continuous progress in statistical multilingual models for syntax, thanks to shared tasks such as) and, more recently,).", "labels": [], "entities": []}, {"text": "As a global trend, we observe that models that incorporate rich global features are typically more accurate, even if pruning is necessary or decoding needs to be approximate;.", "labels": [], "entities": []}, {"text": "The same rationale applies to semantic dependency parsing, also a structured prediction problem, but where the output variable is a semantic graph, rather than a syntactic tree.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.7116788029670715}]}, {"text": "Indeed, the best performing systems in last year shared task on broad-coverage semantic dependency parsing follow this principle.", "labels": [], "entities": [{"text": "broad-coverage semantic dependency parsing", "start_pos": 64, "end_pos": 106, "type": "TASK", "confidence": 0.7259318381547928}]}, {"text": "This year, anew challenge was put forth: how to handle multiple languages and out-ofdomain data?", "labels": [], "entities": []}, {"text": "Our proposed parser ( \u00a72) is essentially the same that we submitted in the previous year to the same SemEval task), where we scored top in the open challenge and second in the closed track.", "labels": [], "entities": [{"text": "SemEval task", "start_pos": 101, "end_pos": 113, "type": "TASK", "confidence": 0.8459220230579376}]}, {"text": "This year, we report results using new out-of-domain and multilingual data (namely, Czech and Chinese, in addition to English).", "labels": [], "entities": []}, {"text": "For the English language, we participated in the closed and open tracks, using as additional resources the syntactic dependency annotations provided by the organizers.", "labels": [], "entities": []}, {"text": "For Czech and Chinese, we only addressed the closed track, since no companion data were provided for these languages.", "labels": [], "entities": []}, {"text": "We did not participate in the gold track that uses gold-standard syntactic annotations; and we did not address the prediction of predicate senses.", "labels": [], "entities": []}], "datasetContent": [{"text": "All models were trained by running 10 epochs of max-loss MIRA with C = 0.01).", "labels": [], "entities": [{"text": "max-loss", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9642394185066223}, {"text": "MIRA", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.8881780505180359}, {"text": "C", "start_pos": 67, "end_pos": 68, "type": "METRIC", "confidence": 0.9362474679946899}]}, {"text": "The cost function takes into account mismatches between predicted and gold dependencies, with a cost c P on labeled arcs incorrectly predicted (false positives) and a cost c Ron gold labeled arcs that were missed (false negatives).", "labels": [], "entities": []}, {"text": "These values were set through cross-validation in the dev set, yielding c P = 0.4 and c R = 0.6 in all runs, except for the English PSD dataset in the closed track, for which c P = 0.3 and c R = 0.7.", "labels": [], "entities": [{"text": "English PSD dataset", "start_pos": 124, "end_pos": 143, "type": "DATASET", "confidence": 0.7313427726427714}]}, {"text": "As in the previous work, we speedup decoding by training a probabilistic unlabeled first-order pruner and discarding the arcs whose posterior probability is below 10 \u22124 . This allows a significant reduction of the search space with a very small drop in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 253, "end_pos": 259, "type": "METRIC", "confidence": 0.9989240765571594}]}, {"text": "shows our final results in the test set, fora model trained in the train and development partitions.", "labels": [], "entities": []}, {"text": "Note that we do not report scores for complete predications, since we did not predict predicate sense.", "labels": [], "entities": []}, {"text": "Our system achieved the best final score in 3 out of the 4 tracks for the English language, and for the in-domain closed track in the Czech language.", "labels": [], "entities": []}, {"text": "For the remaining 3 tracks we scored relatively close to the best system (Peking), which consists of an ensemble of various methods.", "labels": [], "entities": [{"text": "Peking)", "start_pos": 74, "end_pos": 81, "type": "DATASET", "confidence": 0.8324781656265259}]}, {"text": "For all languages, the runtimes are in par with last year's submission (around 1,000 tokens per second).", "labels": [], "entities": []}, {"text": "As expected, the scores obtained for out-ofdomain data are significantly below those obtained with in-domain data.", "labels": [], "entities": []}, {"text": "This degradation becomes particularly striking for Czech, with F 1 -scores dropping more than 15%.", "labels": [], "entities": [{"text": "F 1 -scores", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9848217666149139}]}, {"text": "This suggests that domain adaptation () is an interesting research avenue for future work.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8175328969955444}]}, {"text": "In ad-  dition, as found last year for English, the gap between labeled and unlabeled scores is much higher in the PSD formalism (for English and Czech) then it is for the DM and PAS formalism (for English and Chinese).", "labels": [], "entities": []}, {"text": "Finally, to assess the importance of the second order features, reports experiments in the devset that progressively add several groups of features.", "labels": [], "entities": []}, {"text": "We can see that second order features provide valuable information that improves the final scores.", "labels": [], "entities": []}, {"text": "In particular, the higher-order features are extremely useful for Chinese and Czech, where we can observe gains of 1.5-2.0% over a sibling model that factors over predicates.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Final scores in the test data. For comparison, we show the scores of the Peking system -our best competitor.", "labels": [], "entities": [{"text": "Peking system", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.88888019323349}]}]}