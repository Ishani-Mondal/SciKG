{"title": [{"text": "Shiraz: A Proposed List Wise Approach to Answer Validation", "labels": [], "entities": [{"text": "Answer Validation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.9835540354251862}]}], "abstractContent": [{"text": "Answer Validation is an important step in Automatic Question Answering systems and nowadays by spreading Community Question Answering systems it is known as an important task by itself.", "labels": [], "entities": [{"text": "Answer Validation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9134031534194946}, {"text": "Automatic Question Answering", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6886421541372935}, {"text": "Community Question Answering", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.5676452815532684}]}, {"text": "Previous works just considered it as a binary classification problem in which they try to find the best answer among all the candidate answers fora question.", "labels": [], "entities": []}, {"text": "Accordingly , they do not consider the possible unique information which may have been included other answers.", "labels": [], "entities": []}, {"text": "This can be considered by having a multiclass label classification problem, it is not only able to find the best answer but also can find \"potentially good\", \"bad\", and etc.", "labels": [], "entities": [{"text": "multiclass label classification", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.6080203652381897}]}, {"text": "By doing so, it is fully expected to extract and rate all the necessary information from existing candidates to help questioner to find the best and general answer for his question.", "labels": [], "entities": []}, {"text": "This work tries to consider some features which are gained from importance of comments of the questioner.", "labels": [], "entities": []}, {"text": "Finally , by using a good classifier, we try to overcome this problem.", "labels": [], "entities": []}, {"text": "The designed system participated in subtask A of the Semeval-2015 Task 3.", "labels": [], "entities": [{"text": "Semeval-2015 Task 3", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.5644608537356058}]}, {"text": "The primary submission ranked at the 5th and 7th places in four class label and three class label evaluation, accordingly.", "labels": [], "entities": []}], "introductionContent": [{"text": "By spreading Community Question Answering (CQA) systems, there have been created anew taxonomy for Question Answering (QA) systems: Regular QAs, and CQAs.", "labels": [], "entities": [{"text": "Community Question Answering (CQA)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.7779510219891866}, {"text": "Question Answering (QA)", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.832457172870636}]}, {"text": "A regular QA, accepts a natural language input and after searching into it's available resources, returns the best shortest answer, it could find.", "labels": [], "entities": []}, {"text": "In these systems, answering to factoid questions maybe an easier challenge than the other question types.", "labels": [], "entities": [{"text": "answering to factoid questions", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.9138668477535248}]}, {"text": "One of the features of CQA systems is its users.", "labels": [], "entities": []}, {"text": "Once one asks a question, others try to answer that question.", "labels": [], "entities": []}, {"text": "Then these kinds of systems just try to use users knowledge to answer users questions.", "labels": [], "entities": []}, {"text": "Of course instead of finding the correct answer of an asked question from some candidate answers which must be done by questioner, system tries to tell the questioner which answer is helpful and which one is not.", "labels": [], "entities": []}, {"text": "Then discussing about factoid questions is maybe so hard and it could not be handled just by using the answers and questions body, rather, it should have access to a great knowledge source to check if an answer is corrector not.", "labels": [], "entities": [{"text": "discussing about factoid questions", "start_pos": 5, "end_pos": 39, "type": "TASK", "confidence": 0.7852989733219147}]}, {"text": "Community Question Answering systems' spreaded over the internet, and accordingly, it made researchers to be interested in getting involved to the challenges related to these systems.", "labels": [], "entities": [{"text": "Community Question Answering", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5772639811038971}]}, {"text": "One of the main challenges which maybe so important in the aspect of all the people who are using these systems is Answer Validation.", "labels": [], "entities": [{"text": "Answer Validation", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.9785950481891632}]}, {"text": "More researches has been done as CQA systems are getting more and more popular.", "labels": [], "entities": []}, {"text": "This challenge is a kind of classification problem which classifies comments of a question and by doing so, it can help questioner to find the correct answer, sooner, and without spending so much time to read all the comments.", "labels": [], "entities": []}, {"text": "Alternately, it can help other web users who had searched for the similar question in a search engine and redirected to our website, to find the answer they are looking for.", "labels": [], "entities": []}, {"text": "Next it can help us to find the questions without any proper answer, and in addition it can be used for question routing challenge ().", "labels": [], "entities": [{"text": "question routing challenge", "start_pos": 104, "end_pos": 130, "type": "TASK", "confidence": 0.8670961459477743}]}, {"text": "Eventually its important to CQA systems owners to attract more users and accordingly, attracting more users means earning more money.", "labels": [], "entities": []}, {"text": "In this work anew type of features will be discussed which could be gained by considering the information of questioner comments.", "labels": [], "entities": []}, {"text": "Experiments shows, this kind of features are more valuable in contrast of the most valuable features of previous works.", "labels": [], "entities": []}, {"text": "Some previous works focused on the deep textual features such as syntactic, lexical, and discourse features to find the best answer.", "labels": [], "entities": []}, {"text": "And some others tried to overcome this problem using shallow features such as word count in an answer, answer count fora question, ().", "labels": [], "entities": []}, {"text": "Some others, tried to propose a solution by using reputational features of such a system like user rating (a high ranked user may produce a more reliable answer), Answer rating (an answer with more ratings from other users maybe more reliable),.", "labels": [], "entities": [{"text": "Answer rating", "start_pos": 163, "end_pos": 176, "type": "METRIC", "confidence": 0.8303418159484863}]}, {"text": "Of course previous works, mostly have just tried to find the best answer (designed a binary classifier) but present work classifies answers into six classes: Good, Potential, Bad, Dialogue, Not English, and Other.", "labels": [], "entities": []}, {"text": "Good is a comment with a complete bunch of relevant information.", "labels": [], "entities": []}, {"text": "Potential is a comment with some helpful information but is not a complete answer.", "labels": [], "entities": [{"text": "Potential", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9675827026367188}]}, {"text": "Bad is a comment with no helpful information to answer the question.", "labels": [], "entities": []}, {"text": "Dialogue is a comment which shows a kind of discussion between users and obviously contains no useful information.", "labels": [], "entities": []}, {"text": "Not English is a comment in other languages.", "labels": [], "entities": []}, {"text": "Other is a comment which is not a kind of above mentioned classes.", "labels": [], "entities": []}, {"text": "Samples of English, and Other classes have no valuable information as samples related to Bad and Dialogue classes.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: related works are presented at section 2.", "labels": [], "entities": []}, {"text": "There is an introduction to the used dataset at section 3.", "labels": [], "entities": []}, {"text": "At section 4 the Features will be introduced.", "labels": [], "entities": []}, {"text": "At section 5 experiments are discussed.", "labels": [], "entities": []}, {"text": "Finally, Section 6 would have a conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The source of the corpus is the Qatar Living Forum data . Details of the method of extracting and labeling its content are described at.", "labels": [], "entities": [{"text": "Qatar Living Forum data", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.9827392846345901}]}, {"text": "This corpus was provided into three parts: train set, development set, and test set.", "labels": [], "entities": []}, {"text": "Each of the mentioned sets is consists of a number of questions and for each question, there is some comments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: General Features Gain Ration.", "labels": [], "entities": []}, {"text": " Table 2: System Evaluation Measure values.", "labels": [], "entities": []}, {"text": " Table 3 F1-Score is not improved. Then the dis- cretization method described in Gkotsis", "labels": [], "entities": [{"text": "F1-Score", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.998927652835846}, {"text": "Gkotsis", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.8888179659843445}]}]}