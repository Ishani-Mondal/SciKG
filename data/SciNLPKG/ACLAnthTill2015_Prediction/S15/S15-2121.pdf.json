{"title": [{"text": "V3: Unsupervised Aspect Based Sentiment Analysis for SemEval-2015 Task 12", "labels": [], "entities": [{"text": "Unsupervised Aspect Based Sentiment Analysis", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.5741895616054535}, {"text": "SemEval-2015 Task 12", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.8805844783782959}]}], "abstractContent": [{"text": "This paper presents our participation in SemEval-2015 task 12 (Aspect Based Sentiment Analysis).", "labels": [], "entities": [{"text": "SemEval-2015 task 12", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.9034076531728109}, {"text": "Aspect Based Sentiment Analysis)", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.7040404498577117}]}, {"text": "We participated employing only unsupervised or weakly-supervised approaches.", "labels": [], "entities": []}, {"text": "Our attempt is based on requiring the minimum annotated or hand-crafted content , and avoids training a model using the provided training set.", "labels": [], "entities": []}, {"text": "We use a continuous word representations (Word2Vec) to leverage in-domain semantic similarities of words for many of the involved subtasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "The continuous growing of textual content on the Internet has motivated an important research on finding automatic ways of processing and exploiting this valuable source of information.", "labels": [], "entities": []}, {"text": "That is one of the reasons why sentiment analysis has become a very active research field during the last decade.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9738500118255615}]}, {"text": "Sentiment analysis aims to detect and classify the polarity of sentiments expressed in a text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9582359194755554}]}, {"text": "The granularity of this classification goes from the overall polarity of full documents to paragraphs, sentences or, as in Aspect Based Sentiment Analysis (ABSA), the sentiment about precise aspects being opinionated () () () (.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis (ABSA)", "start_pos": 123, "end_pos": 161, "type": "TASK", "confidence": 0.7278291838509696}]}, {"text": "In this paper we describe our participation in SemEval-2015 task 12 1 (, which is about ABSA.", "labels": [], "entities": [{"text": "SemEval-2015 task 12", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.8480904301007589}, {"text": "ABSA", "start_pos": 88, "end_pos": 92, "type": "TASK", "confidence": 0.8765622973442078}]}, {"text": "We have participated in all subtasks http://alt.qcri.org/semeval2015/task12/ employing unsupervised or weakly supervised approaches.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the SemEval-2015 task 12 competition and provided datasets, and a brief introduction about how we have approached the different slots.", "labels": [], "entities": [{"text": "SemEval-2015 task 12 competition", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.7337557822465897}]}, {"text": "Sections 3, 4 and 5 describe more in detail the employed techniques.", "labels": [], "entities": []}, {"text": "Section 6 shows the results of the evaluation, and finally section 7 summarizes the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have participated in SemEval-2015 Task 12 slot 1 (entity-attribute detection), slot 2 (aspect-term detection) and slot 3 (polarity detection).", "labels": [], "entities": [{"text": "SemEval-2015 Task 12 slot", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.7704490125179291}, {"text": "entity-attribute detection", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.6892695724964142}, {"text": "aspect-term detection", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.6536984592676163}, {"text": "polarity detection", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.7525767683982849}]}, {"text": "In general the task definition is more challenging than in SemEval-2014 ABSA competition 5 as the average results of all participants indicate.", "labels": [], "entities": [{"text": "SemEval-2014 ABSA competition 5", "start_pos": 59, "end_pos": 90, "type": "DATASET", "confidence": 0.6527741551399231}]}, {"text": "The participation number is also lower and varies between of subtasks and domains (15 participants for restaurants slot 1, 9 for laptops slot 1, 21 for restaurants slot 2, and an average of 14 for slot 3 in the three available domains).", "labels": [], "entities": []}, {"text": "As far as we know, we are the only team that has faced the competition using unsupervised approaches.", "labels": [], "entities": []}, {"text": "As expected, the supervised systems obtain better results in general than our unsupervised one.", "labels": [], "entities": []}, {"text": "Slot 2 (detecting explicit aspect terms) was only available for restaurants.", "labels": [], "entities": [{"text": "Slot 2", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9156187176704407}]}, {"text": "After performing the steps described in section 3, we employed the top 500 bootstrapped terms to annotate the provided set of reviews using a simple lemma matching.", "labels": [], "entities": []}, {"text": "The results are shown in table 2, together with the official results of the supervised baseline, the best performing system, and the average of all participants.", "labels": [], "entities": []}, {"text": "Slot 1 (detecting entity-attribute pairs in sentences) was available both for restaurants and laptops.", "labels": [], "entities": []}, {"text": "We employed the described manual bag of words plus Word2Vec approach.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9114493727684021}]}, {"text": "The results are quite modest as it can be appreciated in   domain.", "labels": [], "entities": []}, {"text": "This hidden domain, which was about hotels, was revealed in the last moment and no training data was provided.", "labels": [], "entities": []}, {"text": "For this hidden domain we had no time to develop its own sentiment lexicon so we employed the one from restaurants domain.", "labels": [], "entities": []}, {"text": "The results for all domains are shown in table 4.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on the restaurant reviews for slot 2.", "labels": [], "entities": []}, {"text": " Table 3: Results on the restaurant and laptops reviews for  entity-attribute detection (SemEval-2015 task 12 slot 1).", "labels": [], "entities": [{"text": "entity-attribute detection", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.7129624485969543}, {"text": "SemEval-2015 task 12 slot", "start_pos": 89, "end_pos": 114, "type": "DATASET", "confidence": 0.7614999115467072}]}, {"text": " Table 4: Results on the restaurant, laptops and hotels for  slot 3.", "labels": [], "entities": []}]}