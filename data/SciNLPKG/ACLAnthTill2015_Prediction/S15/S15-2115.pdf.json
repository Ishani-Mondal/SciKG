{"title": [{"text": "LT3: Sentiment Analysis of Figurative Tweets: piece of cake #NotReally", "labels": [], "entities": [{"text": "Sentiment Analysis of Figurative Tweets", "start_pos": 5, "end_pos": 44, "type": "TASK", "confidence": 0.9263943672180176}, {"text": "NotReally", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.6687095165252686}]}], "abstractContent": [{"text": "This paper describes our contribution to the SemEval-2015 Task 11 on sentiment analysis of figurative language in Twitter.", "labels": [], "entities": [{"text": "SemEval-2015 Task 11", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.8747527996699015}, {"text": "sentiment analysis of figurative language in Twitter", "start_pos": 69, "end_pos": 121, "type": "TASK", "confidence": 0.8600991197994777}]}, {"text": "We considered two approaches, classification and regression , to provide fine-grained sentiment scores fora set of tweets that are rich in sarcasm, irony and metaphor.", "labels": [], "entities": []}, {"text": "To this end, we combined a variety of standard lexical and syntactic features with specific features for capturing figurative content.", "labels": [], "entities": []}, {"text": "All experiments were done using supervised learning with LIBSVM.", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.9233171939849854}]}, {"text": "For both runs, our system ranked fourth among fifteen submissions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Handling figurative language is currently one of the most challenging tasks in NLP.", "labels": [], "entities": [{"text": "Handling figurative language", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8120356599489847}]}, {"text": "Figurative language is often characterized by linguistic devices such as sarcasm, irony, metaphors, and humour.", "labels": [], "entities": [{"text": "Figurative language", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8694301545619965}]}, {"text": "Their meaning goes beyond the literal meaning and is therefore often hard to capture, even for humans.", "labels": [], "entities": []}, {"text": "However, as an increasing part of our daily communication takes place on social media (e.g. Twitter, Facebook), which are prone to figurative language use, there is an urgent need for automatic systems that recognize and understand figurative online content.", "labels": [], "entities": []}, {"text": "This is especially the casein the field of sentiment analysis where the presence of figurative language in subjective text can significantly undermine the classification accuracy.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.9590564966201782}, {"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9026002883911133}]}, {"text": "Understanding figurative language often requires world knowledge, which cannot easily be accessed by machines.", "labels": [], "entities": [{"text": "Understanding figurative language", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.747305691242218}]}, {"text": "Moreover, figurative language rapidly evolves due to changes in vocabulary and language, which makes it difficult to train machine learning algorithms.", "labels": [], "entities": []}, {"text": "Nevertheless, the identification of nonliteral uses of language has attracted a fair amount of research interest recently.", "labels": [], "entities": [{"text": "identification of nonliteral uses of language", "start_pos": 18, "end_pos": 63, "type": "TASK", "confidence": 0.7919379671414694}]}, {"text": "Veale (2012) investigated the relation between irony and our stereotypical knowledge of a domain and showed how the insight in stereotypical norms helps to recognize and understand ironic utterances.", "labels": [], "entities": []}, {"text": "built an irony model for Twitter for which they relied on a set of textual features for capturing ironic tweets.", "labels": [], "entities": []}, {"text": "Their model obtained promising results concerning recall (84%).", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9991550445556641}]}, {"text": "In what relates to the detection of metaphors, introduced an algorithm for distinguishing between metaphorical and literal word usages based on the degree of abstractness of a word's context.", "labels": [], "entities": [{"text": "detection of metaphors", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.881476640701294}]}, {"text": "More recent work by presents a cross-lingual model based on lexical semantic word features for metaphor detection in English, Spanish, Farsi and Russian.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.8873657286167145}]}, {"text": "To date, most studies on figurative language use have focussed on the detection of linguistic devices such as sarcasm, irony and metaphor.", "labels": [], "entities": [{"text": "detection of linguistic devices such as sarcasm, irony and metaphor", "start_pos": 70, "end_pos": 137, "type": "TASK", "confidence": 0.5758885849605907}]}, {"text": "By contrast, only a few studies have investigated how these devices affect sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.9567072093486786}]}, {"text": "Indeed, as stated by, it is not sufficient to determine whether a text contains sarcasm or not.", "labels": [], "entities": []}, {"text": "Instead, we need to measure its impact on sentiment analysis if we want to improve the state-of-the-art in sentiment analysis systems.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.9723844826221466}, {"text": "sentiment analysis", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.9153482019901276}]}, {"text": "In this paper we describe our contribution to the SemEval-2015 shared task: Sentiment Analysis of Figurative Language in Twitter ().", "labels": [], "entities": [{"text": "SemEval-2015 shared task", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.805087129275004}, {"text": "Sentiment Analysis of Figurative Language in Twitter", "start_pos": 76, "end_pos": 128, "type": "TASK", "confidence": 0.9040098360606602}]}, {"text": "Our objective is to provide fine-grained sentiment scores fora set of tweets that are rich in sarcasm, irony and metaphor.", "labels": [], "entities": []}, {"text": "The datasets for training, development and testing were provided by the task organizers.", "labels": [], "entities": []}, {"text": "The training dataset contains 8,000 tweets (5,000 sarcastic, 1,000 ironic and 2,000 metaphorical) labeled with a sentiment score between -5 and 5.", "labels": [], "entities": []}, {"text": "This training set was provided with both integer and real-valued sentiment scores.", "labels": [], "entities": []}, {"text": "The trial and test sets were comparable to the training corpus and contain 1,000 1 and 4,000 labeled instances, respectively.", "labels": [], "entities": []}, {"text": "All experiments were done using LIBSVM ().", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 32, "end_pos": 38, "type": "DATASET", "confidence": 0.5758187770843506}]}, {"text": "We submitted two runs for the competition.", "labels": [], "entities": []}, {"text": "To this end, we built two models based on supervised learning: 1) a classification-based (C-SVC) and 2) a regression-based approach (epsilon-SVR).", "labels": [], "entities": []}, {"text": "For both models, we implemented a number of word-based, lexical, sentiment and syntactic features in combination with specific features for capturing figurative content such as sarcasm.", "labels": [], "entities": []}, {"text": "Evaluation was done by calculating the cosine similarity distance between the predicted and the gold-standard sentiment labels.", "labels": [], "entities": [{"text": "cosine similarity distance", "start_pos": 39, "end_pos": 65, "type": "METRIC", "confidence": 0.7978500922520956}]}, {"text": "The remainder of this paper is structured as follows: Section 2 presents our system description whereas Section 2.2 gives an overview of the features we implemented.", "labels": [], "entities": []}, {"text": "The experimental setup is described in Section 3, followed by our results in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we draw conclusions in Section 5 where we also suggest some directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "As the training instances were provided with both integer and real-valued sentiment scores, we used two different approaches to the fine-grained sentiment labeling.", "labels": [], "entities": []}, {"text": "Firstly, we implemented a classification approach where each tweet had to be given a sentiment label on an eleven-point scale ranging from -5 to 5.", "labels": [], "entities": []}, {"text": "Secondly, we used regression to predict a real-valued sentiment score for each tweet, which could be any numeric value between -5 and 5.", "labels": [], "entities": []}, {"text": "Two feature sets were used throughout the experiments: firstly, we included a number of word-based, lexical, sentiment and syntactic features (we refer to these as the sentiment feature set).", "labels": [], "entities": []}, {"text": "Secondly, we implemented an additional set of features for capturing possibly figurative content such as irony and metaphors.", "labels": [], "entities": []}, {"text": "These features are referred to as the figurative feature set.", "labels": [], "entities": []}, {"text": "Using 5-fold cross-validation on the training data, we performed a grid search to find the optimal cost and gamma parameters for both classification (c = 0.03, g = 0.008) and regression (c = 8, g = 0.063).", "labels": [], "entities": []}, {"text": "For regression, an optimal epsilon value of p = 0.5 was determined.", "labels": [], "entities": []}, {"text": "As a first approach to evaluating our features, we used a subset of the trial data 5 . Secondly, we (randomly) split the data into 90% for training and 10% for testing.", "labels": [], "entities": []}, {"text": "We calculated a baseline using the majority class label -3 (see).", "labels": [], "entities": []}, {"text": "present the results on the training and trial data that were obtained throughout the experiments both for classification and for regression.", "labels": [], "entities": []}, {"text": "Cosine Similarity Trial data 0.59 10% training set 0.80 Averaged baseline 0.70   Experimental results for regression (after a parameter grid search).", "labels": [], "entities": []}, {"text": "As the table shows, adding figurative language specific features proves to be beneficial for classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 93, "end_pos": 107, "type": "TASK", "confidence": 0.9672004580497742}]}, {"text": "For regression, by contrast, adding more features does not improve the results on the training and trial data.", "labels": [], "entities": []}, {"text": "However, both approaches clearly outperform the baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Majority class baseline.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results for classification  (after a parameter grid search).", "labels": [], "entities": [{"text": "classification", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.9816426038742065}]}, {"text": " Table 4: Competition results for classification.", "labels": [], "entities": []}, {"text": " Table 5: Competition results for regression.", "labels": [], "entities": [{"text": "regression", "start_pos": 34, "end_pos": 44, "type": "TASK", "confidence": 0.9763886332511902}]}]}