{"title": [{"text": "NLANGP: Supervised Machine Learning System for Aspect Category Classification and Opinion Target Extraction", "labels": [], "entities": [{"text": "NLANGP", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8746566772460938}, {"text": "Aspect Category Classification", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.7281447052955627}, {"text": "Opinion Target Extraction", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.6061872740586599}]}], "abstractContent": [{"text": "This paper describes our system used in the Aspect Based Sentiment Analysis Task 12 of SemEval-2015.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis Task 12 of SemEval-2015", "start_pos": 44, "end_pos": 99, "type": "TASK", "confidence": 0.7863504961133003}]}, {"text": "Our system is based on two supervised machine learning algorithms: sig-moidal feedforward network to train binary classifiers for aspect category classification (Slot 1), and Conditional Random Fields to train classifiers for opinion target extraction (Slot 2).", "labels": [], "entities": [{"text": "aspect category classification", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.6983639597892761}, {"text": "opinion target extraction", "start_pos": 226, "end_pos": 251, "type": "TASK", "confidence": 0.6926994721094767}]}, {"text": "We extract a variety of lexicon and syntactic features, as well as cluster features induced from unlabeled data.", "labels": [], "entities": []}, {"text": "Our system achieves state-of-the-art performances, ranking 1st for three of the evaluations (Slot 1 for both restaurant and laptop domains, and Slot 1 & 2) and 2nd for Slot 2 evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The amount of user-generated content on the web has grown rapidly in recent years, prompting increasing interests in the research area of sentiment analysis and opinion mining.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.9464171826839447}, {"text": "opinion mining", "start_pos": 161, "end_pos": 175, "type": "TASK", "confidence": 0.8146366477012634}]}, {"text": "Most previous work is concerned with detecting the overall polarity of a sentence or paragraph, regardless of the target entities (e.g. restaurants) and their aspects (e.g. food).", "labels": [], "entities": [{"text": "detecting the overall polarity of a sentence or paragraph", "start_pos": 37, "end_pos": 94, "type": "TASK", "confidence": 0.8493521942032708}]}, {"text": "By contrast, the Aspect Based Sentiment Analysis task of SemEval 2014 (SE-ABSA14) is concerned with identifying the aspects of given target entities and the sentiment expressed towards each aspect ().", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis task", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.8402398347854614}, {"text": "SemEval 2014 (SE-ABSA14)", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.5668009221553802}]}, {"text": "The SemEval-2015 Aspect Based Sentiment Analysis (SE-ABSA15) task is a continuation of SE-ABSA14 ().", "labels": [], "entities": [{"text": "SemEval-2015 Aspect Based Sentiment Analysis (SE-ABSA15) task", "start_pos": 4, "end_pos": 65, "type": "TASK", "confidence": 0.7352028489112854}]}, {"text": "The SE-ABSA15 task features a number of changes that address issues raised in SE-ABSA14 and also encourage further in-depth research.", "labels": [], "entities": []}, {"text": "For example, (1) instead of isolated (potentially out of context) sentences, the input datasets will contain entire reviews; (2) information linking aspect terms and aspect categories are now provided; (3) besides in-domain ABSA (Subtask 1), SE-ABSA15 will include an out-of-domain ABSA subtask (Subtask 2).", "labels": [], "entities": []}, {"text": "We participate in Subtask 1 of SE-ABSA15, namely aspect category classification (Slot 1) and opinion target extraction (Slot 2).", "labels": [], "entities": [{"text": "aspect category classification", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.6264545718828837}, {"text": "opinion target extraction", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.6362379888693491}]}, {"text": "We also participate in the evaluation which assesses whether a system identifies both the aspect categories and opinion targets correctly (.", "labels": [], "entities": []}, {"text": "For Slot 1, we model the problem as a multi-class classification problem where binary classifiers are trained to predict the aspect categories.", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.9543820321559906}]}, {"text": "We follow the one-vs-all strategy and train a binary classifier for each category in the training set.", "labels": [], "entities": []}, {"text": "Each classifier is trained using sigmoidal feedforward network with 1 hidden layer.", "labels": [], "entities": []}, {"text": "For Slot 2, we follow the approach of by modeling the problem as a sequential labeling task, using Conditional Random Fields (CRF) as the training algorithm.", "labels": [], "entities": [{"text": "Slot 2", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.9572019577026367}]}, {"text": "For Slot 1 & 2, we perform a simple combination of Slot 1 predictions and Slot 2 predictions.", "labels": [], "entities": [{"text": "Slot 1", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.8588177263736725}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe our system in detail, including the feature description and approaches.", "labels": [], "entities": []}, {"text": "In Section 3, the official results are presented.", "labels": [], "entities": []}, {"text": "Feature ablation results are shown in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes our work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tuned parameter values for Slot 1 on the restau- rant and laptop domain.", "labels": [], "entities": [{"text": "restau- rant and laptop domain", "start_pos": 51, "end_pos": 81, "type": "DATASET", "confidence": 0.7989376584688822}]}, {"text": " Table 4: Comparison of our unconstrained (U) and constrained (C) systems with the top three participating systems  and official baselines for Slot 1, Slot 2 and Slot 1 & 2. P, R, and F1 denote the precision, recall and F1 measure  respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 184, "end_pos": 186, "type": "METRIC", "confidence": 0.998369038105011}, {"text": "precision", "start_pos": 198, "end_pos": 207, "type": "METRIC", "confidence": 0.9994514584541321}, {"text": "recall", "start_pos": 209, "end_pos": 215, "type": "METRIC", "confidence": 0.9944702386856079}, {"text": "F1 measure", "start_pos": 220, "end_pos": 230, "type": "METRIC", "confidence": 0.9808614552021027}]}, {"text": " Table 3: 5-fold cross-validation performances of Slot 2  on the restaurant domain. Each row uses all features  added in the previous rows. The cross-validation experi- ments use Method-1 to train the models.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of F1 performances for Slot 2 eval- uation. Our official submissions for Slot 2 evaluation use  Method-2, which is better than Method-1 used for Slot 1  & 2 evaluation.", "labels": [], "entities": [{"text": "F1", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9957221746444702}, {"text": "Slot 2 eval- uation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.5329516708850861}, {"text": "Slot 1  & 2 evaluation", "start_pos": 166, "end_pos": 188, "type": "TASK", "confidence": 0.539117443561554}]}, {"text": " Table 6: Test set ablation experiments for Slot 1 on the  restaurant and laptop domain. The quantity is the (uncon- strained) F1 measure and loss resulted from the removal  of a single feature group.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 127, "end_pos": 137, "type": "METRIC", "confidence": 0.984416276216507}]}, {"text": " Table 7: Test set ablation experiments for Slot 2 on the  restaurant domain. The quantity is the (unconstrained)  F1 measure and loss resulted from the removal of a single  feature group.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 115, "end_pos": 125, "type": "METRIC", "confidence": 0.9842298924922943}]}]}