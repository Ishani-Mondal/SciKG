{"title": [{"text": "Splusplus: A Feature-Rich Two-stage Classifier for Sentiment Analysis of Tweets", "labels": [], "entities": [{"text": "Sentiment Analysis of Tweets", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.9279282987117767}]}], "abstractContent": [{"text": "This paper describes our sentiment classification system submitted to SemEval-2015 Task 10.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.9251358211040497}, {"text": "SemEval-2015 Task 10", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.8181383013725281}]}, {"text": "In the message-level polarity classification subtask, we obtain the highest macro-averaged F1-scores on three out of six testing sets.", "labels": [], "entities": [{"text": "message-level polarity classification", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.737002948919932}, {"text": "F1-scores", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9466381072998047}]}, {"text": "Specifically, we build a two-stage classifier to predict the sentiment labels for tweets, which enables us to design different features for subjective/objective classification and positive/negative classification.", "labels": [], "entities": [{"text": "subjective/objective classification", "start_pos": 140, "end_pos": 175, "type": "TASK", "confidence": 0.7310481369495392}]}, {"text": "In addition to n-grams, lexicons, word clusters, and twitter-specific features, we develop several deep learning methods to automatically extract features for the message-level sentiment classification task.", "labels": [], "entities": [{"text": "message-level sentiment classification task", "start_pos": 163, "end_pos": 206, "type": "TASK", "confidence": 0.7496768981218338}]}, {"text": "Moreover, we propose a polarity boosting trick which improves the performance of our system.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the task 10 of SemEval-2015, submitted systems are required to categorize tweets to positive, negative, and neutral classes (.", "labels": [], "entities": []}, {"text": "There are six testing sets in.", "labels": [], "entities": []}, {"text": "Four of them are tweets: Twitter13, Twitter14, Twitter14Sarcasm, and Twitter15.", "labels": [], "entities": []}, {"text": "The TwitterSarcasm14 consists of the tweets which express sarcasm.", "labels": [], "entities": []}, {"text": "In order to evaluate the performance on out-of-domain data, the other two datasets are LiveJournal14 and SMS13 that are from web blogs and SMS messages respectively.", "labels": [], "entities": []}, {"text": "The details of these datasets are described in.", "labels": [], "entities": []}, {"text": "* Contribution during internship at Microsoft Research.", "labels": [], "entities": []}, {"text": "We utilize both basic features and deep learning features in our system.", "labels": [], "entities": []}, {"text": "Deep learning is used to automatically learn representations, which has achieved some promising results on sentiment analysis).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.9532324373722076}]}, {"text": "In order to design more flexible features, we use a two-stage classification framework which conducts subjective/objective (sub/obj) classification and positive/negative (pos/neg) classification.", "labels": [], "entities": []}, {"text": "In addition, we introduce a polarity boosting trick that can utilize pos/neg training data to improve classifying tweets to sub/obj.", "labels": [], "entities": []}, {"text": "With the help of these features and methods, our system achieves the best results on three out of six datasets among 40 teams in SemEval-2015.", "labels": [], "entities": []}, {"text": "We describe the basic features and deep learning features used in our system, and compare their contributions.", "labels": [], "entities": []}, {"text": "Moreover, we make the word2vec clustering results on Twitter data publicly available for research purpose.", "labels": [], "entities": []}], "datasetContent": [{"text": "The macro-averaged F1-score of positive and negative classes is used as the evaluation metric.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9523520469665527}]}, {"text": "Notably, this evaluation metric also takes the neutral class into consideration.", "labels": [], "entities": []}, {"text": "We train the model on TRAIN/DEV (7,072/1,120) provided in SemEval-2013.", "labels": [], "entities": [{"text": "TRAIN/DEV", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.8405833641688029}, {"text": "SemEval-2013", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9233385324478149}]}], "tableCaptions": [{"text": " Table 3: Results of ablation experiments.", "labels": [], "entities": []}, {"text": " Table 2: We compare the macro-averaged F1-scores of  our system (Spp) with the best results of other teams  in SemEval-2015. Our system achieves the highest F1- scores on three out of six datasets.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9714030027389526}, {"text": "F1- scores", "start_pos": 158, "end_pos": 168, "type": "METRIC", "confidence": 0.9878526131312052}]}]}