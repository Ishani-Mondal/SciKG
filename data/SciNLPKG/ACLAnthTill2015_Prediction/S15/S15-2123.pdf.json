{"title": [{"text": "UFRGS: Identifying Categories and Targets in Customer Reviews", "labels": [], "entities": [{"text": "UFRGS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8276795148849487}]}], "abstractContent": [{"text": "This paper reports on our participation in SemEval-2015 Task 12, which was devoted to Aspect-Based Sentiment Analysis.", "labels": [], "entities": [{"text": "SemEval-2015 Task 12", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.8884268403053284}, {"text": "Aspect-Based Sentiment Analysis", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7696013649304708}]}, {"text": "Participants were required to identify the category (entity and attribute), the opinion target, and the polarity of customer reviews.", "labels": [], "entities": []}, {"text": "The system we built relies on classification algorithms to identify aspect categories and on a set of rules to identify the opinion target.", "labels": [], "entities": []}, {"text": "We propose a two-phase classification approach for category identification and use a simple method for polarity detection.", "labels": [], "entities": [{"text": "category identification", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.896477609872818}, {"text": "polarity detection", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.7603933215141296}]}, {"text": "Our results outperform the baseline in many cases, which means our system could be used as an alternative for aspect classification.", "labels": [], "entities": [{"text": "aspect classification", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.941746324300766}]}], "introductionContent": [{"text": "Aspect Based Sentiment Analysis aims at discovering the opinions or sentiments expressed by a user on the different aspects of a given entity (.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8394051790237427}]}, {"text": "Recently, a number of methods and techniques have been developed to tackle this task and some of them rely on syntactic dependencies to locate the opinion target (.", "labels": [], "entities": []}, {"text": "A syntactic parser takes a natural language sentence as input and outputs the relationships between the words in the sentence.", "labels": [], "entities": []}, {"text": "shows the dependency tree for the sentence \"The phone has a good screen.\" and the grammatical relations of each token (det, subj, mod, obj).", "labels": [], "entities": []}, {"text": "We explore using grammatical relations to help identify the opinion targets.", "labels": [], "entities": []}, {"text": "In this paper, we describe a system which took part on, and the way it was applied can't write enough good things about this camera,\" \"things\" is extracted as an aspect because it is modified by the opinion word \"good.\"", "labels": [], "entities": []}, {"text": "However, \"things\" is very unlikely to be a product aspect and thus should be pruned.", "labels": [], "entities": []}, {"text": "We propose to use WordNet to automatically generate a list of general words using three typical general words \"thing,\" \"person,\" and \"place\" as seeds.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9472874999046326}]}, {"text": "By extending the DP method with the knowledge that a general word is normally not an aspect, we obtain a major improvement in the precision with almost no drop in recall on a widely used benchmark data set.", "labels": [], "entities": [{"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.999607503414154}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9984079003334045}]}, {"text": "In summary, we make two contributions: (1) We propose to employ Answer Set Programming (ASP) -a variant of Logic Programming -to implement syntactical approach based aspect extraction.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 166, "end_pos": 183, "type": "TASK", "confidence": 0.727007195353508}]}, {"text": "Our implementation of the DP method is more elegant and efficient, and it has only 8 rules, while a Java implementation has about 510 lines of code.", "labels": [], "entities": []}, {"text": "The ASP based implementation can process about 3000 sentences per second, while the Java implementation only processes about 300 sentences per second.", "labels": [], "entities": []}, {"text": "The preciseness and simplicity of the logic programming rules enable the sharing of knowledge used in aspect extraction and the reproducibility of experimental results.", "labels": [], "entities": [{"text": "preciseness", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9776146411895752}, {"text": "aspect extraction", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.8217731714248657}]}, {"text": "(2) We introduce the concept of general words based on WordNet and augment the DP method with the knowledge that general words normally should not betaken as aspects, which results in more accurate aspect extraction.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.9729363918304443}, {"text": "aspect extraction", "start_pos": 198, "end_pos": 215, "type": "TASK", "confidence": 0.7370046079158783}]}, {"text": "Again, the general words and new knowledge can be naturally implemented using ASP.", "labels": [], "entities": []}, {"text": "The remaining of the paper is organized as follows: we present background and related work in Section II and an overview of our logic programming approach in Section III.", "labels": [], "entities": []}, {"text": "The ASP rules to implement the DP method for extracting explicit aspects are described in Section IV.", "labels": [], "entities": [{"text": "ASP", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8259961605072021}]}, {"text": "Our new approach to aspect pruning is presented in Section V. We present the experiments in Section VI and conclude the paper and discuss future work in Section VII.", "labels": [], "entities": [{"text": "aspect pruning", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.8665831983089447}]}], "datasetContent": [{"text": "We experimented with all three datasets from Task 12, namely Restaurants (Res), Laptops (Lap), and Hidden (Hid) for which the domain was unknown.", "labels": [], "entities": []}, {"text": "Details on the datasets are in.", "labels": [], "entities": []}, {"text": "The evaluation occurs in two phases.", "labels": [], "entities": []}, {"text": "In the first phase, participating systems were evaluated on category detection for Restaurants and Laptops.", "labels": [], "entities": [{"text": "category detection", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.714931532740593}]}, {"text": "Additionally, identifying opinion target and the pair (category, target) was requested for the Restaurants domain.", "labels": [], "entities": []}, {"text": "In the second phase, the systems were evaluated on polarity detection on all three domains.", "labels": [], "entities": [{"text": "polarity detection", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7513485252857208}]}], "tableCaptions": [{"text": " Table 1: Opinion Category detection.  Domain Method  P  R  F1  Res  2Phase  0.6556 0.4323 0.5210  Res  1Phase  0.6835 0.4181 0.5188  Res  Baseline  0.5133  Res  1Phase-coref 0.6821 0.4180 0.5184  Res  2Phase-coref 0.6509 0.4090 0.5023  Lap  Baseline  0.4631  Lap  1Phase  0.5066 0.4040 0.4495  Lap  2Phase  0.4773 0.4209 0.4473  Lap  1Phase-coref 0.4834 0.4462 0.4640  Lap  2Phase-coref 0.4689 0.4388 0.4534", "labels": [], "entities": [{"text": "Opinion Category detection", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7657215595245361}]}, {"text": " Table 2: Opinion Target detection.  Domain Method  P  R  F1  Res  2Phase  0.5656 0.4373 0.4932  Res  1Phase  0.5764 0.4244 0.4888  Res  Baseline  0.4807  Res  2Phase-exc. 0.5632 0.4354 0.4911  Res  1Phase-exc. 0.5739 0.4225 0.4867", "labels": [], "entities": [{"text": "Opinion Target detection", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7548160552978516}]}, {"text": " Table 2. The results show that using such a list did  not impact the results.", "labels": [], "entities": []}, {"text": " Table 3: Opinion Category and Target pair detection.  Domain Method  P  R  F1  Res  2Phase  0.4852 0.2722 0.3487  Res  Baseline  0.3444  Res  1Phase  0.4521 0.2734 0.3407  Res  1Phase-coref 0.4694 0.2639 0.3378  Res  2Phase-coref 0.4496 0.2591 0.3288", "labels": [], "entities": [{"text": "Target pair detection", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.6486473580201467}]}]}