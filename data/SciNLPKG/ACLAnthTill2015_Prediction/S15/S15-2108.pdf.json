{"title": [{"text": "SeNTU: Sentiment Analysis of Tweets by Combining a Rule-based Classifier with Supervised Learning", "labels": [], "entities": [{"text": "Sentiment Analysis of Tweets", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.9319417327642441}]}], "abstractContent": [{"text": "We describe a Twitter sentiment analysis system developed by combining a rule-based classifier with supervised learning.", "labels": [], "entities": [{"text": "Twitter sentiment analysis", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.6565891206264496}]}, {"text": "We submitted our results for the message-level sub-task in SemEval 2015 Task 10, and achieved a F 1-score of 57.06%.", "labels": [], "entities": [{"text": "SemEval 2015 Task 10", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.6193326711654663}, {"text": "F 1-score", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9926024079322815}]}, {"text": "The rule-based classi-fier is based on rules that are dependent on the occurrences of emoticons and opinion words in tweets.", "labels": [], "entities": []}, {"text": "Whereas, the Support Vector Machine (SVM) is trained on semantic, dependency , and sentiment lexicon based features.", "labels": [], "entities": []}, {"text": "The tweets are classified as positive, negative or unknown by the rule-based classifier, and as positive, negative or neutral by the SVM.", "labels": [], "entities": [{"text": "SVM", "start_pos": 133, "end_pos": 136, "type": "DATASET", "confidence": 0.9310798645019531}]}, {"text": "The results we obtained show that rules can help refine the SVM's predictions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our opinions and the opinions of others play a very important role in our decision-making process and even influence our behaviour.", "labels": [], "entities": []}, {"text": "In recent times, an increasing number of people have taken to expressing their opinions on a wide variety of topics on microblogging websites such as Twitter.", "labels": [], "entities": []}, {"text": "Being able to analyse this data and extract opinions about a number of topics, can help us make informed choices and predictions regarding those topics.", "labels": [], "entities": []}, {"text": "Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (), politics (; Wang et We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this al., 2012), health and psychology; Harman, ; Harman, ), multimodality (, crowd validation (, and even intelligence and surveillance.) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.9020335972309113}, {"text": "F-score", "start_pos": 192, "end_pos": 199, "type": "METRIC", "confidence": 0.9945510029792786}, {"text": "crowd validation", "start_pos": 314, "end_pos": 330, "type": "TASK", "confidence": 0.733506828546524}]}, {"text": "We created a sentiment analysis system to participate in the message-level task of this competition.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9501406848430634}]}, {"text": "The objective of the system is to label the sentiment of each tweet as \"positive\", \"negative\" or \"neutral\".", "labels": [], "entities": []}, {"text": "In this paper, we describe our sentiment analysis system, which is a combined classifier created by integrating a rule-based classification layer with a support vector machine.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9407638013362885}]}], "datasetContent": [{"text": "We trained a Support Vector Machine (SVM) on 9418 tweets allowed to be used for training purposes.", "labels": [], "entities": []}, {"text": "The results we submitted to SemEval 2015 were yielded by using all SVM features and emoticon-related rules.", "labels": [], "entities": [{"text": "SemEval 2015", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.7416844069957733}]}, {"text": "The sentiment lexiconrelated rules were implemented later, and thus could not be used for the official submission.", "labels": [], "entities": []}, {"text": "shows the official test results for SemEval 2015.: Feature ablation study for the SVM classifier.", "labels": [], "entities": [{"text": "SemEval 2015.", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.6896573007106781}]}, {"text": "Each row shows the precision, recall, and F-score for the positive, negative, and neutral classes respectively, followed by the average positive and negative F-score, which is the chosen evaluation metric.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9995554089546204}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9975671768188477}, {"text": "F-score", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.9988829493522644}, {"text": "F-score", "start_pos": 158, "end_pos": 165, "type": "METRIC", "confidence": 0.9685977697372437}]}, {"text": "All values in the table are between 0 and 1, and are rounded off to 3 decimal places.", "labels": [], "entities": []}, {"text": "reports the results of a feature ablation study carried out by testing the SVM classifier on 3204 development tweets (from SemEval 2013) not included in the training data.", "labels": [], "entities": []}, {"text": "These are cross-validation results obtained using the hold-out method.This study helps us understand the importance of different features.", "labels": [], "entities": []}, {"text": "From the table, we can see that the word and character n-grams features are the most useful, followed by negation and then the rest.", "labels": [], "entities": [{"text": "negation", "start_pos": 105, "end_pos": 113, "type": "TASK", "confidence": 0.9465791583061218}]}, {"text": "All sentiment lexicon related features appear to have similar importance, but we get the best F-score when we append them all to the feature vector.", "labels": [], "entities": [{"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9978105425834656}]}], "tableCaptions": [{"text": " Table 1: Feature ablation study for the SVM classifier. Each row shows the precision, recall, and F-score for the  positive, negative, and neutral classes respectively, followed by the average positive and negative F-score, which is the  chosen evaluation metric. All values in the table are between 0 and 1, and are rounded off to 3 decimal places.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9994494318962097}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9942818880081177}, {"text": "F-score", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9986541271209717}, {"text": "F-score", "start_pos": 216, "end_pos": 223, "type": "METRIC", "confidence": 0.957590639591217}]}, {"text": " Table 2: Average positive and negative F-scores for sys- tem with all SVM features and only emoticon rules.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9891822934150696}]}, {"text": " Table 3: Comparison between the results obtained using  SVM alone, and using SVM with a rule-based layer.", "labels": [], "entities": []}]}