{"title": [{"text": "Leveraging Preposition Ambiguity to Assess Compositional Distributional Models of Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Complex interactions among the meanings of words are important factors in the function that maps word meanings to phrase meanings.", "labels": [], "entities": []}, {"text": "Recently, compositional distributional semantics models (CDSM) have been designed with the goal of emulating these complex interactions ; however, experimental results on the effectiveness of CDSM have been difficult to interpret because the current metrics for assessing them do not control for the confound of lexical information.", "labels": [], "entities": []}, {"text": "We present anew method for assessing the degree to which CDSM capture semantic interactions that dissociates the influences of lexical and compositional information.", "labels": [], "entities": []}, {"text": "We then provide a dataset for performing this type of assessment and use it to evaluate six compositional models using both co-occurrence based and neural language model input vectors.", "labels": [], "entities": []}, {"text": "Results show that neural language input vectors are consistently superior to co-occurrence based vectors, that several CDSM capture substantial compositional information, and that, surprisingly, vector addition matches and is in many cases superior to purpose-built paramaterized models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Consider the meanings of the following phrases: \"red apple,\" \"red hair,\" and \"red state.\"", "labels": [], "entities": []}, {"text": "The meaning of the word \"red\" in each of these examples interacts with the meaning of the noun it modifies, applying * Please address correspondence to the first author at swritter@princeton.edu a different color to the first two and apolitical affiliation to the third.", "labels": [], "entities": []}, {"text": "This is an example of a common phenomenon in natural language in which the meaning of a whole expression is not derived from a simple concatenation of its parts, but is composed by interactions among their meanings.", "labels": [], "entities": []}, {"text": "Cognitive and computer scientists have pointed out this complexity and proposed various models for accommodating it.", "labels": [], "entities": []}, {"text": "A dominant modeling approach seeks to learn functions that combine word representations derived from the distributional structure of large natural language corpora.", "labels": [], "entities": []}, {"text": "Because the word representations to be combined and the compositional functions are generated based on the distributions of words in corpora, these models have been dubbed compositional distributional semantic models, or CDSM ().", "labels": [], "entities": []}, {"text": "CDSM produce fixed-dimensional vector representations of arbitrary sentences and phrases, and the foundational principle of these models is, stated simply, that semantically similar phrases should have vector representations that are close together in the vector space.", "labels": [], "entities": []}], "datasetContent": [{"text": "A list of all of the spatial categories with examples is given in.", "labels": [], "entities": []}, {"text": "The authors chose the set of categories to produce the desired dissociation between lexical meaning and phrase category, taking inspiration from the observations of.", "labels": [], "entities": []}, {"text": "To produce a dataset of expressions fitting these categories, the first and second authors -both native English speakers -generated a large set of locative expressions, intending each expression fora specific category.", "labels": [], "entities": []}, {"text": "Then all of the expressions were independently rated by the first two authors, and any expression for which the ratings disagreed were excluded from the dataset.", "labels": [], "entities": []}, {"text": "In order to achieve a balanced category size, the second author then created additional sentences intended for underrepresented categories.", "labels": [], "entities": []}, {"text": "All additional sentences were stripped of labels and rated independently by the first author.", "labels": [], "entities": []}, {"text": "If the first and second authors' categorizations did not match, the sentence was not added to the dataset.", "labels": [], "entities": []}, {"text": "The dataset contains 500 sentences in total with 100 sentences per category.", "labels": [], "entities": []}, {"text": "There is a large amount of lexical variety in the set, with 242 distinct words occurring in noun position one and 213 occurring in noun position two.", "labels": [], "entities": []}, {"text": "The dataset is publicly available for download at www.princeton.edu/ \u223c swritter.", "labels": [], "entities": []}, {"text": "Classification among the five categories was performed using a naive Bayes classifier.", "labels": [], "entities": []}, {"text": "Two of the categories contained \"in\" as the preposition in all sentences while the other three contained \"on\" in all sentences.", "labels": [], "entities": []}, {"text": "To be certain that the held out sentences on which the classifier was tested did not contain even a single category-informative noun, we operationally defined informativeness and relegated all sentences with an informative noun to the training set.", "labels": [], "entities": []}, {"text": "A noun was deemed informative if it both occurred more than once in the entire data set and it occurred more frequently in one category than in any other.", "labels": [], "entities": []}, {"text": "This criterion yielded a set of 80 sentences with no informative nouns, and a set of 420 sentences with at least one informative noun.", "labels": [], "entities": []}, {"text": "By this method, we ensured that no component of the models' classification accuracy on the test set is due to the recognition of individual nouns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.8198016285896301}]}, {"text": "In addition to the CDSM, we included two nondistributional models for comparison.", "labels": [], "entities": [{"text": "CDSM", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.9407588839530945}]}, {"text": "The first, referred to as word overlap, consists of a binary feature vector containing one feature per vocabulary item.", "labels": [], "entities": [{"text": "word overlap", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.6638321578502655}]}, {"text": "This model's performance provides an upper-bound on the performance that a model can achieve given only the distribution of word tokens in the training set.", "labels": [], "entities": []}, {"text": "The second model, inspired by, contains binary features for Wordnet hypernyms (up to 4 levels) of each sense of the noun and a binary feature for each preposition.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9649654626846313}]}, {"text": "This model's score provides an indication of the amount of task-relevant information contained in the taxonomic features of individual words.", "labels": [], "entities": []}, {"text": "We compared CDSM to a further control that consisted of the concatenation of the word vectors.", "labels": [], "entities": []}, {"text": "The concatenated vectors contain a complete representation of all of the individual word information, so that any performance the CDSM can achieve above the concatenation score can be attributed to semantic interaction information contained in the parameters of the CDSM.", "labels": [], "entities": []}, {"text": "1 1 One other experiment we considered was to test the models on the dataset phrases with prepositions removed.", "labels": [], "entities": []}, {"text": "However, LF and PLF are undefined for such an input, and the element-wise models trivially perform better with the preposition included because the preposition is the only word that is not stripped of informativeness by design of the task.", "labels": [], "entities": [{"text": "PLF", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9081886410713196}]}, {"text": "As such, we excluded this experiment from this report.", "labels": [], "entities": []}], "tableCaptions": []}