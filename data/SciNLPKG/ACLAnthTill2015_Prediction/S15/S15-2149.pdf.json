{"title": [], "abstractContent": [{"text": "Human languages exhibit a variety of strategies for communicating spatial information, including toponyms, spatial nominals, locations that are described in relation to other locations , and movements along paths.", "labels": [], "entities": []}, {"text": "SpaceE-val is a combined information extraction and classification task with the goal of identifying and categorizing such spatial information.", "labels": [], "entities": [{"text": "information extraction and classification task", "start_pos": 25, "end_pos": 71, "type": "TASK", "confidence": 0.7258762955665589}]}, {"text": "In this paper, we describe the SpaceEval task, annotation schema, and corpora, and evaluate the performance of several supervised and semi-supervised machine learning systems developed with the goal of automating this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "SpaceEval builds on the Spatial Role Labeling (SpRL) task introduced in SemEval 2012) and used in SemEval 2013 ().", "labels": [], "entities": [{"text": "Spatial Role Labeling (SpRL) task", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.8091415677751813}]}, {"text": "The base annotation scheme of the previous tasks was introduced in, with empirical practices in (.", "labels": [], "entities": []}, {"text": "While those previous tasks are similar in their goal, SpacEval adopts the annotation specification from ISOspace (; ISO/TC 37/SC 4/WG 2, 2014), anew standard for capturing spatial information.", "labels": [], "entities": [{"text": "SpacEval", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.8640525341033936}, {"text": "ISOspace", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.980929970741272}, {"text": "ISO/TC 37/SC 4/WG 2, 2014)", "start_pos": 116, "end_pos": 142, "type": "DATASET", "confidence": 0.889221035517179}]}, {"text": "The SpRL in SemEval 2012 had a focus on the main roles of trajectors, landmarks, spatial indicators, and the links between these roles which form spatial relations.", "labels": [], "entities": [{"text": "SpRL in SemEval 2012", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.5718335807323456}]}, {"text": "The formal semantics of the relations were considered at a course-grained level, consisting of three types: directional, regional (topological), and distal.", "labels": [], "entities": []}, {"text": "The related annotated data, CLEF IAPR TC-12 Image Benchmark (), contained mostly static spatial relations.", "labels": [], "entities": [{"text": "CLEF IAPR TC-12 Image Benchmark", "start_pos": 28, "end_pos": 59, "type": "DATASET", "confidence": 0.7635169863700867}]}, {"text": "In SemEval 2013, the SpRL task was extended to the recognition of motion indicators and paths, which are applied to the more dynamic spatial relations.", "labels": [], "entities": [{"text": "SpRL task", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.829683929681778}]}, {"text": "Accordingly, the data set was expanded and the text from the Degree Confluence Project webpages were annotated.", "labels": [], "entities": [{"text": "Degree Confluence Project webpages", "start_pos": 61, "end_pos": 95, "type": "DATASET", "confidence": 0.7042374759912491}]}, {"text": "SpaceEval extends the task in several dimensions, first by enriching the granularity of the semantics in both static and dynamic spatial configurations, and secondly by broadening the variety of annotated data and the domains considered.", "labels": [], "entities": []}, {"text": "In SpaceEval the concept of place is distinguished from the concept of spatial entity as a fundamental typing distinction.", "labels": [], "entities": []}, {"text": "That is, the roles of trajector (figure) and landmark (ground) are roles that are assigned to spatial entities and places when occurring in spatial relations.", "labels": [], "entities": []}, {"text": "Places, however, are inherently typed as such, and remain places, regardless of what spatial roles they may occupy.", "labels": [], "entities": []}, {"text": "Obviously, an individual may assume multiple role assignments, and in both ISOspace and SpRL this is assumed to be the case.", "labels": [], "entities": [{"text": "ISOspace", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.8924753665924072}]}, {"text": "However, because SpRL focuses on role assignment, it does not introduce the general concept of spatial entity.", "labels": [], "entities": [{"text": "role assignment", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.7335757613182068}]}, {"text": "There are other differences in the relational schemas of SpRL and SpaceEval which can be easily mapped to each other.", "labels": [], "entities": []}, {"text": "For example, in SpRL the general concept of spatial relation is defined and the semantics of the relationship (e.g., directional, regional) is added as an attribute of the relation while in SpceEval these semantics introduce new types of relations (e.g., QSLINK and OLINK).", "labels": [], "entities": [{"text": "OLINK", "start_pos": 266, "end_pos": 271, "type": "METRIC", "confidence": 0.7810091972351074}]}, {"text": "In addition to the variations in relational schemas, there are some additional extensions in the SpaceEval annotation.", "labels": [], "entities": []}, {"text": "These include augmenting the main elements with more fine-grained attributes.", "labels": [], "entities": []}, {"text": "These attributes, in turn, impact the way the spatial semantics are interpreted.", "labels": [], "entities": []}, {"text": "For example, the spatial entities are described with their dimensionality, form, etc.", "labels": [], "entities": []}, {"text": "SpaceEval, also strongly highlights the concepts involved in dynamic spatial relations by introducing movelink relations and motion tags for annotating motion verbs or nominal motion events and their category from the perspective of spatial semantics.", "labels": [], "entities": []}, {"text": "These fine-grained annotations of all the relevant concepts that contribute to grasping spatial semantics makes this scheme and the accompanying corpus unique.", "labels": [], "entities": [{"text": "grasping spatial semantics", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.872107744216919}]}, {"text": "The details of the task, including the annotation schema, evaluation configurations, breakdown of the sub-tasks, data set, participant systems, and evaluation results are described in the rest of the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Not all groups attempted all of the evaluation configurations . The HRIJP-CRF-VW system was evaluated only for Configuration 1 tasks 1a, 1b, 1d, and 1e (not 1c), and Configuration 3 sub-tasks 3a and 3b.", "labels": [], "entities": []}, {"text": "HRIJP-CRF-VW was not evaluated for Configuration 2 since those sub-tasks were not attempted.", "labels": [], "entities": [{"text": "HRIJP-CRF-VW", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.5769056081771851}, {"text": "Configuration 2", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.8872842788696289}]}, {"text": "The UTD submission only covered Configuration 3, thus was only evaluated for sub-tasks 3a and 3b.", "labels": [], "entities": [{"text": "UTD submission", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9253950715065002}]}], "tableCaptions": [{"text": " Table 2. The scores for extent tags and  MOVELINK indicate high agreement, however link  tag annotation was less consistent for the remaining  link tags. Though the OLINK and QSLINK tag agree- ment is better than chance, it is not high. We believe  the lower agreement for these link tags reflects the  complexity of the annotation task.", "labels": [], "entities": [{"text": "MOVELINK", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9132348299026489}, {"text": "agreement", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9937736988067627}, {"text": "OLINK", "start_pos": 166, "end_pos": 171, "type": "METRIC", "confidence": 0.9897251129150391}, {"text": "QSLINK tag agree- ment", "start_pos": 176, "end_pos": 198, "type": "METRIC", "confidence": 0.7726052284240723}]}, {"text": " Table 2: Overall Fleiss's \u03ba Scores", "labels": [], "entities": [{"text": "Fleiss's \u03ba Scores", "start_pos": 18, "end_pos": 35, "type": "METRIC", "confidence": 0.9092186987400055}]}, {"text": " Table 4: Top Ten Positive Feature Weights", "labels": [], "entities": []}]}