{"title": [{"text": "SGRank: Combining Statistical and Graphical Methods to Improve the State of the Art in Unsupervised Keyphrase Extraction", "labels": [], "entities": []}], "abstractContent": [{"text": "Keyphrase extraction is a fundamental technique in natural language processing.", "labels": [], "entities": [{"text": "Keyphrase extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8719224035739899}, {"text": "natural language processing", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6411685049533844}]}, {"text": "It enables documents to be mapped to a concise set of phrases that can be used for indexing, clustering, ontology building, auto-tagging and other information organization schemes.", "labels": [], "entities": [{"text": "ontology building", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7222422361373901}]}, {"text": "Two major families of unsupervised keyphrase extraction algorithms maybe characterized as statistical and graph-based.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7565216422080994}]}, {"text": "We present a hybrid statistical-graphical algorithm that capitalizes on the heuristics of both families of algorithms and is able to outperform the state of the art in unsupervised keyphrase extraction on several datasets.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 181, "end_pos": 201, "type": "TASK", "confidence": 0.7374952733516693}]}], "introductionContent": [{"text": "Keyphrase extraction algorithms aim to extract, from within the document phrases and words that best represent the document's main topics.", "labels": [], "entities": [{"text": "Keyphrase extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8532153367996216}]}, {"text": "Being able to accurately determine what a document is about allows computers to cluster together documents that share topics (), better answer search queries (, and generate short document summaries).", "labels": [], "entities": []}, {"text": "Furthermore, keyphrase extraction can be used to facilitate the automatic construction of concept maps ( or ontologies () which enable better understanding of the interconnections and relations between different topics.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8535847663879395}]}, {"text": "Keyphrase extraction is also used in content-based recommender systems which help users in discovering information relevant to their previously expressed interests).", "labels": [], "entities": [{"text": "Keyphrase extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.824663519859314}]}, {"text": "The aforementioned techniques are all important tools in the organization and understanding of the ever expanding repositories of textual information available online in the form of research papers, news articles, blog posts, etc. and keyphrase extraction is central to all of them.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 235, "end_pos": 255, "type": "TASK", "confidence": 0.776417076587677}]}, {"text": "Therefore it could be said that keyphrase extraction is a fundamental NLP task, improvements in which could cascade into improvements in higher-level applications that build upon it.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.9104137122631073}]}, {"text": "In this work we have focused on unsupervised keyphrase extraction approaches as not only they are useful in domains where training data is hard to procure but even in the presence of ample training data word weights calculated using unsupervised methods can be used as one of several features in supervised keyphrase extraction algorithms.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7631320655345917}, {"text": "supervised keyphrase extraction", "start_pos": 296, "end_pos": 327, "type": "TASK", "confidence": 0.6464409927527109}]}, {"text": "Therefore increases in the accuracy of unsupervised methods can propagate into the results of supervised algorithms as well.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9986488223075867}]}, {"text": "There are two prominent families of unsupervised keyphrase extraction algorithms.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7500655353069305}]}, {"text": "The older of these two is clustered around the tf-idf term weighting metric where word statistics such as frequency of occurrence in the document or rareness in the corpus are used to distinguish potential keyphrases.", "labels": [], "entities": []}, {"text": "The more recently developed of the two families has been built on the foundation of the TextRank algorithm).", "labels": [], "entities": []}, {"text": "In algorithms of this family a graphical representation of the text is constructed with words as nodes and edges reflecting cooccurrence relations.", "labels": [], "entities": []}, {"text": "This graph is then used to run node ranking algorithms such as) that assign weights to the node-words reflecting their semantic importance to the text.", "labels": [], "entities": []}, {"text": "Although some overlap between these two families of algorithms has occurred in works that incorporate statistical heuristics into graph-based methods this overlap is small and most methods do not utilize the full set of statistical heuristics.", "labels": [], "entities": []}, {"text": "Our aim has been to 1) Construct a keyphrase extraction algorithm based on optimal statistical features and 2) Combine it with a graph-based algorithm for further improvements.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.8134357929229736}]}, {"text": "The advantage of graph-based methods is that they take into account term co-occurrence patterns that are not generally utilized by statistical methods which take a bag of n-grams approach to document representation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our keyphrase extraction algorithm by comparing it to two state-of-the-art algorithms, KP-Miner and TextRank, on three datasets: The Semeval 2010 keyphrase extraction shared task dataset, the Inspec dataset of ACM abstracts and the Krapivin dataset of full length papers.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8682302832603455}, {"text": "Semeval 2010 keyphrase extraction shared task", "start_pos": 145, "end_pos": 190, "type": "TASK", "confidence": 0.646432414650917}, {"text": "Inspec dataset of ACM abstracts", "start_pos": 204, "end_pos": 235, "type": "DATASET", "confidence": 0.8815045475959777}, {"text": "Krapivin dataset of full length papers", "start_pos": 244, "end_pos": 282, "type": "DATASET", "confidence": 0.8829879363377889}]}, {"text": "To obtain results for KP-Miner we have used an executable kindly shared with us by the system's author.", "labels": [], "entities": []}, {"text": "For TextRank we have built on an existing open source implementation.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.880306601524353}]}, {"text": "The comparisons between the algorithms are done using the precision and recall at k metric where the top k terms returned by each algorithm are used to measure precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9991719722747803}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9951179027557373}, {"text": "precision", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9990185499191284}, {"text": "recall", "start_pos": 174, "end_pos": 180, "type": "METRIC", "confidence": 0.9956468939781189}]}, {"text": "Here k ranges from 1 to 15.", "labels": [], "entities": []}, {"text": "We also calculate the F-measure fork = 5, 10 and 15.", "labels": [], "entities": [{"text": "F-measure fork", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.9811489582061768}]}, {"text": "In the following section we describe each dataset in detail and report the results achieved by each algorithm on each dataset.", "labels": [], "entities": []}, {"text": "The Semeval and Inspec datasets have also been used by  The Semeval dataset was used in the Semeval 2010 keyphrase extraction shared task (.", "labels": [], "entities": [{"text": "Inspec datasets", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.7993147075176239}, {"text": "Semeval dataset", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.6686801165342331}, {"text": "Semeval 2010 keyphrase extraction shared task", "start_pos": 92, "end_pos": 137, "type": "TASK", "confidence": 0.7636791268984476}]}, {"text": "To the best of our knowledge this shared task is the largest recent comparison of keyphrase extraction algorithms and an algorithm's performance on this dataset is a relatively good indication of where it stands compared to others in the field.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.8074674308300018}]}, {"text": "The Semeval dataset consists of 284 full length ACM articles divided into a test set of size 100, training set of size 144 and trial set of size 40 which we used as the development set for parameter tuning.", "labels": [], "entities": [{"text": "Semeval dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.7086128443479538}, {"text": "parameter tuning", "start_pos": 189, "end_pos": 205, "type": "TASK", "confidence": 0.7208816111087799}]}, {"text": "Each article has two sets of human assigned keyphrases: the author-assigned and reader-assigned ones.", "labels": [], "entities": []}, {"text": "The gold standard used in our experiments is the combined set of author and reader assigned keyphrases which is the same as was done in the Semeval shared task.", "labels": [], "entities": []}, {"text": "The We have compared our algorithm with KPMiner and TextRank using only the 100 documents in the test set.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.9228915572166443}]}, {"text": "The following diagram shows the average precision and recall achieved by each algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9992376565933228}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9994173049926758}]}, {"text": "As was done in the Semeval task, comparisons are done between once stemmed human assigned keyphrases and ranked candidates returned by each algorithm.", "labels": [], "entities": []}, {"text": "The following table shows the achieved Fmeasure for each algorithm at k=5, 10 and 15.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9818856120109558}]}, {"text": "It also contains the corresponding percentage improvement at each k.", "labels": [], "entities": []}, {"text": "The statistical significance of each improvement is measured using a 2-sided paired t-test.", "labels": [], "entities": []}, {"text": "Improvements are in bold font where they are statistically significant at p < 0.05.", "labels": [], "entities": []}, {"text": "As can be seen from the above results our method outperforms KP-Miner in both precision and recall for all k and achieves statistically significant improvements in the F-measure over KP-Miner for k=10 and 15.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9995601773262024}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9992963075637817}, {"text": "F-measure", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9989390969276428}]}, {"text": "These results are noteworthy considering that in the Semeval keyphrase extraction shared task KP-Miner was the best performing unsupervised algorithm, and the second best overall out of 19 systems, outperforming prominent supervised algorithms such as Maui (.", "labels": [], "entities": [{"text": "Semeval keyphrase extraction shared task KP-Miner", "start_pos": 53, "end_pos": 102, "type": "TASK", "confidence": 0.8592261672019958}]}, {"text": "TextRank seems to generally underperform on longer documents and has performed poorly on the Semeval dataset.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9412893652915955}, {"text": "Semeval dataset", "start_pos": 93, "end_pos": 108, "type": "DATASET", "confidence": 0.8949384689331055}]}, {"text": "The Inspec dataset is comprised of 2000 ACM abstracts divided into test, training and validation sets containing 500, 1000 and 500 abstracts respectively.", "labels": [], "entities": [{"text": "Inspec dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8899543881416321}]}, {"text": "We follow the same approach as taken by shows the average precision and recall for all three algorithms fork from 1 to 15.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9994474053382874}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9990150928497314}]}, {"text": "shows the F-measure improvements made by our method over the two other algorithms for k=5, 10 and 15.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9907269477844238}]}, {"text": "As these results show, on this dataset of relatively short documents, TextRank outperforms KP-Miner for k>2.", "labels": [], "entities": []}, {"text": "Our algorithm achieves higher precision and recall than both KP-Miner and TextRank for all k with statistically significant gains in the F-measure for k=5, 10 and 15.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9994555115699768}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.999629020690918}, {"text": "TextRank", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.9194828867912292}, {"text": "F-measure", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9978563189506531}]}, {"text": "The Krapivin dataset consists of 2000 full length ACM papers.", "labels": [], "entities": [{"text": "Krapivin dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8364406824111938}]}, {"text": "This dataset has been prepared by.", "labels": [], "entities": []}, {"text": "Each article has authorassigned and editor-corrected keyphrases that we use as the gold standard in our evaluation.", "labels": [], "entities": []}, {"text": "Our experiments are done on a 400-document subset of this dataset.", "labels": [], "entities": []}, {"text": "On this dataset keyphrases and candidate terms have been stemmed once before comparison.", "labels": [], "entities": []}, {"text": "Similar to the previously mentioned experiments we have measured the precision and recall of all three algorithms fork from 1 to 15 as shown in. contains the F-measures for all three algorithms at k=5, 10 and 15 along with the improvements made by our algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9993818998336792}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9983171224594116}, {"text": "F-measures", "start_pos": 158, "end_pos": 168, "type": "METRIC", "confidence": 0.9980223178863525}]}, {"text": "Similar to the Semeval dataset TextRank performs very poorly on this dataset of longer documents.", "labels": [], "entities": [{"text": "Semeval dataset TextRank", "start_pos": 15, "end_pos": 39, "type": "DATASET", "confidence": 0.826438307762146}]}, {"text": "KPMiner performs much better but both methods are outperformed by our method on all k with statistical significance as shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Semeval test set statistics.", "labels": [], "entities": []}, {"text": " Table 2. Semeval F-measures and improvements.", "labels": [], "entities": [{"text": "Semeval F-measures", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6904590725898743}]}, {"text": " Table 3. Inspec dataset statistics.", "labels": [], "entities": [{"text": "Inspec dataset statistics", "start_pos": 10, "end_pos": 35, "type": "DATASET", "confidence": 0.8125302493572235}]}, {"text": " Table 4. Inspec F-measures and improvements.", "labels": [], "entities": [{"text": "Inspec F-measures", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8266072571277618}]}, {"text": " Table 5. Krapivin dataset statistics.", "labels": [], "entities": [{"text": "Krapivin dataset statistics", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.8642896413803101}]}, {"text": " Table 6. Krapivin F-measures and improvements.", "labels": [], "entities": [{"text": "Krapivin F-measures", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.3859150856733322}]}, {"text": " Table 7. Comparison with Advanced Graph-based  methods F-measures at K=10.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.8969343304634094}]}, {"text": " Table 7. Also worth noting is  KP-Miner's relatively poor performance on the  shorter documents of the Inspec dataset. This could  potentially be due to the fact that KP-Miner only  considers terms as candidates which occur on their  own in the text i.e. surrounded by punctuation  marks or stop words. In shorter documents it is  more likely that fewer keyphrases would occur in  such conditions in the text, causing them to be  eliminated early on by KP-Miner. Our algorithm  however considers all n-grams without requiring  that they occur on their own. This allows us to  consider more candidates and avoid a performance  reduction in shorter documents. However, there is  an advantage to eliminating terms that never occur  on their own. Many keyphrases are multi-words. In  some cases smaller parts of keyphrases tend to", "labels": [], "entities": [{"text": "Inspec dataset", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.9810548722743988}]}]}