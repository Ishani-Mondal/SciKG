{"title": [{"text": "USAAR-WLV: Hypernym Generation with Deep Neural Nets", "labels": [], "entities": [{"text": "USAAR-WLV", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9784026145935059}, {"text": "Hypernym Generation", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7947356998920441}]}], "abstractContent": [{"text": "This paper describes the USAAR-WLV tax-onomy induction system that participated in the Taxonomy Extraction Evaluation task of SemEval-2015.", "labels": [], "entities": [{"text": "USAAR-WLV", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.9281526207923889}, {"text": "Taxonomy Extraction Evaluation task of SemEval-2015", "start_pos": 87, "end_pos": 138, "type": "TASK", "confidence": 0.7826551496982574}]}, {"text": "We extend prior work on using vector space word embedding models for hypernym-hyponym extraction by simplifying the means to extract a projection matrix that transforms any hyponym to its hypernym.", "labels": [], "entities": [{"text": "hypernym-hyponym extraction", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.727422371506691}]}, {"text": "This is done by making use of function words, which are usually overlooked in vector space approaches to NLP.", "labels": [], "entities": []}, {"text": "Our system performs best in the chemical domain and has achieved competitive results in the overall evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditionally, broad-coverage semantic taxonomies such as CYC and WordNet ontology have been manually created with much effort and yet they suffer from coverage sparsity.", "labels": [], "entities": [{"text": "CYC", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.9535449743270874}]}, {"text": "This motivated the move towards unsupervised approaches to extract structured relational knowledge from texts (.", "labels": [], "entities": []}, {"text": "Previous work in taxonomy extraction focused on rule-based, clustering and graph-based approaches.", "labels": [], "entities": [{"text": "taxonomy extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9169703125953674}]}, {"text": "Although vector space approaches are popular in current NLP researches, ontology induction studies have yet to catch on the frenzy.", "labels": [], "entities": [{"text": "ontology induction", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.8692807853221893}]}, {"text": "proposed a vector space approach to hypernymhyponym identification using word embeddings that trains a projection matrix 2 that converts a hyponym vector to its hypernym.", "labels": [], "entities": [{"text": "hypernymhyponym identification", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.8011126816272736}]}, {"text": "However, their approach requires an existing hypernym-hyponym pairs for training before discovering new pairs.", "labels": [], "entities": []}, {"text": "Our system submitted to the SemEval-2015 taxonomy building task is most similar to the approach by in using word embeddings projections to identify hypernym-hyponym pairs.", "labels": [], "entities": [{"text": "SemEval-2015 taxonomy building task", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.7522831112146378}]}, {"text": "As opposed to previous method our method does not requires prior taxonomical knowledge.", "labels": [], "entities": []}, {"text": "Instead of training a projection matrix, we capitalize on the fact that hypernym-hyponym pair often occurs in a sentence with an 'is a' phrase, e.g. \"The goldfish (Carassius auratus auratus) is a freshwater fish\".", "labels": [], "entities": []}, {"text": "3 Intuitively, if we single-tokenize the 'is a' phrase prior to training a vector space, we can make use of the vector that represents the phrase in capturing a hypernym-hyponym pair as such the multiplication of v(goldfish) and v(is-a) will be similar to the cross product v(fish) There is little or no previous work that manipulates non-content word vectors in vector space models studies for natural language processing.", "labels": [], "entities": []}, {"text": "Often, non-content words were implicitly incorporated into the vector space models by means of syntactic frames () or syntactic parses (.", "labels": [], "entities": []}, {"text": "Our main contribution for ontological induction using vector space models are primarily (i) the use of non-content word vectors and (ii) simplifying a previously complex process of learning a hypernymhyponym transition matrix.", "labels": [], "entities": [{"text": "ontological induction", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.8968691229820251}]}, {"text": "The implementation of our ontological induction approach is open-sourced and available on our GitHub repository.", "labels": [], "entities": [{"text": "ontological induction", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.714479610323906}, {"text": "GitHub repository", "start_pos": 94, "end_pos": 111, "type": "DATASET", "confidence": 0.9101704359054565}]}], "datasetContent": [{"text": "For the TaxEval task, the multi-faceted evaluation scheme presented in Navigli (2013) was adopted to compare the overall structure of the taxonomy against a gold standard, with an approach used for comparing hierarchical clusters.", "labels": [], "entities": []}, {"text": "The multi-faceted  evaluation scheme evaluates (i) the structural measures of the induced taxonomy (left columns of Table 1), (ii) the comparison against gold standard taxonomy (right columns of and leftmost column of) and (iii) manual evaluation of novel edges precision (last row of).", "labels": [], "entities": [{"text": "precision", "start_pos": 262, "end_pos": 271, "type": "METRIC", "confidence": 0.7684720158576965}]}, {"text": "Regarding the two types of automatic evaluation measures, the structural measures provides a gauge of the system's coverage and the ontology structural integrity, i.e. \"tree-likeness\" of the ontology produced by the hypernym-hyponym pairs, and the comparison against the gold standards gives an objective measure of the \"human-likeness\" of the system in producing a taxonomy that is similar to the manually-crafted taxonomy.", "labels": [], "entities": []}, {"text": "presents the evaluation scores for our system in the TaxEval task, the %VC and %EC scores summarize the performance of the system in replicating the gold standard taxonomies.", "labels": [], "entities": [{"text": "VC", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.9379348754882812}, {"text": "EC", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.7976943254470825}]}], "tableCaptions": [{"text": " Table 1: Structural Measures and Comparison against Gold Standards for USAAR-WLV. The labels of the columns  refer to no. of distinct vertices and edges in induced taxonomy (|V| and |E|), no. of connected components (#c.c),  whether the taxonomy is a Directed Acyclic Graph (cycles), vertex and edge coverage, i.e. proportion of gold standard  vertices and edges covered by system (%VC and %EC), no. of vertices and edges in common with gold standard  (#VC and #EC) and ratio of novel edges (:NE).", "labels": [], "entities": [{"text": "Structural Measures", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.879043847322464}, {"text": "USAAR-WLV", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.9792237281799316}]}, {"text": " Table 2: Averaged F&M Measure, Precision, Recall, F-score for All Systems Outputs when Compared to Gold Stan- dard and Manually Evaluated Average Precision of Novel Edges.", "labels": [], "entities": [{"text": "Averaged", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9740589261054993}, {"text": "F&M Measure", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.8105210214853287}, {"text": "Precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.5820577144622803}, {"text": "Recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9655869603157043}, {"text": "F-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9933673739433289}]}]}