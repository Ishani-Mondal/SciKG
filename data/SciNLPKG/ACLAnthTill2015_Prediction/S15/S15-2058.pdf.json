{"title": [{"text": "VUA-background : When to Use Background Information to Perform Word Sense Disambiguation", "labels": [], "entities": [{"text": "VUA-background", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.63126140832901}, {"text": "Perform Word Sense Disambiguation", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.7987447381019592}]}], "abstractContent": [{"text": "We present in this paper our submission to task 13 of SemEval2015, which makes use of background information and external resources (DBpedia and Wikipedia) to automatically disambiguate texts.", "labels": [], "entities": []}, {"text": "Our approach follows two routes for disambiguation: one route is proposed by a state-of-the-art WSD system , and the other one by the predominant sense information extracted in an unsuper-vised way from an automatically built background corpus.", "labels": [], "entities": []}, {"text": "We reached 4th position in terms of F1-score in task number 13 of Se-mEval2015: \"Multilingual All-Words Sense Disambiguation and Entity Linking\" (Moro and Navigli, 2015).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9994439482688904}, {"text": "Multilingual All-Words Sense Disambiguation and Entity Linking\" (Moro and Navigli, 2015)", "start_pos": 81, "end_pos": 169, "type": "TASK", "confidence": 0.7417465388774872}]}, {"text": "All the software and code created for this approach are publicly available on GitHub 1 .", "labels": [], "entities": [{"text": "GitHub 1", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9327428638935089}]}], "introductionContent": [{"text": "Word Sense Disambiguation is still an unsolved problem in Natural Language Processing.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6712609728177389}]}, {"text": "Many different approaches have been proposed throughout the years to tackle this task from different perspectives.", "labels": [], "entities": []}, {"text": "In addition, competitions have been organized to compare the performance of these approaches.", "labels": [], "entities": []}, {"text": "Our hypothesis is that, in general, the context is not being modelled properly by the systems, which usually consider very narrow contexts and do not pay any attention to the background information or information that is not explicitly included in the text.", "labels": [], "entities": []}, {"text": "We conducted an in-depth error analysis of previous all-words tasks (Senseval-2 : English all words (), Senseval-3 : English all words (), Semeval-2007 : all words task 17 (, Semeval-2010 : all words task 17 (), Semeval-2013 : all words task 12) in order to gain better insight as to why some approaches perform better than others, to detect problems not properly addressed and to try to overcome them.", "labels": [], "entities": []}, {"text": "We observed that most systems tend to rely on local features (words surrounding the words in question) to perform word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 114, "end_pos": 139, "type": "TASK", "confidence": 0.714214930931727}]}, {"text": "Besides this, there is a very acute trend by all WSD systems to assign inmost cases the most frequent sense, regardless the domain under consideration, as can be seen in shows the average accuracy of all the systems per competition.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9970957040786743}]}, {"text": "We clearly observe the trend that systems perform well when the sense is the most frequent sense, but not in other cases.", "labels": [], "entities": []}, {"text": "Furthermore, when the sense is not the most frequent one, the systems still propose the most frequent sense.", "labels": [], "entities": []}, {"text": "For instance in Senseval-2, out of 799 tokens for which the correct sense is not the most frequent one, systems still wrongly assign the most frequent sense in 84% of the cases.", "labels": [], "entities": []}, {"text": "Based on these observations, we designed a system that creates background corpora starting from a set of seed documents, from now on SD (preferably from a specific and unique domain).", "labels": [], "entities": []}, {"text": "From this corpus, we use the entities automatically detected to access DBpedia and create the first background corpus, which will be called Entity Article (EA) corpus.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.930152177810669}]}, {"text": "By applying different techniques, we expand this EA corpus with more domain related documents, which results in the Entity Expanded (EE) corpus.", "labels": [], "entities": []}, {"text": "Once the whole background corpus (EA+EE) has been created, we use this information to automatically derive the specific predominant sense of each word in our target domain (the domain of the starting documents and also the domain of the background corpus).", "labels": [], "entities": []}, {"text": "The rationale behind this approach starts with the observation that the predominant sense of a lemma is very dominant in a document.", "labels": [], "entities": []}, {"text": "Hence, by focusing on when to use or not to use this predominant sense, a high performance seems plausible.", "labels": [], "entities": []}, {"text": "In addition, we observed that local features are not always enough to determine the correct sense of a lemma and we should only rely on these features when they are necessary.", "labels": [], "entities": []}, {"text": "The structure of this paper is as follows.", "labels": [], "entities": []}, {"text": "We introduce our approach in section 2.", "labels": [], "entities": []}, {"text": "followed by the results in section 3.", "labels": [], "entities": []}, {"text": "Finally we discuss and conclude our results in section 4.", "labels": [], "entities": []}, {"text": "shows the overall architecture of our system, that will be explained more in detail in this section.", "labels": [], "entities": []}, {"text": "Seed documents: We focused on the WSD part of the task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9115813970565796}]}, {"text": "The input for our approach is a collection of seed documents, which represent the target domain that is used for calculating the predominant domain information.", "labels": [], "entities": []}, {"text": "These documents can either be the task test documents (online approach) or a different set of documents that we could compile in advance if the target domain is known (offline approach).", "labels": [], "entities": []}, {"text": "We first converted these documents to the NAF format (.", "labels": [], "entities": [{"text": "NAF format", "start_pos": 42, "end_pos": 52, "type": "DATASET", "confidence": 0.9396073222160339}]}, {"text": "We then applied a POStagger to get the lemmas and part-of-speech labels for all the tokens.", "labels": [], "entities": []}, {"text": "As explained before, two different approaches were followed: online and offline.", "labels": [], "entities": []}, {"text": "We experimented with both approaches and finally the online approach was selected for our participation due to the mixed-domain nature of the test documents.", "labels": [], "entities": []}, {"text": "The documents follow two different and parallel routes of analysis: one route which favors the domain predominant sense by using the background knowledge and one route which favors the most frequent sense (in a general domain) by using one of the state-of-the-art WSD systems that performs very well in such domains.", "labels": [], "entities": []}, {"text": "Finally, a voting heuristic of the two routes is applied to assign the final senses.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of VUA-background are shown for the  domains: 'All', 'Social issues', 'Math Computer, and  'Biomedical'. The results per domain are presented for  all part of speeches, as well as for nouns and verbs. The  numbers in parentheses are competition ranks.", "labels": [], "entities": [{"text": "VUA-background", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.8095677495002747}]}]}