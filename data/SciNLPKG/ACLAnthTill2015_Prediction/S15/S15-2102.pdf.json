{"title": [{"text": "INESC-ID: A Regression Model for Large Scale Twitter Sentiment Lexicon Induction", "labels": [], "entities": [{"text": "INESC-ID", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7636190056800842}, {"text": "Twitter Sentiment Lexicon Induction", "start_pos": 45, "end_pos": 80, "type": "TASK", "confidence": 0.6493346020579338}]}], "abstractContent": [{"text": "We present the approach followed by INESC-ID in the SemEval 2015 Twitter Sentiment Analysis challenge, subtask E.", "labels": [], "entities": [{"text": "SemEval 2015 Twitter Sentiment Analysis challenge", "start_pos": 52, "end_pos": 101, "type": "TASK", "confidence": 0.7838287154833475}]}, {"text": "The goal was to determine the strength of the association of Twitter terms with positive sentiment.", "labels": [], "entities": []}, {"text": "Using two labeled lexicons, we trained a regression model to predict the sentiment polarity and intensity of words and phrases.", "labels": [], "entities": []}, {"text": "Terms were represented as word embeddings induced in an unsupervised fashion from a corpus of tweets.", "labels": [], "entities": []}, {"text": "Our system attained the top ranking submission , attesting the general adequacy of the proposed approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment lexicons are one of the key resources for the automatic analysis of opinions, emotive and subjective text.", "labels": [], "entities": []}, {"text": "They compile words annotated with their prior polarity of sentiment, regardless of the context.", "labels": [], "entities": []}, {"text": "For instance, words such as beautiful or amazing tend to express a positive sentiment, whereas words like boring or ugly are considered negative.", "labels": [], "entities": []}, {"text": "Most sentiment analysis systems use either word count methods, based on sentiment lexicons, or rely on text classifiers.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.9478978216648102}]}, {"text": "In the former, the polarity of a message is estimated by computing the ratio of (positive and negative) sentiment bearing words.", "labels": [], "entities": []}, {"text": "Despite its simplicity, this method has been widely used.", "labels": [], "entities": []}, {"text": "Even more sophisticated systems, based on supervised classification, can be greatly improved with features derived from lexicons ().", "labels": [], "entities": []}, {"text": "However, manually created sentiment lexicons consist of few carefully selected words.", "labels": [], "entities": []}, {"text": "Consequently, they fail to capture the use of non-conventional word spelling and slang, commonly found in social media.", "labels": [], "entities": []}, {"text": "This problem motivated the creation of a task in the SemEval 2015 Twitter Sentiment Analysis challenge.", "labels": [], "entities": [{"text": "SemEval 2015 Twitter Sentiment Analysis challenge", "start_pos": 53, "end_pos": 102, "type": "TASK", "confidence": 0.9174337784449259}]}, {"text": "This task (subtask E), intended to evaluate automatic methods of generating Twitter specific sentiment lexicons.", "labels": [], "entities": [{"text": "generating Twitter specific sentiment lexicons", "start_pos": 65, "end_pos": 111, "type": "TASK", "confidence": 0.6279059410095215}]}, {"text": "Given a set of words or phrases, the goal was to assign a score between 0 and 1, reflecting the intensity and polarity of sentiment these terms express.", "labels": [], "entities": []}, {"text": "Participants were asked to submit a list, with the candidate terms ranked according to sentiment score.", "labels": [], "entities": []}, {"text": "This list was then compared to a ranked list obtained from human annotations and the submissions were evaluated using the Tau rank correlation metric.", "labels": [], "entities": []}, {"text": "In this paper, we describe a system developed for this challenge, based on a novel method to create large scale, domain-specific sentiment lexicons.", "labels": [], "entities": []}, {"text": "The task is addressed as a regression problem, in which terms are represented as word embeddings, induced from a corpus of 52 million tweets.", "labels": [], "entities": []}, {"text": "Then, using manually annotated lexicons, a regression model was trained to predict the polarity and intensity of sentiment of any word or phrase from that corpus.", "labels": [], "entities": []}, {"text": "We found this approach to be effective for the proposed problem.", "labels": [], "entities": []}, {"text": "The rest of the paper proceeds as follows: we review the work related to lexicon expansion in Section 2 and describe the methods used to derive word embeddings in Section 3.", "labels": [], "entities": [{"text": "lexicon expansion", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7676875591278076}]}, {"text": "Our approach and the experimental results are presented in Sections 5 and 6, respectively.", "labels": [], "entities": []}, {"text": "We conclude in Section 7.", "labels": [], "entities": []}, {"text": "Most of the literature on automatic lexicon expansion consists of dictionary-based or corpora-based approaches.", "labels": [], "entities": [{"text": "automatic lexicon expansion", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.699251393477122}]}, {"text": "In the former, the main idea is to use a dictionary, such as WordNet, to extract semantic relations between words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.9599393010139465}]}, {"text": "simply assign the same polarity to synonyms and the opposite polarity to antonyms, of known words.", "labels": [], "entities": []}, {"text": "Others, create a graph from the semantic relationships, to find new sentiment words and their polarity.", "labels": [], "entities": []}, {"text": "Using the seed words, new terms are classified using a distance measure (), or propagating the labels along the edges of the graph).", "labels": [], "entities": []}, {"text": "However, given that dictionaries mostly describe conventional language, these methods are unsuited for social media.", "labels": [], "entities": []}, {"text": "Corpora based approaches follow the assumption that the polarity of new words can be inferred from co-occurrence patterns with known words.", "labels": [], "entities": []}, {"text": "Hatzivassiloglou and McKeown (1997) discovered new polar adjectives by looking at conjunctions found in a corpus.", "labels": [], "entities": []}, {"text": "The adjectives connected with and got the same polarity, whereas adjectives connected with but were assigned opposing polarities.", "labels": [], "entities": []}, {"text": "Turney and Littman (2003) created two small sets of prototypical polar words, one containing positive and another containing negative examples.", "labels": [], "entities": []}, {"text": "The polarity of anew term was computed using the point-wise mutual information between that word and each of the prototypical sets.", "labels": [], "entities": []}, {"text": "The same method was used by, to create large scale sentiment lexicons for Twitter.", "labels": [], "entities": []}, {"text": "A recently proposed alternative is to learn word embeddings specific for Twitter sentiment analysis, using distant supervision ().", "labels": [], "entities": [{"text": "Twitter sentiment analysis", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.648506373167038}]}, {"text": "The resulting features are then used in a supervised classifier to predict the polarity of phrases.", "labels": [], "entities": []}, {"text": "This work is the most related to our approach, but it differs in the sense that we use general word embeddings, learned from unlabeled data, and predict both polarity and intensity of sentiment.", "labels": [], "entities": []}], "datasetContent": [{"text": "Learning word embeddings from large corpora allowed us to derive representations fora considerable number of words.", "labels": [], "entities": []}, {"text": "Thus, we were able to find embeddings for 94% of the candidate terms.", "labels": [], "entities": []}, {"text": "Using simple normalization steps, we could find embeddings for the remaining terms.", "labels": [], "entities": []}, {"text": "However, we found that this improvement in recall had almost no impact in the performance of the system.", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9996070265769958}]}, {"text": "After mapping terms to their respective embeddings, we performed experiments to find the best regression model and respective hyperparameters.", "labels": [], "entities": []}, {"text": "For this purpose, the LabMT lexicon was employed as the development set and the trial data as a validation set, against which different configurations were evaluated.", "labels": [], "entities": [{"text": "LabMT lexicon", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.9551187753677368}]}, {"text": "After 1000 trials, the SVR model with RBF kernel was selected.", "labels": [], "entities": [{"text": "SVR", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.7950399518013}, {"text": "RBF", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.8646327257156372}]}, {"text": "Finally, we performed detailed experiments to compare word embedding models and vectors of different dimensions.", "labels": [], "entities": []}], "tableCaptions": []}