{"title": [{"text": "Reading Between the Lines: Overcoming Data Sparsity for Accurate Classification of Lexical Relationships", "labels": [], "entities": [{"text": "Accurate Classification of Lexical Relationships", "start_pos": 56, "end_pos": 104, "type": "TASK", "confidence": 0.7598691582679749}]}], "abstractContent": [{"text": "The lexical semantic relationships between word pairs are key features for many NLP tasks.", "labels": [], "entities": []}, {"text": "Most approaches for automatically classifying related word pairs are hindered by data sparsity because of their need to observe two words co-occurring in order to detect the lexical relation holding between them.", "labels": [], "entities": [{"text": "automatically classifying related word pairs", "start_pos": 20, "end_pos": 64, "type": "TASK", "confidence": 0.7127422153949737}]}, {"text": "Even when mining very large corpora, not every related word pair co-occurs.", "labels": [], "entities": []}, {"text": "Using novel representations based on graphs and word embeddings, we present two systems that are able to predict relations between words, even when these are never found in the same sentence in a given corpus.", "labels": [], "entities": []}, {"text": "In two experiments, we demonstrate superior performance of both approaches over the state of the art, achieving significant gains in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9980402588844299}]}], "introductionContent": [{"text": "Resources containing lexical-semantic relations such as hypernymy or meronymy have proven useful in many NLP tasks.", "labels": [], "entities": []}, {"text": "While resources such as WordNet contain many general relations and subsequently have seen widespread adoption, developing this type of rich resource for new languages or for new domains is prohibitively costly and time-consuming.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.9299622178077698}]}, {"text": "Therefore, automated approaches are needed and, in order to create such a lexical-semantic database, a first step is to develop accurate techniques for classifying the type of lexical-semantic relationship between two words.", "labels": [], "entities": []}, {"text": "Approaches to classifying the relationship between a word pair have typically relied on the assumption that contexts where word pairs co-occur will yield information on the semantic relation (if any) between them.", "labels": [], "entities": [{"text": "classifying the relationship between a word pair", "start_pos": 14, "end_pos": 62, "type": "TASK", "confidence": 0.7864865916115897}]}, {"text": "Given a set of example word pairs having some relation, relation-specific patterns maybe automatically acquired from the contexts in which these example pairs co-occur.", "labels": [], "entities": []}, {"text": "Comparing these relation-specific patterns with those seen with other word pairs measures relational similarity, i.e., how similar is the relation holding between two word pairs.", "labels": [], "entities": []}, {"text": "However, any classification system based on patterns of co-occurrence is limited to only those words co-occurring in the data considered; due to the Zipfian distribution of words, even in a very large corpus there are always semantically related word pairs that do not co-occur.", "labels": [], "entities": []}, {"text": "As a result, these patternbased approaches have a strict upper-bound limit on the number of instances that they can classify.", "labels": [], "entities": []}, {"text": "As an alternative to requiring co-occurrence, other works have classified the relation of a word pair using lexical similarity, i.e., the similarity of the concepts themselves.", "labels": [], "entities": []}, {"text": "Given two word pairs, (w 1 , w 2 ) and (w 3 , w 4 ), if w 1 is lexically similar tow 3 and w 2 tow 4 (i.e., are pair-wise similar) then the pairs are said to have the same semantic relation.", "labels": [], "entities": []}, {"text": "These two sources of information are used as two independent units: relational similarity is calculated using co-occurrence information; lexical similarity is calculated using distributional information (, and ultimately these scores are combined.", "labels": [], "entities": []}, {"text": "Experimental evidence has shown that relational similarity cannot necessarily be revealed through lexical similarity, and therefore, the issue of how to collect in-formation for word pairs that do not co-occur is still an open problem.", "labels": [], "entities": []}, {"text": "We propose two new approaches to representing word pairs in order to accurately classify them as instances of lexical-semantic relations -even when the pair members do not co-occur.", "labels": [], "entities": []}, {"text": "The first approach creates a word pair representation based on a graph representation of the corpus created with dependency relations.", "labels": [], "entities": []}, {"text": "The graph encodes the distributional behavior of each word in the pair and consequently, patterns of co-occurrence expressing each target relation are extracted from it as relational information.", "labels": [], "entities": []}, {"text": "The second approach uses word embeddings which have been shown to preserve linear regularities among words and pairs of words, therefore, encoding lexical and relational similarities), a necessary property for our task.", "labels": [], "entities": []}, {"text": "In two experiments comparing with state-of-the-art pattern-based and embedding-based classifiers, we demonstrate that our approaches achieve higher accuracy with significantly increased recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9984602928161621}, {"text": "recall", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.9974205493927002}]}], "datasetContent": [{"text": "While several datasets have been created for detecting semantic relations between two words in context (, in our work we focus on the classification of word pairs as instances of lexical-semantic relations out of context.", "labels": [], "entities": [{"text": "detecting semantic relations between two words in context", "start_pos": 45, "end_pos": 102, "type": "TASK", "confidence": 0.8077467679977417}]}, {"text": "The performance of the GraCE and WECE systems is tested across two datasets, focusing on their ability to classify instances of specific lexical-semantic relations as well as to provide insights into the systems' generalization capabilities.", "labels": [], "entities": [{"text": "WECE", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.6433777809143066}]}, {"text": "Corpora Many pattern-based systems increase the size of the input corpus in an attempt to overcome data sparsity and to achieve a better recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9964640736579895}]}, {"text": "Therefore, in our experiments, we train our systems using 186 two corpora of different sizes: the British National Corpus (BNC), a 100 million-word corpus, and a Wikipedia dump created from 5 million pages and containing 1.5 billion words.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 98, "end_pos": 127, "type": "DATASET", "confidence": 0.966088225444158}]}, {"text": "The size difference allows us to measure the potential impact of increased word co-occurrence on recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9293469190597534}]}, {"text": "Both corpora were initially parsed with the Stanford dependency parser in the collapsed dependency format ().", "labels": [], "entities": []}, {"text": "Embbedings WECE offset and WECE concat are implemented based on a bag-of-words (BoW) () and based on dependency relations (Dep) ().", "labels": [], "entities": []}, {"text": "Evaluation We compare each system by reporting precision (P), recall (R) and F1 measure (F).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 47, "end_pos": 60, "type": "METRIC", "confidence": 0.945780023932457}, {"text": "recall (R)", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9531300514936447}, {"text": "F1 measure (F)", "start_pos": 77, "end_pos": 91, "type": "METRIC", "confidence": 0.9760658383369446}]}, {"text": "Both of the proposed approaches rest on the hypothesis that the graph or embeddings can enable accurate pair classification, even when pairs never co-    occur in text.", "labels": [], "entities": [{"text": "pair classification", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7213167250156403}]}, {"text": "Therefore, in the first experiment, we test whether the recall of classification systems is improved when the word pair representation encodes information about lexical and relational similarity.", "labels": [], "entities": [{"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9980688691139221}]}, {"text": "As an evaluation dataset, we expand on the dataset of, which was collected from hyponym-hypernym instances from WordNet spanning three topical domains: animals, plants and vehicles.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.9469540119171143}]}, {"text": "Because our systems are capable of classifying instances with more than one relation at once, we enhance this dataset with instances of two more relation types: co-hyponymy and meronymy.", "labels": [], "entities": []}, {"text": "Co-hyponyms are extracted directly from the K&H dataset: two words are co-hyponyms if they have the same direct ancestor.", "labels": [], "entities": [{"text": "K&H dataset", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.8586371392011642}]}, {"text": "To avoid including generic nouns, such as \"migrator\" in the \"animal\" domain, only leaf nodes are considered.", "labels": [], "entities": []}, {"text": "The meronym instances are extracted directly from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9800083637237549}]}, {"text": "The final dataset excludes multi-word expressions, which were not easily handled by any of the tested systems.", "labels": [], "entities": []}, {"text": "The total number of instances considered in our experiments is presented in.", "labels": [], "entities": []}, {"text": "Results presents the average of the results obtained by the systems when tested in-domain in y is a direct ancestor of x if there is no other word z which is hypernym of x and hyponym of y. a 10-fold cross-validation setup.", "labels": [], "entities": []}, {"text": "For the in-domain setup, only instances from one domain are used for training and testing.", "labels": [], "entities": []}, {"text": "As expected, all the systems gain recall with a larger corpus, like Wikipedia, showing that the recall depends on the size of that corpus when a system acquires its distributional information directly from the input corpus and thus is dependent on the word pairs co-occurring.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9972858428955078}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9989891648292542}]}, {"text": "Indeed, in the BNC, only 19.4% of the K&H instances never co-occur, while in Wikipedia -a corpus 15 times larger than BNC-the number of co-occurrences rises only to 30.7%, demonstrating the challenge of classifying such pairs.", "labels": [], "entities": [{"text": "BNC", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.9076979756355286}, {"text": "Wikipedia", "start_pos": 77, "end_pos": 86, "type": "DATASET", "confidence": 0.9291514754295349}]}, {"text": "Therefore, the real upper-bound limit for these types of systems is the amount of word pairs co-occurring in the same sentence in the corpus.", "labels": [], "entities": []}, {"text": "The recall achieved by GraCE overcomes this limitation of pattern-based systems: 40% and 78.7% of the instances that never co-occur in BNC and in Wikipedia, respectively, are correctly classified by GraCE.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9979321956634521}]}, {"text": "This ability causes GraCE to improve the BL performance by 8.1 points in precision and 36.1 points in recall on BNC and 4.6 points in precision and 59.3 in recall on Wikipedia.", "labels": [], "entities": [{"text": "GraCE", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.575746476650238}, {"text": "BL", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.7893826961517334}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9992884397506714}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9988126754760742}, {"text": "BNC", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.855752170085907}, {"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9988231062889099}, {"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.9983931183815002}]}, {"text": "Given that the BL system is constructed identically to GraCE but without using a graph, these results demonstrate the performance benefit of joining the distributional information of a corpus into a graphbased corpus representation.", "labels": [], "entities": []}, {"text": "Analyzing the false negatives of the GraCE classifier, we observe that even relying on a graphbased corpus representation to extract the distributional information of a word pair, many errors are still caused by the sparsity of their vectorial representation.", "labels": [], "entities": []}, {"text": "For the word pairs that do not co-occur in the same sentence, the GraCE vector representations of correctly-classified pairs have a median of eight non-zero features, indicating that the graph was beneficial for still providing evidence of a relationship; in contast, incorrectly-classified pairs had a median of only three non-zero features, suggesting that data sparisity is still major contributor to classification error.", "labels": [], "entities": []}, {"text": "By combining all the distributional information into a denser vector, WECE systems are able to improve upon GraCE's results by an average of 2.9 points in precision and 17.9 points in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9993482232093811}, {"text": "recall", "start_pos": 184, "end_pos": 190, "type": "METRIC", "confidence": 0.9985430240631104}]}, {"text": "WECE results see an increase by 62 points in precision and 46 in recall over DS Zhila which used the same em-188 beddings, highlighting the importance of the SVM classifier for learning which features of the embeddings reflect the lexical relation.", "labels": [], "entities": [{"text": "WECE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6088100671768188}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9993436932563782}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9994626641273499}]}, {"text": "Although embeddings have been argued to reflect the semantic or syntactic relations between two words (), our results suggest that additional machine learning (as done with WECE offset ) is needed to identify which dimensions of the embeddings accurately correspond to specific relationships.", "labels": [], "entities": [{"text": "WECE offset", "start_pos": 173, "end_pos": 184, "type": "DATASET", "confidence": 0.7137034237384796}]}, {"text": "Between the WECE systems, WECE concat achieves slightly better results on the K&H dataset.", "labels": [], "entities": [{"text": "K&H dataset", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.9014235436916351}]}, {"text": "In the first experiment, the proposed systems were compared to test the importance of having a representation that includes information about lexical and relational similarities for the classifier to generalize and to gain recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 223, "end_pos": 229, "type": "METRIC", "confidence": 0.9967041611671448}]}, {"text": "Therefore, as further validation, a second experiment is carried out, where the systems have to classify word pairs from a different domain than the domains in the training set.", "labels": [], "entities": []}, {"text": "The objective is to assess the importance of the domain-aware training instances for the classification.", "labels": [], "entities": []}, {"text": "The K&H dataset contains only instances from three domains and is imbalanced between the number of instances across domains and relation types.", "labels": [], "entities": [{"text": "K&H dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.750722348690033}]}, {"text": "Therefore, our second experiment tests each method on the BLESS dataset (, which spans 17 topical domains and includes five relation types, the three in K&H and (a) attributes of concepts, a relation holding between nouns and adjectives, and (b) actions performed by/to concepts a relation holding between nouns and verbs.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9261455833911896}]}, {"text": "In total, the BLESS dataset contains 14400 positive instances and an equal number of negative instances.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.8967471420764923}]}, {"text": "This experiment measures the generalizability of each system and tests the capabilities of the systems for lexical-semantic relation types other than taxonomic relations.", "labels": [], "entities": []}, {"text": "Domain-aware training instances To show the importance of the domain-aware training instances, the average results of the systems obtained for the in-domain setup across the BLESS dataset are compared with the average results obtained when the systems are trained out-of-domain.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 174, "end_pos": 187, "type": "DATASET", "confidence": 0.9247962832450867}]}, {"text": "For the out-ofdomain setup, one domain is left out from the training set and used for testing.", "labels": [], "entities": []}, {"text": "In this experiment, the systems are tested over the BNC corpus to show the capabilities of the systems to classify out-of-domain in a more reduced corpus.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.9519384801387787}]}, {"text": "Results When no examples from a domain are provided, a general significant decrease in performance is observed.", "labels": [], "entities": []}, {"text": "The GraCE performance decreases 39.4 points in F1, while the WECE systems decrease 20.55 points in average.", "labels": [], "entities": [{"text": "GraCE", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.956731915473938}, {"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9991875290870667}, {"text": "WECE", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.820314884185791}]}, {"text": "The results obtained show that when the instances to be classified are less homogeneous, i.e. when the instances belong to different domains, none of the systems can achieve the level of performance reported for the in-domain setup.", "labels": [], "entities": []}, {"text": "These were the expected results for the GraCE system due to the lexical features that it uses and which are domain dependent.", "labels": [], "entities": []}, {"text": "However, the WECE systems are also affected by this lack of domain-aware training instances.", "labels": [], "entities": [{"text": "WECE", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7080187797546387}]}, {"text": "WECE concat results decrease because similar embeddings are associated with similar words.", "labels": [], "entities": [{"text": "WECE concat", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.46677426993846893}]}, {"text": "189 When two words belong to two different topical domains, their embeddings are less similar and, therefore, the SVM system cannot learn distinctive features for each lexical-semantic relation.", "labels": [], "entities": []}, {"text": "In-domain results per relation type In this work we are interested in creating a general approach for the classification of any lexical semantic relation instances.", "labels": [], "entities": [{"text": "classification of any lexical semantic relation instances", "start_pos": 106, "end_pos": 163, "type": "TASK", "confidence": 0.7331418650490897}]}, {"text": "shows the box and whisker plot of the results obtained per relation type across domains in the in-domain setup over the BNC corpus.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 120, "end_pos": 130, "type": "DATASET", "confidence": 0.9513379633426666}]}, {"text": "Discussion The results confirm that the proposed systems achieve satisfactory results across all the relations, the median of the results being around 90 points in F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 164, "end_pos": 166, "type": "METRIC", "confidence": 0.998519241809845}]}, {"text": "The most accurate system is WECE bow , which supports the assertion by that bag-of-word embeddings should offer superior performance to dependencybased embeddings on task involving semantic relations.", "labels": [], "entities": [{"text": "WECE bow", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.5804222971200943}]}, {"text": "Carrying out an error analysis, the lowest results of the WECE systems are obtained in the domains with the fewest training instances, making apparent that word embedding systems are dependent on the number of training instances.", "labels": [], "entities": []}, {"text": "For these domains, GraCE achieves better results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Distribution of K&H dataset, with the % of  instances which occur in the corpora.", "labels": [], "entities": [{"text": "K&H dataset", "start_pos": 26, "end_pos": 37, "type": "DATASET", "confidence": 0.5613895356655121}]}, {"text": " Table 3: Aggregated results obtained for the in- domain setup with the K&H dataset. Detailed results  are presented in the Appendix A.", "labels": [], "entities": [{"text": "K&H dataset", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.9015887975692749}]}]}