{"title": [{"text": "ExB Themis: Extensive Feature Extraction from Word Alignments for Semantic Textual Similarity", "labels": [], "entities": [{"text": "ExB Themis", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.783113032579422}, {"text": "Extensive Feature Extraction from Word Alignments", "start_pos": 12, "end_pos": 61, "type": "TASK", "confidence": 0.7549002865950266}, {"text": "Semantic Textual Similarity", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.5773131748040518}]}], "abstractContent": [{"text": "We present ExB Themis-a word alignment-based semantic textual similarity system developed for SemEval-2015 Task 2: Semantic Textual Similarity.", "labels": [], "entities": [{"text": "ExB Themis-a word alignment-based semantic textual similarity", "start_pos": 11, "end_pos": 72, "type": "TASK", "confidence": 0.71903395652771}, {"text": "SemEval-2015 Task 2", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.8692308266957601}, {"text": "Semantic Textual Similarity", "start_pos": 115, "end_pos": 142, "type": "TASK", "confidence": 0.5715055267016093}]}, {"text": "It combines both string and semantic similarity measures as well as alignment features using Support Vector Regression.", "labels": [], "entities": []}, {"text": "It occupies the first three places on Span-ish data and additionally places second on En-glish data.", "labels": [], "entities": [{"text": "Span-ish data", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.8584586381912231}]}, {"text": "ExB Themis proved to be the best multilingual system among all participants.", "labels": [], "entities": [{"text": "ExB Themis", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9486508369445801}]}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) is the task of measuring the degree of semantic equivalence of a sentence pair and is applicable to problems in Machine Translation and Summarization among others ( . STS has drawn a lot of attention in the last few years leading to the availability of multilingual training and test data and to the development of a variety of approaches.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8022020061810812}, {"text": "Machine Translation and Summarization", "start_pos": 146, "end_pos": 183, "type": "TASK", "confidence": 0.8174731731414795}]}, {"text": "These approaches fall broadly into three categories): Vector space approaches: Texts are represented as bag-of-words vectors and a vector similaritye. g. cosine -is used to compute a similarity score between two texts ().", "labels": [], "entities": []}, {"text": "Alignment approaches: Words and phrases in two texts are aligned and the quality or coverage of the resulting alignments are used as similarity measure ().", "labels": [], "entities": []}, {"text": "Machine Learning approaches: Multiple similarity measures and features are combined using supervised Machine Learning (ML).", "labels": [], "entities": []}, {"text": "This approach relies on the availability of training data).", "labels": [], "entities": []}, {"text": "ExB Themis combines advantages of all three categories: we implemented a complex alignment algorithm focusing on named entities, temporal expressions, measurement expressions and dedicated negation handling.", "labels": [], "entities": [{"text": "ExB Themis", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9123404920101166}]}, {"text": "Unlike other alignment-based approaches, we extract a variety of features to better model the properties of alignments instead of providing only one alignment feature (see Section 4.1).", "labels": [], "entities": []}, {"text": "Moreover, we employ a variety of similarity measures based on strings and lexical items (see Section 4.2).", "labels": [], "entities": []}, {"text": "Our system integrates two well-known language resources -WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9610934257507324}]}, {"text": "Additionally, it uses word embeddings to cope with data sparseness and the insufficiency of overlaps between sentences.", "labels": [], "entities": []}, {"text": "Finally, we train a Support Vector Regression (SVR) model using these features (see Section 5).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}