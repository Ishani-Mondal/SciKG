{"title": [{"text": "SOPA: Random Forests Regression for the Semantic Textual Similarity task", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the system used by the LIPN-IIMAS team in the Task 2, Semantic Textual Similarity, at SemEval 2015, in both the English and Spanish sub-tasks.", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.7444899479548136}]}, {"text": "We included some features based on alignment measures and we tested different learning models, in particular Random Forests, which proved the best among those used in our participation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our participation in SemEval 2015 was focused on solving the technical problems that afflicted our previous participation and including additional features based on alignments, such as the Sultan similarity () and the measure available in CMU) for speech recognition.", "labels": [], "entities": [{"text": "Sultan similarity", "start_pos": 189, "end_pos": 206, "type": "METRIC", "confidence": 0.8752841055393219}, {"text": "speech recognition", "start_pos": 248, "end_pos": 266, "type": "TASK", "confidence": 0.8389467000961304}]}, {"text": "We baptised the new system SOPA from the Spanish word for \"soup\", since it uses a heterogeneous mix of features.", "labels": [], "entities": []}, {"text": "Well aware of the importance that the training corpus and the regression algorithms have for the STS task, we used language models to select the most appropriate training corpus fora given text, and we explored some alternatives to the \u03bd-Support Vector Regression (\u03bd-SVR) () used in our previous participations, specifically the Multi-Layer Perceptron ( and Random Forest) regression algorithms.", "labels": [], "entities": [{"text": "STS task", "start_pos": 97, "end_pos": 105, "type": "TASK", "confidence": 0.9158215224742889}]}, {"text": "The obtained results show that Random Forests outperforms the other algorithms on every test set.", "labels": [], "entities": []}, {"text": "We describe all the features in Section 2; the details on the learning algorithms and the training corpus selection process are described in Section 3, and the results obtained by the system are detailed in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: English results (Official runs).", "labels": [], "entities": [{"text": "English", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.8750752806663513}]}, {"text": " Table 2: Spanish results (Official runs).", "labels": [], "entities": []}]}