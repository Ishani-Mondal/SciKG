{"title": [{"text": "UTD: Ensemble-Based Spatial Relation Extraction", "labels": [], "entities": [{"text": "Ensemble-Based Spatial Relation Extraction", "start_pos": 5, "end_pos": 47, "type": "TASK", "confidence": 0.6832795217633247}]}], "abstractContent": [{"text": "SpaceEval (SemEval 2015 Task 8), which concerns spatial information extraction, builds on the spatial role identification tasks introduced in SemEval 2012 and used in SemEval 2013.", "labels": [], "entities": [{"text": "SemEval 2015 Task 8)", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.5488358020782471}, {"text": "spatial information extraction", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.6749900380770365}, {"text": "spatial role identification", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.6895690560340881}]}, {"text": "Among the host of subtasks presented in SpaceEval, we participated in subtask 3a, which focuses solely on spatial relation extraction.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 106, "end_pos": 133, "type": "TASK", "confidence": 0.6555339992046356}]}, {"text": "To address the complexity of a MOVELINK, we decompose it into smaller relations so that the roles involved in each relation can be extracted in a joint fashion without losing computational tractability.", "labels": [], "entities": [{"text": "MOVELINK", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.7838642001152039}]}, {"text": "Our system was ranked first in the official evaluation, achieving an overall spatial relation extraction F-score of 84.5%.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 77, "end_pos": 104, "type": "TASK", "confidence": 0.5123825867970785}, {"text": "F-score", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.876591682434082}]}], "introductionContent": [{"text": "SpaceEval 1 was organized as a shared task for the semantic evaluation of spatial information extraction (IE) systems.", "labels": [], "entities": [{"text": "semantic evaluation of spatial information extraction (IE)", "start_pos": 51, "end_pos": 109, "type": "TASK", "confidence": 0.7101472583081987}]}, {"text": "The goals of the shared task include identifying and classifying particular constructions in natural language for expressing spatial information that are conveyed through the spatial concepts of locations, entities participating in spatial relations, paths, topological relations, direction and orientation, motion, etc.", "labels": [], "entities": []}, {"text": "It presents a wide spectrum of spatial IE related subtasks for interested participants to choose from, building on the two previous years shared tasks on the same topic (.", "labels": [], "entities": [{"text": "IE related subtasks", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.8819772601127625}]}, {"text": "Our goal in this paper is to describe the version of our spatial relation extraction system that partic-1 http://alt.qcri.org/semeval2015/task8/ ipated in subtask 3a of SpaceEval.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.7127203941345215}]}, {"text": "Systems participating in this subtask assume as input the spatial elements in a text document.", "labels": [], "entities": []}, {"text": "For example, in the sentence The flower is in the vase 1 and the vase 2 is on the table, the set of spatial elements {flower, in, vase 1 , vase 2 , on, table} are given and subsequently used as candidates for predicting spatial relations.", "labels": [], "entities": [{"text": "predicting spatial relations", "start_pos": 209, "end_pos": 237, "type": "TASK", "confidence": 0.8675754070281982}]}, {"text": "Leveraging the successes of a joint role-labeling approach to spatial relation extraction involving stationary objects, we employ it to extract so-called MOVELINKs, which are spatial relations defined over objects in motion.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.743439773718516}]}, {"text": "In particular, we discuss the adaptations needed to handle the complexity of MOVELINKs.", "labels": [], "entities": [{"text": "MOVELINKs", "start_pos": 77, "end_pos": 86, "type": "TASK", "confidence": 0.8873610496520996}]}, {"text": "Experiments on the SpaceEval corpus demonstrate the effectiveness of our ensemble-based approach to spatial relation extraction.", "labels": [], "entities": [{"text": "SpaceEval corpus", "start_pos": 19, "end_pos": 35, "type": "DATASET", "confidence": 0.8903796970844269}, {"text": "spatial relation extraction", "start_pos": 100, "end_pos": 127, "type": "TASK", "confidence": 0.6475009322166443}]}, {"text": "Among the three teams participating in subtask 3a, our team was ranked first in the official evaluation, achieving an overall F-score of 84.5%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.9996194839477539}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first give a brief overview of the subtask 3a of SpaceEval and the corpus (Section 2).", "labels": [], "entities": []}, {"text": "After that, we describes related work (Section 3).", "labels": [], "entities": []}, {"text": "Finally, we present our approach (Section 4), evaluation results (Section 5), and conclusions (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our ensemble approach to spatial relation extraction.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.6293451885382334}]}, {"text": "We use the 59 travel narratives released as the SpaceEval challenge training data for system training and development.", "labels": [], "entities": [{"text": "SpaceEval challenge training data", "start_pos": 48, "end_pos": 81, "type": "DATASET", "confidence": 0.7876687198877335}]}, {"text": "For testing, we use the 16 travel narratives released as the SpaceEval challenge test data.", "labels": [], "entities": [{"text": "SpaceEval challenge test data", "start_pos": 61, "end_pos": 90, "type": "DATASET", "confidence": 0.9095289558172226}]}, {"text": "Evaluation results are obtained using the official SpaceEval challenge scoring program.", "labels": [], "entities": []}, {"text": "Results are expressed in terms of recall (R), precision (P), and F-score (F).", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9601662307977676}, {"text": "precision (P)", "start_pos": 46, "end_pos": 59, "type": "METRIC", "confidence": 0.959304690361023}, {"text": "F-score (F)", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9651120454072952}]}, {"text": "When computing recall and precision, true positives for QSLINKs and OLINKs are those extracted (trajector,landmark,trigger) triplets that match with those in the gold data.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9920883774757385}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9939225316047668}, {"text": "OLINKs", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9935976266860962}]}, {"text": "True positives for MOVELINKs are those extracted (trigger,mover) pairs found in the gold data.", "labels": [], "entities": [{"text": "MOVELINKs", "start_pos": 19, "end_pos": 28, "type": "TASK", "confidence": 0.5000231266021729}]}, {"text": "As mentioned in the previous section, we tune the C and J parameters on development data when training each SVM classifier.", "labels": [], "entities": []}, {"text": "More specifically, during system training and development, we perform five-fold cross validation.", "labels": [], "entities": []}, {"text": "In each fold experiment, we use three folds for training, one fold for development, and one fold for testing.", "labels": [], "entities": []}, {"text": "Since joint tuning of these two parameters are computationally expensive, we tune them as follows.", "labels": [], "entities": []}, {"text": "We first tune C by setting the J parameter to the default value in SVM light . After finding the C parameter that maximizes F-score on the development set, we fix C and tune J to maximize F-score on the development set.", "labels": [], "entities": [{"text": "F-score", "start_pos": 124, "end_pos": 131, "type": "METRIC", "confidence": 0.946519672870636}, {"text": "F-score", "start_pos": 188, "end_pos": 195, "type": "METRIC", "confidence": 0.9651817679405212}]}, {"text": "shows the spatial relation extraction results using gold spatial elements of our classifier ensemble from the official SpaceEval scoring program.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6423962612946829}]}], "tableCaptions": [{"text": " Table 4: Results for spatial relation extraction using gold spatial elements.", "labels": [], "entities": [{"text": "spatial relation extraction", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.6540700197219849}]}, {"text": " Table 5: Overall results for spatial relation extrac- tion of \"True\" relations using gold spatial elements.", "labels": [], "entities": []}]}