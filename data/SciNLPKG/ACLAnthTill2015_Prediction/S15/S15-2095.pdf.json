{"title": [{"text": "Lsislif: Feature Extraction and Label Weighting for Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8900607526302338}]}], "abstractContent": [{"text": "This paper describes our sentiment analysis systems which have been built for SemEval-2015 Task 10 Subtask B and E.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9386220872402191}, {"text": "SemEval-2015 Task 10 Subtask", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.8071262687444687}]}, {"text": "For sub-task B, a Logistic Regression classifier has been trained after extracting several groups of features including lexical, syntactic, lexicon-based, Z score and semantic features.", "labels": [], "entities": []}, {"text": "A weighting schema has been adapted for positive and negative labels in order to take into account the unbalanced distribution of tweets between the positive and negative classes.", "labels": [], "entities": []}, {"text": "This system is ranked third over 40 participants , it achieves average F1 64.27 on Twit-ter data set 2015 just 0.57% less than the first system.", "labels": [], "entities": [{"text": "F1 64.27", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9802731871604919}, {"text": "Twit-ter data set 2015", "start_pos": 83, "end_pos": 105, "type": "DATASET", "confidence": 0.9841365665197372}]}, {"text": "We also present our participation in Subtask E in which our system has got the second rank with Kendall metric but the first one with Spearman for ranking twitter terms according to their association with the positive sentiment.", "labels": [], "entities": [{"text": "Subtask E", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.868867427110672}]}], "introductionContent": [{"text": "Twitter is one of the most social media platforms which allows the users to express their opinions and feelings towards different issues.", "labels": [], "entities": []}, {"text": "The users have become an important source of content.", "labels": [], "entities": []}, {"text": "This content maybe interesting to analyze for those who are interested in understanding user's interests such as buyers, sellers and producers.", "labels": [], "entities": []}, {"text": "Sentiment Analysis can be done in different levels; Document level; Sentence level; Clause level or Aspect-Based level.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9569694697856903}]}, {"text": "SA in Twitter can be seen as sentence level task, but some limitations should be considered in such sentences.", "labels": [], "entities": []}, {"text": "The size of tweet is limited to 140 characters, informal language, emotion icons and non-standard expressions are very used, and many spelling errors can be find due to the absence of correctness verification.", "labels": [], "entities": []}, {"text": "Three different approaches can be identified in the literature of Sentiment Analysis in Twitter, the first approach is a lexicon based which uses specific types of lexicons to derive the polarity of a text, this approach suffers from the limited size of lexicon and requires human expertise to build manual lexicons, in the other hand the automatic lexicons needs labeled data.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8650985658168793}]}, {"text": "The second approach is machine learning one which uses annotated texts with given labels to learn a classifying model.", "labels": [], "entities": []}, {"text": "Both lexicon and machine learning approaches can be combined to achieve a better performance.", "labels": [], "entities": []}, {"text": "These two approaches are used for SA task but the third one is specific for Twitter or social content, the social approach exploits social network properties and data for enhancing the accuracy of the classification.", "labels": [], "entities": [{"text": "SA task", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.9451295435428619}, {"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9984506368637085}]}, {"text": "In this paper, we present our supervised system which adapts a logistic regression classifier with several groups of features and weighting schema for positive and negative labels.", "labels": [], "entities": []}, {"text": "The features are grouped into 5 groups: word n-gram, lexicon-based, negation, Z score and semantic features.", "labels": [], "entities": [{"text": "Z score", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9069373905658722}]}, {"text": "We also describe our system used for ranking terms according to their positivity, in which we derive the term polarity score from different lexicons.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines existing work of sentiment analysis in Twitter.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.9328287541866302}]}, {"text": "Section 3 describes the data and resources.", "labels": [], "entities": []}, {"text": "The features we used for training the classifier presented in Section 4.", "labels": [], "entities": []}, {"text": "Our experiments are described in section 5, our participation in subtask E is described in section 6 and future work is presented in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained the L1-regularized Logistic regression classifier implemented in LIBLINEAR.", "labels": [], "entities": []}, {"text": "The classifier is trained on the training data set using the features of Section 4 with the three polarities (positive, negative, and neutral) as labels.", "labels": [], "entities": [{"text": "training data set", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.8069780468940735}]}, {"text": "A weighting schema is adapted for each class, we use the weighting option \u2212w i which enables a use of different cost parameter C for different classes.", "labels": [], "entities": []}, {"text": "Since the training data is unbalanced, this weighting schema adjusts the probability of each label.", "labels": [], "entities": []}, {"text": "Thus, we tuned the classifier in adjusting the cost parameter C of Logistic Regression, weight wpos of positive class and weight Wneg of negative class.", "labels": [], "entities": []}, {"text": "We used the development set for tuning the three parameters, all combinations of C in range 0.1 to to 4 by step 0.1, w pos in range 1 to 8 by step 0.1, w neg in range 1 to 8 by step 0.1 are tested.", "labels": [], "entities": []}, {"text": "The combination C=0.2, w pos =5.2, w neg =4.2 have given the best F1 score for the development set and therefore it was selected for our submission.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9845485389232635}]}], "tableCaptions": []}