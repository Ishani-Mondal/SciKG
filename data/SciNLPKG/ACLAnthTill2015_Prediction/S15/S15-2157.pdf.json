{"title": [{"text": "LT3: A Multi-modular Approach to Automatic Taxonomy Construction", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes our contribution to the SemEval-2015 task 17 on \"Taxonomy Extraction Evaluation\".", "labels": [], "entities": [{"text": "SemEval-2015 task 17", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.8914256493250529}, {"text": "Taxonomy Extraction Evaluation", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.9117366274197897}]}, {"text": "We propose a hypernym detection system combining three modules: a lexico-syntactic pattern matcher, a morpho-syntactic analyzer and a module retrieving hy-pernym relations from structured lexical resources.", "labels": [], "entities": [{"text": "hypernym detection", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.78193399310112}]}, {"text": "Our system ranked first in the competition when considering the gold standard and manual evaluation, and second in the overall ranking.", "labels": [], "entities": []}, {"text": "In addition, the experimental results show that all modules contribute to finding hy-pernym relations between terms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Because of globalization and rapid technological evolution, it is no longer feasible to manually create and manage taxonomies for the large variety of scientific and technological (sub)domains.", "labels": [], "entities": []}, {"text": "In addition to domain-specific terminology, also companies desire to build their own mono-or bilingual taxonomies containing the relevant sector-and company-specific terminology.", "labels": [], "entities": []}, {"text": "This clear need for automatisation has encouraged researchers to investigate how terminological and semantically structured resources such as taxonomies or ontologies can be automatically constructed from text).", "labels": [], "entities": []}, {"text": "Different approaches have been proposed to automatically detect hierarchical relations between terms: pattern-based approaches), statistical and machine learning techniques (, distributional approaches, morphosyntactic approaches) and word class latices.", "labels": [], "entities": []}, {"text": "The SemEval-2015 \"Taxonomy Extraction Evaluation\" Task () is concerned with automatically finding relations between pairs of terms and organizing them in a hierarchical structure.", "labels": [], "entities": [{"text": "Taxonomy Extraction Evaluation\" Task", "start_pos": 18, "end_pos": 54, "type": "TASK", "confidence": 0.8759779334068298}]}, {"text": "In this way, the task assumes that a list of domain specific terms is already available in order to focus on the relation detection between these terms.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7303916811943054}]}, {"text": "To tackle this SemEval taxonomy learning task, we propose a multi-modular approach that combines lexico-syntactic, morphological and external structured lexical information.", "labels": [], "entities": [{"text": "SemEval taxonomy learning", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.8731172680854797}]}, {"text": "We will describe our hypernym detection system in Section 2.", "labels": [], "entities": [{"text": "hypernym detection", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7768330574035645}]}, {"text": "The results of the evaluation are presented in Section 3, while Section 4 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparative evaluation of all participating systems considering the average Precision, Recall, F-measure and  Cumulative Fowlkes & Mallows measure scores.", "labels": [], "entities": [{"text": "Precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9974961876869202}, {"text": "Recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9550660848617554}, {"text": "F-measure", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9715103507041931}]}, {"text": " Table 2: Precision, Recall, F-measure and Cumulative  Fowlkes & Mallows measure scores for all test sets.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9990202188491821}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9927218556404114}, {"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9908747673034668}, {"text": "Cumulative  Fowlkes & Mallows measure scores", "start_pos": 43, "end_pos": 87, "type": "METRIC", "confidence": 0.8727761308352152}]}, {"text": " Table 3: Precision (P) and recall (R) from relation overlap  scores per hypernym detection module per domain.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9387192279100418}, {"text": "recall (R)", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9616551101207733}]}]}