{"title": [{"text": "LLT-PolyU: Identifying Sentiment Intensity in Ironic Tweets", "labels": [], "entities": [{"text": "LLT-PolyU", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8374158143997192}, {"text": "Identifying Sentiment Intensity in Ironic Tweets", "start_pos": 11, "end_pos": 59, "type": "TASK", "confidence": 0.8082420329252878}]}], "abstractContent": [{"text": "In this paper, we describe the system we built for Task 11 of SemEval2015, which aims at identifying the sentiment intensity of figurative language in tweets.", "labels": [], "entities": [{"text": "identifying the sentiment intensity of figurative language in tweets", "start_pos": 89, "end_pos": 157, "type": "TASK", "confidence": 0.7109138303332858}]}, {"text": "We use various features, including those specially concerned with the identification of irony and sarcasm.", "labels": [], "entities": [{"text": "identification of irony and sarcasm", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.8742561340332031}]}, {"text": "The features are evaluated through a decision tree regression model and a support vector regression model.", "labels": [], "entities": []}, {"text": "The experiment result of the five-cross validation on the training data shows that the tree regression model outperforms the support vector regression model.", "labels": [], "entities": []}, {"text": "The former is therefore used for the final evaluation of the task.", "labels": [], "entities": []}, {"text": "The results show that our model performs especially well in predicting the sentiment intensity of tweets involving irony and sarcasm.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis aims to identify the polarity and intensity of certain texts in order to shed light on people's sentiments, perceptions, opinions, and beliefs about a particular product, service, scheme, etc.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9245085418224335}]}, {"text": "Knowing what people think can, in fact, help companies, political parties, and other public entities in strategizing and decision making.", "labels": [], "entities": [{"text": "decision making", "start_pos": 121, "end_pos": 136, "type": "TASK", "confidence": 0.7677416801452637}]}, {"text": "While impressive results have been achieved in analysing literal texts (), the study of polarity shifting in sentiment analysis still requires much research.", "labels": [], "entities": [{"text": "polarity shifting in sentiment analysis", "start_pos": 88, "end_pos": 127, "type": "TASK", "confidence": 0.7486311316490173}]}, {"text": "For example,, explores the polarity shifters in English which significantly improve the performance of sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.9432920515537262}]}, {"text": "Besides, figurative uses of language, such as irony or sarcasm, are also able to invert the polarity of the surface text.", "labels": [], "entities": []}, {"text": "Theoretical research in irony and sarcasm often emphasize that humans have difficulties in deciphering messages with underlying meaning.", "labels": [], "entities": []}, {"text": "Factors that can facilitate the understanding of these messages include prosody (e.g. stress or intonation), kinesics (e.g. facial gestures), co-text (i.e. immediate textual environment) and context (i.e. wider environment), as well as cultural background.", "labels": [], "entities": []}, {"text": "Computers, however, cannot always rely on this kind of information.", "labels": [], "entities": []}, {"text": "Currently, there is no method that can guarantee the unequivocal recognition of irony or sarcasm.", "labels": [], "entities": [{"text": "unequivocal recognition of irony or sarcasm", "start_pos": 53, "end_pos": 96, "type": "TASK", "confidence": 0.751083051164945}]}, {"text": "Training a computer to perform such a highly pragmatic task does indeed pose a challenge to computational linguists.", "labels": [], "entities": []}, {"text": "A good number of studies have been recently devoted to finding a solution to the problem.", "labels": [], "entities": []}, {"text": "Most of them have focused on tweets ().", "labels": [], "entities": []}, {"text": "Identifying figurative language in short messages (generally consisting of no more than 140 characters) that do not make use of conventional language, but employ \"little space-consuming\" elements, such as emoticons (\":D\"), abbreviations (\"abbr.\") and slang (\"slng\") is not a self-evident task.", "labels": [], "entities": [{"text": "Identifying figurative language in short messages", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.8517642219861349}]}, {"text": "The reason why none of these studies has proved to be the representative method that could widely be adopted and applied by other researchers is that they have not yet reached optimal results.", "labels": [], "entities": []}, {"text": "Thus, the devising of a computational model able to accurately detect polarity is very much on-going.", "labels": [], "entities": []}, {"text": "This paper describes the model we developed for Task 11 of, which is concerned with the Sentiment Analysis of Figurative Language in Twitter.", "labels": [], "entities": [{"text": "Sentiment Analysis of Figurative Language in Twitter", "start_pos": 88, "end_pos": 140, "type": "TASK", "confidence": 0.9151070032800946}]}, {"text": "Our model came first in the SemEval-2015 task for irony and third in the overall ranking, showing that the features we proposed produce more reliable results in sentiment analysis of ironic tweets.", "labels": [], "entities": [{"text": "SemEval-2015 task for irony", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.6271767467260361}, {"text": "sentiment analysis of ironic tweets", "start_pos": 161, "end_pos": 196, "type": "TASK", "confidence": 0.8927448511123657}]}], "datasetContent": [{"text": "In order to avoid noise and sparseness, only features that occur at least 3 times are kept.", "labels": [], "entities": []}, {"text": "All the feature values are normalized into the range [-1, 1] according to the formula shown in Equation 1, where f i,j is the value of feature j in the ith example, and N is the sample size.", "labels": [], "entities": []}, {"text": "We use the correlative coefficient (Pearson's r) measure to rank all the features.", "labels": [], "entities": [{"text": "Pearson's r) measure", "start_pos": 36, "end_pos": 56, "type": "METRIC", "confidence": 0.8102629899978637}]}, {"text": "Then, we can use the threshold value of r to rule out less important features.", "labels": [], "entities": []}, {"text": "The calculation of r is described in Equation 2, where X and Y are the two variables that are evaluated, X i is the ith sample value of X, Y i is the ith sample value of Y and N is the sample size.", "labels": [], "entities": []}, {"text": "Regression model (RepTree) implemented in Weka ( and Support Vector Regression model (SVR) implemented in LibSVM ().", "labels": [], "entities": [{"text": "Regression", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8997144103050232}, {"text": "Weka", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9875549674034119}, {"text": "Support Vector Regression model (SVR)", "start_pos": 53, "end_pos": 90, "type": "METRIC", "confidence": 0.8597089052200317}]}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "The best performance is obtained with the value of r between 0.03 and 0.04 with the RepTree model.", "labels": [], "entities": []}, {"text": "The experiment also shows that RepTree always outperforms SVR (i.e. higher cosine value and lower rmse value).", "labels": [], "entities": []}, {"text": "Therefore, in the following experiments and in the evaluation the RepTree model is adopted.", "labels": [], "entities": []}, {"text": "In the second experiment, we user = 0.035 as threshold for feature selection by testing how different kinds of features contribute to the overall performance.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.6683007627725601}]}, {"text": "The features listed in Section 3.2 are gradually added and their contribution is assessed.", "labels": [], "entities": []}, {"text": "If the new feature does not improve the performance, it is removed in the next running.", "labels": [], "entities": []}, {"text": "The results of the second experiment are shown in.", "labels": [], "entities": []}, {"text": "The baseline is obtained with a naive prediction using the average polarity value of the training data.", "labels": [], "entities": []}, {"text": "As can be seen, only BiT oken harms the performance, while all other features contribute to its improvement.", "labels": [], "entities": [{"text": "BiT", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.839081883430481}]}, {"text": "Based on the described analysis, for the final test we used RepTree and all the feature sets, except for BiT oken.", "labels": [], "entities": [{"text": "RepTree", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.8259338736534119}]}, {"text": "The threshold for feature frequency is set to 3 and the r value for feature selection is set to 0.035.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.6636583358049393}]}, {"text": "Finally, the trained model on the 8,000 tweets is used to predict the sentiment intensity of the evaluation dataset which includes 4,000 tweets.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Among the fifteen participants in the SemEval task on Sentiment Analysis of Figurative Language in Twitter, our model achieves the best performance in the identification of irony, and ranks third in the overall performance.", "labels": [], "entities": [{"text": "SemEval task on Sentiment Analysis of Figurative Language in Twitter", "start_pos": 38, "end_pos": 106, "type": "TASK", "confidence": 0.8287545680999756}, {"text": "identification of irony", "start_pos": 155, "end_pos": 178, "type": "TASK", "confidence": 0.9339493711789449}]}], "tableCaptions": [{"text": " Table 1: Experiment result of the 5-fold cross validation  by RegTree and SVR on the training data.", "labels": [], "entities": [{"text": "RegTree", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9346094727516174}]}, {"text": " Table 2: Test result of SemEval Task 11.", "labels": [], "entities": [{"text": "SemEval Task 11", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.9144952694574991}]}]}