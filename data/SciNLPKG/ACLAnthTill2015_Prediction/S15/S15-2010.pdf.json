{"title": [{"text": "RTM-DCU: Predicting Semantic Similarity with Referential Translation Machines", "labels": [], "entities": [{"text": "Predicting Semantic Similarity with Referential Translation Machines", "start_pos": 9, "end_pos": 77, "type": "TASK", "confidence": 0.7519977688789368}]}], "abstractContent": [{"text": "We use referential translation machines (RTMs) for predicting the semantic similarity of text.", "labels": [], "entities": [{"text": "referential translation machines (RTMs)", "start_pos": 7, "end_pos": 46, "type": "TASK", "confidence": 0.7833701968193054}, {"text": "predicting the semantic similarity of text", "start_pos": 51, "end_pos": 93, "type": "TASK", "confidence": 0.7780350347359976}]}, {"text": "RTMs area computational model effectively judging monolingual and bilingual similarity while identifying translation acts between any two data sets with respect to interpretants.", "labels": [], "entities": []}, {"text": "RTMs pioneer a language independent approach to all similarity tasks and remove the need to access any task or domain specific information or resource.", "labels": [], "entities": []}, {"text": "RTMs become the 2nd system out of 13 systems participating in Paraphrase and Semantic Similarity in Twitter, 6th out of 16 submissions in Semantic Textual Similarity Spanish, and 50th out of 73 submissions in Semantic Textual Similarity English.", "labels": [], "entities": [{"text": "Paraphrase and Semantic Similarity", "start_pos": 62, "end_pos": 96, "type": "TASK", "confidence": 0.663688138127327}, {"text": "Semantic Textual Similarity Spanish", "start_pos": 138, "end_pos": 173, "type": "TASK", "confidence": 0.7000194191932678}, {"text": "Semantic Textual Similarity English", "start_pos": 209, "end_pos": 244, "type": "TASK", "confidence": 0.7551017552614212}]}, {"text": "1 Referential Translation Machine (RTM) We present positive results from a fully automated judge for semantic similarity based on Referential Translation Machines (Bi\u00e7ici and Way, 2014b) in two semantic similarity tasks at SemEval-2015, Semantic Evaluation Exercises-International Workshop on Semantic Evaluation (Nakov et al., 2015).", "labels": [], "entities": [{"text": "Referential Translation Machine (RTM", "start_pos": 2, "end_pos": 38, "type": "TASK", "confidence": 0.8168155491352082}, {"text": "Semantic Evaluation Exercises-International Workshop on Semantic Evaluation (Nakov et al., 2015)", "start_pos": 237, "end_pos": 333, "type": "TASK", "confidence": 0.7538668385573796}]}, {"text": "Referential translation machine (RTM) is a computational model for identifying the acts of translation for translating between any given two data sets with respect to a reference corpus selected in the same domain.", "labels": [], "entities": [{"text": "Referential translation machine (RTM)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8937184810638428}]}, {"text": "An RTM model is based on the selection of interpretants, training data close to both the training set and the test set, which allow shared semantics by providing context for similarity judgments.", "labels": [], "entities": []}, {"text": "Each RTM model is a data translation and translation prediction model between the instances in the training set and the test set and translation acts are indicators of the data transformation and translation.", "labels": [], "entities": [{"text": "data translation and translation prediction", "start_pos": 20, "end_pos": 63, "type": "TASK", "confidence": 0.7702340066432953}]}, {"text": "RTMs present an accurate and language independent solution for making semantic similarity judgments.", "labels": [], "entities": [{"text": "semantic similarity judgments", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.7196014523506165}]}, {"text": "RTMs pioneer a computational model for quality and semantic similarity judgments in monolin-gual and bilingual settings using retrieval of relevant training data (Bi\u00e7ici and Yuret, 2015) as interpre-tants for reaching shared semantics.", "labels": [], "entities": []}, {"text": "RTMs achieve (i) top performance when predicting the quality of translations (Bi\u00e7ici, 2013; Bi\u00e7ici and Way, 2014a); (ii) top performance when predicting monolingual cross-level semantic similarity; (iii) second performance when predicting paraphrase and semantic similarity in Twitter (iv) good performance when judging the semantic similarity of sentences; (iv) good performance when evaluating the semantic re-latedness of sentences and their entailment (Bi\u00e7ici and Way, 2014b).", "labels": [], "entities": [{"text": "predicting monolingual cross-level semantic similarity", "start_pos": 142, "end_pos": 196, "type": "TASK", "confidence": 0.7217224597930908}, {"text": "predicting paraphrase and semantic similarity", "start_pos": 228, "end_pos": 273, "type": "TASK", "confidence": 0.6963259696960449}]}, {"text": "RTMs use Machine Translation Performance Prediction (MTPP) System (Bi\u00e7ici et al., 2013; Bi\u00e7ici and Way, 2014b), which is a state-of-the-art (SoA) performance predictor of translation even without using the translation.", "labels": [], "entities": [{"text": "Machine Translation Performance Prediction (MTPP)", "start_pos": 9, "end_pos": 58, "type": "TASK", "confidence": 0.8012610418455941}]}, {"text": "MTPP system measures the coverage of individual test sentence features found in the training set and derives indicators of the close-ness of test sentences to the available training data, the difficulty of translating the sentence, and the presence of acts of translation for data transformation.", "labels": [], "entities": [{"text": "MTPP", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7451471090316772}]}, {"text": "MTPP features for translation acts are provided in (Bi\u00e7ici and Way, 2014b).", "labels": [], "entities": [{"text": "translation acts", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.9332383275032043}, {"text": "Bi\u00e7ici and Way, 2014b)", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.8277764916419983}]}, {"text": "RTMs become the 2nd system out of 13 systems participating in Paraphrase and Semantic Similarity in Twitter (Task 1) (Xu et al., 2015) and achieve good results in Semantic Tex-56", "labels": [], "entities": [{"text": "Tex-56", "start_pos": 172, "end_pos": 178, "type": "DATASET", "confidence": 0.383928120136261}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of sentences in I (in thousands) se- lected for each task.", "labels": [], "entities": []}, {"text": " Table 2: ParSS test results.", "labels": [], "entities": [{"text": "ParSS test", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.711908221244812}]}, {"text": " Table 4: STS English test r P results for each domain.", "labels": [], "entities": [{"text": "STS English test r P", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.5863552927970886}]}, {"text": " Table 3: ParSS training results of top 5 RTM systems  with further optimization.", "labels": [], "entities": []}, {"text": " Table 3. R uses the regular truecase (Koehn et al.,", "labels": [], "entities": []}, {"text": " Table 5: STS Spanish test results.", "labels": [], "entities": [{"text": "STS Spanish test results", "start_pos": 10, "end_pos": 34, "type": "DATASET", "confidence": 0.7706053704023361}]}, {"text": " Table 6: RTM top test results selected according to Weighted r P among top 3 results on STS as well as top RTM-DCU  results in STS", "labels": [], "entities": [{"text": "Weighted r P", "start_pos": 53, "end_pos": 65, "type": "METRIC", "confidence": 0.9350027441978455}, {"text": "STS", "start_pos": 89, "end_pos": 92, "type": "DATASET", "confidence": 0.897030234336853}, {"text": "STS", "start_pos": 128, "end_pos": 131, "type": "DATASET", "confidence": 0.6409894824028015}]}, {"text": " Table 7: RTM training results of top 3 systems on STS English, English images, English headlines, and Spanish tasks.", "labels": [], "entities": [{"text": "RTM training", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.7347486615180969}, {"text": "STS English", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.8017786741256714}]}]}