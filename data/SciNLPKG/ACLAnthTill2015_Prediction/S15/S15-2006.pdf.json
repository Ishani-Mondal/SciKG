{"title": [{"text": "ECNU: Leveraging Word Embeddings to Boost Performance for Paraphrase in Twitter", "labels": [], "entities": [{"text": "ECNU", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.836231529712677}]}], "abstractContent": [{"text": "This paper describes our approaches to paraphrase recognition in Twitter organized as task 1 in Semantic Evaluation 2015.", "labels": [], "entities": [{"text": "paraphrase recognition", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9311470985412598}]}, {"text": "Lots of approaches have been proposed to address the paraphrasing task on conventional texts (sur-veyed in (Madnani and Dorr, 2010)).", "labels": [], "entities": []}, {"text": "In this work we examined the effectiveness of various linguistic features proposed in traditional paraphrasing task on informal texts, (i.e., Twitter), for example, string based, corpus based, and syntactic features, which served as input of a classification algorithm.", "labels": [], "entities": []}, {"text": "Besides, we also proposed novel features based on distributed word representations, which were learned using deep learning paradigms.", "labels": [], "entities": []}, {"text": "Results on test dataset show that our proposed features improve the performance by a margin of 1.9% in terms of F1-score and our team ranks third among 10 teams with 38 systems.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9995874762535095}]}], "introductionContent": [{"text": "Generally, a paraphrase is an alternative surface form in the same language expressing the same semantic content as the original form and it can appear at different levels, e.g., lexical, phrasal, sentential.", "labels": [], "entities": []}, {"text": "Identifying paraphrase can improve the performance of several natural language processing (NLP) applications, such as query and pattern expansion, machine translation (, question answering), see survey ( for completion.", "labels": [], "entities": [{"text": "query and pattern expansion", "start_pos": 118, "end_pos": 145, "type": "TASK", "confidence": 0.6135916858911514}, {"text": "machine translation", "start_pos": 147, "end_pos": 166, "type": "TASK", "confidence": 0.7862994074821472}, {"text": "question answering)", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.8123123645782471}]}, {"text": "Most of previous work of paraphrase are on formal text.", "labels": [], "entities": [{"text": "paraphrase", "start_pos": 25, "end_pos": 35, "type": "TASK", "confidence": 0.9785136580467224}]}, {"text": "Recently with the rapidly growth of microblogs and social media services, the computational linguistic community is moving its attention to informal genre of text (.", "labels": [], "entities": []}, {"text": "For example, () defined the problem of redundancy detection in Twitter and proposed SVM models based on bag-of-word, syntactic content features to detect paraphrase.", "labels": [], "entities": [{"text": "redundancy detection", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7811407446861267}]}, {"text": "To provide a benchmark so as to compare and develop different paraphrasing techniques in Twitter, the paraphrase and semantic similarity task in SemEval 2015 () requires the participants to determine whether two tweets express the same meaning or not and optionally a degree score between 0 and 1, which can be regarded as a binary classification problem.", "labels": [], "entities": []}, {"text": "Paraphrasing task is very close to semantic textual similarity and textual entailment task) since substantially these tasks all concentrated on modeling the underlying similarity between two sentences.", "labels": [], "entities": []}, {"text": "The commonly-used features in these tasks can be categorized into several following groups: (1) string based which measures the sequence similarities of original strings with others, e.g., n-gram Overlap, cosine similarity; (2) corpus based which measures word or sentence similarities using word distributional vectors learned from large corpora using distributional models, like Latent Semantic Analysis (LSA), etc.", "labels": [], "entities": []}, {"text": "(3) knowledge based which estimates similarities with the aid of external resources, such as WordNet; (4) syntactic based which utilizes syntax information to measure similarities; (5) other features such as using Named Entity similarity.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9495833516120911}]}, {"text": "In this work, we built a supervised binary classifier for paraphrase judgment and adopted multi-ple features used in conventional texts to recognize paraphrase in Twitter, which includes string based features, corpus based features, etc.", "labels": [], "entities": [{"text": "paraphrase judgment", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.9472722113132477}]}, {"text": "Besides, we also proposed a novel feature based on distributed word representations (i.e., word embeddings) learned over a large raw corpus using neural language models.", "labels": [], "entities": []}, {"text": "The results on test dataset demonstrate that linguistic features are effective for paraphrase in Twitter task and proposed word embedding features further improve the performance.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the features used in our systems.", "labels": [], "entities": []}, {"text": "System setups and experimental results on training and test datasets are presented in Section 3.", "labels": [], "entities": []}, {"text": "Finally, conclusions and future work are given in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Top results of different classification algorithms in systems mlfeats and nnfeats on development dataset  together with parameter values in brackets.", "labels": [], "entities": []}, {"text": " Table 2: Performance and rankings of systems mlfeats, nnfeats and baseline systems on test dataset officially  released by the organizers, as well as top ranking systems.", "labels": [], "entities": []}, {"text": " Table 3: The results of feature ablation experiments.", "labels": [], "entities": []}]}