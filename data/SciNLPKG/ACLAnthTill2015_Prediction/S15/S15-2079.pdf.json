{"title": [{"text": "UNITN: Training Deep Convolutional Neural Network for Twitter Sentiment Classification", "labels": [], "entities": [{"text": "UNITN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7664870023727417}, {"text": "Twitter Sentiment Classification", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.7517673770586649}]}], "abstractContent": [{"text": "This paper describes our deep learning system for sentiment analysis of tweets.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.9499425292015076}]}, {"text": "The main contribution of this work is a process to initialize the parameter weights of the convolu-tional neural network, which is crucial to train an accurate model while avoiding the need to inject any additional features.", "labels": [], "entities": []}, {"text": "Briefly, we use an unsupervised neural language model to initialize word embeddings that are further tuned by our deep learning model on a distant supervised corpus.", "labels": [], "entities": []}, {"text": "At a final stage, the pre-trained parameters of the network are used to initialize the model which is then trained on the supervised training data from Semeval-2015.", "labels": [], "entities": []}, {"text": "According to results on the official test sets, our model ranks 1st in the phrase-level subtask A (among 11 teams) and 2nd on the message-level subtask B (among 40 teams).", "labels": [], "entities": []}, {"text": "Interestingly , computing an average rank overall six test sets (official and five progress test sets) puts our system 1st in both subtasks A and B.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this work we describe our deep convolutional neural network for sentiment analysis of tweets.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.9364569187164307}]}, {"text": "Its architecture is most similar to the deep learning systems presented in () that have recently established new stateof-the-art results on various NLP sentence classification tasks also including sentiment analysis.", "labels": [], "entities": [{"text": "NLP sentence classification tasks", "start_pos": 148, "end_pos": 181, "type": "TASK", "confidence": 0.7831999510526657}, {"text": "sentiment analysis", "start_pos": 197, "end_pos": 215, "type": "TASK", "confidence": 0.9491662681102753}]}, {"text": "While already demonstrating excellent results, training a convolutional neural network that would beat hand-engineered approaches that also rely on multiple manual and automatically constructed lexicons, e.g. (, requires careful attention.", "labels": [], "entities": []}, {"text": "This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples.", "labels": [], "entities": []}, {"text": "Turns out, providing the network with good initialisation parameters makes all the difference in training an accurate model.", "labels": [], "entities": []}, {"text": "We propose a three-step process we follow to train our deep learning model for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.9705062508583069}]}, {"text": "It can be summarized as follows: (i) word embeddings are initialized using a neural language model which is trained on a large unsupervised collection of tweets; (ii) we use our convolutional neural network to further refine the embeddings on a large distant supervised corpus (; (iii) the word embeddings and other parameters of the network obtained at the previous stage are used to initialize the network that is then trained on a supervised corpus from Semeval-2015.", "labels": [], "entities": []}, {"text": "We apply our deep learning model on two subtasks of Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge (: phraselevel (subtask A) and message-level (subtask B).", "labels": [], "entities": [{"text": "Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge", "start_pos": 52, "end_pos": 111, "type": "TASK", "confidence": 0.734563065899743}]}, {"text": "Our system ranks 1st on the official test set of the phrase-level and 2nd on the message-level subtask.", "labels": [], "entities": []}, {"text": "In addition to the test set used to establish the final ranking in Semeval-2015, all systems were also evaluated on the progress test set which consists of five test sets, where our system also shows strong results.", "labels": [], "entities": [{"text": "progress test set", "start_pos": 120, "end_pos": 137, "type": "DATASET", "confidence": 0.7019435167312622}]}, {"text": "In particular, we rank all systems according to their performance on each test set and compute their average ranks.", "labels": [], "entities": []}, {"text": "Interestingly, our model appears to be the most robust across all six test sets ranking 1st according to the average rank in both subtasks A and B.", "labels": [], "entities": []}, {"text": "In the following, we describe the architecture of our convolutional neural network and the parameter initialization process process we follow to train it.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test our model on two subtasks from Semeval-2015 Task 10: phrase-level (subtask A) and message-level (subtask B).", "labels": [], "entities": []}, {"text": "The datasets use in Semeval-2015 are summarized in.", "labels": [], "entities": []}, {"text": "We use train and dev from Twitter'13 for training and Twitter'13-test as a validation set.", "labels": [], "entities": []}, {"text": "The other datasets are used for testing, whereas Twitter'15 is used to establish the official ranking of the systems.", "labels": [], "entities": []}, {"text": "Additionally, to pre-train the weights of our network, we use a large unsupervised corpus containing 50M tweets for training the word embeddings and a 10M tweet corpus for distant supervision.", "labels": [], "entities": []}, {"text": "The latter corpus was built similarly to (, where tweets with positive emoticons, like ':)', are assumed to be positive, and tweets with negative emoticons, like ':(', are labeled as negative.", "labels": [], "entities": []}, {"text": "The dataset contains equal number of positive and negative tweets.", "labels": [], "entities": []}, {"text": "The parameters of our model were (chosen on the validation set) as follows: the width m of the convolution filters is set to 5 and the number of convolutional feature maps is 300.", "labels": [], "entities": []}, {"text": "We use ReLU activation function and a simple max-pooling.", "labels": [], "entities": []}, {"text": "The L2 regularization term is set to 1e \u2212 4, dropout is applied to the penultimate level with p = 0.5.", "labels": [], "entities": []}, {"text": "The dimensionality of the word embeddings dis set to 100.", "labels": [], "entities": []}, {"text": "For the phrase-level subtask the size of the word type embeddings, which encode tokens that span the target phrase or not, is set to 10.", "labels": [], "entities": []}, {"text": "To train our deep learn- ing model we follow our 3-step process as described in Sec.", "labels": [], "entities": []}, {"text": "We report the results for training the network on the official supervised dataset from Semeval'15 using parameters that were initialized: (i) completely at random (Random); (ii) using word embeddings from the neural language model trained on a large unsupervised dataset (Unsup) with the word2vec tool and (iii) initializing all the parameters of our model with the parameters of the network which uses the word embeddings from the previous step and are further tuned on a distant supervised dataset (Distant).", "labels": [], "entities": [{"text": "official supervised dataset from Semeval'15", "start_pos": 54, "end_pos": 97, "type": "DATASET", "confidence": 0.8295394778251648}]}, {"text": "summarizes the performance of our model on five test sets using three parameter initialization schemas.", "labels": [], "entities": []}, {"text": "First, we observe that training the network with all parameters initialized completely at random results in a rather mediocre performance.", "labels": [], "entities": []}, {"text": "This is due to a small size of the training set.", "labels": [], "entities": []}, {"text": "Secondly, using embeddings pre-trained by a neural language model considerably boosts the performance.", "labels": [], "entities": []}, {"text": "Finally, using a large distant supervised corpus to further tune the word embeddings to also capture the sentiment aspect of the words they represent results in a further improvement across all test sets (except fora small drop on.", "labels": [], "entities": []}, {"text": "The results from the official rankings for both subtasks A and B are summarized in.", "labels": [], "entities": []}, {"text": "As we can see our system performs particularly well on subtask A ranking 1st on the official Twitter'15 set, while also showing excellent performance on all other test sets.", "labels": [], "entities": []}, {"text": "On subtask B our system ranks 2nd also showing high rankings on the other test sets (apart from the.", "labels": [], "entities": []}, {"text": "In fact, no single system at Semeval-2015 performed equally well across all test sets.", "labels": [], "entities": []}, {"text": "For example, a system that ranked 1st on the official Twitter'15 dataset performs much worse on the progress test sets ranking {14, 14, 11, 7, 12} on {LiveJournal'14, SMS'13, Twitter'13, Twitter'14, and Sarcasm'14} correspondingly.", "labels": [], "entities": [{"text": "Twitter'15 dataset", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.8140141367912292}]}, {"text": "It has an AveRank of 9.8, which is only 6th best result if systems were ranked according to this metric.", "labels": [], "entities": [{"text": "AveRank", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8040419816970825}]}, {"text": "In contrast, our system shows robust results across all tests having the best AveRank of 4.3 among all 40 systems.", "labels": [], "entities": [{"text": "AveRank", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.8898620009422302}]}], "tableCaptions": [{"text": " Table 2: Testing the model on the progress test sets  from Semeval-2015 with different parameter initializion  schemes: Random (random word embeddings); Unsup  (word2vec embeddings); Distant (all parameters from  a network trained on a distant supervised dataset).", "labels": [], "entities": [{"text": "progress test sets  from Semeval-2015", "start_pos": 35, "end_pos": 72, "type": "DATASET", "confidence": 0.796860671043396}]}, {"text": " Table 3: Results on Semeval-2015 for phrase and tweet- level subtasks. Rank shows the absolute position of our  system on each test set. AveRank is the averaged rank  across all test sets.", "labels": [], "entities": []}]}