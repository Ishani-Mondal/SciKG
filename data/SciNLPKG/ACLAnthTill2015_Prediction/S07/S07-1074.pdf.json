{"title": [{"text": "UBC-ALM: Combining k-NN with SVD for WSD", "labels": [], "entities": [{"text": "UBC-ALM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8324834108352661}, {"text": "WSD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.5361748933792114}]}], "abstractContent": [{"text": "This work describes the University of the Basque Country system (UBC-ALM) for lexical sample and all-words WSD subtasks of SemEval-2007 task 17, where it performed in the second and fifth positions respectively.", "labels": [], "entities": [{"text": "SemEval-2007 task 17", "start_pos": 123, "end_pos": 143, "type": "TASK", "confidence": 0.7445353070894877}]}, {"text": "The system is based on a combination of k-Nearest Neighbor classifiers, with each classifier learning from a distinct set of features: local features (syntactic, col-locations features), topical features (bag-of-words, domain information) and latent features learned from a reduced space using Singular Value Decomposition.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our group (UBC-ALM) participated in the lexical sample and all-words WSD subtasks of SemEval-2007 task 17.", "labels": [], "entities": []}, {"text": "We applied a combination of different k-Nearest Neighbor (k-NN) classifiers.", "labels": [], "entities": []}, {"text": "Each classifier manages different information sources (features), making the combination a powerful solution.", "labels": [], "entities": []}, {"text": "This algorithm was previously tested on the datasets from previous editions of Senseval ().", "labels": [], "entities": []}, {"text": "Before submission, the performance of the system was tested on the SemEval lexical sample training data.", "labels": [], "entities": [{"text": "SemEval lexical sample training data", "start_pos": 67, "end_pos": 103, "type": "DATASET", "confidence": 0.8307525515556335}]}, {"text": "For learning we use a rich set of features, including latent features obtained from a reduced space using Singular Value Decomposition (SVD).", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The learning features are presented in section 2, and the learning algorithm and the combinations of single k-NNs are given in section 3.", "labels": [], "entities": []}, {"text": "Section 4 focuses on the tuning experiments.", "labels": [], "entities": []}, {"text": "Finally, section 5 summarizes the official results and some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We optimized and tuned the system differently for each kind of tasks.", "labels": [], "entities": []}, {"text": "We will examine each in turn.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for the best k-NN combinations in  Senseval-3 all-words, using Semcor as training cor- pus.", "labels": [], "entities": []}, {"text": " Table 3: Results for the best k-NN combinations in  training part of SemEval lexical sample, using Sem- cor as training corpus.", "labels": [], "entities": [{"text": "SemEval lexical sample", "start_pos": 70, "end_pos": 92, "type": "DATASET", "confidence": 0.7273789048194885}]}, {"text": " Table 4: Official results for SemEval-2007 task 17  lexical sample and all-words subtasks.", "labels": [], "entities": [{"text": "SemEval-2007 task", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8248715698719025}]}]}