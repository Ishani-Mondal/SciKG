{"title": [{"text": "SemEval-2007 Task 11: English Lexical Sample Task via English-Chinese Parallel Text", "labels": [], "entities": []}], "abstractContent": [{"text": "We made use of parallel texts to gather training and test examples for the English lexical sample task.", "labels": [], "entities": []}, {"text": "Two tracks were organized for our task.", "labels": [], "entities": []}, {"text": "The first track used examples gathered from an LDC corpus, while the second track used examples gathered from a Web corpus.", "labels": [], "entities": []}, {"text": "In this paper, we describe the process of gathering examples from the parallel corpora, the differences with similar tasks in previous SENSEVAL evaluations, and present the results of participating systems .", "labels": [], "entities": [{"text": "SENSEVAL evaluations", "start_pos": 135, "end_pos": 155, "type": "TASK", "confidence": 0.8131502866744995}]}], "introductionContent": [{"text": "As part of the SemEval-2007 evaluation exercise, we organized an English lexical sample task for word sense disambiguation (WSD), where the senseannotated examples were semi-automatically gathered from word-aligned English-Chinese parallel texts.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 97, "end_pos": 128, "type": "TASK", "confidence": 0.7975589235623678}]}, {"text": "Two tracks were organized for this task, each gathering data from a different corpus.", "labels": [], "entities": []}, {"text": "In this paper, we describe our motivation for organizing the task, our task framework, and the results of participants.", "labels": [], "entities": []}, {"text": "Past research has shown that supervised learning is one of the most successful approaches to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9885942935943604}]}, {"text": "However, this approach involves the collection of a large text corpus in which each ambiguous word has been annotated with the correct sense to serve as training data.", "labels": [], "entities": []}, {"text": "Due to the expensive annotation process, only a handful of manually sense-tagged corpora are available.", "labels": [], "entities": []}, {"text": "An effort to alleviate the training data bottleneck is the Open Mind Word Expert project) to collect sense-tagged data from Internet users.", "labels": [], "entities": []}, {"text": "Data gathered through the OMWE project were used in the SENSEVAL-3 English lexical sample task.", "labels": [], "entities": [{"text": "OMWE project", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.799905002117157}, {"text": "SENSEVAL-3 English lexical sample task", "start_pos": 56, "end_pos": 94, "type": "TASK", "confidence": 0.704293429851532}]}, {"text": "In that task, WordNet-1.7.1 was used as the sense inventory for nouns and adjectives, while Wordsmyth 1 was used as the sense inventory for verbs.", "labels": [], "entities": [{"text": "WordNet-1.7.1", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.9548981189727783}]}, {"text": "Another source of potential training data is parallel texts.", "labels": [], "entities": []}, {"text": "Our past research in () has shown that examples gathered from parallel texts are useful for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9866253137588501}]}, {"text": "Briefly, after manually assigning appropriate Chinese translations to each sense of an English word, the English side of a word-aligned parallel text can then serve as the training data, as they are considered to have been disambiguated and \"sense-tagged\" by the appropriate Chinese translations.", "labels": [], "entities": []}, {"text": "Using the above approach, we gathered the training and test examples for our task from parallel texts.", "labels": [], "entities": []}, {"text": "Note that our examples are collected without manually annotating each individual ambiguous word occurrence, allowing us to gather our examples in a much shorter time.", "labels": [], "entities": []}, {"text": "This contrasts with the setting of the English lexical sample task in previous SENSE-VAL evaluations.", "labels": [], "entities": []}, {"text": "In the English lexical sample task of SENSEVAL-2, the sense tagged data were created through manual annotation by trained lexicographers.", "labels": [], "entities": []}, {"text": "In SENSEVAL-3, the data were gathered through manual sense annotation by Internet users.", "labels": [], "entities": []}, {"text": "In the next section, we describe in more detail the process of gathering examples from parallel texts and the two different parallel corpora we used.", "labels": [], "entities": []}, {"text": "We then give a brief description of each of the partici-pating systems.", "labels": [], "entities": []}, {"text": "In Section 4, we present the results obtained by the participants, before concluding in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "English lexical sample task, we used WordNet-1.7.1 as our sense inventory.", "labels": [], "entities": [{"text": "WordNet-1.7.1", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.977994978427887}]}], "tableCaptions": [{"text": " Table 1: Average number of senses, training exam- ples, and test examples per word.", "labels": [], "entities": []}, {"text": " Table 3: Micro-average scores of the most frequent  sense baseline and the various participants on each  noun.", "labels": [], "entities": [{"text": "Micro-average", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9544790387153625}]}, {"text": " Table 4: Micro-average scores of the most frequent  sense baseline and the various participants on each  adjective.", "labels": [], "entities": [{"text": "Micro-average", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9487258195877075}]}]}