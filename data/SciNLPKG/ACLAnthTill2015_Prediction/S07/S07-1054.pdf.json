{"title": [{"text": "NUS-PT: Exploiting Parallel Texts for Word Sense Disambiguation in the English All-Words Tasks", "labels": [], "entities": [{"text": "NUS-PT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9120904207229614}, {"text": "Word Sense Disambiguation", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.7712228198846182}]}], "abstractContent": [{"text": "We participated in the SemEval-2007 coarse-grained English all-words task and fine-grained English all-words task.", "labels": [], "entities": [{"text": "SemEval-2007 coarse-grained English all-words task", "start_pos": 23, "end_pos": 73, "type": "TASK", "confidence": 0.6636935412883759}]}, {"text": "We used a supervised learning approach with SVM as the learning algorithm.", "labels": [], "entities": []}, {"text": "The knowledge sources used include local col-locations, parts-of-speech, and surrounding words.", "labels": [], "entities": []}, {"text": "We gathered training examples from English-Chinese parallel corpora, SEMCOR, and DSO corpus.", "labels": [], "entities": [{"text": "SEMCOR", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.8135071992874146}, {"text": "DSO corpus", "start_pos": 81, "end_pos": 91, "type": "DATASET", "confidence": 0.9691230356693268}]}, {"text": "While the fine-grained sense inventory of WordNet was used to train our system employed for the fine-grained English all-words task, our system employed for the coarse-grained English all-words task was trained with the coarse-grained sense inventory released by the task organizers.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9644755125045776}]}, {"text": "Our scores (for both recall and precision) are 0.825 and 0.587 for the coarse-grained English all-words task and fine-grained English all-words task respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9988688826560974}, {"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9968968629837036}]}, {"text": "These scores put our systems in the first place for the coarse-grained English all-words task 1 and the second place for the fine-grained English all-words task.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe the systems we developed for the coarse-grained English all-words task A system developed by one of the task organizers of the coarse-grained English all-words task gave the highest overall score for the coarse-grained English all-words task, but this score is not considered part of the official scores. and fine-grained English all-words task of In the coarse-grained English all-words task, systems have to perform word sense disambiguation (WSD) of all content words (noun, adjective, verb, and adverb) occurring in five documents, using a coarse-grained version of the WordNet sense inventory.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD) of all content words (noun, adjective, verb, and adverb) occurring in five documents", "start_pos": 445, "end_pos": 561, "type": "TASK", "confidence": 0.8012221045792103}, {"text": "WordNet sense inventory", "start_pos": 601, "end_pos": 624, "type": "DATASET", "confidence": 0.8777114947636923}]}, {"text": "In the fine-grained English all-words task, systems have to predict the correct sense of verbs and head nouns of the verb arguments occurring in three documents, according to the fine-grained sense inventory of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 211, "end_pos": 218, "type": "DATASET", "confidence": 0.9497113823890686}]}, {"text": "Results from previous SENSEVAL English allwords task have shown that supervised learning gives the best performance.", "labels": [], "entities": [{"text": "SENSEVAL English allwords task", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.8389169871807098}]}, {"text": "Further, the best performing system in SENSEVAL-3 English all-words task) used training data gathered from multiple sources, highlighting the importance of having a large amount of training data.", "labels": [], "entities": [{"text": "SENSEVAL-3 English all-words task", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.5549667850136757}]}, {"text": "Hence, besides gathering examples from the widely used SEMCOR corpus, we also gathered training examples from 6 English-Chinese parallel corpora and the DSO corpus).", "labels": [], "entities": [{"text": "SEMCOR corpus", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.875512570142746}, {"text": "DSO corpus", "start_pos": 153, "end_pos": 163, "type": "DATASET", "confidence": 0.9885493516921997}]}, {"text": "We developed 2 separate systems; one for each task.", "labels": [], "entities": []}, {"text": "For both systems, we performed supervised word sense disambiguation based on the approach of () and using Support Vector Machines (SVM) as our learning algorithm.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7357539633909861}]}, {"text": "The knowledge sources used include local collocations, parts-of-speech (POS), and surrounding words.", "labels": [], "entities": []}, {"text": "Our system employed for the coarse-grained English allwords task was trained with the coarse-grained sense inventory released by the task organizers, while our system employed for the fine-grained English allwords task was trained with the fine-grained sense inventory of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 272, "end_pos": 279, "type": "DATASET", "confidence": 0.9788157939910889}]}, {"text": "In the next section, we describe the different sources of training data used.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the knowledge sources used by the learning algorithm.", "labels": [], "entities": []}, {"text": "In Section 4, we present our official evaluation results, before concluding in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We participated in two tasks of SemEval-2007: the coarse-grained English all-words task and the finegrained English all-words task.", "labels": [], "entities": []}, {"text": "In both tasks, when there is no training data at all fora particular word, we tag all test examples of the word with its first sense in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 136, "end_pos": 143, "type": "DATASET", "confidence": 0.9754434823989868}]}, {"text": "Since our systems give exactly one answer for each test example, recall is the same as precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9996474981307983}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9992227554321289}]}, {"text": "Hence we will just report the microaverage recall in this section.", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9192162156105042}]}], "tableCaptions": [{"text": " Table 1: Scores for the coarse-grained English all- words task and fine-grained English all-words task,  using different sets of training data. SC+DSO  refers to using examples gathered from SEMCOR  and DSO corpus. Similarly, SC+DSO+PT refers to  using examples gathered from SEMCOR, DSO cor- pus, and parallel texts.", "labels": [], "entities": [{"text": "SEMCOR", "start_pos": 192, "end_pos": 198, "type": "DATASET", "confidence": 0.8844655156135559}, {"text": "DSO corpus", "start_pos": 204, "end_pos": 214, "type": "DATASET", "confidence": 0.7689200639724731}, {"text": "PT", "start_pos": 234, "end_pos": 236, "type": "METRIC", "confidence": 0.9795178771018982}, {"text": "SEMCOR", "start_pos": 277, "end_pos": 283, "type": "DATASET", "confidence": 0.9538173675537109}]}, {"text": " Table 2: Score of each individual test document, for  the coarse-grained English all-words task.", "labels": [], "entities": [{"text": "Score", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9909323453903198}]}]}