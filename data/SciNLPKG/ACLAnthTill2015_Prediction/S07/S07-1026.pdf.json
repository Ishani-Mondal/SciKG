{"title": [{"text": "CUNIT: A Semantic Role Labeling System for Modern Standard Arabic", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.6245759328206381}, {"text": "Modern Standard Arabic", "start_pos": 43, "end_pos": 65, "type": "DATASET", "confidence": 0.8528968890508016}]}], "abstractContent": [{"text": "In this paper, we present a system for Ara-bic semantic role labeling (SRL) based on SVMs and standard features.", "labels": [], "entities": [{"text": "Ara-bic semantic role labeling (SRL)", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.7046178579330444}]}, {"text": "The system is evaluated on the released SEMEVAL 2007 development and test data.", "labels": [], "entities": [{"text": "SEMEVAL 2007 development and test data", "start_pos": 40, "end_pos": 78, "type": "DATASET", "confidence": 0.8374345997969309}]}, {"text": "The results show an F \u03b2=1 score of 94.06 on argument boundary detection and an overall F \u03b2=1 score of 81.43 on the complete semantic role labeling task using gold parse trees.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9791602253913879}, {"text": "argument boundary detection", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.6418091754118601}, {"text": "F \u03b2=1 score", "start_pos": 87, "end_pos": 98, "type": "METRIC", "confidence": 0.9842512369155884}, {"text": "semantic role labeling", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.6181939045588175}]}], "introductionContent": [{"text": "There is a widely held belief in the computational linguistics field that identifying and defining the roles of predicate arguments, semantic role labeling (SRL), in a sentence has a lot of potential for and is a significant step towards the improvement of important applications such as document retrieval, machine translation, question answering and information extraction.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 133, "end_pos": 161, "type": "TASK", "confidence": 0.7875212927659353}, {"text": "document retrieval", "start_pos": 288, "end_pos": 306, "type": "TASK", "confidence": 0.7732082903385162}, {"text": "machine translation", "start_pos": 308, "end_pos": 327, "type": "TASK", "confidence": 0.8069980144500732}, {"text": "question answering", "start_pos": 329, "end_pos": 347, "type": "TASK", "confidence": 0.9132211208343506}, {"text": "information extraction", "start_pos": 352, "end_pos": 374, "type": "TASK", "confidence": 0.8569516241550446}]}, {"text": "However, effective ways for seeing this belief come to fruition require a lot more research investment.", "labels": [], "entities": []}, {"text": "Since most of the available data resources are for the English language, most of the reported SRL systems to date only deal with English.", "labels": [], "entities": [{"text": "SRL", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9728059768676758}]}, {"text": "Nevertheless, we do see some headway for other languages, such as German and Chinese).", "labels": [], "entities": []}, {"text": "The systems for non-English languages follow the successful models devised for English, e.g. (. However, no SRL system exists for Arabic.", "labels": [], "entities": []}, {"text": "In this paper, we present a system for semantic role labeling for modern standard Arabic.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.6973077058792114}]}, {"text": "To our knowledge, it is the first SRL system fora semitic language in the literature.", "labels": [], "entities": [{"text": "SRL", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9782441854476929}]}, {"text": "It is based on a supervised model that uses support vector machines (SVM) technology for argument boundary detection and argument classification.", "labels": [], "entities": [{"text": "argument boundary detection", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.6650967299938202}, {"text": "argument classification", "start_pos": 121, "end_pos": 144, "type": "TASK", "confidence": 0.7447577118873596}]}, {"text": "It is trained and tested using the pilot Arabic PropBank data released as part of the SEMEVAL 2007 data.", "labels": [], "entities": [{"text": "Arabic PropBank data released", "start_pos": 41, "end_pos": 70, "type": "DATASET", "confidence": 0.9026524275541306}, {"text": "SEMEVAL 2007 data", "start_pos": 86, "end_pos": 103, "type": "DATASET", "confidence": 0.8023447195688883}]}, {"text": "Given the lack of a reliable deep syntactic parser, in this research we use gold trees.", "labels": [], "entities": []}, {"text": "The system yields an F-score of 94.06 on the sub task of argument boundary detection and an F-score of 81.43 on the complete task, i.e. boundary plus classification.", "labels": [], "entities": [{"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9991223216056824}, {"text": "argument boundary detection", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6369455754756927}, {"text": "F-score", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9990910291671753}]}], "datasetContent": [{"text": "In these experiments, we investigate if the technology proposed in previous work for automatic SRL of English texts is suitable for Arabic SRL systems.", "labels": [], "entities": [{"text": "SRL of English texts", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.9164320081472397}, {"text": "SRL", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.9170909523963928}]}, {"text": "From this perspective, we tested each SRL phase, i.e. boundary detection and argument classification, separately.", "labels": [], "entities": [{"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.8865044116973877}, {"text": "boundary detection", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7132161408662796}, {"text": "argument classification", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.7045691460371017}]}, {"text": "The final labeling accuracy that we derive using the official CoNLL evaluator) along with the official development and test data of SEMEVAL provides a reliable assessment of the accuracy achievable by our SRL model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.6943339705467224}, {"text": "CoNLL evaluator", "start_pos": 62, "end_pos": 77, "type": "DATASET", "confidence": 0.9576826691627502}, {"text": "SEMEVAL", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.6658774018287659}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.994126558303833}]}, {"text": "We use the dataset released in the SEMEVAL 2007 Task 18 on Arabic Semantic Labeling, which is sampled from the Pilot Arabic PropBank.", "labels": [], "entities": [{"text": "SEMEVAL 2007 Task 18 on Arabic Semantic Labeling", "start_pos": 35, "end_pos": 83, "type": "TASK", "confidence": 0.5368169657886028}, {"text": "Pilot Arabic PropBank", "start_pos": 111, "end_pos": 132, "type": "DATASET", "confidence": 0.9142526785532633}]}, {"text": "Such data covers the 95 most frequent verbs in the Arabic Treebank III ver.", "labels": [], "entities": [{"text": "Arabic Treebank III ver", "start_pos": 51, "end_pos": 74, "type": "DATASET", "confidence": 0.8562629967927933}]}, {"text": "2 (ATB) ().", "labels": [], "entities": [{"text": "ATB)", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.8856305480003357}]}, {"text": "The ATB consists of MSA newswire data from Annhar newspaper from the months of July through November 2002.", "labels": [], "entities": [{"text": "MSA newswire data from Annhar newspaper", "start_pos": 20, "end_pos": 59, "type": "DATASET", "confidence": 0.877629409233729}]}, {"text": "An important characteristic of the dataset is the use of unvowelized Arabic in the Buckwalter transliteration scheme.", "labels": [], "entities": [{"text": "Buckwalter transliteration scheme", "start_pos": 83, "end_pos": 116, "type": "DATASET", "confidence": 0.9326553146044413}]}, {"text": "We used the gold standard parses in the ATB as a source for syntactic parses for the data.", "labels": [], "entities": [{"text": "ATB", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.5241597890853882}]}, {"text": "The data comprises a development set of 886 sentences, a test set of 902 sentences, and a training set of 8,402 sentences.", "labels": [], "entities": []}, {"text": "The development set comprises 1,725 argument instances, the test data comprises 1,661 argument instances, and training data comprises  The training instances for the boundary detection task relate to parse-tree nodes that do not correspond to correct boundaries.", "labels": [], "entities": [{"text": "boundary detection task", "start_pos": 166, "end_pos": 189, "type": "TASK", "confidence": 0.8000210523605347}]}, {"text": "For efficiency reasons, we use only the first 350K training instances for the boundary classifier out of more than 700K available.", "labels": [], "entities": []}, {"text": "The experiments are carried outwith the SVM-light-TK software available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes tree kernels in the SVM-light software.", "labels": [], "entities": []}, {"text": "This allows us to design a system which can exploit tree kernels in future research.", "labels": [], "entities": []}, {"text": "To implement the boundary classifier and the individual argument classifiers, we use a polynomial kernel with the default regularization parameter (of SVM-light), and a cost-factor equal to 1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Boundary detection F1 results on the development", "labels": [], "entities": [{"text": "Boundary detection F1", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.6668100158373514}]}, {"text": " Table 2: Argument classification results on the development", "labels": [], "entities": [{"text": "Argument classification", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.9404587149620056}]}, {"text": " Table 3: Argument classification results on the test set.", "labels": [], "entities": [{"text": "Argument classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9067546725273132}]}]}