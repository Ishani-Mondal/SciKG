{"title": [{"text": "UNIBA: JIGSAW algorithm for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.7623419562975565}]}], "abstractContent": [{"text": "Word Sense Disambiguation (WSD) is traditionally considered an AI-hard problem.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7776303539673487}]}, {"text": "A breakthrough in this field would have a significant impact on many relevant web-based applications, such as information retrieval and information extraction.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.8548493087291718}, {"text": "information extraction", "start_pos": 136, "end_pos": 158, "type": "TASK", "confidence": 0.838059812784195}]}, {"text": "This paper describes JIGSAW, a knowledge-based WSD system that attemps to disambiguate all words in a text by exploiting WordNet 1 senses.", "labels": [], "entities": []}, {"text": "The main assumption is that a specific strategy for each Part-Of-Speech (POS) is better than a single strategy.", "labels": [], "entities": []}, {"text": "We evaluated the accuracy of JIGSAW on SemEval-2007 task 1 competition 2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9994363188743591}, {"text": "JIGSAW", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.7694699764251709}, {"text": "SemEval-2007 task 1 competition", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7282432317733765}]}, {"text": "This task is an application-driven one, where the application is a fixed cross-lingual information retrieval system.", "labels": [], "entities": []}, {"text": "Participants disambiguate text by assigning WordNet synsets, then the system has to do the expansion to other languages , index the expanded documents and run the retrieval for all the languages in batch.", "labels": [], "entities": []}, {"text": "The retrieval results are taken as a measure for the effectiveness of the disam-biguation.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We performed the experiment following the instructions for.", "labels": [], "entities": []}, {"text": "JIGSAW is implemented in JAVA, by using JWNL library 3 in order to access WordNet 1.6 dictionary.", "labels": [], "entities": [{"text": "JIGSAW", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9541524648666382}, {"text": "JAVA", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.9364485740661621}, {"text": "JWNL library", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.9360055923461914}, {"text": "WordNet 1.6 dictionary", "start_pos": 74, "end_pos": 96, "type": "DATASET", "confidence": 0.8934951623280843}]}, {"text": "We ran the experiment on a Linux-based PC with Intel Pentium D processor having a speed of 3 GHz and 2 GB of RAM.", "labels": [], "entities": [{"text": "RAM", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.9647417664527893}]}, {"text": "The dataset consists of 29,681 documents, including 300 topics.", "labels": [], "entities": []}, {"text": "Only two systems (PART-A and PART-B) partecipated to the competition, thus the organizers decided to add a third system (ORGA-NIZERS) developed by themselves.", "labels": [], "entities": [{"text": "PART-A", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.6788666844367981}, {"text": "PART-B", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.7012380957603455}, {"text": "ORGA-NIZERS", "start_pos": 121, "end_pos": 132, "type": "METRIC", "confidence": 0.9895349144935608}]}, {"text": "The systems were scored according to standard IR/CLIR measures as implemented in the TREC evaluation package 4 . Our system is labelled as PART-A.", "labels": [], "entities": [{"text": "IR", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.6694772839546204}, {"text": "TREC evaluation package 4", "start_pos": 85, "end_pos": 110, "type": "DATASET", "confidence": 0.8284232318401337}, {"text": "PART-A", "start_pos": 139, "end_pos": 145, "type": "DATASET", "confidence": 0.5259210467338562}]}, {"text": "All systems show similar results in IR tasks, while their behaviour is extremely different on CLIR task.", "labels": [], "entities": [{"text": "IR tasks", "start_pos": 36, "end_pos": 44, "type": "TASK", "confidence": 0.9359291195869446}]}, {"text": "WSD results are reported in.", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6498167514801025}]}, {"text": "These results are encouraging as regard precision, considering that our system exploits only WordNet as kwnoledge-base, while ORGANIZERS uses a supervised method that exploits SemCor to train a kNN classifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.998677670955658}, {"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9674728512763977}]}], "tableCaptions": [{"text": " Table 1. Only two systems (PART-A and  PART-B) partecipated to the competition, thus the  organizers decided to add a third system (ORGA- NIZERS) developed by themselves. The systems  were scored according to standard IR/CLIR mea- sures as implemented in the TREC evaluation pack- age 4 . Our system is labelled as PART-A.", "labels": [], "entities": [{"text": "ORGA- NIZERS)", "start_pos": 133, "end_pos": 146, "type": "METRIC", "confidence": 0.9397900402545929}, {"text": "IR/CLIR mea- sures", "start_pos": 219, "end_pos": 237, "type": "METRIC", "confidence": 0.7307515243689219}, {"text": "TREC evaluation pack", "start_pos": 260, "end_pos": 280, "type": "DATASET", "confidence": 0.8229261636734009}]}, {"text": " Table 1: SemEval-2007 task 1 Results", "labels": [], "entities": [{"text": "SemEval-2007 task", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7569756805896759}]}, {"text": " Table 2. These re- sults are encouraging as regard precision, consid- ering that our system exploits only WordNet as  kwnoledge-base, while ORGANIZERS uses a su- pervised method that exploits SemCor to train a  kNN classifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9991596937179565}, {"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.966230571269989}]}, {"text": " Table 2: WSD results on all-words task", "labels": [], "entities": [{"text": "WSD", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7072656750679016}]}]}