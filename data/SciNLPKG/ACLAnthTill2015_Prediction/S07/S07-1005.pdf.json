{"title": [{"text": "SemEval-2007 Task 06: Word-Sense Disambiguation of Prepositions", "labels": [], "entities": [{"text": "Word-Sense Disambiguation of Prepositions", "start_pos": 22, "end_pos": 63, "type": "TASK", "confidence": 0.8057688251137733}]}], "abstractContent": [{"text": "The SemEval-2007 task to disambiguate prepositions was designed as a lexical sample task.", "labels": [], "entities": [{"text": "SemEval-2007 task to disambiguate prepositions", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.742607843875885}]}, {"text": "A set of over 25,000 instances was developed, covering 34 of the most frequent English prepositions, with two-thirds of the instances for training and one-third as the test set.", "labels": [], "entities": []}, {"text": "Each instance identified a preposition to be tagged in a full sentence taken from the FrameNet corpus (mostly from the British National Corpus).", "labels": [], "entities": [{"text": "FrameNet corpus", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.9553960263729095}, {"text": "British National Corpus)", "start_pos": 119, "end_pos": 143, "type": "DATASET", "confidence": 0.9495041370391846}]}, {"text": "Definitions from the Oxford Dictionary of English formed the sense inventories.", "labels": [], "entities": [{"text": "Oxford Dictionary of English", "start_pos": 21, "end_pos": 49, "type": "DATASET", "confidence": 0.9610698819160461}]}, {"text": "Three teams participated, with all achieving supervised results significantly better than baselines, with a high fine-grained precision of 0.693.", "labels": [], "entities": [{"text": "precision", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.8536264896392822}]}, {"text": "This level is somewhat similar to results on lexical sample tasks with open class words, indicating that significant progress has been made.", "labels": [], "entities": []}, {"text": "The data generated in the task provides ample opportunitites for further investigations of preposition behavior.", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval-2007 task to disambiguate prepositions was designed as a lexical sample task to investigate the extent to which an important closed class of words could be disambiguated.", "labels": [], "entities": [{"text": "SemEval-2007 task to disambiguate prepositions", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.6994289934635163}]}, {"text": "In addition, because they area closed class, with stable senses, the requisite datasets for this task are enduring and can be used as long as the problem of preposition disambiguation remains.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 157, "end_pos": 183, "type": "TASK", "confidence": 0.7163378894329071}]}, {"text": "The data used in this task was developed in The Preposition Project (TPP, and), with further refinements to fit the requirements of a SemEval task.", "labels": [], "entities": [{"text": "The Preposition Project (TPP", "start_pos": 44, "end_pos": 72, "type": "DATASET", "confidence": 0.6558865487575531}, {"text": "SemEval task", "start_pos": 134, "end_pos": 146, "type": "TASK", "confidence": 0.9096298515796661}]}, {"text": "In the following sections, we first describe the motivations fora preposition disambiguation task.", "labels": [], "entities": [{"text": "preposition disambiguation task", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.7991341352462769}]}, {"text": "Next, we describe the development of the datasets used for the task, i.e., the instance sets and the sense inventories.", "labels": [], "entities": []}, {"text": "We describe how the task was performed and how it was evaluated (essentially using the same scoring methods as previous Senseval lexical sample tasks).", "labels": [], "entities": []}, {"text": "We present the results obtained from the participating teams and provide an initial analysis of these results.", "labels": [], "entities": []}, {"text": "Finally, we identify several further types of analyses that will provide further insights into the characterization of preposition behavior.", "labels": [], "entities": []}], "datasetContent": [{"text": "The development of the datasets for the preposition disambiguation task grew directly out of TPP.", "labels": [], "entities": [{"text": "preposition disambiguation task", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.8591369787851969}, {"text": "TPP", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.8256943821907043}]}, {"text": "This project essentially articulates the corpus selection, the lexicon choice, and the production of the gold standard.", "labels": [], "entities": [{"text": "corpus selection", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7123878449201584}]}, {"text": "The primary objective of TPP is to characterize each of 847 preposition senses for 373 prepositions (including 220 phrasal prepositions with 309 senses) 2 with a semantic role name and the syntactic and semantic properties of its complement and attachment point.", "labels": [], "entities": []}, {"text": "The preposition sense inventory is taken from the Oxford Dictionary of English (ODE, 2004).", "labels": [], "entities": [{"text": "Oxford Dictionary of English (ODE, 2004)", "start_pos": 50, "end_pos": 90, "type": "DATASET", "confidence": 0.9607144196828207}]}, {"text": "3  The organization followed standard SemEval (Senseval) procedures.", "labels": [], "entities": []}, {"text": "The data were prepared in XML, using Senseval DTDs.", "labels": [], "entities": []}, {"text": "That is, each instance was labeled with an instance identifier as an XML attribute.", "labels": [], "entities": []}, {"text": "Within the <instance> tag, the FrameNet sentence was labeled as the <context> and included one item, the target preposition, in the <head> tag.", "labels": [], "entities": []}, {"text": "The FrameNet sentence identifier was used as the instance identifier, enabling participants to make use of other FrameNet data.", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.9271330237388611}]}, {"text": "Unlike lexical sample tasks for open class words, only one sentence was provided as the context.", "labels": [], "entities": []}, {"text": "Although no examination of whether this is sufficient context for prepositions, it seems likely that all information necessary for preposition disambiguation is contained in the local context.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.723064735531807}]}, {"text": "A trial set of three prepositions was provided (the three smallest instance sets that had been developed).", "labels": [], "entities": []}, {"text": "For each of the remaining 34 prepositions, the data was split in a ratio of two to one between training and test data.", "labels": [], "entities": []}, {"text": "The training data included the sense identifier.", "labels": [], "entities": []}, {"text": "shows the total number of instances for each preposition, along with the number in the training and the test sets.", "labels": [], "entities": []}, {"text": "Answers were submitted in the standard Senseval format, consisting of the lexical item name, the instance identifier, the system sense assignments, and optional comments.", "labels": [], "entities": []}, {"text": "Although participants were not restricted to selecting only one sense, all did so and did not provide either multiple senses or weighting of different senses.", "labels": [], "entities": []}, {"text": "Because of this, a simple Perl script was used to score the results, giving precision, recall, and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9997281432151794}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.999645471572876}, {"text": "F-score", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9982559084892273}]}, {"text": "The answers were also scored using the standard Senseval scoring program, which records a result for \"attempted\" rather than F-score, with precision interpreted as percent of attempted instances that are correct and recall as percent of total instances that are correct.", "labels": [], "entities": [{"text": "F-score", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.9870632290840149}, {"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.9985297918319702}, {"text": "recall", "start_pos": 216, "end_pos": 222, "type": "METRIC", "confidence": 0.9936413168907166}]}, {"text": "8 use the standard notions of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9994537234306335}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9984784722328186}]}, {"text": "present the overall fine-grained and coarse-grained results, respectively, for the three participating teams (University of Melbourne, Ko\u00e7 University, and Instituto Trentino di Cultura, IRST).", "labels": [], "entities": []}, {"text": "The tables show the team designator, and the results overall prepositions, giving the precision, the recall, and the F-score.", "labels": [], "entities": [{"text": "prepositions", "start_pos": 61, "end_pos": 73, "type": "METRIC", "confidence": 0.9529656767845154}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9998192191123962}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9998332262039185}, {"text": "F-score", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.9982315897941589}]}, {"text": "The table also shows the results for two baselines.", "labels": [], "entities": []}, {"text": "The FirstSense baseline selects the first sense of each preposition as the answer (under the assumption that the senses are organized somewhat according to prominence).", "labels": [], "entities": [{"text": "FirstSense baseline", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.840887725353241}]}, {"text": "The FreqSense baseline selects the most frequent sense from the training set.", "labels": [], "entities": [{"text": "FreqSense baseline", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8200828433036804}]}, {"text": "shows the fine-grained recall scores for each team for each preposition.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9599471688270569}]}, {"text": "also shows the entropy and perplexity for each preposition, based on the data from the training sets.", "labels": [], "entities": [{"text": "entropy", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9679914116859436}]}, {"text": "As can be seen, all participating teams performed significantly better than the baselines.", "labels": [], "entities": []}, {"text": "Additional improvements occurred at the coarse grain, although the differences are not dramatically higher.", "labels": [], "entities": [{"text": "coarse grain", "start_pos": 40, "end_pos": 52, "type": "METRIC", "confidence": 0.9328313171863556}]}], "tableCaptions": [{"text": " Table 2. Fine-Grained Scores  (All Prepositions -8096 Instances)  Team  Prec Rec  F  MELB-YB  0.693 1.000 0.818  KU  0.547 1.000 0.707  IRST-BP  0.496 0.864 0.630  FirstSense  0.289 1.000 0.449  FreqSense  0.396 1.000 0.568", "labels": [], "entities": [{"text": "Team  Prec Rec  F  MELB-YB  0.693 1.000 0.818  KU  0.547 1.000 0.707", "start_pos": 67, "end_pos": 135, "type": "METRIC", "confidence": 0.7918574810028076}, {"text": "IRST-BP  0.496 0.864 0.630  FirstSense  0.289 1.000 0.449  FreqSense  0.396 1.000 0.568", "start_pos": 137, "end_pos": 224, "type": "DATASET", "confidence": 0.8234403133392334}]}, {"text": " Table 3. Coarse-Grained Scores  (All Prepositions -8096 Instances)  Team  Prec Rec  F  MELB-YB  0.755 1.000 0.861  KU  0.642 1.000 0.782  IRST-BP  0.610 0.864 0.715  FirstSense  0.441 1.000 0.612  FreqSense  0.480 1.000 0.649", "labels": [], "entities": [{"text": "Team  Prec Rec  F  MELB-YB  0.755 1.000 0.861  KU  0.642 1.000 0.782", "start_pos": 69, "end_pos": 137, "type": "METRIC", "confidence": 0.7959433371822039}, {"text": "IRST-BP  0.610 0.864 0.715  FirstSense  0.441 1.000 0.612  FreqSense  0.480 1.000 0.649", "start_pos": 139, "end_pos": 226, "type": "DATASET", "confidence": 0.841774066289266}]}]}