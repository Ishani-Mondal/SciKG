{"title": [{"text": "UMND2 : SenseClusters Applied to the Sense Induction Task of SENSEVAL-4", "labels": [], "entities": [{"text": "UMND2", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9314569234848022}, {"text": "Sense Induction Task", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.7545246581236521}, {"text": "SENSEVAL-4", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.4133787155151367}]}], "abstractContent": [{"text": "SenseClusters is a freely-available open-source system that served as the University of Minnesota, Duluth entry in the SENSEVAL-4 sense induction task.", "labels": [], "entities": [{"text": "SenseClusters", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8559941053390503}, {"text": "SENSEVAL-4 sense induction task", "start_pos": 119, "end_pos": 150, "type": "TASK", "confidence": 0.863028809428215}]}, {"text": "For this task SenseClusters was configured to construct representations of the instances to be clustered using the centroid of word co-occurrence vectors that replace the words in an instance.", "labels": [], "entities": []}, {"text": "These instances are then clustered using k-means where the number of clusters is discovered automatically using the Adapted Gap Statistic.", "labels": [], "entities": []}, {"text": "In these experiments SenseClusters did not use any information outside of the raw untagged text that was to be clustered, and no tuning of the system was performed using external corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "The object of the sense induction task of SENSEVAL-4 () was to cluster 27,132 instances of 100 different words (35 nouns and 65 verbs) into senses or classes.", "labels": [], "entities": [{"text": "sense induction", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7501799166202545}]}, {"text": "The task data consisted of the combination of the test and training data (minus the sense tags) from the English lexical sample task.", "labels": [], "entities": []}, {"text": "Each instance is a context of several sentences which contains an occurrence of a given word that serves as the target of sense induction.", "labels": [], "entities": [{"text": "sense induction", "start_pos": 122, "end_pos": 137, "type": "TASK", "confidence": 0.681688517332077}]}, {"text": "SenseClusters is based on the presumption that words that occur in similar contexts will have similar meanings.", "labels": [], "entities": []}, {"text": "This intuition has been presented as both the Distributional Hypothesis and the Strong Contextual Hypothesis.", "labels": [], "entities": []}, {"text": "SenseClusters has been in active development at the University of Minnesota, Duluth since 2002.", "labels": [], "entities": []}, {"text": "It is an open-source project that is freely-available from sourceforge, and has been been described in detail in numerous publications (e.g.,),),).", "labels": [], "entities": []}, {"text": "SenseClusters supports a variety of techniques for selecting lexical features, representing contexts to be clustered, determining the appropriate number of cluster automatically, clustering, labeling of clusters, and evaluating cluster quality.", "labels": [], "entities": []}, {"text": "The configuration used in SENSEVAL-4 was just one possible combination of these techniques.", "labels": [], "entities": [{"text": "SENSEVAL-4", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.7475244998931885}]}], "datasetContent": [{"text": "The unsupervised evaluation was based on the traditional clustering measures of F-score, entropy, and purity.", "labels": [], "entities": [{"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9899800419807434}, {"text": "purity", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9884026646614075}]}, {"text": "While the participating systems clustered the full 27,132 instances, only the 4,581 instance subset that corresponds to the English lexical sample evaluation data was scored in the evaluation.", "labels": [], "entities": [{"text": "English lexical sample evaluation data", "start_pos": 124, "end_pos": 162, "type": "DATASET", "confidence": 0.6350580811500549}]}, {"text": "shows the averaged F-scores overall 100 words, all 35 nouns, and all 65 verbs.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9977607727050781}]}, {"text": "In this table the SenseClusters system (UMND2) is compared to the MFS baseline, which is attained by assigning all the instances of a word to a single cluster.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.8499149680137634}]}, {"text": "We also include several random baselines, where randomX indicates that one of X possible clusters was randomly assigned to each instance of a word.", "labels": [], "entities": []}, {"text": "Thus, approximately 100 * X distinct clusters are created across the 100 words.", "labels": [], "entities": []}, {"text": "The random results are not ranked as they were not apart of the official evaluation.", "labels": [], "entities": []}, {"text": "We also present the highest (HIGH, rank 1) and lowest (LOW, rank 7) scores from participating systems, to provide points of comparison.", "labels": [], "entities": [{"text": "HIGH", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.6358515024185181}, {"text": "LOW", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9518628120422363}]}, {"text": "The randomX baseline is useful in determining the sensitivity of the evaluation technique to the number of clusters discovered.", "labels": [], "entities": []}, {"text": "The average number of classes in the gold standard test data is 2.9, so random3 approximates a system that randomly assigns the correct number of clusters.", "labels": [], "entities": [{"text": "gold standard test data", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.774170845746994}]}, {"text": "It attains an F-score of 50.0.", "labels": [], "entities": [{"text": "F-score", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9997835755348206}]}, {"text": "Note that random2 performs somewhat better (59.7), suggesting that all other things being equal, the F-score is biased towards methods that find a smaller than expected number of clusters.", "labels": [], "entities": [{"text": "F-score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9985791444778442}]}, {"text": "As the number of random clusters increases the Fscore declines sharply, showing that it is highly sensitive to the number of clusters discovered, and significantly penalizes systems that find more clusters than indicated in the gold standard data.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9960557222366333}]}, {"text": "We observed for UMND2 that purity (81.7) is quite a bit higher than the F-score (66.1), and that it discovered a smaller number of clusters on average (1.4) than exists in the gold standard data (2.9).", "labels": [], "entities": [{"text": "UMND2", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.7561320662498474}, {"text": "purity", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9971728324890137}, {"text": "F-score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9986862540245056}, {"text": "gold standard data", "start_pos": 176, "end_pos": 194, "type": "DATASET", "confidence": 0.6960528294245402}]}, {"text": "This shows that while SenseClusters was able to find relatively pure clusters, it errored in finding too few clusters, and was therefore penalized to some degree by the F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 169, "end_pos": 176, "type": "METRIC", "confidence": 0.9898123145103455}]}, {"text": "A supervised evaluation was also carried out on the same clustering of the 27,132 instances as was used in the unsupervised evaluation, following the method defined in ().", "labels": [], "entities": []}, {"text": "Here the train portion (22,281 instances) is used to learn a table of probabilities that is used to map discovered clusters in the test data to gold standard classes.", "labels": [], "entities": []}, {"text": "The cluster assigned to each instance in the test portion (4,851 instances) is mapped (assigned) to the most probable class associated with that cluster as defined by this table.", "labels": [], "entities": []}, {"text": "After this transformation is performed, the newly mapped test results are scored using the scorer2 program, which is the official evaluation program of the English lexical sample task and reports the Fmeasure, which in these experiments is simply accuracy since precision and recall are the same.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9945358037948608}, {"text": "accuracy", "start_pos": 247, "end_pos": 255, "type": "METRIC", "confidence": 0.9986621141433716}, {"text": "precision", "start_pos": 262, "end_pos": 271, "type": "METRIC", "confidence": 0.9987537860870361}, {"text": "recall", "start_pos": 276, "end_pos": 282, "type": "METRIC", "confidence": 0.9975565671920776}]}, {"text": "In we show the results of the supervised evaluation, which includes the highest and lowest score from participating systems, as well as We observed that the difference between the score of the best performing system (HIGH) and the random50 baseline is six points (81.6 -75.6).", "labels": [], "entities": []}, {"text": "In the unsupervised evaluation of this same data this difference is 61 points (78.9 -17.9) according to the F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 108, "end_pos": 115, "type": "METRIC", "confidence": 0.9966723918914795}]}, {"text": "The smaller range of values for the supervised measure can be understood by noting that the mapping operation alters the number and distribution of clusters as discovered in the test data.", "labels": [], "entities": []}, {"text": "For example, random3 results in an average of 2.9 clusters per word in the test data, but after mapping the average number of clusters is 1.1.", "labels": [], "entities": []}, {"text": "The average number of clusters discovered by UMND2 is 1.4, but after mapping this average is reduced to 1.1.", "labels": [], "entities": [{"text": "UMND2", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.814740777015686}]}, {"text": "For random50, the average number of clusters per word is 24.1, but after mapping is 2.0.", "labels": [], "entities": []}, {"text": "This shows that the supervised evaluation has a tendency to converge upon the MFS, which corresponds to assigning 1 cluster per word.", "labels": [], "entities": []}, {"text": "When looking at the randomX results in the supervised evaluation, it appears that this method does not penalize systems forgetting the number of clusters incorrect (as the F-score does).", "labels": [], "entities": [{"text": "F-score", "start_pos": 172, "end_pos": 179, "type": "METRIC", "confidence": 0.9431043863296509}]}, {"text": "This is shown by the very similar results for the randomX baselines, where the only difference in their results is the number of clusters.", "labels": [], "entities": [{"text": "randomX baselines", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.8155358135700226}]}, {"text": "This lack of a penalty is due to the fact that the mapping operation takes a potentially large number of clusters and maps them to relatively few classes (e.g., random50) and then performs the evaluation.", "labels": [], "entities": []}, {"text": "An evaluation was carried out on the full 27,132 instance train+test data set using the SenseClusters evaluation methodology, which was first defined in.", "labels": [], "entities": [{"text": "instance train+test data set", "start_pos": 49, "end_pos": 77, "type": "DATASET", "confidence": 0.7936922609806061}]}, {"text": "This corresponds to an unsupervised version of the F-measure, which in these experiments can be viewed as an accuracy measure since precision and recall are the same (as is the case for the supervised measure).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9728708267211914}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9983371496200562}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.999030590057373}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9967336654663086}]}, {"text": "It aligns discovered clusters with classes such that their agreement is maximized.", "labels": [], "entities": []}, {"text": "The clusters and classes must be aligned one to one, so a large penalty can result if the number of discovered clusters differs from the number of gold standard classes.", "labels": [], "entities": []}, {"text": "For UMND2, there were 145 discovered clusters and 368 gold standard classes.", "labels": [], "entities": [{"text": "UMND2", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.8336153626441956}]}, {"text": "Due to the one to one alignment that is required, the 145 discovered clusters were aligned with 145 gold standard classes such that there was agreement for 15,291 of 27,132 instances, leading to an F-measure (accuracy) of 56.36 percent.", "labels": [], "entities": [{"text": "F-measure (accuracy)", "start_pos": 198, "end_pos": 218, "type": "METRIC", "confidence": 0.8953593820333481}]}, {"text": "Note that this is significantly lower than the F-score of UMND2 for the train+test data, which was 63.1.", "labels": [], "entities": [{"text": "F-score", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9996047616004944}, {"text": "UMND2", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.8660876750946045}, {"text": "train+test data", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.814933106303215}]}, {"text": "This illustrates that the SenseClusters F-measure and the F-score are not equivalent.", "labels": [], "entities": [{"text": "SenseClusters", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.5312490463256836}, {"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.4016912579536438}, {"text": "F-score", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9877153038978577}]}], "tableCaptions": [{"text": " Table 1: Unsupervised F-Score (test)  All Nouns Verbs Rank  MFS/HIGH 78.9  80.7  76.8  1  UMND2  66.1  67.1  65.0  4  random2  59.7  60.9  58.4  LOW  56.1  65.8  45.1  7  random3  50.0  49.9  50.1  random4  44.9  44.2  45.7  random10  29.7  28.0  31.7  random50  17.9  14.9  21.1", "labels": [], "entities": [{"text": "F-Score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9387215375900269}, {"text": "MFS/HIGH 78.9  80.7  76.8", "start_pos": 61, "end_pos": 86, "type": "DATASET", "confidence": 0.8769907156626383}]}, {"text": " Table 2: Supervised Accuracy (test)  All Nouns Verbs Rank  HIGH  81.6  86.8  75.7  1  UMND2  80.6  84.5  76.2  2  random2  78.9  81.6  75.8  MFS  78.7  80.9  76.2  4  LOW  78.5  81.4  75.2  7  random4  78.4  81.1  75.5  random3  78.3  80.5  75.9  random10 77.9  79.8  75.8  random50 75.6  78.5  72.4", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9390373229980469}, {"text": "MFS  78.7  80.9  76.2  4  LOW  78.5  81.4  75.2  7  random4  78.4  81.1  75.5  random3  78.3  80.5  75.9  random10 77.9  79.8  75.8  random50 75.6  78.5  72.4", "start_pos": 142, "end_pos": 300, "type": "DATASET", "confidence": 0.8282047693546002}]}]}