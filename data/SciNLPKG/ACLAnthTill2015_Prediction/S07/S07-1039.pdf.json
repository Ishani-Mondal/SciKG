{"title": [{"text": "ILK: Machine learning of semantic relations with shallow features and almost no data", "labels": [], "entities": [{"text": "ILK", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7200677990913391}]}], "abstractContent": [{"text": "This paper summarizes our approach to the Semeval 2007 shared task on \"Classifica-tion of Semantic Relations between Nom-inals\".", "labels": [], "entities": []}, {"text": "Our overall strategy is to develop machine-learning classifiers making use of a few easily computable and effective features , selected independently for each clas-sifier in wrapper experiments.", "labels": [], "entities": []}, {"text": "We train two types of classifiers for each of the seven relations: with and without WordNet information .", "labels": [], "entities": [{"text": "WordNet information", "start_pos": 84, "end_pos": 103, "type": "DATASET", "confidence": 0.924391895532608}]}], "introductionContent": [{"text": "We interpret the task of determining semantic relations between nominals as a classification problem that can be solved, per relation, by machine learning algorithms.", "labels": [], "entities": []}, {"text": "We aim at using straightforward features that are easy to compute and relevant to preferably all of the seven relations central to the task.", "labels": [], "entities": []}, {"text": "The starting conditions of the task provide us with a very small amount of training data, which further stresses the need for robust, generalizable features, that generalize beyond surface words.", "labels": [], "entities": []}, {"text": "We therefore hypothesize that generic information on the lexical semantics of the entities involved in the relation is crucial.", "labels": [], "entities": []}, {"text": "We developed two systems, based on two sources of semantic information.", "labels": [], "entities": []}, {"text": "Since the entities in the provided data were word-sense disambiguated, an obvious way to model their lexical semantics was by utilizing WordNet3.0) (WN).", "labels": [], "entities": [{"text": "WordNet3.0) (WN)", "start_pos": 136, "end_pos": 152, "type": "DATASET", "confidence": 0.8793998599052429}]}, {"text": "One of the systems followed this route.", "labels": [], "entities": []}, {"text": "We also entered a second system, which did not rely on WN but instead made use of automatically generated semantic clusters) to model the semantic classes of the entities.", "labels": [], "entities": []}, {"text": "For both systems we trained seven binary classifiers; one for each relation.", "labels": [], "entities": []}, {"text": "From a pool of easily computable features, we selected feature subsets for each classifier in a number of wrapper experiments, i.e. repeated cross-validation experiments on the training set to test out subset selections systematically.", "labels": [], "entities": []}, {"text": "Along with feature subsets we also chose the machine-learning method independently for each classifier.", "labels": [], "entities": []}, {"text": "Section 2 presents the system description, Section 3, the results, and Section 4, the conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Average accuracy on the training set com- puted in 10-fold CV experiments of the cluster- based system (A) and the WN-based system (B).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9966602325439453}]}, {"text": " Table 4: Test scores for the seven relations of the  cluster-based system trained on 140 examples (A4).", "labels": [], "entities": []}, {"text": " Table 5: Test scores for the seven relations of the  WN-based system trained on 140 examples (B4).", "labels": [], "entities": []}]}