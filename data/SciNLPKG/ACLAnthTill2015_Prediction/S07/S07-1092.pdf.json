{"title": [{"text": "UOY: A Hypergraph Model For Word Sense Induction & Disambiguation", "labels": [], "entities": [{"text": "Word Sense Induction & Disambiguation", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.8073503136634826}]}], "abstractContent": [{"text": "This paper is an outcome of ongoing research and presents an unsupervised method for automatic word sense induction (WSI) and disambiguation (WSD).", "labels": [], "entities": [{"text": "word sense induction (WSI) and disambiguation (WSD)", "start_pos": 95, "end_pos": 146, "type": "TASK", "confidence": 0.7040755721655759}]}, {"text": "The induction algorithm is based on modeling the co-occurrences of two or more words using hypergraphs.", "labels": [], "entities": []}, {"text": "WSI takes place by detecting high-density components in the co-occurrence hypergraphs.", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9610693454742432}]}, {"text": "WSD assigns to each induced cluster a score equal to the sum of weights of its hyperedges found in the local context of the target word.", "labels": [], "entities": []}, {"text": "Our system participates in SemEval-2007 word sense induction and discrimination task.", "labels": [], "entities": [{"text": "SemEval-2007 word sense induction", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.8162983357906342}]}], "introductionContent": [{"text": "The majority of both supervised and unsupervised approaches to WSD is based on the \"fixed-list\" of senses paradigm where the senses of a target word is a closed list of definitions coming from a standard dictionary).", "labels": [], "entities": [{"text": "WSD", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9848700761795044}]}, {"text": "Lexicographers have long warned about the problems of such an approach, since dictionaries are not suited to this task; they often contain general definitions, they suffer from the lack of explicit semantic and topical relations or interconnections, and they often do not reflect the exact content of the context, in which the target word appears.", "labels": [], "entities": []}, {"text": "To overcome this limitation, unsupervised WSD has moved towards inducing the senses of a target word directly from a corpus, and then disambiguating each instance of it.", "labels": [], "entities": [{"text": "WSD", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9696560502052307}]}, {"text": "Most of the work in WSI is based on the vector space model, where the context of each instance of a target word is represented as a vector of features (e.g second-order word cooccurrences)).", "labels": [], "entities": [{"text": "WSI", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.8360769748687744}]}, {"text": "These vectors are clustered and the resulting clusters represent the induced senses.", "labels": [], "entities": []}, {"text": "However, as shown experimentally in), vector-based techniques are unable to detect lowfrequency senses of a target word.", "labels": [], "entities": []}, {"text": "Recently, graph-based methods were employed in WSI to isolate highly infrequent senses of a target word.) and the adaptation of PageRank () have been shown to outperform the most frequent sense (MFS) baseline in terms of supervised recall, but they still fall short of supervised WSD systems.", "labels": [], "entities": [{"text": "WSI", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9516469240188599}, {"text": "recall", "start_pos": 232, "end_pos": 238, "type": "METRIC", "confidence": 0.8587877750396729}]}, {"text": "Graph-based approaches operate on a 2-dimensional space, assuming a one-to-one relationship between co-occurring words.", "labels": [], "entities": []}, {"text": "However, this assumption is insufficient, taking into account the fact that two or more words are usually combined to form a relationship of concepts in the context.", "labels": [], "entities": []}, {"text": "Additionally, graph-based approaches fail to model and exploit the existence of collocations or terms consisting of more than two words.", "labels": [], "entities": []}, {"text": "This paper proposes a method for WSI, which is based on a hypergraph model operating on a n-dimensional space.", "labels": [], "entities": [{"text": "WSI", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9623240828514099}]}, {"text": "In such a model, cooccurrences of two or more words are represented using weighted hyperedges.", "labels": [], "entities": []}, {"text": "A hyperedge is a more expressive representation than a simple edge, because it is able to capture the information shared by two or more words.", "labels": [], "entities": []}, {"text": "Our system participates in SemEval-2007 word sense induction and discrimination task (SWSID)).", "labels": [], "entities": [{"text": "SemEval-2007 word sense induction and discrimination task (SWSID", "start_pos": 27, "end_pos": 91, "type": "TASK", "confidence": 0.7872653106848398}]}], "datasetContent": [{"text": "This method is an outcome of ongoing research.", "labels": [], "entities": []}, {"text": "Due to time restrictions we were able to test and tune, but not optimize, our system only on a very small set of nouns of S3LS targeting at a high supervised recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.987008273601532}]}, {"text": "Our supervised recall on the 10 first nouns of S3LS was 66.8%, 9.8% points above the MFS baseline.: Chosen parameters for our system show the average supervised recall, FScore, entropy and purity of our system on nouns and verbs of the test data respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.8052897453308105}, {"text": "MFS baseline.", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.6111868470907211}, {"text": "recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.8933730125427246}, {"text": "FScore", "start_pos": 169, "end_pos": 175, "type": "METRIC", "confidence": 0.9988269209861755}, {"text": "entropy", "start_pos": 177, "end_pos": 184, "type": "METRIC", "confidence": 0.9440137147903442}, {"text": "purity", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.9803118705749512}]}, {"text": "The submitted answer consisted only of the winning cluster per instance of a target word, in effect assigning it with weight 1 (default).", "labels": [], "entities": []}, {"text": "Entropy measures how well the various gold standard senses are distributed within each cluster, while purity measures how pure a cluster is, containing objects from primarily one class.", "labels": [], "entities": [{"text": "purity", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.982644259929657}]}, {"text": "In general, the lower the entropy and the larger the purity values, the better the clustering algorithm performs.", "labels": [], "entities": []}, {"text": "For nouns our system achieves a low entropy and a high purity outperforming the MFS baseline, but a lower FScore.", "labels": [], "entities": [{"text": "FScore", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9923271536827087}]}, {"text": "This can be explained by the fact that the average number of clusters we produce for nouns is 11, while the gold standard average of senses is around 2.8.", "labels": [], "entities": []}, {"text": "For verbs the performance of our system is worse than for nouns, although entropy and purity still outperform the MFS baseline.", "labels": [], "entities": [{"text": "purity", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9948875308036804}]}, {"text": "FScore is very low, despite that the average number of clusters we produce for verbs (around 8) is less than the number of clusters we produce for nouns.", "labels": [], "entities": [{"text": "FScore", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9246201515197754}]}, {"text": "This means that for verbs the senses of gold standard are much more spread among induced clusters than for nouns, causing a low unsupervised recall.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 40, "end_pos": 53, "type": "METRIC", "confidence": 0.7853212058544159}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9846722483634949}]}, {"text": "Overall, FScore results are in accordance with the idea of microsenses mentioned in (  Our supervised recall for verbs is 73.3%, and below the MFS baseline (76.2%), which no system managed to outperform.", "labels": [], "entities": [{"text": "FScore", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.5563679337501526}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9484438896179199}]}, {"text": "For nouns our supervised recall is 81.6%, which is around 0.7% above the MFS baseline.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.982219934463501}]}, {"text": "In order to fully examine the performance of our system we applied a second evaluation of our methodology using the SWSID official software.", "labels": [], "entities": [{"text": "SWSID official software", "start_pos": 116, "end_pos": 139, "type": "DATASET", "confidence": 0.8840773304303488}]}], "tableCaptions": [{"text": " Table 1: Chosen parameters for our system", "labels": [], "entities": []}, {"text": " Table 2: System performance for nouns.", "labels": [], "entities": []}, {"text": " Table 3: System performance for verbs.", "labels": [], "entities": []}, {"text": " Table 4: Supervised recall in second evaluation.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9934477210044861}]}]}