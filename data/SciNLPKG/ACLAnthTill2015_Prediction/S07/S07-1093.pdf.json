{"title": [{"text": "UP13: Knowledge-poor Methods (Sometimes) Perform Poorly", "labels": [], "entities": [{"text": "UP13", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6566569209098816}]}], "abstractContent": [{"text": "This short paper presents a system developed at the Universit\u00e9 Paris 13 for the Semeval 2007 Metonymy Resolution Task (task #08, location name track; see Markert and Nissim, 2007).", "labels": [], "entities": [{"text": "Semeval 2007 Metonymy Resolution Task", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.8716737389564514}]}, {"text": "The system makes use of plain word forms only.", "labels": [], "entities": []}, {"text": "In this paper, we evaluate the accuracy of this minimalist approach, compare it to a more complex one which uses both syntactic and semantic features, and discuss its usefulness for metonymy resolution in general.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9993700385093689}, {"text": "metonymy resolution", "start_pos": 182, "end_pos": 201, "type": "TASK", "confidence": 0.9591036736965179}]}], "introductionContent": [{"text": "This short paper presents the system developed at the Universit\u00e9 Paris 13 for the Metonymy resolution task, during.", "labels": [], "entities": [{"text": "Metonymy resolution task", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.9568061828613281}]}, {"text": "Two sub-tasks were proposed, concerning 1) country names and 2) company names.", "labels": [], "entities": []}, {"text": "We only participated in the first task (country names).", "labels": [], "entities": []}, {"text": "We developed a simple approach which we present and thoroughly evaluate in this paper.", "labels": [], "entities": []}, {"text": "We discuss the relevance of this approach and compare it to more complex ones.", "labels": [], "entities": []}], "datasetContent": [{"text": "We mainly discuss here the results of the coarse evaluation, where only literal vs non-literal meanings were targeted.", "labels": [], "entities": []}, {"text": "We did not develop any specific strategy for the other tracks (medium and fine) since there were too few examples in the training data.", "labels": [], "entities": []}, {"text": "We just transferred non-literal readings to the most probable class according to the training corpus (metonymic for medium, place-for-people for fine).", "labels": [], "entities": []}, {"text": "However, the performance of our system (i.e. accuracy) is relatively stable between these three tracks, since the distribution of examples between the different classes is very unequally distributed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9991156458854675}]}, {"text": "Before giving the results, recall that our purpose was to investigate a knowledge-poor strategy, in order to establish how far one can get using only surface indicators.", "labels": [], "entities": []}, {"text": "Thus, unsurprisingly, our results for the training corpus were already lower than those obtained using a more sophisticated system.", "labels": [], "entities": []}, {"text": "They are however a good indicator of performance when one uses only surface features.", "labels": [], "entities": []}, {"text": "The accuracy on the training corpus was .815.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997977614402771}, {"text": "training corpus", "start_pos": 20, "end_pos": 35, "type": "DATASET", "confidence": 0.6751119196414948}]}, {"text": "Precision and recall are presented in the", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.708619236946106}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9985550045967102}]}], "tableCaptions": [{"text": " Table 1. Results for the pattern in + LOC  (result tag = literal)", "labels": [], "entities": [{"text": "LOC", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9260305762290955}]}, {"text": " Table 2. Results for the pattern <at+within+\u2026>  + LOC (note that table 1 is contained in table 2)", "labels": [], "entities": [{"text": "LOC", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9969372749328613}]}, {"text": " Table 3. Results for the pattern LOC's  (result tag = literal)", "labels": [], "entities": []}, {"text": " Table 4. Results for the pattern LOC + <was,  should\u2026> (result tag = metonymic)", "labels": [], "entities": []}, {"text": " Table 5. Results for the pattern LOC +  <player, team\u2026> (result tag = metonymic)", "labels": [], "entities": []}, {"text": " Table 6. Overall results on the training corpus", "labels": [], "entities": []}, {"text": " Table 7. Overall results on the test corpus", "labels": [], "entities": []}]}