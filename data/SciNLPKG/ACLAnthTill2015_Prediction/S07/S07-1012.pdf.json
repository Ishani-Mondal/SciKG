{"title": [{"text": "The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task", "labels": [], "entities": [{"text": "SemEval-2007", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.8176186084747314}, {"text": "WePS Evaluation", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.5880138278007507}]}], "abstractContent": [{"text": "This paper presents the task definition, resources , participation, and comparative results for the Web People Search task, which was organized as part of the SemEval-2007 evaluation exercise.", "labels": [], "entities": []}, {"text": "This task consists of clustering a set of documents that mention an ambiguous person name according to the actual entities referred to using that name.", "labels": [], "entities": []}], "introductionContent": [{"text": "Finding information about people in the World Wide Web is one of the most common activities of Internet users.", "labels": [], "entities": [{"text": "Finding information about people in the World Wide Web", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8824278447363112}]}, {"text": "Person names, however, are highly ambiguous.", "labels": [], "entities": []}, {"text": "In most cases, the results fora person name search area mix of pages about different people sharing the same name.", "labels": [], "entities": []}, {"text": "The user is then forced either to add terms to the query (probably losing recall and focusing on one single aspect of the person), or to browse every document in order to filter the information about the person he is actually looking for.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9990397095680237}]}, {"text": "In an ideal system the user would simply type a person name, and receive search results clustered according to the different people sharing that name.", "labels": [], "entities": []}, {"text": "And this is, in essence, the WePS (Web People Search) task we have proposed to participants: systems receive a set of web pages (which are the result of a web search fora person name), and they have to cluster them in as many sets as entities sharing the name.", "labels": [], "entities": []}, {"text": "This task has close links with Word Sense Disambiguation (WSD), which is generally formulated as the task of deciding which sense a word has in a given context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.7821959853172302}]}, {"text": "In both cases, the problem addressed is the resolution of the ambiguity in a natural language expression.", "labels": [], "entities": []}, {"text": "A couple of differences make our problem different.", "labels": [], "entities": []}, {"text": "WSD is usually focused on openclass words (common nouns, adjectives, verbs and adverbs).", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9029761552810669}]}, {"text": "The first difference is that boundaries between word senses in a dictionary are often subtle or even conflicting, making binary decisions harder and sometimes even useless depending on the application.", "labels": [], "entities": []}, {"text": "In contrast, distinctions between people should be easier to establish.", "labels": [], "entities": []}, {"text": "The second difference is that WSD usually operates with a dictionary containing a relatively small number of senses that can be assigned to each word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9102972745895386}]}, {"text": "Our task is rather a case of Word Sense Discrimination, because the number of \"senses\" (actual people) is unknown a priori, and it is in average much higher than in the WSD task (there are 90,000 different names shared by 100 million people according to the U.S. Census Bureau).", "labels": [], "entities": [{"text": "Word Sense Discrimination", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.6995564897855123}, {"text": "WSD task", "start_pos": 169, "end_pos": 177, "type": "TASK", "confidence": 0.8587827980518341}]}, {"text": "There is also a strong relation of our proposed task with the Co-reference Resolution problem, focused on linking mentions (including pronouns) in a text.", "labels": [], "entities": [{"text": "Co-reference Resolution", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.8153426945209503}, {"text": "linking mentions (including pronouns) in a text", "start_pos": 106, "end_pos": 153, "type": "TASK", "confidence": 0.661811888217926}]}, {"text": "Our task can be seen as a co-reference resolution problem where the focus is on solving interdocument co-reference, disregarding the linking of all the mentions of an entity inside each document.", "labels": [], "entities": [{"text": "co-reference resolution", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7613019347190857}]}, {"text": "An early work in name disambiguation () uses the similarity between documents in a Vector Space using a \"bag of words\" representation.", "labels": [], "entities": [{"text": "name disambiguation", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9141066372394562}]}, {"text": "An alternative approach by is based on a rich feature space of automatically extracted biographic information.", "labels": [], "entities": []}, {"text": "propose a Maximum Entropy model trained to give the probability that two names refer to the same individual . The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides a description of the experimental methodology, the training and test data provided to the participants, the evaluation measures, baseline systems and the campaign design.", "labels": [], "entities": []}, {"text": "Section 3 gives a description of the participant systems and provides the evaluation results.", "labels": [], "entities": []}, {"text": "Finally, Section 4 presents some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation was performed in each document set (web pages mentioning an ambiguous person name) of the data distributed as test.", "labels": [], "entities": []}, {"text": "The human annotation was used as the gold standard for the evaluation.", "labels": [], "entities": []}, {"text": "Each system was evaluated using the standard purity and inverse purity clustering measures Purity is related to the precision measure, well known in Information Retrieval.", "labels": [], "entities": [{"text": "precision measure", "start_pos": 116, "end_pos": 133, "type": "METRIC", "confidence": 0.9878807961940765}, {"text": "Information Retrieval", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.7409796118736267}]}, {"text": "This measure focuses on the frequency of the most common category in each cluster, and rewards the clustering solutions that introduce less noise in each cluster.", "labels": [], "entities": []}, {"text": "Being C the set of clusters to be evaluated, L the set of categories (manually annotated) and n the number of clustered elements, purity is computed by taking the weighted average of maximal precision values: where the precision of a cluster Ci fora given category L j is defined as: Inverse Purity focuses on the cluster with maximum recall for each category, rewarding the clustering solutions that gathers more elements of each category in a corresponding single cluster.", "labels": [], "entities": [{"text": "purity", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9854788780212402}, {"text": "precision", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.5107335448265076}, {"text": "precision", "start_pos": 219, "end_pos": 228, "type": "METRIC", "confidence": 0.9938836097717285}, {"text": "recall", "start_pos": 335, "end_pos": 341, "type": "METRIC", "confidence": 0.9951176643371582}]}, {"text": "Inverse Purity is defined as: For the final ranking of systems we used the harmonic mean of purity and inverse purity F \u03b1= 0,5 . The F measure is defined as follows: Inverse Purity F \u03b1= 0,2 is included as an additional measure giving more importance to the inverse purity aspect.", "labels": [], "entities": [{"text": "purity", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.6597198247909546}, {"text": "inverse purity F \u03b1", "start_pos": 103, "end_pos": 121, "type": "METRIC", "confidence": 0.9358081221580505}, {"text": "F measure", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9803680777549744}]}, {"text": "The rationale is that, fora search engine user, it should be easier to discard a few incorrect web pages in a cluster containing all the information needed, than having to collect the relevant information across many different clusters.", "labels": [], "entities": []}, {"text": "Therefore, achieving a high inverse purity should be rewarded more than having high purity.", "labels": [], "entities": [{"text": "inverse purity", "start_pos": 28, "end_pos": 42, "type": "METRIC", "confidence": 0.8428317904472351}, {"text": "purity", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9778278470039368}]}, {"text": "29 teams expressed their interest in the task; this number exceeded our expectations for this pilot experience, and confirms the potential interest of the research community in this highly practical problem.", "labels": [], "entities": []}, {"text": "Out of them, 16 teams submitted results within the deadline; their results are reported below.", "labels": [], "entities": []}, {"text": "Considering only the participant systems, the average value for the ranking measure was 0, 60 and its standard deviation 0, 11.", "labels": [], "entities": []}], "tableCaptions": []}