{"title": [{"text": "SemEval-2007 Task 16: Evaluation of Wide Coverage Knowledge Resources", "labels": [], "entities": [{"text": "SemEval-2007 Task 16", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8408117890357971}]}], "abstractContent": [{"text": "This task tries to establish the relative quality of available semantic resources (derived by manual or automatic means).", "labels": [], "entities": []}, {"text": "The quality of each large-scale knowledge resource is indirectly evaluated on a Word Sense Dis-ambiguation task.", "labels": [], "entities": [{"text": "Word Sense Dis-ambiguation task", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.6341304928064346}]}, {"text": "In particular, we use Senseval-3 and SemEval-2007 English Lexical Sample tasks as evaluation bechmarks to evaluate the relative quality of each resource.", "labels": [], "entities": []}, {"text": "Furthermore, trying to be as neutral as possible with respect the knowledge bases studied, we apply systematically the same disambiguation method to all the resources.", "labels": [], "entities": []}, {"text": "A completely different behaviour is observed on both lexical data sets (Senseval-3 and SemEval-2007).", "labels": [], "entities": [{"text": "Senseval-3", "start_pos": 72, "end_pos": 82, "type": "DATASET", "confidence": 0.922807514667511}]}], "introductionContent": [{"text": "Using large-scale knowledge bases, such as WordNet, has become a usual, often necessary, practice for most current Natural Language Processing (NLP) systems.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9161205291748047}]}, {"text": "Even now, building large and rich enough knowledge bases for broad-coverage semantic processing takes a great deal of expensive manual effort involving large research groups during long periods of development.", "labels": [], "entities": [{"text": "broad-coverage semantic processing", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.7164730628331503}]}, {"text": "In fact, dozens of person-years have been invested in the development of wordnets for various languages.", "labels": [], "entities": []}, {"text": "For example, in more than ten years of manual construction (from version 1.5 to 2.1), WordNet passed from 103,445 semantic relations to 245,509 semantic relations . That is, around one thousand new relations per month.", "labels": [], "entities": []}, {"text": "But this data does not seems to be rich enough to support advanced concept-based NLP applications directly.", "labels": [], "entities": []}, {"text": "It seems that applications will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means.", "labels": [], "entities": []}, {"text": "Fortunately, during the last years, the research community has devised a large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora.", "labels": [], "entities": [{"text": "large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora", "start_pos": 119, "end_pos": 214, "type": "TASK", "confidence": 0.7724169059233232}]}, {"text": "Among others we can mention eXtended WordNet (), large collections of semantic preferences acquired from SemCor () or acquired from British National Corpus (BNC)), largescale Topic Signatures for each synset acquired from the web (Agirre and de la) or acquired from the BNC ().", "labels": [], "entities": [{"text": "British National Corpus (BNC))", "start_pos": 132, "end_pos": 162, "type": "DATASET", "confidence": 0.9723601341247559}, {"text": "BNC", "start_pos": 270, "end_pos": 273, "type": "DATASET", "confidence": 0.9683125615119934}]}, {"text": "Obviously, these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets (or between synsets and words).", "labels": [], "entities": []}, {"text": "Many international research groups are working on knowledge-based WSD using a wide range of approaches).", "labels": [], "entities": [{"text": "WSD", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.8383864164352417}]}, {"text": "However, less attention has been devoted on analysing the quality of each semantic resource.", "labels": [], "entities": []}, {"text": "In fact, each resource presents different volume and accuracy figures).", "labels": [], "entities": [{"text": "volume", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9697003364562988}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9728578925132751}]}, {"text": "In this paper, we evaluate those resources on the SemEval-2007 English Lexical Sample task.", "labels": [], "entities": [{"text": "SemEval-2007 English Lexical Sample task", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.589089435338974}]}, {"text": "For comparison purposes, we also include the results of the same resources on the Senseval-3 English Lexical sample task.", "labels": [], "entities": [{"text": "Senseval-3 English Lexical sample task", "start_pos": 82, "end_pos": 120, "type": "DATASET", "confidence": 0.8182350754737854}]}, {"text": "In both cases, we used only the nominal part of both data sets and we also included some basic baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to compare the knowledge resources, all the resources are evaluated as Topic Signatures (TS).", "labels": [], "entities": []}, {"text": "That is, word vectors with weights associated to a particular synset.", "labels": [], "entities": []}, {"text": "Normally, these word vectors are obtained by collecting from the resource understudy the word senses appearing as direct relatives.", "labels": [], "entities": []}, {"text": "This simple representation tries to be as neutral as possible with respect to the resources studied.", "labels": [], "entities": []}, {"text": "A common WSD method has been applied to all knowledge resources on the test examples of English lexical sample tasks.", "labels": [], "entities": [{"text": "WSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.8922304511070251}]}, {"text": "A simple word overlapping counting is performed between the Topic Signature and the test example.", "labels": [], "entities": [{"text": "word overlapping counting", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.7339252730210623}]}, {"text": "The synset having higher overlapping word counts is selected.", "labels": [], "entities": []}, {"text": "In fact, this is a very simple WSD method which only considers the topical information around the word to be disambiguated.", "labels": [], "entities": [{"text": "WSD", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9189173579216003}]}, {"text": "Finally, we should remark that the results are not skewed (for instance, for resolving ties) by the most frequent sense in WN or any other statistically predicted knowledge.", "labels": [], "entities": []}, {"text": "As an example, table 1 shows a test example of SemEval-2007 corresponding to the first sense of the noun capital.", "labels": [], "entities": []}, {"text": "In bold there are the words that appear in its corresponding Topic Signature acquired from the web.", "labels": [], "entities": []}, {"text": "Note that although there are several important related words, the WSD process implements exact word form matching (no preprocessing is performed).", "labels": [], "entities": [{"text": "word form matching", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.6038756569226583}]}], "tableCaptions": [{"text": " Table 2: P, R and F1 results for English Lexical Sam- ple Baselines of Senseval-3", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9987245202064514}, {"text": "Senseval-3", "start_pos": 72, "end_pos": 82, "type": "TASK", "confidence": 0.6795738339424133}]}, {"text": " Table 1: Example of test id for capital#n which its correct sense is 1", "labels": [], "entities": []}, {"text": " Table 4: Semantic relations uploaded in the MCR", "labels": [], "entities": [{"text": "MCR", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.862017810344696}]}, {"text": " Table 5: Topic Signatures for party#n#1 obtained  from Semcor (11 out of 719 total word senses)", "labels": [], "entities": []}, {"text": " Table 6: P, R and F1 fine-grained results for the  resources evaluated individually at Senseval-03 En- glish Lexical Sample Task.", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9948732256889343}]}, {"text": " Table 7: P, R and F1 fine-grained results for the  resources evaluated individually at SemEval-2007,  English Lexical Sample Task .", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9901780486106873}]}]}