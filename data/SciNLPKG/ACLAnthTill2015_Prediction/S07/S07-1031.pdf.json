{"title": [{"text": "FUH (FernUniversit\u00e4t in Hagen): Metonymy Recognition Using Different Kinds of Context fora Memory-Based Learner", "labels": [], "entities": [{"text": "FUH", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7999956607818604}, {"text": "Metonymy Recognition", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8663385510444641}]}], "abstractContent": [{"text": "For the metonymy resolution task at SemEval-2007, the use of a memory-based learner to train classifiers for the identification of metonymic location names is investigated.", "labels": [], "entities": [{"text": "metonymy resolution task at SemEval-2007", "start_pos": 8, "end_pos": 48, "type": "TASK", "confidence": 0.770574826002121}, {"text": "identification of metonymic location names", "start_pos": 113, "end_pos": 155, "type": "TASK", "confidence": 0.7715677738189697}]}, {"text": "Metonymy is resolved on different levels of granularity, differentiating between literal and non-literal readings on the coarse level; literal, metonymic, and mixed readings on the medium level; and a number of classes covering regular cases of metonymy on a fine level.", "labels": [], "entities": []}, {"text": "Different kinds of context are employed to obtain different features: 1) a sequence of n 1 synset IDs representing subordination information for nouns and for verbs, 2) n 2 prepositions, articles, modal, and main verbs in the same sentence, and 3) properties of n 3 tokens in a context window to the left and to the right of the location name.", "labels": [], "entities": []}, {"text": "Different classifiers were trained on the Mascara data set to determine which values for the context sizes n 1 , n 2 , and n 3 yield the highest accuracy (n 1 = 4, n 2 = 3, and n 3 = 7, determined with the leave-one-out method).", "labels": [], "entities": [{"text": "Mascara data set", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9820516308148702}, {"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9984669089317322}]}, {"text": "Results from these classifiers served as features fora combined classifier.", "labels": [], "entities": []}, {"text": "In the training phase, the combined classifier achieved a considerably higher precision for the Mascara data.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9988003969192505}, {"text": "Mascara data", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.9412283301353455}]}, {"text": "In the SemEval submission , an accuracy of 79.8% on the coarse, 79.5% on the medium, and 78.5% on the fine level is achieved (the baseline accuracy is 79.4%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9995836615562439}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9467923045158386}]}], "introductionContent": [{"text": "Metonymy is typically defined as a figure of speech in which a speaker uses one entity to refer to another that is related to it.", "labels": [], "entities": []}, {"text": "The identification of metonymy becomes important for NLP tasks such as question answering or geographic information retrieval ().", "labels": [], "entities": [{"text": "identification of metonymy", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8582194447517395}, {"text": "question answering", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.8781003057956696}, {"text": "geographic information retrieval", "start_pos": 93, "end_pos": 125, "type": "TASK", "confidence": 0.6241003572940826}]}, {"text": "For regular cases of metonymy for locations and organizations, Markert and Nissim have proposed a set of metonymy classes.", "labels": [], "entities": []}, {"text": "Annotating a subset of the BNC (British National Corpus), they extracted a set of metonymic proper nouns from two categories: country names () and organization names . In the metonymy resolution task at SemEval-2007, the goal was to identify metonymic names in a subset of the BNC.", "labels": [], "entities": [{"text": "BNC (British National Corpus)", "start_pos": 27, "end_pos": 56, "type": "DATASET", "confidence": 0.8451268176237742}, {"text": "metonymy resolution task at SemEval-2007", "start_pos": 175, "end_pos": 215, "type": "TASK", "confidence": 0.8188844919204712}, {"text": "BNC", "start_pos": 277, "end_pos": 280, "type": "DATASET", "confidence": 0.9678668975830078}]}, {"text": "The task consists of two subtasks for company and country names, which are further divided into classification on a coarse level (recognizing literal and non-literal readings), on a medium level (differentiating non-literal readings into mixed and metonymic readings), and on a fine level (identifying classes of regular metonymy, such as a name referring to the population, place-for-people).", "labels": [], "entities": []}, {"text": "The task is described in more detail by Markert and Nissim (2007).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for training the classifiers on the  coarse location name classes (2797 instances, 509  non-literal, leave-one-out) for the Mascara data (P =  precision, R = recall, F = F-score).", "labels": [], "entities": [{"text": "Mascara data", "start_pos": 142, "end_pos": 154, "type": "DATASET", "confidence": 0.9063185751438141}, {"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.95597904920578}, {"text": "recall", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9116623401641846}, {"text": "F-score", "start_pos": 188, "end_pos": 195, "type": "METRIC", "confidence": 0.7558600306510925}]}, {"text": " Table 3: Results for the coarse (908 samples: 721  literal, 187 non-literal), medium (721 literal, 167  metonymic, 20 mixed), and fine classification (721  literal, 141 place-for-people, 10 place-for-event, 1  place-for-product, 4 object-for-name, 11 othermet,  20 mixed) of location names.", "labels": [], "entities": []}]}