{"title": [{"text": "UPV-SI: Word Sense Induction using Self Term Expansion *", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7507224877675375}]}], "abstractContent": [{"text": "In this paper we are reporting the results obtained participating in the \"Eval-uating Word Sense Induction and Discrimination Systems\" task of Semeval 2007.", "labels": [], "entities": [{"text": "Eval-uating Word Sense Induction and Discrimination Systems\" task of Semeval 2007", "start_pos": 74, "end_pos": 155, "type": "TASK", "confidence": 0.7871116250753403}]}, {"text": "Our totally unsupervised system performed an automatic self-term expansion process by mean of co-ocurrence terms and, thereafter, it executed the unsupervised KStar clustering method.", "labels": [], "entities": [{"text": "KStar clustering", "start_pos": 159, "end_pos": 175, "type": "TASK", "confidence": 0.6517093479633331}]}, {"text": "Two ranking tables with different evaluation measures were calculated by the task organizers, every table with two baselines and six runs submitted by different teams.", "labels": [], "entities": []}, {"text": "We were ranked third place in both ranking tables obtaining a better performance than three different baselines, and outperforming the average score.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is a particular problem of computational linguistics which consists in determining the correct sense fora given ambiguous word.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8112323780854543}]}, {"text": "It is well-known that supervised algorithms have obtained the best results in public evaluations, but their accuracy is close related with the amount of hand-tagged data available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9986637830734253}]}, {"text": "The construction of that kind of training data is difficult for real applications.", "labels": [], "entities": []}, {"text": "The unsupervised WSD overcomes this drawback by using clustering algorithms which do * This work has been partially supported by the MCyT TIN2006-15265-C06-04 project, as well as by the BUAP-701 PROMEP/103.5/05/1536 grant not need training data in order to determine the possible sense fora given ambiguous word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9076752066612244}, {"text": "MCyT TIN2006-15265-C06-04", "start_pos": 133, "end_pos": 158, "type": "DATASET", "confidence": 0.8204974234104156}, {"text": "BUAP-701 PROMEP/103.5/05/1536 grant", "start_pos": 186, "end_pos": 221, "type": "DATASET", "confidence": 0.9181471400790744}]}, {"text": "This paper describes a simple technique for unsupervised sense induction for ambiguous words.", "labels": [], "entities": [{"text": "unsupervised sense induction", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.6624443034331003}]}, {"text": "The approach is based on a self term expansion technique which constructs a set of coocurrence terms and, thereafter, it uses this set to expand the target dataset.", "labels": [], "entities": []}, {"text": "The implemented system was performed in the task \"SemEval-2007 Task 2: Evaluating Word Sense Induction and Discrimination Systems\".", "labels": [], "entities": [{"text": "Evaluating Word Sense Induction and Discrimination", "start_pos": 71, "end_pos": 121, "type": "TASK", "confidence": 0.750352660814921}]}, {"text": "The aim of the task was to permit a comparison across sense-induction and discrimination systems.", "labels": [], "entities": []}, {"text": "Moreover, the comparison with other supervised and knowledge-based systems maybe also done, since the test corpus was borrowed from the well known \"English lexicalsample\" task in SemEval-2007, with the usual training + test split.", "labels": [], "entities": []}, {"text": "The self term expansion method consists in replacing terms of a document by a set of corelated terms.", "labels": [], "entities": [{"text": "self term expansion", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.6527250409126282}]}, {"text": "The goal is to improve natural language processing tasks such as clustering narrow-domain short texts.", "labels": [], "entities": [{"text": "clustering narrow-domain short texts", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.8670525550842285}]}, {"text": "This process maybe done by mean of different ways, often just by using a knowledge database.", "labels": [], "entities": []}, {"text": "In information retrieval, for instance, the expansion of query terms is a very investigated topic which has shown to improve results with respect to when query expansion is not employed (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7893862724304199}]}, {"text": "The availability of Machine Readable Resources (MRR) like \"Dictionaries\", \"Thesauri\" and \"Lexicons\" has allowed to apply term ex-pansion to other fields of natural language processing like WSD.", "labels": [], "entities": []}, {"text": "In () we may seethe typical example of using a external knowledge database for determining the correct sense of a word given in some context.", "labels": [], "entities": []}, {"text": "In this approach, every word close to the one we would like to determine its correct sense is expanded with its different senses by using the WordNet lexicon.", "labels": [], "entities": [{"text": "WordNet lexicon", "start_pos": 142, "end_pos": 157, "type": "DATASET", "confidence": 0.9744382202625275}]}, {"text": "Then, an overlapping factor is calculated in order to determine the correct sense of the ambiguous word.", "labels": [], "entities": []}, {"text": "Different other approaches have made use of a similar procedure.", "labels": [], "entities": []}, {"text": "By using dictionaries, the proposals presented in are the most sucessful in WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.6378162503242493}]}, {"text": "Yarowsky used instead thesauri for their experiments.", "labels": [], "entities": []}, {"text": "Finally, in) the use of lexicons in WSD has been investigated.", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9569460153579712}]}, {"text": "Although in some cases the knowledge resource seems not to be used strictly for term expansion, the aplication of co-occurrence terms is included in their algorithms.", "labels": [], "entities": [{"text": "term expansion", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.7605339586734772}]}, {"text": "Like in information retrieval, the application of term expansion in WSD by using corelated terms has shown to improve the baseline results if we carefully select the external resource to use, with a priori knowledge of the domain and the broadness of the corpus (wide or narrow domain).", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.7504577338695526}, {"text": "term expansion", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.7562390565872192}, {"text": "WSD", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9316319823265076}]}, {"text": "Evenmore, we have to be sure that the Lexical Data Base (LDB) has been suitable constructed.", "labels": [], "entities": [{"text": "Lexical Data Base (LDB)", "start_pos": 38, "end_pos": 61, "type": "DATASET", "confidence": 0.8327521880467733}]}, {"text": "Due to the last facts, we consider that the use of a self automatically constructed LDB (using the same test corpora), maybe of high benefit.", "labels": [], "entities": []}, {"text": "This assumption is based on the intrinsic properties extracted from the corpus itself.", "labels": [], "entities": []}, {"text": "Our proposal is related somehow with the investigations presented in and), where words are also expanded with co-ocurrence terms for word sense discrimination.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 133, "end_pos": 158, "type": "TASK", "confidence": 0.7162940303484598}]}, {"text": "The main difference consists in the use of the same corpora for constructing the co-ocurrence list.", "labels": [], "entities": []}, {"text": "Following we describe the self term expansion method used and, thereafter, the results obtained in the task #2 of Semeval 2007 competition.", "labels": [], "entities": []}], "datasetContent": [{"text": "The task organizers decided to use two different measures for evaluating the runs submitted to the task.", "labels": [], "entities": []}, {"text": "The first measure is called unsupervised one, and it is based on the Fscore measure.", "labels": [], "entities": [{"text": "Fscore measure", "start_pos": 69, "end_pos": 83, "type": "METRIC", "confidence": 0.9587780833244324}]}, {"text": "Whereas the second measure is called supervised recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9706268906593323}]}, {"text": "For further information on how these measures are calculated refer to ().", "labels": [], "entities": []}, {"text": "Since these measures give conflicting information, two different evaluation results are reported in this paper.", "labels": [], "entities": []}, {"text": "In we may see our ranking and the Fscore measure obtained (UPV-SI).", "labels": [], "entities": [{"text": "Fscore measure", "start_pos": 34, "end_pos": 48, "type": "METRIC", "confidence": 0.9854230582714081}, {"text": "UPV-SI", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.5376814603805542}]}, {"text": "We also show the best and worst team Fscores; as well as the total average and two baselines proposed by the task organizers.", "labels": [], "entities": [{"text": "Fscores", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9257983565330505}]}, {"text": "The first baseline (Baseline1) assumes that each ambiguous word has only one sense, whereas the second baseline (Baseline2) is a random assignation of senses.", "labels": [], "entities": []}, {"text": "We are ranked as third place and our results are better scored than the other teams except for the best team score.", "labels": [], "entities": []}, {"text": "However, given the similar values with the \"Baseline1\", we may assume that that team presented one cluster per ambiguous word as its result as the Baseline1 did; whereas we obtained 9.03 senses per ambiguous word in average.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Unsupervised evaluation (Fscore per- formance).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9947401881217957}]}, {"text": " Table 3: Supervised evaluation (Recall).", "labels": [], "entities": [{"text": "Recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9094648361206055}]}]}