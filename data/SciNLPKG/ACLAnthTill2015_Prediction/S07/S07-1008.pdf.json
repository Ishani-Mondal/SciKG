{"title": [{"text": "SemEval-2007 Task 09: Multilevel Semantic Annotation of Catalan and Spanish", "labels": [], "entities": [{"text": "Multilevel Semantic Annotation of Catalan and Spanish", "start_pos": 22, "end_pos": 75, "type": "TASK", "confidence": 0.6962826081684658}]}], "abstractContent": [{"text": "In this paper we describe SemEval-2007 task number 9 (Multilevel Semantic Annotation of Catalan and Spanish).", "labels": [], "entities": [{"text": "SemEval-2007 task", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.8640216290950775}, {"text": "Multilevel Semantic Annotation of Catalan and Spanish)", "start_pos": 54, "end_pos": 108, "type": "TASK", "confidence": 0.7272191196680069}]}, {"text": "In this task, we aim at evaluating and comparing automatic systems for the annotation of several semantic linguistic levels for Catalan and Spanish.", "labels": [], "entities": []}, {"text": "Three semantic levels are considered: noun sense disambiguation, named entity recognition , and semantic role labeling.", "labels": [], "entities": [{"text": "noun sense disambiguation", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.8295107483863831}, {"text": "named entity recognition", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.6189187268416086}, {"text": "semantic role labeling", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.6704913675785065}]}], "introductionContent": [{"text": "The Multilevel Semantic Annotation of Catalan and Spanish task is split into the following three subtasks: Noun Sense Disambiguation (NSD): Disambiguation of all frequent nouns (\"all words\" style).", "labels": [], "entities": [{"text": "Noun Sense Disambiguation (NSD)", "start_pos": 107, "end_pos": 138, "type": "TASK", "confidence": 0.6828169276316961}]}, {"text": "Named Entity Recognition (NER): The annotation of (possibly embedding) named entities with basic entity types.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7854276200135549}]}, {"text": "Semantic Role Labeling (SRL): Including also two subtasks, i.e., the annotation of verbal predicates with semantic roles (SR), and verb tagging with semantic-class labels (SC).", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.787026176850001}, {"text": "verb tagging", "start_pos": 131, "end_pos": 143, "type": "TASK", "confidence": 0.7281156778335571}]}, {"text": "All semantic annotation tasks are performed on exactly the same corpora for each language.", "labels": [], "entities": []}, {"text": "We presented all the annotation levels together as a complex global task, since we were interested in approaches which address these problems jointly, possibly taking into account cross-dependencies among them.", "labels": [], "entities": []}, {"text": "However, we were also accepting systems approaching the annotation in a pipeline style, or addressing any of the particular subtasks in any of the languages.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the methodology followed to develop the linguistic corpora for the task.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 summarize the task setting and the participant systems, respectively.", "labels": [], "entities": []}, {"text": "Finally, Section 5 presents a comparative analysis of the results.", "labels": [], "entities": []}, {"text": "For any additional information on corpora, resources, formats, tagsets, annotation manuals, etc.", "labels": [], "entities": []}, {"text": "we refer the reader to the official website of the task 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following subsections we present an analysis of the results obtained by participant systems in the INPUT--------------------------------------------------------------> OUTPUT-----------------------------------BASIC_INPUT_INFO-----> EXTRA_INPUT_INFO---------------------------> NE NS-------> SR------------------------> WORD TN TV LEMMA POS SYNTAX NE NS SC PROPS-----------> --------------------------------------------------------------------------------------------------------------- . We will use a language.source pair to denote a particular test set.", "labels": [], "entities": [{"text": "OUTPUT-----------------------------------BASIC_INPUT_INFO-----> EXTRA_INPUT_INFO---------------------------> NE NS-------> SR------------------------>", "start_pos": 175, "end_pos": 325, "type": "METRIC", "confidence": 0.8142650503861276}, {"text": "WORD TN TV LEMMA POS SYNTAX NE NS SC PROPS", "start_pos": 326, "end_pos": 368, "type": "DATASET", "confidence": 0.8391448885202408}]}, {"text": "Finally, '*' will denote the addition of the two subcorpora, either in the language or source dimensions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1.  BSL stands for a baseline system consisting of as- signing to each word occurrence the most frequent  sense in the training set. For new nouns the first  sense in the corresponding WordNet is selected. The  UPC* team trained a SVM classifier for each word in  a pre-selected subset and applied the baseline in the  rest of cases. The selected words are frequent words  (more than 15 occurrences in the training corpus)  showing a not too skewed distribution of senses in  the training set (the most predominant sense covers  less than 90% of the cases", "labels": [], "entities": [{"text": "WordNet", "start_pos": 192, "end_pos": 199, "type": "DATASET", "confidence": 0.9283022880554199}, {"text": "UPC*", "start_pos": 218, "end_pos": 222, "type": "DATASET", "confidence": 0.8876312673091888}]}, {"text": " Table 1: Overall accuracy on the NSD subtask", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9993072748184204}, {"text": "NSD subtask", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.6798855364322662}]}, {"text": " Table 2: Overall results on the NER subtask", "labels": [], "entities": [{"text": "NER subtask", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.7393787801265717}]}, {"text": " Table 3: Detailed results on the NER subtask: UPC*  team; Test corpus *.*", "labels": [], "entities": [{"text": "NER subtask", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.7660069763660431}, {"text": "UPC*  team", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.639879842599233}, {"text": "Test", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.8317348957061768}, {"text": "corpus", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.47674497961997986}]}, {"text": " Table 4: Results on strong vs. weak named entities:  UPC* team; Test corpus *.*", "labels": [], "entities": [{"text": "UPC", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.7107852697372437}]}, {"text": " Table 5: Overall results on the SRL subtask: seman- tic role labeling (SR)", "labels": [], "entities": [{"text": "SRL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9394810199737549}, {"text": "seman- tic role labeling (SR)", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.6643356494605541}]}, {"text": " Table 6: Overall results on the SRL subtask: seman- tic class tagging (SC)", "labels": [], "entities": [{"text": "SRL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9354174137115479}, {"text": "seman- tic class tagging", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.6309303939342499}]}, {"text": " Table 7: Global results on numbered arguments  (Arg), adjuncts (Adj), and numbered arguments  without thematic role tag (A-TR). Test corpus *.*", "labels": [], "entities": []}]}