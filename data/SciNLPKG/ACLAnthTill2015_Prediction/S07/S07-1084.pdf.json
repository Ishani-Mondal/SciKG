{"title": [{"text": "UC3M: Classification of Semantic Relations between Nominals using Sequential Minimal Optimization", "labels": [], "entities": [{"text": "Classification of Semantic Relations between Nominals", "start_pos": 6, "end_pos": 59, "type": "TASK", "confidence": 0.7867697179317474}]}], "abstractContent": [{"text": "This paper presents a method for automatic classification of semantic relations between nominals using Sequential Minimal Optimization.", "labels": [], "entities": [{"text": "automatic classification of semantic relations between nominals", "start_pos": 33, "end_pos": 96, "type": "TASK", "confidence": 0.7810915623392377}]}, {"text": "We participated in the four categories of SEMEVAL task 4 (A: No Query, No Wordnet; B: Word-Net, No Query; C: Query, No WordNet; D: WordNet and Query) and for all training datasets.", "labels": [], "entities": [{"text": "SEMEVAL task 4", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.8152479926745096}]}, {"text": "Best scores were achieved in category B using a set of feature vectors including lexical file numbers of nominals obtained from WordNet and anew feature WordNet Vector designed for the task 1 .", "labels": [], "entities": [{"text": "WordNet", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.9585137963294983}]}], "introductionContent": [{"text": "The survey of the state-of-art reveals an increasing interest in automatically discovering the underlying semantics in natural language.", "labels": [], "entities": []}, {"text": "In this interdisciplinary field, the growing interest is justified by the number of applications which can directly benefit from introducing semantic information.", "labels": [], "entities": []}, {"text": "Question Answering, Information Retrieval and Text Summarization are examples of these applications).", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8302160501480103}, {"text": "Information Retrieval", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.8323168158531189}, {"text": "Text Summarization", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7879813313484192}]}, {"text": "In the present work and for the purpose of the SEMEVAL task 4, our scope is limited to the semantic relationships between nominals.", "labels": [], "entities": [{"text": "SEMEVAL task 4", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9038220246632894}]}, {"text": "By this definition, we understand it is the process of discovering the underlying relations between two concepts expressed by two nominals.", "labels": [], "entities": []}, {"text": "Within the framework of SEMEVAL, nominals can occur either on the phrase, clause or the sentence level.", "labels": [], "entities": [{"text": "SEMEVAL", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9336957931518555}]}, {"text": "This fact constitutes the major challenge in this task since most of the previous research limited their approaches to certain types of nominals mainly the \"compound nominals\"().", "labels": [], "entities": []}, {"text": "The paper is divided as follows; section 2 is a brief introduction to SMO used as the classifier for the task.", "labels": [], "entities": [{"text": "SMO", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.8793695569038391}]}, {"text": "Section 3 is dedicated to the description of the set of features applied in our experiments.", "labels": [], "entities": []}, {"text": "In section 4, we discuss the experiment's results compared to the baselines of the SEMEVAL task and the top scores.", "labels": [], "entities": [{"text": "SEMEVAL task", "start_pos": 83, "end_pos": 95, "type": "TASK", "confidence": 0.7954499125480652}]}, {"text": "Finally, we summarize our approach, pointing out conclusions and future directions of our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Cross validation is away to test the ability of the model to classify unseen examples.", "labels": [], "entities": [{"text": "Cross validation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7555016577243805}]}, {"text": "We trained the system using 10-fold crossvalidation; the fold number recommended for small training datasets.", "labels": [], "entities": []}, {"text": "For each relation and for each category (A, B, C, D) we selected the set of features that obtained the best results using the indicated cross validation.", "labels": [], "entities": []}, {"text": "We submitted 16 sets of results as we participated in the four categories (A, B, C, D).", "labels": [], "entities": []}, {"text": "We also used all the possible sizes of the training dataset (1: 1 to 35, 2:1 to 70, 3:1 to 106, 4:1 to 140).", "labels": [], "entities": []}, {"text": "For some learning algorithms such as decision trees and rule learning, appropriate selection of features is crucial.", "labels": [], "entities": [{"text": "rule learning", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.7650055289268494}]}, {"text": "For the SVM model, this is not so important due to its learning mechanism, where irrelevant features are usually balanced between positive and negative examples fora given binary classification problem.", "labels": [], "entities": []}, {"text": "However, in the experiments we observed that certain features have strong influence on the results, and its inclusion or elimination from the vector, influenced remarkably the outcomes.", "labels": [], "entities": []}, {"text": "In this section, we will briefly discuss the experiments in the four categories highlighting the most relevant observations.", "labels": [], "entities": []}, {"text": "In category A, we expected to obtain better results, but the overall performance of the system has decreased in the seven relations.", "labels": [], "entities": []}, {"text": "This shows that our system has over-fitted the training set.", "labels": [], "entities": []}, {"text": "The contrast between the F score values in the cross-validation and the final test results demonstrates this fact.", "labels": [], "entities": [{"text": "F score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9886547923088074}]}, {"text": "For all the relations in the category A4, we obtained an average of F=43.1% [average score of all participating teams: F=58.0% and top average score: F=64.8%].", "labels": [], "entities": [{"text": "F", "start_pos": 68, "end_pos": 69, "type": "METRIC", "confidence": 0.9981197714805603}, {"text": "F", "start_pos": 119, "end_pos": 120, "type": "METRIC", "confidence": 0.987758457660675}, {"text": "F", "start_pos": 150, "end_pos": 151, "type": "METRIC", "confidence": 0.945246696472168}]}, {"text": "In Product-Producer relation, only two features were used: the two heads of the nominals.", "labels": [], "entities": []}, {"text": "In training, we obtained an average F= 60% using cross-validation, while in the final test data, we achieved an average score F=57.7%.", "labels": [], "entities": [{"text": "F", "start_pos": 36, "end_pos": 37, "type": "METRIC", "confidence": 0.9993174076080322}, {"text": "F", "start_pos": 126, "end_pos": 127, "type": "METRIC", "confidence": 0.9574955701828003}]}, {"text": "For the relation Theme-Tool, other set of features was employed: nominals, their heads, verb, preposition and the list of word between both nominals.", "labels": [], "entities": []}, {"text": "Based on the results of the 10-fold cross validation, we expected to obtain an average of the F=70%.", "labels": [], "entities": [{"text": "F", "start_pos": 94, "end_pos": 95, "type": "METRIC", "confidence": 0.9993676543235779}]}, {"text": "Nevertheless, the score obtained is F =30%.", "labels": [], "entities": [{"text": "F", "start_pos": 36, "end_pos": 37, "type": "METRIC", "confidence": 0.9995187520980835}]}, {"text": "In category B, our system has achieved better scores.", "labels": [], "entities": []}, {"text": "Our average score F is 64.3% and it is above the average of participating teams (F=63.6%) and the baseline.", "labels": [], "entities": [{"text": "average score", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.7419715225696564}, {"text": "F", "start_pos": 18, "end_pos": 19, "type": "METRIC", "confidence": 0.5326541066169739}, {"text": "F", "start_pos": 81, "end_pos": 82, "type": "METRIC", "confidence": 0.9952243566513062}]}, {"text": "Best results in this category were achieved in the relations: Instrument-Agency (F=73.7%), Product-Producer (F=73.9%), Part-Whole (F=76.4%).", "labels": [], "entities": [{"text": "Instrument-Agency (F=73.7", "start_pos": 62, "end_pos": 87, "type": "METRIC", "confidence": 0.7935027003288269}]}, {"text": "However, for the relation ThemeTool the system obtained lower scores (F=49.1%).", "labels": [], "entities": [{"text": "ThemeTool", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.8958836793899536}, {"text": "F", "start_pos": 70, "end_pos": 71, "type": "METRIC", "confidence": 0.997465968132019}]}, {"text": "It is obvious that introducing WordNet information has improved notably the results compared with the results obtained in the category A.", "labels": [], "entities": []}, {"text": "In categories C and D, only three groups have participated.", "labels": [], "entities": []}, {"text": "In category C (as in category A), the system results have decreased obviously (F=45.3%) with respect to the expected scores in the 10-fold cross validation.", "labels": [], "entities": [{"text": "F", "start_pos": 79, "end_pos": 80, "type": "METRIC", "confidence": 0.9988265633583069}]}, {"text": "Moreover, the score obtained is lower than the average score of all participants (F=58.4%) and the best score (F=65.1%).", "labels": [], "entities": [{"text": "F", "start_pos": 82, "end_pos": 83, "type": "METRIC", "confidence": 0.9983327984809875}, {"text": "F", "start_pos": 111, "end_pos": 112, "type": "METRIC", "confidence": 0.9972507357597351}]}, {"text": "For example, in training the Instrument-Agent relation, the system achieved an average F=78% using 10-fold cross-validation, while for the final score it only obtained F=50.7%.", "labels": [], "entities": [{"text": "F", "start_pos": 87, "end_pos": 88, "type": "METRIC", "confidence": 0.9989344477653503}, {"text": "F", "start_pos": 168, "end_pos": 169, "type": "METRIC", "confidence": 0.9984502792358398}]}, {"text": "Results reveal that the main reason behind the low scores in A and C, is the absence of information from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9813982844352722}]}, {"text": "Hence, the vector design needs further consideration in case no semantic information is provided.", "labels": [], "entities": []}, {"text": "In category D, both WordNet senses and query were used, we achieved an average score F=58.8%.", "labels": [], "entities": [{"text": "F", "start_pos": 85, "end_pos": 86, "type": "METRIC", "confidence": 0.8269641995429993}]}, {"text": "The average score for all participants is F=60.6% and the best system achieved F=62.6%.", "labels": [], "entities": [{"text": "F", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9996844530105591}, {"text": "F", "start_pos": 79, "end_pos": 80, "type": "METRIC", "confidence": 0.9991239905357361}]}, {"text": "However, the slight difference shows that our system worked relatively well in this category.", "labels": [], "entities": []}, {"text": "Both run time and accuracy depend critically on the values given to two parameters: the upper bound on the coefficient's values in the equation for the hyperplane (-C), and the degree of the polynomials in the non-linear mapping (-E).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994914531707764}]}, {"text": "Both are set to 1 by default.", "labels": [], "entities": []}, {"text": "The best settings fora particular dataset can be found only by experimentation.", "labels": [], "entities": []}, {"text": "We made numerous experiments to find the best value for the parameter C (C=1, C=10, C=100, C=1000, C=10000), but the results were not remarkably affected.", "labels": [], "entities": []}, {"text": "Probably, this is due to the small size of the training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 Scores for A4, B4, C4 and D4", "labels": [], "entities": []}]}