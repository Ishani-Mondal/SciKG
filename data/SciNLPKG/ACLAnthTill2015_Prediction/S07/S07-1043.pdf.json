{"title": [{"text": "JU-SKNSB: Extended WordNet Based WSD on the English All-Words Task at SemEval-1", "labels": [], "entities": [{"text": "JU-SKNSB", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9529401063919067}, {"text": "SemEval-1", "start_pos": 70, "end_pos": 79, "type": "TASK", "confidence": 0.5987514853477478}]}], "abstractContent": [{"text": "This paper presents an Extended WordNet based word sense disambiguation system using a major modification to the Lesk algorithm.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6250751813252767}]}, {"text": "The algorithm tries to disambigu-ate nouns, verbs and adjectives.", "labels": [], "entities": []}, {"text": "The algorithm relies on the POS-sense tagged syn-set glosses provided by the Extended WordNet.", "labels": [], "entities": [{"text": "Extended WordNet", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.8269810378551483}]}, {"text": "The basic unit of disambiguation of our algorithm is the entire sentence under consideration.", "labels": [], "entities": []}, {"text": "It takes a global approach where all the words in the target sentence are simultaneously disambigu-ated.", "labels": [], "entities": []}, {"text": "The context includes previous and next sentence.", "labels": [], "entities": []}, {"text": "The system assigns the default WordNet first sense to a word when the algorithm fails to predict the sense of the word.", "labels": [], "entities": []}, {"text": "The system produces a precision and recall of .402 on the SemEval-2007 English All-Words test data.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9996009469032288}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9994569420814514}, {"text": "SemEval-2007 English All-Words test data", "start_pos": 58, "end_pos": 98, "type": "DATASET", "confidence": 0.8089156150817871}]}], "introductionContent": [{"text": "In Senseval 1, most of the systems disambiguating English words, were outperformed by a Lesk variant serving as baseline).", "labels": [], "entities": []}, {"text": "On the other hand, during Senseval 2 and Senseval 3, Lesk baselines were outperformed by most of the systems in the lexical sample track.", "labels": [], "entities": []}, {"text": "In this paper, we explore variants of the Lesk algorithm on the English All Words SemEval 2007 test data (465 instances), as well as on the first 10 Semcor 2.0 files (9642 instances).", "labels": [], "entities": [{"text": "English All Words SemEval 2007 test data", "start_pos": 64, "end_pos": 104, "type": "DATASET", "confidence": 0.8261147482054574}]}, {"text": "The proposed WSD algorithm is POS-sense-tagged gloss (from Extended WordNet) based and is a major modification of the original Lesk algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system has been evaluated on the SemEval-2007 English All-Words Tasks (465 test in-stances), as well as on the first 10 Semcor 2.0 files, which are manually disambiguated text corpora using WordNet senses.", "labels": [], "entities": [{"text": "SemEval-2007 English All-Words Tasks", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.4769723042845726}]}, {"text": "We compute F-Score as 2*P*R / (P+R).", "labels": [], "entities": [{"text": "F-Score", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9902695417404175}]}, {"text": "shows the performance of the four variants of the system (with a context size of 3 sentences) on the first 10 Semcor 2.0 files.", "labels": [], "entities": [{"text": "Semcor 2.0 files", "start_pos": 110, "end_pos": 126, "type": "DATASET", "confidence": 0.8083570996920267}]}, {"text": "From table 2, it is clearly evident that model C produces the best result (precision -.621, recall -.533) among the 4 scoring schemes.", "labels": [], "entities": [{"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9994857311248779}, {"text": "recall -.533)", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.9630460143089294}]}, {"text": "POS-wise evaluation results for model C on Semcor 2.0 data is given in    When default WordNet first senses were assigned to the (40) words for which the algorithm failed to predict senses, both the precision and recall values went up to .402 (this result has been submitted in).", "labels": [], "entities": [{"text": "Semcor 2.0 data", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.7554334004720052}, {"text": "precision", "start_pos": 199, "end_pos": 208, "type": "METRIC", "confidence": 0.9990915060043335}, {"text": "recall", "start_pos": 213, "end_pos": 219, "type": "METRIC", "confidence": 0.9873962998390198}]}, {"text": "The WSD system stood 10 thin the SemEval-2007 English AllWords task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.6491634249687195}, {"text": "SemEval-2007 English AllWords task", "start_pos": 33, "end_pos": 67, "type": "DATASET", "confidence": 0.6927224099636078}]}], "tableCaptions": [{"text": " Table 2. Evaluation of the four models on Sem- cor Data", "labels": [], "entities": [{"text": "Sem- cor Data", "start_pos": 43, "end_pos": 56, "type": "DATASET", "confidence": 0.7826604694128036}]}, {"text": " Table 3. POS-wise Evaluation for model C on  Semcor Data", "labels": [], "entities": [{"text": "Semcor Data", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.8954543471336365}]}, {"text": " Table 3. POS-wise Evaluation on SemEval-2007  English All-Words test data", "labels": [], "entities": [{"text": "SemEval-2007", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.8216208815574646}, {"text": "English All-Words test data", "start_pos": 47, "end_pos": 74, "type": "DATASET", "confidence": 0.749734178185463}]}]}