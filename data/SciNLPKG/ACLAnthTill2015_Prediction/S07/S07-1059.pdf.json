{"title": [{"text": "PU-BCD: Exponential Family Models for the Coarse-and Fine-Grained All-Words Tasks", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes an exponential family model of word sense which captures both occurrences and co-occurrences of words and senses in a joint probability distribution.", "labels": [], "entities": []}, {"text": "This statistical framework lends itself to the task of word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7289519111315409}]}, {"text": "We evaluate the performance of the model in its participation on the SemEval-2007 coarse-and fine-grained all-words tasks under a variety of parameters.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes an exponential family model suited to performing word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.7749291658401489}]}, {"text": "Exponential family models area mainstay of modern statistical modeling and they are widely and successfully used for example in text classification (.", "labels": [], "entities": [{"text": "statistical modeling", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8808940351009369}, {"text": "text classification", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8462656736373901}]}, {"text": "In statistical machine learning research, a general methodology and many algorithms were developed for undirected graphical model representation of exponential families), providing a solid basis for efficient inference.", "labels": [], "entities": []}, {"text": "Our model differs from other probabilistic models used for word sense disambiguation in that it captures not only word-sense co-occurrences but also contextual sense-sense co-occurrences, thereby breaking the na\u00a8\u0131vena\u00a8\u0131ve Bayes assumption.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.7292702794075012}]}, {"text": "Although spare in the types of features, the model is extremely expressive.", "labels": [], "entities": []}, {"text": "Our model has parameters that control for word-sense interaction and sense-sense similarity, allowing us to capture many of the salient features of word and sense use.", "labels": [], "entities": []}, {"text": "After fitting the parameters of our model from a labeled corpus, the task of word sense disambiguation immediately follows by considering the posterior distribution of senses given words.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.7528390487035116}]}, {"text": "We used this model to participate in SemEval-2007 on the coarse-and fine-grained all-words tasks.", "labels": [], "entities": []}, {"text": "In both of these tasks, a series of sentences are given with certain words tagged.", "labels": [], "entities": []}, {"text": "Each competing system must assign a sense from a sense inventory to the tagged words.", "labels": [], "entities": []}, {"text": "In both tasks, performance was gauged by comparing the output of each system to human-tagged senses.", "labels": [], "entities": []}, {"text": "In the fine-grained task, precision and recall were simply and directly computed against the golden annotations.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9994899034500122}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9992265701293945}]}, {"text": "However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses).", "labels": [], "entities": []}, {"text": "Precision and recall were computed against equivalence classes.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.988395094871521}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9992313385009766}]}, {"text": "This paper briefly derives the model and then explores its properties for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.8442411422729492}]}, {"text": "We show how common algorithms, such as \"dominant sense\" and \"most frequent sense,\" can be expressed in the exponential family framework.", "labels": [], "entities": []}, {"text": "We then proceed to present an evaluation of the developed techniques on the SemEval-2007 tasks in which we participated.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section evaluates the performance of the model and the techniques described in the previous sections with respect to the coarse-and fine-grained allwords tasks at In order to train the parameters, we trained our model in a supervised fashion on SemCor (Miller et: Precision for the fine-grained all-words task.", "labels": [], "entities": []}, {"text": "The results corresponding to the bolded value was submitted to the competition.", "labels": [], "entities": []}, {"text": "al., 1993) with Laplace smoothing for parameter estimates.", "labels": [], "entities": []}, {"text": "We utilized the POS tagging and lemmatization given in the coarse-grained all-words test set.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.6202044486999512}]}, {"text": "Wherever a headword was tagged differently between the two test sets, we produced an answer only for the coarse-grained test and not for the finegrained one.", "labels": [], "entities": []}, {"text": "This led to responses on only 93.9% of the fine-grained test words.", "labels": [], "entities": []}, {"text": "Of the 6.1% over which no response was given, 5.3% were tagged as \"U\" in the answer key.", "labels": [], "entities": []}, {"text": "In order to break ties between equally likely senses, for the fine-grained test, the system returned the first one returned in WordNet's sense inventory for that lemma.", "labels": [], "entities": [{"text": "WordNet's sense inventory", "start_pos": 127, "end_pos": 152, "type": "DATASET", "confidence": 0.8642937988042831}]}, {"text": "For the coarse-grained test, an arbitrary sense was returned in case of ties.", "labels": [], "entities": []}, {"text": "The precision results given in this section are over polysemous words (of all parts of speech) for which our system gave an answer and for which the answer key was not tagged with \"U.\"", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.998837411403656}]}], "tableCaptions": [{"text": " Table 1: Precision for the fine-grained all-words task. The results corresponding to the bolded value was  submitted to the competition.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9888803958892822}]}]}