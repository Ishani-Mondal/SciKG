{"title": [{"text": "CITYU-HIF: WSD with Human-Informed Feature Preference", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.8302416205406189}]}], "abstractContent": [{"text": "This paper describes our word sense dis-ambiguation (WSD) system participating in the SemEval-2007 tasks.", "labels": [], "entities": [{"text": "word sense dis-ambiguation (WSD)", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.6714125027259191}, {"text": "SemEval-2007 tasks", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8224329650402069}]}, {"text": "The core system is a fully supervised system based on a Na-\u00efve Bayes classifier using multiple knowledge sources.", "labels": [], "entities": []}, {"text": "Toward a larger goal of incorporating the intrinsic nature of individual target words in disambiguation, thus introducing a cognitive element in automatic WSD, we tried to fine-tune the results obtained from the core system with human-informed feature preference, and compared it with automatic feature selection as commonly practised in statistical WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9107162356376648}]}, {"text": "Despite the insignificant improvement observed in this preliminary attempt, more systematic analysis remains to be done fora cognitively plausible account of the factors underlying the lexical sensitivity of WSD, which would inform and enhance the development of WSD systems in return.", "labels": [], "entities": [{"text": "WSD", "start_pos": 208, "end_pos": 211, "type": "TASK", "confidence": 0.9512868523597717}, {"text": "WSD", "start_pos": 263, "end_pos": 266, "type": "TASK", "confidence": 0.9571683406829834}]}], "introductionContent": [{"text": "In recent years, many research teams allover the world have gained rich experience on word sense disambiguation (WSD) from the shared tasks of the SENSEVAL workshops.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.8077875127394994}]}, {"text": "The need for multiple knowledge sources has become a golden rule, and the \"lexical sensitivity\" once remarked by is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g.).", "labels": [], "entities": []}, {"text": "Another common practice is to use an ensemble of classifiers.", "labels": [], "entities": []}, {"text": "As pointed out by, among the participating systems in the SENSEVAL-3 English lexical sample task, \"several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual classifiers\".", "labels": [], "entities": [{"text": "SENSEVAL-3 English lexical sample task", "start_pos": 58, "end_pos": 96, "type": "TASK", "confidence": 0.6653634786605835}, {"text": "accuracy", "start_pos": 286, "end_pos": 294, "type": "METRIC", "confidence": 0.9849181771278381}]}, {"text": "However, the advancement in WSD is rarely accompanied by any extensive account on the cognitive aspects of the task or qualitative analysis of the relation between the disambiguation results and the nature of individual target words underlying the apparent lexical sensitivity of the task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9912466406822205}]}, {"text": "Given that humans apparently use different strategies in making sense of words, it might be beneficial to have such cognitive aspects, including the type and strength of various kinds of semantic association, realised in NLP systems explicitly.", "labels": [], "entities": []}, {"text": "Thus in addition to an optimal combination of classifiers alone, to better understand the contribution of different information types for different types of target words, it is important to look at WSD in relation to the very intrinsic nature of individual target words, which could comprise many factors such as frequency, abstractness, sense relatedness and parts-of-speech (POS).", "labels": [], "entities": [{"text": "WSD", "start_pos": 198, "end_pos": 201, "type": "TASK", "confidence": 0.7769875526428223}]}, {"text": "We thus use the concept Information Susceptibility () to refer to the relationship between the intrinsic features of a target word and its senses, and the effectiveness of various lexical information to characterise them.", "labels": [], "entities": [{"text": "Information Susceptibility", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.7018178403377533}]}, {"text": "Our current participation in SemEval-2007 is thus intended as a means toward a larger goal, i.e., to incorporate a cognitive element into automatic WSD systems.", "labels": [], "entities": [{"text": "WSD", "start_pos": 148, "end_pos": 151, "type": "TASK", "confidence": 0.9445533752441406}]}, {"text": "In particular, we tried to fine-tune the results obtained from the core system with human-informed feature preference.", "labels": [], "entities": []}, {"text": "In Section 2, we will briefly describe the implementation of our disambiguation system and the features used.", "labels": [], "entities": []}, {"text": "In Section 3 we will discuss the human input on the target nature and the informativeness of various features.", "labels": [], "entities": []}, {"text": "The experiments and results are presented in Section 4, followed by a conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We participated in the Multilingual ChineseEnglish Lexical Sample Task (Task 5) and the English Lexical Sample Task via English-Chinese Parallel Text (Task 11).", "labels": [], "entities": [{"text": "Multilingual ChineseEnglish Lexical Sample Task", "start_pos": 23, "end_pos": 70, "type": "TASK", "confidence": 0.6403647661209106}]}, {"text": "Task 5 consists of 40 Chinese target words, 19 nouns and 21 verbs.", "labels": [], "entities": []}, {"text": "The number of senses for the target words ranges from 2 to 8, with an average of 3.", "labels": [], "entities": []}, {"text": "There are altogether 2,680 training samples, i.e. on average about 22 for each sense.", "labels": [], "entities": []}, {"text": "A total of 935 testing instances were to be tagged, i.e. on average about 23 for each target word.", "labels": [], "entities": []}, {"text": "The data were from People's Daily.", "labels": [], "entities": [{"text": "People's Daily", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.9610175887743632}]}, {"text": "The sense tags are given in the form of their English translations in the Chinese Semantic Dictionary developed by the Institute of Computational Linguistics of Peking University.", "labels": [], "entities": [{"text": "Chinese Semantic Dictionary", "start_pos": 74, "end_pos": 101, "type": "DATASET", "confidence": 0.7435843149820963}]}, {"text": "The task organiser has provided the data with word segmentation and POS for each segmented word.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.6502751111984253}, {"text": "POS", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9982824325561523}]}, {"text": "Task 11 consists of 40 English target words, including 20 nouns and 20 adjectives.", "labels": [], "entities": []}, {"text": "The average number of training samples for each sense is about 42.", "labels": [], "entities": []}, {"text": "The number of senses for the target words ranges from 2 to 6, with an average of 3.125.", "labels": [], "entities": []}, {"text": "The average number of testing samples for each target word is 68.", "labels": [], "entities": []}, {"text": "The data were gathered from wordaligned English-Chinese parallel texts.", "labels": [], "entities": []}, {"text": "In addition, we also used the SENSEVAL-3 Chinese lexical sample data during evaluation, which contains 20 target words.", "labels": [], "entities": [{"text": "SENSEVAL-3 Chinese lexical sample data", "start_pos": 30, "end_pos": 68, "type": "DATASET", "confidence": 0.7251287162303924}]}, {"text": "For Task 5, we made use of the segmentation and POS information provided by the task organiser.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9645185470581055}, {"text": "POS", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9547249674797058}]}, {"text": "For Task 11, we first ran the data through the Brill tagger to obtain the POS, from which we then extracted the feature values.", "labels": [], "entities": [{"text": "Brill tagger", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.8201116025447845}, {"text": "POS", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.6326017379760742}]}, {"text": "On top of the core system, we also tested two value-added conditions, namely automatic feature selection (AFS) and human-informed feature preference (HIF).", "labels": [], "entities": [{"text": "automatic feature selection (AFS)", "start_pos": 77, "end_pos": 110, "type": "METRIC", "confidence": 0.78160493572553}]}, {"text": "For the latter, we run a separate Na\u00efve Bayes classifier in parallel to the core system, using the knowledge source deemed most useful fora given target word by two or more human judges.", "labels": [], "entities": []}, {"text": "When the probability of the best guess from the core classifier is under a certain threshold, the best guess from the other is used instead.", "labels": [], "entities": []}, {"text": "For the current experiment, the probability of the best guess from the core classifier must at least double that for the next best guess.", "labels": [], "entities": []}, {"text": "For evaluation, we ran a 10-fold cross validation on the SemEval-2007 Task 5 training data, with the core system and AFS.", "labels": [], "entities": [{"text": "SemEval-2007 Task 5 training data", "start_pos": 57, "end_pos": 90, "type": "DATASET", "confidence": 0.7931249976158142}, {"text": "AFS", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.8755457997322083}]}, {"text": "In addition, we tested with the Senseval-3 Chinese lexical sample data.", "labels": [], "entities": [{"text": "Senseval-3 Chinese lexical sample data", "start_pos": 32, "end_pos": 70, "type": "DATASET", "confidence": 0.9175752639770508}]}, {"text": "We trained the classifier with the Senseval-3 training data, with the core classifier, AFS, and HIF.", "labels": [], "entities": [{"text": "Senseval-3 training data", "start_pos": 35, "end_pos": 59, "type": "DATASET", "confidence": 0.7551098068555196}, {"text": "AFS", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.926779568195343}]}, {"text": "The results are discussed below.", "labels": [], "entities": []}, {"text": "Apparently, and as known and expected, feature selection is useful for choosing an optimal set of features for each target word.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7094349414110184}]}, {"text": "How this compares and works together with human intuition and the nature of the individual target words and senses is what we would like to further investigate.", "labels": [], "entities": []}, {"text": "In the above experiment, fine-tuning with human-informed feature preference did not improve the performance as significantly as one would like to see, and the effect varied with individual target words.", "labels": [], "entities": []}, {"text": "One possibility is that Na\u00efve Bayes classifiers favour aggregative features, so it might not be most appropriate to do the fine-tuning with a separate classifier.", "labels": [], "entities": []}, {"text": "Rather, we could explore the feasibility of adjusting the weights of individual features based on the feature preference.", "labels": [], "entities": []}, {"text": "Our next step is to perform in-depth and systematic analysis on the difficulty, abstractness and topicality of the target words and senses, with the information gathered from the human judges and the confusion matrices generated from the experiment, in association with psychological evidence like semantic activation and the organisation of the mental lexicon (e.g.).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3 Official Scores for CITYU in", "labels": [], "entities": [{"text": "CITYU", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.8067218065261841}]}]}