{"title": [{"text": "RTV: Tree Kernels for Thematic Role Classification", "labels": [], "entities": [{"text": "Thematic Role Classification", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.825048049290975}]}], "abstractContent": [{"text": "We present a simple, two-steps supervised strategy for the identification and classification of thematic roles in natural language texts.", "labels": [], "entities": [{"text": "identification and classification of thematic roles in natural language texts", "start_pos": 59, "end_pos": 136, "type": "TASK", "confidence": 0.8102882921695709}]}, {"text": "We employ no external source of information but automatic parse trees of the input sentences.", "labels": [], "entities": []}, {"text": "We use a few attribute-value features and tree kernel functions applied to specialized structured features.", "labels": [], "entities": []}, {"text": "The resulting system has an F 1 of 75.44 on the Se-mEval2007 closed task on semantic role labeling .", "labels": [], "entities": [{"text": "F 1", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9938206076622009}, {"text": "semantic role labeling", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.7174408634503683}]}], "introductionContent": [{"text": "In this paper we present a system for the labeling of semantic roles that produces VerbNet () like annotations of free text sentences using only full syntactic parses of the input sentences.", "labels": [], "entities": [{"text": "labeling of semantic roles", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.8500020205974579}]}, {"text": "The labeling process is modeled as a cascade of two distinct classification steps: (1) boundary detection (BD), in which the word sequences that encode a thematic role fora given predicate are recognized, and (2) role classification (RC), in which the type of thematic role with respect to the predicate is assigned.", "labels": [], "entities": [{"text": "boundary detection (BD)", "start_pos": 87, "end_pos": 110, "type": "METRIC", "confidence": 0.6922681212425232}, {"text": "role classification (RC)", "start_pos": 213, "end_pos": 237, "type": "TASK", "confidence": 0.77688570022583}]}, {"text": "After role classification, a set of simple heuristics are applied in order to ensure that only well formed annotations are output.", "labels": [], "entities": [{"text": "role classification", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.8839404284954071}]}, {"text": "We designed our system on a per-predicate basis, training one boundary classifier and a battery of role classifiers for each predicate word.", "labels": [], "entities": []}, {"text": "We clustered all the senses of the same verb together and ended up with 50 distinct boundary classifiers (one for each target predicate word) and 619 role classifiers to recognize the 47 distinct role labels that appear in the training set.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: Section 2 describes in some detail the architecture of our labeling system; Section 3 describes the features that we use to represent the classifier examples; Section 4 describes the experimental setting and reports the accuracy of the system on the SemEval2007 semantic role labeling closed task; finally, Section 5 discusses the results and presents our conclusions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 274, "end_pos": 282, "type": "METRIC", "confidence": 0.9987903237342834}, {"text": "SemEval2007 semantic role labeling closed task", "start_pos": 304, "end_pos": 350, "type": "TASK", "confidence": 0.7743365267912546}]}], "datasetContent": [{"text": "In this section we discuss the setup and the results of the experiments carried out on the dataset of the SemEval2007 closed task on SRL.: SRL accuracy on the development test for the boundary detection (BD) and the complete SRL task (BD+RC) using the polynomial kernel alone (poly) or combined with a tree kernel function (poly + TK).", "labels": [], "entities": [{"text": "SRL", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.7790988087654114}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9808351397514343}, {"text": "boundary detection (BD)", "start_pos": 184, "end_pos": 207, "type": "TASK", "confidence": 0.6063222110271453}, {"text": "SRL task", "start_pos": 225, "end_pos": 233, "type": "TASK", "confidence": 0.8895590305328369}]}, {"text": "All the evaluations were carried out using the CoNLL2005 evaluator tool available at http://www.lsi.upc.es/\u223csrlconll/soft.html.", "labels": [], "entities": [{"text": "CoNLL2005", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.8970001339912415}]}, {"text": "shows the aggregate results on boundary detection (BD) and the complete SRL task (BD+RC) on the development set using the polynomial kernel alone (poly) or in conjunction with the tree kernels and structured features (poly+TK).", "labels": [], "entities": [{"text": "boundary detection (BD)", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.7282279253005981}, {"text": "SRL task (BD+RC)", "start_pos": 72, "end_pos": 88, "type": "METRIC", "confidence": 0.6850229459149497}]}, {"text": "For both tasks, tree kernel functions do trigger automatic feature se-  lection and improve the polynomial kernel by 2.46 and 1.39 F 1 points, respectively.", "labels": [], "entities": []}, {"text": "The SRL accuracy for each one of the 47 distinct role labels is shown in.", "labels": [], "entities": [{"text": "SRL", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9455336332321167}, {"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.76730877161026}]}, {"text": "Column 2 lists the number of instances of each role in the test set.", "labels": [], "entities": []}, {"text": "Many roles have very few positive examples both in the training and the test sets, and therefore have little or no impact on the overall accuracy which is dominated by the few roles which are very frequent, such as Theme, Agent, Topic and ARGM-TMP which account for almost 80% of all the test roles.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.999219536781311}]}], "tableCaptions": [{"text": " Table 1: Composition of the dataset in terms of: number of", "labels": [], "entities": []}, {"text": " Table 2: SRL accuracy on the development test for the bound-", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9701944589614868}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9423880577087402}]}, {"text": " Table 3: Evaluation of the semantic role labeling accuracy on", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6972802877426147}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.8219521641731262}]}]}