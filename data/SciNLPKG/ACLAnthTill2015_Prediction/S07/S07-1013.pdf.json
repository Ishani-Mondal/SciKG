{"title": [{"text": "SemEval-2007 Task 14: Affective Text", "labels": [], "entities": [{"text": "SemEval-2007 Task 14", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8695831100145975}]}], "abstractContent": [{"text": "The \"Affective Text\" task focuses on the classification of emotions and valence (pos-itive/negative polarity) in news headlines, and is meant as an exploration of the connection between emotions and lexical semantics.", "labels": [], "entities": [{"text": "classification of emotions and valence (pos-itive/negative polarity) in news headlines", "start_pos": 41, "end_pos": 127, "type": "TASK", "confidence": 0.679169563310487}]}, {"text": "In this paper, we describe the data set used in the evaluation and the results obtained by the participating systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "All words can potentially convey affective meaning.", "labels": [], "entities": []}, {"text": "Every word, even those apparently neutral, can evoke pleasant or painful experiences due to their semantic relation with emotional concepts or categories.", "labels": [], "entities": []}, {"text": "Some words have emotional meaning with respect to an individual story, while for many others the affective power is part of the collective imagination (e.g., words such as \"mum\", \"ghost\", \"war\").", "labels": [], "entities": []}, {"text": "The automatic detection of emotion in texts is becoming increasingly important from an applicative point of view.", "labels": [], "entities": [{"text": "automatic detection of emotion in texts", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.8443319499492645}]}, {"text": "Consider for example the tasks of opinion mining and market analysis, affective computing, or natural language interfaces such as e-learning environments or educational/edutainment games.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.861738920211792}, {"text": "market analysis", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.7660733759403229}]}, {"text": "Possible beneficial effects of emotions on memory and attention of the users, and in general on fostering their creativity are also well-known in the field of psychology.", "labels": [], "entities": [{"text": "memory", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.928523600101471}]}, {"text": "For instance, the following represent examples of applicative scenarios in which affective analysis would give valuable and interesting contributions: Sentiment Analysis.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 151, "end_pos": 169, "type": "TASK", "confidence": 0.9459824562072754}]}, {"text": "Text categorization according to affective relevance, opinion exploration for market analysis, etc. are just some examples of application of these techniques.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7413621842861176}, {"text": "opinion exploration", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7289996445178986}, {"text": "market analysis", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.7013510912656784}]}, {"text": "While positive/negative valence annotation is an active field of sentiment analysis, we believe that a fine-grained emotion annotation would increase the effectiveness of these applications.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.9489284753799438}]}, {"text": "The automated generation of evaluative expressions with a bias on some polarity orientation area key component for automatic personalized advertisement and persuasive communication.", "labels": [], "entities": []}], "datasetContent": [{"text": "Fine-grained evaluations were conducted using the Pearson measure of correlation between the system scores and the gold standard scores, averaged overall the headlines in the data set.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9546899795532227}]}, {"text": "We have also run a coarse-grained evaluation, where each emotion was mapped to a 0/1 classification (0 = [0,50), 1 = [50,100]), and each valence was mapped to a -1/0/1 classification (-1 = [-100,-50], 0 = (-50,50), 1 = [50,100]).", "labels": [], "entities": []}, {"text": "For the coarse-grained evaluations, we calculated accuracy, precision, and recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9997416138648987}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9996651411056519}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9993984699249268}]}, {"text": "Note that the accuracy is calculated with respect to all the possible classes, and thus it can be artificially high in the case of unbalanced datasets (as some of the emotions are, due to the high number of neutral headlines).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9995598196983337}]}, {"text": "Instead, the precision and recall figures exclude the neutral annotations.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999705970287323}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9986866116523743}]}], "tableCaptions": [{"text": " Table 1. To measure the agreement among  the six annotators, we first measured the agreement  between each annotator and the average of the re- maining five annotators, followed by an average  over the six resulting agreement figures.", "labels": [], "entities": []}, {"text": " Table 1: Pearson correlation for inter-annotator  agreement", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.875890702009201}]}, {"text": " Table 2: System results for valence annotations", "labels": [], "entities": []}, {"text": " Table 3: System results for emotion annotations", "labels": [], "entities": [{"text": "emotion annotations", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7849366068840027}]}]}