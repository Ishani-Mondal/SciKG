{"title": [{"text": "FBK-irst: Lexical Substitution Task Exploiting Domain and Syntagmatic Coherence", "labels": [], "entities": [{"text": "FBK-irst", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9031363129615784}, {"text": "Lexical Substitution Task Exploiting Domain", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.8314775347709655}]}], "abstractContent": [{"text": "This paper summarizes FBK-irst participation at the lexical substitution task of the SEMEVAL competition.", "labels": [], "entities": [{"text": "FBK-irst", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.39536145329475403}, {"text": "lexical substitution task", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.7794783512751261}, {"text": "SEMEVAL competition", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7612271308898926}]}, {"text": "We submitted two different systems, both exploiting synonym lists extracted from dictionaries.", "labels": [], "entities": []}, {"text": "For each word to be substituted, the systems rank the associated synonym list according to a similarity metric based on Latent Semantic Analysis and to the occurrences in the Web 1T 5-gram corpus, respectively.", "labels": [], "entities": [{"text": "Web 1T 5-gram corpus", "start_pos": 175, "end_pos": 195, "type": "DATASET", "confidence": 0.6207931190729141}]}, {"text": "In particular, the latter system achieves the state-of-the-art performance, largely surpassing the baseline proposed by the organizers.", "labels": [], "entities": []}], "introductionContent": [{"text": "The lexical substitution ( can be regarded as a subtask of the lexical entailment, in which fora given word in context the system is asked to select an alternative word that can be replaced in that context preserving the meaning.", "labels": [], "entities": []}, {"text": "Lexical Entailment, and in particular lexical reference) 1 , is in turn a subtask of textual entailment, which is formally defined as a relationship between a coherent text T and a language expression, the hypothesis H.", "labels": [], "entities": [{"text": "Lexical Entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7569828629493713}]}, {"text": "T is said to entail H, denoted by T \u2192 H, if the meaning of H can be inferred from the meaning of T ().", "labels": [], "entities": []}, {"text": "Even though this notion has been only recently proposed in the computational linguistics literature, it attracts more and more attention due to the high generality of its settings and to the usefulness of its (potential) applications.", "labels": [], "entities": []}, {"text": "With respect to lexical entailment, the lexical substitution task has a more restrictive criterion.", "labels": [], "entities": [{"text": "lexical substitution task", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7719053228696188}]}, {"text": "In fact, two words can be substituted when meaning is preserved, while the criterion for lexical entailment is that the meaning of the thesis is implied by the meaning of the hypothesis.", "labels": [], "entities": []}, {"text": "The latter condition is in general ensured by substituting either hyperonyms or synonyms, while the former is more rigid because only synonyms are in principle accepted.", "labels": [], "entities": []}, {"text": "Formally, in a lexical entailment task a system is asked to decide whether the substitution of a particular term w with the term e in a coherent text H w = H l wH r generates a sentence He = H l eH r such that H w \u2192 He , where H land H r denote the left and the right context of w, respectively.", "labels": [], "entities": []}, {"text": "For example, given the source word 'weapon' a system may substitute it with the target synonym 'arm', in order to identify relevant texts that denote the sought concept using the latter term.", "labels": [], "entities": []}, {"text": "A particular case of lexical entailment is recognizing synonymy, where both H w \u2192 He and He \u2192 H w hold.", "labels": [], "entities": [{"text": "lexical entailment", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8972730338573456}]}, {"text": "The lexical substitution task at SEMEVAL addresses exactly this problem.", "labels": [], "entities": [{"text": "lexical substitution task", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7753757238388062}, {"text": "SEMEVAL", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.6559560298919678}]}, {"text": "The task is not easy since lists of candidate entailed words are not provided by the organizers.", "labels": [], "entities": []}, {"text": "Therefore the system is asked first to identify a set of candidate words, and then to select only those words that fit in a particular context.", "labels": [], "entities": []}, {"text": "To promote unsupervised methods, the organizers did not provide neither labeled data for training nor dictionaries or list of synonyms explaining the meanings of the entailing words.", "labels": [], "entities": []}, {"text": "In this paper, we describe our approach to the Lexical Substitution task at SEMEVAL 2007.", "labels": [], "entities": [{"text": "Lexical Substitution task at SEMEVAL 2007", "start_pos": 47, "end_pos": 88, "type": "TASK", "confidence": 0.7856391966342926}]}, {"text": "We developed two different systems (named IRST1-lsa and IRST2-syn in the official task ranking), both exploiting a common lists of synonyms extracted from dictionaries (i.e. WordNet and the Oxford Dictio-nary) and ranking them according to two different criteria: Domain Proximity: the similarity between each candidate entailed word and the context of the entailing word is estimated by means of a cosine between their corresponding vectors in the LSA space.", "labels": [], "entities": [{"text": "IRST2-syn", "start_pos": 56, "end_pos": 65, "type": "DATASET", "confidence": 0.7242608666419983}, {"text": "WordNet", "start_pos": 174, "end_pos": 181, "type": "DATASET", "confidence": 0.968040943145752}, {"text": "Oxford Dictio-nary", "start_pos": 190, "end_pos": 208, "type": "DATASET", "confidence": 0.8928039371967316}, {"text": "LSA space", "start_pos": 449, "end_pos": 458, "type": "DATASET", "confidence": 0.8994829058647156}]}, {"text": "Syntagmatic Coherence: querying a large corpus, the system finds all occurrences of the target sentence, in which the entailing word is substituted with each synonym, and it assigns scores proportional to the occurrence frequencies.", "labels": [], "entities": []}, {"text": "Results show that both methods are effective.", "labels": [], "entities": []}, {"text": "In particular, the second method achieved the best performance in the competition, defining the state-ofthe-art for the lexical substitution task.", "labels": [], "entities": [{"text": "lexical substitution task", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.7880121469497681}]}], "datasetContent": [{"text": "There are basically two scoring methodologies: (i) BEST, which scores the best substitute fora given item, and (ii) OOT, which scores for the best 10 substitutes fora given item, and systems do not benefit from providing less responses 4 . BEST. and 2 report the performance for the domain proximity and syntagmatic coherence ranking.", "labels": [], "entities": [{"text": "BEST", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9982261061668396}, {"text": "OOT", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.9964904189109802}, {"text": "BEST.", "start_pos": 240, "end_pos": 245, "type": "METRIC", "confidence": 0.9551921486854553}]}, {"text": "Please note that in we report both the official score and a score that takes into account just the first proposal of the systems, as the usual interpretation of BEST score methodology would suggest 5 . OOT. and 5 report the performance for the domain proximity and syntagmatic coherence ranking, scoring for the 10 best substitutes.", "labels": [], "entities": [{"text": "BEST score methodology", "start_pos": 161, "end_pos": 183, "type": "DATASET", "confidence": 0.6205600102742513}, {"text": "OOT.", "start_pos": 202, "end_pos": 206, "type": "METRIC", "confidence": 0.9937006235122681}]}, {"text": "The results are quite good especially in the case of syntagmatic coherence ranking.", "labels": [], "entities": []}, {"text": "displays the baselines respectively for the BEST and OOT using WordNet 2.1 as calculated by the task organizers.", "labels": [], "entities": [{"text": "BEST", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9735010862350464}, {"text": "OOT", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.8147143125534058}, {"text": "WordNet 2.1", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.9298970997333527}]}, {"text": "They propose many baseline measures, but we report only the The task proposed a third scoring measure MW that scores precision and recall for detection and identification of multiwords in the input sentences.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9992984533309937}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9979621171951294}, {"text": "detection and identification of multiwords in the input sentences", "start_pos": 142, "end_pos": 207, "type": "TASK", "confidence": 0.7658316493034363}]}, {"text": "However our systems were not designed for this functionality.", "labels": [], "entities": []}, {"text": "For the details of all scoring methodologies please refer to the task description documents.", "labels": [], "entities": []}, {"text": "We misinterpreted that the official scorer divides anyway the figures by the number of proposals.", "labels": [], "entities": []}, {"text": "So for the competition we submitted the oot result file without cutting the words after the first one.", "labels": [], "entities": []}, {"text": "WordNet one, as it is the higher scoring baseline.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9674906134605408}]}, {"text": "We can observe that globally our systems perform quite good with respect to the baselines.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BEST results for LSA ranking (IRST1-lsa)", "labels": [], "entities": [{"text": "BEST", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9934113621711731}, {"text": "LSA", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.8402568101882935}, {"text": "IRST1-lsa", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.5646041035652161}]}, {"text": " Table 2: BEST results for Syntagmatic ranking  (IRST2-syn)", "labels": [], "entities": [{"text": "BEST", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9942517280578613}, {"text": "Syntagmatic ranking", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7826982140541077}]}, {"text": " Table 4: OOT results for LSA ranking (IRST1-lsa)", "labels": [], "entities": [{"text": "OOT", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9376725554466248}, {"text": "LSA", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.7606014609336853}, {"text": "IRST1-lsa", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.5647435188293457}]}, {"text": " Table 5: OOT results for Syntagmatic ranking  (IRST2-syn)", "labels": [], "entities": [{"text": "OOT", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9250329732894897}, {"text": "Syntagmatic ranking", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7503340840339661}]}]}