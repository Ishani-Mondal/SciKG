{"title": [{"text": "LCC-TE: A Hybrid Approach to Temporal Relation Identification in News Text", "labels": [], "entities": [{"text": "LCC-TE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9067525267601013}, {"text": "Temporal Relation Identification in News Text", "start_pos": 29, "end_pos": 74, "type": "TASK", "confidence": 0.8493044177691141}]}], "abstractContent": [{"text": "This paper explores a hybrid approach to temporal information extraction within the TimeML framework.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.6368892391522726}, {"text": "TimeML framework", "start_pos": 84, "end_pos": 100, "type": "DATASET", "confidence": 0.9126361012458801}]}, {"text": "Particularly, we focus on our initial efforts to apply machine learning techniques to identify temporal relations as defined in a constrained manner by the TempEval-2007 task.", "labels": [], "entities": []}, {"text": "We explored several machine learning models and human rules to infer temporal relations based on the features available in TimeBank, as well as a number of other features extracted by our in-house tools.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 123, "end_pos": 131, "type": "DATASET", "confidence": 0.9218049049377441}]}, {"text": "We participated in all three sub-tasks of the TempEval task in SemEval-2007 workshop and the evaluation shows that we achieved comparable results in Task A & B and competitive results in Task C.", "labels": [], "entities": [{"text": "TempEval task", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.6232893764972687}]}], "introductionContent": [{"text": "There has been a growing interest in temporal information extraction in recent years, as more and more operational NLP systems demands dealing with time-related issues in natural languages.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.6454460918903351}]}, {"text": "In this paper, we report on an end-to-end system that is capable of automating identification of temporal referring expressions, events and temporal relations in text by leveraging various NLP tools and linguistic resources at LCC.", "labels": [], "entities": [{"text": "identification of temporal referring expressions, events and temporal relations in text", "start_pos": 79, "end_pos": 166, "type": "TASK", "confidence": 0.8051591416200002}]}, {"text": "It has to be noted that the system we report here is not only intended for TempEval 2007 evaluation, but will also be used as a NLP tool for our other applications (e.g. temporal Question Answering).", "labels": [], "entities": [{"text": "TempEval 2007 evaluation", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.5638859470685323}, {"text": "temporal Question Answering", "start_pos": 170, "end_pos": 197, "type": "TASK", "confidence": 0.654233048359553}]}, {"text": "That is why we experimented to use our own temporal and event extraction capabilities in this work, although time and event tags have already been provided in the testing/training data.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7080357819795609}]}, {"text": "Another reason we use our own temporal tagging is that our temporal tagger extracts more information than that available in the training/testing data.", "labels": [], "entities": [{"text": "temporal tagging", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.6875110417604446}]}, {"text": "For instance, temporal signals are removed from the data that the task organizers provide, but our temporal tagger detects that, as part of the tagging procedure.", "labels": [], "entities": []}, {"text": "The following is an example for the tagged expression \"on this coming Sunday\".", "labels": [], "entities": []}, {"text": "<ArgStructure id=\"65\" type=\"timex\"> <argRef type=\"determiner\" tokStr=\"this\"/> <argRef type=\"directionIndicator\" tokStr=\"coming\"/> <argRef type=\"focus\" tokStr=\"Sunday\"/> <argRef type=\"prepSignal\" tokStr=\"on\"/> <argRef type=\"head\" tokStr=\"this coming Sunday\"/> <argRef type=\"root\" tokStr=\"on this coming Sunday\"/> <argValue type=\"focusType\" value=\"weekOfDay\"/> <argValue type=\"subType\" value=\"Fuzzy\"/> <argValue type=\"type\" value=\"Date\"/> </ArgStructure> Our data structure allows us to easily access and manipulate any part of the tagged chunk of text, which leaves the interpretation of whether the temporal signal on in the example is part of the temporal expression to users of temporal tagger.", "labels": [], "entities": []}, {"text": "Taking as input this data structure, the normalization, including relative date resolution, is a straightforward process, provided that the reference time can be computed from the context.", "labels": [], "entities": [{"text": "relative date resolution", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.5230031708876292}]}, {"text": "For temporal relation identification, by leveraging the capabilities of our temporal tagger, event tagger and several other in-house NLP tools, we derive a rich set of syntactic and semantic features for use by machine learning.", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7468509475390116}, {"text": "event tagger", "start_pos": 93, "end_pos": 105, "type": "TASK", "confidence": 0.6911864578723907}]}, {"text": "We also explored the possibility of combining the rulebased approach with machine learning in an integrated manner so that our system can take advantage of these two approaches for temporal relation identification.", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 181, "end_pos": 213, "type": "TASK", "confidence": 0.6378487646579742}]}], "datasetContent": [{"text": "Based on the features discussed in Section 3.3, we did a series of experiments for each task on four models: Naive-Bayes, Decision Tree (C5.0), Maximum Entropy and Support Vector Machine.", "labels": [], "entities": []}, {"text": "Due to space constraint, we only report results from SVM model 3 , which produces best performance in our case.", "labels": [], "entities": []}, {"text": "We here report two sets of performance numbers.", "labels": [], "entities": []}, {"text": "The first set is based on our evaluation against a set of held-out data, 20 documents for each task, which were taken from the training data.", "labels": [], "entities": []}, {"text": "The second set of performance numbers is based on evaluation against the final testing data provided by task organizers.", "labels": [], "entities": []}, {"text": "According to and 2, it appears that there are significant differences between the TLINK patterns in the held-out data and the final testing data, since the performance of the classifier shows an apparent discrepancy in two cases., 4 and 5 show performance numbers of our system, the average and the best system in comparison.", "labels": [], "entities": [{"text": "TLINK", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9343407154083252}]}, {"text": "There are six teams in total participating in the TempEval 2007 evaluation this year.", "labels": [], "entities": [{"text": "TempEval 2007 evaluation", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.7425574660301208}]}], "tableCaptions": [{"text": " Table 1. Performance figures evaluated against held-out data", "labels": [], "entities": []}]}