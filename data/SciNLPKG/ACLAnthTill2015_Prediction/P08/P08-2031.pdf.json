{"title": [{"text": "Using Automatically Transcribed Dialogs to Learn User Models in a Spoken Dialog System", "labels": [], "entities": []}], "abstractContent": [{"text": "We use an EM algorithm to learn user models in a spoken dialog system.", "labels": [], "entities": []}, {"text": "Our method requires automatically transcribed (with ASR) dialog corpora, plus a model of transcription errors, but does not otherwise need any manual transcription effort.", "labels": [], "entities": []}, {"text": "We tested our method on a voice-controlled telephone directory application , and show that our learned models better replicate the true distribution of user actions than those trained by simpler methods and are very similar to user models estimated from manually transcribed dialogs.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We conducted two sets of experiments on the telephone directory application, one using simulated data, and the other using dialogs collected from actual users.", "labels": [], "entities": []}, {"text": "Both sets of experiments assumed that all the distributions in, except the user model, are known.", "labels": [], "entities": []}, {"text": "The ASR confusion model was estimated by transcribing 50 randomly chosen dialogs from the training set in Section 4.2 and calculating the frequency with which the ASR engine recognized\u02dcAognized\u02dc ognized\u02dcA t such that\u02dcAthat\u02dc that\u02dcA t \ud97b\udf59 = At . The probabilities Pr( \u02dc At | At ) were then constructed by assuming that, when the ASR engine makes an error recognizing a user action, it substitutes another randomly chosen action.", "labels": [], "entities": [{"text": "ASR confusion", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9615655541419983}]}], "tableCaptions": []}