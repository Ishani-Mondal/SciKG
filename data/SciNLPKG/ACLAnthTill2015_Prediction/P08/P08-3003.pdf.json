{"title": [{"text": "Inferring Activity Time in News through Event Modeling", "labels": [], "entities": [{"text": "Inferring Activity Time in News through Event Modeling", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.706681702286005}]}], "abstractContent": [{"text": "Many applications in NLP, such as question-answering and summarization, either require or would greatly benefit from the knowledge of when an event occurred.", "labels": [], "entities": [{"text": "summarization", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.9791513681411743}]}, {"text": "Creating an effective algorithm for identifying the activity time of an event in news is difficult in part because of the sparsity of explicit temporal expressions.", "labels": [], "entities": []}, {"text": "This paper describes a domain-independent machine-learning based approach to assign activity times to events in news.", "labels": [], "entities": []}, {"text": "We demonstrate that by applying topic models to text, we are able to cluster sentences that describe the same event, and utilize the temporal information within these event clusters to infer activity times for all sentences.", "labels": [], "entities": []}, {"text": "Experimental evidence suggests that this is a promising approach, given evaluations performed on three distinct news article sets against the baseline of assigning the publication date.", "labels": [], "entities": []}, {"text": "Our approach achieves 90%, 88.7%, and 68.7% accuracy, respectively, outperform-ing the baseline twice.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9997394680976868}]}], "introductionContent": [{"text": "Many practical applications in NLP either require or would greatly benefit from the use of temporal information.", "labels": [], "entities": []}, {"text": "For instance, question-answering and summarization systems demand accurate processing of temporal information in order to be useful for answering 'when' questions and creating coherent summaries by temporally ordering information.", "labels": [], "entities": [{"text": "summarization", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.9696281552314758}]}, {"text": "Proper processing is especially relevant in news, where multiple disparate events maybe described within one news article, and it is necessary to identify the separate timepoints of each event.", "labels": [], "entities": [{"text": "Proper processing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7238336205482483}]}, {"text": "Event descriptions maybe confined to one sentence, which we establish as our text unit, or be spread over many, thus forcing us to assign all sentences an activity time.", "labels": [], "entities": []}, {"text": "However, only 20%-30% of sentences contain an explicit temporal expression, thus leaving the vast majority of sentences without temporal information.", "labels": [], "entities": []}, {"text": "A similar proportion is reported in, with only 25% of clauses containing explicit temporal expressions.", "labels": [], "entities": []}, {"text": "The sparsity of these expressions poses areal challenge.", "labels": [], "entities": []}, {"text": "Therefore, a method for efficiently and accurately utilizing temporal expressions to infer activity times for the remaining 70%-80% of sentences with no temporal information is necessary.", "labels": [], "entities": []}, {"text": "This paper proposes a domain-independent machine-learning based approach to assign activity times to events in news without deferring to the publication date.", "labels": [], "entities": []}, {"text": "Posing the problem in an information retrieval framework, we model events by applying topic models to news, providing away to automatically distribute temporal information to all sentences.", "labels": [], "entities": []}, {"text": "The result is prototype system which achieves promising results.", "labels": [], "entities": []}, {"text": "In the following section, we discuss related work in temporal information processing.", "labels": [], "entities": [{"text": "temporal information processing", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.6676663855711619}]}, {"text": "Next we motivate the use of topic models for our task, and present our methods for distributing temporal information.", "labels": [], "entities": []}, {"text": "We conclude by presenting and discussing our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In evaluating our approach, we wanted to compare different methods of modeling events prior to performing inference.", "labels": [], "entities": []}, {"text": "\u2022 Method (1) IAA then IRA.2 -Creating IAA models with 20 topics for each news article, and IRA.2 models for each of the three sets of IAA models with 20, 50, and 100 topic.", "labels": [], "entities": [{"text": "IRA.2", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9171532392501831}]}, {"text": "\u2022 Method (2) IAA only -Creating an IAA model with 20 topics for each article \u2022 Method (3) IRA.1 only -Creating IRA.1 model with 20 and 50 topics for each of the three sets of articles.", "labels": [], "entities": []}, {"text": "presents results for the three sets of articles on the six different experiments performed.", "labels": [], "entities": []}, {"text": "Since our approach assigns activity times to all sentences, overall accuracy is measured as the total number of correct activity time assignments made out of the total number of sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9992013573646545}]}, {"text": "The baseline accuracy is computed by assigning each sentence the article publication date, and because news generally describes current events, this achieves remarkably high performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9731537699699402}]}], "tableCaptions": [{"text": " Table 2: Article and Sentence distribution", "labels": [], "entities": [{"text": "Article", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.8118644952774048}]}, {"text": " Table 4: Results : Sentence Breakdown", "labels": [], "entities": [{"text": "Sentence Breakdown", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.9733409285545349}]}]}