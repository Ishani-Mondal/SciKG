{"title": [{"text": "Mixture Model POMDPs for Efficient Handling of Uncertainty in Dialogue Management", "labels": [], "entities": [{"text": "Dialogue Management", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.6936094462871552}]}], "abstractContent": [{"text": "In spoken dialogue systems, Partially Observable Markov Decision Processes (POMDPs) provide a formal framework for making dialogue management decisions under uncertainty , but efficiency and interpretability considerations mean that most current statistical dialogue managers are only MDPs.", "labels": [], "entities": []}, {"text": "These MDP systems encode uncertainty explicitly in a single state representation.", "labels": [], "entities": []}, {"text": "We formalise such MDP states in terms of distributions over POMDP states, and propose anew dialogue system architecture (Mixture Model POMDPs) which uses mixtures of these distributions to efficiently represent uncertainty.", "labels": [], "entities": []}, {"text": "We also provide initial evaluation results (with real users) for this architecture.", "labels": [], "entities": []}], "introductionContent": [{"text": "Partially Observable Markov Decision Processes (POMDPs) provide a formal framework for making decisions under uncertainty.", "labels": [], "entities": []}, {"text": "Recent research in spoken dialogue systems has used POMDPs for dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8790190517902374}]}, {"text": "These systems represent the uncertainty about the dialogue history using a probability distribution over dialogue states, known as the POMDP's belief state, and they use approximate POMDP inference procedures to make dialogue management decisions.", "labels": [], "entities": []}, {"text": "However, these inference procedures are too computationally intensive for most domains, and the system's behaviour can be difficult to predict.", "labels": [], "entities": []}, {"text": "Instead, most current statistical dialogue managers use a single state to represent the dialogue history, thereby making them only Markov Decision Process models (MDPs).", "labels": [], "entities": []}, {"text": "These state representations have been fine-tuned over many development cycles so that common types of uncertainty can be encoded in a single state.", "labels": [], "entities": []}, {"text": "Examples of such representations include unspecified values, confidence scores, and confirmed/unconfirmed features.", "labels": [], "entities": []}, {"text": "We formalise such MDP systems as compact encodings of POMDPs, where each MDP state represents a probability distribution over POMDP states.", "labels": [], "entities": []}, {"text": "We call these distributions \"MDP belief states\".", "labels": [], "entities": []}, {"text": "Given this understanding of MDP dialogue managers, we propose anew POMDP spoken dialogue system architecture which uses mixtures of MDP belief states to encode uncertainty.", "labels": [], "entities": [{"text": "MDP dialogue managers", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7925487359364828}, {"text": "POMDP spoken dialogue", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.5492133299509684}]}, {"text": "A Mixture Model POMDP represents its belief state as a probability distribution over a finite set of MDP states.", "labels": [], "entities": []}, {"text": "This extends the compact representations of uncertainty in MDP states to include arbitrary disjunction between MDP states.", "labels": [], "entities": []}, {"text": "Efficiency is maintained because such arbitrary disjunction is not needed to encode the most common forms of uncertainty, and thus the number of MDP states in the set can be kept small without losing accuracy.", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9712196588516235}, {"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9952908754348755}]}, {"text": "On the other hand, allowing multiple MDP states provides the representational mechanism necessary to incorporate multiple speech recognition hypotheses into the belief state representation.", "labels": [], "entities": []}, {"text": "In spoken dialogue systems, speech recognition is by far the most important source of uncertainty.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7896793186664581}]}, {"text": "By providing a mechanism to incorporate multiple arbitrary speech recognition hypotheses, the proposed architecture leverages the main advantage of POMDP systems while still maintaining the efficiency of MDP-based dialogue managers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have implemented a Mixture Model POMDP architecture as a multi-state version of the DIPPER \"Information State Update\" dialogue manager (.", "labels": [], "entities": []}, {"text": "It uses equation to compute belief state updates, given separate models for MDP state updates (for f (r i t\u22121 , a t\u22121 , h j t )), statistical ASR-SLU (for P (h j t |u t )/P (h j t )), and a statistical user model (for P (h j t |a t\u22121 , r i t\u22121 )).", "labels": [], "entities": [{"text": "ASR-SLU", "start_pos": 142, "end_pos": 149, "type": "METRIC", "confidence": 0.5989063382148743}]}, {"text": "The state list is pruned as described in section 2, where the \"core features\" are the filled information slot values and whether they have been confirmed.", "labels": [], "entities": []}, {"text": "For example, the system will merge two states which agree that the user only wants a cheap hotel, even if they disagree on the sequence of dialogue acts which lead to this information.", "labels": [], "entities": []}, {"text": "It also never prunes the \"null\" state, so that there is always some probability that the system knows nothing.", "labels": [], "entities": []}, {"text": "The system used in the experiments described below uses the MDP state representation and update function from (, which is designed for standard slot-filling dialogues.", "labels": [], "entities": []}, {"text": "For the ASR model, it uses the HTK speech recogniser () and an n-best list of three ASR hypotheses on each user turn.", "labels": [], "entities": [{"text": "ASR", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9857516884803772}, {"text": "HTK speech recogniser", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.7548601826032003}]}, {"text": "The prior over user inputs is assumed to be uniform.", "labels": [], "entities": []}, {"text": "The ASR hypotheses are passed to the SLU model from, which produces a single user input for each ASR hypothesis.", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9654123783111572}, {"text": "ASR hypothesis", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.8719367384910583}]}, {"text": "This SLU model was trained on the TownInfo corpus of dialogues, which was collected using the TownInfo human-machine dialogue systems of (), transcribed, and hand annotated.", "labels": [], "entities": [{"text": "TownInfo corpus of dialogues", "start_pos": 34, "end_pos": 62, "type": "DATASET", "confidence": 0.9699933677911758}, {"text": "TownInfo", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.9572596549987793}]}, {"text": "ASR hypotheses which result in the same user input are merged (summing their probabilities), and the resulting list of at most three ASR-SLU hypotheses are passed to the dialogue manager.", "labels": [], "entities": []}, {"text": "Thus the number of MDP states in the dialogue manager grows by up to three times at each step, before pruning.", "labels": [], "entities": []}, {"text": "For the user model, the system uses an ngram user model, as described in), trained on the annotated TownInfo corpus.", "labels": [], "entities": [{"text": "TownInfo corpus", "start_pos": 100, "end_pos": 115, "type": "DATASET", "confidence": 0.9813325107097626}]}, {"text": "The system's dialogue management policy is a Mixture Model Q-MDP (MM Q-MDP) policy.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7441507875919342}]}, {"text": "As with the MDP states, the MDP Q function is from (.", "labels": [], "entities": []}, {"text": "It was trained in an MDP system using reinforcement learning with simulated users (, and was not modified for use in our MM Q-MDP policy.", "labels": [], "entities": [{"text": "MM Q-MDP policy", "start_pos": 121, "end_pos": 136, "type": "DATASET", "confidence": 0.6511517763137817}]}, {"text": "We tested this system with 10 different users, each attempting 9 tasks in the TownInfo domain (searching for hotels and restaurants in a fictitious town), resulting in 90 test dialogues.", "labels": [], "entities": [{"text": "TownInfo domain", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.9506739377975464}]}, {"text": "The users each attempted 3 tasks with the MDP system of (Lemon and Liu, 2007), 3 tasks with a state-of-the-art handcoded system (see ()), and 3 tasks with the MM Q-MDP system.", "labels": [], "entities": []}, {"text": "Ordering of systems and tasks was controlled, and 3 of the users were not native speakers of English.", "labels": [], "entities": []}, {"text": "We collected the Task Completion (TC), and dialogue length for each system, as reported in table 1.", "labels": [], "entities": [{"text": "Task Completion (TC)", "start_pos": 17, "end_pos": 37, "type": "METRIC", "confidence": 0.6216565430164337}, {"text": "dialogue length", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.64860799908638}]}, {"text": "Task Completion is counted from the system logs when the user replies that they are happy with their chosen option.", "labels": [], "entities": []}, {"text": "Such a small sample size means that these results are not statistically significant, but there is a clear trend showing the superiority of the the MM Q-MDP system, both in terms of more tasks being completed and less variability in overall dialogue length.", "labels": [], "entities": [{"text": "MM Q-MDP", "start_pos": 147, "end_pos": 155, "type": "TASK", "confidence": 0.6805856227874756}]}, {"text": "Georgilla for training this model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Initial test results for human-machine dialogues,  showing task completion and average length.", "labels": [], "entities": [{"text": "length", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.6893389821052551}]}]}