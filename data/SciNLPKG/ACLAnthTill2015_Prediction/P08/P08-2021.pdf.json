{"title": [{"text": "Machine Translation System Combination using ITG-based Alignments *", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7375971078872681}]}], "abstractContent": [{"text": "Given several systems' automatic translations of the same sentence, we show how to combine them into a confusion network, whose various paths represent composite translations that could be considered in a subsequent rescoring step.", "labels": [], "entities": []}, {"text": "We build our confusion networks using the method of Rosti et al.", "labels": [], "entities": []}, {"text": "(2007), but, instead of forming alignments using the tercom script (Snover et al., 2006), we create alignments that minimize invWER (Leusch et al., 2003), a form of edit distance that permits properly nested block movements of substrings.", "labels": [], "entities": []}, {"text": "Oracle experiments with Chinese newswire and weblog translations show that our confusion networks contain paths which are significantly better (in terms of BLEU and TER) than those in tercom-based confusion networks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9991305470466614}, {"text": "TER", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.988521933555603}]}], "introductionContent": [{"text": "Large improvements in machine translation (MT) may result from combining different approaches to MT with mutually complementary strengths.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8488129138946533}, {"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.949456512928009}]}, {"text": "System-level combination of translation outputs is a promising path towards such improvements.", "labels": [], "entities": [{"text": "translation outputs", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8767256736755371}]}, {"text": "Yet there are some significant hurdles in this path.", "labels": [], "entities": []}, {"text": "One must somehow align the multiple outputs-to identify where different hypotheses reinforce each other and where they offer alternatives.", "labels": [], "entities": []}, {"text": "One must then use this alignment to hypothesize a set of new, composite translations, and select the best composite hypothesis from this set.", "labels": [], "entities": []}, {"text": "The alignment step is difficult because different MT approaches usually reorder the translated words differently.", "labels": [], "entities": [{"text": "alignment", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.9623562097549438}, {"text": "MT", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9712985157966614}]}, {"text": "Training the selection step is difficult because identifying the best hypothesis (relative to a known reference translation) means scoring all the composite hypotheses, of which there maybe exponentially many.", "labels": [], "entities": []}, {"text": "Most MT combination methods do create an exponentially large hypothesis set, representing it as a confusion network of strings in the target language (e.g., English).", "labels": [], "entities": [{"text": "MT combination", "start_pos": 5, "end_pos": 19, "type": "TASK", "confidence": 0.9786373674869537}]}, {"text": "(A confusion network is a lattice where every node is on every path; i.e., each time step presents an independent choice among several phrases.", "labels": [], "entities": []}, {"text": "Note that our contributions in this paper could be applied to arbitrary lattice topologies.)", "labels": [], "entities": []}, {"text": "For example, show how to build a confusion network following a multistring alignment procedure of several MT outputs.", "labels": [], "entities": []}, {"text": "The procedure (used primarily in biology, () yields monotone alignments that minimize the number of insertions, deletions, and substitutions.", "labels": [], "entities": []}, {"text": "Unfortunately, monotone alignments are often poor, since machine translations (particularly from different models) can vary significantly in their word order.", "labels": [], "entities": []}, {"text": "Thus, when use this procedure, they deterministically reorder each translation prior to the monotone alignment.", "labels": [], "entities": []}, {"text": "The procedure described by has been shown to yield significant improvements in translation quality, and uses an estimate of Translation Error Rate (TER) to guide the alignment.", "labels": [], "entities": [{"text": "translation", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.9462506771087646}, {"text": "Translation Error Rate (TER)", "start_pos": 124, "end_pos": 152, "type": "METRIC", "confidence": 0.9760694007078806}]}, {"text": "(TER is defined as the minimum number of inser-tions, deletions, substitutions and block shifts between two strings.)", "labels": [], "entities": [{"text": "TER", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.9979786276817322}]}, {"text": "A remarkable feature of that procedure is that it performs the alignment of the output translations (i) without any knowledge of the translation model used to generate the translations, and (ii) without any knowledge of how the target words in each translation align back to the source words.", "labels": [], "entities": []}, {"text": "In fact, it only requires a procedure for creating pairwise alignments of translations that allow appropriate re-orderings.", "labels": [], "entities": []}, {"text": "For this, use the tercom script (), which uses a number of heuristics (as well as dynamic programming) for finding a sequence of edits (insertions, deletions, substitutions and block shifts) that convert an input string to another.", "labels": [], "entities": []}, {"text": "In this paper, we show that one can build better confusion networks (in terms of the best translation possible from the confusion network) when the pairwise alignments are computed not by tercom, which approximately minimizes TER, but instead by an exact minimization of invWER (, which is a restricted version of TER that permits only properly nested sets of block shifts, and can be computed in polynomial time.", "labels": [], "entities": [{"text": "TER", "start_pos": 226, "end_pos": 229, "type": "METRIC", "confidence": 0.996826171875}]}, {"text": "The paper is organized as follows: a summary of TER, tercom, and invWER, is presented in Section 2.", "labels": [], "entities": [{"text": "TER", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9971387386322021}]}, {"text": "The system combination procedure is summarized in Section 3, while experimental (oracle) results are presented in Section 4.", "labels": [], "entities": []}, {"text": "Conclusions are given in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We also tried to understand which alignment method gives higher probability to paths \"close\" to the corresponding oracle.", "labels": [], "entities": []}, {"text": "To do that, we computed the probability that a random path from a confusion network is within x edits from its oracle.", "labels": [], "entities": []}, {"text": "This computation was done efficiently using finite-state-machine operations, and did not involve any randomization.", "labels": [], "entities": []}, {"text": "Preliminary experiments with the invWER-oracles show that the probability of all paths which are within x = 3 edits from the oracle is roughly the same for ITG-based and tercom-based confusion networks.", "labels": [], "entities": []}, {"text": "We plan to report our findings fora whole range of x-values in future work.", "labels": [], "entities": []}, {"text": "Finally, a runtime comparison of the two techniques shows that ITGs are much more computationally intensive: on average, ITG-based alignments took 1.5 hours/sentence (owing to their O(n 6 ) complexity), while tercom-based alignments only took 0.4 sec/sentence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of average per-document ter- comTER with invWER on the EVAL07 GALE Newswire  (\"NW\") and Weblogs (\"WB\") data sets.", "labels": [], "entities": [{"text": "EVAL07 GALE Newswire  (\"NW\") and Weblogs (\"WB\") data sets", "start_pos": 76, "end_pos": 133, "type": "DATASET", "confidence": 0.7719001953418438}]}]}