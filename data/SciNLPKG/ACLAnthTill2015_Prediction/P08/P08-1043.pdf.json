{"title": [{"text": "A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing", "labels": [], "entities": [{"text": "Joint Morphological Segmentation", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.7049157619476318}, {"text": "Syntactic Parsing", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.8282496333122253}]}], "abstractContent": [{"text": "Morphological processes in Semitic languages deliver space-delimited words which introduce multiple, distinct, syntactic units into the structure of the input sentence.", "labels": [], "entities": []}, {"text": "These words are in turn highly ambiguous, breaking the assumption underlying most parsers that the yield of a tree fora given sentence is known in advance.", "labels": [], "entities": []}, {"text": "Here we propose a single joint model for performing both morphological segmenta-tion and syntactic disambiguation which bypasses the associated circularity.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.7125886082649231}]}, {"text": "Using a tree-bank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing , yielding an error reduction of 12% over the best published results so far.", "labels": [], "entities": [{"text": "Hebrew morphological and syntactic processing", "start_pos": 194, "end_pos": 239, "type": "TASK", "confidence": 0.6159056067466736}, {"text": "error reduction", "start_pos": 254, "end_pos": 269, "type": "METRIC", "confidence": 0.9743029475212097}]}], "introductionContent": [{"text": "Current state-of-the-art broad-coverage parsers assume a direct correspondence between the lexical items ingrained in the proposed syntactic analyses (the yields of syntactic parse-trees) and the spacedelimited tokens (henceforth, 'tokens') that constitute the unanalyzed surface forms (utterances).", "labels": [], "entities": [{"text": "broad-coverage parsers", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7625372409820557}]}, {"text": "In Semitic languages the situation is very different.", "labels": [], "entities": []}, {"text": "In Modern Hebrew (Hebrew), a Semitic language with very rich morphology, particles marking conjunctions, prepositions, complementizers and relativizers are bound elements prefixed to the word.", "labels": [], "entities": []}, {"text": "The Hebrew token 'bcl' 1 , for example, stands for the complete prepositional phrase We adopt here the transliteration of).", "labels": [], "entities": []}, {"text": "\"in the shadow\".", "labels": [], "entities": []}, {"text": "This token may further embed into a larger utterance, e.g., 'bcl hneim' (literally \"in-the-shadow the-pleasant\", meaning roughly \"in the pleasant shadow\") in which the dominated Noun is modified by a proceeding space-delimited adjective.", "labels": [], "entities": []}, {"text": "It should be clear from the onset that the particle b (\"in\") in 'bcl' may then attach higher than the bare noun cl (\"shadow\").", "labels": [], "entities": []}, {"text": "This leads to word-and constituent-boundaries discrepancy, which breaks the assumptions underlying current state-of-the-art statistical parsers.", "labels": [], "entities": []}, {"text": "One way to approach this discrepancy is to assume a preceding phase of morphological segmentation for extracting the different lexical items that exist at the token level (as is done, to the best of our knowledge, in all parsing related work on Arabic and its dialects ().", "labels": [], "entities": []}, {"text": "The input for the segmentation task is however highly ambiguous for Semitic languages, and surface forms (tokens) may admit multiple possible analyses as in).", "labels": [], "entities": [{"text": "segmentation task", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.916775107383728}]}, {"text": "The aforementioned surface form bcl, for example, may also stand for the lexical item \"onion\", a Noun.", "labels": [], "entities": []}, {"text": "The implication of this ambiguity fora parser is that the yield of syntactic trees no longer consists of spacedelimited tokens, and the expected number of leaves in the syntactic analysis in not known in advance.", "labels": [], "entities": []}, {"text": "argues that for Semitic languages determining the correct morphological segmentation is dependent on syntactic context and shows that increasing information sharing between the morphological and the syntactic components leads to improved performance on the joint task.", "labels": [], "entities": []}, {"text": "followed upon these results and pro-posed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.", "labels": [], "entities": []}, {"text": "Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.7260094285011292}]}, {"text": "We claim that no particular morphological segmentation is a-priory more likely for surface forms before exploring the compositional nature of syntactic structures, including manifestations of various long-distance dependencies.", "labels": [], "entities": []}, {"text": "Morphological segmentation decisions in our model are delegated to a lexeme-based PCFG and we show that using a simple treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling our model outperforms) and on the joint task and achieves state-of-the-art results on a par with current respective standalone models.", "labels": [], "entities": [{"text": "Morphological segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7139970362186432}]}], "datasetContent": [{"text": "Previous work on morphological and syntactic disambiguation in Hebrew used different sets of data, different splits, differing annotation schemes, and different evaluation measures.", "labels": [], "entities": [{"text": "morphological and syntactic disambiguation", "start_pos": 17, "end_pos": 59, "type": "TASK", "confidence": 0.6498392149806023}]}, {"text": "Our experimental setup therefore is designed to serve two goals.", "labels": [], "entities": []}, {"text": "Our primary goal is to exploit the resources that are most appropriate for the task at hand, and our secondary goal is to allow for comparison of our models' performance against previously reported results.", "labels": [], "entities": []}, {"text": "When a comparison against previous results requires additional pre-processing, we state it explicitly to allow for the reader to replicate the reported results.", "labels": [], "entities": []}, {"text": "Data We use the Hebrew Treebank,), provided by the knowledge center for processing Hebrew, in which sentences from the daily newspaper \"Ha'aretz\" are morphologically segmented and syntactically annotated.", "labels": [], "entities": [{"text": "Hebrew Treebank", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.921227216720581}]}, {"text": "The treebank has two versions, v1.0 and v2.0, containing 5001 and 6501 sentences respectively.", "labels": [], "entities": []}, {"text": "We use v1.0 mainly because previous studies on joint inference reported results w.r.t.", "labels": [], "entities": []}, {"text": "We expect that using the same setup on v2.0 will allow a crosstreebank comparison.", "labels": [], "entities": []}, {"text": "We used the first 500 sentences as our dev set and the rest 4500 for training and report our main results on this split.", "labels": [], "entities": []}, {"text": "To facilitate the comparison of our results to those reported by we use their data set in which 177 empty and \"malformed\" 7 were removed.", "labels": [], "entities": []}, {"text": "The first 3770 trees of the resulting set then were used for training, and the last 418 are used testing.", "labels": [], "entities": []}, {"text": "(we ignored the 419 trees in their development set.)", "labels": [], "entities": []}, {"text": "Morphological Analyzer Ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.", "labels": [], "entities": [{"text": "Morphological Analyzer Ideally", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7495155135790507}]}, {"text": "Such resources exist for Hebrew (), but unfortunately use a tagging scheme which is incom-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Segmentation, Parsing and Tagging Results us- ing the Setup of (Cohen and Smith, 2007) (sentence  length \u2264 40). The Models' are Ordered by Performance.", "labels": [], "entities": [{"text": "Parsing and Tagging", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7014405926068624}]}, {"text": " Table 1: Segmentation, tagging and parsing results on the Standard dev/train Split, for all Sentences", "labels": [], "entities": [{"text": "Standard dev/train Split", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.9073048233985901}, {"text": "Sentences", "start_pos": 93, "end_pos": 102, "type": "TASK", "confidence": 0.560050904750824}]}]}