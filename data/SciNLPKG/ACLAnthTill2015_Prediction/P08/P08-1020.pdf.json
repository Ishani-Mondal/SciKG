{"title": [{"text": "Trainable Generation of Big-Five Personality Styles through Data-driven Parameter Estimation", "labels": [], "entities": [{"text": "Parameter Estimation", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.6399097144603729}]}], "abstractContent": [{"text": "Previous work on statistical language generation has primarily focused on grammat-icality and naturalness, scoring generation possibilities according to a language model or user feedback.", "labels": [], "entities": [{"text": "statistical language generation", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7501938343048096}]}, {"text": "More recent work has investigated data-driven techniques for controlling linguistic style without overgenera-tion, by reproducing variation dimensions extracted from corpora.", "labels": [], "entities": []}, {"text": "Another line of work has produced handcrafted rule-based systems to control specific stylistic dimensions, such as politeness and personality.", "labels": [], "entities": []}, {"text": "This paper describes a novel approach that automatically learns to produce recognisable variation along a meaningful stylistic dimension-personality-without the computational cost incurred by overgeneration techniques.", "labels": [], "entities": []}, {"text": "We present the first evaluation of a data-driven generation method that projects multiple personality traits simultaneously and on a continuous scale.", "labels": [], "entities": []}, {"text": "We compare our performance to a rule-based generator in the same domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the last 20 years, statistical language models (SLMs) have been used successfully in many tasks in natural language processing, and the data available for modeling has steadily grown).", "labels": [], "entities": [{"text": "statistical language models (SLMs)", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.709442933400472}]}, {"text": "first applied SLMs to statistical natural language generation (SNLG), showing that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase.", "labels": [], "entities": [{"text": "statistical natural language generation (SNLG)", "start_pos": 22, "end_pos": 68, "type": "TASK", "confidence": 0.7939026440892901}]}, {"text": "Since then, research in SNLG has explored a range of models for both dialogue and text generation.", "labels": [], "entities": [{"text": "SNLG", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.8427428007125854}, {"text": "text generation", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.7368550449609756}]}, {"text": "One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics;).", "labels": [], "entities": []}, {"text": "Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (;).", "labels": [], "entities": [{"text": "SNLG scoring", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.8909884095191956}]}, {"text": "The error of these scoring models approaches the gold-standard human ranking with a relatively small training set.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9780776500701904}]}, {"text": "A third SNLG approach eliminates the overgeneration phase.", "labels": [], "entities": [{"text": "SNLG", "start_pos": 8, "end_pos": 12, "type": "TASK", "confidence": 0.9434424042701721}]}, {"text": "It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurements.", "labels": [], "entities": []}, {"text": "The generator was shown to reproduce intended factor levels across several factors, thus modelling the stylistic variation as measured in the original corpus.", "labels": [], "entities": []}, {"text": "Our goal is a generation technique that can target multiple stylistic effects simultaneously and over a continuous scale, controlling stylistic dimensions that are commonly understood and thus meaningful to users and application developers.", "labels": [], "entities": []}, {"text": "Our intended applications are output utterances for intelligent training or intervention systems, video game characters, or virtual environment avatars.", "labels": [], "entities": []}, {"text": "In previous work, we presented PERSON-AGE, a psychologically-informed rule-based generator based on the Big Five personality model, and we showed that PERSONAGE can project extreme personality on the extraversion scale, i.e. both introverted and extraverted personality types ( . We used the Big Five model to develop PERSONAGE for several reasons.", "labels": [], "entities": []}, {"text": "First, the Big Five has been shown in psychology to ex- plain much of the variation inhuman perceptions of personality differences.", "labels": [], "entities": []}, {"text": "Second, we believe that the adjectives used to develop the Big Five model provide an intuitive, meaningful definition of linguistic style.", "labels": [], "entities": []}, {"text": "shows some of the trait adjectives associated with the extremes of each Big Five trait.", "labels": [], "entities": []}, {"text": "Third, there are many studies linking personality to linguistic variables, inter alia).", "labels": [], "entities": []}, {"text": "See ( ) for more detail.", "labels": [], "entities": []}, {"text": "In this paper, we further test the utility of basing stylistic variation on the Big Five personality model.", "labels": [], "entities": []}, {"text": "The Big Five traits are represented by scalar values that range from 1 to 7, with values normally distributed among humans.", "labels": [], "entities": []}, {"text": "While our previous work targeted extreme values of individual traits, here we show that we can target multiple personality traits simultaneously and over the continuous scales of the Big Five model.", "labels": [], "entities": []}, {"text": "Section 2 describes a novel parameter-estimation method that automatically learns to produce recognisable variation for all Big Five traits, without overgeneration, implemented in anew SNLG called PERSONAGE-PE.", "labels": [], "entities": []}, {"text": "We show that PERSONAGE-PE generates targets for multiple personality dimensions, using linear and non-linear parameter estimation models to predict generation parameters directly from the scalar targets.", "labels": [], "entities": []}, {"text": "Section 3.2 shows that humans accurately perceive the intended variation, and Section 3.3 compares PERSONAGE-PE (trained) with PERSONAGE (rule-based; . We delay a detailed discussion of related work to Section 4, where we summarize and discuss future work.", "labels": [], "entities": [{"text": "PERSONAGE-PE", "start_pos": 99, "end_pos": 111, "type": "METRIC", "confidence": 0.9432021379470825}, {"text": "PERSONAGE", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9120310544967651}]}], "datasetContent": [{"text": "The generation phase of our parameter estimation SNLG method consists of the following steps: 1.", "labels": [], "entities": [{"text": "parameter estimation SNLG", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.5674612720807394}]}, {"text": "Use the best performing models to predict parameter values from the desired personality scores; 2.", "labels": [], "entities": []}, {"text": "Generate the output utterance using the predicted parameter values.", "labels": [], "entities": []}, {"text": "We then evaluate the output utterances using naive human judges to rate their perceived personality and naturalness.", "labels": [], "entities": []}, {"text": "Given the best performing model for each generation parameter, we generate 5 utterances for each of 5 recommendation and 5 comparison speech acts.", "labels": [], "entities": []}, {"text": "Each utterance targets an extreme value for two traits (either 1 or 7 out of 7) and neutral values for the remaining three traits (4 out of 7).", "labels": [], "entities": []}, {"text": "The goal is for each utterance to project multiple traits on a continuous scale.", "labels": [], "entities": []}, {"text": "To generate a range of alternatives, a Gaussian noise with a standard deviation of 10% of the full scale is added to each target value.", "labels": [], "entities": []}, {"text": "Subjects were 24 native English speakers (12 male and 12 female graduate students from a range of disciplines from both the U.K. and the U.S.).", "labels": [], "entities": []}, {"text": "Subjects evaluate the naturalness and personality of each utterance using the TIPI (.", "labels": [], "entities": [{"text": "TIPI", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.7779489755630493}]}, {"text": "To limit the experiment's duration, only the two traits with extreme target values are evaluated for each utterance.", "labels": [], "entities": [{"text": "duration", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9651492238044739}]}, {"text": "Subjects thus answered 5 questions for 50 utterances, two from the TIPI for each extreme trait and one about naturalness (250 judgments in total per subject).", "labels": [], "entities": [{"text": "TIPI", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.685370922088623}]}, {"text": "Subjects were not told that the utterances were intended to manifest extreme trait values.", "labels": [], "entities": []}, {"text": "shows several sample outputs and the mean personality ratings from the human judges.", "labels": [], "entities": []}, {"text": "For example, utterance 1.a projects a high extraversion through the insertion of an exclamation mark based on the model in, whereas utterance 2.a conveys introversion by beginning with the filled pause err.", "labels": [], "entities": []}, {"text": "The same utterance also projects a low agreeableness by focusing on negative propositions, through a low CONTENT POLARITY parameter value as per the model in.", "labels": [], "entities": [{"text": "CONTENT POLARITY parameter value", "start_pos": 105, "end_pos": 137, "type": "METRIC", "confidence": 0.8906773775815964}]}, {"text": "This evaluation addresses a number of open questions discussed below.", "labels": [], "entities": []}, {"text": "shows that extraversion is the dimension modeled most accurately by the parameter estimation models, producing a .45 correlation with the subjects' ratings (p < .01).", "labels": [], "entities": [{"text": "extraversion", "start_pos": 11, "end_pos": 23, "type": "METRIC", "confidence": 0.9433884024620056}]}, {"text": "Emotional stability, agreeableness, and openness to experience ratings also correlate strongly with the target scores, with correlations of .39, .36 and .17 respectively (p < .01).", "labels": [], "entities": [{"text": "Emotional stability", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.8794066607952118}]}, {"text": "Additionally, shows that the magnitude of the correlation increases when considering the perception of a hypothetical average subject, i.e. smoothing individual variation by averaging the ratings overall 24 judges, producing a correlation r avg up to .80 for extraversion.", "labels": [], "entities": []}, {"text": "These correlations are unexpectedly high; in corpus analyses, significant correlations as low as .05 to .10 are typically observed between personality and linguistic markers).", "labels": [], "entities": []}, {"text": "Conscientiousness is the only dimension whose ratings do not correlate with the target scores.", "labels": [], "entities": [{"text": "Conscientiousness", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.9012898802757263}]}, {"text": "The comparison with rule-based results in Section 3.3 suggests that this is not because conscientiousness cannot be exhibited in our domain or manifested in a single utterance, so perhaps this arises from differing perceptions of conscientiousness between the expert and naive judges.: Pearson's correlation coefficient rand mean absolute error e between the target personality scores and the 480 judges' ratings (20 ratings per trait for 24 judges); r avg is the correlation between the personality scores and the average judges' ratings.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient rand mean absolute error e", "start_pos": 286, "end_pos": 346, "type": "METRIC", "confidence": 0.6641512148910098}]}, {"text": "shows that the mean absolute error varies between 1.89 and 2.79 on a scale from 1 to 7.", "labels": [], "entities": [{"text": "mean absolute error", "start_pos": 15, "end_pos": 34, "type": "METRIC", "confidence": 0.8792612751324972}]}, {"text": "Such large errors result from the decision to ask judges to answer just the TIPI questions for the two traits that were the extreme targets (See Section 3.1), because the judges tend to use the whole scale, with approximately normally distributed ratings.", "labels": [], "entities": []}, {"text": "This means that although the judges make distinctions leading to high correlations, they do soon a compressed scale.", "labels": [], "entities": [{"text": "correlations", "start_pos": 70, "end_pos": 82, "type": "METRIC", "confidence": 0.9561653733253479}]}, {"text": "This explains the large correlations despite the magnitude of the absolute error.", "labels": [], "entities": []}, {"text": "shows results evaluating whether utterances targeting the extremes of a trait are perceived differently.", "labels": [], "entities": []}, {"text": "The ratings differ significantly for all traits but conscientiousness (p \u2264 .001).", "labels": [], "entities": [{"text": "conscientiousness", "start_pos": 52, "end_pos": 69, "type": "METRIC", "confidence": 0.9839324951171875}]}, {"text": "Thus parameter estimation models can be used in applications that only require discrete binary variation.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.6850432753562927}]}, {"text": "It is important to emphasize that generation parameters were predicted based on 5 target personality values.", "labels": [], "entities": []}, {"text": "Thus, the results show that individual traits are perceived even when utterances project other traits as well, confirming that the Big Five theory models independent dimensions and thus provides a useful and meaningful framework for modeling variation in language.", "labels": [], "entities": []}, {"text": "Additionally, although we do not directly evaluate the perception of midrange values of personality target scores, the results suggest that mid-range personality is modeled correctly because the neutral target scores do not affect the perception of extreme traits.", "labels": [], "entities": []}, {"text": "The naive judges also evaluated the naturalness of the outputs of our trained models.", "labels": [], "entities": []}, {"text": "shows that the average naturalness is 3.98 out of 7, which is significantly lower (p < .05) than the naturalness of handcrafted and randomly generated utterances reported by . It is possible that the differences arise from judgments of utterances targeting multiple traits, or that the naive judges are more critical.", "labels": [], "entities": []}, {"text": "Trait Rule-based Random Learned All 4.59 4.38 3.98: Average naturalness ratings for utterances generated using (1) PERSONAGE, the rule-based generator, (2) the random utterances (expert judges) and (3) the outputs of PERSONAGE-PE using the parameter estimation models (Learned, naive judges).", "labels": [], "entities": []}, {"text": "The means differ significantly at the p < .05 level (two-tailed independent sample t-test).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example adjectives associated with extreme values of the Big Five trait scales.", "labels": [], "entities": [{"text": "Big Five trait scales", "start_pos": 67, "end_pos": 88, "type": "DATASET", "confidence": 0.7740581035614014}]}, {"text": " Table 3: Pearson's correlation between parameter model  predictions and continuous parameter values, for differ- ent regression models. Parameters that do not correlate  with any trait are omitted. Aggregation operations are as- sociated with a rhetorical relation (e.g. INFER). Results  are averaged over a 10-fold cross-validation.", "labels": [], "entities": []}, {"text": " Table 5: Example outputs controlled by the parameter estimation models for a comparison (#1) and a recommendation  (#2), with the average judges' ratings (Rating) and naturalness (Nat). Ratings are on a scale from 1 to 7, with 1 = very  low (e.g. neurotic or introvert) and 7 = very high on the dimension (e.g. emotionally stable or extraverted).", "labels": [], "entities": [{"text": "naturalness (Nat)", "start_pos": 168, "end_pos": 185, "type": "METRIC", "confidence": 0.7126637324690819}]}, {"text": " Table 6: Pearson's correlation coefficient r and mean ab- solute error e between the target personality scores and  the 480 judges' ratings (20 ratings per trait for 24 judges);  r avg is the correlation between the personality scores and  the average judges' ratings.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient r", "start_pos": 10, "end_pos": 45, "type": "METRIC", "confidence": 0.8299673676490784}, {"text": "mean ab- solute error e", "start_pos": 50, "end_pos": 73, "type": "METRIC", "confidence": 0.8685755729675293}]}, {"text": " Table 7: Average personality ratings for the utterances  generated with the low and high target values for each  trait on a scale from 1 to 7.", "labels": [], "entities": []}, {"text": " Table 8: Pair-wise comparison between the ratings of  the utterances generated using PERSONAGE-PE with ex- treme target values (Learned Parameters), and the ratings  for utterances generated with Mairesse and Walker's rule- based PERSONAGE generator, (Rule-based). Ratings are  averaged over all judges.", "labels": [], "entities": []}]}