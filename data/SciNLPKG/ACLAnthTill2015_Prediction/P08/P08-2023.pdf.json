{"title": [{"text": "A Novel Feature-based Approach to Chinese Entity Relation Extraction", "labels": [], "entities": [{"text": "Chinese Entity Relation Extraction", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.7879046499729156}]}], "abstractContent": [{"text": "Relation extraction is the task of finding semantic relations between two entities from text.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9673866927623749}]}, {"text": "In this paper, we propose a novel feature-based Chinese relation extraction approach that explicitly defines and explores nine positional structures between two entities.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.5965433915456136}]}, {"text": "We also suggest some correction and inference mechanisms based on relation hierarchy and co-reference information etc.", "labels": [], "entities": []}, {"text": "The approach is effective when evaluated on the ACE 2005 Chinese data set.", "labels": [], "entities": [{"text": "ACE 2005 Chinese data set", "start_pos": 48, "end_pos": 73, "type": "DATASET", "confidence": 0.9829495310783386}]}], "introductionContent": [{"text": "Relation extraction is promoted by the ACE program.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9274735450744629}]}, {"text": "It is the task of finding predefined semantic relations between two entities from text.", "labels": [], "entities": []}, {"text": "For example, the sentence \"Bill Gates is the chairman and chief software architect of Microsoft Corporation\" conveys the ACE-style relation \"ORG-AFFILIATION\" between the two entities \"Bill Gates (PER)\" and \"Microsoft Corporation (ORG)\".", "labels": [], "entities": [{"text": "ORG-AFFILIATION", "start_pos": 141, "end_pos": 156, "type": "METRIC", "confidence": 0.8408588767051697}]}, {"text": "The task of relation extraction has been extensively studied in English over the past years.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.9651929438114166}]}, {"text": "It is typically cast as a classification problem.", "labels": [], "entities": [{"text": "classification problem", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.9123003482818604}]}, {"text": "Existing approaches include feature-based and kernel-based classification.", "labels": [], "entities": [{"text": "kernel-based classification", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6731757372617722}]}, {"text": "Feature-based approaches transform the context of two entities into a liner vector of carefully selected linguistic features, varying from entity semantic information to lexical and syntactic features of the context.", "labels": [], "entities": []}, {"text": "Kernel-based approaches, on the other hand, explore structured representation such as parse tree and dependency tree and directly compute the similarity between trees.", "labels": [], "entities": []}, {"text": "Comparably, feature-based approaches are easier to implement and achieve much success.", "labels": [], "entities": []}, {"text": "In contrast to the significant achievements concerning English and other Western languages, research progress in Chinese relation extraction is quite limited.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.6668885052204132}]}, {"text": "This maybe attributed to the different characteristic of Chinese language, e.g. no word boundaries and lack of morphologic variations, etc.", "labels": [], "entities": []}, {"text": "In this paper, we propose a character-based Chinese entity relation extraction approach that complements entity context (both internal and external) character N-grams with four word lists extracted from a published Chinese dictionary.", "labels": [], "entities": [{"text": "character-based Chinese entity relation extraction", "start_pos": 28, "end_pos": 78, "type": "TASK", "confidence": 0.5891507685184478}]}, {"text": "In addition to entity semantic information, we define and examine nine positional structures between two entities.", "labels": [], "entities": []}, {"text": "To cope with the data sparseness problem, we also suggest some correction and inference mechanisms according to the given ACE relation hierarchy and co-reference information.", "labels": [], "entities": []}, {"text": "Experiments on the ACE 2005 data set show that the positional structure feature can provide stronger support for Chinese relation extraction.", "labels": [], "entities": [{"text": "ACE 2005 data set", "start_pos": 19, "end_pos": 36, "type": "DATASET", "confidence": 0.9872195273637772}, {"text": "Chinese relation extraction", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.7076836228370667}]}, {"text": "Meanwhile, it can be captured with less effort than applying deep natural language processing.", "labels": [], "entities": []}, {"text": "But unfortunately, entity co-reference does not help as much as we have expected.", "labels": [], "entities": []}, {"text": "The lack of necessary co-referenced mentions might be the main reason.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments are conducted on the ACE 2005 Chinese RDC training data (with true entities) where 6 types and 18 subtypes of relations are annotated.", "labels": [], "entities": [{"text": "ACE 2005 Chinese RDC training data", "start_pos": 37, "end_pos": 71, "type": "DATASET", "confidence": 0.9556800822416941}]}, {"text": "We use 75% of it to train SVM classifiers and the remaining to evaluate results.", "labels": [], "entities": [{"text": "SVM classifiers", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.681890070438385}]}, {"text": "The aim of the first set of experiments is to examine the role of structure features.", "labels": [], "entities": []}, {"text": "In these experiments, a \"NONE\" class is added to indicate a null type/subtype.", "labels": [], "entities": [{"text": "NONE", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.7782054543495178}]}, {"text": "With entity features and entity context features and word list features, we consider three different classification contexts: (1), only three coarser structures 1 , i.e. nested, adjacent and separated, are used as feature, and a classifier is trained for each relation type and subtype; (2) similar to (1) but all nine structures are concerned; and (3) similar to (2) but the training data is divided into 9 parts according to structure, i.e. type and subtype classifiers are trained on the data with the same structures.", "labels": [], "entities": []}, {"text": "The results presented in show that 9-structure is much more discriminative than 3-structure.", "labels": [], "entities": []}, {"text": "Also, the performance can be improved significantly by dividing training data based on nine structures.", "labels": [], "entities": []}, {"text": "In the experiments, we find that the training class imbalance problem is quite serious, especially for the separated structure (see above where \"Positive\" and \"Negative\" mean there exists a relation between two entities and otherwise).", "labels": [], "entities": []}, {"text": "A possible solution to alleviate this problem is to detect whether the given two entities have some relation first and if they do then to classify the relation types and subtypes instead of combining detection and classification in one process.", "labels": [], "entities": []}, {"text": "The second set of experiment is to examine the difference between these two implementations.", "labels": [], "entities": []}, {"text": "Against our expectation, the sequence implementation does better than the combination implementation, but not significantly, as shown in   Based on the sequence implementation, we setup the third set of experiments to examine the correction and inference mechanisms.", "labels": [], "entities": []}, {"text": "The results are illustrated in.", "labels": [], "entities": []}, {"text": "The correction with constraints and consistency check is clearly contributing.", "labels": [], "entities": [{"text": "consistency check", "start_pos": 36, "end_pos": 53, "type": "METRIC", "confidence": 0.9777393639087677}]}, {"text": "It improves F-measure 7.40% and 6.47% in type and subtype classification respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9979264736175537}, {"text": "type", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9329606294631958}]}, {"text": "We further compare four possible consistency check strategies in and find that the strategies using subtypes to determine or select types perform better than top down strategies.", "labels": [], "entities": []}, {"text": "This can be attributed to the fact that correction with relation/argument constraints in subtype is tighter than the ones in type.", "labels": [], "entities": []}, {"text": "Finally, we provide our findings from the fourth set of experiments which looks at the detailed contributions from four feature types.", "labels": [], "entities": []}, {"text": "Entity type features themselves do notwork.", "labels": [], "entities": []}, {"text": "We incrementally add the structures, the external contexts and internal contexts, Uni-grams and Bi-grams, and at last the word lists on them.", "labels": [], "entities": [{"text": "Bi-grams", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9812470078468323}]}, {"text": "The observations are: Uni-grams provide more discriminative information than Bi-grams; external context seems more useful than internal context; positional structure provides stronger support than other individual recognized features such as entity type and context; but word list feature cannot further boost the performance.", "labels": [], "entities": []}, {"text": "Evaluation of Feature and Their Combinations", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 Evaluation on Structure Features", "labels": [], "entities": []}, {"text": " Table 3 Imbalance Training Class Problem", "labels": [], "entities": [{"text": "Imbalance Training Class", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.9317382176717123}]}, {"text": " Table 4 Evaluation of Two Detection and Classification Modes", "labels": [], "entities": [{"text": "Detection and Classification", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.6893492937088013}]}, {"text": " Table 6 Comparison of Different Consistency Check Strategies", "labels": [], "entities": []}, {"text": " Table 6 Evaluation of Feature and Their Combinations", "labels": [], "entities": []}]}