{"title": [{"text": "Automatic Editing in a Back-End Speech-to-Text System", "labels": [], "entities": [{"text": "Automatic Editing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7367393672466278}]}], "abstractContent": [{"text": "Written documents created through dictation differ significantly from a true verbatim transcript of the recorded speech.", "labels": [], "entities": []}, {"text": "This poses an obstacle in automatic dictation systems as speech recognition output needs to undergo a fair amount of editing in order to turn it into a document that complies with the customary standards.", "labels": [], "entities": [{"text": "speech recognition output", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.7674314379692078}]}, {"text": "We present an approach that attempts to perform this edit from recognized words to final document automatically by learning the appropriate transformations from example documents.", "labels": [], "entities": []}, {"text": "This addresses a number of problems in an integrated way, which have so far been studied independently, in particular automatic punctuation, text seg-mentation, error correction and disfluency repair.", "labels": [], "entities": [{"text": "error correction", "start_pos": 161, "end_pos": 177, "type": "TASK", "confidence": 0.6517019271850586}, {"text": "disfluency repair", "start_pos": 182, "end_pos": 199, "type": "TASK", "confidence": 0.7532465159893036}]}, {"text": "We study two different learning methods, one based on rule induction and one based on a probabilistic sequence model.", "labels": [], "entities": []}, {"text": "Quantitative evaluation shows that the probabilistic method performs more accurately.", "labels": [], "entities": []}], "introductionContent": [{"text": "Large vocabulary speech recognition today achieves a level of accuracy that makes it useful in the production of written documents.", "labels": [], "entities": [{"text": "Large vocabulary speech recognition", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7244183123111725}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9983470439910889}]}, {"text": "Especially in the medical and legal domains large volumes of text are traditionally produced by means of dictation.", "labels": [], "entities": []}, {"text": "Here document creation is typically a \"back-end\" process.", "labels": [], "entities": [{"text": "document creation", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.7502686679363251}]}, {"text": "The author dictates all necessary information into a telephone handset or a portable recording device and is not concerned with the actual production of the document any further.", "labels": [], "entities": []}, {"text": "A transcriptionist will then listen to the recorded dictation and produce a wellformed document using a word processor.", "labels": [], "entities": []}, {"text": "The goal of introducing speech recognition in this process is to create a draft document automatically, so that the transcriptionist only has to verify the accuracy of the document and to fix occasional recognition errors.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7353083789348602}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9902713894844055}]}, {"text": "We observe that users try to spend as little time as possible dictating.", "labels": [], "entities": []}, {"text": "They usually focus only on the content and rely on the transcriptionist to compose a readable, syntactically correct, stylistically acceptable and formally compliant document.", "labels": [], "entities": []}, {"text": "For this reason there is a considerable discrepancy between the final document and what the speaker has said literally.", "labels": [], "entities": []}, {"text": "In particular in medical reports we see differences of the following kinds: \u2022 Punctuation marks are typically not verbalized.", "labels": [], "entities": []}, {"text": "\u2022 No instructions on the formatting of the report are dictated.", "labels": [], "entities": [{"text": "formatting of the report", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.8622395545244217}]}, {"text": "Section headings are not identified as such.", "labels": [], "entities": [{"text": "Section headings", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6086336076259613}]}, {"text": "\u2022 Frequently section headings are only implied.", "labels": [], "entities": [{"text": "section headings", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7076536566019058}]}, {"text": "(\"vitals are\" \u2192 \"PHYSICAL EXAMINATION: VITAL SIGNS:\") \u2022 Enumerated lists.", "labels": [], "entities": [{"text": "VITAL SIGNS", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.38210150599479675}]}, {"text": "Typically speakers use phrases like \"number one . .", "labels": [], "entities": []}, {"text": "\", which need to be turned into \"1.", "labels": [], "entities": []}, {"text": "\" \u2022 The dictation usually begins with a preamble (e.g. \"This is doctor Xyz ...\") which does not appear in the report.", "labels": [], "entities": []}, {"text": "Similarly there are typical phrases at the end of the dictation which should not be transcribed (e.g. \"End of dictation. Thank you.\")", "labels": [], "entities": [{"text": "End", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9404705762863159}]}, {"text": "\u2022 There are specific standards regarding the use of medical terminology.", "labels": [], "entities": []}, {"text": "Transcriptionists frequently expand dictated abbreviations (e.g. \"CVA\" \u2192 \"cerebrovascular accident\") or otherwise use equivalent terms (e.g. \"nonicteric sclerae\" \u2192 \"no scleral icterus\").", "labels": [], "entities": []}, {"text": "\u2022 The dictation typically has a more narrative style (e.g. \"She has no allergies.\", \"I examined him\").", "labels": [], "entities": []}, {"text": "In contrast, the report is normally more impersonal and structured (e.g. \"ALLERGIES: None.\", \"he was examined\").", "labels": [], "entities": [{"text": "ALLERGIES: None.", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.8031188646952311}]}, {"text": "\u2022 For the sake of brevity, speakers frequently omit function words.", "labels": [], "entities": []}, {"text": "(\"patient\" \u2192 \"the patient\", \"denies fever pain\" \u2192 \"he denies any fever or pain\") \u2022 As the dictation is spontaneous, disfluencies are quite frequent, in particular false starts, corrections and repetitions.", "labels": [], "entities": [{"text": "repetitions", "start_pos": 193, "end_pos": 204, "type": "METRIC", "confidence": 0.8298385739326477}]}, {"text": "(e.g. \"22-year-old female, sorry, male 22-year-old male\" \u2192 \"22-year-old male\") \u2022 Instruction to the transcriptionist and so-called normal reports, pre-defined text templates invoked by a short phrase like \"This is a normal chest x-ray.\"", "labels": [], "entities": []}, {"text": "\u2022 In addition to the above, speech recognition output has the usual share of recognition errors some of which may occur systematically.", "labels": [], "entities": [{"text": "speech recognition output", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8401557405789694}]}, {"text": "These phenomena pose a problem that goes beyond the speech recognition task which has traditionally focused on correctly identifying speech utterances.", "labels": [], "entities": [{"text": "speech recognition task", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7942695915699005}, {"text": "correctly identifying speech utterances", "start_pos": 111, "end_pos": 150, "type": "TASK", "confidence": 0.6149106025695801}]}, {"text": "Even with a perfectly accurate verbatim transcript of the user's utterances, the transcriptionist would need to perform a significant amount of editing to obtain a document conforming to the customary standards.", "labels": [], "entities": []}, {"text": "We need to look for what the user wants rather than what he says.", "labels": [], "entities": []}, {"text": "Natural language processing research has addressed a number of these issues as individual problems: automatic punctuation (), text segmentation () disfluency repair ( and error correction ().", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6533470352490743}, {"text": "text segmentation () disfluency repair", "start_pos": 126, "end_pos": 164, "type": "TASK", "confidence": 0.681587427854538}, {"text": "error correction", "start_pos": 171, "end_pos": 187, "type": "TASK", "confidence": 0.6966974139213562}]}, {"text": "The method we present in the following attempts to address all this by a unified transformation model.", "labels": [], "entities": []}, {"text": "The goal is simply stated as transforming the recognition output into a text document.", "labels": [], "entities": []}, {"text": "We will first describe the general framework of learning transformations from example documents.", "labels": [], "entities": []}, {"text": "In the following two sections we will discuss a ruleinduction-based and a probabilistic transformation method respectively.", "labels": [], "entities": []}, {"text": "Finally we present experimental results in the context of medical transcription and conclude with an assessment of both methods.", "labels": [], "entities": [{"text": "medical transcription", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7279261350631714}]}], "datasetContent": [{"text": "The methods presented were evaluated on a set of real-life medical reports dictated by 51 doctors.", "labels": [], "entities": []}, {"text": "For each doctor we use 30 reports as a test set.", "labels": [], "entities": []}, {"text": "Transformation models are trained on a disjoint set of reports that predated the evaluation reports.", "labels": [], "entities": []}, {"text": "The typical document length is between one hundred and one thousand words.", "labels": [], "entities": []}, {"text": "All dictations were recorded via telephone.", "labels": [], "entities": []}, {"text": "The speech recognizer works with acoustic models that are specifically adapted for each user, not using the test data, of course.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7089034616947174}]}, {"text": "It is hard to quote the verbatim word error rate of the recognizer, because this would require a careful and time-consuming manual transcription of the test set.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 33, "end_pos": 48, "type": "METRIC", "confidence": 0.6837322413921356}]}, {"text": "The recognition output is auto-punctuated by a method similar in spirit to the one proposed by before being passed to the transformation model.", "labels": [], "entities": []}, {"text": "This was done because we considered the auto-punctuation output as the status quo ante which transformation modeling was to be compared to.", "labels": [], "entities": []}, {"text": "Neither of both transformation methods actually relies on having auto-punctuated input.", "labels": [], "entities": []}, {"text": "The auto-punctuation step only inserts periods and commas and the document is not explicitly segmented into sentences.", "labels": [], "entities": []}, {"text": "(The transformation step always applies to entire documents and the interpretation of a period as a sentence boundary is left to the human reader of the document.)", "labels": [], "entities": []}, {"text": "For each doctor a background transformation model was constructed using 100 reports from each of the other users.", "labels": [], "entities": []}, {"text": "This is referred to as the speaker-independent (SI) model.", "labels": [], "entities": []}, {"text": "In the case of the probabilistic model, all models were 3-gram models.", "labels": [], "entities": []}, {"text": "User-specific models were created by augmenting the SI model with 25, 50 or 100 reports.", "labels": [], "entities": []}, {"text": "One report from the test set is shown as an example in the appendix.", "labels": [], "entities": []}, {"text": "The output of the text transformation is aligned with the corresponding tokenized report using a minimum edit cost criterion.", "labels": [], "entities": []}, {"text": "Alignments between section headings and non-section headings are not permitted.", "labels": [], "entities": [{"text": "Alignments between section headings", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7761032432317734}]}, {"text": "Likewise no alignment of punctuation and non-punctuation tokens is allowed.", "labels": [], "entities": []}, {"text": "Using the alignment we compute precision and recall for sections headings and punctuation marks as well as the overall token error rate.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9995170831680298}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9995704293251038}, {"text": "token error rate", "start_pos": 119, "end_pos": 135, "type": "METRIC", "confidence": 0.7539954781532288}]}, {"text": "It should be noted that the so derived error rate is not comparable to word error rates usually reported in speech recognition research.", "labels": [], "entities": [{"text": "error rate", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9014932513237}, {"text": "speech recognition", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.719411700963974}]}, {"text": "All missing or erroneous section headings, punctuation marks and line breaks are counted as errors.", "labels": [], "entities": []}, {"text": "As pointed out in the introduction the reference texts do not represent a literal transcript of the dictation.", "labels": [], "entities": []}, {"text": "Furthermore the data were not cleaned manually.", "labels": [], "entities": []}, {"text": "There are, for example, instances of letter heads or page numbers that were not correctly removed when the text was extracted from the word processor's file format.", "labels": [], "entities": []}, {"text": "The example report shown in the appendix features some of the typical differences between the produced draft and the final report that mayor may not be judged as errors.", "labels": [], "entities": []}, {"text": "(For example, the date of the report was not given in the dictation, the section names \"laboratory data\" and \"laboratory evaluation\" are presumably equivalent and whether \"stable\" is preceded by a hyphen or a period in the last section might not be important.)", "labels": [], "entities": []}, {"text": "Nevertheless, the numbers reported do permit a quantitative comparison between different methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental evaluation of different text transformation techniques with different amounts of user-specific  data. Precision, recall, deletion, insertion and error rate values are given in percent and represent the average of 51  users, where the results for each user are the ratios of sums over 30 reports.", "labels": [], "entities": [{"text": "text transformation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7568219602108002}, {"text": "Precision", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9976589679718018}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9937610030174255}, {"text": "insertion and error rate", "start_pos": 154, "end_pos": 178, "type": "METRIC", "confidence": 0.7934944927692413}]}]}