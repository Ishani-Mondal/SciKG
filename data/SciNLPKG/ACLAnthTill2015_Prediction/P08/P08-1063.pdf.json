{"title": [{"text": "Robustness and Generalization of Role Sets: PropBank vs. VerbNet", "labels": [], "entities": [{"text": "PropBank", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.913764476776123}, {"text": "VerbNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.7103880643844604}]}], "abstractContent": [{"text": "This paper presents an empirical study on the robustness and generalization of two alternative role sets for semantic role labeling: Prop-Bank numbered roles and VerbNet thematic roles.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.6275047163168589}]}, {"text": "By testing a state-of-the-art SRL system with the two alternative role annotations, we show that the PropBank role set is more robust to the lack of verb-specific semantic information and generalizes better to infrequent and unseen predicates.", "labels": [], "entities": [{"text": "PropBank role set", "start_pos": 101, "end_pos": 118, "type": "DATASET", "confidence": 0.8567158977190653}]}, {"text": "Keeping in mind that thematic roles are better for application needs, we also tested the best way to generate VerbNet annotation.", "labels": [], "entities": []}, {"text": "We conclude that tagging first PropBank roles and mapping into Verb-Net roles is as effective as training and tagging directly on VerbNet, and more robust for domain shifts.", "labels": [], "entities": [{"text": "tagging", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9670023322105408}]}], "introductionContent": [{"text": "Semantic Role Labeling is the problem of analyzing clause predicates in open text by identifying arguments and tagging them with semantic labels indicating the role they play with respect to the verb.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7733028332392374}]}, {"text": "Such sentence-level semantic analysis allows to determine \"who\" did \"what\" to \"whom\", \"when\" and \"where\", and, thus, characterize the participants and properties of the events established by the predicates.", "labels": [], "entities": []}, {"text": "This kind of semantic analysis is very interesting fora broad spectrum of NLP applications (information extraction, summarization, question answering, machine translation, etc.), since it opens the door to exploit the semantic relations among linguistic constituents.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.8773404657840729}, {"text": "information extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.8004328012466431}, {"text": "summarization", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.9645821452140808}, {"text": "question answering", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.7958614826202393}, {"text": "machine translation", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.7456506490707397}]}, {"text": "The properties of the semantically annotated corpora available have conditioned the type of research and systems that have been developed so far.", "labels": [], "entities": []}, {"text": "PropBank () is the most widely used corpus for training SRL systems, probably because it contains running text from the Penn Treebank corpus with annotations on all verbal predicates.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.914495050907135}, {"text": "SRL", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.8902391791343689}, {"text": "Penn Treebank corpus", "start_pos": 120, "end_pos": 140, "type": "DATASET", "confidence": 0.9922563831011454}]}, {"text": "Also, a few evaluation exercises on SRL have been conducted on this corpus in the conferences.", "labels": [], "entities": [{"text": "SRL", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9861369132995605}]}, {"text": "However, a serious criticisms to the PropBank corpus refers to the role set it uses, which consists of a set of numbered core arguments, whose semantic translation is verb-dependent.", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9457581639289856}]}, {"text": "While Arg0 and Arg1 are intended to indicate the general roles of Agent and Theme, other argument numbers do not generalize across verbs and do not correspond to general semantic roles.", "labels": [], "entities": [{"text": "Arg0", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9902234673500061}, {"text": "Arg1", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9689279198646545}]}, {"text": "This fact might compromise generalization and portability of SRL systems, especially when the training corpus is small.", "labels": [], "entities": [{"text": "SRL", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9717345237731934}]}, {"text": "More recently, a mapping from PropBank numbered arguments into VerbNet thematic roles has been developed and aversion of the PropBank corpus with thematic roles has been released . Thematic roles represent a compact set of verb-independent general roles widely used in linguistic theory (e.g., Agent, Theme, Patient, Recipient, Cause, etc.).", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 125, "end_pos": 140, "type": "DATASET", "confidence": 0.9492284655570984}]}, {"text": "We foresee two advantages of using such thematic roles.", "labels": [], "entities": []}, {"text": "On the one hand, statistical SRL systems trained from them could generalize better and, therefore, be more robust and portable, as suggested in ( ).", "labels": [], "entities": [{"text": "SRL", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.8009269833564758}]}, {"text": "On the other hand, roles in a paradigm like VerbNet would allow for inferences over the assigned roles, which is only possible in a more limited way with PropBank.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 154, "end_pos": 162, "type": "DATASET", "confidence": 0.9294261336326599}]}, {"text": "Ina previous paper (, we presented a first comparison between the two previous role sets on the SemEval-2007 Task 17 corpus.", "labels": [], "entities": [{"text": "SemEval-2007 Task 17 corpus", "start_pos": 96, "end_pos": 123, "type": "DATASET", "confidence": 0.6840332746505737}]}, {"text": "The SemEval-2007 corpus only comprised examples about 50 different verbs.", "labels": [], "entities": [{"text": "SemEval-2007 corpus", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.8043667078018188}]}, {"text": "The results of that paper were, thus, considered preliminary, as they could depend on the small amount of data (both in training data and number of verbs) or the specific set of verbs being used.", "labels": [], "entities": []}, {"text": "Now, we extend those experiments to the entire PropBank corpus, and we include two extra experiments on domain shifts (using the Brown corpus as test set) and on grouping VerbNet labels.", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.9734211266040802}, {"text": "Brown corpus", "start_pos": 129, "end_pos": 141, "type": "DATASET", "confidence": 0.7815535366535187}]}, {"text": "More concretely, this paper explores two aspects of the problem.", "labels": [], "entities": []}, {"text": "First, having in mind the claim that general thematic roles should be more robust to changing domains and unseen predicates, we study the performance of a state-of-the-art SRL system trained on either codification of roles and some specific settings, i.e. including/excluding verb-specific information, labeling unseen verb predicates, or domain shifts.", "labels": [], "entities": [{"text": "SRL", "start_pos": 172, "end_pos": 175, "type": "TASK", "confidence": 0.972599983215332}]}, {"text": "Second, assuming that application scenarios would prefer dealing with general thematic role labels, we explore the best way to label a text with thematic roles, namely, by training directly on VerbNet roles or by using the PropBank SRL system and perform a posterior mapping into thematic roles.", "labels": [], "entities": [{"text": "PropBank SRL system", "start_pos": 223, "end_pos": 242, "type": "DATASET", "confidence": 0.9085559844970703}]}, {"text": "The results confirm our preliminary findings.", "labels": [], "entities": []}, {"text": "We observe that the PropBank roles are more robust in all tested experimental conditions, i.e., the performance decrease is more severe for VerbNet.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.9053160548210144}]}, {"text": "Besides, tagging first PropBank roles and then mapping into VerbNet roles is as effective as training and tagging directly on VerbNet, and more robust for domain shifts.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 contains some background on PropBank and VerbNet role sets.", "labels": [], "entities": []}, {"text": "Section 3 presents the experimental setting and the base SRL system used for the role set comparisons.", "labels": [], "entities": [{"text": "role set comparisons", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7388500571250916}]}, {"text": "In Section 4 the main comparative experiments on robustness are described.", "labels": [], "entities": []}, {"text": "Section 5 is devoted to analyze the posterior mapping of PropBank outputs into VerbNet thematic roles, and includes results on domain-shift experiments using Brown as test set.", "labels": [], "entities": []}, {"text": "Finally, Sections 6 and 7 contain a discussion of the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data used in this work is the benchmark corpus provided by the SRL shared task of).", "labels": [], "entities": [{"text": "SRL shared task", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.6640067100524902}]}, {"text": "The dataset, of over 1 million tokens, comprises PropBank sections 02-21 for training, and sections 24 and 23 for development and test, respectively.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8838791251182556}]}, {"text": "From the input information, we used part of speech tags and full parse trees (generated using Charniak's parser) and discarded named entities.", "labels": [], "entities": []}, {"text": "Also, we used the publicly available SemLink mapping from PropBank into VerbNet roles  to generate a replicate of the CoNLL-2005 corpus containing also the VerbNet annotation of roles.", "labels": [], "entities": [{"text": "CoNLL-2005 corpus", "start_pos": 118, "end_pos": 135, "type": "DATASET", "confidence": 0.9368875324726105}]}, {"text": "Unfortunately, SemLink version 1.0 does not coverall propositions and arguments in the PropBank corpus.", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.9443829357624054}]}, {"text": "In order to have an homogeneous corpus and not to bias experimental evaluation, we decided to discard all incomplete examples and keep only those propositions that were 100% mapped into VerbNet roles.", "labels": [], "entities": []}, {"text": "The resulting corpus contains 56% of the original propositions, that is, over 50,000 propositions in the training set.", "labels": [], "entities": []}, {"text": "This subcorpus is much larger than the SemEval-2007 Task 17 dataset used 1 http://verbs.colorado.edu/semlink/ in our previous experimental work (.", "labels": [], "entities": [{"text": "SemEval-2007 Task 17 dataset", "start_pos": 39, "end_pos": 67, "type": "DATASET", "confidence": 0.6078325733542442}]}, {"text": "The difference is especially noticeable in the diversity of predicates represented.", "labels": [], "entities": []}, {"text": "In this case, there are 1,709 different verbs (1,505 lemmas) compared to the 50 verbs of the SemEval corpus.", "labels": [], "entities": [{"text": "SemEval corpus", "start_pos": 93, "end_pos": 107, "type": "DATASET", "confidence": 0.8180494010448456}]}, {"text": "We believe that the size and richness of this corpus is enough to test and extract reliable conclusions on the robustness and generalization across verbs of the role sets understudy.", "labels": [], "entities": []}, {"text": "In order to study the behavior of both role sets in out-of-domain data, we made use of the PropBanked Brown corpus for testing, as it is also mapped into VerbNet thematic roles in the SemLink resource.", "labels": [], "entities": [{"text": "PropBanked Brown corpus", "start_pos": 91, "end_pos": 114, "type": "DATASET", "confidence": 0.964280386765798}, {"text": "SemLink resource", "start_pos": 184, "end_pos": 200, "type": "DATASET", "confidence": 0.8224354386329651}]}, {"text": "Again, we discarded those propositions that were not entirely mapped into thematic roles (45%).", "labels": [], "entities": []}, {"text": "VerbNet roles are more numerous than PropBank roles, and that, in itself, could cause a drop in performance.", "labels": [], "entities": []}, {"text": "Motivated by the results in ( , we grouped the 23 VerbNet roles in 7 coarser role groups.", "labels": [], "entities": []}, {"text": "Note that their groupings are focused on the roles which map to PropBank Arg2.", "labels": [], "entities": [{"text": "PropBank Arg2", "start_pos": 64, "end_pos": 77, "type": "DATASET", "confidence": 0.9180876612663269}]}, {"text": "In our case we are interested in a more general grouping which covers all VerbNet roles, so we added two additional groups (Agent-Experiencer and ThemeTopic-Patient).", "labels": [], "entities": []}, {"text": "We re-tagged the roles in the datasets with those groups, and then trained and tested our SRL system on those grouped labels.", "labels": [], "entities": [{"text": "SRL", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9205975532531738}]}, {"text": "The results are shown in the first row of.", "labels": [], "entities": []}, {"text": "In order to judge if our groupings are easier to learn, we can see that he performance gain with respect to the ungrouped roles (fourth row of) is small (76.99 vs. 78.11) but significant.", "labels": [], "entities": []}, {"text": "But if we compare them to the results of the PropBank to VerbNet mapping, where we simply substitute the fine-grained roles by their corresponding groups, we see that they still lag behind (second row in).", "labels": [], "entities": [{"text": "PropBank to VerbNet mapping", "start_pos": 45, "end_pos": 72, "type": "DATASET", "confidence": 0.8328877985477448}]}, {"text": "Although one could argue that better motivated groupings could be proposed, these results indicate that the larger number of VerbNet roles does not explain in itself the performance difference when compared to PropBank.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 210, "end_pos": 218, "type": "DATASET", "confidence": 0.9443032145500183}]}], "tableCaptions": [{"text": " Table 1: Basic results using PropBank (top) and VerbNet (bottom) role sets on different settings.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.9116221070289612}, {"text": "VerbNet", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.8822042942047119}]}, {"text": " Table 2: Detailed results on the CoNLL setting. Refer- ence arguments and verbs have been omitted for brevity,  as well as those with less than 10 occ. The last two  columns refer to the results on the CoNLL setting with  no verb features.", "labels": [], "entities": [{"text": "CoNLL setting", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9274633824825287}, {"text": "CoNLL setting", "start_pos": 203, "end_pos": 216, "type": "DATASET", "confidence": 0.9388299584388733}]}, {"text": " Table 3: F 1 results split according to the frequency of the  verb in the training data.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.97428098320961}]}, {"text": " Table 4: Verbs used in the unseen verb experiment", "labels": [], "entities": []}, {"text": " Table 5: Results on VerbNet roles using two different  strategies. Topmost 4 rows for the usual test set (WSJ),  and the 2 rows below for the Brown test set.", "labels": [], "entities": [{"text": "Brown test set", "start_pos": 143, "end_pos": 157, "type": "DATASET", "confidence": 0.7236111362775167}]}, {"text": " Table 6: Results for VerbNet grouping experiments.", "labels": [], "entities": [{"text": "VerbNet grouping", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7347453534603119}]}]}