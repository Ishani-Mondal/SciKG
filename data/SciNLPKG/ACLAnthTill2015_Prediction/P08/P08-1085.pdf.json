{"title": [{"text": "EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start) *", "labels": [], "entities": []}], "abstractContent": [{"text": "We address the task of unsupervised POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.8306764364242554}]}, {"text": "We demonstrate that good results can be obtained using the robust EM-HMM learner when provided with good initial conditions, even with incomplete dictionaries.", "labels": [], "entities": []}, {"text": "We present a family of algorithms to compute effective initial estimations p(t|w).", "labels": [], "entities": []}, {"text": "We test the method on the task of full morphological disambigua-tion in Hebrew achieving an error reduction of 25% over a strong uniform distribution base-line.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 92, "end_pos": 107, "type": "METRIC", "confidence": 0.972933292388916}]}, {"text": "We also test the same method on the standard WSJ unsupervised POS tagging task and obtain results competitive with recent state-of-the-art methods, while using simple and efficient learning methods.", "labels": [], "entities": [{"text": "WSJ unsupervised POS tagging task", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.7642027020454407}]}], "introductionContent": [{"text": "The task of unsupervised (or semi-supervised) partof-speech (POS) tagging is the following: given a dictionary mapping words in a language to their possible POS, and large quantities of unlabeled text data, learn to predict the correct part of speech fora given word in context.", "labels": [], "entities": [{"text": "partof-speech (POS) tagging", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6235614359378815}]}, {"text": "The only supervision given to the learning process is the dictionary, which in a realistic scenario, contains only part of the word types observed in the corpus to be tagged.", "labels": [], "entities": []}, {"text": "Unsupervised POS tagging has been traditionally approached with relative success by HMM-based generative models, employing EM parameters estimation using the Baum-Welch algorithm.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.8385242819786072}, {"text": "EM parameters estimation", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.6520025034745535}]}, {"text": "However, as recently noted * This work is supported in part by the Lynn and William Frankel Center for Computer Science. by, these works made use of filtered dictionaries: dictionaries in which only relatively probable analyses of a given word are preserved.", "labels": [], "entities": []}, {"text": "This kind of filtering requires serious supervision: in theory, an expert is needed to go over the dictionary elements and filter out unlikely analyses.", "labels": [], "entities": []}, {"text": "In practice, counts from an annotated corpus have been traditionally used to perform the filtering.", "labels": [], "entities": []}, {"text": "Furthermore, these methods require rather comprehensive dictionaries in order to perform well.", "labels": [], "entities": []}, {"text": "In recent work, researchers try to address these deficiencies by using dictionaries with unfiltered POS-tags, and testing the methods on \"diluted dictionaries\" -in which many of the lexical entries are missing) (SE),) (GG),) (TJ).", "labels": [], "entities": []}, {"text": "All the work mentioned above focuses on unsupervised English POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.7083554565906525}]}, {"text": "The dictionaries are all derived from tagged English corpora (all recent work uses the WSJ corpus).", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 87, "end_pos": 97, "type": "DATASET", "confidence": 0.9835465550422668}]}, {"text": "As such, the setting of the research is artificial: there is no reason to perform unsupervised learning when an annotated corpus is available.", "labels": [], "entities": []}, {"text": "The problem is rather approached as a workbench for exploring new learning methods.", "labels": [], "entities": []}, {"text": "The result is a series of creative algorithms, that have steadily improved results on the same dataset: unsupervised CRF training using contrastive estimation (SE), a fully-bayesian HMM model that jointly performs clustering and sequence learning (GG), and a Bayesian LDA-based model using only observed context features to predict tag words (TJ).", "labels": [], "entities": [{"text": "clustering and sequence learning (GG)", "start_pos": 214, "end_pos": 251, "type": "TASK", "confidence": 0.6620283935751233}]}, {"text": "These sophisticated learning algorithms all outperform the traditional baseline of EM-HMM based methods, while relying on similar knowledge: the lexical context of the words to be tagged and their letter structure (e.g., presence of suffixes, capitalization and hyphenation).", "labels": [], "entities": []}, {"text": "Our motivation for tackling unsupervised POS tagging is different: we are interested in developing a Hebrew POS tagger.", "labels": [], "entities": [{"text": "tackling unsupervised POS tagging", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.8517651259899139}, {"text": "POS tagger", "start_pos": 108, "end_pos": 118, "type": "TASK", "confidence": 0.5927837193012238}]}, {"text": "We have access to a good Hebrew lexicon (and a morphological analyzer), and a fair amount of unlabeled training data, but hardly any annotated corpora.", "labels": [], "entities": []}, {"text": "We actually report results on full morphological disambiguation for Hebrew, a task similar but more challenging than POS tagging: we deal with a tagset much larger than English (over 3,561 distinct tags) and an ambiguity level of about 2.7 per token as opposed to 1.4 for English.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.7333419024944305}]}, {"text": "Instead of inventing anew learning framework, we go back to the traditional EM trained HMMs.", "labels": [], "entities": []}, {"text": "We argue that the key challenge to learning an effective model is to define good enough initial conditions.", "labels": [], "entities": []}, {"text": "Given sufficiently good initial conditions, EM trained models can yield highly competitive results.", "labels": [], "entities": []}, {"text": "Such models have other benefits as well: they are simple, robust, and computationally more attractive.", "labels": [], "entities": []}, {"text": "In this paper, we concentrate on methods for deriving sufficiently good initial conditions for EM-HMM learning.", "labels": [], "entities": [{"text": "EM-HMM learning", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.7803985774517059}]}, {"text": "Our method for learning initial conditions for the p(t|w) distributions relies on a mixture of language specific models: a paradigmatic model of similar words (where similar words are words with similar inflection patterns), simple syntagmatic constraints (e.g., the sequence V-V is extremely rare in English).", "labels": [], "entities": []}, {"text": "These are complemented by a linear lexical context model.", "labels": [], "entities": []}, {"text": "Such models are simple to build and test.", "labels": [], "entities": []}, {"text": "We present results for unsupervised PoS tagging of Hebrew text and for the common WSJ English test sets.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.7519167959690094}, {"text": "WSJ English test sets", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.9209669679403305}]}, {"text": "We show that our method achieves state-ofthe-art results for the English setting, even with a relatively small dictionary.", "labels": [], "entities": []}, {"text": "Furthermore, while recent work report results on a reduced English tagset of 17 PoS tags, we also present results for the complete 45 tags tagset of the WSJ corpus.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 153, "end_pos": 163, "type": "DATASET", "confidence": 0.9749687016010284}]}, {"text": "This considerably raises the bar of the EM-HMM baseline.", "labels": [], "entities": []}, {"text": "We also report state-of-the-art results for Hebrew full mor-phological disambiguation.", "labels": [], "entities": [{"text": "Hebrew full mor-phological disambiguation", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.6011546701192856}]}, {"text": "Our primary conclusion is that the problem of learning effective stochastic classifiers remains primarily a search task.", "labels": [], "entities": []}, {"text": "Initial conditions play a dominant role in solving this task and can rely on linguistically motivated approximations.", "labels": [], "entities": []}, {"text": "A robust learning method (EM-HMM) combined with good initial conditions based on a robust feature set can go along way (as opposed to a more complex learning method).", "labels": [], "entities": []}, {"text": "It seems that computing initial conditions is also the right place to capture complex linguistic intuition without fear that over-generalization could lead a learner to diverge.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run a series of experiments with 8 distinct initial conditions, as shown in: our baseline (Uniform) is the uniform distribution overall tags provided by the KC analyzer for each word.", "labels": [], "entities": []}, {"text": "The Syntagmatic initial conditions add the p(t|t \u22121 , t +1 ) constraints described above to the uniform baseline.", "labels": [], "entities": []}, {"text": "The Morphology-Based and Linear-Context initial conditions are computed as described above, while the Morph+Linear is the result of applying the linear-context algorithm over initial values computed by the Morphology-based method.", "labels": [], "entities": []}, {"text": "We repeat  these last 3 models with the addition of the syntagmatic constraints (Synt+Morph).", "labels": [], "entities": []}, {"text": "For each of these, we first compare the computed p(t|w) against a gold standard distribution, taken from the test corpus (90K tokens), according to the measure used by) (Dist).", "labels": [], "entities": [{"text": "Dist", "start_pos": 170, "end_pos": 174, "type": "METRIC", "confidence": 0.9535222053527832}]}, {"text": "On this measure, we confirm that our improved morpholexical approximation improves the results reported by Levinger et al. from 74% to about 80% on a richer tagset, and on a much larger test set (90K vs. 3,400 tokens).", "labels": [], "entities": []}, {"text": "We then report on the effectiveness of p(t|w) as a context-free tagger that assigns to each word the most likely tag, both for full morphological analysis (3,561 tags) (Full) and for the simpler task of token segmentation and POS tag selection (36 tags) (Seg+Pos).", "labels": [], "entities": [{"text": "token segmentation", "start_pos": 203, "end_pos": 221, "type": "TASK", "confidence": 0.8449623584747314}, {"text": "POS tag selection", "start_pos": 226, "end_pos": 243, "type": "TASK", "confidence": 0.734398603439331}]}, {"text": "The best results on this task are 80.8% and 87.5% resp.", "labels": [], "entities": [{"text": "resp", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9974762797355652}]}, {"text": "achieved on the Morph+Linear initial conditions.", "labels": [], "entities": []}, {"text": "Finally, we test effectiveness of the initial conditions with EM-HMM learning.", "labels": [], "entities": []}, {"text": "We reach 88% accuracy on full morphological and 92% accuracy for POS tagging and word segmentation, for the Morph+Linear initial conditions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9995445609092712}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9994310736656189}, {"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.8124518096446991}, {"text": "word segmentation", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.763364851474762}]}, {"text": "As expected, EM-HMM improves results (from 80% to 88%).", "labels": [], "entities": []}, {"text": "Strikingly, EM-HMM improves the uniform initial conditions from 64% to above 85%.", "labels": [], "entities": [{"text": "uniform", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9620713591575623}]}, {"text": "However, better initial conditions bring us much over this particular local maximum -with an error reduction of 20%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 93, "end_pos": 108, "type": "METRIC", "confidence": 0.9744258224964142}]}, {"text": "In all cases, the main improvement over the uniform baseline is brought by the morphology-based initial conditions.", "labels": [], "entities": []}, {"text": "When applied on its own, the linear context brings modest improvement.", "labels": [], "entities": []}, {"text": "But the combination of the paradigmatic morphology-based method with the linear context improves all measures.", "labels": [], "entities": []}, {"text": "A most interesting observation is the detrimental contribution of the syntagmatic constraints we introduced.", "labels": [], "entities": []}, {"text": "We found that 113,453 sentences of the corpus (about 5%) contradict these basic and apparently simple constraints.", "labels": [], "entities": []}, {"text": "As an alternative to these common-sense constraints, we tried to use a small seed of randomly selected sentences (10K annotated tokens) in order to skew the initial uniform distribution of the state transitions.", "labels": [], "entities": []}, {"text": "We initialize the p(t|t \u22121 , t +1 ) distribution with smoothed ML estimates based on tag trigram and bigram counts (ignoring the tag-word annotations).", "labels": [], "entities": []}, {"text": "This small seed initialization (InitTrans) has a great impact on accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9933432340621948}]}, {"text": "Overall, we reach 89.4% accuracy on full morphological and 92.4% accuracy for POS tagging and word segmentation, for the Morph+Linear conditions -an error reduction of more than 25% from the uniform distribution baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9994283318519592}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9994310736656189}, {"text": "POS tagging", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.8283972442150116}, {"text": "word segmentation", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7551337480545044}]}], "tableCaptions": [{"text": " Table 1: Accuracy (%) of Hebrew Morphological  Disambiguation and POS Tagging over various initial  conditions", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987711310386658}, {"text": "Hebrew Morphological  Disambiguation", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.7036627233028412}, {"text": "POS Tagging", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.7498472929000854}]}, {"text": " Table 2: Accuracy (%) of English POS Tagging over various initial conditions", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985365867614746}, {"text": "POS Tagging", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.6750193536281586}]}, {"text": " Table 3: Comparison of English Unsupervised POS Tagging Methods", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.6443545371294022}]}]}