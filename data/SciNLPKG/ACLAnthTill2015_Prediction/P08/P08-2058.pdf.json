{"title": [{"text": "Speakers' Intention Prediction Using Statistics of Multi-level Features in a Schedule Management Domain", "labels": [], "entities": [{"text": "Speakers' Intention Prediction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7526321013768514}]}], "abstractContent": [{"text": "Speaker's intention prediction modules can be widely used as a pre-processor for reducing the search space of an automatic speech re-cognizer.", "labels": [], "entities": [{"text": "Speaker's intention prediction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5997530743479729}]}, {"text": "They also can be used as a pre-processor for generating a proper sentence in a dialogue system.", "labels": [], "entities": []}, {"text": "We propose a statistical model to predict speakers' intentions by using multi-level features.", "labels": [], "entities": []}, {"text": "Using the multi-level features (morpheme-level features, discourse-level features, and domain knowledge-level features), the proposed model predicts speak-ers' intentions that maybe implicated in next utterances.", "labels": [], "entities": []}, {"text": "In the experiments, the proposed model showed better performances (about 29% higher accuracies) than the previous model.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9817427396774292}]}, {"text": "Based on the experiments, we found that the proposed multi-level features are very effective in speaker's intention prediction.", "labels": [], "entities": [{"text": "speaker's intention prediction", "start_pos": 96, "end_pos": 126, "type": "TASK", "confidence": 0.6290578246116638}]}], "introductionContent": [{"text": "A dialogue system is a program in which a user and system communicate in natural language.", "labels": [], "entities": []}, {"text": "To understand user's utterance, the dialogue system should identify his/her intention.", "labels": [], "entities": []}, {"text": "To respond his/her question, the dialogue system should generate the counterpart of his/her intention by referring to dialogue history and domain knowledge.", "labels": [], "entities": []}, {"text": "Most previous researches on speakers' intentions have been focused on intention identification techniques.", "labels": [], "entities": [{"text": "intention identification", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.7301058769226074}]}, {"text": "On the contrary, intention prediction techniques have been not studied enough although there are many practical needs, as shown in.", "labels": [], "entities": [{"text": "intention prediction", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.8403917253017426}]}, {"text": "When is the changed date?", "labels": [], "entities": []}, {"text": "Response, Timetable-update-date Ask-ref, Timetable-update-date, the first example shows that an intention prediction module can be used as a preprocessor for reducing the search space of an ASR (automatic speech recognizer).", "labels": [], "entities": [{"text": "ASR (automatic speech recognizer", "start_pos": 190, "end_pos": 222, "type": "TASK", "confidence": 0.5998204469680786}]}, {"text": "The second example shows that an intention prediction module can be used as a pre-processor for generating a proper sentence based on dialogue history.", "labels": [], "entities": [{"text": "intention prediction", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.6960937529802322}]}, {"text": "There are some researches on user's intention prediction.", "labels": [], "entities": [{"text": "user's intention prediction", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.5808149799704552}]}, {"text": "Reithinger's model used n-grams of speech acts as input features.", "labels": [], "entities": []}, {"text": "Reithinger showed that his model can reduce the searching complexity of an ASR to 19~60%.", "labels": [], "entities": [{"text": "ASR", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9713464379310608}]}, {"text": "However, his model did not achieve good performances because the input features were not rich enough to predict next speech acts.", "labels": [], "entities": []}, {"text": "The researches on system's intention prediction have been treated as apart of researches on dialogue models such as a finite-state model, a frame-based model, and a plan-based model.", "labels": [], "entities": [{"text": "system's intention prediction", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.6038720235228539}]}, {"text": "However, a finite-state model has a weak point that dialogue flows should be predefined.", "labels": [], "entities": []}, {"text": "Although a plan-based model can manage complex dialogue phenomena using plan inference, a plan-based model is not easy to be applied to the real world applications because it is difficult to maintain plan recipes.", "labels": [], "entities": []}, {"text": "In this paper, we propose a statistical model to reliably predict both user's intention and system's intention in a schedule management domain.", "labels": [], "entities": []}, {"text": "The proposed model determines speakers' intentions by using various levels of linguistic features such as clue words, previous intentions, and a current state of a domain frame.", "labels": [], "entities": []}, {"text": "2 Statistical prediction of speakers' intentions", "labels": [], "entities": [{"text": "prediction of speakers' intentions", "start_pos": 14, "end_pos": 48, "type": "TASK", "confidence": 0.6742423251271248}]}], "datasetContent": [{"text": "We collected a Korean dialogue corpus simulated in a schedule management domain such as appointment scheduling and alarm setting.", "labels": [], "entities": [{"text": "appointment scheduling", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.6770287603139877}]}, {"text": "The dialogue corpus consists of 956 dialogues, 21,336 utterances (22.3 utterances per dialogue).", "labels": [], "entities": []}, {"text": "Each utterance in dialogues was manually annotated with speech acts and concept sequences.", "labels": [], "entities": []}, {"text": "The manual tagging of speech acts and concept sequences was done by five graduate students with the knowledge of a dialogue analysis and post-processed by a student in a doctoral course for consistency.", "labels": [], "entities": [{"text": "tagging of speech acts and concept sequences", "start_pos": 11, "end_pos": 55, "type": "TASK", "confidence": 0.7625533512660435}]}, {"text": "To experiment the proposed model, we divided the annotated messages into the training corpus and the testing corpus by a ratio of four (764 dialogues) to one (192 dialogues).", "labels": [], "entities": []}, {"text": "Then, we performed 5-fold cross validation.", "labels": [], "entities": []}, {"text": "We used training factors of CRFs as L-BGFS and Gaussian Prior. and show the accuracies of the proposed model in speech act prediction and concept sequence prediction, respectively.", "labels": [], "entities": [{"text": "speech act prediction", "start_pos": 112, "end_pos": 133, "type": "TASK", "confidence": 0.731500506401062}, {"text": "concept sequence prediction", "start_pos": 138, "end_pos": 165, "type": "TASK", "confidence": 0.6052174866199493}]}, {"text": "In, Accuracy-S means the accuracy of system's intention prediction, and Accuracy-U means the accuracy of user's intention prediction.", "labels": [], "entities": [{"text": "Accuracy-S", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9988436698913574}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9989302754402161}, {"text": "Accuracy-U", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9976759552955627}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.998377799987793}]}, {"text": "Based on these experimental results, we found that multi-level features include different types of information and cooperation of the multilevel features brings synergy effect.", "labels": [], "entities": []}, {"text": "We also found the degree of feature importance in intention prediction (i.e. discourse level features > morphemelevel features > domain knowledge-level features).", "labels": [], "entities": [{"text": "intention prediction", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7314680516719818}]}, {"text": "To evaluate the proposed model, we compare the accuracies of the proposed model with those of Reithinger's model by using the same training and test corpus, as shown in.", "labels": [], "entities": []}, {"text": "As shown in, the proposed model outperformed Reithinger's model in all kinds of predictions.", "labels": [], "entities": []}, {"text": "We think that the differences between accuracies were mainly caused by input features: The proposed model showed similar accuracies to Reithinger's model when it used only domain knowledge-level features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. The accuracies of speech act prediction", "labels": [], "entities": [{"text": "accuracies", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9535775184631348}, {"text": "speech act prediction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.5810033679008484}]}, {"text": " Table 4. The accuracies of concept sequence pre- diction", "labels": [], "entities": []}, {"text": " Table 5. The comparison of accuracies", "labels": [], "entities": [{"text": "accuracies", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9834218621253967}]}]}