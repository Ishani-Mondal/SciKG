{"title": [{"text": "Combining Speech Retrieval Results with Generalized Additive Models", "labels": [], "entities": [{"text": "Combining Speech Retrieval", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6514361401398977}]}], "abstractContent": [{"text": "Rapid and inexpensive techniques for automatic transcription of speech have the potential to dramatically expand the types of content to which information retrieval techniques can be productively applied, but limitations inaccuracy and robustness must be overcome before that promise can be fully realized.", "labels": [], "entities": [{"text": "automatic transcription of speech", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7674670070409775}]}, {"text": "Combining retrieval results from systems built on various errorful representations of the same collection offers some potential to address these challenges.", "labels": [], "entities": []}, {"text": "This paper explores that potential by applying Generalized Additive Models to optimize the combination of ranked retrieval results obtained using transcripts produced automatically for the same spoken content by substantially different recognition systems.", "labels": [], "entities": []}, {"text": "Topic-averaged retrieval effectiveness better than any previously reported for the same collection was obtained, and even larger gains are apparent when using an alternative measure emphasizing results on the most difficult topics.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speech retrieval, like other tasks that require transforming the representation of language, suffers from both random and systematic errors that are introduced by the speech-to-text transducer.", "labels": [], "entities": [{"text": "Speech retrieval", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7700456380844116}]}, {"text": "Limitations in signal processing, acoustic modeling, pronunciation, vocabulary, and language modeling can be accommodated in several ways, each of which make different trade-offs and thus induce different * Dept. of Mathematics/AMSC, UMD \u2020 College of Information Studies, UMD error characteristics.", "labels": [], "entities": [{"text": "acoustic modeling", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7492720782756805}, {"text": "language modeling", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.730358436703682}, {"text": "UMD \u2020 College of Information Studies", "start_pos": 234, "end_pos": 270, "type": "DATASET", "confidence": 0.9034302035967509}]}, {"text": "Moreover, different applications produce different types of challenges and different opportunities.", "labels": [], "entities": []}, {"text": "As a result, optimizing a single recognition system for all transcription tasks is well beyond the reach of present technology, and even systems that are apparently similar on average can make different mistakes on different sources.", "labels": [], "entities": []}, {"text": "A natural response to this challenge is to combine retrieval results from multiple systems, each imperfect, to achieve reasonably robust behavior over a broader range of tasks.", "labels": [], "entities": []}, {"text": "In this paper, we compare alternative ways of combining these ranked lists.", "labels": [], "entities": []}, {"text": "Note, we do not assume access to the internal workings of the recognition systems, or even to the transcripts produced by those systems.", "labels": [], "entities": []}, {"text": "System combination has along history in information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.8031422197818756}]}, {"text": "Most often, the goal is to combine results from systems that search different content (\"collection fusion\") or to combine results from different systems on the same content (\"data fusion\").", "labels": [], "entities": []}, {"text": "When working with multiple transcriptions of the same content, we are again presented with new opportunities.", "labels": [], "entities": []}, {"text": "In this paper we compare some well known techniques for combination of retrieval results with anew evidence combination technique based on a general framework known as Generalized Additive Models (GAMs).", "labels": [], "entities": []}, {"text": "We show that this new technique significantly outperforms several well known information retrieval fusion techniques, and we present evidence that it is the ability of GAMs to combine inputs non-linearly that at least partly explains our improvements.", "labels": [], "entities": [{"text": "information retrieval fusion", "start_pos": 77, "end_pos": 105, "type": "TASK", "confidence": 0.8208620746930441}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first review prior work on evidence com-bination in information retrieval in Section 2, and then introduce Generalized Additive Models in Section 3.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.8075851798057556}]}, {"text": "Section 4 describes the design of our experiments with a 589 hour collection of conversational speech for which information retrieval queries and relevance judgments are available.", "labels": [], "entities": []}, {"text": "Section 5 presents the results of our experiments, and we conclude in Section 6 with a brief discussion of implications of our results and the potential for future work on this important problem.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset is a collection of 272 oral history interviews from the MALACH collection.", "labels": [], "entities": [{"text": "MALACH collection", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.9333849251270294}]}, {"text": "The task is to retrieve short speech segments which were manually designated as being topically coherent by professional indexers.", "labels": [], "entities": []}, {"text": "There are 8,104 such segments (corresponding to roughly 589 hours of conversational speech) and 96 assessed topics.", "labels": [], "entities": []}, {"text": "We follow the topic partition used for the 2007 evaluation by the Cross Language Evaluation Forum's cross-language speech retrieval track (.", "labels": [], "entities": [{"text": "cross-language speech retrieval", "start_pos": 100, "end_pos": 131, "type": "TASK", "confidence": 0.5953847169876099}]}, {"text": "This gives us 63 topics on which to train our combination systems and 33 topics for evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: MAP and GMAP for each combination ap- proach, using the evaluation query set from the CLEF- 2007 CL-SR (MALACH) collection. Shown in paren- theses is the relative improvement in score over the best  single transcripts results (i.e., using our new set of tran- scripts). The best (mean) score for each condition is in  bold.", "labels": [], "entities": [{"text": "CLEF- 2007 CL-SR (MALACH) collection", "start_pos": 96, "end_pos": 132, "type": "DATASET", "confidence": 0.9068460464477539}]}]}