{"title": [{"text": "Applying Morphology Generation Models to Machine Translation", "labels": [], "entities": [{"text": "Applying", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7721555233001709}, {"text": "Machine Translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7423055171966553}]}], "abstractContent": [{"text": "We improve the quality of statistical machine translation (SMT) by applying models that predict word forms from their stems using extensive morphological and syntactic information from both the source and target languages.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.7871376872062683}]}, {"text": "Our inflection generation models are trained independently of the SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9847453236579895}]}, {"text": "We investigate different ways of combining the inflection prediction component with the SMT system by training the base MT system on fully inflected forms or on word stems.", "labels": [], "entities": [{"text": "inflection prediction", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7635801136493683}, {"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9883509874343872}, {"text": "MT", "start_pos": 120, "end_pos": 122, "type": "TASK", "confidence": 0.944750189781189}]}, {"text": "We applied our inflection generation models in translating English into two morphologically complex languages, Russian and Arabic, and show that our model improves the quality of SMT over both phrasal and syntax-based SMT systems according to BLEU and human judgements .", "labels": [], "entities": [{"text": "SMT", "start_pos": 179, "end_pos": 182, "type": "TASK", "confidence": 0.9919427633285522}, {"text": "SMT", "start_pos": 218, "end_pos": 221, "type": "TASK", "confidence": 0.8887895345687866}, {"text": "BLEU", "start_pos": 243, "end_pos": 247, "type": "METRIC", "confidence": 0.9958307147026062}]}], "introductionContent": [{"text": "One of the outstanding problems for further improving machine translation (MT) systems is the difficulty of dividing the MT problem into sub-problems and tackling each sub-problem in isolation to improve the overall quality of MT.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.8529856085777283}, {"text": "MT problem", "start_pos": 121, "end_pos": 131, "type": "TASK", "confidence": 0.8906227648258209}, {"text": "MT", "start_pos": 227, "end_pos": 229, "type": "TASK", "confidence": 0.9739137291908264}]}, {"text": "Evidence for this difficulty is the fact that there has been very little work investigating the use of such independent subcomponents, though we started to see some successful cases in the literature, for example in word alignment, target language capitalization () and case marker generation ( . This paper describes a successful attempt to integrate a subcomponent for generating word inflections into a statistical machine translation (SMT) system.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 216, "end_pos": 230, "type": "TASK", "confidence": 0.8225756287574768}, {"text": "case marker generation", "start_pos": 270, "end_pos": 292, "type": "TASK", "confidence": 0.7302899062633514}, {"text": "statistical machine translation (SMT)", "start_pos": 406, "end_pos": 443, "type": "TASK", "confidence": 0.7735546380281448}]}, {"text": "Our research is built on previous work in the area of using morpho-syntactic information for improving SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9946486353874207}]}, {"text": "Work in this area is motivated by two advantages offered by morphological analysis: (1) it provides linguistically motivated clustering of words and makes the data less sparse; (2) it captures morphological constraints applicable on the target side, such as agreement phenomena.", "labels": [], "entities": []}, {"text": "This second problem is very difficult to address with wordbased translation systems, when the relevant morphological information in the target language is either non-existent or implicitly encoded in the source language.", "labels": [], "entities": [{"text": "wordbased translation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.693304717540741}]}, {"text": "These two aspects of morphological processing have often been addressed separately: for example, morphological pre-processing of the input data is a common method of addressing the first aspect, e.g. (), while the application of a target language model has almost solely been responsible for addressing the second aspect.", "labels": [], "entities": []}, {"text": "introduced away to address these problems by using a rich featurebased model, but did not apply the model to MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.8749285936355591}]}, {"text": "In this paper, we integrate a model that predicts target word inflection in the translations of English into two morphologically complex languages (Russian and Arabic) and show improvements in the MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 197, "end_pos": 199, "type": "TASK", "confidence": 0.9893408417701721}]}, {"text": "We study several alternative methods for integration and show that it is best to propagate uncertainty among the different components as shown by other research, e.g. (), and in some cases, to factor the translation problem so that the baseline MT system can take advantage of the reduction in sparsity by being able to work on word stems.", "labels": [], "entities": [{"text": "integration", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.9566897749900818}, {"text": "MT", "start_pos": 245, "end_pos": 247, "type": "TASK", "confidence": 0.9650862812995911}]}, {"text": "We also demonstrate that our independently trained models are portable, showing that they can improve both syntactic and phrasal SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.8965249061584473}]}], "datasetContent": [{"text": "In this section we briefly report the results of human evaluation on the output of our inflection prediction system, as the correlation between BLEU scores and human evaluation results is not always obvious.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 144, "end_pos": 155, "type": "METRIC", "confidence": 0.9758104979991913}]}, {"text": "We compared the output of our component against the best output of the treelet system without our component.", "labels": [], "entities": []}, {"text": "We evaluated the following three scenarios: (1) Arabic Method 1 with n=1, which corresponds to the best performing system in BLEU according to; (2) Russian, Method 1 with n=1; (3) Russian, Method 3 with n=32, which corresponds to the best performing system in BLEU in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.5120830535888672}, {"text": "BLEU", "start_pos": 260, "end_pos": 264, "type": "DATASET", "confidence": 0.8145942091941833}]}, {"text": "Note that in (1) and (2), the only differences in the compared outputs are the changes in word inflections, while in (3) the outputs may differ in the selection of the stems.", "labels": [], "entities": []}, {"text": "In all scenarios, two human judges (native speakers of these languages) evaluated 100 sentences that had different translations by the baseline system and our model.", "labels": [], "entities": []}, {"text": "The judges were given the reference translations but not the source sentences, and were asked to classify each sentence pair into three categories: (1) the baseline system is better (score=-1), (2) the output of our model is better (score=1), or (3) they are of the same quality (score=0 shows the results of the averaged, aggregated score across two judges per evaluation scenario, along with the BLEU score improvements achieved by applying our model.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 398, "end_pos": 408, "type": "METRIC", "confidence": 0.9770058691501617}]}, {"text": "We see that in all cases, the human evaluation scores are positive, indicating that our models produce translations that are better than those produced by the baseline system.", "labels": [], "entities": []}, {"text": "We also note that in Russian, the human evaluation scores are similar for Method 1 and 3 (0.255 and 0.26), though the BLEU score gains are quite different (1.2 vs 2.6).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.9762086868286133}]}, {"text": "This maybe attributed to the fact that human evaluation typically favors the scenario where only word inflections are different ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on reference translations (accuracy, %).", "labels": [], "entities": [{"text": "reference translations", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.5306196361780167}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9995381832122803}]}, {"text": " Table 3: Test set performance for English-to-Russian MT  (BLEU) results by model using a treelet MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.8717198371887207}, {"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.6916421055793762}]}, {"text": " Table 4: Test set performance for English-to-Russian MT  (BLEU) results by model using a phrasal MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.8738047480583191}, {"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.6981782913208008}]}, {"text": " Table 5: Test set performance for English-to-Arabic MT  (BLEU) results by model using a treelet MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.8162428140640259}, {"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.6522647738456726}]}, {"text": " Table 6: Human evaluation results", "labels": [], "entities": []}]}