{"title": [{"text": "splitSVM: Fast, Space-Efficient, non-Heuristic, Polynomial Kernel Computation for NLP Applications", "labels": [], "entities": [{"text": "splitSVM", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7729378342628479}]}], "abstractContent": [{"text": "We present a fast, space efficient and non-heuristic method for calculating the decision function of polynomial kernel classifiers for NLP applications.", "labels": [], "entities": []}, {"text": "We apply the method to the MaltParser system, resulting in a Java parser that parses over 50 sentences per second on modest hardware without loss of accuracy (a 30 time speedup over existing methods).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9888179302215576}]}, {"text": "The method implementation is available as the open-source splitSVM Java library.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the last decade, many natural language processing tasks are being cast as classification problems.", "labels": [], "entities": [{"text": "natural language processing tasks", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.7093402072787285}]}, {"text": "These are then solved by of-the-shelf machine-learning algorithms, resulting in state-ofthe-art results.", "labels": [], "entities": []}, {"text": "Support Vector Machines (SVMs) have gained popularity as they constantly outperform other learning algorithms for many NLP tasks.", "labels": [], "entities": []}, {"text": "Unfortunately, once a model is trained, the decision function for kernel-based classifiers such as SVM is expensive to compute, and can grow linearly with the size of the training data.", "labels": [], "entities": []}, {"text": "In contrast, the computational complexity for the decisions functions of most non-kernel based classifiers does not depend on the size of the training data, making them orders of magnitude faster to compute.", "labels": [], "entities": []}, {"text": "For this reason, research effort was directed at speeding up the classification process of polynomial-kernel SVMs (;.", "labels": [], "entities": []}, {"text": "Existing accelerated SVM solutions, however, either require large amounts of memory, or resort to heuristics -computing only an approximation to the real decision function.", "labels": [], "entities": []}, {"text": "This work aims at speeding up the decision function computation for low-degree polynomial kernel classifiers while using only a modest amount of memory and still computing the exact function.", "labels": [], "entities": [{"text": "decision function computation", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.7187755902608236}]}, {"text": "This is achieved by taking into account the Zipfian nature of natural language data, and structuring the computation accordingly.", "labels": [], "entities": []}, {"text": "On a sample application (replacing the libsvm classifier used by) with our own), we observe a speedup factor of 30 in parsing time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 118, "end_pos": 125, "type": "TASK", "confidence": 0.9625556468963623}]}], "datasetContent": [{"text": "Using this method, one can accelerate SVM-based NLP application by just changing the classification function, keeping the rest of the logic intact.", "labels": [], "entities": [{"text": "SVM-based NLP", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.7872284948825836}]}, {"text": "We implemented an open-source software toolkit, freely available at http://www.cs.bgu.ac.il/\u223cnlpproj/.", "labels": [], "entities": []}, {"text": "Our toolkit reads models created by popular SVM packages (libsvm, SVMLight, TinySVM and Yamcha) and transforms them into our format.", "labels": [], "entities": [{"text": "SVMLight", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.911989688873291}]}, {"text": "The transformed models can then be used by our efficient Java implementation of the method described in this paper.", "labels": [], "entities": []}, {"text": "We supply wrappers for the interfaces of libsvm and the Java bindings of SVMLight.", "labels": [], "entities": []}, {"text": "Changing existing Java code to accommodate our fast SVM classifier is done by loading a different model, and changing a single function call.", "labels": [], "entities": []}, {"text": "We evaluate our method by using it as the classification engine for the Java version of MaltParser, an SVM-based state of the art dependency parser ().", "labels": [], "entities": []}, {"text": "MaltParser uses the libsvm classification engine.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9688313603401184}]}, {"text": "We used the pre-trained English models (based on sections 0-22 of the Penn WSJ) supplied with MaltParser.", "labels": [], "entities": [{"text": "Penn WSJ)", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.8747795422871908}, {"text": "MaltParser", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.9875940680503845}]}, {"text": "MaltParser already uses an effective Classifiers Splitting heuristic when training these models, setting a high baseline for our method.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9541508555412292}, {"text": "Classifiers Splitting", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7059926390647888}]}, {"text": "The pre-trained parser consists of hundreds of different classifiers, some very small.", "labels": [], "entities": []}, {"text": "We report hereon actual memory requirement and parsing time for sections 23-24, considering the classifier combination.", "labels": [], "entities": [{"text": "memory requirement", "start_pos": 24, "end_pos": 42, "type": "METRIC", "confidence": 0.9241551756858826}, {"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9537346959114075}]}, {"text": "We took rare features to be those appearing in less than 0.5% of the support vectors, which leaves us with less than 300 common features in each of the \"big\" classifiers.", "labels": [], "entities": []}, {"text": "The results are summarized in about 30 times faster, while using only 3 times as much memory.", "labels": [], "entities": []}, {"text": "MaltParser coupled with our fast classifier parses above 3200 sentences per minute.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9284802079200745}]}], "tableCaptions": [{"text": " Table 1: Parsing Time for WSJ Sections 23-24 (3762  sentences), on Pentium M, 1.73GHz", "labels": [], "entities": [{"text": "WSJ Sections", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.5483292639255524}]}]}