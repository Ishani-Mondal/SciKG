{"title": [{"text": "Cohesive Phrase-based Decoding for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8745401899019877}]}], "abstractContent": [{"text": "Phrase-based decoding produces state-of-the-art translations with no regard for syntax.", "labels": [], "entities": []}, {"text": "We add syntax to this process with a cohesion constraint based on a dependency tree for the source sentence.", "labels": [], "entities": []}, {"text": "The constraint allows the decoder to employ arbitrary, non-syntactic phrases, but ensures that those phrases are translated in an order that respects the source tree's structure.", "labels": [], "entities": []}, {"text": "In this way, we target the phrasal decoder's weakness in order model-ing, without affecting its strengths.", "labels": [], "entities": []}, {"text": "To further increase flexibility, we incorporate cohesion as a decoder feature, creating a soft constraint.", "labels": [], "entities": []}, {"text": "The resulting cohesive, phrase-based decoder is shown to produce translations that are preferred over non-cohesive output in both automatic and human evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT) is complicated by the fact that words can move during translation.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8199688841899236}]}, {"text": "If one assumes arbitrary movement is possible, that alone is sufficient to show the problem to be NPcomplete.", "labels": [], "entities": []}, {"text": "Syntactic cohesion 1 is the notion that all movement occurring during translation can be explained by permuting children in a parse tree).", "labels": [], "entities": []}, {"text": "Equivalently, one can say that phrases in the source, defined by subtrees in its parse, remain contiguous after translation.", "labels": [], "entities": []}, {"text": "Early methods for syntactic SMT held to this assumption in its entirety ().", "labels": [], "entities": [{"text": "syntactic SMT", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.7372646033763885}]}, {"text": "These approaches were eventually superseded by tree transducers and tree substitution grammars, which allow translation events to span subtree units, providing several advantages, including the ability to selectively produce uncohesive translations).", "labels": [], "entities": []}, {"text": "What may have been forgotten during this transition is that there is a reason it was once believed that a cohesive translation model would work: for some language pairs, cohesion explains nearly all translation movement.", "labels": [], "entities": []}, {"text": "showed that cohesion is held in the vast majority of cases for English-French, while have shown it to be a strong feature for word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.7905858755111694}]}, {"text": "We attempt to use this strong, but imperfect, characterization of movement to assist a non-syntactic translation method: phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 134, "end_pos": 137, "type": "TASK", "confidence": 0.7148001194000244}]}, {"text": "Phrase-based decoding () is a dominant formalism in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.7270648976167043}]}, {"text": "Contiguous segments of the source are translated and placed in the target, which is constructed from left to right.", "labels": [], "entities": []}, {"text": "The process iterates within abeam search until each word from the source has been covered by exactly one phrasal translation.", "labels": [], "entities": []}, {"text": "Candidate translations are scored by a linear combination of models, weighted according to Minimum Error Rate Training or MERT.", "labels": [], "entities": [{"text": "Candidate translations", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6595411747694016}, {"text": "Minimum Error Rate Training or MERT", "start_pos": 91, "end_pos": 126, "type": "METRIC", "confidence": 0.8756334086259207}]}, {"text": "Phrasal SMT draws strength from being able to memorize noncompositional and context-specific translations, as well as local reorderings.", "labels": [], "entities": [{"text": "Phrasal SMT", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.6746059954166412}]}, {"text": "Its primary weakness is in movement modeling; its default distortion model applies a flat penalty to any deviation from source order, forcing the decoder to rely heavily on its language model.", "labels": [], "entities": [{"text": "movement modeling", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.8466566801071167}]}, {"text": "Recently, a number of data-driven distortion models, based on lexical features and relative distance, have been proposed to compensate for this weakness).", "labels": [], "entities": []}, {"text": "There have been a number of proposals to incorporate syntactic information into phrasal decoding.", "labels": [], "entities": []}, {"text": "Early experiments with syntactically-informed phrases (, and syntactic reranking of K-best lists () produced mostly negative results.", "labels": [], "entities": []}, {"text": "The most successful attempts at syntax-enhanced phrasal SMT have directly targeted movement modeling: modified a phrasal decoder with ITG constraints, while a number of researchers have employed syntax-driven source reordering before decoding begins (.", "labels": [], "entities": [{"text": "syntax-enhanced phrasal SMT", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.5296857953071594}]}, {"text": "We attempt something between these two approaches: our constraint is derived from a linguistic parse tree, but it is used inside the decoder, not as a preprocessing step.", "labels": [], "entities": []}, {"text": "We begin in Section 2 by defining syntactic cohesion so it can be applied to phrasal decoder output.", "labels": [], "entities": []}, {"text": "Section 3 describes how to add both hard and soft cohesion constraints to a phrasal decoder.", "labels": [], "entities": []}, {"text": "Section 4 provides our results from both automatic and human evaluations.", "labels": [], "entities": []}, {"text": "Sections 5 and 6 provide a qualitative discussion of cohesive output and conclude.", "labels": [], "entities": [{"text": "conclude", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9353213310241699}]}], "datasetContent": [{"text": "We have adapted the notion of syntactic cohesion so that it is applicable to phrase-based decoding.", "labels": [], "entities": []}, {"text": "This results in a translation process that respects sourceside syntactic boundaries when distorting phrases.", "labels": [], "entities": []}, {"text": "In this section we will test the impact of such information on an English to French translation task.", "labels": [], "entities": [{"text": "English to French translation task", "start_pos": 66, "end_pos": 100, "type": "TASK", "confidence": 0.7175998330116272}]}, {"text": "We test our cohesion-enhanced Moses decoder trained using 688K sentence pairs of Europarl French-English data, provided by the SMT 2006 Shared Task ().", "labels": [], "entities": [{"text": "Europarl French-English data", "start_pos": 81, "end_pos": 109, "type": "DATASET", "confidence": 0.9422259529431661}, {"text": "SMT 2006 Shared Task", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.642301395535469}]}, {"text": "Word alignments are provided by GIZA++ () with grow-diag-final combination, with infrastructure for alignment combination and phrase extraction provided by the shared task.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.653692215681076}, {"text": "alignment combination", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.7890304028987885}, {"text": "phrase extraction", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.7773133516311646}]}, {"text": "We decode with Moses, using a stack size of 100, abeam threshold of 0.03 and a distortion limit of 4.", "labels": [], "entities": []}, {"text": "Weights for the log-linear model are set using MERT, as implemented by.", "labels": [], "entities": [{"text": "MERT", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9230368733406067}]}, {"text": "Our tuning set is the first 500 sentences of the SMT06 development data.", "labels": [], "entities": [{"text": "SMT06 development data", "start_pos": 49, "end_pos": 71, "type": "DATASET", "confidence": 0.6990785400072733}]}, {"text": "We holdout the remaining 1500 development sentences for development testing (dev-test), and the entirety of the provided 2000-sentence test set for blind testing (test).", "labels": [], "entities": []}, {"text": "Since we require source dependency trees, all experiments test English to French translation.", "labels": [], "entities": []}, {"text": "English dependency trees are provided by.", "labels": [], "entities": []}, {"text": "Our cohesion constraint directly targets sentences for which an unmodified phrasal decoder produces uncohesive output according to the definition in Section 2.", "labels": [], "entities": []}, {"text": "Therefore, we present our results not only on each test set in its entirety, but also on the subsets defined by whether or not the baseline naturally produces a cohesive translation.", "labels": [], "entities": []}, {"text": "The sizes of the resulting evaluation sets are given in.", "labels": [], "entities": []}, {"text": "Our development tests indicated that the soft and hard cohesion constraints performed somewhat similarly, with the soft constraint providing more stable, and generally better results.", "labels": [], "entities": []}, {"text": "We confirmed these trends on our test set, but to conserve space, we provide detailed results for only the soft constraint.", "labels": [], "entities": []}, {"text": "We first present our soft cohesion constraint's effect on BLEU score () for both our dev-test and test sets.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9847899079322815}]}, {"text": "We compare against an unmodified baseline decoder, as well as a decoder enhanced with a lexical reordering model).", "labels": [], "entities": []}, {"text": "For each phrase pair in our translation table, the lexical reordering model tracks statistics on its reordering behavior as observed in our word-aligned training text.", "labels": [], "entities": []}, {"text": "The lexical reordering model provides a good comparison point as a non-syntactic, and potentially orthogonal, improvement to phrase-based movement modeling.", "labels": [], "entities": [{"text": "phrase-based movement modeling", "start_pos": 125, "end_pos": 155, "type": "TASK", "confidence": 0.7235225637753805}]}, {"text": "We use the implementation provided in Moses, with probabilities conditioned on bilingual phrases and predicting three orientation bins: straight, inverted and disjoint.", "labels": [], "entities": []}, {"text": "Since adding features to the decoder's log-linear model is straight-forward, we also experiment with a combined system that uses both the cohesion constraint and a lexical reordering model.", "labels": [], "entities": []}, {"text": "The results of our experiments are shown in Table 3, and reveal some interesting phenomena.", "labels": [], "entities": []}, {"text": "First of all, looking across columns, we can see that there is a definite divide in BLEU score between our two evaluation subsets.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9843976199626923}]}, {"text": "Sentences with cohesive baseline translations receive much higher BLEU scores than those with uncohesive baseline translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9991859793663025}]}, {"text": "This indicates that the cohesive subset is easier to translate with a phrase-based system.", "labels": [], "entities": []}, {"text": "Our definition of cohesive phrasal output appears to provide a useful feature for estimating translation confidence.", "labels": [], "entities": [{"text": "translation", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.6722090244293213}]}, {"text": "Comparing the baseline with and without the soft cohesion constraint, we see that cohesion has only a modest effect on BLEU, when measured on all sentence pairs, with improvements ranging between 0.2 and 0.5 absolute points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9984983205795288}]}, {"text": "Recall that the majority of baseline translations are naturally cohesive.", "labels": [], "entities": []}, {"text": "The cohesion constraint's effect is much more pronounced on the more difficult uncohesive subsets, showing absolute improvements between 0.5 and 1.1 points.", "labels": [], "entities": []}, {"text": "Considering the lexical reordering model, we see that its effect is very similar to that of syntactic cohesion.", "labels": [], "entities": []}, {"text": "Its BLEU scores are very similar, with lex-: BLEU scores with an integrated soft cohesion constraint (coh) or a lexical reordering model (lex).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9817824959754944}, {"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9836832880973816}]}, {"text": "Any system significantly better than base has been highlighted, as tested by bootstrap re-sampling with a 95% confidence interval.", "labels": [], "entities": []}, {"text": "ical reordering also affecting primarily the uncohesive subset.", "labels": [], "entities": [{"text": "ical reordering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6679499447345734}]}, {"text": "This similarity in behavior is interesting, as its data-driven, bilingual reordering probabilities are quite different from our cohesion flag, which is driven by monolingual syntax.", "labels": [], "entities": []}, {"text": "Examining the system that employs both movement models, we see that the combination (lex+coh) receives the highest score on the dev-test set.", "labels": [], "entities": []}, {"text": "A large portion of the combined system's gain is on the cohesive subset, indicating that the cohesion constraint maybe enabling better use of the lexical reordering model on otherwise cohesive translations.", "labels": [], "entities": []}, {"text": "Unfortunately, these same gains are not born out on the test set, where the lexical reordering model appears unable to improve upon the already strong performance of the cohesion constraint.", "labels": [], "entities": []}, {"text": "We also present a human evaluation designed to determine whether bilingual speakers prefer cohesive decoder output.", "labels": [], "entities": []}, {"text": "Our comparison systems are the baseline decoder (base) and our soft cohesion constraint (coh).", "labels": [], "entities": []}, {"text": "We evaluate on our dev-test set, 5 as it has our smallest observed BLEU-score gap, and we wish to determine if it is actually improving.", "labels": [], "entities": [{"text": "BLEU-score gap", "start_pos": 67, "end_pos": 81, "type": "METRIC", "confidence": 0.9770812690258026}]}, {"text": "Our experimental set-up is modeled after the human evaluation presented in ().", "labels": [], "entities": []}, {"text": "We provide two human annotators 6 a set of 75 English source sentences, along with a reference translation and a pair of translation candidates, one from each system.", "labels": [], "entities": []}, {"text": "The annotators are asked to indicate which of the two system translations they prefer, or if they The cohesion constraint has no free parameters to optimize during development, so this does not create an advantage.", "labels": [], "entities": []}, {"text": "Annotators were both native English speakers who speak French as a second language.", "labels": [], "entities": []}, {"text": "Each has a strong comprehension of written French.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of sentences that receive cohesive trans- lations from the baseline decoder. This property also de- fines our evaluation subsets.", "labels": [], "entities": []}, {"text": " Table 3: BLEU scores with an integrated soft cohesion constraint (coh) or a lexical reordering model (lex). Any system  significantly better than base has been highlighted, as tested by bootstrap re-sampling with a 95% confidence interval.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9925054907798767}]}, {"text": " Table 4: Confusion matrix from human evaluation.", "labels": [], "entities": []}]}