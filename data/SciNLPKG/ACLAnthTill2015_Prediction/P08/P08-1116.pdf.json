{"title": [{"text": "Combining Multiple Resources to Improve SMT-based Paraphrasing Model *", "labels": [], "entities": [{"text": "SMT-based Paraphrasing", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8031586408615112}]}], "abstractContent": [{"text": "This paper proposes a novel method that exploits multiple resources to improve statistical machine translation (SMT) based paraphrasing.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) based paraphrasing", "start_pos": 79, "end_pos": 135, "type": "TASK", "confidence": 0.8204094842076302}]}, {"text": "In detail, a phrasal paraphrase table and a feature function are derived from each resource, which are then combined in a log-linear SMT model for sentence-level paraphrase generation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.9770943522453308}, {"text": "sentence-level paraphrase generation", "start_pos": 147, "end_pos": 183, "type": "TASK", "confidence": 0.6337910294532776}]}, {"text": "Experimental results show that the SMT-based paraphrasing model can be enhanced using multiple resources.", "labels": [], "entities": [{"text": "SMT-based paraphrasing", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.8825792372226715}]}, {"text": "The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9414097666740417}]}, {"text": "In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrases are alternative ways of conveying the same meaning.", "labels": [], "entities": []}, {"text": "Paraphrases are important in many natural language processing (NLP) applications, such as machine translation (MT), question answering (QA), information extraction (IE), multidocument summarization (MDS), and natural language generation (NLG).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.8534533262252808}, {"text": "question answering (QA)", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.8558999180793763}, {"text": "information extraction (IE)", "start_pos": 141, "end_pos": 168, "type": "TASK", "confidence": 0.8505881726741791}, {"text": "multidocument summarization (MDS)", "start_pos": 170, "end_pos": 203, "type": "TASK", "confidence": 0.8135799884796142}, {"text": "natural language generation (NLG)", "start_pos": 209, "end_pos": 242, "type": "TASK", "confidence": 0.786281963189443}]}, {"text": "This paper addresses the problem of sentencelevel paraphrase generation, which aims at generating paraphrases for input sentences.", "labels": [], "entities": [{"text": "sentencelevel paraphrase generation", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.734678308169047}]}, {"text": "An example of sentence-level paraphrases can be seen below: S1: The table was setup in the carriage shed.", "labels": [], "entities": []}, {"text": "S2: The table was laid under the cart-shed.", "labels": [], "entities": []}, {"text": "* This research was finished while the first author worked as an intern in Microsoft Research Asia.", "labels": [], "entities": [{"text": "Microsoft Research Asia", "start_pos": 75, "end_pos": 98, "type": "DATASET", "confidence": 0.935786505540212}]}, {"text": "Paraphrase generation can be viewed as monolingual machine translation), which typically includes a translation model and a language model.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9204617440700531}, {"text": "monolingual machine translation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7707266608874003}]}, {"text": "The translation model can be trained using monolingual parallel corpora.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9702491164207458}]}, {"text": "However, acquiring such corpora is not easy.", "labels": [], "entities": []}, {"text": "Hence, data sparseness is a key problem for the SMT-based paraphrasing.", "labels": [], "entities": [{"text": "SMT-based paraphrasing", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.9114243984222412}]}, {"text": "On the other hand, various methods have been presented to extract phrasal paraphrases from different resources, which include thesauri, monolingual corpora, bilingual corpora, and the web.", "labels": [], "entities": []}, {"text": "However, little work has been focused on using the extracted phrasal paraphrases in sentence-level paraphrase generation.", "labels": [], "entities": [{"text": "sentence-level paraphrase generation", "start_pos": 84, "end_pos": 120, "type": "TASK", "confidence": 0.5981203218301138}]}, {"text": "In this paper, we exploit multiple resources to improve the SMT-based paraphrase generation.", "labels": [], "entities": [{"text": "SMT-based paraphrase generation", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.9154849251111349}]}, {"text": "In detail, six kinds of resources are utilized, including: (1) an automatically constructed thesaurus, (2) a monolingual parallel corpus from novels, (3) a monolingual comparable corpus from news articles, (4) a bilingual phrase table, (5) word definitions from Encarta dictionary, and (6) a corpus of similar user queries.", "labels": [], "entities": [{"text": "Encarta dictionary", "start_pos": 262, "end_pos": 280, "type": "DATASET", "confidence": 0.912264347076416}]}, {"text": "Among the resources, (1), (2), (3), and (4) have been investigated by other researchers, while (5) and (6) are first used in this paper.", "labels": [], "entities": []}, {"text": "From those resources, six phrasal paraphrase tables are extracted, which are then used in a log-linear SMTbased paraphrasing model.", "labels": [], "entities": [{"text": "SMTbased paraphrasing", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.8931675851345062}]}, {"text": "Both phrase-level and sentence-level evaluations were carried out in the experiments.", "labels": [], "entities": []}, {"text": "In the former one, phrase substitutes occurring in the paraphrase sentences were evaluated.", "labels": [], "entities": []}, {"text": "While in the latter one, the acceptability of the paraphrase sentences was evaluated.", "labels": [], "entities": []}, {"text": "Experimental results show that: (1) The SMT-based paraphrasing is enhanced using multiple resources.", "labels": [], "entities": [{"text": "SMT-based paraphrasing", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.9038082957267761}]}, {"text": "The phrase-level and sentence-level precision of the generated paraphrases exceed 60% and 55%, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.939723789691925}]}, {"text": "(2) Although the contributions of the resources differ a lot, all the resources are useful.", "labels": [], "entities": []}, {"text": "(3) The performance of the method varies greatly on different test sets and it performs best on the test set of news sentences, which are from the same source as most of the training data.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces the log-linear model for paraphrase generation.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.9655847251415253}]}, {"text": "Section 4 describes the phrasal paraphrase extraction from different resources.", "labels": [], "entities": [{"text": "phrasal paraphrase extraction", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.6379605333010355}]}, {"text": "Section 5 presents the parameter estimation method.", "labels": [], "entities": []}, {"text": "Section 6 shows the experiments and results.", "labels": [], "entities": []}, {"text": "Section 7 draws the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of the method on different types of test data, we used three kinds of sentences for testing, which were randomly extracted from Google news, free online novels, and forums, respectively.", "labels": [], "entities": []}, {"text": "For each type, 50 sentences were extracted as test data and another 25 were extracted as development data.", "labels": [], "entities": []}, {"text": "For each test sentence, top 10 of the generated paraphrases were kept for evaluation.", "labels": [], "entities": []}, {"text": "The phrase-level evaluation was carried out to investigate the contributions of the paraphrase tables.", "labels": [], "entities": []}, {"text": "For each test sentence, all possible phrase substitutes were first extracted from the paraphrase tables and manually labeled as \"correct\" or \"incorrect\".", "labels": [], "entities": []}, {"text": "Here, the criterion for identifying paraphrases is the same as that described in Section 5.", "labels": [], "entities": []}, {"text": "Then, in the stage of decoding, the phrase substitutes were printed out and evaluated using the labeled data.", "labels": [], "entities": []}, {"text": "Two metrics were used here.", "labels": [], "entities": []}, {"text": "The first is the number of distinct correct substitutes (#DCS).", "labels": [], "entities": [{"text": "number of distinct correct substitutes (#DCS)", "start_pos": 17, "end_pos": 62, "type": "METRIC", "confidence": 0.6700631119310856}]}, {"text": "Obviously, the more distinct correct phrase substitutes a paraphrase table can provide, the more valuable it is.", "labels": [], "entities": []}, {"text": "The second is the accuracy of the phrase substitutes, which is computed as: To evaluate the PTs learned from different resources, we first used each PT (from 1 to 6) along with PT-7 in decoding.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994117021560669}]}, {"text": "The results are shown in Table 1.", "labels": [], "entities": []}, {"text": "It can be seen that PT-4 is the most useful, as it provides the most correct substitutes and the accuracy is the highest.", "labels": [], "entities": [{"text": "PT-4", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.8337683081626892}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9998055100440979}]}, {"text": "We believe that it is because PT-4 is much larger than the other PTs.", "labels": [], "entities": [{"text": "PT-4", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9240017533302307}]}, {"text": "Compared with PT-4, the accuracies of the other PTs are fairly: Contributions of the paraphrase tables.", "labels": [], "entities": [{"text": "PT-4", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.9008944034576416}, {"text": "accuracies", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9874832630157471}]}, {"text": "PT-1: from the thesaurus; PT-2: from the monolingual parallel corpus; PT-3: from the monolingual comparable corpus; PT-4: from the bilingual parallel corpus; PT-5: from the Encarta dictionary definitions; PT-6: from the similar MSN user queries; PT-7: self-paraphrases. low.", "labels": [], "entities": []}, {"text": "This is because those PTs are smaller, thus they can provide fewer correct phrase substitutes.", "labels": [], "entities": [{"text": "PTs", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.7944473028182983}]}, {"text": "As a result, plenty of incorrect substitutes were included in the top 10 generated paraphrases.", "labels": [], "entities": []}, {"text": "PT-6 provides the least correct phrase substitutes and the accuracy is the lowest.", "labels": [], "entities": [{"text": "PT-6", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.903510570526123}, {"text": "phrase substitutes", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7011920809745789}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9997639060020447}]}, {"text": "First, many phrases in PT-6 are not real phrases but only sets of keywords (e.g., \"lottery results ny\"), which may not appear in sentences.", "labels": [], "entities": []}, {"text": "Second, many words in this table have spelling mistakes (e.g., \"widows vista\").", "labels": [], "entities": []}, {"text": "Third, some phrase pairs in PT-6 are not paraphrases but only \"related queries\" (e.g., \"back tattoo\" vs. \"butterfly tattoo\").", "labels": [], "entities": []}, {"text": "Fourth, many phrases of PT-6 contain proper names or out-of-vocabulary words, which are difficult to be matched.", "labels": [], "entities": []}, {"text": "The accuracy based on PT-1 is also quite low.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997072815895081}, {"text": "PT-1", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.8980499505996704}]}, {"text": "We found that it is mainly because the phrase pairs in PT-1 are automatically clustered, many of which are merely \"similar\" words rather than synonyms (e.g., \"borrow\" vs. \"buy\").", "labels": [], "entities": []}, {"text": "Next, we try to find out whether it is necessary to combine all PTs.", "labels": [], "entities": []}, {"text": "Thus we conducted several runs, each of which added the most useful PT from the left ones.", "labels": [], "entities": [{"text": "PT", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.9987832903862}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We can see that all the PTs are useful, as each PT provides some new correct phrase substitutes and the accuracy increases when adding each PT except PT-1.", "labels": [], "entities": [{"text": "PTs", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.8842417001724243}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.999464213848114}]}, {"text": "Since the PTs are extracted from different resources, they have different contributions.", "labels": [], "entities": []}, {"text": "Here we only discuss the contributions of PT-5 and PT-6, which are first used in paraphrasing in this paper.", "labels": [], "entities": [{"text": "PT-5", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.6861630082130432}, {"text": "PT-6", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.6195064783096313}, {"text": "paraphrasing", "start_pos": 81, "end_pos": 93, "type": "TASK", "confidence": 0.9725890755653381}]}, {"text": "PT-5 is useful for paraphrasing uncommon concepts since it can \"explain\" concepts with their definitions.", "labels": [], "entities": [{"text": "PT-5", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5741389989852905}, {"text": "paraphrasing uncommon concepts", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.902565081914266}]}, {"text": "For instance, in the following test sentence S 1 , the word \"amnesia\" is a relatively uncommon word, especially for the people using English as the second language.", "labels": [], "entities": []}, {"text": "Based on PT-5, S 1 can be paraphrased into T 1 , which is much easier to understand.", "labels": [], "entities": [{"text": "PT-5", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.7306775450706482}]}, {"text": "In this section, we evaluated the sentence-level quality of the generated paraphrases 11 . In detail, each generated paraphrase was manually labeled as \"acceptable\" or \"unacceptable\".", "labels": [], "entities": []}, {"text": "Here, the criterion for counting a sentence T as an acceptable paraphrase of sentence S is that T is understandable and its meaning is not evidently changed compared with S.", "labels": [], "entities": []}, {"text": "For example, for the sentence S 4 , T 4 is an acceptable paraphrase generated using our method.", "labels": [], "entities": []}, {"text": "The strain on US forces of fighting in Iraq and Afghanistan was exposed yesterday when the Pentagon published a report showing that the number of suicides among US troops is at its highest level since the 1991 Gulf war.", "labels": [], "entities": []}, {"text": "T 4 : The pressure on US troops of fighting in Iraq and Afghanistan was revealed yesterday when the Pentagon released a report showing that the amount of suicides among US forces is at its top since the 1991 Gulf conflict.", "labels": [], "entities": []}, {"text": "We carried out sentence-level evaluation using the top-1, top-5, and top-10 results of each test sentence.", "labels": [], "entities": []}, {"text": "The accuracy of the top-n results was computed as: where N is the number of test sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994958639144897}]}, {"text": "n i is the number of acceptable paraphrases in the top-n paraphrases of the i-th test sentence.", "labels": [], "entities": []}, {"text": "We computed the accuracy on the whole test set (150 sentences) as well as on the three subsets, i.e., the 50 news sentences, 50 novel sentences, and 50 forum sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9996708631515503}]}, {"text": "The results are shown in table 3.", "labels": [], "entities": []}, {"text": "It can be seen that the accuracy varies greatly on different test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9995591044425964}]}, {"text": "The accuracy on the news sentences is the highest, while that on the forum sentences is the lowest.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994217157363892}]}, {"text": "First, the largest PT used in the experiments is extracted using the bilingual parallel data, which are mostly from news documents.", "labels": [], "entities": []}, {"text": "Thus, the test set of news sentences is more similar to the training data.", "labels": [], "entities": []}, {"text": "Second, the news sentences are formal while the novel and forum sentences are less formal.", "labels": [], "entities": []}, {"text": "Especially, some of the forum sentences contain spelling mistakes and grammar mistakes.", "labels": [], "entities": []}, {"text": "Third, we find in the results that, most phrases paraphrased in the novel and forum sentences are commonly used phrases or words, such as \"food\", \"good\", \"find\", etc.", "labels": [], "entities": []}, {"text": "These phrases are more difficult to paraphrase than the less common phrases, since they usually have much more paraphrases in the PTs.", "labels": [], "entities": []}, {"text": "Therefore, it is more difficult to choose the right paraphrase from all the candidates when conducting sentence-level paraphrase generation.", "labels": [], "entities": [{"text": "sentence-level paraphrase generation", "start_pos": 103, "end_pos": 139, "type": "TASK", "confidence": 0.6080370446046194}]}, {"text": "Fourth, the forum sentences contain plenty of words such as \"board (means computer board)\", \"site (means web site)\", \"mouse (means computer mouse)\", etc.", "labels": [], "entities": []}, {"text": "These words are polysemous and have particular meanings in the domains of computer science and internet.", "labels": [], "entities": []}, {"text": "Our method performs poor when paraphrasing these words since the domain of a context sentence is hard to identify.", "labels": [], "entities": []}, {"text": "After observing the results, we find that there are three types of errors: (1) syntactic errors: the generated sentences are ungrammatical.", "labels": [], "entities": []}, {"text": "About 32% of the unacceptable results are due to syntactic errors.", "labels": [], "entities": []}, {"text": "(2) semantic errors: the generated sentences are incomprehensible.", "labels": [], "entities": []}, {"text": "Nearly 60% of the unacceptable paraphrases have semantic errors.", "labels": [], "entities": []}, {"text": "(3) non-paraphrase: the generated sentences are well formed and comprehensible but are not paraphrases of the input sentences.", "labels": [], "entities": []}, {"text": "8% of the unacceptable results are of this type.", "labels": [], "entities": []}, {"text": "We believe that many of the errors above can be avoided by applying syntactic constraints and by making better use of context information in decoding, which is left as our future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Contributions of the paraphrase tables.  PT-1: from the thesaurus; PT-2: from the monolingual  parallel corpus; PT-3: from the monolingual comparable  corpus; PT-4: from the bilingual parallel corpus; PT-5:  from the Encarta dictionary definitions; PT-6: from the  similar MSN user queries; PT-7: self-paraphrases.", "labels": [], "entities": []}, {"text": " Table 2: Performances of different combinations of para- phrase tables.", "labels": [], "entities": []}]}