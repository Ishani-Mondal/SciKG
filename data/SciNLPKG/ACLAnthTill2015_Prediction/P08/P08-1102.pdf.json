{"title": [{"text": "A Cascaded Linear Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging", "labels": [], "entities": [{"text": "Joint Chinese Word Segmentation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.5645786970853806}, {"text": "Part-of-Speech Tagging", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.6935007274150848}]}], "abstractContent": [{"text": "We propose a cascaded linear model for joint Chinese word segmentation and part-of-speech tagging.", "labels": [], "entities": [{"text": "joint Chinese word segmentation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.5372654497623444}, {"text": "part-of-speech tagging", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.6999569535255432}]}, {"text": "With a character-based perceptron as the core, combined with real-valued features such as language models, the cascaded model is able to efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly.", "labels": [], "entities": []}, {"text": "Experiments show that the cascaded model achieves improved accuracies on both seg-mentation only and joint segmentation and part-of-speech tagging.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9931173324584961}, {"text": "part-of-speech tagging", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.6937137395143509}]}, {"text": "On the Penn Chinese Treebank 5.0, we obtain an error reduction of 18.5% on segmentation and 12% on joint seg-mentation and part-of-speech tagging over the perceptron-only baseline.", "labels": [], "entities": [{"text": "Penn Chinese Treebank 5.0", "start_pos": 7, "end_pos": 32, "type": "DATASET", "confidence": 0.9868940114974976}, {"text": "error", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9784610867500305}, {"text": "segmentation", "start_pos": 75, "end_pos": 87, "type": "TASK", "confidence": 0.964282214641571}, {"text": "part-of-speech tagging", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.6903994679450989}]}], "introductionContent": [{"text": "Word segmentation and part-of-speech (POS) tagging are important tasks in computer processing of Chinese and other Asian languages.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6794427782297134}, {"text": "part-of-speech (POS) tagging", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.6535342156887054}]}, {"text": "Several models were introduced for these problems, for example, the Hidden Markov Model (HMM), Maximum Entropy Model (ME), and Conditional Random Fields (CRFs) ().", "labels": [], "entities": [{"text": "Maximum Entropy Model (ME)", "start_pos": 95, "end_pos": 121, "type": "METRIC", "confidence": 0.7826480766137441}]}, {"text": "CRFs have the advantage of flexibility in representing features compared to generative ones such as HMM, and usually behaves the best in the two tasks.", "labels": [], "entities": []}, {"text": "Another widely used discriminative method is the perceptron algorithm, which achieves comparable performance to CRFs with much faster training, so we base this work on the perceptron.", "labels": [], "entities": []}, {"text": "To segment and tag a character sequence, there are two strategies to choose: performing POS tagging following segmentation; or joint segmentation and POS tagging (Joint S&T).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.8090940117835999}, {"text": "POS tagging", "start_pos": 150, "end_pos": 161, "type": "TASK", "confidence": 0.7764716744422913}]}, {"text": "Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag, Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information ().", "labels": [], "entities": [{"text": "Joint S&T", "start_pos": 139, "end_pos": 148, "type": "TASK", "confidence": 0.8811268508434296}]}, {"text": "Compared to performing segmentation and POS tagging one at a time, Joint S&T can achieve higher accuracy not only on segmentation but also on POS tagging ().", "labels": [], "entities": [{"text": "segmentation", "start_pos": 23, "end_pos": 35, "type": "TASK", "confidence": 0.9803596138954163}, {"text": "POS tagging", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.7713333666324615}, {"text": "Joint S&T", "start_pos": 67, "end_pos": 76, "type": "TASK", "confidence": 0.5475129783153534}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.999024510383606}, {"text": "POS tagging", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.7784486711025238}]}, {"text": "Besides the usual character-based features, additional features dependent on POS's or words can also be employed to improve the performance.", "labels": [], "entities": []}, {"text": "However, as such features are generated dynamically during the decoding procedure, two limitation arise: on the one hand, the amount of parameters increases rapidly, which is apt to overfit on training corpus; on the other hand, exact inference by dynamic programming is intractable because the current predication relies on the results of prior predications.", "labels": [], "entities": []}, {"text": "As a result, many theoretically useful features such as higherorder word or POS n-grams are difficult to be incorporated in the model efficiently.", "labels": [], "entities": []}, {"text": "To cope with this problem, we propose a cascaded linear model inspired by the log-linear model () widely used in statistical machine translation to incorporate different kinds of knowledge sources.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 113, "end_pos": 144, "type": "TASK", "confidence": 0.642953117688497}]}, {"text": "Shown in, the cascaded model has a two-layer architecture, with a characterbased perceptron as the core combined with other real-valued features such as language models.", "labels": [], "entities": []}, {"text": "We Labelling: g 4 = P (T |W ) g 4 Generating: Length: g 6 = |W | g 6 S: Structure of Cascaded Linear Model.", "labels": [], "entities": []}, {"text": "|R| denotes the scale of the feature space of the core perceptron.", "labels": [], "entities": []}, {"text": "will describe it in detail in Section 4.", "labels": [], "entities": []}, {"text": "In this architecture, knowledge sources that are intractable to incorporate into the perceptron, can be easily incorporated into the outside linear model.", "labels": [], "entities": []}, {"text": "In addition, as these knowledge sources are regarded as separate features, we can train their corresponding models independently with each other.", "labels": [], "entities": []}, {"text": "This is an interesting approach when the training corpus is large as it reduces the time and space consumption.", "labels": [], "entities": []}, {"text": "Experiments show that our cascaded model can utilize different knowledge sources effectively and obtain accuracy improvements on both segmentation and Joint S&T.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.998828113079071}, {"text": "segmentation", "start_pos": 134, "end_pos": 146, "type": "TASK", "confidence": 0.9842871427536011}, {"text": "Joint S&T", "start_pos": 151, "end_pos": 160, "type": "TASK", "confidence": 0.600440576672554}]}], "datasetContent": [{"text": "We reported results from two set of experiments.", "labels": [], "entities": []}, {"text": "The first was conducted to test the performance of the perceptron on segmentation on the corpus from SIGHAN Bakeoff 2, including the Academia Sinica Corpus (AS), the Hong Kong City University Corpus (CityU), the Peking University Corpus (PKU) and the Microsoft Research Corpus (MSR).", "labels": [], "entities": [{"text": "Hong Kong City University Corpus (CityU)", "start_pos": 166, "end_pos": 206, "type": "DATASET", "confidence": 0.7305685989558697}, {"text": "Peking University Corpus (PKU)", "start_pos": 212, "end_pos": 242, "type": "DATASET", "confidence": 0.7826749185721079}, {"text": "Microsoft Research Corpus (MSR)", "start_pos": 251, "end_pos": 282, "type": "DATASET", "confidence": 0.914969672759374}]}, {"text": "The second was conducted on the Penn Chinese Treebank 5.0 (CTB5.0) to test the performance of the cascaded model on segmentation and Joint S&T.", "labels": [], "entities": [{"text": "Penn Chinese Treebank 5.0 (CTB5.0)", "start_pos": 32, "end_pos": 66, "type": "DATASET", "confidence": 0.9753492048808506}, {"text": "segmentation", "start_pos": 116, "end_pos": 128, "type": "TASK", "confidence": 0.9908055663108826}, {"text": "Joint S&T", "start_pos": 133, "end_pos": 142, "type": "TASK", "confidence": 0.632624164223671}]}, {"text": "In all experiments, we use the averaged parameters for the perceptrons, and F-measure as the accuracy measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9974163770675659}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9995177984237671}]}, {"text": "With precision P and recall R, the balance F-measure is defined as: F = 2P R/(P + R).", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9942157864570618}, {"text": "recall R", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9779704809188843}]}, {"text": "For convenience of comparing with others, we focus only on the close test, which means that any extra resource is forbidden except the designated training corpus.", "labels": [], "entities": []}, {"text": "In order to test the performance of the lexical-target templates and meanwhile determine the best iterations over the training corpus, we randomly chosen 2, 000 shorter sentences (less than 50 words) as the development set and the rest as the training set (84, 294 sentences), then trained a perceptron model named NON-LEX using only nonlexical-target features and another named LEX using both the two kinds of features.", "labels": [], "entities": []}, {"text": "shows their learning curves depicting the F-measure on the development set after 1 to 10 training iterations.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9960260391235352}]}, {"text": "We found that LEX outperforms NON-LEX with a margin of about 0.002 at each iteration, and its learning curve reaches a tableland at iteration 7.", "labels": [], "entities": []}, {"text": "Then we trained LEX on each of the four corpora for 7 iterations.", "labels": [], "entities": []}, {"text": "Test results listed in shows that this model obtains higher accuracy than the best of SIGHAN Bakeoff 2 in three corpora (AS, CityU and MSR).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9992929697036743}, {"text": "CityU", "start_pos": 125, "end_pos": 130, "type": "DATASET", "confidence": 0.9218178391456604}]}, {"text": "On the three corpora, it also outperformed the word-based perceptron model of.", "labels": [], "entities": []}, {"text": "However, the accuracy on PKU corpus is obvious lower than the best score SIGHAN  reported, we need to conduct further research on this problem.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9994798302650452}, {"text": "PKU corpus", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.9180116057395935}]}, {"text": "We turned to experiments on CTB 5.0 to test the performance of the cascaded model.", "labels": [], "entities": [{"text": "CTB 5.0", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9591566622257233}]}, {"text": "According to the usual practice in syntactic analysis, we choose chapters 1 \u2212 260 (18074 sentences) as training set, chapter 271 \u2212 300 (348 sentences) as test set and chapter 301 \u2212 325 (350 sentences) as development set.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7832567095756531}]}, {"text": "At the first step, we conducted a group of contrasting experiments on the core perceptron, the first concentrated on the segmentation regardless of the POS information and reported the F-measure on segmentation only, while the second performed Joint S&T using POS information and reported the F-measure both on segmentation and on Joint S&T.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 185, "end_pos": 194, "type": "METRIC", "confidence": 0.9947420358657837}, {"text": "Joint S&T", "start_pos": 244, "end_pos": 253, "type": "TASK", "confidence": 0.6451102569699287}, {"text": "F-measure", "start_pos": 293, "end_pos": 302, "type": "METRIC", "confidence": 0.9934112429618835}, {"text": "Joint S&T", "start_pos": 331, "end_pos": 340, "type": "DATASET", "confidence": 0.7680476307868958}]}, {"text": "Note that the accuracy of Joint S&T means that a word-POS pair is recognized only if both the boundary tags and the POS's are correctly labelled.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9997100234031677}, {"text": "Joint S&T", "start_pos": 26, "end_pos": 35, "type": "TASK", "confidence": 0.5242534726858139}]}, {"text": "The evaluation results are shown in.", "labels": [], "entities": []}, {"text": "We find that Joint S&T can also improve the segmentation accuracy.", "labels": [], "entities": [{"text": "Joint S&T", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.6957663968205452}, {"text": "segmentation", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.9816375374794006}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9640811681747437}]}, {"text": "However, the F-measure on Joint S&T is obvious lower, about a rate of 95% to the F-measure on segmentation.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9965510368347168}, {"text": "Joint S&T", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.6358540952205658}, {"text": "F-measure", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9936811923980713}, {"text": "segmentation", "start_pos": 94, "end_pos": 106, "type": "TASK", "confidence": 0.9805326461791992}]}, {"text": "Similar trend appeared in experiments of, where they conducted experiments on CTB 3.0 and achieved Fmeasure 0.919 on Joint S&T, a ratio of 96% to the F-measure 0.952 on segmentation.", "labels": [], "entities": [{"text": "CTB 3.0", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9089325666427612}, {"text": "Fmeasure 0.919", "start_pos": 99, "end_pos": 113, "type": "METRIC", "confidence": 0.9785478413105011}, {"text": "Joint S&T", "start_pos": 117, "end_pos": 126, "type": "DATASET", "confidence": 0.8084717094898224}, {"text": "F-measure", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.9857941269874573}, {"text": "segmentation", "start_pos": 169, "end_pos": 181, "type": "TASK", "confidence": 0.9680900573730469}]}, {"text": "As the next step, a group of experiments were conducted to investigate how well the cascaded linear model performs.", "labels": [], "entities": []}, {"text": "Here the core perceptron was just the POS+ model in experiments above.", "labels": [], "entities": []}, {"text": "Besides this perceptron, other sub-models are trained and used as additional features of the outside-layer linear model.", "labels": [], "entities": []}, {"text": "We used SRI Language Modelling Toolkit () to train a 3-gram word LM with modified Kneser-Ney smoothing  LM with Witten-Bell smoothing, and we trained a word-POS co-occurrence model simply by MLE without smoothing.", "labels": [], "entities": [{"text": "MLE", "start_pos": 191, "end_pos": 194, "type": "METRIC", "confidence": 0.8256915807723999}]}, {"text": "To obtain their corresponding weights, we adapted the minimum-error-rate training algorithm to train the outside-layer model.", "labels": [], "entities": []}, {"text": "In order to inspect how much improvement each feature brings into the cascaded model, every time we removed a feature while retaining others, then retrained the model and tested its performance on the test set.", "labels": [], "entities": []}, {"text": "We find that the cascaded model achieves a F-measure increment of about 0.5 points on segmentation and about 0.9 points on Joint S&T, over the perceptron-only model POS+.", "labels": [], "entities": [{"text": "F-measure increment", "start_pos": 43, "end_pos": 62, "type": "METRIC", "confidence": 0.9400509595870972}, {"text": "segmentation", "start_pos": 86, "end_pos": 98, "type": "TASK", "confidence": 0.9556223750114441}, {"text": "Joint S&T", "start_pos": 123, "end_pos": 132, "type": "DATASET", "confidence": 0.6435826569795609}]}, {"text": "We also find that the perceptron model functions as the kernel of the outside-layer linear model.", "labels": [], "entities": []}, {"text": "Without the perceptron, the cascaded model (if we can still call it \"cascaded\") performs poorly on both segmentation and Joint S&T.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 104, "end_pos": 116, "type": "TASK", "confidence": 0.9833986759185791}, {"text": "Joint S&T", "start_pos": 121, "end_pos": 130, "type": "TASK", "confidence": 0.5725286826491356}]}, {"text": "Among other features, the 4-gram POS LM plays the most important role, removing this feature causes F-measure decrement of 0.33 points on segmentation and 0.71 points on Joint S&T.", "labels": [], "entities": [{"text": "F-measure decrement", "start_pos": 100, "end_pos": 119, "type": "METRIC", "confidence": 0.9235517978668213}, {"text": "segmentation", "start_pos": 138, "end_pos": 150, "type": "TASK", "confidence": 0.9734672904014587}, {"text": "Joint S&T", "start_pos": 170, "end_pos": 179, "type": "DATASET", "confidence": 0.7129396796226501}]}, {"text": "Another important feature is the labelling model.", "labels": [], "entities": []}, {"text": "Without it, the F-measure on segmentation and Joint S&T both suffer a decrement of 0.2 points.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9822416305541992}, {"text": "segmentation", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9836122393608093}, {"text": "Joint S&T", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.5423769056797028}]}, {"text": "The generating model, which functions as that in HMM, brings an improvement of about 0.1 points to each test item.", "labels": [], "entities": []}, {"text": "However unlike the three features, the word LM brings very tiny improvement.", "labels": [], "entities": []}, {"text": "We suppose that the character-based features used in the perceptron play a similar role as the lowerorder word LM, and it would be helpful if we train a higher-order word LM on a larger scale corpus.", "labels": [], "entities": []}, {"text": "Finally, the word count penalty gives improvement to the cascaded model, 0.13 points on segmentation and 0.16 points on Joint S&T.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 88, "end_pos": 100, "type": "TASK", "confidence": 0.977229118347168}, {"text": "Joint S&T", "start_pos": 120, "end_pos": 129, "type": "DATASET", "confidence": 0.7808190137147903}]}, {"text": "In summary, the cascaded model can utilize these knowledge sources effectively, without causing the feature space of the percptron becoming even larger.", "labels": [], "entities": []}, {"text": "Experimental results show that, it achieves obvious improvement over the perceptron-only model, about from 0.973 to 0.978 on segmentation, and from 0.925 to 0.934 on Joint S&T, with error reductions of 18.5% and 12% respectively.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 125, "end_pos": 137, "type": "TASK", "confidence": 0.9687151312828064}, {"text": "Joint S&T", "start_pos": 166, "end_pos": 175, "type": "DATASET", "confidence": 0.8177299648523331}, {"text": "error", "start_pos": 182, "end_pos": 187, "type": "METRIC", "confidence": 0.9877468347549438}]}], "tableCaptions": [{"text": " Table 2: F-measure on SIGHAN bakeoff 2. SIGHAN  best: best scores SIGHAN reported on the four corpus,  cited from Zhang and Clark (2007).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9912604689598083}]}, {"text": " Table 4: Contribution of each feture. ALL: all features,  PER: perceptron model, WLM: word language model,  PLM: POS language model, GPR: generating model,  LPR: labelling model, LEN: word count penalty.", "labels": [], "entities": [{"text": "ALL", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9134759902954102}, {"text": "LEN", "start_pos": 180, "end_pos": 183, "type": "METRIC", "confidence": 0.9821364283561707}]}]}