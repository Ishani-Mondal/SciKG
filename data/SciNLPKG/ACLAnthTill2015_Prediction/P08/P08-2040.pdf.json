{"title": [{"text": "Exploiting N-best Hypotheses for SMT Self-Enhancement", "labels": [], "entities": [{"text": "SMT Self-Enhancement", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8547492027282715}]}], "abstractContent": [{"text": "Word and n-gram posterior probabilities estimated on N-best hypotheses have been used to improve the performance of statistical machine translation (SMT) in a rescoring framework.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 116, "end_pos": 153, "type": "TASK", "confidence": 0.7991617371638616}]}, {"text": "In this paper, we extend the idea to estimate the posterior probabilities on N-best hypotheses for translation phrase-pairs, target language n-grams, and source word re-orderings.", "labels": [], "entities": []}, {"text": "The SMT system is self-enhanced with the posterior knowledge learned from N-best hypotheses in a re-decoding framework.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9911292791366577}]}, {"text": "Experiments on NIST Chinese-to-English task show performance improvements for all the strategies.", "labels": [], "entities": [{"text": "NIST Chinese-to-English task", "start_pos": 15, "end_pos": 43, "type": "DATASET", "confidence": 0.887521227200826}]}, {"text": "Moreover, the combination of the three strategies achieves further improvements and outperforms the baseline by 0.67 BLEU score on NIST-2003 set, and 0.64 on NIST-2005 set, respectively.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9850977063179016}, {"text": "NIST-2003 set", "start_pos": 131, "end_pos": 144, "type": "DATASET", "confidence": 0.9792517423629761}, {"text": "NIST-2005 set", "start_pos": 158, "end_pos": 171, "type": "DATASET", "confidence": 0.9835712313652039}]}], "introductionContent": [{"text": "State-of-the-art Statistical Machine Translation (SMT) systems usually adopt a two-pass search strategy.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.8183229764302572}]}, {"text": "In the first pass, a decoding algorithm is applied to generate an N-best list of translation hypotheses; while in the second pass, the final translation is selected by rescoring and re-ranking the N-best hypotheses through additional feature functions.", "labels": [], "entities": []}, {"text": "In this framework, the N-best hypotheses serve as the candidates for the final translation selection in the second pass.", "labels": [], "entities": [{"text": "translation selection", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.8750124573707581}]}, {"text": "These N-best hypotheses can also provide useful feedback to the MT system as the first decoding has discarded many undesirable translation candidates.", "labels": [], "entities": [{"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9639145135879517}]}, {"text": "Thus, the knowledge captured in the N-best hypotheses, such as posterior probabilities for words, n-grams, phrase-pairs, and source word reorderings, etc. is more compatible with the source sentences and thus could potentially be used to improve the translation performance.", "labels": [], "entities": []}, {"text": "Word posterior probabilities estimated from the N-best hypotheses have been widely used for confidence measure in automatic speech recognition) and have also been adopted into machine translation. and used word posterior probabilities to estimate the confidence of machine translation., reported performance improvements by computing target ngrams posterior probabilities estimated on the Nbest hypotheses in a rescoring framework.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 114, "end_pos": 142, "type": "TASK", "confidence": 0.6865918040275574}, {"text": "machine translation.", "start_pos": 176, "end_pos": 196, "type": "TASK", "confidence": 0.8084046244621277}, {"text": "machine translation.", "start_pos": 265, "end_pos": 285, "type": "TASK", "confidence": 0.7504504919052124}]}, {"text": "Transductive learning method ( which repeatedly re-trains the generated sourcetarget N-best hypotheses with the original training data again showed translation performance improvement and demonstrated that the translation model can be reinforced from N-best hypotheses.", "labels": [], "entities": []}, {"text": "In this paper, we further exploit the potential of the N-best hypotheses and propose several schemes to derive the posterior knowledge from the N-best hypotheses, in an effort to enhance the language model, translation model, and source word reordering under a re-decoding framework of any phrase-based SMT system.", "labels": [], "entities": [{"text": "source word reordering", "start_pos": 230, "end_pos": 252, "type": "TASK", "confidence": 0.6260523001352946}, {"text": "SMT", "start_pos": 303, "end_pos": 306, "type": "TASK", "confidence": 0.8574268221855164}]}], "datasetContent": [{"text": "Experiments on Chinese-to-English NIST translation tasks were carried out on the FBIS 1 corpus.", "labels": [], "entities": [{"text": "NIST translation tasks", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8307870427767435}, {"text": "FBIS 1 corpus", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9469591776529948}]}, {"text": "We used NIST 2002 MT evaluation test set as our development set, and the test sets as our test sets as shown in.", "labels": [], "entities": [{"text": "NIST 2002 MT evaluation test set", "start_pos": 8, "end_pos": 40, "type": "DATASET", "confidence": 0.9174015323321024}]}, {"text": "We determine the number of iteration empirically by setting it to 10.", "labels": [], "entities": []}, {"text": "We then observe the BLEU score on the development set for each iteration.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9781081974506378}]}, {"text": "The iteration number which achieved the best BLEU score on development set is selected as the iteration number of iterations for the test set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9774969518184662}]}, {"text": "Further experiments also suggested that, in this experiment scenario, setting the size of N-best list to 3,000 arrives at the greatest performance improvements.", "labels": [], "entities": []}, {"text": "Our evaluation metric is BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9988114833831787}]}, {"text": "The translation performance is reported in, where the column \"#iter.\" refers to the iteration number where the system achieved the best BLEU score on development set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 136, "end_pos": 146, "type": "METRIC", "confidence": 0.9718370139598846}]}, {"text": "Compared with the baseline (\"Base\" in), all three self-enhancement methods (\"TM\", \"LM\", and \"WR\" in) consistently improved the performance.", "labels": [], "entities": []}, {"text": "In general, absolute gains of 0.23-0.38 BLEU score were obtained for each method on two test sets.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9781644642353058}]}, {"text": "While comparing the performance among all three methods, we can see that they achieved very similar improvement.", "labels": [], "entities": []}, {"text": "Combining the three methods showed further gains in BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9543415009975433}]}, {"text": "Totally, the combined system outperformed the baseline by 0.67 BLEU score on NIST'03, and 0.64 on NIST'05 test set, respectively.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9825053215026855}, {"text": "NIST'03", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9760890603065491}, {"text": "NIST'05 test set", "start_pos": 98, "end_pos": 114, "type": "DATASET", "confidence": 0.9886631369590759}]}], "tableCaptions": [{"text": " Table 1: Statistics of training, dev and test sets. Evalua- tion sets of NIST campaigns include 4 references: total  numbers of running words are provided in the table.", "labels": [], "entities": []}, {"text": " Table 2: BLEU% scores of five systems: decoder (Base),  self-enhancement on translation model (TM), language  model (LM), word reordering (WR) and the combina- tion of TM, LM and WR (Comb).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9968302845954895}]}]}