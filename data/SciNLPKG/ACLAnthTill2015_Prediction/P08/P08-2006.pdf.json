{"title": [{"text": "Dialect Classification for online podcasts fusing Acoustic and Language based Structural and Semantic Information", "labels": [], "entities": [{"text": "Dialect Classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7939589023590088}]}], "abstractContent": [{"text": "The variation in speech due to dialect is a factor which significantly impacts speech system performance.", "labels": [], "entities": []}, {"text": "In this study, we investigate effective methods of combining acoustic and language information to take advantage of (i) speaker based acoustic traits as well as (ii) content based word selection across the text sequence.", "labels": [], "entities": []}, {"text": "For acoustics, a GMM based system is employed and for text based dialect classification, we proposed n-gram language models combined with Latent Semantic Analysis (LSA) based dialect classifiers.", "labels": [], "entities": [{"text": "text based dialect classification", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.6618046388030052}]}, {"text": "The performance of the individual classifiers is established for the three dialect family case (DC rates vary from 69.1%-72.4%).", "labels": [], "entities": [{"text": "DC rates", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.98007732629776}]}, {"text": "The final combined system achieved a DC accuracy of 79.5% and significantly outperforms the baseline acoustic classifier with a relative improvement of 30%, confirming that an integrated dialect classification system is effective for American, British and Australian dialects.", "labels": [], "entities": [{"text": "DC", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9989432692527771}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.6880713701248169}]}], "introductionContent": [{"text": "Automatic Dialect Classification has recently gained substantial interest in the speech processing community (.", "labels": [], "entities": [{"text": "Automatic Dialect Classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8024591207504272}]}, {"text": "Dialect classification systems have been employed to improve the performance for Automatic Speech Recognition (ASR) by employing dialect dependent acoustic and language models) and for Rich Indexing of Spoken Document Retrieval Systems(.) focused on identifying pronunciation differences for dialect classification.", "labels": [], "entities": [{"text": "Dialect classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7955043017864227}, {"text": "Automatic Speech Recognition (ASR)", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.8105284571647644}, {"text": "Rich Indexing of Spoken Document Retrieval", "start_pos": 185, "end_pos": 227, "type": "TASK", "confidence": 0.6872214625279108}, {"text": "dialect classification", "start_pos": 292, "end_pos": 314, "type": "TASK", "confidence": 0.743238776922226}]}, {"text": "In this study, unsupervised MFCC based GMM classifiers are employed for pronunciation modeling.", "labels": [], "entities": [{"text": "pronunciation modeling", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.9552203118801117}]}, {"text": "However, English dialects differ in many ways other than pronunciation like Word Selection and Grammar, which cannot be modeled using frame based GMM acoustic information.", "labels": [], "entities": [{"text": "Word Selection", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.7307663112878799}]}, {"text": "For example, This project was funded by AFRL under a subcontract to RADC Inc.", "labels": [], "entities": [{"text": "AFRL", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.9197205305099487}, {"text": "RADC Inc", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.9130605161190033}]}, {"text": "under FA8750-05-C-0029 word selection differences between UK and US dialects such as -\"lorry\" vs. \"truck\", \"lift\", vs. \"elevator\", etc.", "labels": [], "entities": []}, {"text": "Australian English has its own lexical terms such as tucker (food), outback (wilderness), etc.", "labels": [], "entities": []}, {"text": "N-gram language models are employed to address these problems.", "labels": [], "entities": []}, {"text": "One additional factor in which dialects differ is in Semantics.", "labels": [], "entities": []}, {"text": "For example, momentarily which means fora moments duration (UK) vs. in a minute or any minute now (US).", "labels": [], "entities": [{"text": "momentarily", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.9474321603775024}]}, {"text": "The sentence \"This flight will be leaving momentarily\" could represent different time duration in US vs. UK dialects.", "labels": [], "entities": []}, {"text": "Latent Semantic Analysis is a technique that can distinguish these differences (.", "labels": [], "entities": [{"text": "Latent Semantic Analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7070666352907816}]}, {"text": "LSA has been shown to be effective for NLP based problems but has yet to be applied for dialect classification.", "labels": [], "entities": [{"text": "dialect classification", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7548772096633911}]}, {"text": "Therefore, we develop an approach that uses a combination with ngram language modeling and LSA processing to achieve effective language based dialect classification accuracy.", "labels": [], "entities": [{"text": "language based dialect classification", "start_pos": 127, "end_pos": 164, "type": "TASK", "confidence": 0.6734171137213707}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.7238044142723083}]}, {"text": "Sec 4 explains the baseline acoustic classifier.", "labels": [], "entities": []}, {"text": "Language classifiers are described in Sec 5 and the results which are presented in Sec 6 affirm that combining various sources of information significantly outperforms the traditional (or individual) techniques used for dialect classification.", "labels": [], "entities": [{"text": "dialect classification", "start_pos": 220, "end_pos": 242, "type": "TASK", "confidence": 0.7250301241874695}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2 summarizes the acoustic content of the  corpus with 231 speakers and 13.5 hrs of audio.  No. of Hours  Dialect  Males Females  Train Test  US English  48  37  3.2  1.7  UK English  40  32  2.3  1  AU English  36  38  3.3  2  Table 2: Acoustic Statistics", "labels": [], "entities": [{"text": "US English  48  37  3.2  1.7  UK English  40", "start_pos": 148, "end_pos": 192, "type": "DATASET", "confidence": 0.7805633246898651}, {"text": "AU English  36  38  3.3", "start_pos": 206, "end_pos": 229, "type": "DATASET", "confidence": 0.8521424412727356}]}]}