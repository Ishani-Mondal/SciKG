{"title": [{"text": "In-Browser Summarisation: Generating Elaborative Summaries Biased Towards the Reading Context", "labels": [], "entities": [{"text": "In-Browser Summarisation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6113463193178177}, {"text": "Generating Elaborative Summaries Biased", "start_pos": 26, "end_pos": 65, "type": "TASK", "confidence": 0.7768176794052124}]}], "abstractContent": [{"text": "We investigate elaborative summarisation, where the aim is to identify supplementary information that expands upon a key fact.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.8053905963897705}]}, {"text": "We envisage such summaries being useful when browsing certain kinds of (hyper-)linked document sets, such as Wikipedia articles or repositories of publications linked by citations.", "labels": [], "entities": []}, {"text": "For these collections, an elaborative summary is intended to provide additional information on the linking anchor text.", "labels": [], "entities": []}, {"text": "Our contribution in this paper focuses on identifying and exploring areal task in which summarisa-tion is situated, realised as an In-Browser tool.", "labels": [], "entities": []}, {"text": "We also introduce a neighbourhood scoring heuristic as a means of scoring matches to relevant passages of the document.", "labels": [], "entities": []}, {"text": "Ina preliminary evaluation using this method, our sum-marisation system scores above our baselines and achieves a recall of 57% annotated gold standard sentences.", "labels": [], "entities": [{"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9995043277740479}]}], "introductionContent": [{"text": "It has long been held that a summary is useful, particularly if it supports the underlying task of the user -for an overview of summarisation scenarios see Spark.", "labels": [], "entities": []}, {"text": "For example, generic (that is, not query-specific) summaries, which are often indicative, providing just the gist of a document, are only useful if they happen to address the underlying need of the user.", "labels": [], "entities": []}, {"text": "Ina push to make summaries more responsive to user needs, the field of summarisation has explored the overlap with complex question-answering * Information and Communication Technologies Centre research to produce query-focused summaries.", "labels": [], "entities": [{"text": "summaries", "start_pos": 17, "end_pos": 26, "type": "TASK", "confidence": 0.971532940864563}, {"text": "summarisation", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.989000678062439}]}, {"text": "Such work includes the recent DUC challenges on queryfocused summarisation, 1 in which the user needs are represented by short paragraphs of text written by human judges.", "labels": [], "entities": [{"text": "DUC", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.5577385425567627}, {"text": "summarisation", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.7041972279548645}]}, {"text": "These are then used as input to the summarisation process.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.986710250377655}]}, {"text": "However, modelling user needs is a difficult task.", "labels": [], "entities": []}, {"text": "DUC descriptions of information needs are only an artificial stipulation of a user's interest.", "labels": [], "entities": [{"text": "DUC descriptions of information needs", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.773733651638031}]}, {"text": "In this work, we propose a tool built into an internet browser that makes use of a very simple heuristic for determining user interest.", "labels": [], "entities": []}, {"text": "The basic premise of the heuristic is that the text currently being read provides an approximation of the current user interest.", "labels": [], "entities": []}, {"text": "Specifically, as a user reads a sentence, it potentially represents a fine-grained information need.", "labels": [], "entities": []}, {"text": "We identify the sentence of interest without complex methods, relying instead on the user to move the mouse over the anchor text link to request a summary of the linked document, thus identifying to the browser plug-in which sentence is now in focus.", "labels": [], "entities": []}, {"text": "To generate the summary, the whole document, specifically the linking sentence that contains the anchor text, serves as the reading context, a potential indicator of the user interest.", "labels": [], "entities": []}, {"text": "An example of the current output on Wikipedia text is presented in.", "labels": [], "entities": []}, {"text": "It shows an elaborative summary of a document about the Space Shuttle Discovery expanding on the content of the linking sentence.", "labels": [], "entities": []}, {"text": "In this case, it gives further information about a spacewalk in which the shuttle was repaired inflight.", "labels": [], "entities": []}, {"text": "Our summarisation tool, the In-Browser Elabora- tive Summariser (IBES), complements generic summaries in providing additional information about a particular aspect of a page.", "labels": [], "entities": [{"text": "In-Browser Elabora- tive Summariser (IBES", "start_pos": 28, "end_pos": 69, "type": "TASK", "confidence": 0.6060060603278024}]}, {"text": "3 Generic summaries themselves are easy to generate due to rules enforced by the Wikipedia style-guide, which dictates that all titles be noun phrases describing an entity, thus serving as a short generic summary.", "labels": [], "entities": []}, {"text": "Furthermore, the first sentence of the article should contain the title in subject position, which tends to create sentences that define the main entity of the article.", "labels": [], "entities": []}, {"text": "For the elaborative summarisation scenario described, we are interested in exploring ways in which the reading context can be leveraged to produce the elaborative summary.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.7815966606140137}]}, {"text": "One method explored in this paper attempts to map the content of the linked document into the semantic space of the reading context, as defined in vector-space.", "labels": [], "entities": []}, {"text": "We use Singular Value Decomposition (SVD), the underlying method behind Latent Semantic Analysis, as a means of identifying latent topics in the reading context, against which we compare the linked document.", "labels": [], "entities": [{"text": "Singular Value Decomposition (SVD)", "start_pos": 7, "end_pos": 41, "type": "TASK", "confidence": 0.6918422480424246}, {"text": "Latent Semantic Analysis", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.6526049474875132}]}, {"text": "We present our system and the results from our preliminary investigation in the remainder of this paper.", "labels": [], "entities": []}, {"text": "3 http://www.ict.csiro.au/staff/stephen.wan/ibes/", "labels": [], "entities": []}], "datasetContent": [{"text": "In lieu of a user-centered experiment, our preliminary experiments evaluated the effectiveness of the tool in terms of finding justification material for an elaborative summary.", "labels": [], "entities": []}, {"text": "We evaluated the three systems described in Section 3.", "labels": [], "entities": []}, {"text": "Each system selected 5 sentences.", "labels": [], "entities": []}, {"text": "We tested against two baselines.", "labels": [], "entities": []}, {"text": "The first simply returns the first 5 sentences.", "labels": [], "entities": []}, {"text": "The second produces a generic summary based on, independently of the reading context.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Recall and Precision figures for all summarisers  without the first 5 sentences.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9906030893325806}, {"text": "Precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9968945980072021}]}]}