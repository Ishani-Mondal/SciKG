{"title": [{"text": "Four Techniques for Online Handling of Out-of-Vocabulary Words in Arabic-English Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.599394271771113}]}], "abstractContent": [{"text": "We present four techniques for online handling of Out-of-Vocabulary words in Phrase-based Statistical Machine Translation.", "labels": [], "entities": [{"text": "Phrase-based Statistical Machine Translation", "start_pos": 77, "end_pos": 121, "type": "TASK", "confidence": 0.6126834824681282}]}, {"text": "The techniques use spelling expansion, morphological expansion, dictionary term expansion and proper name transliteration to reuse or extend a phrase table.", "labels": [], "entities": [{"text": "spelling expansion", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7902253568172455}, {"text": "dictionary term expansion", "start_pos": 64, "end_pos": 89, "type": "TASK", "confidence": 0.6069521903991699}]}, {"text": "We compare the performance of these techniques and combine them.", "labels": [], "entities": []}, {"text": "Our results show a consistent improvement over a state-of-the-art baseline in terms of BLEU and a manual error analysis.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9993744492530823}]}], "introductionContent": [{"text": "We present four techniques for online handling of Out-of-Vocabulary (OOV) words in phrase-based Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "online handling of Out-of-Vocabulary (OOV) words in phrase-based Statistical Machine Translation (SMT)", "start_pos": 31, "end_pos": 133, "type": "TASK", "confidence": 0.6958875525742769}]}, {"text": "The techniques use morphological expansion (MORPHEX), spelling expansion (SPELLEX), dictionary word expansion (DICTEX) and proper name transliteration (TRANSEX) to reuse or extend phrase tables online.", "labels": [], "entities": [{"text": "spelling expansion", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.6963860243558884}, {"text": "dictionary word expansion", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.507783035437266}, {"text": "proper name transliteration (TRANSEX)", "start_pos": 123, "end_pos": 160, "type": "TASK", "confidence": 0.5633054872353872}]}, {"text": "We compare the performance of these techniques and combine them.", "labels": [], "entities": []}, {"text": "We work with a standard ArabicEnglish SMT system that has been already optimized for minimizing data sparsity through the use of morphological preprocessing and orthographic normalization.", "labels": [], "entities": [{"text": "SMT", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.520540714263916}]}, {"text": "Thus our baseline token OOV rate is rather low (average 2.89%).", "labels": [], "entities": [{"text": "baseline token OOV rate", "start_pos": 9, "end_pos": 32, "type": "METRIC", "confidence": 0.6359654814004898}]}, {"text": "None of our techniques are specific to Arabic and all can be retargeted to other languages given availability of techniquespecific resources.", "labels": [], "entities": []}, {"text": "Our results show that we improve over a state-of-the-art baseline by over 2.7% (relative BLEU score) and handle all OOV instances.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9790915548801422}]}, {"text": "An error analysis shows that, in 60% of the time, our OOV handling successfully produces acceptable output.", "labels": [], "entities": []}, {"text": "Additionally, we still improve in BLEU score even as we increase our system's training data by 10-fold.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9582369327545166}]}], "datasetContent": [{"text": "Experimental Setup All of our training data is available from the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 66, "end_pos": 98, "type": "DATASET", "confidence": 0.8563752273718516}]}, {"text": "For our basic system, we use an ArabicEnglish parallel corpus 5 consisting of 131K sentence pairs, with approximately 4.1M Arabic tokens and 4.4M English tokens.", "labels": [], "entities": [{"text": "ArabicEnglish parallel corpus 5", "start_pos": 32, "end_pos": 63, "type": "DATASET", "confidence": 0.8218097537755966}]}, {"text": "Word alignment is done with GIZA++ (. All evaluated systems use the same surface trigram language model, trained on approximately 340 million words from the English Gigaword corpus (LDC2003T05) using the SRILM toolkit).", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7320147305727005}, {"text": "English Gigaword corpus", "start_pos": 157, "end_pos": 180, "type": "DATASET", "confidence": 0.7873402635256449}]}, {"text": "We use the standard NIST MTEval data sets for the.", "labels": [], "entities": [{"text": "NIST MTEval data sets", "start_pos": 20, "end_pos": 41, "type": "DATASET", "confidence": 0.8715663403272629}]}, {"text": "We report results in terms of case-insensitive 4-gram BLEU () scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9711657166481018}]}, {"text": "The first 200 sentences in the 2002 MTEval test set were used for Minimum Error Training (MERT).", "labels": [], "entities": [{"text": "MTEval test set", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.8034611543019613}, {"text": "Minimum Error Training (MERT)", "start_pos": 66, "end_pos": 95, "type": "TASK", "confidence": 0.6728511353333791}]}, {"text": "We decode using Pharaoh).", "labels": [], "entities": []}, {"text": "We tokenize using the MADA morphological disambiguation system, and TOKAN, a general Arabic tokenizer).", "labels": [], "entities": [{"text": "MADA morphological disambiguation", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.5824983716011047}, {"text": "TOKAN", "start_pos": 68, "end_pos": 73, "type": "METRIC", "confidence": 0.7269779443740845}]}, {"text": "English preprocessing simply included down-casing, separating punctuation from words and splitting off \"'s\".", "labels": [], "entities": []}, {"text": "To see how well our approach scales up, we added over 40M words (1.6M sentences) to our training data using primarily the UN corpus (LDC2004E13).", "labels": [], "entities": [{"text": "UN corpus (LDC2004E13)", "start_pos": 122, "end_pos": 144, "type": "DATASET", "confidence": 0.8903803348541259}]}, {"text": "As expected, the token OOV rates dropped from an average of 2.89% in our baseline to 0.98% in the scaled-up system.", "labels": [], "entities": [{"text": "OOV", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.7307954430580139}]}, {"text": "Our average baseline BLEU score went up from 42.60 to 45.00.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9517351984977722}]}, {"text": "However, using the ALL combination, we still increase the scaled-up system's score to an average BLEU of 45.28 (0.61% relative).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9996335506439209}]}, {"text": "The increase was seen on all data sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: OOV Rates (%) and BLEU Results of Using  Different OOV Handling Techniques", "labels": [], "entities": [{"text": "OOV Rates", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9055618047714233}, {"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9997110962867737}]}]}