{"title": [{"text": "A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model", "labels": [], "entities": [{"text": "String-to-Dependency Machine Translation Algorithm", "start_pos": 6, "end_pos": 56, "type": "TASK", "confidence": 0.7435071468353271}]}], "abstractContent": [{"text": "In this paper, we propose a novel string-to-dependency algorithm for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.7614216605822245}]}, {"text": "With this new framework, we employ a target dependency language model during decoding to exploit long distance word relations, which are unavailable with a traditional n-gram language model.", "labels": [], "entities": []}, {"text": "Our experiments show that the string-to-dependency decoder achieves 1.48 point improvement in BLEU and 2.53 point improvement in TER compared to a standard hierarchical string-to-string system on the NIST 04 Chinese-English evaluation set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.9993370175361633}, {"text": "TER", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.9987157583236694}, {"text": "NIST 04 Chinese-English evaluation set", "start_pos": 200, "end_pos": 238, "type": "DATASET", "confidence": 0.9591535091400146}]}], "introductionContent": [{"text": "In recent years, hierarchical methods have been successfully applied to Statistical Machine Translation ().", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 72, "end_pos": 103, "type": "TASK", "confidence": 0.8651500145594279}]}, {"text": "In some language pairs, i.e. Chinese-to-English translation, state-ofthe-art hierarchical systems show significant advantage over phrasal systems in MT accuracy.", "labels": [], "entities": [{"text": "MT", "start_pos": 149, "end_pos": 151, "type": "TASK", "confidence": 0.9937410950660706}, {"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.8454158902168274}]}, {"text": "For example, showed that the Hiero system achieved about 1 to 3 point improvement in BLEU on the NIST 03/04/05 Chinese-English evaluation sets compared to a start-of-the-art phrasal system.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.7573023438453674}, {"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9995587468147278}, {"text": "NIST 03/04/05 Chinese-English evaluation sets", "start_pos": 97, "end_pos": 142, "type": "DATASET", "confidence": 0.961306631565094}]}, {"text": "Our work extends the hierarchical MT approach.", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.944705605506897}]}, {"text": "We propose a string-to-dependency model for MT, which employs rules that represent the source side as strings and the target side as dependency structures.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.982362687587738}]}, {"text": "We restrict the target side to the so called wellformed dependency structures, in order to cover a large set of non-constituent transfer rules ( ), and enable efficient decoding through dynamic programming.", "labels": [], "entities": []}, {"text": "We incorporate a dependency language model during decoding, in order to exploit long-distance word relations which are unavailable with a traditional n-gram language model on target strings.", "labels": [], "entities": []}, {"text": "For comparison purposes, we replicated the Hiero decoder) as our baseline.", "labels": [], "entities": [{"text": "Hiero decoder)", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.944655199845632}]}, {"text": "Our stringto-dependency decoder shows 1.48 point improvement in BLEU and 2.53 point improvement in TER on the NIST 04 Chinese-English MT evaluation set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9988272786140442}, {"text": "TER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9985887408256531}, {"text": "NIST 04 Chinese-English MT evaluation set", "start_pos": 110, "end_pos": 151, "type": "DATASET", "confidence": 0.8943309585253397}]}, {"text": "In the rest of this section, we will briefly discuss previous work on hierarchical MT and dependency representations, which motivated our research.", "labels": [], "entities": [{"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.9292353391647339}]}, {"text": "In section 2, we introduce the model of string-to-dependency decoding.", "labels": [], "entities": []}, {"text": "Section 3 illustrates of the use of dependency language models.", "labels": [], "entities": []}, {"text": "In section 4, we describe the implementation details of our MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.976150631904602}]}, {"text": "We discuss experimental results in section 5, compare to related work in section 6, and draw conclusions in section 7.", "labels": [], "entities": []}, {"text": "proposed the use of targettree-to-source-string transducers (xRS) to model translation.", "labels": [], "entities": []}, {"text": "In xRS rules, the right-hand-side(rhs) of the target side is a tree with non-terminals(NTs), while the rhs of the source side is a string with NTs.", "labels": [], "entities": []}, {"text": "extended this string-to-tree model by using Context-Free parse trees to represent the target side.", "labels": [], "entities": []}, {"text": "A tree could represent multi-level transfer rules.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out experiments on three models.", "labels": [], "entities": []}, {"text": "\u2022 baseline: replication of the Hiero system.", "labels": [], "entities": [{"text": "baseline", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.9513583779335022}, {"text": "Hiero system", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9404141008853912}]}, {"text": "\u2022 filtered: a string-to-string MT system as in baseline.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9609694480895996}]}, {"text": "However, we only keep the transfer rules whose target side can be generated by a well-formed dependency structure.", "labels": [], "entities": []}, {"text": "\u2022 str-dep: a string-to-dependency system with a dependency LM.", "labels": [], "entities": []}, {"text": "We take the replicated Hiero system as our baseline because it is the closest to our string-todependency model.", "labels": [], "entities": [{"text": "Hiero system", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.8787851929664612}]}, {"text": "They have similar rule extraction and decoding algorithms.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7758858799934387}]}, {"text": "Both systems use only one non-terminal label in rules.", "labels": [], "entities": []}, {"text": "The major difference is in the representation of target structures.", "labels": [], "entities": []}, {"text": "We use dependency structures instead of strings; thus, the comparison will show the contribution of using dependency information in decoding.", "labels": [], "entities": []}, {"text": "All models are tuned on BLEU (, and evaluated on both BLEU and Translation Error Rate (TER)) so that we could detect over-tuning on one metric.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9987126588821411}, {"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9988344311714172}, {"text": "Translation Error Rate (TER))", "start_pos": 63, "end_pos": 92, "type": "METRIC", "confidence": 0.9684853057066599}]}, {"text": "We used part of the NIST 2006 ChineseEnglish large track data as well as some LDC corpora collected for the DARPA GALE program (LDC2005E83, LDC2006E34 and LDC2006G05) as our bilingual training data.", "labels": [], "entities": [{"text": "NIST 2006 ChineseEnglish large track data", "start_pos": 20, "end_pos": 61, "type": "DATASET", "confidence": 0.9406307140986124}, {"text": "DARPA GALE program", "start_pos": 108, "end_pos": 126, "type": "DATASET", "confidence": 0.8434270222981771}]}, {"text": "It contains about 178M/191M words in source/target.", "labels": [], "entities": []}, {"text": "Hierarchical rules were extracted from a subset which has about 35M/41M words 5 , and the rest of the training data were used to extract phrasal rules as in).", "labels": [], "entities": []}, {"text": "The English side of this subset was also used to train a 3-gram dependency LM.", "labels": [], "entities": []}, {"text": "Traditional 3-gram and 5-gram LMs were trained on a corpus of 6G words composed of the LDC Gigaword corpus and text downloaded from Web ( shows the number of transfer rules extracted from the training data for the tuning and test sets.", "labels": [], "entities": [{"text": "LDC Gigaword corpus", "start_pos": 87, "end_pos": 106, "type": "DATASET", "confidence": 0.6788828174273173}]}, {"text": "The constraint of well-formed dependency structures greatly reduced the size of the rule set.", "labels": [], "entities": []}, {"text": "Although the rule size increased a little bit after incorporating dependency structures in rules, the size of string-to-dependency rule set is less than 20% of the baseline rule set size.", "labels": [], "entities": []}, {"text": "shows the BLEU and TER scores on MT04.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992994070053101}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9973189234733582}, {"text": "MT04", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.9435985684394836}]}, {"text": "On decoding output, the string-todependency system achieved 1.48 point improvement in BLEU and 2.53 point improvement in TER compared to the baseline hierarchical stringto-string system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9992194175720215}, {"text": "TER", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9980740547180176}]}, {"text": "After 5-gram rescoring, it achieved 1.21 point improvement in BLEU and 1.19 improvement in TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9995711445808411}, {"text": "TER", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9986914992332458}]}, {"text": "The filtered model does not show improvement on BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9900164008140564}]}, {"text": "The filtered string-to-string rules can be viewed the string projection of stringto-dependency rules.", "labels": [], "entities": []}, {"text": "It means that just using dependency structure does not provide an improvement on performance.", "labels": [], "entities": []}, {"text": "However, dependency structures allow the use of a dependency LM which gives rise to significant improvement.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of transfer rules", "labels": [], "entities": []}, {"text": " Table 2: BLEU and TER scores on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995095729827881}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9994350075721741}]}]}