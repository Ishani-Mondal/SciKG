{"title": [{"text": "Measure Word Generation for English-Chinese SMT Systems", "labels": [], "entities": [{"text": "Measure Word Generation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7192605336507162}, {"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.8660880327224731}]}], "abstractContent": [{"text": "Measure words in Chinese are used to indicate the count of nouns.", "labels": [], "entities": []}, {"text": "Conventional statistical machine translation (SMT) systems do not perform well on measure word generation due to data sparseness and the potential long distance dependency between measure words and their corresponding head words.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.800059994061788}, {"text": "measure word generation", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.721197267373403}]}, {"text": "In this paper, we propose a statistical model to generate appropriate measure words of nouns for an English-to-Chinese SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9226004481315613}]}, {"text": "We model the probability of measure word generation by utilizing lexical and syntactic knowledge from both source and target sentences.", "labels": [], "entities": [{"text": "measure word generation", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.6742536822954813}]}, {"text": "Our model works as a post-processing procedure over output of statistical machine translation systems, and can work with any SMT system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6222995420296987}, {"text": "SMT", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9850848317146301}]}, {"text": "Experimental results show our method can achieve high precision and recall in measure word generation.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.999001681804657}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9992436170578003}, {"text": "measure word generation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.6356384952863058}]}], "introductionContent": [{"text": "In linguistics, measure words (MW) are words or morphemes used in combination with numerals or demonstrative pronouns to indicate the count of nouns 1 , which are often referred to as head words (HW).", "labels": [], "entities": []}, {"text": "Chinese measure words are grammatical units and occur quite often in real text.", "labels": [], "entities": []}, {"text": "According to our survey on the measure word distribution in the Chinese Penn Treebank and the test datasets distributed by Linguistic Data Consortium (LDC) for Chinese-to-English machine translation evaluation, the average occurrence is 0.505 and 0.319 measure The uncommon cases of verbs are not considered.", "labels": [], "entities": [{"text": "Chinese Penn Treebank", "start_pos": 64, "end_pos": 85, "type": "DATASET", "confidence": 0.9403424263000488}, {"text": "Chinese-to-English machine translation evaluation", "start_pos": 160, "end_pos": 209, "type": "TASK", "confidence": 0.7088402509689331}]}, {"text": "Unlike in Chinese, there is no special set of measure words in English.", "labels": [], "entities": []}, {"text": "Measure words are usually used for mass nouns and any semantically appropriate nouns can function as the measure words.", "labels": [], "entities": []}, {"text": "For example, in the phrase three bottles of water, the word bottles acts as a measure word.", "labels": [], "entities": []}, {"text": "Countable nouns are almost never modified by measure words 2 . Numerals and indefinite articles are directly followed by countable nouns to denote the quantity of objects.", "labels": [], "entities": []}, {"text": "Therefore, in the English-to-Chinese machine translation task we need to take additional efforts to generate the missing measure words in Chinese.", "labels": [], "entities": [{"text": "English-to-Chinese machine translation", "start_pos": 18, "end_pos": 56, "type": "TASK", "confidence": 0.5989904900391897}]}, {"text": "For example, when translating the English phrase three books into the Chinese phrases \"\u4e09\u672c\u4e66\", where three corresponds to the numeral \"\u4e09\" and books corresponds to the noun \"\u4e66\", the Chinese measure word \"\u672c\" should be generated between the numeral and the noun.", "labels": [], "entities": []}, {"text": "In most statistical machine translation (SMT) models), some of measure words can be generated without modification or additional processing.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.7757300088802973}]}, {"text": "For example, in above translation, the phrase translation table may suggest the word three be translated into \"\u4e09\", \"\u4e09\u672c\", \"\u4e09\u53ea\", etc, and the word books into \"\u4e66\", \"\u4e66\u672c\", \"\u540d\u518c\" (scroll), etc.", "labels": [], "entities": []}, {"text": "Then the SMT model selects the most likely combination \"\u4e09\u672c\u4e66\" as the final translation result.", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9677478671073914}]}, {"text": "In this example, a measure word candidate set consisting of \"\u672c\" and \"\u53ea\" can be generated by bilingual phrases (or synchronous translation rules), and the best measure word \"\u672c\" from the measure word candidate set can be selected by the SMT decoder.", "labels": [], "entities": [{"text": "SMT decoder", "start_pos": 235, "end_pos": 246, "type": "TASK", "confidence": 0.73606276512146}]}, {"text": "However, as we will show below, existing SMT systems do not deal well with the measure word generation in general due to data sparseness and long distance dependencies between measure words and their corresponding head words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9900816082954407}, {"text": "measure word generation", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.6440229415893555}]}, {"text": "Due to the limited size of bilingual corpora, many measure words, as well as the collocations between a measure and its headword, cannot be well covered by the phrase translation table in an SMT system.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.7053342312574387}, {"text": "SMT", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.9848403334617615}]}, {"text": "Moreover, Chinese measure words often have along distance dependency to their head words which makes language model ineffective in selecting the correct measure words from the measure word candidate set.", "labels": [], "entities": []}, {"text": "For example, in the distance between the measure word \"\u9879\" and its headword \"\u5de5\u7a0b\" (undertaking) is 15.", "labels": [], "entities": []}, {"text": "In this case, an n-gram language model with n<15 cannot capture the MW-HW collocation.", "labels": [], "entities": []}, {"text": "shows the relative position's distribution of head words around measure words in the Chinese Penn Treebank, where a negative position indicates that the headword is to the left of the measure word and a positive position indicates that the headword is to the right of the measure word.", "labels": [], "entities": [{"text": "Chinese Penn Treebank", "start_pos": 85, "end_pos": 106, "type": "DATASET", "confidence": 0.8988591432571411}]}, {"text": "Although lots of measure words are close to the head words they modify, more than sixteen percent of measure words are faraway from their corresponding head words (the absolute distance is more than 5).", "labels": [], "entities": []}, {"text": "To overcome the disadvantage of measure word generation in a general SMT system, this paper proposes a dedicated statistical model to generate measure words for English-to-Chinese translation.", "labels": [], "entities": [{"text": "measure word generation", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.6784543494383494}, {"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9907324314117432}]}, {"text": "We model the probability of measure word generation by utilizing rich lexical and syntactic knowledge from both source and target sentences.", "labels": [], "entities": [{"text": "measure word generation", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.6950783928235372}]}, {"text": "Three steps are involved in our method to generate measure words: Identifying the positions to generate measure words, collecting the measure word candidate set and selecting the best measure word.", "labels": [], "entities": []}, {"text": "Our method is performed as a post-processing procedure of the output of SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.987619161605835}]}, {"text": "The advantage is that it can be easily integrated into any SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9890650510787964}]}, {"text": "Experimental results show our method can significantly improve the quality of measure word generation.", "labels": [], "entities": [{"text": "measure word generation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.6005034744739532}]}, {"text": "We also compared the performance of our model based on different contextual information, and show that both large-scale monolingual data and parallel bilingual data can be helpful to generate correct measure words.", "labels": [], "entities": []}, {"text": "In Chinese, measure words are obligatory in certain contexts, and the choice of measure word usually depends on the head word's semantics (e.g., shape or material).", "labels": [], "entities": []}, {"text": "The set of Chinese measure words is a relatively close set and can be classified into two categories based on whether they have a corresponding English translation.", "labels": [], "entities": []}, {"text": "Those not having an English counterpart need to be generated during translation.", "labels": [], "entities": []}, {"text": "For those having English translations, such as \"\u7c73\" (meter), \"\u5428\" (ton), we just use the translation produced by the SMT system itself.", "labels": [], "entities": [{"text": "SMT", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9623299241065979}]}, {"text": "According to our survey, about 70.4% of measure words in the Chinese Penn Treebank need In Chinese, there are generally stable linguistic collocations between measure words and their head words.", "labels": [], "entities": [{"text": "Chinese Penn Treebank", "start_pos": 61, "end_pos": 82, "type": "DATASET", "confidence": 0.8769428133964539}]}, {"text": "Once the headword is determined, the collocated measure word can usually be selected accordingly.", "labels": [], "entities": []}, {"text": "However, there is no easy way to identify head words in target Chinese sentences since for most of the time an SMT output is not a well formed sentence due to translation errors.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 111, "end_pos": 121, "type": "TASK", "confidence": 0.8760140836238861}]}, {"text": "Mistake of headword identification may cause low quality of measure word generation.", "labels": [], "entities": [{"text": "headword identification", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.9225659966468811}, {"text": "quality of measure word generation", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.6815928936004638}]}, {"text": "In addition, sometimes the headword itself is not enough to determine the measure word.", "labels": [], "entities": []}, {"text": "For example, in Chinese sentences \"\u4ed6\u5bb6\u6709 5 \u53e3\u4eba\" (there are five people in his family) and \"\u603b\u5171\u6709 5 \u4e2a\u4eba\u53c2\u52a0\u4e86\u4f1a\u8bae\" (a total of five people attended the meeting), where \"\u4eba\" (people) is the headword collocated with two different measure words \"\u53e3\" and \"\u4e2a\", we cannot determine the measure word just based on the headword \"\u4eba\".", "labels": [], "entities": []}], "datasetContent": [{"text": "Wsize Baseline Mo-ME Bi-ME Co-ME 6 54.82%.", "labels": [], "entities": []}, {"text": "Recall over SMT output We can see that the Bi-ME model can achieve better results than the Mo-ME model in both recall and precision metrics although only a small sized bilingual corpus is used for Bi-ME model training.", "labels": [], "entities": [{"text": "SMT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9919760823249817}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9978564381599426}, {"text": "precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.9625527858734131}]}, {"text": "The reason is that the Mo-ME model cannot correctly handle the cases where head words are located outside the target window.", "labels": [], "entities": []}, {"text": "However, due to word order differences between English and Chinese, when target head words are outside the target window, their corresponding source head words might be within the source window.", "labels": [], "entities": []}, {"text": "The capacity of capturing head words is improved when both source and target windows are used, which demonstrates that bilingual knowledge is useful for measure word generation.", "labels": [], "entities": [{"text": "measure word generation", "start_pos": 153, "end_pos": 176, "type": "TASK", "confidence": 0.7581832011540731}]}, {"text": "We compare the results for each model with different window sizes.", "labels": [], "entities": []}, {"text": "Larger window size can lead to better results as shown in since more contextual knowledge is used to model measure word generation.", "labels": [], "entities": [{"text": "word generation", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.6852910220623016}]}, {"text": "However, enlarging the window size does not bring significant improvements, The major reason is that even a small window size is already able to cover most of measure word collocations, as indicated by the position distribution of head words in.", "labels": [], "entities": []}, {"text": "The quality of the SMT output also affects the quality of measure word generation since our method is performed in a post-processing step over the SMT output.", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9875613451004028}, {"text": "measure word generation", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.6861325403054556}, {"text": "SMT", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.9403133988380432}]}, {"text": "Although translation errors degrade the measure word generation accuracy, we achieve about 15% improvement in precision and a 10% increase in recall over baseline.", "labels": [], "entities": [{"text": "word generation", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.6684858649969101}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9419153928756714}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9996170997619629}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9995162487030029}]}, {"text": "We notice that the recall is relatively lower.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9991177916526794}]}, {"text": "Part of the reason is some positions to generate measure words are not successfully identified due to translation errors.", "labels": [], "entities": []}, {"text": "In addition to precision and recall, we also evaluate the Bleu score () changes before and after applying our measure word generation method to the SMT output.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9996417760848999}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9995017051696777}, {"text": "Bleu score", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9813610911369324}, {"text": "SMT", "start_pos": 148, "end_pos": 151, "type": "TASK", "confidence": 0.986240804195404}]}, {"text": "For our test data, we only consider sentences containing measure words for Bleu score evaluation.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.68039470911026}]}, {"text": "Our measure word generation step leads to a Bleu score improvement of 0.32 where the window size is set to 10, which shows that it can improve the translation quality of an English-to-Chinese SMT system.", "labels": [], "entities": [{"text": "word generation", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.6726677268743515}, {"text": "Bleu score", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9823367297649384}, {"text": "SMT", "start_pos": 192, "end_pos": 195, "type": "TASK", "confidence": 0.9126619100570679}]}, {"text": "To isolate the impact of the translation errors in SMT output on the performance of our measure word generation model, we conducted another experiment with reference bilingual sentences in which measure words in Chinese sentences are manually removed.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.9007822573184967}, {"text": "measure word generation", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.6943389972050985}]}, {"text": "This experiment can show the performance upper bound of our method without interference from an SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9767230153083801}]}, {"text": "Compared to the results in, the precision improvement in the Mo-ME model is larger than that in the Bi-ME model, which shows that noisy translation of the SMT system has more serious influence on the Mo-ME model than the Bi-ME model.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9996088147163391}, {"text": "SMT", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9768620133399963}]}, {"text": "This also indicates that source information without noises is helpful for measure word generation.", "labels": [], "entities": [{"text": "measure word generation", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7510353724161783}]}], "tableCaptions": [{"text": " Table 1. Position distribution of head words", "labels": [], "entities": []}, {"text": " Table 3. Precision over SMT output", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9334149956703186}, {"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9837700128555298}]}, {"text": " Table 4. Recall over SMT output", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9634239077568054}]}, {"text": " Table 5. Results over reference data", "labels": [], "entities": []}, {"text": " Table 6. Feature contribution in Mo-ME model", "labels": [], "entities": []}, {"text": " Table 7. Feature contribution in Bi-ME model", "labels": [], "entities": []}, {"text": " Table 8.  Most errors are caused by failures in finding posi- tions to generate measure words. The main reason  for this is some hint information used to identify  measure word positions is missing in the noisy  output of SMT systems. Two kinds of errors are  introduced by incomplete head word and MW-HW  collocation coverage, which can be solved by en- larging the size of training corpus. There are also  head word selection errors due to incorrect syntax  parsing.", "labels": [], "entities": [{"text": "SMT", "start_pos": 223, "end_pos": 226, "type": "TASK", "confidence": 0.974565327167511}, {"text": "head word selection", "start_pos": 409, "end_pos": 428, "type": "TASK", "confidence": 0.6493820945421854}, {"text": "syntax  parsing", "start_pos": 453, "end_pos": 468, "type": "TASK", "confidence": 0.7518474757671356}]}]}