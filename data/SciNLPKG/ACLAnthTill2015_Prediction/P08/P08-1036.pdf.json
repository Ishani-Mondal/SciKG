{"title": [{"text": "A Joint Model of Text and Aspect Ratings for Sentiment Summarization", "labels": [], "entities": [{"text": "Sentiment Summarization", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.9697382152080536}]}], "abstractContent": [{"text": "Online reviews are often accompanied with numerical ratings provided by users fora set of service or product aspects.", "labels": [], "entities": []}, {"text": "We propose a statistical model which is able to discover corresponding topics in text and extract tex-tual evidence from reviews supporting each of these aspect ratings-a fundamental problem in aspect-based sentiment summarization (Hu and Liu, 2004a).", "labels": [], "entities": [{"text": "aspect-based sentiment summarization", "start_pos": 194, "end_pos": 230, "type": "TASK", "confidence": 0.6699180006980896}]}, {"text": "Our model achieves high accuracy , without any explicitly labeled data except the user provided opinion ratings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9994040727615356}]}, {"text": "The proposed approach is general and can be used for segmentation in other applications where sequential data is accompanied with correlated signals.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 53, "end_pos": 65, "type": "TASK", "confidence": 0.982071578502655}]}], "introductionContent": [{"text": "User generated content represents a unique source of information in which user interface tools have facilitated the creation of an abundance of labeled content, e.g., topics in blogs, numerical product and service ratings in user reviews, and helpfulness rankings in online discussion forums.", "labels": [], "entities": []}, {"text": "Many previous studies on user generated content have attempted to predict these labels automatically from the associated text.", "labels": [], "entities": []}, {"text": "However, these labels are often present in the data already, which opens another interesting line of research: designing models leveraging these labelings to improve a wide variety of applications.", "labels": [], "entities": []}, {"text": "In this study, we look at the problem of aspectbased sentiment summarization (Hu and Nikos' Fine Dining Food 4/5 \"Best fish in the city\", \"Excellent appetizers\" Decor 3/5 \"Cozy with an old world feel\", \"Too dark\" Service 1/5 \"Our waitress was rude\", \"Awful service\" Value 5/5 \"Good Greek food for the $\", \"Great price!\" Figure 1: An example aspect-based summary.).", "labels": [], "entities": []}, {"text": "An aspect-based summarization system takes as input a set of user reviews fora specific product or service and produces a set of relevant aspects, the aggregated sentiment for each aspect, and supporting textual evidence.", "labels": [], "entities": []}, {"text": "For example, figure 1 summarizes a restaurant using aspects food, decor, service, and value plus a numeric rating out of 5.", "labels": [], "entities": []}, {"text": "Standard aspect-based summarization consists of two problems.", "labels": [], "entities": [{"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.6507339477539062}]}, {"text": "The first is aspect identification and mention extraction.", "labels": [], "entities": [{"text": "aspect identification", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.9391570687294006}, {"text": "mention extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7601131796836853}]}, {"text": "Here the goal is to find the set of relevant aspects fora rated entity and extract all textual mentions that are associated with each.", "labels": [], "entities": []}, {"text": "Aspects can be fine-grained, e.g., fish, lamb, calamari, or coarse-grained, e.g., food, decor, service.", "labels": [], "entities": []}, {"text": "Similarly, extracted text can range from a single word to phrases and sentences.", "labels": [], "entities": []}, {"text": "The second problem is sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.9742177426815033}]}, {"text": "Once all the relevant aspects and associated pieces of texts are extracted, the system should aggregate sentiment over each aspect to provide the user with an average numeric or symbolic rating.", "labels": [], "entities": []}, {"text": "Sentiment classification is a well studied problem) and in many domains users explicitly Food: 5; Decor: 5; Service: 5; Value: 5 The chicken was great.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9070150554180145}]}, {"text": "On top of that our service was excellent and the price was right.", "labels": [], "entities": []}, {"text": "Can't wait to go back!", "labels": [], "entities": []}, {"text": "Food: 2; Decor: 1; Service: 3; Value: 2 We went therefor our anniversary.", "labels": [], "entities": [{"text": "Value", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9798842668533325}]}, {"text": "My soup was cold and expensive plus it felt like they hadn't painted since 1980.", "labels": [], "entities": []}, {"text": "Food: 3; Decor: 5; Service: 4; Value: 5 The food is only mediocre, but well worth the cost.", "labels": [], "entities": [{"text": "Value", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9933164119720459}]}, {"text": "Lot's of fun decorations.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present qualitative and quantitative experiments.", "labels": [], "entities": []}, {"text": "For the qualitative analysis we show that topics inferred by the MAS model correspond directly to the associated aspects.", "labels": [], "entities": []}, {"text": "For the quantitative analysis we show that the MAS model induces a distribution over the rated aspects which can be used to accurately predict whether a text fragment is relevant to an aspect or not.", "labels": [], "entities": [{"text": "MAS", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.6391667723655701}]}, {"text": "To perform qualitative experiments we used a set of reviews of hotels taken from TripAdvisor.com 7 that contained 10,000 reviews (109,024 sentences, 2,145,313 words in total).", "labels": [], "entities": [{"text": "TripAdvisor.com 7", "start_pos": 81, "end_pos": 98, "type": "DATASET", "confidence": 0.88025763630867}]}, {"text": "Every review was rated with at least three aspects: service, location and rooms.", "labels": [], "entities": []}, {"text": "Each rating is an integer from 1 to 5.", "labels": [], "entities": []}, {"text": "The dataset was tokenized and sentence split automatically.", "labels": [], "entities": []}, {"text": "We ran the sampling chain for 700 iterations to produce a sample.", "labels": [], "entities": []}, {"text": "Distributions of words in each topic were estimated as the proportion of words assigned to each topic, taking into account topic model priors \u03b2 gland \u03b2 loc . The sliding windows were chosen to cover 3 sentences for all the experiments.", "labels": [], "entities": []}, {"text": "All the priors were chosen to be equal to 0.1.", "labels": [], "entities": []}, {"text": "We used 15 local topics and 30 global topics.", "labels": [], "entities": []}, {"text": "In the model, the first three local topics were associated to the rating classifiers for each aspects.", "labels": [], "entities": []}, {"text": "As a result, we would expect these topics to correspond to the service, location, and rooms aspects respectively.", "labels": [], "entities": []}, {"text": "Unigram and bigram features were used in the sentiment predictors in the MAS model.", "labels": [], "entities": [{"text": "sentiment predictors", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.9421497285366058}]}, {"text": "Before applying the topic models we removed punctuation and also removed stop words using the standard list of stop words, 8 however, all the words and punctuation were used in the sentiment predictors.", "labels": [], "entities": [{"text": "sentiment predictors", "start_pos": 181, "end_pos": 201, "type": "TASK", "confidence": 0.7925355434417725}]}, {"text": "It does not take many chain iterations to discover initial topics.", "labels": [], "entities": []}, {"text": "This happens considerably faster than the appropriate weights of the sentiment predictor being learned.", "labels": [], "entities": [{"text": "sentiment predictor", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8300400972366333}]}, {"text": "This poses a problem, because, in the beginning, the sentiment predictors are not accurate enough to force the model to discover appropriate topics associated with each of the rated aspects.", "labels": [], "entities": [{"text": "sentiment predictors", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.8035175800323486}]}, {"text": "And as soon as topic are formed, aspect sentiment predictors cannot affect them anymore because they do not 8 http://www.dcs.gla.ac.uk/idom/ir resources/linguistic utils/ stop words have access to the true words associated with their aspects.", "labels": [], "entities": [{"text": "aspect sentiment predictors", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.6993029018243154}]}, {"text": "To combat this problem we first train the sentiment classifiers by assuming that pa f,r,z is equal for all the local topics, which effectively ignores the topic model.", "labels": [], "entities": []}, {"text": "Then we use the estimated parameters within the topic model.", "labels": [], "entities": []}, {"text": "Secondly, we modify the sampling algorithm.", "labels": [], "entities": []}, {"text": "The conditional probability used in sampling, expression (2), is proportional to the product of two factors.", "labels": [], "entities": []}, {"text": "The first factor, \u03b7 d,i v,r,z , expresses a preference for topics likely from the co-occurrence information, whereas the second one, \u03c1 d,i r,z , favors the choice of topics which are predictive of the observable sentiment ratings.", "labels": [], "entities": []}, {"text": "We used (\u03c1 d,i r,z ) 1+0.95 t q in the sampling distribution instead of \u03c1 d,i r,z , where t is the iteration number.", "labels": [], "entities": []}, {"text": "q was chosen to be 4, though the quality of the topics seemed to be indistinguishable with any q between 3 and 10.", "labels": [], "entities": []}, {"text": "This can bethought of as having 1 + 0.95 t q ratings instead of a single vector assigned to each review, i.e., focusing the model on prediction of the ratings rather than finding the topic labels which are good at explaining co-occurrences of words.", "labels": [], "entities": []}, {"text": "These heuristics influence sampling only during the first iterations of the chain.", "labels": [], "entities": []}, {"text": "Top words for some of discovered local topics, in- cluding the first 3 topics associated with the rated aspects, and also top words for some of global topics are presented in.", "labels": [], "entities": []}, {"text": "We can see that the model discovered as its first three topics the correct associated aspects: service, location, and rooms.", "labels": [], "entities": []}, {"text": "Other local topics, as for the MG-LDA model, correspond to other aspects discussed in reviews (breakfast, prices, noise), and as it was previously shown in, aspects for global topics correspond to the types of reviewed items (hotels in Russia, Paris hotels) or background words.", "labels": [], "entities": []}, {"text": "Notice though, that the 3rd local topic induced for the rating rooms is slightly narrow.", "labels": [], "entities": []}, {"text": "This can be explained by the fact that the aspect rooms is a central aspect of hotel reviews.", "labels": [], "entities": []}, {"text": "Avery significant fraction of text in every review can bethought of as apart of the aspect rooms.", "labels": [], "entities": []}, {"text": "These portions of reviews discuss different coherent sub-aspects related to the aspect rooms, e.g., the previously discovered topic noise.", "labels": [], "entities": []}, {"text": "Therefore, it is natural to associate several topics to such central aspects.", "labels": [], "entities": []}, {"text": "To test this we varied the number of topics associated with the sentiment predictor for the aspect rooms.", "labels": [], "entities": []}, {"text": "Top words for resulting topics are presented in.", "labels": [], "entities": []}, {"text": "It can be observed that the topic model discovered appropriate topics while the number of topics was below 4.", "labels": [], "entities": []}, {"text": "With 4 topics a semantically unrelated topic (check-in/arrival) is induced.", "labels": [], "entities": []}, {"text": "Manual selection of the number of topics is undesirable, but this problem can be potentially tackled with Dirichlet Process priors or a topic split criterion based on the accuracy of the sentiment predictor in the MAS model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9893856048583984}]}, {"text": "We found that both service and location did not benefit by the assignment of additional topics to their sentiment rating models.", "labels": [], "entities": []}, {"text": "The experimental results suggest that the MAS model is reliable in the discovery of topics corresponding to the rated aspects.", "labels": [], "entities": [{"text": "MAS", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.5297701358795166}]}, {"text": "In the next section we will show that the induced topics can be used to accurately extract fragments for each aspect.", "labels": [], "entities": []}], "tableCaptions": []}