{"title": [{"text": "A Subcategorization Acquisition System for French Verbs", "labels": [], "entities": [{"text": "Subcategorization Acquisition", "start_pos": 2, "end_pos": 31, "type": "TASK", "confidence": 0.8747155964374542}, {"text": "French Verbs", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.81696617603302}]}], "abstractContent": [{"text": "This paper presents a system capable of automatically acquiring subcategorization frames (SCFs) for French verbs from the analysis of large corpora.", "labels": [], "entities": []}, {"text": "We applied the system to a large newspaper corpus (consisting of 10 years of the French newspaper 'Le Monde') and acquired subcategorization information for 3267 verbs.", "labels": [], "entities": [{"text": "French newspaper 'Le Monde')", "start_pos": 81, "end_pos": 109, "type": "DATASET", "confidence": 0.8891712923844656}]}, {"text": "The system learned 286 SCF types for these verbs.", "labels": [], "entities": []}, {"text": "From the analysis of 25 representative verbs, we obtained 0.82 precision, 0.59 recall and 0.69 F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9982131719589233}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9949017763137817}, {"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9950118064880371}]}, {"text": "These results are comparable with those reported in recent related work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many Natural Language Processing (NLP) tasks require comprehensive lexical resources.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 5, "end_pos": 38, "type": "TASK", "confidence": 0.7229647040367126}]}, {"text": "Handcrafting large lexicons is labour-intensive and errorprone.", "labels": [], "entities": []}, {"text": "A growing body of research focuses therefore on automatic acquisition of lexical resources from text corpora.", "labels": [], "entities": [{"text": "automatic acquisition of lexical resources from text corpora", "start_pos": 48, "end_pos": 108, "type": "TASK", "confidence": 0.8129348158836365}]}, {"text": "One useful type of lexical information for NLP is the number and type of the arguments of predicates.", "labels": [], "entities": []}, {"text": "These are typically expressed in simple syntactic frames called subcategorization frames (SCFs).", "labels": [], "entities": []}, {"text": "SCFs can be useful for many NLP applications, such as parsing or information extraction (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9833340048789978}, {"text": "information extraction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.821806401014328}]}, {"text": "Automatic acquisition of SCFs has therfore been an active research area since the mid-90s.", "labels": [], "entities": [{"text": "Automatic acquisition of SCFs", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8327927440404892}]}, {"text": "Comprehensive subcategorization information is currently not available for most languages.", "labels": [], "entities": []}, {"text": "French is one of these languages: although manually built syntax dictionaries do exist) none of them are ideal for computational use and none also provide frequency information important for statistical NLP.", "labels": [], "entities": []}, {"text": "We developed ASSCI, a system capable of extracting large subcategorization lexicons for French verbs from raw corpus data.", "labels": [], "entities": [{"text": "ASSCI", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.626394510269165}]}, {"text": "Our system is based on a approach similar to that of the well-known Cambridge subcategorization acquisition system for English).", "labels": [], "entities": []}, {"text": "The main difference is that unlike the Cambridge system, our system does not employ a set of predefined SCF types, but learns the latter dynamically from corpus data.", "labels": [], "entities": [{"text": "Cambridge", "start_pos": 39, "end_pos": 48, "type": "DATASET", "confidence": 0.9501941204071045}]}, {"text": "We have recently used ASSCI to acquire LexSchem -a large subcategorization lexicon for French verbs -from a raw journalistic corpus. and have made the resulting resource freely available to the community on the web ( . We describe our SCF acquisition system in section 2 and explain the acquisition of a large subcategorization lexicon for French and its evaluation in section 3.", "labels": [], "entities": []}, {"text": "We finally compare our study with work previously achieved for English and French in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We calculated type precision, type recall and Fmeasure for these 25 verbs.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9156736135482788}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9283207654953003}, {"text": "Fmeasure", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9995666146278381}]}, {"text": "We obtain the best results (0.822 precision, 0.587 recall and 0.685 fmeasure) with the MLE threshold of 0.032 (see fig- shows that even by substantially lowering recall we cannot raise precision over 0.85.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9959080219268799}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9942069053649902}, {"text": "fmeasure", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9771999716758728}, {"text": "MLE threshold", "start_pos": 87, "end_pos": 100, "type": "METRIC", "confidence": 0.9762809872627258}, {"text": "recall", "start_pos": 162, "end_pos": 168, "type": "METRIC", "confidence": 0.9972471594810486}, {"text": "precision", "start_pos": 185, "end_pos": 194, "type": "METRIC", "confidence": 0.998497486114502}]}, {"text": "shows a comparison of three versions of ASSCI for our 25 verbs: \u2022 Unfiltered: the unfiltered output of ASSCI; \u2022 ASSCI-1: one single threshold fixed to 0.0325; \u2022 ASSCI-2: one INTRANS-specific threshold (0.08) and the 0.0325-threshold for all other cases.", "labels": [], "entities": []}, {"text": "These results reveal that the unfiltered version of the lexicon is very noisy indeed (0.01 precision).", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9903486967086792}]}], "tableCaptions": [{"text": " Table 1: Comparison of different versions of ASSCI", "labels": [], "entities": [{"text": "ASSCI", "start_pos": 46, "end_pos": 51, "type": "TASK", "confidence": 0.7197582721710205}]}]}