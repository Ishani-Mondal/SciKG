{"title": [{"text": "BART: A Modular Toolkit for Coreference Resolution", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8727493286132812}, {"text": "Coreference Resolution", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.9705399870872498}]}], "abstractContent": [{"text": "Developing a full coreference system able to run all the way from raw text to semantic interpretation is a considerable engineering effort, yet there is very limited availability of off-the shelf tools for researchers whose interests are not in coreference, or for researchers who want to concentrate on a specific aspect of the problem.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7469468712806702}]}, {"text": "We present BART, a highly modular toolkit for developing coreference applications.", "labels": [], "entities": [{"text": "BART", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.8314443826675415}]}, {"text": "In the Johns Hopkins workshop on using lexical and encyclopedic knowledge for entity dis-ambiguation, the toolkit was used to extend a reimplementation of the Soon et al.", "labels": [], "entities": [{"text": "entity dis-ambiguation", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7185575067996979}]}, {"text": "(2001) proposal with a variety of additional syntactic and knowledge-based features, and experiment with alternative resolution processes , preprocessing tools, and classifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9037902653217316}]}, {"text": "Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction, question answering) and summarization.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.7946381866931915}, {"text": "question answering", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.8935880661010742}, {"text": "summarization", "start_pos": 148, "end_pos": 161, "type": "TASK", "confidence": 0.9920603036880493}]}, {"text": "Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g.; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be.", "labels": [], "entities": [{"text": "summarization or question answering", "start_pos": 326, "end_pos": 361, "type": "TASK", "confidence": 0.6797211468219757}]}, {"text": "We believe that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for researchers interested in coreference resolution, as well as provide a component that can be easily integrated into other NLP applications.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 146, "end_pos": 168, "type": "TASK", "confidence": 0.9298663437366486}]}, {"text": "A number of systems that perform coreference resolution are publicly available, such as GUITAR (, which handles the full coreference task, and JAVARAP (), which only resolves pronouns.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.9392894506454468}, {"text": "GUITAR", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.7125906944274902}, {"text": "JAVARAP", "start_pos": 143, "end_pos": 150, "type": "DATASET", "confidence": 0.6063117980957031}]}, {"text": "However, literature on coreference resolution, if providing a baseline, usually uses the algorithm and feature set of for this purpose.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.9679110944271088}]}, {"text": "Using the built-in maximum entropy learner with feature combination, BART reaches 65.8% F-measure on MUC6 and 62.9% F-measure on MUC7 using Soon et al.'s features, outperforming JAVARAP on pronoun resolution, as well as the.", "labels": [], "entities": [{"text": "BART", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.8727741837501526}, {"text": "F-measure", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9980835914611816}, {"text": "MUC6", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.947922945022583}, {"text": "F-measure", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9963393211364746}, {"text": "MUC7", "start_pos": 129, "end_pos": 133, "type": "DATASET", "confidence": 0.9458218216896057}, {"text": "JAVARAP", "start_pos": 178, "end_pos": 185, "type": "DATASET", "confidence": 0.5687638521194458}, {"text": "pronoun resolution", "start_pos": 189, "end_pos": 207, "type": "TASK", "confidence": 0.7010412216186523}]}, {"text": "Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf.), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in preparation), BART reaches state-of-the-art results on ACE-2.", "labels": [], "entities": [{"text": "BART", "start_pos": 306, "end_pos": 310, "type": "TASK", "confidence": 0.9134078621864319}]}, {"text": "compares our results, obtained using this extended feature set, with results from.", "labels": [], "entities": []}, {"text": "Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as.", "labels": [], "entities": [{"text": "Pronoun resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7519093751907349}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.999672532081604}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance on ACE-2 corpora, basic vs. extended feature set", "labels": [], "entities": []}]}