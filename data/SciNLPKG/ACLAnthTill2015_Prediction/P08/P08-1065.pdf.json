{"title": [{"text": "Automatic Syllabification with Structured SVMs for Letter-To-Phoneme Conversion", "labels": [], "entities": [{"text": "Letter-To-Phoneme Conversion", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.703090637922287}]}], "abstractContent": [{"text": "We present the first English syllabification system to improve the accuracy of letter-to-phoneme conversion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9990646243095398}, {"text": "letter-to-phoneme conversion", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.7226561009883881}]}, {"text": "We propose a novel dis-criminative approach to automatic syllabifica-tion based on structured SVMs.", "labels": [], "entities": []}, {"text": "In comparison with a state-of-the-art syllabification system, we reduce the syllabification word error rate for English by 33%.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 92, "end_pos": 107, "type": "METRIC", "confidence": 0.6311832765738169}]}, {"text": "Our approach also performs well on other languages, comparing favorably with published results on German and Dutch.", "labels": [], "entities": []}], "introductionContent": [{"text": "Pronouncing an unfamiliar word is a task that is often accomplished by breaking the word down into smaller components.", "labels": [], "entities": []}, {"text": "Even small children learning to read are taught to pronounce a word by \"sounding out\" its parts.", "labels": [], "entities": []}, {"text": "Thus, it is not surprising that Letter-to-Phoneme (L2P) systems, which convert orthographic forms of words into sequences of phonemes, can benefit from subdividing the input word into smaller parts, such as syllables or morphemes.", "labels": [], "entities": []}, {"text": "report that incorporating oracle syllable boundary information improves the accuracy of their L2P system, but they fail to emulate that result with any of their automatic syllabification methods., on the other hand, find that morphological segmentation boosts L2P performance in German, but not in English.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9992632269859314}, {"text": "morphological segmentation", "start_pos": 226, "end_pos": 252, "type": "TASK", "confidence": 0.7289821207523346}]}, {"text": "To our knowledge, no previous English orthographic syllabification system has been able to actually improve performance on the larger L2P problem.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the task of automatic orthographic syllabification, with the explicit goal of improving L2P accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9622421860694885}]}, {"text": "A syllable is a subdivision of a word, typically consisting of a vowel, called the nucleus, and the consonants preceding and following the vowel, called the onset and the coda, respectively.", "labels": [], "entities": []}, {"text": "Although in the strict linguistic sense syllables are phonological rather than orthographic entities, our L2P objective constrains the input to orthographic forms.", "labels": [], "entities": []}, {"text": "Syllabification of phonemic representation is in fact an easier task, which we plan to address in a separate publication.", "labels": [], "entities": [{"text": "phonemic representation", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.7281981408596039}]}, {"text": "Orthographic syllabification is sometimes referred to as hyphenation.", "labels": [], "entities": []}, {"text": "Many dictionaries provide hyphenation information for orthographic word forms.", "labels": [], "entities": []}, {"text": "These hyphenation schemes are related to, and influenced by, phonemic syllabification.", "labels": [], "entities": []}, {"text": "They serve two purposes: to indicate where words maybe broken for end-of-line divisions, and to assist the dictionary reader with correct pronunciation.", "labels": [], "entities": []}, {"text": "Although these purposes are not always consistent with our objective, we show that we can improve L2P conversion by taking advantage of the available hyphenation data.", "labels": [], "entities": [{"text": "L2P conversion", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.6141507476568222}]}, {"text": "In addition, automatic hyphenation is a legitimate task by itself, which could be utilized in word editors or in synthesizing new trade names from several concepts.", "labels": [], "entities": [{"text": "word editors", "start_pos": 94, "end_pos": 106, "type": "TASK", "confidence": 0.7373433113098145}]}, {"text": "We present a discriminative approach to orthographic syllabification.", "labels": [], "entities": []}, {"text": "We formulate syllabification as a tagging problem, and learn a discriminative tagger from labeled data using a structured support vector machine (SVM) ().", "labels": [], "entities": []}, {"text": "With this approach, we reduce the error rate for English by 33%, relative to the best existing system.", "labels": [], "entities": [{"text": "error rate", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9899417161941528}]}, {"text": "Moreover, we are also able to improve a state-of-theart L2P system by incorporating our syllabification models.", "labels": [], "entities": []}, {"text": "Our method is not language specific; when applied to German and Dutch, our performance is comparable with the best existing systems in those languages, even though our system has been developed and tuned on English only.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "After discussing previous computational approaches to the problem (Section 2), we introduce structured SVMs (Section 3), and outline how we apply them to orthographic syllabification (Section 4).", "labels": [], "entities": []}, {"text": "We present our experiments and results for the syllabification task in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we apply our syllabification models to the L2P task.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will discuss the results of our best emission feature set (five-gram features with a context window of eleven letters) on held-out unseen test sets.", "labels": [], "entities": []}, {"text": "We explore several different languages and datasets, and perform a brief error analysis.", "labels": [], "entities": []}, {"text": "Datasets are especially important in syllabification tasks.", "labels": [], "entities": []}, {"text": "Dictionaries sometimes disagree on the syllabification of certain words, which makes a gold standard difficult to obtain.", "labels": [], "entities": []}, {"text": "Thus, any reported accuracy is only with respect to a given set of data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9579164981842041}]}, {"text": "In this paper, we report the results of experiments on two datasets: CELEX and NETtalk.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 69, "end_pos": 74, "type": "DATASET", "confidence": 0.9537057876586914}, {"text": "NETtalk", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.860994279384613}]}, {"text": "We focus mainly on CELEX, which has been developed over a period of years by linguists in the Netherlands.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.893612265586853}]}, {"text": "CELEX contains English, German, and Dutch words, and their orthographic syllabifications.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9677157402038574}]}, {"text": "We removed all duplicates and multipleword entries for our experiments.", "labels": [], "entities": []}, {"text": "The NETtalk dictionary was originally developed with the L2P task in mind.", "labels": [], "entities": []}, {"text": "The syllabification data in NETtalk was created manually in the phoneme domain, and then mapped directly to the letter domain.", "labels": [], "entities": []}, {"text": "NETtalk and CELEX do not provide the same syllabification for every word.", "labels": [], "entities": [{"text": "NETtalk", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9706577658653259}, {"text": "CELEX", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.9443163871765137}]}, {"text": "There are numerous instances where the two datasets differ in a perfectly reasonable manner (e.g. for-ging in NETtalk vs. forg-ing in CELEX).", "labels": [], "entities": [{"text": "CELEX", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.922463059425354}]}, {"text": "However, we argue that NETtalk is a vastly inferior dataset.", "labels": [], "entities": []}, {"text": "On a sample of 50 words, NETtalk agrees with Merriam-Webster's syllabifications in only 54% of instances, while CELEX agrees in 94% of cases.", "labels": [], "entities": []}, {"text": "Moreover, NETtalk is riddled with truly bizarre syllabifications, such as be-aver, dis-hcloth and som-ething.", "labels": [], "entities": []}, {"text": "These syllabifications make generalization very hard, and are likely to complicate the L2P task we ultimately want to accomplish.", "labels": [], "entities": [{"text": "generalization", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9846634864807129}]}, {"text": "Because previous work in English primarily used NETtalk, we report our results on both datasets.", "labels": [], "entities": []}, {"text": "Nevertheless, we believe NETtalk is unsuitable for building a syllabification model, and that results on CELEX are much more indicative of the efficacy of our (or any other) approach.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.9142852425575256}]}, {"text": "At 20K words, NETtalk is much smaller than CELEX.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.940452516078949}]}, {"text": "For NETtalk, we randomly divide the data into 13K training examples and 7K test words.", "labels": [], "entities": []}, {"text": "We randomly select a comparably-sized training set for our CELEX experiments (14K), but test on a much larger, 25K set.", "labels": [], "entities": [{"text": "CELEX experiments", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.911920040845871}]}, {"text": "Recall that 5K training examples were held out as a development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Syllabification performance in terms of word ac- curacy and syllable break error percentage.", "labels": [], "entities": [{"text": "word ac- curacy", "start_pos": 50, "end_pos": 65, "type": "METRIC", "confidence": 0.7442461773753166}, {"text": "syllable break error percentage", "start_pos": 70, "end_pos": 101, "type": "METRIC", "confidence": 0.7997742146253586}]}, {"text": " Table 2: Syllabification performance in terms of word ac- curacy percentage.", "labels": [], "entities": [{"text": "word ac- curacy percentage", "start_pos": 50, "end_pos": 76, "type": "METRIC", "confidence": 0.7798977792263031}]}, {"text": " Table 3: Word accuracy percentage on the letter-to- phoneme task with and without the syllabification infor- mation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9246397018432617}]}]}