{"title": [{"text": "Learning Semantic Links from a Corpus of Parallel Temporal and Causal Relations", "labels": [], "entities": [{"text": "Learning Semantic Links from a Corpus of Parallel Temporal and Causal Relations", "start_pos": 0, "end_pos": 79, "type": "TASK", "confidence": 0.5818700467546781}]}], "abstractContent": [{"text": "Finding temporal and causal relations is crucial to understanding the semantic structure of a text.", "labels": [], "entities": []}, {"text": "Since existing corpora provide no parallel temporal and causal annotations, we annotated 1000 conjoined event pairs, achieving inter-annotator agreement of 81.2% on temporal relations and 77.8% on causal relations.", "labels": [], "entities": [{"text": "agreement", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.7123339772224426}]}, {"text": "We trained machine learning models using features derived from WordNet and the Google N-gram corpus, and they out-performed a variety of baselines, achieving an F-measure of 49.0 for temporals and 52.4 for causals.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.943621039390564}, {"text": "F-measure", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9989049434661865}]}, {"text": "Analysis of these models suggests that additional data will improve performance , and that temporal information is crucial to causal relation identification.", "labels": [], "entities": [{"text": "causal relation identification", "start_pos": 126, "end_pos": 156, "type": "TASK", "confidence": 0.7334187030792236}]}], "introductionContent": [{"text": "Working out how events are tied together temporally and causally is a crucial component for successful natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 103, "end_pos": 133, "type": "TASK", "confidence": 0.6604869564374288}]}, {"text": "Consider the text: (1) I ate a bad tuna sandwich, got food poisoning and had to have a shot in my shoulder.", "labels": [], "entities": []}, {"text": "wsj 0409 To understand the semantic structure here, a system must order events along a timeline, recognizing that getting food poisoning occurred BEFORE having a shot.", "labels": [], "entities": []}, {"text": "The system must also identify when an event is not independent of the surrounding events, e.g. got food poisoning was CAUSED by eating a bad sandwich.", "labels": [], "entities": [{"text": "CAUSED", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.934344470500946}]}, {"text": "Recognizing these temporal and causal relations is crucial for applications like question answering which must face queries like How did he get food poisoning? or What was the treatment?", "labels": [], "entities": [{"text": "question answering", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8588006794452667}]}, {"text": "Currently, no existing resource has all the necessary pieces for investigating parallel temporal and causal phenomena.", "labels": [], "entities": []}, {"text": "The TimeBank () links events with BEFORE and AFTER relations, but includes no causal links.", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9937831163406372}]}, {"text": "PropBank) identifies ARGM-TMP and ARGM-CAU relations, but arguments may only be temporal or causal, never both.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9510214328765869}]}, {"text": "Thus existing corpora are missing some crucial pieces for studying temporal-causal interactions.", "labels": [], "entities": []}, {"text": "Our research aims to fill these gaps by building a corpus of parallel temporal and causal relations and exploring machine learning approaches to extracting these relations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Contents of the corpus and its train/test sections", "labels": [], "entities": []}, {"text": " Table 2: Inter-annotator agreement by task.", "labels": [], "entities": []}, {"text": " Table 3: Performance of the temporal relation identifica- tion models: (A)ccuracy, (P)recision, (R)ecall and (F1)- measure. The null label is NO-REL.", "labels": [], "entities": [{"text": "F1)- measure", "start_pos": 111, "end_pos": 123, "type": "METRIC", "confidence": 0.9556548396746317}]}]}