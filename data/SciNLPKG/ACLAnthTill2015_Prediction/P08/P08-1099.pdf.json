{"title": [{"text": "Generalized Expectation Criteria for Semi-Supervised Learning of Conditional Random Fields", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a semi-supervised training method for linear-chain conditional random fields that makes use of labeled features rather than labeled instances.", "labels": [], "entities": []}, {"text": "This is accomplished by using generalized expectation criteria to express a preference for parameter settings in which the model's distribution on un-labeled data matches a target distribution.", "labels": [], "entities": []}, {"text": "We induce target conditional probability distributions of labels given features from both annotated feature occurrences in context and ad-hoc feature majority label assignment.", "labels": [], "entities": []}, {"text": "The use of generalized expectation criteria allows fora dramatic reduction in annotation time by shifting from traditional instance-labeling to feature-labeling, and the methods presented outperform traditional CRF training and other semi-supervised methods when limited human effort is available.", "labels": [], "entities": []}], "introductionContent": [{"text": "A significant barrier to applying machine learning to new real world domains is the cost of obtaining the necessary training data.", "labels": [], "entities": []}, {"text": "To address this problem, work over the past several years has explored semi-supervised or unsupervised approaches to the same problems, seeking to improve accuracy with the addition of lower cost unlabeled data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9983639121055603}]}, {"text": "Traditional approaches to semi-supervised learning are applied to cases in which there is a small amount of fully labeled data and a much larger amount of unlabeled data, presumably from the same data source.", "labels": [], "entities": []}, {"text": "For example, EM), transductive SVMs, entropy regularization (, and graph-based  methods () have all been applied to a limited amount of fully labeled data in conjunction with unlabeled data to improve the accuracy of a classifier.", "labels": [], "entities": [{"text": "entropy regularization", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.691893145442009}, {"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9970594048500061}]}, {"text": "In this paper, we explore an alternative approach in which, instead of fully labeled instances, the learner has access to labeled features.", "labels": [], "entities": []}, {"text": "These features can often be labeled at a lower-cost to the human annotator than labeling entire instances, which may require annotating the multiple sub-parts of a sequence structure or tree.", "labels": [], "entities": []}, {"text": "Features can be labeled either by specifying the majority label fora particular feature or by annotating a few occurrences of a particular feature in context with the correct label (.", "labels": [], "entities": []}, {"text": "To train models using this information we use generalized expectation (GE) criteria.", "labels": [], "entities": [{"text": "generalized expectation (GE)", "start_pos": 46, "end_pos": 74, "type": "METRIC", "confidence": 0.7991856694221496}]}, {"text": "GE criteria are terms in a training objective function that assign scores to values of a model expectation.", "labels": [], "entities": []}, {"text": "In particular we use aversion of GE that prefers parameter settings in which certain model expectations are close to target distributions.", "labels": [], "entities": [{"text": "GE", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.5543879270553589}]}, {"text": "Previous work has shown how to apply GE criteria to maximum entropy classifiers.", "labels": [], "entities": []}, {"text": "In section 4, we extend GE criteria to semi-supervised learning of linear-chain conditional random fields, using conditional probability distributions of labels given features.", "labels": [], "entities": []}, {"text": "To empirically evaluate this method we compare it with several competing methods for CRF training, including entropy regularization and expected gradient, showing that GE provides significant improvements.", "labels": [], "entities": [{"text": "CRF training", "start_pos": 85, "end_pos": 97, "type": "TASK", "confidence": 0.902961939573288}]}, {"text": "We achieve competitive performance in comparison to alternate model families, in particular generative models such as MRFs trained with EM () and HMMs trained with soft constraints (.", "labels": [], "entities": []}, {"text": "Finally, in Section 5.3 we show that feature-labeling can lead to dramatic reductions in the annotation time that is required in order to achieve the same level of accuracy as traditional instance-labeling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9956287145614624}]}], "datasetContent": [{"text": "We use the CLASSIFIEDS data provided by and compare with results reported by HK06 () and CRR07 ().", "labels": [], "entities": [{"text": "CLASSIFIEDS data", "start_pos": 11, "end_pos": 27, "type": "DATASET", "confidence": 0.7686721682548523}, {"text": "HK06", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.9763650298118591}, {"text": "CRR07", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.9570558667182922}]}, {"text": "HK06 introduced a set of 33 features along with their majority labels, these are the primary set of additional constraints.", "labels": [], "entities": [{"text": "HK06", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9732715487480164}]}, {"text": "As HK06 notes, these features are selected using statistics of the labeled data, and here we used similar features herein order to compare with previous results.", "labels": [], "entities": [{"text": "HK06", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.9769207835197449}]}, {"text": "Though in practice we have found that feature selection is often intuitive, recent work has experimented with automatic feature selection using LDA ().", "labels": [], "entities": [{"text": "feature selection", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7254242897033691}]}, {"text": "For some of the experiments we also use two sets of 33 additional features that we chose by the same method as HK06, the first 33 of which are also shown in.", "labels": [], "entities": [{"text": "HK06", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.9415508508682251}]}, {"text": "We use the same tokenization of the dataset as HK06, and training/test/unsupervised sets of 100 instances each.", "labels": [], "entities": [{"text": "HK06", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.9793950915336609}]}, {"text": "This data differs slightly from the tokenization used by CRR07.", "labels": [], "entities": [{"text": "CRR07", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.9799302816390991}]}, {"text": "In particular it lacks the newline breaks which might be a useful piece of information.", "labels": [], "entities": []}, {"text": "There are three types of supervised/semisupervised data used in the experiments.", "labels": [], "entities": []}, {"text": "Labeled instances are the traditional or conventionally  labeled instances used for estimation in traditional CRF training.", "labels": [], "entities": [{"text": "estimation", "start_pos": 84, "end_pos": 94, "type": "TASK", "confidence": 0.973924458026886}]}, {"text": "Majority labeled features are features annotated with their majority label.", "labels": [], "entities": []}, {"text": "Labeled features are features m where the distribution p(y i |f m (x, i)) has been specified.", "labels": [], "entities": []}, {"text": "In Section 5.3 we estimate these distributions from isolated labeled tokens.", "labels": [], "entities": []}, {"text": "We evaluate the system in two scenarios: (1) with feature constraints alone and (2) feature constraints in conjunction with a minimal amount of labeled instances.", "labels": [], "entities": []}, {"text": "There is little prior work that demonstrates the use of both scenarios; CRR07 can only be applied when there is some labeled data, while HK06 could be applied in both scenarios though there are no such published experiments.", "labels": [], "entities": [{"text": "CRR07", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.5301226377487183}, {"text": "HK06", "start_pos": 137, "end_pos": 141, "type": "DATASET", "confidence": 0.9201163649559021}]}], "tableCaptions": [{"text": " Table 1: Features and their associated majority label.  Features for each label were chosen by the method de- scribed in HK06 -top frequency for that label and not  higher frequency for any other label.", "labels": [], "entities": [{"text": "HK06", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.7407297492027283}]}, {"text": " Table 2: Accuracy of semi-supervised learning methods  with majority labeled features alone. GE outperforms  HK06 when neither model has access to SVD features.  When SVD features are included, HK06 has an edge in  accuracy.", "labels": [], "entities": [{"text": "GE", "start_pos": 94, "end_pos": 96, "type": "DATASET", "confidence": 0.770737886428833}, {"text": "HK06", "start_pos": 110, "end_pos": 114, "type": "DATASET", "confidence": 0.8887413144111633}, {"text": "HK06", "start_pos": 195, "end_pos": 199, "type": "DATASET", "confidence": 0.8325155973434448}, {"text": "accuracy", "start_pos": 216, "end_pos": 224, "type": "METRIC", "confidence": 0.9986995458602905}]}, {"text": " Table 3: Accuracy of semi-supervised learning meth- ods with constraints and limited amounts of training  data. Even though CRR07 uses more constraints and re- quires additional development data for estimating mix- ture weights, GE still outperforms CRR07 when that sys- tem is run without applying constraints during inference.  When these constraints are applied during test-time infer- ence, CRR07 has an edge over the CRF trained with GE  criteria.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy of semi-supervised learning methods  comparing the effects of (1) a heuristic for setting con- ditional distributions of labels given features and (2) es- timating this distributions via human annotation. When  GE is given feature distributions are better than the sim- ple heuristic it is able to realize considerable gains.", "labels": [], "entities": []}]}