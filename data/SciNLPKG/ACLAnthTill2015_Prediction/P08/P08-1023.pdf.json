{"title": [], "abstractContent": [{"text": "Among syntax-based translation models, the tree-based approach, which takes as input a parse tree of the source sentence, is a promising direction being faster and simpler than its string-based counterpart.", "labels": [], "entities": []}, {"text": "However, current tree-based systems suffer from a major drawback: they only use the 1-best parse to direct the translation, which potentially introduces translation mistakes due to parsing errors.", "labels": [], "entities": []}, {"text": "We propose a forest-based approach that translates a packed forest of exponentially many parses, which encodes many more alternatives than standard n-best lists.", "labels": [], "entities": []}, {"text": "Large-scale experiments show an absolute improvement of 1.7 BLEU points over the 1-best baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9983924031257629}]}, {"text": "This result is also 0.8 points higher than decoding with 30-best parses, and takes even less time.", "labels": [], "entities": []}], "introductionContent": [{"text": "Syntax-based machine translation has witnessed promising improvements in recent years.", "labels": [], "entities": [{"text": "Syntax-based machine translation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6350672245025635}]}, {"text": "Depending on the type of input, these efforts can be divided into two broad categories: the string-based systems whose input is a string to be simultaneously parsed and translated by asynchronous grammar (), and the tree-based systems whose input is already a parse tree to be directly converted into a target tree or string;).", "labels": [], "entities": []}, {"text": "Compared with their string-based counterparts, treebased systems offer some attractive features: they are much faster in decoding (linear time vs. cubic time, see )), do not require a binary-branching grammar as in string-based models (), and can have separate grammars for parsing and translation, say, a context-free grammar for the former and a tree substitution grammar for the latter ( ).", "labels": [], "entities": [{"text": "parsing and translation", "start_pos": 274, "end_pos": 297, "type": "TASK", "confidence": 0.6233007510503134}]}, {"text": "However, despite these advantages, current tree-based systems suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors).", "labels": [], "entities": []}, {"text": "This situation becomes worse with resource-poor source languages without enough Treebank data to train a high-accuracy parser.", "labels": [], "entities": []}, {"text": "One obvious solution to this problem is to take as input k-best parses, instead of a singletree.", "labels": [], "entities": []}, {"text": "This kbest list postpones some disambiguation to the decoder, which may recover from parsing errors by getting a better translation from anon 1-best parse.", "labels": [], "entities": []}, {"text": "However, a k-best list, with its limited scope, often has too few variations and too many redundancies; for example, a 50-best list typically encodes a combination of 5 or 6 binary ambiguities (since 2 5 < 50 < 2 6 ), and many subtrees are repeated across different parses.", "labels": [], "entities": []}, {"text": "It is thus inefficient either to decode separately with each of these very similar trees.", "labels": [], "entities": []}, {"text": "Longer sentences will also aggravate this situation as the number of parses grows exponentially with the sentence length.", "labels": [], "entities": []}, {"text": "We instead propose anew approach, forest-based translation (Section 3), where the decoder translates a packed forest of exponentially many parses,  which compactly encodes many more alternatives than k-best parses.", "labels": [], "entities": [{"text": "forest-based translation", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6695080399513245}]}, {"text": "This scheme can be seen as a compromise between the string-based and treebased methods, while combining the advantages of both: decoding is still fast, yet does not commit to a single parse.", "labels": [], "entities": []}, {"text": "Large-scale experiments show an improvement of 1.7 BLEU points over the 1-best baseline, which is also 0.8 points higher than decoding with 30-best trees, and takes even less time thanks to the sharing of common subtrees.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9986110925674438}]}], "datasetContent": [{"text": "We can extend the simple model in Equation 1 to a log-linear one (): where T is the 1-best parse, e \u03bb 1 |d| is the penalty term on the number of rules in a derivation, P lm (s) is the language model and e \u03bb 3 |s| is the length penalty term on target translation.", "labels": [], "entities": [{"text": "length penalty term", "start_pos": 220, "end_pos": 239, "type": "METRIC", "confidence": 0.9512550433476766}]}, {"text": "The derivation probability conditioned on 1-best tree, P(d | T ), should now be replaced by P(d | H p ) where H p is the parse forest, which decomposes into the product of probabilities of translation rules r \u2208 d: where each P(r) is the product of five probabilities: Here t and s are the source-side tree and targetside string of ruler, respectively, P(t | s) and P(s | t) are the two translation probabilities, and P lex (\u00b7) are the lexical probabilities.", "labels": [], "entities": []}, {"text": "The only extra term in forest-based decoding is P(t | H p ) denoting the source side parsing probability of the current translation ruler in the parse forest, which is the product of probabilities of each parse hyperedge e p covered in the pattern-match oft against H p (which can be recorded at conversion time):", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU score results from training on large data.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9661845862865448}]}]}