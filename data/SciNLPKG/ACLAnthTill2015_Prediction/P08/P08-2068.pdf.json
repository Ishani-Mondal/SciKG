{"title": [{"text": "Text Segmentation with LDA-Based Fisher Kernel", "labels": [], "entities": [{"text": "Text Segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7226437926292419}]}], "abstractContent": [{"text": "In this paper we propose a domain-independent text segmentation method, which consists of three components.", "labels": [], "entities": [{"text": "domain-independent text segmentation", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.6465326050917307}]}, {"text": "Latent Dirichlet allocation (LDA) is employed to compute words semantic distribution, and we measure semantic similarity by the Fisher kernel.", "labels": [], "entities": [{"text": "Latent Dirichlet allocation (LDA)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6890900731086731}]}, {"text": "Finally global best segmentation is achieved by dynamic programming.", "labels": [], "entities": []}, {"text": "Experiments on Chinese data sets with the technique show it can be effective.", "labels": [], "entities": [{"text": "Chinese data sets", "start_pos": 15, "end_pos": 32, "type": "DATASET", "confidence": 0.7884503602981567}]}, {"text": "Introducing latent semantic information, our algorithm is robust on irregular-sized segments.", "labels": [], "entities": []}], "introductionContent": [{"text": "The aim of text segmentation is to partition a document into a set of segments, each of which is coherent about a specific topic.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7352386564016342}]}, {"text": "This task is inspired by problems in information retrieval, summarization, and language modeling, in which the ability to provide access to smaller, coherent segments in a document is desired.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7664071917533875}, {"text": "summarization", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.9881032109260559}, {"text": "language modeling", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7103213518857956}]}, {"text": "A lot of research has been done on text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8146816492080688}]}, {"text": "Some of them utilize linguistic criteria), while others use statistical similarity measures to uncover lexical cohesion.", "labels": [], "entities": []}, {"text": "Lexical cohesion methods believe a coherent topic segment contains parts with similar vocabularies.", "labels": [], "entities": []}, {"text": "For example, the TextTiling algorithm, introduced by, assumes that the local minima of the word similarity curve are the points of low lexical cohesion and thus the natural boundary candidates. has proposed a method called dotplotting depending on the distribution of word repetitions to find tight regions of topic similarity graphically.", "labels": [], "entities": []}, {"text": "One of the problems with those works is that they treat terms uncorrelated, assigning them orthogonal directions in the feature space.", "labels": [], "entities": []}, {"text": "But in reality words are correlated, and sometimes even synonymous, so that texts with very few common terms can potentially be on closely related topics.", "labels": [], "entities": []}, {"text": "So () utilize semantic similarity to identify cohesion.", "labels": [], "entities": []}, {"text": "Unsupervised models of texts that capture semantic information would be useful, particularly if they could be achieved with a \"semantic kernel\" () , which computes the similarity between texts by also considering relations between different terms.", "labels": [], "entities": []}, {"text": "A Fisher kernel is a function that measures the similarity between two data items not in isolation, but rather in the context provided by a probability distribution.", "labels": [], "entities": []}, {"text": "In this paper, we use the Fisher kernel to describe semantic information similarity.", "labels": [], "entities": [{"text": "semantic information similarity", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.7034435272216797}]}, {"text": "In addition, () has treated this task as an optimization problem with global cost function and used dynamic programming for segments selection.", "labels": [], "entities": [{"text": "segments selection", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.8489580154418945}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, after a brief overview of our method, some key aspects of the algorithm are described.", "labels": [], "entities": []}, {"text": "In section 3, some experiments are presented.", "labels": [], "entities": []}, {"text": "Finally conclusion and future research directions are drawn in section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation against different algorithms on Set  5-20.", "labels": [], "entities": []}]}