{"title": [{"text": "An Unsupervised Vector Approach to Biomedical Term Disambiguation: Integrating UMLS and Medline", "labels": [], "entities": [{"text": "Biomedical Term Disambiguation", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.8275006810824076}, {"text": "Medline", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.7012162208557129}]}], "abstractContent": [{"text": "This paper introduces an unsupervised vector approach to disambiguate words in biomedi-cal text that can be applied to all-word dis-ambiguation.", "labels": [], "entities": []}, {"text": "We explore using contextual information from the Unified Medical Language System (UMLS) to describe the possible senses of a word.", "labels": [], "entities": []}, {"text": "We experiment with automatically creating individualized stoplists to help reduce the noise in our dataset.", "labels": [], "entities": []}, {"text": "We compare our results to SenseClusters and Humphrey et al.", "labels": [], "entities": []}, {"text": "(2006) using the NLM-WSD dataset and with SenseClusters using con-flated data from the 2005 Medline Baseline.", "labels": [], "entities": [{"text": "NLM-WSD dataset", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.960077553987503}, {"text": "Medline Baseline", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.8389852941036224}]}], "introductionContent": [{"text": "Some words have multiple senses.", "labels": [], "entities": []}, {"text": "For example, the word cold could refer to a viral infection or the temperature.", "labels": [], "entities": []}, {"text": "As humans, we find it easy to determine the appropriate sense (concept) given the context in which the word is used.", "labels": [], "entities": []}, {"text": "For a computer, though, this is a difficult problem which negatively impacts the accuracy of biomedical applications such as medical coding and indexing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9985600113868713}, {"text": "medical coding", "start_pos": 125, "end_pos": 139, "type": "TASK", "confidence": 0.691392719745636}, {"text": "indexing", "start_pos": 144, "end_pos": 152, "type": "TASK", "confidence": 0.7670451998710632}]}, {"text": "The goal of our research is to explore using information from biomedical knowledge sources such as the Unified Medical Language System (UMLS) and Medline to help distinguish between different possible concepts of a word.", "labels": [], "entities": [{"text": "Medline", "start_pos": 146, "end_pos": 153, "type": "DATASET", "confidence": 0.9223695397377014}]}, {"text": "In the UMLS, concepts associated with words and terms are enumerated via Concept Unique Identifiers (CUIs).", "labels": [], "entities": []}, {"text": "For example, two possible senses of cold are \"C0009264: Cold Temperature\" and \"C0009443: Common Cold\" in the UMLS release 2008AA.", "labels": [], "entities": [{"text": "UMLS release 2008AA", "start_pos": 109, "end_pos": 128, "type": "DATASET", "confidence": 0.9248799880345663}]}, {"text": "The UMLS is also encoded with different semantic and syntactic structures.", "labels": [], "entities": []}, {"text": "Some such information includes related concepts and semantic types.", "labels": [], "entities": []}, {"text": "A semantic type (ST) is abroad subject categorization assigned to a CUI.", "labels": [], "entities": []}, {"text": "For example, the ST of \"C0009264: Cold Temperature\" is \"Idea or Concept\" while the ST for \"C0009443: Common Cold\" is \"Disease or Syndrome\".", "labels": [], "entities": [{"text": "ST", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.9934872388839722}]}, {"text": "Currently, there exists approximately 1.5 million CUIs and 135 STs in the UMLS.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.9185726046562195}]}, {"text": "Medline is an online database that contains 11 million references biomedical articles.", "labels": [], "entities": [{"text": "Medline", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9641620516777039}]}, {"text": "In this paper, we introduce an unsupervised vector approach to disambiguate words in biomedical text using contextual information from the UMLS and Medline.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 139, "end_pos": 143, "type": "DATASET", "confidence": 0.9628801345825195}]}, {"text": "We compare our approach to and SenseClusters.", "labels": [], "entities": [{"text": "SenseClusters", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.8908529281616211}]}, {"text": "The ability to make disambiguation decisions for words that have the same ST differentiates SenseClusters and our approach from.", "labels": [], "entities": []}, {"text": "For example, the word weight in the UMLS has two possible CUIs, \"C0005912: Body Weight\" and \"C0699807: Weight\", each having the ST \"Quantitative Concept\".", "labels": [], "entities": [{"text": "ST", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.9444792866706848}]}, {"text": "approach relies on the concepts having different STs therefore is unable to disambiguate between these two concepts.", "labels": [], "entities": []}, {"text": "Currently, most word sense disambiguation approaches focus on lexical sample disambiguation which only attempts to disambiguate a predefined set of words.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.7255691190560659}]}, {"text": "This type of disambiguation is not practical for large scale systems.", "labels": [], "entities": []}, {"text": "All-words disambiguation approaches disambiguate all ambiguous words in a running text making them practical for large scale systems.", "labels": [], "entities": [{"text": "All-words disambiguation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6944849044084549}]}, {"text": "Unlike SenseClusters, and our approach can be used to perform all-words disambiguation.", "labels": [], "entities": []}, {"text": "In the following sections, we first discuss related work.", "labels": [], "entities": []}, {"text": "We then discuss our approach, experiments and results.", "labels": [], "entities": []}, {"text": "Lastly, we discuss our conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the National Library of Medicine's Word Sense Disambiguation (NLM-WSD) dataset developed by) as our test set.", "labels": [], "entities": [{"text": "National Library of Medicine's Word Sense Disambiguation (NLM-WSD) dataset", "start_pos": 11, "end_pos": 85, "type": "DATASET", "confidence": 0.7933402135968208}]}, {"text": "This dataset contains 100 instances of 50 ambiguous words from 1998 MEDLINE abstracts.", "labels": [], "entities": [{"text": "MEDLINE abstracts", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.7299948632717133}]}, {"text": "Each instance of a target word was manually disambiguated by 11 human evaluators who assigned the word a CUI or \"None\" if none of the CUIs described the concept.", "labels": [], "entities": []}, {"text": "() evaluate their approach using a subset of 13 out of the 50 words whose majority sense is less than 65% and whose possible concepts do not have the same ST.", "labels": [], "entities": []}, {"text": "Instances tagged as \"None\" were removed from the dataset.", "labels": [], "entities": []}, {"text": "We evaluate our approach using these same words and instances.", "labels": [], "entities": []}, {"text": "To test our algorithm on a larger biomedical dataset, we are creating our own dataset by conflating two or more unambiguous words from the 2005 Medline Baseline.", "labels": [], "entities": [{"text": "Medline Baseline", "start_pos": 144, "end_pos": 160, "type": "DATASET", "confidence": 0.8311849236488342}]}, {"text": "We determine which words to conflate based on the following criteria: i) the words have a single concept in the UMLS, ii) the words occur approximately the same number of times in the corpus, and iii) the words do not co-occur together.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 112, "end_pos": 116, "type": "DATASET", "confidence": 0.9370391964912415}]}, {"text": "We create our dataset using name-conf late 2 to extract instances containing the conflate words from the 2005 Medline Baseline.", "labels": [], "entities": [{"text": "Medline Baseline", "start_pos": 110, "end_pos": 126, "type": "DATASET", "confidence": 0.8227110207080841}]}, {"text": "shows our current set of conflated words with their corresponding number of test (test) and training (train) instances.", "labels": [], "entities": []}, {"text": "We refer to the conflated words as their pseudowords throughout the paper.", "labels": [], "entities": []}, {"text": "In this section, we report the results of our experiments.", "labels": [], "entities": []}, {"text": "First, we compare the results of using the IDF stoplist over a basic stoplist.", "labels": [], "entities": [{"text": "IDF stoplist", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.9342130422592163}]}, {"text": "Second, we compare the results of using the different context descriptions.", "labels": [], "entities": []}, {"text": "Third, we compare our approach to using the NLM-WSD dataset.", "labels": [], "entities": [{"text": "NLM-WSD dataset", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.9610743820667267}]}, {"text": "Lastly, we compare our approach to SenseClusters using the conflated dataset.", "labels": [], "entities": []}, {"text": "In the following tables, CUI refers to the CUI definition of the possible concept as context, ST refers to using the ST definition of the possible concept as context, CUI+ST refers to using both definitions as context, and CUI\u2192ST refers to using the CUI definition unless if one doesn't exist then using ST definition.", "labels": [], "entities": []}, {"text": "refers to the \"majority sense\" baseline which is accuracy that would be achieved by assigning every instance of the target word with the most frequent sense as assigned by the human evaluators.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9989997744560242}]}, {"text": "shows the overall accuracy of our approach using the basic stoplist and the IDF stoplist on the shows the results of our approach using the CUI and ST definitions as context for the possible concepts on the NLM-WSD dataset and shows similar results using the conflate dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994373917579651}, {"text": "IDF", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9490841031074524}, {"text": "NLM-WSD dataset", "start_pos": 207, "end_pos": 222, "type": "DATASET", "confidence": 0.9535172581672668}]}], "tableCaptions": [{"text": " Table 1: Accuracy of Our Approach using Different Context Descriptions", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9911137223243713}]}, {"text": " Table 2: Accuracy of IDF stoplist on the NLM-WSD  dataset", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998379111289978}, {"text": "IDF stoplist", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.5780789703130722}, {"text": "NLM-WSD  dataset", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9322984516620636}]}, {"text": " Table 3: Accuracy of Approaches using the NLM-WSD Dataset", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9941278696060181}, {"text": "NLM-WSD Dataset", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.9298034310340881}]}, {"text": " Table 4: Accuracy of Approaches using the Conflate Dataset", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9931455850601196}, {"text": "Conflate Dataset", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.6966071277856827}]}, {"text": " Table 5: Number of words in CUI and ST Definitions of  Possible the Concepts in the NLM-WSD Dataset", "labels": [], "entities": [{"text": "NLM-WSD Dataset", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.8898869752883911}]}]}