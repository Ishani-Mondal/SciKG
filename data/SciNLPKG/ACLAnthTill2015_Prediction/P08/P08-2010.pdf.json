{"title": [{"text": "Beyond Log-Linear Models: Boosted Minimum Error Rate Training for N-best Re-ranking", "labels": [], "entities": [{"text": "Boosted Minimum Error Rate", "start_pos": 26, "end_pos": 52, "type": "METRIC", "confidence": 0.7487928867340088}, {"text": "Re-ranking", "start_pos": 73, "end_pos": 83, "type": "TASK", "confidence": 0.41489410400390625}]}], "abstractContent": [{"text": "Current re-ranking algorithms for machine translation rely on log-linear models, which have the potential problem of underfitting the training data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8079941272735596}]}, {"text": "We present BoostedMERT, a novel boosting algorithm that uses Minimum Error Rate Training (MERT) as a weak learner and builds a re-ranker far more expressive than log-linear models.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT)", "start_pos": 61, "end_pos": 95, "type": "METRIC", "confidence": 0.8295207491942814}]}, {"text": "BoostedMERT is easy to implement, inherits the efficient optimization properties of MERT, and can quickly boost the BLEU score on N-best re-ranking tasks.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.9781955480575562}]}, {"text": "In this paper, we describe the general algorithm and present preliminary results on the IWSLT 2007 Arabic-English task.", "labels": [], "entities": [{"text": "IWSLT 2007 Arabic-English task", "start_pos": 88, "end_pos": 118, "type": "DATASET", "confidence": 0.8047139048576355}]}], "introductionContent": [{"text": "N-best list re-ranking is an important component in many complex natural language processing applications (e.g. machine translation, speech recognition, parsing).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7999716401100159}, {"text": "speech recognition", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.717859297990799}]}, {"text": "Re-ranking the N-best lists generated from a 1st-pass decoder can bean effective approach because (a) additional knowledge (features) can be incorporated, and (b) the search space is smaller (i.e. choose 1 out of N hypotheses).", "labels": [], "entities": []}, {"text": "Despite these theoretical advantages, we have often observed little gains in re-ranking machine translation (MT) N-best lists in practice.", "labels": [], "entities": [{"text": "re-ranking machine translation (MT) N-best", "start_pos": 77, "end_pos": 119, "type": "TASK", "confidence": 0.7820034793445042}]}, {"text": "It has often been observed that N-best list rescoring only yields a moderate improvement over the first-pass output although the potential improvement as measured by the oracle-best hypothesis for each sentence is much * Work supported by an NSF higher.", "labels": [], "entities": [{"text": "N-best list rescoring", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.547656257947286}]}, {"text": "This shows that hypothesis features are either not discriminative enough, or that the reranking model is too This performance gap can be mainly attributed to two problems: optimization error and modeling error (see).", "labels": [], "entities": []}, {"text": "Much work has focused on developing better algorithms to tackle the optimization problem (e.g. MERT), since MT evaluation metrics such as BLEU and PER are riddled with local minima and are difficult to differentiate with respect to re-ranker parameters.", "labels": [], "entities": [{"text": "MERT", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.6542648673057556}, {"text": "MT evaluation", "start_pos": 108, "end_pos": 121, "type": "TASK", "confidence": 0.8845670521259308}, {"text": "BLEU", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.9977141618728638}, {"text": "PER", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.968148410320282}]}, {"text": "These optimization algorithms are based on the popular loglinear model, which chooses the English translation e of a foreign sentence f by the rule: arg max e p(e|f ) \u2261 arg max e K k=1 \u03bb k \u03c6 k (e, f ) where \u03c6 k (e, f ) and \u03bb k are the K features and weights, respectively, and the argmax is overall hypotheses in the N-best list.", "labels": [], "entities": [{"text": "argmax", "start_pos": 281, "end_pos": 287, "type": "METRIC", "confidence": 0.9759164452552795}]}, {"text": "We believe that standard algorithms such as MERT already achieve low optimization error (this is based on experience where many random re-starts of MERT give little gains); instead the score gap is mainly due to modeling errors.", "labels": [], "entities": []}, {"text": "Standard MT systems use a small set of features (i.e. K \u2248 10) based on language/translation models.", "labels": [], "entities": [{"text": "MT", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.9751572608947754}]}, {"text": "Log-linear models on such few features are simply not expressive enough to achieve the oracle score, regardless of how well the weights {\u03bb k } are optimized.", "labels": [], "entities": []}, {"text": "Figure 1: Both modeling and optimization problems increase the (training set) BLEU score gap between MERT re-ranking and oracle hypotheses.", "labels": [], "entities": [{"text": "BLEU score gap", "start_pos": 78, "end_pos": 92, "type": "METRIC", "confidence": 0.9793592691421509}]}, {"text": "We believe that the modeling problem is more serious for log-linear models of around 10 features and focus on it in this work.", "labels": [], "entities": []}, {"text": "To truly achieve the benefits of re-ranking in MT, one must go beyond the log-linear model.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.97364342212677}]}, {"text": "The reranker should not be a mere dot product operation, but a more dynamic and complex decision maker that exploits the structure of the N-best re-ranking problem.", "labels": [], "entities": []}, {"text": "We present BoostedMERT, a general framework for learning such complex re-rankers using standard MERT as a building block.", "labels": [], "entities": []}, {"text": "BoostedMERT is easy to implement, inherits MERT's efficient optimization procedure, and more effectively boosts the training score.", "labels": [], "entities": [{"text": "MERT", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.6147618889808655}]}, {"text": "We describe the algorithm in Section 2, report experiment results in Section 3, and end with related work and future directions (Sections 4, 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments are done on the IWSLT 2007 Arabic-to-English task (clean text condition).", "labels": [], "entities": [{"text": "IWSLT 2007 Arabic-to-English task", "start_pos": 32, "end_pos": 65, "type": "DATASET", "confidence": 0.8857604116201401}]}, {"text": "We used a standard phrase-based statistical MT system to generated N-best lists (N=2000) on Development4, Development5, and Evaluation sub-sets.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.912693977355957}, {"text": "Development4", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.9234160780906677}]}, {"text": "Development4 is used as the Train set; N-best lists that have the same sentence-level BLEU statistics for all hypotheses are filtered since they are not important in impacting training.", "labels": [], "entities": [{"text": "Development4", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9064731597900391}, {"text": "Train set", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8768915832042694}, {"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9682729840278625}]}, {"text": "Development5 is used as Dev set (in particular, for selecting the number of iterations in boosting), and Evaluation (Eval) is the blind dataset for final ranker comparison.", "labels": [], "entities": [{"text": "Development5", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9473448395729065}]}, {"text": "Nine features are used in re-ranking.", "labels": [], "entities": []}, {"text": "We compare MERT vs. BoostedMERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.911765992641449}]}, {"text": "MERT is randomly re-started 30 times, and BoostedMERT is run for 30 iterations, which makes fora relatively fair comparison.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.699829638004303}]}, {"text": "MERT usually does not improve its Train BLEU score, even with many random restarts (again, this suggests that optimization error is low).", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.5360965728759766}, {"text": "Train", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.6530047059059143}, {"text": "BLEU score", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9707781970500946}, {"text": "optimization error", "start_pos": 110, "end_pos": 128, "type": "METRIC", "confidence": 0.8581094741821289}]}, {"text": "shows the results, with Boosted-MERT outperforming MERT 42.0 vs. 41.2 BLEU on Eval.", "labels": [], "entities": [{"text": "Boosted-MERT", "start_pos": 24, "end_pos": 36, "type": "METRIC", "confidence": 0.994282603263855}, {"text": "MERT", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.7368218898773193}, {"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9941190481185913}, {"text": "Eval", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9599598050117493}]}, {"text": "BoostedMERT has the potential to achieve 43.7 BLEU, if a better method for selecting optimal iterations can be devised.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9710567593574524}]}, {"text": "It should be noted that the Train scores achieved by both MERT and BoostedMERT is still far from the oracle (around 56).", "labels": [], "entities": [{"text": "MERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.8130796551704407}, {"text": "BoostedMERT", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.6915428042411804}]}, {"text": "We found empirically that BoostedMERT is somewhat sensitive to the size (M ) of the Train set.", "labels": [], "entities": [{"text": "BoostedMERT", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.48201730847358704}, {"text": "Train set", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.8766434788703918}]}, {"text": "For small Train sets, BoostedMERT can improve the training score quite drastically; for the current Train set as well as other larger ones, the improvement per iteration is much slower.", "labels": [], "entities": [{"text": "BoostedMERT", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.8735726475715637}, {"text": "Train set", "start_pos": 100, "end_pos": 109, "type": "DATASET", "confidence": 0.9153404533863068}]}, {"text": "We plan to investigate this in future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The first three rows show the BLEU score for  Train, Dev, and Eval from 30 iterations of BoostedMERT  or 30 random re-restarts of MERT. The last row shows  the actual BLEU on Eval when selecting the number  of boosting iterations based on Dev. Last column in- dicates absolute improvements. BoostedMERT outper- forms MERT by 0.8 points on Eval.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9763782918453217}, {"text": "BLEU", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.9962968230247498}]}]}