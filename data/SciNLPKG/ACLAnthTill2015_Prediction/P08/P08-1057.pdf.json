{"title": [{"text": "Combining EM Training and the MDL Principle for an Automatic Verb Classification incorporating Selectional Preferences", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an innovative, complex approach to semantic verb classification that relies on selectional preferences as verb properties.", "labels": [], "entities": [{"text": "semantic verb classification", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.7020385464032491}]}, {"text": "The probabilistic verb class model underlying the semantic classes is trained by a combination of the EM algorithm and the MDL principle, providing soft clusters with two dimensions (verb senses and subcategori-sation frames with selectional preferences) as a result.", "labels": [], "entities": []}, {"text": "A language-model-based evaluation shows that after 10 training iterations the verb class model results are above the baseline results .", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, the computational linguistics community has developed an impressive number of semantic verb classifications, i.e., classifications that generalise over verbs according to their semantic properties.", "labels": [], "entities": [{"text": "semantic verb classifications", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.6805730859438578}]}, {"text": "Intuitive examples of such classifications are the MOTION WITH A VEHICLE class, including verbs such as drive, fly, row, etc., or the BREAK A SOLID SURFACE WITH AN INSTRUMENT class, including verbs such as break, crush, fracture, smash, etc.", "labels": [], "entities": [{"text": "MOTION WITH A VEHICLE class", "start_pos": 51, "end_pos": 78, "type": "METRIC", "confidence": 0.836063539981842}, {"text": "BREAK A SOLID", "start_pos": 134, "end_pos": 147, "type": "METRIC", "confidence": 0.8774476250012716}, {"text": "INSTRUMENT", "start_pos": 164, "end_pos": 174, "type": "METRIC", "confidence": 0.606195330619812}]}, {"text": "Semantic verb classifications are of great interest to computational linguistics, specifically regarding the pervasive problem of data sparseness in the processing of natural language.", "labels": [], "entities": [{"text": "Semantic verb classifications", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7142104307810465}]}, {"text": "Up to now, such classifications have been used in applications such as word sense disambiguation), machine translation (, document classification (, and in statistical lexical acquisition in general (; Schulte im).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.6760044097900391}, {"text": "machine translation", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.8412043750286102}, {"text": "document classification", "start_pos": 122, "end_pos": 145, "type": "TASK", "confidence": 0.8088544309139252}, {"text": "statistical lexical acquisition", "start_pos": 156, "end_pos": 187, "type": "TASK", "confidence": 0.7688721021016439}]}, {"text": "Given that the creation of semantic verb classifications is not an end task in itself, but depends on the application scenario of the classification, we find various approaches to an automatic induction of semantic verb classifications.", "labels": [], "entities": [{"text": "semantic verb classifications", "start_pos": 206, "end_pos": 235, "type": "TASK", "confidence": 0.638305793205897}]}, {"text": "For example, used several machine learning algorithms to perform an automatic aspectual classification of English verbs into event and stative verbs.", "labels": [], "entities": [{"text": "automatic aspectual classification of English verbs into event and stative verbs", "start_pos": 68, "end_pos": 148, "type": "TASK", "confidence": 0.7716617557135496}]}, {"text": "presented an automatic classification of three types of English intransitive verbs, based on argument structure and heuristics to thematic relations. and relied on the ExpectationMaximisation algorithm to induce soft clusters of verbs, based on the verbs' direct object nouns.", "labels": [], "entities": []}, {"text": "Similarly, relied on the Information Bottleneck () and subcategorisation frame types to induce soft verb clusters.", "labels": [], "entities": []}, {"text": "This paper presents an innovative, complex approach to semantic verb classes that relies on selectional preferences as verb properties.", "labels": [], "entities": []}, {"text": "The underlying linguistic assumption for this verb class model is that verbs which agree on their selectional preferences belong to a common semantic class.", "labels": [], "entities": []}, {"text": "The model is implemented as a softclustering approach, in order to capture the polysemy of the verbs.", "labels": [], "entities": []}, {"text": "The training procedure uses the Expectation-Maximisation (EM) algorithm to iteratively improve the probabilistic parameters of the model, and applies the Minimum Description Length (MDL) principle to induce WordNet-based selectional preferences for arguments within subcategorisation frames.", "labels": [], "entities": []}, {"text": "Our model is potentially useful for lexical induction (e.g., verb senses, subcategorisation and selectional preferences, collocations, and verb alternations), and for NLP applications in sparse data situations.", "labels": [], "entities": []}, {"text": "In this paper, we provide an evaluation based on a language model.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces our probabilistic verb class model, the EM training, and how we incorporate the MDL principle.", "labels": [], "entities": []}, {"text": "Section 3 describes the clustering experiments, including the experimental setup, the evaluation, and the results.", "labels": [], "entities": []}, {"text": "Section 4 reports on related work, before we close with a summary and outlook in Section 5.", "labels": [], "entities": [{"text": "summary", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9289055466651917}]}], "datasetContent": [{"text": "The model is generally applicable to all languages for which WordNet exists, and for which the WordNet functions provided by Princeton University are available.", "labels": [], "entities": []}, {"text": "For the purposes of this paper, we choose English as a case study.", "labels": [], "entities": []}, {"text": "The input data for training the verb class models were derived from Viterbi parses of the whole British National Corpus, using the lexicalised PCFG for English by.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 96, "end_pos": 119, "type": "DATASET", "confidence": 0.9472667773564657}, {"text": "PCFG", "start_pos": 143, "end_pos": 147, "type": "DATASET", "confidence": 0.9339644312858582}]}, {"text": "We took only active clauses into account, and disregarded auxiliary and modal verbs as well as particle verbs, leaving a total of 4,852,371 Viterbi parses.", "labels": [], "entities": []}, {"text": "Those input tuples were then divided into 90% training data and 10% test data, providing 4,367,130 training tuples (over 2,769,804 types), and 485,241 test tuples (over 368,103 types).", "labels": [], "entities": []}, {"text": "As we wanted to train and assess our verb class model under various conditions, we used different fractions of the training data in different training regimes.", "labels": [], "entities": []}, {"text": "Because of time and memory constraints, we only used training tuples that appeared at least twice.", "labels": [], "entities": []}, {"text": "(For the sake of comparison, we also trained one model on all tuples.)", "labels": [], "entities": []}, {"text": "Furthermore, we disregarded tuples with personal pronoun arguments; they are not represented in WordNet, and even if they are added (e.g. to general concepts such as person, entity) they have a rather destructive effect.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 96, "end_pos": 103, "type": "DATASET", "confidence": 0.9601093530654907}]}, {"text": "We considered two subsets of the subcategorisation frames with 10 and 20 elements, which were chosen according to their overall frequency in the training data; for example, the 10 most frequent frame types were subj:obj, subj, subj:ap, subj:to, subj:obj:obj2, subj:obj:pp-in, subj:adv, subj:pp-in, subj:vbase, subj:that.", "labels": [], "entities": []}, {"text": "When relying on theses 10/20 subcategorisation frames, plus including the above restrictions, we were left with 39,773/158,134 and 42,826/166,303 training tuple types/tokens, respectively.", "labels": [], "entities": []}, {"text": "The overall number of training tuples was therefore much smaller than the generally available data.", "labels": [], "entities": []}, {"text": "The corresponding numbers including tuples with a frequency of one were 478,717/597,078 and 577,755/701,232.", "labels": [], "entities": []}, {"text": "The number of clusters in the experiments was either 20 or 50, and we used up to 50 iterations over the training tuples.", "labels": [], "entities": []}, {"text": "The model probabilities were output after each 5th iteration.", "labels": [], "entities": []}, {"text": "The output comprises all model probabilities introduced in Section 2.1.", "labels": [], "entities": []}, {"text": "The following sections describe the evaluation of the experiments, and the results.", "labels": [], "entities": []}, {"text": "One of the goals in the development of the presented verb class model was to obtain an accurate statistical model of verb-argument tuples, i.e. a model which precisely predicts the tuple probabilities.", "labels": [], "entities": []}, {"text": "In order to evaluate the performance of the model in this respect, we conducted an evaluation experiment, in which we computed the probability which the verb class model assigns to our test tuples and compared it to the corresponding probability assigned by a baseline model.", "labels": [], "entities": []}, {"text": "The model with the higher probability is judged the better model.", "labels": [], "entities": []}, {"text": "We expected that the verb class model would perform better than the baseline model on tuples where one or more of the arguments were not observed with the respective verb, because either the argument itself or a semantically similar argument (according to the selectional preferences) was observed with verbs belonging to the same cluster.", "labels": [], "entities": []}, {"text": "We also expected that the verb class model assigns a lower probability than the baseline model to test tuples which frequently occurred in the training data, since the verb class model fails to describe precisely the idiosyncratic properties of verbs which are not shared by the other verbs of its cluster.", "labels": [], "entities": []}, {"text": "The Baseline Model The baseline model decomposes the probability of a verb-argument tuple into a product of conditional probabilities: 5 p(v, f, a The probability of our example tuple speak, subj-pp.to, professor, audience in the baseline model is then p(speak) p(subj-pp.to|speak) p(professor|speak, subj-pp.to, subj) p(audience| professor, speak, subj-pp.to, pp.to).", "labels": [], "entities": []}, {"text": "The model contains no hidden variables.", "labels": [], "entities": []}, {"text": "Thus the parameters can be directly estimated from the training data with relative frequencies.", "labels": [], "entities": []}, {"text": "The parameter estimates are smoothed with modified Kneser-Ney smoothing, such that the probability of each tuple is positive.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Clustering results -BNC tuples.", "labels": [], "entities": []}]}