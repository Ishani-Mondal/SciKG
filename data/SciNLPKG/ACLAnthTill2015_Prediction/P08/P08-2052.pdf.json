{"title": [{"text": "FastSum: Fast and accurate query-based multi-document summarization", "labels": [], "entities": [{"text": "summarization", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.7032476663589478}]}], "abstractContent": [{"text": "We present a fast query-based multi-document summarizer called FastSum based solely on word-frequency features of clusters, documents and topics.", "labels": [], "entities": []}, {"text": "Summary sentences are ranked by a regression SVM.", "labels": [], "entities": []}, {"text": "The summa-rizer does not use any expensive NLP techniques such as parsing, tagging of names or even part of speech information.", "labels": [], "entities": []}, {"text": "Still, the achieved accuracy is comparable to the best systems presented in recent academic competitions (i.e., Document Understanding Conference (DUC)).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9995030164718628}, {"text": "Document Understanding Conference (DUC))", "start_pos": 112, "end_pos": 152, "type": "TASK", "confidence": 0.6379022200902303}]}, {"text": "Because of a detailed feature analysis using Least Angle Regression (LARS), FastSum can rely on a minimal set of features leading to fast processing times: 1250 news documents in 60 seconds.", "labels": [], "entities": [{"text": "Least Angle Regression (LARS", "start_pos": 45, "end_pos": 73, "type": "METRIC", "confidence": 0.7755265355110168}]}], "introductionContent": [{"text": "In this paper, we propose a simple method for effectively generating query-based multi-document summaries without any complex processing steps.", "labels": [], "entities": []}, {"text": "It only involves sentence splitting, filtering candidate sentences and computing the word frequencies in the documents of a cluster, topic description and the topic title.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7181844115257263}]}, {"text": "We use a machine learning technique called regression SVM, as proposed by (.", "labels": [], "entities": [{"text": "regression SVM", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.7290208339691162}]}, {"text": "For the feature selection we use anew model selection technique called Least Angle Regression (LARS) ().", "labels": [], "entities": [{"text": "feature selection", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.6837214529514313}, {"text": "Least Angle Regression (LARS)", "start_pos": 71, "end_pos": 100, "type": "METRIC", "confidence": 0.9612519244352976}]}, {"text": "Even though machine learning approaches dominated the field of summarization systems in recent DUC competitions, not much effort has been spent in finding simple but effective features.", "labels": [], "entities": [{"text": "summarization", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9865003228187561}]}, {"text": "Exceptions are the SumBasic system that achieves reasonable results with only one feature (i.e., word frequency in document clusters)).", "labels": [], "entities": []}, {"text": "Our approach goes beyond SumBasic by proposing an even more powerful feature that proves to be the best predictor in all three recent DUC corpora.", "labels": [], "entities": [{"text": "DUC corpora", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.8984050750732422}]}, {"text": "In order to prove that our feature is more predictive than other features we provide a rigorous feature analysis by employing LARS.", "labels": [], "entities": [{"text": "LARS", "start_pos": 126, "end_pos": 130, "type": "METRIC", "confidence": 0.6282336711883545}]}, {"text": "Scalability is normally not considered when different summarization systems are compared.", "labels": [], "entities": [{"text": "Scalability", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9223239421844482}]}, {"text": "Processing time of more than several seconds per summary should be considered unacceptable, in particular, if you bear in mind that using such a system should help a user to process lots of data faster.", "labels": [], "entities": []}, {"text": "Our focus is on selecting the minimal set of features that are computationally less expensive than other features (i.e., full parse).", "labels": [], "entities": []}, {"text": "Since FastSum can rely on a minimal set of features determined by LARS, it can process 1250 news documents in 60 seconds.", "labels": [], "entities": []}, {"text": "A comparison test with the MEAD system 2 showed that FastSum is more than 4 times faster.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.6117148399353027}, {"text": "FastSum", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.745809018611908}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: ROUGE-2 scores of individual features", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9906308054924011}]}, {"text": " Table 2: The 4 top features for the DUC 2005, 2006 and  2007 data", "labels": [], "entities": [{"text": "the DUC 2005", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.7436312238375345}]}]}