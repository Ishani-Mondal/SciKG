{"title": [], "abstractContent": [{"text": "Parser self-training is the technique of taking an existing parser, parsing extra data and then creating a second parser by treating the extra data as further training data.", "labels": [], "entities": []}, {"text": "Here we apply this technique to parser adaptation.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.9424127340316772}]}, {"text": "In particular , we self-train the standard Char-niak/Johnson Penn-Treebank parser using unlabeled biomedical abstracts.", "labels": [], "entities": [{"text": "Char-niak/Johnson Penn-Treebank parser", "start_pos": 43, "end_pos": 81, "type": "DATASET", "confidence": 0.7011228501796722}]}, {"text": "This achieves an f-score of 84.3% on a standard test set of biomedical abstracts from the Genia corpus.", "labels": [], "entities": [{"text": "f-score", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9972063899040222}, {"text": "Genia corpus", "start_pos": 90, "end_pos": 102, "type": "DATASET", "confidence": 0.7016782313585281}]}, {"text": "This is a 20% error reduction over the best previous result on biomedical data (80.2% on the same test set).", "labels": [], "entities": [{"text": "error reduction", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.9849822819232941}]}], "introductionContent": [{"text": "Parser self-training is the technique of taking an existing parser, parsing extra data and then creating a second parser by treating the extra data as further training data.", "labels": [], "entities": []}, {"text": "While for many years it was thought not to help state-of-the art parsers, more recent work has shown otherwise.", "labels": [], "entities": []}, {"text": "In this paper we apply this technique to parser adaptation.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.9517069458961487}]}, {"text": "In particular we self-train the standard Charniak/Johnson Penn-Treebank (C/J) parser using unannotated biomedical data.", "labels": [], "entities": [{"text": "Charniak/Johnson Penn-Treebank (C/J) parser", "start_pos": 41, "end_pos": 84, "type": "DATASET", "confidence": 0.7820992678403854}]}, {"text": "As is well known, biomedical data is hard on parsers because it is so far from more \"standard\" English.", "labels": [], "entities": []}, {"text": "To our knowledge this is the first application of self-training where the gap between the training and self-training data is so large.", "labels": [], "entities": []}, {"text": "In section two, we look at previous work.", "labels": [], "entities": []}, {"text": "In particular we note that there is, in fact, very little data on self-training when the corpora for self-training is so different from the original labeled data.", "labels": [], "entities": []}, {"text": "Section three describes our main experiment on standard test data).", "labels": [], "entities": [{"text": "standard test data", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.640457272529602}]}, {"text": "Section four looks at some preliminary results we obtained on development data that show in slightly more detail how selftraining improved the parser.", "labels": [], "entities": []}, {"text": "We conclude in section five.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used as the base parser the standardly available C/J parser.", "labels": [], "entities": []}, {"text": "We then self-trained the parser on approximately 270,000 sentences -a random selection of abstracts from Medline.", "labels": [], "entities": []}, {"text": "3 Medline is a large database of abstracts and citations from a wide variety of biomedical literature.", "labels": [], "entities": [{"text": "3 Medline", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9324384331703186}]}, {"text": "As we note in the next section, the number 270,000 was selected by observing performance on a development set.", "labels": [], "entities": []}, {"text": "We weighted the original WSJ hand annotated sentences equally with self-trained Medline data.", "labels": [], "entities": [{"text": "WSJ hand annotated sentences", "start_pos": 25, "end_pos": 53, "type": "DATASET", "confidence": 0.7876685112714767}]}, {"text": "So, for example, found that the data from the handannotated WSJ data should be considered at least five times more important than NANC data on an event by event level.", "labels": [], "entities": [{"text": "handannotated WSJ data", "start_pos": 46, "end_pos": 68, "type": "DATASET", "confidence": 0.7471988201141357}, {"text": "NANC data", "start_pos": 130, "end_pos": 139, "type": "DATASET", "confidence": 0.8472852110862732}]}, {"text": "We did no tuning to find out if there is some better weighting for our domain than one-to-one.", "labels": [], "entities": []}, {"text": "The resulting parser was tested on a test corpus of hand-parsed sentences from the Genia Treebank ().", "labels": [], "entities": [{"text": "Genia Treebank", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.8593002557754517}]}, {"text": "These are exactly the same sentences as used in the comparisons of the last section.", "labels": [], "entities": []}, {"text": "Genia is a corpus of abstracts from the Medline database selected from a search with the keywords Human, Blood Cells, and Transcription Factors.", "labels": [], "entities": [{"text": "Medline database", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.9828067421913147}]}, {"text": "Thus the Genia treebank data are all from a small domain within Biology.", "labels": [], "entities": [{"text": "Genia treebank data", "start_pos": 9, "end_pos": 28, "type": "DATASET", "confidence": 0.796895851691564}]}, {"text": "As already noted, the Medline abstracts used for self-training were chosen randomly and thus span a large number of biomedical sub-domains.", "labels": [], "entities": []}, {"text": "The results, the central results of this paper, are shown in.", "labels": [], "entities": []}, {"text": "Medline self-trained parser achieves an f -score of 84.3%, which is an absolute reduction in error of 4.1%.", "labels": [], "entities": [{"text": "Medline self-trained parser", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8715327779452006}, {"text": "f -score", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9949648181597391}, {"text": "absolute reduction in error", "start_pos": 71, "end_pos": 98, "type": "METRIC", "confidence": 0.8368958085775375}]}, {"text": "This corresponds to an error rate reduction of 20% over the L/C baseline.", "labels": [], "entities": [{"text": "error rate reduction", "start_pos": 23, "end_pos": 43, "type": "METRIC", "confidence": 0.9808638095855713}]}], "tableCaptions": []}