{"title": [{"text": "Joint Processing and Discriminative Training for Letter-to-Phoneme Conversion", "labels": [], "entities": [{"text": "Joint Processing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6984027177095413}, {"text": "Letter-to-Phoneme Conversion", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.7548359632492065}]}], "abstractContent": [{"text": "We present a discriminative structure-prediction model for the letter-to-phoneme task, a crucial step in text-to-speech processing.", "labels": [], "entities": []}, {"text": "Our method encompasses three tasks that have been previously handled separately: input segmentation, phoneme prediction, and sequence modeling.", "labels": [], "entities": [{"text": "input segmentation", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7303138971328735}, {"text": "phoneme prediction", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7864422798156738}, {"text": "sequence modeling", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.8003084361553192}]}, {"text": "The key idea is online discriminative training, which updates parameters according to a comparison of the current system output to the desired output, allowing us to train all of our components together.", "labels": [], "entities": []}, {"text": "By folding the three steps of a pipeline approach into a unified dynamic programming framework, we are able to achieve substantial performance gains.", "labels": [], "entities": []}, {"text": "Our results surpass the current state-of-the-art on six publicly available data sets representing four different languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Letter-to-phoneme (L2P) conversion is the task of predicting the pronunciation of a word, represented as a sequence of phonemes, from its orthographic form, represented as a sequence of letters.", "labels": [], "entities": [{"text": "Letter-to-phoneme (L2P) conversion", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6432546615600586}, {"text": "predicting the pronunciation of a word", "start_pos": 50, "end_pos": 88, "type": "TASK", "confidence": 0.8763892451922098}]}, {"text": "The L2P task plays a crucial role in speech synthesis systems (), and is an important part of other applications, including spelling correction and speech-to-speech machine translation (Engelbrecht and.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7505750358104706}, {"text": "spelling correction", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.9310164153575897}, {"text": "speech-to-speech machine translation", "start_pos": 148, "end_pos": 184, "type": "TASK", "confidence": 0.6959605813026428}]}, {"text": "Converting a word into its phoneme representation is not a trivial task.", "labels": [], "entities": []}, {"text": "Dictionary-based approaches cannot achieve this goal reliably, due to unseen words and proper names.", "labels": [], "entities": []}, {"text": "Furthermore, the construction of even a modestly-sized pronunciation dictionary requires substantial human effort for each new language.", "labels": [], "entities": []}, {"text": "Effective rule-based approaches can be designed for some languages such as Spanish.", "labels": [], "entities": []}, {"text": "However, show that in languages with a less transparent relationship between spelling and pronunciation, such as English, Dutch, or German, the number of letter-to-sound rules grows almost linearly with the lexicon size.", "labels": [], "entities": []}, {"text": "Therefore, most recent work in this area has focused on machine-learning approaches.", "labels": [], "entities": []}, {"text": "In this paper, we present a joint framework for letter-to-phoneme conversion, powered by online discriminative training.", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.7324207723140717}]}, {"text": "By updating our model parameters online, considering only the current system output and its feature representation, we are able to not only incorporate overlapping features, but also to use the same learning framework with increasingly complex search techniques.", "labels": [], "entities": []}, {"text": "We investigate two online updates: averaged perceptron and Margin Infused Relaxed Algorithm (MIRA).", "labels": [], "entities": [{"text": "Margin Infused Relaxed Algorithm (MIRA)", "start_pos": 59, "end_pos": 98, "type": "METRIC", "confidence": 0.8074059230940682}]}, {"text": "We evaluate our system on L2P data sets covering English, French, Dutch and German.", "labels": [], "entities": [{"text": "L2P data sets", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.7712826232115427}]}, {"text": "In all cases, our system outperforms the current state of the art, reducing the best observed error rate by as much as 46%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.9163581132888794}]}], "datasetContent": [{"text": "We evaluated our approach on English, German and Dutch CELEX (, French Brulex, English Nettalk and English CMUDict data sets.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.4538457989692688}, {"text": "Brulex", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.8026818633079529}, {"text": "English CMUDict data sets", "start_pos": 99, "end_pos": 124, "type": "DATASET", "confidence": 0.7761936634778976}]}, {"text": "Except for English CELEX, we used the data sets from the PRONALSYL letter-to-phoneme conversion challenge . Each data set is divided into 10 folds: we used the first one for testing, and the rest for training.", "labels": [], "entities": [{"text": "English CELEX", "start_pos": 11, "end_pos": 24, "type": "DATASET", "confidence": 0.7077082693576813}, {"text": "PRONALSYL letter-to-phoneme conversion challenge", "start_pos": 57, "end_pos": 105, "type": "TASK", "confidence": 0.72236368060112}]}, {"text": "In all cases, we holdout 5% of our training data to determine when to stop perceptron or MIRA training.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.6774159669876099}]}, {"text": "We ignored one-to-one alignments included in the PRONALSYL data sets, and instead induced many-to-many alignments using the method of.", "labels": [], "entities": [{"text": "PRONALSYL data sets", "start_pos": 49, "end_pos": 68, "type": "DATASET", "confidence": 0.9414622982343038}]}, {"text": "Our English CELEX data set was extracted directly from the CELEX database.", "labels": [], "entities": [{"text": "English CELEX data set", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.86285300552845}, {"text": "CELEX database", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.9509427547454834}]}, {"text": "After removing duplicate words, phrases, and abbreviations, the data set contained 66,189 word-phoneme pairs, of which 10% was designated as the final test set, and the rest as the training set.", "labels": [], "entities": []}, {"text": "We performed our development experiments on the latter part, and then used the final  test set to compare the performance of our system to other results reported in the literature.", "labels": [], "entities": []}, {"text": "We report the system performance in terms of word accuracy, which rewards only completely correct phoneme sequences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9474402070045471}]}, {"text": "Word accuracy is more demanding than phoneme accuracy, which considers the number of correct phonemes.", "labels": [], "entities": [{"text": "Word accuracy", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.49082279205322266}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9041828513145447}]}, {"text": "We feel that word accuracy is a more appropriate error metric, given the quality of current L2P systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9594502449035645}]}, {"text": "Phoneme accuracy is not sensitive enough to detect improvements in highly accurate L2P systems: report 90% phoneme accuracy is equivalent to approximately 60% word accuracy, while 99% phoneme accuracy corresponds to only 90% word accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.8954119086265564}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.7892762422561646}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.6316307187080383}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.7277339696884155}]}, {"text": "We began development with a zero-order Perceptron HMM with an external segmenter, which uses only the context features from.", "labels": [], "entities": []}, {"text": "The zero-order Perceptron HMM is equivalent to training a multiclass perceptron to make independent substring-tophoneme predictions; however, this framework allows us to easily extend to structured models.", "labels": [], "entities": [{"text": "Perceptron HMM", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.47034676373004913}]}, {"text": "We investigate the effect of augmenting this baseline system in turn with larger context sizes, the MIRA update, joint segmentation, and finally sequence features.", "labels": [], "entities": [{"text": "MIRA update", "start_pos": 100, "end_pos": 111, "type": "METRIC", "confidence": 0.8167219758033752}]}, {"text": "We report the impact of each contribution on our English CELEX development set.", "labels": [], "entities": [{"text": "English CELEX development set", "start_pos": 49, "end_pos": 78, "type": "DATASET", "confidence": 0.9291532337665558}]}, {"text": "shows the performance of our baseline L2P system with different context size values (c).", "labels": [], "entities": []}, {"text": "Increasing the context size has a dramatic effect on accuracy, but the effect begins to level off for context sizes greater than 5.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9989142417907715}]}, {"text": "Henceforth, we report the Perceptron MIRA Separate segmentation 84.5% 85.8% Phrasal decoding 86.6% 88.0% results with context size c = 5.", "labels": [], "entities": [{"text": "Perceptron MIRA Separate segmentation", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.6816638857126236}]}, {"text": "illustrates the effect of varying the size of n-best list in the MIRA update.", "labels": [], "entities": [{"text": "MIRA update", "start_pos": 65, "end_pos": 76, "type": "DATASET", "confidence": 0.7962806522846222}]}, {"text": "n = 1 is equivalent to taking into account only the best answer, which does not address the underfitting problem.", "labels": [], "entities": []}, {"text": "A large n-best list makes it difficult for the optimizer to separate the correct and incorrect answers, resulting in large updates at each step.", "labels": [], "entities": []}, {"text": "We settle on n = 10 for the subsequent experiments.", "labels": [], "entities": []}, {"text": "The choice of MIRA's loss function has a minimal impact on performance, probably because our baseline system already has a very high phoneme accuracy.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.5914026498794556}, {"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9581424593925476}]}, {"text": "We employ the loss function that combines 0-1 and phoneme error rate, due to its marginal improvement over 0-1 loss on the development set.", "labels": [], "entities": [{"text": "phoneme error rate", "start_pos": 50, "end_pos": 68, "type": "METRIC", "confidence": 0.6460646589597067}]}, {"text": "Looking across columns in, we observe over 8% reduction in word error rate when the perceptron update is replaced with the MIRA update.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 59, "end_pos": 74, "type": "METRIC", "confidence": 0.8060836791992188}, {"text": "MIRA", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.7409419417381287}]}, {"text": "Since the perceptron is a considerably simpler algorithm, we continue to report the results of both variants throughout this section.", "labels": [], "entities": []}, {"text": "also shows the word accuracy of our system after adding the option to conduct joint segmentation through phrasal decoding.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9819356799125671}]}, {"text": "The 15% relative reduction in error rate in the second row demonstrates the utility of folding the segmentation step into the search.", "labels": [], "entities": [{"text": "error rate", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9090588390827179}]}, {"text": "It also shows that the joint framework enables the system to reduce and compensate for errors that occur in a pipeline.", "labels": [], "entities": []}, {"text": "This is particularly interesting because our separate instance-based segmenter is highly accurate, achieving 98% segmentation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.947135865688324}]}, {"text": "Our experiments indicate that the application of joint segmentation recovers more than 60% of the available improvements, according to an upper bound determined by utilizing perfect segmentation.", "labels": [], "entities": [{"text": "joint segmentation", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.6752544641494751}]}, {"text": "2 illustrates the effect of our sequence features on both the perceptron and MIRA systems.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.5250780582427979}]}, {"text": "Replacing the zero-order HMM with the first-order HMM makes little difference by itself, but combined with the more powerful linear-chain features, it results in a relative error reduction of about 12%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 173, "end_pos": 188, "type": "METRIC", "confidence": 0.8899477124214172}]}, {"text": "In general, the linear-chain features make a much larger difference than the relatively simple transition features, which underscores the importance of using source-side context when assessing sequences of phonemes.", "labels": [], "entities": []}, {"text": "The results reported in were calculated using cross validation on the training part of the CELEX data set.", "labels": [], "entities": [{"text": "CELEX data set", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.992321252822876}]}, {"text": "With the exception of adding the 1 st order HMM, the differences between versions are statistically significant according to McNemar's test at 95% confidence level.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 125, "end_pos": 139, "type": "DATASET", "confidence": 0.8137827118237814}]}, {"text": "On one CPU of AMD Opteron 2.2GHz with 6GB of installed memory, it takes approximately 32 hours to train the MIRA model with all features, compared to 12 hours for the zero-order model.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.6122859120368958}]}, {"text": "shows the comparison between our approach and other systems on the evaluation data sets.", "labels": [], "entities": [{"text": "evaluation data sets", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.794397254784902}]}, {"text": "We trained our system using n-gram context, transition, and linear-chain features.", "labels": [], "entities": []}, {"text": "All parameters, including the size of n-best list, size of letter context, and the choice of loss functions, were established on the English CELEX development set, as presented in our previous experiments.", "labels": [], "entities": [{"text": "English CELEX development set", "start_pos": 133, "end_pos": 162, "type": "DATASET", "confidence": 0.8650504648685455}]}, {"text": "With the exception of the system described in, which we re-ran on our current test sets, the results of other systems are taken from the original papers.", "labels": [], "entities": []}, {"text": "Although these comparisons are necessarily indirect due to different experimental settings, they strongly suggest that our system outperforms all previous published results on all data sets, in some case by large margins.", "labels": [], "entities": []}, {"text": "When compared to the current stateof-the-art performance of each data set, the relative reductions in error rate range from 7% to 46%.: Word accuracy on the evaluated data sets.", "labels": [], "entities": [{"text": "error rate", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.9751520454883575}, {"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.921946108341217}]}, {"text": "MIRA, Perceptron: our systems.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.6883931159973145}]}, {"text": "M-M HMM: Many-to-Many HMM system (.", "labels": [], "entities": []}, {"text": "Joint n-gram: Joint n-gram model.", "labels": [], "entities": []}, {"text": "CSInf: Constraint satisfaction inference).", "labels": [], "entities": [{"text": "Constraint satisfaction inference", "start_pos": 7, "end_pos": 40, "type": "TASK", "confidence": 0.7067780991395315}]}, {"text": "PbA: Pronunciation by Analogy ().", "labels": [], "entities": [{"text": "PbA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8030576109886169}]}, {"text": "CART: CART decision tree system).", "labels": [], "entities": [{"text": "CART", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7455915212631226}]}, {"text": "The columns marked with * contain results reported in the literature.", "labels": [], "entities": []}, {"text": "\"-\" indicates no reported results.", "labels": [], "entities": []}, {"text": "We have underlined the best previously reported results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The effect of sequence features on the joint sys- tem in terms of word accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9519984722137451}]}, {"text": " Table 4: Word accuracy on the evaluated data sets. MIRA, Perceptron: our systems. M-M HMM: Many-to-Many  HMM system (", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.8985498547554016}, {"text": "MIRA", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9553484320640564}]}]}