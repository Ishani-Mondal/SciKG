{"title": [{"text": "Summarizing Emails with Conversational Cohesion and Subjectivity", "labels": [], "entities": [{"text": "Summarizing Emails", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9340922832489014}]}], "abstractContent": [{"text": "In this paper, we study the problem of summarizing email conversations.", "labels": [], "entities": [{"text": "summarizing email conversations", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.9092483321825663}]}, {"text": "We first build a sentence quotation graph that captures the conversation structure among emails.", "labels": [], "entities": []}, {"text": "We adopt three cohesion measures: clue words, semantic similarity and cosine similarity as the weight of the edges.", "labels": [], "entities": []}, {"text": "Second, we use two graph-based summarization approaches, Generalized ClueWordSummarizer and Page-Rank, to extract sentences as summaries.", "labels": [], "entities": []}, {"text": "Third, we propose a summarization approach based on subjective opinions and integrate it with the graph-based ones.", "labels": [], "entities": [{"text": "summarization", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9803865551948547}]}, {"text": "The empirical evaluation shows that the basic clue words have the highest accuracy among the three cohesion measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9992396831512451}]}, {"text": "Moreover, subjective words can significantly improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9967137575149536}]}], "introductionContent": [{"text": "With the ever increasing popularity of emails, it is very common nowadays that people discuss specific issues, events or tasks among a group of people by emails().", "labels": [], "entities": []}, {"text": "Those discussions can be viewed as conversations via emails and are valuable for the user as a personal information repository.", "labels": [], "entities": []}, {"text": "In this paper, we study the problem of summarizing email conversations.", "labels": [], "entities": [{"text": "summarizing email conversations", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.9092483321825663}]}, {"text": "Solutions to this problem can help users access the information embedded in emails more effectively.", "labels": [], "entities": []}, {"text": "For instance, 10 minutes before a meeting, a user may want to quickly go through a previous discussion via emails that is going to be discussed soon.", "labels": [], "entities": []}, {"text": "In that case, rather than reading each individual email one by one, it would be preferable to read a concise summary of the previous discussion with the major information summarized.", "labels": [], "entities": []}, {"text": "Email summarization is also helpful for mobile email users on a small screen.", "labels": [], "entities": [{"text": "Email summarization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7099843621253967}]}, {"text": "Summarizing email conversations is challenging due to the characteristics of emails, especially the conversational nature.", "labels": [], "entities": []}, {"text": "Most of the existing methods dealing with email conversations use the email thread to represent the email conversation structure, which is not accurate in many cases).", "labels": [], "entities": []}, {"text": "Meanwhile, most existing email summarization approaches use quantitative features to describe the conversation structure, e.g., number of recipients and responses, and apply some general multi-document summarization methods to extract some sentences as the summary () ().", "labels": [], "entities": [{"text": "email summarization", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.704822301864624}]}, {"text": "Although such methods consider the conversation structure somehow, they simplify the conversation structure into several features and do not fully utilize it into the summarization process.", "labels": [], "entities": [{"text": "summarization", "start_pos": 167, "end_pos": 180, "type": "TASK", "confidence": 0.9730646014213562}]}, {"text": "In contrast, in this paper, we propose new summarization approaches by sentence extraction, which rely on a fine-grain representation of the conversation structure.", "labels": [], "entities": [{"text": "summarization", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.9815158843994141}, {"text": "sentence extraction", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7738183736801147}]}, {"text": "We first build a sentence quotation graph by content analysis.", "labels": [], "entities": [{"text": "sentence quotation graph", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.7355118493239085}]}, {"text": "This graph not only captures the conversation structure more accurately, especially for selective quotations, but it also represents the conversation structure at the finer granularity of sentences.", "labels": [], "entities": []}, {"text": "As a second contribution of this paper, we study several ways to measure the cohesion between parent and child sentences in the quotation graph: clue words (re-occurring words in the reply), semantic similarity and cosine similarity.", "labels": [], "entities": []}, {"text": "Hence, we can directly evaluate the importance of each sentence in terms of its cohesion with related ones in the graph.", "labels": [], "entities": []}, {"text": "The extractive summarization problem can be viewed as anode ranking problem.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6576733291149139}]}, {"text": "We apply two summarization algorithms, Generalized ClueWordSummarizer and Page-Rank to rank nodes in the sentence quotation graph and to select the corresponding most highly ranked sentences as the summary.", "labels": [], "entities": []}, {"text": "Subjective opinions are often critical in many conversations.", "labels": [], "entities": []}, {"text": "As a third contribution of this paper, we study how to make use of the subjective opinions expressed in emails to support the summarization task.", "labels": [], "entities": [{"text": "summarization", "start_pos": 126, "end_pos": 139, "type": "TASK", "confidence": 0.9918386340141296}]}, {"text": "We integrate our best cohesion measure together with the subjective opinions.", "labels": [], "entities": []}, {"text": "Our empirical evaluations show that subjective words and phrases can significantly improve email summarization.", "labels": [], "entities": [{"text": "email summarization", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7350204885005951}]}, {"text": "To summarize, this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "After building a sentence quotation graph to represent the conversation structure in Section 3, we apply two summarization methods in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we study summarization approaches with subjective opinions.", "labels": [], "entities": [{"text": "summarization", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9804407358169556}]}, {"text": "Section 6 presents the empirical evaluation of our methods.", "labels": [], "entities": []}, {"text": "We conclude this paper and propose future work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "There are no publicly available annotated corpora to test email summarization techniques.", "labels": [], "entities": [{"text": "email summarization", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.5278025716543198}]}, {"text": "So, the first step in our evaluation was to develop our own corpus.", "labels": [], "entities": []}, {"text": "We use the Enron email dataset, which is the largest public email dataset.", "labels": [], "entities": [{"text": "Enron email dataset", "start_pos": 11, "end_pos": 30, "type": "DATASET", "confidence": 0.9166377782821655}]}, {"text": "In the 10 largest inbox folders in the Enron dataset, there are 296 email conversations.", "labels": [], "entities": [{"text": "Enron dataset", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9464598894119263}]}, {"text": "Since we are studying summarizing email conversations, we required that each selected conversation contained at least 4 emails.", "labels": [], "entities": [{"text": "summarizing email conversations", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.9035076300303141}]}, {"text": "In total, 39 conversations satisfied this requirement.", "labels": [], "entities": []}, {"text": "We use the MEAD package to segment the text into 1,394 sentences ( ).", "labels": [], "entities": [{"text": "MEAD package", "start_pos": 11, "end_pos": 23, "type": "DATASET", "confidence": 0.7527296841144562}]}, {"text": "We recruited 50 human summarizers to review those 39 selected email conversations.", "labels": [], "entities": []}, {"text": "Each email conversation was reviewed by 5 different human summarizers.", "labels": [], "entities": []}, {"text": "For each given email conversation, human summarizers were asked to generate a summary by directly selecting important sentences from the original emails in that conversation.", "labels": [], "entities": []}, {"text": "We asked the human summarizers to select 30% of the total sentences in their summaries.", "labels": [], "entities": []}, {"text": "Moreover, human summarizers were asked to classify each selected sentence as either essential or optional.", "labels": [], "entities": []}, {"text": "The essential sentences are crucial to the email conversation and have to be extracted in any case.", "labels": [], "entities": []}, {"text": "The optional sentences are not critical but are useful to help readers understand the email conversation if the given summary length permits.", "labels": [], "entities": []}, {"text": "By classifying essential and optional sentences, we can distinguish the core information from the supporting ones and find the most convincing sentences that most human summarizers agree on.", "labels": [], "entities": []}, {"text": "As essential sentences are more important than the optional ones, we give more weight to the essential selections.", "labels": [], "entities": []}, {"text": "We compute a GSV alue for each sentence to evaluate its importance according to the human summarizers' selections.", "labels": [], "entities": [{"text": "GSV alue", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.7792750000953674}]}, {"text": "The score is designed as follows: for each sentence s, one essential selection has a score of 3, one optional selection has a score of 1.", "labels": [], "entities": []}, {"text": "Thus, the GSValue of a sentence ranges from 0 to 15 (5 human summarizers x 3).", "labels": [], "entities": [{"text": "GSValue", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8924886584281921}]}, {"text": "The GSValue of 8 corresponds to 2 essential and 2 optional selections.", "labels": [], "entities": [{"text": "GSValue", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.8286229968070984}]}, {"text": "If a sentence has a GSValue no less than 8, we take it as an overall essential sentence.", "labels": [], "entities": [{"text": "GSValue", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.8960098028182983}]}, {"text": "In the 39 conversations, we have about 12% overall essential sentences.", "labels": [], "entities": []}, {"text": "Evaluation of summarization is believed to be a difficult problem in general.", "labels": [], "entities": [{"text": "summarization", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.8041567802429199}]}, {"text": "In this paper, we use two metrics to measure the accuracy of a system generated summary.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9986196756362915}]}, {"text": "One is sentence pyramid precision, and the other is ROUGE recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.8563750982284546}, {"text": "ROUGE", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9790478348731995}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.8497047424316406}]}, {"text": "As to the statistical significance, we use the 2-tail pairwise student t-test in all the experiments to compare two specific methods.", "labels": [], "entities": []}, {"text": "We also use ANOVA to compare three or more approaches together.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.7945689558982849}]}, {"text": "The sentence pyramid precision is a relative precision based on the GSValue.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.7927581667900085}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.7481371760368347}, {"text": "GSValue", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9431321620941162}]}, {"text": "Since this idea is borrowed from the pyramid metric by, we call it the sentence pyramid precision.", "labels": [], "entities": []}, {"text": "In this paper, we simplify it as the pyramid precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.7971696853637695}]}, {"text": "As we have discussed above, with the reviewers' selections, we get a GSValue for each sentence, which ranges from 0 to 15.", "labels": [], "entities": [{"text": "GSValue", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.9926214218139648}]}, {"text": "With this GSValue, we rank all sentences in a descendant order.", "labels": [], "entities": [{"text": "GSValue", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.780893862247467}]}, {"text": "We also group all sentences with the same GSValue together as one tier Ti , where i is the corre-sponding GSValue; i is called the level of the tier Ti . In this way, we organize all sentences into a pyramid: a sequence of tiers with a descendant order of levels.", "labels": [], "entities": []}, {"text": "With the pyramid of sentences, the accuracy of a summary is evaluated over the best summary we can achieve under the same summary length.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9992921352386475}]}, {"text": "The best summary of k sentences are the top k sentences in terms of GSValue.", "labels": [], "entities": [{"text": "GSValue", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.8280088305473328}]}, {"text": "Other than the sentence pyramid precision, we also adopt the ROUGE recall to evaluate the generated summary with a finer granularity than sentences, e.g., n-gram and longest common subsequence.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.6093529462814331}, {"text": "ROUGE recall", "start_pos": 61, "end_pos": 73, "type": "METRIC", "confidence": 0.7996286749839783}]}, {"text": "Unlike the pyramid method which gives more weight to sentences with a higher GSValue, ROUGE is not sensitive to the difference between essential and optional selections (it considers all sentences in one summary equally).", "labels": [], "entities": [{"text": "GSValue", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9718106389045715}, {"text": "ROUGE", "start_pos": 86, "end_pos": 91, "type": "METRIC", "confidence": 0.7685377597808838}]}, {"text": "Directly applying ROUGE may not be accurate in our experiments.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9842132329940796}]}, {"text": "Hence, we use the overall essential sentences as the gold standard summary for each conversation, i.e., sentences in tiers no lower than T 8 . In this way, the ROUGE metric measures the similarity of a system generated summary to a gold standard summary that is considered important by most human summarizers.", "labels": [], "entities": [{"text": "ROUGE metric", "start_pos": 160, "end_pos": 172, "type": "METRIC", "confidence": 0.9582605063915253}]}, {"text": "Specifically, we choose ROUGE-2 and ROUGE-L as the evaluation metric.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9551265239715576}, {"text": "ROUGE-L", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9424064755439758}]}], "tableCaptions": [{"text": " Table 1: Generalized CWS with Different Edge Weights", "labels": [], "entities": []}, {"text": " Table 2: Compare Page-Rank with CWS", "labels": [], "entities": [{"text": "CWS", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.6522613763809204}]}, {"text": " Table 3: Accuracy of Using Subjective Opinions", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9962156414985657}]}]}