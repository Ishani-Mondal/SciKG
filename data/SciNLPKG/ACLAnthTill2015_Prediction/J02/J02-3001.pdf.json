{"title": [], "abstractContent": [{"text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame.", "labels": [], "entities": []}, {"text": "Given an input sentence and a target word and frame, the system labels constituents with either abstract semantic roles, such as Agent or Patient, or more domain-specific semantic roles, such as Speaker, Message, and Topic.", "labels": [], "entities": []}, {"text": "The system is based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project.", "labels": [], "entities": [{"text": "FrameNet semantic labeling", "start_pos": 135, "end_pos": 161, "type": "TASK", "confidence": 0.7149064540863037}]}, {"text": "We then parsed each training sentence into a syntactic tree and extracted various lexical and syntactic features, including the phrase type of each constituent, its grammatical function, and its position in the sentence.", "labels": [], "entities": []}, {"text": "These features were combined with knowledge of the predicate verb, noun, or adjective, as well as information such as the prior probabilities of various combinations of semantic roles.", "labels": [], "entities": []}, {"text": "We used various lexical clustering algorithms to generalize across possible fillers of roles.", "labels": [], "entities": []}, {"text": "Test sentences were parsed, were annotated with these features, and were then passed through the classifiers.", "labels": [], "entities": []}, {"text": "Our system achieves 82% accuracy in identifying the semantic role of presegmented constituents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.999477207660675}]}, {"text": "At the more difficult task of simultaneously segmenting constituents and identifying their semantic role, the system achieved 65% precision and 61% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9996305704116821}, {"text": "recall", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.9990264177322388}]}, {"text": "Our study also allowed us to compare the usefulness of different features and feature combination methods in the semantic role labeling task.", "labels": [], "entities": [{"text": "semantic role labeling task", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.753322958946228}]}, {"text": "We also explore the integration of role labeling with statistical syntactic parsing and attempt to generalize to predicates unseen in the training data.", "labels": [], "entities": [{"text": "role labeling", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.7607223987579346}, {"text": "statistical syntactic parsing", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.6698185205459595}]}], "introductionContent": [{"text": "Recent years have been exhilarating ones for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.6883549590905508}]}, {"text": "The excitement and rapid advances that had characterized other language-processing tasks such as speech recognition, part-of-speech tagging, and parsing have finally begun to appear in tasks in which understanding and semantics play a greater role.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7535391747951508}, {"text": "part-of-speech tagging", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.718953400850296}, {"text": "parsing", "start_pos": 145, "end_pos": 152, "type": "TASK", "confidence": 0.9654850363731384}]}, {"text": "For example, there has been widespread commercial deployment of simple speech-based natural language understanding systems that answer questions about flight arrival times, give directions, report on bank balances, or perform simple financial transactions.", "labels": [], "entities": []}, {"text": "More sophisticated research systems generate concise summaries of news articles, answer fact-based questions, and recognize complex semantic and dialogue structure.", "labels": [], "entities": []}, {"text": "But the challenges that lie ahead are still similar to the challenge that the field has faced since: moving away from carefully hand-crafted, domaindependent systems toward robustness and domain independence.", "labels": [], "entities": []}, {"text": "This goal is not as faraway as it once was, thanks to the development of large semantic databases such as WordNet) and progress in domain-independent machine learning algorithms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9410252571105957}]}, {"text": "Current information extraction and dialogue understanding systems, however, are still based on domain-specific frame-and-slot templates.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.8054018318653107}, {"text": "dialogue understanding", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.8548262119293213}]}, {"text": "Systems for booking airplane information use domain-specific frames with slots like orig city, dest city, or depart time.", "labels": [], "entities": [{"text": "booking airplane information", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.8200950821240743}]}, {"text": "Systems for studying mergers and acquisitions use slots like products, relationship, joint venture company, and amount ().", "labels": [], "entities": [{"text": "amount", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9786965847015381}]}, {"text": "For natural language understanding tasks to proceed beyond these specific domains, we need semantic frames and semantic understanding systems that do not require anew set of slots for each new application domain.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.6485903958479563}]}, {"text": "In this article we describe a shallow semantic interpreter based on semantic roles that are less domain specific than to airport or joint venture company.", "labels": [], "entities": []}, {"text": "These roles are defined at the level of semantic frames of the type introduced by, which describe abstract actions or relationships, along with their participants.", "labels": [], "entities": []}, {"text": "For example, the Judgement frame contains roles like judge, evaluee, and reason, and the Statement frame contains roles like speaker, addressee, and message, as the following examples show: These shallow semantic roles could play an important role in information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 251, "end_pos": 273, "type": "TASK", "confidence": 0.8090411722660065}]}, {"text": "For example, a semantic role parse would allow a system to realize that the ruling that is the direct object of change in (3) plays the same Theme role as the ruling that is the subject of change in (4): The canvassing board changed its ruling on Wednesday.", "labels": [], "entities": [{"text": "semantic role parse", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.6968066096305847}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2  Most frequent values of the path feature in the training data.", "labels": [], "entities": []}, {"text": " Table 3  Distributions calculated for semantic role identification: r indicates semantic role, pt phrase  type, gov grammatical function, h head word, and t target word, or predicate.", "labels": [], "entities": [{"text": "semantic role identification", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.7423619826634725}]}, {"text": " Table 7  Different estimators of grammatical function. The columns of the table correspond to  Figures 8a, 8b, and 8c.", "labels": [], "entities": []}, {"text": " Table 8  Sample probabilities of a constituent's being a frame element.", "labels": [], "entities": []}, {"text": " Table 10  Clustering results on NP constituents only, 4,086 instances.", "labels": [], "entities": []}, {"text": " Table 11  WordNet results on NP constituents only, 4,086 instances.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.926359236240387}]}, {"text": " Table 12  Bootstrapping results on NP constituents only, 4,086 instances.", "labels": [], "entities": []}, {"text": " Table 14  Frame element groups for the verb blame in the Judgment frame.", "labels": [], "entities": []}, {"text": " Table 15  Combined results on boundary identification and role labeling.", "labels": [], "entities": [{"text": "boundary identification", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.8578072190284729}, {"text": "role labeling", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.7564629316329956}]}, {"text": " Table 16  Results on rescoring parser output.", "labels": [], "entities": [{"text": "rescoring parser output", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.8583120107650757}]}, {"text": " Table 16. The results  show a slight, but not statistically significant, increase in recall of frame elements. One  possible reason that the improvement is not greater is the relatively small number of  parses per sentence available for rescoring. Unfortunately, the parsing algorithm used  to generate n-best parses is inefficient, and generating large numbers of parses seems  to be computationally intractable. In theory, the complexity of n-best variations of the  Viterbi chart-parsing algorithm is quadratic in n. One can simply expand the dynamic  programming chart to have n slots for the best solutions to each subproblem, rather  than one. As our grammar forms new constituents from pairs of smaller constituents  (that is, it internally uses a binarized grammar), for each pair of constituents considered  in a single-best parser, up to n 2 pairs would be present in the n-best variant. The  beam search used by modern parsers, however, makes the analysis more complex.  Lexicalization of parse constituents dramatically increases the number of categories  that must be stored in the chart, and efficient parsing requires that constituents below  a particular probability threshold be dropped from further consideration. In practice,  returning a larger number of parses with our algorithm seems to require increasing  the pruning beam size to a degree that makes run times prohibitive.  In addition to the robustness of even relatively simple parsing models, one expla- nation for the modest improvement may be the fact that even our integrated system  includes semantic information for only one word in the sentence. As the coverage of  our frame descriptions increases, it may be possible to do better and to model the  interactions between the frames invoked by a text.", "labels": [], "entities": [{"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9964864253997803}]}, {"text": " Table 19  Cross-frame performance of various distributions. f represents the FrameNet semantic frame.", "labels": [], "entities": [{"text": "FrameNet semantic frame", "start_pos": 78, "end_pos": 101, "type": "DATASET", "confidence": 0.8388270934422811}]}, {"text": " Table 20  Cross-frame performance of various distributions. d represents the FrameNet semantic domain.", "labels": [], "entities": []}, {"text": " Table 21  Cross-domain performance of various distributions.", "labels": [], "entities": []}]}