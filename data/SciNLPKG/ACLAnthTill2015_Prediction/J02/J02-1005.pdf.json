{"title": [{"text": "Squibs and Discussions The DOP Estimation Method Is Biased and Inconsistent", "labels": [], "entities": [{"text": "DOP Estimation", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.8668528497219086}]}], "abstractContent": [{"text": "A data-oriented parsing or DOP model for statistical parsing associates fragments of linguistic representations with numerical weights, where these weights are estimated by normalizing the empirical frequency of each fragment in a training corpus (see Bod [1998] and references cited therein).", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7486945390701294}, {"text": "Bod [1998]", "start_pos": 252, "end_pos": 262, "type": "DATASET", "confidence": 0.9365484714508057}]}, {"text": "This note observes that this estimation method is biased and inconsistent; that is, the estimated distribution does not in general converge on the true distribution as the size of the training corpus increases.", "labels": [], "entities": []}], "introductionContent": [{"text": "The data-oriented parsing or DOP approach to statistical natural language analysis has attracted considerable attention recently and has been used to produce statistical language models based on various kinds of linguistic representation, as described in.", "labels": [], "entities": [{"text": "data-oriented parsing or DOP", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.7621076554059982}, {"text": "statistical natural language analysis", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.671672910451889}]}, {"text": "These models are based on the intuition that statistical generalizations about natural languages should be stated in terms of \"chunks\" or \"fragments\" of linguistic representations.", "labels": [], "entities": []}, {"text": "Linguistic representations are produced by combining these fragments, but unlike in stochastic models such as Probabilistic Context-Free Grammars, a single linguistic representation maybe generated by several different combinations of fragments.", "labels": [], "entities": []}, {"text": "These fragments maybe large, permitting DOP models to describe nonlocal dependencies.", "labels": [], "entities": []}, {"text": "Usually the fragments used in a DOP model are themselves obtained from a training corpus of linguistic representations.", "labels": [], "entities": []}, {"text": "For example, in DOP1 or Tree-DOP the fragments are typically all the connected multinode trees that appear as subgraphs of any tree in the training corpus.", "labels": [], "entities": []}, {"text": "This note shows that the estimation procedure standardly used to set the parameters or fragment weights of a DOP model (see, for example, Bod) is biased and inconsistent.", "labels": [], "entities": [{"text": "Bod", "start_pos": 138, "end_pos": 141, "type": "DATASET", "confidence": 0.9604749083518982}]}, {"text": "This means that as sample size increases, the corresponding sequence of probability distributions estimated by this procedure does not converge to the true distribution that generated the training data.", "labels": [], "entities": []}, {"text": "Consistency is usually regarded as the minimal requirement any estimation method must satisfy, and the inconsistency of the standard DOP estimation method suggests it maybe worth looking for other estimation methods.", "labels": [], "entities": [{"text": "Consistency", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9414748549461365}]}, {"text": "Note that while the bulk of DOP research uses the estimation procedure studied here, recently there has been research that has used other estimators for DOP models, and it would be interesting to investigate the statistical properties of these estimators as well.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}