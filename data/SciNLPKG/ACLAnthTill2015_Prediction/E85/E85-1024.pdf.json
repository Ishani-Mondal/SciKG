{"title": [], "abstractContent": [{"text": "The UCREL team at the University of Lancaster is engaged in the development of a robust parsing mechanism, which will assign the appropriate grammatical structure to sentences in unconstrained English text.", "labels": [], "entities": []}, {"text": "The techniques used involve the calculation of probabilities for competing structures, and are based on the techniques successfully used in tagging (i.e. assigning grammatical word classes) to the LOB (Lancaster-Oslo/Bergen) corpus.", "labels": [], "entities": [{"text": "assigning grammatical word classes)", "start_pos": 154, "end_pos": 189, "type": "TASK", "confidence": 0.6636103391647339}, {"text": "LOB (Lancaster-Oslo/Bergen) corpus", "start_pos": 197, "end_pos": 231, "type": "DATASET", "confidence": 0.6939128168991634}]}, {"text": "The first step in the parsing process involves dictionary lookup of successive pairs of grammatically tagged words, to give a number of possible continuations to the current parse.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9770452976226807}]}, {"text": "Since this lookup will often not be able unambiguously to distinguish the point at which a grammatical constituent should be closed, the second step of the parsing process will have to insert closures and distinguish between alternative parses.", "labels": [], "entities": []}, {"text": "It will generate trees representing these possible alternatives, insert closure points for the constituents, and compute a probability for each parse tree from the probability of each constituent within the tree.", "labels": [], "entities": []}, {"text": "It will then be able to select a preferred parse or parses for output.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present an overview of one part of the work currently being carried out at the Unit for Computer Research on the English Language (UCREL) in the University of Lancaster, under SERC research grant number GR/C/47700.", "labels": [], "entities": [{"text": "SERC research grant number GR/C/47700", "start_pos": 193, "end_pos": 230, "type": "DATASET", "confidence": 0.8134970929887559}]}, {"text": "This work involves the automatic syntactic analysis or parsing of the LOB corpus, using the statistical or constituent-likelihood (CL) grammar ideas of.", "labels": [], "entities": [{"text": "syntactic analysis or parsing", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.7029329538345337}, {"text": "LOB corpus", "start_pos": 70, "end_pos": 80, "type": "DATASET", "confidence": 0.7521293461322784}]}, {"text": "The work is based on the grammatical tagging of the LOB corpus, both as providing a partially analysed text and because of the techniques used in assigning tags.", "labels": [], "entities": [{"text": "LOB corpus", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.8920015692710876}]}, {"text": "We therefore begin by briefly describing this earlier project.", "labels": [], "entities": []}, {"text": "The grammatical tagging of the LOB corpus is described in detail elsewhere (see, for example, Leech,, but in essence there are three stages.", "labels": [], "entities": [{"text": "grammatical tagging", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7105290293693542}, {"text": "LOB corpus", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.7885405123233795}, {"text": "Leech", "start_pos": 94, "end_pos": 99, "type": "DATASET", "confidence": 0.9704996943473816}]}, {"text": "The first stage takes the original corpus, on which a certain amount of pre-editing (both automatic and manual) has been performed.", "labels": [], "entities": []}, {"text": "It assigns to each word in the corpus a set of possible tags, and it is assumed that the correct tag is in this set.", "labels": [], "entities": []}, {"text": "The set of possible tags is chosen without at this stage considering the context in which the word appears, and the choice is made by using an ordered set of decision rules, the most commonly used of which (in about 65-70% of cases) is to look the word up in a dictionary of some 7000 words.", "labels": [], "entities": []}, {"text": "The third stage involves looking at those cases where the first stage has resulted in more than one tag being assigned to a word.", "labels": [], "entities": []}, {"text": "In this case we calculate the probability of each possible sequence of ambiguous tags, and the most likely sequence is chosen as the correct one.", "labels": [], "entities": []}, {"text": "In most cases the probability of a sequence of tags is calculated by multiplying together the pairwise probabilities of one tag following another, and these pairwise probabilities were derived from a statistical analysis of cooccurrence of tags in the tagged Brown corpus.", "labels": [], "entities": []}, {"text": "A further stage was later inserted between the two stages described above.", "labels": [], "entities": []}, {"text": "This stage involves the ability to look for patterns of sequences of words and putative tags assigned by the first stage, and to modify the sets of tags assigned to words.", "labels": [], "entities": []}, {"text": "This enables various problematical situations to be resolved or clarified in order to improve the disambiguating ability of the third stage.", "labels": [], "entities": []}, {"text": "After the third stage (when the appropriate tag will have been automatically selected some 96,5% of the time), the remaining errors are removed by a manual post-editing phase.", "labels": [], "entities": []}, {"text": "The fundamental idea on which our syntactic analysis is based, originally formulated in, is that the general principles behind the tagging system could be used at the parsing level.", "labels": [], "entities": []}, {"text": "Thus a first stage of parsing could be to lookup a tag in a dictionary to derive a set of possible constituents (or \"hypertags\") containing this tag.", "labels": [], "entities": []}, {"text": "Similarly, in the third stage, the probability of any particular constituent being constructed out of a particular set of constituents or word-classes at the next lower level could be used to disambiguate a set of constituents posited at the first stage.", "labels": [], "entities": []}, {"text": "To this end some 2000 sentences from the LOB corpus have been manually parsed, and the results stored as a \"treebank\" or database of information on the frequency of occurrence of possible grammatical structures.", "labels": [], "entities": [{"text": "LOB corpus", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.9381921589374542}]}, {"text": "Thus, for each possible \"mother\" constituent, there will be stored a set of sequences of daughter constituents or word-classes, together with their frequencies.", "labels": [], "entities": []}, {"text": "The second stage generalises to a search for particular syntactic patterns which are recognisable in context, and the resolution of which will improve the accuracy of the third stage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9989314675331116}]}, {"text": "We develop these ideas in the remainder of the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}