{"title": [{"text": "Automatic Evaluation and Uniform Filter Cascades for Inducing N-Best Translation Lexicons", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper shows how to induce an N-best translation lexicon from a bilingual text corpus using statistical properties of the corpus together with four external knowledge sources.", "labels": [], "entities": []}, {"text": "The knowledge sources are cast as filters, so that any subset of them can be cascaded in a uniform framework.", "labels": [], "entities": []}, {"text": "A new objective evaluation measure is used to compare the quality of lexicons induced with different filter cascades.", "labels": [], "entities": []}, {"text": "The best filter cascades improve lexicon quality by up to 137% over the plain vanilla statistical method, and approach human performance.", "labels": [], "entities": []}, {"text": "Drastically reducing the size of the training corpus has a much smaller impact on lexicon quality when these knowledge sources are used.", "labels": [], "entities": []}, {"text": "This makes it practical to train on small hand-built corpora for language pairs where large bilingual corpora are unavailable.", "labels": [], "entities": []}, {"text": "Moreover, three of the four filters prove useful even when used with large training corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "A machine translation system must be able to choose among possible translations based on context.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7351696193218231}]}, {"text": "To do this, it usuMly relies on a translation lexicon that contains a number of possible translations for each word.", "labels": [], "entities": []}, {"text": "N-best translation lexicons contain up to N candidate translations for each word, ordered from most probable to least probable, sometimes specifying a priori probabilities or likelihood scores.", "labels": [], "entities": []}, {"text": "Existing automatic methods for constructing N-best translation lexicons rely on the availability of large training corpora of parallel texts in the source and target languages.", "labels": [], "entities": []}, {"text": "For some methods, the corpora must also be aligned by sentence.", "labels": [], "entities": []}, {"text": "Unfortunately, such training corpora are available for only a handful of language pairs, and the cost to create enough training data manually for new language pairs is very high.", "labels": [], "entities": []}, {"text": "anew automatic evaluation method for N-best translation lexicons, 2.", "labels": [], "entities": []}, {"text": "a filter-based approach for enhancing statistical translation models with non-statistical sources of information, 3.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.737688809633255}]}, {"text": "four sources of information that can drastically reduce the necessary amount of training material.", "labels": [], "entities": []}], "datasetContent": [{"text": "All translation lexicons discussed in this paper were created and evaluated using the procedure in.", "labels": [], "entities": []}, {"text": "First, candidate translations were generated for each pair of aligned training sentences, by taking a simple cross-product of the words.", "labels": [], "entities": []}, {"text": "Next, the candidate translations from each pair of training sentences were passed through a cascade of filters.", "labels": [], "entities": []}, {"text": "The remaining candidate translations from all training sentence pairs were pooled together and fed into a fixed decision procedure.", "labels": [], "entities": []}, {"text": "The output of the decision procedure was a model of word correspondences between the two halves of the training corpus --a translation lexicon.", "labels": [], "entities": []}, {"text": "Each filter combination resulted in a different model.", "labels": [], "entities": []}, {"text": "All the models were compared in terms of how well they represented a held-out test set.", "labels": [], "entities": []}, {"text": "The evaluation was performed objectively and automatically using Bitext-Based Lexicon Evaluation (BIBLE, described below).", "labels": [], "entities": [{"text": "BIBLE", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.7736068367958069}]}, {"text": "BIBLE assigned a score for each model, and these scores were used to compare the effectiveness of various filter cascades.", "labels": [], "entities": [{"text": "BIBLE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8737807273864746}]}, {"text": "As shown in, the only independent variable in the framework is the cascade of filters used on the translation candidates generated by each sentence pair, while the only dependent variable is a numerical score.", "labels": [], "entities": []}, {"text": "Since the filters only serve to remove certain translation candidates, any number of filters can be used in sequence.", "labels": [], "entities": []}, {"text": "This arrangement allows for fair comparison of different filter combinations.", "labels": [], "entities": []}, {"text": "Translation lexicon quality has traditionally been measured on two axes: precision and recall.", "labels": [], "entities": [{"text": "Translation lexicon", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9052161574363708}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9995809197425842}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9973061084747314}]}, {"text": "Recall is the fraction of the source language's vocabulary that appears in the lexicon.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9591325521469116}]}, {"text": "Precision is the fraction of lexicon entries that are correct.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9901160597801208}]}, {"text": "While the true size of the source vocabulary is usually unknown, recall can be estimated using a representative text sample by computing the fraction of words in the text that also appear in the lexicon.", "labels": [], "entities": [{"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9960749745368958}]}, {"text": "Measuring precision is much more difficult, because it is unclear what a \"correct\" lexicon entry is --different translations are appropriate for different contexts, and, inmost cases, more than one translation is correct.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9992067217826843}]}, {"text": "This is why evaluation of translation has eluded automation efforts until now.", "labels": [], "entities": [{"text": "evaluation of translation", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7741315960884094}]}, {"text": "The large number of quantitative lexicon evaluations required for the present study made it infeasible to rely on evaluation by human judges.", "labels": [], "entities": []}, {"text": "The only existing automatic lexicon evaluation method that I am aware of is the perplexity comparisons used by in the fl'amework of their Model 1.", "labels": [], "entities": []}, {"text": "Lexicon perplexity indicates how \"sure\" a translation lexicon is about its contents.", "labels": [], "entities": []}, {"text": "It does not, however, directly measure the quality of those contents.", "labels": [], "entities": []}, {"text": "BIBLE is a family of algorithms, based on the observation that translation pairs 2 tend to appear in corresponding sentences in an aligned bilingual text corpus (a bitext).", "labels": [], "entities": [{"text": "BIBLE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8058555126190186}]}, {"text": "Given a test set of aligned sentences, a better translation lexicon will contain a higher fraction of the (source word, target word) pairs in those sentences.", "labels": [], "entities": []}, {"text": "This fraction can be computed either by token or by type, depending on ghe application.", "labels": [], "entities": []}, {"text": "If only the words in the lexicon are considered, BIBLE gives an estimate of precision.", "labels": [], "entities": [{"text": "BIBLE", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9890402555465698}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9991326928138733}]}, {"text": "If all the words in the text are considered, then BIBLE measures percent correct.", "labels": [], "entities": [{"text": "BIBLE", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9964809417724609}, {"text": "correct", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.9181679487228394}]}, {"text": "The greater the overlap between the vocabulary of the test bitext and the vocabulary of the lexicon being evaluated, the more confidence can be placed in the BIBLE score.", "labels": [], "entities": [{"text": "BIBLE score", "start_pos": 158, "end_pos": 169, "type": "METRIC", "confidence": 0.9365152716636658}]}, {"text": "A bilingual teXt corpus of Canadian parliamentary proceedings (\"Hansards\") was aligned by sentence using the method presented in.", "labels": [], "entities": [{"text": "teXt corpus of Canadian parliamentary proceedings (\"Hansards\")", "start_pos": 12, "end_pos": 74, "type": "DATASET", "confidence": 0.826366964313719}]}, {"text": "From the resulting aligned corpus, this study used only sentence pairs that were aligned one to one, and then only when they were less than 16 words long and aligned with high confidence.", "labels": [], "entities": []}, {"text": "Morphological variants in these sentences were stemmed to a canonical form.", "labels": [], "entities": []}, {"text": "Fifteen thousand sentence pairs were randomly selected and reserved for testing; one hundred thousand were used for training.", "labels": [], "entities": []}, {"text": "The independent variable in the experiments was a varying combination of four different filters, used with six different sizes of training corpora.", "labels": [], "entities": []}, {"text": "These four filters fall into three categories: predicate filters, oracle filters and alignment filters.", "labels": [], "entities": []}, {"text": "A predicate .filter is one where the candidate translation pair (S, T) must satisfy some predicate in order to pass the filter.", "labels": [], "entities": []}, {"text": "Various predicate filters are discussed in.", "labels": [], "entities": []}, {"text": "An oracle filter is useful when a list of likely translation pairs is available a priori.", "labels": [], "entities": []}, {"text": "Then i if the translation pair (S, T) occurs in this oracle list, it is reasonable to filter out all other translation pairs involving S or T in the same sentence pair.", "labels": [], "entities": []}, {"text": "An alignment filter is based on the relative positions of Sand T in their respective texts.", "labels": [], "entities": []}, {"text": "The decision procedure used to select lexicon entries from the multiset of candidate translation pairs is a variation of the method presented in. found binomial log-likelihood ratios to be relatively accurate when dealing with rare tokens.", "labels": [], "entities": []}, {"text": "This statistic was used to estimate dependencies between all co-occuring (source word, target word) pairs.", "labels": [], "entities": []}, {"text": "For each source word S, target words were ranked by their dependence with S.", "labels": [], "entities": []}, {"text": "The top N target words in the rank-ordering for S formed the entry for S in the N-best lexicon.", "labels": [], "entities": []}, {"text": "In other words, the relative magnitude of dependence between Sand its candidate translations was used as a maximum likelihood estimator of the translations of S.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: lexicon entries for French \"grand\" in 7-best lexicons generated with different filters -- The baseline lexicon has correct entries only for the most likely translation and for the second most  likely translation. The POS Filter throws out nouns and pronouns, and makes room for \"high\"  and \"vast.\" The Word Alignment Filter removes enough noise to capture \"high, .... vast,\" \"giant,\"  and \"extensive\" all at once.  ~ Entry #", "labels": [], "entities": []}, {"text": " Table 4: lexicon entries for French \"parti\" in 7-best lexicons generated with different filters -- Only the most likely translation and the fourth most likely translation in the baseline lexicon are  appropriate. The Cognate Filter allows the fourth item, a cognate, to percolate up to second place,  and makes room for \"two-party\" in sixth place.", "labels": [], "entities": []}]}