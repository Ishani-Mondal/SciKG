{"title": [{"text": "A Bayesian hybrid method for context-sensitive spelling correction", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.6715838213761648}]}], "abstractContent": [{"text": "Two classes of methods have been shown to be useful for resolving lexical ambiguity.", "labels": [], "entities": [{"text": "resolving lexical ambiguity", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.8586268226305643}]}, {"text": "The first relies on tile presence of particular words within some distance of tile ambiguous target word; the second uses the pattern of words and part-of-speech tags around the target word.", "labels": [], "entities": []}, {"text": "These methods have complementary coverage: the former captures the lexical \"atmosphere\" (discourse topic, tense, etc.), while tile latter captures local syntax.", "labels": [], "entities": []}, {"text": "Yarowsky has exploited this complementarity by combining the two methods using decision lists.", "labels": [], "entities": []}, {"text": "The idea is to pool the evidence provided by the component methods, and to then solve a target problem by applying the single strongest piece of evidence, whatever type it happens to be.", "labels": [], "entities": []}, {"text": "This paper takes Yarowsky's work as a starting point, applying decision lists to the problem of context-sensitive spelling correction.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.6277217864990234}]}, {"text": "Decision lists are found, by and large, to outperform either component method.", "labels": [], "entities": []}, {"text": "However, it is found that further improvements can be obtained by taking into account not just the single strongest piece of evidence, but all the available evidence.", "labels": [], "entities": []}, {"text": "A new hybrid method, based on Bayesian classifiers, is presented for doing this, and its performance improvements are demonstrated.", "labels": [], "entities": []}], "introductionContent": [{"text": "Two classes of methods have been shown useful for resolving lexical ambiguity.", "labels": [], "entities": [{"text": "resolving lexical ambiguity", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.8482579986254374}]}, {"text": "The first tests for the presence of particular context words within a certain distance of the ambiguous target word.", "labels": [], "entities": []}, {"text": "The second tests for collocations --patterns of words and part-of-speech tags around the target word.", "labels": [], "entities": []}, {"text": "The context-word and collocation methods have complementary coverage: the former captures the lexical \"atmosphere\" (discourse topic, tense, etc.), while the latter captures local syntax. has exploited this complementarity by combining the two methods using decision lists.", "labels": [], "entities": []}, {"text": "The idea is to pool the evidence provided by the component methods, and to then solve a target problem by applying the single strongest piece of evidence, whatever type it happens to be.", "labels": [], "entities": []}, {"text": "Yarowsky applied his method to the task of restoring missing accents in Spanish and French, and found that it outperformed both the method based on context words, and one based on local syntax.", "labels": [], "entities": []}, {"text": "This paper takes Yarowsky's method as a starting point, and hypothesizes that further improvements can be obtained by taking into account not only the single strongest piece of evidence, but all the available evidence.", "labels": [], "entities": []}, {"text": "A method is presented for doing this, based on Bayesian classifiers.", "labels": [], "entities": []}, {"text": "The work reported here was applied not to accent restoration, but to a related lexical disambiguation task: context-sensitive spelling correction.", "labels": [], "entities": [{"text": "accent restoration", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8528726100921631}, {"text": "context-sensitive spelling correction", "start_pos": 108, "end_pos": 145, "type": "TASK", "confidence": 0.6113481819629669}]}, {"text": "The task is to fix spelling errors that happen to result invalid words in the lexicon; for example: I'd like the chocolate cake for ,desert.", "labels": [], "entities": []}, {"text": "where dessert was misspelled as desert.", "labels": [], "entities": []}, {"text": "This goes beyond the capabilities of conventional spell checkers, which can only detect errors that result in non-words.", "labels": [], "entities": [{"text": "spell checkers", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.7277328372001648}]}, {"text": "We start by applying a very simple method to the task, to serve as a baseline for comparison with the other methods.", "labels": [], "entities": []}, {"text": "We then al)ply each of the two component methods mentioned above --context words and collocations.", "labels": [], "entities": []}, {"text": "We try two ways of combining these components: decision lists, and Bayesian classifiers.", "labels": [], "entities": []}, {"text": "We evaluate the above methods by comparing them with an alternative approach to spelling correction based on part-of-speech trigrams.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8917196393013}]}, {"text": "The sections below discuss the task of context-sensitive spelling correction, the five methods we tried for the task (baseline, two component methods, and two hybrid methods), and the evaluation.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.6662871142228445}]}, {"text": "The final section draws some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "While the previous section demonstrated that the Bayesian hybrid method does better than its components, we would still like to know how it compares with alternative methods.", "labels": [], "entities": []}, {"text": "We looked at a method based on part-of-speech trigrams, developed and implemented by.", "labels": [], "entities": []}, {"text": "Schabes's method can be viewed as performing an abductive inference: given a sentence containing an ambiguous word, it asks which choice wi for that word would best explain the observed sequence of words in the sentence.", "labels": [], "entities": []}, {"text": "It answers this question by substituting each wi in turn into the sentence.", "labels": [], "entities": []}, {"text": "The wi that produces the highest-probability sentence is selected.", "labels": [], "entities": []}, {"text": "Sentence probabilities are calculated using a part-of-speech trigram model.", "labels": [], "entities": [{"text": "Sentence probabilities", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8688593506813049}]}, {"text": "We tried Schabes's method on the usual confusion sets; the results are in the last column of.", "labels": [], "entities": []}, {"text": "It can be seen that trigrams and the Bayesian hybrid method each have their better moments.", "labels": [], "entities": []}, {"text": "Trigrams are at their worst when the words in the confusion set have the same part of speech.", "labels": [], "entities": []}, {"text": "In this case, trigrams can distinguish between the words only by their prior probabilities --this follows from the way the method calculates sentence probabilities.", "labels": [], "entities": []}, {"text": "Thus, for {between, among}, for example, where both words are prepositions, trigrams score the same as the baseline method.", "labels": [], "entities": []}, {"text": "In such cases, the Bayesian hybrid method is clearly better.", "labels": [], "entities": []}, {"text": "On the other hand, when the words in the confusion set have different parts of speech --as in, for example, {there, their, they%e} --trigrams are often better than the Bayesian method.", "labels": [], "entities": []}, {"text": "We believe this is because trigrams look not just at a few words on either side of the target word, but at the part-of-speech sequence of the whole sentence.", "labels": [], "entities": []}, {"text": "This analysis indicates a complementarity between trigrams and Bayes, and suggests a combination ill which trigrams would be applied first, but if trigrams determine that the words in the confusion set have the same part of speech for the sentence at issue, then the sentence would be passed to the Bayesian method.", "labels": [], "entities": []}, {"text": "This is a research direction we plan to pursue.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the baseline method for 18 confusion sets. The \"Most frequent word\"  column gives the word in the confusion set that occurred most frequently in the training corpus. (In  subsequent tables, confusion sets will be referred to by their most frequent word.) The \"Baseline\"  column gives the prediction a,ccuracy of the baseline system on the test corpus.", "labels": [], "entities": []}, {"text": " Table 2: Performance of the method of context words as a function of k, the half-width of the context  window. The bottom line of the table shows the number of context words learned, averaged over  all confusion sets, also as a function of k.", "labels": [], "entities": []}, {"text": " Table 3: Performance of the method of collocations as a function of g, the maximum length of a  collocation. The bottom line of the table shows the number of collocations learned, averaged over  all confusion sets, also as a function of e.", "labels": [], "entities": []}, {"text": " Table 6: Performance of decision lists with the reliability and U(xly ) strength metrics.", "labels": [], "entities": [{"text": "reliability", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.994734525680542}, {"text": "U(xly ) strength metrics", "start_pos": 65, "end_pos": 89, "type": "METRIC", "confidence": 0.946284830570221}]}, {"text": " Table 7: Performance of six methods for context-sensitive spelling correction.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 41, "end_pos": 78, "type": "TASK", "confidence": 0.6386367579301199}]}]}