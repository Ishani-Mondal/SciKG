{"title": [{"text": "Lexical Heads, Phrase Structure and the Induction of Grammar", "labels": [], "entities": [{"text": "Lexical Heads", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8275061547756195}, {"text": "Phrase Structure", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7975473999977112}, {"text": "Induction of Grammar", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.6237528920173645}]}], "abstractContent": [{"text": "Acquiring linguistically plausible phrase-structure grammars from ordinary text has proven difficult for standard induction techniques, and researchers have turned to supervised training from bracketed corpora.", "labels": [], "entities": []}, {"text": "We examine why previous approaches have failed to acquire desired grammars, concentrating our analysis on the inside-outside algorithm (Baker, 1979), and propose that with a representation of phrase structure centered on head relations such supervision may not be necessary.", "labels": [], "entities": []}], "introductionContent": [{"text": "Researchers investigating the acquisition of phrase-structure grammars from raw text have had only mixed success.", "labels": [], "entities": [{"text": "acquisition of phrase-structure grammars from raw text", "start_pos": 30, "end_pos": 84, "type": "TASK", "confidence": 0.7862255147525242}]}, {"text": "In particular, unsupervised learning techniques, such as the inside-outside algorithm for estimating the parameters of stochastic context-free grammars (SCFGs), tend to produce grammars that structure text in ways contrary to our linguistic intuitions.", "labels": [], "entities": []}, {"text": "One effective way around this problem is to use hand-structured text like the Penn Treebank to train the learner: (Pereira and demonstrate that the inside-outside algorithm can learn grammars effectively given such constraint; from a bracketed corpus successfully learns rules that iteratively transform a default phrase-structure into a better one fora particular sentence.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 78, "end_pos": 91, "type": "DATASET", "confidence": 0.994077742099762}]}, {"text": "The necessity of bracketed corpora for training is grating to our sensibilities, for several reasons.", "labels": [], "entities": []}, {"text": "First, bracketed corpora are not easy to come by.", "labels": [], "entities": []}, {"text": "Second, there is a sense that in learning from them, little of interest is going on.", "labels": [], "entities": []}, {"text": "In the case of the acquisition of stochastic context-free grammars, the parameters can be read off of a fully-bracketed corpus by simply counting.", "labels": [], "entities": []}, {"text": "Finally, the inability of current models to learn (without supervision) the parameters we desire suggests that our models are mismatched to the problem.", "labels": [], "entities": []}, {"text": "This paper examines why some previous approaches have failed to acquire desired grammars without supervision, and proposes that with a different conception of phrase-structure supervision might not be necessary.", "labels": [], "entities": []}, {"text": "In particular, we examine some reasons why SCFGs are poor models to use for learning human language, especially when combined with the inside-outside algorithm.", "labels": [], "entities": []}, {"text": "We argue that head-driven grammatical formalisms like dependency grammars or link grammars are better suited to the task.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have built a stochastic, feature-based Earley parser () that can be trained using the inside-outside algorithm.", "labels": [], "entities": []}, {"text": "Here we describe some tests that explore the interaction of the head-driven tanguage models described above with this parser and training method.", "labels": [], "entities": []}], "tableCaptions": []}