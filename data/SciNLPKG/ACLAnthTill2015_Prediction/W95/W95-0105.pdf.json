{"title": [{"text": "Disambiguating Noun Groupings with Respect to WordNet Senses", "labels": [], "entities": [{"text": "Disambiguating Noun Groupings", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.820046067237854}]}], "abstractContent": [{"text": "Word groupings useful for language processing tasks are increasingly available, as thesauri appear on-line, and as distributional word clustering techniques improve.", "labels": [], "entities": [{"text": "Word groupings", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.64693184196949}, {"text": "distributional word clustering", "start_pos": 115, "end_pos": 145, "type": "TASK", "confidence": 0.633147676785787}]}, {"text": "However, for many tasks, one is interested in relationships among word senses, not words.", "labels": [], "entities": []}, {"text": "This paper presents a method for automatic sense disambiguafion of nouns appearing within sets of related nouns-the kind of data one finds in on-line thesauri, or as the output of distributional clustering algorithms.", "labels": [], "entities": [{"text": "automatic sense disambiguafion of nouns appearing within sets of related nouns-the", "start_pos": 33, "end_pos": 115, "type": "TASK", "confidence": 0.8167568634856831}]}, {"text": "Disambiguation is performed with respect to WordNet senses, which are fairly fine-gained; however, the method also permits the assignment of higher-level WordNet categories rather than sense labels.", "labels": [], "entities": []}, {"text": "The method is illustrated primarily by example, though results of a more rigorous evaluation are also presented.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word groupings useful for language processing tasks are increasingly available, as thesauri appear on-line, and as distributional techniques become increasingly widespread (e.g. ().", "labels": [], "entities": []}, {"text": "However, for many tasks, one is interested in relationships among word senses, not words.", "labels": [], "entities": []}, {"text": "Consider, for example, the cluster containing attorney, counsel, trial, court, and judge, used by to illustrate a \"semantically sticky\" group of words.", "labels": [], "entities": []}, {"text": "As is often the case where sense ambiguity is involved, we as readers impose the most coherent interpretation on the words within the group without being aware that we are doing so.", "labels": [], "entities": []}, {"text": "Yet a computational system has no choice but to consider other, more awkward possibilities --for example, this cluster might be capturing a distributional relationship between advice (as one sense of counsel) and royalty (as one sense of court).", "labels": [], "entities": []}, {"text": "This would be a mistake for many applications, such as query expansion in information retrieval, where a surfeit of false connections can outweigh the benefits obtained by using lexical knowledge.", "labels": [], "entities": [{"text": "query expansion in information retrieval", "start_pos": 55, "end_pos": 95, "type": "TASK", "confidence": 0.6853660464286804}]}, {"text": "One obvious solution to this problem would be to extend distributional grouping methods to word senses.", "labels": [], "entities": [{"text": "distributional grouping", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.6615807414054871}]}, {"text": "For example, one could construct vector representations of senses on the basis of their co-occurrence with words or with other senses.", "labels": [], "entities": []}, {"text": "Unfortunately, there are few corpora annotated with word sense information, and computing reliable statistics on word senses rather than words will require more data, rather than less.", "labels": [], "entities": []}, {"text": "1 Furthermore, one widely available example of a large, manually sense-tagged corpus --the WordNet group's annotated subset of the Brown corpus 2 --vividly illustrates the difficulty in obtaining suitable data.", "labels": [], "entities": [{"text": "WordNet group's annotated subset of the Brown corpus", "start_pos": 91, "end_pos": 143, "type": "DATASET", "confidence": 0.9450123839908176}]}, {"text": "1Actually, this depends on the fine-grainedness of sense distinctions; clearly one could annotate corpora with very high level semantic distinctions For example, take such a coarse-grained approach, utilizing on the order of 10 to 15 semantic tags fora given domain.", "labels": [], "entities": [{"text": "1Actually", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9218305349349976}]}, {"text": "I assume throughout this paper that finer-grained distinctions than that are necessary.", "labels": [], "entities": []}, {"text": "2Available by anonymous ftp to clarity.princeton.edu as pub/wnl.", "labels": [], "entities": []}, {"text": "Z; Word_Net is described by.", "labels": [], "entities": [{"text": "Word_Net", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.9172101418177286}]}, {"text": "It is quite small, by current corpus standards (on the order of hundreds of thousands of words, rather than millions or tens of millions); the direct annotation methodology used to create it is labor intensive ( found that direct annotation takes twice as long as automatic tagging plus correction, for partof-speech annotation); and the output quality reflects the difficulty of the task (inter-annotator disagreement is on the order of 10%, as contrasted with the approximately 3% error rate reported for part-of-speech annotation by.", "labels": [], "entities": []}, {"text": "There have been some attempts to capture the behavior of semantic categories in a distributional setting, despite the unavailability of sense-annotated corpora.", "labels": [], "entities": []}, {"text": "For example, take steps toward a distributional treatment of WordNet-based classes, using approach to constructing vector representations from a large co-occurrence matrix.", "labels": [], "entities": []}, {"text": "algorithm for sense disambiguation can bethought of as away of determining how Roget's thesaurus categories behave with respect to contextual features.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.7030563652515411}]}, {"text": "And my own treatment of selectional constraints provides away to describe the plausibility of co-occuffence in terms of WordNet's semantic categories, using co-occurrence relationships mediated by syntactic structure.", "labels": [], "entities": []}, {"text": "In each case, one begins with known semantic categories (WordNet synsets, Roget's numbered classes) and non-sense-annotated text, and proceeds to a distributional characterization of semantic category behavior using co-occurrence relationships.", "labels": [], "entities": []}, {"text": "This paper begins from a rather different starting point.", "labels": [], "entities": []}, {"text": "As in the above-cited work, there is no presupposition that sense-annotated text is available.", "labels": [], "entities": []}, {"text": "Here, however, I make the assumption that word groupings have been obtained through some black box procedure, e.g. from analysis of unannotated text, and the goal is to annotate the words within the groupings post hoc using a knowledge-based catalogue of senses.", "labels": [], "entities": []}, {"text": "If successful, such an approach has obvious benefits: one can use whatever sources of good word groupings are available --primarily unsupervised word clustering methods, but also on-line thesauri and the like --without folding in the complexity of dealing with word senses at the same time) The resulting sense groupings should be useful fora variety of purposes, although ultimately this work is motivated by the goal of sense disarnbiguation for unrestricted text using unsupervised methods.", "labels": [], "entities": [{"text": "sense disarnbiguation", "start_pos": 422, "end_pos": 443, "type": "TASK", "confidence": 0.7353867590427399}]}], "datasetContent": [{"text": "The previous section provided illustrative examples, demonstrating the performance of the algorithm on some interesting cases.", "labels": [], "entities": []}, {"text": "In this section, I present experimental results using a more rigorous evaluation methodology.", "labels": [], "entities": []}, {"text": "Input for this evaluation came from the numbered categories of Roget's.", "labels": [], "entities": []}, {"text": "Test instances consisted of a noun group (i.e., all the nouns in a numbered category) together with a single word in that group to be disambiguated.", "labels": [], "entities": []}, {"text": "The test set, chosen at random, contained 125 test cases.", "labels": [], "entities": []}, {"text": "(Note that because of the random choice, there were some cases where more than one test instance came from the same numbered category.)", "labels": [], "entities": []}, {"text": "Two human judges were independently given the test cases to disambiguate.", "labels": [], "entities": []}, {"text": "For each case, they were given the full set of nouns in the numbered category (as shown above) together with descriptions of the WordNet senses for the word to be disambiguated (as, for example, the list of 25 senses for line given in the previous section, though thankfully few words have that many senses!).", "labels": [], "entities": []}, {"text": "It was a forced-choice task; that is, the judge was required to choose exactly one sense.", "labels": [], "entities": []}, {"text": "In addition, for each judgment, the judge was required to provide a confidence value for this decision, ranging from 0 (not at all confident) to 4 (highly confident).", "labels": [], "entities": []}, {"text": "Results are presented here individually by judge.", "labels": [], "entities": []}, {"text": "For purposes of evaluation, test instances for which the judge had low confidence (i.e. confidence ratings of 0 or 1) were excluded.", "labels": [], "entities": []}, {"text": "For Judge 1, there were 99 test instances with sufficiently high confidence to be considered.", "labels": [], "entities": []}, {"text": "As a baseline, ten runs were done selecting senses by random choice, with the average percent correct being 34.8%, standard deviation 3.58.", "labels": [], "entities": [{"text": "correct", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9675662517547607}, {"text": "standard", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9568015933036804}]}, {"text": "As an upper bound, Judge 2 was correct on 65.7% of those test instances.", "labels": [], "entities": []}, {"text": "The disambiguation algorithm shows considerable progress toward this upper bound, with 58.6% correct.", "labels": [], "entities": []}, {"text": "For Judge 2, there were 86 test instances with sufficiently high confidence to be considered.", "labels": [], "entities": []}, {"text": "As a baseline, ten runs were done selecting senses by random choice, with the average percent correct being 33.3%, standard deviation 3.83.", "labels": [], "entities": [{"text": "correct", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9640297293663025}, {"text": "standard", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9605112671852112}]}, {"text": "As an upper bound, Judge 1 was correct on 68.6% of those test instances.", "labels": [], "entities": []}, {"text": "Again, the disambiguation algorithm performs well, with 60.5% correct.", "labels": [], "entities": []}], "tableCaptions": []}