{"title": [{"text": "Unsupervised Learning of Disambiguation Rules for Part of Speech Tagging", "labels": [], "entities": [{"text": "Unsupervised Learning of Disambiguation", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5846164375543594}, {"text": "Part of Speech Tagging", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.8614760339260101}]}], "abstractContent": [{"text": "In this paper we describe an unsupervised learning algorithm for automatically training a rule-based part of speech tagger without using a manually tagged corpus.", "labels": [], "entities": [{"text": "training a rule-based part of speech tagger", "start_pos": 79, "end_pos": 122, "type": "TASK", "confidence": 0.6469953230449131}]}, {"text": "We compare this algorithm to the Baum-Welch algorithm, used for unsupervised training of stochastic taggers.", "labels": [], "entities": []}, {"text": "Next, we show a method for combining unsupervised and supervised rule-based training algorithms to create a highly accurate tagger using only a small amount of manually tagged text.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past.", "labels": [], "entities": [{"text": "automatically training part of speech taggers", "start_pos": 67, "end_pos": 112, "type": "TASK", "confidence": 0.6460210233926773}]}, {"text": "Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.7180127650499344}]}, {"text": "2 For a Markov-model based tagger, training consists of learning both lexical probabilities (P(wordltag)) and contextual probabilities (P(tagiltagi_l ... tagi-n)).", "labels": [], "entities": []}, {"text": "Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities.", "labels": [], "entities": []}, {"text": "The most accurate stochastic taggers use estimates of lexical and contextual probabilities extracted from large manually annotated corpora (eg.).", "labels": [], "entities": []}, {"text": "It is possible to use unsupervised learning to train stochastic taggers without the need fora manually annotated corpus by using the Baum-Welch algorithm.", "labels": [], "entities": []}, {"text": "This algorithm works by iteratively adjusting the lexical and contextual probabilities to increase the overall probability of the training corpus.", "labels": [], "entities": []}, {"text": "If no prior knowledge is available, probabilities are initially either assigned randomly or evenly distributed.", "labels": [], "entities": []}, {"text": "Although less accurate than the taggers built using manually annotated corpora, the fact that they can be trained using only a dictionary listing the allowable parts of speech for each word and not needing a manually tagged corpus is a huge advantage in many situations.", "labels": [], "entities": []}, {"text": "Although a number of manually tagged corpora are available (eg.), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9964519739151001}]}, {"text": "Therefore, if tagged text is needed in training, this would require manually tagging 1This work was funded in part by NSF grant IRI-9502312.", "labels": [], "entities": [{"text": "NSF grant IRI-9502312", "start_pos": 118, "end_pos": 139, "type": "DATASET", "confidence": 0.6676493684450785}]}, {"text": "2Some other approaches to tagging are described in. text each time the tagger is to be apphed to anew language, and even when being applied to anew type of text.", "labels": [], "entities": [{"text": "2Some", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9451575875282288}, {"text": "tagging", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9611656665802002}]}, {"text": "In, a rule-based part of speech tagger is described which achieves highly competitive performance compared to stochastic taggers, and captures the learned knowledge in a set of simple deterministic rules instead of a large table of statistics.", "labels": [], "entities": [{"text": "speech tagger", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.7535548508167267}]}, {"text": "In addition, the learned rules can be converted into a deterministic finite state transducer.", "labels": [], "entities": []}, {"text": "Tagging with this finite state transducer requires n steps to tag a sequence of length n, independent of the number of rules, and results in apart of speech tagger ten times faster than the fastest stochastic tagger.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9632520079612732}]}, {"text": "One weakness of this rulebased tagger is that no unsupervised training algorithm has been presented for learning rules automatically without a manually annotated corpus.", "labels": [], "entities": []}, {"text": "In this paper we present such an algorithm.", "labels": [], "entities": []}, {"text": "We describe an algorithm for both unsupervised and weakly supervised training of a rule-based part of speech tagger, and compare the performance of this algorithm to that of the Baum-Welch algorithm.", "labels": [], "entities": [{"text": "speech tagger", "start_pos": 102, "end_pos": 115, "type": "TASK", "confidence": 0.7084433138370514}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Unsupervised Training: Test Set Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.7752343416213989}]}, {"text": " Table 2: Unsupervised + Supervised vs. Purely Supervised Training.", "labels": [], "entities": []}]}