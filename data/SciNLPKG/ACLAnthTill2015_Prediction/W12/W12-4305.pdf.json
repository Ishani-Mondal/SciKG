{"title": [{"text": "A Three-Way Perspective on Scientific Discourse Annotation for Knowledge Extraction", "labels": [], "entities": [{"text": "Knowledge Extraction", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.7076874226331711}]}], "abstractContent": [{"text": "This paper presents a three-way perspective on the annotation of discourse in scientific literature.", "labels": [], "entities": []}, {"text": "We use three different schemes, each of which focusses on different aspects of discourse in scientific articles, to annotate a corpus of three full-text papers, and compare the results.", "labels": [], "entities": []}, {"text": "One scheme seeks to identify the core components of scientific investigations at the sentence level, a second annotates meta-knowledge pertaining to bio-events and a third considers how epistemic knowledge is conveyed at the clause level.", "labels": [], "entities": []}, {"text": "We present our analysis of the comparison, and a discussion of the contributions of each scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "The literature boom in the life sciences over the past few years has sparked increasing interest into text mining tools, which facilitate the automatic extraction of useful knowledge from text ( ;.", "labels": [], "entities": [{"text": "text mining", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.7976563572883606}, {"text": "automatic extraction of useful knowledge from text", "start_pos": 142, "end_pos": 192, "type": "TASK", "confidence": 0.7837790421077183}]}, {"text": "Most of these tools have focussed on entity recognition and relation extraction and with few exceptions, e.g.,, do not take into account the discourse context of the knowledge extracted.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.8022714257240295}, {"text": "relation extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8060007393360138}]}, {"text": "However, failure to take this context into account results in the loss of information vital for the correct interpretation of extracted knowledge, e.g. the scope of the relations, or the level of certainty with which they are expressed.", "labels": [], "entities": []}, {"text": "A particular piece of knowledge may represent, e.g., an accepted fact, hypothesis, results of an experiment, analysis based on experimental results, factual or speculative statements etc.", "labels": [], "entities": []}, {"text": "Furthermore, this knowledge may represent the author's current work, or work reported elsewhere.", "labels": [], "entities": []}, {"text": "The ability to recognise different discourse elements automatically provides crucial information for the correct interpretation of extracted knowledge, allowing scientific claims to be linked to experimental evidence, or newly reported experimental knowledge to be isolated.", "labels": [], "entities": []}, {"text": "The importance of categorising such knowledge becomes more pronounced as analysis moves from abstracts to full papers, where the content is richer and linguistic constructions are more complex).", "labels": [], "entities": []}, {"text": "Analysis of full papers is extremely important, since less than 8% of scientific claims occur in abstracts.", "labels": [], "entities": [{"text": "Analysis of full papers", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8870492428541183}]}, {"text": "Various different schemes for annotating discourse elements in scientific texts have been proposed.", "labels": [], "entities": []}, {"text": "The schemes vary along several axes, including perspective, motivation, complexity and the granularity of the units of text to which the scheme is applied.", "labels": [], "entities": [{"text": "perspective", "start_pos": 47, "end_pos": 58, "type": "METRIC", "confidence": 0.9523646831512451}]}, {"text": "Faced with such variety, it is important to be able to select the best scheme(s) for the purpose at hand.", "labels": [], "entities": []}, {"text": "Answers to questions such as the following can help in the selection process: 1.", "labels": [], "entities": [{"text": "selection", "start_pos": 59, "end_pos": 68, "type": "TASK", "confidence": 0.9664866328239441}]}, {"text": "What are the relative merits of the different schemes?", "labels": [], "entities": []}, {"text": "2. What are the similarities and differences between schemes?", "labels": [], "entities": []}, {"text": "3. Can annotation according to multiple schemes provide enhanced information?", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3. Event Meta-knowledge vs CoreSC", "labels": [], "entities": [{"text": "CoreSC", "start_pos": 34, "end_pos": 40, "type": "TASK", "confidence": 0.4379476010799408}]}, {"text": " Table 4: Segments vs CoreSC", "labels": [], "entities": [{"text": "CoreSC", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.5347356200218201}]}, {"text": " Table 5: Segments vs Event Meta-Knowledge", "labels": [], "entities": [{"text": "Segments", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.962259829044342}]}]}