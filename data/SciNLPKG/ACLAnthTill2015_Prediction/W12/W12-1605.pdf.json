{"title": [{"text": "Unsupervised Topic Modeling Approaches to Decision Summarization in Spoken Meetings", "labels": [], "entities": [{"text": "Decision Summarization", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7620111107826233}]}], "abstractContent": [{"text": "We present a token-level decision summariza-tion framework that utilizes the latent topic structures of utterances to identify \"summary-worthy\" words.", "labels": [], "entities": []}, {"text": "Concretely, a series of unsupervised topic models is explored and experimental results show that fine-grained topic models, which discover topics at the utterance-level rather than the document-level, can better identify the gist of the decision-making process.", "labels": [], "entities": []}, {"text": "Moreover, our proposed token-level summarization approach, which is able to remove redundancies within utterances , outperforms existing utterance ranking based summarization methods.", "labels": [], "entities": [{"text": "token-level summarization", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.6073261201381683}]}, {"text": "Finally, context information is also investigated to add additional relevant information to the summary.", "labels": [], "entities": []}], "introductionContent": [{"text": "Meetings are an important way for information sharing and collaboration, where people can discuss problems and make concrete decisions.", "labels": [], "entities": [{"text": "information sharing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7367874383926392}]}, {"text": "Not surprisingly, there is an increasing interest in developing methods for extractive summarization for meetings and conversations).", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.7235315442085266}]}, {"text": "describe the specific need for focused summaries of meetings, i.e., summaries of a particular aspect of a meeting rather than of the meeting as a whole.", "labels": [], "entities": []}, {"text": "For example, the decisions made, the action items that emerged and the problems arised are all important outcomes of meetings.", "labels": [], "entities": []}, {"text": "In particular, decision summaries would allow participants to review decisions from previous meetings and understand the related topics quickly, which facilitates preparation for the upcoming meetings.", "labels": [], "entities": [{"text": "decision summaries", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.739774078130722}]}, {"text": "DECISION 2: The remote will have a latex case.", "labels": [], "entities": [{"text": "DECISION", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.6841256618499756}]}, {"text": "DECISION 3: The remote will have pushbuttons.", "labels": [], "entities": [{"text": "DECISION", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.6192508339881897}]}, {"text": "DECISION 4: The remote will have a power button, volume buttons, channel preset buttons, and a menu button.", "labels": [], "entities": [{"text": "DECISION", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.6392621397972107}]}, {"text": "Figure 1: A clip of a meeting from the AMI meeting corpus ( . A, B, C and D refer to distinct speakers; the numbers in parentheses indicate the associated meeting decision: DECISION 1, 2, 3 or 4.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 39, "end_pos": 57, "type": "DATASET", "confidence": 0.8914011319478353}, {"text": "DECISION", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.8239670991897583}]}, {"text": "Also shown is the gold-standard (manual) abstract (summary) for each decision.", "labels": [], "entities": []}, {"text": "Meeting conversation is intrinsically different from well-written text, as meetings may not be well organized and most utterances have low density of salient content.", "labels": [], "entities": []}, {"text": "Therefore, multiple problems need to be addressed for speech summarization.", "labels": [], "entities": [{"text": "speech summarization", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.7477428615093231}]}, {"text": "Consider the sample dialogue snippet in from the AMI meeting corpus ).", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 49, "end_pos": 67, "type": "DATASET", "confidence": 0.9420784910519918}]}, {"text": "Only decision-related dialogue acts (DRDAs) -utter-ances at least one decision made in the meeting 1 -are listed and ordered by time.", "labels": [], "entities": []}, {"text": "Each DRDA is labeled numerically according to the decision it supports; so the second and third utterances (in bold) support DECISION 2, as do the fifth utterance in the snippet.", "labels": [], "entities": []}, {"text": "Manually constructed decision abstracts for each decision are shown at the bottom of the Besides the prevalent dialogue phenomena (such as \"Uh I'm kinda liking\" in), disfluencies and off-topic expressions, we notice that single utterance is usually not informative enough to form a decision.", "labels": [], "entities": []}, {"text": "For instance, no single DRDA associated with DECISION 4 corresponds all that well with its decision abstract: \"pushbuttons\", \"menu button\" and \"Pre-set channels\" are mentioned in separate DAs.", "labels": [], "entities": []}, {"text": "As a result, extractive summarization methods that select individual utterance to form the summary will perform poorly.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7926559746265411}]}, {"text": "Furthermore, it is difficult to identify the core topic when multiple topics are discussed in one utterance.", "labels": [], "entities": []}, {"text": "For example, all of the bold DRDAs supporting DECISION 2 contain the word \"latex\".", "labels": [], "entities": []}, {"text": "However, the last DA in bold also mentions \"bigger impact\" and \"the scroll wheel\", which are not specifically relevant for DECISION 2.", "labels": [], "entities": [{"text": "DA", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.6126312017440796}]}, {"text": "Though this problem can be approached by training a classifier to identify the relevant phrases and ignore the irrelevant ones or dialogue phenomena, it needs expensive human annotation and is limited to the specific domain.", "labels": [], "entities": []}, {"text": "Note also that for DECISION 4, the \"power button\" is not specified in any of the listed DRDAs supporting it.", "labels": [], "entities": [{"text": "DECISION 4", "start_pos": 19, "end_pos": 29, "type": "TASK", "confidence": 0.7825077772140503}]}, {"text": "By looking at the transcript, we find \"power button\" mentioned in one of the preceding, but not decision-related DAs.", "labels": [], "entities": []}, {"text": "Consequently another challenge would be to add complementary knowledge when the DRDAs cannot provide complete information.", "labels": [], "entities": [{"text": "DRDAs", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.9588041305541992}]}, {"text": "Therefore, we need a summarization approach that is tolerant of dialogue phenomena, can determine the key semantic content and is easily transferable between domains.", "labels": [], "entities": [{"text": "summarization", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9609804749488831}]}, {"text": "Recently, topic modeling approaches have been investigated and achieved state-of-the-art results in multi-document summarization ().", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7586084604263306}, {"text": "multi-document summarization", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.6235685348510742}]}, {"text": "Thus, topic models appear to be a better ref for document similarity w.r.t. semantic concepts than simple literal word matching.", "labels": [], "entities": []}, {"text": "However, very little work has investigated its role in spoken document summarization, and much less conducted comparisons among topic modeling approaches for focused summarization in meetings.", "labels": [], "entities": [{"text": "spoken document summarization", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.6414966881275177}]}, {"text": "In contrast to previous work, we study the unsupervised token-level decision summarization in meetings by identifying a concise set of key words or phrases, which can either be output as a compact summary or be a starting point to generate abstractive summaries.", "labels": [], "entities": [{"text": "token-level decision summarization", "start_pos": 56, "end_pos": 90, "type": "TASK", "confidence": 0.6106242140134176}]}, {"text": "This paper addresses problems mentioned above and make contributions as follows: \u2022 As a step towards creating the abstractive summaries that people prefer when dealing with spoken language (Murray et al., 2010b), we propose a token-level rather than sentence-level framework for identifying components of the summary.", "labels": [], "entities": []}, {"text": "Experimental results show that, compared to the sentence ranking based summarization algorithms, our token-level summarization framework can better identify the summary-worthy words and remove the redundancies.", "labels": [], "entities": []}, {"text": "\u2022 Rather than employing supervised learning methods that rely on costly manual annotation, we explore and evaluate topic modeling approaches of different granularities for the unsupervised decision summarization at both the token-level and dialogue act-level.", "labels": [], "entities": []}, {"text": "We investigate three topic models -Local LDA (LocalLDA)), Multi-grain LDA (MG-LDA) and Segmented Topic Model (STM) () -which can utilize the latent topic structure on utterance level instead of document level.", "labels": [], "entities": []}, {"text": "Under our proposed token-level summarization framework, three finegrained models outperform the basic LDA model and two extractive baselines that select the longest and the most representative utterance for each decision, respectively.", "labels": [], "entities": [{"text": "token-level summarization", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.6895946264266968}]}, {"text": "(ROUGE-SU4 F score of 14.82% for STM vs. 13.58% and 13.46% for the baselines, given the perfect clusterings of DRDAs.)", "labels": [], "entities": [{"text": "ROUGE-SU4", "start_pos": 1, "end_pos": 10, "type": "METRIC", "confidence": 0.9985596537590027}, {"text": "F score", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.916565477848053}, {"text": "STM", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.5756200551986694}]}, {"text": "\u2022 In line with prior research that explore the role of context for utterance-based extractive summariza-tion (, we investigate the role of context in our token-level summarization framework.", "labels": [], "entities": []}, {"text": "For the given clusters of DRDAs, We study two types of context information -the DAs preceding and succeeding a DRDA and DAs of high TF-IDF similarity with a DRDA.", "labels": [], "entities": []}, {"text": "We also investigate two ways to select relevant words from the context DA.", "labels": [], "entities": []}, {"text": "Experimental results show that two types of context have comparable effect, but selecting words from the dominant topic of the center DRDA performs better than from the dominant topic of the context DA.", "labels": [], "entities": []}, {"text": "Moreover, by leveraging context, the recall exceeds the provided upperbound's recall (ROUGE-1 recall: 48.10% vs. 45.05% for upperbound by using DRDA only) although the F scores decrease after adding context information.", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9990947246551514}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9663699269294739}, {"text": "ROUGE-1 recall", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.8283010423183441}, {"text": "F", "start_pos": 168, "end_pos": 169, "type": "METRIC", "confidence": 0.9908692836761475}]}, {"text": "Finally, we show that when the true DRDA clusterings are not available, adding context can improve both the recall and F score.", "labels": [], "entities": [{"text": "DRDA clusterings", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.5202186703681946}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9997333884239197}, {"text": "F score", "start_pos": 119, "end_pos": 126, "type": "METRIC", "confidence": 0.9855865240097046}]}], "datasetContent": [{"text": "We evaluate our approach on the AMI meeting corpus ) that consists of 140 multi-party meetings.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.8443673849105835}]}, {"text": "The 129 scenariodriven meetings involve four participants playing different roles on a design team.", "labels": [], "entities": []}, {"text": "A short (usually one-sentence) abstract is manually constructed to summarize each decision discussed in the meeting and used as gold-standard summaries in our experiments.", "labels": [], "entities": []}, {"text": "Our summarization system requires as input a partitioning of the DRDAs according to the decision(s) that each supports (i.e., one cluster of DRDAs per decision).", "labels": [], "entities": []}, {"text": "As mentioned earlier, we assume for all experiments that the DRDAs for each meeting have been identified.", "labels": [], "entities": []}, {"text": "For evaluation we consider two system input settings.", "labels": [], "entities": []}, {"text": "In the True Clusterings setting, we use the AMI annotations to create perfect partitionings of the DRDAs as the input; in the System Clusterings setting, we employ a hierarchical agglomerative clustering algorithm used for this task in previous work ().", "labels": [], "entities": []}, {"text": "The clustering method groups DRDAs according to their LDA topic distribution similarity.", "labels": [], "entities": []}, {"text": "As better approaches for DRDA clustering become available, they could be employed instead.", "labels": [], "entities": [{"text": "DRDA clustering", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8285660445690155}]}, {"text": "To evaluate the performance of various summarization approaches, we use the widely accepted ROUGE ( metrics.", "labels": [], "entities": [{"text": "summarization", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.9735736846923828}, {"text": "ROUGE", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.9896770119667053}]}, {"text": "We use the stemming option of the ROUGE software at http://berouge.com/ and remove stopwords from both the system and gold-standard summaries, same as do.", "labels": [], "entities": []}, {"text": "Inference and Hyperparameters We use the implementation from (Lu et al., 2011) for the three topic models in Section 4.", "labels": [], "entities": []}, {"text": "The collapsed Gibbs Sampling approach () is exploited for inference.", "labels": [], "entities": []}, {"text": "Hyperparameters are chosen according to, and (.", "labels": [], "entities": []}, {"text": "In LDA and LocalLDA, \u03b1 and \u03b2 are both set to 0.1 . For MG-LDA, \u03b1 gl , \u03b1 loc and \u03b1 mix are set to 0.1; \u03b3 is 0.1 and the window size T is 3.", "labels": [], "entities": []}, {"text": "And the number of local topic is set as the same number of global topic as discussed in.", "labels": [], "entities": []}, {"text": "In STM, \u03b1, a and bare set to 0.5, 0.1 and 1, respectively.", "labels": [], "entities": [{"text": "STM", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.8981432914733887}]}], "tableCaptions": [{"text": " Table 1: ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGE-SU4", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8783842921257019}, {"text": "ROUGE-2", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.8604795932769775}, {"text": "ROUGE-SU4", "start_pos": 43, "end_pos": 52, "type": "DATASET", "confidence": 0.698894739151001}]}, {"text": " Table 2: ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGE-SU4", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8910403251647949}, {"text": "ROUGE-2", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.873496949672699}, {"text": "ROUGE-SU4", "start_pos": 43, "end_pos": 52, "type": "DATASET", "confidence": 0.7134020328521729}]}]}