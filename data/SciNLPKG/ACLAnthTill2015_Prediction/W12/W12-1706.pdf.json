{"title": [{"text": "Sequential vs. Hierarchical Syntactic Models of Human Incremental Sentence Processing", "labels": [], "entities": [{"text": "Sequential vs. Hierarchical Syntactic Models of Human Incremental Sentence Processing", "start_pos": 0, "end_pos": 85, "type": "TASK", "confidence": 0.5680353343486786}]}], "abstractContent": [{"text": "Experimental evidence demonstrates that syntactic structure influences human online sentence processing behavior.", "labels": [], "entities": [{"text": "human online sentence processing behavior", "start_pos": 71, "end_pos": 112, "type": "TASK", "confidence": 0.7034249842166901}]}, {"text": "Despite this evidence , open questions remain: which type of syntactic structure best explains observed behavior-hierarchical or sequential, and lexi-calized or unlexicalized?", "labels": [], "entities": []}, {"text": "Recently, Frank and Bod (2011) find that unlexicalized sequential models predict reading times better than unlexicalized hierarchical models, relative to a baseline prediction model that takes word-level factors into account.", "labels": [], "entities": []}, {"text": "They conclude that the human parser is insensitive to hierarchical syntactic structure.", "labels": [], "entities": []}, {"text": "We investigate these claims and find a picture more complicated than the one they present.", "labels": [], "entities": []}, {"text": "First, we show that incorporating additional lexical n-gram probabilities estimated from several different corpora into the baseline model of Frank and Bod (2011) eliminates all differences inaccuracy between those unlexicalized sequential and hierarchical models.", "labels": [], "entities": []}, {"text": "Second, we show that lexi-calizing the hierarchical models used in Frank and Bod (2011) significantly improves prediction accuracy relative to the unlexicalized versions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9356868863105774}]}, {"text": "Third, we show that using state-of-the-art lexicalized hierarchical models further improves prediction accuracy.", "labels": [], "entities": [{"text": "prediction", "start_pos": 92, "end_pos": 102, "type": "TASK", "confidence": 0.9510781168937683}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.8854806423187256}]}, {"text": "Our results demonstrate that the claim of Frank and Bod (2011) that sequential models predict reading times better than hierarchical models is premature , and also that lexicalization matters for prediction accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.6568101644515991}]}], "introductionContent": [{"text": "Various factors influence human reading times during online sentence processing, including word-level factors such as word length, unigram and bigram probabilities, and position in the sentence.", "labels": [], "entities": []}, {"text": "Yet wordlevel factors cannot explain many observed processing phenomena; ample experimental evidence exists for the influence of syntax on human behavior during online sentence processing, beyond what can be predicted using word-level factors alone.", "labels": [], "entities": []}, {"text": "Examples include the English subject/object relative clause asymmetry ( and anti-locality effects in German (,), and Japanese (.", "labels": [], "entities": []}, {"text": "shows that these processing phenomena can be explained by surprisal theory under a hierarchical probabilistic context-free grammar (PCFG).", "labels": [], "entities": []}, {"text": "Other evidence of syntactic expectation in sentence processing includes the facilitation of processing at \"or\" following \"either\" ( ); expectations of heavy noun phrase shifts ( ); ellipsis processing (); and syntactic priming).", "labels": [], "entities": [{"text": "ellipsis processing", "start_pos": 181, "end_pos": 200, "type": "TASK", "confidence": 0.7050871551036835}]}, {"text": "Experimental evidence for the influence of syntax on human behavior is not limited to experiments carefully designed to isolate a particular processing phenomenon.", "labels": [], "entities": []}, {"text": "Several broad-coverage experimental studies have shown that surprisal under hierarchical syntactic models predicts human processing difficulty on large corpora of naturally occurring text, even after word-level factors have been taken into account.", "labels": [], "entities": []}, {"text": "Despite this evidence, in recent work Frank and Bod (2011) challenge the notion that hierarchical syntactic structure is strictly necessary to predict reading times.", "labels": [], "entities": []}, {"text": "They compare per-word surprisal predictions from unlexicalized hierarchical and sequential models of syntactic structure along two axes: linguistic accuracy (how well the model predicts the test corpus) and psychological accuracy (how well the model predicts observed reading times on the test corpus).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.7620001435279846}, {"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.5736607313156128}]}, {"text": "They find that, while hierarchical phrase-structure grammars (PSG's) achieve better linguistic accuracy, sequential echo state networks (ESN's) achieve better psychological accuracy on the English Dundee corpus ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9526221752166748}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.8921241760253906}, {"text": "English Dundee corpus", "start_pos": 189, "end_pos": 210, "type": "DATASET", "confidence": 0.8948113719622294}]}, {"text": "Frank and Bod (2011) do not include lexicalized syntactic models in the comparison on the grounds that, once word-level factors have been included as control predictors in the reading times model, lexicalized syntactic models do not predict reading times better than unlexicalized syntactic models.", "labels": [], "entities": []}, {"text": "Based on the results of their comparisons between unlexicalized models, they conclude that the human parser is insensitive to hierarchical syntactic structure.", "labels": [], "entities": []}, {"text": "In light of the existing evidence that hierarchical syntax influences human sentence processing, the claim of Frank and Bod (2011) is surprising.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7430554926395416}]}, {"text": "In this work, we investigate this claim, and find a picture more complicated than the one they present.", "labels": [], "entities": []}, {"text": "We first replicate the results of Frank and Bod (2011) using the dataset provided by the authors, verifying that we obtain the same linguistic and psychological accuracies reported by the authors.", "labels": [], "entities": []}, {"text": "We then extend their work in several ways.", "labels": [], "entities": []}, {"text": "First, we repeat their comparisons using additional, more robustly estimated lexical n-gram probabilities as control predictors in the baseline model.", "labels": [], "entities": []}, {"text": "We show that when these additional lexical n-gram probabilities are used as control predictors, any differences in psychological accuracy between the hierarchical and sequential models used in vanish.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9659053683280945}]}, {"text": "Second, while they restrict their comparisons to un-lexicalized models over part-of-speech (POS) tags, we investigate the lexicalized versions of each hierarchical model, and show that lexicalization significantly improves psychological accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 237, "end_pos": 245, "type": "METRIC", "confidence": 0.9699856042861938}]}, {"text": "Third, while they explore only a subset of the PSG's implemented under the incremental parser of, we explore a state-of-the-art lexicalized hierarchical model that conditions on richer contexts, and show that this model performs still better.", "labels": [], "entities": []}, {"text": "Our findings demonstrate that Frank and Bod (2011)'s strong claim that sequential models predict reading times better than hierarchical models is premature, and also that lexicalization improves the psychological accuracy of hierarchical models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 213, "end_pos": 221, "type": "METRIC", "confidence": 0.9731036424636841}]}], "datasetContent": [{"text": "Following Frank and Bod (2011), we compare the per-word surprisal predictions from hierarchical and sequential models of syntactic structure along two axes: linguistic accuracy (how well the model explains the test corpus) and psychological accuracy (how well the model explains observed reading times on the test corpus).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.8079658150672913}, {"text": "accuracy", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.5753127336502075}]}, {"text": "The prefix parser is available at: www.http://idiom.ucsd.edu/ rlevy/prefixprobabilityparser.html We consider words appearing fewer than 5 times in the training data to be unknown.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Estimated coefficients and |t|-values for sur- prisal estimates shown in", "labels": [], "entities": [{"text": "Estimated", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9967564940452576}]}]}