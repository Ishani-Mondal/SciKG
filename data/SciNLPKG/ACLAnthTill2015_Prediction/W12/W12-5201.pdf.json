{"title": [], "abstractContent": [{"text": "The aim of Linked Open Data (LOD) is to improve information management and integration by enhancing accessibility to the existing various forms of open data.", "labels": [], "entities": [{"text": "Linked Open Data (LOD)", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.5307609091202418}, {"text": "information management", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7931807637214661}]}], "introductionContent": [{"text": "Research on Linked Open Data (LOD) 1 on the Web is relatively new, but it is rapidly growing nowadays.", "labels": [], "entities": [{"text": "Linked Open Data (LOD) 1", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6281967844281878}]}, {"text": "The aim of LOD is to improve information management and integration by enhancing accessibility to the existing various formats of open data.", "labels": [], "entities": [{"text": "information management", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8339664041996002}]}, {"text": "To ease the integration of data from different sources, it is desirable to use standards () such as the W3C Resource Description Framework (RDF).", "labels": [], "entities": [{"text": "W3C Resource Description Framework (RDF)", "start_pos": 104, "end_pos": 144, "type": "DATASET", "confidence": 0.6660928896495274}]}, {"text": "There is a huge amount of unstructured text in many languages in web pages.", "labels": [], "entities": []}, {"text": "Traditionally, these web pages have been interlinked using hyperlinks.", "labels": [], "entities": []}, {"text": "However, researchers in the domain of the semantic web are focusing on data and resources, rather than web pages.", "labels": [], "entities": []}, {"text": "In the context of semantic web, such resources are usually modelled as RDF triples ().", "labels": [], "entities": []}, {"text": "This paper aims to describe an NLP platform presented in), but focuses on the Korean language processing.", "labels": [], "entities": []}, {"text": "Such detailed desciption was missing in).", "labels": [], "entities": []}, {"text": "In () the authors present a novel framework to acquire entities from unstructured Korean text and describe them as RDF resoruces.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are as follows: (1) Describing in detail how to build an open Korean NLP platform which produces POS tag, CFG and DG parsing results from one-time input; and (2) Providing further details on how to convert NLP outputs to the RDF.", "labels": [], "entities": []}, {"text": "The goals of this converting are to achieve universal interoperability between the results of several NLP tools, and make Korean resource to linkable entities.", "labels": [], "entities": []}, {"text": "Existing Korean NLP tools, such as a morphological analyser and a syntactic parser, are reused and merged.", "labels": [], "entities": []}, {"text": "The Sejong corpus and its POS tagset (Korean Language Institue, 2012) are used as training data.", "labels": [], "entities": [{"text": "Sejong corpus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.8783778548240662}, {"text": "POS tagset (Korean Language Institue, 2012)", "start_pos": 26, "end_pos": 69, "type": "DATASET", "confidence": 0.9041999512248569}]}, {"text": "In this case the output provides RDF so entities which tokenized morpheme units have an identifier URI and can be link with existing RDF stores from the LOD-cloud.", "labels": [], "entities": []}, {"text": "Especially, entities can be mapped with subjects in DBpedia triples.", "labels": [], "entities": []}, {"text": "Section 2 surveys previous work on Korean NLP and linked data.", "labels": [], "entities": [{"text": "Korean NLP", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.8198075294494629}]}, {"text": "The Korean NLP platform is described with a more detailed explanation in section 3.", "labels": [], "entities": [{"text": "Korean NLP platform", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9241545796394348}]}, {"text": "Section 4 provides some new details on how to convert the NLP output to RDF and how to link entities with Wikipedia pages, and some tries to link entities with Wikipedia page.", "labels": [], "entities": []}, {"text": "We discuss a conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}