{"title": [{"text": "Semantic Specificity in Spoken Dialogue Requests", "labels": [], "entities": [{"text": "Semantic Specificity in Spoken Dialogue Requests", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7291394074757894}]}], "abstractContent": [{"text": "Ambiguous or open-ended requests to a dialogue system result in more complex dialogues.", "labels": [], "entities": []}, {"text": "We present a semantic-specificity metric to gauge this complexity for dialogue systems that access a relational database.", "labels": [], "entities": []}, {"text": "An experiment where a simulated user makes requests to a dialogue system shows that semantic specificity correlates with dialogue length.", "labels": [], "entities": []}], "introductionContent": [{"text": "A dialogue system (DS) and its users have asymmetric knowledge.", "labels": [], "entities": []}, {"text": "The DS has access to knowledge the user is not privy to, and the user has intentions that the DS attempts to recognize.", "labels": [], "entities": []}, {"text": "When the user's intentions are difficult for her to specify fully, the user and DS must collaborate to formulate the intention.", "labels": [], "entities": []}, {"text": "The thesis of this work is that a DS can assess the specificity of its knowledge with respect to the user intentions it is designed to address.", "labels": [], "entities": []}, {"text": "Our principal result is that, fora DS that queries a relational database, measures of the ambiguity of database attributes can be used both to assess the scope of the DS's task and to guide its dialogue strategy.", "labels": [], "entities": []}, {"text": "To demonstrate our thesis, we have developed a semantic specificity metric applicable to any DS that queries a relational database.", "labels": [], "entities": []}, {"text": "This metric measures the degree to which one or more attributes can uniquely specify an item in the database.", "labels": [], "entities": []}, {"text": "Attributes whose values are more often ambiguous have lower semantic specificity.", "labels": [], "entities": []}, {"text": "CheckItOut To compare the specificity of TITLE and AUTHOR, we calculated query return size, the number of distinct books in the Heiskell database returned by each possible attribute value.", "labels": [], "entities": [{"text": "TITLE", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9473626017570496}, {"text": "AUTHOR", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9308829307556152}, {"text": "query return size", "start_pos": 73, "end_pos": 90, "type": "METRIC", "confidence": 0.6201845904191335}, {"text": "Heiskell database", "start_pos": 128, "end_pos": 145, "type": "DATASET", "confidence": 0.9109524190425873}]}, {"text": "tallies how many attribute values have the same query return size.", "labels": [], "entities": [{"text": "tallies", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9558389782905579}]}, {"text": "TI-TLE partitions the books into 10 subsets, where the two most ambiguous TITLE values, Collected Stories and Sanctuary, each return 10 distinct books.", "labels": [], "entities": [{"text": "TITLE", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9707249402999878}]}, {"text": "AUTHOR produces 89 subsets; its most ambiguous value, Louis L'Amour, returns 184 distinct books.", "labels": [], "entities": [{"text": "AUTHOR", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.553806722164154}]}, {"text": "Clearly, TITLE has higher specificity than AUTHOR.", "labels": [], "entities": [{"text": "TITLE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.5025661587715149}, {"text": "AUTHOR", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.5211329460144043}]}, {"text": "After a survey of related work, this paper defines a semantic specificity metric that is a weighted sum of the number of query return sizes for one or more attributes.", "labels": [], "entities": []}, {"text": "We show through simulation that dialogue length varies with semantic specificity fora DS with a simple system-initiative dialogue strategy.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: When used as a query, many TITLE values return  unique books, but AUTHOR values are less specific.", "labels": [], "entities": [{"text": "TITLE", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.6201006174087524}, {"text": "AUTHOR", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9857271313667297}]}]}