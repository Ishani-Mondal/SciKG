{"title": [{"text": "An Unsupervised Approach to User Simulation: toward Self-Improving Dialog Systems", "labels": [], "entities": [{"text": "User Simulation", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.8067583441734314}]}], "abstractContent": [{"text": "This paper proposes an unsupervised approach to user simulation in order to automatically furnish updates and assessments of a deployed spoken dialog system.", "labels": [], "entities": []}, {"text": "The proposed method adopts a dynamic Bayesian network to infer the unobservable true user action from which the parameters of other components are naturally derived.", "labels": [], "entities": []}, {"text": "To verify the quality of the simulation, the proposed method was applied to the Let's Go domain (Raux et al., 2005) and a set of measures was used to analyze the simulated data at several levels.", "labels": [], "entities": []}, {"text": "The results showed a very close correspondence between the real and simulated data, implying that it is possible to create a realistic user simulator that does not necessitate human intervention.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the past decade statistical approaches to dialog modeling have shown positive results for optimizing a dialog strategy with real data by applying wellunderstood machine learning methods such as reinforcement learning).", "labels": [], "entities": [{"text": "dialog modeling", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.9285238683223724}]}, {"text": "User simulation is becoming an essential component in developing and evaluating such systems.", "labels": [], "entities": []}, {"text": "In this paper we describe an unsupervised process to automatically develop user simulators.", "labels": [], "entities": []}, {"text": "The motivation for this comes from the fact that many systems are presently moving from being simple lab simulations to actual deployed systems with real users.", "labels": [], "entities": []}, {"text": "These systems furnish a constant flow of new data that needs to be processed in someway.", "labels": [], "entities": []}, {"text": "Our goal is to minimize human intervention in processing this data.", "labels": [], "entities": []}, {"text": "Previously, data had to be hand-annotated, a slow and costly process.", "labels": [], "entities": []}, {"text": "Recently crowdsourcing has made annotation faster and less expensive, but all of the data still has to be processed and time must be spent in creating the annotation interface and tasks, and in quality control.", "labels": [], "entities": []}, {"text": "Our goal is to process the metadata (e.g. user actions, goals, error typology) in an unsupervised manner.", "labels": [], "entities": []}, {"text": "And our method eliminates the need for human transcription and annotation by inferring the user goal from grounding information.", "labels": [], "entities": []}, {"text": "We also consider user actions as latent variables which are inferred based on observations from Automatic Speech Recognition (ASR).", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 96, "end_pos": 130, "type": "TASK", "confidence": 0.7803190598885218}]}, {"text": "We used the above inferred user actions paired with the observed actions to build an error model.", "labels": [], "entities": []}, {"text": "Since the focus of this work is placed on improving and evaluating the dialog strategy, error simulation can be carried out at the semantic level.", "labels": [], "entities": []}, {"text": "This eliminates the need for transcription, which would have necessitated an error simulation at the surface level.", "labels": [], "entities": []}, {"text": "The end result here will be a system that has as little human intervention as possible.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes previous research and the novelty of our approach.", "labels": [], "entities": []}, {"text": "Section 3 elaborates on our proposed unsupervised approach to user simulation.", "labels": [], "entities": []}, {"text": "Section 4 explains the experimental setup.", "labels": [], "entities": []}, {"text": "Section 5 presents and discusses the results.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes with a brief summary and suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: A description of experimental data sets.", "labels": [], "entities": []}, {"text": " Table 4: A comparison of dialog completion rate (DCR)  and averaged dialog length (ADL) which is presented ac- cording to the dialog result.", "labels": [], "entities": [{"text": "completion rate (DCR)", "start_pos": 33, "end_pos": 54, "type": "METRIC", "confidence": 0.9408786773681641}, {"text": "averaged dialog length (ADL)", "start_pos": 60, "end_pos": 88, "type": "METRIC", "confidence": 0.8214266896247864}]}]}