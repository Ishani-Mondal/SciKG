{"title": [{"text": "Partially modelling word reordering as a sequence labelling problem", "labels": [], "entities": [{"text": "word reordering", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7490258812904358}]}], "abstractContent": [{"text": "Source side reordering has been shown to improve the performance of phrase based machine translation systems.", "labels": [], "entities": [{"text": "phrase based machine translation", "start_pos": 68, "end_pos": 100, "type": "TASK", "confidence": 0.6514658182859421}]}, {"text": "In this work, we explore the learning of source side reordering given a training corpus of word aligned data.", "labels": [], "entities": []}, {"text": "Given the large number of re-orderings this problem is NP-hard.", "labels": [], "entities": []}, {"text": "We explore the possibility of representing the problem as a reordering of word sequences, instead of words.", "labels": [], "entities": []}, {"text": "To this end, we propose a sequence labelling framework to identify work sequences.", "labels": [], "entities": []}, {"text": "We also model the reversal of word sequences as a sequence labelling problem.", "labels": [], "entities": [{"text": "reversal of word sequences", "start_pos": 18, "end_pos": 44, "type": "TASK", "confidence": 0.83058862388134}]}, {"text": "These transformations reduce the problem to a phrase reordering problem, which has a smaller search space.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7058487385511398}]}], "introductionContent": [{"text": "Phrase based machine translation is one of the most successful SMT paradigms in recent times.", "labels": [], "entities": [{"text": "Phrase based machine translation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8501044809818268}, {"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9963932633399963}]}, {"text": "However, one of its major weaknesses has been the lack of a good distortion model, due to which reordering could not be handled correctly.", "labels": [], "entities": []}, {"text": "Distance based penalty models would work only for language pairs where the word order is very similar.", "labels": [], "entities": []}, {"text": "Practical constraints like the decoder's large search space also limit the possible reorderings that can be searched during decoding.", "labels": [], "entities": []}, {"text": "Lexical binary reordering model proposes a limited reordering model conditioned on the phrases.", "labels": [], "entities": []}, {"text": "An alternative approach which has been proposed is to reorder the source language sentence to conform to the target language word order before decoding.", "labels": [], "entities": []}, {"text": "The search space for the decoder is thus simplified, and thus translation can be performed effectively with a simple distortion model.", "labels": [], "entities": [{"text": "translation", "start_pos": 62, "end_pos": 73, "type": "TASK", "confidence": 0.970608115196228}]}, {"text": "Many solutions for manipulating source side parse trees, with manual ( or automatic rules (), have shown improvement in the performance of PBSMT.", "labels": [], "entities": []}, {"text": "However, these solutions are language pair specific, cannot be easily scaled to new language pairs and may require linguistic resources like parsers on the source/target sides.", "labels": [], "entities": []}, {"text": "Therefore, recently, approaches have been explored to learn word reorderings on the source side in a language independent way.", "labels": [], "entities": [{"text": "learn word reorderings", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.6167829235394796}]}, {"text": "model the word reordering as a Travelling salesperson problem whereas model it as a linear ordering problem.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.6850049495697021}]}, {"text": "Given the large number of re-orderings this problem is NP-hard.", "labels": [], "entities": []}, {"text": "We explore the possibility of representing the problem as a reordering of word sequences, instead of words.", "labels": [], "entities": []}, {"text": "To this end, we propose a sequence labelling framework to identify work sequences.", "labels": [], "entities": []}, {"text": "We also model the reversal of word sequences as a sequence labelling problem.", "labels": [], "entities": [{"text": "reversal of word sequences", "start_pos": 18, "end_pos": 44, "type": "TASK", "confidence": 0.83058862388134}]}, {"text": "These transformations reduce the problem to a phrase reordering problem, which has a smaller search space.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7058487385511398}]}, {"text": "In Section 2, we discuss our word sequence based reordering model, and how it has been partially cast as a sequence labelling problem.", "labels": [], "entities": []}, {"text": "Section 3 discusses our experiments.", "labels": [], "entities": []}, {"text": "Section 4 describes the results of our experiments and analyses the results. and have considered the source reordering problem to be a problem of learning word reordering from word-aligned data.", "labels": [], "entities": []}, {"text": "Finding the right reordering is exponential in the number of words in the sentence and hence intractable.", "labels": [], "entities": []}, {"text": "Use of heuristics to overcome this bottleneck will result in suboptimal solutions.", "labels": [], "entities": []}, {"text": "However, a key observation that can be made is that word sequences, as opposed to individual words, are displaced from their original position.", "labels": [], "entities": []}, {"text": "Another common transformation is that a sequence of words get reversed.", "labels": [], "entities": []}, {"text": "As an example, in 1, we can see that the that are two word sequences.", "labels": [], "entities": []}, {"text": "The second word sequence also undergoes reversal.", "labels": [], "entities": []}, {"text": "Source side reordering can thus be considered to be a composition of the following operations on a sentence:", "labels": [], "entities": [{"text": "Source side reordering", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6737237175305685}]}], "datasetContent": [{"text": "This section describes the dataset used and the sequence labelling, cost modelling and TSP experiments.", "labels": [], "entities": [{"text": "sequence labelling", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.6212602406740189}, {"text": "TSP", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.6962172985076904}]}], "tableCaptions": [{"text": " Table 2: Best sequence labelling results", "labels": [], "entities": []}, {"text": " Table 3: Baseline Results (dev set)", "labels": [], "entities": []}, {"text": " Table 4: Evaluation results for different sizes of cost regression training data", "labels": [], "entities": []}]}