{"title": [{"text": "An Unsupervised and Data-Driven Approach for Spell Checking in Vietnamese OCR-scanned Texts", "labels": [], "entities": [{"text": "Spell Checking in Vietnamese OCR-scanned Texts", "start_pos": 45, "end_pos": 91, "type": "TASK", "confidence": 0.8836702009042104}]}], "abstractContent": [{"text": "OCR (Optical Character Recognition) scanners do not always produce 100% accuracy in recognizing text documents, leading to spelling errors that make the texts hard to process further.", "labels": [], "entities": [{"text": "OCR (Optical Character Recognition) scanners", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6195010457720075}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.997531533241272}]}, {"text": "This paper presents an investigation for the task of spell checking for OCR-scanned text documents.", "labels": [], "entities": [{"text": "spell checking for OCR-scanned text documents", "start_pos": 53, "end_pos": 98, "type": "TASK", "confidence": 0.6687259376049042}]}, {"text": "First, we conduct a detailed analysis on characteristics of spelling errors given by an OCR scanner.", "labels": [], "entities": [{"text": "OCR scanner", "start_pos": 88, "end_pos": 99, "type": "DATASET", "confidence": 0.8140120804309845}]}, {"text": "Then, we propose a fully automatic approach combining both error detection and correction phases within a unique scheme.", "labels": [], "entities": [{"text": "error detection and correction", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.6252604946494102}]}, {"text": "The scheme is designed in an un-supervised & data-driven manner, suitable for resource-poor languages.", "labels": [], "entities": []}, {"text": "Based on the evaluation on real dataset in Vietnamese language, our approach gives an acceptable performance (detection accuracy 86%, correction accuracy 71%).", "labels": [], "entities": [{"text": "detection accuracy", "start_pos": 110, "end_pos": 128, "type": "METRIC", "confidence": 0.7742856442928314}, {"text": "correction accuracy", "start_pos": 134, "end_pos": 153, "type": "METRIC", "confidence": 0.8240202963352203}]}, {"text": "In addition, we also give a result analysis to show how accurate our approach can achieve.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We used the following measure to evaluate the performance of VOSE: -For Detection: Where: \u2212 DR (Detection Recall) = the fraction of errors correctly detected.", "labels": [], "entities": [{"text": "VOSE", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.41811391711235046}, {"text": "DR (Detection Recall)", "start_pos": 92, "end_pos": 113, "type": "METRIC", "confidence": 0.8856116890907287}]}, {"text": "\u2212 DP (Detection Precision) = the fraction of detected errors that are correct.", "labels": [], "entities": [{"text": "DP (Detection Precision)", "start_pos": 2, "end_pos": 26, "type": "METRIC", "confidence": 0.7666413724422455}]}, {"text": "\u2212 DF (Detection F-Measure) = the combination of detection recall and precision.", "labels": [], "entities": [{"text": "DF (Detection F-Measure)", "start_pos": 2, "end_pos": 26, "type": "METRIC", "confidence": 0.7741498589515686}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9247738718986511}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9991955161094666}]}, {"text": "-For Correction: Where: \u2212 CR (Correction Recall) = the fraction of errors correctly amended.", "labels": [], "entities": [{"text": "CR (Correction Recall)", "start_pos": 26, "end_pos": 48, "type": "METRIC", "confidence": 0.8660319447517395}, {"text": "fraction of errors correctly amended", "start_pos": 55, "end_pos": 91, "type": "METRIC", "confidence": 0.6752816498279571}]}, {"text": "\u2212 CP (Correction Precision) = the fraction of amended errors that are correct.", "labels": [], "entities": [{"text": "CP (Correction Precision)", "start_pos": 2, "end_pos": 27, "type": "METRIC", "confidence": 0.8222208261489868}]}, {"text": "\u2212 CF (Correction F-Measure) = the combination of correction recall and precision.", "labels": [], "entities": [{"text": "CF (Correction F-Measure)", "start_pos": 2, "end_pos": 27, "type": "METRIC", "confidence": 0.825215744972229}, {"text": "correction", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.8857148289680481}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.619431734085083}, {"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9986220598220825}]}], "tableCaptions": [{"text": " Table 3: Ngram extraction data statistics.", "labels": [], "entities": [{"text": "Ngram extraction data", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.7218858997027079}]}, {"text": " Table 4: Evaluation results. Abbreviations: TVN (Tone & Vowel Normalization); N-LM (N-order  Language Modelling); DS (Dataset); PK (Prior Knowledge); WC (Weighting-based Corrector).", "labels": [], "entities": [{"text": "Abbreviations", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.9907394647598267}]}]}