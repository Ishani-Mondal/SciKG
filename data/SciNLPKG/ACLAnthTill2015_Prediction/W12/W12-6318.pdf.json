{"title": [{"text": "A Comparison of Chinese Word Segmentation on News and Microblog Corpora with a Lexicon Based Method", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.5504859487215678}]}], "abstractContent": [{"text": "Microblog is anew and important social media nowadays.", "labels": [], "entities": [{"text": "Microblog", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9539353847503662}]}, {"text": "Can traditional methods deal well with Chinese microblog word segmenta-tion?", "labels": [], "entities": []}, {"text": "We adopt the forward maximum matching (FMM) method and design rules to recognize words with non-Chinese characters.", "labels": [], "entities": [{"text": "forward maximum matching (FMM)", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.529608741402626}]}, {"text": "We focus on comparing results between news text and microblog.", "labels": [], "entities": []}, {"text": "The lexicon based method allows us to investigate well new words emerging in microblog by comparing with lexicon words.", "labels": [], "entities": []}, {"text": "Experimental results show that the performance on microblog outperforms that on news text under the same setup, which maybe a signal that microblog word segmentation is not as hard as expected.", "labels": [], "entities": [{"text": "microblog word segmentation", "start_pos": 138, "end_pos": 165, "type": "TASK", "confidence": 0.6208188831806183}]}], "introductionContent": [{"text": "Chinese is writtern as a sequence of characters, with no boundary between words.", "labels": [], "entities": []}, {"text": "Word segmentation or word breaking is a task to recognize words and turn a sequence of characters into a sequence of words.", "labels": [], "entities": [{"text": "Word segmentation or word breaking", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6971573412418366}]}, {"text": "Because word is the basic unit of a language, word segmentation is considered as the first step of Chinese language processing.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7302336096763611}, {"text": "Chinese language processing", "start_pos": 99, "end_pos": 126, "type": "TASK", "confidence": 0.6207499404748281}]}, {"text": "Extensive work has been done on Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.5960688392321268}]}, {"text": "Word segmentation methods can be divided into two categories.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6844612061977386}]}, {"text": "The first category is lexicon based method.", "labels": [], "entities": []}, {"text": "This method needs a predefined lexicon or word list.", "labels": [], "entities": []}, {"text": "Solely based on the lexicon, maximum matching method can be used for word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7611639201641083}]}, {"text": "Combined with labeled corpus, statistical methods can be applied.", "labels": [], "entities": []}, {"text": "The other category is character tagging method.", "labels": [], "entities": [{"text": "character tagging", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.9114088416099548}]}, {"text": "This method considers word segmentation as a character position classification problem or sequence labeling problem, and applies related machine learning models.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7789805233478546}, {"text": "character position classification problem or sequence labeling", "start_pos": 45, "end_pos": 107, "type": "TASK", "confidence": 0.6970152727195195}]}, {"text": "Supervised machine learning methods need labeled data.", "labels": [], "entities": []}, {"text": "In order to alleviate human labeling labor and utilize large scale unlabeled data, semisupervised (Sun and Xu, 2011) and unsupervised methods () are also studied.", "labels": [], "entities": []}, {"text": "SIGHAN has organized several bakeoff tasks for Chinese word segmentation on news corpora, which has greatly pushed the advancement of Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.6008978386720022}, {"text": "Chinese word segmentation", "start_pos": 134, "end_pos": 159, "type": "TASK", "confidence": 0.5867681304613749}]}, {"text": "This year it turns to microblog word segmentation, in the face of the great development of microblog and social network in Chinese.", "labels": [], "entities": [{"text": "microblog word segmentation", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.6224356393019358}]}, {"text": "Compared with news text, microblog has more words containing non-Chinese characters, like numbers, alphabets, symbols, etc.", "labels": [], "entities": []}, {"text": "Such words are of great number but can be classified into different types and recognized respectively based on rules.", "labels": [], "entities": []}, {"text": "Chinese character sequences in microblog are relatively shorter than those in news text.", "labels": [], "entities": []}, {"text": "So a traditional segmenter enhanced by a special process of non-Chinese characters may have a good performance.", "labels": [], "entities": []}, {"text": "In this paper, we propose a lexicon and rule based method, using forward maximum matching (FMM) method to recognize Chinese words and regular expressions to recognize words with non-Chinese characters.", "labels": [], "entities": [{"text": "forward maximum matching (FMM)", "start_pos": 65, "end_pos": 95, "type": "METRIC", "confidence": 0.8721301853656769}]}, {"text": "FMM is simple and fast implemented, and is always taken as a baseline method.", "labels": [], "entities": [{"text": "FMM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7390713095664978}]}, {"text": "Here we take FMM to compare the baseline performance on corpora of different styles.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the word segmentation process.", "labels": [], "entities": [{"text": "word segmentation process", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.7877835730711619}]}, {"text": "Section 3 gives experimental results and analysis, including comparison of different lexicons, comparison of different corpora, and comparison of experimental results.", "labels": [], "entities": []}, {"text": "Conclusions are given in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "Several popular Chinese lexicons are compared to explore the impact of lexicons on the FMM method.", "labels": [], "entities": []}, {"text": "Word distributions are compared between news and microblog corpora.", "labels": [], "entities": []}, {"text": "Experimental results with respect to different metrics are compared and analyzed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Size of vocabulary intersection of dif- ferent lexicons", "labels": [], "entities": []}, {"text": " Table 4. The official result", "labels": [], "entities": []}]}