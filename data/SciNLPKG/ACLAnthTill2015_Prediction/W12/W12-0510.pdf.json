{"title": [{"text": "Coupling Knowledge-Based and Data-Driven Systems for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.7907596627871195}]}], "abstractContent": [{"text": "Within Information Extraction tasks, Named Entity Recognition has received much attention over latest decades.", "labels": [], "entities": [{"text": "Information Extraction tasks", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.8521127899487814}, {"text": "Named Entity Recognition", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7187464038530985}]}, {"text": "From symbolic / knowledge-based to data-driven / machine-learning systems, many approaches have been experimented.", "labels": [], "entities": []}, {"text": "Our work maybe viewed as an attempt to bridge the gap from the data-driven perspective back to the knowledge-based one.", "labels": [], "entities": []}, {"text": "We use a knowledge-based system, based on manually implemented transducers, that reaches satisfactory performances.", "labels": [], "entities": []}, {"text": "It has the undisputable advantage of being modular.", "labels": [], "entities": []}, {"text": "However, such a hand-crafted system requires substantial efforts to cope with dedicated tasks.", "labels": [], "entities": []}, {"text": "In this context , we implemented a pattern extractor that extracts symbolic knowledge, using hierarchical sequential pattern mining over annotated corpora.", "labels": [], "entities": []}, {"text": "To assess the accuracy of mined patterns, we designed a module that recognizes Named Entities in texts by determining their most probable boundaries.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9980974793434143}]}, {"text": "Instead of considering Named Entity Recognition as a labeling task, it relies on complex context-aware features provided by lower-level systems and considers the tagging task as a markovian process.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.6358528037865957}]}, {"text": "Using thos systems, coupling knowledge-based system with extracted patterns is straightforward and leads to a competitive hybrid NE-tagger.", "labels": [], "entities": []}, {"text": "We report experiments using this system and compare it to other hybridization strategies along with a baseline CRF model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entity Recognition (NER) is an information extraction (IE) task that aims at extracting and categorizing specific entities (proper names or dedicated linguistic units as time expressions, amounts, etc.) in texts.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.787294382850329}, {"text": "information extraction (IE) task", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.8654608527819315}, {"text": "extracting and categorizing specific entities (proper names or dedicated linguistic units as time expressions, amounts, etc.) in texts", "start_pos": 83, "end_pos": 217, "type": "TASK", "confidence": 0.5810823670842431}]}, {"text": "These texts can be produced in diverse conditions.", "labels": [], "entities": []}, {"text": "In particular, they may correspond to either electronic written documents) or more recently speech transcripts provided by a human expert or an automatic speech recognition (ASR) system ().", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 144, "end_pos": 178, "type": "TASK", "confidence": 0.7628106971581777}]}, {"text": "The recognized entities may later be used by higher-level tasks for different purposes such as Information Retrieval or Open-Domain Question-Answering).", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.7858621776103973}]}, {"text": "While NER is often considered as quite a simple task, there is still room for improvement when it is confronted to difficult contexts.", "labels": [], "entities": [{"text": "NER", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9792218804359436}]}, {"text": "For instance, NER systems may have to cope with noisy data such as word sequences containing speech recognition errors in ASR.", "labels": [], "entities": []}, {"text": "In addition, NER is no more circumscribed to proper names, but may also involve common nouns (e.g., \"the judge\") or complex multi-word expressions (e.g. \"the Computer Science department of the New York University\").", "labels": [], "entities": [{"text": "NER", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.97365802526474}]}, {"text": "These complementary needs for robust and detailed processing explain that knowledgebased and data-driven approaches remain equally competitive on NER tasks as shown by numerous evaluation campaigns.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 146, "end_pos": 155, "type": "TASK", "confidence": 0.917966365814209}]}, {"text": "For instance, the Frenchspeaking Ester2 evaluation campaign on radio broadcasts () has shown that knowledge-based approaches outperformed datadriven ones on manual transcriptions while a system based on Conditional Random Fields (CRFs, participant LIA) is ranked first on noisy ASR transcripts.", "labels": [], "entities": [{"text": "Frenchspeaking Ester2 evaluation", "start_pos": 18, "end_pos": 50, "type": "DATASET", "confidence": 0.922998329003652}]}, {"text": "This is why the development of hybrid systems has been investigated by the NER community.", "labels": [], "entities": [{"text": "NER", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.8508689403533936}]}, {"text": "In this paper, we present a strategy of hybridization benefiting from features produced by a knowledge-based system (CasEN) and a datadriven pattern extractor (mineXtract).", "labels": [], "entities": []}, {"text": "CasEN has been manually implemented based on finitestate transducers.", "labels": [], "entities": []}, {"text": "Such a hand-crafted system requires substantial efforts to be adapted to dedicated tasks.", "labels": [], "entities": []}, {"text": "We developed mineXtract, a textmining system that automatically extracts informative rules, based on hierarchical sequential pattern mining.", "labels": [], "entities": [{"text": "hierarchical sequential pattern mining", "start_pos": 101, "end_pos": 139, "type": "TASK", "confidence": 0.6720030456781387}]}, {"text": "Both implement processings that are context-aware and use lexicons.", "labels": [], "entities": []}, {"text": "Finally, to recognize NEs, we propose mStruct, alight multipurpose automatic annotator, parameterized using logistic regression over available features.", "labels": [], "entities": []}, {"text": "It takes into account features provided by lower-level systems and annotation scheme constraints to output a valid annotation maximizing likelihood.", "labels": [], "entities": []}, {"text": "Our experiments show that the resulting hybrid system outperforms standalone systems and reaches performances comparable to a baseline hybrid CRF system.", "labels": [], "entities": []}, {"text": "We consider this as a step forward towards a tighter integration of knowledge-based and data-driven approaches for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9837311506271362}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the context of this work and reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 describes CasEN, the knowledge-based NE-tagger.", "labels": [], "entities": []}, {"text": "Section 4 details the process of extracting patterns from annotated data as informative rules.", "labels": [], "entities": []}, {"text": "We then introduce the automatic annotator mStruct in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 describes how to gather features from systems and present diverse hybridization strategies.", "labels": [], "entities": []}, {"text": "Corpora, metrics used and evaluation results are reported in Section 7.", "labels": [], "entities": [{"text": "Section 7", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.8947525024414062}]}, {"text": "We conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "This paper focuses on NER in the context of the Ester2 evaluation campaign (.", "labels": [], "entities": [{"text": "NER", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9642216563224792}, {"text": "Ester2 evaluation campaign", "start_pos": 48, "end_pos": 74, "type": "DATASET", "confidence": 0.8144788146018982}]}, {"text": "This campaign assesses system's performance for IE tasks over ASR outputs and manual transcriptions of radio broadcast news (see details in Section 7).", "labels": [], "entities": [{"text": "IE tasks", "start_pos": 48, "end_pos": 56, "type": "TASK", "confidence": 0.9141025543212891}]}, {"text": "The annotation guidelines specified 7 kinds of entities to be detected and categorized: persons ('pers'), organizations ('org'), locations ('loc'), amounts ('amount'), time expressions ('time'), functions ('func'), products ('prod').", "labels": [], "entities": []}, {"text": "Technically, the annotation scheme is quite simple: only one annotation per entity, al- Tokens and NEs s 1 <pers> Isaac Newton </pers> was admitted in <time> June 1661 </time> to <org> Cambridge </org>.", "labels": [], "entities": [{"text": "Cambridge", "start_pos": 185, "end_pos": 194, "type": "DATASET", "confidence": 0.9327021837234497}]}, {"text": "s 2 <time> In 1696 </time>, he moved to <loc> London </loc> as <func> warden of the Royal Mint </func>.", "labels": [], "entities": [{"text": "Royal Mint", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.9568370282649994}]}, {"text": "s 3 He was buried in <loc> Westminster Abbey </loc>.: Sentences from an annotated corpus most no nesting (except for persons collocated with their function: both should be embedded in an encompassing 'pers' NE).", "labels": [], "entities": [{"text": "Westminster Abbey", "start_pos": 27, "end_pos": 44, "type": "DATASET", "confidence": 0.9762588143348694}]}, {"text": "We illustrate the annotation scheme using a running example.", "labels": [], "entities": []}, {"text": "presents the expected annotation in the context of Ester2 from \"Isaac Newton was admitted in June 1661 to Cambridge.", "labels": [], "entities": [{"text": "Ester2", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.6188285946846008}, {"text": "Isaac Newton was admitted in June 1661 to Cambridge", "start_pos": 64, "end_pos": 115, "type": "DATASET", "confidence": 0.7735774252149794}]}, {"text": "In 1696, he moved to London as warden of the Royal Mint.", "labels": [], "entities": [{"text": "Royal Mint", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.9801332354545593}]}, {"text": "He was buried in Westminster Abbey.\".", "labels": [], "entities": [{"text": "Westminster Abbey.", "start_pos": 17, "end_pos": 35, "type": "DATASET", "confidence": 0.9845390021800995}]}, {"text": "This example illustrates frequent problems for NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 47, "end_pos": 55, "type": "TASK", "confidence": 0.8937352895736694}]}, {"text": "Determining the extent of a NE maybe difficult.", "labels": [], "entities": [{"text": "NE", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.49924999475479126}]}, {"text": "For instance, NER should consider here either \"Westminster\" (city) or \"Westminster Abbey\" (church, building).", "labels": [], "entities": [{"text": "NER", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.4926204979419708}, {"text": "Westminster", "start_pos": 47, "end_pos": 58, "type": "DATASET", "confidence": 0.9482886791229248}, {"text": "Westminster Abbey\"", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.9359351197878519}]}, {"text": "Categorizing NEs is confronted to words ambiguities, for instance \"Cambridge\" maybe considered as a city ('loc') or a university ('org').", "labels": [], "entities": []}, {"text": "In addition, oral transcripts may contain disfluencies, repetitions, hesitations, speech recognition errors: overall difficulty is significantly increased.", "labels": [], "entities": [{"text": "repetitions", "start_pos": 56, "end_pos": 67, "type": "METRIC", "confidence": 0.9466202855110168}, {"text": "speech recognition", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.6457594782114029}, {"text": "difficulty", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9774659872055054}]}, {"text": "For these reasons, NER over such noisy data is a challenging task.", "labels": [], "entities": [{"text": "NER", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9930452704429626}]}], "tableCaptions": [{"text": " Table 2: Characteristics of Corpora", "labels": [], "entities": []}, {"text": " Table 3: Performance of Systems", "labels": [], "entities": []}, {"text": " Table 4: Comparing performances of systems", "labels": [], "entities": []}, {"text": " Table 5: Impact of 'func' over SER and f-score", "labels": [], "entities": [{"text": "Impact", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9559610486030579}, {"text": "SER", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9973498582839966}]}]}