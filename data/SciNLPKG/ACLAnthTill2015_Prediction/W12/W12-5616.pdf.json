{"title": [{"text": "A Three Stage Hybrid Parser for Hindi", "labels": [], "entities": []}], "abstractContent": [{"text": "The present paper describes a three stage technique to parse Hindi sentences.", "labels": [], "entities": [{"text": "parse Hindi sentences", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.8868235349655151}]}, {"text": "In the first stage we create a model with the features of head words of each chunk and their dependency relations.", "labels": [], "entities": []}, {"text": "Here, the dependency relations are inter-chunk dependency relations.", "labels": [], "entities": []}, {"text": "We have experimentally fixed a feature set for learning this model.", "labels": [], "entities": []}, {"text": "In the second stage, we extract the intra-chunk dependency relations using a set of rules.", "labels": [], "entities": []}, {"text": "The first stage is combined with the second stage to build a two-stage word level Hindi dependency parser.", "labels": [], "entities": [{"text": "word level Hindi dependency parser", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.5778079926967621}]}, {"text": "In the third stage, we formulate some rules based on features and used them to post-process the output given by the two-stage parser.", "labels": [], "entities": []}, {"text": "1 Introduction Parsing a sentence can be considered as finding the dependency relations of some pair of words in a sentence.", "labels": [], "entities": []}, {"text": "The words must be related in such away that they form a leveled tree structure where nodes are words, edges are assigned between the pairs of words which are related and levels are name of relations.", "labels": [], "entities": []}, {"text": "Leveled tree structures fora set of sentences are referred to as dependency Treebank.", "labels": [], "entities": []}, {"text": "In Hindi dependency tree, the groups of words which are related by intra-chunk dependency relations occur as adjacent nodes.", "labels": [], "entities": []}, {"text": "Each such group is referred to as chunk.", "labels": [], "entities": []}, {"text": "The Hindi Treebank released in MTPIL-2012 shared task contains the chunk information (boundary, tag, head) and dependency relations between the constituents of the chunk (intra-chunk dependency relations) and between chunks (inter-chunk dependency relations).", "labels": [], "entities": [{"text": "Hindi Treebank released in MTPIL-2012 shared task", "start_pos": 4, "end_pos": 53, "type": "DATASET", "confidence": 0.8792173862457275}]}, {"text": "Instead of considering each word as anode, we reduce Hindi dependency tree structure by considering each chunk as anode in a statistical parser.", "labels": [], "entities": []}, {"text": "However, this tree structure does not contain the intra-chunk relations.", "labels": [], "entities": []}, {"text": "Intra-chunk relations are identified using a rule based approach.", "labels": [], "entities": []}, {"text": "We have compared this chunk level statistical parsing followed by the rule based intra-chunk relation identification stage (two-stage technique) with the word level statistical parsing where each word is considered as anode.", "labels": [], "entities": [{"text": "chunk level statistical parsing", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.6030780896544456}, {"text": "intra-chunk relation identification", "start_pos": 81, "end_pos": 116, "type": "TASK", "confidence": 0.7389905452728271}, {"text": "word level statistical parsing", "start_pos": 154, "end_pos": 184, "type": "TASK", "confidence": 0.5876642093062401}]}, {"text": "Finally, we have formulated some rules based on the list of Hindi specific constraints and used them to improve the relations assigned by the two-stage technique.", "labels": [], "entities": []}, {"text": "Each stages of this three-stage parsing are evaluated using the official CoNLL-07 shared task evaluation script eval07.pl.", "labels": [], "entities": [{"text": "CoNLL-07 shared task evaluation script eval07.pl", "start_pos": 73, "end_pos": 121, "type": "DATASET", "confidence": 0.8239735464255015}]}, {"text": "2 Related Work Some work has been done on using Paninian framework for parsing Hindi sentences.", "labels": [], "entities": [{"text": "Paninian framework", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.8530564308166504}, {"text": "parsing Hindi sentences", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.893782913684845}]}, {"text": "(2002) have developed a Hindi parser by translating Hindi grammatical 155", "labels": [], "entities": []}], "introductionContent": [{"text": "Parsing a sentence can be considered as finding the dependency relations of some pair of words in a sentence.", "labels": [], "entities": [{"text": "Parsing a sentence", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8900575041770935}]}, {"text": "The words must be related in such away that they form a leveled tree structure where nodes are words, edges are assigned between the pairs of words which are related and levels are name of relations.", "labels": [], "entities": []}, {"text": "Leveled tree structures fora set of sentences are referred to as dependency Treebank.", "labels": [], "entities": []}, {"text": "In Hindi dependency tree, the groups of words which are related by intra-chunk dependency relations occur as adjacent nodes.", "labels": [], "entities": []}, {"text": "Each such group is referred to as chunk.", "labels": [], "entities": []}, {"text": "The Hindi Treebank released in MTPIL -2012 shared task contains the chunk information (boundary, tag, head) and dependency relations between the constituents of the chunk (intra-chunk dependency relations) and between chunks (inter-chunk dependency relations).", "labels": [], "entities": [{"text": "Hindi Treebank released in MTPIL -2012 shared task", "start_pos": 4, "end_pos": 54, "type": "DATASET", "confidence": 0.882003492779202}]}, {"text": "Instead of considering each word as anode, we reduce Hindi dependency tree structure by considering each chunk as anode in a statistical parser.", "labels": [], "entities": []}, {"text": "However, this tree structure does not contain the intra-chunk relations.", "labels": [], "entities": []}, {"text": "Intra-chunk relations are identified using a rule based approach.", "labels": [], "entities": []}, {"text": "We have compared this chunk level statistical parsing followed by the rule based intrachunk relation identification stage (two-stage technique) with the word level statistical parsing where each word is considered as anode.", "labels": [], "entities": [{"text": "chunk level statistical parsing", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.6206647679209709}, {"text": "intrachunk relation identification", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.7039067347844442}, {"text": "word level statistical parsing", "start_pos": 153, "end_pos": 183, "type": "TASK", "confidence": 0.5814497694373131}]}, {"text": "Finally, we have formulated some rules based on the list of Hindi specific constraints and used them to improve the relations assigned by the two-stage technique.", "labels": [], "entities": []}, {"text": "Each stages of this three-stage parsing are evaluated using the official CoNLL-07 shared task evaluation script eval07.pl.", "labels": [], "entities": [{"text": "CoNLL-07 shared task evaluation script eval07.pl", "start_pos": 73, "end_pos": 121, "type": "DATASET", "confidence": 0.8239735464255015}]}], "datasetContent": [{"text": "To find the optimal feature set we have experimented on the features in data driven parser.", "labels": [], "entities": []}, {"text": "The same feature set is used for parsing both the chunk level and word level parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.9730778336524963}, {"text": "word level parsing", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.5816531876722971}]}, {"text": "The chunk level parsing is then combined with the second and third stages to build the three-stage parser (Parser1).", "labels": [], "entities": []}, {"text": "Again, the word level parsing is combined with the third stage to build a hybrid parser (Parser2).", "labels": [], "entities": [{"text": "word level parsing", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.5499442716439565}]}, {"text": "Parser1 and Parser2 are compared to find the effect of our approach.", "labels": [], "entities": []}, {"text": "The Hindi Treebank used in this task is provided by the organizers of the MTPIL -2012 Shared Task.", "labels": [], "entities": [{"text": "Hindi Treebank", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.876726359128952}, {"text": "MTPIL -2012 Shared Task", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.6959299206733703}]}, {"text": "Three parts of the Treebank and their sizes are shown below.", "labels": [], "entities": [{"text": "the Treebank", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.7072929441928864}]}, {"text": "\u2022 We have used MaltParser of for training the models and using them for statistically annotating dependency relations between words or chunks in Hindi sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. The time taken to execute the second and  third stages of our approach can be negligible.", "labels": [], "entities": []}]}