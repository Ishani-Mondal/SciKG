{"title": [{"text": "A random forest system combination approach for error detection in digital dictionaries", "labels": [], "entities": [{"text": "error detection", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7342151254415512}]}], "abstractContent": [{"text": "When digitizing a print bilingual dictionary, whether via optical character recognition or manual entry, it is inevitable that errors are introduced into the electronic version that is created.", "labels": [], "entities": []}, {"text": "We investigate automating the process of detecting errors in an XML representation of a digitized print dictionary using a hybrid approach that combines rule-based, feature-based, and language model-based methods.", "labels": [], "entities": []}, {"text": "We investigate combining methods and show that using random forests is a promising approach.", "labels": [], "entities": []}, {"text": "We find that in isolation, unsupervised methods rival the performance of supervised methods.", "labels": [], "entities": []}, {"text": "Random forests typically require training data so we investigate how we can apply random forests to combine individual base methods that are themselves unsupervised without requiring large amounts of training data.", "labels": [], "entities": []}, {"text": "Experiments reveal empirically that a relatively small amount of data is sufficient and can potentially be further reduced through specific selection criteria.", "labels": [], "entities": []}], "introductionContent": [{"text": "Digital versions of bilingual dictionaries often have errors that need to be fixed.", "labels": [], "entities": []}, {"text": "For example, Figures 1 through 5 show an example of an error that occurred in one of our development dictionaries and how the error should be corrected.", "labels": [], "entities": []}, {"text": "shows the entry for the word \"turfah\" as it appeared in the original print copy of.", "labels": [], "entities": []}, {"text": "We see this word has three senses with slightly different meanings.", "labels": [], "entities": []}, {"text": "The third sense is \"rare\".", "labels": [], "entities": []}, {"text": "In the original digitized XML version of) depicted in, this was misrepresented as not being the meaning  of \"turfah\" but instead being a usage note that frequency of use of the third sense was rare.", "labels": [], "entities": []}, {"text": "shows the tree corresponding to this XML representation.", "labels": [], "entities": []}, {"text": "The corrected digital XML representation is depicted in and the corresponding corrected tree is shown in.  presented a method for repairing a digital dictionary in an XML format using a dictionary markup language called DML.", "labels": [], "entities": []}, {"text": "It remains time-consuming and error-prone however to have a human read through and manually correct a digital version of a dictionary, even with languages such as DML available.", "labels": [], "entities": []}, {"text": "We therefore investigate automating the detection of errors.", "labels": [], "entities": []}, {"text": "We investigate the use of three individual methods.", "labels": [], "entities": []}, {"text": "The first is a supervised feature-based method trained using SVMs    method that replicates the method presented in ).", "labels": [], "entities": []}, {"text": "The third is a simple rule inference method.", "labels": [], "entities": []}, {"text": "The three individual methods have different performances.", "labels": [], "entities": []}, {"text": "So we investigate how we can combine the methods most effectively.", "labels": [], "entities": []}, {"text": "We experiment with majority vote, score combination, and random forest methods and find that random forest combinations work the best.", "labels": [], "entities": []}, {"text": "For many dictionaries, training data will not be available in large quantities a priori and therefore methods that require only small amounts of training data are desirable.", "labels": [], "entities": []}, {"text": "Interestingly, for automatically detecting errors in dictionaries, we find that the unsupervised methods have performance that rivals that of the supervised feature-based method trained using SVMs.", "labels": [], "entities": []}, {"text": "Moreover, when we combine methods using the random forest method, the combination of unsupervised methods works better than the supervised method in isolation and almost as well as the combination of all available methods.", "labels": [], "entities": []}, {"text": "A potential drawback of using the random forest combination method however is that it requires training data.", "labels": [], "entities": []}, {"text": "We investigated how much training data is needed and find that the amount of training data required is modest.", "labels": [], "entities": []}, {"text": "Furthermore, by selecting the training data to be labeled with the use of specific selection methods reminiscent of active learning, it maybe possible to train the random forest system combination method with even less data without sacrificing performance.", "labels": [], "entities": []}, {"text": "In section 2 we discuss previous related work and in section 3 we explain the three individual methods we use for our application.", "labels": [], "entities": []}, {"text": "In section 4 we explain the three methods we explored for combining methods; in section 5 we present and discuss experimental results and in section 6 we conclude and discuss future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section explains the details of the experiments we conducted testing the performance of the various individual and combined systems.", "labels": [], "entities": []}, {"text": "Subsection 5.1 explains the details of the data we experiment on; subsection 5.2 provides a summary of the main results of our experiments; and subsection 5.3 discusses the results.", "labels": [], "entities": []}, {"text": "We obtained the data for our experiments using a digitized version of DML to correct errors in a digital, XML representation of the Kitabistan Urdu dictionary.", "labels": [], "entities": [{"text": "Kitabistan Urdu dictionary", "start_pos": 132, "end_pos": 158, "type": "DATASET", "confidence": 0.7612531781196594}]}, {"text": "The current research compared the source XML document and the DML commands to identify the elements that the language experts decided to modify.", "labels": [], "entities": []}, {"text": "We consider those elements to be errors.", "labels": [], "entities": []}, {"text": "This is the ground truth used for training and evaluation.", "labels": [], "entities": []}, {"text": "We evaluate at two tiers, corresponding to two node types in the XML representation of the dictionary: ENTRY and SENSE.", "labels": [], "entities": [{"text": "ENTRY", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.9921090006828308}, {"text": "SENSE", "start_pos": 113, "end_pos": 118, "type": "METRIC", "confidence": 0.9286802411079407}]}, {"text": "The example depicted in shows an example of SENSE.", "labels": [], "entities": []}, {"text": "The intuition of the tier is that errors are detectable (or learnable) from observing the elements within a tier, and do not cross tier boundaries.", "labels": [], "entities": []}, {"text": "These tiers are specific to the Kitabistan Urdu dictionary, and we selected them by observing the data.", "labels": [], "entities": [{"text": "Kitabistan Urdu dictionary", "start_pos": 32, "end_pos": 58, "type": "DATASET", "confidence": 0.8438823024431864}]}, {"text": "A limitation of our work is that we do not know at this time whether they are generally useful across dictionaries.", "labels": [], "entities": []}, {"text": "Future work will be to automatically discover the meaningful evaluation tiers fora new dictionary.", "labels": [], "entities": []}, {"text": "After this process, we have a dataset with 15,808 Entries, of which 47.53% are marked as errors and 78,919 Senses, of which 10.79% are marked as errors.", "labels": [], "entities": []}, {"text": "We perform tenfold cross-validation in all experiments.", "labels": [], "entities": []}, {"text": "In our random forest experiments, we use 12 decision trees, each with only 1 feature.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of individual systems at  ENTRY tier.", "labels": [], "entities": [{"text": "ENTRY", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.7158836126327515}]}, {"text": " Table 2: Performance of individual systems at  SENSE tier.", "labels": [], "entities": []}, {"text": " Table 3: Mean and std of evaluation measures from 100 iterations of experiments using RULE+RF.  (ENTRY tier)", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9969531297683716}, {"text": "RULE+RF", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.803065836429596}, {"text": "ENTRY", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.9860636591911316}]}, {"text": " Table 4: Mean and std of evaluation measures from 100 iterations of experiments using RULE+RF.  (SENSE tier)", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9969668984413147}, {"text": "RULE+RF", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.6537489096323649}, {"text": "SENSE", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.8794347643852234}]}, {"text": " Table 5: LM+RULE+FV (ENTRY tier)", "labels": [], "entities": [{"text": "RULE", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.781564474105835}, {"text": "FV", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.7952772378921509}, {"text": "ENTRY", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9828407764434814}]}, {"text": " Table 6: System combination based on random forest (LM+RULE). (ENTRY tier, mean (std))", "labels": [], "entities": [{"text": "RULE", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9303123950958252}, {"text": "ENTRY", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9974578022956848}]}, {"text": " Table 7: System combination based on random forest (LM+RULE). (SENSE tier, mean (std))", "labels": [], "entities": [{"text": "RULE", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9373362064361572}, {"text": "SENSE", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9536007046699524}]}, {"text": " Table 8: System combination based on random forest (LM+RULE+FV). (ENTRY tier, mean (std))", "labels": [], "entities": [{"text": "RULE+FV", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.7335097988446554}, {"text": "ENTRY", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.9968607425689697}]}, {"text": " Table 9: System combination based on random forest (LM+RULE+FV). (SENSE tier, mean (std))", "labels": [], "entities": [{"text": "RULE+FV", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.6655206680297852}, {"text": "SENSE", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.9320225119590759}]}, {"text": " Table 10: Effect of choice of training data based on rule based method (Mean evaluation measures  from 100 iterations of experiments using RULE+LM at ENTRY tier). We choose 1% of the data for  training and the first column in the table specifies the percentage of training data chosen from Entries  with anomalous score larger than 0.9.", "labels": [], "entities": [{"text": "RULE+LM", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.8944722016652426}, {"text": "ENTRY", "start_pos": 151, "end_pos": 156, "type": "METRIC", "confidence": 0.8661941885948181}]}]}