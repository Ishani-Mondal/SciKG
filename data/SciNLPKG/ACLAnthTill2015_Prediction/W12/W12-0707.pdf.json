{"title": [{"text": "Dependency Parsing domain adaptation using transductive SVM", "labels": [], "entities": [{"text": "Dependency Parsing domain adaptation", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8267367631196976}]}], "abstractContent": [{"text": "Dependency Parsing domain adaptation involves adapting a dependency parser, trained on an annotated corpus from a given domain (e.g., newspaper articles), to work on a different target domain (e.g., legal documents), given only an unannotated corpus from the target domain.", "labels": [], "entities": [{"text": "Dependency Parsing domain adaptation", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8731505423784256}]}, {"text": "We present a shift/reduce dependency parser that can handle unlabeled sentences in its training set using a transductive SVM as its action selection classifier.", "labels": [], "entities": []}, {"text": "We illustrate the the experiments we performed with this parser on a domain adaptation task for the Italian language.", "labels": [], "entities": [{"text": "domain adaptation task", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.795332133769989}]}], "introductionContent": [{"text": "Dependency parsing is the task of identifying syntactic relationships between words of a sentence and labeling them according to their type.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8891023695468903}]}, {"text": "Typically, the dependency relationships are not defined by an explicit grammar, rather implicitly through a human-annotated corpus which is then processed by a machine learning procedure, yielding a parser trained on that corpus.", "labels": [], "entities": []}, {"text": "Shift-reduce parsers) are an accurate and efficient (linear complexity) approach to this task: They scan the words of a sentence while updating an internal state by means of shift-reduce actions selected by a classifier trained on the annotated corpus.", "labels": [], "entities": []}, {"text": "Since the training corpora are made by human annotators, they are expensive to produce and are typically only available for few domains that don't adequately cover the whole spectrum of the language.", "labels": [], "entities": []}, {"text": "Parsers typically lose significant accuracy when applied on text from domains not covered by their training corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9985059499740601}]}, {"text": "Several techniques have been proposed to adapt a parser to anew domain, even when only unannotated samples from it are available (.", "labels": [], "entities": []}, {"text": "In this work we present a domain adaptation based on the semi-supervised training of the classifier of a shift-reduce parser.", "labels": [], "entities": []}, {"text": "We implement the classifier as a multi-class SVM and train it with a transductive SVM algorithm that handles both labeled examples (generated from the source-domain annotated corpus) and unlabeled examples (generated from the the target-domain unannotated corpus).", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed our experiments using the DeSR parser) on the data sets for the Evalita 2011 dependency parsing domain adaptation task for the Italian language.", "labels": [], "entities": [{"text": "Evalita 2011 dependency parsing domain adaptation task", "start_pos": 77, "end_pos": 131, "type": "TASK", "confidence": 0.8354805878230503}]}, {"text": "The data set consists in an annotated sourcedomain corpus (newspaper articles) and an unannotated target-domain corpus (legal documents), plus a small annotated development corpus also from the target domain, which we used to evaluate the performance.", "labels": [], "entities": []}, {"text": "We performed a number of runs of the DeSR parser in various configurations, which differed in the number and type of features extracted, the sentence scanning direction, and whether or not parse tree revision was enabled.", "labels": [], "entities": [{"text": "DeSR parser", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.7028311491012573}, {"text": "sentence scanning", "start_pos": 141, "end_pos": 158, "type": "TASK", "confidence": 0.7261888682842255}, {"text": "parse tree revision", "start_pos": 189, "end_pos": 208, "type": "TASK", "confidence": 0.73688143491745}]}, {"text": "The SVM classifiers always used a quadratic kernel.", "labels": [], "entities": []}, {"text": "In order to keep the running time of transductive SVM training acceptable, we limited the number of unannotated sentences to one hundred, which resulted in about 3200 unlabeled training examples fed to the classifiers.", "labels": [], "entities": [{"text": "SVM training", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.8093252182006836}]}, {"text": "The annotated sentences were 3275.", "labels": [], "entities": []}, {"text": "We performed one run with 500 unannotated sentences and, at the cost of a greatly increased running time, the accuracy improvement was about 1%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9996039271354675}]}, {"text": "We conjecture that a faster semi-supervised training algorithm could allow greater performance improvements by increasing the size of the unannotated corpus that can be processed.", "labels": [], "entities": []}, {"text": "All the experiments were performed on a machine equipped with an quad-core Intel Xeon X3440 processor (8M Cache, 2.53 GHz) and 12 Gigabytes of RAM.", "labels": [], "entities": []}], "tableCaptions": []}