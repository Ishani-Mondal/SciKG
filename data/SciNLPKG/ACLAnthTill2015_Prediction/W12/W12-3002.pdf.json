{"title": [{"text": "Collectively Representing Semi-Structured Data from the Web", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose a single low-dimensional representation of a large collection of table and hyponym data, and show that with a small number of primitive operations , this representation can be used effectively for many purposes.", "labels": [], "entities": []}, {"text": "Specifically we consider queries like set expansion, class prediction etc.", "labels": [], "entities": [{"text": "set expansion", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.7471293807029724}, {"text": "class prediction", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.748943030834198}]}, {"text": "We evaluate our methods on publicly available semi-structured datasets from the Web.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semi-structured data extracted from the web (in some cases extended with hyponym data derived from Hearst patterns like \"X such as Y\") have been used in several tasks, including set expansion () automatic setinstance acquisition (), fact extraction (), and semi-supervised learning of concepts.", "labels": [], "entities": [{"text": "set expansion", "start_pos": 178, "end_pos": 191, "type": "TASK", "confidence": 0.6967373043298721}, {"text": "setinstance acquisition", "start_pos": 205, "end_pos": 228, "type": "TASK", "confidence": 0.6880550980567932}, {"text": "fact extraction", "start_pos": 233, "end_pos": 248, "type": "TASK", "confidence": 0.8166627585887909}]}, {"text": "In past work, these tasks have been addressed using different methods and data structures.", "labels": [], "entities": []}, {"text": "In this paper, we propose a single low-dimensional representation of a large collection of table and hyponym data, and show that with a small number of primitive operations, this representation can be used effectively for many purposes.", "labels": [], "entities": []}, {"text": "In particular, we propose a low-dimensional representation for entities based on the embedding used by the PIC algorithm ().", "labels": [], "entities": []}, {"text": "PIC assigns each node in a graph an initial random value, and then performs an iterative update which brings together the values assigned to near-by nodes, thus producing a one-dimensional embedding of a graph.", "labels": [], "entities": []}, {"text": "In past work, PIC has been used for unsupervised clustering of graphs (; it has also been extended to bipartite graphs (), and it has been shown that performance can be improved by using multiple random starting points, thus producing a low-dimensional (but not one-dimensional) embedding of a graph).", "labels": [], "entities": []}], "datasetContent": [{"text": "Although PIC algorithm is very scalable, in this paper we evaluate performance using smaller datasets which are extensively labeled.", "labels": [], "entities": []}, {"text": "In particular, we use the Delicious Sports, Toy Apple and Hyponym Concept datasets made publicly available by) to evaluate our techniques.", "labels": [], "entities": [{"text": "Toy Apple and Hyponym Concept datasets", "start_pos": 44, "end_pos": 82, "type": "DATASET", "confidence": 0.7956987917423248}]}, {"text": "shows some statistics about these datasets.", "labels": [], "entities": []}, {"text": "Numbers for |Y s | and |(x, Y s )| are derived using the Hyponym Concept Dataset.", "labels": [], "entities": [{"text": "Hyponym Concept Dataset", "start_pos": 57, "end_pos": 80, "type": "DATASET", "confidence": 0.7546683748563131}]}], "tableCaptions": [{"text": " Table 1: Table datasets Statistics", "labels": [], "entities": []}, {"text": " Table 2: Comparison of Run Time on Delicious Sports", "labels": [], "entities": []}]}