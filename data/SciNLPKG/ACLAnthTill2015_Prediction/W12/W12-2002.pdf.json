{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 12-21, Identifying science concepts and student misconceptions in an interactive essay writing tutor", "labels": [], "entities": []}], "abstractContent": [{"text": "We present initial steps towards an interactive essay writing tutor that improves science knowledge by analyzing student essays for misconceptions and recommending science web-pages that help correct those misconceptions.", "labels": [], "entities": []}, {"text": "We describe the five components in this system: identifying core science concepts, determining appropriate pedagogical sequences for the science concepts, identifying student misconceptions in essays, aligning student misconceptions to science concepts, and recommending webpages to address misconceptions.", "labels": [], "entities": []}, {"text": "We provide initial models and evaluations of the models for each component.", "labels": [], "entities": []}], "introductionContent": [{"text": "Students come to class with a variety of misconceptions present in their science knowledge.", "labels": [], "entities": []}, {"text": "For example, science assessments developed by the American Association for the Advancement of Science (AAAS) showed that 49% of American 6th-8th graders believe that the Earth's tectonic plates are only feet thick (while in fact they are miles thick) and that 48% of American 6th-8th graders believe that atoms of a solid are not moving (while in fact all atoms are inconstant motion).", "labels": [], "entities": []}, {"text": "A key challenge for interactive tutoring systems is thus to identify and correct such student misconceptions.", "labels": [], "entities": []}, {"text": "In this article, we develop an interactive essay writing tutor that tries to address these challenges.", "labels": [], "entities": [{"text": "essay writing", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.7133516669273376}]}, {"text": "The tutor first examines a set of science webpages to identify key concepts (Section 4) and attempts to order 1 http://assessment.aaas.org/ the science concepts in a pedagogically appropriate learning path (Section 5).", "labels": [], "entities": []}, {"text": "Then the tutor examines a student essay and identifies misconception sentences (Section 6) and aligns these misconceptions to the true science concepts (Section 7).", "labels": [], "entities": []}, {"text": "Finally, the tutor suggests science webpages that can help the student address each of the misconceptions (Section 8).", "labels": [], "entities": []}, {"text": "The key contributions of this work are: \u2022 Demonstrating that a summarization approach can identify core science concepts \u2022 Showing how a learning path model can be bootstrapped from webpages with grade metadata \u2022 Developing models for misconception identification based on textual entailment techniques \u2022 Presenting an information retrieval approach to aligning misconceptions to science concepts \u2022 Designing a system that recommends webpages to address student misconceptions", "labels": [], "entities": [{"text": "summarization", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9694897532463074}, {"text": "misconception identification", "start_pos": 235, "end_pos": 263, "type": "TASK", "confidence": 0.7387030124664307}]}], "datasetContent": [{"text": "As a preliminary evaluation of the resource recommendation model, we obtained student misconception sentences that had been aligned to concepts in a knowledge map of plate tectonics.", "labels": [], "entities": []}, {"text": "The concepts in the knowledge map were originally drawn from 37 domain webpages, thus each concept could serve as a link between a student misconception and a recommended webpage.", "labels": [], "entities": []}, {"text": "For evaluation, we took all 11 misconceptions fora single student, where each misconception had been aligned through the concepts to on average 3.4 URLs.", "labels": [], "entities": []}, {"text": "For each misconception, we asked the recommender model to rank the 37 domain URLs in order of their relevance to the student misconception.", "labels": [], "entities": []}, {"text": "We expect the final interactive essay writing system to return up to k = 5 resources for each misconception, so we evaluated the performance of the recommender model in terms of precision at five (P@5).", "labels": [], "entities": [{"text": "precision", "start_pos": 178, "end_pos": 187, "type": "METRIC", "confidence": 0.998506486415863}]}, {"text": "That is, of the top five URLs recommended by the system, how many were also recommended by the experts?", "labels": [], "entities": []}, {"text": "Averaging over the 11 student misconception queries, the current model achieves P@5 of 32%, an acceptable initial baseline as randomly recommending resources would achieve only P@5 of 9%.", "labels": [], "entities": [{"text": "P@5", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9811044931411743}]}], "tableCaptions": [{"text": " Table 4: Development set results for identifying miscon- ceptions.", "labels": [], "entities": []}, {"text": " Table 6: Development set results for aligning concepts to  misconceptions.", "labels": [], "entities": []}]}