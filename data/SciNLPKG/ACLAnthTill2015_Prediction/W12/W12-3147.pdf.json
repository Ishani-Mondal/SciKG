{"title": [{"text": "LIUM's SMT Machine Translation Systems for WMT 2012", "labels": [], "entities": [{"text": "SMT Machine Translation", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.893507738908132}, {"text": "WMT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.7485836148262024}]}], "abstractContent": [{"text": "This paper describes the development of French-English and English-French statistical machine translation systems for the 2012 WMT shared task evaluation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.6727683544158936}, {"text": "WMT shared task evaluation", "start_pos": 127, "end_pos": 153, "type": "TASK", "confidence": 0.7968039512634277}]}, {"text": "We developed phrase-based systems based on the Moses de-coder, trained on the provided data only.", "labels": [], "entities": []}, {"text": "Additionally , new features this year included improved language and translation model adaptation using the cross-entropy score for the corpus selection.", "labels": [], "entities": [{"text": "translation model adaptation", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.805686374505361}]}], "introductionContent": [{"text": "This paper describes the statistical machine translation systems developed by the Computer Science laboratory at the University of Le Mans (LIUM) for the 2012 WMT shared task evaluation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6268628338972727}, {"text": "WMT shared task evaluation", "start_pos": 159, "end_pos": 185, "type": "TASK", "confidence": 0.8501413315534592}]}, {"text": "We only considered the translation between French and English (in both directions).", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9663333892822266}]}, {"text": "The main differences with respect to previous year's system ) are as follows: (i) use of more training data as provided by the organizers and (ii) better selection of the monolingual and parallel data according to the domain, using the cross-entropy difference with respect to in-domain and out-of-domain language models.", "labels": [], "entities": []}, {"text": "We kept some previous features: the improvement of the translation model adaptation by unsupervised training, a parallel corpus retrieved by Information Retrieval (IR) techniques and finally, the rescoring with a continuous space target language model for the translation into French.", "labels": [], "entities": [{"text": "translation model adaptation", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.8858246008555094}]}, {"text": "These different points are described in the rest of the paper, together with a summary of the experimental results showing the impact of each component.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: English-French and French-English results: number of source words (in million) and scores on the develop- ment (newstest2011) and internal test (newstest2010) sets for the different systems developed. The BLEU scores and  the number in parentheses are the average and standard deviation over 3 or 4 values when available (see Section 4.)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 215, "end_pos": 219, "type": "METRIC", "confidence": 0.99847012758255}]}]}