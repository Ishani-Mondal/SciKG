{"title": [{"text": "Turning the pipeline into a loop: Iterated unsupervised dependency parsing and PoS induction", "labels": [], "entities": [{"text": "Iterated unsupervised dependency parsing", "start_pos": 34, "end_pos": 74, "type": "TASK", "confidence": 0.5559363961219788}]}], "abstractContent": [], "introductionContent": [], "datasetContent": [{"text": "Because the different kinds of features are assumed to be independent in the BMMM, it is easy to add more features into the model; this simply increases the number of factors in equation 2.", "labels": [], "entities": [{"text": "BMMM", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.8541666865348816}]}, {"text": "To incorporate dependency information, we added a feature for word-word dependencies.", "labels": [], "entities": []}, {"text": "In the model, this means that fora word type j with n j tokens, we observe n j dependency features (each being the head of one token of j).", "labels": [], "entities": []}, {"text": "Like all other features, these are assumed to be drawn from a class-specific multinomial \u03c6 with a Dirichlet prior \u03b2 (d) . Using lexicalized head dependencies introduces sparsity issues in much the same way contextual information does.", "labels": [], "entities": []}, {"text": "In the case of context words, the BMMM and most vector-based clustering systems use a fixed number of most frequent words as features; however in the case of dependencies we use the induced PoS tags of the previous generation as grouping labels: we aggregate the head dependency counts of words that have the same PoS tag, so the dimension of \u03c6 For designing the iterated learning experiments, we used the 10-word version of the WSJ corpus (WSJ10) as development data and ran the iterative learning process for 10 generations.", "labels": [], "entities": [{"text": "BMMM", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.8945908546447754}, {"text": "WSJ corpus (WSJ10)", "start_pos": 429, "end_pos": 447, "type": "DATASET", "confidence": 0.9365874052047729}]}, {"text": "To evaluate the quality of the induced PoS tags we used the manyto-1 (M1) and V-Measure (VM) metrics and for the induced dependencies we used directed and undirected accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.953671395778656}]}, {"text": "presents the developmental result of the iterated learning experiments on WSJ10 where only directed dependencies where used as features.", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.9698238968849182}]}, {"text": "We can see that although there was some improvement in the PoS induction score after the first generation, the rest of the metrics show no significant improvement throughout the experiment.", "labels": [], "entities": [{"text": "PoS induction score", "start_pos": 59, "end_pos": 78, "type": "METRIC", "confidence": 0.7757188280423483}]}, {"text": "When we used undirected dependencies as features () the improvement over iterations was substantial: nearly 8.5% increase in M1 and 1.3% in VM after only 5 iterations.", "labels": [], "entities": [{"text": "M1", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.9330900311470032}]}, {"text": "We can also see that the results of the DMV parser are improving as well: 7% increase in directed and 3.8% in undirected accuracy.", "labels": [], "entities": [{"text": "DMV parser", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.6444247364997864}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9768162965774536}]}, {"text": "This is to be expected, since as show, there is a (weak) correlation between the intrinsic scores of a PoS inducer and the 98 performance of an unsupervised dependency parser trained on the inducer's output.", "labels": [], "entities": []}, {"text": "Using the same development set we selected the remaining system parameters; for the BMMM we fixed the number of induced classes to the number of gold-standard PoS tags for each language and used 500 sampling iterations with annealing.", "labels": [], "entities": [{"text": "BMMM", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.8817173838615417}]}, {"text": "For the DMV model we used 20 EM iterations.", "labels": [], "entities": []}, {"text": "Finally we used observed that after 5 generations the rate of improvement seems to level, so for the rest of the languages we use only 5 learning iterations.", "labels": [], "entities": []}], "tableCaptions": []}