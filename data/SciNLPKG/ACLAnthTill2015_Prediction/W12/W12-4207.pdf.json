{"title": [{"text": "Head Finalization Reordering for Chinese-to-Japanese Machine Translation", "labels": [], "entities": [{"text": "Head Finalization Reordering", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.806711753209432}, {"text": "Chinese-to-Japanese Machine Translation", "start_pos": 33, "end_pos": 72, "type": "TASK", "confidence": 0.6166916390260061}]}], "abstractContent": [{"text": "In Statistical Machine Translation, reordering rules have proved useful in extracting bilingual phrases and in decoding during translation between languages that are structurally different.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.833540658156077}]}, {"text": "Linguistically motivated rules have been incorporated into Chinese-to-English (Wang et al., 2007) and English-to-Japanese (Isozaki et al., 2010b) translation with significant gains to the statistical translation system.", "labels": [], "entities": []}, {"text": "Here, we carryout a linguistic analysis of the Chinese-to-Japanese translation problem and propose one of the first reordering rules for this language pair.", "labels": [], "entities": [{"text": "Chinese-to-Japanese translation problem", "start_pos": 47, "end_pos": 86, "type": "TASK", "confidence": 0.7470773458480835}]}, {"text": "Experimental results show substantially improvements (from 20.70 to 23.17 BLEU) when head-finalization rules based on HPSG parses are used, and further gains (to 24.14 BLEU) were obtained using more refined rules.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9988699555397034}, {"text": "HPSG", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.9089896082878113}, {"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9985272884368896}]}], "introductionContent": [{"text": "In state-of-the-art Statistical Machine Translation (SMT) systems, bilingual phrases are the main building blocks for constructing a translation given a sentence from a source language.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.7893970211346945}]}, {"text": "To extract those bilingual phrases from a parallel corpus, the first step is to discover the implicit wordto-word correspondences between bilingual sentences (.", "labels": [], "entities": []}, {"text": "Then, a symmetrization matrix is built () by using word-to-word alignments, and a wide variety * Now at Baidu Japan Inc.", "labels": [], "entities": [{"text": "Baidu Japan Inc", "start_pos": 104, "end_pos": 119, "type": "DATASET", "confidence": 0.9005716244379679}]}, {"text": "\u2020 Now at Nara Institute of of heuristics can be used to extract the bilingual phrases (.", "labels": [], "entities": [{"text": "Nara Institute", "start_pos": 9, "end_pos": 23, "type": "DATASET", "confidence": 0.950066477060318}]}, {"text": "This method performs relatively well when the source and the target languages have similar word order, as in the case of French, Spanish, and English.", "labels": [], "entities": []}, {"text": "However, when translating between languages with very different structures, as in the case of English and Japanese, or Japanese and Chinese, the quality of extracted bilingual phrases and the overall translation quality diminishes.", "labels": [], "entities": []}, {"text": "In the latter scenario, a simple but effective strategy to cope with this problem is to reorder the words of sentences in one language so that it resembles the word order of another language).", "labels": [], "entities": []}, {"text": "The advantages of this strategy are twofold.", "labels": [], "entities": []}, {"text": "The first advantage is at the decoding stage, since it enables the translation to be constructed almost monotonically.", "labels": [], "entities": []}, {"text": "The second advantage is at the training stage, since automatically estimated word-to-word alignments are likely to be more accurate and symmetrization matrices reveal more evident bilingual phrases, leading to the extraction of better quality bilingual phrases and cleaner phrase tables.", "labels": [], "entities": []}, {"text": "In this work, we focus on Chinese-to-Japanese translation, motivated by the increasing interaction between these two countries and the need to improve direct machine translation without using a pivot language.", "labels": [], "entities": [{"text": "Chinese-to-Japanese translation", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.66379614174366}, {"text": "machine translation", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.749460756778717}]}, {"text": "Despite the countries' close cultural relationship, their languages significantly differ in terms of syntax, which poses a severe difficulty in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 144, "end_pos": 175, "type": "TASK", "confidence": 0.6971370577812195}]}, {"text": "The syntactic relationship of this language pair has not been carefully studied before in the machine translation field, and our work aims to contribute in this direction as follows: \u2022 We present a detailed syntactic analysis of several reordering issues in Chinese-Japanese translation using the information provided by an HPSG-based deep parser.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7365423738956451}]}, {"text": "\u2022 We introduce novel reordering rules based on head-finalization and linguistically inspired refinements to make words in Chinese sentences resemble Japanese word order.", "labels": [], "entities": []}, {"text": "We empirically show its effectiveness (e.g. 20.70 to 24.23 BLEU improvement).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9971187114715576}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the background and gives an overview of similar techniques related to this work.", "labels": [], "entities": []}, {"text": "Section 3 describes the proposed method in detail.", "labels": [], "entities": []}, {"text": "Experimental evaluation of the performance of the proposed method is described in section 4.", "labels": [], "entities": []}, {"text": "There is an error analysis on the obtained results in section 5.", "labels": [], "entities": [{"text": "error", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.9839343428611755}]}, {"text": "Conclusions and a short description on future work derived from this research are given in the final section.", "labels": [], "entities": []}], "datasetContent": [{"text": "The corpus we used as training data comes from the China Workshop on Machine Translation (CWMT) ().", "labels": [], "entities": [{"text": "China Workshop on Machine Translation (CWMT)", "start_pos": 51, "end_pos": 95, "type": "TASK", "confidence": 0.8064456358551979}]}, {"text": "This is a Japanese-Chinese parallel corpus in the news domain, containing 281, 322 sentence pairs.", "labels": [], "entities": []}, {"text": "We also collected another Japanese-Chinese parallel corpus from news containing 529, 769 sentences and merged it with the CWMT corpus to create an extended version of the CWMT corpus.", "labels": [], "entities": [{"text": "CWMT corpus", "start_pos": 122, "end_pos": 133, "type": "DATASET", "confidence": 0.9570012390613556}, {"text": "CWMT corpus", "start_pos": 171, "end_pos": 182, "type": "DATASET", "confidence": 0.9439855515956879}]}, {"text": "We will refer to this corpus as \"CWMT ext.\"", "labels": [], "entities": []}, {"text": "We split an inverted multi-reference set into a development and a test set containing 1, 000 sentences each.", "labels": [], "entities": []}, {"text": "In these two sets, the Chinese input was different, but the Japanese reference was identical.", "labels": [], "entities": []}, {"text": "We think that this split does not pose any severe problem to the comparison fairness of the experiment, since no new phrases are added during tuning and the experimental conditions remain equal for all tested The POSs are from Penn Chinese Treebank.  methods.", "labels": [], "entities": [{"text": "Penn Chinese Treebank.", "start_pos": 227, "end_pos": 249, "type": "DATASET", "confidence": 0.9794050306081772}]}, {"text": "Detailed Corpus statistics can be found in.", "labels": [], "entities": [{"text": "Detailed Corpus", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.8612188100814819}]}, {"text": "To parse Chinese sentences, we used Chinese Enju (, an HPSG-based parser trained with the Chinese HPSG treebank converted from Penn Chinese Treebank.", "labels": [], "entities": [{"text": "parse Chinese sentences", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.8646858334541321}, {"text": "Chinese HPSG treebank", "start_pos": 90, "end_pos": 111, "type": "DATASET", "confidence": 0.6443271934986115}, {"text": "Penn Chinese Treebank", "start_pos": 127, "end_pos": 148, "type": "DATASET", "confidence": 0.8768798112869263}]}, {"text": "Chinese Enju requires segmented and POS-tagged sentences to do parsing.", "labels": [], "entities": [{"text": "Chinese Enju", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8528789579868317}]}, {"text": "We used the Stanford Chinese segmenter ( and Stanford POStagger ( to obtain the segmentation and POS-tagging of the Chinese side of the training, development, and test sets.", "labels": [], "entities": []}, {"text": "The baseline system was trained following the instructions of recent SMT evaluation campaigns) by using the MT toolkit Moses ( ) in its default configuration.", "labels": [], "entities": [{"text": "SMT evaluation", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.9415015280246735}, {"text": "MT toolkit Moses", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.8511874079704285}]}, {"text": "Phrase pairs were extracted from symmetrized word alignments and distortions generated by GIZA++ ( using the combination of heuristics \"grow-diagfinal-and\" and \"msd-bidirectional-fe\".", "labels": [], "entities": []}, {"text": "The language model was a 5-gram language model estimated on the target side of the parallel corpora by using the modified Kneser-Ney smoothing) implemented in the SRILM) toolkit.", "labels": [], "entities": []}, {"text": "The weights of the log-linear combination of feature functions were estimated by using MERT) on the development set described in.", "labels": [], "entities": [{"text": "MERT", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.970499575138092}]}, {"text": "The effectiveness of the reorderings proposed in Section 3.3 was assessed by using two precision metrics and two error metrics on translation quality.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.99518221616745}]}, {"text": "The first evaluation metric is BLEU), a very common accuracy metric in SMT that measures N -gram precision, with a penalty for too short sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.999086856842041}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9906272888183594}, {"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9909607768058777}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.56694096326828}]}, {"text": "The second evaluation metric was RIBES, a recent precision metric used to evaluate translation quality between structurally different languages.", "labels": [], "entities": [{"text": "RIBES", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.807462215423584}, {"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9776371717453003}]}, {"text": "It uses notions on rank correlation coefficients and precision measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9986314177513123}]}, {"text": "The third evaluation metric is TER), another error metric that computes the minimum number of edits required to convert translated sentences into its corresponding references.", "labels": [], "entities": [{"text": "TER)", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9864639639854431}]}, {"text": "Possible edits include insertion, deletion, substitution of single words, and shifts of word sequences.", "labels": [], "entities": []}, {"text": "The fourth evaluation metric is WER, an error metric inspired in the Levenshtein distance at word level.", "labels": [], "entities": [{"text": "WER", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9952988028526306}]}, {"text": "BLEU, WER, and TER were used to provide a sense of comparison but they do not significantly penalize long-range word order errors.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9899829626083374}, {"text": "WER", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.9970813393592834}, {"text": "TER", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9987280964851379}]}, {"text": "For this reason, RIBES was used to account for this aspect of translation quality.", "labels": [], "entities": [{"text": "RIBES", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.8281193375587463}, {"text": "translation", "start_pos": 62, "end_pos": 73, "type": "TASK", "confidence": 0.9622226357460022}]}, {"text": "The baseline system was trained and tuned using the same configuration setup described in this section, but no reordering rule was implemented at the preprocessing stage.", "labels": [], "entities": []}, {"text": "Three systems have been run to translate the test set for comparison when the systems were trained using the two training data sets.", "labels": [], "entities": []}, {"text": "They are the baseline system, the system consisting in the na\u00a8\u0131vena\u00a8\u0131ve implementation of HF reordering, and the system with refined HFC reordering rules.", "labels": [], "entities": []}, {"text": "Assessment of translation quality can be found in.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9624658823013306}]}, {"text": "As can be observed in, the translation quality, as measured by precision and error metrics, was consistently and significantly increased when the HFC reordering rule was used and was significantly improved further when the refinement proposed in this work was used.", "labels": [], "entities": [{"text": "translation", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9384905695915222}, {"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9982482194900513}]}, {"text": "Specifically, the BLEU score increased from 19.94 to 20.79 when the CWMT corpus was used, and from 23.17 to 24.14 when the extended CWMT corpus was used.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9821654260158539}, {"text": "CWMT corpus", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.9217915534973145}, {"text": "CWMT corpus", "start_pos": 132, "end_pos": 143, "type": "DATASET", "confidence": 0.8504456877708435}]}], "tableCaptions": [{"text": " Table 6: Characteristics of CWMT and extended  CWMT Chinese-Japanese corpus. Dev. stands for De- velopment, OoV for \"Out of Vocabulary\" words, K for  thousands of elements, and M for millions of elements.  Data statistics were collected after tokenizing.", "labels": [], "entities": [{"text": "CWMT Chinese-Japanese corpus", "start_pos": 48, "end_pos": 76, "type": "DATASET", "confidence": 0.8204210797945658}]}, {"text": " Table 7: Evaluation of translation quality of a test set when CWMT and CWMT extended corpus were used for  training. Results are given in terms of BLEU, RIBES, TER, and WER for baseline, head finalization, and proposed  refinement of head finalization reordering rules.", "labels": [], "entities": [{"text": "translation", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9522618651390076}, {"text": "CWMT extended corpus", "start_pos": 72, "end_pos": 92, "type": "DATASET", "confidence": 0.7897116343180338}, {"text": "BLEU", "start_pos": 148, "end_pos": 152, "type": "METRIC", "confidence": 0.9992151260375977}, {"text": "RIBES", "start_pos": 154, "end_pos": 159, "type": "METRIC", "confidence": 0.9959422945976257}, {"text": "TER", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.9967803955078125}, {"text": "WER", "start_pos": 170, "end_pos": 173, "type": "METRIC", "confidence": 0.99779212474823}, {"text": "head finalization", "start_pos": 188, "end_pos": 205, "type": "TASK", "confidence": 0.7938503324985504}, {"text": "head finalization reordering", "start_pos": 235, "end_pos": 263, "type": "TASK", "confidence": 0.8264054656028748}]}]}