{"title": [{"text": "Towards Scalable Speech Act Recognition in Twitter: Tackling Insufficient Training Data", "labels": [], "entities": [{"text": "Scalable Speech Act Recognition", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.7989518046379089}, {"text": "Tackling Insufficient Training", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.8610533873240153}]}], "abstractContent": [{"text": "Recognizing speech act types in Twitter is of much theoretical interest and practical use.", "labels": [], "entities": []}, {"text": "Our previous research did not adequately address the deficiency of training data for this multi-class learning task.", "labels": [], "entities": []}, {"text": "In this work, we set out by assuming only a small seed training set and experiment with two semi-supervised learning schemes, transductive SVM and graph-based label propagation, which can leverage the knowledge about unlabeled data.", "labels": [], "entities": [{"text": "graph-based label propagation", "start_pos": 147, "end_pos": 176, "type": "TASK", "confidence": 0.6891675790150961}]}, {"text": "The efficacy of semi-supervised learning is established by our extensive experiments, which also show that transductive SVM is more suitable than graph-based label propagation for our task.", "labels": [], "entities": [{"text": "graph-based label propagation", "start_pos": 146, "end_pos": 175, "type": "TASK", "confidence": 0.727295994758606}]}, {"text": "The empirical findings and detailed evidences can contribute to scalable speech act recognition in Twitter.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.6442272762457529}]}], "introductionContent": [{"text": "The social media platform of Twitter makes available a plethora of data to probe the communicative act of people in asocial network woven by interesting events, people, topics, etc.", "labels": [], "entities": []}, {"text": "Communicative acts such as disseminating information, asking questions, or expressing feelings all fall in the purview of \"speech act\", along established area in pragmatics.", "labels": [], "entities": []}, {"text": "The automatic recognition of speech act in tons of tweets has both theoretical and practical appeal.", "labels": [], "entities": [{"text": "automatic recognition of speech act in tons of tweets", "start_pos": 4, "end_pos": 57, "type": "TASK", "confidence": 0.7701749437385135}]}, {"text": "Practically, it helps tweeters to find topics to read or tweet about based on speech act compositions.", "labels": [], "entities": []}, {"text": "Theoretically, it introduces anew dimension to study social media content as well as providing real-life data to validate or falsify claims in the speech act theory.", "labels": [], "entities": []}, {"text": "Different taxonomies of speech act have been proposed by linguists and computational linguists, ranging from a few to over a hundred types.", "labels": [], "entities": []}, {"text": "In this work, we adopt the 5 types of speech act used in our previous work (), which are in turn inherited from: statement, question, suggestion, comment, and miscellaneous.", "labels": [], "entities": []}, {"text": "Our choice is based on the fact that unlike face-to-face communication, twittering is more in a \"broadcasting\" style than on a personal basis.", "labels": [], "entities": []}, {"text": "Statement and comment, which are usually intended to make one's knowledge, thought, and sentiment known, thus befit Twitter's communicative style.", "labels": [], "entities": []}, {"text": "Question and suggestion on Twitter are usually targeted at other tweeters in general or one's followers.", "labels": [], "entities": []}, {"text": "More interpersonal speech acts such as \"threat\" or \"thank\" as well as rare speech acts in Twitter \"commissives\" and \"declaratives\") are relegated to \"miscellaneous\".", "labels": [], "entities": []}, {"text": "Some examples from our experimental datasets are provided in.", "labels": [], "entities": []}, {"text": "Assuming one tweet demonstrates only one speech act, the automatic recognition of those speech act types in Twitter is a multi-class classification task.", "labels": [], "entities": []}, {"text": "We concede that this assumption may not always hold in real situations.", "labels": [], "entities": []}, {"text": "But given the short length of tweets, multi-speech act tweets are rare and we find this simplifying assumption effective in reducing the complexity of our problem.", "labels": [], "entities": []}, {"text": "A major problem with this task is the deficiency of training data.", "labels": [], "entities": []}, {"text": "Tweeters as well as face-to-face interlocutors do not often identify their speech acts; human annotation is costly and time-consuming.", "labels": [], "entities": []}, {"text": "Although our previous research () sheds light on the preparation of training data, it did not adequately address this problem.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are designed to answer two questions: 1) How useful is semi-supervised speech act learning in comparison with supervised learning?", "labels": [], "entities": []}, {"text": "2) Which semi-supervised learning approach is more appropriate for our problem?", "labels": [], "entities": []}, {"text": "We use the 6 datasets in our previous study 1 , which fall into 3 categories: News, Entity, Longstanding Topic (LST).", "labels": [], "entities": []}, {"text": "Each of the total 8613 tweets is labeled with one of the following speech act types: sta (statement), que (question), sug (suggestion), com (comment), mis (miscellaneous).", "labels": [], "entities": []}, {"text": "In addition, we randomly select 1000 tweets from each of the categories to create a Mixed category of 3000 tweets.", "labels": [], "entities": []}, {"text": "Figures 2 to 5 illustrate the distributions of the speech act types in the 3 original categories and the Mixed category.", "labels": [], "entities": []}, {"text": "For each category, we use two labeled/unlabeled data settings, with labeled data accounting for 5% and 10% of the total so that the labeled/unlabeled ratios are set at approximately 1:19 and 1:9.", "labels": [], "entities": []}, {"text": "The labeled data in each category are randomly selected in a stratified way: using the same percentage to select labeled data with each speech act type.", "labels": [], "entities": []}, {"text": "The stratified selection is intended to keep the speech act distributions in both labeled and unlabeled data.", "labels": [], "entities": []}, {"text": "list the details of data splitting using the two settings.", "labels": [], "entities": [{"text": "data splitting", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7537745237350464}]}, {"text": "The threshold is set to be \u03bc + \u03c3, the mean of all weights plus one standard deviation.", "labels": [], "entities": []}, {"text": "Almost without exception, transductive SVM achieves the best performance.", "labels": [], "entities": [{"text": "SVM", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.7598665952682495}]}, {"text": "Measured by macro-average F, it outperforms inductive SVM with again of 10.7% (Mixed) to 34.2% (News).", "labels": [], "entities": [{"text": "F", "start_pos": 26, "end_pos": 27, "type": "METRIC", "confidence": 0.9551898241043091}]}, {"text": "Consistent with supervised learning results, semi-supervised learning results degrade with News > Entity > LST, indicating that both semisupervised learning and supervised learning are sensitive to dataset characteristics.", "labels": [], "entities": []}, {"text": "More uniform tweet set (e.g., News) leads to better classification and greater improvement by semisupervised learning.", "labels": [], "entities": [{"text": "News", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.834722638130188}]}, {"text": "That also explains why the Mixed category, composed of the most diversified tweets, benefits least from semisupervised learning.", "labels": [], "entities": []}, {"text": "Conversely, supervised learning (inductive SVM) on the Mixed category benefits from the data hodgepodge even though the test data are 19 times the training data.", "labels": [], "entities": []}, {"text": "Its macro-average F is higher than the other categories although it does not have the most training data.", "labels": [], "entities": [{"text": "F", "start_pos": 18, "end_pos": 19, "type": "METRIC", "confidence": 0.9549134373664856}]}, {"text": "Its weightedaverage F using inductive SVM is even higher than using transductive SVM.", "labels": [], "entities": [{"text": "F", "start_pos": 20, "end_pos": 21, "type": "METRIC", "confidence": 0.764336347579956}]}, {"text": "It is a little surprising to find that the graphbased label propagation performs very poorly.", "labels": [], "entities": [{"text": "graphbased label propagation", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.6754758656024933}]}, {"text": "In all but one place, the GLP score is lower than its iSVM counterpart.", "labels": [], "entities": [{"text": "GLP score", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9541646540164948}]}, {"text": "This may indicate that the graph method cannot adapt well to the multiclass scenario and we will show more evidences in the next two sections.", "labels": [], "entities": []}, {"text": "To understand the effectiveness of semisupervised learning, a better way than doing numerical calculation is juxtaposing semisupervised data settings with their comparable supervised data settings, which is shown in.", "labels": [], "entities": []}, {"text": "The supervised data settings are of those with the closest weighted average F (waF) to the semi-supervised (tSVM) waF from our previous results).", "labels": [], "entities": [{"text": "F (waF)", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.8692178726196289}]}, {"text": "Obviously semi-supervised learning by transductive SVM can achieve classification performance comparable to supervised learning by inductive SVM, with less training data and much lower labeled/unlabeled ratio.", "labels": [], "entities": []}, {"text": "This shows that semi-supervised learning such as transductive SVM holds much promise for scalable speech act recognition in Twitter.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.635931392510732}]}, {"text": "It is tempting to think that with more labeled data and higher labeled/unlabeled ratio, semisupervised learning performance should improve.", "labels": [], "entities": []}, {"text": "To put this conjecture to test, we double the labeled data (from 5% to 10%) and labeled/unlabeled ratio (from 1/19 to 1/9), with results in  Compared with, increased labeled data does lead to some improvement, but not much as we would expect, the largest gain being 15.9% (macro-average F on Mixed, using GLP).", "labels": [], "entities": [{"text": "F", "start_pos": 287, "end_pos": 288, "type": "METRIC", "confidence": 0.8642028570175171}]}, {"text": "Note that this is achieved at the cost of labeling twice as much data and predicting half as much.", "labels": [], "entities": []}, {"text": "In contrast, the inductive SVM performance is improved by as much as 41.3% (macro-average F on Entity).", "labels": [], "entities": [{"text": "F", "start_pos": 90, "end_pos": 91, "type": "METRIC", "confidence": 0.9496559500694275}]}, {"text": "Such evidence shows that semisupervised learning of speech acts in Twitter benefits disproportionately little from increased labeled data, or at least the gain is not worth the pain.", "labels": [], "entities": []}, {"text": "In fact, this is good news for scalable speech act recognition.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.6664271950721741}]}, {"text": "For more microscopic inspection, we also report the classification results on individual classes for all categories.", "labels": [], "entities": []}, {"text": "In, we list the rankings of F measures by each classifier for each speech act type and each category.", "labels": [], "entities": []}, {"text": "The one-letter notations i, t, g are short for iSVM, tSVM, and GLP.", "labels": [], "entities": []}, {"text": "Therefore, t > g > i means tSVM outperforms GLP, which outperforms iSVM, in terms of F measure.", "labels": [], "entities": [{"text": "F measure", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9249237179756165}]}, {"text": "The labeled data are 5%.", "labels": [], "entities": []}, {"text": "In 15 out of the 20 rankings, transductive SVM or graph-based label propagation beats inductive SVM, which shows the efficacy of semi-supervised learning in this class-based perspective.", "labels": [], "entities": []}, {"text": "Transductive SVM is the champion, claiming 14 top places.", "labels": [], "entities": [{"text": "Transductive SVM", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.42762087285518646}]}, {"text": "We also find that the overall performance of graph-based label propagation is the poorest, claiming 12 out of 20 bottom places.", "labels": [], "entities": [{"text": "graph-based label propagation", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.645637700955073}]}, {"text": "After inspecting the data, we observe that the underlying assumption of GLP that similar objects belong to the same class is questionable for speech act recognition in Twitter.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.6539358794689178}]}, {"text": "Tweets with different speech acts (e.g., question and comment) may appear very similar on the graph.", "labels": [], "entities": []}, {"text": "The maximal margin approach is apparently more appropriate for our problem.", "labels": [], "entities": [{"text": "maximal margin", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.769085019826889}]}, {"text": "On the other hand, the GLP performance evaluated on individual classes is better than evaluated on the multi-class if we compare, where GLP is almost always the lowest achiever.", "labels": [], "entities": [{"text": "GLP", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.8414950370788574}]}, {"text": "This indicates that in multi-class classification, GLP suffers further from the onevs-all converting scheme, a point we will make clearer in the following.", "labels": [], "entities": [{"text": "GLP", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.7251436114311218}]}], "tableCaptions": [{"text": " Table 2. Stratified Data Splitting with 5% as  Labeled", "labels": [], "entities": [{"text": "Stratified Data Splitting", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.7614389657974243}]}, {"text": " Table 3. Stratified Data Splitting with 10% as  Labeled", "labels": [], "entities": [{"text": "Stratified Data Splitting", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.7723977168401083}]}, {"text": " Table 4. Multi-class F scores (5% labeled data)", "labels": [], "entities": [{"text": "F scores", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8597607612609863}]}, {"text": " Table 5. Semi-supervised Learning vs.  Supervised Learning", "labels": [], "entities": []}, {"text": " Table 6. Multi-class F scores (10% labeled data)", "labels": [], "entities": [{"text": "F scores", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8583730757236481}]}]}