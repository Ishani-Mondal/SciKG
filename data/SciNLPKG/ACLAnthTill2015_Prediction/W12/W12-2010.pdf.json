{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 86-94, Using an Ontology for Improved Automated Content Scoring of Spontaneous Non-Native Speech", "labels": [], "entities": [{"text": "Improved Automated Content Scoring of Spontaneous Non-Native Speech", "start_pos": 120, "end_pos": 187, "type": "TASK", "confidence": 0.7935646250844002}]}], "abstractContent": [{"text": "This paper presents an exploration into automated content scoring of non-native spontaneous speech using ontology-based information to enhance a vector space approach.", "labels": [], "entities": [{"text": "automated content scoring of non-native spontaneous speech", "start_pos": 40, "end_pos": 98, "type": "TASK", "confidence": 0.7942277533667428}]}, {"text": "We use content vector analysis as a baseline and evaluate the correlations between human rater proficiency scores and two cosine similarity based features, previously used in the context of automated essay scoring.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 200, "end_pos": 213, "type": "TASK", "confidence": 0.671196773648262}]}, {"text": "We use two ontology-facilitated approaches to improve feature correlations by exploiting the semantic knowledge encoded in WordNet: (1) extending word vectors with semantic concepts from the WordNet ontology (synsets); and (2) using a reasoning approach for estimating the concept weights of concepts not present in the set of training responses by exploiting the hierarchical structure of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 123, "end_pos": 130, "type": "DATASET", "confidence": 0.9217767119407654}, {"text": "WordNet", "start_pos": 390, "end_pos": 397, "type": "DATASET", "confidence": 0.9676055312156677}]}, {"text": "Furthermore, we compare features computed from human transcriptions of spoken responses with features based on output from an automatic speech recognizer.", "labels": [], "entities": []}, {"text": "We find that (1) for one of the two features, both ontologically based approaches improve average feature correlations with human scores, and that (2) the correlations for both features decrease only marginally when moving from human speech transcriptions to speech recognizer output.", "labels": [], "entities": []}], "introductionContent": [{"text": "Currently, automated speech scoring systems mainly utilize features related to the acoustic aspects of a spoken response of a test taker, for example, fluency, pronunciation, and prosody features (.", "labels": [], "entities": []}, {"text": "In terms of the content aspect of speech, for highly predictable speech, such as reading a passage aloud, scoring of content reduces to measuring the reading accuracy of the read passage which is typically achieved by computing the string edit distance between the target passage and the actual text read by the test taker, using the speech recognizer hypothesis as a proxy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.7957665324211121}]}, {"text": "For high entropy speech whose content is difficult to predict such as spontaneous speech in this study, on the other hand, content scoring has not been investigated much so far, mostly due to the difficulty of obtaining accurate word hypotheses for spontaneous non-native speech by Automated Speech Recognition (ASR) systems.", "labels": [], "entities": [{"text": "Automated Speech Recognition (ASR)", "start_pos": 282, "end_pos": 316, "type": "TASK", "confidence": 0.7840952376524607}]}, {"text": "In this paper, we use spoken responses from an English language spoken proficiency test where candidates, all non-native speakers of English, respond to four different prompts 1 with a speaking time of one minute per response.", "labels": [], "entities": []}, {"text": "For this study, we decide to use a baseline approach for content scoring of spontaneous speech that was previously employed fora similar task in the context of automated essay scoring), namely Content Vector Analysis (CVA) where every document is represented as a vector of word weights, based on their frequencies in a document or document collection.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 170, "end_pos": 183, "type": "TASK", "confidence": 0.7171896398067474}, {"text": "Content Vector Analysis (CVA", "start_pos": 193, "end_pos": 221, "type": "TASK", "confidence": 0.7328727424144745}]}, {"text": "However, there are two issues with the CVA vector of words representation that we want to address with this study: (1) Similar words are treated in isolation and not grouped together.", "labels": [], "entities": [{"text": "CVA vector of words representation", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.5267655193805695}]}, {"text": "Words with similar meaning should be treated in the same way in an automated scoring system, so grouping word synonyms into semantic concepts can help with this issue.", "labels": [], "entities": [{"text": "grouping word synonyms into semantic concepts", "start_pos": 96, "end_pos": 141, "type": "TASK", "confidence": 0.7712769508361816}]}, {"text": "(2) The vector of word representation is based on an exist-ing corpus of training documents.", "labels": [], "entities": [{"text": "word representation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7199469953775406}]}, {"text": "When encountering a word or concept in a test document that is not contained in the training set, it is difficult to decide the relevance of that word or concept.", "labels": [], "entities": []}, {"text": "We propose to use ontology-facilitated approaches as solutions to these two issues, aiming at enriching speech content representations to improve speech content scoring.", "labels": [], "entities": [{"text": "speech content scoring", "start_pos": 146, "end_pos": 168, "type": "TASK", "confidence": 0.667596439520518}]}, {"text": "Specifically, to address issue (1), we represent speech content by concept-level vectors, using the synsets (lists of synonymous words) of the WordNet ontology.", "labels": [], "entities": [{"text": "WordNet ontology", "start_pos": 143, "end_pos": 159, "type": "DATASET", "confidence": 0.9337321817874908}]}, {"text": "As for issue (2), we expand the vector representation by inferring the importance (weight) of concepts not present in the training vectors based on their path distance to known concepts or words in the hierarchical structure of the WordNet ontology.", "labels": [], "entities": []}, {"text": "Since we only look at the content aspect of speech without considering the acoustic features in this study, we work on speech transcripts exclusively, both from human transcribers as well as from a state-of-the-art automated speech recognition system, and compare results between the ideal human transcripts and the imperfect transcripts generated by the speech recognizer.", "labels": [], "entities": []}, {"text": "For the purpose of simplified illustration, speech transcripts are often referred to as \"documents\" in the paper as they area special type of textual documents.", "labels": [], "entities": [{"text": "simplified illustration", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.7997210323810577}]}, {"text": "The remainder of this paper is organized as follows: in Section 2, we review related research in content scoring of texts, particularly student essays; Section 3 describes the data set we use for this study and the ASR system; and Section 4 presents the ontologically-facilitated methods we are using in detail.", "labels": [], "entities": [{"text": "ASR", "start_pos": 215, "end_pos": 218, "type": "TASK", "confidence": 0.9449936747550964}]}, {"text": "In Section 5, we present our experiments along with their results, followed by a discussion in Section 6, and we conclude the paper with a summary and outlook in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We design experiments according to the above approaches.", "labels": [], "entities": []}, {"text": "The first experiment group is the baseline system using two features employed by erater, max.cos and cos.w4.", "labels": [], "entities": []}, {"text": "The second and third experiment groups implement the two ontologyfacilitated approaches, respectively.", "labels": [], "entities": []}, {"text": "We first run CVA and compare several different parameter setups to optimize them for further experiments.", "labels": [], "entities": []}, {"text": "For the CVA method, we need to decide (1) which term weighting scheme to use, and (2) whether or not to use a list of stopwords to exclude common non-content words such as determiners or prepositions from consideration.", "labels": [], "entities": []}, {"text": "We compare five commonly used term weighting schemes, each one with or without using a stoplist, based on averaged correlations with human scores across all four prompts.", "labels": [], "entities": []}, {"text": "The best results are obtained for the weighting scheme (TF/EDL)*IDF, where TF is the frequency of a term in a document, EDL is the Euclidean document length 3 , and IDF is the inverse document frequency of a term based on a collection of documents.", "labels": [], "entities": [{"text": "IDF", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.5244132876396179}, {"text": "TF", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9820205569267273}, {"text": "EDL", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.9317940473556519}, {"text": "IDF", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.9957346320152283}]}, {"text": "For this scheme, as for most others, there is almost no difference between using vs. not using a stoplist and we decide to use a stoplist for our experiments based on the tradition in the field.", "labels": [], "entities": []}, {"text": "The selected term weighting scheme is applied in the same way for both the score-level vectors as well as the test document vectors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Size of training and test data sets. The numbers  in parentheses are the number of documents on score  levels 1-4.", "labels": [], "entities": []}, {"text": " Table 2. Correlations between the max.cos feature and human scores (Hum=using human transcriptions; ASR=using  ASR hypotheses).", "labels": [], "entities": [{"text": "Hum", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.8981153964996338}, {"text": "ASR", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.920453667640686}]}, {"text": " Table 3. Correlations between the cos.w4 feature and human scores (Hum=using human transcriptions; ASR=using  ASR hypotheses)", "labels": [], "entities": [{"text": "Hum", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.8195791244506836}, {"text": "ASR", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.8843614459037781}]}]}