{"title": [{"text": "Recognizing Arguing Subjectivity and Argument Tags", "labels": [], "entities": [{"text": "Recognizing Arguing Subjectivity", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.855009396870931}]}], "abstractContent": [{"text": "In this paper we investigate two distinct tasks.", "labels": [], "entities": []}, {"text": "The first task involves detecting arguing subjectivity, a type of linguistic sub-jectivity on which relatively little work has yet to be done.", "labels": [], "entities": [{"text": "detecting arguing subjectivity", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.8564890821774801}]}, {"text": "The second task involves labeling instances of arguing subjectivity with argument tags reflecting the conceptual argument being made.", "labels": [], "entities": []}, {"text": "We refer to these two tasks collectively as \"recogniz-ing arguments\".", "labels": [], "entities": []}, {"text": "We develop anew annotation scheme and assemble anew annotated corpus to support our learning efforts.", "labels": [], "entities": []}, {"text": "Through our machine learning experiments , we investigate the utility of a sentiment lexicon, discourse parser, and semantic similarity measures with respect to recognizing arguments.", "labels": [], "entities": []}, {"text": "By incorporating information gained from these resources , we outperform a unigram baseline by a significant margin.", "labels": [], "entities": []}, {"text": "In addition, we explore a two-phase approach to recognizing arguments, with promising results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subjectivity analysis is a thriving field within natural language processing.", "labels": [], "entities": [{"text": "Subjectivity analysis", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9458407163619995}]}, {"text": "However, most research into subjectivity has focused on sentiment with respect to concrete things such as product debates (e.g.,, ) and movie reviews (e.g.,,), ().", "labels": [], "entities": []}, {"text": "Analysis often follows the opinion-target paradigm, in which expressions of sentiment are assessed with respect to the aspects of the object(s) under consideration towards which they are targeted.", "labels": [], "entities": []}, {"text": "For example, in the domain of smartphone reviews, aspects could include product features such as the keyboard, screen quality, and battery life.", "labels": [], "entities": []}, {"text": "Although sentiment analysis is interesting and important in its own right, this paradigm does not seem to be the best match for finegrained analysis of ideological domains.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.9512827396392822}]}, {"text": "While sentiment is also present in documents from this domain, previous work has found that arguing subjectivity, a less-studied form of subjectivity, is more frequently employed and more relevant fora robust assessment of ideological positions.", "labels": [], "entities": []}, {"text": "Whereas sentiment conveys the polarity of a writer's affect towards a topic, arguing subjectivity is a type of linguistic subjectivity in which a person expresses a controversial belief about what is true or what action ought to betaken regarding a central contentious issue.", "labels": [], "entities": [{"text": "sentiment conveys the polarity of a writer's affect towards a topic, arguing subjectivity is a type of linguistic subjectivity in which a person expresses a controversial belief about what is true or what action ought to betaken regarding a central contentious issue", "start_pos": 8, "end_pos": 274, "type": "Description", "confidence": 0.757806278087876}]}, {"text": "For example, consider this sentence about healthcare reform: (1) Almost everyone knows that we must start holding insurance companies accountable and give Americans a greater sense of stability and security when it comes to their healthcare.", "labels": [], "entities": []}, {"text": "Ina traditional opinion-target or sentimenttopic paradigm, perhaps this sentence could be labeled as containing a negative sentiment towards a topic representing \"insurance companies\", or a positive sentiment towards a topic representing \"stability\" or \"security\".", "labels": [], "entities": []}, {"text": "However, a reader of apolitical editorial or blog maybe more interested in why the author is negative to-wards insurers, and how the author proposes to improve stability of the healthcare system.", "labels": [], "entities": []}, {"text": "By focusing on the arguments conveyed through arguing subjectivity, we aim to capture these kind of conceptual reasons an author provides when arguing for his or her position.", "labels": [], "entities": []}, {"text": "However, identifying when someone is arguing is only part of the challenge.", "labels": [], "entities": [{"text": "identifying when someone is arguing", "start_pos": 9, "end_pos": 44, "type": "TASK", "confidence": 0.8250886559486389}]}, {"text": "Since arguing subjectivity is used to express arguments, the next natural step is to identify the argument being expressed through each instance of arguing subjectivity.", "labels": [], "entities": []}, {"text": "To illustrate this distinction, consider the following three example spans: (2) the bill is a job destroyer (3) President Obamas signature domestic policy will throw 100,000 people out of work come January (4) he can't expand his business because he can't afford the burden of Obamacare Each of these examples contains arguing subjectivity, but more importantly, each expresses roughly the same idea, namely, that the recently-passed healthcare reform bill will cause economic harm.", "labels": [], "entities": []}, {"text": "This latent, shared idea giving rise to each of the three spans is what we mean by \"argument tag\".", "labels": [], "entities": []}, {"text": "However, although all three are related, example spans (2) and (3) are more similar than (4) in terms of the notions they convey: while the first two explicitly are concerned with the loss of jobs, the last focuses on business expansion and the economy as a whole.", "labels": [], "entities": []}, {"text": "If we were to tag these three spans with respect to the argument that each is making, should they all receive the same tag, or should (4)'s tag be different?", "labels": [], "entities": []}, {"text": "To address these challenges, we propose in this work anew annotation scheme for identifying arguing subjectivity and a hierarchical model for organizing \"argument tags\".", "labels": [], "entities": []}, {"text": "In our hierarchical model, (4) would receive a different tag from (2) and (3), but because of the tags' relatedness all would share the same parent tag.", "labels": [], "entities": []}, {"text": "In addition to presenting this new scheme for labeling arguing subjectivity, we also explore sentiment, discourse, and distributional similarity as tools to enhance identification and classification of arguing subjectivity.", "labels": [], "entities": []}, {"text": "Finally, we also investigate splitting the arguing subjectivity detection task up into two distinct phases: identifying expressions of arguing subjectivity, and labelling each such expression with an appropriate argument tag.", "labels": [], "entities": [{"text": "arguing subjectivity detection task", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.7436213046312332}]}, {"text": "Since no corpora annotated for arguing subjectivity yet exist, we gather and annotate a corpus of blog posts and op-eds about a controversial topic, namely, the recently-passed \"ObamaCare\" healthcare reform bill.", "labels": [], "entities": [{"text": "ObamaCare\" healthcare reform", "start_pos": 178, "end_pos": 206, "type": "TASK", "confidence": 0.6675584465265274}]}], "datasetContent": [{"text": "For this study, we chose to focus on online editorials and blog posts concerning the ongoing debate over health insurance reform legislation in the United States.", "labels": [], "entities": [{"text": "health insurance reform legislation", "start_pos": 105, "end_pos": 140, "type": "TASK", "confidence": 0.7678248882293701}]}, {"text": "Our intuition is that blogs and editorials represent a genre rich in both \"pro\" documents 37 \"pro\" sentences 1,222 \"anti\" documents 47 \"anti\" sentences 1,456 total documents 84 total sentences 2,678: Arguing and argument label statistics for the \"pro\" stance.", "labels": [], "entities": [{"text": "Arguing", "start_pos": 200, "end_pos": 207, "type": "METRIC", "confidence": 0.939775288105011}]}, {"text": "We collected documents written both before and after the passage of the final \"Patient Protection and Affordable Care Act\" bill using the \"Google Blog Search\" 3 and \"Daily Op Ed\" 4 search portals.", "labels": [], "entities": []}, {"text": "By choosing a relatively broad time window, from early 2009 to late 2011, we aimed to capture a wide range of arguments expressed throughout the debate.", "labels": [], "entities": []}, {"text": "The focus of this paper is on sentence-level argument detection rather than document-level stance classification (e.g.,,), (Somasundaran and Wiebe, 2010), (Burfoot et al., 2011)).", "labels": [], "entities": [{"text": "sentence-level argument detection", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.648826390504837}, {"text": "document-level stance classification", "start_pos": 76, "end_pos": 112, "type": "TASK", "confidence": 0.5819444358348846}]}, {"text": "We treat stance classification as a separate step preceding arguing subjectivity detection, and thus provide oracle stance labels for our data.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.8801810443401337}, {"text": "subjectivity detection", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.772302657365799}]}, {"text": "We treat documents written from the \"pro\"  stance and documents written from the \"anti\" stance as separate datasets.", "labels": [], "entities": []}, {"text": "Being written from different positions, the two stances will have different argument labels and may employ different styles of arguing subjectivity.", "labels": [], "entities": []}, {"text": "provides an overview of the size of this dataset.", "labels": [], "entities": []}, {"text": "Summary statistics concerning the density of arguing and argument labels in the two sides of the dataset is presented in.", "labels": [], "entities": []}, {"text": "However, since it can be difficult to summarize a complex argument in a short phrase, many of these labels by themselves do not clearly convey the meaning they are meant to represent.", "labels": [], "entities": [{"text": "summarize a complex argument", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.8190044164657593}]}, {"text": "To better illustrate the meanings of some of the more ambiguous labels, presents several annotated example spans for some of the more unclear ambiguous argument labels.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset summary statistics.", "labels": [], "entities": []}, {"text": " Table 2: Arguing and argument label statistics for  the \"pro\" stance.", "labels": [], "entities": [{"text": "Arguing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9905419945716858}]}, {"text": " Table 3: Arguing and argument label statistics for  the \"anti\" stance.", "labels": [], "entities": [{"text": "Arguing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9879613518714905}]}, {"text": " Table 5: Inter-annotator span agr (top) and argu- ment label kappa on overlapping spans (bottom).", "labels": [], "entities": [{"text": "Inter-annotator span agr", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.8094547192255656}, {"text": "argu- ment label kappa", "start_pos": 45, "end_pos": 67, "type": "METRIC", "confidence": 0.9090172529220581}]}, {"text": " Table 7: Classifier accuracy for differing feature sets.  Significant improvement (p < 0.05) over baseline is  boldfaced (0.05 < p < 0.1 italicized). Underline in- dicates best performance per column.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9808892607688904}]}, {"text": " Table 8: Accuracies of two-stage classifiers across dif- ferent combinations of feature sets for the \"arg\" and  \"tag\" phases. Italics indicate improvement over the  top \"combined\" configuration which approaches sig- nificance (0.05 < p < 0.1). Underline indicates best  overall performance.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9833831191062927}, {"text": "Underline", "start_pos": 245, "end_pos": 254, "type": "METRIC", "confidence": 0.9658668637275696}]}]}