{"title": [{"text": "Unsupervised Content Discovery from Concise Summaries", "labels": [], "entities": [{"text": "Unsupervised Content Discovery from Concise Summaries", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.6169876058896383}]}], "abstractContent": [{"text": "Domain adaptation is a time consuming and costly procedure calling for the development of algorithms and tools to facilitate its automation.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8196313381195068}]}, {"text": "This paper presents an unsupervised algorithm able to learn the main concepts in event summaries.", "labels": [], "entities": [{"text": "event summaries", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.5900702327489853}]}, {"text": "The method takes as input a set of domain summaries annotated with shallow linguistic information and produces a domain template.", "labels": [], "entities": []}, {"text": "We demonstrate the viability of the method by applying it to three different domains and two languages.", "labels": [], "entities": []}, {"text": "We have evaluated the generated templates against human templates obtaining encouraging results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our research is concerned with the development of techniques for knowledge induction in the field of text summarization.", "labels": [], "entities": [{"text": "knowledge induction", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.750806599855423}, {"text": "text summarization", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7157620042562485}]}, {"text": "Our goal is to automatically induce the necessary knowledge for the generation of concise event summaries such as the one shown in.", "labels": [], "entities": []}, {"text": "This kind of summaries, which can be found on the Web and in text collections, contain key information of the events they describe.", "labels": [], "entities": []}, {"text": "Previous work in the area of text summarization) addressed the problem of generating this type of concise summaries from texts, relying on information extraction and text generation techniques.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6897990107536316}, {"text": "information extraction", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.7116550505161285}, {"text": "text generation", "start_pos": 166, "end_pos": 181, "type": "TASK", "confidence": 0.724099189043045}]}, {"text": "These approaches were difficult to port to new domains and languages because of the efforts needed for modelling the underlying event template structure.", "labels": [], "entities": []}, {"text": "In this paper we propose a method for learning the main concepts in domain summaries in an unsupervised iterative procedure.", "labels": [], "entities": []}, {"text": "The proposed algorithm takes a set of unannotated summaries in a given domain and produces auto-annotated summaries which can be used for training information extraction and text generation systems.", "labels": [], "entities": [{"text": "training information extraction", "start_pos": 138, "end_pos": 169, "type": "TASK", "confidence": 0.6704087058703104}, {"text": "text generation", "start_pos": 174, "end_pos": 189, "type": "TASK", "confidence": 0.8139893114566803}]}, {"text": "Domain adaptation is essential for text summarization and information extraction, and the last two decades have seen a plethora of methods for supervised, semisupervised, and unsupervised learning from texts.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7783384323120117}, {"text": "text summarization", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8198836743831635}, {"text": "information extraction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.8083581328392029}]}], "datasetContent": [{"text": "In order to evaluate the discovered concepts we have treated learning as information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7481474876403809}]}, {"text": "In order to evaluate them in this context we first need to map each learnt concept onto one of the human concepts.", "labels": [], "entities": []}, {"text": "The mapping, which is based on the concept extension, is straightforward: a discovered concept is mapped onto the human concept with which it has a majority of string matches.", "labels": [], "entities": []}, {"text": "Note that we match the discovered text offsets in the analysed documents and not only the identified strings.", "labels": [], "entities": []}, {"text": "In order to evaluate the matching procedure we have used precision, recall, and f-score measures comparing the automatic concept with the human concept.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9995582699775696}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9988259673118591}, {"text": "f-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.985636830329895}]}, {"text": "Note that we use a lenient procedure -counting as correct strings those with a partial match.", "labels": [], "entities": []}, {"text": "This is justified since discovering the exact boundaries of a concept instance is a very difficult task.", "labels": [], "entities": []}, {"text": "shows some examples of the human annotated instances and related discovered one.", "labels": [], "entities": []}, {"text": "It can be appreciated that the learnt concepts have a reasonable match degree with the human annotated ones.", "labels": [], "entities": []}, {"text": "gives information extraction results per domain and language for the best configuration of the algorithm.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 6, "end_pos": 28, "type": "TASK", "confidence": 0.7561597526073456}]}, {"text": "The best scores are generally obtained when coverage is set to 10% of the number of summaries, except for the learning of conceptual information in Spanish for the earthquake domain where the system performs better for 10% summary coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9935799837112427}]}, {"text": "The parameter controlling string repetition in the concept extension should be kept small.", "labels": [], "entities": []}, {"text": "The obtained results are quite satisfactory consider-   ing the small dataset and the limited use of linguistic resources during learning.", "labels": [], "entities": []}, {"text": "These results compare favorably to cross-validation results obtained using supervised machine learning techniques (Saggion and Szasz, 2011).", "labels": [], "entities": []}, {"text": "Learning from the earthquake domain appears to be more challenging given the more verbose characteristics of these texts.", "labels": [], "entities": []}, {"text": "Even though space restricions prevent us from showing all evaluation results, in we present detailed results for the two domains and languages.", "labels": [], "entities": []}, {"text": "Note that the concepts listed constitute the slots of the induced domain template.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Concepts Discovered in the Aviation Domain.  They correspond (in order) to the type of aircraft, date  of the incident, place of the accident, number of victims,  flight number, and year of the accident.", "labels": [], "entities": []}, {"text": " Table 2: Examples of Concept Extensions Partially  Matched", "labels": [], "entities": []}, {"text": " Table 3: Performance in terms of Precision, Recall, and  F-Score per Domain and Language. % rep and % cov are  the repetition and coverage parameters used.", "labels": [], "entities": [{"text": "Precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9971701502799988}, {"text": "Recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9785125255584717}, {"text": "F-Score", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9984945058822632}, {"text": "repetition", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.9963734745979309}]}, {"text": " Table 4: Learning Evaluation in the Train and Aviation  Accident and Earthquake Domains (Spanish and English  Dataset)", "labels": [], "entities": [{"text": "Spanish and English  Dataset", "start_pos": 90, "end_pos": 118, "type": "DATASET", "confidence": 0.659068800508976}]}]}