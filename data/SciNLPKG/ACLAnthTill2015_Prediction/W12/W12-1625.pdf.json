{"title": [{"text": "Probabilistic Dialogue Models with Prior Domain Knowledge", "labels": [], "entities": []}], "abstractContent": [{"text": "Probabilistic models such as Bayesian Networks are now in widespread use in spoken dialogue systems, but their scalability to complex interaction domains remains a challenge.", "labels": [], "entities": []}, {"text": "One central limitation is that the state space of such models grows exponentially with the problem size, which makes parameter estimation increasingly difficult, especially for domains where only limited training data is available.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.7170698940753937}]}, {"text": "In this paper, we show how to capture the underlying structure of a dialogue domain in terms of probabilistic rules operating on the dialogue state.", "labels": [], "entities": []}, {"text": "The probabilistic rules are associated with a small, compact set of parameters that can be directly estimated from data.", "labels": [], "entities": []}, {"text": "We argue that the introduction of this abstraction mechanism yields probabilistic models that are easier to learn and generalise better than their unstructured counterparts.", "labels": [], "entities": []}, {"text": "We empirically demonstrate the benefits of such an approach learning a dialogue policy fora human-robot interaction domain based on a Wizard-of-Oz data set.", "labels": [], "entities": [{"text": "Wizard-of-Oz data set", "start_pos": 134, "end_pos": 155, "type": "DATASET", "confidence": 0.810207188129425}]}], "introductionContent": [{"text": "Spoken dialogue systems increasingly rely on probabilistic models at various stages of their pipeline.", "labels": [], "entities": []}, {"text": "Statistical methods have notably been applied to tasks such as disfluency detection (), semantic parsing (), dialogue act recognition (Stolcke et al.,, dialogue management (, natural language generation;) and speech synthesis ().", "labels": [], "entities": [{"text": "disfluency detection", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.756746232509613}, {"text": "semantic parsing", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7294047027826309}, {"text": "dialogue act recognition", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.7646824916203817}, {"text": "dialogue management", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.8291015923023224}, {"text": "natural language generation", "start_pos": 175, "end_pos": 202, "type": "TASK", "confidence": 0.7008880972862244}, {"text": "speech synthesis", "start_pos": 209, "end_pos": 225, "type": "TASK", "confidence": 0.7784095406532288}]}, {"text": "There are two compelling reasons for this growing interest in statistical approaches: first, spoken dialogue is pervaded with noise and uncertainty (due to e.g. speech recognition errors, linguistic and pragmatic ambiguities, and unknown user intentions), which must be dealt with at all processing stages.", "labels": [], "entities": []}, {"text": "Second, a decisive advantage of probabilistic models lies in their ability to be automatically optimised from data, enabling statistically-based dialogue systems to exhibit conversational behaviours that are often more robust, flexible and adaptive than hand-crafted systems (.", "labels": [], "entities": []}, {"text": "Despite their success, the use of probabilistic models also presents a number of challenges.", "labels": [], "entities": []}, {"text": "The most pressing issue is the paucity of appropriate data sets.", "labels": [], "entities": []}, {"text": "Stochastic models often require large amounts of training data to estimate their parameters -either directly) or indirectly byway of a user simulator (.", "labels": [], "entities": []}, {"text": "Unfortunately, real interaction data is scarce, expensive to acquire, and difficult to transfer from one domain to another.", "labels": [], "entities": []}, {"text": "Moreover, many dialogue domains are inherently open-ended, which means they are not limited to the completion of a single task with predefined features but have to represent a varying number of tasks, complex user models and a rich, dynamic environment.", "labels": [], "entities": []}, {"text": "Examples of such domains include human-robot interaction (, cognitive assistants and companions, and tutoring systems (.", "labels": [], "entities": []}, {"text": "In such settings, the dialogue system might need to track a large number of variables in the course of the interaction, which quickly leads to a combinatorial explosion of the state space.", "labels": [], "entities": []}, {"text": "There is an extensive body of work in the machine learning and planning literature that shows how to address this issue by relying on more expressive representations, able to capture relevant aspects of the problem structure in a compact manner.", "labels": [], "entities": []}, {"text": "By taking advantage of hierarchical or relational abstractions, system developers can leverage their domain knowledge to yield probabilistic models that are easier to learn (due to a reduced number of parameters) and more efficient to use (since the structure can be exploited by the inference algorithm).", "labels": [], "entities": []}, {"text": "The contributions of this paper are twofold.", "labels": [], "entities": []}, {"text": "We first present anew framework for encoding prior knowledge in probabilistic dialogue models, based on the concept of probabilistic rules.", "labels": [], "entities": []}, {"text": "The framework is very general and can accommodate a wide spectrum of domains and learning tasks, from fully statistical models with virtually no prior knowledge to manually designed models with only a handful of parameters.", "labels": [], "entities": []}, {"text": "Second, we demonstrate how this framework can be exploited to learn stochastic dialogue policies with limited data sets using a Bayesian learning approach.", "labels": [], "entities": []}, {"text": "The following pages spell out the approach in more detail.", "labels": [], "entities": []}, {"text": "In Section 2, we provide the general background on probabilistic models and their use in spoken dialogue systems.", "labels": [], "entities": []}, {"text": "We describe in Section 3 how to encode such models via probabilistic rules and estimate their parameters from data.", "labels": [], "entities": []}, {"text": "In Section 4, we detail the empirical evaluation of our approach in a human-robot interaction domain, given small amounts of data collected in Wizard-of-Oz experiments.", "labels": [], "entities": []}, {"text": "Finally, we discuss and compare our approach to related work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our approach in the context of a dialogue policy learning task fora human-robot interaction scenario.", "labels": [], "entities": []}, {"text": "The main question we decided to address is the following: how much does the rule structure contribute to the parameter estimation of a given probabilistic model, especially for domains with limited amounts of available data?", "labels": [], "entities": []}, {"text": "The objective of the experiment was to learn the rule parameters corresponding to the policy model Q(a m |s) from a Wizard-of-Oz data collection.", "labels": [], "entities": [{"text": "Wizard-of-Oz data collection", "start_pos": 116, "end_pos": 144, "type": "DATASET", "confidence": 0.7961169282595316}]}, {"text": "In this particular case, the parameters correspond to the utilities of the various actions.", "labels": [], "entities": []}, {"text": "The policy model used in the experiment included a total of 14 rules.", "labels": [], "entities": []}, {"text": "We compared our approach with two baselines which are essentially \"flattened\" or rolled-out versions of the rule-based model.", "labels": [], "entities": []}, {"text": "The input and output variables remain identical, but they are directly connected, without the \u03c6 and \u03c8 nodes serving as intermediate structures.", "labels": [], "entities": []}, {"text": "The two baselines are (1) a plain multinomial model and (2) a linear model of the input variables.", "labels": [], "entities": []}, {"text": "We are thus comparing three versions of the Q(a m |s) model: two baselines where am is directly dependent on the state variables, and our approach where the dependency is realised indirectly through condition and effect nodes.", "labels": [], "entities": []}, {"text": "The scenario for the Wizard-of-Oz experiment involved a human user and a Nao robot 1 (see).", "labels": [], "entities": []}, {"text": "The user was instructed to teach the robot a sequence of basic movements (lift the left arm, step forward, kneel down, etc.) using spoken commands.", "labels": [], "entities": []}, {"text": "The interaction included various dialogue acts such A programmable humanoid robot developed by Aldebaran Robotics, http://www.aldebaran-robotics.com.", "labels": [], "entities": []}, {"text": "as clarification requests, feedbacks, acknowledgements, corrections, etc.", "labels": [], "entities": []}, {"text": "Short examples of recorded dialogues are provided in the appendix.", "labels": [], "entities": []}, {"text": "In addition to the policy model, the dialogue system include a speech recognizer (Vocon 3200 from Nuance) connected to the robot microphones, shallow components for dialogue act recognition and generation, a text-to-speech module, and components for planning the robot movements and controlling its motors in real-time.", "labels": [], "entities": [{"text": "dialogue act recognition and generation", "start_pos": 165, "end_pos": 204, "type": "TASK", "confidence": 0.7165418922901153}]}, {"text": "All components are connected to the shared belief state, and read/write to it as they process their data flow.", "labels": [], "entities": []}, {"text": "We collected a total of 20 interactions with 7 users and one wizard playing the role of the policy model, fora total of 1020 system turns, summing to around 1h of interaction.", "labels": [], "entities": []}, {"text": "All the interactions were performed in English.", "labels": [], "entities": []}, {"text": "The wizard only had access to the N-best list output from the speech recogniser, and could then select which action to perform from a list of 14 alternatives (such as AskRepeat, DemonstrateMove, UndoMove, AskForConfirmation, etc).", "labels": [], "entities": []}, {"text": "Each selected action was recorded along with the belief state (including the full probability distribution for every state variable) in effect at the time of the selection.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy results for the three action selection  models on a test set, using the full training set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9959163069725037}]}]}