{"title": [{"text": "Automatically Annotating A Five-Billion-Word Corpus of Japanese Blogs for Affect and Sentiment Analysis", "labels": [], "entities": [{"text": "Affect and Sentiment Analysis", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.638356402516365}]}], "abstractContent": [{"text": "This paper presents our research on automatic annotation of a five-billion-word corpus of Japanese blogs with information on affect and sentiment.", "labels": [], "entities": []}, {"text": "We first perform a study in emotion blog corpora to discover that there has been no large scale emotion corpus available for the Japanese language.", "labels": [], "entities": []}, {"text": "We choose the largest blog corpus for the language and annotate it with the use of two systems for affect analysis: ML-Ask for word-and sentence-level affect analysis and CAO for detailed analysis of emoticons.", "labels": [], "entities": [{"text": "word-and sentence-level affect analysis", "start_pos": 127, "end_pos": 166, "type": "TASK", "confidence": 0.5367128178477287}, {"text": "CAO", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.8847169280052185}]}, {"text": "The annotated information includes affective features like sentence subjectivity (emotive/non-emotive) or emotion classes (joy, sadness, etc.), useful in affect analysis.", "labels": [], "entities": [{"text": "affect analysis", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.7586635649204254}]}, {"text": "The annotations are also generalized on a 2-dimensional model of affect to obtain information on sentence valence/polarity (positive/negative) useful in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.9655510485172272}]}, {"text": "The annotations are evaluated in several ways.", "labels": [], "entities": []}, {"text": "Firstly, on a test set of a thousand sentences extracted randomly and evaluated by over forty respondents.", "labels": [], "entities": []}, {"text": "Secondly, the statistics of annotations are compared to other existing emotion blog corpora.", "labels": [], "entities": []}, {"text": "Finally, the corpus is applied in several tasks, such as generation of emotion object ontology or retrieval of emotional and moral consequences of actions.", "labels": [], "entities": [{"text": "generation of emotion object ontology", "start_pos": 57, "end_pos": 94, "type": "TASK", "confidence": 0.815140426158905}, {"text": "retrieval of emotional and moral consequences of actions", "start_pos": 98, "end_pos": 154, "type": "TASK", "confidence": 0.7996049150824547}]}], "introductionContent": [{"text": "There is alack of large corpora for Japanese applicable in sentiment and affect analysis.", "labels": [], "entities": [{"text": "sentiment and affect analysis", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.8411900252103806}]}, {"text": "Although there are large corpora of newspaper articles, like Mainichi Shinbun Corpus 1 , or corpora of classic literature, like Aozora Bunko 2 , they are usually unsuitable for research on emotions since spontaneous emotive expressions either appear rarely in these kinds of texts (newspapers), or the vocabulary is not up to date (classic literature).", "labels": [], "entities": [{"text": "Mainichi Shinbun Corpus 1", "start_pos": 61, "end_pos": 86, "type": "DATASET", "confidence": 0.9553265422582626}]}, {"text": "Although there exist speech corpora, such as Corpus of Spontaneous Japanese , which could become suitable for this kind of research, due to the difficulties with compilation of such corpora they are relatively small.", "labels": [], "entities": []}, {"text": "In research such as the one by it was proved that public Internet services, such as forums or blogs, area good material for affect analysis because of their richness in evaluative and emotive information.", "labels": [], "entities": [{"text": "affect analysis", "start_pos": 124, "end_pos": 139, "type": "TASK", "confidence": 0.760343462228775}]}, {"text": "One kind of these services are blogs, open diaries in which people encapsulate their own experiences, opinions and feelings to be read and commented by other people.", "labels": [], "entities": []}, {"text": "Recently blogs have come into the focus of opinion mining or sentiment and affect analysis.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8003248274326324}, {"text": "sentiment and affect analysis", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.729136735200882}]}, {"text": "Therefore creating a large blog-based emotion corpus could help overcome both problems: the lack in quantity of corpora and their applicability in sentiment and affect analysis.", "labels": [], "entities": [{"text": "sentiment and affect analysis", "start_pos": 147, "end_pos": 176, "type": "TASK", "confidence": 0.7181480973958969}]}, {"text": "There have been only a few small Japanese emotion corpora developed so far).", "labels": [], "entities": []}, {"text": "On the other hand, although there exist large Web-based corpora (), access to them is usually allowed only from the Web interface, which makes additional annotations with affective information difficult.", "labels": [], "entities": []}, {"text": "In this paper we present the first attempt to automatically annotate affect on YACIS, a large scale corpus of Japanese blogs.", "labels": [], "entities": [{"text": "YACIS, a large scale corpus of Japanese blogs", "start_pos": 79, "end_pos": 124, "type": "DATASET", "confidence": 0.8285846643977695}]}, {"text": "To do that we use two systems for affect analysis of Japanese, one for wordand sentence-level affect analysis and another especially for detailed analysis of emoticons, to annotate on the corpus different kinds of affective information (emotive expressions, emotion classes, etc.).", "labels": [], "entities": [{"text": "affect analysis of Japanese", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.8121552765369415}, {"text": "wordand sentence-level affect analysis", "start_pos": 71, "end_pos": 109, "type": "TASK", "confidence": 0.599253349006176}]}, {"text": "The outline of the paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the related research in emotion corpora.", "labels": [], "entities": []}, {"text": "Section 3 presents our choice of the corpus for annotation of affect-and sentiment-related information.", "labels": [], "entities": []}, {"text": "Section 4 describes tools used in annotation.", "labels": [], "entities": []}, {"text": "Section 5 presents detailed data and evaluation of the annotations.", "labels": [], "entities": []}, {"text": "Section 6 presents tasks in which the corpus has already been applied.", "labels": [], "entities": []}, {"text": "Finally the paper is concluded and future applications are discussed.", "labels": [], "entities": []}], "datasetContent": [{"text": "It is physically impossible to manually evaluate all annotations on the corpus 6 . Therefore we applied three different types of evaluation.", "labels": [], "entities": []}, {"text": "First was based on a sample of 1000 sentences randomly extracted from the corpus and annotated by laypeople.", "labels": [], "entities": []}, {"text": "In second we compared YACIS annotations to other emotion corpora.", "labels": [], "entities": []}, {"text": "The third evaluation was application based and is be described in section 6.", "labels": [], "entities": []}, {"text": "Evaluation of Affective Annotations: Firstly, we needed to confirm the performance of affect analysis systems on YACIS, since the performance is often related to the type of test set used in evaluation.", "labels": [], "entities": [{"text": "YACIS", "start_pos": 113, "end_pos": 118, "type": "DATASET", "confidence": 0.5964264869689941}]}, {"text": "ML-Ask was positively evaluated on separate sentences and on an online forum (  culated as a ratio of success to the overall number of samples, are summarized in.", "labels": [], "entities": [{"text": "ML-Ask", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7554974555969238}]}, {"text": "The performance of discrimination between emotive and nonemotive sentences of ML-Ask baseline was a high 98.8%, which is much higher than in original evaluation of ML-Ask (around 90%).", "labels": [], "entities": []}, {"text": "This could indicate that sentences with which the system was notable to deal with appear much less frequently on Ameblo.", "labels": [], "entities": [{"text": "Ameblo", "start_pos": 113, "end_pos": 119, "type": "DATASET", "confidence": 0.9664390683174133}]}, {"text": "As for CAO, it is capable of detecting the presence of emoticons in a sentence, which is partially equivalent to detecting emotive sentences in ML-Ask, since emoticons are one type of features determining sentence as emotive.", "labels": [], "entities": []}, {"text": "The performance of CAO was also high, 97.6%.", "labels": [], "entities": [{"text": "CAO", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9160320162773132}]}, {"text": "This was due to the fact that grand majority of emotive sentences contained emoticons.", "labels": [], "entities": []}, {"text": "Finally, ML-Ask supported with CAO achieved remarkable 100% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9960293769836426}]}, {"text": "This was a surprisingly good result, although it must be remembered that the test sample contained only 1000 sentences (less than 0.0003% of the whole corpus).", "labels": [], "entities": []}, {"text": "Next we verified emotion class annotations on sentences.", "labels": [], "entities": []}, {"text": "The baseline of ML-Ask achieved slightly better results (73.4%) than in its primary evaluation () (67% of balanced Fscore with P=85.7% and R=54.7%).", "labels": [], "entities": [{"text": "ML-Ask", "start_pos": 16, "end_pos": 22, "type": "DATASET", "confidence": 0.4802251160144806}, {"text": "balanced", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9390000700950623}, {"text": "Fscore", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.8555068373680115}, {"text": "P", "start_pos": 127, "end_pos": 128, "type": "METRIC", "confidence": 0.9362021088600159}, {"text": "R", "start_pos": 139, "end_pos": 140, "type": "METRIC", "confidence": 0.9845545887947083}]}, {"text": "Interestingly, this makes CAO a better affect analysis system than ML-Ask.", "labels": [], "entities": [{"text": "affect analysis", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7159893363714218}]}, {"text": "However, the condition is that a sentence must contain an emoticon.", "labels": [], "entities": []}, {"text": "The best result, close to 90%, was achieved by ML-Ask supported with CAO.", "labels": [], "entities": [{"text": "ML-Ask", "start_pos": 47, "end_pos": 53, "type": "DATASET", "confidence": 0.7996631264686584}, {"text": "CAO", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.9233630895614624}]}, {"text": "We also checked the results when only the dimensions of valence and activation were taken into account.", "labels": [], "entities": []}, {"text": "ML-Ask achieved 88.6%, CAO nearly 95%.", "labels": [], "entities": [{"text": "ML-Ask", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9383628368377686}, {"text": "CAO", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9966692328453064}]}, {"text": "Support of CAO to ML-Ask again resulted in the best score, 97.5%.", "labels": [], "entities": [{"text": "CAO", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.7593031525611877}, {"text": "ML-Ask", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.7988061308860779}]}, {"text": "Statistics of Affective Annotations: There were nearly twice as many emotive sentences than nonemotive (ratio 1.94).", "labels": [], "entities": []}, {"text": "This suggests that the corpus is biased in favor of emotive contents, which could be considered as a proof for the assumption that blogs make a good base for emotion related re- search.", "labels": [], "entities": [{"text": "emotion related re- search", "start_pos": 158, "end_pos": 184, "type": "TASK", "confidence": 0.6898493111133576}]}, {"text": "When it comes to statistics of each emotive feature (emoteme), the most frequent class were interjections.", "labels": [], "entities": []}, {"text": "Second frequent was the exclamative marks class, which includes punctuation marks suggesting emotive engagement (such as \"!\", or \"??\").", "labels": [], "entities": []}, {"text": "Third frequent emoteme class was emoticons, followed by endearments.", "labels": [], "entities": []}, {"text": "As an interesting remark, emoteme class that was the least frequent were vulgarities.", "labels": [], "entities": []}, {"text": "As one possible interpretation of this result we propose the following.", "labels": [], "entities": []}, {"text": "Blogs are social space, where people describe their experiences to be read and commented by other people (friends, colleagues).", "labels": [], "entities": []}, {"text": "The use of vulgar language could discourage potential readers from further reading, making the blog less popular.", "labels": [], "entities": []}, {"text": "Next, we checked the statistics of emotion classes annotated on emotive sentences.", "labels": [], "entities": []}, {"text": "The results are represented in.", "labels": [], "entities": []}, {"text": "The most frequent emotions were joy (31%), dislike (20%) and fondness (19%), which covered over 70% of all annotations.", "labels": [], "entities": []}, {"text": "However, it could happen that the number of expressions included in each emotion class database influenced the number of annotations (database containing many expressions has higher probability to gather more annotations).", "labels": [], "entities": []}, {"text": "Therefore we verified if there was a correlation between the number of annotations and the number of emotive expressions in each emotion class database.", "labels": [], "entities": []}, {"text": "The verification was based on Spearman's rank correlation test between the two sets of numbers.", "labels": [], "entities": [{"text": "rank correlation test", "start_pos": 41, "end_pos": 62, "type": "METRIC", "confidence": 0.7975207964579264}]}, {"text": "The test revealed no statistically significant correlation between the two types of data, with \u03c1=0.38.", "labels": [], "entities": [{"text": "\u03c1", "start_pos": 95, "end_pos": 96, "type": "METRIC", "confidence": 0.9822741150856018}]}, {"text": "In evaluation of sentiment and affect analysis systems it is very important to provide a statistically reliable random sample of sentences or documents as a test set (to be further annotated by laypeople).", "labels": [], "entities": [{"text": "evaluation of sentiment and affect analysis", "start_pos": 3, "end_pos": 46, "type": "TASK", "confidence": 0.7693729201952616}]}, {"text": "The larger is the source, the more statistically reliable is the test set.", "labels": [], "entities": []}, {"text": "Since YACIS contains 354 mil.", "labels": [], "entities": [{"text": "YACIS", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.7642847895622253}]}, {"text": "documents, it can be considered sufficiently reliable for the task of test set extraction, as probability of extracting twice the same sentence is close to zero.", "labels": [], "entities": [{"text": "test set extraction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.7031117677688599}]}, {"text": "already used YACIS to randomly extract a 1000 sentence sample and used it in their evaluation of emoticon analysis system.", "labels": [], "entities": [{"text": "YACIS", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.6085211634635925}, {"text": "emoticon analysis", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7459481060504913}]}, {"text": "The sample was also used in this research and is described in more detail in section 5.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of emotion corpora ordered by the amount of annotations (abbreviations: T=tokenization,  POS=part-of-speech tagging, L=lemmatization, DP=dependency parsing, NER=Named Entity Recognition).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.686275452375412}]}, {"text": " Table 2: General Statistics of YACIS.", "labels": [], "entities": [{"text": "General Statistics of YACIS", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.8115849867463112}]}, {"text": " Table 3: Distribution of separate expressions across emo- tion classes in Nakamura's dictionary (overall 2100 ex.).", "labels": [], "entities": [{"text": "Nakamura's dictionary", "start_pos": 75, "end_pos": 96, "type": "DATASET", "confidence": 0.8624452153841654}]}, {"text": " Table 4: Evaluation results of ML-Ask and CAO.", "labels": [], "entities": [{"text": "ML-Ask", "start_pos": 32, "end_pos": 38, "type": "DATASET", "confidence": 0.5242230892181396}, {"text": "CAO", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.7760517597198486}]}, {"text": " Table 6: Emotion class annotations with percentage.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of positive and negative sentences  between KNB and YACIS.", "labels": [], "entities": [{"text": "YACIS", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.3683100938796997}]}, {"text": " Table 8: Comparison of number of emotive expressions  in three different corpora including ratio within this set of  emotions and results of Spearman's rank correlation test.", "labels": [], "entities": []}]}