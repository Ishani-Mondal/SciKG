{"title": [{"text": "Using Nominal Compounds for Word Sense Discrimination", "labels": [], "entities": [{"text": "Word Sense Discrimination", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.6802456875642141}]}], "abstractContent": [{"text": "In many morphologically rich languages, conceptually independent morphemes are glued together to form anew word (a compound) with a meaning that is often at least in part predictable from the meanings of the contributing morphemes.", "labels": [], "entities": []}, {"text": "Assuming that most compounds express a subconcept of exactly one sense of its nominal head, we use compounds as a higher-quality alternative to simply using general second-order collocate terms in the task of word sense discrimination.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 209, "end_pos": 234, "type": "TASK", "confidence": 0.7338119745254517}]}, {"text": "We evaluate our approach using lexical entries from the German wordnet GermaNet (Henrich and Hinrichs, 2010).", "labels": [], "entities": [{"text": "German wordnet GermaNet", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.6721953948338827}]}], "introductionContent": [{"text": "In several morphologically rich languages such as German and Dutch, compounds are usually written as one word: Ina process where nouns, verbs and other prefixes combine with ahead noun (called the simplex when it occurs on its own), a novel word can be formed which is typically interpretable by considering its parts and the means of combination.", "labels": [], "entities": []}, {"text": "The process of compounding is both highly productive and subject to lexicalization (i.e., the creation of non-transparent compounds that can only be interpreted as a whole rather than as a combination of parts).", "labels": [], "entities": []}, {"text": "The analysis of compounds have been subject to interest in machine translation as well as in the semantic processing of morphologically rich languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7746464610099792}]}, {"text": "The analysis of compounds is generally challenging for many reasons.", "labels": [], "entities": []}, {"text": "In particular, compounds leave us with the dilemma of either modeling them as complete units, yielding a more accurate picture for lexicalized compounds but creating a more severe sparse data problem in general, or trying to separate out their parts and ending up with problems of wrongly split lexicalized compounds, or of incurring mis-splits where spurious ambiguities occur.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to address the question of whether semantic information of compound occurrences can be used to learn more about the sense distribution of the simplex head, with respect to a text collection.", "labels": [], "entities": []}, {"text": "Specifically, this paper focuses on the task of word sense discrimination, where the goal is to find different senses of a word without assuming a hand-crafted lexical resource as training material (in contrast to word sense disambiguation, where the exact sense inventory to be tagged is known at training and inference time, and where making effective use of a resource such as WordNet is an important part of the problem to be solved).", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.7716823220252991}, {"text": "word sense disambiguation", "start_pos": 214, "end_pos": 239, "type": "TASK", "confidence": 0.6603235006332397}, {"text": "WordNet", "start_pos": 380, "end_pos": 387, "type": "DATASET", "confidence": 0.9344900846481323}]}, {"text": "While the present paper focuses on nominal compounds in German, the method as such can also be applied to other languages where compounds are written as one word.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our evaluation framework is based on retrieving a set of words related to the target item (the candidate set), and then using collocate vectors extracted from a corpus to cluster the candidate set into multiple subsets.", "labels": [], "entities": []}, {"text": "Once we have a clustering of the generated terms, we want a quantitative evaluation of the clustering.", "labels": [], "entities": []}, {"text": "The underlying idea for this is that we would like to have, for each sense of the target word, a cluster that has one or several words describing it.", "labels": [], "entities": []}, {"text": "(We should not assume that it is always possible to find many related words fora particular sense).", "labels": [], "entities": []}, {"text": "As target items, we used a list of simplexes that are most productive in terms of compounding, using a set of gold-standard compound splits that were created by Henrich and Hinrichs (2011); candidate words (both compounds and general neighbours) were selected using a frequency list extracted from the T\u00fcPP-D/Z corpus).", "labels": [], "entities": [{"text": "T\u00fcPP-D/Z corpus", "start_pos": 302, "end_pos": 317, "type": "DATASET", "confidence": 0.845868781208992}]}, {"text": "For the experiments themselves, no information about correct splits of the compounds was assumed and potential compounds were simply retrieved as lemma forms that have the target word as a suffix.", "labels": [], "entities": []}, {"text": "The subsets from clustering the candidate set are then evaluated according to whether the mostcentral related words in that cluster are related to the same sense of the target word, and how many senses of the target word are covered by the clusters.", "labels": [], "entities": []}, {"text": "Given the committee lists that are output by the candidate selection and output, we calculate an evaluation score by creating a mapping between senses of the target word and the committees that are the output of the clustering algorithm, choosing that mapping according to a quality measure that describes how well the committee members match that synset (the precision of that possible pairing between a committee and a sense of the target word), as shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 360, "end_pos": 369, "type": "METRIC", "confidence": 0.9937545657157898}]}, {"text": "(Ideally, the committee would contain words only related to one sense).", "labels": [], "entities": []}, {"text": "Using the Kuhn-Munkres algorithm, we compute a mapping between each represented synset sand a cluster C s such that P s P (C s , s) is maximized.", "labels": [], "entities": []}, {"text": "The final score for one target word is this sum divided by the total number of synsets for the target word -this means that a method that yields a less representative set of candidate words will normally not get a better score, unless the clusters are of higher enough quality, than one that has candidate terms for each cluster.", "labels": [], "entities": []}, {"text": "In addition to the score metric, we calculated a quality metric that divides the raw sum by the number of senses covered in the candidate set, and a coverage metric that corresponds to the fraction of senses covered by the candidate set in the first place (see).", "labels": [], "entities": []}, {"text": "contains quantitative results for the different methods and also evaluation statistics for some lower and upper baselines: Selecting exactly one related word as a candidate (and putting it in a cluster of its own) would yield a quality of 1.0, since that cluster is related to exactly one synset, but a very poor coverage of 0.325.", "labels": [], "entities": []}, {"text": "For the profile upper baseline, which takes related terms from GermaNet and uses imperfect information only in clustering, we see that our clustering approach is able to reconstruct committees of sense-identical terms out of the candidate list fairly well: given related terms for each sense, distributional similarity yields fairly good quality (0.801) and, unsurprisingly, nearperfect coverage for all senses (0.946).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation scores for the different methods and  baselines", "labels": [], "entities": []}]}