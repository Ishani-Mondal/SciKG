{"title": [{"text": "Zero Pronoun Resolution can Improve the Quality of J-E Translation", "labels": [], "entities": [{"text": "Zero Pronoun Resolution", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6009369194507599}]}], "abstractContent": [{"text": "In Japanese, particularly, spoken Japanese, subjective, objective and possessive cases are very often omitted.", "labels": [], "entities": []}, {"text": "Such Japanese sentences are often translated by Japanese-English statistical machine translation to the English sentence whose subjective, objective and possessive cases are omitted, and it causes to decrease the quality of translation.", "labels": [], "entities": []}, {"text": "We performed experiments of J-E phrase based translation using Japanese sentence, whose omitted pronouns are complemented by human.", "labels": [], "entities": [{"text": "J-E phrase based translation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.5791037604212761}]}, {"text": "We introduced 'antecedent F-measure' as a score for measuring quality of the translated En-glish.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.8616805076599121}]}, {"text": "As a result, we found that it improves the scores of antecedent F-measure while the BLEU scores were almost unchanged.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9600074887275696}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9994983673095703}]}, {"text": "Every effectiveness of the zero pronoun resolution differs depending on the type and case of each zero pronoun.", "labels": [], "entities": [{"text": "zero pronoun resolution", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.6861809293429056}]}], "introductionContent": [{"text": "Today, statistical translation systems have been able to translate between languages at high accuracy using a lot of corpora . However, the quality of translation of Japanese to English is not high comparing with the other language pairs that have the similar syntactic structure such as the French-English pair.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.6381493955850601}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9938061237335205}]}, {"text": "Particularly, the quality of translation from spoken Japanese to English is in low.", "labels": [], "entities": [{"text": "translation from spoken Japanese to English", "start_pos": 29, "end_pos": 72, "type": "TASK", "confidence": 0.8821747203667959}]}, {"text": "There are many reasons for the low quality.", "labels": [], "entities": []}, {"text": "One is the different syntactic structures, that is, Japanese sentence structure is SOV while English one is SVO.", "labels": [], "entities": []}, {"text": "This problem has been partly solved by head finalization techniques (.", "labels": [], "entities": [{"text": "head finalization", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.8600306212902069}]}, {"text": "Another big problem is that subject, object and possessive cases are often eliminated in Japanese, particularly, spoken Japanese.", "labels": [], "entities": []}, {"text": "In the case of Japanese to English translation, the source language has lesser information in surface than the target language, and the quality of the translation tends to below.", "labels": [], "entities": [{"text": "Japanese to English translation", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.6206927374005318}]}, {"text": "We show the example of the omissions in In this example, the Japanese subject watashi wa ('I') and the object anata ni ('to you') are eliminated in the sentence.", "labels": [], "entities": []}, {"text": "These omissions are not problems for human speakers and hearers because people easily recognize who is the questioner or responder (that is, 'I' and 'you') from the context.", "labels": [], "entities": []}, {"text": "However, generally speaking, the recognition is difficult for statistical translation systems.", "labels": [], "entities": [{"text": "recognition", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.9511809945106506}, {"text": "statistical translation", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.6469855904579163}]}, {"text": "Some European languages allow the elimination of subject.", "labels": [], "entities": []}, {"text": "We show an example in Spanish in In this case, the subject is eliminated, and it leaves traces including the case and the sex, on the related verb.", "labels": [], "entities": []}, {"text": "The Spanish word, tengo is the first person singular form of the verb, tener (it means 'have').", "labels": [], "entities": []}, {"text": "So it is easier to resolve elimination comparing with Japanese one for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9811469316482544}]}, {"text": "Otherwise, Japanese verbs usually have no inflectional form depending on the case and sex.", "labels": [], "entities": []}, {"text": "So, we need take another way for elimination resolution.", "labels": [], "entities": [{"text": "elimination resolution", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.9838806688785553}]}, {"text": "For example, if the eliminated Japanese subject is always 'I' when the sentence is declarative, and the subject is always 'you' when the sentence is a question sentence, phrase based translation systems are probably able to translate subjecteliminated Japanese sentences to correct English sentences.", "labels": [], "entities": []}, {"text": "However, the hypothesis is not always: Spanish Ellipsis true.", "labels": [], "entities": [{"text": "Spanish Ellipsis", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.8885767161846161}]}, {"text": "In this paper, we show that the quality of spoken Japanese to English translation can improve using a phrase-based translation system if we can use an ideal elimination resolution system.", "labels": [], "entities": [{"text": "Japanese to English translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.7386380434036255}, {"text": "phrase-based translation", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.7008808851242065}]}, {"text": "However, we also show that a simple elimination resolution system is not effective to the improvement and it is necessary to recognize correctly the modality of the sentence.", "labels": [], "entities": [{"text": "elimination resolution", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8151647746562958}]}], "datasetContent": [{"text": "Fig shows the outline of the procedure of our experiment.", "labels": [], "entities": []}, {"text": "We used Moses ( for the training of the translation and language models, tuning with MERT and the decoding.", "labels": [], "entities": [{"text": "MERT", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.832247257232666}]}, {"text": "First, we prepared the data for learning which consists of parallel English and Japanese sentences.", "labels": [], "entities": []}, {"text": "We used MeCab 1 as Japanese tokenizer and the tokenizer in Moses Tool kit as English tokenizer.", "labels": [], "entities": [{"text": "MeCab 1", "start_pos": 8, "end_pos": 15, "type": "DATASET", "confidence": 0.9100303649902344}, {"text": "Moses Tool kit", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.9608157873153687}]}, {"text": "We used default settings for the parameters of Moses.", "labels": [], "entities": []}, {"text": "Next, Moses learns language model and translation model from the Japanese and English sentence pairs.", "labels": [], "entities": [{"text": "translation", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.9616718888282776}]}, {"text": "Then, the learned model was tuned by completed sentences with MERT. and Moses decoded the completed Japanese sentences to English sentences.", "labels": [], "entities": [{"text": "MERT.", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.9958615899085999}]}, {"text": "We used BLEU () and antecedent Precision, Recall and F-measure for the 1 http://mecab.sourceforge.net/ evaluation of the performances, comparing the system outputs with the English references of test data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9991469383239746}, {"text": "Precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9806573987007141}, {"text": "Recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.98475581407547}, {"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9967735409736633}]}, {"text": "Using only BLEU score is not adequate for evaluation of pronoun translation).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.999086856842041}, {"text": "pronoun translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7138488590717316}]}, {"text": "We were inspired empty node recovery evaluation by) and defined antecedent Precision (P), Recall (R) and F-measure (F) as follows, Here, S is the set of each pronoun in English translated by decoder, G is the set of the gold standard zero pronoun.", "labels": [], "entities": [{"text": "empty node recovery evaluation", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7556467205286026}, {"text": "Precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.8066384792327881}, {"text": "Recall (R)", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9339576810598373}, {"text": "F-measure (F)", "start_pos": 105, "end_pos": 118, "type": "METRIC", "confidence": 0.9445016533136368}]}, {"text": "We evaluated the effect of performance of every case among completed sentences by human, ones by the baseline system, and the original sentences.", "labels": [], "entities": []}, {"text": "We show the BLEU scores in. and the antecedent precision, recall and F-measure in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9997218251228333}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9890088438987732}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9994779229164124}, {"text": "F-measure", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9985548853874207}]}, {"text": "The BLEU scores for experiments using our baseline system and human annotation, are slightly better than for one without ellipsis resolution, 45.4% and 45.6%, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9991948008537292}]}, {"text": "However, the scores of antecedent F-measure have major difference between 'original' and 'human'.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.8634442687034607}]}, {"text": "Particularly, the recall is improved.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9997528195381165}]}, {"text": "Each 1st, 2nd and 3rd person score is better than original one.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The Type Distributions of Zero Pronouns in Test Set", "labels": [], "entities": []}, {"text": " Table 4: Antecedent precision, recall and F-measure for every pronoun", "labels": [], "entities": [{"text": "Antecedent", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9971688389778137}, {"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9337203502655029}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9997736811637878}, {"text": "F-measure", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9985812902450562}]}]}