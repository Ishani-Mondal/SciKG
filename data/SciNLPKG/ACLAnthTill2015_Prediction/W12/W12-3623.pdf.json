{"title": [{"text": "A Dependency Treebank of Urdu and its Evaluation", "labels": [], "entities": [{"text": "Dependency Treebank of Urdu", "start_pos": 2, "end_pos": 29, "type": "DATASET", "confidence": 0.8092811107635498}]}], "abstractContent": [{"text": "In this paper we describe a currently underway treebanking effort for Urdu-a South Asian language.", "labels": [], "entities": []}, {"text": "The treebank is built from a newspaper corpus and uses a Karaka based grammatical framework inspired by Paninian grammatical theory.", "labels": [], "entities": [{"text": "Paninian grammatical theory", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.6374807357788086}]}, {"text": "Thus far 3366 sentences (0.1M words) have been annotated with the linguistic information at morpho-syntactic (morphological, part-of-speech and chunk information) and syntactico-semantic (depen-dency) levels.", "labels": [], "entities": []}, {"text": "This work also aims to evaluate the correctness or reliability of this manual annotated dependency treebank.", "labels": [], "entities": [{"text": "correctness", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.9703518152236938}, {"text": "reliability", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.8783770799636841}]}, {"text": "Evaluation is done by measuring the inter-annotator agreement on a manually annotated data set of 196 sentences (5600 words) annotated by two annotators.", "labels": [], "entities": []}, {"text": "We present the qualitative analysis of the agreement statistics and identify the possible reasons for the disagreement between the annotators.", "labels": [], "entities": []}, {"text": "We also show the syntactic annotation of some constructions specific to Urdu like Ezaf e and discuss the problem of word segmentation (tokenization).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.719209760427475}]}], "introductionContent": [{"text": "Hindi and Urdu 1 are often socially considered distinct language varieties, but linguistically the division between the two varieties is not well-founded.", "labels": [], "entities": []}, {"text": "explains that while they are different languages officially, they are not even different dialects or sub-dialects in a linguistic sense; rather, they are different literary styles based on the same linguistically defined sub-dialect.", "labels": [], "entities": []}, {"text": "He further explains that at colloquial level, Hindi and Urdu are nearly identical, both in terms of core vocabulary and grammar.", "labels": [], "entities": []}, {"text": "However, at formal and literary levels, vocabulary differences begin to loom much larger (Hindi drawing its higher lexicon from Sanskrit and Urdu from Persian and Arabic) to the point where the two styles/languages become mutually unintelligible.", "labels": [], "entities": []}, {"text": "In written form not only lexical items but the way Urdu and Hindi is written makes one believe that they are two separate languages.", "labels": [], "entities": []}, {"text": "They are written in separate orthographies, Hindi being written in Devanagari, and Urdu in a modified Perso-Arabic script.", "labels": [], "entities": []}, {"text": "Under the treebanking effort for Indian languages, two separate treebanks are being built for both Hindi and Urdu.", "labels": [], "entities": []}, {"text": "Among the two, however, Hindi treebank has matured and grown considerably , . The paper is arranged as follows, next Section gives a brief overview of the related works on syntactic treebanking.", "labels": [], "entities": [{"text": "Hindi treebank", "start_pos": 24, "end_pos": 38, "type": "DATASET", "confidence": 0.8839231133460999}]}, {"text": "Section 3 describes the grammatical formalism chosen for the annotation.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss treebanking pipeline of Urdu followed by some of the Urdu specific issues in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6 we discuss the empirical results of interannotator agreement.", "labels": [], "entities": []}, {"text": "Section 7, concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Agreement among the Annotators on Karaka  roles given a Case Marker.", "labels": [], "entities": []}, {"text": " Table 4: Confusion Matrix between the Annotators.", "labels": [], "entities": []}, {"text": " Table 5: Agreement and Disagreement between the An- notators.", "labels": [], "entities": [{"text": "Agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8657864332199097}]}]}