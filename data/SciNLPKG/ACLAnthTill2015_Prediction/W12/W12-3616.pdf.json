{"title": [{"text": "Exploring Temporal Vagueness with Mechanical Turk", "labels": [], "entities": [{"text": "Exploring Temporal Vagueness", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.794046938419342}]}], "abstractContent": [{"text": "This paper proposes schematic changes to the TempEval framework that target the temporal vagueness problem.", "labels": [], "entities": []}, {"text": "Specifically, two elements of vagueness are singled out for special treatment: vague time expressions, and explicit/implicit temporal modification of events.", "labels": [], "entities": []}, {"text": "As proof of concept, an annotation experiment on explicit/implicit modification is conducted on Amazon's Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 96, "end_pos": 120, "type": "DATASET", "confidence": 0.9558349698781967}]}, {"text": "Results show that the quality of a considerable segment of the annotation is comparable to annotation obtained in the traditional double-blind setting, only with higher coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.978140115737915}]}, {"text": "This approach offers additional flexibility in how the temporal annotation data can be used.", "labels": [], "entities": []}], "introductionContent": [{"text": "Event-based temporal inference aims at determining temporal anchoring and relative ordering of events in text.", "labels": [], "entities": [{"text": "Event-based temporal inference", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5837469398975372}, {"text": "temporal anchoring", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7067192494869232}]}, {"text": "It is a fundamental natural language technology that supports a wide range of natural language applications, such as Information Extraction, Question Answering (;) and Text Summarization ().", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.8312516808509827}, {"text": "Question Answering", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.8402235507965088}, {"text": "Text Summarization", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.7994098365306854}]}, {"text": "Crucial to developing this technology is consistently annotated, domain-independent data sufficient to train automatic systems, but this has proven to be challenging.", "labels": [], "entities": []}, {"text": "The difficulty has mainly been attributed to rampant temporal vagueness in natural language, affecting all high-level annotation tasks ().", "labels": [], "entities": []}, {"text": "Focusing on one of the tasks, show that by pairing up discourse-related events and by making the classification scheme paying more attention to vagueness in natural language, inter-annotator agreement increases from 65% to the low 80%.", "labels": [], "entities": [{"text": "agreement", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.8583831191062927}]}, {"text": "Despite the significant improvement, problems identified by towards the end of their paper suggest that how temporal modification is handled in the TempEval annotation scheme needs to be revised to further keep vagueness inline.", "labels": [], "entities": [{"text": "TempEval annotation scheme", "start_pos": 148, "end_pos": 174, "type": "DATASET", "confidence": 0.6576162576675415}]}, {"text": "This paper is an attempt in that direction.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In Section 2, we first offer arguments for changing the way temporal modification is handled in temporal annotation, then layout an outline for the change and motivate the experiment being carried out on Amazon's Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 251, "end_pos": 275, "type": "DATASET", "confidence": 0.9677594304084778}]}, {"text": "We then describe the design of the experiment in detail in Section 3, and present experiment results in Section 4.", "labels": [], "entities": []}, {"text": "And finally in Section 5, we conclude the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Agreement with expert annotation", "labels": [], "entities": []}, {"text": " Table 3: Comparison with double-blind annotation of the  same data. Coverage: no. of events in a link/total no. of  events;  *  : this number is directly based on the TempEval- 2 Chinese data.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9581149816513062}, {"text": "TempEval- 2 Chinese data", "start_pos": 168, "end_pos": 192, "type": "DATASET", "confidence": 0.9032073974609375}]}]}