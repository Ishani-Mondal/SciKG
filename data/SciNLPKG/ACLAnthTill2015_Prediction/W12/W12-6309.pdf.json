{"title": [{"text": "Soochow University Word Segmenter for SIGHAN 2012 Bakeoff", "labels": [], "entities": [{"text": "Soochow University Word Segmenter", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.8386950194835663}, {"text": "SIGHAN 2012 Bakeoff", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.6405568718910217}]}], "abstractContent": [{"text": "This paper presents a Chinese Word Segmentation system on MicroBlog corpora for the CIPS-SIGHAN Word Segmentation Bakeoff 2012.", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.5861627956231436}, {"text": "MicroBlog corpora", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.9491011202335358}, {"text": "CIPS-SIGHAN Word Segmentation Bakeoff 2012", "start_pos": 84, "end_pos": 126, "type": "DATASET", "confidence": 0.8150803685188294}]}, {"text": "Our system employs Conditional Random Fields (CRF) as the segmentation model.", "labels": [], "entities": []}, {"text": "To make our model more adaptive to MicroBlog, we manually analyze and annotate many MicroBlog messages.", "labels": [], "entities": [{"text": "MicroBlog", "start_pos": 35, "end_pos": 44, "type": "DATASET", "confidence": 0.9141499996185303}]}, {"text": "After manually checking and analyzing the MicroBlog text, we propose several pre-processing and post-processing rules to improve the performance.", "labels": [], "entities": [{"text": "MicroBlog text", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9696559607982635}]}, {"text": "As a result, our system obtains a competitive F-score in comparison with other participating systems.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9991135001182556}]}], "introductionContent": [{"text": "Because Chinese context is written without natural delimiters, word segmentation becomes an essential initial step in many tasks on Chinese language processing.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7331036478281021}, {"text": "Chinese language processing", "start_pos": 132, "end_pos": 159, "type": "TASK", "confidence": 0.6199685633182526}]}, {"text": "Though recognizing words seems easy for human beings, automatic Chinese Word Segmentation by computers is not a trivial problem).", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 64, "end_pos": 89, "type": "TASK", "confidence": 0.6048828860123953}]}, {"text": "The state-of-the-art Chinese Word Segmentation systems have achieved a quite high precision on traditional media text.", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.5719791253407797}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9988589286804199}]}, {"text": "However, the performance of segmentation is not so satisfying for MicroBlog corpora.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.9768950939178467}, {"text": "MicroBlog corpora", "start_pos": 66, "end_pos": 83, "type": "DATASET", "confidence": 0.8723068535327911}]}, {"text": "MicroBlog messages are often short, and they make heavy use of colloquial language.", "labels": [], "entities": [{"text": "MicroBlog", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8500726819038391}]}, {"text": "Furthermore, they require situational context for interpretation.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9586547613143921}]}, {"text": "Thus, we first analyze and annotate some MicroBlog messages, and then propose a novel pre-processing and postprocessing approach on the CRF-based segmentation system for the MicroBlog corpora.", "labels": [], "entities": [{"text": "MicroBlog corpora", "start_pos": 174, "end_pos": 191, "type": "DATASET", "confidence": 0.9423423111438751}]}, {"text": "The experimental results show that our system performs well on MicroBlog corpora and could yield comparable segmentation results with other participants.", "labels": [], "entities": [{"text": "MicroBlog corpora", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.9418770670890808}]}], "datasetContent": [{"text": "For this CIPS-SIGHAN bakeoff, we focus on the Chinese Word Segmentation task on MicroBlog corpora.", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6263708770275116}, {"text": "MicroBlog corpora", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.9624192416667938}]}, {"text": "Before the final test, we use the data provided by SIGHAN 2012 which consists of approximately 500 messages from MicroBlog to test our approaches described in the previous sections.", "labels": [], "entities": [{"text": "SIGHAN 2012", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.7785702645778656}, {"text": "MicroBlog", "start_pos": 113, "end_pos": 122, "type": "DATASET", "confidence": 0.9678700566291809}]}, {"text": "The results are shown in, where P, R, F represents the precision rate, recall rate and harmonic average measure rate respectively.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 55, "end_pos": 69, "type": "METRIC", "confidence": 0.9894014596939087}, {"text": "recall rate", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.99045330286026}, {"text": "harmonic average measure rate", "start_pos": 87, "end_pos": 116, "type": "METRIC", "confidence": 0.8592587262392044}]}, {"text": "The approaches we used are: \uf06c Basic represents the result of our model using only the corpora of PKU.", "labels": [], "entities": [{"text": "PKU", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.9091312885284424}]}, {"text": "\uf06c +Pre represents the result of our model using the preprocessing rules.", "labels": [], "entities": [{"text": "Pre", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.9667141437530518}]}, {"text": "\uf06c +Post represents the result of our model using the post-processing rules.", "labels": [], "entities": []}, {"text": "\uf06c +Ann represents the result of our model using the annotated data.", "labels": [], "entities": []}, {"text": "As the table shows, after the use of preprocessing rules, the results are somehow decreased.", "labels": [], "entities": []}, {"text": "The reason fora worse performance is that when we use preprocessing rules, we treat all the digits, other types alike, as the same, whereas they are always different in some circumstance.", "labels": [], "entities": []}, {"text": "For example, we always regard \"\u4e00\u4e2a\" as one word, but others like \"\u4e09\u4e2a\", \"\u4e94\u4e2a\" all regard as two words.", "labels": [], "entities": []}, {"text": "These problems are solved in post-processing, and we can see that the designed post-processing rules are effective and thus could greatly improve the results.", "labels": [], "entities": []}, {"text": "Performance of the final test.", "labels": [], "entities": []}, {"text": "The final test data consists of approximately 5,000 texts from MicroBlog.", "labels": [], "entities": [{"text": "MicroBlog", "start_pos": 63, "end_pos": 72, "type": "DATASET", "confidence": 0.9805113673210144}]}, {"text": "The performances are shown in, where CS indicates the sum of correct sentences, and CSP indicates the percentage of correct sentences in all the sentences.", "labels": [], "entities": [{"text": "CSP", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.98240065574646}]}, {"text": "The F-score we achieved is 0.9365, which is higher than the results when only 500 texts are used.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9989805817604065}]}], "tableCaptions": [{"text": " Table 3 Performances tested before final test", "labels": [], "entities": []}, {"text": " Table 4 Performance of the final test.", "labels": [], "entities": []}]}