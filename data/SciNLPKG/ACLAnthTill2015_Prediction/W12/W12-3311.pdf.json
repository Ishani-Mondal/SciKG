{"title": [{"text": "A Generic Framework for Multiword Expressions Treatment: from Acquisition to Applications", "labels": [], "entities": [{"text": "Multiword Expressions", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.797153115272522}]}], "abstractContent": [{"text": "This paper presents an open and flexible method-ological framework for the automatic acquisition of multiword expressions (MWEs) from monolingual textual corpora.", "labels": [], "entities": [{"text": "automatic acquisition of multiword expressions (MWEs) from monolingual textual corpora", "start_pos": 75, "end_pos": 161, "type": "TASK", "confidence": 0.7582248250643412}]}, {"text": "This research is motivated by the importance of MWEs for NLP applications.", "labels": [], "entities": []}, {"text": "After briefly presenting the modules of the framework, the paper reports extrinsic evaluation results considering two applications: computer-aided lexicography and statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 164, "end_pos": 195, "type": "TASK", "confidence": 0.7529343366622925}]}, {"text": "Both applications can benefit from automatic MWE acquisition and the expressions acquired automatically from corpora can both speedup and improve their quality.", "labels": [], "entities": [{"text": "MWE acquisition", "start_pos": 45, "end_pos": 60, "type": "TASK", "confidence": 0.980872631072998}]}, {"text": "The promising results of previous and ongoing experiments encourage further investigation about the optimal way to integrate MWE treatment into these and many other applications.", "labels": [], "entities": [{"text": "MWE treatment", "start_pos": 125, "end_pos": 138, "type": "TASK", "confidence": 0.9782534539699554}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) range over linguistic constructions such as idioms (to pay an arm and a leg), fixed phrases (rock 'n' roll) and noun compounds (dry ice).", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7884844303131103}]}, {"text": "There is no unique and widely accepted definition for the term multiword expression.", "labels": [], "entities": []}, {"text": "It can bean \"arbitrary and recurrent word combination\" or \"a syntactic and semantic unit whose exact and unambiguous meaning or connotation cannot be derived directly from the meaning or connotation of its components\" or simply an \"idiosyncratic interpretation that crosses word boundaries (or spaces)\").", "labels": [], "entities": []}, {"text": "MWEs lie in the fuzzy zone between lexicon and syntax, thus constituting areal challenge for NLP systems.", "labels": [], "entities": []}, {"text": "In addition, they are very pervasive, occurring frequently in everyday language as well as in specialised communications.", "labels": [], "entities": []}, {"text": "Some common properties of MWEs are:  \u2022 Arbitrariness: sometimes valid constructions are not acceptable because people do not use them.", "labels": [], "entities": [{"text": "Arbitrariness", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.9967992305755615}]}, {"text": "illustrates this by presenting 8 different ways of referring to the Dow Jones index, among which only 4 are used.", "labels": [], "entities": [{"text": "Dow Jones index", "start_pos": 68, "end_pos": 83, "type": "DATASET", "confidence": 0.9657506148020426}]}, {"text": "\u2022 Institutionalisation: MWEs are recurrent, as they correspond to conventional ways of saying things.", "labels": [], "entities": []}, {"text": "Jackendoff (1997) estimates that they compose half of the entries of a speaker's lexicon, and point out that this maybe an underestimate if we consider domain-specific MWEs.", "labels": [], "entities": []}, {"text": "\u2022 Limited semantic variability: MWEs do not undergo the same semantic compositionality rules as ordinary word combinations.", "labels": [], "entities": []}, {"text": "This is expressed in terms of (i) non-compositionality, as the meaning of the whole expression often cannot be directly inferred from the meaning of the parts composing it, (ii) non-substitutability, as it is not possible to replace part of an MWE by a related (synonym/equivalent) word or construction, and (iii) no word-forword translation.", "labels": [], "entities": [{"text": "word-forword translation", "start_pos": 317, "end_pos": 341, "type": "TASK", "confidence": 0.7154340147972107}]}, {"text": "\u2022 Limited syntactic variability: standard grammatical rules do not apply to MWEs.", "labels": [], "entities": []}, {"text": "This can be expressed in terms of (i) lexicalisation, as one cannot list all MWEs in the lexicon (undergeneration) nor include them all in the grammar (overgeneration) and (ii) extragrammaticality, as MWEs are unpredictable and seem \"weird\" fora second language learner who only knows general rules.", "labels": [], "entities": []}, {"text": "2 \u2022 Heterogeneity: MWEs are hard to define because they encompass a large amount of phenomena.", "labels": [], "entities": []}, {"text": "Thus, NLP applications cannot use a unified approach and need to rely on some typology 3 . In this paper, I adopt the definition by, who define MWEs as: different but related phenomena can be described as a sequence 4 of words that acts as a single unit at some level of linguistic analysis.", "labels": [], "entities": []}, {"text": "This generic and intentionally vague definition can be narrowed down according to the application needs.", "labels": [], "entities": []}, {"text": "For example, for the statistical machine translation (MT) system 5 used in the examples shown in, an MWE is any sequence of words which, when not translated as a unit, generates errors: ungrammatical or unnatural verbal constructions (sentence 1), awkward literal translations of idioms (sentence 2) and problems of lexical choice and word order in specialised texts (sentence 3).", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 21, "end_pos": 57, "type": "TASK", "confidence": 0.7717692106962204}]}, {"text": "These examples illustrate the importance of correctly dealing with MWEs in MT applications and, more generally, MWEs can speedup and help remove ambiguities in many current NLP applications, for example: \u2022 Lexicography: Church and Hanks (1990) used a lexicographic environment as their evaluation scenario, comparing manual and intuitive research with the automatic association ratio they proposed.", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9628804922103882}]}, {"text": "\u2022 Word sense disambiguation: MWEs tend to be less polysemous than simple words.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 2, "end_pos": 27, "type": "TASK", "confidence": 0.6950145562489828}]}, {"text": "exemplify that the word world has 9 senses in Wordnet 1.6, record has 14, but world record has only 1.", "labels": [], "entities": [{"text": "Wordnet 1.6", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.9712546467781067}]}, {"text": "\u2022 POS tagging and parsing: recent work in parsing and POS tagging indicates that MWEs can help remove syntactic ambiguities (Seretan, 2008).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 2, "end_pos": 13, "type": "TASK", "confidence": 0.7761130630970001}, {"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.8699817657470703}, {"text": "POS tagging", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.7301968038082123}]}, {"text": "\u2022 Information retrieval: when MWEs like pop star are indexed as a unit, the accuracy of the system improves on multiword queries (Acosta et al., 2011).", "labels": [], "entities": [{"text": "Information retrieval", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.7984213531017303}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9990070462226868}]}, {"text": "Despite the importance of MWEs in several applications, they are often neglected in the design and construction of real-life systems.", "labels": [], "entities": []}, {"text": "In 1993, Smadja pointed out that \".", "labels": [], "entities": []}, {"text": "although disambiguation was originally considered as a performance task, the collocations retrieved have not been used for any specific computational task.\"", "labels": [], "entities": []}, {"text": "Most of the recent and current research in the MWE community still focuses on MWE acquisition instead of integration of automatically acquired or manually compiled resources into applications.", "labels": [], "entities": [{"text": "MWE community", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.8488383591175079}, {"text": "MWE acquisition", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.9737475216388702}]}, {"text": "The main contribution of my thesis is that it represents a step toward the integration of automatically extracted MWEs into real-life applications.", "labels": [], "entities": []}, {"text": "Concretely, my contributions can be classified in two categories: first, I propose a unified, open and flexible methodological framework ( \u00a7 3) for automatic MWE acquisition from corpora; and second, I am performing an intrinsic and extrinsic evaluation of MWE acquisition ( \u00a7 4), dissecting the influence of the different types of resources employed in the acquisition on the quality of the MWEs.", "labels": [], "entities": [{"text": "MWE acquisition", "start_pos": 158, "end_pos": 173, "type": "TASK", "confidence": 0.9441956579685211}, {"text": "MWE acquisition", "start_pos": 257, "end_pos": 272, "type": "TASK", "confidence": 0.907828688621521}]}, {"text": "The results of ongoing experiments are interesting but further work is needed to better understand the contributions of MWEs to the systems ( \u00a7 5).", "labels": [], "entities": []}, {"text": "Methodological Framework To date, there is no agreement on whether there is a single best method for MWE acquisition, or whether a different subset of methods works better fora given MWE type.", "labels": [], "entities": [{"text": "MWE acquisition", "start_pos": 101, "end_pos": 116, "type": "TASK", "confidence": 0.9873945116996765}]}, {"text": "Most of recent work on MWE treatment focuses on candidate extraction from preprocessed text and on the automatic filtering and ranking through association measures), but few authors provide a whole picture of the MWE treatment pipeline.", "labels": [], "entities": [{"text": "MWE treatment", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9804314374923706}, {"text": "candidate extraction from preprocessed text", "start_pos": 48, "end_pos": 91, "type": "TASK", "confidence": 0.81549032330513}, {"text": "MWE treatment", "start_pos": 213, "end_pos": 226, "type": "TASK", "confidence": 0.9375004172325134}]}, {"text": "One of the advantages of the framework I propose is that it models the whole acquisition process with modular tasks that can be chained in several ways, each task having multiple available techniques.", "labels": [], "entities": []}, {"text": "Therefore, it is highly customisable and allows fora large number of parameters to be tuned according to the target MWE types.", "labels": [], "entities": []}, {"text": "Moreover, the techniques I have developed do not depend on a fixed length of candidate expression nor on adjacency assumptions, as the words in an expression might occur several words away.", "labels": [], "entities": []}, {"text": "Thanks to this flexibility, this methodology can be easily applied to virtually any language, MWE type and domain, not strictly depending on a given formalism or tool . Intuitively, fora given language, if some preprocessing tools like POS taggers and/or parsers are available, the results will be much better than running the methods on raw text.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 236, "end_pos": 247, "type": "TASK", "confidence": 0.6670709997415543}]}, {"text": "But since such tools are not available for all languages, the methodology was conceived to be applicable even in the absence of preprocessing.", "labels": [], "entities": []}], "datasetContent": [{"text": "Published results comparing MWE extraction techniques usually evaluate them on small controlled data sets using objective measures such as precision, recall and mean average precision ().", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9912070035934448}, {"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.999560534954071}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9980700612068176}, {"text": "mean average precision", "start_pos": 161, "end_pos": 183, "type": "METRIC", "confidence": 0.8766323526700338}]}, {"text": "On the one hand, the results of intrinsic evaluation are often vague or inconclusive: although they shed some light on the optimal parameters for the given scenario, they are hard to generalise and cannot be directly applied to other configurations.", "labels": [], "entities": []}, {"text": "The quality of acquired MWEs as measured by objective criteria depends on the language, domain and type of the target construction, on corpus size and genre, on already available resources , on the applied filters, preprocessing steps, etc.", "labels": [], "entities": []}, {"text": "On the other hand, extrinsic evaluation consists of inserting acquired MWEs into areal NLP application and evaluating the impact of this new data on the overall performance of the system.", "labels": [], "entities": []}, {"text": "For instance, it maybe easier to ask a human annotator to evaluate the output of an MT system than to ask whether a sequence of words constitutes an MWE.", "labels": [], "entities": [{"text": "MT system", "start_pos": 84, "end_pos": 93, "type": "TASK", "confidence": 0.8834099173545837}]}, {"text": "Thus, another original contribution of my thesis is application-oriented extrinsic evaluation of MWE acquisition on two study cases: computer-aided lexicography and statistical machine translation.", "labels": [], "entities": [{"text": "MWE acquisition", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.9824725985527039}, {"text": "statistical machine translation", "start_pos": 165, "end_pos": 196, "type": "TASK", "confidence": 0.7435484727223715}]}, {"text": "My goal is to investigate (1) how much the MWEs impact on the application and what is (are) the best way(s) of integrating them in the complex pipeline of the target application.", "labels": [], "entities": []}, {"text": "In this paper, I described an open framework for the automatic acquisition of MWEs from corpora.", "labels": [], "entities": [{"text": "automatic acquisition of MWEs from corpora", "start_pos": 53, "end_pos": 95, "type": "TASK", "confidence": 0.6499430040518442}]}, {"text": "What distinguishes it from related work is that it provides an integrated environment covering the whole acquisition pipeline.", "labels": [], "entities": []}, {"text": "For each module, there are multiple available techniques which are flexible, portable and can be combined in several ways.", "labels": [], "entities": []}, {"text": "The usefulness of the framework is then presented in terms of extrinsic application-based evaluation.", "labels": [], "entities": []}, {"text": "I presented summarised results of ongoing experiments in computer-aided lexicography and in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9927636981010437}]}, {"text": "Although our results are promising, the experiments on SMT need further investigation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9949239492416382}]}, {"text": "I am currently applying syntax-based identification and analysing word alignment and translation table entries fora set of prototypical MWEs, in order to obtain a better understanding of the impact of each integration strategy on the system.", "labels": [], "entities": [{"text": "syntax-based identification", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.725067526102066}, {"text": "word alignment", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.7067486047744751}]}, {"text": "Moreover, I would like to pursue previous experiments on bilingual MWE acquisition from parallel and comparable resources.", "labels": [], "entities": [{"text": "MWE acquisition", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.8820889294147491}]}, {"text": "Finally, I would like to experiment on MWE simplification (e.g. replacing a multiword verb like go back by its simplex form regress) as preprocessing for SMT, in order to improve translation quality by making the source language look more like the target language.As these improvements depend in the MT paradigm, I would also like to evaluate strategies for the integration of verbal MWEs inexpert MT systems.", "labels": [], "entities": [{"text": "MWE simplification", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.93387770652771}, {"text": "SMT", "start_pos": 154, "end_pos": 157, "type": "TASK", "confidence": 0.9933952689170837}, {"text": "MT paradigm", "start_pos": 300, "end_pos": 311, "type": "TASK", "confidence": 0.9164073765277863}]}, {"text": "In spite of a large amount of work in the area, the treatment of MWEs in NLP applications is still an open and challenging problem.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.9292977452278137}]}, {"text": "This is not surprising, given their complex and heterogeneous behaviour (.", "labels": [], "entities": []}, {"text": "At the beginning of the 2000's, asked whether the identification of MWEs was a solved problem, and the answer that paper gave was 'no, it is not'.", "labels": [], "entities": [{"text": "identification of MWEs", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.9069282213846842}]}, {"text": "The MWE workshop series have shown that this is still the case, listing several challenges in MWE treatment like lexical representation and application-oriented evaluation.", "labels": [], "entities": [{"text": "MWE workshop series", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.7091938455899557}, {"text": "MWE treatment", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9282195270061493}, {"text": "lexical representation", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.6952914297580719}]}, {"text": "Therefore, I believe that my thesis will be a significant step toward the full integration of MWE treatment in NLP applications, but there is still along road to go. like to thank my supervisors Aline Villavicencio and Christian Boitet, as well as the colleagues who contributed to this work: Evita Linardaki, Valia Kordoni, Magali Sanchez Duran and Vitor De Araujo.", "labels": [], "entities": [{"text": "MWE treatment", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9659615457057953}]}], "tableCaptions": [{"text": " Table 3: Evaluation of translation of phrasal verbs in test set.", "labels": [], "entities": []}]}