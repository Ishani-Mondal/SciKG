{"title": [{"text": "Nudging the Envelope of Direct Transfer Methods for Multilingual Named Entity Recognition", "labels": [], "entities": [{"text": "Multilingual Named Entity Recognition", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.6643247008323669}]}], "abstractContent": [{"text": "In this paper, we study direct transfer methods for multilingual named entity recognition.", "labels": [], "entities": [{"text": "multilingual named entity recognition", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.6405147165060043}]}, {"text": "Specifically, we extend the method recently proposed by T\u00e4ckstr\u00f6m et al.", "labels": [], "entities": []}, {"text": "(2012), which is based on cross-lingual word cluster features.", "labels": [], "entities": [{"text": "cross-lingual word cluster", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.5991650919119517}]}, {"text": "First, we show that by using multiple source languages, combined with self-training for target language adaptation, we can achieve significant improvements compared to using only single source direct transfer.", "labels": [], "entities": [{"text": "target language adaptation", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.7833987871805826}]}, {"text": "Second, we investigate how the direct transfer system fares against a supervised target language system and conclude that between 8,000 and 16,000 word tokens need to be annotated in each target language to match the best direct transfer system.", "labels": [], "entities": []}, {"text": "Finally, we show that we can significantly improve target language performance, even after annotating up to 64,000 tokens in the target language, by simply concatenating source and target language annotations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognition of named entities in natural language text is an important subtask of information extraction and thus bears importance for modern text mining and information retrieval applications.", "labels": [], "entities": [{"text": "Recognition of named entities in natural language text", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.9037494957447052}, {"text": "information extraction", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.7736191153526306}, {"text": "text mining", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.736306294798851}, {"text": "information retrieval", "start_pos": 158, "end_pos": 179, "type": "TASK", "confidence": 0.7195345759391785}]}, {"text": "The need to identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in Wikification of documents, and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation () and question answering (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 308, "end_pos": 327, "type": "TASK", "confidence": 0.7864492535591125}, {"text": "question answering", "start_pos": 335, "end_pos": 353, "type": "TASK", "confidence": 0.9153581261634827}]}, {"text": "The advent of massive machine readable factual databases, such as Freebase 1 and the proposed 1 http://www.freebase.com Wikidata 2 , will likely push the need for automatic extraction tools further.", "labels": [], "entities": [{"text": "Freebase 1", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.9477993249893188}]}, {"text": "While these databases store information about entity types and the relationships between those types, the named entity recognition (NER) task concerns finding occurrences of named entities in context.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 106, "end_pos": 136, "type": "TASK", "confidence": 0.8330471316973368}]}, {"text": "This view originated with the Message Understanding Conferences (MUC).", "labels": [], "entities": [{"text": "Message Understanding Conferences (MUC)", "start_pos": 30, "end_pos": 69, "type": "TASK", "confidence": 0.8073281049728394}]}, {"text": "As with the majority of tasks in contemporary natural language processing, most approaches to NER have been based on supervised machine learning.", "labels": [], "entities": [{"text": "NER", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9664735794067383}]}, {"text": "However, although resources fora handful of languages have been created, through initiatives such as MUC, the Multilingual Entity Task () and the CoNLL shared tasks, coverage is still very limited in terms of both domains and languages.", "labels": [], "entities": [{"text": "MUC", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.9135870337486267}]}, {"text": "With fine-grained entity taxonomies such as that proposed by, who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.", "labels": [], "entities": []}, {"text": "Although semi-supervised approaches have been shown to reduce the need for manual annotation, these methods still require a substantial amount of manual annotation for each target language.", "labels": [], "entities": []}, {"text": "Manually creating a sufficient amount of annotated resources for all entity types in all languages thus seems like an Herculean task.", "labels": [], "entities": []}, {"text": "In this study, we turn to direct transfer methods) as away to combat the need for annotated resources in all languages.", "labels": [], "entities": []}, {"text": "These methods allow one to train a system fora target language, using only annotations in some source language, as long as all source language features also have support in the target languages.", "labels": [], "entities": []}, {"text": "Specifically, we extend the direct transfer method proposed by in two ways.", "labels": [], "entities": []}, {"text": "First, in \u00a73, we use multiple source languages for training.", "labels": [], "entities": []}, {"text": "We then propose a self-training algorithm, which allows for the inclusion of additional target language specific features, in \u00a74.", "labels": [], "entities": []}, {"text": "By combining these extensions, we achieve significant error reductions on all tested languages.", "labels": [], "entities": [{"text": "error", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.9533426761627197}]}, {"text": "Finally, in \u00a75, we assess the viability of the different direct transfer systems compared to a supervised system trained on target language annotations, and conclude that direct transfer methods maybe useful even in this scenario.", "labels": [], "entities": []}], "datasetContent": [{"text": "In these experiments we combine direct transfer with self-training using unlabeled target data.", "labels": [], "entities": []}, {"text": "This is the transductive setting, as we include the test data (with labels removed, of course) in the unlabeled target data.", "labels": [], "entities": []}, {"text": "We investigate the effect of adding self-training (SELF) to the single-source and multi-source transfer settings of \u00a73, where only cross-lingual features are used (SINGLE and MULTI, respectively).", "labels": [], "entities": [{"text": "MULTI", "start_pos": 175, "end_pos": 180, "type": "METRIC", "confidence": 0.7496517300605774}]}, {"text": "We further study the effect of including native monolingual word cluster features in addition to the cross-lingual features (SELF/NATVE).", "labels": [], "entities": [{"text": "SELF/NATVE)", "start_pos": 125, "end_pos": 136, "type": "METRIC", "confidence": 0.7543054521083832}]}, {"text": "The experimental settings and datasets used are the same as those described in \u00a73.", "labels": [], "entities": []}, {"text": "We performed self-training for T = 5 iterations for all languages, as preliminary experiments indicated that the procedure converges to a stable solution after this number of iterations.", "labels": [], "entities": []}, {"text": "CRFSuite was used to compute all the required probabilities for the filtering and sampling steps.", "labels": [], "entities": [{"text": "CRFSuite", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8876931667327881}]}, {"text": "The results of these experiments are shown in Table 3.", "labels": [], "entities": []}, {"text": "By itself, self-training without target specific features result in an average relative error reduction of less than 4%, compared to the baseline direct transfer system.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 79, "end_pos": 103, "type": "METRIC", "confidence": 0.7794707814852396}]}, {"text": "This is only slightly better than the improvement achieved with multi-source transfer.", "labels": [], "entities": []}, {"text": "However, when adding target specific features, selftraining works better, with a 7% reduction.", "labels": [], "entities": []}, {"text": "Combining multi-source transfer with self-training, without target specific features, performs even better with a 10% reduction.", "labels": [], "entities": []}, {"text": "Finally, combining multi-source transfer and self-training with target specific features, gives the best result across all three languages, with an average relative error reduction of more than 14%.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 156, "end_pos": 180, "type": "METRIC", "confidence": 0.7602683901786804}]}, {"text": "The results for German are particularly interesting, in that they highlight a rather surprising general trend.", "labels": [], "entities": []}, {"text": "The relative improvement achieved by combining multi-source transfer and self training with native clusters is almost twice as large as that achieved when using only self-training with native clusters, despite the fact that multi-source transfer is not very effective on its own -in the case of German, multisource transfer actually hurts results when used in isolation.", "labels": [], "entities": [{"text": "multisource transfer", "start_pos": 303, "end_pos": 323, "type": "TASK", "confidence": 0.742412269115448}]}, {"text": "One explanation for this behavior could be that the regularization imposed by the use of multiple source languages is beneficial to self-training, in that it generates better confidence estimates.", "labels": [], "entities": []}, {"text": "Another, perhaps more speculative, explanation could be that each source language shares different characteristics with the target language.", "labels": [], "entities": []}, {"text": "Even though the predictions on the target language are not much better on average in this case, as long as a large enough subset of the confident predictions are better than with singlesource transfer, these predictions can be exploited during self-training.", "labels": [], "entities": []}, {"text": "In addition to using self-training with native word cluster features, we also experimented with creating target language specific versions of the cross-lingual features by means of the feature duplication trick.", "labels": [], "entities": []}, {"text": "However, preliminary experiments suggested that this is not an effective strategy in the      cross-lingual direct transfer scenario.", "labels": [], "entities": [{"text": "cross-lingual direct transfer", "start_pos": 94, "end_pos": 123, "type": "TASK", "confidence": 0.6090867320696512}]}, {"text": "It thus seems likely that the significant improvements that we observe are at least in part explained by the fact that the native features are distinct from the cross-lingual features and not mere duplicates.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of multi-source direct transfer, measured  with F 1 -score on the CoNLL 2002/2003 development and  test sets. ALL: all languages except the target language  are used as source languages.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9834831953048706}, {"text": "CoNLL 2002/2003 development and  test sets", "start_pos": 84, "end_pos": 126, "type": "DATASET", "confidence": 0.9615322723984718}]}, {"text": " Table 3: Results of different extensions to direct trans- fer as measured with F 1 -score on the CoNLL 2002/2003  development and test sets. SINGLE: single-source trans- fer, MULTI: multi-source transfer, SELF: self-training  with only cross-lingual word clusters, SELF/NATIVE: self- training with cross-lingual and native word clusters.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9734992533922195}, {"text": "CoNLL 2002/2003  development and test sets", "start_pos": 98, "end_pos": 140, "type": "DATASET", "confidence": 0.961535856127739}, {"text": "SELF", "start_pos": 206, "end_pos": 210, "type": "METRIC", "confidence": 0.826324462890625}]}]}