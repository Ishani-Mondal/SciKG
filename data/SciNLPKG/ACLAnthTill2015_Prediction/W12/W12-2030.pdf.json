{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 257-262, A Naive Bayes classifier for automatic correction of preposition and determiner errors in ESL text", "labels": [], "entities": []}], "abstractContent": [{"text": "This is the report for the CNGL ILT team entry to the HOO 2012 shared task.", "labels": [], "entities": [{"text": "CNGL ILT team entry to the HOO 2012 shared task", "start_pos": 27, "end_pos": 74, "type": "DATASET", "confidence": 0.7284356534481049}]}, {"text": "A Naive-Bayes-based classifier was used in the task which involved error detection and correction in ESL exam scripts.", "labels": [], "entities": [{"text": "error detection and correction in ESL exam scripts", "start_pos": 67, "end_pos": 117, "type": "TASK", "confidence": 0.545198455452919}]}, {"text": "The features we use include n-grams of words and POS tags together with features based on the external Google N-Grams corpus.", "labels": [], "entities": [{"text": "Google N-Grams corpus", "start_pos": 103, "end_pos": 124, "type": "DATASET", "confidence": 0.7346925139427185}]}, {"text": "Our system placed 11th out of 14 teams for the detection and recognition tasks and 11th out of 13 teams for the correction task based on F-score for both preposition and determiner errors.", "labels": [], "entities": [{"text": "detection and recognition", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.8571516474088033}, {"text": "F-score", "start_pos": 137, "end_pos": 144, "type": "METRIC", "confidence": 0.9985804557800293}]}], "introductionContent": [{"text": "The HOO 2012 shared task seeks to apply computational methods to the correction of certain types of errors in non-native English texts.", "labels": [], "entities": [{"text": "HOO 2012 shared task", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.8339815437793732}, {"text": "correction of certain types of errors in non-native English texts", "start_pos": 69, "end_pos": 134, "type": "TASK", "confidence": 0.6448856085538864}]}, {"text": "The previous year's task, (), focused on a larger scale of errors and a corpus of academic articles.", "labels": [], "entities": []}, {"text": "This year's task focuses on six error types in a corpus of non-native speaker text.", "labels": [], "entities": []}, {"text": "In Section 2, we give a brief summary of the data for the shared task and in Section 3 we explain the 1 http://correcttext.org/hoo2012/ errortypes.html last verified, individual steps in the system.", "labels": [], "entities": []}, {"text": "Section 4 details the different configurations for each of the runs submitted and finally, Section 5 presents the results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Overall results on original data: TC", "labels": [], "entities": [{"text": "TC", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.7808700203895569}]}, {"text": " Table 4: Overall results on revised data: TC", "labels": [], "entities": [{"text": "TC", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.8347693681716919}]}, {"text": " Table 5: Top results on original test data", "labels": [], "entities": []}]}