{"title": [{"text": "Natural Language Inspired Approach for Handwritten Text Line Detection in Legacy Documents *", "labels": [], "entities": [{"text": "Handwritten Text Line Detection in Legacy Documents", "start_pos": 39, "end_pos": 90, "type": "TASK", "confidence": 0.7139304833752769}]}], "abstractContent": [{"text": "Document layout analysis is an important task needed for handwritten text recognition among other applications.", "labels": [], "entities": [{"text": "Document layout analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9455719987551371}, {"text": "handwritten text recognition", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.6279652814070383}]}, {"text": "Text layout commonly found in handwritten legacy documents is in the form of one or more paragraphs composed of parallel text lines.", "labels": [], "entities": [{"text": "Text layout", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.6969979703426361}]}, {"text": "An approach for handwritten text line detection is presented which uses machine-learning techniques and methods widely used in natural language processing.", "labels": [], "entities": [{"text": "handwritten text line detection", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.621603861451149}]}, {"text": "It is shown that text line detection can be accurately solved using a formal methodology, as opposed to most of the proposed heuris-tic approaches found in the literature.", "labels": [], "entities": [{"text": "text line detection", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8249589999516805}]}, {"text": "Experimental results show the impact of using increasingly constrained \"vertical layout language models\" in text line detection accuracy.", "labels": [], "entities": [{"text": "text line detection", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7744326988855997}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.6960040330886841}]}], "introductionContent": [{"text": "Handwritten text transcription is becoming an increasingly important task, in order to provide historians and other researchers new ways of indexing, consulting and querying the huge amounts of historic handwritten documents which are being published in on-line digital libraries.", "labels": [], "entities": [{"text": "Handwritten text transcription", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7414958278338114}]}, {"text": "Transcriptions of such documents are currently obtained with solutions that range from the use of systems that aim at fully automatic handwritten text recognition ( (HTR), to computer assisted transcription (CATTI), were the users participate interactively in the proper transcription process ().", "labels": [], "entities": [{"text": "handwritten text recognition", "start_pos": 134, "end_pos": 162, "type": "TASK", "confidence": 0.6682087779045105}, {"text": "computer assisted transcription (CATTI)", "start_pos": 175, "end_pos": 214, "type": "TASK", "confidence": 0.7699248095353445}]}, {"text": "* Work supported under the MIPRCV \"Consolider Ingenio 2010\" program (CSD2007-00018), MITTRAL (TIN2009-14633-C03-01) and also Univ. Polit\u00e9cnica Valencia The basic input to these systems consists of text line images.", "labels": [], "entities": [{"text": "MITTRAL", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.8175315856933594}]}, {"text": "Hence, text line detection and extraction from a given document page image becomes a necessary preprocessing step in any kind of transcription systems.", "labels": [], "entities": [{"text": "text line detection", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.6850025355815887}]}, {"text": "Furthermore the quality of line segmentation directly influences the final accuracy achieved by such systems.", "labels": [], "entities": [{"text": "line segmentation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.739017128944397}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9853174090385437}]}, {"text": "Detection of handwritten text lines in an image entails a greater difficulty, in comparison with printed text lines, due to the inherent properties of handwritten text: variable inter-line spacing, overlapping and touching strokes of adjacent handwritten lines, etc.", "labels": [], "entities": [{"text": "Detection of handwritten text lines", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8421766281127929}]}, {"text": "The difficulty is further increased in the case of ancient documents, due to common problems appearing in them: presence of smear, significant background variations and uneven illumination, spots due to the humidity, and marks resulting from the ink that goes through the paper (generally called \"bleed-through\").", "labels": [], "entities": []}, {"text": "Among the most popular state-of-the art methods involved in handwritten text line detection we find four main families: based on (vertical) projection profiles (), on the Hough transform, the repulsive-attractive network approach) and finally the so-called stochastic methods (), which combine probabilistic models such as Hidden Markov Models (HMMs) along with dynamic programming techniques (e.g. Viterbi algorithm) to derive optimal paths between overlapping text lines.", "labels": [], "entities": [{"text": "handwritten text line detection", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.5943260714411736}]}, {"text": "It is worth noting that, most of the mentioned approaches somewhat involve heuristic adjustments of their parameters, which have to be properly tuned according to the characteristics of each task in order to obtain adequate results.", "labels": [], "entities": []}, {"text": "In this work, the text line detection problem in legacy handwritten documents is approached by using machine-learning techniques and methods which are widely used in natural language processing (NLP).", "labels": [], "entities": [{"text": "text line detection", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7002890010674795}, {"text": "natural language processing (NLP)", "start_pos": 166, "end_pos": 199, "type": "TASK", "confidence": 0.7103111843268076}]}, {"text": "It is shown that the text line detection problem can be solved by using a formal methodology, as opposed to most of the currently proposed heuristic based approaches found in the literature.", "labels": [], "entities": [{"text": "text line detection", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7778051098187765}]}], "datasetContent": [{"text": "In order to study the efficacy of the line detection approach proposed in this paper, different experiments were carried out.", "labels": [], "entities": [{"text": "line detection", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7775047123432159}]}, {"text": "We are mainly interested in assessing the impact upon final text line detec- tion accuracy of employing increasingly restrictive LMs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9074631929397583}]}, {"text": "We measure the quality of the text line detection by means of the \"line error rate\" (LER) which is performed by comparing the sequences of automatically obtained region labels with the corresponding reference label sequences.", "labels": [], "entities": [{"text": "text line detection", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.6509012679258982}, {"text": "line error rate\" (LER)", "start_pos": 67, "end_pos": 89, "type": "METRIC", "confidence": 0.8761186514581952}]}, {"text": "The LER is computed in the same way as the well known WER, with equal costs assigned to deletions, insertions and substitutions).", "labels": [], "entities": [{"text": "LER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9883142709732056}, {"text": "WER", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.45610734820365906}]}, {"text": "A series of experiments were performed on the CS corpus using a simple hold-out validation as per the CS \"book\" partition.", "labels": [], "entities": [{"text": "CS corpus", "start_pos": 46, "end_pos": 55, "type": "DATASET", "confidence": 0.8780565559864044}]}, {"text": "Initially some parameters were set up: feature extraction dimension D, HMM topology (number of states and Gaussians),number of Baum-Welch iterations, and decoding grammar scale factor (GSF) and word insertion penalty (WIP).", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7111693471670151}, {"text": "grammar scale factor (GSF)", "start_pos": 163, "end_pos": 189, "type": "METRIC", "confidence": 0.8040926853815714}, {"text": "word insertion penalty (WIP)", "start_pos": 194, "end_pos": 222, "type": "METRIC", "confidence": 0.7504563728968302}]}, {"text": "After some informal experimentation, adequate values were found for several of them: feature vectors dimension of 2, leftto-right HMMs with 4 states topology, 32 Gaussian mixtures per state trained by running 3 cycles of Baum-Welch re-estimation algorithm.", "labels": [], "entities": []}, {"text": "The remaining parameters, all related with the decoding process itself, were tuned to obtain the best figures for each of the two following language models: the prior and conditional represented by topologically different SFSGs.", "labels": [], "entities": []}, {"text": "The prior model transition probabilities are estimated from the training set as the fraction of the number of appearances of each vertical region label over the whole count of labels.", "labels": [], "entities": []}, {"text": "The conditional model also considers the previous label in order to perform the estimation.", "labels": [], "entities": []}, {"text": "These estimates resemble the uni-gram and bi-gram LMs calculations, except no smoothing strategy is implemented here.", "labels": [], "entities": []}, {"text": "Additionally, it is defined for each test page a line-number constrained LM which uses the conditional probabilities to populate the model but enforces a total number of possible line-regions to detect as per the number of reference line-region labels of that test page.", "labels": [], "entities": []}, {"text": "reports the obtained LER results for each of these LMs.", "labels": [], "entities": [{"text": "LER", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9886853694915771}]}, {"text": "As can be seen, the more restrictive the LM is, the better accuracy is achieved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9994882345199585}]}, {"text": "Concerning the line-number constrained, they are really conceived for its utilization in (parts of) documents or document collections with homogeneous numbers of lines per page.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Basic statistics of the Cristo-Salvador corpus  partition.  Number of:  Training Test Total  Pages  33  20  53  Normal-text lines (NL)  685 497 1 182  Blank Lines (BL)  73  70  143  Non-text Lines (NT)  16  8  24  Inter Lines (IL)  701 505 1 206", "labels": [], "entities": [{"text": "Cristo-Salvador corpus  partition", "start_pos": 34, "end_pos": 67, "type": "DATASET", "confidence": 0.78004718820254}]}, {"text": " Table 2: Best detection LER(%) obtained for each  kind of language model: Prior, Conditional and Line- Number Constrained.", "labels": [], "entities": [{"text": "LER", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.6274532675743103}]}]}