{"title": [{"text": "Analyzing Patient Records to Establish If and When a Patient Suffered from a Medical Condition", "labels": [], "entities": [{"text": "Establish If and When a Patient Suffered from a Medical Condition", "start_pos": 29, "end_pos": 94, "type": "TASK", "confidence": 0.747872379693118}]}], "abstractContent": [{"text": "The growth of digital clinical data has raised questions as to how best to leverage this data to aid the world of healthcare.", "labels": [], "entities": []}, {"text": "Promising application areas include Information Retrieval and Question-Answering systems.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.8172554075717926}]}, {"text": "Such systems require an in-depth understanding of the texts that are processed.", "labels": [], "entities": []}, {"text": "One aspect of this understanding is knowing if a medical condition outlined in a patient record is recent, or if it occurred in the past.", "labels": [], "entities": []}, {"text": "As well as this, patient records often discuss other individuals such as family members.", "labels": [], "entities": []}, {"text": "This presents a second problem-determining if a medical condition is experienced by the patient described in the report or some other individual.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the suitabil-ity of a machine learning (ML) based system for resolving these tasks on a previously unex-plored collection of Patient History and Physical Examination reports.", "labels": [], "entities": [{"text": "Patient History and Physical Examination", "start_pos": 155, "end_pos": 195, "type": "TASK", "confidence": 0.6421925127506256}]}, {"text": "Our results show that our novel Score-based feature approach outperforms the standard Linguistic and Con-textual features described in the related literature.", "labels": [], "entities": []}, {"text": "Specifically, near-perfect performance is achieved in resolving if a patient experienced a condition.", "labels": [], "entities": []}, {"text": "While for the task of establishing when a patient experienced a condition, our ML system significantly outperforms the ConText system (87% versus 69% f-score, respectively).", "labels": [], "entities": [{"text": "establishing when a patient experienced a condition", "start_pos": 22, "end_pos": 73, "type": "TASK", "confidence": 0.8035152554512024}, {"text": "f-score", "start_pos": 150, "end_pos": 157, "type": "METRIC", "confidence": 0.9864605665206909}]}], "introductionContent": [{"text": "The growth of the digitization of clinical documents has fostered interest in how to best leverage this data in providing assistance in the world of healthcare, including novel information retrieval (, question answering) and clinical summarization systems.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 177, "end_pos": 198, "type": "TASK", "confidence": 0.746477335691452}, {"text": "question answering)", "start_pos": 202, "end_pos": 221, "type": "TASK", "confidence": 0.7994054853916168}, {"text": "clinical summarization", "start_pos": 226, "end_pos": 248, "type": "TASK", "confidence": 0.4584713727235794}]}, {"text": "Given the richness of the language found in clinical reports, novel systems require a deeper understanding of this textual data.", "labels": [], "entities": []}, {"text": "One aspect of this understanding is the assertion status of medical conditions).", "labels": [], "entities": [{"text": "assertion status of medical", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.8208374083042145}]}, {"text": "The assertion status of a medical condition may refer to Negation Resolution, Temporal Grounding (deciding if a condition is currently or historical, and Condition Attribution (deciding if a condition is experienced by the patient described in the report or some other individual).", "labels": [], "entities": [{"text": "Negation Resolution", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.9437610507011414}]}, {"text": "The focus of this paper rests on the latter two tasks of Temporal Grounding and Condition Attribution as Negation has been satisfactorily addressed in.", "labels": [], "entities": [{"text": "Temporal Grounding", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.9700175821781158}, {"text": "Condition Attribution", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7778965532779694}]}, {"text": "Several approaches, ranging in complexity, have been proposed for resolving temporal information.", "labels": [], "entities": [{"text": "resolving temporal information", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.8422613143920898}]}, {"text": "modeled the task as a constraint satisfaction problem.", "labels": [], "entities": []}, {"text": "Another rule-based approach that achieved moderate results uses regular expressions matching occurrences of trigger terms.", "labels": [], "entities": []}, {"text": "A trigger term in this context refers to a term or phrase that provides strong evidence supporting the attribution (e.g., patient, family member) or temporality (e.g., current, past) of a condition.", "labels": [], "entities": []}, {"text": "Given the limitations of solely using pre-composed trigger term lists, recent focus has been placed on the use of rule-based learning systems with different feature sets (.", "labels": [], "entities": []}, {"text": "Section headers, tense and aspect are investigated as features, with promising results for the temporality task achieving an accuracy score of 89%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9995742440223694}]}, {"text": "However, the authors' acknowledge that conclusions drawn must be tentative as a majority class classifier achieved an accuracy of 86.9% (only 13% of conditions in the dataset are historical).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9994902610778809}]}, {"text": "This paper extends current work in the domain in the following ways.", "labels": [], "entities": []}, {"text": "The dataset used in these experiments is generated from a collection of previously unannotated History & Physical (H&P) Examination reports.", "labels": [], "entities": [{"text": "History & Physical (H&P) Examination reports", "start_pos": 95, "end_pos": 139, "type": "DATASET", "confidence": 0.5925675094127655}]}, {"text": "Prior work has focused on other report types such as discharge summaries and emergency department reports.", "labels": [], "entities": [{"text": "discharge summaries", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.6885794997215271}]}, {"text": "In these cases the distribution of historical and recent conditions is often heavily skewed in favour of descriptions of recent conditions experienced by the patient.", "labels": [], "entities": []}, {"text": "As H&P reports aim to provide a comprehensive picture of a patient's past and present state, a more uniform distribution of historical and recent conditions is present in this report type.", "labels": [], "entities": []}, {"text": "This work extends previous work by exploring the use of machine learning (ML) as an alternative to hand-crafted rule based systems and rule-based ML approaches to resolving these tasks.", "labels": [], "entities": []}, {"text": "In this work, a comparative analysis of several ML algorithms from different paradigms are evaluated, in order to determine the best approach for our tasks.", "labels": [], "entities": [{"text": "ML", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9584388136863708}]}, {"text": "Building on this, the performance of four automatically extracted feature sets are evaluated, identifying their contributions and also their interactions.", "labels": [], "entities": []}, {"text": "This work also extends existing work by automatically extracting features that were previously extracted manually as well as the proposal of a set of novel score-based features.", "labels": [], "entities": []}, {"text": "The performance of the ML algorithms are compared to the rule-based system -ConText.", "labels": [], "entities": [{"text": "ML", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9475459456443787}, {"text": "ConText", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9075148701667786}]}, {"text": "Our results show that the ML approaches significantly outperform this rule-based system on the Temporal Grounding task.", "labels": [], "entities": [{"text": "ML", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.8982469439506531}, {"text": "Temporal Grounding task", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.9110742012659708}]}], "datasetContent": [{"text": "There are two aims of the experiments reported in this section: firstly, to evaluate the performance of ML algorithms in resolving the assertion status of medical conditions.", "labels": [], "entities": [{"text": "ML algorithms", "start_pos": 104, "end_pos": 117, "type": "TASK", "confidence": 0.8889464735984802}, {"text": "resolving the assertion status of medical conditions", "start_pos": 121, "end_pos": 173, "type": "TASK", "confidence": 0.7696311729294913}]}, {"text": "Secondly, to assess the performance of individual feature sets in order to discover the most contributory and informatory features or sets of features.", "labels": [], "entities": []}, {"text": "To evaluate the latter, classifications using all possible combinations of feature sets (listed in) were performed.", "labels": [], "entities": []}, {"text": "The systems are evaluated by the metrics precision, recall and f-score: where TP is the number of true positives, FP is the number of false positives, FN is the number of false negatives.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9982000589370728}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9997591376304626}, {"text": "f-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9864873290061951}, {"text": "TP", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9868331551551819}, {"text": "FP", "start_pos": 114, "end_pos": 116, "type": "METRIC", "confidence": 0.9835703372955322}, {"text": "FN", "start_pos": 151, "end_pos": 153, "type": "METRIC", "confidence": 0.990591824054718}]}, {"text": "Systems are evaluated using both cross-validation and hold-out methods.", "labels": [], "entities": []}, {"text": "In the hold-out method there are two data sets, one used for training the classifier and a second for testing it on a blind sub-set of test material.", "labels": [], "entities": []}, {"text": "10-fold cross-validation is performed on the training sets and final results are reported in this paper on the held-out blind test set.", "labels": [], "entities": []}, {"text": "Three hold-out classification splits were experimented with (i.e., train/test splits: 30%/70%; 50%/50%; 70%/30%).", "labels": [], "entities": []}, {"text": "We found that results for each of the data splits and cross-validation experiments were largely uniform.", "labels": [], "entities": []}, {"text": "To avoid repetition of results, Section 5 focuses on experiments using a held-out method training/test split of 70%/30%.", "labels": [], "entities": []}, {"text": "All hold-out experiments were implemented using Weka's () Experimenter interface.", "labels": [], "entities": []}, {"text": "Cross-Validation experiments were performed using a script developed by the authors in conjunction with Weka's API.", "labels": [], "entities": []}, {"text": "This allowed the ML approaches and the ConText algorithm to be evaluated against the same test-folds.", "labels": [], "entities": []}, {"text": "4.1.1 Comparison with a rule-based system ConText () is a simple yet effective rule-based system designed to resolve the assertion status of medical conditions.", "labels": [], "entities": [{"text": "ConText", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.8317064642906189}, {"text": "resolve the assertion status of medical conditions", "start_pos": 109, "end_pos": 159, "type": "TASK", "confidence": 0.8182830895696368}]}, {"text": "Comparative analysis is performed between an implementation of ConText 5 and the ML approaches described in 3.2.", "labels": [], "entities": []}, {"text": "The ML systems were trained on 70% of the dataset (610 conditions).", "labels": [], "entities": [{"text": "ML", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.8644800782203674}]}, {"text": "The remaining 30% (262 conditions) was used as a test set for both ConText and the Machine Learning systems.", "labels": [], "entities": [{"text": "ConText", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.8910701870918274}]}, {"text": "For cross-validation experiments, ConText was evaluated against each test set fold.", "labels": [], "entities": []}, {"text": "For the Condition Attribution experiments training was performed on 675 conditions with testing performed on 290 conditions.", "labels": [], "entities": [{"text": "Condition Attribution", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.8876605927944183}]}, {"text": "In evaluating Temporal Grounding the training set comprised of 610 conditions with the test-set containing 262 conditions.", "labels": [], "entities": [{"text": "Temporal Grounding", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9660617709159851}]}, {"text": "This section reports results of the experiments outlined in Section 4.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Annotated Condition Attribution Occurrences", "labels": [], "entities": [{"text": "Annotated Condition Attribution Occurrences", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.6263981759548187}]}, {"text": " Table 2: Annotated Temporal Grounding Occurrences", "labels": [], "entities": []}, {"text": " Table 4: Selected feature-sets (f-score) using Cross- Validation for the Condition Attribution task", "labels": [], "entities": [{"text": "Condition Attribution", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.8201666474342346}]}, {"text": " Table 5: Temporal Grounding ConText Comparison", "labels": [], "entities": [{"text": "Temporal Grounding ConText Comparison", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.8063184320926666}]}]}