{"title": [{"text": "Bootstrapping Method for Chunk Alignment in Phrase Based SMT", "labels": [], "entities": [{"text": "Chunk Alignment", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8378255665302277}, {"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.8291174173355103}]}], "abstractContent": [{"text": "The processing of parallel corpus plays very crucial role for improving the overall performance in Phrase Based Statistical Machine Translation systems (PB-SMT).", "labels": [], "entities": [{"text": "Phrase Based Statistical Machine Translation", "start_pos": 99, "end_pos": 143, "type": "TASK", "confidence": 0.6087645053863525}]}, {"text": "In this paper the automatic alignments of different kind of chunks have been studied that boosts up the word alignment as well as the machine translation quality.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 104, "end_pos": 118, "type": "TASK", "confidence": 0.7312445044517517}, {"text": "machine translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.6465773731470108}]}, {"text": "Single-tokenization of Noun-noun MWEs, phrasal preposition (source side only) and reduplicated phrases (target side only) and the alignment of named entities and complex predicates provide the best SMT model for bootstrapping.", "labels": [], "entities": [{"text": "Noun-noun MWEs", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.4822906404733658}, {"text": "SMT", "start_pos": 198, "end_pos": 201, "type": "TASK", "confidence": 0.9881343245506287}]}, {"text": "Automatic bootstrap-ping on the alignment of various chunks makes significant gains over the previous best English-Bengali PB-SMT system.", "labels": [], "entities": []}, {"text": "The source chunks are translated into the target language using the PB-SMT system and the translated chunks are compared with the original target chunk.", "labels": [], "entities": []}, {"text": "The aligned chunks increase the size of the parallel corpus.", "labels": [], "entities": []}, {"text": "The processes are run in a bootstrapping manner until all the source chunks have been aligned with the target chunks or no new chunk alignment is identified by the bootstrapping process.", "labels": [], "entities": []}, {"text": "The proposed system achieves significant improvements (2.25 BLEU over the best System and 8.63 BLEU points absolute over the baseline system, 98.74% relative improvement over the baseline system) on an English-Bengali translation task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9985427856445312}, {"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9852112531661987}]}], "introductionContent": [{"text": "The objective of the present research work is to analyze effects of chunk alignment in EnglishBengali parallel corpus in a Phrase Based Statistical Machine Translation system.", "labels": [], "entities": [{"text": "chunk alignment", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.8215587437152863}, {"text": "EnglishBengali parallel corpus", "start_pos": 87, "end_pos": 117, "type": "DATASET", "confidence": 0.7900228103001913}, {"text": "Phrase Based Statistical Machine Translation", "start_pos": 123, "end_pos": 167, "type": "TASK", "confidence": 0.6311023831367493}]}, {"text": "The initial sentence level aligned English-Bengali corpus is cleaned and filtered using a semi-automatic process.", "labels": [], "entities": []}, {"text": "More effective chunk level alignments are carried out by bootstrapping on the training corpus to the PB-SMT system.", "labels": [], "entities": [{"text": "chunk level alignments", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.6714678804079691}]}, {"text": "The objective in the present task is to align the chunks in a bootstrapping manner using a Single tokenized MWE aligned SMT model and then modifying the model by inserting the aligned chunks to the parallel corpus after each iteration of the bootstrapping process, thereby enhancing the performance of the SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 306, "end_pos": 309, "type": "TASK", "confidence": 0.9855304956436157}]}, {"text": "In turn, this method deals with the many-to-many word alignments in the parallel corpus.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7366970181465149}]}, {"text": "Several types of MWEs like phrasal prepositions and Verbobject combinations are automatically identified on the source side while named-entities and complex predicates are identified on both sides of the parallel corpus.", "labels": [], "entities": []}, {"text": "In the target side only, identification of the Noun-noun MWEs and reduplicated phrases are carried out.", "labels": [], "entities": [{"text": "identification of the Noun-noun MWEs", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.6005379915237427}]}, {"text": "Simple rulebased and statistical approaches have been used to identify these MWEs.", "labels": [], "entities": []}, {"text": "The parallel corpus is modified by considering the MWEs as single tokens.", "labels": [], "entities": []}, {"text": "Source and target language NEs are aligned using a statistical transliteration technique.", "labels": [], "entities": []}, {"text": "These automatically aligned NEs and Complex predicates are treated as translation examples, i.e., as additional entries in the phrase table).", "labels": [], "entities": []}, {"text": "Using this augmented phrase table each individual source chunk is translated into the target chunk and then validated with the target chunks on the target side.", "labels": [], "entities": []}, {"text": "The validated source-target chunks are con-sidered as further parallel examples, which in effect are instances of atomic translation pairs to the parallel corpus.", "labels": [], "entities": []}, {"text": "This is a well-known practice in domain adaptation in SMT (.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7377873063087463}, {"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9214993715286255}]}, {"text": "The preprocessing of the parallel corpus results in improved MT quality in terms of automatic MT evaluation metrics.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9873960614204407}, {"text": "MT evaluation", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9153641164302826}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly elaborates the related work.", "labels": [], "entities": []}, {"text": "The PB-SMT system is described in Section 3.", "labels": [], "entities": []}, {"text": "The resources used in the present work are described in Section 4.", "labels": [], "entities": []}, {"text": "The various experiments carried out and the corresponding evaluation results have been reported in Section 5.", "labels": [], "entities": [{"text": "Section 5", "start_pos": 99, "end_pos": 108, "type": "DATASET", "confidence": 0.9189536869525909}]}, {"text": "The conclusions are drawn in Section 6 along with future work roadmap.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have randomly identified 500 sentences each for the development set and the test set from the initial parallel corpus.", "labels": [], "entities": []}, {"text": "The rest are considered as the training corpus.", "labels": [], "entities": []}, {"text": "The training corpus was filtered with the maximum allowable sentence length of 100 words and sentence length ratio of 1:2 (either way).", "labels": [], "entities": [{"text": "sentence length ratio", "start_pos": 93, "end_pos": 114, "type": "METRIC", "confidence": 0.6790777742862701}]}, {"text": "Finally the training corpus contains 13,176 sentences.", "labels": [], "entities": []}, {"text": "In addition to the target side of the parallel corpus, a monolingual Bengali corpus containing 293,207 words from the tourism domain was used for the target language model.", "labels": [], "entities": []}, {"text": "The experiments have been carried outwith different n-gram settings for the language model and the maximum phrase length and found that a 4-gram language model and a maximum phrase length of 4 produce the optimum baseline result.", "labels": [], "entities": []}, {"text": "The rest of the experiments have been carried out using these settings.", "labels": [], "entities": []}, {"text": "The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India.", "labels": [], "entities": []}, {"text": "The system continues with the various preprocessing of the corpus.", "labels": [], "entities": []}, {"text": "The hypothesis is that as more and more MWEs and chunks are identified and aligned properly, the system shows the improvement in the translation procedure.", "labels": [], "entities": []}, {"text": "shows the MWE statistics of the parallel training corpus.", "labels": [], "entities": []}, {"text": "It is observed from  Single tokenization of NEs and MWEs of any length on both the sides followed by GIZA++ alignment has given a huge impetus to system performance (6.38 BLEU points absolute, 73% relative improvement over the baseline).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 171, "end_pos": 175, "type": "METRIC", "confidence": 0.9986211061477661}]}, {"text": "In the source side, the system treats the phrasal prepositions, verb-object combinations and noun-noun compounds as a single token.", "labels": [], "entities": []}, {"text": "In the target side, single tokenization of reduplicated phrases and noun-noun compounds has been done followed by alignments using the GIZA++ tool.", "labels": [], "entities": []}, {"text": "From the observation of  The system performance improves when the alignment list of NEs and complex predicates as well as sentence level aligned chunk are incorporated in the baseline best system.", "labels": [], "entities": []}, {"text": "It achieves the BLEU score of 17.37 after the final iteration.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.9651363492012024}]}, {"text": "This is the best result obtained so far with respect to the baseline system (8.63 BLEU points absolute, 98.74% relative improvement in).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9893515706062317}]}, {"text": "It maybe observed from  Intrinsic evaluation of the chunk alignment could not be performed as gold-standard word alignment was not available.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.6734086275100708}]}, {"text": "Thus, extrinsic evaluation was carried out on the MT quality using the well known automatic MT evaluation metrics: BLEU () and NIST).", "labels": [], "entities": [{"text": "MT", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9876536726951599}, {"text": "MT evaluation", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.8880712389945984}, {"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9974748492240906}, {"text": "NIST", "start_pos": 127, "end_pos": 131, "type": "DATASET", "confidence": 0.8737649917602539}]}, {"text": "Bengali is a morphologically rich language and has relatively free phrase order.", "labels": [], "entities": []}, {"text": "Proper evaluation of the English-Bengali MT evaluation ideally requires multiple set of reference translations.", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9417241811752319}]}, {"text": "Moreover, the training set was smaller in size.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. MWE Statistics. (T -Total occurrence,  U -Unique, CP -complex predicates, NE - Named Entities)", "labels": [], "entities": [{"text": "MWE Statistics", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.7617849111557007}, {"text": "T -Total occurrence", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.813156321644783}]}, {"text": " Table 3. Evaluation results for different experi- mental setups. (The ' \u2020' marked systems produce  statistically significant improvements on BLEU  over the baseline system)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9976550340652466}]}]}