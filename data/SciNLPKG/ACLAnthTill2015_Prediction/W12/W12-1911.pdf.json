{"title": [{"text": "Unsupervised Dependency Parsing using Reducibility and Fertility features *", "labels": [], "entities": [{"text": "Fertility", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9384262561798096}]}], "abstractContent": [{"text": "This paper describes a system for unsuper-vised dependency parsing based on Gibbs sampling algorithm.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7152210623025894}]}, {"text": "The novel approach introduces a fertility model and reducibility model, which assumes that dependent words can be removed from a sentence without violating its syntactic correctness.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the traditional linguistic criteria for recognizing dependency relations (including their headdependent orientation) is that stepwise deletion of dependent elements within a sentence preserves its syntactic correctness.", "labels": [], "entities": []}, {"text": "If a word can be removed from a sentence without damaging it, then it is likely to be dependent on some other (still present) word.", "labels": [], "entities": []}, {"text": "Our approach allows to utilize information from very large corpora.", "labels": [], "entities": []}, {"text": "While the computationally demanding sampling procedure can be applied only on limited data, the unrepeated precomputation of * This research was supported by the grants GA201/09/H057 (Res Informatica), MSM0021620838, GAUK 116310, and by the European Commission's 7th Framework Program (FP7) under grant agreement n \u2022 247762 (FAUST).", "labels": [], "entities": [{"text": "GA201/09/H057", "start_pos": 169, "end_pos": 182, "type": "DATASET", "confidence": 0.9331008195877075}, {"text": "GAUK 116310", "start_pos": 217, "end_pos": 228, "type": "DATASET", "confidence": 0.9114510118961334}, {"text": "European Commission's 7th Framework Program (FP7)", "start_pos": 241, "end_pos": 290, "type": "DATASET", "confidence": 0.6442468166351318}, {"text": "FAUST", "start_pos": 325, "end_pos": 330, "type": "DATASET", "confidence": 0.5080882906913757}]}, {"text": "Of course, all the above works had to respond to the notorious fact that there are many language phenomena precluding the ideal (word by word) sentence reducibility (e.g. in the case of prepositional groups, or in the case of subjects in English finite clauses).", "labels": [], "entities": []}, {"text": "However, we borrow only the very core of the reducibility idea.", "labels": [], "entities": []}, {"text": "statistics for reducibility estimates can easily exploit much larger data.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our parser on 10 treebanks included in the WILS shared-task data.", "labels": [], "entities": [{"text": "WILS shared-task data", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.8467502593994141}]}, {"text": "Similarly to some previous papers on unsupervised parsing  English development data for checking functionality of the individual models and for optimizing hyperparameter values.", "labels": [], "entities": []}, {"text": "The best configuration of the parser achieved on English was then used for parsing all other languages.", "labels": [], "entities": []}, {"text": "This simulates the situation in which we have only one treebank (English) on which we can tune our parser and we want to parse other languages for which we have no manually annotated treebanks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Wikipedia texts statistics", "labels": [], "entities": [{"text": "Wikipedia texts", "start_pos": 10, "end_pos": 25, "type": "DATASET", "confidence": 0.9268204569816589}]}, {"text": " Table 3: Directed attachment scores on the WILS testing data (all sentences). Punctuation was excluded. Comparison  with simple baselines and the given baseline system", "labels": [], "entities": [{"text": "WILS testing data", "start_pos": 44, "end_pos": 61, "type": "DATASET", "confidence": 0.9230530261993408}, {"text": "Punctuation", "start_pos": 79, "end_pos": 90, "type": "METRIC", "confidence": 0.9252361059188843}]}]}