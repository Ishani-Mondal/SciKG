{"title": [{"text": "Combining the Sparsity and Unambiguity Biases for Grammar Induction", "labels": [], "entities": [{"text": "Sparsity", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9456777572631836}, {"text": "Grammar Induction", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7421739101409912}]}], "abstractContent": [{"text": "In this paper we describe our participating system for the dependency induction track of the PASCAL Challenge on Grammar Induction.", "labels": [], "entities": [{"text": "dependency induction", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7717660963535309}, {"text": "PASCAL Challenge on Grammar Induction", "start_pos": 93, "end_pos": 130, "type": "TASK", "confidence": 0.5888631761074066}]}, {"text": "Our system incorporates two types of induc-tive biases: the sparsity bias and the unambi-guity bias.", "labels": [], "entities": [{"text": "sparsity bias", "start_pos": 60, "end_pos": 73, "type": "METRIC", "confidence": 0.9519332349300385}]}, {"text": "The sparsity bias favors a grammar with fewer grammar rules.", "labels": [], "entities": [{"text": "sparsity", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9338344931602478}]}, {"text": "The unambi-guity bias favors a grammar that leads to un-ambiguous parses, which is motivated by the observation that natural language is remarkably unambiguous in the sense that the number of plausible parses of a natural language sentence is very small.", "labels": [], "entities": []}, {"text": "We introduce our approach to combining these two types of biases and discuss the system implementation.", "labels": [], "entities": []}, {"text": "Our experiments show that both types of inductive biases are beneficial to grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.8356049060821533}]}], "introductionContent": [{"text": "Grammar induction refers to the induction of a formal grammar from a corpus of unannotated sentences.", "labels": [], "entities": [{"text": "Grammar induction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7515856921672821}]}, {"text": "There has been significant progress over the past decade in the research of natural language grammar induction.", "labels": [], "entities": [{"text": "natural language grammar induction", "start_pos": 76, "end_pos": 110, "type": "TASK", "confidence": 0.7379941418766975}]}, {"text": "A variety of approaches and techniques have been proposed, most of which are designed to induce probabilistic dependency grammars.", "labels": [], "entities": []}, {"text": "The PASCAL Challenge on Grammar Induction aims to provide a thorough evaluation of approaches to natural language grammar induction.", "labels": [], "entities": [{"text": "PASCAL Challenge on Grammar Induction", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.5892706632614135}, {"text": "natural language grammar induction", "start_pos": 97, "end_pos": 131, "type": "TASK", "confidence": 0.6786337271332741}]}, {"text": "The challenge includes three tracks: inducing dependency structures using the gold standard partof-speech tags, inducing both dependency structures and part-of-speech tags directly from text, and an open-resource track which allows other external resources to be used.", "labels": [], "entities": []}, {"text": "Ten corpora of nine different languages are used in the challenge:), Basque (), Czech (), Danish (Buch-,), English WSJ, English CHILDES (), Portuguese (), Slovene (, and Swedish ().", "labels": [], "entities": [{"text": "CHILDES", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.8479105234146118}]}, {"text": "For each corpus, a large set of unannotated sentences are provided as the training data, along with a small set of annotated sentences as the development data; the predictions on the unannotated test data submitted by challenge participants are evaluated against the gold standard annotations.", "labels": [], "entities": []}, {"text": "We participate in the track of inducing dependency structures from gold standard part-of-speech tags.", "labels": [], "entities": []}, {"text": "Our system incorporates two types of inductive biases in learning dependency grammars: the sparsity bias and the unambiguity bias.", "labels": [], "entities": []}, {"text": "The sparsity bias favors a grammar with fewer grammar rules.", "labels": [], "entities": [{"text": "sparsity", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9338344931602478}]}, {"text": "We employ two different approaches to inducing sparsity: Dirichlet priors over grammar rule probabilities and an approach based on posterior regularization ( ).", "labels": [], "entities": []}, {"text": "The unambiguity bias favors a grammar that leads to unambiguous parses, which is motivated by the observation that natural language is remarkably unambiguous in the sense that the number of plausible parses of a natural language sentence is very small.", "labels": [], "entities": []}, {"text": "To induce unambiguity in the learned grammar we propose an approach named unambiguity regularization based on the posterior regularization framework ( . To combine Dirichlet priors with unam-biguity regularization, we derive a mean-field variational inference algorithm.", "labels": [], "entities": []}, {"text": "To combine the sparsityinducing posterior regularization approach with unambiguity regularization, we employ a simplistic approach that optimizes the two regularization terms separately.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the two approaches that we employ to induce sparsity.", "labels": [], "entities": []}, {"text": "Section 3 introduces the unambiguity bias and the unambiguity regularization approach.", "labels": [], "entities": []}, {"text": "Section 4 discusses how we combine the sparsity bias with the unambiguity bias.", "labels": [], "entities": []}, {"text": "Section 5 provides details of our implementation and training procedure.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system was built on top of the PR-Dep-Parsing package . We implemented both approaches introduced in section 4, i.e., unambiguity regularization with Dirichlet priors and combined posterior regularization of sparsity and unambiguity.", "labels": [], "entities": []}, {"text": "For the latter, we did not implement the \u03c3 u \u2265 1 case and the annealing of \u03c3 u because of time constraint.", "labels": [], "entities": []}, {"text": "We preprocessed the corpora to remove all the punctuations as denoted by the universal POS tags.", "labels": [], "entities": []}, {"text": "One exception is that for the English WSJ corpus we did not remove the $ symbol because we found that removing it significantly decreased the accuracy of the learned grammar.", "labels": [], "entities": [{"text": "English WSJ corpus", "start_pos": 30, "end_pos": 48, "type": "DATASET", "confidence": 0.6516489386558533}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9990311861038208}]}, {"text": "We combined the provided training, development and test set as our training set.", "labels": [], "entities": []}, {"text": "We trained our system on the fine POS tags except for the Dutch corpus.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.713868647813797}, {"text": "Dutch corpus", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9423945844173431}]}, {"text": "In the Dutch corpus, the fine POS tags are the same as the coarse POS tags except that each multi-word unit is annotated with the concatenation of the POS tags of all the component words, making the training data for such tags extremely sparse.", "labels": [], "entities": [{"text": "Dutch corpus", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.885047972202301}]}, {"text": "So we chose to use the coarse POS tags for the Dutch corpus.", "labels": [], "entities": [{"text": "Dutch corpus", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.9494070410728455}]}, {"text": "We employed the informed initialization proposed in () and ran our two approaches on the training set.", "labels": [], "entities": []}, {"text": "We tuned the param-1 Available at http://code.google.com/p/ pr-toolkit/ eters by coordinate ascent on the development set.", "labels": [], "entities": []}, {"text": "The parameters that we tuned include the maximal length of sentences used in training, the valence and back-off strength of the E-DMV model, the hyperparameter \u03b1 of Dirichlet priors, the type (PR-S or PR-AS) and strength \u03c3 s of sparsity-inducing posterior regularization, and the strength \u03c3 u of unambiguity regularization.", "labels": [], "entities": []}, {"text": "Sparsity-inducing posterior regularization has a high computational cost.", "labels": [], "entities": [{"text": "posterior regularization", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.5368235558271408}]}, {"text": "Consequently, we were notable to run our second approach on the English CHILDES corpus and the Czech corpus, and performed relatively limited parameter tuning of the second approach on the other eight corpora.", "labels": [], "entities": [{"text": "English CHILDES corpus", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.87038254737854}, {"text": "Czech corpus", "start_pos": 95, "end_pos": 107, "type": "DATASET", "confidence": 0.8590547144412994}]}, {"text": "shows, for each corpus, the approach and the parameters that we found to perform the best on the development set and were hence used to learn the final grammar that produced the submitted predictions on the test set.", "labels": [], "entities": []}, {"text": "Each of our two approaches was found to be the better approach for five of the ten corpora.", "labels": [], "entities": []}, {"text": "The sparsity bias was found to be beneficial (i.e., \u03b1 < 1 if Dirichlet priors were used, or \u03c3 s > 0 if sparsity-inducing posterior regularization was used) for six of the ten corpora.", "labels": [], "entities": []}, {"text": "The unambiguity bias was found to be beneficial (i.e., \u03c3 u > 0) for seven of the ten corpora.", "labels": [], "entities": []}, {"text": "This implies the usefulness of both types of inductive biases in grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7643400430679321}]}, {"text": "For only one corpus, the English CHILDES corpus, neither the sparsity bias nor the unambiguity bias was found to be beneficial, probably because this corpus is a collection of child language and the corresponding grammar might be less sparse and more ambiguous than adult grammars.", "labels": [], "entities": [{"text": "English CHILDES corpus", "start_pos": 25, "end_pos": 47, "type": "DATASET", "confidence": 0.7683537801106771}]}], "tableCaptions": []}