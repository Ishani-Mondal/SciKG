{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Utilizing Cumulative Logit Models and Human Computation on Automated Speech Assessment", "labels": [], "entities": [{"text": "Automated Speech Assessment", "start_pos": 118, "end_pos": 145, "type": "TASK", "confidence": 0.6492554446061453}]}], "abstractContent": [{"text": "We report two new approaches for building scoring models used by automated speech scoring systems.", "labels": [], "entities": []}, {"text": "First, we introduce the Cumulative Logit Model (CLM), which has been widely used in modeling categorical outcomes in statistics.", "labels": [], "entities": []}, {"text": "On a large set of responses to an English proficiency test, we systematically compare the CLM with two other scoring models that have been widely used, i.e., linear regression and decision trees.", "labels": [], "entities": []}, {"text": "Our experiments suggest that the CLM has advantages in its scoring performance and its robust-ness to limited-sized training data.", "labels": [], "entities": []}, {"text": "Second, we propose a novel way to utilize human rating processes in automated speech scoring.", "labels": [], "entities": [{"text": "automated speech scoring", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.6457217435042063}]}, {"text": "Applying accurate human ratings on a small set of responses can improve the whole scoring system's performance while meeting cost and score-reporting time requirements.", "labels": [], "entities": []}, {"text": "We find that the scoring difficulty of each speech response , which could be modeled by the degree to which it challenged human raters, could provide away to select an optimal set of responses for the application of human scoring.", "labels": [], "entities": []}, {"text": "Ina simulation, we show that focusing on challenging responses can achieve a larger scoring performance improvement than simply applying human scoring on the same number of randomly selected responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated assessment is a process by which computer algorithms are used to score test-taker inputs, which could be essays, short-text descriptions, readaloud sentences, or spontaneous speech responses to open-end questions.", "labels": [], "entities": [{"text": "Automated assessment", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7251898646354675}]}, {"text": "Until recently, human scoring has been predominantly used for scoring these types of inputs.", "labels": [], "entities": []}, {"text": "Several limitations of the human scoring process have been identified in previous research).", "labels": [], "entities": [{"text": "human scoring process", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.6118058363596598}]}, {"text": "First, the human scoring process is influenced by many hidden factors, such as human raters' mood and fatigue conditions.", "labels": [], "entities": []}, {"text": "In addition, human raters may not strictly follow the rubrics designed to guide the scoring process in their practical scoring sessions.", "labels": [], "entities": []}, {"text": "Furthermore, human rating is also an expensive and slow process, especially for large-scale tests.", "labels": [], "entities": [{"text": "human rating", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.6944807469844818}]}, {"text": "There has been an increasing number of studies concerning the use of speech processing and natural language processing (NLP) technologies to automatically score spoken responses.", "labels": [], "entities": []}, {"text": "In these machine scoring systems, a set of features related to multiple aspects of human speaking capabilities, e.g., fluency, pronunciation, intonation, vocabulary usage, grammatical accuracy, and content, is extracted automatically.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.8677651286125183}]}, {"text": "Then, statistical models, such as the widely used linear regression models, classification and regression trees (CART), are trained based on human ratings and these features.", "labels": [], "entities": [{"text": "classification and regression trees (CART)", "start_pos": 76, "end_pos": 118, "type": "TASK", "confidence": 0.6458756668227059}]}, {"text": "For new responses, the trained statistical models are applied to predict machine scores.", "labels": [], "entities": []}, {"text": "The performance of current automated speech scoring systems, especially for spontaneous speech responses, still lags markedly behind the performance of human scoring.", "labels": [], "entities": []}, {"text": "To improve the performance of automated speech scoring, an increasing number of research studies have been undertaken.", "labels": [], "entities": [{"text": "automated speech scoring", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.6223427851994833}]}, {"text": "However, these studies have mostly focused on exploring additional speech features, not on building alternative scoring models.", "labels": [], "entities": []}, {"text": "Hence, in this paper, we will report on two new lines of research focusing on the scoring model part of au-tomated speech scoring systems.", "labels": [], "entities": []}, {"text": "In particular, we will introduce the Cumulative Logit Model (CLM), which is not widely used in NLP, and compare it systematically with other widely-used modeling methods.", "labels": [], "entities": []}, {"text": "In addition, we will propose a hybrid scoring system inspired by the recent trend of involving human computation in machine learning tasks, which consists of both human scoring and machine scoring to achieve a balance of scoring accuracy, speed, and cost.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 229, "end_pos": 237, "type": "METRIC", "confidence": 0.989085853099823}, {"text": "speed", "start_pos": 239, "end_pos": 244, "type": "METRIC", "confidence": 0.960635781288147}]}, {"text": "The remainder of the paper is organized as follows: Section 2 reviews the previous research efforts; Section 3 describes both the test from which our experimental data were collected and the automated speech scoring system; Section 4 introduces the Cumulative Logit Model (CLM) and reports a systematic comparison with two other widely used modeling approaches; Section 5 proposes using both human scoring and machine scoring to achieve a trade-off between scoring accuracy, speed, and cost, and shows a simulation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 465, "end_pos": 473, "type": "METRIC", "confidence": 0.9747026562690735}, {"text": "speed", "start_pos": 475, "end_pos": 480, "type": "METRIC", "confidence": 0.9582513570785522}]}, {"text": "Finally, Section 6 concludes the paper and describes our plans for future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 describes the data size and final score  distribution of the four score levels.", "labels": [], "entities": []}]}