{"title": [{"text": "Rel-grams: A Probabilistic Model of Relations in Text", "labels": [], "entities": [{"text": "Rel-grams", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9345090985298157}]}], "abstractContent": [{"text": "We introduce the Rel-grams language model, which is analogous to an n-grams model, but is computed over relations rather than over words.", "labels": [], "entities": []}, {"text": "The model encodes the conditional probability of observing a relational tuple R, given that R was observed in a window of prior relational tuples.", "labels": [], "entities": []}, {"text": "We build a database of Rel-grams co-occurence statistics from Re-Verb extractions over 1.8M news wire documents and show that a graphical model based on these statistics is useful for automatically discovering event templates.", "labels": [], "entities": []}, {"text": "We make this database freely available and hope it will prove a useful resource fora wide variety of NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Google N-grams corpus) has enjoyed immense popularity in NLP and has proven effective fora wide range of applications (.", "labels": [], "entities": [{"text": "Google N-grams corpus", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.6415160993734995}]}, {"text": "However, it is a lexical resource and provides only local, sentence-level information.", "labels": [], "entities": []}, {"text": "It does not capture the flow of semantic content within a larger document or even in neighboring sentences.", "labels": [], "entities": []}, {"text": "We introduce the novel Rel-grams database 1 containing corpus statistics on frequently occurring sequences of open-domain relational tuples.", "labels": [], "entities": [{"text": "Rel-grams database 1", "start_pos": 23, "end_pos": 43, "type": "DATASET", "confidence": 0.9066997170448303}]}, {"text": "Relgrams is analogous to n-grams except that instead of word sequences within a sentence, it tabulates relation sequences within a document.", "labels": [], "entities": []}, {"text": "Thus, we expect Rel-grams to model semantic and discourselevel regularities in the English language.", "labels": [], "entities": []}, {"text": "We have compiled a Rel-grams database from 1.8 million New York Times articles from the Gigaword corpus).", "labels": [], "entities": [{"text": "Rel-grams database from 1.8 million New York Times articles from the Gigaword corpus", "start_pos": 19, "end_pos": 103, "type": "DATASET", "confidence": 0.8320995110731858}]}, {"text": "The implementation is linear in the size of the corpus and easily scaled to far larger corpora.", "labels": [], "entities": []}, {"text": "Rel-grams database facilitates several tasks including: Relational Language Models: We define a relational language model, which encodes the probability of relational tuple R, having observed R in the k previous tuples.", "labels": [], "entities": []}, {"text": "This can be used for discourse coherence, sentence order in summarization, etc.", "labels": [], "entities": []}, {"text": "Event Template Construction: We cluster commonly co-occuring relational tuples as in and use them as the basis for open event templates (see).", "labels": [], "entities": [{"text": "Event Template Construction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7223319113254547}]}, {"text": "Our work builds on and generalizes earlier efforts by.", "labels": [], "entities": []}, {"text": "Expectation-driven Extraction: The probabilities output by the relational language model maybe 101 used to inform an information extractor.", "labels": [], "entities": [{"text": "information extractor", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.7104411423206329}]}, {"text": "As has been the case with n-gram models and resources such as DIRT (), we expect the community to suggest additional applications leveraging this large scale, public resource.", "labels": [], "entities": []}, {"text": "An intriguing possibility is to use Rel-grams in document-level extraction or summarization to assess the discourse coherence of alternate hypotheses in a decoding step in much the same way that n-grams have been used in speech or statistical MT.", "labels": [], "entities": [{"text": "document-level extraction", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.7083781808614731}, {"text": "summarization", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.8715919256210327}, {"text": "MT", "start_pos": 243, "end_pos": 245, "type": "TASK", "confidence": 0.7926632165908813}]}], "datasetContent": [{"text": "First we evaluated the semantic cohesiveness of a random sample of the 50 clusters with highest connectivity.", "labels": [], "entities": []}, {"text": "We found that about 89% of the nodes in each cluster were semantically related to the implicit topic of the cluster.", "labels": [], "entities": []}, {"text": "Next, we evaluate Rel-clusters with an independent gold standard.", "labels": [], "entities": []}, {"text": "We compare against MUC-4 templates for terrorist events: bombing, attack, kidnapping, and arson.", "labels": [], "entities": [{"text": "MUC-4", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.8162357807159424}]}, {"text": "MUC-4 templates have six primary extraction slots -perpetrator, victim, physical target (omitted for kidnapping), instrument (omitted for kidnapping and arson), date, and location.", "labels": [], "entities": [{"text": "MUC-4 templates", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.88148432970047}]}, {"text": "To obtain Rel-clusters for these four terrorist event types, we look for clusters that include the seed extractions: (bomb; explode; ?), (attack; kill; ?), (?; kidnap; ?), (?; set fire; ?).", "labels": [], "entities": []}, {"text": "We examine the argument values for these nodes to see whether the argument type corresponds to a slot in the MUC-4 event template and use it to compute recall.", "labels": [], "entities": [{"text": "MUC-4 event template", "start_pos": 109, "end_pos": 129, "type": "DATASET", "confidence": 0.7858172059059143}, {"text": "recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9924037456512451}]}, {"text": "shows the performance our Rel-clusters and compares it with the MUC-4 template slots discovered by an unsupervised template extraction approach (Chambers and Jurafsky, 2011).", "labels": [], "entities": []}, {"text": "We find that Rel-clusters were able to find anode with arguments for all six slots for bombing and attack event types.", "labels": [], "entities": []}, {"text": "It had more difficulty with kidnapping and arson, missing the date and location for kidnapping and missing the victim and location for arson.", "labels": [], "entities": []}, {"text": "Chambers missed one victim and did not include date or location for any template.", "labels": [], "entities": []}, {"text": "We view these as promising preliminary results but do not draw any strong conclusions on the comparison with Chambers and Jurafsky, as unlike our system, theirs was designed to produce not only templates, but also extractors for the slots.", "labels": [], "entities": []}, {"text": "In the future, we will automatically determine semantic types for the slots.", "labels": [], "entities": []}, {"text": "We will also split slots that have a mixture of semantic types, as in the example of the arguments {percent, year} for the extraction (sale; increase; ?) in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Both Rel-clusters and Chambers system dis-", "labels": [], "entities": [{"text": "Rel-clusters", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.8084629774093628}]}]}