{"title": [{"text": "Adapting Conventional Chinese Word Segmenter for Segmenting Micro-blog Text: Combining Rule-based and Statistic-based Approaches", "labels": [], "entities": [{"text": "Adapting Conventional Chinese Word Segmenter", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8344489455223083}]}], "abstractContent": [{"text": "We describe two adaptation strategies which are used in our word segmenta-tion system in participating the Micro-blog word segmentation bake-off: Domain invariant information is extracted from the in-domain unlabelled corpus, and is incorporated as supplementary features to conventional word segmenter based on Conditional Random Field (CRF), we call it statistic-based adaptation.", "labels": [], "entities": [{"text": "Micro-blog word segmentation bake-off", "start_pos": 107, "end_pos": 144, "type": "TASK", "confidence": 0.7800872325897217}]}, {"text": "Some heuristic rules are further used to post-process the word segmentation result in order to better handle the characters in emoticons, name entities and special punctuation patterns which extensively exist in micro-blog text, and we call it rule-based adaptation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7186946868896484}, {"text": "rule-based adaptation", "start_pos": 244, "end_pos": 265, "type": "TASK", "confidence": 0.7401178777217865}]}, {"text": "Experimentally , using both adaptation strategies , our system achieved 92.46 points of F-score, compared with 88.73 points of F-score of the unadapted CRF word seg-menter on the pre-released development data.", "labels": [], "entities": [{"text": "F-score", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9996073842048645}, {"text": "F-score", "start_pos": 127, "end_pos": 134, "type": "METRIC", "confidence": 0.9982228875160217}]}, {"text": "Our system achieved 92.51 points of F-score on the final test data.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9993988275527954}]}], "introductionContent": [{"text": "Recent years have witnessed the great development of Chinese word segmentation (CWS) techniques.", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.7594032535950342}]}, {"text": "Among various approaches, character labelling via Conditional Random Field (CRF) modelling has become a prevailing technique (), due to its good performance in OOV words recognition and low development cost.", "labels": [], "entities": [{"text": "character labelling", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8662695288658142}, {"text": "OOV words recognition", "start_pos": 160, "end_pos": 181, "type": "TASK", "confidence": 0.7985155582427979}]}, {"text": "Given a large-scale corpus with human annotation, the only issue the developer need to focus on is to design an expressive set of feature templates which captures the various characteristics of word segmentation to achieve better performance.", "labels": [], "entities": []}, {"text": "The demand for Chinese micro-blog data mining has been unprecedentedly increased, owing to the growing number of the Chinese micro-blog users in the past few years.", "labels": [], "entities": [{"text": "Chinese micro-blog data mining", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.5469323694705963}]}, {"text": "In these tasks, Chinese word segmentation plays an important role in correctly understanding the micro-blog text.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.607767273982366}]}, {"text": "Chinese word segment on the micro-blog text is a challenging task.", "labels": [], "entities": [{"text": "Chinese word segment", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.5348553558190664}]}, {"text": "On one hand, it is difficult to obtain large-scale labelled corpora of micro-blog domain for CRF-based learning, and the only labelled corpus we have is People's Daily corpus (PDC) which comes from the News domain; on the other, compared with the News text, the micro-blog text contains a large number of new words, name entities, URLs, emoticons (such as \":)\"), punctuation patterns (such as \"....\"), as well as structured symbols representing conversation (\"@\"), repost(\"//@\"), and topic (\"#...#\") etc.", "labels": [], "entities": [{"text": "CRF-based learning", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.8957245945930481}, {"text": "People's Daily corpus (PDC)", "start_pos": 153, "end_pos": 180, "type": "DATASET", "confidence": 0.8687860539981297}]}, {"text": "The word distribution and usage of micro-blog text are also much more free than the News text, making things more difficult.", "labels": [], "entities": [{"text": "News text", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.9110080897808075}]}, {"text": "In this paper, we adapt the conventional Chinese word segmenter which is trained on out-ofdomain (News domain) labelled corpus using CRF to segment in-domain micro-blog text, without using any information from the labelled in-domain data.", "labels": [], "entities": [{"text": "News domain) labelled corpus", "start_pos": 98, "end_pos": 126, "type": "DATASET", "confidence": 0.8857490658760071}]}, {"text": "We use two adaptation strategies: the first is statistic-based adaptation.", "labels": [], "entities": [{"text": "statistic-based adaptation", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.7678597271442413}]}, {"text": "We incorporate domain invariant information extracted from the indomain unlabelled corpus as supplementary features to the conventional CRF segmenter, in order to enhance its ability of recognizing domainspecific words.", "labels": [], "entities": []}, {"text": "The unlabelled corpus can be conveniently crawled from the web; the other is rulebased adaptation.", "labels": [], "entities": [{"text": "rulebased adaptation", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.6420638561248779}]}, {"text": "We proposed some heuristic rules to further post-process the word segmentation result in order to enhance to better handle the characters in emoticons, name entities and special punctuation patterns which extensively exist in micro-blog text.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7105985134840012}]}, {"text": "Experimentally, using both adaptation strategies, our system achieved 92.46 points of F-score, compared with 88.73 points of F-score of the unadapted CRF word segmenter on the pre-released development data.", "labels": [], "entities": [{"text": "F-score", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.999512791633606}, {"text": "F-score", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.9977484345436096}, {"text": "CRF word segmenter", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.592778205871582}]}, {"text": "Our system achieved 92.51 points of F-score on the final test data.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9993988275527954}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 5: Results of our systems on development  data, measured in P: precision, R: recall, and F:  F-score. RB: rule-base adaptation. WF0: word- based feature using dictionary extracted from data  (a). WF1: word-based feature using dictionary ex- tract from both data (a) and data (b). MF: metric- based feature.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9985511898994446}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.984774649143219}, {"text": "F-score", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9672215580940247}]}, {"text": " Table 6: Comparison of our system and the best system in the Bake-off on the final test data. CS: the  number of correct sentences. CS(%): percent of the number of correct sentences.", "labels": [], "entities": [{"text": "Bake-off", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.37099558115005493}, {"text": "CS", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.9723109602928162}, {"text": "CS", "start_pos": 133, "end_pos": 135, "type": "METRIC", "confidence": 0.9613802433013916}]}]}