{"title": [{"text": "The Structure and Generality of Spoken Route Instructions", "labels": [], "entities": [{"text": "Spoken Route Instructions", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.6396025121212006}]}], "abstractContent": [{"text": "A robust system that understands route instructions should be able to process instructions generated naturally by humans.", "labels": [], "entities": []}, {"text": "Also desirable would be the ability to handle repairs and other modifications to existing instructions.", "labels": [], "entities": []}, {"text": "To this end, we collected a corpus of spoken instructions (and modified instructions) produced by subjects provided with an origin and a destination.", "labels": [], "entities": []}, {"text": "We found that instructions could be classified into four categories, depending on their intent such as imperative, feedback, or meta comment.", "labels": [], "entities": []}, {"text": "We asked a different set of subjects to follow these instructions to determine the usefulness and comprehensibility of individual instructions.", "labels": [], "entities": []}, {"text": "Finally , we constructed a semantic grammar and evaluated its coverage.", "labels": [], "entities": []}, {"text": "To determine whether instruction-giving forms a predictable sub-language, we tested the grammar on three corpora collected by others and determined that this was largely the case.", "labels": [], "entities": []}, {"text": "Our work suggests that predictable sub-languages may exist for well-defined tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generating and interpreting instructions is a topic of enduring interest.", "labels": [], "entities": [{"text": "Generating and interpreting instructions", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7300251573324203}]}, {"text": "Cognitive psychologists have examined how people perceive spatial entities and structure route instructions ().", "labels": [], "entities": []}, {"text": "Linguists and others have investigated how people articulate route instructions in conversation with people or agents (.", "labels": [], "entities": []}, {"text": "Artificial intelligence researchers have shown that under supervised conditions autonomous agents can learn to interpret route instructions (.", "labels": [], "entities": []}, {"text": "While the subject has been approached from different perspectives, it has been generally held that the language of directions is mostly limited and only parts of the vocabulary (such as location names) will vary from case to case.", "labels": [], "entities": []}, {"text": "We are interested in being able to interpret natural directions, as might be given to a robot, and generating corresponding trajectory.", "labels": [], "entities": []}, {"text": "But natural directions contain different types of information, some (more-or-less) easily interpreted (e.g., \"go to the end of the hall\") while others seem daunting (e.g., \"walk past the abstract mural with birds\").", "labels": [], "entities": []}, {"text": "So the question might actually be \"is there enough interpretable data inhuman directions to support planning a usable trajectory?\".", "labels": [], "entities": []}, {"text": "The language of instructions contains a variety of relevant propositions: a preface to a route, an imperative statement, or a description of a landmark.", "labels": [], "entities": []}, {"text": "Previous work has proposed both coarse and fine-grained instruction taxonomies.", "labels": [], "entities": []}, {"text": "() proposed a taxonomy of 15 primitive categories in a concrete \"action\" framework.", "labels": [], "entities": []}, {"text": "In contrast, () suggested a five-way categorization based on cognitive properties of instructions.", "labels": [], "entities": []}, {"text": "Instructions vary greatly and can include superfluous detail.", "labels": [], "entities": []}, {"text": "found that when people were asked to read and assess a set of instructions some of the instructions were deemed unnecessary and could be discarded.", "labels": [], "entities": []}, {"text": "There is some evidence () that only the mention of significant landmarks along the route leads to better-quality instructions.", "labels": [], "entities": []}, {"text": "Computational (rather than descriptive) approaches to this problem include: using sequence labeling approach to capture spatial relations, landmarks, and action verbs (, generating a frame structure for an instruction), or using statistical machine translation techniques to translate instructions into actions).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 229, "end_pos": 260, "type": "TASK", "confidence": 0.681022047996521}]}, {"text": "We describe anew instructions corpus, its analysis in terms of a taxonomy suitable for automated understanding and a verification that the instructions are in fact usable by humans.", "labels": [], "entities": []}, {"text": "With a view to automating understanding, we also constructed a grammar capable of processing this language, and show that it provides good coverage for both our corpus and three other corpora () This paper is organized as following: Section 2 describes the corpus collection study.", "labels": [], "entities": [{"text": "corpus collection", "start_pos": 257, "end_pos": 274, "type": "TASK", "confidence": 0.7067915499210358}]}, {"text": "Then in Section 3, we discuss the taxonomy of route instructions.", "labels": [], "entities": []}, {"text": "Section 4 focuses on which categories are important for navigation.", "labels": [], "entities": [{"text": "navigation", "start_pos": 56, "end_pos": 66, "type": "TASK", "confidence": 0.9819779992103577}]}, {"text": "In Section 5, we report our results and error analysis on parsing instructions from our corpus and three other corpora containing route instructions, followed by lessons learned and future work.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 40, "end_pos": 54, "type": "METRIC", "confidence": 0.9148682653903961}]}], "datasetContent": [{"text": "The Navagati (NAV) corpus instructions were divided into training set (henceforth abbreviated as NAV-train) and testing set (abbreviated as NAV-test) of size 654 (of 6 subjects) and 280 (of 3 subjects).", "labels": [], "entities": []}, {"text": "The training set was used to create a grammar based on the taxonomy described in Section 3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Simple vs Repair Scenario", "labels": [], "entities": [{"text": "Simple vs Repair Scenario", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6842577680945396}]}, {"text": " Table 2: Perplexity of Simple/Repair Language Models", "labels": [], "entities": []}, {"text": " Table 3.  For instance, \"You want to take a right\" belongs to the  Imperative category. \"You will see a black door\" is an  Advisory instruction about the surroundings. \"You are on  the first floor\" denotes Grounding. \"Your destination is  located in another building and you will walk across three  buildings in this route\" gives an overview of the route, a  Meta Comment. From", "labels": [], "entities": []}, {"text": " Table 5: Higher level and Leaf node Concepts in Grammar", "labels": [], "entities": []}, {"text": " Table 7: Error Analysis for Incomplete and Misparsed instruc- tions", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9263168573379517}]}]}