{"title": [{"text": "Parsing TCT with a Coarse-to-fine Approach", "labels": [], "entities": [{"text": "Parsing TCT", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8112694621086121}, {"text": "Approach", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9328125715255737}]}], "abstractContent": [{"text": "A key observation is that concept compound constituent labels are detrimental to parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 81, "end_pos": 88, "type": "TASK", "confidence": 0.9669179916381836}]}, {"text": "We use a PCFG parsing algorithm that uses a multilevel coarse-to-fine scheme.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.7601998448371887}]}, {"text": "Our approach requires a sequence of nested partitions or equivalence classes of the PCFG nonterminals, where the nonterminals of each PCFG are clusters of nonterminals of the finer PCFG.", "labels": [], "entities": []}, {"text": "We use the results of parsing at a coarser level to prune the next finer level.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9690003395080566}]}, {"text": "The coarse-to-fine method use hierarchical projections for incremental pruning.", "labels": [], "entities": []}, {"text": "We present experiments which show that parsing with hierarchical state-splitting is fast and accurate on Tsinghua Chinese Treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.96698397397995}, {"text": "Tsinghua Chinese Treebank", "start_pos": 105, "end_pos": 130, "type": "DATASET", "confidence": 0.7259433468182882}]}, {"text": "In addition, we propose a multiple-model method that adds concept compound labels to the output of the simple PCFG model and gains higher bracketing recall from the simple model.", "labels": [], "entities": [{"text": "recall", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.9437435269355774}]}, {"text": "This scheme can be implemented by training two models on different labeling styles.", "labels": [], "entities": []}], "introductionContent": [{"text": "The peculiarity of the annotation of this released edition of TCT is that the tree structure is very compact, where there are no unary productions except root nodes and leaf nodes.", "labels": [], "entities": []}, {"text": "A major observation is that parser on treebank with concept compound constituent labels performs worse than without concept compound constituent.", "labels": [], "entities": []}, {"text": "The average crossing is 4% lower in presence of concept compound constituent labels.", "labels": [], "entities": []}, {"text": "Since all phrases have a clausal and phrasal constituent label, while only a fraction have concept compound constituent label.", "labels": [], "entities": []}, {"text": "We can regard a phrase label with both clausal and phrasal constituent label and concept compound constituent label as a subsymbol of the clausal and phrasal constituent label merely.", "labels": [], "entities": []}, {"text": "The coarse categories in these grammars can be regarded as clusters or equivalence classes of the fine nonterminal categories.", "labels": [], "entities": []}, {"text": "We require that the partition of the nonterminals defined by the equivalence classes at finer level be a refinement of the partition defined at coarser level.", "labels": [], "entities": []}, {"text": "This means that each nonterminal category at finer level is mapped to a unique nonterminal category at coarser level (although in general the mapping is many to one, i.e., each nonterminal category at coarser level corresponds to several nonterminal categories at finer level).", "labels": [], "entities": []}, {"text": "We use the correspondence between categories at different levels to prune possible constituents.", "labels": [], "entities": []}, {"text": "A constituent is considered at finer level only if the corresponding constituent at coarser level has a probability exceeding some threshold.", "labels": [], "entities": []}, {"text": "Parsing with hierarchical grammar leads to considerable efficiency improvements.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.974789559841156}]}, {"text": "Treebank parsing comprises two problems: learning, in which we must select a model given a treebank, and inference, in which we must select a parse fora sentence given the learned model.", "labels": [], "entities": [{"text": "Treebank parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.5716239809989929}]}, {"text": "Previous work has shown that highquality unlexicalized PCFGs can be learned from a treebank, either by manual annotation or automatic state splitting ().", "labels": [], "entities": []}, {"text": "In particular, we demonstrated in that a hierarchically split PCFG could exceed the accuracy of lexicalized PCFGs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9987412095069885}]}, {"text": "We adopted here a multilevel coarse-to-fine PCFG parsing algorithm as in  and.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.6951127350330353}]}, {"text": "The multilevel coarse-to-fine PCFG parsing algorithm reduces the complexity of the search involved in finding the best parse and attempts to constrain the fine parsing space to the coarse parsing space.", "labels": [], "entities": [{"text": "multilevel coarse-to-fine PCFG parsing", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.5285928323864937}]}, {"text": "It defines a sequence of increasingly more complex PCFGs.  has demonstrated that coarse PCFG identified the locations of correct constituents of the parse tree (the \"gold constituents\") with high recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.998648464679718}]}], "datasetContent": [{"text": "We have parsed with three different annotation setups.", "labels": [], "entities": []}, {"text": "First, we train our model our model with only phrasal labels, and evaluate the precision and recall on only the phrasal labels.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9996604919433594}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9991783499717712}]}, {"text": "Second, we train our model with full labels, and evaluate the precision and recall on only the phrasal labels.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9996985197067261}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9992202520370483}]}, {"text": "Third\uff0cwe train the model with full labels, and evaluate the precision and recall on full labels.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9997046589851379}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9991388320922852}]}, {"text": "Take a concrete example, we show two parsing output with different annotations as below: The input sentence is: Parsing output with only phrasal constituent labels: Parsing output with full labels: The gold parse tree is as follows: In the former parsing result, not only the phrasal constituent tags are labels more accurately, its syntactic structures are segmented more reasonably.", "labels": [], "entities": []}, {"text": "The parsing performances metrics convinced that the concept compound is detrimental to the parser performance even we only evaluate the phrasal constituent labels' precision and recall.", "labels": [], "entities": [{"text": "parsing performances", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8748479783535004}, {"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9960842132568359}, {"text": "recall", "start_pos": 178, "end_pos": 184, "type": "METRIC", "confidence": 0.9973711967468262}]}, {"text": "Furthermore, we compare the metrics of exact match, average crossing, no crossing and 2 or less crossing, which show that the higher accuracy gained by stripping the concept compound labels lies in both its more accurate bracketing and tagging ability.", "labels": [], "entities": [{"text": "exact match", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.926651805639267}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9986419081687927}, {"text": "tagging", "start_pos": 236, "end_pos": 243, "type": "TASK", "confidence": 0.9367425441741943}]}, {"text": "We ran experiments on TCT.", "labels": [], "entities": []}, {"text": "The training and test data set splits are described in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Experiment Results of SC and ULC", "labels": [], "entities": [{"text": "ULC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.3933435380458832}]}, {"text": " Table 3. Experiment Results of LC", "labels": [], "entities": [{"text": "LC", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.5716164708137512}]}, {"text": " Table 4. Experiment Results of Tot4", "labels": [], "entities": [{"text": "Tot4", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.6912936568260193}]}]}