{"title": [{"text": "Twitter Translation using Translation-Based Cross-Lingual Retrieval", "labels": [], "entities": [{"text": "Translation-Based Cross-Lingual Retrieval", "start_pos": 26, "end_pos": 67, "type": "TASK", "confidence": 0.6045326590538025}]}], "abstractContent": [{"text": "Microblogging services such as Twitter have become popular media for real-time user-created news reporting.", "labels": [], "entities": [{"text": "real-time user-created news reporting", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.679941825568676}]}, {"text": "Such communication often happens in parallel in different languages , e.g., microblog posts related to the same events of the Arab spring were written in Arabic and in English.", "labels": [], "entities": []}, {"text": "The goal of this paper is to exploit this parallelism in order to eliminate the main bottleneck in automatic Twitter translation, namely the lack of bilingual sentence pairs for training SMT systems.", "labels": [], "entities": [{"text": "automatic Twitter translation", "start_pos": 99, "end_pos": 128, "type": "TASK", "confidence": 0.6463867823282877}, {"text": "SMT", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.9393823146820068}]}, {"text": "We show that translation-based cross-lingual information retrieval can retrieve microblog messages across languages that are similar enough to be used to train a standard phrase-based SMT pipeline.", "labels": [], "entities": [{"text": "translation-based cross-lingual information retrieval", "start_pos": 13, "end_pos": 66, "type": "TASK", "confidence": 0.6669166386127472}, {"text": "SMT pipeline", "start_pos": 184, "end_pos": 196, "type": "TASK", "confidence": 0.8715062737464905}]}, {"text": "Our method outper-forms other approaches to domain adaptation for SMT such as language model adaptation, meta-parameter tuning, or self-translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9696285128593445}, {"text": "language model adaptation", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.6591087281703949}]}], "introductionContent": [{"text": "Among the various social media platforms, microblogging services such as Twitter have become popular communication tools.", "labels": [], "entities": []}, {"text": "This is due to the easy accessibility of microblogging platforms via internet or mobile phones, and due to the need fora fast mode of communication that microblogging satisfies: Twitter messages are short (limited to 140 characters) and simultaneous (due to frequent updates by prolific microbloggers).", "labels": [], "entities": []}, {"text": "Twitter users form asocial network by \"following\" the updates of other users, either reciprocal or one-way.", "labels": [], "entities": []}, {"text": "The topics discussed in Twitter messages range from private chatter to important real-time witness reports.", "labels": [], "entities": []}, {"text": "1 http://twitter.com/ Events such as the Arab spring have shown the power and also the shortcomings of this new mode of communication.", "labels": [], "entities": [{"text": "Arab spring", "start_pos": 41, "end_pos": 52, "type": "DATASET", "confidence": 0.9381227493286133}]}, {"text": "Microblogging services played a crucial role in quickly spreading the news about important events, furthermore they were useful in helping organizers plan their protest.", "labels": [], "entities": []}, {"text": "The fact that news on microblogging platforms is sometimes ahead of newswire is one of the most interesting facets of this new medium.", "labels": [], "entities": []}, {"text": "However, while Twitter messaging is happening in multiple languages, most networks of \"friends\" and \"followers\" are monolingual and only about 40% of all messages are in English . One solution to sharing news quickly and internationally was crowdsourcing manual translations, for example at Meedan 3 , a nonprofit organization built to share news and opinion between the Arabic and English speaking world, by translating articles and blogs, using machine translation and human expert corrections.", "labels": [], "entities": []}, {"text": "The goal of our research is to automate this translation process, with a further aim of providing rapid crosslingual data access for downstream applications.", "labels": [], "entities": [{"text": "translation process", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.9000664353370667}]}, {"text": "The automated translation of microblogging messages is facing two main problems.", "labels": [], "entities": [{"text": "automated translation of microblogging messages", "start_pos": 4, "end_pos": 51, "type": "TASK", "confidence": 0.749189269542694}]}, {"text": "First, there are no bilingual sentence pair data from microblogging domains available.", "labels": [], "entities": []}, {"text": "Second, the colloquial, nonstandard language of many microblogging messages makes it very difficult to adapt a machine translation system trained on any of the available bilingual resources such as transcriptions from political organizations or news text.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.741773247718811}]}, {"text": "The approach presented in this paper aims to exploit the fact that microblogging often happens in parallel in different languages, e.g., microblog posts related to the same events of the Arab spring were published in parallel in Arabic and in English.", "labels": [], "entities": []}, {"text": "The central idea is to crawl a large set of topically related Arabic and English microblogging messages, and use Arabic microblog messages as search queries in a cross-lingual information retrieval (CLIR) setup.", "labels": [], "entities": [{"text": "cross-lingual information retrieval (CLIR)", "start_pos": 162, "end_pos": 204, "type": "TASK", "confidence": 0.7560232778390249}]}, {"text": "We use the probabilistic translation-based retrieval technique of that naturally integrates translation tables for cross-lingual retrieval.", "labels": [], "entities": []}, {"text": "The retrieval results are then used as input to a standard SMT pipeline to train translation models, starting from unsupervised induction of word alignments) to phrase-extraction () and phrase-based decoding ( . We investigate several filtering techniques for retrieval and phrase extraction () and find a straightforward application of phrase extraction from symmetrized alignments to be optimal.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9860550761222839}, {"text": "phrase extraction", "start_pos": 274, "end_pos": 291, "type": "TASK", "confidence": 0.7873570024967194}, {"text": "phrase extraction", "start_pos": 337, "end_pos": 354, "type": "TASK", "confidence": 0.7483381927013397}]}, {"text": "Furthermore, we compare our approach to related domain adaptation techniques for SMT and find our approach to yield large improvements overall related techniques.", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9938431978225708}]}, {"text": "Finally, a side-product of our research is a corpus of around 1,000 Arabic Twitter messages with 3 manual English translations each, which were created using crowdsourcing techniques.", "labels": [], "entities": []}, {"text": "This corpus is used for development and testing in our experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted a series of experiments to evaluate our strategy of using CLIR and phrase-extraction to extract comparable data in the Twitter domain.", "labels": [], "entities": []}, {"text": "We also explored more standard ways of domain adaptation such as using English microblog messages to build an in-domain language model, or generating synthetic bilingual corpora from monolingual data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7423283010721207}]}, {"text": "All experiments were conducted using the Moses machine translation system 15 ( ) with standard settings.", "labels": [], "entities": [{"text": "Moses machine translation", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.6850891510645548}]}, {"text": "Language models were built using the SRILM toolkit 16.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.8534720242023468}]}, {"text": "For all experiments, we report lowercased BLEU-4 scores () as calculated by Moses' multi-bleu script.", "labels": [], "entities": [{"text": "BLEU-4 scores", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.9783988893032074}]}, {"text": "For assessing significance, we apply the approximate randomization test).", "labels": [], "entities": [{"text": "significance", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.9287094473838806}]}, {"text": "We consider pairwise differing results scoring a p-value < 0.05 as significant.", "labels": [], "entities": []}, {"text": "Our baseline model was trained using 5,823,363 million parallel sentences in Modern Standard Arabic (MSA) (198,500,436 tokens) and English tokens) from the NIST evaluation campaign.", "labels": [], "entities": [{"text": "NIST evaluation campaign", "start_pos": 156, "end_pos": 180, "type": "DATASET", "confidence": 0.927907129128774}]}, {"text": "This data contains parallel text from different domains, including UN reports, newsgroups, newswire, broadcast news and weblogs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Twitter corpus statistics", "labels": [], "entities": [{"text": "Twitter corpus statistics", "start_pos": 10, "end_pos": 35, "type": "DATASET", "confidence": 0.9517401854197184}]}, {"text": " Table 4: Domain adaptation experiments. Asterisks indicate significant improvements over baseline (1).", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8258516490459442}]}, {"text": " Table 5: CLIR domain adaptation experiments. All weights were optimized on the Twitter dev set and used  the Twitter and NIST language models. One Asterisk indicates a significant improvement over baseline run  (5) from table 4. Two Asterisks indicate a significant improvement over run (8).", "labels": [], "entities": [{"text": "CLIR domain adaptation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6755943397680918}, {"text": "Twitter dev set", "start_pos": 80, "end_pos": 95, "type": "DATASET", "confidence": 0.8350879947344462}]}, {"text": " Table 8: Dialectal content in our test set as classified  by the AOC dataset.", "labels": [], "entities": [{"text": "AOC dataset", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.9848917424678802}]}, {"text": " Table 6: Examples of nearly parallel tweets found by our retrieval method.", "labels": [], "entities": []}, {"text": " Table 7: OOV-rate and precision for different adaptation methods.", "labels": [], "entities": [{"text": "OOV-rate", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9877118468284607}, {"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9996637105941772}]}]}