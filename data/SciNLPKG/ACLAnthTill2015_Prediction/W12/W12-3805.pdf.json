{"title": [{"text": "Improving Speculative Language Detection using Linguistic Knowledge", "labels": [], "entities": [{"text": "Improving Speculative Language Detection", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8917275667190552}]}], "abstractContent": [{"text": "In this paper we present an iterative methodology to improve classifier performance by incorporating linguistic knowledge, and propose away to incorporate domain rules into the learning process.", "labels": [], "entities": []}, {"text": "We applied the methodology to the tasks of hedge cue recognition and scope detection and obtained competitive results on a publicly available corpus.", "labels": [], "entities": [{"text": "hedge cue recognition", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.7125649650891622}, {"text": "scope detection", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.9252656102180481}]}], "introductionContent": [{"text": "A common task in Natural Language Processing (NLP) is to extractor infer factual information from textual data.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 17, "end_pos": 50, "type": "TASK", "confidence": 0.7423378825187683}, {"text": "extractor infer factual information from textual data", "start_pos": 57, "end_pos": 110, "type": "TASK", "confidence": 0.7848277262278965}]}, {"text": "In the field of natural sciences this task turns out to be of particular importance, because science aims to discover or describe facts from the world around us.", "labels": [], "entities": []}, {"text": "Extracting these facts from the huge and constantly growing body of research articles in areas such as, for example, molecular biology, becomes increasingly necessary, and has been the subject of intense research in the last decade ().", "labels": [], "entities": [{"text": "Extracting", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9685066342353821}, {"text": "molecular biology", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.8212082982063293}]}, {"text": "The fields of information extraction and text mining have paid particular attention to this issue, seeking to automatically populate structured databases with data extracted or inferred from text.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7661851346492767}, {"text": "text mining", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.816613644361496}]}, {"text": "In both cases, the problem of speculative language detection is a challenging one, because it may correspond to a subjective attitude of the writer towards the truth value of certain facts, and that information should not be lost when the fact is extracted or inferred.", "labels": [], "entities": [{"text": "speculative language detection", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.8494839866956075}]}, {"text": "When researchers express facts and relations in their research articles, they often use speculative language to convey their attitude to the truth of what is said.", "labels": [], "entities": []}, {"text": "Hedging, a term first introduced by to describe 'words whose job is to make things fuzzier or less fuzzy' is 'the expression of tentativeness and possibility in language use', and is extensively used in scientific writing.", "labels": [], "entities": []}, {"text": "reports one hedge in every 50 words of a corpus of research articles; mention that 11% of the sentences in MEDLINE contain speculative language.", "labels": [], "entities": []}, {"text": "report that 18% of the sentences in the scientific abstracts section of the Bioscope corpus correspond to speculations.", "labels": [], "entities": [{"text": "Bioscope corpus", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.863867312669754}]}, {"text": "Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example,).", "labels": [], "entities": [{"text": "speculative language detection", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.7638667424519857}]}, {"text": "This approach does not take into account the fact that hedging usually affects propositions or claims and that sentences often include more than one of them.", "labels": [], "entities": []}, {"text": "When the Bioscope corpus) was developed the notions of hedge cue (corresponding to what was previously called just 'hedges' in the literature) and scope (the propositions affected by the hedge cues) were introduced.", "labels": [], "entities": [{"text": "Bioscope corpus", "start_pos": 9, "end_pos": 24, "type": "DATASET", "confidence": 0.8995854556560516}]}, {"text": "In this context, speculative language recognition can be seen as a two-phase process: first, the existence of a hedge cue in a sentence is detected, and second, the scope of the induced hedge is determined.", "labels": [], "entities": [{"text": "speculative language recognition", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.7546811699867249}]}, {"text": "This approach was first used by and subsequently in many of the studies presented in the, and is the one used in this paper.", "labels": [], "entities": []}, {"text": "For example, the sentence (1) This finding { suggests suggests that the BZLF1 promoter { may maybe regulated by the degree of squamous differentiation} may } suggests . contains the word 'may' that acts as a hedge cue (i.e. attenuating the affirmation); this hedge only affects the propositions included in the subordinate clause that contains it.", "labels": [], "entities": []}, {"text": "Each of these phases can be modelled (albeit with some differences, described in the following sections) as a sequential classification task, using a similar approach to that commonly used for named entity recognition or semantic labelling: every word in the sentence is assigned a class, identifying spans of text (as, for example, scopes) with, for example, a special class for the first and last element of the span.", "labels": [], "entities": [{"text": "sequential classification task", "start_pos": 110, "end_pos": 140, "type": "TASK", "confidence": 0.7583161890506744}, {"text": "named entity recognition or semantic labelling", "start_pos": 193, "end_pos": 239, "type": "TASK", "confidence": 0.6529755592346191}]}, {"text": "Correctly learning these classes is the computational task to be solved.", "labels": [], "entities": []}, {"text": "In this paper we present a methodology and machine learning system implementing it that, based on previous work on speculation detection, studies how to improve recognition by analysing learning errors and incorporating advice from domain experts in order to solve the errors without hurting overall performance.", "labels": [], "entities": [{"text": "speculation detection", "start_pos": 115, "end_pos": 136, "type": "TASK", "confidence": 0.7841785252094269}]}, {"text": "The methodology proposes the use of domain knowledge rules that suggest a class for an instance, and shows how to incorporate them into the learning process.", "labels": [], "entities": []}, {"text": "In our particular task domain knowledge is linguistic knowledge, as hedging and scopes issues are general linguistic devices.", "labels": [], "entities": []}, {"text": "In this paper we are going both terms interchangeably.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review previous theoretical work on speculative language and the main computational approaches to the task of detecting speculative sentences.", "labels": [], "entities": [{"text": "detecting speculative sentences", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.8032105366388956}]}, {"text": "Section 3 briefly describes the corpus used for training and evaluation.", "labels": [], "entities": []}, {"text": "In Section 4 we present the specific computational task to which our methodology was applied.", "labels": [], "entities": []}, {"text": "In Section 5 we present the learning methodology we propose to use, and describe the system we implemented, including lexical, syntactic and semantic attributes we experimented with.", "labels": [], "entities": []}, {"text": "We present and discuss the results obtained in Section 6.", "labels": [], "entities": []}, {"text": "Finally, in Section 7 we analyse the approach presented here and discuss its advantages and problems, suggesting future lines of research.", "labels": [], "entities": []}], "datasetContent": [{"text": "To determine classifier performance, we evaluated the classifiers found after improvement on the evaluation corpus.", "labels": [], "entities": []}, {"text": "We also evaluated the less efficient classifiers to see whether applying the iterative improvement had overfitted the classifier to the corpus.", "labels": [], "entities": []}, {"text": "To evaluate scope detection, we used the best configuration found in the evaluation corpus for hedge cue identification.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.8977002799510956}, {"text": "hedge cue identification", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.6409008006254832}]}, {"text": "show the results for the hedge cue recognition and scope resolution, respectively.", "labels": [], "entities": [{"text": "hedge cue recognition", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.6897063255310059}, {"text": "scope resolution", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.6876494437456131}]}, {"text": "In both tasks, classifier performance   improved in a similar way to the results obtained on the held out corpus.", "labels": [], "entities": []}, {"text": "Finally, to compare our results with state-of-theart methods (even though that was not the main objective of the study), we used the corpus of de CoNLL 2010 Shared Task to train and evaluate our classifiers, using the best configurations found in the evaluation corpus, and obtained competitive results in both subtasks of Task 2.", "labels": [], "entities": [{"text": "de CoNLL 2010 Shared Task", "start_pos": 143, "end_pos": 168, "type": "DATASET", "confidence": 0.7957041144371033}]}, {"text": "Our classifier for hedge cue detection achieved an F-measure of 79.9, better than the third position in the Shared Task for hedge identification.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8624272147814432}, {"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.999672532081604}, {"text": "hedge identification", "start_pos": 124, "end_pos": 144, "type": "TASK", "confidence": 0.7696755528450012}]}, {"text": "Scope detection results (using learned hedge cues) achieved an F-measure of 54.7, performing better than the fifth result in the corresponding task, and five points below the best results obtained so far in the corpus (", "labels": [], "entities": [{"text": "Scope detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9519312083721161}, {"text": "F-measure", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9996243715286255}]}], "tableCaptions": [{"text": " Table 1: Bioscope corpus statistics about hedging", "labels": [], "entities": [{"text": "Bioscope corpus", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.756387323141098}, {"text": "hedging", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.4729543626308441}]}, {"text": " Table 3: Classification performance on the held out cor- pus for hedge cue detection. Conf1 corresponds to win- dows of Word, Lemma and POS attributes and Conf2 in- corporates hedge cue candidates and cooccuring words", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7793718973795573}]}, {"text": " Table 4: Classification performance on the held out cor- pus. The baseline used a window of Word, Lemma,  POS attributes and hedge cue tag; Conf1 included parent  scopes, Conf2 added grandparents information; Conf3  added postprocessing rules. Finally, Conf4 used adjusted  scopes and incorporated new postprocessing rules", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9663186073303223}]}, {"text": " Table 5: Classification performance on the evaluation  corpus for hedge cue detection", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.8862212498982748}]}, {"text": " Table 6: Classification performance on the evaluation  corpus for scope detection", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9549705982208252}, {"text": "scope detection", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.9824767410755157}]}, {"text": " Table 7: Classification performance compared with  best results in CoNLL Shared Task. Figures represent  Precision/Recall/F1-measure", "labels": [], "entities": [{"text": "CoNLL Shared Task", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.7436721722284952}, {"text": "Precision/Recall/F1-measure", "start_pos": 106, "end_pos": 133, "type": "METRIC", "confidence": 0.7036324858665466}]}]}