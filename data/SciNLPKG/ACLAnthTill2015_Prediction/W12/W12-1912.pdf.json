{"title": [{"text": "Induction of Linguistic Structure with Combinatory Categorial Grammars", "labels": [], "entities": [{"text": "Induction of Linguistic Structure", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.9017178267240524}]}], "abstractContent": [{"text": "Our system consists of a simple, EM-based induction algorithm (Bisk and Hockenmaier, 2012), which induces a language-specific Combinatory Categorial grammar (CCG) and lexicon based on a small number of linguistic principles, e.g. that verbs maybe the roots of sentences and can take nouns as arguments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much of the recent work on grammar induction has focused on the development of sophisticated statistical models that incorporate expressive priors or linguistic universals) that have all been shown to be very helpful.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7906369566917419}]}, {"text": "But, with some notable exceptions, such as, the question of what underlying linguistic representation to use has received considerably less attention.", "labels": [], "entities": []}, {"text": "Our induction algorithm is based on Combinatory Categorial Grammar), a linguistically expressive, lexicalized grammar formalism which associates words with rich syntactic categories that capture language-specific facts about basic word order and subcategorization.", "labels": [], "entities": []}, {"text": "While have shown that linguists can easily devise a language-specific inventory of such categories that allows a parser to achieve high performance in the absence of annotated training data, our algorithm automatically discovers the set of categories it requires to parse the sentences in the training data.", "labels": [], "entities": []}], "datasetContent": [{"text": "Although the analysis of constructions involving basic head-argument and head-modifier dependencies is generally uncontroversial, many common constructions allow a number of plausible analyses.", "labels": [], "entities": []}, {"text": "This makes it very difficult to evaluate and compare different unsupervised approaches for grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7882058918476105}]}, {"text": "The corpora used in this workshop also assume different conventions fora number of constructions.", "labels": [], "entities": []}, {"text": "shows the three different types of analysis for coordination adopted by the corpora used in this shared task (as well as the standard CCG analysis).", "labels": [], "entities": []}, {"text": "The numbers to the side indicate for each corpus what percentage of our system's error rate is due to missed dependencies within coordinated structures (i.e between a conjunction and a conjunct, or between two conjuncts).", "labels": [], "entities": []}, {"text": "It is important to note that the way in which we extract dependencies from coordinations is somewhat arbitrary (and completely independent of the underlying probability model, which currently captures no explicit de-93: Different analyses of coordination in the various corpora used in this shared task.", "labels": [], "entities": []}, {"text": "Our system adopts the CoNLL-07 convention, instead of the standard CCG analysis.", "labels": [], "entities": [{"text": "CoNLL-07 convention", "start_pos": 22, "end_pos": 41, "type": "DATASET", "confidence": 0.8266890048980713}]}, {"text": "For the development set of each corpus, we also indicate what percentage of the errors our system makes is due to missed coordination dependencies.", "labels": [], "entities": []}, {"text": "These systematic differences of analysis are also reflected in our final results.", "labels": [], "entities": []}, {"text": "The only exception is the Childes corpus, where coordination is significantly rarer.", "labels": [], "entities": [{"text": "Childes corpus", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.976965457201004}]}, {"text": "However, this is a general problem.", "labels": [], "entities": []}, {"text": "There are many other constructions for which no agreed-upon standard exists.", "labels": [], "entities": []}, {"text": "For example, the Wall Street Journal data used in this shared task assumes a dependency between the verb of the main clause and the verb of a subordinate clause, whereas the CoNLL-07 analysis stipulates a dependency between the main verb and the subordinating conjunction: We therefore believe that much further work is required to address the problems surrounding evaluation and comparison of unsupervised induction systems adequately.", "labels": [], "entities": [{"text": "Wall Street Journal data", "start_pos": 17, "end_pos": 41, "type": "DATASET", "confidence": 0.9591128975152969}]}, {"text": "Even if the community cannot agree on a single gold standard, systems should not be penalized for producing one kind of linguistically plausible analysis over another.", "labels": [], "entities": []}, {"text": "The systematic divergences that arise with coordination for our approach are relatively easy to fix, since we only need to change the way in which we read off dependencies.", "labels": [], "entities": []}, {"text": "But this points to a deeper underlying problem that affects the entire field.", "labels": [], "entities": []}], "tableCaptions": []}