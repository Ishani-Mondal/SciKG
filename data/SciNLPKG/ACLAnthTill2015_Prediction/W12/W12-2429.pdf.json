{"title": [{"text": "Scaling up WSD with Automatically Generated Examples", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.6664783954620361}]}], "abstractContent": [{"text": "The most accurate approaches to Word Sense Disambiguation (WSD) for biomedical documents are based on supervised learning.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.8067896962165833}]}, {"text": "However , these require manually labeled training examples which are expensive to create and consequently supervised WSD systems are normally limited to disambiguating a small set of ambiguous terms.", "labels": [], "entities": [{"text": "WSD", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9591975212097168}]}, {"text": "An alternative approach is to create labeled training examples automatically and use them as a substitute for manually labeled ones.", "labels": [], "entities": []}, {"text": "This paper describes a large scale WSD system based on automatically labeled examples generated using information from the UMLS Metathesaurus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9741427302360535}, {"text": "UMLS Metathesaurus", "start_pos": 123, "end_pos": 141, "type": "DATASET", "confidence": 0.9385737776756287}]}, {"text": "The labeled examples are generated without any use of labeled training data whatsoever and is therefore completely unsupervised (unlike some previous approaches).", "labels": [], "entities": []}, {"text": "The system is evaluated on two widely used data sets and found to outper-form a state-of-the-art unsupervised approach which also uses information from the UMLS Metathesaurus.", "labels": [], "entities": [{"text": "UMLS Metathesaurus", "start_pos": 156, "end_pos": 174, "type": "DATASET", "confidence": 0.92723548412323}]}], "introductionContent": [{"text": "The information contained in the biomedical literature that is available in electronic formats is useful for health professionals and researchers).", "labels": [], "entities": []}, {"text": "The amount is so vast that it is difficult for researchers to identify information of interest without the assistance of automated tools).", "labels": [], "entities": []}, {"text": "However, processing these documents automatically is made difficult by the fact that they contain terms that are ambiguous.", "labels": [], "entities": []}, {"text": "For example, \"culture\" can mean \"laboratory procedure\" (e.g. \"In peripheral blood mononuclear cell culture\") or \"anthropological culture\" (e.g. \"main accomplishments of introducing a quality management culture\").", "labels": [], "entities": []}, {"text": "These lexical ambiguities are problematic for language understanding systems.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.7519440650939941}]}, {"text": "Word sense disambiguation (WSD) is the process of automatically identifying the meanings of ambiguous terms.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8170595765113831}, {"text": "automatically identifying the meanings of ambiguous terms", "start_pos": 50, "end_pos": 107, "type": "TASK", "confidence": 0.4377592291150774}]}, {"text": "Some WSD systems for the biomedical domain are only able to disambiguate a small number of ambiguous terms (see Section 2).", "labels": [], "entities": [{"text": "WSD", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9494706988334656}]}, {"text": "However, for WSD systems to be useful in applications they should be able to disambiguate all ambiguous terms.", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9609051942825317}]}, {"text": "One way to create such a WSD system is to automatically create the labeled data that is used to train supervised WSD systems.", "labels": [], "entities": []}, {"text": "Several approaches ( have used information from the UMLS Metathesaurus 1 to create labeled training data that have successfully been used to create WSD systems.", "labels": [], "entities": [{"text": "UMLS Metathesaurus 1", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.9445466796557108}, {"text": "WSD", "start_pos": 148, "end_pos": 151, "type": "TASK", "confidence": 0.9496241807937622}]}, {"text": "A key decision for any system that automatically generates labeled examples is the number of examples of each sense to create, known as the bias of the data set.", "labels": [], "entities": []}, {"text": "It has been shown that the bias of a set of labeled examples affects the performance of the WSD system it is used to train).", "labels": [], "entities": []}, {"text": "Some of the previous approaches to generating labeled data relied on manually annotated examples to determine the bias of the data sets and were therefore not completely unsupervised.", "labels": [], "entities": []}, {"text": "This paper describes the development of a large scale WSD system that is able to disambiguate all terms that are ambiguous in the UMLS Metathesaurus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9362823963165283}, {"text": "UMLS Metathesaurus", "start_pos": 130, "end_pos": 148, "type": "DATASET", "confidence": 0.9356138706207275}]}, {"text": "The system relies on labeled examples that are created using information from UMLS.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9106978178024292}]}, {"text": "Various bias options are explored, including ones that do not make use of information from manually labeled examples, and thus we can create a completely unsupervised system.", "labels": [], "entities": []}, {"text": "Evaluation is carried out on two standard datasets (the NLM-WSD and MSH-WSD corpora).", "labels": [], "entities": [{"text": "NLM-WSD", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9093371629714966}]}, {"text": "We find that WSD systems can be created without using any information from manually labeled examples and that their performance is better than a state-of-the-art unsupervised approach.", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9410224556922913}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Previous approaches to WSD in biomedical documents are described in the next Section.", "labels": [], "entities": [{"text": "WSD", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9953852295875549}]}, {"text": "Section 3 presents the methods used to identify bias in the labeled examples and WSD system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.620973527431488}]}, {"text": "Experiments in which these approaches are compared are described in Section 4 and their results in Section 5.", "labels": [], "entities": [{"text": "Section", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.8884090781211853}]}], "datasetContent": [{"text": "The WSD system described in Section 3 was tested using each of the three techniques for determining the bias, i.e. number of examples generated for each CUI.", "labels": [], "entities": [{"text": "WSD", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.7621439695358276}]}, {"text": "Performance is compared against various alternative approaches.", "labels": [], "entities": []}, {"text": "Two supervised approaches are included.", "labels": [], "entities": []}, {"text": "The first, most frequent sense (MFS) (), is widely used baseline for supervised WSD systems.", "labels": [], "entities": [{"text": "frequent sense (MFS)", "start_pos": 16, "end_pos": 36, "type": "METRIC", "confidence": 0.8228537321090699}, {"text": "WSD", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9456056952476501}]}, {"text": "It consists of assigning each ambiguous term the meaning that is more frequently observed in the training data.", "labels": [], "entities": []}, {"text": "The second supervised approach is to train the WSD system using manually labeled examples from the NLM-WSD and MSH-WSD corpora.", "labels": [], "entities": [{"text": "WSD", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9675688147544861}, {"text": "NLM-WSD", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9179375171661377}, {"text": "MSH-WSD corpora", "start_pos": 111, "end_pos": 126, "type": "DATASET", "confidence": 0.8283863961696625}]}, {"text": "10-fold cross validation is applied to evaluate this approach.", "labels": [], "entities": []}, {"text": "Performance of the Personalised Page Rank approach described in Section 2.1 is also provided to allow comparison with an unsupervised algorithm.", "labels": [], "entities": []}, {"text": "Both Personalised Page Rank and the techniques we employ to generate labeled data, base disambiguation decisions on information from the UMLS Metathesaurus.", "labels": [], "entities": [{"text": "UMLS Metathesaurus", "start_pos": 137, "end_pos": 155, "type": "DATASET", "confidence": 0.9607505202293396}]}, {"text": "The performance of all approaches is measured in terms of the percentage of instances which are correctly disambiguated for each term with the average across all terms reported.", "labels": [], "entities": []}, {"text": "Confidence intervals (95%) computed using bootstrap resampling are also shown.", "labels": [], "entities": [{"text": "Confidence intervals", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.9754863083362579}]}], "tableCaptions": [{"text": " Table 2. However, the gold  standard distribution is different from the one ob- tained from the MBR. The drop in performance of  MMB compared with GBS in", "labels": [], "entities": [{"text": "MBR", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.9787550568580627}]}, {"text": " Table 4: Average KL divergence for abbreviations and  terms in the MSH-WSD data set.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.5324259251356125}, {"text": "MSH-WSD data set", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.9901195168495178}]}]}