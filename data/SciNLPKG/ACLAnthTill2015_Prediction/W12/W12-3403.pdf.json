{"title": [{"text": "Building an Arabic Multiword Expressions Repository", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce a list of Arabic multiword expressions (MWE) collected from various dictionaries.", "labels": [], "entities": [{"text": "Arabic multiword expressions (MWE)", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.6465675632158915}]}, {"text": "The MWEs are grouped based on their syntactic type.", "labels": [], "entities": []}, {"text": "Every constituent word in the expressions is manually annotated with its full context-sensitive morphological analysis.", "labels": [], "entities": []}, {"text": "Some of the expressions contain semantic variables as place holders for words that play the same semantic role.", "labels": [], "entities": []}, {"text": "In addition, we have automatically annotated a large corpus of Arabic text using a pattern-matching algorithm that considers some morpho-syntactic features as expressed by a highly inflected language, such as Arabic.", "labels": [], "entities": []}, {"text": "A sample part of the corpus is manually evaluated and the results are reported in this paper.", "labels": [], "entities": []}], "introductionContent": [{"text": "A multiword expression (MWE) refers to a multiword unit or a collocation of words that cooccur together statistically more than chance.", "labels": [], "entities": [{"text": "multiword expression (MWE)", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.6815479874610901}]}, {"text": "A MWE is a cover term for different types of collocations, which vary in their transparency and fixedness.", "labels": [], "entities": []}, {"text": "MWEs are pervasive in natural language, especially in web based texts and speech genres.", "labels": [], "entities": []}, {"text": "Identifying MWEs and understanding their meaning is essential to language understanding, hence they are of crucial importance for any Natural Language Processing (NLP) applications that aim at handling robust language meaning and use.", "labels": [], "entities": [{"text": "Identifying MWEs", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7363197803497314}, {"text": "language understanding", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.739631712436676}]}, {"text": "In fact, the seminal paper () refers to this problem as a key issue for the development of high-quality NLP applications.", "labels": [], "entities": []}, {"text": "MWEs are classified based on their syntactic constructions.", "labels": [], "entities": []}, {"text": "Among the various classes, one can find the Verb Noun Constructions (VNC), Noun Noun Construction (NNC) and others.", "labels": [], "entities": [{"text": "Verb Noun Constructions (VNC)", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.6346463759740194}, {"text": "Noun Noun Construction (NNC)", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.7523057262102762}]}, {"text": "A MWE typically has an idiosyncratic meaning that is more or different from the meaning of its component words.", "labels": [], "entities": []}, {"text": "In this paper we focus on MWEs in Arabic.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.9734642505645752}]}, {"text": "Like many other Semitic languages, Arabic is highly inflected; words are derived from a root and a pattern (template), combined with prefixes, suffixes and circumfixes.", "labels": [], "entities": []}, {"text": "As opposed to English equivalents, Arabic MWEs can be expressed in a large number of forms, expressing various inflections and derivations of the words while maintaining the exact same meaning, for example, where the predicate takes on the feminine inflection.", "labels": [], "entities": []}, {"text": "However, in many cases, there are morphological features that cannot be changed in different contexts, for example, mkrh >xAk lA bTl, \"forced with no choice\", in this example, regardless of context, the words of the MWE do not agree in number and gender with the surrounding context.", "labels": [], "entities": []}, {"text": "These are considered frozen expressions.", "labels": [], "entities": []}, {"text": "One of the challenges in building MWE list for Arabic is to identify those features and document them in every MWE.", "labels": [], "entities": []}, {"text": "Our resource is available for download.", "labels": [], "entities": []}, {"text": "We have manually collected a large number of MWEs from various Arabic dictionaries, which are based on MSA corpora, and then filtered by Arabic native linguists.", "labels": [], "entities": []}, {"text": "We then classified them based on their syntactic constructions, considering the relevant syntactic phenomena expressed in Arabic.", "labels": [], "entities": []}, {"text": "The MWEs were manually annotated with the context-sensitive SAMA morphological analysis for each word to assist an automated identification of MWEs in a large corpus of text.", "labels": [], "entities": [{"text": "identification of MWEs", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.732003927230835}]}, {"text": "Part of the Arabic Gigaword 4.0 (Parker, 2009) is processed accordingly and the MWEs are annotated based on a deterministic algorithm considering different variants of every MWE in our list.", "labels": [], "entities": [{"text": "Arabic Gigaword 4.0 (Parker, 2009)", "start_pos": 12, "end_pos": 46, "type": "DATASET", "confidence": 0.908135674893856}]}, {"text": "There are diverse tasks that require a corpus with annotated MWEs, which have not been addressed in Arabic due to the lack of such a resource.", "labels": [], "entities": []}, {"text": "However, a lot of attention is put on those tasks when implemented in English and other languages.", "labels": [], "entities": []}, {"text": "Among those tasks, classifying MWEs in a running text is the most common one.", "labels": [], "entities": [{"text": "classifying MWEs in a running text", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.8527796864509583}]}, {"text": "applied a supervised learning framework to the problem of classifying token level English MWEs in context.", "labels": [], "entities": [{"text": "classifying token level English MWEs", "start_pos": 58, "end_pos": 94, "type": "TASK", "confidence": 0.788552463054657}]}, {"text": "They used the annotated corpus provided by, a resource of almost 3000 English sentences annotated with VNC usage at the token level.", "labels": [], "entities": []}, {"text": "carried out a vector similarity comparison between the context of an English MWE and that of the constituent words using Latent Semantic Analysis to determine if the expression is idiomatic or not.", "labels": [], "entities": []}, {"text": "In work by, they addressed token classification into idiomatic versus literal for Japanese MWEs of all types.", "labels": [], "entities": [{"text": "token classification", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8185362219810486}]}, {"text": "They annotated a corpus of 102K sentences, and used it to train a supervised classifier for MWEs.", "labels": [], "entities": []}, {"text": "Using MWEs in machine translation is another application.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.6908393651247025}]}, {"text": "studied the effect of integrating English MWEs with a statistical translation system.", "labels": [], "entities": []}, {"text": "They used the WordNet 3.0 lexical database as the main source for MWEs., extracted Arabic MWEs from various resources.", "labels": [], "entities": [{"text": "WordNet 3.0 lexical database", "start_pos": 14, "end_pos": 42, "type": "DATASET", "confidence": 0.9393760859966278}]}, {"text": "They focused only on nominal MWEs and used diverse techniques for automatic MWE extraction from cross-lingual parallel Wikipedia titles, machine-translated English MWEs taken from the English WordNet and the Arabic Gigaword 4.0 corpus.", "labels": [], "entities": [{"text": "MWE extraction from cross-lingual parallel Wikipedia titles", "start_pos": 76, "end_pos": 135, "type": "TASK", "confidence": 0.8246892690658569}]}, {"text": "They found a large number of MWEs, however only a few of them were evaluated.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.9050543904304504}]}, {"text": "In this paper, we describe the process of manually creating a relatively comprehensive Arabic MWE list.", "labels": [], "entities": [{"text": "Arabic MWE list", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.7517399191856384}]}, {"text": "We use the resulting list to tag MWE occurrences in context in a corpus.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: In Section 2 we describe the process of creating the Arabic MWE list.", "labels": [], "entities": [{"text": "Arabic MWE list", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9037417769432068}]}, {"text": "Section 3 discusses the algorithm for automatic deterministic tagging of MWEs in running text, based on pattern matching.", "labels": [], "entities": [{"text": "automatic deterministic tagging of MWEs", "start_pos": 38, "end_pos": 77, "type": "TASK", "confidence": 0.7136816680431366}]}, {"text": "Sections 4 and 5 summarize the results of applying the pattern-matching algorithm on a corpus.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The annotations are manually evaluated by a native speaker of Arabic.", "labels": [], "entities": []}, {"text": "We sub sampled the corpus and examined each MWE instance that is identified by the pattern-matching algorithm.", "labels": [], "entities": []}, {"text": "The evaluation set is relatively small.", "labels": [], "entities": []}, {"text": "Nevertheless, one can see that inmost cases the annotations are correct.", "labels": [], "entities": []}, {"text": "For the VNC, the pattern matching algorithm achieves an accuracy of 98%, for VPC, we get an accuracy of 77.6%, and NNC we achieve an accuracy of 99%.", "labels": [], "entities": [{"text": "pattern matching", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.776111900806427}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9992545247077942}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9988180994987488}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9990322589874268}]}, {"text": "It is worth noting that NNCs are the only category that employs the gapping.", "labels": [], "entities": []}, {"text": "The VVC category contains only a few MWE types, in the sampled set we evaluated 111 instances of merely two different types from which, one was constantly identified incorrectly by the algorithm and it constitutes the majority of the instances (109 instances).", "labels": [], "entities": []}], "tableCaptions": []}