{"title": [{"text": "Two-stage Approach for Hindi Dependency Parsing Using MaltParser", "labels": [], "entities": [{"text": "Hindi Dependency Parsing", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.8133955796559652}, {"text": "MaltParser", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.822900652885437}]}], "abstractContent": [{"text": "In this paper, we present our approach towards dependency parsing of Hindi language as apart of Hindi Shared Task on Parsing, COLING 2012.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.8073295652866364}, {"text": "Hindi Shared Task on Parsing, COLING 2012", "start_pos": 96, "end_pos": 137, "type": "DATASET", "confidence": 0.4789578914642334}]}, {"text": "Our approach includes the effect of using different settings available in Malt Parser following the two-step parsing strategy i.e. splitting the data into interChunks and intraChunks to obtain the best possible LAS 1 , UAS 2 and LA 3 accuracy.", "labels": [], "entities": [{"text": "LAS", "start_pos": 211, "end_pos": 214, "type": "METRIC", "confidence": 0.9133503437042236}, {"text": "UAS 2", "start_pos": 219, "end_pos": 224, "type": "METRIC", "confidence": 0.7904658615589142}, {"text": "LA 3 accuracy", "start_pos": 229, "end_pos": 242, "type": "METRIC", "confidence": 0.7132964332898458}]}, {"text": "Our system achieved best LAS of 90.99% for Gold Standard track and second best LAS of 83.91% for Automated data.", "labels": [], "entities": [{"text": "LAS", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.952567458152771}, {"text": "Gold Standard track", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.6125378906726837}, {"text": "LAS", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9740530252456665}]}], "introductionContent": [{"text": "Hindi is a morphologically rich and relatively free-word order language(MoR-FWO).", "labels": [], "entities": []}, {"text": "Parsing is a challenging task for such MoR-FWO languages like Turkish, Basque, Czech, Arabic, etc.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9592053890228271}]}, {"text": "It has been suggested that these kind of languages can be represented better using dependency framework rather than constituent framework.", "labels": [], "entities": []}, {"text": "Previous efforts on parsing MoR-FWO languages includes, best results were obtained by (, which uses Malt parser with SVM classifier for labeling and using local morph-syntactic, chunk and automatic semantic information as features.  has explored two-stage approach of parsing Hindi.", "labels": [], "entities": [{"text": "parsing MoR-FWO languages", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.7977475523948669}, {"text": "parsing Hindi", "start_pos": 268, "end_pos": 281, "type": "TASK", "confidence": 0.9205718338489532}]}, {"text": "It divided the data into two parts namely, interChunks and intraChunks.", "labels": [], "entities": []}, {"text": "The inter chunk part of the data contains only dependency relations between chunk heads of the sentences while the intra chunk data has the dependency relations between the tokens of a chunk.", "labels": [], "entities": []}, {"text": "The dependency relation labels for interChunk and intraChunk are disjoint.", "labels": [], "entities": []}, {"text": "This approach helps in avoiding intraChunk relations to be marked as interChunk relations and vice-versa.", "labels": [], "entities": []}, {"text": "Following this approach, we explored different parsing algorithm parameters and learner algorithm settings of Malt Parser.", "labels": [], "entities": [{"text": "parsing algorithm", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.8679900467395782}]}, {"text": "The rest of the paper is divided into four sections.", "labels": [], "entities": []}, {"text": "In section 2, we briefly discuss about the training and testing data, accompanied by a few statistics from the treebank, which guides the parameter selection for our experiments.", "labels": [], "entities": []}, {"text": "Section 3 contains the details of our experiments along with the results.", "labels": [], "entities": []}, {"text": "In section 4 we present error analysis.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 24, "end_pos": 38, "type": "METRIC", "confidence": 0.9173840582370758}]}, {"text": "Finally, we conclude the paper in section 5 with a summary and the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments we have used freely available Malt Parser (version 1.6.1) (.", "labels": [], "entities": []}, {"text": "In this section we give an account of experiments performed in a series.", "labels": [], "entities": []}, {"text": "Each experiment focuses on choosing the best option fora certain parameter/feature keeping the other parameter/feature fixed.", "labels": [], "entities": []}, {"text": "In the subsequently following experiments the best parameter chosen from previous experiment is retained.", "labels": [], "entities": []}, {"text": "MaltPaser has a default constraint to give only projectiive output.", "labels": [], "entities": [{"text": "MaltPaser", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9467852115631104}]}, {"text": "However, in the training data we find approximately 1.1% arcs to be non-projective.", "labels": [], "entities": []}, {"text": "To address the nonprojectivity in data, we use pseudo-projective algorithm as proposed by.", "labels": [], "entities": []}, {"text": "We only incorporated the pseudo-projective algorithm in case of interChunk data as in intraChunk we found the arcs to be always projective.", "labels": [], "entities": []}, {"text": "There are three options available with the pseudo-projective algorithm in MaltParser.", "labels": [], "entities": []}, {"text": "We performed intermediary 6 experiments on all of these and got some interesting results.", "labels": [], "entities": []}, {"text": "Pseudo-projective algorithm replaces all the non-projective arcs in the input data to projective arcs by applying a lifting operation.", "labels": [], "entities": []}, {"text": "The lifts are encoded in the dependency labels of the lifted arcs.", "labels": [], "entities": []}, {"text": "In order to apply an inverse transformation to recover the underlying (non projective) dependency graph, there is a need to encode information about lifting operations in arc-labels.", "labels": [], "entities": []}, {"text": "The encoding scheme can be varied according to marking_strategy and there are currently five of them: none, baseline, head, path and head+path().", "labels": [], "entities": []}, {"text": "We performed intermediary experiments separately on each of them and observed that head option gives the best result.", "labels": [], "entities": []}, {"text": "This option projectivizes input data with head encoding for labels.", "labels": [], "entities": []}, {"text": "Secondly, there is an option called covered_root, which is mainly used for handling dangling punctuation.", "labels": [], "entities": []}, {"text": "This option has five values: none, ignore, left, right and head.", "labels": [], "entities": [{"text": "head", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9417509436607361}]}, {"text": "In our intermediary experiments, we found that ignore gave better results than others.", "labels": [], "entities": []}, {"text": "On the basis of lifting order, there are two ways to lift the non-projective arcs namely, shortest and deepest.", "labels": [], "entities": []}, {"text": "In the deepest lifting order, most deeply nested non-projective arc is lifted first, not the shortest one.", "labels": [], "entities": []}, {"text": "In our experiments we found that deepest has no effect in increasing the parsing accuracy rather there is a slight decrease in the accuracy as compared to shortest.", "labels": [], "entities": [{"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9614388942718506}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.936250627040863}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9994939565658569}]}, {"text": "We tried to experiment with the types of features that can be used in FEATS column in the CoNLL-X format.", "labels": [], "entities": [{"text": "FEATS", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.47174492478370667}, {"text": "CoNLL-X format", "start_pos": 90, "end_pos": 104, "type": "DATASET", "confidence": 0.8791713118553162}]}, {"text": "We considered four ways: 1)without any information in FEATS column 2) only tam 4 and vib 5 information, 3)tam and vib along with chunkType and 4)with all the information present by default.", "labels": [], "entities": [{"text": "FEATS", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.7079840898513794}]}, {"text": "The best results were obtained using all information.", "labels": [], "entities": []}, {"text": "All this could only be done for the Gold track as such information about the features is not provided for Automatic track.", "labels": [], "entities": [{"text": "Gold track", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.9460257291793823}]}, {"text": "This is the major reason for the difference in the parsing accuracies between gold and auto data. has shown that nivre_eager algorithm gives the best accuracy for Hindi.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9632352590560913}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9986675977706909}]}, {"text": "Our intermediary experiments also support the same.", "labels": [], "entities": []}, {"text": "We also explored the roothandling option which can be normal, strict and relaxed.", "labels": [], "entities": []}, {"text": "Our experiments showed that relaxed option gives the best accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9993090629577637}]}, {"text": "In relaxed option, root dependents are not attached during parsing (attached with default label afterwards) and reduction of unattached tokens is permissible.", "labels": [], "entities": []}, {"text": "There are three types of prediction strategies available in MaltParser : 1.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.9188782572746277}]}, {"text": "combined(default): Combines the prediction of the transition and the arc label . 2. sequential: Predicts the transition and continues to predict the arc label if the transition requires an arc label.", "labels": [], "entities": []}, {"text": "3. branching: Predicts the transition and if the transition does not require any arc label then the non determinism is resolved, but if the predicted transition requires an arc label then the parser continues to predict the arc label.", "labels": [], "entities": []}, {"text": "We performed experiments with the above options and found that using branching there is an increase in the parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 107, "end_pos": 114, "type": "TASK", "confidence": 0.9641975164413452}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9129857420921326}]}, {"text": "In our experiments, we used the LIBSVM learner algorithm following the SVM settings(s0t1d2g0.12r0.3n0.5m100c0.7e0.5) in experiments reported by) for Hindi.", "labels": [], "entities": []}, {"text": "These settings gave a better result over the default SVM settings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Top 5 most frequent errors", "labels": [], "entities": []}]}