{"title": [{"text": "Graph Based Similarity Measures for Synonym Extraction from Parsed Text", "labels": [], "entities": [{"text": "Similarity Measures", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.785278856754303}, {"text": "Synonym Extraction from Parsed Text", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.9013181805610657}]}], "abstractContent": [{"text": "We learn graph-based similarity measures for the task of extracting word synonyms from a corpus of parsed text.", "labels": [], "entities": [{"text": "extracting word synonyms from a corpus of parsed text", "start_pos": 57, "end_pos": 110, "type": "TASK", "confidence": 0.8433434698316786}]}, {"text": "A constrained graph walk variant that has been successfully applied in the past in similar settings is shown to outperform a state-of-the-art syntactic vector-based approach on this task.", "labels": [], "entities": []}, {"text": "Further, we show that learning specialized similarity measures for different word types is advantageous.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many applications of natural language processing require measures of lexico-semantic similarity.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.6982463796933492}]}, {"text": "Examples include summarization (), question answering (, and textual entailment ().", "labels": [], "entities": [{"text": "summarization", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.973109781742096}, {"text": "question answering", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9107893109321594}]}, {"text": "Graph-based methods have been successfully applied to evaluate word similarity using available ontologies, where the underlying graph included word senses and semantic relationships between them (.", "labels": [], "entities": []}, {"text": "Another line of research aims at eliciting semantic similarity measures directly from freely available corpora, based on the distributional similarity assumption.", "labels": [], "entities": []}, {"text": "In this domain, vector-space methods give state-ofthe-art performance.", "labels": [], "entities": []}, {"text": "Previously, a graph based framework has been proposed that models word semantic similarity from parsed text.", "labels": [], "entities": [{"text": "word semantic similarity from parsed text", "start_pos": 66, "end_pos": 107, "type": "TASK", "confidence": 0.8095673024654388}]}, {"text": "The underlying graph in this case describes a text corpus as connected dependency structures, according to the schema shown in.", "labels": [], "entities": []}, {"text": "The toy graph shown includes the dependency analysis of two sentences: \"a major environmental disaster is under way\", and \"combat the environmental catastrophe\".", "labels": [], "entities": []}, {"text": "In the graph, word mentions (in circles) and word types (in squares) are both represented as nodes.", "labels": [], "entities": []}, {"text": "Each word mention is linked to its corresponding word type; for example, the nodes \"environmental 3 \" and \"environmental 204 \" represent distinct word mentions and both nodes are linked to the word type \"environmental\".", "labels": [], "entities": []}, {"text": "1 For every edge in the graph, there exists an edge in the opposite direction (not shown in the.", "labels": [], "entities": []}, {"text": "In this graph, the terms disaster and catastrophe are related due to the connecting path disaster \u2212\u2192 disaster 3 Given a query, which consists of a word of interest (e.g., 'disaster'), various graph-based similarity metrics can be used to assess inter-node relatedness, so that a list of nodes ranked by their similarity to the query is returned to the user.", "labels": [], "entities": []}, {"text": "An advantage of graph-based similarity approaches is that they produce similarity scores that reflect structural infor-mation in the graph.", "labels": [], "entities": []}, {"text": "Semantically similar terms are expected to share connectivity patterns with the query term in the graph, and thus appear at the top of the list.", "labels": [], "entities": []}, {"text": "Notably, different edge types, as well as the paths traversed, may have varying importance for different types of similarity sought.", "labels": [], "entities": []}, {"text": "For example, in the parsed text domain, noun similarity and verb similarity are associated with different syntactic phenomena.", "labels": [], "entities": [{"text": "noun similarity", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7685982584953308}]}, {"text": "To this end, we consider a path constrained graph walk (PCW) algorithm, which allows one to learn meaningful paths given a small number of labeled examples and incorporates this information in assessing node relatedness in the graph (.", "labels": [], "entities": []}, {"text": "PCW have been successfully applied to the extraction of named entity coordinate terms, including city and person names, from graphs representing newswire text, where the specialized measures learned outperformed the state-ofthe-art dependency vectors method) for small-and medium-sized corpora.", "labels": [], "entities": [{"text": "PCW", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8051254153251648}, {"text": "extraction of named entity coordinate terms", "start_pos": 42, "end_pos": 85, "type": "TASK", "confidence": 0.8248472015062968}]}, {"text": "In this work, we apply the path constrained graph walk method to the task of eliciting general word relatedness from parsed text, conducting a set of experiments on the task of synonym extraction.", "labels": [], "entities": [{"text": "general word relatedness from parsed text", "start_pos": 87, "end_pos": 128, "type": "TASK", "confidence": 0.7421255260705948}, {"text": "synonym extraction", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.9281989932060242}]}, {"text": "While the tasks of named entity extraction and synonym extraction from text have been treated separately in the literature, this work shows that both tasks can be addressed using the same general framework.", "labels": [], "entities": [{"text": "named entity extraction", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.6194569170475006}, {"text": "synonym extraction from text", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.892143651843071}]}, {"text": "Our results are encouraging: the PCW model yields superior results to the dependency vectors approach.", "labels": [], "entities": []}, {"text": "Further, we show that learning specialized similarity measures per word type (nouns, verbs and adjectives) is preferable to applying a uniform model for all word types.", "labels": [], "entities": []}], "datasetContent": [{"text": "To allow effective learning, we constructed a dataset that represents strict word synonymy relations for multiple word types.", "labels": [], "entities": []}, {"text": "The dataset consists of 68 examples, where each example query consists of a single term of interest, with its synonym defined as a single correct answer.", "labels": [], "entities": []}, {"text": "The dataset includes noun synonym pairs (22 examples), adjectives (24) and verbs.", "labels": [], "entities": []}, {"text": "Example synonym pairs are shown in.", "labels": [], "entities": []}, {"text": "A corpus of parsed text was constructed using the British National Corpus.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 50, "end_pos": 73, "type": "DATASET", "confidence": 0.9292221069335938}]}, {"text": "The full BNC corpus is a 100-million word collection of samples of written and spoken contemporary British English texts.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.9354657232761383}]}, {"text": "We extracted relevant sentences, which contained the synonymous words, from the BNC corpus.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 80, "end_pos": 90, "type": "DATASET", "confidence": 0.9698328971862793}]}, {"text": "(The number of extracted sentences was limited to 2,000 per word.)", "labels": [], "entities": []}, {"text": "For infrequent words, we extracted additional example sentences from Associated Press (AP) articles included in the AQUAINT corpus (.", "labels": [], "entities": [{"text": "AQUAINT corpus", "start_pos": 116, "end_pos": 130, "type": "DATASET", "confidence": 0.8997713625431061}]}, {"text": "(Sentence count was complemented to 300 per word, where applicable.)", "labels": [], "entities": [{"text": "Sentence count", "start_pos": 1, "end_pos": 15, "type": "METRIC", "confidence": 0.7793617844581604}]}, {"text": "The constructed corpus, BNC+AP, includes 1.3 million words overall.", "labels": [], "entities": [{"text": "BNC+AP", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.6740888555844625}]}, {"text": "This corpus was parsed using the Stanford dependency parser  Given a query like {term=\"movie\"}, we would like to get synonymous words, such as film, to appear at the top of the retrieved list.", "labels": [], "entities": []}, {"text": "In our experimental setting, we assume that the word type of the query term is known.", "labels": [], "entities": []}, {"text": "Rather than rank all words (terms) in response to a query, we use available (noisy) part of speech information to narrow down the search to the terms of the same type as the query term, e.g. for the query \"film\" we retrieve nodes of type \u03c4 =noun.", "labels": [], "entities": []}, {"text": "We applied the PCW method to learn separate models for noun, verb and adjective queries.", "labels": [], "entities": []}, {"text": "The path trees were constructed using the paths leading to the node known to be a correct answer, as well as to the otherwise irrelevant top-ranked 10 terms.", "labels": [], "entities": []}, {"text": "We required the paths considered by PCW to include exactly 6 segments (edges).", "labels": [], "entities": [{"text": "PCW", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.9468716979026794}]}, {"text": "Such paths represent distributional similarity phenomena, allowing a direct comparison against the DV method.", "labels": [], "entities": []}, {"text": "In conducting the constrained walk, we applied a threshold of 0.5 to truncate paths associated with lower probability of reaching a relevant response, following on previous work.", "labels": [], "entities": []}, {"text": "We implemented DV using code made available by its authors, 3 where we converted the syntactic patterns specified to Stanford dependency parser conventions.", "labels": [], "entities": []}, {"text": "The parameters of the DV method were set to medium context and oblique edge weighting scheme, which were found to perform best.", "labels": [], "entities": []}, {"text": "In applying a vector-space based method, a similarity score needs to be computed between every candidate from the corpus and the query term to construct a ranked list.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 43, "end_pos": 59, "type": "METRIC", "confidence": 0.9608485102653503}]}, {"text": "In practice, we used the union of the top 300 words retrieved by PCW as candidate terms for DV.", "labels": [], "entities": [{"text": "PCW", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9663052558898926}, {"text": "DV", "start_pos": 92, "end_pos": 94, "type": "TASK", "confidence": 0.7964913845062256}]}, {"text": "We evaluate the following variants of DV: hav-  ing inter-word similarity computed using Lin's measure (Lin, 1998) (DV-Lin), or using cosine similarity (DV-Cos).", "labels": [], "entities": []}, {"text": "In addition, we consider a non-syntactic variant, where a word's vector consists of its cooccurrence counts with other terms (using a window of two words); that is, ignoring the dependency structure (CO-Lin).", "labels": [], "entities": []}, {"text": "Finally, in addition to the PCW model described above (PCW), we evaluate the PCW approach in settings where random, noisy, edges have been eliminated from the underlying graph.", "labels": [], "entities": []}, {"text": "Specifically, dependency links in the graph maybe associated with pointwise mutual information (PMI) scores of the linked word mention pairs; edges with low scores are assumed to represent word co-occurrences of low significance, and so are removed.", "labels": [], "entities": []}, {"text": "We empirically set the PMI score threshold to 2.0, using cross validation (PCW-P).", "labels": [], "entities": [{"text": "PMI score threshold", "start_pos": 23, "end_pos": 42, "type": "METRIC", "confidence": 0.8176002105077108}]}, {"text": "In addition to the specialized PCW models, we also learned a uniform model overall word types in these settings; that is, this model is trained using the union of all training examples, being learned and tested using a mixture of queries of all types (PCW-P-U).", "labels": [], "entities": []}, {"text": "gives the results of 5-fold cross-validation experiments in terms of mean average precision (MAP).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 69, "end_pos": 97, "type": "METRIC", "confidence": 0.9148516853650411}]}, {"text": "Since there is a single correct answer per query, these results correspond to the mean reciprocal rank (MRR).", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 82, "end_pos": 108, "type": "METRIC", "confidence": 0.7982514103253683}]}, {"text": "5 As shown, the dependency vectors model applied using Lin similarity (DV-Lin) performs best among the vector-based models.", "labels": [], "entities": [{"text": "Lin similarity (DV-Lin)", "start_pos": 55, "end_pos": 78, "type": "METRIC", "confidence": 0.8207849621772766}]}, {"text": "The improvement achieved due to edge weighting com-pared with the co-occurrence model (CO-Lin) is large, demonstrating that syntactic structure is very informative for modeling word semantics.", "labels": [], "entities": []}, {"text": "Interestingly, the impact of applying the Lin similarity measure versus cosine (DV-Cos) is even more profound.", "labels": [], "entities": [{"text": "Lin similarity measure", "start_pos": 42, "end_pos": 64, "type": "METRIC", "confidence": 0.8801449537277222}]}, {"text": "Unlike the cosine measure, Lin's metric was designed for the task of evaluating word similarity from corpus statistics; it is based on the mutual information measure, and allows one to downweight random word co-occurrences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: 5-fold cross validation results: MAP", "labels": [], "entities": [{"text": "MAP", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.4012729525566101}]}]}