{"title": [{"text": "Toward Learning Perceptually Grounded Word Meanings from Unaligned Parallel Data", "labels": [], "entities": []}], "abstractContent": [{"text": "In order for robots to effectively understand natural language commands, they must be able to acquire a large vocabulary of meaning representations that can be mapped to perceptual features in the external world.", "labels": [], "entities": []}, {"text": "Previous approaches to learning these grounded meaning representations require detailed annotations at training time.", "labels": [], "entities": []}, {"text": "In this paper, we present an approach which is capable of jointly learning a policy for following natural language commands such as \"Pick up the tire pallet,\" as well as a mapping between specific phrases in the language and aspects of the external world; for example the mapping between the words \"the tire pallet\" and a specific object in the environment.", "labels": [], "entities": []}, {"text": "We assume the action policy takes a parametric form that factors based on the structure of the language, based on the G 3 framework and use stochastic gradient ascent to optimize policy parameters.", "labels": [], "entities": []}, {"text": "Our preliminary evaluation demonstrates the effectiveness of the model on a corpus of \"pick up\" commands given to a robotic forklift by untrained users.", "labels": [], "entities": []}], "introductionContent": [{"text": "In order for robots to robustly understand human language, they must have access to meaning representations capable of mapping between symbols in the language and aspects of the external world which are accessible via the robot's perception system.", "labels": [], "entities": []}, {"text": "Previous approaches have represented word meanings as symbols in some specific symbolic language, either programmed by hand] or learned.", "labels": [], "entities": []}, {"text": "Because word meanings are represented as symbols, rather than perceptually grounded features, the mapping between these symbols and the external world must still be defined.", "labels": [], "entities": []}, {"text": "Furthermore, the uncertainty of the mapping between constituents in the language and aspects of the external world cannot be explicitly represented by the model.", "labels": [], "entities": []}, {"text": "Language grounding approaches, in contrast, map words in the language to groundings in the external world.", "labels": [], "entities": []}, {"text": "Groundings are the specific physical concept that is referred to by the language and can be objects (e.g., a truck or a door), places (e.g., a particular location in the world), paths (e.g., a trajectory through the environment), or events (e.g., a sequence of robot actions).", "labels": [], "entities": [{"text": "Groundings are the specific physical concept that is referred to by the language and can be objects (e.g., a truck or a door), places (e.g., a particular location in the world), paths (e.g., a trajectory through the environment), or events (e.g., a sequence of robot actions)", "start_pos": 0, "end_pos": 275, "type": "Description", "confidence": 0.8054752017630905}]}, {"text": "This symbol grounding approach represents word meanings as functions which take as input a perceptual representation of a grounding and return whether it matches words in the language.", "labels": [], "entities": []}, {"text": "Recent work has demonstrated how to learn grounded word meanings from a parallel corpus of natural language commands paired with groundings in the external world.", "labels": [], "entities": []}, {"text": "However, learning model parameters required that the parallel corpus be augmented with additional annotations specifying the alignment between specific phrases in the language and corresponding groundings in the external world.", "labels": [], "entities": []}, {"text": "shows an example command from the training set paired with these alignment annotations, represented as arrows 7 pointing from each linguistic constituent to a corresponding grounding.", "labels": [], "entities": []}, {"text": "Our approach in this paper relaxes these annotation requirements and learns perceptually grounded word meanings from an unaligned parallel corpus that only provides supervision for the top-level action that corresponds to a natural language command.", "labels": [], "entities": []}, {"text": "Our system takes as input a state/action space for the robot defining a space of possible groundings and available actions in the external world.", "labels": [], "entities": []}, {"text": "In addition it requires a corpus of natural language commands paired with the correct action executed in the environment.", "labels": [], "entities": []}, {"text": "For example, an entry in the corpus consists of a natural language command such as \"Pick up the tire pallet\" given to a robotic forklift, paired with an action sequence of the robot as drives to the tire pallet, inserts its forks, and raises it off the ground, drives to the truck, and sets it down.", "labels": [], "entities": []}, {"text": "To learn from an unaligned corpus, we derive anew training algorithm that combines the Generalized Grounding Graph (G 3 ) framework introduced by with the policy gradient method described by.", "labels": [], "entities": []}, {"text": "We assume a specific parametric form for the action policy that is defined by the linguistic structure of the natural language command.", "labels": [], "entities": []}, {"text": "The system learns a policy parameters that maximize expected reward using stochastic gradient ascent.", "labels": [], "entities": []}, {"text": "By factoring the policy according to the structure of language, we can propagate the error signal to each term, allowing the system to infer groundings for each linguistic constituent even without direct supervision.", "labels": [], "entities": []}, {"text": "We evaluate our model using a corpus of natural language commands collected from untrained users on the internet, commanding the robot to pickup objects or drive to locations in the environment.", "labels": [], "entities": []}, {"text": "The evaluation demonstrates that the model is able to predict both robot actions and noun phrase groundings with high accuracy, despite having no direct supervision for noun phrase groundings.", "labels": [], "entities": [{"text": "noun phrase groundings", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.6553540130456289}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9986490607261658}, {"text": "noun phrase groundings", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.6752967238426208}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on the training set and test set.", "labels": [], "entities": []}]}