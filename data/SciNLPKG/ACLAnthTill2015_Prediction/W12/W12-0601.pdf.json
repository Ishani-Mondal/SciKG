{"title": [{"text": "Unsupervised Part-of-Speech Tagging in Noisy and Esoteric Domains with a Syntactic-Semantic Bayesian HMM", "labels": [], "entities": [{"text": "Unsupervised Part-of-Speech Tagging", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5781091054280599}]}], "abstractContent": [{"text": "Unsupervised part-of-speech (POS) tagging has recently been shown to greatly benefit from Bayesian approaches where HMM parameters are integrated out, leading to significant increases in tagging accuracy.", "labels": [], "entities": [{"text": "Unsupervised part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.578515370686849}, {"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9441028833389282}]}, {"text": "These improvements in unsuper-vised methods are important especially in specialized social media domains such as Twitter where little training data is available.", "labels": [], "entities": []}, {"text": "Here, we take the Bayesian approach one step further by integrating semantic information from an LDA-like topic model with an HMM.", "labels": [], "entities": []}, {"text": "Specifically, we present Part-of-Speech LDA (POSLDA), a syntactically and semantically consistent genera-tive probabilistic model.", "labels": [], "entities": []}, {"text": "This model discovers POS specific topics from an unla-belled corpus.", "labels": [], "entities": []}, {"text": "We show that this model consistently achieves improvements in un-supervised POS tagging and language mod-eling over the Bayesian HMM approach with varying amounts of side information in the noisy and esoteric domain of Twitter.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.8179197311401367}]}], "introductionContent": [{"text": "The explosion of social media in recent years has led to the need for NLP tools like part-of-speech (POS) taggers that are robust enough to handle data that is becoming increasingly \"noisy.\"", "labels": [], "entities": [{"text": "part-of-speech (POS) taggers", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.658553683757782}]}, {"text": "Unfortunately, many NLP systems fail at out-of-domain data and struggle with the informal style of social text.", "labels": [], "entities": []}, {"text": "With spelling errors, abbreviations, uncommon acronyms, and excessive use of slang, systems that are designed for traditional corpora such as news articles may perform poorly when given difficult input such as a Twitter feed (.", "labels": [], "entities": []}, {"text": "Recognizing the limitations of existing systems, develop a POS tagger specifically for Twitter, by creating a training corpus as well as devising a tag set that includes parts of speech that are uniquely found in online language, such as emoticons (smilies).", "labels": [], "entities": []}, {"text": "This is an important step forward, but a POS tagger tailored to Twitter cannot tackle the social Web as a whole.", "labels": [], "entities": []}, {"text": "Other online communities have their own styles, slang, memes, and other idiosyncrasies, so a system trained for one community may not apply to others.", "labels": [], "entities": []}, {"text": "For example, the 140-character limit of Twitter encourages abbreviations and word-dropping that may not be found in less restrictive venues.", "labels": [], "entities": []}, {"text": "The first-person subject is often assumed in \"status messages\" that one finds in Twitter and Facebook, so the pronominal subject can be dropped, even in English, leading to messages like \"Went out\" instead of \"I went out.\"", "labels": [], "entities": []}, {"text": "Not only does Twitter follow these unusual grammatical patterns, but many messages contain \"hashtags\" which could be considered their own syntactic class not found in other data sources.", "labels": [], "entities": []}, {"text": "For these reasons, POS parameters learned from Twitter data will not necessarily fit other social data.", "labels": [], "entities": []}, {"text": "In general, concerns about the limitations of domain-dependent models have motivated the use of sophisticated unsupervised methods.", "labels": [], "entities": []}, {"text": "Interest in unsupervised POS induction has been revived in recent years after Bayesian HMMs are shown to increase accuracy by up to 14 percentage points over basic maximum-likelihood estimation.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9136554598808289}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9988154172897339}]}, {"text": "Despite falling well short of the accuracy obtained with supervised taggers, unsupervised approaches are preferred in situations where there is no access to large quantities of training data in a specific domain, which is increasingly common with Web data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9989479184150696}]}, {"text": "We therefore hope to continue improving accuracy with unsupervised approaches by introducing semantics as an additional source of information for this task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.99798583984375}]}, {"text": "The ambiguities of language are amplified through social media, where new words or spellings of words are routinely invented.", "labels": [], "entities": []}, {"text": "For example, \"ow\" on Twitter can be a shorthand for \"how,\" in addition to its more traditional use as an expression of pain (ouch).", "labels": [], "entities": []}, {"text": "While POS assignment is inherently a problem of syntactic disambiguation, we hypothesize that the underlying semantic content can aid the disambiguation task.", "labels": [], "entities": [{"text": "POS assignment", "start_pos": 6, "end_pos": 20, "type": "TASK", "confidence": 0.9376819431781769}, {"text": "syntactic disambiguation", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.740544855594635}]}, {"text": "If we know that the overall content of a message is about police, then the word \"cop\" is likely to be a noun, whereas if the context is about shopping, this could be slang for acquiring or stealing (verb).", "labels": [], "entities": []}, {"text": "The HMM approach will often be able to tag these occurrences appropriately given the context, but in many cases the syntactic context maybe limited or misleading due to the noisy nature of the data.", "labels": [], "entities": []}, {"text": "Thus, we believe that semantic context will offer additional evidence toward making an accurate prediction.", "labels": [], "entities": []}, {"text": "Following this intuition, this paper presents a semantically and syntactically coherent Bayesian model that uncovers POS-specific sub-topics within general semantic topics, as in latent Dirichlet allocation (LDA) (, which we call part-of-speech LDA, or POSLDA.", "labels": [], "entities": []}, {"text": "The resulting posterior distributions will reflect specialized topics such as \"verbs about dining\" or \"nouns about politics\".", "labels": [], "entities": []}, {"text": "To the best of our knowledge, we also present the first experiments with unsupervised tagging fora social media corpus.", "labels": [], "entities": []}, {"text": "In this work, we focus on Twitter because the labeled corpus by allows us to quantitatively evaluate our approach.", "labels": [], "entities": []}, {"text": "We demonstrate the model's utility as a predictive language model by its low perplexity on held-out test data as compared to several related topic models, and most importantly, we show that this model achieves statistically significant and consistent improvements in unsupervised POS tagging accuracy over a Bayesian HMM.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 280, "end_pos": 291, "type": "TASK", "confidence": 0.7754674255847931}, {"text": "accuracy", "start_pos": 292, "end_pos": 300, "type": "METRIC", "confidence": 0.8431951403617859}]}, {"text": "These results support our hypothesis that semantic information can directly improve the quality of POS induction, and our experiments present an in-depth exploration of this task on informal social text.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 99, "end_pos": 112, "type": "TASK", "confidence": 0.9830667674541473}]}, {"text": "The next section discusses related work, which is followed by a description of our model, POSLDA.", "labels": [], "entities": [{"text": "POSLDA", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.7813370227813721}]}, {"text": "We then present POS tagging results on the Twitter POS dataset ().", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.7791061401367188}, {"text": "Twitter POS dataset", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.882867713769277}]}, {"text": "Section 5 describes further experiments on the POSLDA model and section 6 includes a discussion on the results and why POSLDA can do better on POS tagging than a vanilla Bayesian HMM.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 143, "end_pos": 154, "type": "TASK", "confidence": 0.7581698894500732}]}, {"text": "Finally, section 7 concludes with a discussion on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate the veracity of our approach, we performed a number of POS tagging experiments using the POSLDA model.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.7659202814102173}]}, {"text": "Our data is the recent Twitter POS dataset released at ACL 2011 by consisting of approximately 26,000 words across 1,827 tweets.", "labels": [], "entities": [{"text": "Twitter POS dataset released at ACL 2011", "start_pos": 23, "end_pos": 63, "type": "DATASET", "confidence": 0.8168365359306335}]}, {"text": "This dataset provides a unique opportunity to test our unsupervised approach in a domain where it would likely be of most use -one that is novel and therefore lacking large amounts of training data.", "labels": [], "entities": []}, {"text": "We feel that this sort of specialized domain will become the norm -particularly in social media analysis -as user generated content continues to grow in size and accessibility.", "labels": [], "entities": [{"text": "social media analysis", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.7873110771179199}]}, {"text": "The Twitter dataset uses a domain-dependent tag set of 25 tags that are described in).", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9123652577400208}]}, {"text": "For our experiments, we follow the established form of and Goldwater and Griffiths (2007) for unsupervised POS tagging by making use of a tag dictionary to constrain the possible tag choices for each word and therefore render the problem closer to disambiguation.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 107, "end_pos": 118, "type": "TASK", "confidence": 0.8075295388698578}]}, {"text": "Like, we employ a number of dictionaries with varying degrees of knowledge.", "labels": [], "entities": []}, {"text": "We use the full corpus of tweets 1 and construct a tag dictionary which contains the tag information fora word only when it appears more than d times in the corpus.", "labels": [], "entities": []}, {"text": "We ran experiments ford = 1, 2, 3, 5, 10, and \u221e where the problem becomes POS clustering.", "labels": [], "entities": [{"text": "POS clustering", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.6440149396657944}]}, {"text": "We report both tagging accuracy and the variation of information (VI), which computes the information lost in moving from one clustering C to another C :.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9876353144645691}, {"text": "variation of information (VI)", "start_pos": 40, "end_pos": 69, "type": "METRIC", "confidence": 0.9656188984711965}]}, {"text": "This can be interpreted as a measure of similarity between the clusterings, where a smaller value indicates higher similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9833210706710815}]}, {"text": "We run our Gibbs sampler for 20,000 iterations and obtain a maximum a posteriori (MAP) estimate for each word's tag by employing simulated annealing.", "labels": [], "entities": [{"text": "maximum a posteriori (MAP) estimate", "start_pos": 60, "end_pos": 95, "type": "METRIC", "confidence": 0.8201325706073216}]}, {"text": "Each posterior probability p(c, z|\u00b7) in the sampling distribution is raised to the power of bringing a system from an arbitrary state to one with the lowest energy, thus viewing the Gibbs sampling procedure as a random search whose goal is to identify the MAP tag sequence -a technique that is also employed by.", "labels": [], "entities": []}, {"text": "Finally, we run each experiment 5 times from random initializations and report the average accuracy and variation of information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.999258816242218}]}, {"text": "In our experiments, we use 8 content classes that correspond to the following parts-of-speech: noun, proper noun, proper noun + possessive, proper noun + verbal, verb, adjective, adverb, and other abbreviations / foreign words.", "labels": [], "entities": []}, {"text": "We chose these classes because intuitively they are the types of words whose generative probability will depend on the given latent topic.", "labels": [], "entities": []}, {"text": "As the Twitter POS data consists of 25 distinct tags, this leaves 17 remaining classes for function words.", "labels": [], "entities": [{"text": "Twitter POS data", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.7924894491831461}]}, {"text": "In this section, we report results for K = 10 topics.", "labels": [], "entities": []}, {"text": "We will discuss the effect of varying K in section 4.2.", "labels": [], "entities": [{"text": "K", "start_pos": 38, "end_pos": 39, "type": "METRIC", "confidence": 0.9207173585891724}]}, {"text": "We set symmetric priors with \u03b1 = 1.0/K = 0.1, \u03b2 = 0.5, and \u03b3 = 0.01.", "labels": [], "entities": []}, {"text": "As is demonstrated in, our POSLDA model shows marked improvements over a random tag assignment and, more importantly, the Bayesian HMM approach described by  In this section we present further experiments on the raw output of POSLDA to demonstrate its capabilities beyond simply POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 279, "end_pos": 290, "type": "TASK", "confidence": 0.7246085107326508}]}, {"text": "We show the model's ability both qualitatively and quantitatively to capture the semantic (or \"content\") and syntactic (or \"functional\") axes of information prevalent in a corpus made up of social media data.", "labels": [], "entities": []}, {"text": "We begin qualitatively with topic interpretability when the model is learned given a collection of unannotated Twitter messages, and then present quantitative results on the ability of POSLDA as a predictive language model in the Twitter domain.", "labels": [], "entities": [{"text": "topic interpretability", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.682715117931366}]}], "tableCaptions": [{"text": " Table 1: POS tagging results on Twitter dataset.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7326868623495102}, {"text": "Twitter dataset", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.9353857636451721}]}]}