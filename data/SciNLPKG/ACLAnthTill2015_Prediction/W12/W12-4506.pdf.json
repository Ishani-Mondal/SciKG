{"title": [{"text": "ICT: System Description for CoNLL-2012", "labels": [], "entities": [{"text": "ICT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8051546216011047}, {"text": "CoNLL-2012", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.7326284050941467}]}], "abstractContent": [{"text": "In this paper, we present our system description for the CoNLL-2012 coreference resolution task on English, Chinese and Arabic.", "labels": [], "entities": [{"text": "CoNLL-2012 coreference resolution task", "start_pos": 57, "end_pos": 95, "type": "TASK", "confidence": 0.6954245567321777}]}, {"text": "We investigate a projection-based model in which we first translate Chinese and Arabic into English, run a publicly available coreference system, and then use anew projection algorithm to map the coreferring entities back from English into mention candidates detected in the Chi-nese and Arabic source.", "labels": [], "entities": []}, {"text": "We compare to a baseline that just runs the English coref-erence system on the supplied parses for Chinese and Arabic.", "labels": [], "entities": []}, {"text": "Because our method does not beat the baseline system on the development set, we submit outputs generated by the baseline system as our final submission.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modeling multilingual unrestricted coreference in the OntoNotes data is the shared task for CoNLL-2012.", "labels": [], "entities": [{"text": "OntoNotes data", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.8967018127441406}, {"text": "CoNLL-2012", "start_pos": 92, "end_pos": 102, "type": "DATASET", "confidence": 0.9210561513900757}]}, {"text": "This is an extension of the CoNLL-2011 shared task and would involve automatic anaphoric mention detection and coreference resolution across three languages -English, Chinese and Arabic -using OntoNotes v5.0 corpus, given predicted information on the syntax, proposition, word sense and named entity layers.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7046559303998947}, {"text": "coreference resolution", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.8807274699211121}]}, {"text": "Automatic identification of coreferring entities and events in text has been an uphill battle for several decades, partly because it can require world knowledge which is not well-defined and partly owing to the lack of substantial annotated data.", "labels": [], "entities": [{"text": "Automatic identification of coreferring entities and events in text", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.8496089908811781}]}, {"text": "For more details, readers can refer to.", "labels": [], "entities": []}, {"text": "Before this year's task, researchers proposed two typical novel methods to address the problem of natural language processing across multiple languages: projection and joint learning).", "labels": [], "entities": []}, {"text": "Specific to this year's coreference resolution task, for projection based method, we could first develop a strong resolver or utilize a publicly available system on English, and translate other languages into English, eventually, we could project the coreferring entities resolved on English back into other language sides.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.9411605596542358}]}, {"text": "Generally, a projection method is easier to develop since it doesn't need sentence alignment across multiple languages.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7174907624721527}]}, {"text": "Thus, in this year's task, we investigate a translation based model to resolve coreference on English, Chinese and Arabic.", "labels": [], "entities": []}, {"text": "The whole process is illustrated in, in which we first use Google Translator to translate Chinese and Arabic into English, and we then employ a strong English coreference resolver to generate coreferring entities, after mapping entities from English into Chinese and Arabic mention candidates, we could obtain coreferring entities for these languages.", "labels": [], "entities": []}, {"text": "Intuitively, the performance of coreference resolver on English should perform better than that on Chinese and Arabic since we have substantial corpus for English and coreference resolution on English is well studied compared to another two languages.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.9282620549201965}, {"text": "coreference resolution", "start_pos": 167, "end_pos": 189, "type": "TASK", "confidence": 0.9322051703929901}]}, {"text": "Thus we could imagine that projecting the results from English into Chinese and Arabic should still beats the baseline system using monolingual resolution method.", "labels": [], "entities": []}, {"text": "However, in our experiments, we obtain negative results on developing set that means our projection based model perform worse than the baseline system.", "labels": [], "entities": []}, {"text": "According to our experimental results on developing set, finally, we submit results of baseline system in order to obtain better ranking.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows, in section 2, we will introduce our method in details, and section 3 is our experimental results, we draw conclusion in section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Experimental results on developing set(F-score) for English.", "labels": [], "entities": [{"text": "developing set(F-score)", "start_pos": 34, "end_pos": 57, "type": "METRIC", "confidence": 0.6579603254795074}]}, {"text": " Table 2: Experimental results on developing set(F-score) for Chinese and Arabic using CoreNLP and  our system.", "labels": [], "entities": [{"text": "F-score", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9191020131111145}, {"text": "CoreNLP", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9667829275131226}]}, {"text": " Table 3: Experimental results on testing set(F-score) using predicted parse tree.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9873020648956299}]}, {"text": " Table 4: Experimental results on testing set(F-score) using golden parse tree.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9892532229423523}]}]}