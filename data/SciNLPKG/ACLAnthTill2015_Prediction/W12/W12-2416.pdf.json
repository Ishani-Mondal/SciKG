{"title": [{"text": "A Prototype Tool Set to Support Machine-Assisted Annotation", "labels": [], "entities": []}], "abstractContent": [{"text": "Manually annotating clinical document corpora to generate reference standards for Natural Language Processing (NLP) systems or Machine Learning (ML) is a time-consuming and labor-intensive endeavor.", "labels": [], "entities": []}, {"text": "Although a variety of open source annotation tools currently exist, there is a clear opportunity to develop new tools and assess functionalities that introduce efficiencies into the process of generating reference standards.", "labels": [], "entities": []}, {"text": "These features include: management of document corpora and batch assignment , integration of machine-assisted verification functions, semi-automated cu-ration of annotated information, and support of machine-assisted pre-annotation.", "labels": [], "entities": [{"text": "batch assignment", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7556920945644379}]}, {"text": "The goals of reducing annotator workload and improving the quality of reference standards are important considerations for development of new tools.", "labels": [], "entities": []}, {"text": "An infrastructure is also needed that will support large-scale but secure annotation of sensitive clinical data as well as crowdsourcing which has proven successful fora variety of annotation tasks.", "labels": [], "entities": []}, {"text": "We introduce the Ex-tensible Human Oracle Suite of Tools (eHOST) http://code.google.com/p/ehost that provides such functionalities that when coupled with server integration offer an end-to-end solution to carryout small or large scale as well as crowd sourced annotation projects.", "labels": [], "entities": []}], "introductionContent": [{"text": "Supervised learning methods benefit from a reference standard that is used to train and evaluate the performance of Natural Language Processing (NLP) or Machine Learning (ML) systems for information extraction and classification.", "labels": [], "entities": [{"text": "information extraction and classification", "start_pos": 187, "end_pos": 228, "type": "TASK", "confidence": 0.7712287306785583}]}, {"text": "Ideally, generating a reference standard involves the review of more than one annotator with an accompanying adjudication step to resolve discrepancies (.", "labels": [], "entities": []}, {"text": "However, manual annotation of clinical, texts is time-consuming, expensive, and requires considerable effort.", "labels": [], "entities": []}, {"text": "Reducing the time and costs required for manual annotation could be achieved by developing new tools that integrate methods to more efficiently annotate clinical texts and integrate a management interface that allows administration of large or small scale annotation projects.", "labels": [], "entities": []}, {"text": "Such a tool could also integrate methods to pre-annotate entities such as noun phrases or clinical concepts mapped to a standard vocabulary.", "labels": [], "entities": []}, {"text": "Efficiencies could be realized via reduction inhuman workload, modification of annotation tasks that could include crowd sourcing, and implementation of machineassisted approaches.", "labels": [], "entities": [{"text": "crowd sourcing", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.7489571571350098}]}, {"text": "Typically annotation of clinical texts requires human reviewers to identify information classes of interest called \"markables\".", "labels": [], "entities": []}, {"text": "These tasks may also require reviewers to assign attributes to those information classes and build relations between spans of annotated text.", "labels": [], "entities": []}, {"text": "For each annotation task there maybe one or many types of markables and each markable class maybe associated with one or more spans of text and may include single or even multiple tokens.", "labels": [], "entities": []}, {"text": "These tasks may occur simultaneously, or may also be done in different steps and by multiple reviewers.", "labels": [], "entities": []}, {"text": "Furthermore, these activities require written guidelines that clearly explicate what infor-mation to annotate, specifics about each markable class, such as how much information to include in annotated spans, or syntactic rules to provide further guidance on annotated spans.", "labels": [], "entities": []}, {"text": "Annotation tasks may benefit by incorporating rules or guidelines as part of the annotation task itself in the form of machine-assisted verification.", "labels": [], "entities": []}, {"text": "There are many annotation tools available, and the majority of them were designed for linguistic or gene annotation.", "labels": [], "entities": []}, {"text": "Linguistic annotation tools such as Callisto and WordFreak are standalone clients suitable for small to medium scale tasks where collaborative effort is not emphasized.", "labels": [], "entities": [{"text": "WordFreak", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.968756377696991}]}, {"text": "Functionality integrated with eHOST was inspired by existing features of these tools with the intent of providing a more efficient means of reference standard generation in a large collaborative environment.", "labels": [], "entities": []}, {"text": "One annotation tool called Knowtator, a plug-in for Prot\u00e9g\u00e9) developed by has been widely used to annotate clinical texts and generate reference standards.", "labels": [], "entities": []}, {"text": "However, no standalone system exists that can provide end users with the ability to manually or semiautomatically edit, curate, and easily navigate annotated information.", "labels": [], "entities": []}, {"text": "There are also specific functionalities that are missing from open source annotation tools in the clinical and biomedical domains that would introduce efficiencies into manual annotation tasks.", "labels": [], "entities": []}, {"text": "These functionalities include: annotation of clinical texts along with database storage of stand-off annotations, the ability to interactively annotate texts in away that allows users to react to either preannotations imported from NLP or ML systems or use exact string matching across an active corpus to identify similar spans of text to those already annotated.", "labels": [], "entities": []}, {"text": "Additionally, these systems do not generally support crowd sourcing, machine-assisted pre-annotation or verification approaches integrated directly with the annotation tool.", "labels": [], "entities": [{"text": "crowd sourcing", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.8214309513568878}]}, {"text": "This paper discusses development of a prototype open source system designed to provide functionality that supports these activities and offers an end-to-end solution when coupled with server integration to reduce both annotator and administrative workload associated with reference standard.", "labels": [], "entities": []}, {"text": "We introduce the Extensible Human Oracle Suite of Tools (eHOST) created with these expectations in mind.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}