{"title": [{"text": "Results from the ML4HMT-12 Shared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine Translation", "labels": [], "entities": [{"text": "ML4HMT-12 Shared Task", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.5615740617116293}, {"text": "Hybrid Machine Translation", "start_pos": 117, "end_pos": 143, "type": "TASK", "confidence": 0.5841297308603922}]}], "abstractContent": [{"text": "We describe the second edition of the ML4HMT shared task which challenges participants to create hybrid translations from the translation output of several individual MT systems.", "labels": [], "entities": [{"text": "ML4HMT shared task", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8413853247960409}]}, {"text": "We provide an overview of the shared task and the data made available to participants before briefly describing the individual systems.", "labels": [], "entities": []}, {"text": "We report on the results using automatic evaluation metrics and conclude with a summary of ML4HMT-12 and an outlook to future work.", "labels": [], "entities": [{"text": "ML4HMT-12", "start_pos": 91, "end_pos": 100, "type": "DATASET", "confidence": 0.7090273499488831}]}], "introductionContent": [{"text": "The ML4HMT-12 workshop and associated shared task are an effort to trigger a systematic investigation on improving state-of-the-art hybrid machine translation, making use of advanced machine-learning (ML) methodologies.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.7132239043712616}]}, {"text": "The first edition of the workshop (ML4HMT-11) also road-tested a shared task (and associated data set) described and summarised in.", "labels": [], "entities": []}, {"text": "The main focus of the ML4HMT-12 (and ML4HMT-11) shared task is to address the question: Can Hybrid MT and System Combination techniques benefit from extra information (linguistically motivated, decoding, runtime, confidence scores or other meta-data) from the individual MT systems involved?", "labels": [], "entities": []}, {"text": "Participants are invited to build hybrid MT systems and/or system combinations by using the output of several MT systems of different types, as provided by the organisers.", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9698688387870789}]}, {"text": "While participants are encouraged to explore machine learning techniques to explore the additional meta-data information sources, other approaches aimed at general improvements in hybrid and combination based MT are welcome to participate in the challenge.", "labels": [], "entities": [{"text": "MT", "start_pos": 209, "end_pos": 211, "type": "TASK", "confidence": 0.8930550217628479}]}, {"text": "For systems that exploit additional meta-data information the challenge is that additional meta-data is highly heterogeneous and specific to individual systems.", "labels": [], "entities": []}, {"text": "One of the core objectives of the challenge is to build an MT combination (or more generally a hybrid MT) mechanism, where possible making effective use of the system-specific MT meta-data output produced by the participating individual MT systems as provided by the challenge development set data comprising outputs of four distinct MT systems and various meta-data annotations.", "labels": [], "entities": [{"text": "MT", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.9312984347343445}]}, {"text": "The development set provided by the organisers can be used for tuning the combination or hybrid systems during the development phase.", "labels": [], "entities": []}], "datasetContent": [{"text": "The organisers of the ML4HMT-12 shared task provide two data sets, one for the language pair Spanish\u2192English (ES-EN), the other for Chinese\u2192English (ZH-EN).", "labels": [], "entities": [{"text": "ML4HMT-12 shared task", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.5659815470377604}]}, {"text": "ES-EN Participants are given a development bilingual data set aligned at a sentence level.", "labels": [], "entities": []}, {"text": "Each \"bilingual sentence\" contains: 1.", "labels": [], "entities": []}, {"text": "the source sentence; 2.", "labels": [], "entities": []}, {"text": "the target (reference) sentence; and 3.", "labels": [], "entities": []}, {"text": "the corresponding translations from four individual component MT systems, based on different machine translation paradigms (Apertium (); Lucy (Alonso and Thurmair, 2003); two different variants of Moses (: PB-SMT and HPB-SMT).", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9646329283714294}]}, {"text": "The output has been automatically annotated with system-internal meta-data information derived from the translation process of each of the systems.", "labels": [], "entities": []}, {"text": "ZH-EN A corresponding data set for Chinese\u2192English with output translations from three systems (Moses; ICT_Chiero (); Huajian RBMT) was prepared.", "labels": [], "entities": [{"text": "ZH-EN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8890315294265747}, {"text": "Huajian RBMT", "start_pos": 118, "end_pos": 130, "type": "DATASET", "confidence": 0.8240839242935181}]}, {"text": "Again, system output has been automatically annotated with system-internal meta-data information.", "labels": [], "entities": []}, {"text": "In total, with the development data participants received 20,000 translations per system for training and had to translate a test set containing 3,003 sentences (\"newstest2011\") for Spanish\u2192English, while for the other language pair Chinese\u2192English, a total of 6,752 training sentences per system were available while the test set had a size of 1,357 sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Translation quality of ML4HMT-12 submissions measured using Meteor, NIST, and BLEU  scores for language pair Spanish\u2192English. Best system per metric printed in bold face.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9438301920890808}, {"text": "Meteor", "start_pos": 70, "end_pos": 76, "type": "DATASET", "confidence": 0.5602884888648987}, {"text": "NIST", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.7779151797294617}, {"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.998272180557251}]}]}