{"title": [{"text": "\"Love ya, jerkface\": using Sparse Log-Linear Models to Build Positive (and Impolite) Relationships with Teens", "labels": [], "entities": []}], "abstractContent": [{"text": "One challenge of implementing spoken dialogue systems for long-term interaction is how to adapt the dialogue as user and system become more familiar.", "labels": [], "entities": []}, {"text": "We believe this challenge includes evoking and signaling aspects of long-term relationships such as rapport.", "labels": [], "entities": []}, {"text": "For tutoring systems, this may additionally require knowing how relationships are signaled among non-adult users.", "labels": [], "entities": []}, {"text": "We therefore investigate conversational strategies used by teenagers in peer tutoring dialogues, and how these strategies function differently among friends or strangers.", "labels": [], "entities": []}, {"text": "In particular, we use annotated and automatically extracted linguistic devices to predict impoliteness and posi-tivity in the next turn.", "labels": [], "entities": []}, {"text": "To take into account the sparse nature of these features in real data we use models including Lasso, ridge estima-tor, and elastic net.", "labels": [], "entities": []}, {"text": "We evaluate the predictive power of our models under various settings, and compare our sparse models with standard non-sparse solutions.", "labels": [], "entities": []}, {"text": "Our experiments demonstrate that our models are more accurate than non-sparse models quantitatively, and that teens use unexpected kinds of language to do relationship work such as signal-ing rapport, but friends and strangers, tutors and tutees, carryout this work in quite different ways from one another.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We predict impoliteness vs. non-impoliteness and positivity vs. non-positivity of an interlocutor in the immediate future turn, given only information from current/previous turns.", "labels": [], "entities": []}, {"text": "Because accuracy, precision, recall and F-measure are threshold-based point estimation metrics that might prevent one from observing the big picture of system performance, we consider the Receiver Operating Characteristic (ROC) metric to evaluate the dynamics of the true positive rate vs. the false positive rate) in our system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9991483688354492}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9989909529685974}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9991968274116516}, {"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9976175427436829}]}, {"text": "We mainly use Area Under Curve (AUC) as a metric to compare classifiers, since it maps the ROC metric to a single scalar value representing expected performance.", "labels": [], "entities": [{"text": "Area Under Curve (AUC)", "start_pos": 14, "end_pos": 36, "type": "METRIC", "confidence": 0.7653796672821045}]}, {"text": "A random classifier will have an AUC of 0.5).", "labels": [], "entities": [{"text": "AUC", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9925426244735718}]}, {"text": "A previous study (Ogan et al., 2012) on these same data seemed to indicate that negative conversational strategies composed of linguistic devices such as complaining and insults were correlated with learning in the friend dyads and negatively correlated with learning in strangers.", "labels": [], "entities": []}, {"text": "However the small number of stranger dyads prevented them from drawing conclusions about particular linguistic devices from the data.", "labels": [], "entities": []}, {"text": "Here, we empirically show the predictive performance of different feature sets on both friend and stranger test sets in , using a sparse Lasso model with features from only the current turn.", "labels": [], "entities": []}, {"text": "In the impoliteness prediction task, when predicting on the test set that consists of only friends, we observe statistically significant improvement over a random baseline, using surface-level language behavior features, lexical, lexical + syntactic, all automatic, and all features.", "labels": [], "entities": [{"text": "impoliteness prediction task", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.7853779991467794}]}, {"text": "When combining all features, the best AUC is .621.", "labels": [], "entities": [{"text": "AUC", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9618639349937439}]}, {"text": "The automatic features, mainly including n-grams and partof-speech tags, have emerged as a useful automated feature space.", "labels": [], "entities": []}, {"text": "On the other hand, we do not observe any significant results on the stranger datasets, suggesting that strangers do not respond with impoliteness in the same way that friends do.", "labels": [], "entities": []}, {"text": "When predicting positivity on the friend dataset, we see that the performance of surface-level language behavior features has dropped from the first task, and the statistical t-test is non-significant when comparing to a random baseline.", "labels": [], "entities": []}, {"text": "This is not surprising, because we have shown in the previous section that surfacelevel language behavior features are strong indicators of impoliteness, but might not have advantages in predicting positivity for friends.", "labels": [], "entities": []}, {"text": "Interestingly, the automated features outperform the combination of all features, indicating a promising future for the actual deployment of an SDS that can interact using appropriate positivity and impoliteness.", "labels": [], "entities": []}, {"text": "When predicting positivity in the stranger dataset, we find the opposite trend.", "labels": [], "entities": []}, {"text": "In contrast to the impoliteness prediction task, the overall performance on the stranger dataset improved, and the lexical, lexical+syntactic, and all feature combination have significantly outperformed the chance baseline.", "labels": [], "entities": [{"text": "impoliteness prediction task", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.7694754600524902}]}, {"text": "These results suggest that positivity is a predictable behavior among strangers, who may all express uniform positivity across all dyads, while it is the impoliteness that is predictable among friends.", "labels": [], "entities": []}, {"text": "Perhaps it is that through the development of a rapport with a partner, the particular ways in which positivity is expressed becomes personalized to the dyad, and can no longer be applied to other groups who have their own expressions of positivity.", "labels": [], "entities": []}, {"text": "In other words, unlike in Tolstoy's world, here unhappy families are all alike; every happy family is happy in its own way.", "labels": [], "entities": []}, {"text": "We must look to the easily-predictable impoliteness among friends instead, arguing strongly for the inclusion of impoliteness in a model of rapport.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparing the Learned Weights of Different Features when Predicting the Partner's Impoliteness in a Non- Sparse Log-Linear Model. Tr-Te: predict tutee turn with tutor turn. Te-Tr: predict tutor turn with tutee turn. For full  name of features, see Section 3.", "labels": [], "entities": []}]}