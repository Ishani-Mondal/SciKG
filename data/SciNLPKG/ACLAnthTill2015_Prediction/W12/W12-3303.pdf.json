{"title": [], "abstractContent": [{"text": "In sentiment classification, unlabeled user reviews are often free to collect for new products, while sentiment labels are rare.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.9706535339355469}]}, {"text": "In this case, active learning is often applied to build a high-quality classifier with as small amount of labeled instances as possible.", "labels": [], "entities": []}, {"text": "However, when the labeled instances are insufficient, the performance of active learning is limited.", "labels": [], "entities": []}, {"text": "In this paper, we aim at enhancing active learning by employing the labeled reviews from a different but related (source) domain.", "labels": [], "entities": []}, {"text": "We propose a framework Active Vector Rotation (AVR), which adaptively utilizes the source domain data in the active learning procedure.", "labels": [], "entities": [{"text": "Active Vector Rotation (AVR)", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.7322311401367188}]}, {"text": "Thus, AVR gets benefits from source domain when it is helpful, and avoids the negative affects when it is harmful.", "labels": [], "entities": []}, {"text": "Extensive experiments on toy data and review texts show our success, compared with other state-of-the-art active learning approaches, as well as approaches with domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 161, "end_pos": 178, "type": "TASK", "confidence": 0.7126083523035049}]}], "introductionContent": [{"text": "To get a good generalization in traditional supervised learning, we need sufficient labeled instances in training, which are drawn from the same distribution as testing instances.", "labels": [], "entities": []}, {"text": "When there are plenty of unlabeled instances but labels are insufficient and expensive to obtain, active learning) selects a small set of critical instances from target domain to be labeled, but costs are incurred for each label.", "labels": [], "entities": []}, {"text": "On the other hand, transfer learning (), also known as domain adaptation), aims at leveraging instances from other related source domains to construct high-quality models in the target domain.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.9580200016498566}, {"text": "domain adaptation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7261326611042023}]}, {"text": "For example, we may employ labeled user reviews of similar products, to predict sentiment labels of new product reviews.", "labels": [], "entities": [{"text": "predict sentiment labels of new product reviews", "start_pos": 72, "end_pos": 119, "type": "TASK", "confidence": 0.7161484786442348}]}, {"text": "When the distributions of source and target domain are similar, transfer learning would work well.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.9646086990833282}]}, {"text": "But significant distribution divergence might cause negative transfer ().", "labels": [], "entities": []}, {"text": "To further reduce the labeling cost and avoid negative transfer, we propose a framework, namely Active Vector Rotation (AVR), which takes advantage of both active learning and transfer learning techniques.", "labels": [], "entities": []}, {"text": "Basically, AVR makes model's parameter vector \ud97b\udf59 actively rotate towards its optimal direction with as few labeled instances in target domain as possible.", "labels": [], "entities": []}, {"text": "Specifically, AVR first applies certain unsupervised learning techniques to make source and target domain's distributions more 'similar', and then leverages source domain information to query the most informative instances of target domain.", "labels": [], "entities": []}, {"text": "Most importantly, it carefully reweights instances to mitigate the risk of negative transfer.", "labels": [], "entities": []}, {"text": "AVR is general enough to incorporate various active learning and transfer learning modules, as well as varied basic learners such as LR and SVM.", "labels": [], "entities": [{"text": "AVR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8938312530517578}]}, {"text": "proposed an approach AcTraK, using labeled source and target domain instances to build a so-called 'transfer classifier' to help label actively selected target domain instances.", "labels": [], "entities": []}, {"text": "AcTraK initially requires labeled target domain instances, and relies too much on the transfer classifier.", "labels": [], "entities": []}, {"text": "Thus it might be degenerated by negative transfer.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform AVR on a set of toy data and two real world datasets, 20 Newsgroups Dataset 1 and Multi-Domain Sentiment Dataset 2 , comparing it with several baseline methods.", "labels": [], "entities": [{"text": "20 Newsgroups Dataset", "start_pos": 65, "end_pos": 86, "type": "DATASET", "confidence": 0.6646048029263815}]}, {"text": "In this paper, we use model accuracy \ud97b\udf59 \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 under fixed labeling budget \ud97b\udf59 \ud97b\udf59 as the evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9718601703643799}]}, {"text": "We used LR and L2-SVM as basic learner respectively, but due to space limit, we only report the results of LR.", "labels": [], "entities": []}, {"text": "20 Newsgroups Dataset is commonly used in machine learning and NLP tasks.", "labels": [], "entities": [{"text": "20 Newsgroups Dataset", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.9153615832328796}]}, {"text": "It contains about 20000 newsgroup documents which are categorized into 6 top categories and 20 subcategories.", "labels": [], "entities": []}, {"text": "We split it into 6 pair of \ud97b\udf59 and \ud97b\udf59 , with each pair includes only two top categories documents, such as \"comp\" and \"rec\", but \ud97b\udf59 and \ud97b\udf59 are drawn from different subcategories, e.g. \ud97b\udf59 has \"comp.graphics\" and \"comp.graphics\", but \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 has \"comp.windows.x\" and \"sci.autos\".", "labels": [], "entities": []}, {"text": "The task is to leverage \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 to distinguish the top categories of documents in \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 . Our settings of 20 Newsgroups Dataset is identical with, details can be found there.", "labels": [], "entities": [{"text": "20 Newsgroups Dataset", "start_pos": 104, "end_pos": 125, "type": "DATASET", "confidence": 0.7243584990501404}]}, {"text": "On this dataset, AVR's configuration is similar with that on toy data, with \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59 varies from 500 to 800 on different pairs.", "labels": [], "entities": [{"text": "AVR", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.6824377179145813}]}, {"text": "Due to space limit, we only report results on the pair of \"comp vs. rec\" in, with all methods are averaged over 30 runs.", "labels": [], "entities": []}, {"text": "The results on other pairs are similar.", "labels": [], "entities": []}, {"text": "Since AVR-U and AVR-W are variants of AVR, with similar performance, we only report the results of AVR.", "labels": [], "entities": [{"text": "AVR-U", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.7866072654724121}, {"text": "AVR-W", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.7241256833076477}, {"text": "AVR", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.7299975752830505}]}, {"text": "The sentiment dataset consists of user reviews about several products (Book, DVD, Electronic, Kitchen) from Amazon.com, the task is to classify a review's sentiment label as positive or negative.", "labels": [], "entities": []}, {"text": "We have 12 pairs with each pair has two products as \ud97b\udf59 and \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 respectively.", "labels": [], "entities": []}, {"text": "On this dataset, AVR employs VMVPCA () to project \ud97b\udf59 and \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 , and initializes \ud97b\udf59 \ud97b\udf59\ud97b\udf59 with \ud97b\udf59 \ud97b\udf59 \ud97b\udf59 1000 instances from \ud97b\udf59 \ud97b\udf59\ud97b\udf59\ud97b\udf59 w.r.t., while the other configuration is the same as that described in Section 4.1.", "labels": [], "entities": [{"text": "AVR", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.7784021496772766}]}, {"text": "To be comparable, the baseline methods which leverage \ud97b\udf59 are preprocessed by VMVPCA.", "labels": [], "entities": [{"text": "VMVPCA", "start_pos": 76, "end_pos": 82, "type": "DATASET", "confidence": 0.8813891410827637}]}, {"text": "We also add another baseline method Source-A' here, which is identical with Source-A, except that it is not projected by VMVPCA.", "labels": [], "entities": [{"text": "VMVPCA", "start_pos": 121, "end_pos": 127, "type": "DATASET", "confidence": 0.9549890756607056}]}, {"text": "Given space limit, we only report the results on the pair \"DVD \ud97b\udf59 Kitchen\", with other pairs have similar performance.", "labels": [], "entities": [{"text": "DVD \ud97b\udf59 Kitchen", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9521734317143759}]}, {"text": "Figure 3: AVR does better than previous work on the \"DVD\ud97b\udf59Kitchen\" dataset for all budget sizes.", "labels": [], "entities": [{"text": "AVR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.535279393196106}, {"text": "DVD\ud97b\udf59Kitchen\" dataset", "start_pos": 53, "end_pos": 73, "type": "DATASET", "confidence": 0.9415011048316956}]}], "tableCaptions": [{"text": " Table 3: Performance of different methods on toy  data, where AcTraK unfairly uses two more labels.", "labels": [], "entities": []}]}