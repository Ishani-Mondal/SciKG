{"title": [{"text": "Learning to Model Multilingual Unrestricted Coreference in OntoNotes", "labels": [], "entities": []}], "abstractContent": [{"text": "Coreference resolution, which aims at correctly linking meaningful expressions in text, is a much challenging problem in Natural Language Processing community.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9072304964065552}]}, {"text": "This paper describes the multilingual coreference modeling system of Web Information Processing Group, Henan University of Technology, China, for the CoNLL-2012 shared task (closed track).", "labels": [], "entities": []}, {"text": "The system takes a supervised learning strategy, and consists of two cascaded components: one for detecting mentions, and the other for clustering mentions.", "labels": [], "entities": []}, {"text": "To make the system applicable for multiple languages, generic syntactic and semantic features are used to model coreference in text.", "labels": [], "entities": []}, {"text": "The system obtained combined official score 41.88 over three languages (Arabic, Chinese, and English) and ranked 7 th among the 15 systems in the closed track.", "labels": [], "entities": [{"text": "official score", "start_pos": 29, "end_pos": 43, "type": "METRIC", "confidence": 0.951206386089325}]}], "introductionContent": [{"text": "Coreference resolution, which aims at correctly linking meaningful expressions in text, has become a central research problem in natural language processing community with the advent of various supporting resources (e.g. corpora and different kinds of knowledge bases).", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8955560624599457}]}, {"text": "OntoNotes (), compared to MUC) and ACE) corpora, is a large-scale, multilingual corpus for general anaphoric coreference that covers entities and events not limited to noun phrases or a limited set of entity types.", "labels": [], "entities": []}, {"text": "It greatly stimulates the research on this challenging problem -Coreference Resolution.", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.9563353061676025}]}, {"text": "Moreover, resources like WordNet and the advancement of different kinds of syntactic and semantic analysis technologies, make it possible to do in-depth research on this topic, which is demanded inmost of natural language processing applications, such as information extraction, machine translation, question answering, summarization, and soon.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.931307315826416}, {"text": "information extraction", "start_pos": 255, "end_pos": 277, "type": "TASK", "confidence": 0.8221229314804077}, {"text": "machine translation", "start_pos": 279, "end_pos": 298, "type": "TASK", "confidence": 0.8144651353359222}, {"text": "question answering", "start_pos": 300, "end_pos": 318, "type": "TASK", "confidence": 0.8892743587493896}, {"text": "summarization", "start_pos": 320, "end_pos": 333, "type": "TASK", "confidence": 0.9801709651947021}]}, {"text": "Our group is exploring how to extract information from grain/cereal related Chinese text for business intelligence.", "labels": [], "entities": [{"text": "business intelligence", "start_pos": 93, "end_pos": 114, "type": "TASK", "confidence": 0.7872883677482605}]}, {"text": "This shared task provides a good platform for advancing our research on IE related topics.", "labels": [], "entities": [{"text": "IE related topics", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.935122569402059}]}, {"text": "We experiment with a machine learning strategy to model multilingual coreference for the CoNLL-2012 shared task ().", "labels": [], "entities": [{"text": "CoNLL-2012 shared task", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.813436230023702}]}, {"text": "Two steps are taken to detect coreference in text: mention detection and mention clustering.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7353757619857788}, {"text": "mention clustering", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.6519728600978851}]}, {"text": "We consider mentions that correspond to a word or an internal node in a syntactic tree and ignore the rest mentions, as we think a mention should be a valid meaningful unit of a sentence.", "labels": [], "entities": []}, {"text": "Maximal entropy algorithm is used to model what a mention is and how two mentions link to each other.", "labels": [], "entities": []}, {"text": "Generic features are designed to facilitate these modeling.", "labels": [], "entities": []}, {"text": "Our official submission obtained combined official score 41.88 over three languages, which ranked the system 7 th among 15 systems participating the closed track.", "labels": [], "entities": []}, {"text": "Our system performs poor on the Arabic data, and has relatively high precision but low recall.", "labels": [], "entities": [{"text": "Arabic data", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.7863975465297699}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9992032647132874}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9988058805465698}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives the overview of our system, while Section 3 discusses the first component of our system for mention detection.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.6911605894565582}]}, {"text": "Section 4 explains how our system links mentions.", "labels": [], "entities": []}, {"text": "We present our experiments and analyses in Section 5, and conclude in Section 6.", "labels": [], "entities": []}, {"text": "gives the architecture of our CoNLL-2012 system, which consists of four pipelined processing modules: pre-processing, mention detection, mention clustering, and post-processing.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.8361285626888275}, {"text": "mention clustering", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7356341183185577}]}], "datasetContent": [{"text": "The datasets of the CoNLL-2012 shared task contain three languages: Arabic (ARB), Chinese (CHN), and English (ENG).", "labels": [], "entities": []}, {"text": "No predicted names and propositions are provided in the Arabic data, while no predicted names are given in the Chinese data.", "labels": [], "entities": []}, {"text": "show statistical information of both training and development datasets for each language.", "labels": [], "entities": []}, {"text": "In the Arabic datasets, about 7.9% mentions do not correspond to a valid phrasal sub-structure.", "labels": [], "entities": [{"text": "Arabic datasets", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.7030155062675476}]}, {"text": "This number of the Chinese dataset is 6%, while that of English 3%.", "labels": [], "entities": [{"text": "Chinese dataset", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9297848641872406}]}, {"text": "These small percentages verify that our assumption that a mention is expected to be a valid phrasal sub-structure is reasonable.", "labels": [], "entities": []}, {"text": "The average numbers of sentences in a document in the three language datasets are roughly 21, 22, and 27 respectively, while the longest document that has 283 sentences is found in the Chinese train dataset.", "labels": [], "entities": [{"text": "Chinese train dataset", "start_pos": 185, "end_pos": 206, "type": "DATASET", "confidence": 0.9151771664619446}]}, {"text": "The average numbers of tokens in a sentence in the three language datasets are roughly 31, 19, and 17 respectively, while the longest sentence with 384 tokens is found in the Arabic train dataset.", "labels": [], "entities": [{"text": "Arabic train dataset", "start_pos": 175, "end_pos": 195, "type": "DATASET", "confidence": 0.8540281256039938}]}, {"text": "For producing the results on the test datasets, we combined both train and development datasets for training maximal entropy classifiers.", "labels": [], "entities": []}, {"text": "The official score adopted by CoNLL-2012 is the unweighted average of scores on three languages, while for each language, the score is derived by averaging the three metrics MUC (), B-CUBED (, and CEAF(E) (Constrained Entity Aligned F-measure) as follows: Our system achieved the combined official score 42.32 over three languages (Arabic, Chinese, and English).", "labels": [], "entities": [{"text": "MUC", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.9485782980918884}, {"text": "B-CUBED", "start_pos": 182, "end_pos": 189, "type": "METRIC", "confidence": 0.9850283861160278}, {"text": "CEAF(E) (Constrained Entity Aligned F-measure)", "start_pos": 197, "end_pos": 243, "type": "METRIC", "confidence": 0.7600451290607453}]}, {"text": "On each of the three languages, the system obtained scores 33.53, 46.27, and 45.85 respectively.", "labels": [], "entities": []}, {"text": "It performs poor on the Arabic dataset, but equally well on the Chinese and English datasets., and 5 give the detailed results on three languages respectively..", "labels": [], "entities": []}, {"text": "Official results of our system on the English test dataset.", "labels": [], "entities": [{"text": "English test dataset", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.9588622450828552}]}], "tableCaptions": [{"text": " Table 1. Statistical information of the three language  datasets (train and development) (part 1).", "labels": [], "entities": []}, {"text": " Table 2. Statistical information of the three language  datasets (train and development) (part 2).", "labels": [], "entities": []}, {"text": " Table 3. Official results of our system on the Arabic test  dataset.", "labels": [], "entities": [{"text": "Arabic test  dataset", "start_pos": 48, "end_pos": 68, "type": "DATASET", "confidence": 0.9555195371309916}]}, {"text": " Table 4. Official results of our system on the Chinese  test dataset.", "labels": [], "entities": [{"text": "Chinese  test dataset", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.9734813570976257}]}, {"text": " Table 5. Official results of our system on the English  test dataset.", "labels": [], "entities": [{"text": "English  test dataset", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.9600775043169657}]}, {"text": " Table 6. Mention Detection Scores on the test datasets.", "labels": [], "entities": [{"text": "Mention Detection Scores", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.9199197093645731}]}, {"text": " Table 7. Mention Detection Scores on the development  (Dev) datasets. \"-Sing\" means without singletons, which  is required by the task specification, while \"+Sing\"  means including singletons.", "labels": [], "entities": []}]}