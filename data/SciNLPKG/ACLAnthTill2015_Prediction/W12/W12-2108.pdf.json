{"title": [{"text": "Language Identification for Creating Language-Specific Twitter Collections", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6481517404317856}]}], "abstractContent": [{"text": "Social media services such as Twitter offer an immense volume of real-world linguistic data.", "labels": [], "entities": []}, {"text": "We explore the use of Twitter to obtain authentic user-generated text in low-resource languages such as Nepali, Urdu, and Ukrainian.", "labels": [], "entities": []}, {"text": "Automatic language identification (LID) can be used to extract language-specific data from Twitter, but it is unclear how well LID performs on short, informal texts in low-resource languages.", "labels": [], "entities": [{"text": "Automatic language identification (LID)", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7243568499883016}]}, {"text": "We address this question by annotating and releasing a large collection of tweets in nine languages, focusing on confus-able languages using the Cyrillic, Arabic, and Devanagari scripts.", "labels": [], "entities": []}, {"text": "This is the first publicly-available collection of LID-annotated tweets in non-Latin scripts, and should become a standard evaluation set for LID systems.", "labels": [], "entities": []}, {"text": "We also advance the state-of-the-art by evaluating new, highly-accurate LID systems, trained both on our new corpus and on standard materials only.", "labels": [], "entities": []}, {"text": "Both types of systems achieve a huge performance improvement over the existing state-of-the-art, correctly classifying around 98% of our gold standard tweets.", "labels": [], "entities": []}, {"text": "We provide a detailed analysis showing how the accuracy of our systems vary along certain dimensions , such as the tweet-length and the amount of in-and out-of-domain training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9990031123161316}]}], "introductionContent": [{"text": "Twitter is an online social-networking service that lets users send and receive short texts called tweets.", "labels": [], "entities": []}, {"text": "Twitter is enormously popular; more than 50 million users login daily and billions of tweets are sent each month.", "labels": [], "entities": []}, {"text": "Tweets are publicly-available by de-1 http://mashable.com/2011/09/08/ Twitter-has-100-million-active-users/ fault and thus provide an enormous and growing free resource of authentic, unedited text by ordinary people.", "labels": [], "entities": []}, {"text": "Researchers have used Twitter to study how human language varies by timezone, census area), gender), and ethnicity (.", "labels": [], "entities": []}, {"text": "Twitter also provides a wealth of user dialog, and a variety of dialog acts have been observed () and predicted (.", "labels": [], "entities": []}, {"text": "Of course, working with Twitter is not all roses and rainbows.", "labels": [], "entities": []}, {"text": "Twitter is a difficult domain because unlike, for example, news articles, tweets are short (limited to 140 characters), vary widely in style, and contain many spelling and grammatical errors.", "labels": [], "entities": []}, {"text": "Moreover, unlike articles written by a particular news organization, a corpus constructed from Twitter will contain tweets in many different languages.", "labels": [], "entities": []}, {"text": "This latter point is particularly troubling because the majority of language-processing technology is predicated on knowing which language is being processed.", "labels": [], "entities": []}, {"text": "We are pursuing a long-term effort to build social media collections in a variety of low-resource languages, and we need robust language identification (LID) technology.", "labels": [], "entities": [{"text": "language identification (LID)", "start_pos": 128, "end_pos": 157, "type": "TASK", "confidence": 0.7866363167762757}]}, {"text": "While LID is often viewed as a solved problem, recent research has shown that LID can be made arbitrarily difficult by choosing domains with (a) informal writing, (b) lots of languages to choose from, (c) very short texts, and (d) unbalanced data (;.", "labels": [], "entities": []}, {"text": "Twitter exhibits all of these properties.", "labels": [], "entities": []}, {"text": "While the problem of LID on Twitter has been considered previously (, these studies have only targeted five or six western European languages, and not the diversity of languages and writing systems that we would like to process.", "labels": [], "entities": []}, {"text": "Our main contribution is the release of a large collection of tweets in nine languages using the Cyrillic, Arabic, and Devanagari alphabets.", "labels": [], "entities": []}, {"text": "We test different methods for obtaining tweets in a given target language ( \u00a72).", "labels": [], "entities": []}, {"text": "We then use an online crowdsourcing platform to have these tweets annotated by fluent speakers of that language ( \u00a73).", "labels": [], "entities": []}, {"text": "We generate over 18,000 triple-consensus tweets, providing the first publicly-available collection of LID-annotated tweets in non-Latin scripts.", "labels": [], "entities": []}, {"text": "The annotated corpus is available online at: http://apl.jhu.edu/ \u02dc paulmac/lid.html.", "labels": [], "entities": []}, {"text": "We anticipate our multilingual Twitter collection becoming a standard evaluation set for LID systems.", "labels": [], "entities": []}, {"text": "We also implement two LID approaches and evaluate these approaches against state-of-the-art competitors.", "labels": [], "entities": []}, {"text": "\u00a74.1 describes a discriminative classifier that leverages both the tweet text and the tweet metadata (such as the username, location, and landing pages for shortened URLs).", "labels": [], "entities": []}, {"text": "\u00a74.2 describes an efficient tool based on compression language models.", "labels": [], "entities": []}, {"text": "Both types of systems achieve a huge improvement over existing state-of-the-art approaches, including the Google Compact Language Detector (part of the Chrome browser), and a recent LID system from.", "labels": [], "entities": [{"text": "Google Compact Language Detector", "start_pos": 106, "end_pos": 138, "type": "TASK", "confidence": 0.6427652537822723}]}, {"text": "Finally, we provide further analysis of our systems in this unique domain, showing how accuracy varies with the tweet-length and the amount of in-domain and out-of-domain training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9992634654045105}]}, {"text": "In addition to the datasets, we are releasing our compression language model tool for public use.", "labels": [], "entities": []}], "datasetContent": [{"text": "For major languages (e.g. Arabic and Russian), we can accurately obtain tweets in the target language, perhaps obviating the need for LID.", "labels": [], "entities": [{"text": "LID", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.8720273971557617}]}, {"text": "For the Urdu sets, however, a large percentage of tweets are not in Urdu, and thus neither collection method is reliable.", "labels": [], "entities": []}, {"text": "An LID tool is needed to validate the data.", "labels": [], "entities": [{"text": "LID", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.8272557258605957}]}, {"text": "A native Arabic speaker verified that most of our invalid Urdu tweets were Arabic.", "labels": [], "entities": []}, {"text": "Ukrainian is the most glaringly impure language that we collected, with less than 15% of our intended tweets actually in Ukrainian.", "labels": [], "entities": []}, {"text": "Russian is widely spoken in Ukraine and seems to be the dominant language on Twitter, but more analysis is required.", "labels": [], "entities": []}, {"text": "Finally, Marathi and Bulgarian also have significant impurities.", "labels": [], "entities": []}, {"text": "The complete annotation of all nine languages cost only around $350 USD.", "labels": [], "entities": []}, {"text": "While not insignificant, this was a small expense relative to the total human effort we are expending on this project.", "labels": [], "entities": []}, {"text": "Scaling our approach to hundreds of languages would only cost on the order of a few thousand dollars, and we are investigating whether such an effort could be supported by enough fluent AMT workers.", "labels": [], "entities": []}, {"text": "The nine languages in our annotated data use one of three different writing systems: Arabic, Devanagari, or Cyrillic.", "labels": [], "entities": []}, {"text": "We therefore define three classification tasks, each choosing between three languages that have the same writing system.", "labels": [], "entities": []}, {"text": "We divide our annotated corpus into training, development and test data for these experiments.", "labels": [], "entities": []}, {"text": "For the Arabic data, we merge the tweets obtained via our two collection methods ( \u00a72); for Devanagari/Cyrillic, all tweets are obtained using the Sources method.", "labels": [], "entities": []}, {"text": "We ensure that tweets by a unique Twitter user occur in at most only one of the sets.", "labels": [], "entities": []}, {"text": "The proportion of each language in each set is roughly the same as the proportions of gold tweets in  as tuning the regularization parameter of the LogR classifier) is done on the development set.", "labels": [], "entities": []}, {"text": "Our evaluation metric is Accuracy: what proportion of tweets in each held-out test set are predicted correctly.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995344877243042}]}], "tableCaptions": [{"text": " Table 1: Statistics of the Annotated Multilingual Twitter  Corpus: 18,269 total tweets in nine languages.", "labels": [], "entities": [{"text": "Annotated Multilingual Twitter  Corpus", "start_pos": 28, "end_pos": 66, "type": "DATASET", "confidence": 0.5470239818096161}]}, {"text": " Table 3: Number of tweets used in experiments, by writ- ing system/classification task", "labels": [], "entities": []}, {"text": " Table 5: The benefits of aggregating predictions by user:  Mean accuracy of LogR-chars as you make predictions  on multiple Devanagari tweets at a time", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.928246259689331}]}, {"text": " Table 6: Number of tweets", "labels": [], "entities": []}]}