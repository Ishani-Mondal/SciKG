{"title": [{"text": "Linking Uncertainty in Physicians' Narratives to Diagnostic Correctness", "labels": [], "entities": [{"text": "Linking Uncertainty in Physicians' Narratives to Diagnostic Correctness", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.7121943011879921}]}], "abstractContent": [{"text": "In the medical domain, misdiagnoses and diagnostic uncertainty put lives at risk and incur substantial financial costs.", "labels": [], "entities": []}, {"text": "Clearly, medical reasoning and decision-making need to be better understood.", "labels": [], "entities": [{"text": "medical reasoning", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7042503356933594}]}, {"text": "We explore a possible link between linguistic expression and diagnostic correctness.", "labels": [], "entities": []}, {"text": "We report on an unusual data set of spoken diagnostic narratives used to com-putationally model and predict diagnostic cor-rectness based on automatically extracted and linguistically motivated features that capture physicians' uncertainty.", "labels": [], "entities": []}, {"text": "A multimodal data set was collected as dermatologists viewed images of skin conditions and explained their diagnostic process and observations aloud.", "labels": [], "entities": []}, {"text": "We discuss experimentation and analysis in initial and secondary pilot studies.", "labels": [], "entities": []}, {"text": "In both cases, we experimented with computational model-ing using features from the acoustic-prosodic and lexical-structural linguistic modalities.", "labels": [], "entities": []}], "introductionContent": [{"text": "Up to 20% of post-mortem diagnoses in the United States are inconsistent with the diagnosis before death ().", "labels": [], "entities": []}, {"text": "These misdiagnoses cost both human lives and estimated millions of dollars every year.", "labels": [], "entities": []}, {"text": "To find where and why misdiagnoses occur, it is necessary to improve our understanding of doctors' diagnostic reasoning and how it is linked to diagnostic uncertainty and correctness.", "labels": [], "entities": []}, {"text": "Our contribution begins to explore the computational modeling of this phenomenon in diagnostic narratives.", "labels": [], "entities": [{"text": "diagnostic narratives", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.9243061542510986}]}, {"text": "From a cognitive science perspective, we are contributing to the research on medical reasoning and how it is linguistically expressed.", "labels": [], "entities": []}, {"text": "In the long term, this area of work could be a useful decision-making component for flagging diagnoses that need further review.", "labels": [], "entities": [{"text": "flagging diagnoses", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.9685675799846649}]}, {"text": "The study used an unusual multimodal data set collected in a modified Master-Apprentice interaction scenario.", "labels": [], "entities": []}, {"text": "It comprises both gaze and linguistic data.", "labels": [], "entities": []}, {"text": "The present study focuses on the linguistic data which in turn can be conceptualized as consisting of both acoustic-prosodic and lexical-structural modalities.", "labels": [], "entities": []}, {"text": "This data set can further be used to link vision and language research to understand human cognition inexpert decision-making scenarios.", "labels": [], "entities": []}, {"text": "We report on a study conducted in two phases.", "labels": [], "entities": []}, {"text": "First, an initial pilot study involved a preliminary annotation of a small subset of the collected diagnostic narratives and also investigated the prediction of diagnostic correctness using a set of linguistic features from speech recordings and their verbal transcriptions.", "labels": [], "entities": []}, {"text": "This provided initial features relevant to classification, helped us identify annotation issues, and gave us insight on how to improve the annotation scheme used for annotating ground truth data.", "labels": [], "entities": [{"text": "classification", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.9606660604476929}]}, {"text": "Next, a second pilot study was performed, building on what was learned in the initial pilot study.", "labels": [], "entities": []}, {"text": "The second pilot study involved a larger data set with a revised and improved annotation scheme that considered gradient correctness at different steps of the diagnostic reasoning process: (1) medical lesion morphology (e.g. recognizing the lesion type as a scaly erythematous plaque), (2) differential diagnosis (i.e. providing a set of possible final diagnoses), and (3) final diagnosis (e.g. identifying the disease condition as psoriasis).", "labels": [], "entities": [{"text": "differential diagnosis", "start_pos": 290, "end_pos": 312, "type": "TASK", "confidence": 0.6568258553743362}, {"text": "final diagnosis", "start_pos": 373, "end_pos": 388, "type": "TASK", "confidence": 0.7418943345546722}]}, {"text": "We also experiment with classification using an expanded feature set motivated by the initial pilot study and by previously published research.", "labels": [], "entities": [{"text": "classification", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.9693365097045898}]}, {"text": "We report on results that consider different algorithms, feature set modalities, diagnostic reasoning steps, and coarse vs. fine grained classes as explained below in Section 4.3.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test if one linguistic modality was more important for classification, experiments were run in each of three different ways: with only lexical-structural features, with only acoustic-prosodic features, and with all features.", "labels": [], "entities": [{"text": "classification", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.9631693363189697}]}, {"text": "We considered the final diagnosis and differential diagnosis scenarios.", "labels": [], "entities": [{"text": "final diagnosis", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.5878917276859283}, {"text": "differential diagnosis", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7131295949220657}]}, {"text": "It was decided not to run this experiment in terms of medical lesion morphology because of its extreme class imbalance with a high baseline of 83%.", "labels": [], "entities": [{"text": "medical lesion morphology", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.7016118963559469}]}, {"text": "Medical lesion morphology also differs in being a descriptive step unlike the other two which are more like conclusions.", "labels": [], "entities": [{"text": "Medical lesion morphology", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6545308629671732}]}, {"text": "Again, a leave-one-out cross-validation method was used.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "These results show that, regarding final diagnosis, considering only acoustic-prosodic features seemed to yield somewhat higher accuracy than when features were combined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.999103307723999}]}, {"text": "This might reflect that, conceptually, final diagnosis captures a global end step in the decision-making process, and we extracted voice features at a global level (across the narrative).", "labels": [], "entities": [{"text": "final diagnosis", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7906601428985596}]}, {"text": "In the case of differential diagnosis, the lexicalstructural features performed best, matching the accuracy of the combined feature set (5% over the majority class baseline).", "labels": [], "entities": [{"text": "differential diagnosis", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.8494062125682831}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9993042945861816}]}, {"text": "Future study could determine which individual features in these sets were most important.", "labels": [], "entities": []}, {"text": "Another set of experiments examined performance for adjusted label combinations.", "labels": [], "entities": []}, {"text": "To learn more about the model, experiments were run in which selected classes were combined or only certain classes were considered.", "labels": [], "entities": []}, {"text": "The class proportions thus changed due to the combinations and/or removal of classes.", "labels": [], "entities": []}, {"text": "This was done utilizing all features, the Weka SVM algorithm, and a leave-oneout methodology.", "labels": [], "entities": [{"text": "Weka SVM algorithm", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.812824567159017}]}, {"text": "Only logically relevant tests that increased class balance are reported here.", "labels": [], "entities": [{"text": "class balance", "start_pos": 45, "end_pos": 58, "type": "METRIC", "confidence": 0.6402556896209717}]}, {"text": "An experiment was run on the differential diagnosis step.", "labels": [], "entities": [{"text": "differential diagnosis", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8842146694660187}]}, {"text": "The no differential given label was ignored to allow the binary classification of narratives that included differential diagnoses.", "labels": [], "entities": []}, {"text": "The new majority class baseline for this test was 62% and this classification performed 1% over its baseline.", "labels": [], "entities": []}, {"text": "A similar experiment was run on the final diagnosis diagnostic step.", "labels": [], "entities": [{"text": "final diagnosis diagnostic", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.5803812742233276}]}, {"text": "Class labels of incorrect and none given were combined to form binary set of class labels with a 62% baseline.", "labels": [], "entities": []}, {"text": "This classification performed 6% over the baseline, i.e., slightly improved performance compared to the scenario with three class labels.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Labels for various steps of the diagnostic process  as well as their count and ratios of the total narratives, af- ter eliminating those with no annotator agreement. These  labels are explained in section 4.3.", "labels": [], "entities": [{"text": "diagnostic process", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8995228111743927}, {"text": "count", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9888448119163513}]}, {"text": " Table 4. Ac- curacy is considered in relation to the majority class  baseline in each case. With this in mind, the high  accuracies found when testing medical lesion mor- phology are caused by a large class imbalance. Dif- ferential diagnosis' best result is 5% more accurate  than its baseline while final diagnosis and medical  lesion morphology are closer to their baselines.", "labels": [], "entities": [{"text": "Ac- curacy", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9714167912801107}]}, {"text": " Table 4: Accuracy ratios of four algorithms (implemented  in Weka) as well as diagnostic steps' majority class base- lines. Experiments used algorithms' default parameters  for final diagnosis (3 labels), differential diagnosis (3 la- bels), and medical lesion morphology (4 labels) using  leave-one-out cross-validation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9932128190994263}, {"text": "Weka", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.9576152563095093}, {"text": "final diagnosis", "start_pos": 178, "end_pos": 193, "type": "TASK", "confidence": 0.6310924738645554}, {"text": "differential diagnosis", "start_pos": 206, "end_pos": 228, "type": "TASK", "confidence": 0.7064445614814758}]}, {"text": " Table 5: Precision and recall of class labels. These were  obtained using the Weka SVM algorithm with default pa- rameters using leave-one-out cross-validation. These cor- respond to the experiment for SVM in Table 4.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8853868246078491}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9967502355575562}]}, {"text": " Table 6: Accuracy ratios for various modalities. Tests  were performed for final diagnosis and differential diag- nosis tags with Weka's SVM algorithm using a leave- out-out cross-validation method. Lexical-structural and  acoustic-prosodic cases used only features in their respec- tive set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9897828698158264}, {"text": "differential diag- nosis tags", "start_pos": 96, "end_pos": 125, "type": "TASK", "confidence": 0.5853971838951111}]}]}