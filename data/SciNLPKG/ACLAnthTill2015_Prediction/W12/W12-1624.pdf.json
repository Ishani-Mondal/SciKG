{"title": [{"text": "Landmark-based Location Belief Tracking in a Spoken Dialog System", "labels": [], "entities": [{"text": "Landmark-based Location Belief Tracking", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5880050286650658}]}], "abstractContent": [{"text": "Many modern spoken dialog systems use probabilistic graphical models to update their belief over the concepts under discussion, increasing robustness in the face of noisy input.", "labels": [], "entities": []}, {"text": "However, such models are ill-suited to prob-abilistic reasoning about spatial relationships between entities.", "labels": [], "entities": []}, {"text": "In particular, a car navigation system that infers users' intended destination using nearby landmarks as descriptions must be able to use distance measures as a factor in inference.", "labels": [], "entities": []}, {"text": "In this paper, we describe a belief tracking system fora location identification task that combines a semantic belief tracker for categorical concepts based on the DPOT framework (Raux and Ma, 2011) with a kernel density estimator that incorporates landmark evidence from multiple turns and landmark hypotheses, into a posterior probability over candidate locations.", "labels": [], "entities": [{"text": "location identification task", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.8486654957135519}, {"text": "DPOT framework", "start_pos": 164, "end_pos": 178, "type": "DATASET", "confidence": 0.9111993312835693}]}, {"text": "We evaluate our approach on a corpus of destination setting dialogs and show that it significantly out-performs a deterministic baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Mobile devices such as smart phones and in-car infotainment systems have generated demand fora new generation of location-based services such as local business search, turn-by-turn navigation, and social event recommendation.", "labels": [], "entities": [{"text": "turn-by-turn navigation", "start_pos": 168, "end_pos": 191, "type": "TASK", "confidence": 0.7070538550615311}, {"text": "social event recommendation", "start_pos": 197, "end_pos": 224, "type": "TASK", "confidence": 0.66652978459994}]}, {"text": "Accessing such services in a timely manner through speech is a crucial requirement, particularly on the go when the user is unable to resort to other modalities e.g. where safety regulations prohibit drivers from using buttons or a touchscreeen while driving.", "labels": [], "entities": []}, {"text": "In such systems, a Point of Interest (POI) or a destination such as a restaurant, store or a public place is often specified.", "labels": [], "entities": []}, {"text": "For example, a car navigation system needs the user to input the destination before giving directions.", "labels": [], "entities": [{"text": "car navigation", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.7800402939319611}]}, {"text": "Similarly, a photo tagging application must allow its users to designate the location where a picture was taken.", "labels": [], "entities": [{"text": "photo tagging", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.74325031042099}]}, {"text": "While postal addresses can be used to unambigously identify locations, they are often either unknown or hard for users to remember.", "labels": [], "entities": []}, {"text": "A more natural (though potentially ambiguous) means of specifying locations is to use landmarks such as \"the Italian restaurant near Red Rock cafe on Castro Street\" or \"the bakery near that mall with a Subway and a 7 Eleven\".", "labels": [], "entities": [{"text": "Italian restaurant near Red Rock cafe on Castro Street", "start_pos": 109, "end_pos": 163, "type": "DATASET", "confidence": 0.6718097958299849}]}, {"text": "A location-based dialog system that understands referring expressions using landmarks could lead to more succinct dialogs, higher recognition accuracy and a greater appearance of intelligence to the user.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9409343004226685}]}, {"text": "We present a system that performs belief tracking over multiple turns of user speech input to infer the most probable target location.", "labels": [], "entities": [{"text": "belief tracking", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.8125203251838684}]}, {"text": "The user interacts with the system through speech in order to specify a target location, and may include references to one or more landmarks.", "labels": [], "entities": []}, {"text": "Such a system must handle two sources of uncertainty.", "labels": [], "entities": []}, {"text": "First, ASR is notoriously error-prone and modern ASR engines provide ranked lists of possible interpretations of speech input rather than single hypotheses.", "labels": [], "entities": [{"text": "ASR", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9897464513778687}, {"text": "ASR", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9619584679603577}]}, {"text": "Second, the suitability of a particular landmark or its likelihood of usage by the speaker depends on a number of factors such as distance, size and prominence of the landmark, familiarity of the user and his expectation of common ground for understanding.", "labels": [], "entities": []}, {"text": "These factors, or at least the resulting variability, must betaken into account when making inferences about target locations from landmark-based expressions.", "labels": [], "entities": []}, {"text": "The first source of ambiguity (speech understanding) has been the target of research on belief tracking (.", "labels": [], "entities": [{"text": "speech understanding", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7433484792709351}, {"text": "belief tracking", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.7469252943992615}]}, {"text": "In previous work, the concepts of interest are entities that are ontologically related (i.e. with is-a or has-a relations), thus discrete probabilistic graphical models such as DBNs have generally sufficed as representations.", "labels": [], "entities": []}, {"text": "But these models are ill-suited for dense continuous spatial relations like the distance between any two locations on a map.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a kernel-based belief tracker as a probabilistic model for inferring target locations from (uncertain) landmarks.", "labels": [], "entities": []}, {"text": "The kernel-based representation allows a natural way to weigh the suitability of a landmark and the speech understanding confidence.", "labels": [], "entities": []}, {"text": "The output of this tracker is combined with that of a Dynamic Probabilistic Ontology Tree (DPOT) (, which performs ontological reasoning over other features of the target location, to give a posterior distribution over the intended location.", "labels": [], "entities": []}, {"text": "We evaluate our approach on anew corpus of location setting dialogs specially collected for this work and find it to significantly outperform a deterministic baseline.", "labels": [], "entities": [{"text": "location setting dialogs", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.7728909254074097}]}], "datasetContent": [{"text": "The architecture of our experimental system is shown in.", "labels": [], "entities": []}, {"text": "The web client, shown in, runs in the participant's web browser and displays the target location of the current scenario using the Google Map API.", "labels": [], "entities": []}, {"text": "The user's goal is to convey this target location to the system through speech only.", "labels": [], "entities": []}, {"text": "The system backend consists of a database of 2902 businesses located in Mountain View, California with their name, street, street number, business category, latitude and longitude provided.", "labels": [], "entities": []}, {"text": "The grammar rules for the NLU and the probability tables in the DPOT are populated from this database.", "labels": [], "entities": [{"text": "NLU", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.9584261775016785}, {"text": "DPOT", "start_pos": 64, "end_pos": 68, "type": "DATASET", "confidence": 0.9392249584197998}]}, {"text": "The web client captures the user speech and sends it to our server with a push-to-talk interface based on the WAMI toolkit ().", "labels": [], "entities": []}, {"text": "The server uses a commercial cloud-based ASR service with generic acoustic and language models, which were not adapted to our task.", "labels": [], "entities": []}, {"text": "The n-best list of hypotheses from the ASR is sent to our robust natural language understanding module for parsing.", "labels": [], "entities": [{"text": "ASR", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8383737206459045}, {"text": "parsing", "start_pos": 107, "end_pos": 114, "type": "TASK", "confidence": 0.9645566344261169}]}, {"text": "Our NLU uses a hybrid approach combining a weighted finite-state transducer (WFST) with string matching based rescoring of the output.", "labels": [], "entities": []}, {"text": "The WFST incorporates out-of-grammar word loops that allow skipping input words at certain points in the parse 2 . This parser robustly maps free form utterances (e.g. \"Okay let's go to that Italian place near, uh..., Red Rock Cafe, on Castro\") to semantic frames (e.g. [Category=italian restaurant, Street=castro street, Landmark=red rock coffee company]).", "labels": [], "entities": [{"text": "WFST", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9578317403793335}]}, {"text": "The NLU confidence score is computed based on the number of words skipped while parsing, and how close the important concept words match the canonical phrases found in the database.", "labels": [], "entities": [{"text": "NLU confidence score", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.6064806083838145}]}, {"text": "For instance, \"Red Rock Cafe\" matches the canonical name \"Red Rock Coffee Company\" with high confidence because rare words (Red, Rock) are identical, and differing but common words (Cafe, Coffee, Company) have a low weight in the score.", "labels": [], "entities": [{"text": "Red Rock Coffee Company\"", "start_pos": 58, "end_pos": 82, "type": "DATASET", "confidence": 0.8055165648460388}]}, {"text": "The string matching score is based on the term-frequency/inverse document frequency (TF-IDF) metric commonly used in information retrieval.", "labels": [], "entities": [{"text": "string matching", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.6423004269599915}, {"text": "term-frequency/inverse document frequency (TF-IDF) metric", "start_pos": 42, "end_pos": 99, "type": "METRIC", "confidence": 0.8086305061976115}, {"text": "information retrieval", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.7673999071121216}]}, {"text": "In our case, the weight of different terms (IDF) is estimated based on their frequency of occurrence in different database entries (i.e. how uniquely they describe a matching entry).", "labels": [], "entities": [{"text": "IDF)", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9705148637294769}]}, {"text": "We use the secondstring open-source library for string matching.", "labels": [], "entities": [{"text": "string matching", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7392282783985138}]}, {"text": "For any ASR hypothesis, the NLU is likely to generate several parses which are all merged in a global list of candidate parses.", "labels": [], "entities": [{"text": "ASR", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9859484434127808}]}, {"text": "For each candidate parse, the system generates a set of dialog acts (one per concept in the parse) which are input to the belief tracker with their confidence score.", "labels": [], "entities": []}, {"text": "Following the approach described in section 3, dialog acts corresponding to the Landmark concept are sent to the kernel-based location belief tracker, while all other concepts are sent to a Dynamic Probabilistic Ontology Trees (DPOT) semantic belief tracker, whose structure is shown in.", "labels": [], "entities": []}, {"text": "We use a two-level tree.", "labels": [], "entities": []}, {"text": "The value of the root node (Id) is never directly observed and represents the database entry targeted by the user.", "labels": [], "entities": []}, {"text": "The leaf nodes correspond to the relevant attributes Name, Category, and Street.", "labels": [], "entities": []}, {"text": "For any database entry e, attribute a and value of that attribute v a , the conditional probability P (a = v a |Id = e) is set to 1 if the value of a is v a for entry e in the database, and to 0 otherwise.", "labels": [], "entities": []}, {"text": "For attributes such as Category, which allow several possible values for each entry, the probability is split equally among valid values.", "labels": [], "entities": []}, {"text": "After each user utterance, the network is augmented with anew Evidence Network capturing the possible interpretations and their likelihood, as computed by the NLU.", "labels": [], "entities": [{"text": "NLU", "start_pos": 159, "end_pos": 162, "type": "DATASET", "confidence": 0.9626887440681458}]}, {"text": "The posterior probability distribution over user goals is computed and rescored using the kernel-based location tracker.", "labels": [], "entities": []}, {"text": "Finally, the Response Generator takes the highest scoring target location from the belief tracker and sends it back to the web client which displays it on the map and also indicates what are the values of the Name, Category, and Street concepts for the top belief (see).", "labels": [], "entities": []}, {"text": "If the top belief location does not match the goal of the scenario, the user can speak again to refine or correct the system belief.", "labels": [], "entities": []}, {"text": "After the user has spoken 5 utterances, they also get the choice of moving onto the next scenario (in which case the dialog is considered a failure).", "labels": [], "entities": []}], "tableCaptions": []}