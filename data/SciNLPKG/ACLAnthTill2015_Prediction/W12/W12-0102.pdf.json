{"title": [{"text": "Measuring Comparability of Documents in Non-Parallel Corpora for Efficient Extraction of (Semi-)Parallel Translation Equivalents", "labels": [], "entities": [{"text": "Efficient Extraction of (Semi-)Parallel Translation Equivalents", "start_pos": 65, "end_pos": 128, "type": "TASK", "confidence": 0.6693956620163388}]}], "abstractContent": [{"text": "In this paper we present and evaluate three approaches to measure comparability of documents in non-parallel corpora.", "labels": [], "entities": []}, {"text": "We develop a task-oriented definition of comparability , based on the performance of automatic extraction of translation equivalents from the documents aligned by the proposed metrics, which formalises intuitive definitions of comparability for machine translation research.", "labels": [], "entities": [{"text": "machine translation research", "start_pos": 245, "end_pos": 273, "type": "TASK", "confidence": 0.8384852409362793}]}, {"text": "We demonstrate application of our metrics for the task of automatic extraction of parallel and semi-parallel translation equivalents and discuss how these resources can be used in the frameworks of statistical and rule-based machine translation.", "labels": [], "entities": [{"text": "automatic extraction of parallel and semi-parallel translation equivalents", "start_pos": 58, "end_pos": 132, "type": "TASK", "confidence": 0.7393713071942329}, {"text": "machine translation", "start_pos": 225, "end_pos": 244, "type": "TASK", "confidence": 0.6857143938541412}]}], "introductionContent": [{"text": "Parallel corpora have been extensively exploited in different ways in machine translation (MT) -both in Statistical (SMT) and more recently, in Rule-Based (RBMT) architectures: in SMT aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in RBMT, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.8610654354095459}]}, {"text": "However, large parallel resources are not always available, especially for under-resourced languages or narrow domains.", "labels": [], "entities": []}, {"text": "Therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the MT community).", "labels": [], "entities": [{"text": "MT", "start_pos": 116, "end_pos": 118, "type": "TASK", "confidence": 0.9738053679466248}]}, {"text": "Most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction), parallel phrase extraction (), and parallel sentence extraction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.766989678144455}, {"text": "bilingual lexicon extraction", "start_pos": 132, "end_pos": 160, "type": "TASK", "confidence": 0.6481467386086782}, {"text": "parallel phrase extraction", "start_pos": 163, "end_pos": 189, "type": "TASK", "confidence": 0.6344593266646067}, {"text": "parallel sentence extraction", "start_pos": 198, "end_pos": 226, "type": "TASK", "confidence": 0.6982286175092062}]}, {"text": "Comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.", "labels": [], "entities": []}, {"text": "The problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.", "labels": [], "entities": []}, {"text": "Research on comparable corpora needs not only good measures for comparability, but also a clearer, technologicallygrounded and quantifiable definition of comparability in the first place.", "labels": [], "entities": []}, {"text": "In this paper we relate comparability to usefulness of comparable texts for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.9924943447113037}]}, {"text": "In particular, we propose a performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents -words, phrases and sentences which are translations of each other.", "labels": [], "entities": []}, {"text": "This definition directly relates comparability to texts' potential to improve the quality of MT by adding extracted phrases to phrase tables, training corpus or dictionaries.", "labels": [], "entities": [{"text": "MT", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.9901719689369202}]}, {"text": "It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in.", "labels": [], "entities": []}, {"text": "Still, successful detection of translation equivalents from comparable corpora very much de-pends on the quality of these corpora, specifically on the degree of their textual equivalence and successful alignment on various text units.", "labels": [], "entities": []}, {"text": "Therefore, the goal of this work is to provide comparability metrics which can reliably identify crosslingual comparable documents from raw corpora crawled from the Web, and characterize the degree of their similarity, which enriches comparable corpora with the document alignment information, filters out documents that are not useful and eventually leads to extraction of good-quality translation equivalents from the corpora.", "labels": [], "entities": []}, {"text": "To achieve this goal, we need to define a scale to assess comparability qualitatively, metrics to measure comparability quantitatively, and the sources to get comparable corpora from.", "labels": [], "entities": []}, {"text": "In this work, we directly characterize comparability by how useful comparable corpora are for the task of detecting translation equivalents in them, and ultimately to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.807819128036499}]}, {"text": "We focus on document-level comparability, and use three categories for qualitative definition of comparability levels, defined in terms of granularity for possible alignment: \u2022 Parallel: Traditional parallel texts that are translations of each other or approximate translations with minor variations, which can be aligned on the sentence level.", "labels": [], "entities": []}, {"text": "\u2022 Strongly-comparable: Texts that talk about the same event or subject, but in different languages.", "labels": [], "entities": []}, {"text": "For example, international news about oil spill in the Gulf of Mexico, or linked articles in Wikipedia about the same topic.", "labels": [], "entities": []}, {"text": "These documents can be aligned on the document level on the basis of their origin.", "labels": [], "entities": []}, {"text": "\u2022 Weakly-comparable: Texts in the same subject domain which describe different events.", "labels": [], "entities": []}, {"text": "For example, customer reviews about hotel and restaurant in London.", "labels": [], "entities": []}, {"text": "These documents do not have an independent alignment across languages, but sets of texts can be aligned on the basis of belonging to the same subject domain or sub-domain.", "labels": [], "entities": []}, {"text": "In this paper, we present three different approaches to measure the comparability of crosslingual (especially under-resourced languages) comparable documents: a lexical mapping based approach, a keyword based approach, and a machine translation based approach.", "labels": [], "entities": []}, {"text": "The experimental results show that all of them can effectively predict the comparability levels of the compared document pairs.", "labels": [], "entities": []}, {"text": "We then further investigate the applicability of the proposed metrics by measuring their impact on the task of parallel phrase extraction from comparable corpora.", "labels": [], "entities": [{"text": "parallel phrase extraction", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.6261634131272634}]}, {"text": "It turns out that, higher comparability level predicted by the metrics consistently lead to more number of parallel phrase extracted from comparable documents.", "labels": [], "entities": []}, {"text": "Thus, the metrics can help select more comparable document pairs to improve the performance of parallel phrase extraction.", "labels": [], "entities": [{"text": "parallel phrase extraction", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.6467032333215078}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses previous work.", "labels": [], "entities": []}, {"text": "Section 3 introduces our comparability metrics.", "labels": [], "entities": []}, {"text": "Section 4 presents the experimental results and evaluation.", "labels": [], "entities": []}, {"text": "Section 5 describes the application of the metrics.", "labels": [], "entities": []}, {"text": "Section 6 discusses the pros and cons of the proposed metrics, followed by conclusions and future work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We adopt a simple method for evaluation.", "labels": [], "entities": []}, {"text": "For each language pair, we compute the average scores for all the document pairs in the same comparability level, and compare them to the gold: Data distribution of gold standard corpora standard comparability labels.", "labels": [], "entities": []}, {"text": "In addition, in order to better reveal the relation between the scores obtained from the proposed metrics and comparability levels, we also measure the Pearson correlation between them 8 . For the keyword based metric, top 30 keywords are extracted from each text for experiment.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 152, "end_pos": 171, "type": "METRIC", "confidence": 0.9879883527755737}]}, {"text": "For the machine translation based metric, we empirically set \u03b1 = 0.5, \u03b2 = \u03b3 = 0.2, and \u03b4 = 0.1.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.6787007302045822}]}, {"text": "This is based on the assumption that, lexical feature can best characterize the comparability given the good translation quality provided by the powerful MT system, while keyword and named entity features are also better indicators of comparability than the simple document length information.", "labels": [], "entities": []}, {"text": "The results for the lexical mapping based metric, the keyword based metric and the machine translation based metric are listed in    ably reflect the comparability levels across different language pairs, as the average scores for higher comparable levels are always significantly larger than those of lower comparable levels, namely SC(parallel)>SC(stronglycomparable)>SC(weakly-comparable).", "labels": [], "entities": []}, {"text": "In addition, in all the three metrics, the Pearson correlation scores are very high (over 0.93) across different language pairs, which indicate that there is strong correlation between the comparability scores obtained from the metrics and the corresponding comparability level.", "labels": [], "entities": [{"text": "Pearson correlation scores", "start_pos": 43, "end_pos": 69, "type": "METRIC", "confidence": 0.9588425159454346}]}, {"text": "Moreover, from the comparison of, 3, and 4, we also have several other findings.", "labels": [], "entities": []}, {"text": "Firstly, the performance of keyword based metric (see) is comparable to the lexical mapping based metric (see) as their comparability scores for the corresponding comparability levels are similar.", "labels": [], "entities": []}, {"text": "This means it is reasonable to determine the comparability level by only comparing a small number of keywords of the texts.", "labels": [], "entities": []}, {"text": "Secondly, the scores obtained from the machine translation based metric (see) are significantly higher than those in both the lexical mapping based metric and the keyword based metric.", "labels": [], "entities": []}, {"text": "Clearly, this is due to the advantages of using the state-of-theart MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.9653690457344055}]}, {"text": "In comparison to the approach of using dictionary for word-for-word mapping, it can provide much better text translation which allows detecting more proportion of lexical overlapping and mining more useful features in the translated texts.", "labels": [], "entities": [{"text": "word-for-word mapping", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7376794815063477}, {"text": "text translation", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.7368208169937134}]}, {"text": "Thirdly, in the lexical mapping based metric and keyword based metric, we can also see that, although the average scores for EL-RO (both under-resourced languages) conform to the comparability levels, they are much lower than those of the other 5 language pairs.", "labels": [], "entities": []}, {"text": "The reason is that, the size of the parallel corpora in JRCAcquis for these 5 language pairs are significantly larger (over 1 million parallel sentences) than that of EL-EN, RO-EN 9 , and EL-RO, thus the resulting dictionaries of these 5 language pairs also contain many more dictionary entries.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data distribution of gold standard corpora", "labels": [], "entities": []}, {"text": " Table 2: Average comparability scores for lexical map- ping based metric", "labels": [], "entities": []}, {"text": " Table 3: Average comparability scores for keyword  based metric", "labels": [], "entities": []}, {"text": " Table 4: Average comparability scores for machine  translation based metric", "labels": [], "entities": [{"text": "machine  translation", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.8004985153675079}]}, {"text": " Table 5: Impact of the lexical mapping based metric to  parallel phrase extraction", "labels": [], "entities": [{"text": "parallel phrase extraction", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.6416709125041962}]}, {"text": " Table 6: Impact of the keyword based metric to parallel  phrase extraction", "labels": [], "entities": [{"text": "parallel  phrase extraction", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.6138808031876882}]}, {"text": " Table 7: Impact of the machine translation based met- ric to parallel phrase extraction", "labels": [], "entities": [{"text": "parallel phrase extraction", "start_pos": 62, "end_pos": 88, "type": "TASK", "confidence": 0.6969473361968994}]}]}