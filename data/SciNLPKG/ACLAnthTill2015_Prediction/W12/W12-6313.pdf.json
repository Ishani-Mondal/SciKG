{"title": [{"text": "Cascaded Chinese Weibo Segmentation Based on CRFs", "labels": [], "entities": [{"text": "Cascaded Chinese Weibo Segmentation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5952866449952126}]}], "abstractContent": [{"text": "With the developments of Web2.0, the process for the data on Internet becomes necessary.", "labels": [], "entities": []}, {"text": "This Paper reports our work for Chinese weibo segmentation in the 2012 CIPS-SIGHAN bakeoff.", "labels": [], "entities": [{"text": "Chinese weibo segmentation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.5398765802383423}, {"text": "CIPS-SIGHAN bakeoff", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.8092695772647858}]}, {"text": "In order to improve the recognition accuracy of out-of-vocabulary words, we propose a cascaded model which first segments and disam-biguates in-vocabulary words, then recovers out-of-vocabulary words from the fragments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9322249889373779}]}, {"text": "Both the two process are trained by a character-based CRFs model with user-edited external vocabulary.", "labels": [], "entities": []}, {"text": "The final performance on the test data shows that our system achieves a promising result.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since there are no spaces in Chinese sentences, Chinese word segmentation becomes a vital and fundamental task in Chinese language processing.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.61635688940684}, {"text": "Chinese language processing", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.6550543308258057}]}, {"text": "Many approaches have been implemented in Chinese segmentation, including simple Forward Maximum Match (FMM), statistic based methods like Hidden Markov model, conditional random fields model, along with other learning models().", "labels": [], "entities": [{"text": "Chinese segmentation", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.5036022067070007}, {"text": "Forward Maximum Match (FMM)", "start_pos": 80, "end_pos": 107, "type": "METRIC", "confidence": 0.9444039662679037}]}, {"text": "The main problems of segmentation are word boundary ambiguities and out-of-vocabulary (OOV) word recognition while many researchers have been working on them ().", "labels": [], "entities": [{"text": "segmentation", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.9677179455757141}, {"text": "OOV) word recognition", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.6529147922992706}]}, {"text": "Recent developments in Web 2.0 have heightened the need for Web text processing (, which makes the problems above more prominent.", "labels": [], "entities": [{"text": "Web text processing", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.5694246888160706}]}, {"text": "Being different from traditional texts like news reports and literary works, Web texts like microblogs, tweets tend to be more oral, casual, and have plenty of catchwords, typos and OOVs in them, which bring much challenge to language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 226, "end_pos": 248, "type": "TASK", "confidence": 0.7216679751873016}]}, {"text": "For example, \"Gelivable\" is a Chinglish word coined by Chinese people stands for the word \"\u7ed9\u529b\" (awesome), which is a popular Chinese catchword in Web texts.", "labels": [], "entities": [{"text": "Gelivable", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9419243931770325}]}, {"text": "Some users leave the typos deliberately to unique and individual.", "labels": [], "entities": []}, {"text": "For instance, \"\u788e\u53eb\" (shleep) stands for \"\u7761 \u89c9\" (sleep).", "labels": [], "entities": []}, {"text": "Although human people would understand the meaning of this piece of Chinese tweets, segmenter based on dictionary may never understand how it went wrong).", "labels": [], "entities": []}, {"text": "In the next place, thousands of new words emerge from current event, social phenomena or even actors' lines.", "labels": [], "entities": []}, {"text": "For instance, \"\u55b5\u661f\u4eba\" and \"\u57fa\u53cb\" are the new words that emerged from Internet not long ago, which stands for \"cat\" and \"gay friend\" respectively.", "labels": [], "entities": []}, {"text": "And the sentence patterns like \" \u795e\u9a6c\u90fd \u662f\u6d6e\u4e91\" (Everything is nothing.) a prevalent slogan of many people on the Internet.", "labels": [], "entities": []}, {"text": "These phenomena exemplified above exacerbate the OOV problem (.", "labels": [], "entities": [{"text": "OOV", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.6049705743789673}]}, {"text": "Take weibo, a popular Chinese MicroBlog, for example, within apiece of text restricted to 140 Chinese characters, there are 21.7(15.5%) OOV words on average.", "labels": [], "entities": []}, {"text": "Finally, the structure of MicroBlog sentences prone to be simple, elliptical, non-predicate and incompleteness.", "labels": [], "entities": []}, {"text": "Some of the sentences are mixed with words in foreign languages and emoticons (like :), ToT).", "labels": [], "entities": [{"text": "ToT", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.5755569338798523}]}, {"text": "Hence the segmenter based on linguistic knowledge would not be efficient enough (.", "labels": [], "entities": []}, {"text": "In order to better solve the Web text problems, we propose an efficient Chinese Web text segmentation model based on CRF model with a useredited dictionary.", "labels": [], "entities": [{"text": "Chinese Web text segmentation", "start_pos": 72, "end_pos": 101, "type": "TASK", "confidence": 0.6318681091070175}]}, {"text": "Specifically, we first conduct a coarse-grained segment for input Web text, then refine the results through models learned from new word vocabulary provided by users.", "labels": [], "entities": []}, {"text": "Following sections describe in detail the proposed method and its results on the SIGHAN 2012 Chinese MicroBlog segmentation task.", "labels": [], "entities": [{"text": "SIGHAN 2012 Chinese MicroBlog segmentation task", "start_pos": 81, "end_pos": 128, "type": "TASK", "confidence": 0.7230737408002218}]}, {"text": "In sec-tion 2 to 4, we introduce the main idea of our method.", "labels": [], "entities": []}, {"text": "Section 5 gives experiment results and related analysis, which proves the effectiveness of our model.", "labels": [], "entities": []}, {"text": "Section 6 addresses the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We design 4 experiments to test contributions of different features, and the effectiveness of our proposed model.", "labels": [], "entities": []}, {"text": "The comparison of the result is made and shown in.", "labels": [], "entities": []}, {"text": "The base training data we used is 6 months of People Daily in year 2000 built by Peking University ().", "labels": [], "entities": [{"text": "People Daily in year 2000", "start_pos": 46, "end_pos": 71, "type": "DATASET", "confidence": 0.9536488652229309}, {"text": "Peking University", "start_pos": 81, "end_pos": 98, "type": "DATASET", "confidence": 0.8000115156173706}]}, {"text": "Experiment 1 uses features listed in, and experiment 2 adds features listed in.", "labels": [], "entities": []}, {"text": "The test data of experiment 1 and 2 are MicroBlog training samples.", "labels": [], "entities": [{"text": "MicroBlog training samples", "start_pos": 40, "end_pos": 66, "type": "DATASET", "confidence": 0.9030467669169108}]}, {"text": "In experiment 3, we add half of training samples of SIGHAN, while the rest half is used for test data.", "labels": [], "entities": [{"text": "SIGHAN", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.4954116940498352}]}, {"text": "Experiment 4 uses base training data and all the MicroBlog training samples provided by SIGHAN, and is evaluated on the test data provided by SIGHAN.", "labels": [], "entities": [{"text": "MicroBlog training samples", "start_pos": 49, "end_pos": 75, "type": "DATASET", "confidence": 0.8714499076207479}, {"text": "SIGHAN", "start_pos": 88, "end_pos": 94, "type": "DATASET", "confidence": 0.8321537375450134}, {"text": "SIGHAN", "start_pos": 142, "end_pos": 148, "type": "DATASET", "confidence": 0.9288357496261597}]}, {"text": "From the results of experiment 1 and 2,we can observe that adding cohesion ratio of two characters listed in achieves a higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9982238411903381}]}, {"text": "The cohesion ratio of characters is a strong sign for them being a word or not.", "labels": [], "entities": []}, {"text": "From the result of experiment 2 and 3, we learn that to achieve a better performance in mirco-blog sengmentation, more corpora or features that embody the characteristics of MicroBlog is vitally needed.", "labels": [], "entities": [{"text": "mirco-blog sengmentation", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.7809099555015564}]}], "tableCaptions": [{"text": " Table 2: Context features and character type fea- tures we used.", "labels": [], "entities": []}, {"text": " Table 5: Experiment results comparison in differ- ent data settings, in which Weibo stands for Weibo  samples and test data is the given Weibo test data.", "labels": [], "entities": [{"text": "Weibo  samples", "start_pos": 96, "end_pos": 110, "type": "DATASET", "confidence": 0.8872197866439819}, {"text": "Weibo test data", "start_pos": 138, "end_pos": 153, "type": "DATASET", "confidence": 0.9534059564272562}]}, {"text": " Table 6: Feature used here is the cohesion ratio  feature.  Table 6 demonstrates test result on the text from  a month of People Daily. We can observe that F  score is improved to 0.973 after adding cohesion  features of characters, which is consistent with the  observation on MicroBlog data in Experiment 2.", "labels": [], "entities": [{"text": "People Daily", "start_pos": 123, "end_pos": 135, "type": "DATASET", "confidence": 0.9071348011493683}, {"text": "F  score", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9911554753780365}, {"text": "MicroBlog data", "start_pos": 279, "end_pos": 293, "type": "DATASET", "confidence": 0.964621514081955}]}]}