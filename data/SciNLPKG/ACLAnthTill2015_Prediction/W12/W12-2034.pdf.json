{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 289-294, Memory-based text correction for preposition and determiner errors", "labels": [], "entities": [{"text": "Memory-based text correction", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.5298749804496765}]}], "abstractContent": [{"text": "We describe the Valkuil.net team entry for the HOO 2012 Shared Task.", "labels": [], "entities": [{"text": "Valkuil.net team entry", "start_pos": 16, "end_pos": 38, "type": "DATASET", "confidence": 0.8767549196879069}, {"text": "HOO 2012 Shared Task", "start_pos": 47, "end_pos": 67, "type": "DATASET", "confidence": 0.7528938502073288}]}, {"text": "Our systems consists of four memory-based classifiers that generate correction suggestions for middle positions in small text windows of two words to the left and to the right.", "labels": [], "entities": []}, {"text": "Trained on the Google 1TB 5-gram corpus, the first two classifiers determine the presence of a determiner or a preposition between all words in a text in which the actual determiners and prepositions are masked.", "labels": [], "entities": [{"text": "Google 1TB 5-gram corpus", "start_pos": 15, "end_pos": 39, "type": "DATASET", "confidence": 0.7954213470220566}]}, {"text": "The second pair of classifiers determines which is the most likely correction given a masked de-terminer or preposition.", "labels": [], "entities": []}, {"text": "The hyperparameters that govern the classifiers are optimized on the shared task training data.", "labels": [], "entities": []}, {"text": "We point out a number of obvious improvements to boost the medium-level scores attained by the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our Valkuil.net team entry, known under the abbreviation 'VA' in the, is a simplistic text correction system based on four memory-based classifiers.", "labels": [], "entities": [{"text": "Valkuil.net team entry", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.8795547286669413}, {"text": "VA", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9840976595878601}, {"text": "text correction", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.712243378162384}]}, {"text": "The goal of the system is to be lightweight: simple to setup and train, fast in execution.", "labels": [], "entities": []}, {"text": "It requires a (preferably very large) corpus to train on, and a closed list of words which together form the category of interest-in the HOO 2012 Shared Task context, the two categories of interest are prepositions and determiners.", "labels": [], "entities": [{"text": "HOO 2012 Shared Task context", "start_pos": 137, "end_pos": 165, "type": "DATASET", "confidence": 0.9041917085647583}]}, {"text": "As a corpus we used the Google 1TB 5-gram corpus (), and we used two lists, one consisting of 47 prepositions and one consisting of 24 determiners, both extracted from the HOO 2012 Shared Task training data.", "labels": [], "entities": [{"text": "Google 1TB 5-gram corpus", "start_pos": 24, "end_pos": 48, "type": "DATASET", "confidence": 0.8547592461109161}, {"text": "HOO 2012 Shared Task training data", "start_pos": 172, "end_pos": 206, "type": "DATASET", "confidence": 0.8650848964850107}]}, {"text": "Using the Google corpus means that we restricted ourselves to a simple 5-gram context, which obviously places a limit on the context sensitivity of our system; yet, we were able to make use of the entire Google corpus.", "labels": [], "entities": [{"text": "Google corpus", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8955618739128113}, {"text": "Google corpus", "start_pos": 204, "end_pos": 217, "type": "DATASET", "confidence": 0.8603266775608063}]}, {"text": "Memory-based classifiers have been used for confusible disambiguation (Van den) and agreement error detection (Stehouwer and Van den Bosch, 2009).", "labels": [], "entities": [{"text": "agreement error detection", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.5595022340615591}]}, {"text": "In both studies it is argued that fast approximations of memory-based discriminative classifiers are effective and efficient modules for spelling correction, particularly because of their insensitivity to the number of classes to be predicted.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.9766676127910614}]}, {"text": "They can act as simple binary decision makers (e.g. for confusible pairs: given this context, is then or than more likely?), and at the same time they can handle missing word prediction with up to millions of possible outcomes, all in the same model.", "labels": [], "entities": [{"text": "missing word prediction", "start_pos": 162, "end_pos": 185, "type": "TASK", "confidence": 0.6673819422721863}]}, {"text": "Van den Bosch (2006) also showed consistent log-linear performance gains in learning curve experiments, indicating that more training data continues to be better for these models even at very large amounts of training data.", "labels": [], "entities": []}, {"text": "The interested reader is referred to the two studies for more details.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Semi-automatically established thresholds that  optimize precision, recall, and F-Score. Optimization  was performed on the HOO 2012 Shared Task training  data.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9987390637397766}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9996106028556824}, {"text": "F-Score", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9978752136230469}, {"text": "Optimization", "start_pos": 99, "end_pos": 111, "type": "METRIC", "confidence": 0.9337811470031738}, {"text": "HOO 2012 Shared Task training  data", "start_pos": 134, "end_pos": 169, "type": "DATASET", "confidence": 0.9406126042207082}]}, {"text": " Table 2: Best scores of our system before (left) and after (right) revisions. Scores are reported at the overall level (top),  on prepositions (middle), and determiners (bottom).", "labels": [], "entities": [{"text": "determiners", "start_pos": 158, "end_pos": 169, "type": "METRIC", "confidence": 0.9627866744995117}]}]}