{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 122-126, Scoring Spoken Responses Based on Content Accuracy", "labels": [], "entities": [{"text": "Scoring Spoken Responses Based on Content Accuracy", "start_pos": 100, "end_pos": 150, "type": "TASK", "confidence": 0.8430363195283073}]}], "abstractContent": [{"text": "Accuracy of content have not been fully utilized in the previous studies on automated speaking assessment.", "labels": [], "entities": [{"text": "automated speaking assessment", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.6022239228089651}]}, {"text": "Compared to writing tests, responses in speaking tests are noisy (due to recognition errors), full of incomplete sentences, and short.", "labels": [], "entities": []}, {"text": "To handle these challenges for doing content-scoring in speaking tests, we propose two new methods based on information extraction (IE) and machine learning.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 108, "end_pos": 135, "type": "TASK", "confidence": 0.8491976022720337}]}, {"text": "Compared to using an ordinary content-scoring method based on vector analysis , which is widely used for scoring written essays, our proposed methods provided content features with higher correlations to human holistic scores.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there is an increasing interest of using speech processing and natural language processing (NLP) technologies to automatically score speaking tests.", "labels": [], "entities": []}, {"text": "A set of features related to speech delivery, such as fluency, pronunciation, and intonation, has been utilized in these studies.", "labels": [], "entities": [{"text": "speech delivery", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.7046356648206711}]}, {"text": "However, accuracy of an answer's content to the question being asked, important factors to be considered during the scoring process, have not been fully utilized.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9985747337341309}]}, {"text": "In this paper, we will report our initial efforts exploring content scoring in an automated speaking assessment task.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.7441582977771759}]}, {"text": "To start, we will briefly describe the speaking test questions in our research.", "labels": [], "entities": []}, {"text": "In the test we used for evaluation, there were two types of questions.", "labels": [], "entities": []}, {"text": "The first type, survey, requires a test-taker to provide answers specific to one or several key points in a survey question without any background reading/listening related to the topic of the survey.", "labels": [], "entities": []}, {"text": "Typical questions could be \"how frequently do you go shopping?\" or \"what kind of products did you purchase recently?\"", "labels": [], "entities": []}, {"text": "In contrast, the second type, opinion, requires a testtaker to speak as long as 60 seconds to present his or her opinions about some topic.", "labels": [], "entities": []}, {"text": "An example of such questions could be, \"Do you agree with the statement that online shopping will be dominant in future or not?\"", "labels": [], "entities": []}, {"text": "Compared to the essays in writing tests, these spoken responses could just be incomplete sentences.", "labels": [], "entities": []}, {"text": "For example, for the survey questions, test-takers could just say several words.", "labels": [], "entities": []}, {"text": "For the questions described above, some test-takers may just use phrases like \"once a week\" or \"books\".", "labels": [], "entities": []}, {"text": "In addition, given short responding durations, the number of words in test-takers' responses is limited.", "labels": [], "entities": []}, {"text": "Furthermore, since scoring speech responses requires speech recognition, more noisy inputs are expected.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7259185016155243}]}, {"text": "To tackle these challenges, we propose two novel content scoring methods in this paper.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.682482585310936}]}, {"text": "The remainder of the paper is organized as follows: Section 2 reviews the related previous research efforts; Section 3 proposes the two contentscoring methods we designed for two types of questions described above; Section 4 reports the experimental results of applying the proposed methods; finally, Section 5 concludes our reported research and describes our plans for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experimental data was from a test for international workplace English.", "labels": [], "entities": []}, {"text": "Six testing papers were used in our study and each individual test contains three survey questions (1, 2, and 3) and two opinion questions (4 and 5).", "labels": [], "entities": []}, {"text": "lists examples for these question types.", "labels": [], "entities": []}, {"text": "From the real test, we collected spoken responses from a total of 1, 838 test-takers.", "labels": [], "entities": []}, {"text": "1, 470 test-takers were used for training and 368 were used for testing.", "labels": [], "entities": []}, {"text": "Following scoring rubrics developed for this test by considering speakers' various language skill aspects, such as fluency, pronunciation, vocabulary, as well as content accuracy, the survey and opinion responses were scored by a group of experienced human raters by using a 3-point scale and a 5-point scale respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9088598489761353}]}, {"text": "For the survey responses, the human judged scores were centered on 2; for the opinion responses, the human judged scores were centered on 3 and 4.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. First, we find that CVA, which is de- signed for scoring lengthy written essays, does not  work well for the survey questions, especially on", "labels": [], "entities": [{"text": "CVA", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.5497967600822449}]}]}