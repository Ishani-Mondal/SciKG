{"title": [], "abstractContent": [{"text": "This paper describes LIMSI's submissions to the shared translation task.", "labels": [], "entities": [{"text": "shared translation task", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.701875239610672}]}, {"text": "We report results for French-English and German-English in both directions.", "labels": [], "entities": []}, {"text": "Our submissions use n-code, an open source system based on bilingual n-grams.", "labels": [], "entities": []}, {"text": "In this approach, both the translation and target language models are estimated as conventional smoothed n-gram models; an approach we extend hereby estimating the translation probabilities in a continuous space using neural networks.", "labels": [], "entities": []}, {"text": "Experimental results show a significant and consistent BLEU improvement of approximately 1 point for all conditions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9994788765907288}]}, {"text": "We also report preliminary experiments using an \"on-the-fly\" translation model.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes LIMSI's submissions to the shared translation task of the Seventh Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "shared translation task of the Seventh Workshop on Statistical Machine Translation", "start_pos": 48, "end_pos": 130, "type": "TASK", "confidence": 0.6340529024600983}]}, {"text": "LIMSI participated in the French-English and German-English tasks in both directions.", "labels": [], "entities": [{"text": "LIMSI", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7920122742652893}]}, {"text": "For this evaluation, we used n-code, an open source in-house Statistical Machine Translation (SMT) system based on bilingual n-grams 1 . The main novelty of this year's participation is the use, in a large scale system, of the continuous space translation models described in).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 61, "end_pos": 98, "type": "TASK", "confidence": 0.7785157263278961}, {"text": "continuous space translation", "start_pos": 227, "end_pos": 255, "type": "TASK", "confidence": 0.7175354361534119}]}, {"text": "These models estimate the n-gram probabilities of bilingual translation units using neural networks.", "labels": [], "entities": []}, {"text": "We also investigate an alternative approach where the translation probabilities of a phrase based system are estimated \"on-the-fly\" http://ncode.limsi.fr/ by sampling relevant examples, instead of considering the entire training set.", "labels": [], "entities": []}, {"text": "Finally we also describe the use in a rescoring step of several additional features based on IBM1 models and word sense disambiguation information.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 109, "end_pos": 134, "type": "TASK", "confidence": 0.6532039443651835}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of the baseline systems built with n-code, including the standard translation model (TM).", "labels": [], "entities": []}, {"text": "The continuous space translation models are then described in Section 3.", "labels": [], "entities": [{"text": "continuous space translation", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6990768313407898}]}, {"text": "As in our previous participations, several steps of data preprocessing, cleaning and filtering are applied, and their improvement took a non-negligible part of our work.", "labels": [], "entities": [{"text": "data preprocessing", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7217686474323273}]}, {"text": "These steps are summarized in Section 5.", "labels": [], "entities": []}, {"text": "The last two sections report experimental results obtained with the \"on-the-fly\" system in Section 6 and with n-code in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "For this year's evaluation, we also investigated several additional features based on IBM1 models and word sense disambiguation (WSD) information in rescoring.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 102, "end_pos": 133, "type": "TASK", "confidence": 0.6143206655979156}]}, {"text": "As for the SOUL models, these features are added after the n-best list generation step.", "labels": [], "entities": []}, {"text": "In previous work), the IBM1 features () are found helpful.", "labels": [], "entities": []}, {"text": "As the IBM1 model is asymmetric, two models are estimated, one in both directions.", "labels": [], "entities": []}, {"text": "Contrary to the reported results, these additional features do not yield significant improvements over the baseline system.", "labels": [], "entities": []}, {"text": "We assume that the difficulty is to add information to an already extensively optimized system.", "labels": [], "entities": []}, {"text": "Moreover, the IBM1 models are estimated on the same training corpora as the translation system, a fact that may explain the redundancy of these additional features.", "labels": [], "entities": []}, {"text": "Ina separate series of experiments, we also add WSD features calculated according to a variation of the method proposed in.", "labels": [], "entities": [{"text": "WSD", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.7272641658782959}]}, {"text": "For each word of a subset of the input (source language) vocabulary, a simple WSD classifier produces a probability distribution over a set of translations 8 . During reranking, each translation hypothesis is scanned and the word translations that match one of the proposed variant are rewarded using an additional score.", "labels": [], "entities": []}, {"text": "While this method had given some", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results in terms of BLEU scores  measured on the newstest2011 and newstest2012. For  newstest2012, the scores are provided by the organizers.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9989551305770874}, {"text": "newstest2011", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.9559538960456848}, {"text": "newstest2012", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.9134808778762817}]}]}