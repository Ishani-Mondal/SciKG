{"title": [{"text": "Effect of Language and Error Models on Efficiency of Finite-State Spell-Checking and Correction", "labels": [], "entities": []}], "abstractContent": [{"text": "We inspect the viability of finite-state spell-checking and contextless correction of non-word errors in three languages with a large degree of morphological variety.", "labels": [], "entities": [{"text": "contextless correction of non-word errors", "start_pos": 60, "end_pos": 101, "type": "TASK", "confidence": 0.7950916767120362}]}, {"text": "Overviewing previous work, we conduct large-scale tests involving three languages-English, Finnish and Greenlandic-and a variety of error models and algorithms, including proposed improvements of our own.", "labels": [], "entities": []}, {"text": "Special reference is made to on-line three-way composition of the input, the error model and the language model.", "labels": [], "entities": []}, {"text": "Tests are run on real-world text acquired from freely available sources.", "labels": [], "entities": []}, {"text": "We show that the finite-state approaches discussed are sufficiently fast for high-quality correction, even for Greenlandic which, due to its morphological complexity, is a difficult task for non-finite-state approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "In most implementations of spell-checking, efficiency is a limiting factor for selecting or discarding spell-checking solutions.", "labels": [], "entities": []}, {"text": "In the case of finitestate spell-checking it is known that finite-state language models can efficiently encode dictionaries of natural languages, even for polysynthetic languages.", "labels": [], "entities": []}, {"text": "Most contemporary spell-checking and correction systems are still based on programmatic solutions (e.g. hunspell 1 , and its *spell relatives), or at most specialised algorithms for implementing error-tolerant traversal of the finite-state dictionaries.", "labels": [], "entities": [{"text": "spell-checking and correction", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.6994999249776205}]}, {"text": "There have also been few fully finite-state implementations that both detect and correct errors (.", "labels": [], "entities": []}, {"text": "In this paper we further evaluate the use of finite-state dictionaries with two-tape finitestate automatons as a mechanism for correcting misspellings, and optimisations to the finite-state error models, intending to demonstrate that purely finitestate algorithms can be made sufficiently efficient.", "labels": [], "entities": []}, {"text": "To evaluate the general usability and efficiency of finite-state spell-checking we test a number of possible implementations of such a system with three languages of typologically different morphological features and reference implementations for contemporary spell-checking applications: English as a morphologically more isolating language with essentially a word-list approach to spell-checking; Finnish, whose computational complexity has been just beyond the edge of being too hard to implement nicely in eg. hunspell); and Greenlandic, a polysynthetic language which is implemented as a finite-state system using Xerox's original finite-state morphology formalism.", "labels": [], "entities": []}, {"text": "As a general purpose finite-state library we use HFST 3 , which also contains our spell- We will not go into details regarding the morphological features of these languages.", "labels": [], "entities": [{"text": "HFST 3", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.886993944644928}]}, {"text": "We thank the anonymous reviewer for guiding us to make a rough comparison using apiece of translated text.", "labels": [], "entities": []}, {"text": "We observe from the translations of the Universal Declaration of Human Rights (with pre-amble included) as follows: the number of word-like tokens for English is 1,746, for Finnish 1,275 and for Greenlandic 1,063.", "labels": [], "entities": []}, {"text": "The count of the 15 most frequent tokens are for English 120-28, for Finnish 85-10 and for Greenlandic 38-7.", "labels": [], "entities": []}, {"text": "The average word length is 5.0 characters for English, 7.8 for Finnish and 14.9 for Greenlandic.", "labels": [], "entities": []}, {"text": "For the complexity of computational models refer to in this article.", "labels": [], "entities": []}, {"text": "3 http://hfst.sf.net checking code.", "labels": [], "entities": []}, {"text": "As neither Finnish nor Greenlandic have been successfully implemented in the hunspell formalism, we mainly use them to evaluate how the complexity of a language model affects the efficiency of finite-state spell-checking.", "labels": [], "entities": []}, {"text": "For a full-scale survey on the state-of-the-art non-finite-state spell-checking, refer to.", "labels": [], "entities": []}, {"text": "The efficiency results are contrasted with the existing research on finite-state spell-checking in and the theoretical results on finitestate error-models in.", "labels": [], "entities": []}, {"text": "Our contribution primarily comprises the addition of morphologically complex languages with actual cyclic dictionary automata (i.e. infinite dictionaries formed by compounding and recurring derivation) and more complex structure in general, compared to those of English and Arabic.", "labels": [], "entities": []}, {"text": "Our goal is to demonstrate that finite-state spelling is tractable for these complex languages, to document their implications for performance and to present an algorithm for the task.", "labels": [], "entities": [{"text": "finite-state spelling", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.6739923059940338}]}, {"text": "We also point out that previous approaches have neglected to simultaneously constrain the error model and the dictionary with each other in on-line composition, which affords a significant speed benefit compared to generating the two component compositions.", "labels": [], "entities": []}, {"text": "The rest of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we discuss the spell-checking task, current non-finite-state spell-checkers and previously used finite-state methods for spell-checking and correction and propose some possible speed optimisations for the error models.", "labels": [], "entities": [{"text": "spell-checking and correction", "start_pos": 134, "end_pos": 163, "type": "TASK", "confidence": 0.7097940246264139}]}, {"text": "We also investigate algorithmic limitations of finite-state approaches and ways to remedy them.", "labels": [], "entities": []}, {"text": "In Section 3 we present the language models, error models and the testing corpora.", "labels": [], "entities": []}, {"text": "In Section 4 we present the comparisons of speed and quality with combinations of different language and error models and corpora for spell-checking.", "labels": [], "entities": [{"text": "speed", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.9894639253616333}]}, {"text": "In Section 5 we summarise our findings and results, and outline future goals.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran various combinations of language and error models on the corpora described in section 3.", "labels": [], "entities": []}, {"text": "We give tabular results of the speed of the system and the effect of the error model on recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9974350333213806}]}, {"text": "The latter  is to establish that simpler error models lead to degraded recall-and not to more generally evaluate the present system as a spell-checker.", "labels": [], "entities": [{"text": "recall-and", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.998252809047699}]}, {"text": "The evaluations in this section are performed on quad-core Intel Xeon E5450 running at 3 GHz with 64 GiB of RAM memory.", "labels": [], "entities": []}, {"text": "The times are averaged over five test runs of 10,000 words in a stable server environment with no server processes or running graphical interfaces or other uses.", "labels": [], "entities": []}, {"text": "The test results are measured using the getrusage C function on a system that supports the maximum resident stack size ru maxrss and user time ru utime fields.", "labels": [], "entities": []}, {"text": "The times are also verified with the GNU time command.", "labels": [], "entities": [{"text": "GNU time command", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.8019424875577291}]}, {"text": "The results for hunspell, Voikkospell and foma processes are only measured with time and top.", "labels": [], "entities": []}, {"text": "The respective versions of the software are Voikkospell 3.3, hunspell 1.2.14, and Foma 0.9.16alpha.", "labels": [], "entities": [{"text": "Voikkospell", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.8800985217094421}, {"text": "Foma 0.9.16alpha", "start_pos": 82, "end_pos": 98, "type": "DATASET", "confidence": 0.8684132695198059}]}, {"text": "The reference systems are tested with default settings, meaning that they will only give some fixed number of suggestions whereas our system will calculate all strings within the given error model.", "labels": [], "entities": []}, {"text": "As a reference implementation for English we use hunspell's en-US dictionary and fora finite-state implementation we use a weighted word-list from.", "labels": [], "entities": []}, {"text": "As a Finnish reference implementation we use Voikko , with a LAG-based dictionary using Malaga 11 . The reference correction task for Greenlandic is done with foma's apply med function with default settings . The baseline feature set and the efficiency of spell-checking we are targeting is defined by the currently de facto standard spelling suite in open source systems, hunspell.", "labels": [], "entities": [{"text": "reference correction", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.8139675855636597}]}, {"text": "In we measure the speed of the spellchecking process on native language Wikipedia text with real-world spelling errors and unknown strings.", "labels": [], "entities": []}, {"text": "The error model rows are defined as follows: on the Reference impl.", "labels": [], "entities": []}, {"text": "row, we test the spellchecking speed of the hunspell tool for English, and Voikkospell tool for Finnish.", "labels": [], "entities": []}, {"text": "On the edit distance 2 row we use the basic traditional edit distance 2 without any modifications.", "labels": [], "entities": []}, {"text": "On the No first edits row we use the error model that does not modify the first character of the word.", "labels": [], "entities": []}, {"text": "On the No redundancy row we use the edit distance 2 error model with the redundant edit combinations removed.", "labels": [], "entities": [{"text": "edit distance 2 error", "start_pos": 36, "end_pos": 57, "type": "METRIC", "confidence": 0.8352645933628082}]}, {"text": "On the No redundancy and firsts rows we use the combined error model of No first edits and No redundancy functionalities.", "labels": [], "entities": []}, {"text": "On the row Lower order first we apply a lower order edit distance model first, then if no results are found, a higher order model is used.", "labels": [], "entities": []}, {"text": "In the tables and formulae we routinely use the language codes to denote the languages: en for English, fi for Finnish and kl for Greenlandic (Kalaallisut).", "labels": [], "entities": []}, {"text": "The results show that not editing the first position does indeed give significant boost to the speed, regardless of language model, which is of course caused by the significant reduction in search space.", "labels": [], "entities": [{"text": "speed", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9970821738243103}]}, {"text": "However, the redundancy avoidance does not seem to make a significant difference.", "labels": [], "entities": [{"text": "redundancy avoidance", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.9162388741970062}]}, {"text": "This is most likely because the amount of duplicate paths in the search space is not so proportionally large and their traversal will be relatively fast.", "labels": [], "entities": []}, {"text": "The separate application http://code.google.com/p/Foma/ of error models gives the expected timing result between its relevant primary and secondary error models.", "labels": [], "entities": [{"text": "Foma", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9864697456359863}, {"text": "timing", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9193626046180725}]}, {"text": "It should be noteworthy that, when thinking of real world applications, the speed of the most of the models described here is greater than 1 word per second (i.e. 10,000 seconds per 10,000 words).", "labels": [], "entities": []}, {"text": "We measured memory consumption when performing the same tests.", "labels": [], "entities": []}, {"text": "Varying the error model had little to no effect.", "labels": [], "entities": []}, {"text": "Memory consumption was almost entirely determined by the language model, giving consumptions of 13-7 MiB for English, 0.2 GiB for Finnish and 1.6 GiB for Greenlandic.", "labels": [], "entities": [{"text": "Memory", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.867389976978302}]}, {"text": "To measure the degradation of quality when using different error models we count the proportion of suggestion sets that contain the correct correction among the corrected strings.", "labels": [], "entities": []}, {"text": "The suggestion sets are the entire (unrestricted by number) results of correction, with no attempt to evaluate precision   This test with automatically introduced errors shows us that with uniformly distributed errors the penalty of using an error model that ignores wordinitial corrections could be significant.", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9978328347206116}]}, {"text": "This contrasts to our findings with real world errors, that the distribution of errors tends towards the end of the word, described in 2.2 and, but it should be noted that degradation can be as bad as given here.", "labels": [], "entities": []}, {"text": "Finally we measure how the text type used will affect the speed of spell-checking.", "labels": [], "entities": [{"text": "speed", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9690126776695251}]}, {"text": "As the best-case scenario we use the unmodified texts of Wikipedia, which contain probably the most realistic native-language-speaker-like typing error dis-tribution available.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.7949797511100769}]}, {"text": "For text with more errors, where the majority of errors should be recoverable, we introduce automatically generated errors in the Wikipedia texts.", "labels": [], "entities": [{"text": "Wikipedia texts", "start_pos": 130, "end_pos": 145, "type": "DATASET", "confidence": 0.8944165706634521}]}, {"text": "Finally to seethe performance in the worst case scenario where most of the words have unrecoverable spelling errors we use texts from other languages, in this case English texts for Finnish and Greenlandic spell-checking and Finnish texts for English spell-checking, which should bring us close to the lower bounds on performance.", "labels": [], "entities": []}, {"text": "The effects of text type (i.e. frequency of non-words) on speed of spell-checking is given in.", "labels": [], "entities": []}, {"text": "All of the tests in this category were performed with error models under the avoid redundancy and firsts ed 2 row in previous tables, which gave us the best speed/quality ratio.", "labels": [], "entities": [{"text": "avoid", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9981270432472229}, {"text": "firsts ed 2 row", "start_pos": 98, "end_pos": 113, "type": "METRIC", "confidence": 0.8402446508407593}, {"text": "speed/quality ratio", "start_pos": 157, "end_pos": 176, "type": "METRIC", "confidence": 0.9150818884372711}]}, {"text": "Here we chiefly note that the amount of nonwords in text directly reflects the speed of spellchecking.", "labels": [], "entities": []}, {"text": "This shows that the dominating factor of the speed of spell-checking is indeed in the correcting of misspelled words.", "labels": [], "entities": [{"text": "correcting of misspelled words", "start_pos": 86, "end_pos": 116, "type": "TASK", "confidence": 0.8261137753725052}]}], "tableCaptions": [{"text": " Table 1: State classification by minimum input consumed  for the Finnish dictionary", "labels": [], "entities": [{"text": "State classification", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7441229820251465}, {"text": "Finnish dictionary", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.8093856573104858}]}, {"text": " Table 2: The sizes of dictionaries as automata", "labels": [], "entities": []}, {"text": " Table 3: The sizes of error models as automata", "labels": [], "entities": []}, {"text": " Table 4: Effect of language and error models to speed  (time in seconds per 10,000 word forms)", "labels": [], "entities": []}, {"text": " Table 5: Effect of language and error models to quality  (recall, proportion of suggestion sets containing a cor- rectly suggested word)", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9991998076438904}]}, {"text": " Table 6. All of  the tests in this category were performed with er- ror models under the avoid redundancy and firsts  ed 2 row in previous tables, which gave us the best  speed/quality ratio.", "labels": [], "entities": [{"text": "avoid", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9973310232162476}, {"text": "speed/quality ratio", "start_pos": 172, "end_pos": 191, "type": "METRIC", "confidence": 0.9136553704738617}]}, {"text": " Table 6: Effect of text type on error models to speed (in  seconds per 10,000 word-forms)", "labels": [], "entities": []}]}