{"title": [{"text": "Handling Unknown Words in Arabic FST Morphology", "labels": [], "entities": [{"text": "Handling Unknown Words in Arabic FST Morphology", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.6070660437856402}]}], "abstractContent": [{"text": "A morphological analyser only recognizes words that it already knows in the lexical database.", "labels": [], "entities": []}, {"text": "It needs, however, away of sensing significant changes in the language in the form of newly borrowed or coined words with high frequency.", "labels": [], "entities": []}, {"text": "We develop a finite-state morphological guesser in a pipelined methodology for extracting unknown words, lemmatizing them, and giving them a priority weight for inclusion in a lexicon.", "labels": [], "entities": [{"text": "finite-state morphological guesser", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.6845468878746033}]}, {"text": "The processing is performed on a large contemporary corpus of 1,089,111,204 words and passed through a machine-learning-based annotation tool.", "labels": [], "entities": []}, {"text": "Our method is tested on a manually-annotated gold standard of 1,310 forms and yields good results despite the complexity of the task.", "labels": [], "entities": []}, {"text": "Our work shows the usability of a highly non-deterministic finite state guesser in a practical and complex application.", "labels": [], "entities": [{"text": "finite state guesser", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7083678245544434}]}], "introductionContent": [{"text": "Due to the complex and semi-algorithmic nature of the Arabic morphology, it has always been a challenge for computational processing and analysis.", "labels": [], "entities": [{"text": "computational processing and analysis", "start_pos": 108, "end_pos": 145, "type": "TASK", "confidence": 0.6714012026786804}]}, {"text": "A lexicon is an indispensable part of a morphological analyser (, and the coverage of the lexical database is a key factor in the coverage of the morphological analyser.", "labels": [], "entities": []}, {"text": "This is why an automatic method for updating a lexical database is crucially important.", "labels": [], "entities": []}, {"text": "We present the first attempt, to the best of our knowledge, to address lemmatization of Arabic unknown words.", "labels": [], "entities": []}, {"text": "The specific problem with lemmatizing unknown words is that they cannot be matched against a morphological lexicon.", "labels": [], "entities": []}, {"text": "We develop a rule-based finite-state morphological guesser and use a machine learning disambiguator, MADA, in a pipelined approach to lemmatization.", "labels": [], "entities": [{"text": "finite-state morphological guesser", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.6619922717412313}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "The remainder of the introduction reviews previous work on Arabic unknown word extraction and lemmatization, and explains the data used in our experiments.", "labels": [], "entities": [{"text": "Arabic unknown word extraction", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.5350153148174286}]}, {"text": "Section 2 presents the methodology followed in extracting and analysing unknown words.", "labels": [], "entities": [{"text": "extracting and analysing unknown words", "start_pos": 47, "end_pos": 85, "type": "TASK", "confidence": 0.7407488942146301}]}, {"text": "Section 3 provides details on the morphological guesser we have developed to help deal with the problem.", "labels": [], "entities": []}, {"text": "Section 4 shows and discusses the testing and evaluation results, and finally Section 5 gives the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our methodology we create a manually annotated gold standard test suite of randomly selected surface form types.", "labels": [], "entities": []}, {"text": "For these surface forms, the gold lemma and part of speech are manually given.", "labels": [], "entities": []}, {"text": "Besides, the human annotator gives a preference on whether or not to include the entry in a dictionary.", "labels": [], "entities": []}, {"text": "This feature helps to evaluate our lemma weighting equation.", "labels": [], "entities": []}, {"text": "The annotator tends to include nouns, verbs and adjectives, and only proper nouns that have a high frequency.", "labels": [], "entities": []}, {"text": "The size of the test suite is 1,310.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Evaluation of POS tagging", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.8160154521465302}]}, {"text": " Table 3. Evaluation of lemma weighting and ranking", "labels": [], "entities": [{"text": "ranking", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.43298235535621643}]}]}