{"title": [{"text": "Combining EBMT, SMT, TM and IR Technologies for Quality and Scale", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9681853652000427}]}], "abstractContent": [{"text": "In this paper we present a hybrid statistical machine translation (SMT)-example-based MT (EBMT) system that shows significant improvement over both SMT and EBMT base-line systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)-example-based MT", "start_pos": 34, "end_pos": 88, "type": "TASK", "confidence": 0.8083839826285839}, {"text": "SMT", "start_pos": 148, "end_pos": 151, "type": "TASK", "confidence": 0.9594541192054749}]}, {"text": "First we present a runtime EBMT system using a subsentential translation memory (TM).", "labels": [], "entities": []}, {"text": "The EBMT system is further combined with an SMT system for effective hybridization of the pair of systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9662190079689026}]}, {"text": "The hybrid system shows significant improvement in translation quality (0.82 and 2.75 absolute BLEU points) for two different language pairs (English-Turkish (En-Tr) and English-French (En-Fr)) over the baseline SMT system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9796294569969177}, {"text": "SMT", "start_pos": 212, "end_pos": 215, "type": "TASK", "confidence": 0.9824184775352478}]}, {"text": "However, the EBMT approach suffers from significant time complexity issues fora runtime approach.", "labels": [], "entities": []}, {"text": "We explore two methods to make the system scalable at runtime.", "labels": [], "entities": []}, {"text": "First, we use an heuristic-based approach.", "labels": [], "entities": []}, {"text": "Secondly, we use an IR-based indexing technique to speedup the time-consuming matching procedure of the EBMT system.", "labels": [], "entities": []}, {"text": "The index-based matching procedure substantially improves run-time speed without affecting translation quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "State-of-the-art phrase-based SMT) is the most successful MT approach in many large scale evaluations, such as WMT, and.", "labels": [], "entities": [{"text": "SMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.6580584645271301}, {"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9924363493919373}, {"text": "WMT", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.7311018705368042}]}, {"text": "The success of an SMT system often depends on the amount of parallel training corpora available for the particular language pair.", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9951382875442505}]}, {"text": "However, low translation accuracy has been observed for language pairs with limited training resources (.", "labels": [], "entities": [{"text": "translation", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9358099699020386}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8934885859489441}]}, {"text": "SMT systems effectively discard the actual training data once the models (translation model and language model) have been estimated.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9836434721946716}]}, {"text": "This can lead to their inability to guarantee good quality translation for sentences closely matching those in the training corpora.", "labels": [], "entities": []}, {"text": "By contrast, EBMT systems usually maintain a linked relationship between the full sentence pairs in source and target texts.", "labels": [], "entities": []}, {"text": "Because of this EBMT systems can often capture long range dependencies and rich morphology at runtime.", "labels": [], "entities": []}, {"text": "In contrast to SMT, however, most EBMT models lack a wellformed probability model, which restricts the use of statistical information in the translation process.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.989429771900177}]}, {"text": "Keeping these in mind, our objective is to develop a good quality MT system choosing the best approach for each input in the form of a hybrid SMT-EBMT approach.", "labels": [], "entities": [{"text": "MT", "start_pos": 66, "end_pos": 68, "type": "TASK", "confidence": 0.9931121468544006}, {"text": "SMT-EBMT", "start_pos": 142, "end_pos": 150, "type": "TASK", "confidence": 0.9894982576370239}]}, {"text": "It is often the case that an EBMT system produces a good translation where SMT systems fail and vice versa).", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9415501952171326}]}, {"text": "An EBMT system relies on past translations to derive the target output fora given input.", "labels": [], "entities": []}, {"text": "Runtime EBMT approaches generally do not include any training stage, which has the advantage of not having to depend on time-consuming preprocessing.", "labels": [], "entities": []}, {"text": "On the other hand, their runtime complexity can be considerable.", "labels": [], "entities": []}, {"text": "This is due to the time-consuming matching stage at runtime that finds the example (or set of examples) which most closely matches the source-language sentence to be translated.", "labels": [], "entities": []}, {"text": "This matching step often uses some variation of string edit-distance measures which has quadratic time complexity.", "labels": [], "entities": []}, {"text": "3 This is quite timeconsuming even when a moderate amount of training examples are used for the matching procedure.", "labels": [], "entities": []}, {"text": "We adopt two alternative approaches to tackle the above problem.", "labels": [], "entities": []}, {"text": "First we use heuristics which are often useful to avoid some of the computations.", "labels": [], "entities": []}, {"text": "For a input sentence, in the matching process, we may not need to compute the string edit distance with all sentences in the example base.", "labels": [], "entities": []}, {"text": "In order to prune some of the computation, we rely on the fact that the input sentence and its closest match sentence from the example-base are likely to have a similar sentence length.", "labels": [], "entities": []}, {"text": "Search engine indexing is an effective way of storing data for fast and accurate retrieval of information.", "labels": [], "entities": [{"text": "Search engine indexing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5499734083811442}]}, {"text": "During retrieval, a set of documents are extracted based on their similarity to the input query.", "labels": [], "entities": []}, {"text": "In our second approach, we use this concept to efficiently retrieve a potential set of suitable candidate sentences from the example-base to find the closest match.", "labels": [], "entities": []}, {"text": "We index the entire example-base considering each source-side sentence as a document for the indexer.", "labels": [], "entities": []}, {"text": "We show that improvements can be made with our approach in terms of time complexity without affecting the translation quality.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents work related to our EBMT approach.", "labels": [], "entities": []}, {"text": "Section 3 describes the MT systems used in our experiments.", "labels": [], "entities": [{"text": "MT", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9756786823272705}]}, {"text": "Section 4 focuses on the two techniques used to make the system scalable.", "labels": [], "entities": []}, {"text": "Section 5 presents the experiments in detail.", "labels": [], "entities": []}, {"text": "Section 6 presents and discusses the results and provides an error analysis.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 61, "end_pos": 75, "type": "METRIC", "confidence": 0.9154353737831116}]}, {"text": "We conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct different experiments to report the accuracy of our EBMT systems for En-Tr and En-Fr translation tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9992443323135376}, {"text": "En-Fr translation tasks", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.6705624858538309}]}, {"text": "In order to compare the performance of our approaches we use two baseline systems.", "labels": [], "entities": []}, {"text": "We use the Moses SMT system as one base-line.", "labels": [], "entities": [{"text": "Moses SMT system", "start_pos": 11, "end_pos": 27, "type": "DATASET", "confidence": 0.7950394650300344}]}, {"text": "Furthermore, based on the matching step (Section 3.2) of the EBMT approach, we obtain the closest target-side equivalent (the skeleton sentence) and consider this as the baseline output for the input to be translated.", "labels": [], "entities": []}, {"text": "This is referred to as TM in the experiment below.", "labels": [], "entities": []}, {"text": "We will consider this as the baseline accuracy for our EBMT using TM approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9989160299301147}]}, {"text": "In addition, we conduct two experiments with our EBMT system.", "labels": [], "entities": []}, {"text": "After obtaining the skeleton translation through the matching and alignment steps, in the recombination step, we use TM to translate any unmatched segments based on Algorithm 1.", "labels": [], "entities": []}, {"text": "We call this EBMT TM . We found that there are cases where the EBMT TM system produces the correct translation but SMT fails and vice-versa.", "labels": [], "entities": [{"text": "SMT", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9502355456352234}]}, {"text": "In order to further improve translation quality, we use a combination of EBMT and SMT.", "labels": [], "entities": [{"text": "translation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9713940024375916}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9566404819488525}]}, {"text": "Here we use some features to decide whether to rely on the output produced by the EBMT TM system.", "labels": [], "entities": [{"text": "EBMT TM", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.8593669533729553}]}, {"text": "These features include fuzzy match scoreFMS (as in (i)) and the number of mismatched segments in each of s, s c , t c (EqUS 6 as in).", "labels": [], "entities": [{"text": "fuzzy match scoreFMS", "start_pos": 23, "end_pos": 43, "type": "METRIC", "confidence": 0.5506785809993744}]}, {"text": "We assume that the translations of an input sentence s produced by EBMT TM and SMT systems are respectively T EBMT (s) and T SMT (s).", "labels": [], "entities": [{"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9427157640457153}]}, {"text": "If the value of FMS is greater than some threshold and EqUS exists between sand s c , we rely on the output T EBMT (s); otherwise we take the output from T SMT (s).", "labels": [], "entities": [{"text": "FMS", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.5625664591789246}, {"text": "EqUS", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9964575171470642}, {"text": "EBMT", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.8517614006996155}]}, {"text": "We refer to this system as EBMT TM + SMT.", "labels": [], "entities": [{"text": "EBMT TM + SMT", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7174386084079742}]}, {"text": "To test the scalability of the system, we conducted two more experiments based on the approach described in Section 4.", "labels": [], "entities": []}, {"text": "First, we conducted an experiment based on the sentence lengthbased grouping heuristics (Section 4.1).", "labels": [], "entities": [{"text": "sentence lengthbased grouping heuristics", "start_pos": 47, "end_pos": 87, "type": "TASK", "confidence": 0.6832087486982346}]}, {"text": "We refer to this system as EBMT TM + SMT + group i , where i indicates the window size while comparing the length of the input sentence with the bins.", "labels": [], "entities": [{"text": "EBMT TM + SMT + group i", "start_pos": 27, "end_pos": 50, "type": "DATASET", "confidence": 0.6382764237267631}]}, {"text": "We conduct a second experiment based on the LMbased indexing technique (Section 4.2) we have used to retrieve a potential set of candidate sentences from the indexed example-base.", "labels": [], "entities": []}, {"text": "We call this system EBMT TM + SMT + index.", "labels": [], "entities": [{"text": "EBMT TM + SMT + index", "start_pos": 20, "end_pos": 41, "type": "DATASET", "confidence": 0.7519607742627462}]}, {"text": "Note that the EBMT TM + SMT system is used as the baseline accuracy while conducting the experiments for scal- If s, sc and tc agree in the number of mismatched segments, EqUS evaluates to 1, otherwise 0.", "labels": [], "entities": [{"text": "EBMT TM + SMT", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.6653798967599869}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9975711703300476}, {"text": "EqUS", "start_pos": 171, "end_pos": 175, "type": "METRIC", "confidence": 0.9005700945854187}]}, {"text": "ability of the EBMT system.", "labels": [], "entities": [{"text": "EBMT", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.8129937648773193}]}, {"text": "We used two data sets for all our experiments representing two language pairs of different size and type.", "labels": [], "entities": []}, {"text": "In the first data-set, we have used the En-Tr corpus from IWSLT09.", "labels": [], "entities": [{"text": "En-Tr corpus from IWSLT09", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.8218566328287125}]}, {"text": "The training data consists of 19,972 parallel sentences.", "labels": [], "entities": []}, {"text": "We used the IWSLT09 development set as our testset which consists of 414 sentences.", "labels": [], "entities": [{"text": "IWSLT09 development set", "start_pos": 12, "end_pos": 35, "type": "DATASET", "confidence": 0.9623305400212606}]}, {"text": "The IWSLT09 data set is comprised of short sentences (with an average of 9.5 words per sentence) from a particular domain (the C-STAR project's Basic Travel Expression Corpus).", "labels": [], "entities": [{"text": "IWSLT09 data set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9600428740183512}, {"text": "C-STAR project's Basic Travel Expression Corpus)", "start_pos": 127, "end_pos": 175, "type": "DATASET", "confidence": 0.828631266951561}]}, {"text": "Our second data set consists of an En-Fr corpus from the European Medicines Agency (EMEA) 8 ().", "labels": [], "entities": [{"text": "En-Fr corpus from the European Medicines Agency (EMEA) 8", "start_pos": 35, "end_pos": 91, "type": "DATASET", "confidence": 0.9276718551462347}]}, {"text": "The training data consists of 250,806 unique parallel sentences.", "labels": [], "entities": []}, {"text": "As a testset we use a set of 10,000 randomly drawn sentences disjoint from the training corpus.", "labels": [], "entities": []}, {"text": "This data also represents a particular domain (medicine) but with longer sentence lengths (with an average of 18.8 words per sentence) compared to the IWSLT09 data.", "labels": [], "entities": [{"text": "IWSLT09 data", "start_pos": 151, "end_pos": 163, "type": "DATASET", "confidence": 0.963403582572937}]}], "tableCaptions": [{"text": " Table 1: Moses phrase equivalence probabilities.", "labels": [], "entities": []}, {"text": " Table 2: Baseline BLEU scores of the two systems  and the scores for EBMT TM system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9443767666816711}, {"text": "EBMT TM", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.749271035194397}]}, {"text": " Table 3: En-Tr MT system accuracies of the com- bined systems (EBMT TM + SMT) with different  combining factors. The second column indicates the  number (and percentage) of sentences translated by  the EBMT TM system during combination.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.8376439809799194}, {"text": "EBMT TM + SMT", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.7062584310770035}]}, {"text": " Table 4: En-Fr MT system accuracies for the com- bined systems (EBMT TM + SMT) with different  combining factors.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.8212803602218628}]}, {"text": " Table 5: Running time of the three different systems.", "labels": [], "entities": [{"text": "Running time", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8870355784893036}]}, {"text": " Table 6: BLEU scores of the three different systems for En-Tr and En-Fr under different conditions. i  denotes the number of bins considered during grouping.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990209341049194}]}]}