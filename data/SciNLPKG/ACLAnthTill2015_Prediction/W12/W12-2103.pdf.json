{"title": [{"text": "Detecting Hate Speech on the World Wide Web", "labels": [], "entities": [{"text": "Detecting Hate Speech", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9212356011072794}]}], "abstractContent": [{"text": "We present an approach to detecting hate speech in online text, where hate speech is defined as abusive speech targeting specific group characteristics, such as ethnic origin, religion , gender, or sexual orientation.", "labels": [], "entities": []}, {"text": "While hate speech against any group may exhibit some common characteristics, we have observed that hatred against each different group is typically characterized by the use of a small set of high frequency stereotypical words; however, such words maybe used in either a positive or a negative sense, making our task similar to that of words sense disambigua-tion.", "labels": [], "entities": []}, {"text": "In this paper we describe our definition of hate speech, the collection and annotation of our hate speech corpus, and a mechanism for detecting some commonly used methods of evading common \"dirty word\" filters.", "labels": [], "entities": []}, {"text": "We describe pilot classification experiments in which we classify anti-semitic speech reaching an accuracy 94%, precision of 68% and recall at 60%, for an F1 measure of .6375.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9989870190620422}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9996277093887329}, {"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.999645471572876}, {"text": "F1 measure", "start_pos": 155, "end_pos": 165, "type": "METRIC", "confidence": 0.9822390377521515}]}], "introductionContent": [{"text": "Hate speech is a particular form of offensive language that makes use of stereotypes to express an ideology of hate.", "labels": [], "entities": []}, {"text": "Nockleby) defines hate speech as \"any communication that disparages a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic.\"", "labels": [], "entities": [{"text": "hate speech as \"any communication that disparages a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other", "start_pos": 18, "end_pos": 215, "type": "Description", "confidence": 0.8317917255978835}]}, {"text": "In the United States, most hate speech is protected by the First Amendment of the U.", "labels": [], "entities": []}, {"text": "S. Constitution, which, except for obscenity, \"fighting words\" and incitement, guarantees the right to free speech, and internet commentators exercise this right in online forums such as blogs, newsgroups, Twitter and Facebook.", "labels": [], "entities": []}, {"text": "However, terms of service for such hosted services typically prohibit hate speech.", "labels": [], "entities": []}, {"text": "Terms Of Service 1 prohibits posting \"Content that is unlawful, harmful, threatening, abusive, harassing, tortuous, defamatory, vulgar, obscene, libelous, invasive of another's privacy, hateful, or racially, ethnically or otherwise objectionable.\"", "labels": [], "entities": [{"text": "Terms Of Service 1 prohibits posting \"Content that is unlawful, harmful, threatening, abusive, harassing, tortuous, defamatory, vulgar, obscene, libelous, invasive of another's privacy, hateful, or racially, ethnically or otherwise objectionable", "start_pos": 0, "end_pos": 245, "type": "Description", "confidence": 0.8313059250513712}]}, {"text": "Facebook's terms 2 are similar, forbidding \"content that: is hateful, threatening, or pornographic; incites violence.\"", "labels": [], "entities": [{"text": "Facebook's terms", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9053751428922018}]}, {"text": "While user submissions are typically filtered fora fixed list of offensive words, no publicly available automatic classifier currently exists to identify hate speech itself.", "labels": [], "entities": []}, {"text": "In this paper we describe the small amount of existing literature relevant to our topic in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3 we motivate our working definition of hate speech.", "labels": [], "entities": []}, {"text": "In Section 4 we describe the resources and corpora of hate and non-hate speech we have used in our experiments.", "labels": [], "entities": []}, {"text": "In Section 5 we describe the annotation scheme we have developed and interlabeler reliability of the labeling process.", "labels": [], "entities": [{"text": "interlabeler", "start_pos": 69, "end_pos": 81, "type": "METRIC", "confidence": 0.9561066031455994}, {"text": "reliability", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.7479472160339355}]}, {"text": "In Section 6 we describe our approach to the classification problem and the features we used.", "labels": [], "entities": [{"text": "classification problem", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.9319561421871185}]}, {"text": "We present preliminary results in Section 7, follow with an analysis of classification errors in 8 and conclude in Section 9 with an outline of further work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}