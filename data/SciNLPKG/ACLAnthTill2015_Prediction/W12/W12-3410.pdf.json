{"title": [{"text": "Using an SVM Ensemble System for Improved Tamil Dependency Parsing", "labels": [], "entities": [{"text": "Tamil Dependency Parsing", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.5817338327566782}]}], "abstractContent": [{"text": "Dependency parsing has been shown to improve NLP systems in certain languages and in many cases helps achieve state of the art results in NLP applications, in particular applications for free word order languages.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.842169463634491}]}, {"text": "Morphologically rich languages are often short on training data or require much higher amounts of training data due to the increased size of their lexicon.", "labels": [], "entities": []}, {"text": "This paper examines anew approach for addressing morphologically rich languages with little training data to start.", "labels": [], "entities": []}, {"text": "Using Tamil as our test language, we create 9 dependency parse models with a limited amount of training data.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.6936142891645432}]}, {"text": "Using these models we train an SVM classifier using only the model agreements as features.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7594328820705414}]}, {"text": "We use this SVM classifier on an edge by edge decision to form an ensemble parse tree.", "labels": [], "entities": []}, {"text": "Using only model agreements as features allows this method to remain language independent and applicable to a wide range of morphologically rich languages.", "labels": [], "entities": []}, {"text": "We show a statistically significant 5.44% improvement over the average dependency model and a statistically significant 0.52% improvement over the best individual system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsing has made many advancements in recent years.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9315218925476074}]}, {"text": "A prime reason for the quick advancement has been the CoNLL shared task competitions, which gave the community a common training/testing framework along with many open source systems.", "labels": [], "entities": []}, {"text": "These systems have, for certain languages, achieved high accuracy ranging from on average from approximately 60% to 80%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9994014501571655}]}, {"text": "The range of scores are more often language dependent rather than system dependent, as some languages contain more morphological complexities.", "labels": [], "entities": []}, {"text": "While some of these languages are morphologically rich, we would like to additionally address dependency parsing methods that may help under-resourced languages as well, which often overlaps with morphologically rich languages.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7297256886959076}]}, {"text": "For this reason, we have chosen to do the experiments in this paper using the Tamil Treebank (Ramasamy and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y, 2012).", "labels": [], "entities": [{"text": "Tamil Treebank (Ramasamy and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y, 2012)", "start_pos": 78, "end_pos": 155, "type": "DATASET", "confidence": 0.9445899799466133}]}, {"text": "Tamil belongs to Dravidian family of languages and is mainly spoken in southern India and also in parts of Sri Lanka, Malaysia and Singapore.", "labels": [], "entities": []}, {"text": "Tamil is agglutinative and has a rich set of morphological suffixes.", "labels": [], "entities": []}, {"text": "Tamil has nouns and verbs as two major word classes, and hundreds of word forms can be produced by the application of concatenative and derivational morphology.", "labels": [], "entities": []}, {"text": "Tamil's rich morphology makes the language free word order except that it is strictly head final.", "labels": [], "entities": []}, {"text": "When working with small datasets it is often very difficult to determine which dependency model will best represent your data.", "labels": [], "entities": []}, {"text": "One can try to pick the model through empirical means on a tuning set but as the data grows in the future this model may no longer be the best choice.", "labels": [], "entities": []}, {"text": "The change in the best model maybe due to new vocabulary or through a domain shift.", "labels": [], "entities": []}, {"text": "If the wrong single model is chosen early on when training is cheap, when the model is applied in semi supervised or self training it could lead to significantly reduced annotation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.7513406872749329}]}, {"text": "72 For this reason, we believe ensemble combinations are an appropriate direction for lesser resourced languages, often a large portion of morphologically rich languages.", "labels": [], "entities": []}, {"text": "Ensemble methods are robust as data sizes grow, since the classifier can easily be retrained with additional data and the ensemble model chooses the best model on an edge by edge basis.", "labels": [], "entities": []}, {"text": "This cost is substantially less than retraining multiple dependency models.", "labels": [], "entities": []}], "datasetContent": [{"text": "Made a standard in the CoNLL shared tasks competition, two standard metrics for comparing dependency parsing systems are typically used.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.6906655877828598}]}, {"text": "Labeled attachment score (LAS) and unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "Labeled attachment score (LAS)", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.7930293530225754}, {"text": "unlabeled attachment score (UAS)", "start_pos": 35, "end_pos": 67, "type": "METRIC", "confidence": 0.8411781986554464}]}, {"text": "UAS studies the structure of a dependency tree and assesses whether the output has the correct head and dependency arcs.", "labels": [], "entities": [{"text": "UAS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5871638059616089}]}, {"text": "In addition to the structure score in UAS, LAS also measures the accuracy of the dependency labels on each arc).", "labels": [], "entities": [{"text": "UAS", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.7669602036476135}, {"text": "LAS", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9427208304405212}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9993288516998291}]}, {"text": "Since we are mainly concerned with the structure of the ensemble parse, we report only UAS scores in this paper.", "labels": [], "entities": [{"text": "UAS", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9120240807533264}]}, {"text": "To test statistical significance we use Wilcoxon paired signed-rank test.", "labels": [], "entities": []}, {"text": "For each data split we have 100 iterations each with different sampling.", "labels": [], "entities": []}, {"text": "Each model is compared against the same samples so a paired testis appropriate in this case.", "labels": [], "entities": []}, {"text": "We report statistical significance values for p < 0.01 and p < 0.05.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.7176443040370941}]}, {"text": "For each of the data splits, shows the percent increase in our SVM system over both the average of the 9 individual models and over the best individual model.", "labels": [], "entities": []}, {"text": "As the shows, our approach seems to decrease in value along with the decrease in tuning data.", "labels": [], "entities": []}, {"text": "In both cases when we only used 5% tuning data we did not get any improvement in our average UAS scores.", "labels": [], "entities": [{"text": "UAS", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.5563467144966125}]}, {"text": "Examining, shows that the decrease in the 90-5-5 split is not statistically significant however the decrease in 85-5-10 is a statistically significant drop.", "labels": [], "entities": []}, {"text": "However, the increases in all data splits are statistically significant except for the 60-20-20 data split.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: TamilTB: data statistics", "labels": [], "entities": [{"text": "TamilTB", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.8852019906044006}]}, {"text": " Table 3: Average increases and decreases in UAS score  for different Training-Tuning-Test samples. The average  was calculated over all 9 models while the best was se- lected for each data split", "labels": [], "entities": [{"text": "UAS score", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.7012948989868164}]}, {"text": " Table 5. Since the TamilTB is relatively small  when compared to other CoNLL treebanks, we ex- pect that this ratio may shift more when additional  data is supplied since the amount of out of vocab- ulary, OOV, words will decrease as well. As OOV  words decrease, we expect the use of additional test  data to have less of an effect.", "labels": [], "entities": [{"text": "TamilTB", "start_pos": 20, "end_pos": 27, "type": "DATASET", "confidence": 0.8480865359306335}, {"text": "CoNLL treebanks", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.9471830725669861}]}, {"text": " Table 5: Variance of the UAS Scores of our Ensemble  SVM System over 100 data splits", "labels": [], "entities": [{"text": "UAS Scores", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.8388928771018982}]}]}