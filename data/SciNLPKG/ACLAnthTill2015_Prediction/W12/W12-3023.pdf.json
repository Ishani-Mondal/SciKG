{"title": [{"text": "Using Textual Patterns to Learn Expected Event Frequencies", "labels": [], "entities": []}], "abstractContent": [{"text": "Commonsense reasoning requires knowledge about the frequency with which ordinary events and activities occur: How often do people eat a sandwich, go to sleep, write a book, or get married?", "labels": [], "entities": []}, {"text": "This paper introduces work to acquire a knowledge base pairing factoids about such events with frequency categories learned from simple textual patterns.", "labels": [], "entities": []}, {"text": "We are releasing a collection of the resulting event frequencies , which are evaluated for accuracy, and we demonstrate an initial application of the results to the problem of knowledge refinement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9991853833198547}, {"text": "knowledge refinement", "start_pos": 176, "end_pos": 196, "type": "TASK", "confidence": 0.7540158927440643}]}], "introductionContent": [{"text": "A general problem in artificial intelligence is knowledge acquisition: AI applications require both a background of general, commonsense knowledge about the world and the specific knowledge pertaining to the application's domain.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7346450984477997}]}, {"text": "This knowledge needs to be available in a form that facilitates reasoning, and it needs to be of high quality.", "labels": [], "entities": []}, {"text": "While early work tended to hand-code knowledge -and this continues to be the preferred method for projects like Cyc -this is labor-intensive and neglects the systematic connection that can be made between natural language and representations suitable for inference.", "labels": [], "entities": []}, {"text": "However, most efforts to acquire knowledge from text, such as KNEXT), TEXT-RUNNER (, or DART, are underspecified in a number of important respects, including word sense, quantificational structure, and the likelihood of their conclusions.", "labels": [], "entities": [{"text": "TEXT-RUNNER", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9430707693099976}, {"text": "DART", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.8593265414237976}]}, {"text": "In this paper, we address the lack of information about the expected temporal frequency of ordinary events.", "labels": [], "entities": []}, {"text": "Repeatable stage-level predications vary from those done with great frequency, such as a person saying something, to those done quite infrequently, such as a woman giving birth.", "labels": [], "entities": []}, {"text": "We will describe a simple method to learn rough frequencies of such events from text.", "labels": [], "entities": []}, {"text": "Our focus is on the commonsense knowledge needed for many AI applications, rather than more specific domain knowledge.", "labels": [], "entities": []}, {"text": "This work looks for the frequency of everyday events -such as going to work -that might be mentioned in ordinary text like newspaper articles, rather than big events -like earthquakes devastating a city, which tend to be rare and unpredictable -or small events -like atoms decaying, which would typically escape our notice.", "labels": [], "entities": []}, {"text": "We are unaware of any previous work aimed at systematically learning the expected or normal frequency of events in the world.", "labels": [], "entities": []}, {"text": "However, our basic approach to this problem aligns with a long-running line of work using textual references to learn specific kinds of world knowledge.", "labels": [], "entities": []}, {"text": "This approach has been popular at least since Hearst (1992) used lexicosyntactic patterns like 'NP 0 such as {NP 1 , NP 2 , . .", "labels": [], "entities": []}, {"text": ", (and|or)} NP n ' to learn hyponym relations, such as 'Bambara ndang is a bow lute' from large text corpora.", "labels": [], "entities": []}, {"text": "In addressing the problem of quantificational disambiguation, learn the expected sizes of sets of entities that participate in a relation; e.g., how many capitals a country has or how many cities a person tends to live in.", "labels": [], "entities": [{"text": "quantificational disambiguation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7858372032642365}]}, {"text": "They do this by using buckets of numeric phrases in handcrafted extraction patterns like '(I|he|she) word+ numeric noun', which would match 'she visited four countries'.", "labels": [], "entities": []}, {"text": "They apply these patterns to Google's Web1Tgram Corpus of n-grams.", "labels": [], "entities": [{"text": "Web1Tgram Corpus of n-grams", "start_pos": 38, "end_pos": 65, "type": "DATASET", "confidence": 0.9082212150096893}]}, {"text": "(2011) presented a similar approach to learning event durations using query patterns sent to a Web search engine, e.g., 'event past for * bucket', where the bucket is a category in [seconds, minutes, hours, . .", "labels": [], "entities": [{"text": "learning event durations", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.6100444793701172}]}, {"text": ", decades] for classifying the event's expected duration.", "labels": [], "entities": []}, {"text": "Both of these papers are notable for gaining wide coverage by indirectly using Web-scale text.", "labels": [], "entities": []}, {"text": "However, they are limited by the brevity of patterns in n-grams and by the coarse matching abilities of Web queries, respectively.", "labels": [], "entities": []}, {"text": "We will discuss these trade-offs and our approach, focusing on large offline corpora, in Section 2.", "labels": [], "entities": []}, {"text": "The contribution of this paper is the application of a traditional technique to anew problem.", "labels": [], "entities": []}, {"text": "Temporal frequencies are of key importance to improving the quality of automatically learned knowledge for commonsense reasoning.", "labels": [], "entities": [{"text": "commonsense reasoning", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.8506118357181549}]}, {"text": "Additionally, we hope that providing a knowledge base of expected frequencies for factoids about everyday events will serve as anew resource for other work in knowledge extraction and reasoning.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 159, "end_pos": 179, "type": "TASK", "confidence": 0.7413673102855682}]}], "datasetContent": [], "tableCaptions": []}