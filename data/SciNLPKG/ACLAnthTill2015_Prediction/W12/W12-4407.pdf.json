{"title": [{"text": "Syllable-based Machine Transliteration with Extra Phrase Features", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes our syllable-based phrase transliteration system for the NEWS 2012 shared task on English-Chinese track and its back.", "labels": [], "entities": [{"text": "syllable-based phrase transliteration", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6185255646705627}, {"text": "NEWS 2012 shared task on English-Chinese track", "start_pos": 78, "end_pos": 124, "type": "DATASET", "confidence": 0.7906497546604702}]}, {"text": "Grapheme-based Transliteration maps the character(s) in the source side to the target character(s) directly.", "labels": [], "entities": []}, {"text": "However, character-based segmentation on English side will cause ambiguity in alignment step.", "labels": [], "entities": [{"text": "character-based segmentation", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.6821383833885193}]}, {"text": "In this paper we utilize Phrase-based model to solve machine transliteration with the mapping between Chinese characters and English syllables rather than English characters.", "labels": [], "entities": []}, {"text": "Two heuristic rule-based syllable segmentation algorithms are applied.", "labels": [], "entities": [{"text": "heuristic rule-based syllable segmentation", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.66054867208004}]}, {"text": "This transliteration model also incorporates three phonetic features to enhance discriminative ability for phrase.", "labels": [], "entities": []}, {"text": "The primary system achieved 0.330 on Chinese-English and 0.177 on English-Chinese in terms of top-1 accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9842451214790344}]}], "introductionContent": [{"text": "Machine transliteration, based on the pronunciation, transforms the script of a word from a source language to a target language automatically.", "labels": [], "entities": [{"text": "Machine transliteration", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7175295352935791}]}, {"text": "With a continuous growth of out-of-vocabulary names to be transliterated, the traditional dictionary-based methods are no longer suitable.", "labels": [], "entities": []}, {"text": "So data-driven method is gradually prevailing now, and many new approaches are explored.", "labels": [], "entities": []}, {"text": "proposes a phoneme-based approach to solve the transliteration between English names and Japanese katakana.", "labels": [], "entities": []}, {"text": "It makes use of a common phonetic representation as a pivot.", "labels": [], "entities": []}, {"text": "The phoneme-based approach needs a pronunciation dictionary for one or two languages.", "labels": [], "entities": []}, {"text": "These dictionaries usually do not exist or can't coverall the names.", "labels": [], "entities": []}, {"text": "So grapheme-based() approach has gained lots of attention recently.", "labels": [], "entities": []}, {"text": "proposes a novel nonparametric Bayesian using synchronous adaptor grammars to model the grapheme-based transliteration.", "labels": [], "entities": []}, {"text": "builds the pivot transliteration model with grapheme-based method.", "labels": [], "entities": []}, {"text": "The hybrid approach tries to utilize both phoneme and grapheme information, and usually integrates the output of multiple engines to improve transliteration.", "labels": [], "entities": []}, {"text": "integrate both phoneme and grapheme features into a single leaning framework.", "labels": [], "entities": []}, {"text": "As an instance of grapheme-based approach, Jia(2009) views machine transliteration as a special example of machine translation and uses the phrase-based machine translation model to solve it.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7304539233446121}, {"text": "phrase-based machine translation", "start_pos": 140, "end_pos": 172, "type": "TASK", "confidence": 0.65977676709493}]}, {"text": "The approach is simple and effective.", "labels": [], "entities": []}, {"text": "Our paper follows this way.", "labels": [], "entities": []}, {"text": "However, using the English letters and Chinese characters as basic mapping units will make ambiguity in the alignment and translation step.", "labels": [], "entities": [{"text": "alignment", "start_pos": 108, "end_pos": 117, "type": "TASK", "confidence": 0.9564204812049866}, {"text": "translation", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.8726769685745239}]}, {"text": "One Chinese character usually maps one syllable, so syllabifying English words can be more discriminative.", "labels": [], "entities": []}, {"text": "We present a solution to this ambiguity by replacing the English character with an English syllable which is consecutive characters and can keep some phonetic properties.", "labels": [], "entities": []}, {"text": "For this purpose, two heuristic and simple syllable segmentation algorithms are used to syllabify English side into syllables sequence.", "labels": [], "entities": [{"text": "syllable segmentation", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.7509821057319641}]}, {"text": "Besides two above, three extra phrase features for transliteration are used to enhance the model.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the phrase-based model briefly.", "labels": [], "entities": []}, {"text": "Section 3 describes two rule-based syllable segmentation methods and three new special features for transliteration in detail.", "labels": [], "entities": [{"text": "syllable segmentation", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7188616245985031}]}, {"text": "Experiments and analyses are discussed in section 4.", "labels": [], "entities": []}, {"text": "Conclusions and future work are addressed in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the data sets, experimental setup, experimental results and analyses.", "labels": [], "entities": []}, {"text": "The Moses () is used to implement the model in this paper.", "labels": [], "entities": []}, {"text": "The Srilm() toolkit is used to count n-gram on the target of the training set.", "labels": [], "entities": [{"text": "Srilm", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8358421325683594}]}, {"text": "Here we use a 3-gram language model.", "labels": [], "entities": []}, {"text": "In the transliteration model training step, the Giza++( generates the alignment with the grow-diag-andfinal heuristic, while other setup is default.", "labels": [], "entities": []}, {"text": "In order to guarantee monotone decoding, the distortion distance is limited to 0.", "labels": [], "entities": [{"text": "distortion distance", "start_pos": 45, "end_pos": 64, "type": "METRIC", "confidence": 0.968535304069519}]}, {"text": "The MERT is used to tune model's weights.", "labels": [], "entities": [{"text": "MERT", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9841095805168152}]}, {"text": "The method of () is the baseline setup.", "labels": [], "entities": []}, {"text": "The following 4 metrics are used to measure the quality of the transliteration results (): Word Accuracy in Top-1 (ACC), Fuzziness in Top-1 (Mean F-score), Mean Reciprocal Rank (MRR), MAPref.", "labels": [], "entities": [{"text": "Word Accuracy in Top-1 (ACC)", "start_pos": 91, "end_pos": 119, "type": "METRIC", "confidence": 0.8164098858833313}, {"text": "Fuzziness in Top-1 (Mean F-score)", "start_pos": 121, "end_pos": 154, "type": "METRIC", "confidence": 0.7377412489482335}, {"text": "Mean Reciprocal Rank (MRR)", "start_pos": 156, "end_pos": 182, "type": "METRIC", "confidence": 0.9618562360604604}, {"text": "MAPref.", "start_pos": 184, "end_pos": 191, "type": "METRIC", "confidence": 0.9343797564506531}]}], "tableCaptions": [{"text": " Table 1: Average syllables of names based on  different segmentation methods", "labels": [], "entities": []}, {"text": " Table 3 shows the performance of our system  corresponding to baseline, SSA and FSA on the  closed test set of EnCh track. BE, L1,L2 and  BE+L1+L2 are implemented on the basis of FSA.", "labels": [], "entities": [{"text": "FSA", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.9963616728782654}, {"text": "EnCh track", "start_pos": 112, "end_pos": 122, "type": "DATASET", "confidence": 0.8943903148174286}, {"text": "BE", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9950419664382935}, {"text": "BE", "start_pos": 139, "end_pos": 141, "type": "METRIC", "confidence": 0.9486647844314575}, {"text": "FSA", "start_pos": 180, "end_pos": 183, "type": "DATASET", "confidence": 0.6161438822746277}]}, {"text": " Table 3 shows that the forward transliteration  performance gets consistent improvement from  baseline to FSA. None of new three features can  improve by self, while combining three features  can gain a little.", "labels": [], "entities": [{"text": "FSA", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.715446949005127}]}]}