{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 44-53, Exploring Grammatical Error Correction with Not-So-Crummy Machine Translation *", "labels": [], "entities": [{"text": "Not-So-Crummy Machine Translation", "start_pos": 142, "end_pos": 175, "type": "TASK", "confidence": 0.7212916612625122}]}], "abstractContent": [{"text": "To date, most work in grammatical error correction has focused on targeting specific error types.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.7426093816757202}]}, {"text": "We present a probe study into whether we can use round-trip translations obtained from Google Translate via 8 different pivot languages for whole-sentence grammatical error correction.", "labels": [], "entities": [{"text": "whole-sentence grammatical error correction", "start_pos": 140, "end_pos": 183, "type": "TASK", "confidence": 0.6748685240745544}]}, {"text": "We develop a novel alignment algorithm for combining multiple round-trip translations into a lattice using the TERp machine translation metric.", "labels": [], "entities": [{"text": "TERp machine translation", "start_pos": 111, "end_pos": 135, "type": "TASK", "confidence": 0.5446723600228628}]}, {"text": "We further implement six different methods for extracting whole-sentence corrections from the lattice.", "labels": [], "entities": [{"text": "extracting whole-sentence corrections", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.6729926764965057}]}, {"text": "Our preliminary experiments yield fairly satisfactory results but leave significant room for improvement.", "labels": [], "entities": []}, {"text": "Most importantly, though, they make it clear the methods we propose have strong potential and require further study.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given the large and growing number of non-native English speakers around the world, detecting and correcting grammatical errors in learner text currently ranks as one of the most popular educational NLP applications.", "labels": [], "entities": [{"text": "detecting and correcting grammatical errors in learner text", "start_pos": 84, "end_pos": 143, "type": "TASK", "confidence": 0.8462230935692787}]}, {"text": "Previously published work has explored the effectiveness of using round-trip machine translation (translating an English sentence to some foreign language F, called the pivot, and then translating the F language sentence back to English) for correcting preposition errors.", "labels": [], "entities": [{"text": "round-trip machine translation", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.6975240508715311}, {"text": "correcting preposition errors", "start_pos": 242, "end_pos": 271, "type": "TASK", "confidence": 0.8216990431149801}]}, {"text": "In this paper, we present a pilot study that explores the effectiveness of extending this approach to whole-sentence grammatical error correction.", "labels": [], "entities": [{"text": "whole-sentence grammatical error correction", "start_pos": 102, "end_pos": 145, "type": "TASK", "confidence": 0.8079173713922501}]}, {"text": "Specifically, we explore whether using the concept of round-trip machine translation via multiple-rather than single-pivot languages has the potential of correcting most, if not all, grammatical errors present in a sentence.", "labels": [], "entities": [{"text": "round-trip machine translation", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.716479500134786}]}, {"text": "To do so, we develop a round-trip translation framework using the Google Translate API.", "labels": [], "entities": []}, {"text": "Furthermore, we propose a novel combination algorithm that can combine the evidence present in multiple round-trip translations and increase the likelihood of producing a wholesentence correction.", "labels": [], "entities": []}, {"text": "Details of our methodology are presented in \u00a73 and of the dataset we use in \u00a74.", "labels": [], "entities": []}, {"text": "Since this work is of an exploratory nature, we conduct a detailed error analysis and present the results in \u00a75.", "labels": [], "entities": []}, {"text": "Finally, \u00a76 summarizes the contributions of this pilot study and provides a discussion of possible future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the six techniques for generating corrections, we designed an evaluation task where the annotators would be shown a correction along with the original sentence for which it was generated.", "labels": [], "entities": []}, {"text": "Since there are 6 corrections for each of the 200 sentences, this yields a total of 1, 200 units for pairwise preference judgments.", "labels": [], "entities": []}, {"text": "We chose two annotators, both native English speakers, each of whom annotated half of the judgment units.", "labels": [], "entities": []}, {"text": "Given the idiosyncrasies of the statistical machine translation process underlying our correction techniques, it is quite possible that: \u2022 A correction may fix some, but not all, of the grammatical errors present in the original sentence, and \u2022 A correction maybe more fluent but might change the meaning of the original sentence.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6415529052416483}]}, {"text": "\u2022 A correction may introduce anew disfluency, even though other errors in the sentence have been largely corrected.", "labels": [], "entities": []}, {"text": "This is especially likely to be the case for longer sentences.", "labels": [], "entities": []}, {"text": "Therefore, the pairwise preference judgment task is non-trivial in that it expects the annotators to consider two dimensions: that of grammaticality and of meaning.", "labels": [], "entities": [{"text": "pairwise preference judgment task", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.7106900960206985}]}, {"text": "To accommodate these considerations, we designed the evaluation task such that it asked the annotators to answer the following two questions: 1.", "labels": [], "entities": []}, {"text": "The annotators were asked to choose between three options: \"Original sentence sounds better\", \"Correction sounds better\" and \"Both sound about the same\".", "labels": [], "entities": []}, {"text": "The annotators were asked to choose between two options: \"Correction preserves the original meaning\" and \"Correction changes the original meaning\".", "labels": [], "entities": []}, {"text": "It should be noted that determining change in or preservation of meaning was treated as a very strict judgment.", "labels": [], "entities": [{"text": "determining change in or preservation of meaning", "start_pos": 24, "end_pos": 72, "type": "TASK", "confidence": 0.7771229573658535}]}, {"text": "Subtle changes such as the omission of a determiner were deemed to change the meaning.", "labels": [], "entities": []}, {"text": "In some cases, the original sentences were too garbled to determine the original meaning itself.: A matrix illustrating the Success-Failure-Draw evaluation criterion for the 162 errorful sentences.", "labels": [], "entities": []}, {"text": "The rows represent the meaning dimension (1 = meaning preserved, 0 = meaning changed) and the columns represent the grammaticality dimension (C > O denotes correction being more grammatical than the original, C = O denotes they are about the same and C < O denotes that the correction is worse).", "labels": [], "entities": []}, {"text": "Such a matrix is computed for each of the six techniques.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The distribution of grammatical errors for the  162 errorful sentences.", "labels": [], "entities": []}]}