{"title": [{"text": "Statistical Parsing of Spanish and Data Driven Lemmatization", "labels": [], "entities": [{"text": "Statistical Parsing of Spanish and Data Driven Lemmatization", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.8408040106296539}]}], "abstractContent": [{"text": "Although parsing performances have greatly improved in the last years, grammar inference from treebanks for morphologically rich languages , especially from small treebanks, is still a challenging task.", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9694450497627258}, {"text": "grammar inference", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.7997905313968658}]}, {"text": "In this paper we investigate how state-of-the-art parsing performances can be achieved on Spanish, a language with a rich verbal morphology, with a non-lexicalized parser trained on a treebank containing only around 2,800 trees.", "labels": [], "entities": []}, {"text": "We rely on accurate part-of-speech tagging and data-driven lemmatization to provide parsing models able to cope lexical data sparseness.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7169778794050217}]}, {"text": "Providing state-of-the-art results on Spanish, our methodology is applicable to other languages with high level of inflection.", "labels": [], "entities": []}], "introductionContent": [{"text": "Grammar inference from treebanks has become the standard way to acquire rules and weights for parsing devices.", "labels": [], "entities": [{"text": "Grammar inference", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7795075476169586}]}, {"text": "Although tremendous progress has been achieved in this domain, exploiting small treebanks is still a challenging task, especially for languages with a rich morphology.", "labels": [], "entities": []}, {"text": "The main difficulty is to make good generalizations from small example sets exhibiting data sparseness.", "labels": [], "entities": []}, {"text": "This difficulty is even greater when the inference process relies on semi-supervised or unsupervised learning techniques which are known to require more training examples, as these examples do not explicitly contain all the information.", "labels": [], "entities": []}, {"text": "In this paper we want to explore how we can cope with this difficulty and get state-of-the-art syntactic analyses with a non-lexicalized parser that uses modern semisupervised inference techniques.", "labels": [], "entities": []}, {"text": "We rely on accurate data-driven lemmatization and partof-speech tagging to reduce data sparseness and ease the burden on the parser.", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7733428478240967}]}, {"text": "We try to see how we can improve parsing structure predictions solely by modifying the terminals and/or the preterminals of the trees.", "labels": [], "entities": [{"text": "parsing structure predictions", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.9319067597389221}]}, {"text": "We keep the rest of the tagset as is.", "labels": [], "entities": []}, {"text": "In order to validate our method, we perform experiments on the Cast3LB constituent treebank for Spanish.", "labels": [], "entities": [{"text": "Cast3LB constituent treebank", "start_pos": 63, "end_pos": 91, "type": "DATASET", "confidence": 0.9001934925715128}]}, {"text": "This corpus is quite small, around 3,500 trees, and Spanish is known to have a rich verbal morphology, making the tag set quite complex and difficult to predict. and already showed interesting results on this corpus that will provide us with a comparison for this work, especially on the lexical aspects as they used lexicalized frameworks while we choose PCFG-LAs.", "labels": [], "entities": [{"text": "PCFG-LAs", "start_pos": 356, "end_pos": 364, "type": "DATASET", "confidence": 0.9328842163085938}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the Cast3LB corpus in details.", "labels": [], "entities": [{"text": "Cast3LB corpus", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.9107339382171631}]}, {"text": "In Section 3 we present our experimental setup and results which we discuss and compare in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the presentation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on the Cast3LB development set in order to test various treebank modifications, that can be divided in two categories: (i) modification of the preterminal symbols of the treebank by using simplified POS tagsets; (ii) modification of the terminal symbols of the treebank by replacing word tokens by lemmas.", "labels": [], "entities": [{"text": "Cast3LB development set", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.873031477133433}]}, {"text": "In this section we describe the parsing formalism and POS tagging settings used in our experiments.", "labels": [], "entities": [{"text": "parsing formalism", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.8958110511302948}, {"text": "POS tagging", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.698000431060791}]}], "tableCaptions": [{"text": " Table 2: MElt POS tagging accuracy on the Cast3LB  development set for each of the three tagsets. We pro- vide results obtained with the standard MElt algorithm  (MEMM) as well as with the multiclass perceptron, used  in this paper, for which training is two orders of magni- tude faster. Unknown words represent as high as 13.5 %  of all words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9913570880889893}, {"text": "Cast3LB  development set", "start_pos": 43, "end_pos": 67, "type": "DATASET", "confidence": 0.8705833752950033}]}, {"text": " Table 3: Baseline PARSEVAL scores on Cast3LB dev. set  (\u2264 40 words)", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9181563854217529}, {"text": "Cast3LB dev. set", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.971662163734436}]}, {"text": " Table 4: PARSEVAL scores on Cast3LB development set  with reduced2 tagset (\u2264 40 words)", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8223235607147217}, {"text": "Cast3LB development set", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.9241132934888204}]}, {"text": " Table 5: PARSEVAL scores on Cast3LB development set  with reduced3 tagset (\u2264 40 words)", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8308828473091125}, {"text": "Cast3LB development set", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.9062486886978149}]}, {"text": " Table 6: Lemmatization performance on the Cast3LB.", "labels": [], "entities": [{"text": "Lemmatization", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9738794565200806}]}, {"text": " Table 8: PARSEVAL F-score results on the Cast3LB test set", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9276967644691467}, {"text": "F-score", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.7451513409614563}, {"text": "Cast3LB test set", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.8837189873059591}]}]}