{"title": [{"text": "Markov Logic Networks for Situated Incremental Natural Language Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "We present work on understanding natural language in a situated domain, that is, language that possibly refers to visually present entities , in an incremental, word-byword fashion.", "labels": [], "entities": []}, {"text": "Such type of understanding is required in conversational systems that need to act immediately on language input, such as multi-modal systems or dialogue systems for robots.", "labels": [], "entities": []}, {"text": "We explore a set of models specified as Markov Logic Networks, and show that a model that has access to information about the visual context of an utterance, its discourse context, as well as the linguistic structure of the utterance performs best.", "labels": [], "entities": []}, {"text": "We explore its incremen-tal properties, and also its use in a joint parsing and understanding module.", "labels": [], "entities": []}, {"text": "We conclude that MLNs offer a promising framework for specifying such models in a general, possibly domain-independent way.", "labels": [], "entities": []}], "introductionContent": [{"text": "We speak situated in time and space.", "labels": [], "entities": []}, {"text": "Speech by necessity unfolds sequentially in time; and in a conversation, all speech but that of the opening utterance is preceded by other speech belonging to the same conversation.", "labels": [], "entities": []}, {"text": "In many, if not most, conversational situations speaker and addressee are co-located in space, and their speech may refer to their shared situation.", "labels": [], "entities": []}, {"text": "Most current spoken dialogue systems attempt to abstract from this fact, however.", "labels": [], "entities": []}, {"text": "They work in domains where physical co-location is not necessary, such as information look-up, and they quantize time into discrete turn units by endpointing utterances (see discussion in).", "labels": [], "entities": []}, {"text": "In this paper we present our current work on overcoming these abstractions for the task of natural language understanding (NLU).", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 91, "end_pos": 127, "type": "TASK", "confidence": 0.7961806009213129}]}, {"text": "We have created a statistical model that can be trained on conversational data and which can be used as an NLU module for an incremental, situated dialogue system (such as that described in ().", "labels": [], "entities": []}, {"text": "We show that this model beats baseline approaches by a wide margin, and that making available the full set of information comprising visual context, discourse context, and linguistic structure gives significantly better results than any subset of these information sources on their own.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: we first discuss related work and introduce some background, and then describe in detail our set of experiments, and present and analyse our results.", "labels": [], "entities": []}, {"text": "We close with a general discussion of this work and possible future extensions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We will now describe our experiments with using Markov Logic Networks for situated incremental natural language understanding.", "labels": [], "entities": [{"text": "situated incremental natural language understanding", "start_pos": 74, "end_pos": 125, "type": "TASK", "confidence": 0.7188572287559509}]}], "tableCaptions": [{"text": " Table 1: Majority class and Action contextual baselines", "labels": [], "entities": []}, {"text": " Table 2: Comparison of combinations using World, EPs  (words), RMRS and Previous context. Number in brack- ets are for tests on automatically transcribed speech.", "labels": [], "entities": [{"text": "World", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.7159411311149597}, {"text": "RMRS", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.6475856900215149}, {"text": "Number", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9608410000801086}]}, {"text": " Table 3: Feedback strategies comparison for hard-coded  (HC), automatic (MLN) and no feedback (none)", "labels": [], "entities": []}, {"text": " Table 4: Incremental Results for Action, Argument, and  Option with varying sentence lengths", "labels": [], "entities": []}]}