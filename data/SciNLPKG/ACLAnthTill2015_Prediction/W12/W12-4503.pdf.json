{"title": [{"text": "Data-driven Multilingual Coreference Resolution using Resolver Stacking", "labels": [], "entities": [{"text": "Multilingual Coreference Resolution", "start_pos": 12, "end_pos": 47, "type": "TASK", "confidence": 0.6243743697802225}]}], "abstractContent": [{"text": "This paper describes our contribution to the CoNLL 2012 Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2012 Shared Task", "start_pos": 45, "end_pos": 67, "type": "DATASET", "confidence": 0.8180906921625137}]}, {"text": "1 We present a novel decoding algorithm for coreference resolution which is combined with a standard pair-wise coreference resolver in a stacking approach.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.9600456357002258}]}, {"text": "The stacked decoders are evaluated on the three languages of the Shared Task.", "labels": [], "entities": []}, {"text": "We obtain an official overall score of 58.25 which is the second highest in the Shared Task.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present our contribution to the).", "labels": [], "entities": []}, {"text": "We follow the standard architecture where mentions are extracted in the first step, then they are clustered using a pair-wise classifier (see e.g.,).", "labels": [], "entities": []}, {"text": "For English, the set of extracted mentions is filtered by removing non-referential occurrences of certain pronouns.", "labels": [], "entities": []}, {"text": "Our coreference resolver at its core relies on a pair-wise classifier.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7977232336997986}]}, {"text": "To overcome the problems associated with the isolated pair-wise decisions, we devised a novel decoding algorithm which compares a mention to partially built clusters.", "labels": [], "entities": []}, {"text": "For our Shared Task contribution we combined this algorithm with conventional pair-wise decoding algorithms in a stacking approach.", "labels": [], "entities": []}, {"text": "In the Shared Task evaluation, our system received an overall official score of 58.25, which is the second highest among the sixteen participants.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the non-referential classifier used for English. Precision, recall, and F-measure are broken  down by pronoun (top three rows), and the micro-average over all three (bottom row). The left side uses a probability  threshold of 0.5, and the right one a threshold of 0.95. The last column denotes the number of occurrences of the  corresponding token. All numbers are computed on the development set.", "labels": [], "entities": [{"text": "Precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9959944486618042}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.996859073638916}, {"text": "F-measure", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9968320727348328}]}, {"text": " Table 2: Performance of different decoders on the devel- opment set for each language. The configuration of the  Stacked systems is described in detail in Section 7.", "labels": [], "entities": []}, {"text": " Table 3: Performance on the shared task test set. Us- ing predicted mentions (PM; i.e., the official evalua- tion), gold mentions boundaries (GB), and gold mentions  (GM).", "labels": [], "entities": [{"text": "Us- ing predicted mentions (PM", "start_pos": 51, "end_pos": 81, "type": "METRIC", "confidence": 0.6938403717109135}, {"text": "gold mentions boundaries (GB)", "start_pos": 117, "end_pos": 146, "type": "METRIC", "confidence": 0.6297175486882528}, {"text": "gold mentions  (GM)", "start_pos": 152, "end_pos": 171, "type": "METRIC", "confidence": 0.679550290107727}]}]}