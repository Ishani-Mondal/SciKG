{"title": [{"text": "Evaluating Joint Modeling of Yeast Biology Literature and Protein-Protein Interaction Networks", "labels": [], "entities": [{"text": "Evaluating Joint Modeling", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7382213373978933}, {"text": "Yeast Biology Literature", "start_pos": 29, "end_pos": 53, "type": "DATASET", "confidence": 0.6226961414019266}]}], "abstractContent": [{"text": "Block-LDA is a topic modeling approach to perform data fusion between entity-annotated text documents and graphs with entity-entity links.", "labels": [], "entities": []}, {"text": "We evaluate Block-LDA in the yeast biology domain by jointly modeling PubMed R articles and yeast protein-protein interaction networks.", "labels": [], "entities": [{"text": "PubMed R articles", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.9595567385355631}]}, {"text": "The topic coherence of the emergent topics and the ability of the model to retrieve relevant scientific articles and proteins related to the topic are compared to that of a text-only approach that does not make use of the protein-protein interaction matrix.", "labels": [], "entities": []}, {"text": "Evaluation of the results by biologists show that the joint modeling results in better topic coherence and improves retrieval performance in the task of identifying top related papers and proteins.", "labels": [], "entities": []}], "introductionContent": [{"text": "The prodigious rate at which scientific literature is produced makes it virtually impossible for researchers to manually read every article to identify interesting and relevant papers.", "labels": [], "entities": []}, {"text": "It is therefore critical to have automatic methods to analyze the literature to identify topical structure in it.", "labels": [], "entities": []}, {"text": "The latent structure that is identified can be used for different applications such as enabling browsing, retrieval of papers related to a particular sub-topic etc.", "labels": [], "entities": []}, {"text": "Such applications assist in common scenarios such as helping a researcher identify a set of articles to read (perhaps a set of well-regarded surveys) to familiarize herself with anew sub-field; helping a researcher to stay abreast with the latest advances in his field by identifying relevant articles etc.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the task of organizing a large collection of literature about yeast biology to enable topic oriented browsing and retrieval from the literature.", "labels": [], "entities": []}, {"text": "The analysis is performed using topic modeling() which has, in the last decade, emerged as a versatile tool to uncover latent structure in document corpora by identifying broad topics that are discussed in it.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7156074792146683}]}, {"text": "This approach complements traditional information retrieval tasks where the objective is to fulfill very specific information needs.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.7580588161945343}]}, {"text": "In addition to literature, there often exist other sources of domain information related to it.", "labels": [], "entities": []}, {"text": "In the case of yeast biology, an example of such a resource is a database of known protein-protein interactions (PPI) which have been identified using wetlab experiments.", "labels": [], "entities": []}, {"text": "We perform data fusion by combining text information from articles and the database of yeast protein-protein interactions, by using a latent variable model -Block-LDA () that jointly models the literature and PPI networks.", "labels": [], "entities": []}, {"text": "We evaluate the ability of the topic models to return meaningful topics by inspecting the top papers and proteins that pertain to them.", "labels": [], "entities": []}, {"text": "We compare the performance of the joint model i.e. Block-LDA with a model that only considers the text corpora by asking a yeast biologist to evaluate the coherence of topics and the relevance of the retrieved articles and proteins.", "labels": [], "entities": []}, {"text": "This evaluation serves to test the utility of Block-LDA on areal task as opposed to an internal evaluation (such as by using perplexity metrics for example).", "labels": [], "entities": []}, {"text": "Our evaluaton shows that the joint model outperforms the text-only approach both in topic co-herence and in top paper and protein retrieval as measured by precision@10 values.", "labels": [], "entities": [{"text": "protein retrieval", "start_pos": 122, "end_pos": 139, "type": "TASK", "confidence": 0.7458252310752869}, {"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9949297308921814}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the topic modeling approach used in the paper.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.7595703601837158}]}, {"text": "Section 3 describes the datasets used followed by Section 4 which details the setup of the experiments.", "labels": [], "entities": []}, {"text": "The results of the evaluation are presented in Section 5 which is followed by the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the topics, a yeast biologist who is an expert in the field was asked to mark each topic with a binary flag indicating if the top words of the distribution represented a coherent sub-topic in yeast biology.", "labels": [], "entities": []}, {"text": "This process was repeated for the 3 different variants of the model.", "labels": [], "entities": []}, {"text": "The variant used to obtain results is concealed from the evaluator to remove the possibility of bias.", "labels": [], "entities": []}, {"text": "In the next step of the evaluation, the top articles and proteins assigned to each topic were presented in a ranked list and a similar judgement was requested to indicate if the article/protein was relevant to the topic in question.", "labels": [], "entities": []}, {"text": "Similar to the topic coherence judgements, the process was repeated for each variant of the model.", "labels": [], "entities": []}, {"text": "Screenshots of the tool used for obtaining the judgments can be seen in.", "labels": [], "entities": []}, {"text": "It should be noted that since the nature of the topics in the literature considered was highly technical and specialized, it was impractical to get judgements from multiple annotators.", "labels": [], "entities": []}, {"text": "To evaluate the retrieval of the top articles and proteins, we measure the quality of the results by computing its precision@10 score.", "labels": [], "entities": [{"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9992289543151855}]}], "tableCaptions": []}