{"title": [{"text": "Midge: Generating Descriptions of Images *", "labels": [], "entities": [{"text": "Midge: Generating Descriptions of Images", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6515357395013174}]}], "abstractContent": [{"text": "We demonstrate a novel, robust vision-to-language generation system called Midge.", "labels": [], "entities": [{"text": "Midge", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.9248532652854919}]}, {"text": "Midge is a prototype system that connects computer vision to syntactic structures with semantic constraints, allowing for the automatic generation of detailed image descriptions.", "labels": [], "entities": [{"text": "Midge", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9077591896057129}]}, {"text": "We explain how to connect vision detections to trees in Penn Treebank syntax, which provides the scaffolding necessary to further refine data-driven statistical generation approaches fora variety of end goals.", "labels": [], "entities": [{"text": "Penn Treebank syntax", "start_pos": 56, "end_pos": 76, "type": "DATASET", "confidence": 0.9880892435709635}]}], "introductionContent": [{"text": "There has been a growing interest in tackling the problem of how to describe an image using computer vision detections.", "labels": [], "entities": [{"text": "computer vision detections", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.6919160087903341}]}, {"text": "This problem is difficult in part because computer vision detections are often wrong: State-of-the-art vision technology predicts things that are not there, and misses things that are obvious to a human observer.", "labels": [], "entities": [{"text": "computer vision detections", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.7220214207967123}]}, {"text": "This problem is also difficult because it is not clear what kind of language should be generated -the language that makes up a \"description\" can take many forms.", "labels": [], "entities": []}, {"text": "At the bare minimum, an automatic vision-tolanguage system, given an image with a single detection of, for example, a dog, should be able to generate a dog, and a longer phrase if requested.", "labels": [], "entities": []}, {"text": "To be useful in real-world applications, it should be able to create basic descriptions that are as true as possible to the image, as well as descriptions that guess probable information based on language analysis alone.", "labels": [], "entities": []}, {"text": "To our knowledge, no current system provides this functionality.", "labels": [], "entities": []}, {"text": "Midge is built based on these goals.", "labels": [], "entities": [{"text": "Midge", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6636044979095459}]}, {"text": "Our approach converts object detections to descriptive sentences using a tree-generating derivation process that fleshes out lexicalized syntactic * Thanks to the CLSP 2011 summer workshop at Johns Hopkins for making this system possible.", "labels": [], "entities": [{"text": "object detections", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7219878733158112}, {"text": "CLSP 2011 summer workshop at Johns Hopkins", "start_pos": 163, "end_pos": 205, "type": "TASK", "confidence": 0.5366752573422023}]}, {"text": "Midge is available to try online at http://recognition.cs.stonybrook.edu:8080/\u02dcmitchema/midge/ and http://mcvl.cewit.stonybrook.edu//\u02dcmitchema/midge/ and screenshots at http://www.abdn.ac.uk/\u02dcr07mm9/midge/ structure around object nouns.", "labels": [], "entities": []}, {"text": "Likely subtrees are learned from a cleaned version of the Flickr dataset () parsed using the Berkeley parser.", "labels": [], "entities": [{"text": "Flickr dataset", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.9551726281642914}]}, {"text": "The final structures generated by the system are present-tense declarative sentences in Penn Treebank syntax.", "labels": [], "entities": [{"text": "Penn Treebank syntax", "start_pos": 88, "end_pos": 108, "type": "DATASET", "confidence": 0.9841445883115133}]}, {"text": "With this in place, the system can generate a dog, a black dog sleeping, a furry black dog sleeping by a cat, etc., while also suggesting further detectors for the vision system to run.", "labels": [], "entities": []}, {"text": "Approaching the problem in this way, Midge provides a starting point for generation to meet different goals: from automatically creating stories or summaries based on visual data, to suggesting phrases that a speech-impaired AAC user can select to assist in conversation.", "labels": [], "entities": []}, {"text": "There is still much work to be done, but we believe that the basic architecture used by this system is a solid starting point for generating a wide variety of descriptive content, and makes clear some of the issues a visionto-language system must handle in order to generate natural-sounding descriptions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}