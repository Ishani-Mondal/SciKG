{"title": [{"text": "The Study of Effect of Length in Morphological Segmentation of Agglutinative Languages", "labels": [], "entities": [{"text": "Morphological Segmentation of Agglutinative Languages", "start_pos": 33, "end_pos": 86, "type": "TASK", "confidence": 0.8123038351535797}]}], "abstractContent": [{"text": "Morph length is one of the indicative feature that helps learning the morphology of languages , in particular agglutinative languages.", "labels": [], "entities": [{"text": "Morph length", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.8353065848350525}]}, {"text": "In this paper, we introduce a simple unsu-pervised model for morphological segmenta-tion and study how the knowledge of morph length affect the performance of the seg-mentation task under the Bayesian framework.", "labels": [], "entities": []}, {"text": "The model is based on (Goldwater et al., 2006) unigram word segmentation model and assumes a simple prior distribution over morph length.", "labels": [], "entities": [{"text": "unigram word segmentation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.5690817932287852}]}, {"text": "We experiment this model on two highly related and agglutinative languages namely Tamil and Telugu, and compare our results with the state of the art Mor-fessor system.", "labels": [], "entities": []}, {"text": "We show that, knowledge of morph length has a positive impact and provides competitive results in terms of overall performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most of the NLP tasks require one way or another the handling of morphology.", "labels": [], "entities": [{"text": "handling of morphology", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.8233551780382792}]}, {"text": "The task becomes very crucial when the language in question is morphologically rich as is the casein many Indo-European languages.", "labels": [], "entities": []}, {"text": "The application of morphology is evident in applications such as Statistical Machine Translation (SMT)), dependency parsing, information retrieval and soon.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT))", "start_pos": 65, "end_pos": 103, "type": "TASK", "confidence": 0.840393195549647}, {"text": "dependency parsing", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.8874745070934296}, {"text": "information retrieval", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.8635400235652924}]}, {"text": "Apart from the morphological analysis as in the traditional linguistic sense, morphological segmentation is also widely used as an easy alternative to full fledged morphological analysis.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 78, "end_pos": 104, "type": "TASK", "confidence": 0.7152213603258133}]}, {"text": "In this paper we mainly focus on the task of morphological segmentation.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.8674948215484619}]}, {"text": "The main task in morphological segmentation is to segment the given token or wordform into set of morphs or identifying the location of each morpheme boundary within the token.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.8774672150611877}]}, {"text": "Morphological segmentation is most suitable for agglutinative languages (such as Finnish or Turkish) than fusional languages (such as Semitic languages).", "labels": [], "entities": [{"text": "Morphological segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9318515956401825}]}, {"text": "Though both supervised) and unsupervised methods) are extensively studied for morphological segmentation, unsupervised techniques have the appeal of application to multilingual data with cost effective manner.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 78, "end_pos": 104, "type": "TASK", "confidence": 0.8847093284130096}]}, {"text": "Within unsupervised paradigm, various methods have been explored.", "labels": [], "entities": []}, {"text": "Minimum Description Length (MDL)) based approaches are most popular in which the best segmentation corresponds to the compact representation of morphology and the resulting lexicon.", "labels": [], "entities": []}, {"text": "( attempted word segmentation and joint segmentation of related languages using Bayesian approach.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7381372004747391}, {"text": "joint segmentation of related languages", "start_pos": 34, "end_pos": 73, "type": "TASK", "confidence": 0.8227758407592773}]}, {"text": "applied various probabilistic measures to discover affixes of wordforms.", "labels": [], "entities": []}, {"text": "() explored ways to model orthographic rules of wordforms.", "labels": [], "entities": []}, {"text": "In this work, we are mainly going to focus on Bayesian approach.", "labels": [], "entities": []}, {"text": "Bayesian approaches provide natural way of modeling subjective knowledge as well as separating problem specific aspects from general aspects.", "labels": [], "entities": []}, {"text": "In the case of agglutinative lan-guages, the number of morphemes in a word as well as morph length play a major role in morphological process.", "labels": [], "entities": []}, {"text": "The main rationale for this work is to study linguistic factors (mainly morph length), so that language specific priors can be applied over different languages.", "labels": [], "entities": []}, {"text": "This will especially be useful when modeling resource poor languages (RPL) with little or no data, as well as building resources for RPL from resource rich languages (RRL).", "labels": [], "entities": []}, {"text": "Towards that objective, our main contribution in this work is, we introduce a simple unsupervised segmentation model based on Bayesian approach and we study the effect of morph length prior for two agglutinative languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments are carried out for the unigram segmentation model (unsup-uni) as described in Section 3 and Morfessor system).", "labels": [], "entities": [{"text": "unigram segmentation", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.6925973892211914}, {"text": "Morfessor system", "start_pos": 109, "end_pos": 125, "type": "DATASET", "confidence": 0.9105622172355652}]}, {"text": "For both Tamil and Telugu, we perform the following experiments: (i) baseline (ii) unsup-uni with base distribution PA 0 (unsup-uni-p0-len) (iii) unsup-uni with base distribution P B 0 (unsup-unip0-lex-len) and (iv) with Morfessor.", "labels": [], "entities": []}, {"text": "For each system, we add some knowledge about morph length (l) and report the accuracy.", "labels": [], "entities": [{"text": "morph length (l)", "start_pos": 45, "end_pos": 61, "type": "METRIC", "confidence": 0.8676552653312684}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9990599751472473}]}, {"text": "The experiments (ii), (iii) and (iv) use additional dataset known as extra-data.", "labels": [], "entities": []}, {"text": "Extra-data is an unannotated/unsegmented data which augments the test data while training the systems.", "labels": [], "entities": []}, {"text": "As test data with gold segmentation is very small, we feel this step is necessary to make the evaluation credible.", "labels": [], "entities": []}, {"text": "The following subsection describes the datasets in detail.", "labels": [], "entities": []}, {"text": "Baseline system corresponds to random segmentation.", "labels": [], "entities": []}, {"text": "We evaluate baseline system for morph lengths 1 to 10.", "labels": [], "entities": []}, {"text": "For each morph length (l) experiment, we change the probability of adding a boundary at each character position to be ( 1 l ) except at l = 1 where the probability is 0.75.", "labels": [], "entities": []}, {"text": "Unsup-uni-p0-len experiment uses base distribution PA 0 (see Section 3.1).", "labels": [], "entities": [{"text": "base distribution PA 0", "start_pos": 33, "end_pos": 55, "type": "METRIC", "confidence": 0.6817181333899498}]}, {"text": "We conduct this experiment in 2 steps: (i) running the Gibbs sampler with the extra-data and (ii) use the parameters (including morph counts) from step (i) and run the Gibbs sampler on test data.", "labels": [], "entities": []}, {"text": "We set the expected morph length (l) in the base distribution PA 0 every time we run the experiment for different morph length.", "labels": [], "entities": []}, {"text": "For the step (i), the Gibbs sampler is run for 10000 iterations with different concentration parameter (\u03b1).", "labels": [], "entities": []}, {"text": "We collect samples every 1000 iterations and we store the last sample as our model along with other parameters.", "labels": [], "entities": []}, {"text": "For step (ii), we use the model from step (i) and run the Gibbs sampler on test data.", "labels": [], "entities": []}, {"text": "We collect the final sample as our predicted segmentation of the test data and perform evaluation on the predicted segmentation.", "labels": [], "entities": []}, {"text": "In unsup-uni-p0-lexlen experiment, we use the base distribution P B 0 (see Section 3.1).", "labels": [], "entities": []}, {"text": "P B 0 includes morpheme probability apart from the length prior.", "labels": [], "entities": []}, {"text": "Experiments for unsup-uni-p0-lex-len is carried out in the same way as that of unsup-uni-p0-len.", "labels": [], "entities": []}, {"text": "We use gamma distribution length prior for experiments with Morfessor.", "labels": [], "entities": [{"text": "Morfessor", "start_pos": 60, "end_pos": 69, "type": "DATASET", "confidence": 0.9370882511138916}]}, {"text": "We train Morfessor on extra-data for morph lengths 1 to 10.", "labels": [], "entities": []}, {"text": "We change the expected length in the gamma prior for each morph length experiment.", "labels": [], "entities": []}, {"text": "Then we run the Morfessor on test data with same parameters created during the training.", "labels": [], "entities": []}, {"text": "We use Precision (P), Recall (R) and F-score (F) for evaluating our predicted segmentation with gold segmentation.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 7, "end_pos": 20, "type": "METRIC", "confidence": 0.9590825736522675}, {"text": "Recall (R)", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.9641397893428802}, {"text": "F-score (F)", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.9695417881011963}]}, {"text": "Our evaluation is same as ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Gold segmentation: statistics", "labels": [], "entities": [{"text": "Gold segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.708787351846695}]}, {"text": " Table 2: Results for Tamil and Telugu", "labels": [], "entities": []}]}