{"title": [{"text": "Using Senses in HMM Word Alignment", "labels": [], "entities": [{"text": "HMM Word Alignment", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.6620904207229614}]}], "abstractContent": [{"text": "Some of the most used models for statistical word alignment are the IBM models.", "labels": [], "entities": [{"text": "statistical word alignment", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.7799621820449829}, {"text": "IBM", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.9091780781745911}]}, {"text": "Although these models generate acceptable alignments, they do not exploit the rich information found in lexical resources, and as such have no reasonable means to choose better translations for specific senses.", "labels": [], "entities": []}, {"text": "We try to address this issue by extending the IBM HMM model with an extra hidden layer which represents the senses a word can take, allowing similar words to share similar output distributions.", "labels": [], "entities": [{"text": "IBM HMM model", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.8233641386032104}]}, {"text": "We test a preliminary version of this model on English-French data.", "labels": [], "entities": []}, {"text": "We compare different ways of generating senses and assess the quality of the alignments relative to the IBM HMM model, as well as the generated sense probabilities, in order to gauge the usefulness in Word Sense Disambiguation.", "labels": [], "entities": [{"text": "IBM HMM model", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.8683334589004517}, {"text": "Word Sense Disambiguation", "start_pos": 201, "end_pos": 226, "type": "TASK", "confidence": 0.606805682182312}]}], "introductionContent": [{"text": "Modern machine translation is dominated by statistical methods, most of which are trained on wordaligned parallel corpora (, which need to be generated separately.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7681494057178497}]}, {"text": "One of the most commonly used methods to generate these word alignments is to use the IBM models 1-5, which generate one-directional alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.717726394534111}]}, {"text": "Although the IBM models perform well, they fail to take into account certain situations.", "labels": [], "entities": []}, {"text": "For example, if an alignment between two words f 1 and e 1 is considered, and f 1 is an uncommon translation fore 1 , the translation probability will below.", "labels": [], "entities": []}, {"text": "It might happen, that an alignment to a different nearby word is preferred by the model.", "labels": [], "entities": []}, {"text": "Consider for example the situation where f 1 is 'taal' (Dutch, meaning language), and e 1 is 'tongue'.", "labels": [], "entities": []}, {"text": "The translation probability for this maybe low, as 'tongue' usually translates as 'tong', meaning the body part.", "labels": [], "entities": []}, {"text": "In this case the preference of the alignment model may dominate, leading to the wrong alignment.", "labels": [], "entities": []}, {"text": "Moreover, the standard tools for word alignment fail to make use of the lexical resources that already exist, and which could contribute useful information for the task.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.8354927599430084}]}, {"text": "In particular, the ontology defined in WordNet could be put to good use.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9674289226531982}]}, {"text": "Intuitively, the translation of a word should depend on the sense of the word being used.", "labels": [], "entities": []}, {"text": "The current work seeks to explore this idea, by explicitly modeling the senses in the translation process.", "labels": [], "entities": []}, {"text": "It does so, by modifying the HMM alignment model to include synsets as an intermediate stage of translation.", "labels": [], "entities": [{"text": "HMM alignment", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.8087139129638672}]}, {"text": "This would facilitate sharing of translation distributions between words with similar senses that should generate the correct sense.", "labels": [], "entities": [{"text": "sharing of translation", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.6680849393208822}]}, {"text": "In terms of the example above, one of the senses for 'tongue' will share the translation distribution with 'language', for which we will have more relevant translation probabilities.", "labels": [], "entities": []}, {"text": "As well as performing word alignment this model can be used to generate sense annotations on one side of a parallel corpus, given an alignment, or even generate sense annotations while aligning a corpus.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7804794609546661}]}, {"text": "Thus, the model could learn to align a corpus and do WSD at the same time.", "labels": [], "entities": [{"text": "WSD", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.5528666377067566}]}, {"text": "In this paper, the effect the usage of senses has on alignment is investigated, and the potential usefulness of the model for WSD is explored.", "labels": [], "entities": [{"text": "WSD", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9779508113861084}]}, {"text": "In the next section related work is discussed, after which in section 3 the current model is 39 discussed.", "labels": [], "entities": []}, {"text": "In section 4 the evaluation of the model is discussed, in two parts.", "labels": [], "entities": []}, {"text": "In the first part, the model is evaluated for English-French on gold standard manually aligned data and compared to the results of the base HMM model.", "labels": [], "entities": []}, {"text": "In the second part, the model is qualitatively evaluated by inspecting the senses and associated output distributions of selected words.", "labels": [], "entities": []}], "datasetContent": [{"text": "We will evaluate the early results of this model against the HMM and Model 1 results, and will do a qualitative analysis of the distribution over senses and French words that the model obtains, in order to find out if reasonable predictions for senses are made.", "labels": [], "entities": []}, {"text": "The sense HMM model will be evaluated using the three sense inventories suggested in subsection 3.1.", "labels": [], "entities": []}, {"text": "The dataset used was a 1 million sentence aligned English-French corpus, taken from the Europarl corpus).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9948389232158661}]}, {"text": "The data was tokenised, length limited to a maximum length of 50, and lowercased.", "labels": [], "entities": [{"text": "length", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9543763399124146}]}, {"text": "The results are evaluated on the test set from the ACL 2005 shared task, using Alignment Error Rate.", "labels": [], "entities": [{"text": "ACL 2005 shared task", "start_pos": 51, "end_pos": 71, "type": "DATASET", "confidence": 0.8791728764772415}, {"text": "Alignment Error Rate", "start_pos": 79, "end_pos": 99, "type": "METRIC", "confidence": 0.8613067666689554}]}, {"text": "The models are all trained for 5 iterations, and a pruning threshold is employed that removes probabilities from the translation tables if it is below 1.0 \u00b7 10 \u22126 . The results of training models based on senses generated in the 3 ways listed above is shown in.", "labels": [], "entities": []}, {"text": "The three SHMM models are compared against Model 1, and the standard HMM model, each of which is trained for 5 iterations.", "labels": [], "entities": []}, {"text": "The HMM model is initialised from Model 1, and the SHMM models initialised from the HMM model.", "labels": [], "entities": []}, {"text": "As the figure shows, the AER score for the last two iterations of the HMM model is very similar to the scores that the three variations of the SHMM model attain.", "labels": [], "entities": [{"text": "AER score", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9804064631462097}]}, {"text": "The scores for the three HMM models range from 0.185 to 0.192 A possible reason for this performance is that the models didn't have enough sharing going on between the senses.", "labels": [], "entities": []}, {"text": "The corpus contains 70700 unique words.", "labels": [], "entities": []}, {"text": "Looking at the amount of senses that are found in the 'none' condition, meaning that all of the WordNet senses share output probabilities, there are 17194 words that have at least one of these senses listed, and there are 27120 distinct senses available in that setting.", "labels": [], "entities": []}, {"text": "For the other 53500 senses, no sharing is going on whatsoever.", "labels": [], "entities": []}, {"text": "In the 'merge' and 'synth' conditions, there are more senses taken from WordNet (for a total from WordNet of 33133), but these don't add any shar-: Senses for the word 'severe' in the 'none' version of the SHMM model, their WordNet definition, the probability of the sense for the word severe, and the most likely French words for the senses given in order of likelihood. ing.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.9691442251205444}, {"text": "WordNet", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.9657375812530518}]}, {"text": "It might be then, that the model has insufficient opportunity to share output distributions, causing it to behave much as the HMM alignment model.", "labels": [], "entities": [{"text": "HMM alignment", "start_pos": 126, "end_pos": 139, "type": "TASK", "confidence": 0.7022025287151337}]}, {"text": "Another possibility is, that the senses insufficiently well-defined, and share probabilities between words that are too dissimilar, negating any positive effect this may have and possibly pushing the model towards less sharing.", "labels": [], "entities": []}, {"text": "We will suggest possibilities for dealing with this in section 5.", "labels": [], "entities": []}, {"text": "Regardless of the performance of the model in word alignment, if the model learns probabilities for senses that are reasonable, it can be used as a word sense disambiguation system for parallel corpora, with the candidate senses being made up from the senses out of WordNet.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.8046243190765381}, {"text": "WordNet", "start_pos": 266, "end_pos": 273, "type": "DATASET", "confidence": 0.9715332984924316}]}, {"text": "Those words not listed in WordNet, are treated as being monosemous words in this context.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.9706560969352722}]}, {"text": "The 'merge' and 'none' conditions are most useful for this: if a WSD system chooses a sense that is not linked to a WordNet sense, it is not clearly defined which sense is meant here.", "labels": [], "entities": []}, {"text": "In order to find out if the model makes sensible distinctions between different senses, we have picked a random polysemous word, and looked at the senses associated with it in the 'none' condition.: Senses for the word 'rigorous' in the 'none' version of the SHMM model, their WordNet definition, the probability of the senses of the word 'rigorous', and the most likely French words for the senses given in order of likelihood.", "labels": [], "entities": [{"text": "WordNet definition", "start_pos": 277, "end_pos": 295, "type": "DATASET", "confidence": 0.9189087748527527}]}, {"text": "cause the differences between the senses are listed in table 2.", "labels": [], "entities": []}, {"text": "It can be seen that the only difference between severe.s.04 and severe.s.06 is the addition of the word 'spartan' for the first.", "labels": [], "entities": [{"text": "spartan", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.9718440771102905}]}, {"text": "As 'spartan' only occurs 67 times in the corpus, versus 484 for severe, it is possible that they are so similar, because the counts for 'spartan' get overshadowed.", "labels": [], "entities": []}, {"text": "For the other senses however, the most likely translations vary quite a bit.", "labels": [], "entities": []}, {"text": "The sense 'hard.s.04', meaning very strong or vigorous, also includes translations to 'plus' and 'dur', which seems more likely given the sense.", "labels": [], "entities": []}, {"text": "Given these translation probabilities though, it should at least be possible to distinguish between different senses of the word severe, given that it's aligned to a different french word.", "labels": [], "entities": []}, {"text": "One more example is listed in table 3, showing the probabilities for two different senses, and their most likely translations.", "labels": [], "entities": []}, {"text": "The most likely sense for rigorous under the model is in the sense of 'allowing no deviation from a standard'.", "labels": [], "entities": []}, {"text": "This is the only of the two senses that can translate to 'rigueur' in french, literally rigor.", "labels": [], "entities": []}, {"text": "The other sense, meaning 'demanding strict attention to rules and procedures', is more likely to translate to 'strictes', 'stricte' and 's\u00e9v\u00e8res', which reflects the WordNet definition.", "labels": [], "entities": [{"text": "WordNet definition", "start_pos": 166, "end_pos": 184, "type": "DATASET", "confidence": 0.9412728250026703}]}, {"text": "The difference in contributing English words between these two senses can be found in.", "labels": [], "entities": []}, {"text": "Interestingly, the three forms of the word strict are associated with the sense rigorous.s.01, even though the naive translations of these words into French are more likely for rigorous.s.02.", "labels": [], "entities": []}, {"text": "Even so, the results match the WordNet definitions better.", "labels": [], "entities": [{"text": "WordNet definitions", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.9817224740982056}]}, {"text": "These results show that useful translations are found, and the corresponding senses can be learned as well.", "labels": [], "entities": []}, {"text": "For sense discrimination in parallel corpuses then, this model shows potential, and for", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7287447303533554}]}], "tableCaptions": []}