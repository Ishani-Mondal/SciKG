{"title": [{"text": "Rich Morphology Generation Using Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6650314132372538}]}], "abstractContent": [{"text": "We present an approach for generation of morphologically rich languages using statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.6180592676003774}]}, {"text": "Given a sequence of lem-mas and any subset of morphological features, we produce the inflected word forms.", "labels": [], "entities": []}, {"text": "Testing on Arabic, a morphologically rich language, our models can reach 92.1% accuracy starting only with lemmas, and 98.9% accuracy if all the gold features are provided.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9992766976356506}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9993672966957092}]}], "introductionContent": [{"text": "Many natural language processing (NLP) applications, such as summarization and machine translation (MT), require natural language generation (NLG).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 5, "end_pos": 38, "type": "TASK", "confidence": 0.7693642874558767}, {"text": "summarization", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.9863848090171814}, {"text": "machine translation (MT)", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.8209865689277649}, {"text": "natural language generation (NLG)", "start_pos": 113, "end_pos": 146, "type": "TASK", "confidence": 0.8049598733584086}]}, {"text": "Generation for morphologically rich languages, which introduce a lot of challenges for NLP in general, has gained a lot of attention recently, especially in the context of statistical MT (SMT).", "labels": [], "entities": [{"text": "MT (SMT)", "start_pos": 184, "end_pos": 192, "type": "TASK", "confidence": 0.8167939186096191}]}, {"text": "The common wisdom for handling morphological richness is to reduce the complexity in the internal application models and then generate complex word forms in a final step.", "labels": [], "entities": []}, {"text": "In this paper, we present a SMT-based approach for generation of morphologically rich languages.", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.9954484105110168}]}, {"text": "Given a sequence of lemmas and any subset of morphological features, we produce the inflected word forms.", "labels": [], "entities": []}, {"text": "The SMT model parameters are derived from a parallel corpus mapping lemmas and morphological features to the inflected word forms.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.985988199710846}]}, {"text": "As a case study, we focus on Arabic, a morphologically rich language.", "labels": [], "entities": []}, {"text": "Our models can reach 92.1% accuracy starting only with tokenized lemmas and predicting some features, up from 55.0% accuracy without inflecting the lemmas.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9993646740913391}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9979109168052673}]}, {"text": "If all of the gold morphological features are provided as input, our best model achieves 98.9% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9989720582962036}]}, {"text": "This work was funded by a Google research award.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation Setup All of the training data we use is available from the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 71, "end_pos": 103, "type": "DATASET", "confidence": 0.8583141267299652}]}, {"text": "For SMT training and language modeling (LM), we use 200M words from the Arabic Gigaword corpus (LDC2007T40).", "labels": [], "entities": [{"text": "SMT training", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9317707419395447}, {"text": "language modeling (LM)", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.8456325173377991}, {"text": "Arabic Gigaword corpus (LDC2007T40)", "start_pos": 72, "end_pos": 107, "type": "DATASET", "confidence": 0.787083367506663}]}, {"text": "We use 5-grams for all LMs implemented using the SRILM toolkit).", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9049522280693054}]}, {"text": "MADA+TOKAN) is used to preprocess the Arabic text for generation and language modeling.", "labels": [], "entities": [{"text": "MADA+TOKAN", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.5039419134457906}, {"text": "language modeling", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7017830014228821}]}, {"text": "MADA+TOKAN tokenizes, lemmatizes and selects all morphological features in context.", "labels": [], "entities": []}, {"text": "All generation experiments are conducted using the Moses phrase-based SMT system (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.879535436630249}]}, {"text": "The decoding weight optimization is done using a set of 300 Arabic sentences from the 2004 NIST MT evaluation test set (MT04).", "labels": [], "entities": [{"text": "decoding weight optimization", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8632339239120483}, {"text": "NIST MT evaluation test set (MT04)", "start_pos": 91, "end_pos": 125, "type": "DATASET", "confidence": 0.8800379112362862}]}, {"text": "The tuning is based on tokenized Arabic without detokenization.", "labels": [], "entities": []}, {"text": "We use a maximum phrase length of size 4.", "labels": [], "entities": []}, {"text": "We report results on the Arabic side of the 2005 NIST MT evaluation set (MT05), our development set.", "labels": [], "entities": [{"text": "Arabic side of the 2005 NIST MT evaluation set (MT05)", "start_pos": 25, "end_pos": 78, "type": "DATASET", "confidence": 0.7269773508111635}]}, {"text": "We use the Arabic side of MT06 NIST data set for blind test.", "labels": [], "entities": [{"text": "MT06 NIST data set", "start_pos": 26, "end_pos": 44, "type": "DATASET", "confidence": 0.8716002553701401}]}, {"text": "We evaluate using BLEU-1 and BLEU-4 ().", "labels": [], "entities": [{"text": "BLEU-1", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9970123767852783}, {"text": "BLEU-4", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9972547888755798}]}, {"text": "BLEU is a precision-based evaluation metric commonly used in MT research.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9835593104362488}, {"text": "precision-based", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9941307902336121}, {"text": "MT research", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9407848417758942}]}, {"text": "Given the way we define our generation task to exclude reordering and word deletion/addition, BLEU-1 can be interpreted as a measure of word accuracy.", "labels": [], "entities": [{"text": "word deletion/addition", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.7486704215407372}, {"text": "BLEU-1", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9982929825782776}, {"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9244034290313721}]}, {"text": "BLEU-4 is the geometric mean of unigram, bigram, trigram and 4-gram precision.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9891447424888611}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9485186338424683}]}, {"text": "Since Arabic text is generally written without diacritics, we evaluate on undiacritized text only.", "labels": [], "entities": []}, {"text": "In the future, we plan to study generation into diacritized Arabic, a more challenging goal.", "labels": [], "entities": []}, {"text": "Baseline We conducted two baseline experiments.", "labels": [], "entities": []}, {"text": "First, as a degenerate baseline, we only used detokenization to generate the inflected words from LEMMAs.", "labels": [], "entities": []}, {"text": "Second, we used a generation step before detokenization to generate the inflected tokens from LEMMAs.", "labels": [], "entities": []}, {"text": "The BLEU-1/BLEU-4 scores of the two baselines on the MT05 set are 55.04/24.51 and 91.54/82.19.", "labels": [], "entities": [{"text": "BLEU-1", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9987732768058777}, {"text": "BLEU-4", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9972696900367737}, {"text": "MT05 set", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.9677502810955048}]}, {"text": "We get a significant improvement (\u223c35% BLEU-1 & \u223c58% BLEU-4) by using the generation step before detokenization.", "labels": [], "entities": [{"text": "BLEU-1", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9978766441345215}, {"text": "BLEU-4", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9985628724098206}]}, {"text": "Generation with Gold Features We built several SMT systems translating from LEMMAs plus one or more morphological features to Arabic inflected tokens.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9922072291374207}]}, {"text": "We then use the detokenization step to recombine the tokens and produce the surface words.", "labels": [], "entities": []}, {"text": "shows the BLEU scores for MT05 set as LEMMAs plus different morphological features and their combinations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9984126091003418}, {"text": "MT05 set", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.7260182201862335}, {"text": "LEMMAs", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9036877155303955}]}, {"text": "We greedily combined the features based on the performance of each feature separately.", "labels": [], "entities": []}, {"text": "Features with higher performance are combined first.", "labels": [], "entities": []}, {"text": "As expected, the more features are included the better the results.", "labels": [], "entities": []}, {"text": "Oddly, when we add the POS to the feature combination, the performance drops.", "labels": [], "entities": []}, {"text": "That could be explained by the redundancy in information provided by the POS given all the other features and the added sparsity.", "labels": [], "entities": [{"text": "POS", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.8799261450767517}]}, {"text": "Although STT and MOD features hurt the performance when added incrementally to the feature combination, removing them from the complete feature set led to a drop in performance.", "labels": [], "entities": [{"text": "STT", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.7812191247940063}]}, {"text": "We suspect that there are synergies in combining different features.", "labels": [], "entities": []}, {"text": "We plan to investigate this point extensively in the future.", "labels": [], "entities": []}, {"text": "BLEU scores are very high because the input is golden in terms of word order, lemma choice and features.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9841648936271667}]}, {"text": "These scores should be seen as the upper limit of our model's performance.", "labels": [], "entities": []}, {"text": "Most of the errors are detokenization and word form underspecification errors.", "labels": [], "entities": []}, {"text": "Generation with Predicted Features We compare results of generation with a variety of predicted features (see).", "labels": [], "entities": []}, {"text": "The results show that using predicted features can help improve the generation quality over the baseline in some cases, e.g.,  when the LEMMAs are enriched with CAS, ASP, PER, VOX or MOD features.", "labels": [], "entities": []}, {"text": "Our best performer is LEMMA+MOD.", "labels": [], "entities": [{"text": "LEMMA+MOD", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.7569863597551981}]}, {"text": "Unlike gold features, greedily combining predicted features hurts the performance and the more features added the worse the performance.", "labels": [], "entities": []}, {"text": "One explanation is that each feature is predicted independently which may lead to incompatible feature values.", "labels": [], "entities": []}, {"text": "In the future, we plan to investigate ways of combining features that could help performance such predicting more than one feature together and filtering out bad feature combinations.", "labels": [], "entities": []}, {"text": "The feature prediction accuracy does not always correlate with the generation performance, e.g., CAS has lower accuracy than GEN, but has a relatively higher BLEU score.", "labels": [], "entities": [{"text": "feature prediction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.6222783774137497}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.6381945013999939}, {"text": "CAS", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.7896302938461304}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9964590668678284}, {"text": "GEN", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.718392550945282}, {"text": "BLEU", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.9991359114646912}]}, {"text": "This maybe due to the fact that some features are mostly realized as diacritics (CAS) which are ignored in our evaluation.", "labels": [], "entities": []}, {"text": "Blind Test Set To validate our results, we applied different versions of our system to a blind test set (MT06  lower than our development set, but the trends and conclusions are consistent.", "labels": [], "entities": [{"text": "Blind Test Set", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.7262988487879435}, {"text": "MT06", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.7324082255363464}]}], "tableCaptions": [{"text": " Table 1: Accuracy (%) of feature prediction starting from Ara-", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987668991088867}, {"text": "feature prediction", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7636661231517792}]}, {"text": " Table 2: Results of generation from gold Arabic lemmas", "labels": [], "entities": []}, {"text": " Table 3: Results of generation from LEMMA plus different sets", "labels": [], "entities": []}]}