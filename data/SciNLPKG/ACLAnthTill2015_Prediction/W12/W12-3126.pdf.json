{"title": [{"text": "CCG Syntactic Reordering Models for Phrase-based Machine Translation", "labels": [], "entities": [{"text": "Syntactic Reordering", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.6353899240493774}, {"text": "Phrase-based Machine Translation", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.8342300454775492}]}], "abstractContent": [{"text": "Statistical phrase-based machine translation requires no linguistic information beyond word-aligned parallel corpora (Zens et al., 2002; Koehn et al., 2003).", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.6288672784964243}]}, {"text": "Unfortunately, this linguistic agnosticism often produces un-grammatical translations.", "labels": [], "entities": []}, {"text": "Syntax, or sentence structure, could provide guidance to phrase-based systems, but the \"non-constituent\" word strings that phrase-based decoders manipulate complicate the use of most recursive syntactic tools.", "labels": [], "entities": []}, {"text": "We address these issues by using Combinatory Categorial Grammar, or CCG, (Steedman, 2000), which has a much more flexible notion of constituency, thereby providing more labels for putative non-constituent multiword translation phrases.", "labels": [], "entities": []}, {"text": "Using CCG parse charts, we train a syntactic analogue of a lexicalized reordering model by labelling phrase table entries with multiword labels and demonstrate significant improvements in translating between Urdu and En-glish, two language pairs with divergent sentence structure.", "labels": [], "entities": [{"text": "translating", "start_pos": 188, "end_pos": 199, "type": "TASK", "confidence": 0.9721220135688782}]}], "introductionContent": [{"text": "Statistical phrase-based machine translation (PMT) is attractive, as it requires no linguistic information beyond word-aligned parallel corpora (;.", "labels": [], "entities": [{"text": "Statistical phrase-based machine translation (PMT)", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.6928666532039642}]}, {"text": "Unfortunately, this linguistic agnosticism leaves phrase-based systems with no precise characterization of the word order relationships between languages, often leading to ungrammatical translations.", "labels": [], "entities": []}, {"text": "Syntax could provide guidance to phrase-based systems, by steering them towards reorderings that reflect the structural relationships between languages, but using syntax to guide a phrase-based system is problematic.", "labels": [], "entities": []}, {"text": "Phrasebased systems build the result incrementally from the beginning of the target string to the end, and the intermediate strings need not constitute complete traditional syntactic constituents.", "labels": [], "entities": []}, {"text": "It is difficult to reconcile traditional recursive syntactic processing with this regime, because not all intermediate strings considered by the decoder would even have a syntactic category to assess.", "labels": [], "entities": []}, {"text": "As a result, most phrase-based decoders control reordering using simple distancebased distortion models, which penalize all reordering equally, and lexicalized reordering models (), which probabilistically score various reordering configurations conditioned on specific lexical translations.", "labels": [], "entities": []}, {"text": "While undoubtedly better than nothing, these models perform poorly when languages diverge considerably in sentence structure.", "labels": [], "entities": []}, {"text": "Distance-based distortion models are too coarse-grained to distinguish correct from incorrect reordering, while lexical reordering models suffer from data sparsity and fail to capture more general patterns.", "labels": [], "entities": []}, {"text": "We argue that finding away to label translation phrases with syntactic labels will abstract over the observed reordering configurations thereby address both all three deficiencies of granularity, data sparsity and lack of generality.", "labels": [], "entities": []}, {"text": "The present work presents a novel syntactic analogue of the lexicalized reordering model that uses multiword syntactic labels to capture the general reordering patterns between two languages with very different word order.", "labels": [], "entities": []}, {"text": "We accomplish this by using Combinatory Categorial Grammar, or CCG), a word-centered syntax that allows a great deal of flexibility in how sentence analyses are formed.", "labels": [], "entities": []}, {"text": "Syntactic derivations in CCG are massively spuriously ambiguous, i.e., there are many ways to derive the same semantic analysis of a sentence, similar to how a mathematical equation can be reduced by canceling out variables in different orders.", "labels": [], "entities": []}, {"text": "Despite its name, spurious ambiguity is a benefit to us, as it provides many different labelled bracketings for the same dependency graph of the same sentence, thereby increasing the chance that any substring of that sentence will have a syntactic label.", "labels": [], "entities": []}, {"text": "Our approach exploits this property of CCG to derive multiword CCG syntactic labels for target translation strings in a phrase table, thus providing a firmer basis on which to collect syntactic reordering statistics.", "labels": [], "entities": []}, {"text": "In particular: \u2022 We show how CCG can derive constituent labels for target-side phrase-table entries that are often lamented as \"non-constituents\" or as \"crossing a phrase boundary\".", "labels": [], "entities": []}, {"text": "\u2022 Our CCG categories are not limited to singleword supertags.", "labels": [], "entities": []}, {"text": "Rather, as these labels are drawn from CCG parse charts, they can span multiple words.", "labels": [], "entities": []}, {"text": "Further, the labels are tailored specifically to each translation constituent's boundaries (Section 2.1).", "labels": [], "entities": []}, {"text": "As a consequence, \u224870% of phrase table entries receive a single syntactic label (Section 5), largely removing the terminological inconsistency of calling lexical translation constituents \"phrases\".", "labels": [], "entities": []}, {"text": "Now, more of them actually are syntactic phrases.", "labels": [], "entities": []}, {"text": "\u2022 We use these labels to train a target-language bidirectional reordering model over CCG syntactic sequences (Section 3), which, when added to the baseline system, is found to be superior to systems that use both lexicalized reordering models and supertag reordering models (Section 5).", "labels": [], "entities": []}, {"text": "With only minor modifications, we incorporate these enhancements into a state-of-the-art PMT decoder ( , achieving significant improvements over two competitive baselines in an UrduEnglish translation task (Sections 5).", "labels": [], "entities": [{"text": "PMT decoder", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.9190669655799866}, {"text": "UrduEnglish translation task", "start_pos": 177, "end_pos": 205, "type": "TASK", "confidence": 0.7670176227887472}]}, {"text": "This language pair was chosen to highlight the promise of this approach for languages with considerable, but syntactically governed, word-order differences to one another.", "labels": [], "entities": []}, {"text": "Finally, in a small discussion we provide qualitative evidence that the improvements in automatic metric scores correspond to real gains in target language fluency.", "labels": [], "entities": [{"text": "automatic metric scores", "start_pos": 88, "end_pos": 111, "type": "METRIC", "confidence": 0.752999742825826}]}], "datasetContent": [{"text": "We empirically validate our technique by translating from Urdu into English.", "labels": [], "entities": []}, {"text": "Urdu has a canonical word order of SOV -subject, object(s), verb -whereas English has SVO, leading to indefinitely long distances between corresponding verbs and objects.", "labels": [], "entities": []}, {"text": "This language pair is therefore a strong test case fora reordering model.", "labels": [], "entities": []}, {"text": "For decoding we use Moses ( ), a state-of-the-art PMT decoder, with IRST LM for language model inference.", "labels": [], "entities": [{"text": "IRST LM", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.7808055281639099}, {"text": "language model inference", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.6641783515612284}]}, {"text": "For Urdu-English parallel data, we use the OpenMT 2008 training set which consists of 88 thousand sentence-level translations and a translation dictionary of \u2248114 thousand word and phrase translations.", "labels": [], "entities": [{"text": "OpenMT 2008 training set", "start_pos": 43, "end_pos": 67, "type": "DATASET", "confidence": 0.9640104174613953}]}, {"text": "We use half of the OpenMT 2008 UrduEnglish evaluation data for development and perform development testing on the other half.", "labels": [], "entities": [{"text": "OpenMT 2008 UrduEnglish evaluation data", "start_pos": 19, "end_pos": 58, "type": "DATASET", "confidence": 0.9444515943527222}]}, {"text": "Both halves are \u2248900 sentences long and were balanced to contain approximately the same number of tokens.", "labels": [], "entities": []}, {"text": "Our blind test set is the entire OpenMT 2009 Urdu-English evaluation set.", "labels": [], "entities": [{"text": "OpenMT 2009 Urdu-English evaluation set", "start_pos": 33, "end_pos": 72, "type": "DATASET", "confidence": 0.9716095566749573}]}, {"text": "All evaluation sets had 4 reference translations for each tuning or testing instance.", "labels": [], "entities": []}, {"text": "All system component weights were tuned using minimum error-rate training, with three tuning runs for each condition.", "labels": [], "entities": []}, {"text": "The data was normalized, tokenized and the English sentences were lowercased, As a baseline, we train a standard phrase-based system with a bidirectional MSD lexicalized reordering model using word-based extraction.", "labels": [], "entities": [{"text": "word-based extraction", "start_pos": 193, "end_pos": 214, "type": "TASK", "confidence": 0.7236673533916473}]}, {"text": "Our CCG-augmented reordering system has all of the model components of the baseline, as well as a bidirectional orientation reordering model over targetside multiword syntactic labels.", "labels": [], "entities": []}, {"text": "To directly test the effect of using CCG parse charts -as opposed to simply using a CCG supertagger -we also added a CCG supertag bidirectional MSD reordering model to the baseline set-up.", "labels": [], "entities": []}, {"text": "All systems were tuned and tested with distortion limit of 15 words, and test runs were performed with and without 200-best minimum Bayes' risk (MBR) hypothesis selection ().", "labels": [], "entities": [{"text": "distortion limit", "start_pos": 39, "end_pos": 55, "type": "METRIC", "confidence": 0.9467251598834991}, {"text": "200-best minimum Bayes' risk (MBR) hypothesis selection", "start_pos": 115, "end_pos": 170, "type": "METRIC", "confidence": 0.8241283628675673}]}, {"text": "To acquire CCG labels for our English parallel data, we use the C&C CCG toolkit of.", "labels": [], "entities": [{"text": "C&C CCG toolkit", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.7133774638175965}]}, {"text": "We build CCG parse charts by reworking the normal-form derivations from the C&C parser in all spuriously ambiguous ways, as described in Section 2.1.", "labels": [], "entities": []}, {"text": "For supertags, we tag with the C&C supertagger.", "labels": [], "entities": [{"text": "C&C supertagger", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.9162084460258484}]}, {"text": "Rather than training separate phrase tables for our CCG systems, however, we instead decorate the baseline phrase tables with CCG multiword labels or supertags.", "labels": [], "entities": []}, {"text": "To smooth over parsing and tagging errors, we only use those labels whose relative frequency (rf) is sufficiently high w.r.t. the most frequent label for that phrase pair LAB* . More precisely, for each phrase pair, we use the set of labels: {LAB |rf(LAB ) \u2265 \u03b2 \u00b7 rf(LAB* )} This is reminiscent of the \u03b2-best tagging approach of (), but performed in a batch process when creating the syntactic phrase tables (both supertag and CCG chart-derived).", "labels": [], "entities": []}, {"text": "We set: Case-insensitive BLEU-4, METEOR, TER and hypothesis/reference length ratio (LENGTH) fora lexicalized reordering baseline (LR), a system with only a distance-based distortion model (NO-LR), a system with an additional CCG supertag reordering model (ST+LR) and our system with an additional CCG chart-derived reordering model (CCG+LR).", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9500846266746521}, {"text": "METEOR", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9959869980812073}, {"text": "TER", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9970619082450867}, {"text": "hypothesis/reference length ratio (LENGTH", "start_pos": 49, "end_pos": 90, "type": "METRIC", "confidence": 0.6839755518095834}]}, {"text": "Systems were run with (left of slash) and without (right of slash) 200-best-list MBR hypothesis selection.", "labels": [], "entities": [{"text": "MBR hypothesis selection", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6256979703903198}]}, {"text": "All boldfaced results were found to be significantly better than the baseline at \u2265 the 95% confidence level using method described in) with 3 separate MERT tuning runs for each system.", "labels": [], "entities": [{"text": "MERT", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.8550141453742981}]}, {"text": "Non-boldfaced numbers are statistically indistinguishable from (or worse than) the baseline.", "labels": [], "entities": []}, {"text": "\u03b2 = 0.5 in all of our CCG experiments.", "labels": [], "entities": []}, {"text": "To minimize disruption to the Moses decoder (which only supports single-word labels in phrasebased mode), we project multiword labels across the words they label as single-word factors with bookkeeping characters, similar to the \"microtag\" annotations of asynchronous factored translation models (.", "labels": [], "entities": []}, {"text": "We modified to the decoder to reassemble the multiple single-word factors into a single label before querying the reordering model.", "labels": [], "entities": []}, {"text": "As an example, we might have the phrase pair le v\u00e9lo rouge \u21d4 the|NP( red|NP+ bike|NP) . Before querying the reordering model, the factor sequence NP( NP+ NP) is collapsed into the single, multiword label 'NP' by the rule schema X( . .", "labels": [], "entities": []}, {"text": "We train a language model using all of the WMT 2011 NEWSCRAWL, NEWSCOMENTARY and EU-ROPARL monolingual data, 10 tokenized and lowercased as above, but de-duplicated to address the redundancy of the Web-crawled portion of that data set.", "labels": [], "entities": [{"text": "WMT 2011 NEWSCRAWL", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.8661120732625326}, {"text": "NEWSCOMENTARY", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.8792068362236023}, {"text": "EU-ROPARL monolingual data", "start_pos": 81, "end_pos": 107, "type": "DATASET", "confidence": 0.8040989637374878}]}, {"text": "We also train a separate language model on the English portion of the Urdu-English parallel corpus (minus the dictionary entries), and interpolate the two models by optimizing perplexity on our tuning set.", "labels": [], "entities": []}, {"text": "lists our results, where we see significant improvement over both of our baselines, lexicalized reordering (LR) and supertag reordering plus lexicalized reordering (ST+LR).", "labels": [], "entities": []}, {"text": "To test the effects of the lexicalized reordering model itself, we also evaluate a system with no lexicalized reordering model (only a distance-based distortion model).", "labels": [], "entities": []}, {"text": "This last system (a system which almost always prefers not to reorder) is considerably worse than all other systems, demonstrating the need for non-monotonic reordering configurations when accounting for the Urdu-English data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Case-insensitive BLEU-4, METEOR, TER and hypothesis/reference length ratio (LENGTH) for a lexicalized reordering", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9594477415084839}, {"text": "METEOR", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9983568787574768}, {"text": "TER", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9977447986602783}, {"text": "hypothesis/reference length ratio", "start_pos": 51, "end_pos": 84, "type": "METRIC", "confidence": 0.6367290079593658}, {"text": "LENGTH", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.628052830696106}]}]}