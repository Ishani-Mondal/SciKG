{"title": [{"text": "Hybrid Combination of Constituency and Dependency Trees into an Ensemble Dependency Parser", "labels": [], "entities": []}], "abstractContent": [{"text": "Dependency parsing has made many advancements in recent years, in particular for English.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9151418209075928}]}, {"text": "There area few dependency parsers that achieve comparable accuracy scores with each other but with very different types of errors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9981257319450378}]}, {"text": "This paper examines creating anew dependency structure through ensemble learning using a hybrid of the outputs of various parsers.", "labels": [], "entities": []}, {"text": "We combine all tree outputs into a weighted edge graph, using 4 weighting mechanisms.", "labels": [], "entities": []}, {"text": "The weighted edge graph is the input into our ensemble system and is a hybrid of very different parsing techniques (constituent parsers, transition-based dependency parsers, and a graph-based parser).", "labels": [], "entities": []}, {"text": "From this graph we take a maximum spanning tree.", "labels": [], "entities": []}, {"text": "We examine the new dependency structure in terms of accuracy and errors on individual part-of-speech values.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9989377856254578}, {"text": "errors", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9481570720672607}]}, {"text": "The results indicate that using a greater number of more varied parsers will improve accuracy results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9985591769218445}]}, {"text": "The combined ensemble system, using 5 parsers based on 3 different parsing techniques, achieves an accuracy score of 92.58%, beating all single parsers on the Wall Street Journal section 23 test set.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 99, "end_pos": 113, "type": "METRIC", "confidence": 0.9837326109409332}, {"text": "Wall Street Journal section 23 test set", "start_pos": 159, "end_pos": 198, "type": "DATASET", "confidence": 0.9678775497845241}]}, {"text": "Additionally, the ensemble system reduces the average relative error on selected POS tags by 9.82%.", "labels": [], "entities": [{"text": "relative error", "start_pos": 54, "end_pos": 68, "type": "METRIC", "confidence": 0.8905312120914459}]}], "introductionContent": [{"text": "Dependency parsing has made many advancements in recent years.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9315218925476074}]}, {"text": "A prime reason for the quick advancement has been the CoNLL shared task competitions.", "labels": [], "entities": [{"text": "CoNLL shared task", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.5318426191806793}]}, {"text": "These competitions gave the community a common training/testing framework along with many open source systems.", "labels": [], "entities": []}, {"text": "These systems have, for certain languages, achieved fairly high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9982686042785645}]}, {"text": "Many of the top systems have comparable accuracy but vary on the types of errors they make.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.999147891998291}]}, {"text": "The approaches used in the shared task vary from graph-based techniques to transition-based techniques to the conversion of constituent trees produced by state-of-the-art constituent parsers.", "labels": [], "entities": []}, {"text": "This varied error distribution makes dependency parsing a prime area for the application of new hybrid and ensemble algorithms.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7236140370368958}]}, {"text": "Increasing accuracy of dependency parsing often is in the realm of feature tweaking and optimization.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9984880685806274}, {"text": "dependency parsing", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7465228736400604}]}, {"text": "The idea behind ensemble learning is to take the best of each parser as it currently is and allow the ensemble system to combine the outputs to form a better overall parse using prior knowledge of each individual parser.", "labels": [], "entities": []}, {"text": "This is often done by different weighting or voting schemes.", "labels": [], "entities": []}], "datasetContent": [{"text": "Much of the current progress in dependency parsing has been a result of the availability of common data sets in a variety of languages, made available through the CoNLL shared task ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8506456315517426}]}, {"text": "This data is in 13 languages and 7 language families.", "labels": [], "entities": []}, {"text": "Later shared tasks also released data in other genres to allow for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.7704876661300659}]}, {"text": "The availability of standard competition, gold level, data has been an important factor in dependency based research.", "labels": [], "entities": []}, {"text": "For this study we use the English CoNLL data.", "labels": [], "entities": [{"text": "English CoNLL data", "start_pos": 26, "end_pos": 44, "type": "DATASET", "confidence": 0.8471694389979044}]}, {"text": "This data comes from the Wall Street Journal (WSJ) section of the Penn treebank (.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) section of the Penn treebank", "start_pos": 25, "end_pos": 79, "type": "DATASET", "confidence": 0.9343220645731146}]}, {"text": "All parsers are trained on sections 02-21 of the WSJ except for the Stanford parser which uses sections 01-21.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.9083833694458008}]}, {"text": "Charniak, Stanford and Zpar use pre-trained models ec50spfinal, wsjPCFG.ser.gz, english.tar.gz respectively.", "labels": [], "entities": []}, {"text": "For testing we use section 23 of the WSJ for comparability reasons with other papers.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.9236422777175903}]}, {"text": "This test data contains 56,684 tokens.", "labels": [], "entities": []}, {"text": "For tuning we use section 22.", "labels": [], "entities": []}, {"text": "This data is used for determining some of the weighting features.", "labels": [], "entities": []}, {"text": "As an artifact of the CoNLL shared tasks competition, two standard metrics for comparing dependency parsing systems emerged.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.6720577329397202}]}, {"text": "Labeled attachment score (LAS) and unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "Labeled attachment score (LAS)", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.7930292636156082}, {"text": "unlabeled attachment score (UAS)", "start_pos": 35, "end_pos": 67, "type": "METRIC", "confidence": 0.8411781986554464}]}, {"text": "UAS studies the structure of a dependency tree and assesses whether the output has the correct head and dependency arcs.", "labels": [], "entities": [{"text": "UAS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5871636271476746}]}, {"text": "In addition to the structure score in UAS, LAS also measures the accuracy of the dependency labels on each arc.", "labels": [], "entities": [{"text": "UAS", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.7427310347557068}, {"text": "LAS", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.8981223106384277}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9993366599082947}]}, {"text": "A third, but less common metric, is used to judge the percentage of sentences that are completely correct in regards to their LAS score.", "labels": [], "entities": [{"text": "LAS score", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9785481095314026}]}, {"text": "For this paper since we are primarily concerned with the merging of tree structures we only evaluate UAS ().", "labels": [], "entities": [{"text": "UAS", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.8771026730537415}]}], "tableCaptions": [{"text": " Table 2: Our baseline parsers and corresponding UAS  used in our ensemble experiments", "labels": [], "entities": [{"text": "UAS", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9046017527580261}]}]}