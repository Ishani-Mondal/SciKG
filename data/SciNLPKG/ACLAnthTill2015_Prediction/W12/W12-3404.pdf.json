{"title": [{"text": "Unsupervised frame based semantic role induction: application to French and English", "labels": [], "entities": [{"text": "Unsupervised frame based semantic role induction", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.5873492260773977}]}], "abstractContent": [{"text": "This paper introduces a novel unsupervised approach to semantic role induction that uses a generative Bayesian model.", "labels": [], "entities": [{"text": "semantic role induction", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.8227898279825846}]}, {"text": "To the best of our knowledge, it is the first model that jointly clusters syntactic verbs arguments into semantic roles, and also creates verbs classes according to the syntactic frames accepted by the verbs.", "labels": [], "entities": []}, {"text": "The model is evaluated on French and English, outperforming, in both cases, a strong baseline.", "labels": [], "entities": []}, {"text": "On English, it achieves results comparable to state-of-the-art unsuper-vised approaches to semantic role induction.", "labels": [], "entities": [{"text": "semantic role induction", "start_pos": 91, "end_pos": 114, "type": "TASK", "confidence": 0.7364003856976827}]}], "introductionContent": [], "datasetContent": [{"text": "We evaluate our model both on English to situate our approach with respect to the state of the art; and on French to demonstrate its portability to other languages.", "labels": [], "entities": []}, {"text": "The model's parameters have been tuned with a few rounds of trial-and-error on the English development corpus: For the hyper-parameters, we set \u03b1 F = 0.5, \u03b1 R = 1.e \u22123 , \u03b1 V = 1.e \u22127 , \u03b1 V o = 1.e \u22123 , \u03b1 D = 1.e \u22128 and \u03b1 W = 0.5.", "labels": [], "entities": [{"text": "English development corpus", "start_pos": 83, "end_pos": 109, "type": "DATASET", "confidence": 0.9275694290796915}]}, {"text": "For the evaluation on French, we only changed the \u03b1 F and \u03b1 W parameters.", "labels": [], "entities": [{"text": "French", "start_pos": 22, "end_pos": 28, "type": "DATASET", "confidence": 0.9774263501167297}, {"text": "F", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.7522648572921753}]}, {"text": "In order to reflect the rather uniform distribution of verb instances across verb classes we set \u03b1 F to 1.", "labels": [], "entities": []}, {"text": "Moreover, we set \u03b1 W to 0.001 because of the smaller number of words and roles in the French corpus.", "labels": [], "entities": [{"text": "French corpus", "start_pos": 86, "end_pos": 99, "type": "DATASET", "confidence": 0.8441458344459534}]}, {"text": "The number of roles and frames were chosen based on the properties of each corpus.", "labels": [], "entities": []}, {"text": "We set number of roles to 40 and 10, and the number of frames to 300 and 60 for English and French respectively.", "labels": [], "entities": [{"text": "frames", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9484238624572754}]}, {"text": "As done in and, we use purity and collocation measures to assess the quality of our role induction process.", "labels": [], "entities": [{"text": "purity", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9931814074516296}, {"text": "role induction process", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.7972584764162699}]}, {"text": "For each verb, the purity of roles' clusters is computed as follows: where Ci is the set of arguments in the i th cluster found, G j is the set of arguments in the j th gold class, and N is the number of argument instances.", "labels": [], "entities": [{"text": "purity", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9753015637397766}]}, {"text": "Ina similar way, the collocation of roles' clusters is computed as follows: Then, each score is averaged overall verbs.", "labels": [], "entities": []}, {"text": "In the same way as, we use the micro-average obtained by weighting the scores for individual verbs proportionally to the number of argument instances for that verb.", "labels": [], "entities": []}, {"text": "Finally the F1 measure is the harmonic mean of the aggregated values of purity and collocation:  To evaluate our model on French, we used a manually annotated corpora consisting on sentences from the Paris 7 Treebank (), containing verbs extracted from the gold standard V-GOLD ( selected and annotated with VerbNet-style thematic roles.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.984297901391983}, {"text": "Paris 7 Treebank", "start_pos": 200, "end_pos": 216, "type": "DATASET", "confidence": 0.957536002000173}]}, {"text": "In some cases, the annotated roles were obtained by merging some of the VerbNet roles (e.g., Actor, Actor1 and Actor2 are merged); or by grouping together classes sharing the same thematic grids.", "labels": [], "entities": []}, {"text": "The resulting roles assignment groups 116 verbs into 12 VerbNet classes, each associated with a unique thematic grid.", "labels": [], "entities": []}, {"text": "shows the set of roles used and their relation to VerbNet roles.", "labels": [], "entities": []}, {"text": "This constitutes our gold evaluation corpus.", "labels": [], "entities": [{"text": "gold evaluation corpus", "start_pos": 21, "end_pos": 43, "type": "DATASET", "confidence": 0.7932006120681763}]}, {"text": "The baseline model is the \"syntactic function\" used for instance in, which simply clusters predicate arguments according to the dependency relation to their head.", "labels": [], "entities": []}, {"text": "This is a standard baseline for unsupervised SRL, which, although simple, has been shown difficult to outperform.", "labels": [], "entities": [{"text": "SRL", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9601843357086182}]}, {"text": "As done in previous work, it is implemented by allocating a different cluster to each of the 10 most frequent syntactic relations, and one extra cluster for all the other relations.", "labels": [], "entities": []}, {"text": "Evaluation results are shown in.", "labels": [], "entities": []}, {"text": "The proposed model significantly outperforms the deterministic baseline, which validates the unsupervised learning process.: Comparison of the Syntactic Function baseline with the proposed system initialized randomly, evaluated with gold parses and argument identification (French).", "labels": [], "entities": [{"text": "argument identification", "start_pos": 249, "end_pos": 272, "type": "TASK", "confidence": 0.6767540723085403}]}, {"text": "We made our best to follow the setup used in previous work, in order to compare with the current state of the art.", "labels": [], "entities": []}, {"text": "The data used is the standard CoNLL 2008 shared task () version of Penn Treebank WSJ and PropBank.", "labels": [], "entities": [{"text": "CoNLL 2008 shared task", "start_pos": 30, "end_pos": 52, "type": "DATASET", "confidence": 0.8493889272212982}, {"text": "Penn Treebank WSJ", "start_pos": 67, "end_pos": 84, "type": "DATASET", "confidence": 0.9793622692426046}, {"text": "PropBank", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.7994325757026672}]}, {"text": "Our model is evaluated on gold generated parses, using the gold PropBank annotations.", "labels": [], "entities": []}, {"text": "In PropBank, predicates are associated with a set of roles, where roles A2-A5 or AA are verb specific, while adjuncts roles (AM) are consistent across verbs.", "labels": [], "entities": [{"text": "AA", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9336897134780884}]}, {"text": "Besides, roles A0 and A1 attempt to capture Proto-Agent and Proto-Patient roles, and thus are more valid across verbs and verb instances than A2-A5 roles.", "labels": [], "entities": []}, {"text": "reports the evaluation results of the proposed model along with those of the baseline system and of some of the latest state-of-the-art results.: Comparison of the proposed system (last 2 rows) with other unsupervised semantic role inducers evaluated on gold parses and argument identification.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 270, "end_pos": 293, "type": "TASK", "confidence": 0.717478409409523}]}, {"text": "We can first note that, despite our efforts to reproduce the same baseline, there is still a difference between our baseline (Synt.Func.) and the baseline reported in The other results respectively correspond to the Split Merge approach presented in) (Split Merge), the Graph Partitioning algorithm (Graph Part.) presented in (Lang and Lapata, 2011b), and two Bayesian approaches presented in, which achieve the best current unsupervised SRL results.", "labels": [], "entities": [{"text": "SRL", "start_pos": 438, "end_pos": 441, "type": "TASK", "confidence": 0.939295768737793}]}, {"text": "The first such model (TK-Bay.1) clusters argument fillers and directly maps some syntactic labels to semantic roles for some adjunct like modifiers that are explicitly represented in the syntax, while the second model (TK-Bay.2) does not include these two features.", "labels": [], "entities": []}, {"text": "Two versions of the proposed model are reported in the last rows of: one with random (uniform) initialization of all variables, and the other with deterministic initialization of all R i from the syntactic function.", "labels": [], "entities": []}, {"text": "Indeed, although many unsupervised system are very sensitive to initialization, we observe that in the proposed model, unsupervised inference reaches reasonably good performances even with a knowledge-free initialization.", "labels": [], "entities": [{"text": "initialization", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.9740556478500366}]}, {"text": "Furthermore, when initialized with the strong deterministic baseline, the model still learns new evidences and improves over the baseline to give comparable results to the best unsupervised state-of-the-art systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: VerbNet role groups (French).", "labels": [], "entities": []}, {"text": " Table 2. The proposed model significantly  outperforms the deterministic baseline, which vali- dates the unsupervised learning process.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of the Syntactic Function baseline  with the proposed system initialized randomly, evaluated  with gold parses and argument identification (French).", "labels": [], "entities": [{"text": "argument identification", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.6668418496847153}]}, {"text": " Table 3: Comparison of the proposed system (last 2 rows)  with other unsupervised semantic role inducers evaluated  on gold parses and argument identification.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.725458636879921}]}]}