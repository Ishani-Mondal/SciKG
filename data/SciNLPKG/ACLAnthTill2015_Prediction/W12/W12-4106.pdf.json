{"title": [{"text": "Identifying Untyped Relation Mentions in a Corpus given an Ontology", "labels": [], "entities": [{"text": "Identifying Untyped Relation Mentions in a Corpus", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.9025195155824933}]}], "abstractContent": [{"text": "In this paper we present the SDOI rmi text graph-based semi-supervised algorithm for the task for relation mention identification when the underlying concept mentions have already been identified and linked to an ontology.", "labels": [], "entities": [{"text": "relation mention identification", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.763963500658671}]}, {"text": "To overcome the lack of annotated data, we propose a labelling heuristic based on information extracted from the ontology.", "labels": [], "entities": []}, {"text": "We evaluated the algorithm on the kdd09cma1 dataset using a leave-one-document-out framework and demonstrated an increase in F1 in performance over a co-occurrence based AllTrue baseline algorithm.", "labels": [], "entities": [{"text": "kdd09cma1 dataset", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.7058855444192886}, {"text": "F1", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.9995852112770081}]}, {"text": "An extrinsic evaluation of the predictions suggests a worthwhile precision on the more confidently predicted additions to the ontology.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9990524649620056}]}], "introductionContent": [{"text": "The growing availability of text documents and of ontologies will significantly increase in value once these two resources become deeply interlinked such that all of the concepts and relationships mentioned in each document link to their formal definitions.", "labels": [], "entities": []}, {"text": "This type of semantic information can be used, for example, to aid information retrieval, textual entailment, text summarization, and ontology engineering).", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.7269132286310196}, {"text": "textual entailment", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7509765923023224}, {"text": "text summarization", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.755001574754715}]}, {"text": "An obstacle to this vision of semantically grounded documents however is the significant amount of effort required of domain experts to semantically annotate the text ().", "labels": [], "entities": []}, {"text": "Some automation of the annotation task is a precondition to the envisioned future of deeply interlinked information.", "labels": [], "entities": []}, {"text": "Fortunately, the task of linking concept mentions to their referent in an ontology has matured.", "labels": [], "entities": []}, {"text": "Far less progress has been made on the task of linking of relation mentions to the referent relation in a knowledge base.", "labels": [], "entities": [{"text": "linking of relation mentions", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.8518252372741699}]}, {"text": "To overcome the lack of explicit annotation of relation mentions, we propose the use of a data labelling heuristic that assigns a TRUE or FALSE label if the candidate mention refers to a link that exists or does not exist in the ontology.", "labels": [], "entities": [{"text": "TRUE", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9939127564430237}, {"text": "FALSE label", "start_pos": 138, "end_pos": 149, "type": "METRIC", "confidence": 0.9621768891811371}]}, {"text": "SDOI RMI .is related to proposals by ( and) except that their proposal attempt to both identify and to classify relation mentions.", "labels": [], "entities": [{"text": "SDOI RMI", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.607188880443573}]}, {"text": "By only tackling the first (identification) portion of the task our 1 SDOI is for Supervised Document to Ontology Interlinking algorithm can identify relation mentions of types that are not yet present (or are poorly represented) in the ontology.", "labels": [], "entities": []}, {"text": "An extrinsic evaluation of the usability of identified relation mentions to update an ontology provides evidence that SDOI RMI 's performance levels can contribute to a real-world setting.", "labels": [], "entities": []}, {"text": "Our envisioned real-world application is to assist a knowledge engineer to process anew set of documents by receiving a ranked list of candidate relation mentions not yet in the ontology.", "labels": [], "entities": []}, {"text": "With such a list, the knowledge engineer could dedicate more attention to comprehending the meaning of the passages that (very likely) contain high-quality relation mention candidates.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: we first define our proposed algorithm: SDOI rmi ,, and conclude with an empirical analysis of its performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "In  Similar to evaluation of SDOI's two other component algorithms for concept mention identification and linking, we use a leave-onedocument-out method on the kdd09cma1 corpus.", "labels": [], "entities": [{"text": "concept mention identification", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.6412510573863983}]}, {"text": "For each unseen document, we predict which of its binary relation mention candidates (with linked concept mentions) already exist in the ontology.", "labels": [], "entities": []}, {"text": "Those relations that do not exist in the ontology are proposed candidates for addition to the ontology.", "labels": [], "entities": []}, {"text": "A challenge associated with this task, as found in the concept-mention linking task, is the highly skewed distribution of the labels.", "labels": [], "entities": [{"text": "concept-mention linking task", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.7616842488447825}]}, {"text": "In this case, we do not propose a filtering heuristic to change the training data.", "labels": [], "entities": []}, {"text": "Instead, we propose an algorithmic change by tuning SVMlight's cost-factor parameter that multiplies the training error penalty for misclassification of positive examples.", "labels": [], "entities": []}, {"text": "We set aside three documents to tune the parameter, and based on an analysis to optimize F1 we set the cost-factor to 8.", "labels": [], "entities": [{"text": "F1", "start_pos": 89, "end_pos": 91, "type": "METRIC", "confidence": 0.9988031387329102}]}, {"text": "presents some of the key statistics for the kdd09cma1 from the perspective of relation mention candidates.", "labels": [], "entities": []}, {"text": "The corpus contains 44,896 relation mention candidates.", "labels": [], "entities": []}, {"text": "Of these, which quantifies the task's data skew, only 3.55% of the mention candidates are found in the ontology.", "labels": [], "entities": []}, {"text": "The baseline algorithm that we compare SDOI rml 's performance against on the relation-mention identification task is an unsupervised cooccurrence-based algorithm that predicts all permutations of linked concept mention pairs regardless of distance between them.", "labels": [], "entities": [{"text": "relation-mention identification task", "start_pos": 78, "end_pos": 114, "type": "TASK", "confidence": 0.8091888229052225}]}, {"text": "This is the baseline algorithm compared against in.", "labels": [], "entities": []}, {"text": "We refer to this algorithm as AllTrue.", "labels": [], "entities": []}, {"text": "We also include as a baseline aversion of SDOI rml with a restricted feature space that contains the features originally proposed for TeGRR.", "labels": [], "entities": []}, {"text": "presents the results of the leave-one out performance analysis.", "labels": [], "entities": []}, {"text": "SDOI rml outperforms the baseline algorithm in terms of precision and F1.", "labels": [], "entities": [{"text": "SDOI rml", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7040141522884369}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9995556473731995}, {"text": "F1", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.999648928642273}]}, {"text": "The proposed feature space for SDOI also outperforms the original feature space proposed for TeGRR.", "labels": [], "entities": [{"text": "TeGRR", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.8980823159217834}]}, {"text": "-Leave-one-out performance results on the relation mention identification task on the kdd09cma1 corpus (excluding the three tuning abstracts) by SDOI, SDOI with its feature space restricted to those originally proposed for TeGRR, and the AllTrue baseline.", "labels": [], "entities": [{"text": "relation mention identification task", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.8429790437221527}, {"text": "AllTrue baseline", "start_pos": 238, "end_pos": 254, "type": "DATASET", "confidence": 0.9424860179424286}]}, {"text": "In practice, a common method of applying selflabelled learning is to treat the labelling heuristic as a means to seed a bootstrapped process where subsequent rounds of labelling are based on the most confident predictions by the newly trained model).", "labels": [], "entities": []}, {"text": "Generally, evaluations of this approach have assumed highaccuracy seed labels -either from a small manually curated training set, such as in), or with high-accuracy labelling patterns, such as in.", "labels": [], "entities": []}, {"text": "Each iteration sacrifices some precision for additional recall performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9990192651748657}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9985468983650208}]}, {"text": "In our case a bootstrapped process does not begin with high precision to sacrifice, because of our labelling heuristic does not start with high-precision predictions.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9908490180969238}]}, {"text": "However, we performed a bootstrap experiment by iteratively selecting the 10% of relation mentions that were predicted to be True with the highest likelihood score, and then labelled these candidates as True in the subsequent iteration (even if no direct link existed in the ontology for the corresponding concept pair).", "labels": [], "entities": []}], "tableCaptions": []}