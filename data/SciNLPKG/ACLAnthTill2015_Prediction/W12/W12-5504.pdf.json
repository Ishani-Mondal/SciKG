{"title": [{"text": "End-to-End Sentiment Analysis of Twitter Data", "labels": [], "entities": [{"text": "End-to-End Sentiment Analysis of Twitter", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7679625749588013}]}], "abstractContent": [{"text": "In this paper, we present an end-to-end pipeline for sentiment analysis of a popular micro-blogging website called Twitter.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9629583060741425}]}, {"text": "We acknowledge that much of current research adheres to parts of this pipeline.", "labels": [], "entities": []}, {"text": "However, to the best of our knowledge, there is no work that explores the classifier design issues explored in this paper.", "labels": [], "entities": []}, {"text": "We build a hierarchal cascaded pipeline of three models to label a tweet as one of Objective, Neutral, Positive, Negative class.", "labels": [], "entities": []}, {"text": "We compare the performance of this hierarchal pipeline with that of a 4-way classification scheme.", "labels": [], "entities": []}, {"text": "In addition, we explore the trade-off between making a prediction on lesser number of tweets versus F1-measure.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.998325765132904}]}, {"text": "Overall we show that a cascaded design is better than a 4-way classifier design.", "labels": [], "entities": []}], "introductionContent": [{"text": "Microblogging websites have evolved to become a source of varied kind of information.", "labels": [], "entities": []}, {"text": "This is due to nature of microblogs on which people post real time messages about their opinions on a variety of topics, discuss current issues, complain, and express positive sentiment for products they use in daily life.", "labels": [], "entities": []}, {"text": "In fact, companies manufacturing such products have started to poll these microblogs to get a sense of general sentiment for their product.", "labels": [], "entities": []}, {"text": "Many times these companies study user reactions and reply to users on microblogs.", "labels": [], "entities": []}, {"text": "One challenge is to build technology to detect and summarize an overall sentiment.", "labels": [], "entities": [{"text": "summarize an overall sentiment", "start_pos": 51, "end_pos": 81, "type": "TASK", "confidence": 0.849320650100708}]}, {"text": "In this paper, we look atone such popular micro-blog called Twitter 2 and propose an end-to-end pipeline for classifying tweets into one of four categories: Objective, Neutral, Positive, Negative.", "labels": [], "entities": []}, {"text": "Traditionally, Objective category is defined as text segments containing facts and devoid of opinion ().", "labels": [], "entities": [{"text": "Objective category", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7925237715244293}]}, {"text": "In the context of micro-blogs, we extend this definition to include intelligible text, like \"SAPSPKSAPKOASKOP SECAFLOZ PSOKASPKOA\".", "labels": [], "entities": [{"text": "SAPSPKSAPKOASKOP SECAFLOZ PSOKASPKOA", "start_pos": 93, "end_pos": 129, "type": "DATASET", "confidence": 0.5996043086051941}]}, {"text": "Note, since we are only concerned with sentiment analysis of English language micro-blogs, text in other languages will also fall under the intelligible category and thus under Objective text.", "labels": [], "entities": [{"text": "sentiment analysis of English language micro-blogs", "start_pos": 39, "end_pos": 89, "type": "TASK", "confidence": 0.8852443595727285}]}, {"text": "One option to classify tweets into one of the four aforementioned categories is to simply implement a 4-way classifier.", "labels": [], "entities": []}, {"text": "Another option is to build a cascaded design, stacking 3 classifiers on top of each other: Objective versus Subjective, Polar versus Non-polar and Positive versus Negative.", "labels": [], "entities": []}, {"text": "In this paper, we explore these possibilities of building a classifier.", "labels": [], "entities": []}, {"text": "In addition, we study the trade-off between making predictions on lesser number of examples versus F1-measure.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 99, "end_pos": 109, "type": "METRIC", "confidence": 0.9950540065765381}]}, {"text": "If the confidence of the classifier falls below a threshold, we reserve prediction on that example.", "labels": [], "entities": [{"text": "prediction", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9499830603599548}]}, {"text": "In expectation, this will boost the F1-measure, because we are reserving prediction on harder examples.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9989079236984253}]}, {"text": "But a-priori the relation between the two (threshold and F1-measure) is unclear.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9966844916343689}]}, {"text": "Moreover, it is unclear in which of the aforementioned three designs, this trade-off is least.", "labels": [], "entities": []}, {"text": "We present this relation graphically and show that one of the cascaded designs is significantly better than the other designs.", "labels": [], "entities": []}, {"text": "We use manually annotated Twitter data for our experiments.", "labels": [], "entities": []}, {"text": "Part of the data, Positive, Negative and Neutral labeled tweets were introduced and made publicly available in).", "labels": [], "entities": []}, {"text": "Annotations for tweets belonging to the Objective category are made publicly available through this In this paper, we do not introduce anew feature space or explore new machine learning paradigms for classification.", "labels": [], "entities": []}, {"text": "For feature design and exploration of the best machine learning model, we use our previous work).", "labels": [], "entities": [{"text": "feature design", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7473983764648438}]}], "datasetContent": [{"text": "In this section, we present experiments and results for each of the pipelines described in section 3: 4-way, PNP-only-neutral and PNP-objective-neutral.", "labels": [], "entities": []}, {"text": "Experimental Setup: For all our experiments, we use support vector machines with linear classifier to create the models.", "labels": [], "entities": []}, {"text": "We perform cross-validation to choose the right C value that determines the cost of mis-classifying an example at the time of learning.", "labels": [], "entities": []}, {"text": "We report results on an unseen test set whose distribution is given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of instances of each class used for training and testing", "labels": [], "entities": []}, {"text": " Table 2: Results for different classifier designs as mentioned in section 3. Note all numbers are  rounded off to 2 significant digits.", "labels": [], "entities": []}]}