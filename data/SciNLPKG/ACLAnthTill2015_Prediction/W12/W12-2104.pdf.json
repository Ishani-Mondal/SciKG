{"title": [{"text": "A Demographic Analysis of Online Sentiment during Hurricane Irene", "labels": [], "entities": [{"text": "Demographic Analysis of Online Sentiment during Hurricane Irene", "start_pos": 2, "end_pos": 65, "type": "TASK", "confidence": 0.7340738587081432}]}], "abstractContent": [{"text": "We examine the response to the recent natural disaster Hurricane Irene on Twitter.com.", "labels": [], "entities": []}, {"text": "We collect over 65,000 Twitter messages relating to Hurricane Irene from August 18th to August 31st, 2011, and group them by location and gender.", "labels": [], "entities": []}, {"text": "We train a sentiment classi-fier to categorize messages based on level of concern, and then use this classifier to investigate demographic differences.", "labels": [], "entities": []}, {"text": "We report three principal findings: (1) the number of Twit-ter messages related to Hurricane Irene in directly affected regions peaks around the time the hurricane hits that region; (2) the level of concern in the days leading up to the hurri-cane's arrival is dependent on region; and (3) the level of concern is dependent on gender, with females being more likely to express concern than males.", "labels": [], "entities": []}, {"text": "Qualitative linguistic variations further support these differences.", "labels": [], "entities": []}, {"text": "We conclude that social media analysis provides a viable, real-time complement to traditional survey methods for understanding public perception towards an impending disaster.", "labels": [], "entities": []}], "introductionContent": [{"text": "In 2011, natural disasters cost the United States more than 1,000 lives and $52 billion.", "labels": [], "entities": []}, {"text": "The number of disasters costing over $1 billion in 2011 (twelve) is more than in the entire decade of the 1980s.", "labels": [], "entities": []}, {"text": "As the number of people living in disasterprone areas grows, it becomes increasingly important to have reliable, up-to-the-minute assessments of emergency preparedness during impending disas-ters.", "labels": [], "entities": []}, {"text": "Understanding issues such as personal risk perception, preparedness, and evacuation plans helps public agencies better tailor emergency warnings, preparations, and response.", "labels": [], "entities": []}, {"text": "Social scientists typically investigate these issues using polling data.", "labels": [], "entities": []}, {"text": "The research shows significant demographic differences in response to government warnings, personal risk assessment, and evacuation decisions).", "labels": [], "entities": []}, {"text": "For example, find that minorities differ in their risk perception and in their response to emergency warnings, with some groups having fatalistic sentiments that lead to greater fear and less preparedness.", "labels": [], "entities": []}, {"text": "find that people with lower income and education, Hispanics, and women all expressed greater fear of earthquakes.", "labels": [], "entities": []}, {"text": "This past research suggests governments could benefit by tailoring their messaging and response to address the variability between groups.", "labels": [], "entities": []}, {"text": "While survey data have advanced our knowledge of these issues, they have two major drawbacks for use in disaster research.", "labels": [], "entities": []}, {"text": "First, most surveys rely on responses to hypothetical scenarios, for example by asking subjects if they would evacuate under certain scenarios.", "labels": [], "entities": []}, {"text": "This hypothetical bias is well-known ().", "labels": [], "entities": []}, {"text": "Second, surveys are often impractical in disaster scenarios.", "labels": [], "entities": []}, {"text": "Ina rapidly-changing environment, governments cannot wait fora timeconsuming survey to be conducted and the results analyzed before making warning and response decisions.", "labels": [], "entities": []}, {"text": "Additionally, survey response rates shortly before or after a disaster are likely to be quite low, as citizens are either without power or are busy preparing or rebuilding.", "labels": [], "entities": []}, {"text": "Thus, it is difficult to collect data during the critical times immediately before and after the disaster.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the feasibility of assessing public risk perception using social media analysis.", "labels": [], "entities": []}, {"text": "Social media analysis has recently been used to estimate trends of interest such as stock prices, movie sales (, political mood (O'), and influenza rates.", "labels": [], "entities": [{"text": "political mood (O')", "start_pos": 113, "end_pos": 132, "type": "METRIC", "confidence": 0.6765579104423523}]}, {"text": "We apply a similar methodology hereto assess the public's level of concern toward an impending natural disaster.", "labels": [], "entities": []}, {"text": "As a case study, we examine attitudes toward Hurricane Irene expressed on Twitter.com.", "labels": [], "entities": []}, {"text": "We collect over 65,000 Twitter messages referencing Hurricane Irene between August 18th and August 31st, 2011; and we train a sentiment classifier to annotate messages by level of concern.", "labels": [], "entities": []}, {"text": "We specifically look at how message volume and sentiment varies overtime, location, and gender.", "labels": [], "entities": []}, {"text": "Our findings indicate that message volume increases over the days leading up to the hurricane, and then sharply decreases following its dispersal.", "labels": [], "entities": []}, {"text": "The timing of the increase and subsequent decrease in messages differs based on the location relative to the storm.", "labels": [], "entities": []}, {"text": "There is also an increasing proportion of concerned messages leading up to Hurricane Irene's arrival, which then decreases after Irene dissipation.", "labels": [], "entities": []}, {"text": "A demographic analysis of the proportion of concerned messages shows significant differences both by region and gender.", "labels": [], "entities": []}, {"text": "The gender differences in particular are supported by previous survey results from the social science literature.", "labels": [], "entities": []}, {"text": "These results suggest that social media analysis is a viable technology for understanding public perception during a hurricane.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: First, we describe the data collection methodology, including how messages are annotated with location and gender.", "labels": [], "entities": []}, {"text": "Next, we present sentiment classification experiments comparing various classifiers, tokenization procedures, and feature sets.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.9319908022880554}]}, {"text": "Finally, we apply this classifier to the entire message set and analyze demographic variation in levels of concern.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of messages in sample for each filter.", "labels": [], "entities": []}, {"text": " Table 3: Average accuracy (with standard error) and  micro-averaged precision, recall, and F1 for the three sen- timent classifiers, using their best configurations. The dif- ference in accuracy between MaxEnt and the other clas- sifiers is statistically significant (paired t-test, p < 0.01).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9964325428009033}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.8759984970092773}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9996494054794312}, {"text": "F1", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9998394250869751}, {"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.9902462959289551}]}, {"text": " Table 4: Summary of the impact of various tokenization  and feature choices. The second and third columns list the  average and maximum accuracy over all possible system  configurations with that setting. All results use the Max- Ent classifier and 10-fold cross-validation. Tokenizer1,  Remove Stop Words, and Worry Lexicon result in the  largest improvements in accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9986997842788696}, {"text": "accuracy", "start_pos": 365, "end_pos": 373, "type": "METRIC", "confidence": 0.9978832602500916}]}]}