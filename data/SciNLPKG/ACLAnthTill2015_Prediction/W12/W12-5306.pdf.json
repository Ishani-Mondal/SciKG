{"title": [{"text": "Entity Centric Opinion Mining from Blogs", "labels": [], "entities": []}], "abstractContent": [{"text": "With the growth of web 2.0, people are using it as a medium to express their opinion and thoughts.", "labels": [], "entities": []}, {"text": "With the explosion of blogs, journal like user-generated content on the web, companies , celebrities and politicians are concerned about mining and analyzing the discussions about them or their products.", "labels": [], "entities": []}, {"text": "In this paper, we present a method to perform opinion mining and summarize opinions at entity level for English blogs.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.8161114752292633}, {"text": "summarize opinions", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.9152530431747437}]}, {"text": "We first identify various objects (named entities) which are talked about by the blogger, then we identify the modifiers which modify the orientation towards these objects.", "labels": [], "entities": []}, {"text": "Finally, we generate object centric opinionated summary from blogs.", "labels": [], "entities": []}, {"text": "We perform experiments like named entity identification, entity-modifier relationship extraction and modifier orientation estimation.", "labels": [], "entities": [{"text": "named entity identification", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.6174050470193228}, {"text": "entity-modifier relationship extraction", "start_pos": 57, "end_pos": 96, "type": "TASK", "confidence": 0.6261826356252035}, {"text": "modifier orientation estimation", "start_pos": 101, "end_pos": 132, "type": "TASK", "confidence": 0.7804786562919617}]}, {"text": "Experiments and Results presented in this paper are cross verified with the judgment of human annotators.", "labels": [], "entities": []}, {"text": "A Blog is a web page where an individual or group of users record opinions, information, etc.", "labels": [], "entities": []}, {"text": "Blogs are written on many diverse topics like politics, sports, travel and even products.", "labels": [], "entities": []}, {"text": "However, the quality of the text generated from these sources is generally poor and noisy.", "labels": [], "entities": []}, {"text": "These texts are informally written and suffer from spelling mistakes, grammatical errors, random/irrational capitalization (Dey and Haque, 2008).", "labels": [], "entities": []}, {"text": "Opinion Mining from blogs aims at identifying the viewpoint of the author about the objects 1.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7026058882474899}]}, {"text": "Summarizing these expressed viewpoints can be useful for many business and organizations where they analyze the sentiment of the people on a product, or for an individual(s) who are curious to know opinions of other people.", "labels": [], "entities": []}, {"text": "Current approaches on opinion identification divide the larger problem (document) into sub-problems (sentences) and approach each sub-problem separately.", "labels": [], "entities": [{"text": "opinion identification", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8608089089393616}]}, {"text": "These approaches have a drawback that they cannot capture the context flow and opinion towards multiple objects within the blog.", "labels": [], "entities": []}], "introductionContent": [{"text": "Blog summarization task is considered as normal text summarization, without giving significance to the nature and structure of the blog.", "labels": [], "entities": [{"text": "Blog summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.692400649189949}, {"text": "text summarization", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7321122586727142}]}, {"text": "Current state of art summarization systems perform candidate sentences selection from the content and generate the summary.", "labels": [], "entities": []}, {"text": "In this paper 2 , we present anew picture to blog opinion mining, an entity perspective blog opinion mining and summarization.", "labels": [], "entities": [{"text": "blog opinion mining", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.6641700665156046}, {"text": "entity perspective blog opinion mining", "start_pos": 69, "end_pos": 107, "type": "TASK", "confidence": 0.7017181754112244}, {"text": "summarization", "start_pos": 112, "end_pos": 125, "type": "TASK", "confidence": 0.9811516404151917}]}, {"text": "Here, we identify the objects which the blogger has mentioned in the blog along with his view points on these objects.", "labels": [], "entities": []}, {"text": "In this work, named entities are potential objects for opinion mining.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.9038073122501373}]}, {"text": "We perform opinion mining for each of these objects by linking modifiers to each of these objects and deciding the orientation of these modifiers using a pre-constructed subjective lexicon.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.7246829718351364}]}, {"text": "And finally, we generate two different concept summaries: an object wise opinionated summary of the document and opinionated summary of the object across the dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have collected 100 blogs from Telegraph 4 in sports domain.", "labels": [], "entities": [{"text": "Telegraph 4", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9770887494087219}, {"text": "sports domain", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.8633112907409668}]}, {"text": "These blogs are from various categories like London Olympics, Cricket, Boxing, etc.", "labels": [], "entities": []}, {"text": "While working on this data, we observed that blogs are usually comparison between two or more objects like \"X is better than Y under some circumstances\".", "labels": [], "entities": []}, {"text": "Hence, we have found many objects in the blog but we find very few opinion words for various entities.", "labels": [], "entities": []}, {"text": "Refer for the dataset used in this research.", "labels": [], "entities": []}, {"text": "We decided to go with a more formal dataset because of two reasons.", "labels": [], "entities": []}, {"text": "Firstly, there was no dataset available aprior which was annotated in the required format.", "labels": [], "entities": []}, {"text": "Secondly, to avoid any form of biasness while collecting the dataset, we simply crawled top 100 blogs from Telegraph sports section.", "labels": [], "entities": [{"text": "Telegraph sports section", "start_pos": 107, "end_pos": 131, "type": "DATASET", "confidence": 0.9790151119232178}]}, {"text": "Although this dataset is free from most of the anomalies present in general blog data, but helps us to present the essence of our proposed approach very clearly.", "labels": [], "entities": []}, {"text": "A few observations we made while working on blog dataset were: Much of the information present in the blog(s) were factual, most of the opinions expressed were either in comparison format or negatively orientated.", "labels": [], "entities": []}, {"text": "In this subsection, we explain the method used for evaluating our approach.", "labels": [], "entities": []}, {"text": "We hired three human annotators for this task and calculation of their mutual agreement is done using Cohen's Kappa measurement . Validation task was divided into three basic steps 1.", "labels": [], "entities": [{"text": "Validation", "start_pos": 130, "end_pos": 140, "type": "TASK", "confidence": 0.958998441696167}]}, {"text": "Object Identification: Each human annotator was asked to identify all the named entities (person, organizations, location, etc) from the text.", "labels": [], "entities": [{"text": "Object Identification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7791792452335358}]}, {"text": "This process is similar to step 1 of our proposed approach.", "labels": [], "entities": []}, {"text": "Modifier Identification: After step 1, they were asked to mark and decide the orientation (positive or negative) for all the modifier words (adjectives, adverbs and verbs) from the text.", "labels": [], "entities": [{"text": "Modifier Identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8359198272228241}]}, {"text": "This step involved a good understanding of English language and word usage.", "labels": [], "entities": []}, {"text": "This corresponds to step 2 of our approach.", "labels": [], "entities": []}, {"text": "gives the agreement of human annotators for modifier identification.", "labels": [], "entities": [{"text": "modifier identification", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.8733590245246887}]}, {"text": "3. Object-Modifier Relation: Here, they were asked to assign/link modifiers to named entities i.e. to determine the opinion of the blogger towards the objects.", "labels": [], "entities": [{"text": "Object-Modifier Relation", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.7692282497882843}]}, {"text": "This step was the most tricky step as it requires a clear understanding of language construct(s).", "labels": [], "entities": []}, {"text": "This corresponds to step 3 in our approach where we use dependency processor to handle this.", "labels": [], "entities": []}, {"text": "Dependency Processor is a module which reads the typed dependencies retrieved from stanford parser and relates the attributes of these dependency tags with each other.", "labels": [], "entities": []}, {"text": "In the end, for the cases where the annotators failed to achieve an agreement, first and second authors of this paper performed the task of annotation to resolve the disagreement.", "labels": [], "entities": []}, {"text": "gives the kappa (\u03ba) statistics of human agreement for each of these tasks.", "labels": [], "entities": [{"text": "kappa (\u03ba)", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9448786377906799}]}, {"text": "One striking observation we made was that majority of the modifiers were negatively orientated i.e. blogs are frequently written to express negative sentiments (or disagreement) about the object.", "labels": [], "entities": []}, {"text": "We divide the experiment into four steps as discussed in Section 3 (Approach).", "labels": [], "entities": [{"text": "Approach", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9942371845245361}]}, {"text": "In this section, we describe the experiment using a small running example 6 from the corpus.", "labels": [], "entities": []}, {"text": "We illustrate the: Kappa Scores for Manual Agreement tools we have used for each step with a small description.", "labels": [], "entities": []}, {"text": "We also highlight the task done in each step for snippet example in.", "labels": [], "entities": []}, {"text": "Using Stanford NER, our system discovered a total 1756 unique named entities from 1984 unique named entities tagged by human annotators.", "labels": [], "entities": [{"text": "Stanford NER", "start_pos": 6, "end_pos": 18, "type": "DATASET", "confidence": 0.8678830862045288}]}, {"text": "In the sample snippet shown in, we have 4 named entities \"Channel 4\", \"Clare Balding\", \"Jon Snow\" and \"Ade Adepitan\".", "labels": [], "entities": [{"text": "Channel 4", "start_pos": 58, "end_pos": 67, "type": "DATASET", "confidence": 0.940525621175766}, {"text": "Clare Balding", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.6278734803199768}]}, {"text": "\u2022 In Step 2, we identify adjectives, adverbs and verbs which modify the named entities identified in step 1.", "labels": [], "entities": []}, {"text": "We link the named entities and modifiers using the dependencies (like amod, advmod, nsubj, etc) given by Stanford parser.", "labels": [], "entities": []}, {"text": "We perform dependency association to a level of depth 2.", "labels": [], "entities": [{"text": "dependency association", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8677328526973724}]}, {"text": "We also discard all the modifiers which are not mapped to any named entity as they are of no use to our system later.", "labels": [], "entities": []}, {"text": "Stanford parser and Stanford part-of-speech used in this step is also available in Stanford CoreNLP toolkit.", "labels": [], "entities": [{"text": "Stanford CoreNLP toolkit", "start_pos": 83, "end_pos": 107, "type": "DATASET", "confidence": 0.9115381240844727}]}, {"text": "Using Stanford parser and part-of-speech tagger, our system discovered 3755 correct modifiers (adjectives + adverbs + verbs).", "labels": [], "entities": []}, {"text": "This is 82.7% of what human annotators identified (4540).", "labels": [], "entities": []}, {"text": "For the sample snippet in mappings (modifier to entity) are shown in.", "labels": [], "entities": []}, {"text": "\u2022 Using SentiWordNet, we identified the orientation of these modifiers in Step 3.", "labels": [], "entities": []}, {"text": "We use the most common used sense of each word for scoring in order to handle multiple senses of each word.", "labels": [], "entities": []}, {"text": "\u2022 In Step 4, we create a tabular summary of objects and their respective modifiers (Refer).", "labels": [], "entities": [{"text": "Refer", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.8891224265098572}]}, {"text": "This summary belongs to type 1 : Blog level summary.", "labels": [], "entities": []}, {"text": "Using this kind of summary, we can draw a picture of user's mind and how he/she thinks about various entities.", "labels": [], "entities": []}, {"text": "The second type of summary generated can be used to compare two different entities.", "labels": [], "entities": []}, {"text": "reports the accordance of our proposed algorithm with human annotators.", "labels": [], "entities": []}, {"text": "Opinion orientation agreement is calculated as an aggregate opinion towards an entity.", "labels": [], "entities": [{"text": "Opinion orientation agreement", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7758416930834452}]}], "tableCaptions": [{"text": " Table 1: Summary of Blog Dataset", "labels": [], "entities": [{"text": "Blog Dataset", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.7871772050857544}]}, {"text": " Table 2: Manual agreement scores for Object and Modifier Identification", "labels": [], "entities": [{"text": "Object and Modifier Identification", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.7754862457513809}]}, {"text": " Table 3: Kappa Scores for Manual Agree- ment", "labels": [], "entities": [{"text": "Kappa Scores", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8207113742828369}, {"text": "Manual Agree- ment", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.5203669518232346}]}, {"text": " Table 7: Results of Stanford CoreNLP on the sample sentence", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.8768267631530762}]}]}