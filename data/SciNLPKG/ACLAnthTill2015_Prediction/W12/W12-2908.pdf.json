{"title": [{"text": "Generating Situated Assisting Utterances to Facilitate Tactile-Map Understanding: A Prototype System", "labels": [], "entities": [{"text": "Generating Situated Assisting Utterances", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7392454743385315}, {"text": "Tactile-Map Understanding", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.6864780485630035}]}], "abstractContent": [{"text": "Tactile maps are important substitutes for visual maps for blind and visually impaired people and the efficiency of tactile-map reading can largely be improved by giving assisting utterances that make use of spatial language.", "labels": [], "entities": []}, {"text": "In this paper, we elaborate earlier ideas fora system that generates such utterances and present a prototype implementation based on a semantic conceptualization of the movements that the map user performs.", "labels": [], "entities": []}, {"text": "A worked example shows the plausibility of the solution and the output that the prototype generates given input derived from experimental data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humans use maps in everyday scenarios.", "labels": [], "entities": []}, {"text": "Especially for blind and visually impaired people, tactile maps are helpful accessible substitutes for visual maps).", "labels": [], "entities": []}, {"text": "However, tactile maps are less efficient than visual maps, as they have to be read sequentially.", "labels": [], "entities": []}, {"text": "A further problem of physical tactile maps is restricted availability.", "labels": [], "entities": [{"text": "physical tactile maps", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.6549651424090067}]}, {"text": "While physical tactile maps are rarely available and costly to produce, modern haptic human-computer interfaces can be used to present virtual variants of tactile maps (virtual tactile maps) providing a similar functionality.", "labels": [], "entities": []}, {"text": "For example, the Sensable Phantom Omni device used in our research enables a user to feel virtual three-dimensional objects (see).", "labels": [], "entities": []}, {"text": "It can bethought of as a reverse robotic arm that makes virtual haptic perception possible by generating force feedback.", "labels": [], "entities": []}, {"text": "In the context of the research discussed, these objects are virtual tactile maps.", "labels": [], "entities": []}, {"text": "These consist of a virtual plane on which streets and potential landmarks (such as buildings) are presented as cavities.", "labels": [], "entities": []}, {"text": "In recent work, have suggested a multi-modal map called Verbally Assisting Virtual-Environment Tactile Map (VAVETaM) with the goal to enable more efficient acquisition of spatial survey (overview) knowledge for blind and visually impaired people.", "labels": [], "entities": []}, {"text": "VAVETaM extends the approaches towards multimodal maps (see Section 2) by generating situated spatial language.", "labels": [], "entities": [{"text": "VAVETaM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8311153650283813}]}, {"text": "The prototype described reacts to the user's exploration movements more like a human verbally assisting a tactile map reader would do, e.g., by describing spatial relations between objects on the map.", "labels": [], "entities": []}, {"text": "The users may explore the map freely, i.e., they choose which map objects are of interest and in which order they explore them.", "labels": [], "entities": []}, {"text": "This demands for situated natural language generation, which produces timely appropriate assisting utterances.", "labels": [], "entities": []}, {"text": "Previously, the suggested system has not been implemented.", "labels": [], "entities": []}, {"text": "The goal of this paper is to show that the ideas of and can be implemented in a prototype which is able to generate helpful assisting utterances; that is, to show that the languagegeneration components of VAVETaM are technically possible.", "labels": [], "entities": [{"text": "VAVETaM", "start_pos": 205, "end_pos": 212, "type": "DATASET", "confidence": 0.8476834893226624}]}, {"text": "The remainder of the paper is structured as follows: We first briefly survey some related work in Section 2, and then describe the overall structure of VAVETaM in Section 3.", "labels": [], "entities": [{"text": "VAVETaM", "start_pos": 152, "end_pos": 159, "type": "DATASET", "confidence": 0.6648023724555969}]}, {"text": "We then present a description of our system in Section 4 paying special attention to the input to natural language generation (Subsection 4.1) and the generation component itself.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.7397968967755636}]}, {"text": "We show the appropriateness of the approach by discussing an example input, the pro- cesses performed, and the automatically generated output in Section 5 before we close with concluding remarks in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}