{"title": [{"text": "Using Group History to Identify Character-directed Utterances in Multi-child Interactions", "labels": [], "entities": [{"text": "Identify Character-directed Utterances", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.7820449670155843}]}], "abstractContent": [{"text": "Addressee identification is an element of all language-based interactions, and is critical for turn-taking.", "labels": [], "entities": [{"text": "Addressee identification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9059900045394897}]}, {"text": "We examine the particular problem of identifying when each child playing an interactive game in a small group is speaking to an animated character.", "labels": [], "entities": []}, {"text": "After analyzing child and adult behavior, we explore a family of machine learning models to integrate audio and visual features with temporal group interactions and limited, task-independent language.", "labels": [], "entities": []}, {"text": "The best model performs identification about 20% better than the model that uses the audiovisual features of the child alone.", "labels": [], "entities": [{"text": "identification", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.9597791433334351}]}], "introductionContent": [{"text": "Multi-party interaction between a group of participants and an autonomous agent is an important but difficult task.", "labels": [], "entities": []}, {"text": "Key problems include identifying when speech is present, who is producing it, and to whom it is directed, as well as producing an appropriate response to its intended meaning.", "labels": [], "entities": []}, {"text": "Solving these problems is made more difficult when some or all of the participants are young children, who have high variability in language, knowledge, and behavior.", "labels": [], "entities": []}, {"text": "Prior research has tended to look at single children) or multiperson groups of adults ().", "labels": [], "entities": []}, {"text": "We are interested in interactions between animated or robotic characters and small groups of four to ten year old children.", "labels": [], "entities": []}, {"text": "The interaction can be brief but should be fun.", "labels": [], "entities": []}, {"text": "Here we focus specifically on the question of deciding whether or not a child's utterance is directed to the character, a binary form of the addressee identification (AID) problem.", "labels": [], "entities": [{"text": "addressee identification (AID) problem", "start_pos": 141, "end_pos": 179, "type": "TASK", "confidence": 0.7975014547506968}]}, {"text": "Our broad goals in this research are to understand how children's behavior in group interaction with a character differs from adults', how controllable aspects of the character and physical environment determine participants' behavior, and how an autonomous character can take advantage of these regularities.", "labels": [], "entities": []}, {"text": "We collected audio and video data of groups of up to four children and adults playing language-based games with animated characters that were under limited human control.", "labels": [], "entities": []}, {"text": "An autonomous character can make two kinds of AID mistakes: failing to detect when it is being spoken to, and acting as if it has been spoken to when it has not.", "labels": [], "entities": []}, {"text": "The former can be largely prevented by having the character use examples of the language that it can recognize as part of the game.", "labels": [], "entities": []}, {"text": "Such exemplification cannot prevent the second kind of mistake, however.", "labels": [], "entities": []}, {"text": "It occurs, for example, when children confer to negotiate the next choice, respond emotionally to changes in the game state, or address each other without making eye contact.", "labels": [], "entities": []}, {"text": "As a result, models that use typical audiovisual features to decide AID will not be adequate in multi-child environments.", "labels": [], "entities": [{"text": "AID", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.8159950971603394}]}, {"text": "By including temporal conversational interactions between group members, however, we can both detect character-directed utterances and ignore the remainder about 20% better than simple audio-visual models alone, with less than 15% failure when being spoken to, and about 20% failure when not addressed.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Comparison of models", "labels": [], "entities": []}, {"text": " Table 3: Excerpts from the dictionary for task-specific  and task-independent words", "labels": [], "entities": []}]}