{"title": [{"text": "Exploiting Machine-Transcribed Dialog Corpus to Improve Multiple Dialog States Tracking Methods", "labels": [], "entities": [{"text": "Improve Multiple Dialog States Tracking", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.8933918595314025}]}], "abstractContent": [{"text": "This paper proposes the use of unsuper-vised approaches to improve components of partition-based belief tracking systems.", "labels": [], "entities": [{"text": "partition-based belief tracking", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.6175574461619059}]}, {"text": "The proposed method adopts a dynamic Bayesian network to learn the user action model directly from a machine-transcribed dialog corpus.", "labels": [], "entities": []}, {"text": "It also addresses confidence score calibration to improve the observation model in a unsuper-vised manner using dialog-level grounding information.", "labels": [], "entities": [{"text": "confidence score calibration", "start_pos": 18, "end_pos": 46, "type": "METRIC", "confidence": 0.8635042707125345}]}, {"text": "To verify the effectiveness of the proposed method, we applied it to the Let's Go domain (Raux et al., 2005).", "labels": [], "entities": []}, {"text": "Overall system performance for several comparative models were measured.", "labels": [], "entities": []}, {"text": "The results show that the proposed method can learn an effective user action model without human intervention.", "labels": [], "entities": []}, {"text": "In addition, the calibrated confidence score was verified by demonstrating the positive influence on the user action model learning process and on overall system performance.", "labels": [], "entities": [{"text": "calibrated confidence score", "start_pos": 17, "end_pos": 44, "type": "METRIC", "confidence": 0.7413827578226725}]}], "introductionContent": [{"text": "With present Automatic Speech Recognition (ASR) and Spoken Language Understanding (SLU) errors, it is impossible to directly observe the true user goal and action.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.739281435807546}]}, {"text": "It is crucial, therefore, to efficiently infer this true state from erroneous observations over multiple dialog turns.", "labels": [], "entities": []}, {"text": "The Partially Observable Markov Decision Process (POMDP) framework has offered a well-founded theory for this purpose.", "labels": [], "entities": [{"text": "Partially Observable Markov Decision Process (POMDP)", "start_pos": 4, "end_pos": 56, "type": "TASK", "confidence": 0.6976615414023399}]}, {"text": "Several approximate methods have also emerged to tackle the vast complexity of representing and maintaining belief states, e.g., partition-based approaches and Bayesian network (BN)-based methods ().", "labels": [], "entities": []}, {"text": "The partition-based approaches attempt to group user goals into a small number of partitions and split a partition only when a distinction is required by observations.", "labels": [], "entities": []}, {"text": "This property endows it with the high scalability that is suitable for fairly complex domains.", "labels": [], "entities": []}, {"text": "However, the parameter learning procedures for the partition-based methods is still limited to hand-crafting or the use of a simple maximum likelihood estimation (.", "labels": [], "entities": []}, {"text": "In contrast, several unsupervised methods which do not require human transcription and annotation have been recently proposed to learn BN-based models.", "labels": [], "entities": []}, {"text": "In this paper we describe an unsupervised process that can be applied to the partition-based methods.", "labels": [], "entities": []}, {"text": "We adopt a dynamic Bayesian network to learn the user action model which defines the likelihood of user actions fora given context.", "labels": [], "entities": []}, {"text": "In addition, we propose a simple confidence score calibration method to improve the observation model which represents the probability of an observation given the true user action.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes previous research and the novelty of our approach.", "labels": [], "entities": []}, {"text": "Section 3 and Section 4 elaborate on our proposed unsupervised approach.", "labels": [], "entities": []}, {"text": "Section 5 explains the experimental setup.", "labels": [], "entities": []}, {"text": "Section 6 presents and discusses the results.", "labels": [], "entities": []}, {"text": "Finally, Section 7 concludes with a brief summary and suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "To verify the proposed method, three months of data from the Let's Go domain were used to train the user action model and the observation model.", "labels": [], "entities": []}, {"text": "The training data consists of 2,718 dialogs and 23,044 turns in total.", "labels": [], "entities": []}, {"text": "To evaluate the user action model, we compared overall system performance with three different configurations: 1) the uniform distribution, 2) the user action model without historical information 5 which is comparable to the bigram model of (, 3) the user action model with historical information included.", "labels": [], "entities": []}, {"text": "For system performance evaluation, we used a user simulator () which provides a large number of dialogs with statistically similar conditions.", "labels": [], "entities": [{"text": "system performance evaluation", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.694717009862264}]}, {"text": "Also, the simulated user enables us to examine how performance changes over a variety of error levels.", "labels": [], "entities": []}, {"text": "This simulated user supports four error levels and each model was evaluated by generating 2,000 dialogs at each error level.", "labels": [], "entities": []}, {"text": "System performance was measured in terms of average dialog success rate.", "labels": [], "entities": []}, {"text": "A dialog is considered to be successful if the system provides the bus schedule information that satisfies the user goal.", "labels": [], "entities": []}, {"text": "To measure the effectiveness of the calibration method, we conducted two experiments.", "labels": [], "entities": []}, {"text": "First, we applied the calibration method to parameter learning for the user action model by using the calibrated confidence score in Equation 7.", "labels": [], "entities": []}, {"text": "We compared the log-likelihood of two models, one with calibration and the other without calibration.", "labels": [], "entities": []}, {"text": "Second, we compared overall system performance with four different settings: 1) the user action model with histori-", "labels": [], "entities": []}], "tableCaptions": []}