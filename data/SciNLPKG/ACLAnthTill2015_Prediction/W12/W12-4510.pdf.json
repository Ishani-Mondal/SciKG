{"title": [{"text": "Chinese Coreference Resolution via Ordered Filtering *", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.7404864728450775}]}], "abstractContent": [{"text": "We in this paper present the model for our participation (BCMI) in the CoNLL-2012 Shared Task.", "labels": [], "entities": [{"text": "BCMI", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.866747260093689}, {"text": "CoNLL-2012 Shared Task", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.7321574489275614}]}, {"text": "This paper describes a pure rule-based method, which assembles different filters in a proper order.", "labels": [], "entities": []}, {"text": "Different filters handle different situations and the filtering strategies are designed manually.", "labels": [], "entities": []}, {"text": "These filters are assigned to different ordered tiers from general to special cases.", "labels": [], "entities": []}, {"text": "We participated in the Chinese and En-glish closed tracks, scored 51.83 and 59.24 respectively.", "labels": [], "entities": [{"text": "Chinese and En-glish closed tracks", "start_pos": 23, "end_pos": 57, "type": "DATASET", "confidence": 0.7055470585823059}]}], "introductionContent": [{"text": "In this paper, we describes the approaches we utilized for our participation in the CoNLL-2012 Shared Task.", "labels": [], "entities": [{"text": "CoNLL-2012 Shared Task", "start_pos": 84, "end_pos": 106, "type": "DATASET", "confidence": 0.6816599567731222}]}, {"text": "This year's shared task targets at modeling coreference resolution for multiple languages.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7695497870445251}]}, {"text": "Following), we extends the methodology of deterministic coreference model, using manually designed rules to recognize expressions with corresponding entities.", "labels": [], "entities": []}, {"text": "The deterministic coreference model (Raghu- * This work was partially supported by the National Natural Science Foundation of China nathan et al., 2010) has shown good performance in the shared task of.", "labels": [], "entities": []}, {"text": "This kind of model focuses on filtering with ordered tiers: One filter is applied atone time, from highest to lowest precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9839850068092346}]}, {"text": "However, compared with learning approaches (), since effective rules are quite heterogeneous in different languages, several filtering methods should be redesigned when different languages are considered.", "labels": [], "entities": []}, {"text": "We modified the original Stanford English coreference system 1 to adapt to the Chinese scenario.", "labels": [], "entities": [{"text": "Stanford English coreference system 1", "start_pos": 25, "end_pos": 62, "type": "DATASET", "confidence": 0.9114159345626831}]}, {"text": "For the English participation, we implemented the full strategies and interface of the semantic-based filters which are not obtained from the open source toolkit.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: In Section 2, we review the related work; In Section 3, we describe the detail of our model of handling coreference resolution in Chinese; Experiment results are reported in Section 4 and the conclusion is presented in Section 5.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 152, "end_pos": 174, "type": "TASK", "confidence": 0.8509543836116791}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance of the mention detection com- ponent, before and after coreference resolution, with  both gold and auto linguistic annotations on devel- opment set.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.8669845461845398}]}, {"text": " Table 3: Performance of the mention detection com- ponent, after coreference resolution, with auto lin- guistic annotations on test set.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.8552416861057281}]}, {"text": " Table 5: Results on the official test set (closed track).", "labels": [], "entities": [{"text": "official test set", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.7310402790705363}]}, {"text": " Table 4: Results on the official development set (closed track). GMB stands for Gold Mention Boundaries", "labels": [], "entities": [{"text": "official development set", "start_pos": 25, "end_pos": 49, "type": "DATASET", "confidence": 0.68585205078125}, {"text": "GMB", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9389971494674683}, {"text": "Gold Mention Boundaries", "start_pos": 81, "end_pos": 104, "type": "METRIC", "confidence": 0.9114076693852743}]}, {"text": " Table 6: Results (Avg F1) on different data types of the development set (closed track).", "labels": [], "entities": [{"text": "Avg F1)", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9485495090484619}]}, {"text": " Table 7: Results ( Recall of mention detection and Avg F1) on different data types and different mention  types of the development set with linguistic annotations (closed track).", "labels": [], "entities": [{"text": "mention detection", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.659782886505127}, {"text": "Avg F1", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9055452942848206}]}]}