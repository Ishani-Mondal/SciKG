{"title": [{"text": "Latent Semantic Transliteration using Dirichlet Mixture", "labels": [], "entities": []}], "abstractContent": [{"text": "Transliteration has been usually recognized by spelling-based supervised models.", "labels": [], "entities": []}, {"text": "However, a single model cannot deal with mixture of words with different origins, such as \"get\" in \"piaget\" and \"target\".", "labels": [], "entities": []}, {"text": "(2007) propose a class translit-eration method, which explicitly models the source language origins and switches them to address this issue.", "labels": [], "entities": []}, {"text": "In contrast to their model which requires an explicitly tagged training corpus with language origins, Hagiwara and Sekine (2011) have proposed the latent class transliteration model, which models language origins as latent classes and train the transliteration table via the EM algorithm.", "labels": [], "entities": []}, {"text": "However, this model, which can be formulated as uni-gram mixture, is prone to overfitting since it is based on maximum likelihood estimation.", "labels": [], "entities": []}, {"text": "We propose a novel latent semantic transliteration model based on Dirichlet mixture, where a Dirichlet mixture prior is introduced to mitigate the overfitting problem.", "labels": [], "entities": []}, {"text": "We have shown that the proposed method considerably outperform the conventional transliteration models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Transliteration (e.g., \u30d0 \u30e9 \u30af \u30aa \u30d0 \u30de baraku obama \"Barak Obama\") is phonetic translation between languages with different writing systems, which is a major way of importing foreign words into different languages.", "labels": [], "entities": []}, {"text": "Supervised, spelling-based grapheme-to-grapheme models such as), which directly align characters in the training corpus without depending on phonetic information, and statistically computing their correspondence, have been a popular method to detect and/or generate transliterations, in contrast to phonetic-based methods such as).", "labels": [], "entities": []}, {"text": "However, single, monolithic models fail to deal with sets of foreign words with multiple language origins mixed together.", "labels": [], "entities": []}, {"text": "For example, the \"get\" part of \"piaget / \u30d4 \u30a2 \u30b8\u30a7 piaje\" and \"target / \u30bf\u30fc \u30b2\u30c3 \u30c8 t\u0101getto\" differ in pronunciation and spelling correspondence depending on their source languages, which are French and English in this case.", "labels": [], "entities": []}, {"text": "To address this issue, have proposed class transliteration model, which explicitly models and classifies classes of languages (such as Chinese Hanzi, Japanese Katakana, and so on) and genders, and switches corresponding transliteration models based on the input.", "labels": [], "entities": []}, {"text": "This model requires training sets of transliterated word pairs tagged with language origin, which is difficult to obtain.", "labels": [], "entities": []}, {"text": "Hagiwara and Sekine proposed the latent class transliteration (LCT) model (), which models source language origins as directly unobservable latent classes and applies appropriate transliteration models to given transliteration pairs.", "labels": [], "entities": []}, {"text": "The model parameters are learned from corpora without language origins in an unsupervised manner.", "labels": [], "entities": []}, {"text": "This enables us to correctly assign latent classes for English and French to \"piaget / \u30d4\u30a2\u30b8\u30a7piaje\" and \"target / \u30bf\u30fc\u30b2\u30c3 \u30c8 t\u0101getto\" and to identify their transliteration correspondence correctly.", "labels": [], "entities": []}, {"text": "However, this model is based on maximum likelihood estimation on multinomials and thus sensitive to noise in the training data such as transliteration pairs with irregular pronunciation, and tends to overfit the data.", "labels": [], "entities": []}, {"text": "Considering the atomic re-writing unit (transliteration unit, or TU, e.g., \"get / \u30b2\u30c3 \u30c8 getto\") as a word, and a transliteration pair as a document consisting of a word sequence, class-based transliteration can be modeled by the perfect analogy to document topic models proposed in tha past.", "labels": [], "entities": []}, {"text": "In fact, the LCT model, where the transliteration probability is defined by a mixture of multinomials, can be regarded as a variant of a topic model, namely Unigram Mixuture (UM) ().", "labels": [], "entities": []}, {"text": "There has been an extension of unigram mixture proposed () which introduces a Dirichlet mixture distribution as a prior and alleviates the overfitting problem.", "labels": [], "entities": []}, {"text": "We can expect to improve the transliteration accuracy by formulating the transliteration problem using a similar framework to these topic models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9655885100364685}]}, {"text": "In this paper, we formalize class-based transliteration based on language origins in the framework of topic models.", "labels": [], "entities": []}, {"text": "We then propose the latent semantic transliteration model based on Dirichlet mixture (DM-LST).", "labels": [], "entities": []}, {"text": "We show through experiments that it can significantly improve the transliteration performance by alleviating the overfitting issue.", "labels": [], "entities": []}, {"text": "Note that we tackle the task of transliteration generation in this paper, in contrast to transliteration recognition.", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.8688131868839264}, {"text": "transliteration recognition", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.8359243869781494}]}, {"text": "A transliteration generation task is, given an input word s (such as \"piaget\"), the system is asked to generate from scratch the most probable transliterated word t (e.g., \"\u30d4\u30a2 \u30b8\u30a7piaje\").", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.8775467276573181}]}, {"text": "The transliteration recognition task, on the other hand, is to induce the most probable transliteration t * \u2208 T such that t * = arg max t\u2208T P (s, t) given the input word sand a pool of transliteration candidates T . We call P (s, t) transliteration model in this paper.", "labels": [], "entities": [{"text": "transliteration recognition", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.9016225636005402}]}, {"text": "This model can be regarded as the hybrid of an unsupervised alignment technique for transliteration and class-based transliteration.", "labels": [], "entities": []}, {"text": "Related researches for the former include), who estimate character-based error probabilities from query logs via the EM algorithm.", "labels": [], "entities": []}, {"text": "For the latter, showed that source language origins may improve the pronunciation of proper nouns in text-to-speech systems.", "labels": [], "entities": []}, {"text": "The structure of this paper is as follows: we introduce the alpha-beta model) in Section 2, which is the most basic spelling-based transliteration model on which other models are based.", "labels": [], "entities": []}, {"text": "In the following Section 3, we introduce and relate the joint source channel (JSC) model () to the alphabeta model.", "labels": [], "entities": []}, {"text": "We describe the LCT model as an extension to the JSC model in Section 4.", "labels": [], "entities": [{"text": "JSC model", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.7909422814846039}]}, {"text": "In Section 5, we propose the DM-LST model, and show the experimental results on transliteration generation in Section 6.", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.8808001577854156}]}], "datasetContent": [{"text": "In this section, we compare the following models: alpha-beta (AB), joint source channel (JSC), latent class transliteration (LCT), and latent semantic transliteration based on Dirichlet mixture (DM-LST).", "labels": [], "entities": []}, {"text": "For the performance evaluation, we used three language pairs, namely, English-Japanese (EnJa), English-Chinese (En-Ch), and EnglishKorean (En-Ko), from the transliteration shared task at NEWS 2009 ().", "labels": [], "entities": [{"text": "NEWS 2009", "start_pos": 187, "end_pos": 196, "type": "DATASET", "confidence": 0.9201769828796387}]}, {"text": "The size of each training/test set is shown in the first column of.", "labels": [], "entities": []}, {"text": "In general, r n , a set of one or more reference transliterated words, is associated with the n-th input s n in the training/test corpus.", "labels": [], "entities": []}, {"text": "Let c n,i , c n,2 , ...", "labels": [], "entities": []}, {"text": "be the output of the transliteration system, i.e., the candidates with highest probabilities assigned by the transliteration model being evaluated.", "labels": [], "entities": []}, {"text": "We used the following three performance measures: \u2022 ACC (averaged Top-1 accuracy): For every s n , r n , let an be an = 1 if the candidate with the highest probability c n,1 is contained in the reference set r n and an = 0 otherwise.", "labels": [], "entities": [{"text": "ACC", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9978492259979248}, {"text": "accuracy)", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9088569283485413}]}, {"text": "ACC is then calculated as \u2022 MFS (mean F score): Let the reference transliterated word closest to the top-1 candidate c n , 1 be r * n = arg min r n,j \u2208rn ED(c n,1 , r n,j ), where ED is the edit distance.", "labels": [], "entities": [{"text": "ACC", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.932890772819519}, {"text": "MFS", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9360572099685669}, {"text": "F score)", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9648212790489197}, {"text": "ED", "start_pos": 180, "end_pos": 182, "type": "METRIC", "confidence": 0.9845578074455261}]}, {"text": "The F-score of the top candidate c n,1 for the n-th input s n is then given by: where |x| is the length of string x, and LCS(x, y) is the length of the longest common subsequence of x and y.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9977328777313232}, {"text": "LCS", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.992254376411438}]}, {"text": "Edit distance, lengths of strings, and LCS are measured in Unicode characters.", "labels": [], "entities": [{"text": "Edit distance", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.7948929071426392}, {"text": "LCS", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9950306415557861}]}, {"text": "Finally, MFS is defined as \u2022 MRR (mean reciprocal rank): Of the ranked candidates c n,1 , c n,2 , ..., let the highest ranked one which is also included in the reference set r n be c n,j . We then define reciprocal rank RR n = 1/j.", "labels": [], "entities": [{"text": "MFS", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.8108581304550171}, {"text": "MRR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9963048696517944}]}, {"text": "If none of the candidates are in the reference, RR n = 0.", "labels": [], "entities": [{"text": "RR n", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9691846370697021}]}, {"text": "MRR is then defined by We used Kneser-Nay smoothing to smooth the TU probabilities for LCT.", "labels": [], "entities": [{"text": "MRR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.4805113673210144}]}, {"text": "The number of EM iterations is fixed to 15 for all the models, based on the result of preliminary experiments.", "labels": [], "entities": []}, {"text": "The reduce width Rand the beam width B for the stack decoder are fixed to R = 8 and B = 32, because the transliteration generation performance increased very little beyond these widths based on the experiment using the development set.", "labels": [], "entities": []}, {"text": "We also optimized M , i.e., the number of latent classes for LCT and DM-LST, for each language pair and model in the same way based on the development set.", "labels": [], "entities": [{"text": "M", "start_pos": 18, "end_pos": 19, "type": "METRIC", "confidence": 0.956285834312439}]}], "tableCaptions": [{"text": " Table 1: Performance comparison of transliteration  models", "labels": [], "entities": []}]}