{"title": [{"text": "TopicTiling: A Text Segmentation Algorithm based on LDA", "labels": [], "entities": [{"text": "Text Segmentation Algorithm", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7553010483582815}]}], "abstractContent": [{"text": "This work presents a Text Segmentation algorithm called TopicTiling.", "labels": [], "entities": [{"text": "Text Segmentation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.734440267086029}]}, {"text": "This algorithm is based on the well-known TextTiling algorithm , and segments documents using the Latent Dirichlet Allocation (LDA) topic model.", "labels": [], "entities": []}, {"text": "We show that using the mode topic ID assigned during the inference method of LDA, used to annotate unseen documents, improves performance by stabilizing the obtained topics.", "labels": [], "entities": []}, {"text": "We show significant improvements overstate of the art segmentation algorithms on two standard datasets.", "labels": [], "entities": []}, {"text": "As an additional benefit, TopicTiling performs the segmentation in linear time and thus is computationally less expensive than other LDA-based segmentation methods.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.9752482771873474}]}], "introductionContent": [{"text": "The task tackled in this paper is Text Segmentation (TS), which is to be understood as the segmentation of texts into topically similar units.", "labels": [], "entities": [{"text": "Text Segmentation (TS)", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8429599285125733}]}, {"text": "This implies, viewing the text as a sequence of subtopics, that a subtopic change marks anew segment.", "labels": [], "entities": []}, {"text": "The challenge fora text segmentation algorithm is to find the sub-topical structure of a text.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7414299249649048}]}, {"text": "In this work, this semantic information is gained from Topic Models (TMs).", "labels": [], "entities": []}, {"text": "We introduce a newly developed TS algorithm called TopicTiling.", "labels": [], "entities": [{"text": "TS", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9010089635848999}]}, {"text": "The core algorithm is a simplified version of TextTiling, where blocks of text are compared via bag-of-word vectors.", "labels": [], "entities": []}, {"text": "TopicTiling uses topic IDs, obtained by the LDA inference method, instead of words.", "labels": [], "entities": []}, {"text": "As some of the topic IDs obtained by the inference method tend to change for different runs, we recommend to use the most probable topic ID assigned during the inference.", "labels": [], "entities": []}, {"text": "We denote this most probable topic ID as the mode (most frequent across all inference steps) of the topic assignment.", "labels": [], "entities": []}, {"text": "These IDs are used to calculate the cosine similarity between two adjacent blocks of sentences, represented as two vectors, containing the frequency of each topic ID.", "labels": [], "entities": []}, {"text": "Without parameter optimization we obtain state-of-the-art results based on the Choi dataset).", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.962517112493515}]}, {"text": "We show that the mode assignment improves the results substantially and improves even more when parameterizing the size of sampled blocks using a window size parameter.", "labels": [], "entities": []}, {"text": "Using these optimizations, we obtain significant improvements compared to other algorithms based on the Choi dataset and also on a more difficult Wall Street Journal (WSJ) corpus provided by.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 104, "end_pos": 116, "type": "DATASET", "confidence": 0.9154167771339417}, {"text": "Wall Street Journal (WSJ) corpus", "start_pos": 146, "end_pos": 178, "type": "DATASET", "confidence": 0.9324302417891366}]}, {"text": "Not only does TopicTiling deliver state-of-the-art segmentation results, it also performs the segmentation in linear time, as opposed to most other recent TS algorithms.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: The next section gives an overview of text segmentation algorithms.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7758839726448059}]}, {"text": "Section 3 introduces the TopicTiling TS algorithm.", "labels": [], "entities": [{"text": "TopicTiling TS", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.771941602230072}]}, {"text": "The Choi and the Galley datasets used to measure the performance of TopicTiling are described in Section 4.", "labels": [], "entities": [{"text": "Choi and the Galley datasets", "start_pos": 4, "end_pos": 32, "type": "DATASET", "confidence": 0.6492074191570282}]}, {"text": "In the evaluation section, the results of TopicTiling are demonstrated on these datasets, followed by a conclusion and discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Choi dataset) is commonly used in the field of TS (see e.g. ().", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9134583175182343}, {"text": "TS", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9736772179603577}]}, {"text": "It is a corpus, generated artificially from the Brown corpus and consists of 700 documents.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.9741172790527344}]}, {"text": "For document generation, ten segments of 3-11 sentences each, taken from different documents, are combined forming one document.", "labels": [], "entities": [{"text": "document generation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7451046705245972}]}, {"text": "400 documents consist of segments with a sentence length of 3-11 sentences and there are 100 documents each with sentence lengths of 3-5, 6-8 and 9-11.", "labels": [], "entities": []}, {"text": "(2003) present two corpora for written language, each having 500 documents, which are also generated artificially.", "labels": [], "entities": []}, {"text": "In comparison to Choi's dataset, the segments in its 'documents' vary from 4 to 22 segments, and are composed by concatenating full source documents.", "labels": [], "entities": [{"text": "Choi's dataset", "start_pos": 17, "end_pos": 31, "type": "DATASET", "confidence": 0.887389063835144}]}, {"text": "One dataset is generated based on WSJ documents of the Penn Treebank (PTB) project and the other is based on Topic Detection Track (TDT) documents.", "labels": [], "entities": [{"text": "WSJ documents", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9499762058258057}, {"text": "Penn Treebank (PTB) project", "start_pos": 55, "end_pos": 82, "type": "DATASET", "confidence": 0.9543776313463846}]}, {"text": "As the WSJ dataset seems to be harder (consistently higher error rates across several works), we use this dataset for experimentation.", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9707699716091156}]}, {"text": "The performance of TopicTiling is evaluated using two measures, commonly used in the TS task: The P k measure and the WindowDiff (WD) measure).", "labels": [], "entities": [{"text": "TS task", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.8824329972267151}]}, {"text": "Besides the training corpus, the following parameters need to be specified for LDA: The number of topics T , the number of sample iterations for the model m and two hyperparameters \u03b1 and \u03b2, specifying the sparseness of the topic-document and the topic-word distribution.", "labels": [], "entities": []}, {"text": "For the inference method, the number of sampling iterations i is required.", "labels": [], "entities": []}, {"text": "In line with, the following standard parameters are used: T = 100, \u03b1 = 50/T , \u03b2 = 0.01, m = 500, i = 100.", "labels": [], "entities": [{"text": "T", "start_pos": 58, "end_pos": 59, "type": "METRIC", "confidence": 0.9826924800872803}]}, {"text": "We use the JGibbsLDA implementation described in.", "labels": [], "entities": []}, {"text": "For the evaluation we use a 10-fold Cross Validation (CV): the full dataset of 700 documents is split into 630 documents for training the topic model and 70 documents that are segmented.", "labels": [], "entities": []}, {"text": "These two steps are repeated ten times to have all 700 documents segmented.", "labels": [], "entities": []}, {"text": "For this dataset, no part-of-speech based word filtering is necessary.", "labels": [], "entities": [{"text": "word filtering", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.6936494559049606}]}, {"text": "The results for different parameter settings are listed in.", "labels": [], "entities": []}, {"text": "When using only the window parameter without the mode (d=false), the results demonstrate a sig- nificant error reduction when using a window of 2 sentences.", "labels": [], "entities": []}, {"text": "An impairment is observed when using a too large window (w=5).", "labels": [], "entities": []}, {"text": "This is expected, as the size of the segments is in a range of 3-11 sentences: A window of 5 sentences therefore leads to blocks that contain segment boundaries.", "labels": [], "entities": []}, {"text": "We can also see that the mode method improves the results when using a window of one, except for the documents having small segments ranging from 3-5 sentences.", "labels": [], "entities": []}, {"text": "The lowest error rates are obtained with the mode method and a window size of 2.", "labels": [], "entities": []}, {"text": "As described above, the algorithm is also able to automatically estimate the number of segments using a threshold value (see).: Results on the Choi dataset without given number of segments as parameter.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 143, "end_pos": 155, "type": "DATASET", "confidence": 0.9542384743690491}]}, {"text": "For the evaluation on Galley's WSJ dataset, a topic model is created from the WSJ collection of the PTB project.", "labels": [], "entities": [{"text": "Galley's WSJ dataset", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.8828986883163452}, {"text": "WSJ collection of the PTB project", "start_pos": 78, "end_pos": 111, "type": "DATASET", "confidence": 0.821079432964325}]}, {"text": "The dataset for model estimation consists of 2499 WSJ articles, and is the same dataset Galley used as a source corpus.", "labels": [], "entities": [{"text": "model estimation", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7260176539421082}, {"text": "WSJ articles", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.9359137415885925}]}, {"text": "The evaluation generally leads to higher error rates than in the evaluation for the Choi dataset, as shown in.", "labels": [], "entities": [{"text": "error", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9776951670646667}, {"text": "Choi dataset", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.9247854650020599}]}, {"text": "In case of the WSJ dataset, we find the optimal setting for w=5.", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.9621671140193939}]}, {"text": "As the test documents contain whole articles, which consist of at least 4 sentences, a larger window is advantageous here, yet a value of 10 is too large.", "labels": [], "entities": []}, {"text": "Filtering the documents for parts of speech leads to \u223c 1% absolute error rate reduction, as can be seen in the last two columns of.", "labels": [], "entities": [{"text": "absolute error rate reduction", "start_pos": 58, "end_pos": 87, "type": "METRIC", "confidence": 0.9026298224925995}]}, {"text": "Again, we observe that the mode assignment always leads to better results, gaining at least 0.6%.", "labels": [], "entities": []}, {"text": "Especially the window size of 5 helps TopicTiling to decrease the error rate to a third of the value observed with d=false and w=1.", "labels": [], "entities": [{"text": "error rate", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9821661412715912}]}, {"text": "Similar to the previous findings, results decline when using a too large window.", "labels": [], "entities": []}, {"text": "shows the results we achieve with the threshold-based estimation of segment boundaries for the unfiltered and filtered data.", "labels": [], "entities": []}, {"text": "In contrast to the results obtained with the Choi dataset (see) no decline is observed when the threshold approach is used in combination with the window approach.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.959426760673523}]}, {"text": "We attribute this due to the small segments and documents used in the Choi setting.", "labels": [], "entities": []}, {"text": "Comparing the all-words data with pos-filtered data, an improvement is always observed.", "labels": [], "entities": []}, {"text": "Also a continuous decreasing of both error rates, P k and W D, is detected when using the mode and using a larger window size, even for w=10.", "labels": [], "entities": []}, {"text": "The reason for this is that too many boundaries are detected when using small windows.", "labels": [], "entities": []}, {"text": "As the window approach smoothes the similarity scores, this leads to less segmentation boundaries, which improve results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results based on the Choi dataset with varying  parameters.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.6647629588842392}]}, {"text": " Table 2: Results on the Choi dataset without given num- ber of segments as parameter.", "labels": [], "entities": [{"text": "Choi dataset", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9496941566467285}]}, {"text": " Table 3: Lowest P k values for the Choi data set for vari- ous algorithms in the literature with number of segments  provided", "labels": [], "entities": [{"text": "Lowest P k", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9327318469683329}, {"text": "Choi data set", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.7532407641410828}]}, {"text": " Table 4: Results for Galley's WSJ dataset using differ- ent parameters with using unfiltered documents and with  filtered documents using only verbs, nouns (proper and  common) and adjectives.", "labels": [], "entities": [{"text": "Galley's WSJ dataset", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.7947299480438232}]}, {"text": " Table 5: Table with results the WSJ dataset without num- ber of segments given, using all words and content words  only.", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9546857178211212}]}, {"text": " Table 6: List of results based on the WSJ dataset. Values  for C99, U00 and LCseg as stated in (Galley et al., 2003).", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.9805322289466858}]}]}