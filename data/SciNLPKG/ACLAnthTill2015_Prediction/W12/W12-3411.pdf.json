{"title": [{"text": "Korean Treebank Transformation for Parser Training", "labels": [], "entities": [{"text": "Korean Treebank", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9466102719306946}, {"text": "Parser Training", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.8701118528842926}]}], "abstractContent": [{"text": "Korean is a morphologically rich language in which grammatical functions are marked by inflections and affixes, and they can indicate grammatical relations such as subject, object, predicate, etc.", "labels": [], "entities": []}, {"text": "A Korean sentence could bethought as a sequence of eojeols.", "labels": [], "entities": []}, {"text": "An eo-jeol is a word or its variant word form agglutinated with grammatical affixes, and eo-jeols are separated by white space as in En-glish written texts.", "labels": [], "entities": []}, {"text": "Korean treebanks (Choi et al., 1994; Han et al., 2002; Korean Language Institute, 2012) use eojeol as their fundamental unit of analysis, thus representing an eojeol as a prepreterminal phrase inside the constituent tree.", "labels": [], "entities": [{"text": "Korean Language Institute, 2012", "start_pos": 55, "end_pos": 86, "type": "DATASET", "confidence": 0.9328388929367065}]}, {"text": "This eojeol-based annotating schema introduces various complexity to train the parser, for example an entity represented by a sequence of nouns will be annotated as two or more different noun phrases, depending on the number of spaces used.", "labels": [], "entities": []}, {"text": "In this paper, we propose methods to transform eojeol-based Korean treebanks into entity-based Korean treebanks.", "labels": [], "entities": [{"text": "eojeol-based Korean treebanks into entity-based Korean treebanks", "start_pos": 47, "end_pos": 111, "type": "DATASET", "confidence": 0.622077043567385}]}, {"text": "The methods are applied to Sejong treebank, which is the largest constituent treebank in Korean, and the transformed treebank is used to train and test various probabilistic CFG parsers.", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 27, "end_pos": 42, "type": "DATASET", "confidence": 0.9549783170223236}]}, {"text": "The experimental result shows that the proposed transformation methods reduce ambiguity in the training corpus, increasing the overall F1 score up to about 9 %.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9905053973197937}]}], "introductionContent": [{"text": "The result of syntactic parsing is useful for many NLP applications, such as named entity recognition (, semantic role labeling (), or sentimental analysis (.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.739025890827179}, {"text": "named entity recognition", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.6535577972730001}, {"text": "semantic role labeling", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.6619532108306885}, {"text": "sentimental analysis", "start_pos": 135, "end_pos": 155, "type": "TASK", "confidence": 0.9199965596199036}]}, {"text": "Currently most of the state-of-the-art constituent parsers take statistical parsing approach (, which use manually annotated syntactic trees to train the probabilistic models of each consituents.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.588591530919075}]}, {"text": "Even though there exist manually annotated Korean treebank corpora such as Sejong Treebank), very few research projects about the Korean parser, especially using phrase structure grammars have been conducted.", "labels": [], "entities": [{"text": "Sejong Treebank", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.8771778345108032}]}, {"text": "In this paper, we aim to transform the treebank so that it could be better used as training data for the alreadyexisting English constituent parsers.", "labels": [], "entities": []}, {"text": "Most of Korean treebank corpora use eojeols as their fundamental unit of analysis.", "labels": [], "entities": [{"text": "Korean treebank corpora", "start_pos": 8, "end_pos": 31, "type": "DATASET", "confidence": 0.7480850219726562}]}, {"text": "An eojeol is a word or its variant word form agglutinated with grammatical affixes, and eojeols are separated by white space as in English written texts). is one of the example constituent tree from the Sejong Treebank.", "labels": [], "entities": [{"text": "Sejong Treebank", "start_pos": 203, "end_pos": 218, "type": "DATASET", "confidence": 0.8994204699993134}]}, {"text": "As can be observed, an eojeol is always determined as a prepreterminal phrase . But this kind of bracketing guideline could cause ambiguities to the existing algorithms for parsing English, because: (1) English does not have the concept of \"eojeol\", and (2) an eojeol can contain two or more morphemes with different grammatical roles.", "labels": [], "entities": []}, {"text": "For example, Korean case par- ticles ('josa') are normally written inside the same eojeol with their argument nouns, but the whole eojeol is always considered as a prepreterminal noun phrase in the Korean treebank, as can be seen in the eojeol Ungaro-GA.", "labels": [], "entities": []}, {"text": "Considering that the case particles in Korean play important role in determining the syntactic structure of a sentence, this could cause loss of information during the training phase.", "labels": [], "entities": []}, {"text": "Moreover, Emanuel Ungaro is considered as two different noun phrases, because they simply belong to the two different eojeols (that is, a space exists between eojeols Emanuel and Ungaro-GA).", "labels": [], "entities": []}, {"text": "In this paper, we propose methods to refine the Sejong treebank which is currently the largest Korean treebank corpus.", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.9151734411716461}, {"text": "Korean treebank corpus", "start_pos": 95, "end_pos": 117, "type": "DATASET", "confidence": 0.8894396424293518}]}, {"text": "The methods are aimed at decreasing the ambiguities during the training phase of parsers, by separating phrases which are integrated into the same prepreterminal phrase due to the reason that they happen to be in the same eojeol, and integrating phrases into the same prepreterminal phrase which are separated because they happen to be in different eojeols.", "labels": [], "entities": []}, {"text": "The refined datasets are trained and tested against three state-of-the-art parsers, and the evaluation results for each dataset are reported.", "labels": [], "entities": []}, {"text": "In section 2, the work about Korean parsers are briefly introduced.", "labels": [], "entities": []}, {"text": "Sejong treebank is described with more detailed explanation in section 3, while the methods to transform the treebank are introduced in section 4.", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9283561706542969}]}, {"text": "In section 5 the evaluation results of the transformed treebank using the three existing stateof-the-art parsers are introduced with an error report, and we discuss conclusions in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, several experiment results using the standard F1 metric (2P R/(P + R)) are introduced to show the effect of each transforming method, and the most frequently shown error cases are explained.", "labels": [], "entities": [{"text": "F1 metric (2P R/(P + R))", "start_pos": 63, "end_pos": 87, "type": "METRIC", "confidence": 0.807113653421402}]}, {"text": "The proposed transformation methods are applied to the Sejong treebank, and the converted treebanks are used to train and test three different well-known statistical parsers, namely Stanford parser (, Bikel-Collins parser and Berkeley parser ().", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9280709326267242}]}, {"text": "To figure out the effect of each method, all six methods are sequentially applied one by one, and each version of the treebank is used to train and test each parser.", "labels": [], "entities": []}, {"text": "The baseline treebank is the original Sejong treebank without any transformations.", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.7537633180618286}]}, {"text": "For the Korean headword extraction which will be used during parsing, the head percolation rule of (Choi and Palmer, 2011) is adapted.", "labels": [], "entities": [{"text": "headword extraction", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.6921039968729019}, {"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9694194197654724}]}, {"text": "According to that paper, particles and endings were the most useful morphemes to determine dependencies between eojeols.", "labels": [], "entities": []}, {"text": "Based on the observation, their rules are changed so that they give the best priorities on those morphemes.", "labels": [], "entities": []}, {"text": "We use the preprocessing method described in) for training trees.", "labels": [], "entities": []}, {"text": "It replaces symboles with PennTreebank-like tags and corrects wrong morpheme See for its transcription and translation.", "labels": [], "entities": [{"text": "PennTreebank-like", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.9404550790786743}]}, {"text": "boundary marks within the eojeol.", "labels": [], "entities": [{"text": "eojeol", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.9099597930908203}]}, {"text": "Methods are applied cumulatively; for example, symbol 'M 1-6' means the version of a treebank to which method 1, 2, 3, 4, 5 and 6 are applied cumulatively.", "labels": [], "entities": []}, {"text": "System Corpus PR F1 Stan.", "labels": [], "entities": [{"text": "System Corpus PR F1 Stan", "start_pos": 0, "end_pos": 24, "type": "DATASET", "confidence": 0.9590099096298218}]}, {"text": "shows the experimental results on each version of the treebanks using each parser.", "labels": [], "entities": []}, {"text": "Since the corpus covers various domains (i.e. the style of sentences is not homogeneous.), we perform 10-fold cross-validation for our experiments.", "labels": [], "entities": []}, {"text": "represents Stanford parser, Bikel.", "labels": [], "entities": []}, {"text": "represents BikelCollins parser, and Berk.", "labels": [], "entities": [{"text": "Berk", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.6161510348320007}]}, {"text": "For the Berkeley parser, we set the number of iteration as two for latent annotations.", "labels": [], "entities": []}, {"text": "In this set of experiments, only phrase tags are the target of training and testing, not including functional tags.", "labels": [], "entities": []}, {"text": "As can be observed from the evaluation result, the performance is improved due to methods 2 and 6 are quite big compared to the effect of other four As pointed out by reviewers, we are planning the reversibility of transformations to be evaluated on the same trees for meaning comparison.  methods.", "labels": [], "entities": []}, {"text": "Especially, the performance increase due to the method 6 strongly suggests that Sejong phrase tagsets are not enough to distinguish the types of phrases effectively.", "labels": [], "entities": [{"text": "Sejong phrase tagsets", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.6441137989362081}]}, {"text": "Except those two methods, only the method 5 increases the overall performance slightly, and methods 1, 3 and 4 do not have any significant effect on the performance or even sometimes decrease the overall performance.", "labels": [], "entities": []}, {"text": "Although the usage of functional tags is different from that of phrase tags, the Sejong treebank has a very rich functional tag set.", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 81, "end_pos": 96, "type": "DATASET", "confidence": 0.902223527431488}]}, {"text": "Considering the results of the previous experiments, it is highly likely that some of phrasal information is encoded into the functional tags.", "labels": [], "entities": []}, {"text": "To prove that, another set of experiments is carried out.", "labels": [], "entities": []}, {"text": "In this time, parsers are trained not only on phrase tags but also on functional tags.", "labels": [], "entities": []}, {"text": "As can be observed, by keeping functional tags to train and test parsers, the baseline performance increases 3 to 6 % for the Stanford and Berkeley parsers.", "labels": [], "entities": []}, {"text": "Only the performance of the Bikel parser is decreased -it is highly possible that the parser fails to find out the appropriate headword for each possible tag, because the number of possible tags is increased greatly by using the functional tags along with the phrase tags.", "labels": [], "entities": []}, {"text": "In both set of experiments, the method 3 decreases the overall performance.", "labels": [], "entities": []}, {"text": "This strongly suggests that finding the actual argument of josa directly is quite a challenging work.", "labels": [], "entities": []}, {"text": "The performance drop is considered mainly because the branching problem at the higher level of the constituent tree is counted twice due to the josa.", "labels": [], "entities": []}, {"text": "To show the effect of the transformation methods more clearly, the Penn Korean Treebank () is used as another treebank for experimentation: (Chung et al., 2010) describes about major difficulties of parsing Penn Korean Treebank.", "labels": [], "entities": [{"text": "Penn Korean Treebank", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.9886083801587423}, {"text": "parsing", "start_pos": 199, "end_pos": 206, "type": "TASK", "confidence": 0.9492914080619812}, {"text": "Penn Korean Treebank", "start_pos": 207, "end_pos": 227, "type": "DATASET", "confidence": 0.9081516663233439}]}, {"text": "The same three parsers are trained and tested using the treebank.", "labels": [], "entities": []}, {"text": "Due to the different annotation guidelines and different tagsets, transformation methods 1, 5 and 6 cannot be applied on the treebank.", "labels": [], "entities": []}, {"text": "Thus, only method 2, 3 and 4 are used to transform the treebank.", "labels": [], "entities": []}, {"text": "The overall performance of training the Penn Korean treebank is higher than that of the Sejong treebank.", "labels": [], "entities": [{"text": "Penn Korean treebank", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.9861663579940796}, {"text": "Sejong treebank", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9100110530853271}]}, {"text": "There could be two possible explanations.", "labels": [], "entities": []}, {"text": "First one is, since the Penn Korean treebank tries to follow English Penn treebank guidelines as much as possible, thus annotation guidelines of the Korean Penn treebank could be much \"familiar\" to the parsers than that of the Sejong treebank.", "labels": [], "entities": [{"text": "Penn Korean treebank", "start_pos": 24, "end_pos": 44, "type": "DATASET", "confidence": 0.9491199254989624}, {"text": "English Penn treebank guidelines", "start_pos": 61, "end_pos": 93, "type": "DATASET", "confidence": 0.8260718435049057}, {"text": "Korean Penn treebank", "start_pos": 149, "end_pos": 169, "type": "DATASET", "confidence": 0.678356538216273}, {"text": "Sejong treebank", "start_pos": 227, "end_pos": 242, "type": "DATASET", "confidence": 0.9139571785926819}]}, {"text": "The second explanation is, since the domain of the Penn Korean treebank is much more restricted than that of the Sejong treebank, the system could be trained for the specific domain.", "labels": [], "entities": [{"text": "Penn Korean treebank", "start_pos": 51, "end_pos": 71, "type": "DATASET", "confidence": 0.9858894546826681}, {"text": "Sejong treebank", "start_pos": 113, "end_pos": 128, "type": "DATASET", "confidence": 0.9374271333217621}]}, {"text": "The best performance was gained with the Stanford parser, with the treebank transformed by method 2.", "labels": [], "entities": []}, {"text": "Actually, ( also investigated parsing accuracy on the Penn Korean treebank; the direct comparison could be very difficult because parsing criteria is different.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9822314381599426}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9638233780860901}, {"text": "Penn Korean treebank", "start_pos": 54, "end_pos": 74, "type": "DATASET", "confidence": 0.9877309203147888}, {"text": "parsing", "start_pos": 130, "end_pos": 137, "type": "TASK", "confidence": 0.9723951816558838}]}], "tableCaptions": [{"text": " Table 3: Evaluation results of parsers, with various trans- formed versions of the Sejong treebank.", "labels": [], "entities": [{"text": "Sejong treebank", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.9314126670360565}]}, {"text": " Table 4: Evaluation results of parsers, with phrase tags  and functional tags together as learning target.", "labels": [], "entities": []}, {"text": " Table 5: Evaluation on Penn Korean Treebank.", "labels": [], "entities": [{"text": "Penn Korean Treebank", "start_pos": 24, "end_pos": 44, "type": "DATASET", "confidence": 0.9568831125895182}]}]}