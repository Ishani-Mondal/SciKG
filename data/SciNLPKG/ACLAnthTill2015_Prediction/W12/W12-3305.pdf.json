{"title": [{"text": "Evaluating Unsupervised Ensembles when applied to Word Sense Induction", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.5985166529814402}]}], "abstractContent": [{"text": "Ensembles combine knowledge from distinct machine learning approaches into a general flexible system.", "labels": [], "entities": []}, {"text": "While supervised ensembles frequently show great benefit, unsupervised ensembles prove to be more challenging.", "labels": [], "entities": []}, {"text": "We propose evaluating various unsupervised ensembles when applied to the unsupervised task of Word Sense Induction with a framework for combining diverse feature spaces and clustering algorithms.", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.6077199876308441}]}, {"text": "We evaluate our system using standard shared tasks and also introduce new automated semantic evaluations and supervised baselines, both of which highlight the current limitations of existing Word Sense Induction evaluations.", "labels": [], "entities": [{"text": "Word Sense Induction evaluations", "start_pos": 191, "end_pos": 223, "type": "TASK", "confidence": 0.6348260715603828}]}], "introductionContent": [{"text": "Machine learning problems often benefit from many differing solutions using ensembles) and supervised Natural Language Processing tasks have been no exception.", "labels": [], "entities": []}, {"text": "However, use of unsupervised ensembles in NLP tasks has not yet been rigorously evaluated.", "labels": [], "entities": []}, {"text": "first considered unsupervised ensembles by combining four state of the art Word Sense Disambiguation systems using a simple voting scheme with much success.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.6184791723887125}]}, {"text": "Later, combined different feature sets using a probabilistic Word Sense Induction model and found that only some combinations produced an improved system.", "labels": [], "entities": []}, {"text": "These early and limited evaluations show both the promise and drawback of combining different unsupervised models: * This work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344 (LLNL-CONF-530791).", "labels": [], "entities": []}, {"text": "particular combinations provide a benefit but selecting these combinations is non-trivial.", "labels": [], "entities": []}, {"text": "We propose applying anew and more general framework for combining unsupervised systems known as Ensemble Clustering to unsupervised NLP systems and focus on the fully unsupervised task of Word Sense Induction.", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 188, "end_pos": 208, "type": "TASK", "confidence": 0.6443619231383005}]}, {"text": "Ensemble Clustering can combine together multiple and diverse clustering algorithms or feature spaces and has been shown to noticeably improve clustering accuracy for both text based datasets and other datasets ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9661344289779663}]}, {"text": "Since Word Sense Induction is fundamentally a clustering problem, with many variations, it serves well as a NLP case study for Ensemble Clustering.", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 6, "end_pos": 26, "type": "TASK", "confidence": 0.7534603277842203}]}, {"text": "The task of Word Sense Induction extends the problem of Word Sense Disambiguation by simply assuming that a model must first learn and define a sense inventory before disambiguating multi-sense words.", "labels": [], "entities": [{"text": "Word Sense Induction", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.7386059363683065}, {"text": "Word Sense Disambiguation", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.6436437964439392}]}, {"text": "This induction step frees the disambiguation process from any fixed sense inventory and can instead flexibly define senses based on observed patterns within a dataset).", "labels": [], "entities": []}, {"text": "However, this induction step has proven to be greatly challenging, in the most recent shared tasks, induction systems either appear to perform poorly or fail to outperform the simple Most Frequent Sense baseline.", "labels": [], "entities": []}, {"text": "In this work, we propose applying Ensemble Clustering as a general framework for combining not only different feature spaces but also a variety of different clustering algorithms.", "labels": [], "entities": []}, {"text": "Within this framework we will explore which types of models should be combined and how to best combine them.", "labels": [], "entities": []}, {"text": "In addition, we propose two new evaluations: (1) new semantic coherence measures that evaluate the seman- tic quality and uniqueness of induced word senses without referring to an external sense inventory (2) and anew set of baseline systems based on supervised learning algorithms.", "labels": [], "entities": []}, {"text": "With the new evaluations and a framework for combining general induction models, we intend to find not only improved models but a better understanding of how to improve later induction models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first propose evaluating ensemble configurations of Word Sense Induction models using the standard shared tasks from SemEval-1 (Agirre and Soroa, 2007a) and SemEval-2 ( . We then propose comparing these results, and past SemEval results, to supervised baselines as a gauge of how well the algorithms do compared to more informed models.", "labels": [], "entities": []}, {"text": "We then finally propose an intrinsic evaluation that rates the semantic interpretability and uniqueness of each induced sense.", "labels": [], "entities": []}, {"text": "Evaluating Ensemble Configurations must be done to determine which variation of Ensemble Clustering best applies to the Word Sense Induction tasks.", "labels": [], "entities": [{"text": "Word Sense Induction tasks", "start_pos": 120, "end_pos": 146, "type": "TASK", "confidence": 0.8145829141139984}]}, {"text": "Preliminary research has shown that Homogeneous ensemble combined with the HAC consensus function typically improve base models while combining heterogeneous induction models greatly reduces performance.", "labels": [], "entities": []}, {"text": "We thus propose various sets of ensembles to evaluate whether or not certain context models or clustering algorithms can be effectively combined: 1.", "labels": [], "entities": []}, {"text": "mixing different feature vector models with the same clustering algorithm, 2.", "labels": [], "entities": []}, {"text": "mixing different clustering algorithms using the same context model, 3.", "labels": [], "entities": []}, {"text": "mixing feature vector context models and graph context models using matching clustering algorithms, 4.", "labels": [], "entities": []}, {"text": "mixing all possible models, 5. and improving each heterogeneous algorithm by first boosting them with homogeneous ensembles.", "labels": [], "entities": []}, {"text": "SemEval Shared Tasks provide a shared corpus and evaluations for comparing different WSI Models.", "labels": [], "entities": []}, {"text": "Both shared tasks from SemEval provide a corpus of training data for 100 multi-sense words and then compare the induced sense labels generated fora set of test contexts with human annotated sense using a fixed sense inventory.", "labels": [], "entities": []}, {"text": "The task provides two evaluations: an unsupervised evaluation that treats each set of induced senses as a clustering solution and measures accuracy with simple metrics such as the Paired F-Score, V-Measure, and Adjusted Mutual Information; and a supervised evaluation that builds a simple supervised word sense disambiguation system using the sense labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9990003705024719}, {"text": "F-Score", "start_pos": 187, "end_pos": 194, "type": "METRIC", "confidence": 0.5331530570983887}]}, {"text": "Supervised Baselines should set an upper limit on the performance we can expect from most unsupervised algorithms, as has been observed in other NLP tasks.", "labels": [], "entities": []}, {"text": "We train these baselines by using feature vector models in combination with the SemEval-1 dataset . We propose several standard supervised machine learning algorithms as different baselines: Naive Bayes, Logistic Regression, Decision Trees, Support Vector Machines, and various ensembles of each such as simple Bagged Ensembles.", "labels": [], "entities": [{"text": "SemEval-1 dataset", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.813798189163208}]}, {"text": "Semantic Coherence evaluations balance the shared task evaluations by functioning without a sense inventory.", "labels": [], "entities": []}, {"text": "Any evaluation against an existing inventory cannot accurately measure newly detected senses, overlapping senses, or different sense granularities.", "labels": [], "entities": []}, {"text": "Therefore, our proposed sense coherence measures focus on the semantic quality of a sense, adapted from topic coherence measures).", "labels": [], "entities": []}, {"text": "These evaluate the degree to which features in an induced sense describe the meaning of the word sense, where highly related features constitute a more coherent sense and unrelated features indicate an incoherent sense.", "labels": [], "entities": []}, {"text": "Furthermore, we adapt the coherence metric to evaluate the amount of semantic overlap between any two induced senses.", "labels": [], "entities": []}], "tableCaptions": []}