{"title": [], "abstractContent": [{"text": "What makes a tweet worth sharing?", "labels": [], "entities": []}, {"text": "We study the content of tweets to uncover linguistic tendencies of shared microblog posts (re-tweets), by examining surface linguistic features , deeper parse-based features and Twitter-specific conventions in tweet content.", "labels": [], "entities": []}, {"text": "We show how these features correlate with a functional classification of tweets, thereby categorizing people's writing styles based on their different intentions on Twitter.", "labels": [], "entities": []}, {"text": "We find that both linguistic features and functional classification contribute to re-tweeting.", "labels": [], "entities": []}, {"text": "Our work shows that opinion tweets favor originality and pithiness and that update tweets favor direct statements of a tweeter's current activity.", "labels": [], "entities": []}, {"text": "Judicious use of #hashtags also helps to encourage retweeting.", "labels": [], "entities": []}], "introductionContent": [{"text": "Tweeting 1 is a modern phenomenon.", "labels": [], "entities": [{"text": "Tweeting 1", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.8381859362125397}]}, {"text": "Complementing short message texting, instant messaging, and email, tweeting is a public outlet for netizens to broadcast themselves.", "labels": [], "entities": []}, {"text": "The short, informal nature of tweets allows users to post often and quickly react to others' posts, making Twitter an important form of close-to-real-time communication.", "labels": [], "entities": []}, {"text": "Perhaps as a consequence of its usability, form, and public nature, tweets are becoming an important source of data for mining emerging trends and opinion analysis.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 147, "end_pos": 163, "type": "TASK", "confidence": 0.6875350326299667}]}, {"text": "Of particular interest are retweets, tweets that share previous tweets from others.", "labels": [], "entities": []}, {"text": "Tweets with a high retweet count can betaken as a first cut towards trend detection.", "labels": [], "entities": [{"text": "trend detection", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7955442667007446}]}, {"text": "It is known that social network effects exert marked influence on re-tweeting (.", "labels": [], "entities": []}, {"text": "But what about the content of the post?", "labels": [], "entities": []}, {"text": "To the best of our knowledge, little is known about what properties of tweet content motivate people to share.", "labels": [], "entities": []}, {"text": "Are there content signals that mark a tweet as important and worthy of sharing?", "labels": [], "entities": []}, {"text": "To answer these questions, we delve into the data, analyzing tweets to better understand posting behavior.", "labels": [], "entities": []}, {"text": "Using a classification scheme informed by previous work, we annotate 860 tweets and propagate the labeling to a large 9M corpus (Section 2).", "labels": [], "entities": [{"text": "9M corpus", "start_pos": 118, "end_pos": 127, "type": "DATASET", "confidence": 0.8228131532669067}]}, {"text": "On this corpus, we observe regularities in emoticon use, sentiment analysis, verb tense, named entities and hashtags, that enable us to specify feature classes for re-tweet prediction.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.9093188047409058}, {"text": "re-tweet prediction", "start_pos": 164, "end_pos": 183, "type": "TASK", "confidence": 0.7185284495353699}]}, {"text": "Importantly, the outcome of our analysis is that a single holistic treatment of tweets is suboptimal, and that re-tweeting is better understood with respect to the specific function of the individual tweet.", "labels": [], "entities": []}, {"text": "These building blocks allow us to build a per-function based re-tweet predictor (Section 4) that outperforms a baseline.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collected three months of public tweets (from July to September in 2011) through Twitter's streaming API 2 . Non-English tweets were removed using regular expressions, incurring occasional errors.", "labels": [], "entities": []}, {"text": "We note that tweets containing URLs are often spam tweets or tweets from automated services (e.g., Foursquare location check-ins), and that any retweet analysis of such tweets would need to focus much more on the linked content rather than the tweet's content.", "labels": [], "entities": [{"text": "Foursquare location check-ins", "start_pos": 99, "end_pos": 128, "type": "DATASET", "confidence": 0.8526238004366556}]}, {"text": "We thus removed tweets containing URLs from our study.", "labels": [], "entities": []}, {"text": "While this limits the scope of our study, we wanted to focus on the (linguistic quality of) content alone.", "labels": [], "entities": []}, {"text": "The final dataset explicitly identifies 1,558,996 retweets (hereafter, RT-data) and 7,989,009 non-retweets.", "labels": [], "entities": [{"text": "RT-data", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.7077496647834778}]}, {"text": "To perform further analysis on Twitter hashtags (i.e., \"#thankyousteve\"), we break them into separate words using the Microsoft Data-Driven Word-Breaking API . This also benefits the classification task in terms of converting hashtags to known words.", "labels": [], "entities": []}, {"text": "We employed U.S.-based workers on Amazon's Mechanical Turk to annotate a random subset of the preprocessed tweets.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.9176317602396011}]}, {"text": "We collected annotations for 860 tweets (520 retweets; 340 non-retweets) randomly sampled from the final dataset, paying 10 cents per block of 10 tweets labeled.", "labels": [], "entities": []}, {"text": "Each tweet was labeled by 3 different workers who annotated using the Level-2 scheme.", "labels": [], "entities": []}, {"text": "Gold standard labels were inferred by majority.", "labels": [], "entities": [{"text": "Gold standard labels", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.8196661869684855}]}, {"text": "Inter-annotator agreement via Fleiss' \u03ba showed strong (0.79) and modest (0.43) agreement at Level-1 and Level-2, respectively.'s rightmost columns illustrate the distribution of the annotated tweets on each category.", "labels": [], "entities": []}, {"text": "From our Level-1 classification, Opinion, Update and Interaction, makeup the bulk of the tweets in the annotated sample set.", "labels": [], "entities": [{"text": "Interaction", "start_pos": 53, "end_pos": 64, "type": "METRIC", "confidence": 0.9235317707061768}]}, {"text": "The remaining categories of Facts, Deals and Others makeup only 8.1% in total.", "labels": [], "entities": [{"text": "Facts, Deals and Others", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.8524977445602417}]}, {"text": "We thus focus only on the three major groups.", "labels": [], "entities": []}, {"text": "We first examine RTpF distribution over the 9M tweets in the dataset.", "labels": [], "entities": [{"text": "RTpF", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.8434098958969116}]}, {"text": "plots RTpF rank against retweet count on both normal and log-log scales.", "labels": [], "entities": [{"text": "RTpF rank", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.9735634922981262}]}, {"text": "While the normal scale seems to show atypical exponential curve, the log-log scale reveals a clear inflection point that corresponds to an RTpF of 0.1.", "labels": [], "entities": [{"text": "RTpF", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.9963490962982178}]}, {"text": "We use this inflection point to break the predicted RTpF values into three ordinal classes: no retweets (\"N\", RTpF = 0), low (\"L\", RTpF < 0.1), and high (\"H\", RTpF \u2265 0.1).", "labels": [], "entities": []}, {"text": "We use 10-fold cross validation logistic regression in Weka3 ( ) to learn prediction models.", "labels": [], "entities": [{"text": "Weka3", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.9574816823005676}]}, {"text": "The regression models use both binary presence-of feature classes (quotation; past, present tense; 16 types of discourse relations; 10 NE types; 3 hashtag positions) as well as normalized numeric features (tweet length, hashtag count, sentence similarity, 3 sentiment polarity strengths).", "labels": [], "entities": []}, {"text": "Note that the models reported here do not factor the content (lexi-   cal items) directly, but represent content through the lens of the feature classes given.", "labels": [], "entities": []}, {"text": "We build individual regression models for the three major Level-1 classes, and aggregate models that predict RTpF for all three classes.", "labels": [], "entities": [{"text": "RTpF", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9840686917304993}]}, {"text": "The two aggregate models differ in that one is informed of the Level-1 class of the tweets, while the other is not.", "labels": [], "entities": []}, {"text": "We report average F-measure in over the three RTpF classes (\"N\", \"L\" and \"H\").", "labels": [], "entities": [{"text": "F-measure", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9957177042961121}]}, {"text": "Adding the Level-1 classification improves the RTpF prediction result by 10% in terms of average F 1 . This results validate our hypothesis -we see that building separate logistic models for each class improves classification results uniformly for all three classes.", "labels": [], "entities": [{"text": "RTpF prediction", "start_pos": 47, "end_pos": 62, "type": "METRIC", "confidence": 0.9068673551082611}, {"text": "F 1", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9850935339927673}]}], "tableCaptions": [{"text": " Table 2: Weighted average F-measure results for  the labeled LDA classification. Legend: C: tweet  context; I: Interaction; T: Tense; D: Discourse Rela- tions; H: Hashtags; E: Named Entities.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.7511564493179321}]}, {"text": " Table 3: Manual sentiment annotation results and  confusion matrix. Bolded numbers highlight the er- ror caused by neutral posts.", "labels": [], "entities": [{"text": "Manual sentiment annotation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6185406943162283}, {"text": "er- ror", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.9393685062726339}]}, {"text": " Table 4: The distribution of top 100 named entities 8 .", "labels": [], "entities": []}, {"text": " Table 6: Logistic regression results. Salient features  also shown with their respective weight, where a +ve  value denotes a +ve contribution to retweet volume.", "labels": [], "entities": []}]}