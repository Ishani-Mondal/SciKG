{"title": [{"text": "Automatic pronunciation assessment for language learners with acoustic-phonetic features", "labels": [], "entities": [{"text": "Automatic pronunciation assessment", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7584854165712992}]}], "abstractContent": [{"text": "Computer-aided spoken language learning has been an important area of research.", "labels": [], "entities": [{"text": "Computer-aided spoken language learning", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6251851543784142}]}, {"text": "The assessment of a learner\"s pronunciation with respect to native pronunciation lends itself to automation using speech recognition technology.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7071136087179184}]}, {"text": "However phone recognition accuracies achievable in state-of-the-art automatic speech recognition systems make their direct application challenging.", "labels": [], "entities": [{"text": "phone recognition", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.8073429465293884}, {"text": "speech recognition", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.7266044169664383}]}, {"text": "In this work, linguistic knowledge and the knowledge of speech production are incorporated to obtain a system that discriminates clearly between native and non-native speech.", "labels": [], "entities": []}, {"text": "Experimental results on aspirated consonants of Hindi by 10 speakers shows that acoustic-phonetic features outperform traditional cepstral features in a statistical likelihood based assessment of pronunciation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Fluency in spoken language by a language learner must be judged based on the achieved articulation and prosody in comparison with that of native speakers of the language.", "labels": [], "entities": []}, {"text": "The articulation is influenced by how well the learner has mastered the pronunciation of the phone set of the new language as well as the usage of the phones in the context of the words.", "labels": [], "entities": []}, {"text": "Language learning is an important activity and automating aspects of it via speech recognition technology has been an area of recent research globally (.", "labels": [], "entities": [{"text": "Language learning", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7137173265218735}]}, {"text": "One aspect of spoken language learning that lends itself to such automation is the assessment of pronunciation.", "labels": [], "entities": [{"text": "assessment of pronunciation", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.8325799306233724}]}, {"text": "The phones uttered by the speaker can be compared to their native acoustic forms to provide corrective feedback about the extent and type of errors.", "labels": [], "entities": []}, {"text": "Automatic speech recognition (ASR) technology would seem to provide the solution to automatic pronunciation error detection by its ability to decode speech into word and phone sequences and provide acoustic likelihood scores indicating the match with trained native speech models.", "labels": [], "entities": [{"text": "Automatic speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7957245310147604}, {"text": "automatic pronunciation error detection", "start_pos": 84, "end_pos": 123, "type": "TASK", "confidence": 0.7052919566631317}, {"text": "acoustic likelihood scores", "start_pos": 198, "end_pos": 224, "type": "METRIC", "confidence": 0.8099521994590759}]}, {"text": "However, state-of-the-art ASR systems fare poorly on phone recognition accuracy unless aided by powerful language models.", "labels": [], "entities": [{"text": "ASR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9897394776344299}, {"text": "phone recognition", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7754339277744293}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.7938380241394043}]}, {"text": "In an application such as pronunciation assessment, language models would obscure genuine pronunciation errors by the non-native learner.", "labels": [], "entities": [{"text": "pronunciation assessment", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.955418735742569}]}, {"text": "Further, for better raw phone recognition accuracy, the acoustic models need to be trained on actual non-native speech.", "labels": [], "entities": [{"text": "raw phone recognition", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.6623113453388214}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.8347570300102234}]}, {"text": "Such a speech database is unlikely to be available.", "labels": [], "entities": []}, {"text": "A way to deal with the problem of poor phone recognition accuracies from ASR is to exploit any available knowledge about the type of pronunciation errors.", "labels": [], "entities": [{"text": "phone recognition", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.6735552698373795}, {"text": "ASR", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8065128326416016}]}, {"text": "It is observed, for instance, that the errors made by a non-native speaker learning the language (L2) tend to be heavily influenced by his own native tongue (L1).", "labels": [], "entities": []}, {"text": "These phone segment level errors arise from (1) the absence of certain L2 phones in the L1 leading to phone substitutions by available similar phones, and (2) phonotactic constraints of L1 leading to improper usage of phones in certain word-level contexts.", "labels": [], "entities": []}, {"text": "A knowledge of the common phone-level errors in the non-native speech can help to reduce the search space in speech decoding thus improving the phone recognition accuracy.", "labels": [], "entities": [{"text": "phone recognition", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.7225067913532257}, {"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9047010540962219}]}, {"text": "However, since the phone errors typically involve phone substitution by closely matching phones borrowed from the speaker\"s L1, the discrimination is more challenging.", "labels": [], "entities": []}, {"text": "Proper feature design in the acoustic space can contribute to improved discrimination between different phones that otherwise share several articulatory attributes.", "labels": [], "entities": []}, {"text": "In the present work, we investigate the design of acoustic features in the context of specific pronunciation errors made by learners of spoken Hindi.", "labels": [], "entities": []}, {"text": "We restrict ourselves to speakers whose L1 is Tamil.", "labels": [], "entities": []}, {"text": "This language-pair provides prominent examples of phone substitution errors arising from the differences in the phonetic inventories of languages of two distinct language groups viz.", "labels": [], "entities": [{"text": "phone substitution", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7548744976520538}]}, {"text": "Indo-Aryan (Hindi) and Dravidian (Tamil).", "labels": [], "entities": []}, {"text": "Although the reported work is restricted to a specific type of pronunciation error, namely that relating to aspirated stops, the methodology presented in this paper can be usefully generalised.", "labels": [], "entities": []}, {"text": "In the next section, we describe the task of pronunciation assessment in the context of the chosen languages and the design of databases for training and system evaluation.", "labels": [], "entities": [{"text": "pronunciation assessment", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.9630424082279205}]}, {"text": "Acoustic-phonetic features are described next followed by an experimental evaluation involving traditional ASR features as well.", "labels": [], "entities": [{"text": "ASR", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.9790343642234802}]}], "datasetContent": [{"text": "The two systems using two different acoustic feature sets are used to obtain the statistical likelihood for the presence or absence of aspiration for each unvoiced stop across the entire list of word utterances by a test speaker.", "labels": [], "entities": []}, {"text": "The MFCC-based system uses the HMM phone recogniser in a 2-class (aspirated/unaspirated) forced alignment mode on the unvoiced stops using 39 MFCCs.", "labels": [], "entities": [{"text": "HMM phone recogniser", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.6859113574028015}]}, {"text": "The AP system uses a 5-dimensional feature vector in a GMM framework.", "labels": [], "entities": []}, {"text": "A likelihood ratio distance measure is computed using equation.", "labels": [], "entities": [{"text": "likelihood ratio distance measure", "start_pos": 2, "end_pos": 35, "type": "METRIC", "confidence": 0.9294788986444473}]}, {"text": "where is the likelihood of a test point x in the observation space for model of class 1 (likewise for class 2).", "labels": [], "entities": []}, {"text": "Here class1 refers to unaspirated stops and class2 to aspirated stops.", "labels": [], "entities": []}, {"text": "In case of proper articulation, d(x) is expected to be greater than zero for unaspirated stops and less than zero for aspirated stops.", "labels": [], "entities": [{"text": "d(x)", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.8916074335575104}]}, {"text": "For each test speaker, we compute the distribution of the likelihood ratios computed across the speaker\"s set of intended unaspirated stops and also across the set of intended aspirated stops.", "labels": [], "entities": []}, {"text": "If the stops are all properly articulated, we expect a good separation of the two distributions.", "labels": [], "entities": []}, {"text": "show the distributions obtained for each of the 10 native and non-native speakers using the AP features system.", "labels": [], "entities": []}, {"text": "We note the prominent difference in the extent of overlap between the likelihood ratios in the case of native speakers with respect to that of non-native speakers.", "labels": [], "entities": []}, {"text": "shows the corresponding results for the MFCC feature system.", "labels": [], "entities": [{"text": "MFCC feature", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.6775335371494293}]}, {"text": "While there is a difference in the overlap observed for the non-native speakers, the distinction between native and non-native speakers is much more clear across speakers with the AP features.", "labels": [], "entities": []}, {"text": "The difference between the performances of MFCC and AP features in the task of detecting nonnative pronunciation can be understood from the values of F-ratios across the 10 speakers in.", "labels": [], "entities": [{"text": "detecting nonnative pronunciation", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.8767514228820801}, {"text": "F-ratios", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9838654398918152}]}, {"text": "The F-ratio is computed for the pair of corresponding of unaspirated-aspirated likelihood ratio distributions for each speaker and each feature set.", "labels": [], "entities": [{"text": "F-ratio", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9985461235046387}]}, {"text": "A larger value of F-ratio indicates a better separation of the particular speaker\"s aspirated and unaspirated utterances in the corresponding feature space, which maybe interpreted as higher intelligibility.", "labels": [], "entities": [{"text": "F-ratio", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9984444975852966}]}, {"text": "We see from that this intelligibility measure takes on distinctly different values in the case of the AP feature based system, and consequently an accurate detection of non-nativeness is possible.", "labels": [], "entities": []}, {"text": "In the case of the MFCC features, however, there is no clear threshold separating the F-ratios of nonnative from native speakers.", "labels": [], "entities": [{"text": "F-ratios", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9890103936195374}]}, {"text": "To summarise, we have proposed a methodology for evaluating pronunciation quality in the context of a selected phonemic attribute.", "labels": [], "entities": []}, {"text": "It was demonstrated that acoustic-phonetic features provide better discriminability between correctly and incorrectly uttered aspirated stops of Hindi compared with the more generic MFCC features.", "labels": [], "entities": []}, {"text": "Future work will address other phonemic attributes while also expanding the dataset of test speakers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. The F-ratio is computed for the pair of corresponding of unaspirated-aspirated likelihood  ratio distributions for each speaker and each feature set. A larger value of F-ratio indicates a  better separation of the particular speaker\"s aspirated and unaspirated utterances in the  corresponding feature space, which may be interpreted as higher intelligibility. We see from", "labels": [], "entities": [{"text": "F-ratio", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9980432987213135}, {"text": "F-ratio", "start_pos": 178, "end_pos": 185, "type": "METRIC", "confidence": 0.9960272312164307}]}]}