{"title": [{"text": "TTT: A tree transduction language for syntactic and semantic processing", "labels": [], "entities": [{"text": "TTT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.701257586479187}, {"text": "syntactic and semantic processing", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.6447665467858315}]}], "abstractContent": [{"text": "In this paper we present the tree to tree transduction language, TTT.", "labels": [], "entities": [{"text": "TTT", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.7290517091751099}]}, {"text": "We motivate the overall \"template-to-template\" approach to the design of the language, and outline its constructs, also providing some examples.", "labels": [], "entities": []}, {"text": "We then show that TTT allows transparent formalization of rules for parse tree refinement and correction, logical form refinement and predicate disam-biguation, inference, and verbalization of logical forms.", "labels": [], "entities": [{"text": "TTT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.6513205170631409}, {"text": "parse tree refinement and correction", "start_pos": 68, "end_pos": 104, "type": "TASK", "confidence": 0.7032723128795624}, {"text": "logical form refinement", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.6566509207089742}]}], "introductionContent": [{"text": "Pattern matching and pattern-driven transformations of list-structured symbolic expressions or trees are fundamental tools in AI.", "labels": [], "entities": [{"text": "Pattern matching", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8906504511833191}]}, {"text": "They facilitate many symbol manipulation tasks, including operations on parse trees and logical forms, and even inference and aspects of dialogue and translation.", "labels": [], "entities": [{"text": "symbol manipulation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7779087722301483}]}, {"text": "The TTT system allows concise and transparent specification of rules for such tasks, in particular (as we will show), parse tree refinement and correction, predicate disambiguation, logical form refinement, inference, and verbalization into English.", "labels": [], "entities": [{"text": "parse tree refinement and correction", "start_pos": 118, "end_pos": 154, "type": "TASK", "confidence": 0.7524027943611145}, {"text": "predicate disambiguation", "start_pos": 156, "end_pos": 180, "type": "TASK", "confidence": 0.7532080411911011}, {"text": "logical form refinement", "start_pos": 182, "end_pos": 205, "type": "TASK", "confidence": 0.6798174977302551}]}, {"text": "In parse tree refinement, our particular focus has been on repair of malformed parses of image captions, as obtained by the Charniak-Johnson parser).", "labels": [], "entities": [{"text": "parse tree refinement", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.8017321825027466}]}, {"text": "This has encompassed such tasks as distinguishing passive participles from past participles and temporal nominals from non-temporal ones, among other tasks which will be discussed later.", "labels": [], "entities": []}, {"text": "For example, standard treebank parses tag both past participles (as in \"has written\") and passive participles (as in \"was written\") as VBN.", "labels": [], "entities": []}, {"text": "This is undesirable for subsequent compositional interpretation, as the meanings of past and passive participles are distinct.", "labels": [], "entities": [{"text": "compositional interpretation", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.713064894080162}]}, {"text": "We can easily relabel the past participles as VBEN by looking for parse tree subexpressions where a VBN is preceded by a form of \"have\", either immediately or with an intervening adverb or adverbial, and replacing VBN by VBEN in such subexpressions.", "labels": [], "entities": []}, {"text": "Of course this can be accomplished in a standard symbol manipulation language like Lisp, but the requisite multiple lines of code obscure the simple nature of the task.", "labels": [], "entities": []}, {"text": "We have also been able to repair systematic PP (prepositional phrase) misattachments, at least in the limited domain of image captions.", "labels": [], "entities": [{"text": "PP (prepositional phrase) misattachments", "start_pos": 44, "end_pos": 84, "type": "TASK", "confidence": 0.6131158371766409}]}, {"text": "For example, a common error is attachment of a PP to the last conjunct of a conjunction, where instead the entire conjunction should be modified by the PP.", "labels": [], "entities": []}, {"text": "Thus when a statistically obtained parse of the sentence \" Tanya and Grandma Lillian at her highschool graduation party\" brackets as \"Tanya and (Grandma Lillian (at her highschool graduation party.))\", we want to lift the PP so that \"at her highschool graduation party\" modifies \"Tanya and Grandma Lillian\".", "labels": [], "entities": []}, {"text": "Another systematic error is faulty classification of relative pronouns/determiners as wh-question pronouns/determiners, e.g., \"the student whose mother contacted you\" vs. \"I know whose mother contacted you\" -an important distinction in compositional semantics.", "labels": [], "entities": []}, {"text": "(Note that only the first occurrence, i.e., the relative determiner, can be paraphrased as with the property that his, and only the second occurrence, in which whose forms a whnominal, can be paraphrased as the person with the property that his.)", "labels": [], "entities": []}, {"text": "An important point here is that detecting the relative-determiner status of a wh-word like whose may require taking account of an arbitrarily deep context.", "labels": [], "entities": []}, {"text": "For example, in the phrase \"the student in front of whose parents you are standing\", whose lies two levels of phrasal structure below the nominal it is semantically bound to.", "labels": [], "entities": []}, {"text": "Such phenomena motivate the devices in TTT for detecting \"vertical patterns\" of arbitrary depth.", "labels": [], "entities": [{"text": "TTT", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.6981394290924072}]}, {"text": "Furthermore, we need to be able to make local changes \"on the fly\" in matching vertical patterns, because the full set of tree fragments flanking a vertical match cannot in general be saved using match variables.", "labels": [], "entities": []}, {"text": "In the case of a wh-word that is to be re-tagged as a relative word, we need to rewrite it at the point where the vertical pattern matches it, rather than in a separate tree-(re)construction phase following the tree-matching phase.", "labels": [], "entities": []}, {"text": "An example of a discourse phenomenon that requires vertical matching is anaphoric referent determination.", "labels": [], "entities": [{"text": "anaphoric referent determination", "start_pos": 72, "end_pos": 104, "type": "TASK", "confidence": 0.6452035208543142}]}, {"text": "In particular, consider the wellknown rule that a viable referent for an anaphoric pronoun is an NP that C-commands it, i.e., that is a (usually left) sibling of an ancestor of the pronoun.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"John shows Lillian the snowman that he built\", the NP for John C-commands the pronominal NP for he, and thus is a viable referent for it (modulo gender and number agreement).", "labels": [], "entities": []}, {"text": "We will later show a simple TTT rule that tags such an anaphoric pronoun with the indices of its C-commanding NP nodes, thus setting the stage for semantic interpretation.", "labels": [], "entities": [{"text": "TTT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.7524806261062622}, {"text": "semantic interpretation", "start_pos": 147, "end_pos": 170, "type": "TASK", "confidence": 0.8265404999256134}]}, {"text": "We have also been able to perform Skolemization, conjunct separation, simple inference, and logical form verbalization with TTT and suspect its utility to logic tasks will increase as development continues.", "labels": [], "entities": [{"text": "Skolemization", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.8800348043441772}, {"text": "conjunct separation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7462958097457886}]}, {"text": "The rest of the paper is organized as follows: we discuss related work in section 2, discuss the TTT language (including pattern matching and transduction syntax, and some theoretical properties) in section 3, and go though several detailed example applications in section 4.", "labels": [], "entities": [{"text": "TTT language", "start_pos": 97, "end_pos": 109, "type": "TASK", "confidence": 0.6309541761875153}, {"text": "pattern matching", "start_pos": 121, "end_pos": 137, "type": "TASK", "confidence": 0.7851424515247345}]}, {"text": "A beta version of the system can be found at http://www.cs.rochester.edu/research/ttt/.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}