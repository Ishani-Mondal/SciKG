{"title": [{"text": "Morpheme-and POS-based IBM1 scores and language model scores for translation quality estimation", "labels": [], "entities": [{"text": "translation quality estimation", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.8738939960797628}]}], "abstractContent": [{"text": "We present a method we used for the quality estimation shared task of WMT 2012 involving IBM1 and language model scores calculated on morphemes and POS tags.", "labels": [], "entities": [{"text": "quality estimation shared task of WMT 2012", "start_pos": 36, "end_pos": 78, "type": "TASK", "confidence": 0.6649035598550525}]}, {"text": "The IBM1 scores calculated on morphemes and POS-4grams of the source sentence and obtained translation output are shown to be competitive with the classic evaluation metrics for ranking of translation systems.", "labels": [], "entities": [{"text": "IBM1", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.7891375422477722}]}, {"text": "Since these scores do not require any reference translations, they can be used as features for the quality estimation task presenting a connection between the source language and the obtained target language.", "labels": [], "entities": []}, {"text": "In addition, target language model scores of morphemes and POS tags are investigated as estimates for the obtained target language quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic quality estimation is a topic of increasing interest in machine translation.", "labels": [], "entities": [{"text": "Automatic quality estimation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6461165845394135}, {"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.8221580982208252}]}, {"text": "Different from evaluation task, quality estimation does not rely on any reference translations -it relies only on information about the input source text, obtained target language text, and translation process.", "labels": [], "entities": [{"text": "quality estimation", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.6162087023258209}]}, {"text": "Being anew topic, it still does not have well established baselines, datasets or standard evaluation metrics.", "labels": [], "entities": []}, {"text": "The usual approach is to use a set of features which are used to train a classifier in order to assign a prediction score to each sentence.", "labels": [], "entities": []}, {"text": "In this work, we propose a set of features based on the morphological and syntactic properties of involved languages thus abstracting away from word surface particularities (such as vocabulary and domain).", "labels": [], "entities": []}, {"text": "This approach is shown to be very useful for evaluation task).", "labels": [], "entities": []}, {"text": "The features investigated in this work are based on the language model (LM) scores and on the IBM1 lexicon scores.", "labels": [], "entities": [{"text": "IBM1 lexicon scores", "start_pos": 94, "end_pos": 113, "type": "DATASET", "confidence": 0.7666740218798319}]}, {"text": "The inclusion of IBM1 scores in translation systems has shown experimentally to improve translation quality (.", "labels": [], "entities": []}, {"text": "They also have been used for confidence estimation for machine translation (.", "labels": [], "entities": [{"text": "confidence estimation", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.6729350388050079}, {"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8213295340538025}]}, {"text": "The IBM1 scores calculated on morphemes and POS-4grams are shown to be competitive with the classic evaluation metrics based on comparison with given reference translations).", "labels": [], "entities": []}, {"text": "To the best of our knowledge, these scores have not yet been used for translation quality estimation.", "labels": [], "entities": [{"text": "translation quality estimation", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.89909694592158}]}, {"text": "The LM scores of words and POS tags are used for quality estimation in previous work, and in our work we investigate the scores calculated on morphemes and POS tags.", "labels": [], "entities": []}, {"text": "At this point, only preliminary experiments have been carried out in order to determine if the proposed features are promising at all.", "labels": [], "entities": []}, {"text": "We did not use any classifier, we used the obtained scores to rank the sentences of a given translation output from the best to the worst.", "labels": [], "entities": []}, {"text": "The Spearman's rank correlation coefficients between our ranking and the ranking obtained using human scores are then computed on the provided manually annotated data sets.", "labels": [], "entities": [{"text": "Spearman's rank correlation", "start_pos": 4, "end_pos": 31, "type": "METRIC", "confidence": 0.532412476837635}]}, {"text": "2 Morpheme-and POS-based features A number of features for quality estimation have been already investigated in previous work.", "labels": [], "entities": [{"text": "quality estimation", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.5629554390907288}]}, {"text": "In this paper, we investigate two sets of features which do not depend on any aspect of translation process but only on the morphological and syntactic structures of the involved languages: the IBM1 scores and the LM scores calculated on morphemes and POS tags.", "labels": [], "entities": []}, {"text": "The IBM1 scores describe the correspondences between the structures of the source and the target language, and the LM scores describe the structure of the target language.", "labels": [], "entities": []}, {"text": "In addition to the input source text and translated target language hypothesis, a parallel bilingual corpus for the desired language pair and a monolingual corpus for the desired target language are required in order to learn IBM1 and LM probabilities.", "labels": [], "entities": []}, {"text": "Appropriate POS taggers and tools for splitting words into morphemes are necessary for each of the languages.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.7720382213592529}]}, {"text": "The POS tags cannot be only basic but must have all details (e.g. verb tenses, cases, number, gender, etc.).", "labels": [], "entities": []}], "datasetContent": [{"text": "The IBM1 probabilities necessary for the IBM1 scores are learnt using the WMT 2010 News Commentary Spanish-English, French-English and German-English parallel texts.", "labels": [], "entities": [{"text": "WMT 2010 News Commentary Spanish-English", "start_pos": 74, "end_pos": 114, "type": "DATASET", "confidence": 0.9571102142333985}]}, {"text": "The language models are trained on the corresponding target parts of this corpus using the SRI language model tool).", "labels": [], "entities": [{"text": "SRI language model", "start_pos": 91, "end_pos": 109, "type": "DATASET", "confidence": 0.8010454177856445}]}, {"text": "The POS tags for all languages were produced using the TreeTagger 1 , and the morphemes are obtained using the Morfessor tool).", "labels": [], "entities": []}, {"text": "The tool is corpus-based and language-independent: it takes a text as input and produces a segmentation of the word forms observed in the text.", "labels": [], "entities": []}, {"text": "The obtained results are not strictly linguistic, however they often resemble a linguistic morpheme segmentation.", "labels": [], "entities": []}, {"text": "Once a morpheme segmentation has been learnt from some text, it can be used for segmenting new texts.", "labels": [], "entities": [{"text": "segmenting new texts", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.8598729173342387}]}, {"text": "In our experiments, the splitting are learnt from the training corpus used for the IBM1 lexicon probabilities.", "labels": [], "entities": [{"text": "IBM1 lexicon probabilities", "start_pos": 83, "end_pos": 109, "type": "DATASET", "confidence": 0.8808929324150085}]}, {"text": "The obtained segmentation is then used for splitting the corresponding source texts and hypotheses.", "labels": [], "entities": []}, {"text": "Detailed corpus statistics are shown in.", "labels": [], "entities": []}, {"text": "Using the obtained probabilities, the scores described in Section 2 are calculated for the provided annotated data: the English-Spanish data from two data sets range from 1 to 4, and for the third data set from 1 to 3.", "labels": [], "entities": []}, {"text": "The interpretation of human scores is: 1.", "labels": [], "entities": []}, {"text": "requires complete retranslation (bad) 2.", "labels": [], "entities": []}, {"text": "post-editing quicker than retranslation (edit \u2212 ); this class was omitted for the third data set 3.", "labels": [], "entities": []}, {"text": "little post-editing needed (edit + ) 4.", "labels": [], "entities": []}, {"text": "fit for purpose (good) As a first step, the arithmetic means and standard deviations are calculated for each feature and each class in order to see if the features are at all possible candidates for quality estimation, i.e. if the values for different classes are distinct.", "labels": [], "entities": []}, {"text": "After that, the main testis carried out: for each of the features, the Spearman correlation coefficient \u03c1 with the human ranking are calculated for each document.", "labels": [], "entities": [{"text": "Spearman correlation coefficient \u03c1", "start_pos": 71, "end_pos": 105, "type": "METRIC", "confidence": 0.7902987524867058}]}, {"text": "In total, 9 correlation coefficients are obtained for each score -four Spanish outputs from the WMT 2008 task, one Spanish and one English output from the WMT 2010 as well as one English and two German outputs from the WMT 2011 task.", "labels": [], "entities": [{"text": "correlation", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9622657895088196}, {"text": "WMT 2008 task", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.877910315990448}, {"text": "WMT", "start_pos": 155, "end_pos": 158, "type": "DATASET", "confidence": 0.9268902540206909}, {"text": "WMT 2011 task", "start_pos": 219, "end_pos": 232, "type": "DATASET", "confidence": 0.8869086106618246}]}, {"text": "The obtained correlation results were then summarised into the following two values: \u2022 mean a correlation coefficient averaged overall translation outputs; \u2022 rank> percentage of translation outputs where the particular feature has better correlation than the other investigated features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the corpora for training IBM1 lexicon models and language models.", "labels": [], "entities": []}, {"text": " Table 2: Arithmetic means with standard deviations of PLM6 and P4IBM1 sh scores for four translation outputs: first  two rows present decently separated classes, third row illustrates the overlap problem concerning the bad and the edit \u2212  class, the last row illustrates the overlap problem concerning the bad and the edit + class.", "labels": [], "entities": []}, {"text": " Table 3: Features sorted by average correlation (column 1) and rank> value (column 2). The most promising score  is the arithmetic mean of all individual features. The most promising individual features are POS-4gram IBM1 scores  followed by POS-6gram language model score.", "labels": [], "entities": []}]}