{"title": [{"text": "An End-to-End Evaluation of Two Situated Dialog Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "We present and evaluate two state-of-the art dialogue systems developed to support dialog with French speaking virtual characters in the context of a serious game: one hybrid statis-tical/symbolic and one purely statistical.", "labels": [], "entities": []}, {"text": "We conducted a quantitative evaluation where we compare the accuracy of the interpreter and of the dialog manager used by each system; a user based evaluation based on 22 subjects using both the statistical and the hybrid system; and a corpus based evaluation where we examine such criteria as dialog coherence, dialog success, interpretation and generation errors in the corpus of Human-System interactions collected during the user-based evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9974303841590881}]}, {"text": "We show that although the statistical approach is slightly more robust, the hybrid strategy seems to be better at guiding the player through the game.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been much research on creating situated conversational characters i.e., virtual characters (VCs) that look and act like humans but inhabit a virtual environment (.", "labels": [], "entities": []}, {"text": "In this paper, we focus on French speaking, situated conversational agents who interact with virtual characters in the context of a serious game designed to promote careers in the plastic industry (The Mission Plastechnologie game or MP).", "labels": [], "entities": []}, {"text": "We present and compare two state-of-the art dialogue systems.", "labels": [], "entities": []}, {"text": "The first system (H) is a hybrid approach that combines an information-state dialogue manager) with a classifier for interpreting the players' phrases.", "labels": [], "entities": []}, {"text": "The second system (QA) is a question/answering character model which predicts the system dialog move given a player's utterance (.", "labels": [], "entities": []}, {"text": "Both systems use a generation-by-selection strategy (; where the system's utterances are selected from a corpus of possible outputs based on the dialog manager output.", "labels": [], "entities": []}, {"text": "While previous work focuses on relatively short dialogs in a static setting, in our systems we consider long interactions in which dialogs occur in a setting that dynamically evolves as the game unfolds.", "labels": [], "entities": []}, {"text": "We evaluate the two dialog systems in the context of the 3D game they were developed for and seek to determine the degree to which a dialog system is operational.", "labels": [], "entities": []}, {"text": "To answer this question, we analyse both systems with respect not only to quantitative metrics such as accuracy but also to user-and corpus-based metrics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9970663189888}]}, {"text": "User-based metrics are computed based on a questionnaire the users filled in; while corpus-based metrics are manually extracted from the corpus of Player-VC interactions collected during the user-based evaluation.", "labels": [], "entities": []}, {"text": "As suggested by evaluation frameworks such as PARADISE () and SASSI), we show that a multiview evaluation permits a better assessment of how well the dialog system functions \"in the real world\".", "labels": [], "entities": [{"text": "SASSI", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.5265940427780151}]}, {"text": "The metrics proposed assess dialog success and coherence, as well the costs of dialog components.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the MP game, the dialogue strategies used in the different dialogs and the dialog data used for training.", "labels": [], "entities": []}, {"text": "Section 3 presents the two dialog systems we compare.", "labels": [], "entities": []}, {"text": "Section 4 presents the evaluation schemes used to compare these two systems and discusses the results obtained.", "labels": [], "entities": []}, {"text": "Section 5 concludes with directions for further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In evaluating the two systems, we seek to compare their usability: Which system is best suited for use by real users in the context of the MP serious game?", "labels": [], "entities": []}, {"text": "We also seek to better understand which module causes which errors and why.", "labels": [], "entities": []}, {"text": "To address these questions we conducted a quantitative evaluation where we compare the accuracy of the interpreter and the dialog manager integrated in each system; a user based evaluation involving 22 subjects using both the QA and the hybrid system; and a corpus based evaluation where we examine such criteria as dialog coherence, dialog success, interpretation and generation errors in the corpus of Human-System interactions collected during the user-based evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.998698353767395}]}, {"text": "We begin by evaluating the accuracy of the interpreter and the dialog manager used by the hybrid and the QA system respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9992712140083313}]}, {"text": "These two classifiers were trained on the Emospeech corpus mentioned above and evaluated with 30-fold cross-validation.", "labels": [], "entities": [{"text": "Emospeech corpus", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9733664989471436}]}, {"text": "Hybrid System As we mentioned in section 3.1, since the game includes different dialogs, a natural question arise: whether to implement the inter-preter with a single classifier for the whole dataset, or using a different classifier for each dialog in the game.", "labels": [], "entities": []}, {"text": "To answer this question, we compared the accuracy reached in each case.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9995346069335938}]}, {"text": "The details of these experiments are described in.", "labels": [], "entities": []}, {"text": "The highest accuracy is reported when using a single classifier for the whole game, reaching an accuracy of 90.26%, as opposed to 88.22% in average for each dialog.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9994868040084839}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9994687438011169}]}, {"text": "In both cases, the classifier used is LR, with L1 regularisation and applying the tf*idf filtering.", "labels": [], "entities": []}, {"text": "However, although the classifier trained on the whole dialog data has better accuracy (learning a model per dialog often run into the sparse data issue), we observed that, in practice, it often predicted interpretations that were unrelated to the current dialog thereby introducing incoherent responses in dialogs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9988962411880493}]}, {"text": "For instance, in the dialog below, the player wants to know how waste is managed in the factory.", "labels": [], "entities": []}, {"text": "The best prediction given by the interpreter is a goal related to another dialog thereby creating a mismatch with the DM expectations.", "labels": [], "entities": []}, {"text": "Re-interpretation then fails producing a system response that informs the player of the next goal to be pursued in the game instead of answering the player's request.", "labels": [], "entities": []}, {"text": "For the user based experiment, we therefore use the LR models with one classifier per dialog.", "labels": [], "entities": []}, {"text": "QA System For evaluating the QA classifier, we also compared results with or without tf*idf filtering.", "labels": [], "entities": [{"text": "QA", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7876954078674316}]}, {"text": "The best results were obtained by the LR classifier for each dialog with tf*idf filtering yielding an accuracy of 88.27% as shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9993606209754944}]}, {"text": "The accuracy of the interpreter and the dialog manager used by the hybrid and the QA system only gives partial information on the usability of the dialog engine in a situated setting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993340373039246}]}, {"text": "We therefore conducted a user-based evaluation which aims to assess the following points: interpretation quality, overall system quality, dialog clarity, game clarity and timing.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.9451500177383423}, {"text": "clarity", "start_pos": 145, "end_pos": 152, "type": "METRIC", "confidence": 0.9232550859451294}, {"text": "clarity", "start_pos": 159, "end_pos": 166, "type": "METRIC", "confidence": 0.9153069853782654}, {"text": "timing", "start_pos": 171, "end_pos": 177, "type": "METRIC", "confidence": 0.982004702091217}]}, {"text": "We invited 22 subjects to play the game twice,: Results of the LR classifier for mapping players' utterances to system moves, with content-words and a context of four previous system moves, with and without tf*idf filtering.", "labels": [], "entities": []}, {"text": "once with one system and once with the other.", "labels": [], "entities": []}, {"text": "The experiment is biased however in that the players always used the hybrid system first.", "labels": [], "entities": []}, {"text": "This is because in practice, the QA system often fail to provide novice players with enough guidance to play the game.", "labels": [], "entities": []}, {"text": "This can be fixed by having the player first use the hybrid system.", "labels": [], "entities": []}, {"text": "Interestingly, the game guidance made possible by the Information State approach is effective in guiding players through the game e.g., by proposing new goals to be discussed at an appropriate point in the dialog; and by taking dialog history into account.", "labels": [], "entities": []}, {"text": "After playing, each user completed the questionnaire shown in.", "labels": [], "entities": []}, {"text": "For those criteria such as dialog and game clarity, we do not report the scores since these are clearly impacted by how many times the player has played the game.", "labels": [], "entities": [{"text": "clarity", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9290329217910767}]}, {"text": "shows the mean of the quantitative scores given by the 22 subjects for interpretation, overall system quality and timing.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.9682613611221313}, {"text": "timing", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9859898090362549}]}, {"text": "We computed a significance test between the scores given by the subjects, using the Wilcoxon signed-rank test . As shown in the Table, for all criteria, except Q.4, the QA performs significantly (p < 0.01) better than the Hybrid system.", "labels": [], "entities": [{"text": "QA", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9266335964202881}]}, {"text": "The User-Based evaluation resulted in the collection of 298 dialogs (690 player and 1813 system turns) with the Hybrid system and 261 dialogs (773 player and 1411 system turns) with the QA system.", "labels": [], "entities": [{"text": "QA system", "start_pos": 186, "end_pos": 195, "type": "DATASET", "confidence": 0.9082064628601074}]}, {"text": "To better understand the causes of the scores derived from the user-filled questionnaire, we performed manual error analysis on this data focusing on dialog incoherences, dialog success, dialog management and generation errors (reported in).", "labels": [], "entities": [{"text": "dialog management", "start_pos": 187, "end_pos": 204, "type": "TASK", "confidence": 0.8607960641384125}]}], "tableCaptions": [{"text": " Table 2: Results of the LR classifier for mapping play- ers' utterances to system moves, with content-words and  a context of four previous system moves, with and with- out tf*idf filtering.", "labels": [], "entities": []}, {"text": " Table 4: Mean of the quantitative scores given by 22 in- dividuals. (*) denotes statistical significance at p < 0.01  (two-tailed significance level).", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988046884536743}, {"text": "statistical significance", "start_pos": 81, "end_pos": 105, "type": "METRIC", "confidence": 0.7750404477119446}]}, {"text": " Table 5: DM and generation errors detected in the hybrid  and the QA systems.", "labels": [], "entities": [{"text": "DM", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8806464076042175}]}, {"text": " Table 6: Overall dialog errors, the percentage of unsuc- cessful dialogs", "labels": [], "entities": []}]}