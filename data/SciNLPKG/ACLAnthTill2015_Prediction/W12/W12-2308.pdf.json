{"title": [], "abstractContent": [{"text": "We show that a class of cases that has been previously studied in terms of learning of abstract phonological underlying representations (URs) can be handled by a learner that chooses URs from a contextually conditioned distribution over observed surface representations.", "labels": [], "entities": []}, {"text": "We implement such a learner in a Maximum Entropy version of Optimality Theory, in which UR learning is an instance of semi-supervised learning.", "labels": [], "entities": []}, {"text": "Our objective function incorporates a term aimed to ensure generalization , independently required for phonotac-tic learning in Optimality Theory, and does not have a bias for single URs for morphemes.", "labels": [], "entities": []}, {"text": "This learner is successful on a test language provided by Tesar (2006) as a challenge for UR learning.", "labels": [], "entities": [{"text": "UR learning", "start_pos": 90, "end_pos": 101, "type": "TASK", "confidence": 0.9588118195533752}]}, {"text": "We also provide successful results on learning of a toy case modeled on French vowel alternations, which have also been previously analyzed in terms of abstract URs.", "labels": [], "entities": []}, {"text": "This case includes lexically conditioned variation, an aspect of the data that cannot be handled by abstract URs, showing that in this respect our approach is more general.", "labels": [], "entities": []}], "introductionContent": [{"text": "Phonological underlying representations (URs) introduce structural ambiguity.", "labels": [], "entities": []}, {"text": "For example, a morpheme that alternates in voicing, like the one meaning 'cat' in, could have as its underlying representation /bet/ or /bed/, amongst other possibilities.", "labels": [], "entities": []}, {"text": "Underlying /bed/ for surface requires final devoicing, while intervocalic voicing is required for underlying /bet+a/ for (/-a/ marks the plural).", "labels": [], "entities": []}, {"text": "The ambiguity can often be resolved on the basis of further data.", "labels": [], "entities": []}, {"text": "For example, if the language includes both voiced and voiceless consonants intervocalically, as in our toy language which also contains, then intervocalic voicing cannot apply across-the-board.", "labels": [], "entities": []}, {"text": "The standard phonological analysis, proposed by Jakobson (1948) for similar data from Russian, would thus posit /bed/ as the underlying form for 'cat', as in, along with a phonological grammar that generates final devoicing.", "labels": [], "entities": []}, {"text": "An alternating morpheme can also be given a UR that encodes only the fixed aspects of its structure.", "labels": [], "entities": [{"text": "UR", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9471659064292908}]}, {"text": "For example, 'cat' could have as its UR /beT/, where /T/ represents an alveolar plosive unspecified for voicing.", "labels": [], "entities": [{"text": "UR", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9659774303436279}]}, {"text": "The grammar would then fill in its voicing specification appropriately in both contexts, adding [\u2212voice] finally, and intervocalically.", "labels": [], "entities": []}, {"text": "One use of this underspecification is to capture instances of three-way contrast.", "labels": [], "entities": []}, {"text": "For example, the language in has consonants that alternate in voicing, as in the singular and plural of 'cat', as well as consonants that are both fixed voiceless ('dog'/'dogs') and voiced ('pig'/'pigs').", "labels": [], "entities": []}, {"text": "Given the URs shown in, the surface forms are generated if a grammar fills in voicing on underspecified consonants, and does not change specified ones, as in the analysis of Turkish in.", "labels": [], "entities": []}, {"text": "There are alternatives to this sort of underspecification.", "labels": [], "entities": []}, {"text": "For example, the analysis of Turkish in posits lexically specific intervocalic voicing, applying to some words but not others.", "labels": [], "entities": []}, {"text": "Here we pursue the learning consequences of a proposal in, which involves a grammar that chooses different URs across surface contexts.", "labels": [], "entities": []}, {"text": "In this example, /bet/ would be chosen when the morpheme occurs word-finally as in, and /bed/ when it occurs prevocalically, as in [beda] (see rows a. and b.).", "labels": [], "entities": []}, {"text": "This is a kind of over-specification in that the meaning 'cat' has two phonological URs.", "labels": [], "entities": []}, {"text": "The non-alternating morphemes /mot/ and /wid/ differ in having only a single UR, with voiceless and voiced final consonants respectively, thus yielding the three-way contrast.", "labels": [], "entities": [{"text": "UR", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9157806038856506}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 7: Learned analysis of Tesar's language", "labels": [], "entities": [{"text": "Learned analysis of Tesar's language", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.8419478237628937}]}, {"text": " Table 8: Learned weights for Tesar's language", "labels": [], "entities": [{"text": "Tesar's language", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.9305590987205505}]}, {"text": " Table 10: Learned analysis of French", "labels": [], "entities": [{"text": "Learned analysis of French", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.8907231837511063}]}, {"text": " Table 11: Learned weights for French", "labels": [], "entities": [{"text": "French", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.5866242051124573}]}]}