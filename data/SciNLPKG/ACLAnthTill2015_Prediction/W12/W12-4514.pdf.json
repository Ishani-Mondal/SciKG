{"title": [{"text": "Hybrid Rule-based Algorithm for Coreference Resolution *", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.9699320495128632}]}], "abstractContent": [{"text": "This paper describes our coreference resolution system for the CoNLL-2012 shared task.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.9231787025928497}, {"text": "CoNLL-2012 shared task", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.6520357131958008}]}, {"text": "Our system is based on the Stanford's dcore-f deterministic system which applies multiple sieves with the order from high precision to low precision to generate coreference chains.", "labels": [], "entities": []}, {"text": "We introduce the newly added constraints and sieves and discuss the improvement on the original system.", "labels": [], "entities": []}, {"text": "We evaluate the system using OntoNotes data set and report our results of average F-score 58.25 in the closed track.", "labels": [], "entities": [{"text": "OntoNotes data set", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.9258129994074503}, {"text": "F-score", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.9976100921630859}]}], "introductionContent": [{"text": "In this paper, our coreference resolution system for CoNLL-2012 shared task () is summarized.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.9211282432079315}]}, {"text": "Our system is an extension of Stanford's multi-pass sieve system, ( and), by adding novel constraints and sieves.", "labels": [], "entities": []}, {"text": "In the original model , sieves are sorted in decreasing order of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.998479425907135}]}, {"text": "Initially each mention is in its own cluster.", "labels": [], "entities": []}, {"text": "Mention clusters are combined by satisfying the condition of each sieve in the scan pass.", "labels": [], "entities": []}, {"text": "Through empirical studies, we proposed some extensions and algorithms for furthermore enhancing the performance.", "labels": [], "entities": []}, {"text": "* This work was partially supported by the National Natural Science Foundation of China (Grant No.  Many other existing systems applied supervised or unsupervised learning models. The classical resolution algorithm was proposed by).", "labels": [], "entities": []}, {"text": "Semantic knowledge like word associations was involved by).", "labels": [], "entities": []}, {"text": "Most of the supervised learning models in CoNLL-2011 shared task) used classifiers (Maximum Entropy or SVM) to train the models for obtaining the pairwise mention scores.", "labels": [], "entities": [{"text": "CoNLL-2011 shared task)", "start_pos": 42, "end_pos": 65, "type": "DATASET", "confidence": 0.832813635468483}]}, {"text": "However, the training process usually takes much longer time than unsupervised or deterministic systems.", "labels": [], "entities": []}, {"text": "In contrast, ( proposed a rulebased model which obtained competitive result with less time.", "labels": [], "entities": []}, {"text": "Two considerable extensions to the Stanford model in this paper are made to guarantee higher precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9995139837265015}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9987014532089233}]}, {"text": "First, we recorded error patterns from outputs of the original Stanford system and found that the usual errors are mention boundary mismatches, pronoun mismatches and soon.", "labels": [], "entities": [{"text": "Stanford system", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.935396820306778}]}, {"text": "To avoid the irrational coreference errors, we added some constraints to the mention detection for eliminating some unreasonable mention boundary mismatches.", "labels": [], "entities": []}, {"text": "Second, we added some constraints in the coreference sieves based on the errors on the training set and the development set.", "labels": [], "entities": []}, {"text": "We participated in the closed track and received an official F-score (unweighted mean of MUC, BCUBED and CEAF(E) metric) of 58.25 for English.", "labels": [], "entities": [{"text": "F-score", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9988657236099243}, {"text": "MUC", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9080865979194641}, {"text": "BCUBED", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9923216700553894}, {"text": "CEAF(E) metric)", "start_pos": 105, "end_pos": 120, "type": "METRIC", "confidence": 0.9295245110988617}]}, {"text": "The system with our extensions is briefly introduced in Section 2.", "labels": [], "entities": []}, {"text": "We report our evaluation results and discuss in Section 3. 118", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: CoNLL-2012 Shared Task Test Results", "labels": [], "entities": [{"text": "CoNLL-2012 Shared Task Test", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.7445916533470154}]}, {"text": " Table 2: Comparison between original system and our  system on the development set", "labels": [], "entities": []}]}