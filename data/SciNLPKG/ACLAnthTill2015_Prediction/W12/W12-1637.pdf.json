{"title": [{"text": "A Study in How NLU Performance Can Affect the Choice of Dialogue System Architecture", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an analysis of how the level of performance achievable by an NLU module can affect the optimal modular design of a dialogue system.", "labels": [], "entities": []}, {"text": "We present an evaluation that shows how NLU accuracy levels impact the overall performance of a system that includes an NLU module and a rule-based dialogue policy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9585916996002197}]}, {"text": "We contrast these performance levels with the performance of a direct classification design that omits a separate NLU module.", "labels": [], "entities": []}, {"text": "We conclude with a discussion of the potential fora hybrid architecture incorporating the strengths of both approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently computer-driven conversational characters or virtual humans have started finding real-life applications ranging from education to health services and museums;.", "labels": [], "entities": []}, {"text": "As proliferation of these systems increases, there is a growing demand for the design and construction of virtual humans to be made more efficient and accessible to people without extensive linguistics and computer science backgrounds, such as writers, designers, and educators.", "labels": [], "entities": []}, {"text": "We are specifically interested in making the language processing and dialogue management components in a virtual human easier for such potential authors to develop.", "labels": [], "entities": [{"text": "language processing and dialogue management", "start_pos": 45, "end_pos": 88, "type": "TASK", "confidence": 0.6526694238185883}]}, {"text": "Some system building steps that can be challenging for such authors include annotating the meaning of user and system utterances in a semantic formalism, developing a formal representation of information state, and writing detailed rules that govern dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 250, "end_pos": 269, "type": "TASK", "confidence": 0.709581658244133}]}, {"text": "We are generally interested in the extent to which these various authoring steps are necessary in order to achieve specific levels of system performance.", "labels": [], "entities": []}, {"text": "In this paper, we present a case study analysis of the performance of two alternative architectures fora specific virtual human.", "labels": [], "entities": []}, {"text": "The two architectures, which have been developed and evaluated in prior work), differ substantially in their semantic annotation and policy authoring requirements.", "labels": [], "entities": []}, {"text": "We describe these architectures and our evaluation corpus in Section 2.", "labels": [], "entities": []}, {"text": "We focus our new analysis specifically on how the overall performance of one of the architectures, which uses a natural language understanding (NLU) module and hand-authored rules for the dialogue policy, depends on the performance of the NLU module.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our finding that, depending on the attainable level of NLU accuracy, this modular approach mayor may not perform better than a simpler direct classification design that omits a separate NLU module and has a lower annotation and rule authoring burden.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9666961431503296}]}, {"text": "In Section 4, we present an initial exploration of whether a hybrid architecture maybe able to combine these approaches' strengths.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the dialogue policies in our experiments through 19-fold cross-validation of our 19 dialogues.", "labels": [], "entities": []}, {"text": "In each fold, we holdout one dialogue and use the remaining 18 as training data.", "labels": [], "entities": []}, {"text": "To measure policy performance, we count an automatically produced system SA as correct if that SA was chosen by the original wizard or at least one external referee for that dialogue turn.", "labels": [], "entities": []}, {"text": "We then count the proportion of the correct SAs among all the SAs produced across all 19 dialogues, and use this measure of weak accuracy to score dialogue policies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9947056174278259}]}, {"text": "We can use the weak accuracy of one referee, measured against all the others, to establish a performance ceiling for this metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9986782670021057}]}, {"text": "This score is .79; see DeVault et al.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Weak accuracy results for baseline systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9941297769546509}]}]}