{"title": [{"text": "A Computational Model of Memory, Attention, and Word Learning", "labels": [], "entities": [{"text": "Memory, Attention, and Word Learning", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.5807932274682182}]}], "abstractContent": [{"text": "There is considerable evidence that people generally learn items better when the presentation of items is distributed over a period of time (the spacing effect).", "labels": [], "entities": []}, {"text": "We hypothesize that both forgetting and attention to novelty play a role in the spacing effect in word learning.", "labels": [], "entities": [{"text": "word learning", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.7447506487369537}]}, {"text": "We build an incremental probabilistic computational model of word learning that incorporates a forgetting and attentional mechanism.", "labels": [], "entities": [{"text": "word learning", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.7596712410449982}]}, {"text": "Our model accounts for experimental results on children as well as several patterns observed in adults.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "First, we examine the overall word learning behaviour in our new model.", "labels": [], "entities": [{"text": "word learning", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.8505104780197144}]}, {"text": "Then we look at spacing effects in the learning of novel words.", "labels": [], "entities": []}, {"text": "In both these experiments, we compare the behavior of our model with the model of FAS10 to clearly illustrate the effects of forgetting and attention to novelty in the new model.", "labels": [], "entities": [{"text": "FAS10", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.5008507370948792}]}, {"text": "Next we turn to further experiments exploring in more detail the interaction of forgetting and attention to novelty in producing spacing effects.", "labels": [], "entities": []}, {"text": "First, the model is trained on 100 utterance-scene pairs to simulate the operation of normal word learning prior to the experiment.", "labels": [], "entities": []}, {"text": "Then a randomly picked novel word (nw) that did not appear in the training trials is introduced to the model in 3 teaching trials, similar to experiment.", "labels": [], "entities": []}, {"text": "For each teaching trial, nw is added to a different utterance, and its probabilistically-generated meaning representation (see Section 3) is added to the corresponding scene.", "labels": [], "entities": []}, {"text": "We add nw to an utterance-scene pair from our corpus to simulate the presentation of the novel word during the natural interaction with the child in the experimental setting.", "labels": [], "entities": []}, {"text": "The spacing interval between each of these 3 teaching trials is varied from 0 to 29 utterances, resulting in 30 different simulations for each nw.", "labels": [], "entities": []}, {"text": "For example, when the spacing interval is 5, there are 5 utterances between each presentation of nw.", "labels": [], "entities": []}, {"text": "A spacing of 0 utterances yields the massed presentation.", "labels": [], "entities": []}, {"text": "We run the experiment for 20 randomly-chosen novel words to ensure that the pattern of the results is not related to the meaning representation of a specific word.", "labels": [], "entities": []}, {"text": "For each spacing interval, we look at the acq score of the novel word at two points in time, to simulate two retention intervals: One immediately after the last presentation of the novel word (imm condition) and one at a later point in time (lat condition).", "labels": [], "entities": [{"text": "acq score", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9791157841682434}]}, {"text": "By looking at these two conditions, we can further observe the effect of forgetting in our model, since the decay in the model's memory would be more severe in the lat condition, compared to the imm condition.", "labels": [], "entities": []}, {"text": "The results reported here for each spacing interval average the acq scores of all the novel words at the corresponding points in time.", "labels": [], "entities": [{"text": "acq", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9940343499183655}]}, {"text": "shows the results of the simulations in our model and the FAS10 model.", "labels": [], "entities": [{"text": "FAS10 model", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.8812346756458282}]}, {"text": "We assume that very small spacing intervals (but greater than 0) correspond to the spaced presentation in the experiments, while a spacing of 0 corresponds to the massed presentation.", "labels": [], "entities": []}, {"text": "In the FAS10 model, the average acq score of words does not change with spacing, and there is no difference between the imm and lat conditions, confirming that this model fails to mimic the observed spacing effects.", "labels": [], "entities": [{"text": "FAS10", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.7494236826896667}, {"text": "acq score", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9721247255802155}]}, {"text": "By contrast, in our model the average acq score is greater in the small spacing intervals (1-3) than in the massed presentation, mimicking the results on children.", "labels": [], "entities": [{"text": "acq score", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9833436608314514}]}, {"text": "This happens because a nw appears more novel with larger spacing intervals between each of its presentations resulting in stronger alignments.", "labels": [], "entities": []}], "tableCaptions": []}