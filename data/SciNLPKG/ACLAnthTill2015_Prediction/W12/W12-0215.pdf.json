{"title": [{"text": "Using context and phonetic features in models of etymological sound change", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a novel method for aligning etymological data, which models context-sensitive rules governing sound change, and utilizes phonetic features of the sounds.", "labels": [], "entities": []}, {"text": "The goal is, fora given corpus of cognate sets, to find the best alignment at the sound level.", "labels": [], "entities": []}, {"text": "We introduce an imputa-tion procedure to compare the goodness of the resulting models, as well as the goodness of the data sets.", "labels": [], "entities": []}, {"text": "We present evaluations to demonstrate that the new model yields improvements in performance, compared to previously reported models.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper introduces a context-sensitive model for alignment and analysis of etymological data.", "labels": [], "entities": [{"text": "alignment and analysis of etymological data", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.6495773593584696}]}, {"text": "Given a raw collection of etymological data (the corpus)-we first aim to find the \"best\" alignment at the sound or symbol level.", "labels": [], "entities": []}, {"text": "We take the corpus (or possibly several different corpora) fora language family as given; different data sets are typically conflicting, which creates the need to determine which is more correct.", "labels": [], "entities": []}, {"text": "Etymological data sets are found in digital etymological databases, such as ones we use for the Uralic language family.", "labels": [], "entities": []}, {"text": "A database is typically organized into cognate sets; all elements within a cognate set are posited (by the database creators) to be derived from a common origin, which is a word-form in the ancestral proto-language.", "labels": [], "entities": []}, {"text": "Etymology encompasses several problems, including: discovery of sets of cognatesgenetically related words; determination of genetic relations among groups of languages, based on linguistic data; discovering regular sound correspondences across languages in a given language family; and reconstruction of forms in the proto-languages.", "labels": [], "entities": []}, {"text": "Computational methods can provide valuable tools for the etymological community.", "labels": [], "entities": []}, {"text": "The methods can be judged by how well they model certain aspects of etymology, and by whether the automatic analysis produces results that match theories established by manual analysis.", "labels": [], "entities": []}, {"text": "In this work, we allow all the data-and only the data-to determine what rules underly it, rather than relying on external (and possibly biased) rules that try to explain the data.", "labels": [], "entities": []}, {"text": "This approach will provide a means of measuring the quality of the etymological data sets in terms of their internal consistency-a dataset that is more consistent should receive a higher score.", "labels": [], "entities": []}, {"text": "We seek methods that analyze the data automatically, in an unsupervised fashion, to determine whether a complete description of the correspondences can be discovered automatically, directly from raw etymological data-cognate sets within the language family.", "labels": [], "entities": []}, {"text": "Another way to state the question is: what alignment rules are \"inherently encoded\" in the given corpus itself.", "labels": [], "entities": []}, {"text": "At present, our aim is to analyze given etymological datasets, rather than to construct new ones from scratch.", "labels": [], "entities": []}, {"text": "Because our main goal is to develop methods that are as objective as possible, the models make no a priori assumptions or \"universal\" principles-e.g., no preference to align vowel with vowels, or a symbol with itself.", "labels": [], "entities": []}, {"text": "The models are not aware of the identity of a symbol across languages, and do not try to preserve identity, of symbols, or even of features-rather they try to find maximally regular correspondences.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the data used in our experiments, and review approaches to etymological alignment over the last decade.", "labels": [], "entities": [{"text": "etymological alignment", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.8262226581573486}]}, {"text": "We formalize the problem of alignment in Section 3, give the technical details of our models in Section 4.", "labels": [], "entities": [{"text": "alignment", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.9753166437149048}]}, {"text": "We present results and discussion in Sections 5 and 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "One way to evaluate the presented models would require a gold-standard aligned corpus; the models produce alignments which could be compared to the gold-standard alignments, and we could measure performance quantitatively, e.g., in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.9977172613143921}]}, {"text": "However, building a gold-standard aligned corpus for the Uralic data proved to be extremely difficult.", "labels": [], "entities": [{"text": "Uralic data", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.8419370353221893}]}, {"text": "In fact, it quickly becomes clear that this problem is at least as difficult as building a full reconstruction for all internal nodes in the family tree (and probably harder), since it requires full knowledge of all sound correspondences within the family.", "labels": [], "entities": []}, {"text": "It is also compounded by the problem that the word-forms in the corpus may contain morphological material that is etymologically unrelated: some databases give \"dictionary\" forms, which contain extraneous affixes, and thereby obscure which parts of a given word form stand in etymological relationship with other members in the cognates set, and which do not.", "labels": [], "entities": []}, {"text": "We therefore introduce other methods to evaluate the models.", "labels": [], "entities": []}, {"text": "Compression: In, we compare the context model, and use as baselines the standard data compressors, Gzip and Bzip, as well as the more basic models presented in), (labeled \"1x1 and \"2x2\").", "labels": [], "entities": [{"text": "Bzip", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9268079400062561}]}, {"text": "We test the compression of up to 3200 Finnish-Estonian word pairs, from SSA.", "labels": [], "entities": []}, {"text": "Gzip and Bzip compress data by finding regularities in it (i.e., frequent substrings).", "labels": [], "entities": [{"text": "Bzip", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9402214884757996}]}, {"text": "The comparison with Gzip is a \"sanity check\": we would like to confirm whether our models find more regularity in the data than would an off-the-shelf data compressor, that has no knowledge that the words in the data are etymologically related.", "labels": [], "entities": []}, {"text": "Of course, our models know that they should align pairs of consecutive lines.", "labels": [], "entities": []}, {"text": "This test shows that learning about the \"vertical\" correspondences achieves much better compression rates-allows the models to extract greater regularity from the data.", "labels": [], "entities": []}, {"text": "Rules of correspondence: One our main goals is to model rules of correspondence among languages.", "labels": [], "entities": []}, {"text": "We can evaluate the models based on how good they are at discovering rules.", "labels": [], "entities": []}, {"text": "showed that aligning multiple symbols captures some of the context and thereby finds more complex rules than their 1-1 alignment model.", "labels": [], "entities": []}, {"text": "However, certain alignments, such as t\u223ct/d, p\u223cp/b, and k\u223ck/g between Finnish and Estonian, cannot be explained by the multiple-symbol model.", "labels": [], "entities": []}, {"text": "This is due to the rule of voicing of word-medial plosives in Estonian.", "labels": [], "entities": []}, {"text": "This rule could be expressed in terms of Two-level Morphology, as: a voiceless plosive in Finnish, may correspond to voiced in Estonian, if not word-initial.", "labels": [], "entities": []}, {"text": "The context model finds this rule, shown in.", "labels": [], "entities": []}, {"text": "This tree codes the Target-level (i.e., Estonian) Voiced consonant feature.", "labels": [], "entities": []}, {"text": "In each node, the counts of corresponding feature values are shown in brackets.", "labels": [], "entities": []}, {"text": "In the root node-prior to knowing anything about the environment-there is almost complete uncertainty (i.e., high entropy) about the value of Voiced feature of an Estonian consonant: 821 voiceless to 801 voiced in our data.", "labels": [], "entities": []}, {"text": "Redder nodes indicate higher entropy, bluer nodes-lower entropy.", "labels": [], "entities": []}, {"text": "The query in the root node tells us to check the context Finnish Itself Voiced for the most informative clue about whether the current Estonian consonant is voiced or not.", "labels": [], "entities": []}, {"text": "Tracing the options down left to right from the root, we obtain the rules.", "labels": [], "entities": []}, {"text": "The leftmost branch says, if the Finnish is voiced (\u2295), then the Estonian is almost certainly voiced as well-615 voiced to 2 voiceless in this case.", "labels": [], "entities": []}, {"text": "If the Finnish is voiceless (Finnish Itself Voiced = ), it says voicing may occur, but only in the red nodes-i.e., only if preceded by a voiced consonant on Estonian level (the branch marked by \u2295, 56 cases), or-if previous position is not a consonant (the = branch indicates that the candidate's query does not apply: i.e., the sound found in that position is not a consonant)-it can be voiced only if the corresponding Finnish is a plosive (P, 78 cases).", "labels": [], "entities": []}, {"text": "The blue nodes in this branch say that otherwise, the Estonian consonant almost certainly remains voiceless.", "labels": [], "entities": []}, {"text": "The context models discover numerous complex rules for different language pairs.", "labels": [], "entities": []}, {"text": "For example, they learn a rule that initial Finnish k \"changes\" (corresponds) to h in Hungarian, if it is followed by aback vowel; the correspondence between Komi trills and Udmurt sibilants; etc.", "labels": [], "entities": []}, {"text": "Imputation: We introduce a novel test of the quality of the models, by using them to impute unseen data, as follows.", "labels": [], "entities": []}, {"text": "For a given model, and a language pair (L 1 , L 2 )-e.g., (Finnish, Estonian)-hold out one word pair, and train the model on the remaining data.", "labels": [], "entities": []}, {"text": "Then show the model the hidden Finnish word and let it guess the corresponding Estonian.", "labels": [], "entities": []}, {"text": "Imputation can be done for all models with a simple dynamic programming algorithm, similar to the Viterbi-like search used during training.", "labels": [], "entities": []}, {"text": "Formally, given the hidden Finnish string, the imputation procedure selects from all possible Estonian strings the most probable Estonian string, given the model.", "labels": [], "entities": []}, {"text": "We then compute an edit distance between the imputed sting and the true withheld Estonian word (e.g., using the Levenshtein distance).", "labels": [], "entities": []}, {"text": "We repeat this procedure for all word pairs in the (L 1 , L 2 ) data set, sum the edit distances and normalize by the total size of the (true) L 2 data-this yields the Imputation is a more intuitive measure of the model's quality than code length, with a clear practical interpretation.", "labels": [], "entities": [{"text": "Imputation", "start_pos": 168, "end_pos": 178, "type": "METRIC", "confidence": 0.9550538063049316}]}, {"text": "NED is also the ultimate test of the model's quality.", "labels": [], "entities": [{"text": "NED", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.48448097705841064}]}, {"text": "If model M imputes better than M -i.e., N ED(L 2 |L 1 , M ) < N ED(L 2 |L 1 , M )-then it is difficult to argue that M could be in any sense \"worse\" than Mit has learned more about the regularities between L 1 and L 2 , and it knows more about L 2 given L 1 . The context model, which has much lower cost than the baseline, almost always has lower NED.", "labels": [], "entities": [{"text": "NED", "start_pos": 348, "end_pos": 351, "type": "METRIC", "confidence": 0.8673708438873291}]}, {"text": "This also yields an important insight: it is an encouraging indication that optimizing the code length is a good approach-the algorithm does not optimize NED directly, and yet the cost correlates strongly with NED, which is a simple and intuitive measure of the model's quality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pairwise normalized edit distances for Finno- Ugric languages, on StarLing data (symmetrized by  averaging over the two directions of imputation).", "labels": [], "entities": [{"text": "StarLing data", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9347180724143982}]}]}