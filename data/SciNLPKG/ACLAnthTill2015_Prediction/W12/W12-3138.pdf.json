{"title": [{"text": "Machine Learning for Hybrid Machine Translation", "labels": [], "entities": [{"text": "Hybrid Machine Translation", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.7037410338719686}]}], "abstractContent": [{"text": "We describe a substitution-based system for hybrid machine translation (MT) that has been extended with machine learning components controlling its phrase selection.", "labels": [], "entities": [{"text": "hybrid machine translation (MT)", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.8510471284389496}, {"text": "phrase selection", "start_pos": 148, "end_pos": 164, "type": "TASK", "confidence": 0.7634020745754242}]}, {"text": "The approach is based on a rule-based MT (RBMT) system which creates template translations.", "labels": [], "entities": []}, {"text": "Based on the rule-based generation parse tree and target-to-target alignments, we identify the set of \"interesting\" translation candidates from one or more translation engines which could be substituted into our translation templates.", "labels": [], "entities": []}, {"text": "The substitution process is either controlled by the output from a binary classifier trained on feature vectors from the different MT engines, or it is depending on weights for the decision factors, which have been tuned using MERT.", "labels": [], "entities": []}, {"text": "We are able to observe improvements in terms of BLEU scores over a baseline version of the hybrid system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9993878602981567}]}], "introductionContent": [{"text": "In recent years, machine translation (MT) systems have achieved increasingly better translation quality.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.8761503219604492}]}, {"text": "Still each paradigm has its own challenges: while statistical MT (SMT) systems suffer from alack of grammatical structure, resulting in ungrammatical sentences, RBMT systems have to deal with alack of lexical coverage.", "labels": [], "entities": [{"text": "MT (SMT)", "start_pos": 62, "end_pos": 70, "type": "TASK", "confidence": 0.8507555276155472}]}, {"text": "Hybrid architectures intend to combine the advantages of the individual paradigms to achieve an overall better translation.  and have shown that using a substitutionbased approach can improve the translation quality of a baseline RBMT system.", "labels": [], "entities": []}, {"text": "Our submission to WMT12 is anew, improved version following these approaches.", "labels": [], "entities": [{"text": "WMT12", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.9085750579833984}]}, {"text": "The output of an RBMT engine serves as our translation backbone, and we substitute noun phrases by translations mined from other systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using the \"newstest2012\" test set, we created baseline translations for the four MT systems used in our hybrid system.", "labels": [], "entities": [{"text": "newstest2012\" test set", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.8606446534395218}, {"text": "MT", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.8944758176803589}]}, {"text": "Then we performed three runs of our hybrid system: a) a baseline run, using the factors and uniformly distributed weights; b) a run using the weights trained on the development set; c) a run using the decision tree learned from annotated data.", "labels": [], "entities": []}, {"text": "shows the results for automatic metrics' scores.", "labels": [], "entities": []}, {"text": "Besides BLEU (), we also report its case-sensitive variant, BLEU-cased, and TER () scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9991534948348999}, {"text": "BLEU-cased", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9990635514259338}, {"text": "TER", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9989905953407288}]}, {"text": "Comparing the scores, we see that both advanced hybrid methods perform better than the original, baseline hybrid as well as the Lucy baseline system.", "labels": [], "entities": []}, {"text": "The MERT approach performs slightly better than the decision tree.", "labels": [], "entities": [{"text": "MERT", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.6470772624015808}]}, {"text": "This proves that using machinelearning to adapt the substitution approach results in better translation quality.", "labels": [], "entities": []}, {"text": "Other baseline systems, however, still outperform the hybrid systems.", "labels": [], "entities": []}, {"text": "In part this is due to the fact that we are preserving the basic structure of the RBMT translation and do not reorder the new hybrid translation.", "labels": [], "entities": [{"text": "RBMT translation", "start_pos": 82, "end_pos": 98, "type": "TASK", "confidence": 0.5337724983692169}]}, {"text": "To improve the hybrid approach further, there is more research required.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experimental results for all component and hybrid systems applied to the WMT12 \"newstest2012\" test set  data for language pair English\u2192German.", "labels": [], "entities": [{"text": "WMT12 \"newstest2012\" test set  data", "start_pos": 83, "end_pos": 118, "type": "DATASET", "confidence": 0.9199513367244175}]}]}