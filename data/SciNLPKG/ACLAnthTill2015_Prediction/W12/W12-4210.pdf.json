{"title": [{"text": "Using Domain-specific and Collaborative Resources for Term Translation", "labels": [], "entities": [{"text": "Term Translation", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.8930681049823761}]}], "abstractContent": [{"text": "In this article we investigate the translation of terms from English into German and vice versa in the isolation of an ontology vocabulary.", "labels": [], "entities": []}, {"text": "For this study we built new domain-specific resources from the translation search engine Linguee and from the online encyclopedia Wikipedia.", "labels": [], "entities": []}, {"text": "We learned that a domain-specific resource produces better results than a bigger, but more general one.", "labels": [], "entities": []}, {"text": "The first finding of our research is that the vocabulary and the structure of the parallel corpus are important.", "labels": [], "entities": []}, {"text": "By integrating the multilingual knowledge base Wikipedia, we further improved the translation wrt.", "labels": [], "entities": [{"text": "translation wrt", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.7958047688007355}]}, {"text": "the domain-specific resources, whereby some translation evaluation metrics outperformed the results of Google Translate.", "labels": [], "entities": [{"text": "translation evaluation", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.9066506028175354}]}, {"text": "This finding leads us to the conclusion that a hybrid translation system, a combination of bilingual terminological resources and statistical machine translation can help to improve translation of domain-specific terms.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 130, "end_pos": 161, "type": "TASK", "confidence": 0.6489323377609253}, {"text": "translation of domain-specific terms", "start_pos": 182, "end_pos": 218, "type": "TASK", "confidence": 0.8292339444160461}]}], "introductionContent": [{"text": "Our research on translation of ontology vocabularies is motivated by the challenge of translating domainspecific terms with restricted or no additional textual context that in other cases can be used for translation improvement.", "labels": [], "entities": [{"text": "translation of ontology vocabularies", "start_pos": 16, "end_pos": 52, "type": "TASK", "confidence": 0.9200944751501083}, {"text": "translation improvement", "start_pos": 204, "end_pos": 227, "type": "TASK", "confidence": 0.9571872651576996}]}, {"text": "For our experiment we started by translating financial terms with baseline systems trained on the EuroParl () corpus and the JRC-Acquis () corpus.", "labels": [], "entities": [{"text": "EuroParl () corpus", "start_pos": 98, "end_pos": 116, "type": "DATASET", "confidence": 0.932181735833486}, {"text": "JRC-Acquis () corpus", "start_pos": 125, "end_pos": 145, "type": "DATASET", "confidence": 0.8946200609207153}]}, {"text": "Although both resources contain a large amount of parallel data, the translations were not satisfying.", "labels": [], "entities": []}, {"text": "To improve the translations of the financial ontology vocabulary we built anew parallel resource, which was generated using Linguee , an online translation query service.", "labels": [], "entities": []}, {"text": "With this data, we could train a small system, which produced better translations than the baseline model using only general resources.", "labels": [], "entities": []}, {"text": "Since the manual development of terminological resources is a time intensive and expensive task, we used Wikipedia as a background knowledge base and examined articles, tagged with domain-specific categories.", "labels": [], "entities": []}, {"text": "With this extracted domain-specific data we built a specialised English-German lexicon to store translations of domain-specific terms.", "labels": [], "entities": []}, {"text": "These terms were then used in a pre-processing method in the decoding approach.", "labels": [], "entities": []}, {"text": "This approach incorporates the work by, which suggests a sub-term analysis.", "labels": [], "entities": []}, {"text": "We split the financial terms into n-grams and search for financial sub-terms in Wikipedia.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.9691986441612244}]}, {"text": "The remainder of the paper is organised like this.", "labels": [], "entities": []}, {"text": "In Section 2 we describe related work while in Section 3 the ontology data, the training data that we used in training the language model, and the translation decoder are discussed.", "labels": [], "entities": []}, {"text": "Section 4 presents the new resources which were used for improving the term translation.", "labels": [], "entities": [{"text": "term translation", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.8081669509410858}]}, {"text": "In Section 5 we discuss the results of exploiting the different resources.", "labels": [], "entities": []}, {"text": "We conclude with a summary and give an outlook on future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiment started with an analysis of the terms in the ontology to be translated, which was stored in RDF 2 data model.", "labels": [], "entities": [{"text": "RDF 2 data model", "start_pos": 107, "end_pos": 123, "type": "DATASET", "confidence": 0.8130894899368286}]}, {"text": "These terms were used to automatically extract any corresponding Wikipedia Categories, which helped us to define more exactly the domain(s) of the ontology to be translated.", "labels": [], "entities": []}, {"text": "The collected Categories were further used to build a domain-specific lexicon to be used for improving term translation.", "labels": [], "entities": [{"text": "term translation", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.7696244120597839}]}, {"text": "At the same time anew parallel corpus was built, which was also generated with the help of the ontology terms.", "labels": [], "entities": []}, {"text": "This new data was then used to pre-process the input data for the decoder and to build a specialised training model which yielded to a translation improvement.", "labels": [], "entities": [{"text": "translation", "start_pos": 135, "end_pos": 146, "type": "TASK", "confidence": 0.9656747579574585}]}, {"text": "In this section, several types of data will be presented and furthermore the translation decoder, which has to access this data to build the training models.", "labels": [], "entities": []}, {"text": "Section 3.1 gives an overview of the data that was used in translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.9709337949752808}]}, {"text": "In Sections 3.2 and 3.3 we describe the data that is used to train the translation and language model.", "labels": [], "entities": [{"text": "translation", "start_pos": 71, "end_pos": 82, "type": "TASK", "confidence": 0.9804988503456116}]}, {"text": "We used different parallel corpora, JRC-Acquis, EuroParl and a domain-specific corpus built from Linguee.", "labels": [], "entities": [{"text": "JRC-Acquis", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.8910619616508484}, {"text": "EuroParl", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.9759239554405212}, {"text": "Linguee", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.9497982859611511}]}, {"text": "In Section 3.4, we discuss a domain-specific lexicon, extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "In the last Section 3.5 we describe the phrase-based machine translation decoder Moses that we used for our experiments.", "labels": [], "entities": [{"text": "phrase-based machine translation decoder", "start_pos": 40, "end_pos": 80, "type": "TASK", "confidence": 0.6961520910263062}]}, {"text": "For the translation dataset a financial ontology developed by the XBRL European Business Registers 3 (xEBR) Working Group was used.", "labels": [], "entities": [{"text": "translation", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.9687002301216125}, {"text": "XBRL European Business Registers 3 (xEBR) Working Group", "start_pos": 66, "end_pos": 121, "type": "DATASET", "confidence": 0.873777961730957}]}, {"text": "This financial ontology is a framework for describing financial accounting and profile information of business entities across Europe, see also.", "labels": [], "entities": []}, {"text": "The ontology holds 263 concepts and is partially translated into German, Dutch, Spanish, French and Italian.", "labels": [], "entities": []}, {"text": "The terms in each language are aligned via the SKOS 4 Exact Match mechanism to the xEBR core taxonomy.", "labels": [], "entities": [{"text": "xEBR core taxonomy", "start_pos": 83, "end_pos": 101, "type": "DATASET", "confidence": 0.9003231724103292}]}, {"text": "In this partially translated taxonomy, we identified 63 English financial terms and their German equivalents, which were used as reference translations in evaluating the different experiment steps.", "labels": [], "entities": []}, {"text": "The xEBR financial terms are not really terms from a linguistic point of view, but they are used in financial or accounting reports as unique finan- cial expressions or tags to organize and retrieve automatically reported information.", "labels": [], "entities": []}, {"text": "Therefore it is important to translate these financial terms exactly.", "labels": [], "entities": []}, {"text": "illustrates the structure of xEBR terms.", "labels": [], "entities": []}, {"text": "It is obvious that they are not comparable to general language, but instead are more like headlines in newspapers, which are often short, very informative and written in a telegraphic style.", "labels": [], "entities": []}, {"text": "xEBR terms are often only noun phrases without determiners.", "labels": [], "entities": []}, {"text": "The length of the financial terms varies, e.g. the longest financial term considered for translation has a length of 11 tokens, while others may consist of 1 or 2.", "labels": [], "entities": [{"text": "translation", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.9783537983894348}]}, {"text": "Tables 4 to 5 illustrate the final results for our experiments on translating xEBR ontology terms, using the NIST), BLEU (), and Meteor (Lavie and) algorithms.", "labels": [], "entities": [{"text": "translating xEBR ontology terms", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.8210078030824661}, {"text": "NIST", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.8743476867675781}, {"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9971886277198792}]}, {"text": "To further study any translation improvements of our experiment, we also used Google Translate 8 in translating 63 financial xEBR terms (cf. Section 3.1) from English into German and from German into English.", "labels": [], "entities": []}, {"text": "In our experiments translation models built from a general resource performed worst.", "labels": [], "entities": []}, {"text": "These re-   German words), but evaluation scores are more than double than those for JRC-Acquis.", "labels": [], "entities": [{"text": "evaluation", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9305034875869751}, {"text": "JRC-Acquis", "start_pos": 85, "end_pos": 95, "type": "DATASET", "confidence": 0.9185488820075989}]}, {"text": "This is clear evidence that such a resource benefits the translation of terms in a specific domain.", "labels": [], "entities": []}, {"text": "The models produced by the Linguee search engine are generating better translations than those produced by general resources.", "labels": [], "entities": [{"text": "Linguee search engine", "start_pos": 27, "end_pos": 48, "type": "DATASET", "confidence": 0.8335893352826437}]}, {"text": "This approach outperforms Google Translate translations from German into English for all used evaluation metrics.", "labels": [], "entities": []}, {"text": "The table further shows results for our approach in using extracted Wikipedia terms as an examplebased approach.", "labels": [], "entities": []}, {"text": "For this we used the terms extracted from Wikipedia and exchanged English terms with German translations and vice versa.", "labels": [], "entities": []}, {"text": "The evaluation metrics are very low in this case; only for Correct Translation we generate four positive findings.", "labels": [], "entities": [{"text": "Correct Translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7178056836128235}]}, {"text": "Finally, the table gives results for our approach in using a combination of domain-specific parallel financial corpus with the lexicon extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "The domain-specific lexicon contains 3228 English-German translations, which were extracted from 18 different financial Categories.", "labels": [], "entities": []}, {"text": "This combination of highly specialised resources gives the best results in our experiment.", "labels": [], "entities": []}, {"text": "Translating financial terms into German, we get more Correct Translations as well as the Meteor metric shows better results compared to Google Translate.", "labels": [], "entities": [{"text": "Correct Translations", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.676411509513855}, {"text": "Meteor metric", "start_pos": 89, "end_pos": 102, "type": "DATASET", "confidence": 0.8225226104259491}]}, {"text": "For translations into English, all used evaluation metrics show better results than those of Google Translate.", "labels": [], "entities": []}, {"text": "As a final observation, we learned that translations made by domain-specific resources are on the same quality level, either if we translate from English into German or vice versa.", "labels": [], "entities": []}, {"text": "In comparison, we see that Google Translate has a larger discrepancy when translating into German or English respectively.", "labels": [], "entities": []}, {"text": "Our research showed that translations from English into German built by specialised resources were slightly better, which goes along with Google Translate that also produces better translations into German.", "labels": [], "entities": []}, {"text": "In addition to the automatic evaluation with BLEU, NIST, and Meteor scores, we have also undertaken a manual evaluation campaign to assess the translation quality of the different systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9953081011772156}, {"text": "NIST", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.8973871469497681}, {"text": "Meteor scores", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.7782914042472839}, {"text": "translation", "start_pos": 143, "end_pos": 154, "type": "TASK", "confidence": 0.952263355255127}]}, {"text": "In this section, we will a) describe the annotation setup and task presented to the human annotators, b) report on the translation quality achieved by the different systems, and c) present inter-annotator agreement scores that allow to judge the reliability of the human rankings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of xEBR terms", "labels": [], "entities": []}, {"text": " Table 3: Most frequent Categories based on the xEBR  terms and their Interwiki links", "labels": [], "entities": [{"text": "Interwiki", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.8117643594741821}]}, {"text": " Table 4: Evaluation scores for German term translations", "labels": [], "entities": [{"text": "German term translations", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6332982381184896}]}, {"text": " Table 5: Evaluation scores for English term translations", "labels": [], "entities": [{"text": "English term translations", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.5617479383945465}]}, {"text": " Table 6: Results from the manual evaluation into German", "labels": [], "entities": []}, {"text": " Table 7: Results from the manual evaluation into English", "labels": [], "entities": []}, {"text": " Table 8: Annotator agreement scores for German", "labels": [], "entities": [{"text": "Annotator agreement scores", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.6777560710906982}]}, {"text": " Table 9: Annotator agreement scores for English", "labels": [], "entities": [{"text": "Annotator agreement scores", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.652732918659846}]}]}