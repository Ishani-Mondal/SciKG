{"title": [{"text": "Identification of Truth and Deception in Text: Application of Vector Space Model to Rhetorical Structure Theory", "labels": [], "entities": [{"text": "Identification of Truth and Deception", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8961812257766724}]}], "abstractContent": [{"text": "The paper proposes to use Rhetorical Structure Theory (RST) analytic framework to identify systematic differences between deceptive and truthful stories in terms of their coherence and structure.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.7661711871623993}]}, {"text": "A sample of 36 elicited personal stories, self-ranked as completely truthful or completely deceptive, is manually analyzed by assigning RST discourse relations among a story's constituent parts.", "labels": [], "entities": [{"text": "RST discourse", "start_pos": 136, "end_pos": 149, "type": "TASK", "confidence": 0.8708004951477051}]}, {"text": "Vector Space Model (VSM) assesses each story's position in multi-dimensional RST space with respect to its distance to truth and deceptive centers as measures of the story's level of deception and truthfulness.", "labels": [], "entities": []}, {"text": "Ten human judges evaluate if each story is deceptive or not, and assign their confidence levels, which produce measures of the human expected deception and truthfulness levels.", "labels": [], "entities": []}, {"text": "The paper contributes to deception detection research and RST twofold: a) demonstration of discourse structure analysis in pragmatics as a prominent way of automated deception detection and, as such, an effective complement to lexico-semantic analysis, and b) development of RST-VSM methodology to interpret RST analysis in identification of previously unseen deceptive texts.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.8997677862644196}, {"text": "RST", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9872714877128601}, {"text": "discourse structure analysis", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.6863222718238831}, {"text": "automated deception detection", "start_pos": 156, "end_pos": 185, "type": "TASK", "confidence": 0.7024168372154236}, {"text": "RST analysis", "start_pos": 308, "end_pos": 320, "type": "TASK", "confidence": 0.8329495787620544}, {"text": "identification of previously unseen deceptive texts", "start_pos": 324, "end_pos": 375, "type": "TASK", "confidence": 0.8569927414258321}]}], "introductionContent": [{"text": "Automated deception detection is a challenging task, only recently proven feasible with natural language processing and machine learning techniques).", "labels": [], "entities": [{"text": "Automated deception detection", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8708492318789164}]}, {"text": "The idea is to distinguish truthful information from deceptive, where deception usually implies an intentional and knowing attempt on the part of the sender to create a false belief or false conclusion in the mind of the receiver of the information (e.g.,).", "labels": [], "entities": []}, {"text": "In this paper we focus solely on textual information, in particular, in computer-mediated personal communications such as e-mails or online posts.", "labels": [], "entities": []}, {"text": "Previously suggested techniques for detecting deception in text reach modest accuracy rates at the level of lexico-semantic analysis.", "labels": [], "entities": [{"text": "detecting deception in text", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.8588643223047256}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9989060163497925}]}, {"text": "Certain lexical items are considered to be predictive linguistic cues, and could be derived, for examples, from the Statement Validity Analysis techniques used in law enforcement for credibility assessments (as in.", "labels": [], "entities": [{"text": "Statement Validity Analysis", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.7749591668446859}]}, {"text": "Though there is no clear consensus on reliable predictors of deception, deceptive cues are identified in texts, extracted and clustered conceptually, for instance, to represent diversity, complexity, specificity, and non-immediacy of the analyzed texts (e.g.,).", "labels": [], "entities": []}, {"text": "When implemented with standard classification algorithms (such as neural nets, decision trees, and logistic regression), such methods achieve 74% accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9994102716445923}]}, {"text": "Existing psycholinguistic lexicons (e.g., LWIC by) have been adapted to perform binary text classifications for truthful versus deceptive opinions, with an average classifier demonstrating 70% accuracy rate.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 193, "end_pos": 206, "type": "METRIC", "confidence": 0.985264927148819}]}, {"text": "These modest results, though usually achieved on restricted topics, are promising since they supersede notoriously unreliable human abilities in lie-truth discrimination tasks.", "labels": [], "entities": [{"text": "lie-truth discrimination tasks", "start_pos": 145, "end_pos": 175, "type": "TASK", "confidence": 0.7870643933614095}]}, {"text": "On average, people are not very good at spotting lies, succeeding generally only about half of the time).", "labels": [], "entities": [{"text": "spotting lies", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.9321335256099701}]}, {"text": "For instance, a meta-analytical review of over 100 experiments with over 1,000 participants, showed a 54% mean accuracy rate at identifying deception).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9945498108863831}, {"text": "identifying deception", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.8538255095481873}]}, {"text": "Human judges achieve 50 -63% success rates, depending on what is considered deceptive on a seven-point scale of truth-to-deception continuum (, but the higher the actual selfreported deception level of the story, the more likely a story would be confidently assigned as deceptive.", "labels": [], "entities": []}, {"text": "In other words, extreme degrees of deception are more transparent to judges.", "labels": [], "entities": []}, {"text": "The task for current automated deception detection techniques has been formulated as binary text categorization -is a message deceptive or truthful -and the decision applies to the whole analyzed text.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7438609153032303}]}, {"text": "Since it is an overall discourse level decision, it maybe reasonable to consider discourse or pragmatic features of each message.", "labels": [], "entities": []}, {"text": "Thus far, discourse is surprisingly rarely considered, if at all, and the majority of the effort has been restricted to lexico-semantic verbal predictors.", "labels": [], "entities": []}, {"text": "A rare exception up to date has been a Bachenko, study that focuses on truth or falsity of individual propositions, achieving a finer-grained level of analysis 1 , but the propositional interrelations within the discourse structure are not considered.", "labels": [], "entities": []}, {"text": "To the best of our knowledge there have been no advances in that automation deception detection task to incorporate discourse structure features and/or text coherence analysis at the pragmatic levels of story interpretation.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7874986231327057}, {"text": "text coherence analysis", "start_pos": 152, "end_pos": 175, "type": "TASK", "confidence": 0.645974745353063}, {"text": "story interpretation", "start_pos": 203, "end_pos": 223, "type": "TASK", "confidence": 0.7621310353279114}]}], "datasetContent": [], "tableCaptions": []}