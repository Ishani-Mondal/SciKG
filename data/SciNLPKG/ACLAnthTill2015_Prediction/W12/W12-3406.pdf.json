{"title": [{"text": "Machine Learning of Syntactic Attachment from Morphosyntactic and Semantic Co-occurrence Statistics", "labels": [], "entities": [{"text": "Machine Learning of Syntactic Attachment from Morphosyntactic and Semantic Co-occurrence Statistics", "start_pos": 0, "end_pos": 99, "type": "TASK", "confidence": 0.7005300738594749}]}], "abstractContent": [{"text": "The paper presents a novel approach to extracting dependency information in morphologically rich languages using co-occurrence statistics based not only on lexical forms (as in previously described collocation-based methods), but also on morphosyntactic and wordnet-derived semantic properties of words.", "labels": [], "entities": [{"text": "extracting dependency information in morphologically rich languages", "start_pos": 39, "end_pos": 106, "type": "TASK", "confidence": 0.81494140625}]}, {"text": "Statistics generated from a corpus annotated only at the morphosyntactic level are used as features in a Machine Learning classifier which is able to detect which heads of groups found by a shallow parser are likely to be connected by an edge in the complete parse tree.", "labels": [], "entities": []}, {"text": "The approach reaches the precision of 89% and the recall of 65%, with an extra 6% recall , if only words present in the wordnet are considered.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9996931552886963}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9996163845062256}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9989987015724182}]}], "introductionContent": [{"text": "The practical issue handled in this paper is how to connect syntactic groups found by a shallow parser into a possibly complete syntactic tree, i.e., how to solve the attachment problem.", "labels": [], "entities": []}, {"text": "To give a well-known example from English, the task is to decide whether in I shot an elephant in my pajamas 1 , the group in my pajamas should be attached to an elephant or to shot (or perhaps to I).", "labels": [], "entities": []}, {"text": "The standard approach to this problem relies on finding collocation strengths between syntactic objects, usually between lexical items which are heads of these objects, and resolve attachment ambiguities on the basis of such collocation information.", "labels": [], "entities": []}, {"text": "The current work extends this approach in two main ways.", "labels": [], "entities": []}, {"text": "First, we consider a very broad range of features: not only lexical, but also lexico-semantic, lexico-grammatical, and grammatical.", "labels": [], "entities": []}, {"text": "Second, and more importantly, we train classifiers based not on these features directly, but rather on various association measures calculated for each of the considered features.", "labels": [], "entities": []}, {"text": "This way the classifier selects which types of features are important and which association measures are most informative for any feature type.", "labels": [], "entities": []}, {"text": "The proposed method is evaluated on Polish, a language with rich inflection (and relatively free word order), which exacerbates the usual data sparseness problem in NLP.", "labels": [], "entities": []}, {"text": "In this work we assume that input texts are already part-of-speech tagged and chunked, the latter process resulting in the recognition of basic syntactic groups.", "labels": [], "entities": []}, {"text": "A syntactic group may, e.g., consist of a verb with surrounding adverbs and particles or a noun with its premodifiers.", "labels": [], "entities": []}, {"text": "We assume that all groups have a syntactic head and a semantic head.", "labels": [], "entities": []}, {"text": "In verbal and nominal groups both heads are the same word, but in prepositional and numeral groups they usually differ: the preposition and the numeral are syntactic heads of the respective constituents, while the semantic head is the head noun within the nominal group contained in these constituents.", "labels": [], "entities": []}, {"text": "To simplify some of the descriptions below, by syntactic object we will understand either a shallow group or a word.", "labels": [], "entities": []}, {"text": "We will also uniformly talk about syntactic and semantic heads of all syntactic objects; in case of words, the word itself is its own syntactic and semantic head.", "labels": [], "entities": []}, {"text": "In effect, any syntactic object maybe represented by a pair of words (the two heads), and each word is characterised by its base form and its morphosyntactic tag.", "labels": [], "entities": []}], "datasetContent": [{"text": "The approach presented above has been evaluated on Polish.", "labels": [], "entities": [{"text": "Polish", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.9816160202026367}]}, {"text": "First, a manually annotated 1-million-word subcorpus of the National Corpus of Polish (, specifically, its morphosyntactic and shallow syntactic annotation, was Removing enough negative instances in the training set to balance the numbers of instances representing both classes.", "labels": [], "entities": [{"text": "National Corpus of Polish", "start_pos": 60, "end_pos": 85, "type": "DATASET", "confidence": 0.9674539119005203}]}, {"text": "used to compute the co-occurrence statistics.", "labels": [], "entities": []}, {"text": "The wordnet used for lexico-semantic measures was S\u0142owosie\u00b4cS\u0142owosie\u00b4c (, the largest Polish wordnet.", "labels": [], "entities": []}, {"text": "Then a random subset of sentences from this corpus was shallow-parsed by) and given to linguists, who added annotation for the dependency links between syntactic objects.", "labels": [], "entities": []}, {"text": "Each sentence was processed by two linguists, and in case of any discrepancy, the sentence was simply rejected.", "labels": [], "entities": []}, {"text": "The final corpus contains 963 sentences comprising over 8000 tokens.", "labels": [], "entities": []}, {"text": "From this data we obtained over 23 500 classification problem instances.", "labels": [], "entities": [{"text": "classification problem", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9037921726703644}]}, {"text": "Then we performed the classification using a BRF classifier written for Weka) as part of the research work on definition extraction with BRFs.", "labels": [], "entities": [{"text": "Weka", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.7261256575584412}, {"text": "definition extraction", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.8896597623825073}]}, {"text": "The results were 10-fold cross-validated.", "labels": [], "entities": []}, {"text": "A similar experiment was performed taking into account only those instances which describe syntactic objects with semantic heads present in the wordnet.", "labels": [], "entities": []}, {"text": "The results were measured in terms of precision and recall over edges in the syntactic tree: what percentage of found edges are correct (precision) and what percentage of correct edges were found by the algorithm (recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9992262125015259}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9981204867362976}, {"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9968275427818298}, {"text": "recall", "start_pos": 214, "end_pos": 220, "type": "METRIC", "confidence": 0.9968309998512268}]}, {"text": "The obtained measures are presented in We also looked at the actual decision trees that were generated during the training.", "labels": [], "entities": []}, {"text": "We note that the signal most frequently observed near the tops of decision trees was the one from handwritten rules.", "labels": [], "entities": []}, {"text": "The second one was the distance.", "labels": [], "entities": [{"text": "distance", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.8107662200927734}]}, {"text": "By looking at the trees, we could not see any clear preferences for other types of signals.", "labels": [], "entities": []}, {"text": "This suggests that both morphosyntactic and lexico-semantic signals contribute to the accuracy of the classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9990704655647278}]}, {"text": "Based on this inspection of decision trees, we performed another experiment to learn how much improvement we get from generalised collocation signals.", "labels": [], "entities": []}, {"text": "We evaluated -on the same data -a not so trivial baseline algorithm which, for each syntactic object, creates an edge to its nearest neighbour accepted by the handwritten rules, if any.", "labels": [], "entities": []}, {"text": "Note that this baseline builds on the fact that anode in a parse tree has at most one parent, whereas the algorithm described above does not encode this property, yet; clearly, there is still some room for improvement.", "labels": [], "entities": []}, {"text": "The baseline reaches 0.78 precision and 0.47 recall (F-measure is 0.59).", "labels": [], "entities": [{"text": "baseline", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9717705249786377}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9976229071617126}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9949166774749756}, {"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9980905652046204}]}, {"text": "Therefore, the improvement from co-occurrence signals over this strong baseline is 0.13, which is rather high.", "labels": [], "entities": []}, {"text": "Also, given the high precision, our algorithm maybe suitable for using in a cascade of classifiers.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9984371066093445}]}], "tableCaptions": [{"text": " Table 1: Confusion matrix (# of instances) and measures  for the full data set and for data present in wordnet.", "labels": [], "entities": []}]}