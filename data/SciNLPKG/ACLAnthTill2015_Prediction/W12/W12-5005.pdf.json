{"title": [{"text": "Comparing Different Criteria for Vietnamese Word Segmentation", "labels": [], "entities": [{"text": "Vietnamese Word Segmentation", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.6135476032892863}]}], "abstractContent": [{"text": "Syntactically annotated corpora have become important resources for natural language processing due in part to the success of corpus-based methods.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.6734068989753723}]}, {"text": "Since words are often considered as primitive units of language structures, the annotation of word segmentation forms the basis of these corpora.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7667468190193176}]}, {"text": "This is also an issue for the Vietnamese Treebank (VTB), which is the first and only publicly available syntactically annotated corpus for the Vietnamese language.", "labels": [], "entities": [{"text": "Vietnamese Treebank (VTB)", "start_pos": 30, "end_pos": 55, "type": "DATASET", "confidence": 0.9439796447753906}]}, {"text": "Although word segmentation is straightforward for space-delimited languages like English, this is not the case for languages like Vietnamese for which a standard criterion for word segmentation does not exist.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7724018096923828}, {"text": "word segmentation", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.7269233167171478}]}, {"text": "This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB.", "labels": [], "entities": [{"text": "Vietnamese word segmentation", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.5567045211791992}]}, {"text": "Then, by combining and splitting the inconsistent annotations that were detected, we are able to observe the influence of different word segmentation criteria on automatic word segmentation, and the applications of word segmentation, including text classification and English-Vietnamese statistical machine translation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 172, "end_pos": 189, "type": "TASK", "confidence": 0.7152565866708755}, {"text": "word segmentation", "start_pos": 215, "end_pos": 232, "type": "TASK", "confidence": 0.7120512276887894}, {"text": "text classification", "start_pos": 244, "end_pos": 263, "type": "TASK", "confidence": 0.8104268014431}, {"text": "statistical machine translation", "start_pos": 287, "end_pos": 318, "type": "TASK", "confidence": 0.6270227134227753}]}, {"text": "The analysis and experimental results showed that our methods improved the quality of VTB, which positively affected the performance of its applications.", "labels": [], "entities": []}, {"text": "Title and Abstract in another language, L 2 (optional, and on same page) So s\u00e1nh c\u00e1c ti\u00eau ch\u00ed t\u00e1ch tt kh\u00e1c nhau th\u00f4ng qua ng ddng Trong b\u00e0i b\u00e1o n\u00e0y, ch\u00fang t\u00f4i khho s\u00e1t nhng nh\u00e3n ranh giii tt \u0111\u01b0\u01b0c \u0111\u00e1nh ddu trong ngg liiu c\u00e2y c\u00fa ph\u00e1p tiing Viit ggi ttt l\u00e0 VTB.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.987015962600708}, {"text": "VTB", "start_pos": 254, "end_pos": 257, "type": "DATASET", "confidence": 0.8140257596969604}]}, {"text": "TT viic khho s\u00e1t nhhng tr\u01b0ng hhp bb g\u00e1n nh\u00e3n kh\u00f4ng nhht qu\u00e1n, ch\u00fang t\u00f4i x\u00e1c \u0111\u0111nh mmt ss tr\u01b0\u01b0ng hhp kh\u00f3 kh\u0103n cca b\u00e0i to\u00e1n t\u00e1ch tt.", "labels": [], "entities": []}, {"text": "DDa tr\u00ean nhhng tr\u01b0\u01b0ng hhp n\u00e0y, ch\u00fang t\u00f4i x\u00e2y ddng v\u00e0 khho s\u00e1t mmt ss ti\u00eau ch\u00ed t\u00e1ch tt kh\u00e1c nhau.", "labels": [], "entities": []}, {"text": "CC thh, ch\u00fang t\u00f4i \u0111\u00e3 \u0111\u00e1nh gi\u00e1 c\u00e1c c\u00e1c ti\u00eau ch\u00ed n\u00e0y th\u00f4ng qua b t\u00e1ch tt tt \u0111ng, v\u00e0 hai ng ddng: ddch tt \u0111ng Anh-Viit theo ph\u01b0\u01a1ng ph\u00e1p thhng k\u00ea v\u00e0 ph\u00e2n looi v\u0103n bbn tiing Viit.", "labels": [], "entities": []}, {"text": "KKt quu th\u00ed nghiim cho thhy: (1) c\u00e1c ti\u00eau ch\u00ed t\u00e1ch tt kh\u00e1c nhau c\u00f3 nh h\u01b0\u01b0ng \u0111\u0111n \u0111\u0111 ch\u00ednh x\u00e1c cca ng ddng, (2) viic n\u00e2ng cao chht l\u01b0\u01b0ng cho VTB l\u00e0 ccn thiit \u0111\u0111 x\u00e2y ddng ng ddng c\u00f3 chht l\u01b0\u01b0ng cao.", "labels": [], "entities": []}], "introductionContent": [{"text": "Treebanks, which are corpora annotated with syntactic structures, have become more and more important for language processing.", "labels": [], "entities": [{"text": "language processing", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7108578979969025}]}, {"text": "In order to strengthen the automatic processing of the Vietnamese language, the Vietnamese Treebank has been built as apart of the national project, \"Vietnamese language and speech processing (VLSP)\").", "labels": [], "entities": [{"text": "Vietnamese Treebank", "start_pos": 80, "end_pos": 99, "type": "DATASET", "confidence": 0.96023228764534}, {"text": "Vietnamese language and speech processing (VLSP)\")", "start_pos": 150, "end_pos": 200, "type": "TASK", "confidence": 0.6973773464560509}]}, {"text": "However, in our preliminary experiment with VTB, when we trained the Berkeley parser () and evaluated it by using the corpus, the parser achieved only 65.8% in F-score.", "labels": [], "entities": [{"text": "VTB", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.8711972236633301}, {"text": "F-score", "start_pos": 160, "end_pos": 167, "type": "METRIC", "confidence": 0.9977754950523376}]}, {"text": "This score is far lower than the state-of-the-art performance reported for the Berkeley parser on the English Penn Treebank, which reported 90.3% in F-score ().", "labels": [], "entities": [{"text": "Berkeley parser on the English Penn Treebank", "start_pos": 79, "end_pos": 123, "type": "DATASET", "confidence": 0.7430229272161212}, {"text": "F-score", "start_pos": 149, "end_pos": 156, "type": "METRIC", "confidence": 0.9990366697311401}]}, {"text": "There are two possible reasons to explain this outcome.", "labels": [], "entities": []}, {"text": "One reason for this outcome is the difficulty of parsing Vietnamese, which requires new parsing techniques.", "labels": [], "entities": [{"text": "parsing Vietnamese", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8213933110237122}]}, {"text": "The second reason is the quality of VTB, including the quality of the annotation scheme, the annotation guidelines, and the annotation process.", "labels": [], "entities": [{"text": "VTB", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.7808828353881836}]}, {"text": "The Vietnamese Treebank (VTB) contains 10.433 sentences (274.266 tokens) annotated with three layers: word segmentation, POS tagging, and bracketing.", "labels": [], "entities": [{"text": "Vietnamese Treebank (VTB)", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.9556328296661377}, {"text": "word segmentation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.713495060801506}, {"text": "POS tagging", "start_pos": 121, "end_pos": 132, "type": "TASK", "confidence": 0.820598304271698}]}, {"text": "This paper focuses on the word segmentation, since words are the most basic unit of a treebank, and defining words is the first step).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7098354995250702}]}, {"text": "For languages like English, defining words is almost trivial, because the blank spaces denote word delimiters.", "labels": [], "entities": []}, {"text": "However, for an isolating language like Vietnamese, for which blank spaces play a role of syllable delimiters, defining words is not a trivial problem.", "labels": [], "entities": []}, {"text": "For example, the sentence \"HHc sinh hhc sinh hhc (students learn biology) 2 \" is composed of three words \"hhc sinh (student)\", \"hhc (learn),\" and \"sinh hhc (biology)\".", "labels": [], "entities": [{"text": "HHc sinh hhc sinh hhc (students learn biology) 2", "start_pos": 27, "end_pos": 75, "type": "DATASET", "confidence": 0.789476443420757}]}, {"text": "Word segmentation is expected to breakdown the sentence at the boundaries of these words, instead of splitting \"hhc sinh (student)\" and \"sinh hhc (biology).\"", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6953188329935074}]}, {"text": "Note that the terminology word segmentation also refers to the task of extracting \"words\" statistically without concerning a gold-standard for segmentation, as in ().", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7546681761741638}]}, {"text": "In such a context, the extracted \"words\" are more appropriate for building a dictionary, rather than for corpus-based language processing, which are outside of the scope of this paper.", "labels": [], "entities": []}, {"text": "Because of the discussed characteristics of the language, there are challenges in establishing a gold standard for Vietnamese word segmentation.", "labels": [], "entities": [{"text": "Vietnamese word segmentation", "start_pos": 115, "end_pos": 143, "type": "TASK", "confidence": 0.6032005051771799}]}, {"text": "The difficulties in Vietnamese word segmentation have been recognized by many researchers.", "labels": [], "entities": [{"text": "Vietnamese word segmentation", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.5790122052033743}]}, {"text": "Although most people agree that the Vietnamese language has two types of words: single and compound, there is little consensus as to the methodology for segmenting a sentence into words.", "labels": [], "entities": [{"text": "segmenting a sentence into words", "start_pos": 153, "end_pos": 185, "type": "TASK", "confidence": 0.8027790904045105}]}, {"text": "The disagreement occurs not only because of the different functions of blank spaces (as mentioned above), but also because Vietnamese is not an inflectional language, as is the case for English or Japanese, for which morphological forms can provide useful clues for word segmentation . While similar problems also occur with Chinese word segmentation), Vietnamese word segmentation maybe more difficult, because the modern Vietnamese writing system is based on Latin characters, which represent the pronunciation, but not the meaning of words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 266, "end_pos": 283, "type": "TASK", "confidence": 0.7221489548683167}, {"text": "Chinese word segmentation", "start_pos": 325, "end_pos": 350, "type": "TASK", "confidence": 0.7363038261731466}, {"text": "Vietnamese word segmentation", "start_pos": 353, "end_pos": 381, "type": "TASK", "confidence": 0.6387859980265299}]}, {"text": "All these characteristics make it difficult to perform word segmentation for Vietnamese, both manually and automatically, and have thus resulted in different criteria for word segmenation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7538270354270935}]}, {"text": "However, so far there have been few studies on the challenges in word segmentation, and the comparison of different word segmentation criteria.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7781297862529755}, {"text": "word segmentation", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.6883985996246338}]}, {"text": "In this paper, a brief introduction of the Vietnamese Treebank (VTB) and its annotation scheme are provided in Section 2.", "labels": [], "entities": [{"text": "Vietnamese Treebank (VTB)", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.9637413620948792}]}, {"text": "Then, we described our methods for the detection and correction of the problematic annotations in the VTB corpus (Section 4.2).", "labels": [], "entities": [{"text": "detection and correction", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.7155322631200155}, {"text": "VTB corpus", "start_pos": 102, "end_pos": 112, "type": "DATASET", "confidence": 0.9743643701076508}]}, {"text": "We classified the problematic annotations into several patterns of inconsistency, part of which were manually fixed to improve the quality of the corpus.", "labels": [], "entities": []}, {"text": "The rest, which can be considered as the most difficult and controversial instances of word segmentation, were used to create different versions of the VTB corpus representing different word segmentation criteria.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7591302692890167}, {"text": "VTB corpus", "start_pos": 152, "end_pos": 162, "type": "DATASET", "confidence": 0.9049302637577057}, {"text": "word segmentation", "start_pos": 186, "end_pos": 203, "type": "TASK", "confidence": 0.7315222918987274}]}, {"text": "Finally, we evaluated these criteria in automatic word segmentation, and its application in text classification and English-Vietnamese statistical machine translation in Section 4.", "labels": [], "entities": [{"text": "automatic word segmentation", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.5888914167881012}, {"text": "text classification", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.814239501953125}, {"text": "statistical machine translation", "start_pos": 135, "end_pos": 166, "type": "TASK", "confidence": 0.6303941706816355}]}, {"text": "This study is not only beneficial for the development of computational processing technologies for Vietnamese, a language spoken by over 90 million people, but also for similar languages such as Thai, Laos, and soon.", "labels": [], "entities": []}, {"text": "This study also promotes the computational linguistic studies on how to transfer methods developed fora popular language, like English, to a language that has not yet intensively studied.", "labels": [], "entities": []}], "datasetContent": [{"text": "We estimated the precision of our method by randomly selecting 130 2-gram variation instances, extracted from the method described above, and manually checked whether the inconsistencies are true.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9995512366294861}]}, {"text": "We found that 129 cases occupying 99.2% of all extracted 2-grams are true inconsistencies.", "labels": [], "entities": []}, {"text": "Only one instance of inconsistency was an ambiguous sequence gi\u00e1 c, which is one word when it means price, and two words gi\u00e1/price c/all in \u0111\u0111u c\u00f3 gi\u00e1 c/all have (their own) price.", "labels": [], "entities": []}, {"text": "The precision of our method is high, so we can use the extracted variations to provide insights on the word segmentation problem.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9992613196372986}, {"text": "word segmentation", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7473892867565155}]}, {"text": "Seven data sets corresponding to different segmentation criteria are organized as follows.", "labels": [], "entities": [{"text": "segmentation criteria", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.8850900530815125}]}, {"text": "\u2022 ORG : The original VTB corpus.", "labels": [], "entities": [{"text": "ORG", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.8249374032020569}, {"text": "VTB corpus", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.9142517745494843}]}, {"text": "\u2022 BASE : The original VTB corpus + Manual modification of special characters done in Section 3.3.", "labels": [], "entities": [{"text": "BASE", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.99909508228302}, {"text": "VTB corpus", "start_pos": 22, "end_pos": 32, "type": "DATASET", "confidence": 0.9276492893695831}]}, {"text": "\u2022 VAR_SPLIT : BASE + split all variations detected in Section 3.1.", "labels": [], "entities": [{"text": "VAR_SPLIT", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.8359440565109253}, {"text": "BASE", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9855068922042847}]}, {"text": "\u2022 VAR_COMB : BASE + combine all variations detected in Section 3.1.", "labels": [], "entities": [{"text": "VAR", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.9917683601379395}, {"text": "COMB", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.5073824524879456}, {"text": "BASE", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9899349808692932}]}, {"text": "\u2022 VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3.1.", "labels": [], "entities": [{"text": "VAR_", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9520305395126343}, {"text": "FREQ", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.7439197301864624}, {"text": "BASE", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9987717270851135}, {"text": "segmentation", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.965548574924469}]}, {"text": "\u2022 STRUCT_NC : BASE + combine all classifier nouns detected in Section 3.2 with the words they modify.", "labels": [], "entities": [{"text": "STRUCT_NC", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9109613498051962}, {"text": "BASE", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9822852611541748}]}, {"text": "\u2022 STRUCT_AFFIX : BASE + combine all suffixes detected in Section 3.2 with the words they modify.", "labels": [], "entities": [{"text": "STRUCT_", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9159866571426392}, {"text": "AFFIX", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.5677341818809509}, {"text": "BASE", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.982568085193634}]}, {"text": "These data sets are used in our experiments as illustrated in.", "labels": [], "entities": []}, {"text": "The names of the data sets are also used to label our experimental configurations.", "labels": [], "entities": []}, {"text": "In this section, we briefly describe the task settings and the methods used for word segmentation (WS), text classification (TC), and English-Vietnamese statistical machine translation (SMT).", "labels": [], "entities": [{"text": "word segmentation (WS)", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.8484777390956879}, {"text": "text classification (TC)", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.8572933316230774}, {"text": "English-Vietnamese statistical machine translation (SMT)", "start_pos": 134, "end_pos": 190, "type": "TASK", "confidence": 0.7469173669815063}]}, {"text": "Recall: Evaluation results of SMT with different word segmentation methods statistical machine translation are shown in, respectively.", "labels": [], "entities": [{"text": "SMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9915347695350647}, {"text": "word segmentation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.702762633562088}, {"text": "machine translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7706094682216644}]}, {"text": "There are two important conclusions that can be drawn from these tables: (1) The quality of the treebank strongly affects the applications, since our BASE model and most of the other enhanced models improved the performance of TC and SMT systems; (2) \"Splitting\" seems to be a good solution for word segmentation of controversial cases, including the split of variations, affixes, and classifier nouns.", "labels": [], "entities": [{"text": "BASE", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.8914531469345093}, {"text": "SMT", "start_pos": 234, "end_pos": 237, "type": "TASK", "confidence": 0.8118501901626587}, {"text": "Splitting\"", "start_pos": 252, "end_pos": 262, "type": "TASK", "confidence": 0.902495950460434}, {"text": "word segmentation", "start_pos": 295, "end_pos": 312, "type": "TASK", "confidence": 0.749218761920929}]}, {"text": "According to the result in, the VAR_SPLIT criterion gives the highest WS performance.", "labels": [], "entities": [{"text": "VAR_SPLIT criterion", "start_pos": 32, "end_pos": 51, "type": "METRIC", "confidence": 0.9065027236938477}, {"text": "WS", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.7167444825172424}]}, {"text": "With the exception of STRUCT_NC, all of the modifications to the original VTB corpus increase the performance of WS.", "labels": [], "entities": [{"text": "STRUCT_NC", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.6030663847923279}, {"text": "VTB corpus", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9284937381744385}, {"text": "WS", "start_pos": 113, "end_pos": 115, "type": "TASK", "confidence": 0.9072763323783875}]}, {"text": "However, the word segmentation criterion with higher performance is not necessarily a better criterion, but a criterion should also be judged through applications of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7274985462427139}, {"text": "word segmentation", "start_pos": 166, "end_pos": 183, "type": "TASK", "confidence": 0.7196877002716064}]}, {"text": "In both SMT and TC experiments, the BASE model, which is based on the manually-modified inconsistency of special characters, achieved better results than the ORG model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.989686906337738}, {"text": "BASE", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9898481965065002}]}, {"text": "In particular, in the TC experiment, the BASE model achieved 0.66 point higher than ORG, which is a significant improvement.", "labels": [], "entities": [{"text": "TC", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.7038074731826782}, {"text": "BASE", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9976981282234192}, {"text": "ORG", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.997809112071991}]}, {"text": "The results support the conclusion that the quality of the word-segmentation corpus is very important for building NLP applications.", "labels": [], "entities": []}, {"text": "The SMT results show that three out of six augmented models, VAR_SPLIT, VAR_FREQ and BASE, performed better than the ORG configuration.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9744406938552856}, {"text": "VAR_SPLIT", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.7992223699887594}, {"text": "VAR_", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.859847754240036}, {"text": "FREQ", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.513171911239624}, {"text": "BASE", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9952972531318665}]}, {"text": "Among them, the best-performing model, VAR_SPLIT achieved 36.91 BLEU score, which is 0.55 higher than ORG.", "labels": [], "entities": [{"text": "VAR_SPLIT", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.8023202220598856}, {"text": "BLEU score", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9628980159759521}, {"text": "ORG", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.6094241142272949}]}, {"text": "In TC results, all six augmented models achieved higher results than ORG.", "labels": [], "entities": [{"text": "TC", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9206199645996094}]}, {"text": "In general, the augmented models performed better than the ORG.", "labels": [], "entities": []}, {"text": "Additionally, because our automatic methods for inconsistency detection could not coverall of the types of inconsistencies in word segmentation annotation, further improvement of corpus quality is demanded.", "labels": [], "entities": [{"text": "inconsistency detection", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.7563490569591522}, {"text": "word segmentation annotation", "start_pos": 126, "end_pos": 154, "type": "TASK", "confidence": 0.8201621969540914}]}, {"text": "Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS, TC, and SMT, we can observe that combining affixes with their head nouns resulted in slightly better results for WS and TC, and did not change the performance of SMT.", "labels": [], "entities": [{"text": "AFFIX", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.61997389793396}, {"text": "BASE", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9986590147018433}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.8727310299873352}, {"text": "SMT", "start_pos": 231, "end_pos": 234, "type": "TASK", "confidence": 0.988347589969635}]}, {"text": "However, the combination of classifier nouns with their head nouns had negative effects on WS and SMT.", "labels": [], "entities": [{"text": "WS", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9723032116889954}, {"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9780606627464294}]}, {"text": "Another part of the scope of our experiment is to compare two solutions for controversial cases of word segmentation, splitting and combining.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7431992739439011}]}, {"text": "Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT, while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify.", "labels": [], "entities": [{"text": "VAR_COMB", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.680688718954722}, {"text": "VAR_SPLIT", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.8051717480023702}, {"text": "AFFIX", "start_pos": 89, "end_pos": 94, "type": "METRIC", "confidence": 0.6025906801223755}]}, {"text": "STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where affixes and classifier nouns remain untouched.", "labels": [], "entities": [{"text": "AFFIX", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.5916732549667358}, {"text": "BASE", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.8530842065811157}]}, {"text": "Comparing VAR_COMB and VAR_SPLIT in both the TC experiment and SMT experiment, we see that the VAR_SPLIT results are better in both cases.", "labels": [], "entities": [{"text": "VAR_COMB", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9012313087781271}, {"text": "VAR", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9448469281196594}, {"text": "TC experiment", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.7339159548282623}, {"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9586513042449951}, {"text": "VAR", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.9260959625244141}]}, {"text": "Since the ratio of combined variations in the ORG corpus is 60.9%, it can be observed that splitting seems to be better than combining for WS, TC and SMT.", "labels": [], "entities": [{"text": "ORG corpus", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.926239013671875}]}], "tableCaptions": [{"text": " Table 3: Statistics of N-gram variations", "labels": [], "entities": []}, {"text": " Table 5: Counts of POS sequences of 2-gram variation inconsistencies grouped by the first  POS", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9454078674316406}]}, {"text": " Table 6: Counts of POS sequences of 2-gram variation inconsistencies grouped by the second  POS", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9521978497505188}]}, {"text": " Table 7: Statistics of targeted structural inconsistency", "labels": [], "entities": []}, {"text": " Table 8: Data used in the text classification experiment", "labels": [], "entities": [{"text": "text classification", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8191897869110107}]}, {"text": " Table 9: Evaluation results of automatic word segmentation with different WS criteria  Evaluation of word segmentation models trained on different versions of the VTB are  given in Table 9. The experimental results with text classification and English-Vietnamese", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7092257589101791}, {"text": "WS", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.8528319597244263}, {"text": "word segmentation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.6951776295900345}, {"text": "VTB", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.9549581408500671}, {"text": "text classification", "start_pos": 221, "end_pos": 240, "type": "TASK", "confidence": 0.7876379489898682}]}, {"text": " Table 10: Evaluation results of text classification with different word segmentation methods  BLEU  ORG  36.36  BASE  36.44  VAR_COMB  36.03  VAR_SPLIT  36.91  VAR_FREQ  36.75  STRUCT_NC  35.41  STRUCT_AFFIX 36.36", "labels": [], "entities": [{"text": "text classification", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7276888340711594}, {"text": "word segmentation", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7174680829048157}, {"text": "BLEU  ORG  36.36  BASE  36.44  VAR_COMB  36.03  VAR_SPLIT  36.91  VAR_FREQ  36.75  STRUCT_NC  35.41  STRUCT_AFFIX 36.36", "start_pos": 95, "end_pos": 214, "type": "METRIC", "confidence": 0.7138999950885773}]}, {"text": " Table 11: Evaluation results of SMT with different word segmentation methods", "labels": [], "entities": [{"text": "SMT", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9934098124504089}, {"text": "word segmentation", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7325742840766907}]}]}