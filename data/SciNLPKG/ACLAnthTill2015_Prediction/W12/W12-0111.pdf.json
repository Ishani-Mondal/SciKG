{"title": [], "abstractContent": [{"text": "I present an automatic post-editing approach that combines translation systems which produce syntactic trees as output.", "labels": [], "entities": []}, {"text": "The nodes in the generation tree and target-side SCFG tree are aligned and form the basis for computing structural similarity.", "labels": [], "entities": []}, {"text": "Structural similarity computation aligns subtrees and based on this alignment, sub-trees are substituted to create more accurate translations.", "labels": [], "entities": []}, {"text": "Two different techniques have been implemented to compute structural similarity: leaves and tree-edit distance.", "labels": [], "entities": []}, {"text": "I report on the translation quality of a machine translation (MT) system where both techniques are implemented.", "labels": [], "entities": [{"text": "translation", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.9639658331871033}, {"text": "machine translation (MT)", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.8540088653564453}]}, {"text": "The approach shows significant improvement over the baseline for MT systems with limited training data and structural improvement for MT systems trained on Europarl.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9886661767959595}, {"text": "MT", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.9802068471908569}, {"text": "Europarl", "start_pos": 156, "end_pos": 164, "type": "DATASET", "confidence": 0.99497389793396}]}], "introductionContent": [{"text": "Statistical MT (SMT) and rule-based MT (RBMT) have complimentary strengths and combining their output can improve translation quality.", "labels": [], "entities": [{"text": "Statistical MT (SMT", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6181741952896118}]}, {"text": "The underlying models in SMT lack linguistic sophistication when compared to RBMT systems and there is a trend towards incorporating more linguistic knowledge by creating hybrid systems that can exploit the linguistic knowledge contained in hand-crafted rules and the knowledge extracted from large amounts of text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9892571568489075}]}, {"text": "Hierarchical phrases) are encoded in a tree structure just as linguistic trees.", "labels": [], "entities": []}, {"text": "Most RBMT systems also encode the analysis of a sentence in a tree.", "labels": [], "entities": []}, {"text": "The rules generating hierarchical trees are inferred from unlabeled corpora and RBMT systems use hand-crafted rules based in linguistic knowledge.", "labels": [], "entities": []}, {"text": "While the trees are generated differently, alignments between nodes and subtrees in the generation phase can be computed.", "labels": [], "entities": []}, {"text": "Based on the computed alignments, substitution can be performed between the trees.", "labels": [], "entities": []}, {"text": "The automatic post-editing approach proposed in this paper is based on structural similarity.", "labels": [], "entities": []}, {"text": "The tree structures are aligned and subtree substitution based on the similarity of subtrees performed.", "labels": [], "entities": []}, {"text": "This knowledge-poor approach is compatible with the surface-near nature of SMT systems, does not require other information than what is available in the output, and ensures that the approach is generic so it can, in principle, be applied to any language pair.", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9928387999534607}]}], "datasetContent": [{"text": "The experiments have been conducted between Danish and English.", "labels": [], "entities": []}, {"text": "The language model trained with EMS is used to re-rank translation alternatives.", "labels": [], "entities": []}, {"text": "BLEU (), TER) and METEOR () scores will be reported.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.987036943435669}, {"text": "TER", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9966098666191101}, {"text": "METEOR", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9913357496261597}]}, {"text": "Two sets of five experiments have been conducted.", "labels": [], "entities": []}, {"text": "The first set of experiments use the initial 100,000 lines from Europarl for training Moses and the second set of experiments use the full Europarl corpus of ca.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9569442868232727}, {"text": "Europarl corpus of ca", "start_pos": 139, "end_pos": 160, "type": "DATASET", "confidence": 0.9651955366134644}]}, {"text": "The SMT baseline is the hierarchical version of Moses.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9717563390731812}]}, {"text": "distance to the dependency tree from the rulebased system is investigated.", "labels": [], "entities": []}, {"text": "In one setting, the cost functions adhere to the constrictions of computing a distance metric.", "labels": [], "entities": []}, {"text": "Two settings test the impact of biasing the insertion and deletion cost functions to assign a lower cost to inserting/deleting nonterminals, i.e. turning the dependency tree into the hierarchical tree and vice versa.", "labels": [], "entities": []}, {"text": "The results of the automatic evaluation can be seen in.", "labels": [], "entities": []}, {"text": "Skeleton indicates that TED was used to pick the hierarchical tree.", "labels": [], "entities": [{"text": "Skeleton", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9304264783859253}, {"text": "TED", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9196192026138306}]}, {"text": "The best evaluations are in bold.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatic evaluation. 100k experiments in parentheses", "labels": [], "entities": [{"text": "Automatic evaluation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.6957131028175354}]}, {"text": " Table 2: Rankings from the manual evaluation of the  second set of experiments.", "labels": [], "entities": []}]}