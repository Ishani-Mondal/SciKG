{"title": [{"text": "Hierarchical Maximum Pattern Matching with Rule Induction Approach for Sentence Parsing", "labels": [], "entities": [{"text": "Hierarchical Maximum Pattern Matching", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6226547732949257}, {"text": "Approach", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.5696332454681396}, {"text": "Sentence Parsing", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.9363177716732025}]}], "abstractContent": [{"text": "Chinese parsing has been a highly active research area in recent years.", "labels": [], "entities": [{"text": "Chinese parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6663725972175598}]}, {"text": "This paper describes a hierarchical maximum pattern matching to integrate rule induction approach for sentence parsing on traditional Chinese parsing task.", "labels": [], "entities": [{"text": "rule induction", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.6988058686256409}, {"text": "sentence parsing", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.7261008471250534}]}, {"text": "We have analyzed and extracted statistical POS (part-of-speech) tagging information from training corpus, then used the related information for labeling unknown words in test data.", "labels": [], "entities": [{"text": "POS (part-of-speech) tagging", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.5305082023143768}]}, {"text": "Finally, the rule induction regulation was applied to extract of the structure of short-term syntactic and then performed maximum pattern matching for long-term syntactic structure.", "labels": [], "entities": []}, {"text": "On Sentence Parsing task, our system performs at 44% precision, 53% recall, and F1 is 48% in the formal testing evaluation.", "labels": [], "entities": [{"text": "Sentence Parsing task", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.9289821187655131}, {"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9995747208595276}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9997581839561462}, {"text": "F1", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9996860027313232}]}, {"text": "The proposed method can achieve the significant performance in traditional Chinese sentence parsing.", "labels": [], "entities": [{"text": "Chinese sentence parsing", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.6050316294034322}]}], "introductionContent": [{"text": "Recently, natural language processing has become one of the most essential issues in computational linguistics especially inhuman centric computing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6498466829458872}]}, {"text": "In Chinese text processing, it is important to distinguish words significance in syntactic analysis.", "labels": [], "entities": [{"text": "Chinese text processing", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.6017841597398123}, {"text": "syntactic analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7546525299549103}]}, {"text": "In order to comprehend the word significance, sentence parsing becomes one of the important techniques in the natural language understanding.", "labels": [], "entities": [{"text": "comprehend the word significance", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.64996337890625}, {"text": "sentence parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7306922972202301}, {"text": "natural language understanding", "start_pos": 110, "end_pos": 140, "type": "TASK", "confidence": 0.6640560428301493}]}, {"text": "The aim of sentence parsing is assigning a Part of Speech (POS) tag to each word and recognizing the syntactic structure in a given sentence.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7044951170682907}]}, {"text": "Therefore, it will help us to understand the text by correct sentence parsing by give the structure information.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7779599130153656}]}, {"text": "For Chinese knowledge, there was a research on Categorical analyzing (Chinese Knowledge Information Processing. and then developed balanced Chinese corpora.", "labels": [], "entities": [{"text": "Categorical analyzing", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.6873786300420761}]}, {"text": "The Sinica Treebank has been developed and released for academic research since 2000 by Chinese Knowledge Information Processing (CKIP) group at Academia Sinica (, it under the framework of the Information-based Case grammar (ICG), a lexical feature-based grammar formalism, each lexical item containing both syntactic and semantic information In word segmentation, Hidden Markov Models were used to solve word segmentation problem (.", "labels": [], "entities": [{"text": "Sinica Treebank", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.7676162719726562}, {"text": "word segmentation", "start_pos": 347, "end_pos": 364, "type": "TASK", "confidence": 0.7612966299057007}, {"text": "word segmentation", "start_pos": 406, "end_pos": 423, "type": "TASK", "confidence": 0.7643769979476929}]}, {"text": "combined Hidden Markov Model-based word segment and a Support Vector Machine-based chunker for Chinese word segmentation.", "labels": [], "entities": [{"text": "Hidden Markov Model-based word segment", "start_pos": 9, "end_pos": 47, "type": "TASK", "confidence": 0.6177388072013855}, {"text": "Chinese word segmentation", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.5942498743534088}]}, {"text": "In later research, used a dictionary-based approach, and then apply a machine-learning-based approach to solve the segmentation problem.", "labels": [], "entities": [{"text": "segmentation problem", "start_pos": 115, "end_pos": 135, "type": "TASK", "confidence": 0.9257247447967529}]}, {"text": "In sentence parsing, there were two kinds of general methods, one was the statistical-based and the other was the rule-based.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 3, "end_pos": 19, "type": "TASK", "confidence": 0.7619197070598602}]}, {"text": "In rule-based, it wanted Expert knowledge and needed human labeling, but human labeling would not only produce a lot of problems but spent a lot of time.", "labels": [], "entities": [{"text": "human labeling", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.6939161568880081}]}, {"text": "In rule-based approaches, showed that used context-rule classifier for partof-speech tagging and performed better than Markov bi-gram model.", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7880065441131592}]}, {"text": "In statistical-based, recently commonly used machine learning algorithm to solve it.", "labels": [], "entities": []}, {"text": "For example, Support Vector Machine (SVM), Hidden Markov Model (HMM), Maximum Entropy (ME) and TransformationBased Learning Algorithm (TBL) be used widely.", "labels": [], "entities": [{"text": "Maximum Entropy (ME)", "start_pos": 70, "end_pos": 90, "type": "METRIC", "confidence": 0.8373362183570862}]}, {"text": "However, single machine learning algorithm had not enough, in order to had better performance that usually combined different machine learning algorithm , for instance () purposed a method that used maximum matching to upgrade accuracy of Hidden Markov Model (HMM) and conditional random fields (CRF).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 227, "end_pos": 235, "type": "METRIC", "confidence": 0.997462272644043}]}, {"text": "However, if only used statistical-based methods and machine learning algorithm was need fora lot of corpus to train models, and it lack for expert knowledge.", "labels": [], "entities": []}, {"text": "In semantic role labeling, ( showed that adopted dependency decision making and example-based approaches to automatic semantic roles labeling system for structured trees of Chinese sentences.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7190671563148499}]}, {"text": "It used statistical information and combined with grammar rules for role assignments.", "labels": [], "entities": [{"text": "role assignments", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.7765737771987915}]}, {"text": "Unknown word extraction was an important issue in many Chinese text processing tasks.", "labels": [], "entities": [{"text": "Unknown word extraction", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6821176608403524}, {"text": "Chinese text processing tasks", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.7188923060894012}]}, {"text": "showed that used statistical information and as much information as possible, such as morphology, syntax, semantics, and world knowledge in unknown word extraction.", "labels": [], "entities": [{"text": "unknown word extraction", "start_pos": 140, "end_pos": 163, "type": "TASK", "confidence": 0.6323215464750925}]}, {"text": "In 2003 research, showed that proposed a bottom-up merging algorithm to solve a problem that superfluous character strings with strong statistical associations were extracted as well.", "labels": [], "entities": []}, {"text": "In Traditional Chinese Parsing Bakeoff, there are two sub-tasks: Sentence Parsing and Semantic Role Labeling.", "labels": [], "entities": [{"text": "Traditional Chinese Parsing Bakeoff", "start_pos": 3, "end_pos": 38, "type": "TASK", "confidence": 0.5275167897343636}, {"text": "Sentence Parsing", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.9178463816642761}, {"text": "Semantic Role Labeling", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.73905877272288}]}, {"text": "This paper focuses on Sentence Parsing task and proposes hierarchical maximum pattern matching with rule induction approach to recognize the syntactic structure.", "labels": [], "entities": [{"text": "Sentence Parsing task", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.9443891644477844}]}, {"text": "We present the bakeoff results evaluation and provide analysis on the system performance in the following sections.", "labels": [], "entities": []}, {"text": "In the opening section of the paper, we illustrated the research motivations and related works.", "labels": [], "entities": []}, {"text": "The system framework is illustrated in the section 2 that is composed of rule induction regulation and maximum pattern matching.", "labels": [], "entities": [{"text": "rule induction regulation", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.7833154400189718}, {"text": "maximum pattern matching", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.680767556031545}]}, {"text": "The evaluate data and results are both described in third part.", "labels": [], "entities": []}, {"text": "Finally, some findings and future works is shown in conclusion illustrated in section 4.", "labels": [], "entities": []}, {"text": "illustrates the block diagram of the proposed parsing system for traditional Chinese sentence.", "labels": [], "entities": []}, {"text": "In preparation of starting the system, we created a dictionary by training data that the words with only one POS tagging, and also extracted the relation information according to their POS tagging.", "labels": [], "entities": []}, {"text": "The POS tagging frequency is calculated in proceeding and cascading of each POS tagging, and used to predict the POS tagging of those token undefined in the dictionary.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6635003983974457}, {"text": "POS tagging", "start_pos": 113, "end_pos": 124, "type": "TASK", "confidence": 0.6799079477787018}]}], "datasetContent": [{"text": "In training data, there are 65K token strings, we extract 39K token to create the dictionary.", "labels": [], "entities": []}, {"text": "In testing evaluations, there are 1K token strings to be testing.", "labels": [], "entities": []}, {"text": "The evaluation of our system in sentence parsing sub-task is shown in table 1.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7250625491142273}]}, {"text": "Our system obtains 44% precision, 53% recall and 48% F1.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9997292160987854}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9997811913490295}, {"text": "F1", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9996678829193115}]}, {"text": "shows the details parser ratio of each syntactic structure.", "labels": [], "entities": []}, {"text": "For the result, it has highest ratio about 80% on sentence level parser.", "labels": [], "entities": []}, {"text": "In test data, the token of each string are more than 6, it has more probability correspond to the syntactic structure of sentence level parser.", "labels": [], "entities": []}, {"text": "For NP-Phrase parser, it has second rank.", "labels": [], "entities": [{"text": "NP-Phrase parser", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7514717280864716}]}, {"text": "During we observe the training data, there are most NP-Phrase structures, and some noun of type can be NP-Phrase itself.", "labels": [], "entities": []}, {"text": "So we focus on NP-Phrase when design the rule induction.", "labels": [], "entities": [{"text": "rule induction", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.712143063545227}]}, {"text": "VP-Phrase and PP-Phrase have lower ratio, some verb will combine noun to be NP-Phrase, and the rule we design on both VP-Phrase and PP-Phrase are not robustness to cause maximum pattern matching fail.", "labels": [], "entities": []}, {"text": "GPPhrase sample is rare in training data, it only a rule in our system.", "labels": [], "entities": [{"text": "GPPhrase sample", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.8572472035884857}]}], "tableCaptions": [{"text": " Table 2. Evaluation result in details", "labels": [], "entities": []}]}