{"title": [{"text": "Exploiting Partial Annotations with EM Training", "labels": [], "entities": []}], "abstractContent": [{"text": "For many NLP tasks, EM-trained HMMs are the common models.", "labels": [], "entities": []}, {"text": "However, in order to escape local maxima and find the best model, we need to start with a good initial model.", "labels": [], "entities": []}, {"text": "Researchers suggested repeated random restarts or constraints that guide the model evolution.", "labels": [], "entities": []}, {"text": "Restarts are time-intensive, and most constraint-based approaches require serious re-engineering or external solvers.", "labels": [], "entities": []}, {"text": "In this paper we measure the effectiveness of very limited initial constraints: specifically, annotations of a small number of words in the training data.", "labels": [], "entities": []}, {"text": "We vary the amount and distribution of initial partial annotations, and compare the results to unsupervised and supervised approaches.", "labels": [], "entities": []}, {"text": "We find that partial annotations improve accuracy and can reduce the need for random restarts, which speeds up training time considerably.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9988170862197876}]}], "introductionContent": [{"text": "While supervised learning methods achieve good performance in many NLP tasks, they are incapable of dealing with missing annotations.", "labels": [], "entities": []}, {"text": "For most new problems, however, missing data is the norm, which makes it impossible to train supervised models.", "labels": [], "entities": []}, {"text": "Unsupervised learning techniques can make use of unannotated data and are thus well-suited for these problems.", "labels": [], "entities": []}, {"text": "For sequential labeling tasks (POS-tagging, NErecognition), EM-trained HMMs are the most common unsupervised model.", "labels": [], "entities": []}, {"text": "However, running vanilla forward-backward-EM leads to mediocre results, due to various properties of the training method.", "labels": [], "entities": []}, {"text": "Running repeated restarts with random initialization can help escape local maxima, but in order to find the global optimum, we need to run a great number (100 or more) of them ().", "labels": [], "entities": []}, {"text": "However, there is another solution.", "labels": [], "entities": []}, {"text": "Various papers have shown that the inclusion of some knowledge greatly enhances performance of unsupervised systems.", "labels": [], "entities": []}, {"text": "They introduce constraints on the initial model and the parameters.", "labels": [], "entities": []}, {"text": "This directs the learning algorithm towards a better parameter configuration.", "labels": [], "entities": []}, {"text": "Types of constraints include ILP-based methods (, and posterior regularization.", "labels": [], "entities": []}, {"text": "While those approaches are powerful and yield good results, they require us to reformulate the constraints in a certain language, and either use an external solver, or re-design parts of the maximization step.", "labels": [], "entities": []}, {"text": "This is time-consuming and requires a certain expertise.", "labels": [], "entities": []}, {"text": "One of the most natural ways of providing constraints is to annotate a small amount of data.", "labels": [], "entities": []}, {"text": "This can either be done manually, or via simple heuristics, for example, if some words' parts of speech are unambiguous.", "labels": [], "entities": []}, {"text": "This can significantly speedup learning and improve accuracy of the learned models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9989724159240723}]}, {"text": "These partial annotations area common technique for semi-supervised learning.", "labels": [], "entities": []}, {"text": "It requires no changes to the general framework, or the use of external solvers.", "labels": [], "entities": []}, {"text": "While this well-known, it is unclear exactly how much annotation, and annotation of what, is most effective to improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9940416216850281}]}, {"text": "To our knowledge, no paper has investigated this aspect empirically.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy of various PSD systems. Baseline is  most frequent sense.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9961853623390198}, {"text": "PSD", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9630094766616821}, {"text": "Baseline", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.956987202167511}]}, {"text": " Table 2: Accuracy of various POS systems. Random  baseline averaged over 10 runs.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9876707792282104}, {"text": "Random  baseline", "start_pos": 43, "end_pos": 59, "type": "METRIC", "confidence": 0.9590816795825958}]}]}