{"title": [{"text": "Improving AMBER, an MT Evaluation Metric", "labels": [], "entities": [{"text": "Improving AMBER", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6097969710826874}, {"text": "MT Evaluation Metric", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.8166643977165222}]}], "abstractContent": [{"text": "A recent paper described anew machine translation evaluation metric, AMBER.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.843021810054779}, {"text": "AMBER", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.6358842849731445}]}, {"text": "This paper describes two changes to AMBER.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.7397864460945129}]}, {"text": "The first one is incorporation of anew ordering penalty; the second one is the use of the downhill simplex algorithm to tune the weights for the components of AMBER.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 159, "end_pos": 164, "type": "DATASET", "confidence": 0.9285063147544861}]}, {"text": "We tested the impact of the two changes, using data from the WMT metrics task.", "labels": [], "entities": [{"text": "WMT metrics task", "start_pos": 61, "end_pos": 77, "type": "DATASET", "confidence": 0.7151409983634949}]}, {"text": "Each of the changes by itself improved the performance of AMBER, and the two together yielded even greater improvement, which in some cases was more than additive.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.5602982044219971}]}, {"text": "The new version of AMBER clearly outperforms BLEU in terms of correlation with human judgment.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.4225923717021942}, {"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9983816146850586}]}], "introductionContent": [{"text": "AMBER is a machine translation evaluation metric first described in).", "labels": [], "entities": [{"text": "AMBER", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.5394423604011536}, {"text": "machine translation evaluation", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.838649332523346}]}, {"text": "It is designed to have the advantages of BLEU), such as nearly complete language independence and rapid computability, while attaining even higher correlation with human judgment.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9938467144966125}]}, {"text": "According to the paper just cited: \"It can bethought of as a weighted combination of dozens of computationally cheap features based on word surface forms for evaluating MT quality\".", "labels": [], "entities": [{"text": "MT quality", "start_pos": 169, "end_pos": 179, "type": "TASK", "confidence": 0.8942875266075134}]}, {"text": "Many recently defined machine translation metrics seek to exploit deeper sources of knowledge than are available to BLEU, such as external lexical and syntactic resources.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.740543931722641}, {"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.594925582408905}]}, {"text": "Unlike these and like BLEU, AMBER relies entirely on matching surface forms in tokens in the hypothesis and reference, thus sacrificing depth of knowledge for simplicity and speed.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9753229022026062}, {"text": "AMBER", "start_pos": 28, "end_pos": 33, "type": "TASK", "confidence": 0.8515433669090271}]}, {"text": "In this paper, we describe two improvements to AMBER.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.5813738107681274}]}, {"text": "The first is anew ordering penalty called \"v\" developed in.", "labels": [], "entities": []}, {"text": "The second remedies a weakness in the 2011 version of AMBER by carrying out automatic, rather than manual, tuning of this metric's free parameters; we now use the simplex algorithm to do the tuning.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.9026277661323547}]}], "datasetContent": [{"text": "The experiments are carried out on WMT metric task data: specifically, the English-to-all submissions.", "labels": [], "entities": [{"text": "WMT metric task data", "start_pos": 35, "end_pos": 55, "type": "DATASET", "confidence": 0.6500423699617386}]}, {"text": "The languages \"all\" (\"xx\" in  We used 2008 and 2011 data as dev sets, 2009 and 2010 data as test sets.", "labels": [], "entities": []}, {"text": "Spearman's rank correlation coefficient \u03c1 was employed to measure correlation of the metric with system-level human judgments of translation.", "labels": [], "entities": [{"text": "rank correlation coefficient \u03c1", "start_pos": 11, "end_pos": 41, "type": "METRIC", "confidence": 0.8653473556041718}]}, {"text": "The human judgment score was based on the \"Rank\" only, i.e., how often the translations of the system were rated as better than those from other systems).", "labels": [], "entities": []}, {"text": "Thus, BLEU and the new version of AMBER were evaluated on how well their rankings correlated with the human ones.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.996692419052124}, {"text": "AMBER", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.6934090256690979}]}, {"text": "For the segment level, we followed) in using Kendall's rank correlation coefficient \u03c4.", "labels": [], "entities": [{"text": "Kendall's rank correlation coefficient \u03c4", "start_pos": 45, "end_pos": 85, "type": "METRIC", "confidence": 0.6686814626057943}]}, {"text": "In what follows, \"AMBER1\" will denote a variant of AMBER as described in.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.7631046772003174}]}, {"text": "Specifically, it is the variant AMBER that is, the variant in which results are averaged over two runs with the following preprocessing: 1.", "labels": [], "entities": [{"text": "AMBER", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.4631771445274353}]}, {"text": "A run with tokenization and lower-casing 2.", "labels": [], "entities": []}, {"text": "A run in which tokenization and lowercasing are followed by the word splitting.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.9645727872848511}, {"text": "word splitting", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.6999668926000595}]}, {"text": "Each word with more than 4 letters is segmented into two sub-words, with one being the first 4 letters and the other the last 2 letters.", "labels": [], "entities": []}, {"text": "If the word has 5 letters, the 4 th letter appears twice: e.g., \"gangs\" becomes \"gang\" + \"gs\".", "labels": [], "entities": []}, {"text": "If the word has more than 6 letters, the middle part is thrown away.", "labels": [], "entities": []}, {"text": "The second run above requires some explanation.", "labels": [], "entities": []}, {"text": "Recall that in AMBER, we wish to avoid use of external resources such as stemmers and morphological analyzers, and we aim at maximal language independence.", "labels": [], "entities": []}, {"text": "Here, we are doing a kind of \"poor man's morphological analysis\".", "labels": [], "entities": []}, {"text": "The first four letters of a word are an approximation of its stem, and the last two letters typically carry at least some information about number, gender, case, etc.", "labels": [], "entities": []}, {"text": "Some information is lost, but on the other hand, when we use the metric fora new language (or at least, anew Indo-European language) we know that it will extract at least some of the information hidden inside morphologically complex words.", "labels": [], "entities": []}, {"text": "The results shown in compare the correlation of variants of AMBER with human judgment; compares the best version of AMBER (AMBER2) with BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9957364797592163}]}, {"text": "For instance, to calculate segment-level correlations using Kendall's \u03c4, we carried out 33,071 paired comparisons for out-of-English and 31,051 paired comparisons for into-English.", "labels": [], "entities": []}, {"text": "The resulting \u03c4 was calculated per system, then averaged for each condition (out-of-English and into-English) to obtain one out-of-English value and one into-English value.", "labels": [], "entities": []}, {"text": "First, we compared the performance of AMBER1 with aversion of AMBER1 that includes the new reordering penalty v, at the system and segment levels.", "labels": [], "entities": [{"text": "AMBER1", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.8563145399093628}, {"text": "AMBER1", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9273983240127563}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The greatest impact of v is on \"out of English\" at the segment level, but none of the results are particularly impressive.", "labels": [], "entities": []}, {"text": "Second, we compared the performance of manually tuned AMBER1 with AMBER1 whose parameters were tuned by the simplex method.", "labels": [], "entities": [{"text": "AMBER1", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.9079281687736511}, {"text": "AMBER1", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.9476003050804138}]}, {"text": "The tuning was run four times on the dev set, once for each possible combination of into/out-of English and system/segment level.", "labels": [], "entities": []}, {"text": "shows the results on the test set.", "labels": [], "entities": []}, {"text": "This change had a greater impact, especially on the segment level.", "labels": [], "entities": []}, {"text": "Then, we compared the performance of AMBER1 with AMBER1 that contains v and that has been tuned by the simplex method.", "labels": [], "entities": [{"text": "AMBER1", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.8980448246002197}, {"text": "AMBER1", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9594957232475281}]}, {"text": "We will denote the new version of AMBER containing both changes \"AMBER2\".", "labels": [], "entities": [{"text": "AMBER", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.8748602271080017}, {"text": "AMBER2", "start_pos": 65, "end_pos": 71, "type": "DATASET", "confidence": 0.8411635756492615}]}, {"text": "It will be seen from that AMBER2 is a major improvement over AMBER1 at the segment level.", "labels": [], "entities": [{"text": "AMBER2", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.6318667531013489}, {"text": "AMBER1", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.9026933312416077}]}, {"text": "In the case of \"into English\" at the segment level, the impact of the two changes seems to have been synergistic: adding together the percentage improvements due to v and simplex from, one would have expected an improvement of 4.5% for both changes together, but the actual improvement was 6.2%.", "labels": [], "entities": []}, {"text": "Furthermore, there was no improvement at the system level for \"out of English\" when either change was tried separately, but there was a small improvement when the two changes were combined.", "labels": [], "entities": []}, {"text": "Of course, the most important question is: does the new version of AMBER (AMBER2) perform better than BLEU?", "labels": [], "entities": [{"text": "AMBER (AMBER2", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.7525960206985474}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9975565671920776}]}, {"text": "answers this question (the version of BLEU used here was smoothed BLEU (mteval-v13a)).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9968302845954895}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9920729994773865}]}, {"text": "There is a clear advantage for AMBER2 over BLEU at both the system and segment levels, for both \"into English\" and \"out of English\".", "labels": [], "entities": [{"text": "AMBER2", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.6266604065895081}, {"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9898255467414856}]}], "tableCaptions": [{"text": " Table 1: Statistics of the WMT dev and test sets.", "labels": [], "entities": [{"text": "WMT dev and test sets", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.7837066888809204}]}, {"text": " Table  2. The greatest impact of v is on \"out of English\" at  the segment level, but none of the results are par- ticularly impressive.", "labels": [], "entities": []}, {"text": " Table 2: Correlation with human judgment for  AMBER1 vs. (AMBER1 including v).", "labels": [], "entities": []}, {"text": " Table 3: Correlation with human judgment for  AMBER1 vs. simplex-tuned AMBER1.", "labels": [], "entities": []}, {"text": " Table 4: Correlation with human judgment for  AMBER1 vs. AMBER2.", "labels": [], "entities": [{"text": "AMBER2", "start_pos": 58, "end_pos": 64, "type": "DATASET", "confidence": 0.8976896405220032}]}, {"text": " Table 5: Correlation with human judgment for  BLEU vs. AMBER2.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.995850682258606}, {"text": "AMBER2", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.8857282996177673}]}]}