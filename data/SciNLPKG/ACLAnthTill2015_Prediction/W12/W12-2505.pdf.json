{"title": [{"text": "Aligning Bilingual Literary Works: a Pilot Study", "labels": [], "entities": [{"text": "Aligning Bilingual Literary Works", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.9079808592796326}]}], "abstractContent": [{"text": "Electronic versions of literary works abound on the In-ternet and the rapid dissemination of electronic readers will make electronic books more and more common.", "labels": [], "entities": [{"text": "In-ternet", "start_pos": 52, "end_pos": 61, "type": "DATASET", "confidence": 0.9440633654594421}]}, {"text": "It is often the case that literary works exist in more than one language, suggesting that, if properly aligned, they could be turned into useful resources for many practical applications, such as writing and language learning aids, translation studies, or data-based machine translation.", "labels": [], "entities": [{"text": "translation studies", "start_pos": 232, "end_pos": 251, "type": "TASK", "confidence": 0.978489875793457}, {"text": "machine translation", "start_pos": 267, "end_pos": 286, "type": "TASK", "confidence": 0.7118769139051437}]}, {"text": "To be of any use, these bilingual works need to be aligned as precisely as possible, a notoriously difficult task.", "labels": [], "entities": []}, {"text": "In this paper, we revisit the problem of sentence alignment for literary works and explore the performance of anew, multi-pass, approach based on a combination of systems.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7299561500549316}]}, {"text": "Experiments conducted on excerpts often masterpieces of the French and English literature show that our approach significantly outperforms two open source tools.", "labels": [], "entities": []}], "introductionContent": [{"text": "The alignment of bitexts, i.e. of pairs of texts assumed to be mutual translations, consists in finding correspondences between logical units in the input texts.", "labels": [], "entities": []}, {"text": "The set of such correspondences is called an alignment.", "labels": [], "entities": []}, {"text": "Depending on the logical units that are considered, various levels of granularity for the alignment are obtained.", "labels": [], "entities": []}, {"text": "It is usual to align paragraphs, sentences, phrases or words (see) for recent reviews).", "labels": [], "entities": []}, {"text": "Alignments are used in many fields, ranging from Translation Studies and Computer Assisted Language Learning (CALL) to Multilingual Natural Language Processing (NLP) applications (Cross-Lingual Information Retrieval, Writing Aids for Translators, Multilingual Terminology Extraction and Machine Translation (MT)).", "labels": [], "entities": [{"text": "Translation Studies", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9817001223564148}, {"text": "Computer Assisted Language Learning (CALL)", "start_pos": 73, "end_pos": 115, "type": "TASK", "confidence": 0.7418035609381539}, {"text": "Cross-Lingual Information Retrieval", "start_pos": 180, "end_pos": 215, "type": "TASK", "confidence": 0.676454484462738}, {"text": "Machine Translation (MT))", "start_pos": 287, "end_pos": 312, "type": "TASK", "confidence": 0.8574955463409424}]}, {"text": "For all these applications, sentence alignments have to be computed.", "labels": [], "entities": [{"text": "sentence alignments", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7422958314418793}]}, {"text": "Sentence alignment is generally thought to be fairly easy and many efficient sentence alignment programs are freely available . Such programs rely on two main assumptions: (i) the relative order of sentences is the same on the two sides of the bitext, and (ii) sentence parallelism can be identified using simple surface cues.", "labels": [], "entities": [{"text": "Sentence alignment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9321673214435577}, {"text": "sentence alignment", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7382290959358215}]}, {"text": "Hypothesis (i) warrants efficient sentence alignment algorithms based on dynamic programming techniques.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7253150045871735}]}, {"text": "Regarding (ii), various surface similarity measures have been proposed: on the one hand, length-based measures () rely on the fact that the translation of a short (resp. long) sentence is short (resp. long).", "labels": [], "entities": []}, {"text": "On the other hand, lexical matching approaches () identify sure anchor points for the alignment using bilingual dictionaries or surface similarities of word forms.", "labels": [], "entities": []}, {"text": "Lengthbased approaches are fast but error-prone, while lexical matching approaches seem to deliver more reliable results.", "labels": [], "entities": []}, {"text": "Most state-of-the-art approaches use both types of information.", "labels": [], "entities": []}, {"text": "In most applications, only high-confidence oneto-one sentence alignments are considered useful and kept for subsequent processing stages.", "labels": [], "entities": [{"text": "oneto-one sentence alignments", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.6078100800514221}]}, {"text": "Indeed, when the objective is to build subsentential align-ments (at the level of words, terms or phrases), other types of mappings between sentences are deemed to be either insufficiently reliable or inappropriate.", "labels": [], "entities": []}, {"text": "As it were, the one-to-one constraint is viewed as a proxy to literalness/compositionality of the translation and warrants the search of finer-grained alignments.", "labels": [], "entities": []}, {"text": "However, for certain types of bitexts 2 , such as literary texts, translation often departs from a straight sentence-by-sentence alignment and using such a constraint can discard a significant proportion of the bitext.", "labels": [], "entities": []}, {"text": "For MT, this is just a regrettable waste of potentially useful training material, all the more so as parallel literary texts constitute a very large reservoir of parallel texts online.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9794144034385681}]}, {"text": "For other applications implying to mine, visualize or read the actual translations in their context (second language learning, translators training, automatic translation checking, etc.), the entire bitext has to be aligned.", "labels": [], "entities": [{"text": "translators training", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.9324926435947418}, {"text": "translation checking", "start_pos": 159, "end_pos": 179, "type": "TASK", "confidence": 0.8039766252040863}]}, {"text": "Furthermore, areas where the translation is only partial or approximative need to be identified precisely.", "labels": [], "entities": []}, {"text": "The work reported in this study aims to explore the quality of existing sentence alignment techniques for literary work and to explore the usability of a recently proposed multiple-pass approach, especially designed for recovering many-to-one pairings.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.7499569654464722}]}, {"text": "Ina nutshell, this approach uses sure one-to-one mappings detected in a first pass to train a discriminative sentence alignment system, which is then used to align the regions which remain problematic.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.726611316204071}]}, {"text": "Our experiments on the BAF corpus) and on a small literary corpus consisting often books show that this approach produces high quality alignments and also identifies the most problematic passages better than its competitors.", "labels": [], "entities": [{"text": "BAF corpus", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.8858709931373596}]}, {"text": "The rest of this paper is organized as follows: we first report the results of a pilot study aimed at aligning our corpus with existing alignment methods (Section 2).", "labels": [], "entities": []}, {"text": "In Section 3, we briefly describe our two-pass method, including some recent improvements, and present experimental performance on the BAF corpus.", "labels": [], "entities": [{"text": "BAF corpus", "start_pos": 135, "end_pos": 145, "type": "DATASET", "confidence": 0.9240680038928986}]}, {"text": "Attempts to apply this technique to our larger literary corpus are reported and discussed in Section 4.", "labels": [], "entities": []}, {"text": "We discuss further prospects and conclude in Section 5. 2 Book alignment with off-the-shelf tools", "labels": [], "entities": []}], "datasetContent": [{"text": "Sentence alignment tools are usually evaluated using standard recall and precision measures, combined in the F-measure, with respect to some manually defined gold alignment).", "labels": [], "entities": [{"text": "Sentence alignment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.919381856918335}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9987478256225586}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9724569320678711}, {"text": "F-measure", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.9955423474311829}]}, {"text": "These measures can be computed at various levels of granularity: the level of alignment links, of sentences, of words, and of characters.", "labels": [], "entities": []}, {"text": "As gold references only specify alignment links, the other references are automatically derived in the most inclusive way.", "labels": [], "entities": []}, {"text": "For instance, if the reference alignment links state that the pair of source sentences f 1 , f 2 is aligned with target e, the reference sentence alignment will contain both (f 1 , e) and (f 2 , e); likewise, the reference word alignment will contain all the possible word alignments between tokens in the source and the target side.", "labels": [], "entities": []}, {"text": "For such metrics, missing the alignment of a large \"block\" of sentences gets a higher penalty than missing a small one; likewise, misaligning short sentences is less penalized than misaligning longer ones.", "labels": [], "entities": []}, {"text": "As aside effect, all metrics, but the more severe one, ignore null alignments.", "labels": [], "entities": []}, {"text": "Our results are therefore based on the link-level and sentence-level F-measure, to reflect the importance of correctly predicting unaligned sentences in our applicative scenario.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.8693448305130005}]}, {"text": "In this section, we report the results of experiments run using again Jules Verne's book from the BAF corpus.", "labels": [], "entities": [{"text": "BAF corpus", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.855705976486206}]}, {"text": "Figures are reported in where we contrast our approach with two simple baselines: (i) keep only Moore's links; (ii) complete Moore's links with one single many-to-many alignment for We enclose the source and target texts between begin and end markers to enforce alignment of the first and last sentences.: Performance of maxent-based alignments each block.", "labels": [], "entities": []}, {"text": "For the maxent-based approach, we also report the precision on just those links that are not predicted by Moore.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9996286630630493}]}, {"text": "A more complete set of experiments conducted with other portions of the BAF are reported elsewhere () and have shown to deliver state-of-the-art results.", "labels": [], "entities": [{"text": "BAF", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.5250757932662964}]}, {"text": "As expected, complementing the very accurate prediction of Moore's systems with our links significantly boosts the sentence-based alignment performance: recall rises from 0.62 to 0.80 for \u03b1 = 0, which has a clear effect on the corresponding Fmeasure (from 0.76 to 0.86).", "labels": [], "entities": [{"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9991476535797119}, {"text": "Fmeasure", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.9869421720504761}]}, {"text": "The performance differences with the default strategy of keeping those blocks unsegmented are also very clear.", "labels": [], "entities": []}, {"text": "Sentencewise, maxent-based alignments are also quite precise, especially when the value of \u03b1 is chosen with care (P=0.91 for \u03b1=0.06); however, this optimization has a very small overall effect, given that only a limited number of alignment links are actually computed by the maxent classifier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Baseline alignment experiments", "labels": [], "entities": [{"text": "Baseline alignment", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7745789289474487}]}, {"text": " Table 3: Performance of maxent-based alignments", "labels": [], "entities": [{"text": "maxent-based alignments", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.5910628437995911}]}, {"text": " Table 4: Evaluating alignment systems on a sample of \"real-world\" books", "labels": [], "entities": [{"text": "Evaluating alignment", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8667901158332825}]}]}