{"title": [{"text": "Human-Machine Cooperation with Epistemological DBs: Supporting User Corrections to Knowledge Bases", "labels": [], "entities": []}], "abstractContent": [{"text": "Knowledge bases (KB) provide support for real-world decision making by exposing data in a structured format.", "labels": [], "entities": []}, {"text": "However, constructing knowledge bases requires gathering data from many heterogeneous sources.", "labels": [], "entities": []}, {"text": "Manual efforts for this task are accurate, but lack scalabil-ity, and automated approaches provide good coverage, but are not reliable enough for real-world decision makers to trust.", "labels": [], "entities": []}, {"text": "These two approaches to KB construction have complementary strengths: in this paper we propose a novel framework for supporting human-proposed edits to knowledge bases.", "labels": [], "entities": [{"text": "KB construction", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.9791596233844757}]}], "introductionContent": [{"text": "Knowledge bases (KB) facilitate real-world decision making by providing access to structured relational information that enables pattern discovery and semantic queries.", "labels": [], "entities": [{"text": "decision making", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.6936294883489609}, {"text": "pattern discovery", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.7539624273777008}]}, {"text": "However, populating KBs requires the daunting task of gathering and assembling information from a variety of structured and unstructured sources at scale: a complex multi-task process riddled with uncertainty.", "labels": [], "entities": [{"text": "populating KBs", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7639204561710358}]}, {"text": "Uncertainty about the reliability of different sources, uncertainty about the accuracy of extraction, uncertainty about integration ambiguity, and uncertainty about changes overtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9985878467559814}]}, {"text": "While this data can be gathered manually with high accuracy, it can be achieved at greater scale using automated approaches such as information extraction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9763696789741516}, {"text": "information extraction", "start_pos": 132, "end_pos": 154, "type": "TASK", "confidence": 0.8824360370635986}]}, {"text": "Indeed manual and automated approaches to knowledge base construction have complementary strengths: humans have high accuracy while machines have high coverage.", "labels": [], "entities": [{"text": "knowledge base construction", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6391126811504364}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9980294108390808}]}, {"text": "However, integrating the two approaches is difficult because it is not clear how to best resolve conflicting assertions on knowledge base content.", "labels": [], "entities": []}, {"text": "For example, it is risky to just allow users to directly modify the KB's notion of \"the truth\" because sometimes humans will be wrong, sometimes humans disagree, and sometimes the human edits become out-of-date in response to new events (and should be later over-written by IE).", "labels": [], "entities": []}, {"text": "We propose anew framework for supporting human edits to knowledge bases.", "labels": [], "entities": []}, {"text": "Rather than treating each human edit as a deterministic truth, each edit is simply anew piece of evidence that can participate in inference with other pieces of raw evidence.", "labels": [], "entities": []}, {"text": "In particular, a graphical model of \"the truth\" contains factors that weigh these various sources of evidence (documents culled by a web spider, outputs from IE systems, triples pulled from semantic web ontologies, rows streamed from external databases, etc.) against edits provided by enthusiastic groups of users.", "labels": [], "entities": []}, {"text": "Inference runs in the background-foreverconstantly improving the current best known truth.", "labels": [], "entities": []}, {"text": "We call this an epistemological approach to KB construction because the truth is never observed (i.e., provided deterministically from humans or IE), rather, it is inferred from raw evidence with inference.", "labels": [], "entities": [{"text": "KB construction", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.9568572640419006}]}, {"text": "Further, because the truth is simply a random variable in a graphical model, we can jointly reason about the value of the truth as well as the reliability of human edits (which we save for future work).", "labels": [], "entities": [{"text": "reliability", "start_pos": 143, "end_pos": 154, "type": "METRIC", "confidence": 0.9722368121147156}]}, {"text": "In the next section we describe the task of constructing a bibliographic KB, motivate the importance of coreference, and describe how to enable human edits in this context.", "labels": [], "entities": []}, {"text": "Then we empiricallyName:,Fernando,Pereira, (not,enough,evidence,to,merge), (a) A recursive coreference model with two predicted Fernando Pereira entities.", "labels": [], "entities": []}, {"text": "Black squares represent factors, and the numbers represent their their log scores, which indicate the compatibilities of the various coreference decisions.", "labels": [], "entities": []}, {"text": "There is not enough evidence to merge these two entities together.", "labels": [], "entities": []}, {"text": "(b) How a human edit can correct the coreference error in the previous A human asserts that the \"Prolog F. Pereira is also the NLP F.", "labels": [], "entities": [{"text": "Prolog F. Pereira", "start_pos": 97, "end_pos": 114, "type": "DATASET", "confidence": 0.7608644167582194}]}, {"text": "This statement creates two mentions with a should-link constraint.", "labels": [], "entities": []}, {"text": "During inference, the mentions are first moved into different entities.", "labels": [], "entities": []}, {"text": "Then, when inference proposes to merge those two entities, the model gives a small bonus to this possible world because the two should-link mentions are placed in the same entity.", "labels": [], "entities": []}, {"text": "demonstrate that treating user edits as evidence allows corrections to propagate throughout the database resulting in an additional 43% improvement over an approach that deterministically treats edits as the truth.", "labels": [], "entities": []}, {"text": "We also demonstrate robustness to incorrect human edits.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the purpose of these experiments we focus on the problem of author coreference, which is a notoriously difficult problem due to common first and last names, spelling errors, extraction errors, and lack of \"within document boundaries.\"", "labels": [], "entities": [{"text": "author coreference", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7248250246047974}]}, {"text": "In order to evaluate our approach, we label a highly ambiguous \"F.", "labels": [], "entities": [{"text": "F", "start_pos": 64, "end_pos": 65, "type": "METRIC", "confidence": 0.9679780602455139}]}, {"text": "Pereira\" dataset from BibTeX files.", "labels": [], "entities": [{"text": "Pereira\" dataset from BibTeX files", "start_pos": 0, "end_pos": 34, "type": "DATASET", "confidence": 0.8206988970438639}]}, {"text": "We select this first-initial last name combination because it is fairly common in Portugal, Brazil and several other countries, and as a result there are multiple prominent researchers in the field of computer science.", "labels": [], "entities": []}, {"text": "We construct this dataset with two strategies.", "labels": [], "entities": []}, {"text": "First, from a publicly available collection of BibTeX files, we identify citation entries that have an author with last name \"Pereira\" and first name beginning with \"F.\"", "labels": [], "entities": []}, {"text": "Each of the Pereira mentions gathered in this manner are manually disambiguated by identifying the real-world author to which they refer.", "labels": [], "entities": []}, {"text": "Second, we identified five prominent Pereira entities from the initial labeling and for three of them we were able to find their publication page and enter each publication into our dataset manually.", "labels": [], "entities": []}, {"text": "The number of mentions in the five entities is as follows: (181 mentions, 92 mentions, 43 mentions, 7 mentions, 2 mentions).", "labels": [], "entities": []}], "tableCaptions": []}