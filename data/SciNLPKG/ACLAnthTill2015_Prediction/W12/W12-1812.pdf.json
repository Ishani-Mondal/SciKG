{"title": [{"text": "A belief tracking challenge task for spoken dialog systems", "labels": [], "entities": [{"text": "belief tracking challenge task", "start_pos": 2, "end_pos": 32, "type": "TASK", "confidence": 0.873046025633812}]}], "abstractContent": [{"text": "Belief tracking is a promising technique for adding robustness to spoken dialog systems, but current research is fractured across different teams, techniques, and domains.", "labels": [], "entities": [{"text": "Belief tracking", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8387762010097504}]}, {"text": "This paper amplifies past informal discussions (Raux, 2011) to call fora belief tracking challenge task, based on the Spoken dialog challenge corpus (Black et al., 2011).", "labels": [], "entities": [{"text": "belief tracking challenge task", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.8206043839454651}, {"text": "Spoken dialog challenge corpus", "start_pos": 118, "end_pos": 148, "type": "DATASET", "confidence": 0.5540682375431061}]}, {"text": "Benefits, limitations , evaluation design issues, and next steps are presented.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "There are many (not one!) metrics to evaluate.", "labels": [], "entities": []}, {"text": "It is crucial to design these in advance and implement them as computer programs for use during development.", "labels": [], "entities": []}, {"text": "Specific metrics could draw on the following core concepts.", "labels": [], "entities": []}, {"text": "Baseline accuracy measures the speech recognition 1-best -i.e., accuracy without belief tracking.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9068110585212708}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9991381168365479}]}, {"text": "1-best accuracy measures how often the belief tracker's 1-best hypothesis is correct.", "labels": [], "entities": [{"text": "1-best", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9424912929534912}, {"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.5727624893188477}]}, {"text": "Mean reciprocal rank measures the quality of the ordering of the belief state, ignoring the probabilities used to order; log-likelihood measures the quality of the probabilities.", "labels": [], "entities": []}, {"text": "ROC curves measure the 1-best discrimination of the belief tracker at different false-accept rates, or at the equal error rate.", "labels": [], "entities": [{"text": "ROC", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5929796695709229}]}, {"text": "An important question is at which turns to assess the accuracy of the belief in a slot.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9988094568252563}]}, {"text": "For example, accuracy could be measured at every turn; every turn after a slot is first mentioned; only turns where a slot is mentioned; only turns where a slot appears in the speech recognition result; and soon.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9991853833198547}, {"text": "speech recognition", "start_pos": 176, "end_pos": 194, "type": "TASK", "confidence": 0.7305031716823578}]}, {"text": "Depending on the evaluation metric, it maybe necessary to annotate dialogs for the user's goal, which could be done automatically or manually.", "labels": [], "entities": []}, {"text": "Another issue is how to automatically determine whether a belief state value is correct at the semantic level.", "labels": [], "entities": []}, {"text": "A final question is how to divide the corpus into a training and test set in away that measures robustness to the different conditions.", "labels": [], "entities": []}, {"text": "Perhaps some of the data from the second round (which has not yet been released) could beheld back for evaluation.", "labels": [], "entities": []}], "tableCaptions": []}