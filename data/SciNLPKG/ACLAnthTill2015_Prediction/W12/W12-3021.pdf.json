{"title": [{"text": "Monte Carlo MCMC: Efficient Inference by Sampling Factors", "labels": [], "entities": []}], "abstractContent": [{"text": "Conditional random fields and other graphical models have achieved state of the art results in a variety of NLP and IE tasks including coref-erence and relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.8438211977481842}]}, {"text": "Increasingly, practitioners are using models with more complex structure-higher tree-width, larger fan-out, more features, and more data-rendering even approximate inference methods such as MCMC inefficient.", "labels": [], "entities": []}, {"text": "In this paper we propose an alternative MCMC sampling scheme in which transition probabilities are approximated by sampling from the set of relevant factors.", "labels": [], "entities": []}, {"text": "We demonstrate that our method converges more quickly than a traditional MCMC sampler for both marginal and MAP inference.", "labels": [], "entities": []}, {"text": "In an author coreference task with over 5 million mentions, we achieve a 13 times speedup over regular MCMC inference.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conditional random fields and other graphical models are at the forefront of many natural language processing (NLP) and information extraction (IE) tasks because they provide a framework for discriminative modeling while succinctly representing dependencies among many related output variables.", "labels": [], "entities": [{"text": "natural language processing (NLP) and information extraction (IE)", "start_pos": 82, "end_pos": 147, "type": "TASK", "confidence": 0.7251743351419767}]}, {"text": "Previously, most applications of graphical models were limited to structures where exact inference is possible, for example linear-chain CRFs).", "labels": [], "entities": []}, {"text": "More recently there has been a desire to include more factors, longer range dependencies and larger numbers of more sophisticated features; these include skip-chain CRFs for named entity recognition (), higher-order models for dependency parsing, entity-wise models for coreference () and global models of relations ().", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 174, "end_pos": 198, "type": "TASK", "confidence": 0.6965966721375784}, {"text": "dependency parsing", "start_pos": 227, "end_pos": 245, "type": "TASK", "confidence": 0.7249773740768433}]}, {"text": "The increasing sophistication of these individual NLP components compounded with the community's desire to model these tasks jointly across cross-document considerations has resulted in graphical models for which inference is computationally prohibitive.", "labels": [], "entities": []}, {"text": "Even popular approximate inference techniques such as loopy belief propagation and Markov chain Monte Carlo (MCMC) maybe prohibitive.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7126854360103607}, {"text": "Markov chain Monte Carlo (MCMC", "start_pos": 83, "end_pos": 113, "type": "METRIC", "confidence": 0.6937435368696848}]}, {"text": "MCMC algorithms such as Metropolis-Hastings (MH) are usually efficient for graphical models because the only factors needed to score a proposal are those touching the changed variables.", "labels": [], "entities": []}, {"text": "However, if the model variables have high degree (neighbor many factors), if computation of factor scores is slow, or if each proposal modifies a substantial number of variables (e.g. to satisfy deterministic constraints, such as transitivity in coreference), then even MH can be prohibitively slow.", "labels": [], "entities": [{"text": "MH", "start_pos": 270, "end_pos": 272, "type": "TASK", "confidence": 0.8185830116271973}]}, {"text": "For example, the seemingly innocuous proposal changing the type of a single entity requires scoring a linear number of factors (in the number of mentions of that entity).", "labels": [], "entities": []}, {"text": "Often, however, the factors are somewhat redundant, for example, not all the mentions of the \"USA\" entity need to be examined to confidently conclude that it is a COUNTRY.", "labels": [], "entities": [{"text": "USA\" entity", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9122357765833536}]}, {"text": "In this paper we propose an approximate MCMC framework that facilitates efficient inference in highdegree graphical models.", "labels": [], "entities": []}, {"text": "In particular, we approximate the acceptance ratio in the Metropolis-Hastings algorithm by replacing the exact model scores witha stochastic approximation.", "labels": [], "entities": [{"text": "acceptance ratio", "start_pos": 34, "end_pos": 50, "type": "METRIC", "confidence": 0.9592794477939606}]}, {"text": "We propose two strategies for this approximation: static uniform sampling and adaptive confidence-based sampling, and demonstrate significant speedups on synthetic and real-world information extraction tasks.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 179, "end_pos": 201, "type": "TASK", "confidence": 0.7317592948675156}]}, {"text": "MCMC is a popular method for dealing with large, dense graphical models for tasks in NLP and information extraction (.", "labels": [], "entities": [{"text": "MCMC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8505781292915344}, {"text": "information extraction", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.7907499372959137}]}, {"text": "Popular probabilistic programming packages also rely on MCMC for inference and learning, and parallel approaches to MCMC have also been recently proposed.", "labels": [], "entities": []}, {"text": "A generic method to speedup MCMC inference could have significant applicability.", "labels": [], "entities": [{"text": "MCMC inference", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.8837145566940308}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Speedups on DBLP to reach 80% B 3 F1", "labels": [], "entities": [{"text": "DBLP", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.6898003816604614}, {"text": "B", "start_pos": 40, "end_pos": 41, "type": "METRIC", "confidence": 0.9890812635421753}]}]}