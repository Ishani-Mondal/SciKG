{"title": [{"text": "Hedge Detection as a Lens on Framing in the GMO Debates: A Position Paper", "labels": [], "entities": [{"text": "Hedge Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8412982225418091}, {"text": "GMO Debates", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.6615091264247894}]}], "abstractContent": [{"text": "Understanding the ways in which participants in public discussions frame their arguments is important in understanding how public opinion is formed.", "labels": [], "entities": []}, {"text": "In this paper, we adopt the position that it is time for more computationally-oriented research on problems involving framing.", "labels": [], "entities": []}, {"text": "In the interests of furthering that goal, we propose the following specific, interesting and, we believe, relatively accessible question: In the controversy regarding the use of genetically-modified organisms (GMOs) in agriculture, do pro-and anti-GMO articles differ in whether they choose to adopt a more \"scientific\" tone?", "labels": [], "entities": []}, {"text": "Prior work on the rhetoric and sociology of science suggests that hedging may distinguish popular-science text from text written by professional scientists for their colleagues.", "labels": [], "entities": []}, {"text": "We propose a detailed approach to studying whether hedge detection can be used to understanding scientific framing in the GMO debates , and provide corpora to facilitate this study.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.8539064526557922}, {"text": "understanding scientific framing in the GMO debates", "start_pos": 82, "end_pos": 133, "type": "TASK", "confidence": 0.677753244127546}]}, {"text": "Some of our preliminary analyses suggest that hedges occur less frequently in scientific discourse than in popular text, a finding that contradicts prior assertions in the literature.", "labels": [], "entities": []}, {"text": "We hope that our initial work and data will encourage others to pursue this promising line of inquiry.", "labels": [], "entities": []}], "introductionContent": [{"text": "1.1 Framing, \"scientific discourse\", and GMOs in the media The issue of framing) is of great importance in understanding how public opinion is formed.", "labels": [], "entities": [{"text": "Framing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.8097705245018005}]}, {"text": "In their Annual Review of Political Science survey, describe framing effects as occurring \"when (often small) changes in the presentation of an issue or an event produce (sometimes large) changes of opinion\" (p.", "labels": [], "entities": [{"text": "Annual Review of Political Science survey", "start_pos": 9, "end_pos": 50, "type": "DATASET", "confidence": 0.682394782702128}]}, {"text": "104); as an example, they cite a study wherein respondents answered differently, when asked whether a hate group should be allowed to hold a rally, depending on whether the question was phrased as one of \"free speech\" or one of \"risk of violence\".", "labels": [], "entities": []}, {"text": "The genesis of our work is in a framing question motivated by a relatively current political issue.", "labels": [], "entities": []}, {"text": "In media coverage of transgenic crops and the use of genetically modified organisms (GMOs) in food, do pro-GMO vs. anti-GMO articles differ not just with respect to word choice, but in adopting a more \"scientific\" discourse, meaning the inclusion of more uncertainty and fewer emotionally-laden words?", "labels": [], "entities": []}, {"text": "We view this as an interesting question from a text analysis perspective (with potential applications and implications that lie outside the scope of this article).", "labels": [], "entities": [{"text": "text analysis", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.8193735480308533}]}], "datasetContent": [{"text": "As stated in Section 1, our proposal requires developing an effective hedge detection algorithm.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.8184367120265961}]}, {"text": "Our approach for the preliminary work described in this paper is to re-implement Georgescul's (2010) algorithm; the experimental results on the Bio+Wiki domain, given in Section 5.1, are encouraging.", "labels": [], "entities": [{"text": "Bio+Wiki domain", "start_pos": 144, "end_pos": 159, "type": "DATASET", "confidence": 0.7444759905338287}]}, {"text": "Then we use this method to attempt to validate (at a larger scale than in our manual pilot annotation) whether hedges can be used to distinguish between profscience and pop-science discourse on GMOs.", "labels": [], "entities": []}, {"text": "Unfortunately, our results, given in Section 5.2, are inconclusive, since our trained model could not achieve satisfactory automatic hedge-detection accuracy on the WOS+LEXIS domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9813965559005737}, {"text": "WOS+LEXIS domain", "start_pos": 165, "end_pos": 181, "type": "DATASET", "confidence": 0.6737088188529015}]}], "tableCaptions": [{"text": " Table 1: Basic descriptive statistics for the main corpora we worked with. We created the first two. Higher Flesch  scores indicate text that is easier to read.", "labels": [], "entities": [{"text": "Flesch  scores", "start_pos": 109, "end_pos": 123, "type": "METRIC", "confidence": 0.9675482213497162}]}, {"text": " Table 2: Percentages of uncertain sentences.", "labels": [], "entities": []}, {"text": " Table 3: Number of features.", "labels": [], "entities": []}, {"text": " Table 4: Best 5-fold cross-validation performance for Bio  and/or Wiki after parameter tuning. As a reminder, we  repeat that our intended final test set is the WOS+LEXIS  corpus, which is disjoint from Bio+Wiki.", "labels": [], "entities": [{"text": "WOS+LEXIS  corpus", "start_pos": 162, "end_pos": 179, "type": "DATASET", "confidence": 0.7022248581051826}]}, {"text": " Table 5: The upper part shows the performance on WOS  and LEXIS based on models trained on the CoNLL  dataset. The lower part gives the sub-corpus results for  Bio, which provided the best performance on the full  WOS+LEXIS corpus.", "labels": [], "entities": [{"text": "CoNLL  dataset", "start_pos": 96, "end_pos": 110, "type": "DATASET", "confidence": 0.9830262660980225}, {"text": "Bio", "start_pos": 161, "end_pos": 164, "type": "DATASET", "confidence": 0.8239137530326843}, {"text": "WOS+LEXIS corpus", "start_pos": 215, "end_pos": 231, "type": "DATASET", "confidence": 0.6804348453879356}]}, {"text": " Table 7: For completeness, we report here the percentage  of uncertain sentences in WOS and LEXIS according to  our trained classifiers, although we regard these results as  unreliable since those classifiers have low accuracy. Bio  refers to the best model trained on Bio only in Section 5.1,  while Tuned refers to the model in Table 6 that is tuned  based on the 153 labeled sentences in WOS+LEXIS.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 219, "end_pos": 227, "type": "METRIC", "confidence": 0.9943487048149109}]}]}