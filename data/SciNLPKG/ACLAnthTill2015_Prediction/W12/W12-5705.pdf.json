{"title": [{"text": "Topic Modeling-based Domain Adaptation for System Combination", "labels": [], "entities": [{"text": "Topic Modeling-based Domain Adaptation", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.881292462348938}]}], "abstractContent": [{"text": "This paper gives the system description of the domain adaptation team of Dublin City University for our participation in the system combination task in the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid MT (ML4HMT-12).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7094339281320572}, {"text": "Dublin City University", "start_pos": 73, "end_pos": 95, "type": "DATASET", "confidence": 0.972058117389679}, {"text": "Division of Labour in Hybrid MT (ML4HMT-12)", "start_pos": 228, "end_pos": 271, "type": "TASK", "confidence": 0.6590255631340874}]}, {"text": "We used the results of unsupervised document classification as meta information to the system combination module.", "labels": [], "entities": [{"text": "document classification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7427477240562439}]}, {"text": "For the Spanish-English data, our strategy achieved 26.33 BLEU points, 0.33 BLEU points absolute improvement over the standard confusion-network-based system combination.", "labels": [], "entities": [{"text": "Spanish-English data", "start_pos": 8, "end_pos": 28, "type": "DATASET", "confidence": 0.7215409278869629}, {"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9993446469306946}, {"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9973576664924622}]}, {"text": "This was the best score in terms of BLEU among six participants in ML4HMT-12.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.99968421459198}, {"text": "ML4HMT-12", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.612453043460846}]}], "introductionContent": [{"text": "This paper describes anew extension to our system combination module developed in Dublin City University (.", "labels": [], "entities": [{"text": "Dublin City University", "start_pos": 82, "end_pos": 104, "type": "DATASET", "confidence": 0.9842473069826762}]}, {"text": "We have added a domain adaptation technique to our system combination module and tested it in the system combination task at the ML4HMT-2012 workshop.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7130062282085419}, {"text": "system combination task", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.7823015650113424}, {"text": "ML4HMT-2012 workshop", "start_pos": 129, "end_pos": 149, "type": "DATASET", "confidence": 0.7406176328659058}]}, {"text": "The study of translation outputs obtained by systems trained on out-of-domain training data has contributed to the advance of domain adaptation techniques for statistical machine translation (SMT)).", "labels": [], "entities": [{"text": "statistical machine translation (SMT))", "start_pos": 159, "end_pos": 197, "type": "TASK", "confidence": 0.7925652116537094}]}, {"text": "The literature shows that the performance gain obtained by using indomain data (compared to out-of-domain data) is, inmost cases, rather significant.", "labels": [], "entities": []}, {"text": "Although it is often the casein the SMT literature that genre classification is done in a supervised setting), analogous to genre-specific dictionaries in rule-based machine translation (RBMT) systems, a cache-based approach further investigates this on a fine-grained level of context, which does not need the notion of genre.", "labels": [], "entities": [{"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.986295759677887}, {"text": "genre classification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7096390277147293}, {"text": "rule-based machine translation (RBMT)", "start_pos": 155, "end_pos": 192, "type": "TASK", "confidence": 0.8208541174729665}]}, {"text": "Therefore, one idea worth exploring is to employ unsupervised document classification to cluster the documents ().", "labels": [], "entities": [{"text": "document classification", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.7613817155361176}]}, {"text": "In the context of system combination, the effect of out-of-domain training data is slightly different.", "labels": [], "entities": []}, {"text": "Unlike the training of SMT systems, system combination essentially handles only the translation outputs, which can be considered to be in-domain.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9923769235610962}]}, {"text": "However, if we consider a training procedure which takes two steps (), these two steps are possible candidates that have a connection with the out-of-domain data.", "labels": [], "entities": []}, {"text": "This two step approach to system combination tunes parameters in the first step over the development set and subsequently produces a final translation combining fragments obtained by translating the test set with different MT systems using such parameters.", "labels": [], "entities": [{"text": "system combination", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7374487817287445}]}, {"text": "Apart from this line of motivation, a number of times we have encountered obstacles to deploy a system combination module whose origin is difficult to trace.", "labels": [], "entities": []}, {"text": "Although the system combination strategy works effectively inmost cases, with some particular datasets we have experienced difficulties trying to achieve better performance than the single best system.", "labels": [], "entities": []}, {"text": "Such cases include the ZH-EN translation task () and the EN-FR direction in the system combination task at WMT09 1 . In order to investigate this issue, we need to hypothesise what the cause might be.", "labels": [], "entities": [{"text": "ZH-EN translation task", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7151792148749033}, {"text": "WMT09 1", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.8786091506481171}]}, {"text": "The super confusion network approach of assumed that the cause was related to the alignment metric.", "labels": [], "entities": []}, {"text": "The strategy was then to incorporate not only one alignment metric but multiple metrics.", "labels": [], "entities": []}, {"text": "The current paper hypothesises that the genre of the test and tuning sets exhibit variance, hence out-of-domain effects, and that this causes some variance in the performance of each MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 183, "end_pos": 185, "type": "TASK", "confidence": 0.9793297648429871}]}, {"text": "If this is indeed the case, as is our assumption, the two methods explored in this paper should be effective: to identify and remove the out-of-domain data from the tuning set and to train on in-domain partitioned data.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes our algorithm.", "labels": [], "entities": []}, {"text": "In Section 3, our experimental results are presented.", "labels": [], "entities": []}, {"text": "We conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "ML4HMT-2012 provides four translation outputs (s1 to s4) which are MT output by two RBMT systems, APERTIUM and LUCY, PB-SMT (MOSES) and HPB-SMT (MOSES), respectively.: The results of out-of-domain data cleaning compared with without cleaning.", "labels": [], "entities": [{"text": "ML4HMT-2012", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9117781519889832}, {"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9567539095878601}, {"text": "APERTIUM", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9910690784454346}, {"text": "LUCY", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.8820217251777649}]}, {"text": "use TERP 4 as alignment metrics in monolingual word alignment.", "labels": [], "entities": [{"text": "monolingual word alignment", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.6414293150107065}]}, {"text": "We use MALLET 6 for topic modeling.", "labels": [], "entities": [{"text": "MALLET", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.7139662504196167}, {"text": "topic modeling", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.8780070543289185}]}, {"text": "Although topic modeling is often used to obtain unsupervised clustering, our interest is focused on unsupervised classification of documents.", "labels": [], "entities": []}, {"text": "Given a specified number of classes C, we run MALLET to train the model on the tuning set.", "labels": [], "entities": [{"text": "MALLET", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9758968353271484}]}, {"text": "In this process, we obtained the label distribution for each document.", "labels": [], "entities": []}, {"text": "Then, we infer the class using the trained model which yields the label distribution for each document.", "labels": [], "entities": []}, {"text": "Results are shown in the performance of translation outputs s1 to s4 and results of system combination on development set.", "labels": [], "entities": []}, {"text": "shows the performance on standard system combination, with and without data cleaning.", "labels": [], "entities": []}, {"text": "In this out-of-domain data cleaning, we removed 2,207 sentences (11.0%) from the tuning data.", "labels": [], "entities": []}, {"text": "The remaining 17,793 sentences are considered to be in-domain data from the point of view of the test set.", "labels": [], "entities": []}, {"text": "However, this out-of-domain data cleaning did not quite work as expected.", "labels": [], "entities": []}, {"text": "shows the performance on the development set.", "labels": [], "entities": []}, {"text": "The performance of s1 and s2 is radically lower than that of s3 and s4 across all evaluation metrics considered.", "labels": [], "entities": []}, {"text": "Although it maybe that the performance of s1 and s2 is always inferior to that of the other systems, it may also be that s1 and s2 do notwork well for some particular genre (the results shown in seem to corroborate this hypothesis, particularly for s2).", "labels": [], "entities": []}, {"text": "We also performed the in-domain partitioning with the out-of-domain tuning set and without using the out-of-domain tuning set.", "labels": [], "entities": []}, {"text": "shows our results when we partitioned into 2, 3, 4, and 5 clusters.", "labels": [], "entities": []}, {"text": "The results show that 4 class classification achieved the best result, namely 26.33 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9985539317131042}]}, {"text": "This is an improvement of 0.33 BLEU points absolute over system combination without topic modeling.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9986557960510254}]}, {"text": "Note that the baseline achieved 26.00 BLEU points, the best single system in terms of BLEU was s4 which achieved 25.31 BLEU points, and the best single system in terms of METEOR was s2 which achieved 0.5853.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9989451766014099}, {"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.998525083065033}, {"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9976608753204346}, {"text": "METEOR", "start_pos": 171, "end_pos": 177, "type": "METRIC", "confidence": 0.9033589959144592}]}], "tableCaptions": [{"text": " Table 1: Unsupervised document classification by a fixed number of clusters. Each column  shows the number of items classified in each class.", "labels": [], "entities": [{"text": "Unsupervised document classification", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.6316863695780436}]}, {"text": " Table 2: The results of out-of-domain data cleaning compared with without cleaning.", "labels": [], "entities": []}, {"text": " Table 4: Table includes our results on testset (the row 4 to 7).", "labels": [], "entities": []}]}