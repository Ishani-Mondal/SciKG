{"title": [{"text": "The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 95-104, Predicting Learner Levels for Online Exercises of Hebrew", "labels": [], "entities": []}], "abstractContent": [{"text": "We develop a system for predicting the level of language learners, using only a small amount of targeted language data.", "labels": [], "entities": []}, {"text": "In particular, we focus on learners of Hebrew and predict level based on restricted placement exam exercises.", "labels": [], "entities": []}, {"text": "As with many language teaching situations, a major problem is data sparsity, which we account for in our feature selection, learning algorithm , and in the setup.", "labels": [], "entities": []}, {"text": "Specifically, we define a two-phase classification process, isolating individual errors and linguistic constructions which are then aggregated into a second phase; such a two-step process allows for easy integration of other exercises and features in the future.", "labels": [], "entities": []}, {"text": "The aggregation of information also allows us to smooth over sparse features.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We use TiMBL (), a memory-based learner (MBL), for both phases.", "labels": [], "entities": []}, {"text": "We use TiMBL because MBL has been shown to work well with small data sets; allows for the use of both text-based and numeric features; and does not suffer from a fragmented class space.", "labels": [], "entities": []}, {"text": "We mostly use the default settings of TiMBL-the IB1 learning algorithm and overlap comparison metric between instances-and experiment with different values of k.", "labels": [], "entities": [{"text": "TiMBL-the IB1 learning", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.7058459321657816}]}, {"text": "For prediction of phenomenon level (phase 1) and learner level (phase 2), the system is trained on data from placement exams previously collected in a Hebrew language program, as described in sec.", "labels": [], "entities": []}, {"text": "2. With only 38 learners, we use leave-one-out testing, training on the data from the 37 other learners in order to run a model on each learner's sentences.", "labels": [], "entities": []}, {"text": "All of phase 1 is completed (i.e., automatically analyzed) before training the phase 2 models.", "labels": [], "entities": []}, {"text": "As a baseline, we use the majority class (level 150); choosing this for all learners gives an accuracy of 34.2% (13/38).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9994262456893921}]}, {"text": "Phase 1 probability distributions Because TiMBL retrieves all neighbor with the k nearest distances rather than the k nearest neighbors, we can use the number of neighbors in phase 1 to adjust the values of, e.g., 150-level classes.", "labels": [], "entities": []}, {"text": "For example, the output from phase 1 for two different vectors might be as in The Composite error feature combines all classes features into one score, inversely weighing them by level, so that more low-level errors give a high value.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Intra-token feature categories", "labels": [], "entities": []}, {"text": " Table 2: Inter-token feature categories", "labels": [], "entities": []}, {"text": " Table 3: Global feature categories", "labels": [], "entities": [{"text": "Global feature categories", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6663165291150411}]}, {"text": " Table 5: Phase 1 accuracies", "labels": [], "entities": [{"text": "accuracies", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9213392734527588}]}, {"text": " Table 6: Phase 2 accuracies for different phase 1 settings", "labels": [], "entities": [{"text": "accuracies", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9656772017478943}]}, {"text": " Table 7: Classification confusion matrices", "labels": [], "entities": [{"text": "Classification confusion", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.983614057302475}]}]}