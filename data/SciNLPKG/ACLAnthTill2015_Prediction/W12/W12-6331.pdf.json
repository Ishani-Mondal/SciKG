{"title": [{"text": "Parsing TCT with Split Conjunction Categories", "labels": [], "entities": [{"text": "Parsing TCT", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7744618654251099}]}], "abstractContent": [{"text": "We demonstrate that an unlexicalized PCFG with refined conjunction categories can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which breakdown false independence assumptions latent in a vanilla treebank grammar and reflect the Chinese idi-osyncratic grammatical property.", "labels": [], "entities": []}, {"text": "Indeed, its performance is the best result in the 3nd Chi-nese Parsing Evaluation of single model.", "labels": [], "entities": []}, {"text": "This result has showed that refine the function words to represent Chinese subcat frame is a good method.", "labels": [], "entities": []}, {"text": "An unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity , and easier to optimize.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, most research on parsing has focused on English and parsing on English has reported good performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.980377733707428}]}, {"text": "However, parsing accuracy on Chinese is generally significantly inferior.", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9639041423797607}, {"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9819221496582031}]}, {"text": "According to the first and second Chinese parsing evaluations and CIPS-SIGHAN-), the evaluation results in the Chinese clause and sentence levels show that the complex sentence parsing is still a big challenge for the Chinese language.", "labels": [], "entities": [{"text": "Chinese parsing", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.6487432569265366}, {"text": "complex sentence parsing", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.7954017917315165}]}, {"text": "Other work has also investigated aspects of automatic grammar refinement, for example, learn annotations such as head rules in a constrained declarative language for tree-adjoining grammars.", "labels": [], "entities": [{"text": "automatic grammar refinement", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.6612596611181895}]}, {"text": "Probabilistic context-free grammars (PCFGs) underlie most high-performance parsers in one way or another).", "labels": [], "entities": []}, {"text": "However, as demonstrated in and, a PCFG which simply takes the empirical rules and probabilities off of a treebank does not perform well.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the learning of a grammar consistent with a treebank at the level of evaluation symbols (such as NP, VP, etc.) addressed this question from a linguistic perspective, starting with a Markov grammar and manually splitting symbols in response to observed linguistic trends in the data.", "labels": [], "entities": []}, {"text": "For example, the symbol NP might be split into the subsymbol NP\u02c6S in subject position and the subsymbol NP\u02c6VP in object position.,, Petrov (2006) induce splits in a fully automatic fashion.", "labels": [], "entities": []}, {"text": "parses with a well-engineered grammar (as supplied for English).", "labels": [], "entities": []}, {"text": "It is fast, accurate, requires much less memory, and in many real-world uses, lexical preferences are unavailable or inaccurate across domains or genres and the unlexicalized parser will perform just as well as a lexicalized parser.", "labels": [], "entities": []}, {"text": "However, the factored parser will sometimes provide greater accuracy on English through knowledge of lexical dependencies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.998146653175354}]}, {"text": "Moreover, it is considerably better than the PCFG parser alone for most other languages (with less rigid word order), including German, Chinese, and Arabic.", "labels": [], "entities": []}, {"text": "Automatically split-merge approach is 4% higher than manual unlexicalized parsing in English.", "labels": [], "entities": []}, {"text": "However, this may not be the casein Chinese due to the idiosyncratic property and spe-cialized annotation style in Chinese Penn Treebank.", "labels": [], "entities": [{"text": "Chinese Penn Treebank", "start_pos": 115, "end_pos": 136, "type": "DATASET", "confidence": 0.7326856056849161}]}, {"text": "With carefully engineered split from linguistic perspective and automatically split approach, we achieve a relatively accuracy interpretable parser.", "labels": [], "entities": []}, {"text": "Incorporating language-dependent idiosyncratic property improved performance on many languages.", "labels": [], "entities": []}, {"text": "As for Chinese parsing, there is still along way to go.", "labels": [], "entities": [{"text": "Chinese parsing", "start_pos": 7, "end_pos": 22, "type": "TASK", "confidence": 0.7356106042861938}]}, {"text": "High-performance parsers on English have employed linguistically-motivated features.", "labels": [], "entities": []}, {"text": "(Collins 1998) and) make use of lexicalized nonterminals, which allows lexical items' idiosyncratic parsing preferences to be modeled, but the preferences between head words and modifiers are language-dependent.", "labels": [], "entities": []}, {"text": "Furthermore, model in) include distance measure, subcat frame features and wh-movement, which are all tightly interrelated to particular language.", "labels": [], "entities": []}, {"text": "(Charniak 1997) uses a scheme of clustering the head words like that in.", "labels": [], "entities": []}, {"text": "There have been some attempts to adapt parsers developed for English to Chinese.", "labels": [], "entities": []}, {"text": "Adapting lexicalized parsers to other languages is not a trivial task as it requires at least the specification of head rules, and has had limited success.", "labels": [], "entities": [{"text": "Adapting lexicalized parsers", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9341981808344523}]}, {"text": "() has transplanted lexicalized parsing to Chinese and the results on English and Chinese are far from equal.", "labels": [], "entities": []}, {"text": "Adapting unlexicalized parsers appears to be equally difficult: () adapt the unlexicalized parser of ( exhibited a very accurate category split-andmerge approach without any language dependent modifications.", "labels": [], "entities": [{"text": "Adapting unlexicalized parsers", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8910889228185018}]}, {"text": "This automatically inducing latent structure generalizes well across language boundaries and results instate of the art performance for Chinese.", "labels": [], "entities": []}, {"text": "All above are probabilistic methods on the utility of PCFGs, but the same situation is in other grammar systems.", "labels": [], "entities": []}, {"text": "SPATTER parser based on decision-tree learning techniques in Magerman (1995) highly involves special characters of words.", "labels": [], "entities": [{"text": "SPATTER parser", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7198755443096161}]}, {"text": "30 binary questions represent 30 different binary partitions of the word vocabulary, and these questions are defined such that it is possible to identify each word by asking all 30 questions.", "labels": [], "entities": []}, {"text": "adapts stochastic TAG model on English) to Chinese and report Label Precision below 75%.", "labels": [], "entities": [{"text": "Label Precision", "start_pos": 62, "end_pos": 77, "type": "METRIC", "confidence": 0.6509605646133423}]}], "datasetContent": [{"text": "We ran experiments on TCT.", "labels": [], "entities": []}, {"text": "The training and test data set splits are described in For our model, input trees were annotated or transformed to refine the conjunction word categories.", "labels": [], "entities": []}, {"text": "Given a set of transformed trees, we viewed the local trees as grammar rewrite rules in the standard way, and used smoothed maximum-likelihood estimates for rule probabilities.", "labels": [], "entities": []}, {"text": "To parse the grammar, we used an arraybased Java implementation of a generalized CKY scheme and automatically split and merge approach in Petrov (2006).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Experiment Results of SC and ULC", "labels": [], "entities": [{"text": "ULC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.3933435380458832}]}, {"text": " Table 2. Experiment Results of SC and ULC", "labels": [], "entities": [{"text": "ULC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.3933435380458832}]}, {"text": " Table 2. Experiment Results of SC and ULC", "labels": [], "entities": [{"text": "ULC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.3933435380458832}]}]}