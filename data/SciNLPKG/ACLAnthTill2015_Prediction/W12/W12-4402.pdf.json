{"title": [{"text": "Report of NEWS 2012 Machine Transliteration Shared Task", "labels": [], "entities": [{"text": "NEWS 2012 Machine Transliteration Shared Task", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.7718819280465444}]}], "abstractContent": [{"text": "This report documents the Machine Transliteration Shared Task conducted as apart of the Named Entities Workshop (NEWS 2012), an ACL 2012 workshop.", "labels": [], "entities": [{"text": "Machine Transliteration Shared Task", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.8836378008127213}, {"text": "NEWS 2012)", "start_pos": 113, "end_pos": 123, "type": "DATASET", "confidence": 0.7465641299883524}]}, {"text": "The shared task features machine translit-eration of proper names from English to 11 languages and from 3 languages to English.", "labels": [], "entities": []}, {"text": "In total, 14 tasks are provided.", "labels": [], "entities": []}, {"text": "7 teams participated in the evaluations.", "labels": [], "entities": []}, {"text": "Finally, 57 standard and 1 non-standard runs are submitted, where diverse translit-eration methodologies are explored and reported on the evaluation data.", "labels": [], "entities": []}, {"text": "We report the results with 4 performance metrics.", "labels": [], "entities": []}, {"text": "We believe that the shared task has successfully achieved its objective by providing a common benchmarking platform for the research community to evaluate the state-of-the-art technologies that benefit the future research and development.", "labels": [], "entities": []}], "introductionContent": [{"text": "Names play a significant role in many Natural Language Processing (NLP) and Information Retrieval (IR) systems.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.8112572431564331}]}, {"text": "They are important in Cross Lingual Information Retrieval (CLIR) and Machine Translation (MT) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies).", "labels": [], "entities": [{"text": "Cross Lingual Information Retrieval (CLIR)", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.7206013117517743}, {"text": "Machine Translation (MT)", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.8465173721313477}]}, {"text": "The traditional source for name equivalence, the bilingual dictionaries -whether handcrafted or statistical -offer only limited support because new names always emerge.", "labels": [], "entities": [{"text": "name equivalence", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7461424171924591}]}, {"text": "All of the above point to the critical need for robust Machine Transliteration technology and systems.", "labels": [], "entities": []}, {"text": "Much research effort has been made to address the transliteration issue in the research community (;).", "labels": [], "entities": []}, {"text": "These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods.", "labels": [], "entities": []}, {"text": "Graphemebased method () treats transliteration as a direct orthographic mapping and only uses orthography-related features while phonemebased method) makes use of phonetic correspondence to generate the transliteration.", "labels": [], "entities": []}, {"text": "Hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 104, "end_pos": 130, "type": "TASK", "confidence": 0.8554128706455231}]}, {"text": "The first machine transliteration shared task () was held in NEWS 2009 at ACL-IJCNLP 2009.", "labels": [], "entities": [{"text": "machine transliteration shared task", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7429331094026566}, {"text": "NEWS 2009 at ACL-IJCNLP 2009", "start_pos": 61, "end_pos": 89, "type": "DATASET", "confidence": 0.8572288155555725}]}, {"text": "It was the first time to provide common benchmarking data in diverse language pairs for evaluation of state-of-the-art techniques.", "labels": [], "entities": []}, {"text": "While the focus of the 2009 shared task was on establishing the quality metrics and on baselining the transliteration quality based on those metrics, the 2010 shared task () expanded the scope of the transliteration generation task to about a dozen languages, and explored the quality depending on the direction of transliteration, between the languages.", "labels": [], "entities": [{"text": "transliteration generation task", "start_pos": 200, "end_pos": 231, "type": "TASK", "confidence": 0.8476933638254801}]}, {"text": "In NEWS 2011 (), we significantly increased the hand-crafted parallel named entities corpora to include 14 different language pairs from 11 language families, and made them available as the common dataset for the shared task.", "labels": [], "entities": [{"text": "NEWS 2011", "start_pos": 3, "end_pos": 12, "type": "DATASET", "confidence": 0.9512798488140106}]}, {"text": "NEWS 2012 was a continued effort of NEWS 2011, NEWS 10 2010 and NEWS 2009.", "labels": [], "entities": [{"text": "NEWS 2012", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9306354522705078}, {"text": "NEWS", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.8812353610992432}, {"text": "NEWS 10 2010", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.8831721544265747}, {"text": "NEWS 2009", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.9033960103988647}]}, {"text": "The rest of the report is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines the machine transliteration task and the corpora used and Section 3 discusses the metrics chosen for evaluation, along with the rationale for choosing them.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present the participation in the shared task and the results with their analysis, respectively.", "labels": [], "entities": []}, {"text": "Section 6 concludes the report.", "labels": [], "entities": []}], "datasetContent": [{"text": "The participants have been asked to submit results of up to four standard and four non-standard runs.", "labels": [], "entities": []}, {"text": "One standard run must be named as the primary submission and is used for the performance summary.", "labels": [], "entities": []}, {"text": "Each run contains a ranked list of up to 10 candidate transliterations for each source name.", "labels": [], "entities": []}, {"text": "The submitted results are compared to the ground truth (reference transliterations) using 4 evaluation metrics capturing different aspects of transliteration performance.", "labels": [], "entities": []}, {"text": "The same as the NEWS 2011, we have dropped two M AP metrics used in NEWS 2009 because they don't offer additional information to M AP ref . Since a name may have multiple correct transliterations, all these alternatives are treated equally in the evaluation, that is, any of these alternatives is considered as a correct transliteration, and all candidates matching any of the reference transliterations are accepted as correct ones.", "labels": [], "entities": [{"text": "NEWS 2011", "start_pos": 16, "end_pos": 25, "type": "DATASET", "confidence": 0.9664647877216339}, {"text": "NEWS 2009", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.9503949284553528}]}, {"text": "The following notation is further assumed: N : Total number of names (source words) in the test set n i : Number of reference transliterations for i-th name in the test set (n i \u2265 1) r i,j : j-th reference transliteration for i-th name in the test set c i,k : k-th candidate transliteration (system output) for i-th name in the test set (1 \u2264 k \u2264 10) K i : Number of candidate transliterations produced by a transliteration system", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Source and target languages for the shared task on transliteration.", "labels": [], "entities": []}, {"text": " Table 2: Number of runs submitted for each task. Number of participants coincides with the number of  standard runs submitted.", "labels": [], "entities": []}, {"text": " Table 4: Runs submitted for English to Chinese task.", "labels": [], "entities": []}, {"text": " Table 5: Runs submitted for Chinese to English back-transliteration task.", "labels": [], "entities": []}, {"text": " Table 6: Runs submitted for English to Thai task.", "labels": [], "entities": []}, {"text": " Table 7: Runs submitted for Thai to English back-transliteration task.  18", "labels": [], "entities": [{"text": "Thai to English back-transliteration task", "start_pos": 29, "end_pos": 70, "type": "TASK", "confidence": 0.6566235423088074}]}, {"text": " Table 10: Runs submitted for English to Kannada task.", "labels": [], "entities": []}, {"text": " Table 11: Runs submitted for English to Japanese Katakana task.", "labels": [], "entities": [{"text": "Japanese Katakana task", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.6989739040533701}]}, {"text": " Table 12: Runs submitted for English to Korean task.", "labels": [], "entities": [{"text": "English to Korean task", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.5033109933137894}]}, {"text": " Table 13: Runs submitted for English to Japanese Kanji back-transliteration task.  19", "labels": [], "entities": []}, {"text": " Table 14: Runs submitted for Arabic to English task.", "labels": [], "entities": []}, {"text": " Table 15: Runs submitted for English to Bengali (Bangla) task.", "labels": [], "entities": [{"text": "English to Bengali (Bangla) task", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.4484990153993879}]}, {"text": " Table 16: Runs submitted for English to Persian task.", "labels": [], "entities": [{"text": "English to Persian task", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.4810308814048767}]}, {"text": " Table 17: Runs submitted for English to Hebrew task.", "labels": [], "entities": []}]}