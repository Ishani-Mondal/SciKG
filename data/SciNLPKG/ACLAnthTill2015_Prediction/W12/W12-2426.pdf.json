{"title": [{"text": "Using Natural Language Processing to Identify Pharmacokinetic Drug- Drug Interactions Described in Drug Package Inserts", "labels": [], "entities": [{"text": "Identify Pharmacokinetic Drug- Drug Interactions Described in Drug Package Inserts", "start_pos": 37, "end_pos": 119, "type": "TASK", "confidence": 0.8817118839784102}]}], "abstractContent": [{"text": "The package insert (aka drug product label) is the only publicly-available source of information on drug-drug interactions (DDIs) for some drugs, especially newer ones.", "labels": [], "entities": []}, {"text": "Thus, an automated method for identifying DDIs in drug package inserts would be a potentially important complement to methods for identifying DDIs from other sources such as the scientific literature.", "labels": [], "entities": []}, {"text": "To develop such an algorithm , we created a corpus of Federal Drug Administration approved drug package insert statements that have been manually annotated for pharmacokinetic DDIs by a pharmacist and a drug information expert.", "labels": [], "entities": []}, {"text": "We then evaluated three different machine learning algorithms for their ability to 1) identify pharmacokinetic DDIs in the package insert corpus and 2) classify pharmacokinetic DDI statements by their modality (i.e., whether they report a DDI or no interaction between drug pairs).", "labels": [], "entities": []}, {"text": "Experiments found that a support vector machine algorithm performed best on both tasks with an F-measure of 0.859 for pharmacokinetic DDI identification and 0.949 for modality assignment.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9989575147628784}, {"text": "DDI identification", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.702093631029129}]}, {"text": "We also found that the use of syntactic information is very helpful for addressing the problem of sentences containing both interacting and non-interacting pairs of drugs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Package inserts (PIs, aka drug product label) are the primary source of information for newly approved drugs and a potentially authoritative source of drug information from a medical-legal standpoint.", "labels": [], "entities": [{"text": "Package inserts (PIs, aka drug product label)", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7051092594861984}]}, {"text": "Among the information provided by PIs are drug-drug interactions (DDIs): known and predicted drug combinations that could lead to a clinically meaningful alteration in the effect of one of the drugs.", "labels": [], "entities": []}, {"text": "The United States Federal Drug Administration (FDA) mandates that PIs for FDA-approved drugs include both observed and predicted clinically significant DDIs, as well as the results of pharmacokinetic studies that establish the absence of effect.", "labels": [], "entities": []}, {"text": "Moreover, the PI is the only publicallyavailable source of information on DDIs for some drugs, especially newer ones ().", "labels": [], "entities": [{"text": "PI", "start_pos": 14, "end_pos": 16, "type": "DATASET", "confidence": 0.8052213788032532}]}, {"text": "Hence, an automated method for identifying DDIs from drug PIs would bean important complement to methods for identifying DDIs from other sources such as the scientific literature.", "labels": [], "entities": [{"text": "identifying DDIs from drug PIs", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7314713001251221}]}, {"text": "In this paper we describe the creation of anew corpus of FDA-approved drug package insert statements that have been manually annotated for pharmacokinetic DDIs.", "labels": [], "entities": []}, {"text": "We then discuss how three different machine learning algorithms were evaluated for their ability to 1) identify pharmacokinetic DDIs in drug package inserts and 2) classify pharmacokinetic DDI statements by their modality (i.e., whether they report a DDI or that a drug pair does not interact).", "labels": [], "entities": []}], "datasetContent": [{"text": "Once the set of DDI annotations was compiled, we devised two machine learning tasks.", "labels": [], "entities": []}, {"text": "The first task was to determine whether two drugs mentioned in a statement taken from a PI are noted as either interacting or not interacting with each other by pharmacokinetic mechanisms (i.e., does the statement report a PK DDI with the drug pair of either a positive or negative modality?).", "labels": [], "entities": []}, {"text": "The second task was to determine the modality of a given PK DDI.", "labels": [], "entities": [{"text": "PK DDI", "start_pos": 57, "end_pos": 63, "type": "TASK", "confidence": 0.553207278251648}]}, {"text": "The first task did not include determining the roles of the drugs if an interaction is found, i.e., which member of the pair of drug mentions is the precipitant and which one is the object.", "labels": [], "entities": []}, {"text": "To enable the exploration of the performance of multiple machine learning methods, we divided two-thirds of the annotated PI statements into a development set and one-third into a blind test set.", "labels": [], "entities": []}, {"text": "PI statements annotated as reporting DDIs were stratified within the two sets using a random selection method that ensured a representative balance of sentence distance between drug mentions, DDI modality, DDI type, and drug PI age designation (see above).", "labels": [], "entities": []}, {"text": "Statements not containing an interaction were stratified by sentence distance between drug mentions, and PI age designation.", "labels": [], "entities": [{"text": "PI age designation", "start_pos": 105, "end_pos": 123, "type": "METRIC", "confidence": 0.7876675923665365}]}, {"text": "Stratification was done on the level of statements.", "labels": [], "entities": []}, {"text": "Thus, statements taken from the same package insert may have been distributed over the development and test set.", "labels": [], "entities": []}, {"text": "We observed that 99% of corpus statements annotated as a PK DDI mentioned an interacting drug pair within a three sentence region.", "labels": [], "entities": []}, {"text": "Thus, we created a baseline dataset by iterating through PI statements in the development set and identifying all drug pair mentions that occurred within a threesentence span.", "labels": [], "entities": []}, {"text": "Throughout the remainder of this paper we refer to the statements identified by this process as instances.", "labels": [], "entities": []}, {"text": "Instances containing drug pairs that were manually annotated as participating in an interaction (either with positive or negative modality) were labeled as positive instances for the extraction task; all other pairs were labeled as negative instances.", "labels": [], "entities": []}, {"text": "Prior to generating features for machine learning, each instance was pre-processed.", "labels": [], "entities": []}, {"text": "Numbers (e.g. \"1\", \"34\", \"5.2\", etc.) were replaced by the string \"num\" to make them more meaningful to a learning algorithm across instances.", "labels": [], "entities": []}, {"text": "This allowed the algorithm to associate numerical references with each other using a general pattern, instead of learning phrases with specific numbers (e.g. the phrase \"num mg\" maybe significant, whereas \"10 mg\" maybe less significant).", "labels": [], "entities": []}, {"text": "Similarly, to abstract away from specific names, the names of drug products, active ingredients, and metabolites in each statement were replaced by the string \"drugname\".", "labels": [], "entities": []}, {"text": "This forces the learning algorithm to generalize over the participants of interactions, preventing it from identifying interactions based on the identity of the participants.", "labels": [], "entities": []}, {"text": "In the baseline dataset, each instance's preprocessed sentence text was translated to bigrams using TagHelper, a text analysis program written on top of the Weka machine learning software ().", "labels": [], "entities": [{"text": "Weka machine learning software", "start_pos": 157, "end_pos": 187, "type": "DATASET", "confidence": 0.8783692866563797}]}, {"text": "Bigrams area comprehensive set of consecutive word pairs that appear in a sentence.", "labels": [], "entities": []}, {"text": "Words in bigrams were stemmed by TagHelper to facilitate learning more general concepts conveyed by phrases.", "labels": [], "entities": []}, {"text": "For example, the commonly occurring phrases \"increases auc\" and \"increased auc\" are stemmed to \"increase auc\" and then merged to the bigram.", "labels": [], "entities": []}, {"text": "The baseline set of instances was loaded into Weka and three models were built using three different machine learning algorithms.", "labels": [], "entities": [{"text": "Weka", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.9787881374359131}]}, {"text": "The three algorithms were a rule learner (\"JRip\"), a decision tree (\"J48\"), and an SVM algorithm (\"SMO\").", "labels": [], "entities": []}, {"text": "Algorithm parameters were left at Weka defaults and 10-fold crossvalidation was used to develop each model.", "labels": [], "entities": [{"text": "Weka", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.9486980438232422}]}, {"text": "Exploration of Weka predictions from the baseline dataset showed that a major source of confusion for the machine learning algorithms was an inability to distinguish between pairs of drugs that do and do not interact within the same sentence.", "labels": [], "entities": []}, {"text": "A frequent source of this kind of occurrence in the package insert text was coordinate structures such as \"Drug A interacts with Drugs B and C\", where \"B and C\" is a coordinate structure.", "labels": [], "entities": []}, {"text": "For such sentences, the baseline dataset contains the interacting pairs (A,B) and (A,C), along with the noninteracting pair (B,C).", "labels": [], "entities": []}, {"text": "However, because all three pairs are represented by the same set of bigrams, it is obvious that information from bigrams alone is insufficient to distinguish which pairs interact and which simply co-occur within the sentence.", "labels": [], "entities": []}, {"text": "Another problem was that of multiple mentions of the same drug within an instance's sentence span, as, for example, in the sentence \"Coadministration of A and B leads to increased AUC levels for B.\"", "labels": [], "entities": [{"text": "AUC levels", "start_pos": 180, "end_pos": 190, "type": "METRIC", "confidence": 0.9812256097793579}]}, {"text": "Because the annotators had identified only one drug mention per annotated interaction, the algorithms incorrectly considered other mentions of the same drug as part of a non-interacting pair.", "labels": [], "entities": []}, {"text": "Two solutions were implemented to help alleviate these problems.", "labels": [], "entities": []}, {"text": "First, the dataset was condensed to a set of instances with unique drug pairs and sentence spans.", "labels": [], "entities": []}, {"text": "If any of the baseline instances contributing to the condensed instance contained interactions, the condensed instance was said to contain an interaction.", "labels": [], "entities": []}, {"text": "In this way, multiple drug mentions within a sentence span containing an interaction would translate to a single instance representing an interaction between the two drugs.", "labels": [], "entities": []}, {"text": "Second, two natural language dependency parsers were used to extract extra features from the sentence text for each instance: the Stanford NLP Parser and ClearParser (Choi 2011).", "labels": [], "entities": [{"text": "Stanford NLP Parser", "start_pos": 130, "end_pos": 149, "type": "DATASET", "confidence": 0.883578340212504}]}, {"text": "Following approaches to relation extraction proposed in other domains e.g.,, the dependency structure produced by each parser was searched for the shortest path between the pair of drug mentions of the instance.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.8537284731864929}]}, {"text": "The words on this path were stemmed using the Stanford NLP Tools stemmer, and added to the dataset as the instance's \"syntactic path\".", "labels": [], "entities": [{"text": "Stanford NLP Tools stemmer", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.8949771374464035}]}, {"text": "Once a statement is classified as describing a PK DDI between two drugs, it is important to know if there is an observed effect or alack of effect between two coadministered drugs (i.e., positive vs negative modality statements).", "labels": [], "entities": [{"text": "PK DDI", "start_pos": 47, "end_pos": 53, "type": "TASK", "confidence": 0.7062563002109528}]}, {"text": "To present the learning algorithms with the most relevant training data, modality prediction was treated as a separate task from interaction prediction.", "labels": [], "entities": [{"text": "modality prediction", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7215847373008728}, {"text": "interaction prediction", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.7201592177152634}]}, {"text": "Development and test sets were created in the same manner as for interaction prediction, however instances that did not represent interactions were excluded.", "labels": [], "entities": [{"text": "interaction prediction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7649448215961456}]}, {"text": "Only bigram features were used for modality prediction.", "labels": [], "entities": [{"text": "modality prediction", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7614623308181763}]}, {"text": "Model training and testing proceeded in the same manner as for interaction prediction.", "labels": [], "entities": [{"text": "interaction prediction", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8012427687644958}]}], "tableCaptions": [{"text": " Table 1. PK DDI statement modality shown by in- teraction type.", "labels": [], "entities": [{"text": "PK DDI statement modality", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.5499090701341629}]}, {"text": " Table 2. A summary of consensus annotated PK DDIs by precipitant and object type.", "labels": [], "entities": [{"text": "PK DDIs", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.54402294754982}]}, {"text": " Table 3. Results for interaction prediction on the baseline, development, and blind test set. Also shown are re- sults for modality prediction for the blind test set (results over the development set are similar but not shown).", "labels": [], "entities": [{"text": "interaction prediction", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.7401072978973389}]}]}