{"title": [], "abstractContent": [{"text": "In the early 1990's, online communication was restricted to ASCII (English) only environments.", "labels": [], "entities": []}, {"text": "A convention evolved for typing Arabic in Roman characters, this scripting took various names including: Franco Arabic, Romanized Arabic, Arabizi, Arabish, etc\u2026 The convention was widely adopted and today, romanized Arabic (RAr) is everywhere: In instant messaging, forums, blog postings, product and movie ads, on mobile phones and on TV!", "labels": [], "entities": []}, {"text": "The problem is that the majority of Arab users are more used to the English keyboard layout, and while romanized Arabic is easier to type, Arabic is significantly easier to read, the obvious solution was automatic conversion of romanized Arabic to Arabic script, which would also lead to increasing the amount and quality of authored Arabic online content.", "labels": [], "entities": []}, {"text": "The main challenges are that no standard convention of Romanized Arabic (many \uf0e0 1 mappings) is available and there are no parallel data available.", "labels": [], "entities": []}, {"text": "We present here a hybrid approach that we devised and implemented to build a romanized Arabic transliteration engine that was later on scaled to cover other scripts.", "labels": [], "entities": []}, {"text": "Our approach leverages the work done by Sherif and Kondrak's (2007b) and Cherry and Suzuki (2009), and is heavily inspired by the basic phrase-based statistical machine translation approach devised by (Och, 2003).", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 136, "end_pos": 180, "type": "TASK", "confidence": 0.5543213114142418}]}], "introductionContent": [{"text": "Transliteration automates the conversion from a source text into the corresponding target text, where usually both source and target texts are written suing different scripts.", "labels": [], "entities": []}, {"text": "Both texts might belong to the same language as in the case of \"Roman-script Arabic\" to \"Arabic-script Arabic\" or to two different languages as in the case where the source text is English written in Roman script and the target one is Arabic written in Arabic script.", "labels": [], "entities": []}, {"text": "Our initial implementation was targeting the transliteration of colloquial Arabic, written in roman script, into colloquial Arabic written in Arabic script.", "labels": [], "entities": []}, {"text": "Later on the same engine has been used to transliterate English text written in roman characters into Arabic written in Arabic script and visa-versa, then it was scaled to cover other scripts such as Farsi, Hebrew, Urdu and many others.", "labels": [], "entities": []}, {"text": "The engine was integrated into a multitude of applications, the first one being a TSF (Text Service Framework) component.", "labels": [], "entities": []}, {"text": "TSF provides a simple and scalable framework for the delivery of advanced text input and natural language technologies.", "labels": [], "entities": [{"text": "TSF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8109564185142517}]}, {"text": "It can be enabled in applications, or as a text service.", "labels": [], "entities": []}, {"text": "TSF services provide multilingual support and deliver text services such as keyboard processors, handwriting recognition, and speech recognition.", "labels": [], "entities": [{"text": "handwriting recognition", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.8949790298938751}, {"text": "speech recognition", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.8163453042507172}]}, {"text": "In this design, TSF was used to provide a candidate list for what the user types-in across Windows applications, and the service is easily discoverable through the language bar.", "labels": [], "entities": []}, {"text": "The user will be able to get the transliteration functionality in any TSF-Aware control (e.g. RichEdit).", "labels": [], "entities": []}, {"text": "The second target application is Machine Translation, where transliteration will be called to address out-of-vocabulary words, mostly named entities.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.9081827700138092}]}, {"text": "Having the above target applications in mind, the design should be devised in away to account for all relevant requirements and expectations in terms of scalability, accuracy, functionality, robustness and performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9989238381385803}]}, {"text": "The first section of this paper presents the architecture that we devised to implement our transliteration engine initially targeting romanized Arabic conversion.", "labels": [], "entities": [{"text": "romanized Arabic conversion", "start_pos": 134, "end_pos": 161, "type": "TASK", "confidence": 0.6828124821186066}]}, {"text": "In the second section, we present an innovative technique for extracting training data out of parallel sentences, for training a \"named entity\" transliterator.", "labels": [], "entities": []}, {"text": "In the third section we present our scoring mechanism, and in section 4, we present our evaluation and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have adopted two evaluation metrics, namely the mean reciprocal rank (MRR) and Topmost candidate, both techniques are on the word-level: Mean reciprocal rank is a measure for evaluating any process that produces a list of possible responses to an input, ordered by probability of correctness.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 51, "end_pos": 77, "type": "METRIC", "confidence": 0.9072169959545135}, {"text": "Topmost candidate", "start_pos": 82, "end_pos": 99, "type": "METRIC", "confidence": 0.9242927134037018}]}, {"text": "The reciprocal rank of a given input is the multiplicative inverse of the rank of the first correct answer.", "labels": [], "entities": []}, {"text": "The mean reciprocal rank is the average of the reciprocal ranks of results fora sample of input strings.", "labels": [], "entities": []}, {"text": "In the Topmost technique, only the first (topmost) candidate, i.e the one with the highest probability of correctness is considered during evaluation.", "labels": [], "entities": []}, {"text": "The evaluation is done on the wordlevel, by comparing the generated candidate with the reference.", "labels": [], "entities": []}, {"text": "\uf0b7 To account for applications where no further selection could be allowed, the Top candidates only were evaluated against the gold standard.", "labels": [], "entities": []}, {"text": "\uf0b7 And for other applications where further selection was allowed, we evaluate the MRR for the n-best candidates, in our case, we considered the 5-best candidates: o Linear scoring: assign (1-i)/n for the i th candidate in an n-best scheme o MRR : assign 1/(i+1) for the i th candidate in an n-best scheme above shows the results of the hybrid system for the different metrics using a test set of 5K words.", "labels": [], "entities": [{"text": "MRR", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.8986049890518188}]}, {"text": "We were able to achieve 90% accuracy on the MRR metric considering the 5-best candidates, and 85% considering only the top candidate only.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9996168613433838}, {"text": "MRR", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.5647621750831604}]}], "tableCaptions": []}