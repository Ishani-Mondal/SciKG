{"title": [{"text": "A finite-state approach to phrase-based statistical machine translation", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a finite-state approach to phrase-based statistical machine translation where a log-linear modelling framework is implemented by means of an on-the-fly composition of weighted finite-state transducers.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 47, "end_pos": 91, "type": "TASK", "confidence": 0.6166606992483139}]}, {"text": "Moses, a well-known state-of-the-art system, is used as a machine translation reference in order to validate our results by comparison.", "labels": [], "entities": [{"text": "machine translation reference", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.7596344451109568}]}, {"text": "Experiments on the TED corpus achieve a similar performance to that yielded by Moses.", "labels": [], "entities": [{"text": "TED corpus", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.8269204497337341}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) is a pattern recognition approach to machine translation which was defined by as follows: given a sentence s from a certain source language, a corresponding sentenc\u00ea tin a given target language that maximises the posterior probability Pr(t|s) is to be found.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8271949787934622}, {"text": "pattern recognition", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.746899425983429}, {"text": "machine translation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7710016667842865}, {"text": "posterior probability Pr", "start_pos": 251, "end_pos": 275, "type": "METRIC", "confidence": 0.8359233339627584}]}, {"text": "State-of-the-art SMT systems model the translation distribution Pr(t|s) via the log-linear approach ): where h m (s, t) is a logarithmic function representing an important feature for the translation of s into t, M is the number of features (or models), and \u03bb m is the weight of h min the log-linear combination.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9931269884109497}]}, {"text": "This feature set typically includes several translation models so that different relations between a source and a target sentence can be considered.", "labels": [], "entities": []}, {"text": "Nowadays, these models are strongly based on phrases, i.e. variable-length n-grams, which means that they are built from some other lower-context models that, in this case, are defined at phrase level.", "labels": [], "entities": []}, {"text": "Phrase-based (PB) models) constitute the core of the current state-of-the-art in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9943130016326904}]}, {"text": "The basic idea of PB-SMT systems is: 1.", "labels": [], "entities": []}, {"text": "to segment the source sentence into phrases, then 2.", "labels": [], "entities": []}, {"text": "to translate each source phrase into a target phrase, and finally 3.", "labels": [], "entities": []}, {"text": "to reorder them in order to compose the final translation in the target language.", "labels": [], "entities": []}, {"text": "Ina monotone translation framework however, the third step is omitted as the final translation is just generated by concatenation of the target phrases.", "labels": [], "entities": []}, {"text": "Apart from translation functions, the log-linear approach is also usually composed by means of a target language model and some other additional elements such as word penalties or phrase penalties.", "labels": [], "entities": []}, {"text": "The word and phrase penalties allow an SMT system to limit the number of words or target phrases, respectively, that constitute a translation hypothesis.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9951872825622559}]}, {"text": "In this paper, a finite-state approach to a PB-SMT state-of-the-art system, Moses (, is presented.", "labels": [], "entities": []}, {"text": "Experimental results validate our work because they are similar to those yielded by Moses.", "labels": [], "entities": []}, {"text": "A related study can be found in for the alignment template model ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were carried out on the TED corpus, which is described in depth throughout Section 5.1.", "labels": [], "entities": [{"text": "TED corpus", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.8253069818019867}]}, {"text": "Automatic evaluation for SMT is often considered and we use the measures enumerated in Section 5.2.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9969124794006348}]}, {"text": "Results are shown and also discussed, in Section 5.3.", "labels": [], "entities": []}, {"text": "Since its appearance as a translation quality measure, the BLEU metric (), which stands for bilingual evaluation understudy, has become consolidated in the area of automatic evaluation as the most widely used SMT measure.", "labels": [], "entities": [{"text": "BLEU metric", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9836103916168213}, {"text": "SMT", "start_pos": 209, "end_pos": 212, "type": "TASK", "confidence": 0.9952331185340881}]}, {"text": "Nevertheless, it was later found that its correlation factor with subjective evaluations (the original reason for its success) is actually not so high as first thought).", "labels": [], "entities": []}, {"text": "Anyway, it is still the most popular SMT measure in the literature.", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.992412269115448}]}, {"text": "However, the word error rate (WER) is a very common measure in the area of speech recognition which is also quite usually applied in SMT ().", "labels": [], "entities": [{"text": "word error rate (WER)", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.8422279755274454}, {"text": "speech recognition", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.7270278930664062}, {"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.9930980801582336}]}, {"text": "Although it is not so widely employed as BLEU, there exists some work that shows a better correlation of WER with human assessments (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9959074258804321}, {"text": "WER", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.6732632517814636}]}, {"text": "Of course, the WER measure has some bad reviews as well and one of the main criticisms that it receives in SMT areas is about the fact that there is only one translation reference to compare with.", "labels": [], "entities": [{"text": "WER", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.7167385220527649}, {"text": "SMT", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.9862995743751526}]}, {"text": "The MWER measure () is an attempt to relax this dependence by means of an average error rate with respect to a set of multiple references of equivalent meaning, provided that they are available.", "labels": [], "entities": [{"text": "MWER measure", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.6799254715442657}]}, {"text": "Another measure also based on the edit distance concept has recently arisen as an evolution of WER towards SMT.", "labels": [], "entities": [{"text": "WER", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.9032837152481079}, {"text": "SMT", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.9858607053756714}]}, {"text": "It is the translation edit rate (TER), and it has become popular because it takes into account the basic post-process operations that professional translators usually do during their daily work.", "labels": [], "entities": [{"text": "translation edit rate (TER)", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.8859187563260397}]}, {"text": "Statistically, it is considered as a measure highly correlated with the result of one or more subjective evaluations ().", "labels": [], "entities": []}, {"text": "The definition of these evaluation measures is as follows: BLEU: It computes the precision of the unigrams, bigrams, trigrams, and fourgrams that appear in the hypotheses with respect to the n-grams of the same order that occur in the translation reference, with a penalty for too short sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.999244213104248}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9984394907951355}]}, {"text": "Unlike the WER measure, BLEU is not an error rate but an accuracy measure.", "labels": [], "entities": [{"text": "WER measure", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.8981687128543854}, {"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9984800219535828}, {"text": "error rate", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9182006120681763}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9990109205245972}]}, {"text": "WER: This measure computes the minimum number of editions (replacements, insertions or deletions) that are needed to turn the system hypothesis into the corresponding reference.", "labels": [], "entities": [{"text": "WER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9702867269515991}]}, {"text": "TER: It is computed similarly to WER, using an additional edit operation.", "labels": [], "entities": [{"text": "TER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9827234745025635}, {"text": "WER", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.6561092734336853}]}, {"text": "TER allows the movement of phrases, besides replacements, insertions, and deletions.", "labels": [], "entities": [{"text": "TER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7019597887992859}]}], "tableCaptions": [{"text": " Table 1: A Spanish-into-English PB translation table.  Each source-target phrase pair is scored by all \u03b7 models.", "labels": [], "entities": [{"text": "PB translation", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7069850265979767}]}, {"text": " Table 2: An English word-based backoff n-gram model.  The likelihood and the backoff model score for each n- gram.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9809811115264893}]}, {"text": " Table 5: English-to-French results for development and  test data according to different log-linear scenarios.", "labels": [], "entities": []}, {"text": " Table 6: French-to-English results for development  and test data according to different log-linear scenarios.", "labels": [], "entities": []}]}