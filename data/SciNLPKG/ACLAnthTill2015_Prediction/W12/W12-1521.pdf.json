{"title": [{"text": "Natural Language Generation fora Smart Biology Textbook NP is detach from NP resulting in NP at NP NP detach from NP resulting in NP at NP Detachment of NP from NP resulting in NP at NP", "labels": [], "entities": [{"text": "Smart Biology Textbook", "start_pos": 33, "end_pos": 55, "type": "DATASET", "confidence": 0.6462962925434113}]}], "abstractContent": [{"text": "In this demo paper we describe the natural language generation component of an electronic textbook application, called Inquire 1.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.6634602049986521}]}, {"text": "Inquire interacts with a knowledge base which encodes information from a biology textbook.", "labels": [], "entities": []}, {"text": "The application includes a question-understanding module which allows students to ask questions about the contents of the book, and a question-answering module which retrieves the corresponding answer from the knowledge base.", "labels": [], "entities": []}, {"text": "The task of the natural language generation module is to present specific parts of the answer in English.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6636017461617788}]}, {"text": "Our current generation pipeline handles inputs that describe the biological functions of entities, the steps of biological processes, and the spatial relations between parts of entities.", "labels": [], "entities": []}, {"text": "Our ultimate goal is to generate paragraph-length texts from arbitrary paths in the knowledge base.", "labels": [], "entities": []}, {"text": "We describe here the natural language generation pipeline and demonstrate the inputs and generated texts.", "labels": [], "entities": [{"text": "natural language generation pipeline", "start_pos": 21, "end_pos": 57, "type": "TASK", "confidence": 0.7282562851905823}]}, {"text": "In the demo presentation we will show the textbook application and the knowledge base authoring environment, and provide an opportunity to interact with the system.", "labels": [], "entities": []}, {"text": "2 The Knowledge Base The knowledge base contains information from a college-level biology textbook 2 , encoded by bi-1 The work described in this paper and presented in the demo is funded by Vulcan Inc.", "labels": [], "entities": [{"text": "Vulcan Inc", "start_pos": 191, "end_pos": 201, "type": "DATASET", "confidence": 0.8752756714820862}]}, {"text": "ologists as part of project HALO at SRI 3.", "labels": [], "entities": [{"text": "SRI 3", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8001796901226044}]}, {"text": "The core of the knowledge base is the CLIB ontol-ogy 4 , which is extended with biology-specific information.", "labels": [], "entities": [{"text": "CLIB ontol-ogy 4", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.8458349506060282}]}, {"text": "The knowledge base encodes entity-to-event relations (similar to thematic roles in linguistics), event-to-event relations (discourse relations), various property values and relations between properties, spatial relations, cardinality constraints, and roles that participants play in events.", "labels": [], "entities": []}, {"text": "The input to the generation pipeline is a set of triples extracted from the biology knowledge base.", "labels": [], "entities": []}, {"text": "Currently our content selection includes either an event and the entities that participate in the event, or a set of entities and spatial relations between them.", "labels": [], "entities": []}, {"text": "3 Generation Grammar and Lexicon Our generation grammar consists of a set of Tree Adjoining Grammar (TAG) elementary trees.", "labels": [], "entities": []}, {"text": "Each tree is associated with either a single relation , or a set of relations in the knowledge base.", "labels": [], "entities": []}, {"text": "As an example, Fig 1 illustrates the mapping between elementary trees and event participant relations in the KB for the above input.", "labels": [], "entities": []}, {"text": "We currently associate up to three different elementary trees with each event and the connected set of participant relations: an active senten-tial tree, a passive sentential tree and a complex noun phrase.", "labels": [], "entities": []}, {"text": "The knowledge base provides concept-to-word 3 Gunning Et al, 2010.", "labels": [], "entities": [{"text": "Gunning Et al, 2010", "start_pos": 46, "end_pos": 65, "type": "DATASET", "confidence": 0.870935320854187}]}, {"text": "Project halo update progress toward digital aristotle.", "labels": [], "entities": []}, {"text": "AI Magazine Fall:33-58.", "labels": [], "entities": [{"text": "AI Magazine Fall", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.776614656051}]}, {"text": "See also Figure 1: The grammar of the surface realizer mappings (a list of synonyms) for every concept, and the words are used in the generation lexicon to anchor elementary TAG trees.", "labels": [], "entities": []}, {"text": "Our generation grammar consists of a set of TAG tree templates, which are defined as combinations of tree fragments and are compiled using the XMG metgrammar toolkit 5.", "labels": [], "entities": [{"text": "XMG metgrammar toolkit", "start_pos": 143, "end_pos": 165, "type": "DATASET", "confidence": 0.8678711255391439}]}, {"text": "These underspecified elementary trees are further specified in the generation lexicon, which maps concepts onto elementary tree templates, and associates a word (an anchor) with the tree, along with other idiosynchratic information (e.g., preposition choice).", "labels": [], "entities": []}, {"text": "We create a generation lexicon dynamically at run-time, by mapping tree templates onto concepts based on the number and types of participants, and the lexical information associated with the event (e.g., the preposition requirements of the verb).", "labels": [], "entities": []}, {"text": "Concept names for entities are included in the elementary trees as features on the corresponding NP nodes.", "labels": [], "entities": []}, {"text": "These features form part of the input to the referring expression generation module, which looks up the concept name 5 https://sourcesup.renater.fr/xmg/ in the concept-to-word mapping to obtain a list of possible noun phrases.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.6269801159699758}]}, {"text": "4 Realization Our natural language generation pipeline is centered around the GenI surface realizer 6,7.", "labels": [], "entities": [{"text": "GenI surface realizer 6,7", "start_pos": 78, "end_pos": 103, "type": "DATASET", "confidence": 0.8867909610271454}]}, {"text": "The set of triples yielded by content selection are first aggregated and converted to GenI's input format , a set of flat semantic literals.", "labels": [], "entities": []}, {"text": "We then feed this input to GenI to produce an underspecified surface form in which referring expressions are still underspecified:", "labels": [], "entities": [{"text": "GenI", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.9291219115257263}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}