{"title": [{"text": "Combining Incremental Language Generation and Incremental Speech Synthesis for Adaptive Information Presentation", "labels": [], "entities": [{"text": "Incremental Language Generation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.7068763573964437}, {"text": "Incremental Speech Synthesis", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6121328870455424}, {"text": "Adaptive Information Presentation", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.7013503313064575}]}], "abstractContent": [{"text": "Participants in a conversation are normally receptive to their surroundings and their interlocutors , even while they are speaking and can, if necessary, adapt their ongoing utterance.", "labels": [], "entities": []}, {"text": "Typical dialogue systems are not receptive and cannot adapt while uttering.", "labels": [], "entities": []}, {"text": "We present combin-able components for incremental natural language generation and incremental speech synthesis and demonstrate the flexibility they can achieve with an example system that adapts to a listener's acoustic understanding problems by pausing, repeating and possibly rephrasing problematic parts of an utterance.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.8386901418368021}, {"text": "speech synthesis", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.7995144128799438}]}, {"text": "In an evaluation , this system was rated as significantly more natural than two systems representing the current state of the art that either ignore the interrupting event or just pause; it also has a lower response time.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current spoken dialogue systems often produce prescripted system utterances or use templates with variable substitution during language generation.", "labels": [], "entities": []}, {"text": "If a dialogue system uses grammar-based generation at all, it produces complete utterances that are then synthesised and realised in one big chunk.", "labels": [], "entities": []}, {"text": "As systems become increasingly more conversational, however, the need arises to make output generation 1 more flexible.", "labels": [], "entities": []}, {"text": "In particular, capabilities for incrementally generating output become desirable, for two kinds of reasons.", "labels": [], "entities": []}, {"text": "(a) In situations where fast system responses are important, production of output can begin before the content that is to be presented is fully specified -even if what is being produced is just a turn-taking signal.", "labels": [], "entities": []}, {"text": "(b) A system that produces its output incrementally can react to events happening while it is realising an utterance.", "labels": [], "entities": []}, {"text": "This can be beneficial in domains where the state of the world that the system relays information about can change mid-utterance, so that a need may arise to adapt while speaking.", "labels": [], "entities": []}, {"text": "It should also improve naturalness by allowing the system to react to dialogue phenomena such as concurrent feedback signals from the user ().", "labels": [], "entities": []}, {"text": "We present work towards enabling such capabilities.", "labels": [], "entities": []}, {"text": "We have implemented and connected a component for incremental natural language generation (iNLG) that works with specifications of subutterance-sized communicative intentions and a component for incremental speech synthesis (iSS) that can handle sub-utterance-sized input and modifications to not-yet-spoken parts of the utterance with very low latencies.", "labels": [], "entities": [{"text": "incremental natural language generation", "start_pos": 50, "end_pos": 89, "type": "TASK", "confidence": 0.7608645260334015}]}, {"text": "To explore whether such an output generation capability can indeed be advantageous, we have created a test system that can react to random noise events that occur during a system utterance by repeating and modifying the last sub-utterance chunk.", "labels": [], "entities": []}, {"text": "In an evaluation, we found that this system is in general more reactive than a non-incremental variant and that humans rate its behaviour to be more natural than two non-incremental and non-responsive systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "One important argument in favour of incremental processing is the possibility of speeding up system response time, which for non-incremental systems is the sum of the times taken by all processors to do their work.", "labels": [], "entities": []}, {"text": "An incremental system, in contrast, can fold large amounts of its processing time into the ongoing speech output; what matters is the sum of the onset times of each processor, i. e., the time until a first output becomes available to the next processor.", "labels": [], "entities": []}, {"text": "summarises the runtime for the three major steps in output production of our system using nine utterances from our domain.", "labels": [], "entities": []}, {"text": "Both NLG and speech synthesis' onset times are greatly reduced in the incremental system.", "labels": [], "entities": [{"text": "speech synthesis'", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.6385071277618408}, {"text": "onset", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.55156010389328}]}, {"text": "2 Combined, they reduce system response time by more than a second.", "labels": [], "entities": []}, {"text": "This is mostly due to the almost complete folding of HMM optimisation and vocoding times into the spoken utterance.", "labels": [], "entities": []}, {"text": "NLG profits from the fact that at the beginning of an utterance only two chunks have to be generated (instead of an average of 6.5 chunks in the nonincremental system) and that the first chunk is often very simple.", "labels": [], "entities": [{"text": "NLG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8985084891319275}]}, {"text": "To further test whether the system's behaviour in noisy situations resembles that of a human speaker in a similar situation, we let humans rate utterances produced by the fully incremental, adaptive system and utterances produced by two non-incremental and less responsive variants (we have not used nonincremental TTS in combination with iNLG as another possible base-line as pretests showed this to sound very unnatural due to the missing prosodic linkage between phrases).", "labels": [], "entities": []}, {"text": "The participants were to rate whether they agree to the statement 'I found the behaviour of the system in this situation as I would expect it from a human speaker' on a 7-point Likert-scale.", "labels": [], "entities": []}, {"text": "In condition A, full utterances were generated nonincrementally, synthesised non-incrementally and played without responding to noise-interruptions in the channel (as if the system did not notice them).", "labels": [], "entities": []}, {"text": "Utterances in condition B were generated and synthesised as in condition A, but playback responded to the noisy channel, stopping when the noise was noticed and continuing when noise ended.", "labels": [], "entities": []}, {"text": "For condition C, utterances were generated with the fully incremental and adaptive system described in Section 5.", "labels": [], "entities": []}, {"text": "Upon noise detection, speech synthesis is interrupted and, when the noise ends, iNLG will re-generate the interrupted sub-utterance chunk -using the adaptation strategy outlined in Section 5.2.", "labels": [], "entities": [{"text": "noise detection", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.7610136866569519}, {"text": "speech synthesis", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.6994588077068329}]}, {"text": "This then triggers iSS into action and shortly after, the system continues speaking.", "labels": [], "entities": []}, {"text": "Nine system runs, each producing a different utterance from the calendar domain, were recorded in each of the three conditions, resulting in a total of 27 stimuli.", "labels": [], "entities": []}, {"text": "Before the actual stimuli were presented, participants listened to two example stimuli without noise interruptions to get an impression of how an average utterance produced by the system sounds.", "labels": [], "entities": []}, {"text": "After the presentation of these two examples, the 27 stimuli were presented in the same random order.", "labels": [], "entities": []}, {"text": "Participants listened once to each stimulus and rated it immediately after every presentation.", "labels": [], "entities": []}, {"text": "Twelve PhD-students (3 female, 9 male; mean age 30.5 years; 11 with German as one of their first languages; none with uncorrected hearing impairment) from Bielefeld University participated in our study and listened to and rated the 27 stimuli.", "labels": [], "entities": []}, {"text": "A Friedman rank sum test revealed a highly significant difference between the perceived humanlikeness of the three systems (\u03c7 2 = 151, p < .0001).", "labels": [], "entities": []}, {"text": "Median values of stimulus ratings in the conditions A, B and C were 2, 2 and 6 respectively, indicating that the fully incremental system was rated considerably more human-like.", "labels": [], "entities": []}, {"text": "This was also shown through a post-hoc analysis with Wilcoxon signed rank tests which found no significant difference between condition A and B (V = 1191.5, p = .91) . Conditions A and C, however, differed highly significantly (V = 82, p < .0001), as did conditions B and C (V = 22.5, p < .0001) -even after applying a Bonferroni correction to correct fora possible cumulation of \u03b1-errors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Processing time per processing step before deliv- ery can begin (in ms; averaged over nine stimuli taking the  median of three runs for each stimulus; calculated from  log messages; code paths preheated for optimisation).", "labels": [], "entities": []}]}