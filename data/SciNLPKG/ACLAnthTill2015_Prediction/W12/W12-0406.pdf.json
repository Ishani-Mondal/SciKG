{"title": [{"text": "On the Use of Homogenous Sets of Subjects in Deceptive Language Analysis", "labels": [], "entities": [{"text": "Deceptive Language Analysis", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7388261357943217}]}], "abstractContent": [{"text": "Recent studies on deceptive language suggest that machine learning algorithms can be employed with good results for classification of texts as truthful or untruthful.", "labels": [], "entities": []}, {"text": "However, the models presented so far do not attempt to take advantage of the differences between subjects.", "labels": [], "entities": []}, {"text": "In this paper, models have been trained in order to classify statements issued in Court as false or not-false, not only taking into consideration the whole corpus, but also by identifying more homogenous subsets of producers of deceptive language.", "labels": [], "entities": []}, {"text": "The results suggest that the models are effective in recognizing false statements, and their performance can be improved if subsets of homogeneous data are provided.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detecting deceptive communication is a challenging task, but one that could have a number of useful applications.", "labels": [], "entities": [{"text": "Detecting deceptive communication", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.917637825012207}]}, {"text": "A wide variety of approaches to the discovery of deceptive statements have been attempted, ranging from using physiological sensors such as lie detectors to using neuroscience methods (.", "labels": [], "entities": []}, {"text": "More recently, a number of techniques have been developed for recognizing deception on the basis of the communicative behavior of subjects.", "labels": [], "entities": [{"text": "recognizing deception", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.9297109246253967}]}, {"text": "Given the difficulty of the task, many such methods rely on both verbal and non-verbal behavior, to increase accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9971141815185547}]}, {"text": "So for instance De considered more than 150 cues, verbal and non-verbal, directly observed through experimental subjects.", "labels": [], "entities": []}, {"text": "But finding clues indicating deception through manual inspection is not easy.", "labels": [], "entities": [{"text": "finding clues indicating deception", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.6437247395515442}]}, {"text": "De Paulo et al. asserted that \"behaviors that are indicative of deception can be indicative of other states and processes as well\".", "labels": [], "entities": []}, {"text": "The same point is made in more recent literature: thus write \"We find that there is no clue or clue pattern that is specific to deception, although there are clues specific to emotion and cognition\", and they wish for \"real-world databases, identifying base rates for malfeasant behavior in security settings, optimizing training, and identifying preexisting excellence within security organizations\".", "labels": [], "entities": []}, {"text": "exploited cues coming from audio, video and textual data.", "labels": [], "entities": []}, {"text": "One solution is to let statistical and machine learning methods discover the clues.", "labels": [], "entities": []}, {"text": "Work such as;; suggests that these techniques can perform reasonably well at the task of discovering deception even just from linguistic data, provided that corpora containing examples of deceptive and truthful texts are available.", "labels": [], "entities": []}, {"text": "The availability of such corpora is not a trivial problem, and indeed, the creation of a realistic such corpus is one of the problems in which we invested substantial effort in our own previous work, as discussed in Section 3.", "labels": [], "entities": []}, {"text": "In the work discussed in this paper, we tackle an issue which to our knowledge has not been addressed before, due to the limitations of the datasets previously available: this is whether the individual difference between experimental subjects affect deception detection.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 250, "end_pos": 269, "type": "TASK", "confidence": 0.9285666048526764}]}, {"text": "In previous work, lexical) and surface) features were employed to classify deceptive statements issued in Italian Courts.", "labels": [], "entities": [{"text": "classify deceptive statements issued in Italian Courts", "start_pos": 66, "end_pos": 120, "type": "TASK", "confidence": 0.8156262040138245}]}, {"text": "In this study, we report the results of experiments in which our methods were trained either over the whole corpus or over smaller subsets consisting of the utterances produced by more homogenous subsets of subjects.", "labels": [], "entities": []}, {"text": "These subsets were identified either automatically, by clustering subjects according to their language profile, or by using meta-information about the subjects included in the corpus, such as their gender.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2 some background knowledge is introduced.", "labels": [], "entities": []}, {"text": "In Section 3 the data set is described.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss our machine learning and experimental methods.", "labels": [], "entities": []}, {"text": "Finally, the results are presented in Section 5 and discussed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Three experiments were carried out.", "labels": [], "entities": []}, {"text": "In the first experiment, the entire corpus was used to train and test our algorithms.", "labels": [], "entities": []}, {"text": "In the second and third experiment, sub-corpora were identified.", "labels": [], "entities": []}, {"text": "In the first experiment, the classification task has been carried out simply employing the training set and the test set as described above, in order to have a control as reference point in relation to the following experiments.", "labels": [], "entities": [{"text": "classification task", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.8864074349403381}]}, {"text": "In the second experiment, a more homogeneous subset of DECOUR was obtained by automatically identifying and removing outliers.", "labels": [], "entities": [{"text": "DECOUR", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.7082956433296204}]}, {"text": "This was done in an unsupervised way by building vector descriptions of the hearings and clustering them.", "labels": [], "entities": []}, {"text": "The features of these vectors were the same ngrams described above, collected from the whole This data set has been transformed into a matrix of between-hearing distances and a MultiDimensional Scaling -MDS function has been applied to this matrix.", "labels": [], "entities": []}, {"text": "shows the plot of MDS function.", "labels": [], "entities": [{"text": "MDS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.6049323081970215}]}, {"text": "Each entity corresponds to a hearing, and is represented by a letter indicating the sex of the speaker.", "labels": [], "entities": []}, {"text": "Getting a glimpse at, it is possible to notice that, in general, almost all the hearings are quite close -that is, similar -to each other.", "labels": [], "entities": []}, {"text": "Only three hearings seem to be clearly more peripheral than all the others, particularly the three most to the left in.", "labels": [], "entities": []}, {"text": "These hearings have been considered as outliers and shutout from the experiment.", "labels": [], "entities": []}, {"text": "They are two hearings from Trento and one from Prato.", "labels": [], "entities": []}, {"text": "In practice, it means that the training set, coming from the hearings of Bologna and Bolzano, remained the same as the previous experiment, while two hearings have been removed from the test set, which was constituted only by the hearings of Trento.", "labels": [], "entities": []}, {"text": "Different from the previous one, the third experiment does not rely on a subset of data automatically identified.", "labels": [], "entities": []}, {"text": "Instead, the subset comes from personal information concerning the subjects involved in the hearings.", "labels": [], "entities": []}, {"text": "In fact, their sex, place of birth and age at the moment of the hearing are known.", "labels": [], "entities": []}, {"text": "In this paper, places of birth and age have not been taken into consideration, since grouping them together in reliable categories raises issues that do not have a straightforward solution, and the size of the subsets of corpus which would be obtained must betaken into account.", "labels": [], "entities": []}, {"text": "Therefore this experiment has been carried out taking into consideration only the sex of the subjects, and in particular it concerned only the hearings involving men.", "labels": [], "entities": []}, {"text": "This meant reducing the training set consistently, where seven hearings of women were present and thence removed.", "labels": [], "entities": []}, {"text": "Instead from the test set just three hearings have been taken off, one involving a woman and two involving a transsexual.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The most frequent n-grams collected", "labels": [], "entities": []}, {"text": " Table 2: Whole training and test set", "labels": [], "entities": []}, {"text": " Table 3: Test set without outliers", "labels": [], "entities": []}, {"text": " Table 4: Training and test set with only male speakers", "labels": [], "entities": []}]}