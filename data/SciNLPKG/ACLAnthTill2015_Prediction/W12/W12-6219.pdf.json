{"title": [{"text": "Lattice-Based Minimum Error Rate Training using Weighted Finite-State Transducers with Tropical Polynomial Weights", "labels": [], "entities": []}], "abstractContent": [{"text": "Minimum Error Rate Training (MERT) is a method for training the parameters of a log-linear model.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT", "start_pos": 0, "end_pos": 33, "type": "METRIC", "confidence": 0.7485748926798502}]}, {"text": "One advantage of this method of training is that it can use the large number of hypotheses encoded in a translation lattice as training data.", "labels": [], "entities": []}, {"text": "We demonstrate that the MERT line optimisation can be modelled as computing the shortest distance in a weighted finite-state transducer using a tropical polynomial semiring.", "labels": [], "entities": [{"text": "MERT line optimisation", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.8203355272610983}]}], "introductionContent": [{"text": "Minimum Error Rate Training (MERT) is an iterative procedure for training a log-linear statistical machine translation (SMT) model).", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT", "start_pos": 0, "end_pos": 33, "type": "METRIC", "confidence": 0.7612756739060084}, {"text": "statistical machine translation (SMT)", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.803186963001887}]}, {"text": "MERT optimises model parameters directly against a criterion based on an automated translation quality metric, such as BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9977291226387024}]}, {"text": "provides a full description of the SMT task and MERT.", "labels": [], "entities": [{"text": "SMT task", "start_pos": 35, "end_pos": 43, "type": "TASK", "confidence": 0.9118328094482422}, {"text": "MERT", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.7681648135185242}]}, {"text": "MERT uses a line optimisation procedure) to identify a range of points along a line in parameter space that maximise an objective function based on the BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 152, "end_pos": 162, "type": "METRIC", "confidence": 0.967722624540329}]}, {"text": "A key property of the line optimisation is that it can consider a large set of hypotheses encoded as a weighted directed acyclic graph (, which is called a lattice.", "labels": [], "entities": []}, {"text": "The line optimisation procedure can also be applied to a hypergraph representation of the hypotheses ().", "labels": [], "entities": []}, {"text": "* The work reported in this paper was carried out while the author was at the University of Cambridge.", "labels": [], "entities": []}, {"text": "It has been noted that line optimisation over a lattice can be implemented as a semiring of sets of linear functions.", "labels": [], "entities": []}, {"text": "provide a formal description of such a semiring, which they denote the MERT semiring.", "labels": [], "entities": []}, {"text": "The difference between the various algorithms derives from the differences in their formulation and implementation, but not in the objective they attempt to optimise.", "labels": [], "entities": []}, {"text": "Instead of an algebra defined in terms of transformations of sets of linear functions, we propose an alternative formulation using the tropical polynomial semiring.", "labels": [], "entities": []}, {"text": "This semiring provides a concise formalism for describing line optimisation, an intuitive explanation of the MERT shortest distance, and draws on techniques in the currently active field of Tropical Geometry ( . We begin with a review of the line optimisation procedure, lattice-based MERT, and the weighted finite-state transducer formulation in Section 2.", "labels": [], "entities": [{"text": "MERT shortest distance", "start_pos": 109, "end_pos": 131, "type": "METRIC", "confidence": 0.6520022749900818}, {"text": "MERT", "start_pos": 285, "end_pos": 289, "type": "TASK", "confidence": 0.8305240869522095}]}, {"text": "In Section 3, we introduce our novel formulation of lattice-based MERT using tropical polynomial weights.", "labels": [], "entities": [{"text": "MERT", "start_pos": 66, "end_pos": 70, "type": "TASK", "confidence": 0.8931931853294373}]}, {"text": "Section 4 compares the performance of our approach with k-best and lattice-based MERT.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare feature weight optimisation using kbest MERT, lattice MERT (, and tropical geometry MERT.", "labels": [], "entities": []}, {"text": "We refer to these as MERT, LMERT, and TGMERT, resp.", "labels": [], "entities": [{"text": "MERT", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.969205915927887}, {"text": "LMERT", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9229713678359985}, {"text": "TGMERT", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9698489904403687}]}, {"text": "We investigate MERT performance in the context of the Arabic-to-English GALE P4 and Chineseto-English GALE P3 evaluations 3 . For Arabic-toEnglish translation, word alignments are generated over around 9M sentences of GALE P4 parallel text.", "labels": [], "entities": [{"text": "MERT", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.6595807075500488}]}, {"text": "Following de, word alignments for Chinese-to-English translation are trained from a subset of 2M sentences of GALE P3 parallel text.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7040440291166306}, {"text": "Chinese-to-English translation", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.6541397273540497}, {"text": "GALE P3 parallel text", "start_pos": 110, "end_pos": 131, "type": "DATASET", "confidence": 0.7531401515007019}]}, {"text": "Hierarchical rules are extracted from alignments using the constraints described in with additional count and pattern filters See http://projects.ldc.upenn.edu/gale/data/catalog.html).", "labels": [], "entities": []}, {"text": "We use a hierarchical phrasebased decoder () which directly generates word lattices from recursive translation networks without any intermediate hypergraph representation).", "labels": [], "entities": []}, {"text": "The LMERT and TGMERT optimisation algorithms are particularly suitable for this realisation of hiero in that the lattice representation avoids the need to use the hypergraph formulation of MERT given by.", "labels": [], "entities": []}, {"text": "MERT optimises the weights of the following features: target language model, source-to-target and target-to-source translation models, word and rule penalties, number of usages of the glue rule, word deletion scale factor, source-to-target and target-tosource lexical models, and three count-based features that track the frequency of rules in the parallel data.", "labels": [], "entities": [{"text": "word deletion scale factor", "start_pos": 195, "end_pos": 221, "type": "METRIC", "confidence": 0.6675037294626236}]}, {"text": "In both Arabic-to-English and Chinese-to-English experiments all MERT implementations start from a flat feature weight initialization.", "labels": [], "entities": [{"text": "MERT", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.9016997218132019}]}, {"text": "At each iteration new lattices and k-best lists are generated from the best parameters at the previous iteration, and each subsequent iteration includes 100 hypotheses from the previous iteration.", "labels": [], "entities": []}, {"text": "For Arabic-to-English we consider an additional twenty random starting parameters at every iteration.", "labels": [], "entities": []}, {"text": "All translation scores are reported for the IBM implementation of BLEU using case-insensitive matching.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.7120392918586731}]}, {"text": "We report BLEU scores for the Tune set at the start and end of each iteration.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9736069142818451}]}, {"text": "The results for Arabic-to-English and Chineseto-English are shown in.", "labels": [], "entities": []}, {"text": "Both TGMERT and LMERT converge to a small gain over MERT in fewer iterations, consistent with previous reports (.", "labels": [], "entities": [{"text": "TGMERT", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9452180862426758}, {"text": "LMERT", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9153127670288086}, {"text": "MERT", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.6959488391876221}]}], "tableCaptions": [{"text": " Table 1: GALE AR\u2192EN and ZH\u2192EN BLEU scores  by MERT iteration. BLEU scores at the initial and final  points of each iteration are shown for the Tune sets.", "labels": [], "entities": [{"text": "GALE AR", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8293107450008392}, {"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9864159822463989}, {"text": "MERT", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9927850961685181}, {"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9991747736930847}]}]}