{"title": [{"text": "English to Indian Languages Machine Transliteration System at NEWS 2010", "labels": [], "entities": [{"text": "English to Indian Languages Machine Transliteration", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.5520596355199814}, {"text": "NEWS 2010", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.9553875923156738}]}], "abstractContent": [{"text": "This paper reports about our work in the NEWS 2010 Shared Task on Transliteration Generation held as part of ACL 2010.", "labels": [], "entities": [{"text": "NEWS 2010 Shared Task on Transliteration Generation held as part of ACL 2010", "start_pos": 41, "end_pos": 117, "type": "TASK", "confidence": 0.6657062814785883}]}, {"text": "One standard run and two non-standard runs were submitted for English to Hindi and Bengali transliteration while one standard and one non-standard run were submitted for Kannada and Tamil.", "labels": [], "entities": []}, {"text": "The transliteration systems are based on Orthographic rules and Phoneme based technology.", "labels": [], "entities": []}, {"text": "The system has been trained on the NEWS 2010 Shared Task on Translitera-tion Generation datasets.", "labels": [], "entities": [{"text": "NEWS 2010 Shared Task on Translitera-tion Generation datasets", "start_pos": 35, "end_pos": 96, "type": "DATASET", "confidence": 0.8103042319417}]}, {"text": "For the standard run, the system demonstrated mean F-Score values of 0.818 for Bengali, 0.714 for Hindi, 0.663 for Kannada and 0.563 for Tamil.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.991363525390625}]}, {"text": "The reported mean F-Score values of non-standard runs are 0.845 and 0.875 for Bengali non-standard run-1 and 2, 0.752 and 0.739 for Hindi non-standard run-1 and 2, 0.662 for Kannada non-standard run-1 and 0.760 for Tamil non-standard run-1.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9988603591918945}]}, {"text": "Non-Standard Run-2 for Ben-gali has achieved the highest score among all the submitted runs.", "labels": [], "entities": []}, {"text": "Hindi Non-Standard Run-1 and Run-2 runs are ranked as the 5 th and 6 th among all submitted Runs.", "labels": [], "entities": [{"text": "Hindi Non-Standard Run-1", "start_pos": 0, "end_pos": 24, "type": "DATASET", "confidence": 0.7730924685796102}]}], "introductionContent": [{"text": "Transliteration is the method of translating one source language word into another target language by expressing and preserving the original pronunciation in their source language.", "labels": [], "entities": []}, {"text": "Thus, the central problem in transliteration is predicting the pronunciation of the original word.", "labels": [], "entities": [{"text": "predicting the pronunciation of the original word", "start_pos": 48, "end_pos": 97, "type": "TASK", "confidence": 0.8848551426615033}]}, {"text": "Transliteration between two languages that use the same set of alphabets is trivial: the word is left as it is.", "labels": [], "entities": []}, {"text": "However, for languages those use different alphabet sets the names must be transliterated or rendered in the target language alphabets.", "labels": [], "entities": []}, {"text": "Transliteration of words is necessary in many applications, such as machine translation, corpus alignment, cross-language Information Retrieval, information extraction and automatic lexicon acquisition.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8110645413398743}, {"text": "corpus alignment", "start_pos": 89, "end_pos": 105, "type": "TASK", "confidence": 0.7430370599031448}, {"text": "cross-language Information Retrieval", "start_pos": 107, "end_pos": 143, "type": "TASK", "confidence": 0.7118048568566641}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.8385172486305237}, {"text": "automatic lexicon acquisition", "start_pos": 172, "end_pos": 201, "type": "TASK", "confidence": 0.6578724980354309}]}, {"text": "In the literature, a number of transliteration algorithms are available involving English (, European languages () and some of the Asian languages, namely Chinese (), Japanese (), Korean () and Arabic.", "labels": [], "entities": []}, {"text": "Recently, some works have been initiated involving Indian languages (.", "labels": [], "entities": []}, {"text": "The detailed report of our participation in NEWS 2009 could be found in (  The TUs are the basic lexical units for machine transliteration.", "labels": [], "entities": [{"text": "NEWS 2009", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.8073682188987732}]}, {"text": "The system considers the English and Indian languages contextual information in the form of collocated TUs simultaneously to calculate the plausibility of transliteration from each English TU to various Indian languages candidate TUs and chooses the one with maximum probability.", "labels": [], "entities": []}, {"text": "The system learns the mappings automatically from the bilingual NEWS 2010 training set being guided by linguistic features/knowledge.", "labels": [], "entities": [{"text": "NEWS 2010 training set", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.9434669017791748}]}, {"text": "The output of the mapping process is a decision-list classifier with collocated TUs in the source language and their equivalent TUs in collocation in the target language along with the probability of each decision obtained from the training set.", "labels": [], "entities": []}, {"text": "A Direct example base has been maintained that contains the bilingual training examples that do not result in the equal number of TUs in both the source and target sides during alignment.", "labels": [], "entities": [{"text": "TUs", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.9624049067497253}]}, {"text": "The Direct example base is checked first during machine transliteration of the input English word.", "labels": [], "entities": []}, {"text": "If no match is obtained, the system uses direct orthographic mapping by identifying the equivalent TU in Indian languages for each English TU in the input and then placing the target language TUs in order.", "labels": [], "entities": []}, {"text": "The IPA based model has been used for English dictionary words.", "labels": [], "entities": []}, {"text": "Words which are not present in the dictionary are handled by other orthographic models as Trigram, JSC, MJSC and IMJSC.", "labels": [], "entities": [{"text": "MJSC", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.8240301012992859}, {"text": "IMJSC", "start_pos": 113, "end_pos": 118, "type": "DATASET", "confidence": 0.7623655796051025}]}], "datasetContent": [{"text": "We have trained our transliteration models using the NEWS 2010 datasets obtained from the NEWS 2010 Machine Transliteration Shared Task (.", "labels": [], "entities": [{"text": "NEWS 2010 datasets", "start_pos": 53, "end_pos": 71, "type": "DATASET", "confidence": 0.9767434000968933}, {"text": "NEWS 2010 Machine Transliteration Shared Task", "start_pos": 90, "end_pos": 135, "type": "DATASET", "confidence": 0.8074605663617452}]}, {"text": "A brief statistics of the datasets are presented in.", "labels": [], "entities": []}, {"text": "During training, we have split multi-words into collections of single word transliterations.", "labels": [], "entities": []}, {"text": "It was observed that the number of tokens in the source and target sides mismatched in various multi-words and these cases were not considered further.", "labels": [], "entities": []}, {"text": "Following are some examples: Paris Charles de Gaulle \ud97b\udf59", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Stress Level on Vowel  A pre-processing module checks whether a  targeted source English word is a valid  dictionary word or not. The dictionary words are  then handled by phoneme based transliteration  module.", "labels": [], "entities": []}, {"text": " Table 4: The ranking  decision is based on the experiments as described  in (", "labels": [], "entities": []}, {"text": " Table 5: Statistics of Dataset  There is less number of known examples in  the NEWS 2010 test set from training set. The  exact figure is reported in the Table 6.", "labels": [], "entities": [{"text": "NEWS 2010 test set from training set", "start_pos": 80, "end_pos": 116, "type": "DATASET", "confidence": 0.9045338715825763}]}, {"text": " Table 6: Statistics of Dataset  If the outputs of any two transliteration models  are same for any word then only one output are  provided for that particular word. Evaluation re- sults of the final system are shown in", "labels": [], "entities": []}, {"text": " Table 7: Results on Bengali Test Set", "labels": [], "entities": [{"text": "Bengali Test Set", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.9025361935297648}]}, {"text": " Table 8: Results on Hindi Test Set", "labels": [], "entities": [{"text": "Hindi Test Set", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.9602477153142294}]}, {"text": " Table 9: Results on Kannada Test Set", "labels": [], "entities": [{"text": "Kannada Test Set", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.9722111622492472}]}, {"text": " Table 10: Results on Tamil Test Set", "labels": [], "entities": [{"text": "Tamil Test Set", "start_pos": 22, "end_pos": 36, "type": "DATASET", "confidence": 0.9701512654622396}]}]}