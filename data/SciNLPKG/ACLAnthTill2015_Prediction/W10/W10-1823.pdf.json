{"title": [{"text": "A Feature Type Classification for Therapeutic Purposes: a preliminary evaluation with non-expert speakers", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a feature type classification thought to be used in a therapeutic context.", "labels": [], "entities": [{"text": "feature type classification", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.6668410102526346}]}, {"text": "Such a scenario lays behind our need fora easily usable and cognitively plausible classification.", "labels": [], "entities": []}, {"text": "Nevertheless, our proposal has both a practical and a theoretical outcome, and its applications range from computational linguistics to psycholinguistics.", "labels": [], "entities": []}, {"text": "An evaluation through inter-coder agreement has been performed to highlight the strength of our proposal and to conceive some improvements for the future.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most common therapeutic practices for anomia rehabilitation rely either on the therapist's intuitive linguistic knowledge or on different kinds of resources that have to be consulted manually.", "labels": [], "entities": [{"text": "anomia rehabilitation", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8616503477096558}]}, {"text": "STaRS.sys (Semantic Task Rehabilitation Support system) is a tool thought for supporting the therapist in the preparation of a semantic task (cfr.).", "labels": [], "entities": [{"text": "Semantic Task Rehabilitation Support", "start_pos": 11, "end_pos": 47, "type": "TASK", "confidence": 0.6468327045440674}]}, {"text": "To be effective, such a system must lean on a knowledge base in which every concept is associated with different kinds of featural descriptions.", "labels": [], "entities": []}, {"text": "The notion of feature refers to the linguistic descriptions of a property that can be obtained by asking a subject to describe a concept.", "labels": [], "entities": []}, {"text": "Examples of concept-feature pairings will be represented here as <concept> feature 1 couples such as <dog> has a tailor <dog> barks.", "labels": [], "entities": []}, {"text": "As a consequence of this scenario, an intuitive and cognitively plausible classification of the feature types that can be associated with a concept is a vital component of our tool.", "labels": [], "entities": []}, {"text": "In this paper, we present a classification that meets such criteria, built by moving from an analysis of the relevant proposals available in the literature.", "labels": [], "entities": []}, {"text": "We evaluated our classification by asking to a group of naive Italian speakers to annotate a test set by using our categories.", "labels": [], "entities": []}, {"text": "The resulting agreement has been interpreted both as an index of reliability and as a measure of ease of learning and use by non-expert speakers.", "labels": [], "entities": [{"text": "reliability", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9908925294876099}]}, {"text": "In these preliminary phases we focus on Italian, leaving to future evaluations whether or how to extend the domain of our tool to other languages.", "labels": [], "entities": []}, {"text": "These pages are organized as follows: in Section 2 we briefly review the relevant works for the following discussion.", "labels": [], "entities": []}, {"text": "In Section 3 we introduce our classification and in the remaining part we evaluate its reliability and usability.", "labels": [], "entities": [{"text": "reliability", "start_pos": 87, "end_pos": 98, "type": "METRIC", "confidence": 0.99391770362854}]}], "datasetContent": [{"text": "Participants: 5 Italian speakers with a university degree were recruited for this evaluation.", "labels": [], "entities": []}, {"text": "None of them had any previous experience in lexicography, nor any education in lexical semantics.", "labels": [], "entities": []}, {"text": "Materials: 300 concept-feature pairs were selected mainly from a non-normalized version of the Kremer et al's (2008) norms.", "labels": [], "entities": []}, {"text": "We choose this dataset because (1) it's a collection of descriptions generated by Italian speakers and (2) we wanted to avoid any bias due to a normalization procedure, so as to provide our subjects with descriptions that were as plausible as possible.", "labels": [], "entities": []}, {"text": "The experimental concept-attribute pairs have been chosen so to have the more balanced distribution of concepts and feature types as possible, by not allowing duplicated pairs.", "labels": [], "entities": []}, {"text": "As for the concepts, an uniform distribution of features per category (30 feature for all the ten categories of the original dataset) and of features per concept (i.e. between 4 and 7) has been easily obtained.", "labels": [], "entities": []}, {"text": "The attempt to balance feature types, however, has revealed impracticable, mainly due to the nature of the concepts of the Kremer's collection and to the skewness of its type distribution.", "labels": [], "entities": [{"text": "Kremer's collection", "start_pos": 123, "end_pos": 142, "type": "DATASET", "confidence": 0.7540165483951569}]}, {"text": "Therefore, we fixed an arbitrary minimum threshold often plausible features per type.", "labels": [], "entities": []}, {"text": "Plausible features have been obtained from a pilot annotation experiment performed by one author and an additional subject.", "labels": [], "entities": []}, {"text": "We further translated 23 concept-feature pairs from the McRae (11 cases) and from the Leuven (12 cases) datasets for balancing types as much as possible.", "labels": [], "entities": [{"text": "McRae", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.9869269728660583}]}, {"text": "Still, it has not been possible to find ten features for the following types: has Geographical Part, has Phase and has Member (no features at all: this is a consequence of the kind of concept represented the dataset), has Portion (only four cases, again, this is a consequence of the source dataset), has Domain (5) and has Sound (6).", "labels": [], "entities": []}, {"text": "We nevertheless decided to include these types in the instructions and the relevant features in the test set.", "labels": [], "entities": []}, {"text": "Our decision has been motivated by the results of the pilot experiment, in which the subjects made reference to such types as a secondary interpretation in more than ten cases.", "labels": [], "entities": []}, {"text": "Procedure: The participants were asked to label every concept-feature pair with the appropriate type label, relying primarily on the linguistic form of the feature.", "labels": [], "entities": []}, {"text": "They received a 17-pages booklet providing an explanation of the annotation goals, a definition and some examples for every type class and for every type, a decision flowchart and a reference table.", "labels": [], "entities": []}, {"text": "Every participant was asked to read carefully the instructions, to complete a training set of 30 concept-feature pairs and to discuss his/her decisions with one of the two authors before starting the experimental session.", "labels": [], "entities": []}, {"text": "The test set was presented as a unique excel sheet.", "labels": [], "entities": []}, {"text": "On the average, labeling the 300 experimental pairs took 2 hours.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Type-wise agreement values", "labels": [], "entities": []}]}