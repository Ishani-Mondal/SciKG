{"title": [{"text": "Syntactic Constraints on Phrase Extraction for Phrase-Based Machine Translation", "labels": [], "entities": [{"text": "Phrase Extraction", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.834747314453125}, {"text": "Phrase-Based Machine Translation", "start_pos": 47, "end_pos": 79, "type": "TASK", "confidence": 0.6771973172823588}]}], "abstractContent": [{"text": "A typical phrase-based machine translation (PBMT) system uses phrase pairs extracted from word-aligned parallel corpora.", "labels": [], "entities": [{"text": "phrase-based machine translation (PBMT)", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.7698837717374166}]}, {"text": "All phrase pairs that are consistent with word alignments are collected.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.6737452447414398}]}, {"text": "The resulting phrase table is very large and includes many non-syntactic phrases which may not be necessary.", "labels": [], "entities": []}, {"text": "We propose to filter the phrase table based on source language syntactic constraints.", "labels": [], "entities": []}, {"text": "Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.", "labels": [], "entities": [{"text": "phrase segmentation ambiguity", "start_pos": 100, "end_pos": 129, "type": "TASK", "confidence": 0.7739874223868052}]}, {"text": "Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9994133710861206}]}], "introductionContent": [{"text": "Both PBMT models () and syntax-based machine translation models (;; and numerous others) are the state-of-theart statistical machine translation (SMT) methods.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7215283364057541}, {"text": "statistical machine translation (SMT)", "start_pos": 113, "end_pos": 150, "type": "TASK", "confidence": 0.8131288588047028}]}, {"text": "Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches.", "labels": [], "entities": []}, {"text": "made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model.", "labels": [], "entities": []}, {"text": "proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model.", "labels": [], "entities": []}, {"text": "proposed a tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information.", "labels": [], "entities": []}, {"text": "The converse of the above methods is to incorporate syntactic information into the PBMT model.", "labels": [], "entities": []}, {"text": "started with a complete set of phrases as extracted by traditional PBMT heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span. and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis.", "labels": [], "entities": []}, {"text": "In their PBMT decoders, a candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur a cost if it violates a constituent boundary.", "labels": [], "entities": []}, {"text": "proposed a syntax-driven bracketing model to predict whether a phrase (a sequence of contiguous words) is bracketable or not using rich syntactic constraints.", "labels": [], "entities": []}, {"text": "In this paper, we try to utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for PBMT system.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7317228466272354}]}, {"text": "Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words.", "labels": [], "entities": [{"text": "phrase segmentation ambiguity", "start_pos": 100, "end_pos": 129, "type": "TASK", "confidence": 0.7739874223868052}]}, {"text": "Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to the baseline PBMT system with full-size tables.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9994233846664429}]}], "datasetContent": [{"text": "Our SMT system is based on a fairly typical phrase-based model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9911810159683228}]}, {"text": "For the training of our SMT model, we use a modified training toolkit adapted from the MOSES decoder.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9930365681648254}, {"text": "MOSES decoder", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.9452521502971649}]}, {"text": "Our decoder can operate on the same principles as the MOSES decoder.", "labels": [], "entities": [{"text": "MOSES decoder", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.927649199962616}]}, {"text": "Minimum error rate training (MERT) with respect to BLEU score is used to tune the decoder's parameters, and it is performed using the standard technique of.", "labels": [], "entities": [{"text": "Minimum error rate training (MERT)", "start_pos": 0, "end_pos": 34, "type": "METRIC", "confidence": 0.8603409358433315}, {"text": "BLEU score", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9834803938865662}]}, {"text": "A lexicalized reordering model was built by using the \"msdbidirectional-fe\" configuration in our experiments.", "labels": [], "entities": []}, {"text": "The translation model was created from the FBIS parallel corpus.", "labels": [], "entities": [{"text": "FBIS parallel corpus", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.8653504649798075}]}, {"text": "We used a 5-gram language model trained with modified Kneser-Ney smoothing.", "labels": [], "entities": []}, {"text": "The language model was trained on the target side of the FBIS corpus and the Xinhua news in the GIGAWORD corpus.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.9406737983226776}, {"text": "GIGAWORD corpus", "start_pos": 96, "end_pos": 111, "type": "DATASET", "confidence": 0.9258754551410675}]}, {"text": "The development and test sets are from the NIST MT08 evaluation campaign.", "labels": [], "entities": [{"text": "NIST MT08 evaluation campaign", "start_pos": 43, "end_pos": 72, "type": "DATASET", "confidence": 0.9084194749593735}]}, {"text": "The Chinese sentences are segmented, POS tagged and parsed by the tools described in and, both of which are trained on the Penn Chinese Treebank 6.0.", "labels": [], "entities": [{"text": "Penn Chinese Treebank 6.0", "start_pos": 123, "end_pos": 148, "type": "DATASET", "confidence": 0.9873578697443008}]}, {"text": "We use GIZA++ to align the sentences in both the Chinese-English and English-Chinese directions.", "labels": [], "entities": []}, {"text": "Then we combine the alignments using the standard \"grow-diag-final-and\" procedure provided with MOSES.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.8838608264923096}]}, {"text": "In the combined word alignments, 614,369 or 9.82% of the Chinese words are unaligned.", "labels": [], "entities": []}, {"text": "shows the top 10 most frequently unaligned words.", "labels": [], "entities": []}, {"text": "Basically, these words are auxiliary words or function words whose usage is very flexible.", "labels": [], "entities": []}, {"text": "So it would be difficult to automatically align them to the target words.", "labels": [], "entities": []}, {"text": "In order to confirm that it is advantageous to apply appropriate syntactic constraints on phrase extraction, we performed three translation experiments by using different ways of phrase extraction.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.8216140568256378}, {"text": "phrase extraction", "start_pos": 179, "end_pos": 196, "type": "TASK", "confidence": 0.7864972949028015}]}, {"text": "In the first experiment, we used the method introduced in Section 2 to extract all possible phrase translation pairs without using any constraints arising from knowledge of syntax.", "labels": [], "entities": [{"text": "phrase translation pairs", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.7650383909543356}]}, {"text": "The second experiment used source language syntactic constraints to filter out all nonsyntactic phrases during phrase pair extraction.", "labels": [], "entities": [{"text": "phrase pair extraction", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.7255440950393677}]}, {"text": "The third experiment used source language syntactic constraints to filter out only nonsyntactic phrases whose first or last source word was unaligned.", "labels": [], "entities": []}, {"text": "With the exception of the above differences in phrase translation pair extraction, all the other settings were the identical in the three experiments.", "labels": [], "entities": [{"text": "phrase translation pair extraction", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.8564035147428513}]}, {"text": "The evaluation metric is casesensitive BLEU-4 () which estimates the accuracy of translation output with respect to a set of reference translations.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9978864789009094}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9980641007423401}]}, {"text": "As shown in the table, it is harmful to fully apply syntactic constraints on phrase extraction, even just on the source language side.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.8256858587265015}]}, {"text": "This is consistent with the observation of () who applied both source and target constraints in German to English translation experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Comparison of different constraints on  phrase pair extraction by translation quality", "labels": [], "entities": [{"text": "phrase pair extraction", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7200115919113159}]}]}