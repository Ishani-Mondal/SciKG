{"title": [{"text": "Crowdsourcing and language studies: the new generation of linguistic data", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a compendium of recent and current projects that utilize crowdsourcing technologies for language studies, finding that the quality is comparable to controlled laboratory experiments, and in some cases superior.", "labels": [], "entities": []}, {"text": "While crowdsourcing has primarily been used for annotation in recent language studies, the results here demonstrate that far richer data maybe generated in a range of linguistic disciplines from semantics to psycholinguistics.", "labels": [], "entities": []}, {"text": "For these, we report a number of successful methods for evaluating data quality in the absence of a 'correct' response for any given data point.", "labels": [], "entities": []}], "introductionContent": [{"text": "Crowdsourcing's greatest contribution to language studies might be the ability to generate new kinds of data, especially within experimental paradigms.", "labels": [], "entities": []}, {"text": "The speed and cost benefits for annotation are certainly impressive) but we hope to show that some of the greatest gains are in the very nature of the phenomena that we can now study.", "labels": [], "entities": [{"text": "speed", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9961612224578857}]}, {"text": "For psycholinguistic experiments in particular, we are not so much utilizing 'artificial artificial' intelligence as the plain intelligence and linguistic intuitions of each crowdsourced worker -the 'voices in the crowd', so to speak.", "labels": [], "entities": []}, {"text": "In many experiments we are studying gradient phenomena where there are no right answers.", "labels": [], "entities": []}, {"text": "Even when there is binary response we are often interested in the distribution of responses over many speakers rather than specific data points.", "labels": [], "entities": []}, {"text": "This differentiates experimentation from more common means of determining the quality of crowdsourced results as there is no gold standard against which to evaluate the quality or 'correctness' of each individual response.", "labels": [], "entities": []}, {"text": "The purpose of this paper is therefore two-fold.", "labels": [], "entities": []}, {"text": "We summarize seven current projects that are utilizing crowdsourcing technologies, all of them somewhat novel to the NLP community but with potential for future research in computational linguistics.", "labels": [], "entities": []}, {"text": "For each, we also discuss methods for evaluating quality, finding the crowdsourced results to often be indistinguishable from controlled laboratory experiments.", "labels": [], "entities": []}, {"text": "In Section 2 we present the results from semantic transparency experiments showing near-perfect interworker reliability and a strong correlation between crowdsourced data and lab results.", "labels": [], "entities": []}, {"text": "Extending to audio data, we show in Section 3 that crowdsourced subjects were statistically indistinguishable from a lab control group in segmentation tasks.", "labels": [], "entities": []}, {"text": "Section 4 shows that laboratory results from simple Cloze tasks can be reproduced with crowdsourcing.", "labels": [], "entities": []}, {"text": "In Section 5 we offer strong evidence that crowdsourcing can also replicate limited-population, controlled-condition lab results for grammaticality judgments.", "labels": [], "entities": [{"text": "grammaticality judgments", "start_pos": 133, "end_pos": 157, "type": "TASK", "confidence": 0.8877851665019989}]}, {"text": "In Section 6 we use crowdsourcing to support corpus studies with a precision not possible with even very large corpora.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9977905750274658}]}, {"text": "Moving to the brain itself, Section 7 demonstrates that ERP brainwave analysis can be enhanced by crowdsourced analysis of experimental stimuli.", "labels": [], "entities": [{"text": "ERP brainwave analysis", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.8578430414199829}]}, {"text": "Finally, in Section 8 we outline simple heuristics for ensuring that microtasking workers are applying the linguistic attentiveness required to undertake more complex tasks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}