{"title": [{"text": "Detecting Semantic Category in Simultaneous EEG/MEG Recordings", "labels": [], "entities": [{"text": "Detecting Semantic Category", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8811676104863485}, {"text": "EEG/MEG Recordings", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.5516285002231598}]}], "abstractContent": [{"text": "Electroencephalography (EEG) and magne-toencephalography (MEG) are closely related neuroimaging technologies that both measure summed electrical activity of synchronous sources of neural activity.", "labels": [], "entities": []}, {"text": "However they differ in the portions of the brain to which they are more sensitive, in the frequency bands they can detect, and to the amount of noise to which they are subject.", "labels": [], "entities": []}, {"text": "Since semantic representations are thought to be widely distributed in the brain, this preliminary study considered if the broader coverage offered by simultaneous EEG/MEG recordings would increase sensitivity to these cognitive states.", "labels": [], "entities": []}, {"text": "The results showed that MEG data allowed stimuli in two semantic categories (mammals and tools) to be distinguished more accurately, despite some experimental settings that were op-timised for EEG.", "labels": [], "entities": []}, {"text": "The addition of EEG data did not prove informative, indicating that it maybe redundant relative to MEG, even when using dimensionality reduction techniques to combat overfitting.", "labels": [], "entities": [{"text": "MEG", "start_pos": 99, "end_pos": 102, "type": "DATASET", "confidence": 0.6331639885902405}]}], "introductionContent": [{"text": "Electroencephalography (EEG) and magnetoencephalography (MEG) are similar methods for recording activity in the brain.", "labels": [], "entities": []}, {"text": "Both detect signals that are produced by the mixing of neural sources, where each source represents macro-scale synchronisation between the firing of individual neurons.", "labels": [], "entities": []}, {"text": "The sum of these activities induce voltages at the scalp that are recorded with EEG, and magnetic fields that are detected with MEG.", "labels": [], "entities": [{"text": "EEG", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.5121091604232788}]}, {"text": "But the signals yielded by each technique are not identical for several reasons.", "labels": [], "entities": []}, {"text": "EEG signals are heavily attenuated and filtered (both in time in space) by the passage through skull and tissue.", "labels": [], "entities": []}, {"text": "As a result, MEG signals are less noisy, have finer spatial resolution, capture a wider range of frequencies, and so have the potential to be more informative.", "labels": [], "entities": []}, {"text": "Further, the signal footprint of MEG and EEG signals on the brain is not the same: EEG sensors are more sensitive to currents that are radial to the scalp and so predominantly detect activity in the at the top of gyri and the bottom of sulci (the top and bottom of folds in the surface of the brain); while MEG is more sensitive to currents that are tangential to the scalp, and so detects more activity in the side walls of sulci.", "labels": [], "entities": []}, {"text": "The high spatial resolution of MEG means that it cannot see as deeply into the brain as EEG can.", "labels": [], "entities": [{"text": "MEG", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.6347904205322266}]}, {"text": "Finally, MEG sensors of different types (in this case magnetometers and planar gradiometers) are sensitive to magnetic fields of different orientations (see): planar gradiometers are most sensitive to current generators of a particular orientation directly under the sensor position; magnetometers record generators that are tangential and peripheral to the sensor area.", "labels": [], "entities": []}, {"text": "The distribution of sensor coverage maybe important for the decoding of semantic categories in particular.", "labels": [], "entities": []}, {"text": "Neuroimaging evidence suggests that semantic representations maybe widely distributed in the brain.", "labels": [], "entities": []}, {"text": "For example there are well-established differences in neural activity in the fusiform gyrus that correspond to higher level categories (natural vs non-natural kinds; people vs places -see e.g.); there is also evidence that the meaning of bodily actions is encoded in the motorcortex; and concepts associated with eating (e.g. foodstuffs) seem to be represented at least in part by activations in gustatory cortex (.", "labels": [], "entities": []}, {"text": "Hence a wide coverage of sensors that are sensitive to different but overlapping portions of brain tissue may provide a fuller description of semantic memories.", "labels": [], "entities": []}, {"text": "Given the fact that it has been possible to decode conceptual categories and language semantics from EEG signals (, the question is if MEG signals can be shown to be more informative.", "labels": [], "entities": []}, {"text": "Similar studies on lower-level tasks typically used in brain-computer interfaces suggests that it may be: find that there is a modest increase in the decoding accuracy on imagined motor activity with MEG, relative to EEG, and have similar findings detecting the direction of hand movements.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9920297861099243}]}, {"text": "A related question is whether the information supplied by EEG and MEG is complementary, and if so how best it should be combined.", "labels": [], "entities": [{"text": "EEG", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.8918092250823975}, {"text": "MEG", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.7948523759841919}]}, {"text": "This depends critically on the number of signals used: raising the number of input signals increases the information supplied to the machine learning methods, but interacts with their tendency to overfit, if the number of descriptive dimensions (recorded signals) is of a similar order of magnitude to the number of training cases (experimental trials in which a stimulus is presented).", "labels": [], "entities": []}, {"text": "This is often the case with data from neuroimaging experiments, as there are practical limitations on the number of data points that can be collected: individual stimuli must usually be separated by several seconds so that neural signals can return to baseline between each, and participants can usually only be expected to perform a task at full attention for 60 minutes or so, in such experimental environments.", "labels": [], "entities": []}, {"text": "To investigate this question, we replicated an existing EEG experiment (.", "labels": [], "entities": []}, {"text": "In that experiment participants had been presented with images of animals and tools, while EEG activity was recorded at 64 standard 10-10 locations, and single trials (stimulus presentations) could be classified as representing the category of animal or tool with an average accuracy of 72% overall seven participants.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 275, "end_pos": 283, "type": "METRIC", "confidence": 0.9975835084915161}]}, {"text": "The classification methods used were an adaptive time/frequency window optimisation (, a supervised spatial component signal decomposition (Common Spatial Patterns,) that yielded measures of neural activity based on signal power, and a supportvector machine).", "labels": [], "entities": []}, {"text": "The replication experiment reported here was carried outwith two participants, and used the same task and materials, while simultaneously recording with a 306-channel MEG system (204 gradiometers, 102 magnetometers) and a high-density 124-channel EEG system.", "labels": [], "entities": []}, {"text": "This data was then analysed using the same machine learning methods as previously, but varying the number and type of input signals, and using dimensionality reduction to address increased dimensionality.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two male native speakers of Italian took part in the study, aged 30 and 47.", "labels": [], "entities": []}, {"text": "Both were right-handed with corrected or normal vision.", "labels": [], "entities": [{"text": "corrected or normal vision", "start_pos": 28, "end_pos": 54, "type": "METRIC", "confidence": 0.6808061376214027}]}, {"text": "Participants in this study receive compensation of 7 euros per hour.", "labels": [], "entities": []}, {"text": "The experiment is conducted under the approval of the ethics committee at the University of Trento, and participants gave informed consent.", "labels": [], "entities": []}, {"text": "The participants were asked to perform a silent naming task on grey-scale images of 30 landmammals and 30 work tools.", "labels": [], "entities": [{"text": "silent naming task", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7745532989501953}]}, {"text": "Each stimulus was presented between four and six times, in randomised order.", "labels": [], "entities": []}, {"text": "The participants satin a relaxed upright posi-tion 1.5m from a projector screen in moderate lighting conditions.", "labels": [], "entities": []}, {"text": "Images were presented on a medium grey background and fell within a 6 degree viewing angle.", "labels": [], "entities": []}, {"text": "The task duration was split into five blocks and the participants were given the choice to pause between each.", "labels": [], "entities": []}, {"text": "The cumulative task time did not exceed 45 minutes.", "labels": [], "entities": []}, {"text": "Each trial began with the presentation of a fixation cross for 0.25s, followed by the stimulus image, a further fixation cross for 0.75s and a blank screen for 1s.", "labels": [], "entities": []}, {"text": "Participants were instructed to silently name the object represented in their native tongue (Italian), using the first appropriate label that came to mind, and to press the keyboard space-bar with the left-hand to indicate they had found an appropriate word.", "labels": [], "entities": []}, {"text": "If the participant could not think of a suitable label, they were asked not to make a response.", "labels": [], "entities": []}, {"text": "The image remained on the screen until the participant responded, or until a time-out of three seconds was reached.", "labels": [], "entities": []}, {"text": "The participants were asked to keep still during the task, and to avoid eye-movements and facial muscle activity in particular, except during the blank period.", "labels": [], "entities": []}, {"text": "The materials were chosen to represent welldefined semantic categories and to minimise nonsemantic, associative confounds.", "labels": [], "entities": []}, {"text": "The set of 30 land mammals were chosen to be both non-domesticated and non-threatening, to avoid emotional valence whether positive (e.g. pets) or negative (e.g. predators).", "labels": [], "entities": []}, {"text": "Thirty hardware and garden implements were chosen as genuine work tools.", "labels": [], "entities": []}, {"text": "Appropriate photographs were sourced from the internet, and normalised visually: each image file measured 300 pixels square; the image proper was converted to greyscale, superimposed on a homogeneous light-grey background and had maximal horizontal and vertical dimensions of 250 pixels; image contrast was normalised.", "labels": [], "entities": []}, {"text": "The concepts represented are listed below.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification accuracy, participant 1  Type (available signals) 60 ch. all ch. 60 cp.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9335891008377075}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9674851298332214}]}, {"text": " Table 2: Classification accuracy, participant 2  Type (available signals) 60 ch. all ch. 60 cp.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9266127943992615}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9707279801368713}]}]}