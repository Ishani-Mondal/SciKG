{"title": [{"text": "EmotiBlog: a finer-grained and more precise learning of subjectivity expression models", "labels": [], "entities": [{"text": "EmotiBlog", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9221034049987793}]}], "abstractContent": [{"text": "The exponential growth of the subjective information in the framework of the Web 2.0 has led to the need to create Natural Language Processing tools able to analyse and process such data for multiple practical applications.", "labels": [], "entities": []}, {"text": "They require training on specifically annotated corpora, whose level of detail must be fine enough to capture the phenomena involved.", "labels": [], "entities": []}, {"text": "This paper presents EmotiBlog-a fine-grained annotation scheme for subjectivity.", "labels": [], "entities": []}, {"text": "We show the manner in which it is built and demonstrate the benefits it brings to the systems using it for training, through the experiments we carried out on opinion mining and emotion detection.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 159, "end_pos": 173, "type": "TASK", "confidence": 0.8586794137954712}, {"text": "emotion detection", "start_pos": 178, "end_pos": 195, "type": "TASK", "confidence": 0.832799106836319}]}, {"text": "We employ corpora of different textual genres-a set of annotated reported speech extracted from news articles, the set of news titles annotated with polarity and emotion from the SemEval 2007 (Task 14) and ISEAR, a corpus of real-life self-expressed emotion.", "labels": [], "entities": [{"text": "SemEval 2007 (Task 14)", "start_pos": 179, "end_pos": 201, "type": "DATASET", "confidence": 0.6941391825675964}]}, {"text": "We also show how the model built from the EmotiBlog annotations can be enhanced with external resources.", "labels": [], "entities": [{"text": "EmotiBlog annotations", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.9232810437679291}]}, {"text": "The results demonstrate that EmotiBlog, through its structure and annotation paradigm, offers high quality training data for systems dealing both with opinion mining, as well as emotion detection .", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 151, "end_pos": 165, "type": "TASK", "confidence": 0.7929319739341736}, {"text": "emotion detection", "start_pos": 178, "end_pos": 195, "type": "TASK", "confidence": 0.8260122835636139}]}], "introductionContent": [{"text": "The exponential growth of the subjective information with Web 2.0 created the need to develop new Natural Language Processing (NLP) tools to automatically process and manage the content available on the Internet.", "labels": [], "entities": []}, {"text": "Apart from the traditional textual genres, at present we have new ones such as blogs, forums and reviews.", "labels": [], "entities": []}, {"text": "The main difference between them is that the latter are predominantly subjective, containing personal judgments.", "labels": [], "entities": []}, {"text": "At the moment, NLP tools and methods for analyzing objective information have a better performance than the new ones the research community is creating for managing the subjective content.", "labels": [], "entities": []}, {"text": "The survey called \"The State of the Blogosphere 2009\", published by Technorati 1 , demonstrates that users are blogging more than ever.", "labels": [], "entities": []}, {"text": "Furthermore, in contrast to the general idea about bloggers, each day it is more and more the number of professionals who decide to use this means of communication, contradicting the common belief about the predominance of an informal editing ( . Due to the growing interest in this text type, the subjective data of the Web is increasing on a daily basis, becoming a reflection of people's opinion about a wide range of topics.).", "labels": [], "entities": []}, {"text": "Blogs represent an important source of real-time, unbiased information, useful for the development of many applications for concrete purposes.", "labels": [], "entities": []}, {"text": "Given the proved importance of automatically processing this data, anew task has appeared in NLP task, dealing with the treatment of subjective data: Sentiment Analysis (SA).", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 150, "end_pos": 173, "type": "TASK", "confidence": 0.784908002614975}]}, {"text": "The main objective of this paper is to present EmotiBlog ( ), a fine-grained annotation scheme for labeling subjectivity in the new textual genres.", "labels": [], "entities": []}, {"text": "Subjectivity can be reflected in text through expressions of emotions beliefs, views (a way of considering something) and opinions, generally denominated \"private states\", not open to verification.", "labels": [], "entities": []}, {"text": "We performed a series of experiments focused on demonstrating that EmotiBlog represents a step forward to previous research in this field; its use allows a finer-grained and more precise learning of subjectivity expression models.", "labels": [], "entities": []}, {"text": "Starting form) we created an annotation schema able to capture a wide range and key elements, which give subjectivity, moving a step forward the mere polarity recognition.", "labels": [], "entities": []}, {"text": "In particular, the experiments concern expressions of emotion, as a finer-grained analysis of affect in text and a subsequent task to opinion mining (OM) and classification.", "labels": [], "entities": [{"text": "opinion mining (OM)", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.8450738847255707}]}, {"text": "To that aim, we employ corpora of different textual genres-a set of annotated reported speech extracted from news articles (denominated JRC quotes) ( and the set of news titles annotated with polarity and emotion from the, as well as a corpus of real-life selfexpressed emotion entitled ISEAR ().", "labels": [], "entities": [{"text": "JRC quotes", "start_pos": 136, "end_pos": 146, "type": "DATASET", "confidence": 0.8986606895923615}]}, {"text": "We subsequently show, through the quality of the results obtained, that EmotiBlog, through its structure and annotation paradigm, offers high quality training for systems dealing both with opinion mining, as well as emotion detection.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 189, "end_pos": 203, "type": "TASK", "confidence": 0.7964993417263031}, {"text": "emotion detection", "start_pos": 216, "end_pos": 233, "type": "TASK", "confidence": 0.8116607069969177}]}], "datasetContent": [{"text": "In order to evaluate the appropriateness of the EmotiBlog annotation scheme and to prove that the fine-grained level it aims at has a positive impact on the performance of the systems employing it as training, we performed several experiments.", "labels": [], "entities": []}, {"text": "Given that a) EmotiBlog contains annotations for individual words, as well as for multi-word expressions and at a sentence level, and b) they are labeled with polarity, but also emotion, our experiments show how the annotated elements can be used as training for the opinion mining and polarity classification task, as well as for emotion detection.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 267, "end_pos": 281, "type": "TASK", "confidence": 0.7667029201984406}, {"text": "polarity classification task", "start_pos": 286, "end_pos": 314, "type": "TASK", "confidence": 0.7968749205271403}, {"text": "emotion detection", "start_pos": 331, "end_pos": 348, "type": "TASK", "confidence": 0.734310656785965}]}, {"text": "Moreover, taking into consideration the fact that EmotiBlog labels the intensity level of the annotated elements, we performed a brief experiment on determining the sentiment intensity, measured on a three-level scale: low, medium and high.", "labels": [], "entities": []}, {"text": "In order to perform these three different evaluations, we chose three different corpora.", "labels": [], "entities": []}, {"text": "The first one is a collection of quotes (reported speech) from newspaper articles presented in (, enriched with the manual fine-grained Finally, the third one is a corpus of self-reported emotional response -ISEAR ().", "labels": [], "entities": [{"text": "ISEAR", "start_pos": 208, "end_pos": 213, "type": "METRIC", "confidence": 0.7147884368896484}]}, {"text": "The intensity classification task is evaluated only on the second corpus, given that it is the only one in which scores between -100 and 0 and 0 and 100, respectively, are given for the polarity of the titles.", "labels": [], "entities": [{"text": "intensity classification", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6923363953828812}]}, {"text": "In order to evaluate the performance of the models extracted from the features of the annotations in EmotiBlog, we performed different tests.", "labels": [], "entities": [{"text": "EmotiBlog", "start_pos": 101, "end_pos": 110, "type": "DATASET", "confidence": 0.9381802082061768}]}, {"text": "The first one regarded the evaluation of the polarity and intensity classification task using the Emoitblog I and II constructed models on two test sets -the JRC quotes collection and the SemEval 2007 Task Number 14 test set.", "labels": [], "entities": [{"text": "polarity and intensity classification task", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.6883056163787842}, {"text": "JRC quotes collection", "start_pos": 158, "end_pos": 179, "type": "DATASET", "confidence": 0.9661124547322592}, {"text": "SemEval 2007 Task Number 14 test set", "start_pos": 188, "end_pos": 224, "type": "DATASET", "confidence": 0.6810439654758998}]}, {"text": "Since the quotes often contain more than a sentence, we consider the polarity and intensity of the entire quote as the most frequent result in each class, corresponding to its constituent sentences.", "labels": [], "entities": []}, {"text": "Also, given the fact that the SemEval Affective Text headlines were given intensity values between -100 and 100, we mapped the values contained in the Gold Standard of the task into three categories: [-100, -67] is high (value 3 in intensity) and negative (value -1 in polarity),] medium negative and is low negative.", "labels": [], "entities": [{"text": "SemEval Affective Text headlines", "start_pos": 30, "end_pos": 62, "type": "DATASET", "confidence": 0.6233640909194946}, {"text": "Gold Standard", "start_pos": 151, "end_pos": 164, "type": "DATASET", "confidence": 0.732395738363266}]}, {"text": "The values between [1 and 100] are mapped in the same manner to the positive category.", "labels": [], "entities": []}, {"text": "0 was considered objective, so containing the value 0 for intensity.", "labels": [], "entities": [{"text": "intensity", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9842851758003235}]}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "Results for polarity and intensity classification using the models built from the EmotiBlog annotations The results shown in show a significantly high improvement over the results obtained in the SemEval task in 2007.", "labels": [], "entities": [{"text": "intensity classification", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.778977632522583}, {"text": "EmotiBlog annotations", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.9201560914516449}]}, {"text": "This is explainable, on the one hand, by the fact that sys-8 http://www.cs.waikato.ac.nz/ml/weka/ tems performing the opinion task did not have at their disposal the lexical resources for opinion employed in the EmotiBlog II model, but also because of the fact that they did not use machine learning on a corpus comparable to EmotiBlog (as seen from the results obtained when using solely the EmotiBlog I corpus).", "labels": [], "entities": [{"text": "EmotiBlog", "start_pos": 326, "end_pos": 335, "type": "DATASET", "confidence": 0.9672114253044128}, {"text": "EmotiBlog I corpus", "start_pos": 393, "end_pos": 411, "type": "DATASET", "confidence": 0.9177859624226888}]}, {"text": "Compared to the NTCIR 8 Multilingual Analysis Task this year, we obtained significant improvements in precision, with a recall that is comparable to most of the participating systems.", "labels": [], "entities": [{"text": "NTCIR 8 Multilingual Analysis Task", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.7766018390655518}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9996389150619507}, {"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.999580442905426}]}, {"text": "In the second experiment, we tested the performance of emotion classification using the two models built using EmotiBlog on the three corpora -JRC quotes, SemEval 2007 Task No.14 test set and the ISEAR corpus.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.8069486320018768}, {"text": "EmotiBlog", "start_pos": 111, "end_pos": 120, "type": "DATASET", "confidence": 0.925438642501831}, {"text": "JRC quotes", "start_pos": 143, "end_pos": 153, "type": "DATASET", "confidence": 0.859626978635788}, {"text": "SemEval 2007 Task No.14 test set", "start_pos": 155, "end_pos": 187, "type": "DATASET", "confidence": 0.6690728068351746}, {"text": "ISEAR corpus", "start_pos": 196, "end_pos": 208, "type": "DATASET", "confidence": 0.8985568583011627}]}, {"text": "The JRC quotes are labeled using EmotiBlog; however, the other two are labeled with a small set of emotions -6 in the case of the SemEval data (joy, surprise, anger, fear, sadness, disgust) and 7 in ISEAR (joy, sadness, anger, fear, guilt, shame, disgust).", "labels": [], "entities": [{"text": "EmotiBlog", "start_pos": 33, "end_pos": 42, "type": "DATASET", "confidence": 0.9557384252548218}, {"text": "SemEval data", "start_pos": 130, "end_pos": 142, "type": "DATASET", "confidence": 0.7270493656396866}, {"text": "ISEAR", "start_pos": 199, "end_pos": 204, "type": "METRIC", "confidence": 0.5019375085830688}]}, {"text": "Moreover, the SemEval data contains more than one emotion per title in the Gold Standard, therefore we consider as correct any of the classifications containing one of them.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.9695228040218353}]}, {"text": "In order to unify the results and obtain comparable evaluations, we assessed the performance of the system using the alternative dimensional structures defined in.", "labels": [], "entities": []}, {"text": "The ones not overlapping with the category of any of the 8 different emotions in SemEval and ISEAR are considered as \"Other\" and are not included either in the training, nor test set.", "labels": [], "entities": []}, {"text": "The results of the evaluation are presented in.", "labels": [], "entities": []}, {"text": "Results for emotion classification using the models built from the EmotiBlog annotations.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.8310768306255341}, {"text": "EmotiBlog annotations", "start_pos": 67, "end_pos": 88, "type": "DATASET", "confidence": 0.9429513812065125}]}, {"text": "The best results for emotion detection were obtained for the \"anger\" category, where the precision was around 35 percent, fora recall of 19 percent.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.8088292479515076}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9993646740913391}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9994069337844849}]}, {"text": "The worst results obtained were for the ISEAR category of \"shame\", where precision was around 12 percent, with a recall of 15 per-cent.", "labels": [], "entities": [{"text": "ISEAR", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.6739511489868164}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9998266100883484}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9995368719100952}]}, {"text": "We believe this is due to the fact that the latter emotion is a combination of more complex affective states and it can be easily misclassified to other categories of emotion.", "labels": [], "entities": []}, {"text": "Moreover, from the analysis performed on the errors, we realized that many of the affective phenomena presented were more explicit in the case of texts expressing strong emotions such as \"joy\" and \"anger\", and were mostly related to common-sense interpretation of the facts presented in the weaker ones.", "labels": [], "entities": []}, {"text": "As it can be seen in, results for the texts pertaining to the news category obtain better results, most of all news titles.", "labels": [], "entities": []}, {"text": "This is due to the fact that such texts, although they contain a few words, have a more direct and stronger emotional charge than direct speech (which maybe biased by the need to be diplomatic, find the best suited words etc.).", "labels": [], "entities": []}, {"text": "Finally, the error analysis showed that emotion that is directly reported by the persons experiencing is more \"hidden\", in the use of words carrying special signification or related to general human experience.", "labels": [], "entities": []}, {"text": "This fact makes emotion detection in such texts a harder task.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8211021721363068}]}, {"text": "Nevertheless, the results in all corpora are comparable, showing that the approach is robust enough to handle different text types.", "labels": [], "entities": []}, {"text": "All in all, the results obtained using the fine and coarse-grained annotations in EmotiBlog increased the performance of emotion detection as compared to the systems in the SemEval competition.", "labels": [], "entities": [{"text": "EmotiBlog", "start_pos": 82, "end_pos": 91, "type": "DATASET", "confidence": 0.9155954122543335}, {"text": "emotion detection", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.7866091430187225}]}], "tableCaptions": [{"text": " Table 3. Results for polarity and intensity classifi- cation using the models built from the EmotiBlog  annotations", "labels": [], "entities": [{"text": "EmotiBlog  annotations", "start_pos": 94, "end_pos": 116, "type": "DATASET", "confidence": 0.9376223385334015}]}, {"text": " Table 4. Again,  the values I and II correspond to the models  EmotiBlog I and II. The \"Emotions\" category  contains the following emotions: joy, sadness,  anger, fear, guilt, shame, disgust, surprise.", "labels": [], "entities": []}, {"text": " Table 4. Results for emotion classification using the  models built from the EmotiBlog annotations.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8332434594631195}, {"text": "EmotiBlog annotations", "start_pos": 78, "end_pos": 99, "type": "DATASET", "confidence": 0.9419124722480774}]}]}