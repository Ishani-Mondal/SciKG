{"title": [{"text": "Robust and Efficient Page Rank for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Efficient Page Rank", "start_pos": 11, "end_pos": 30, "type": "METRIC", "confidence": 0.8543240030606588}, {"text": "Word Sense Disambiguation", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6167156795660654}]}], "abstractContent": [{"text": "Graph-based methods that are en vogue in the social network analysis area, such as centrality models, have been recently applied to linguistic knowledge bases, including unsupervised Word Sense Disam-biguation.", "labels": [], "entities": []}, {"text": "Although the achievable accuracy is rather high, the main drawback of these methods is the high computational demanding whenever applied to the large scale sense repositories.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9609950184822083}]}, {"text": "In this paper an adaptation of the PageRank algorithm recently proposed for Word Sense Dis-ambiguation is presented that preserves the reachable accuracy while significantly reducing the requested processing time.", "labels": [], "entities": [{"text": "Word Sense Dis-ambiguation", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.6073121428489685}, {"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9548060297966003}]}, {"text": "Experimental analysis over well-known benchmarks will be presented in the paper and the results confirm our hypothesis.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical ambiguity is a fundamental aspect of natural language.", "labels": [], "entities": [{"text": "Lexical ambiguity", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8707240521907806}]}, {"text": "Word Sense Disambiguation (WSD) investigates methods to automatically determine the intended sense of a word in a given context according to a predefined set of sense definitions, provided by a semantic lexicon.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7802856216828028}]}, {"text": "Intuitively, WSD can be usefully exploited in a variety of NLP (e.g. Machine Translation () and Information Retrieval tasks such as ad hoc retrieval) or Question Answering ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9142271280288696}, {"text": "Machine Translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7924196422100067}, {"text": "Information Retrieval tasks", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.8026892940203348}, {"text": "Question Answering", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.8374614417552948}]}, {"text": "However controversial results have been often obtained, as for example the study on text classification reported in ().", "labels": [], "entities": [{"text": "text classification", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.8381641209125519}]}, {"text": "The impact of WSD on IR tasks is still an open issue and large scale assessment is needed.", "labels": [], "entities": [{"text": "WSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9561185836791992}, {"text": "IR tasks", "start_pos": 21, "end_pos": 29, "type": "TASK", "confidence": 0.9198596179485321}]}, {"text": "For this reason, unsupervised approaches to inductive WSD are appealing.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.856373131275177}]}, {"text": "In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in IR research.", "labels": [], "entities": [{"text": "IR", "start_pos": 218, "end_pos": 220, "type": "TASK", "confidence": 0.9781988859176636}]}, {"text": "In recent years different approaches to Word Sense Disambiguation task have been evaluated through comparative campaigns, such as the earlier Senseval evaluation exercises.", "labels": [], "entities": [{"text": "Word Sense Disambiguation task", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.8035854548215866}]}, {"text": "() or the most recent ().", "labels": [], "entities": []}, {"text": "The best accuracy is reached by WSD based on supervised methods that exploit large amounts of hand-tagged data to train discriminative or generative disambiguation models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9989283680915833}, {"text": "WSD", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.8902984857559204}, {"text": "generative disambiguation", "start_pos": 138, "end_pos": 163, "type": "TASK", "confidence": 0.8955673575401306}]}, {"text": "The common alternative to supervised systems are knowledgebased WSD systems that try to exploit information made available by large Lexical Knowledge Bases (LKB).", "labels": [], "entities": []}, {"text": "They enable the definition of several metrics to estimate semantic similarity (e.g. or (Agirre and, ( ) methods) and then use it to rank the alternative senses according to the incoming context.", "labels": [], "entities": []}, {"text": "Moreover they make available large relationship sets between pairs of lexical meaning units, such as synonymy, hyponymy or meronymy.", "labels": [], "entities": []}, {"text": "The resulting networks represent at various grains and degrees of approximation models of the mental lexicons.", "labels": [], "entities": []}, {"text": "It is not by chance that early research on WSD based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in) for precise and fast disambiguation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9575868248939514}]}, {"text": "It has been more recently that graph-based methods for knowledge-based WSD have gained much attention in the NLP community,,,).", "labels": [], "entities": [{"text": "WSD", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.8255099654197693}]}, {"text": "In these methods a graph representation for senses (nodes) and relation (edges) is first built.", "labels": [], "entities": []}, {"text": "Then graph-based techniques that are sensible to the structural properties of the graph are used to find the best senses for words in the incoming contexts.", "labels": [], "entities": []}, {"text": "The relation employed by the different methods are of several types such as synonymy, antonymy but also co-occurrence based lexical similarity computed externally over a corpus.", "labels": [], "entities": []}, {"text": "These give rise to real-valued weights that determine large weighted directed graphs.", "labels": [], "entities": []}, {"text": "Usu-ally, the employed disambiguation is carried out by ranking the graph nodes.", "labels": [], "entities": []}, {"text": "Thus the concepts with highest ranks are assigned to the corresponding words.", "labels": [], "entities": []}, {"text": "In), a comparative analysis of different graph-based models over two well known WSD benchmarks is reported.", "labels": [], "entities": [{"text": "WSD", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.8758323192596436}]}, {"text": "In the paper two variants of the random surfer model as defined by PageRank model) are analyzed.", "labels": [], "entities": []}, {"text": "A special emphasis for the resulting computational efficiency is also posed there.", "labels": [], "entities": []}, {"text": "In particular, a variant called Personalized PageRank (P P R) is proposed) that tries to trade-off between the amount of the employed lexical information and the overall efficiency.", "labels": [], "entities": []}, {"text": "In synthesis, along the ideas of the Topic sensitive PageRank), PP R suggests that a proper initialization of the teleporting vector p suitably captures the context information useful to drive the random surfer PageRank model over the graph to converge towards the proper senses in fewer steps.", "labels": [], "entities": []}, {"text": "The basic idea behind the adoption of PP R is to impose a personalized vector that expresses the contexts of all words targeted by the disambiguation.", "labels": [], "entities": [{"text": "PP R", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.6849739402532578}]}, {"text": "This method improves on the complexity of the previously presented methods (e.g. () as it allows to contextualize the behaviors of PageRank over a sentence, without asking fora different graph: in this way the WordNet graph is always adopted, in a word or sentence oriented fashion.", "labels": [], "entities": []}, {"text": "Moreover, it is possible to avoid to rebuild a graph for each target word, as the entire sentence can be coded into the personalization vector.", "labels": [], "entities": []}, {"text": "In (Agirre and Soroa, 2009), a possible, and more accurate alternative, is also presented called PPR word2word (P P Rw2w) where a different personalization vector is used for each word in a sentence.", "labels": [], "entities": []}, {"text": "Although clearly less efficient in terms of time complexity, this approach guarantees the best accuracy, so that it can be considered the state-ofthe art in unsupervised WSD.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9992986917495728}, {"text": "WSD", "start_pos": 170, "end_pos": 173, "type": "TASK", "confidence": 0.8087126612663269}]}, {"text": "In this paper a different approach to personalization of the PageRank is presented, aiming at preserving the suitable efficiency of the sentence oriented PPR algorithm for WSD but achieving an accuracy at least as high as the PP Rw2w one.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 193, "end_pos": 201, "type": "METRIC", "confidence": 0.9988473653793335}]}, {"text": "We propose to use distributional evidence that can be automatically acquired from a corpus to define the topical information encoded by the personalization vector, in order to amplify the bias on the resulting PP Rand improve the performance of the sentence oriented version.", "labels": [], "entities": []}, {"text": "The intuition is that distributional evidence is able to cover the gap between word oriented usages of the PP R as for the PP Rw2w defined in, and its sentence oriented counterpart.", "labels": [], "entities": []}, {"text": "In this way we can preserve higher accuracy levels while limiting the number of PageRank runs, i.e. increasing efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9981139898300171}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first give a more detailed overview of the PageRank and Personalized PageRank algorithms in Section 2.", "labels": [], "entities": []}, {"text": "In Section, 3 a description of our distributional approach to the personalized PageRank is provided.", "labels": [], "entities": []}, {"text": "A comparative evaluation with respect to previous works is then reported in Section 4 while section 5 is left for conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of the proposed model was focused on two main aspects.", "labels": [], "entities": []}, {"text": "First we want to measure the impact of the topical expansion at sentence level on the accuracy reachable by the personalized PageRank PPR.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9989733695983887}, {"text": "PageRank PPR", "start_pos": 125, "end_pos": 137, "type": "DATASET", "confidence": 0.8766314387321472}]}, {"text": "This will be done also comparatively with the state of the art of unsupervised systems over a consolidated benchmark, i.e. Semeval 2007.", "labels": [], "entities": []}, {"text": "The adopted vector space has been acquired over a significant subset of the BNC 2.0 corpus, made of 923k sentences.", "labels": [], "entities": [{"text": "BNC 2.0 corpus", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.9407879312833151}]}, {"text": "The most frequent 200k words (i.e. the contextual features) were acquired through LSA.", "labels": [], "entities": []}, {"text": "The corpus has been processed with the LTH parser to obtain POS tags for every token.", "labels": [], "entities": []}, {"text": "Moreover, a dimensionality reduction factor of k = 100 was applied.", "labels": [], "entities": []}, {"text": "In subsection 4.1, a comparative analysis of the accuracy achieved in the disambiguation task is discussed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999315619468689}, {"text": "disambiguation task", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.9075673222541809}]}, {"text": "Subsection 4.2 presents a corresponding study of the execution times aiming to compare the relative efficiency of the methods and their application into a document semantic tagging task.", "labels": [], "entities": [{"text": "document semantic tagging task", "start_pos": 155, "end_pos": 185, "type": "TASK", "confidence": 0.736262172460556}]}, {"text": "The approaches proposed in Semeval 2007 can be partitioned into two major types.", "labels": [], "entities": []}, {"text": "The supervised or semi-supervised approaches and the unsupervised ones that rely usually on WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 92, "end_pos": 99, "type": "DATASET", "confidence": 0.9616725444793701}]}, {"text": "As the basic Page Rank as well as our LSA extension makes no use of sense labeled data, we will mainly focus on the comparative evaluation among unsupervised WSD systems.", "labels": [], "entities": []}, {"text": "In order to compare the quality of the proposed approach, the results of the personalized PageRank proposed in (Agirre and Soroa, 2009) over the same dataset are reported in).", "labels": [], "entities": []}, {"text": "The LSA UKB 1.7 and LSA UKB 3.0 show the rank of the model proposed in this paper.", "labels": [], "entities": [{"text": "LSA UKB 1.7", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8097891807556152}, {"text": "LSA UKB 3.0", "start_pos": 20, "end_pos": 31, "type": "DATASET", "confidence": 0.8408371011416117}]}, {"text": "formances are obtained according to the PPRw2w word oriented approach.", "labels": [], "entities": []}, {"text": "For sake of comparison we applied the LSAbased expansion to the Personalized Page Rankin a sentence oriented fashion (i.e., only one PageRank is run for all the target words of a sentence, PP R).", "labels": [], "entities": []}, {"text": "Notice that PP R models the context of the sentence with a single iterative run of PageRank, while PP Rw2w disambiguates each word with a dedicated PageRank.", "labels": [], "entities": []}, {"text": "The 1.7 configuration provides: Accuracy of the LSA-based sentence expansion PageRank model, as compared with the sentence (P P R) and word oriented (w2w) versions of the personalized PageRank over the Semeval 2007 datasets.", "labels": [], "entities": [{"text": "Semeval 2007 datasets", "start_pos": 202, "end_pos": 223, "type": "DATASET", "confidence": 0.8518540064493815}]}, {"text": "17x and 30g refer to the extended resources of WordNet 1.7 and 3.0, respectively.", "labels": [], "entities": [{"text": "WordNet 1.7", "start_pos": 47, "end_pos": 58, "type": "DATASET", "confidence": 0.92975714802742}]}, {"text": "the most efficient one as it runs the original PPR against a graph built around the only hyponymy relations among synsets.", "labels": [], "entities": []}, {"text": "We used the Senseval'02 and Senseval'03 datasets to fine tune parameters of our LSA model, that are: (1) the dimensionality cut k to derive the LSA space; (2) the threshold \u03c4 to determine the expansion dictionary in the LSA space for every POS tag (e.g. noun or adjectives), that may require different values; (3) the damping factor \u03b1 and (4) the number of iteration over the graph.", "labels": [], "entities": [{"text": "Senseval'03 datasets", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.8676691055297852}]}, {"text": "In (Agirre and Soroa, 2009) the suggested parameters are \u03b1 = 0.85 as the damping factor and 30 as the upper limit to the PageRank iterations.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.9280860424041748}]}, {"text": "We always adopted this setting to estimate the performances of the standard PP Rand PP Rw2w algorithms referred through U KB.", "labels": [], "entities": [{"text": "U KB", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.7871455252170563}]}, {"text": "Due the novel configuration of the graph that in our model also includes many other similar terms, the damping factor and the number of iterations have been re-estimated.", "labels": [], "entities": []}, {"text": "k has been set to 100 as different values did not seem to influence accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9984537363052368}]}, {"text": "We adopted fixed limits for sentence expansion where values from 20 up to 150 terms have been tested.", "labels": [], "entities": [{"text": "sentence expansion", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7820562720298767}]}, {"text": "The good scores obtained on the development set suggested that a number of iterations lower than 30 is in general enough to get good accuracy levels: 15 iterations, instead of 30, have been judged adequate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9991693496704102}]}, {"text": "Finally, on average, the total number of lexical items in the expanded sentence T (\u03c3) includes about 40% of nouns, 30% of verbs, 20% of adjectives and 10% of adverbs.", "labels": [], "entities": []}, {"text": "Finally, a damping factor \u03b1 = 0.98 has been used.", "labels": [], "entities": []}, {"text": "reports Precision, Recall and F1 scores of the different models as obtained over the test SemEval '07 data.", "labels": [], "entities": [{"text": "Precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9993259906768799}, {"text": "Recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9903246164321899}, {"text": "F1", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.9957590699195862}, {"text": "SemEval '07 data", "start_pos": 90, "end_pos": 106, "type": "DATASET", "confidence": 0.674584224820137}]}, {"text": "Every row pair compares the LSA model with the original corresponding UKB version over a given graph (from WN1.7 to WN30g).", "labels": [], "entities": [{"text": "UKB", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.9824199676513672}, {"text": "WN1.7", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.9670060276985168}, {"text": "WN30g", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.7535008788108826}]}, {"text": "For each model the accuracy corresponding to two iterations) is reported to analyze also the overall trend during PageRank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9993676543235779}, {"text": "PageRank", "start_pos": 114, "end_pos": 122, "type": "DATASET", "confidence": 0.9457084536552429}]}, {"text": "The best F1 scores between any pair are emphasized in bold, to comparatively asses the results.", "labels": [], "entities": [{"text": "F1", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.9995266199111938}]}, {"text": "As a confirmation of the outcome in), different lexical resources achieve different results.", "labels": [], "entities": []}, {"text": "In general by adopting the graph derived from WN3.0 (i.e. WN30 and WN30g) lower performance can be achieved.", "labels": [], "entities": [{"text": "WN3.0", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.9709262847900391}, {"text": "WN30", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9462121725082397}, {"text": "WN30g", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.8392914533615112}]}, {"text": "Moreover, the word-by-word model (last three columns for the w2w side of the is evidently superior.", "labels": [], "entities": []}, {"text": "Interestingly, almost on every type of graph and for every approach (sentence or word oriented) the LSA-based method outperforms the original UKB PPR.", "labels": [], "entities": [{"text": "UKB PPR", "start_pos": 142, "end_pos": 149, "type": "DATASET", "confidence": 0.978426069021225}]}, {"text": "This confirms that the impact of the topical information provided by the LSA expansion of the sentence is beneficial fora better use of the lexical graph.", "labels": [], "entities": []}, {"text": "An even more interesting outcome is that the improvement implied by the proposed LSA method on the sentence oriented model (i.e. the standard PPR method of) is higher, so that the difference between the performances of the PP Rw2w model are no longer strikingly better than the PP R one.", "labels": [], "entities": []}, {"text": "For example, on the simple WN1.7 hyponymy network the PP R \u2212 LSA100 3 method abolishes the gap of about 4% previously observed for the PPR-UKB model.", "labels": [], "entities": [{"text": "WN1.7 hyponymy network", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.9204118847846985}, {"text": "PP R \u2212 LSA100 3", "start_pos": 54, "end_pos": 69, "type": "METRIC", "confidence": 0.6377355456352234}]}, {"text": "When LSA is used, it seems that the wordby-word approach is no longer required.", "labels": [], "entities": []}, {"text": "On the contrary, in the WN17x case the best figure after 5 iterations is obtained by the PPR-LSA100 method instead of the w2w-LSA100 one (71.5% vs. 71.1%).", "labels": [], "entities": [{"text": "WN17x", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.8440821170806885}]}, {"text": "The good accuracy reachable by the sentence oriented strategy (i.e. LSA100 and w2w) is also very interesting as for the higher efficiency of the PPR approach with respect to the word-byword PP Rw2w one.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9986163377761841}]}], "tableCaptions": [{"text": " Table 1: Official Results over the Semeval'07  dataset. The * systems was presented in (Agirre", "labels": [], "entities": [{"text": "Semeval'07  dataset", "start_pos": 36, "end_pos": 55, "type": "DATASET", "confidence": 0.8282755315303802}, {"text": "Agirre", "start_pos": 89, "end_pos": 95, "type": "DATASET", "confidence": 0.9136956930160522}]}, {"text": " Table 2: Accuracy of the LSA-based sentence ex- pansion PageRank model, as compared with the  sentence (P P R) and word oriented (w2w) ver- sions of the personalized PageRank over the Se- meval 2007 datasets. 17x and 30g refer to the ex- tended resources of WordNet 1.7 and 3.0, respec- tively.", "labels": [], "entities": [{"text": "Se- meval 2007 datasets", "start_pos": 185, "end_pos": 208, "type": "DATASET", "confidence": 0.7415680706501007}]}, {"text": " Table 3: Accuracy of the LSA-based P P R model  when applied in a document oriented fashion on  the Semeval '07 dataset. LSA400 stands for the  size t of the applied sentence expansion T (\u03c3).", "labels": [], "entities": [{"text": "Semeval '07 dataset", "start_pos": 101, "end_pos": 120, "type": "DATASET", "confidence": 0.710823729634285}]}]}