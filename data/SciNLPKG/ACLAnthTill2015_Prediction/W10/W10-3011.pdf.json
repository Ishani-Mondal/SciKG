{"title": [{"text": "Exploiting Rich Features for Detecting Hedges and Their Scope", "labels": [], "entities": [{"text": "Detecting Hedges and Their Scope", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.9436177253723145}]}], "abstractContent": [{"text": "This paper describes our system about detecting hedges and their scope in natural language texts for our participation in CoNLL-2010 shared tasks.", "labels": [], "entities": [{"text": "CoNLL-2010 shared tasks", "start_pos": 122, "end_pos": 145, "type": "TASK", "confidence": 0.619136651357015}]}, {"text": "We formalize these two tasks as sequence labeling problems, and implement them using conditional random fields (CRFs) model.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.6499597579240799}]}, {"text": "In the first task, we use a greedy forward procedure to select features for the classifier.", "labels": [], "entities": []}, {"text": "These features include part-of-speech tag, word form, lemma, chunk tag of tokens in the sentence.", "labels": [], "entities": []}, {"text": "In the second task, our system exploits rich syntactic features about dependency structures and phrase structures, which achieves a better performance than only using the flat sequence features.", "labels": [], "entities": []}, {"text": "Our system achieves the third score in biological data set for the first task, and achieves 0.5265 F1 score for the second task.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9878962635993958}]}], "introductionContent": [{"text": "In recent years, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction.", "labels": [], "entities": [{"text": "detecting speculative and negative information from biomedical and natural language texts", "start_pos": 68, "end_pos": 157, "type": "TASK", "confidence": 0.8211299777030945}, {"text": "information extraction", "start_pos": 200, "end_pos": 222, "type": "TASK", "confidence": 0.8266982734203339}]}, {"text": "These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as), Negfinder (), and NegExpander (), to machine learning approaches, including semi-supervised methods, and supervised methods.", "labels": [], "entities": []}, {"text": "In this paper, we describe the machine learning system submitted to.", "labels": [], "entities": []}, {"text": "Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach.", "labels": [], "entities": []}, {"text": "In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task.", "labels": [], "entities": []}, {"text": "Our system follows the study of, but applies more refined feature selection.", "labels": [], "entities": []}, {"text": "In the first task, we use a greedy forward procedure to select features for the classifier.", "labels": [], "entities": []}, {"text": "In the second task, we exploit rich syntactic information to improve the performance of the model, from dependency structures and phrase structures.", "labels": [], "entities": []}, {"text": "A rule-based post processing procedure is used to eliminate the errors brought by the classifier for each task.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we briefly describe the task and the details of our system, including how to select features for the hedge cue detection system, and how to find the corresponding scope for each hedge cue.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7244149645169576}]}, {"text": "The experimental results are discussed in section 3.", "labels": [], "entities": []}, {"text": "In section 4 we put forward some conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Result of biological evaluation data set  without/with post processing", "labels": [], "entities": []}, {"text": " Table 4: Results of scope finding system with  different feature sets on abstract data set", "labels": [], "entities": [{"text": "scope finding", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9146966338157654}]}, {"text": " Table 5: Results of scope finding system with  gold-standard hedge cues", "labels": [], "entities": [{"text": "scope finding", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9561271965503693}]}, {"text": " Table 6: Results of scope finding system  with/without dependency features using both  gold-standard and predicated hedge cues", "labels": [], "entities": [{"text": "scope finding", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9341603815555573}]}]}