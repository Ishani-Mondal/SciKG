{"title": [{"text": "Towards a noisy-channel model of dysarthria in speech recognition", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7699320614337921}]}], "abstractContent": [{"text": "Modern automatic speech recognition is ineffective at understanding relatively unintelligi-ble speech caused by neuro-motor disabilities collectively called dysarthria.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.7376019159952799}]}, {"text": "Since dysarthria is primarily an articulatory phenomenon, we are collecting a database of vocal tract measurements during speech of individuals with cerebral palsy.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate that articulatory knowledge can remove ambiguities in the acoustics of dysarthric speakers by reducing entropy relatively by 18.3%, on average.", "labels": [], "entities": []}, {"text": "Furthermore, we demonstrate that dysarthric speech is more precisely portrayed as a noisy-channel distortion of an abstract representation of articulatory goals, rather than as a distortion of non-dysarthric speech.", "labels": [], "entities": []}, {"text": "We discuss what implications these results have for our ongoing development of speech systems for dysarthric speakers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dysarthria is a set of congenital and traumatic neuro-motor disorders that impair the physical production of speech and affects approximately 0.8% of individuals in North America (.", "labels": [], "entities": []}, {"text": "Causes of dysarthria include cerebral palsy (CP), multiple sclerosis, Parkinson's disease, and amyotrophic lateral sclerosis (ALS).", "labels": [], "entities": []}, {"text": "These impairments reduce or remove normal control of the primary vocal articulators but do not affect the abstract production of meaningful, syntactically correct language.", "labels": [], "entities": []}, {"text": "The neurological origins of dysarthria involve damage to the cranial nerves that control the speech articulators).", "labels": [], "entities": []}, {"text": "Spastic dysarthria, for instance, is partially caused by lesions in the facial and hypoglossal nerves, which control the jaw and tongue respectively, resulting in slurred speech and a less differentiable vowel space ().", "labels": [], "entities": []}, {"text": "Similarly, damage to the glossopharyngeal nerve can reduce control over vocal fold vibration (i.e., phonation), resulting in guttural or grating raspiness.", "labels": [], "entities": []}, {"text": "Inadequate control of the soft palate caused by disruption of the vagus nerve may lead to a disproportionate amount of air released through the nose during speech (i.e., hypernasality).", "labels": [], "entities": []}, {"text": "Unfortunately, traditional automatic speech recognition (ASR) is incompatible with dysarthric speech, often rendering such software inaccessible to those whose neuro-motor disabilities might make other forms of interaction (e.g., keyboards, touch screens) laborious.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.837630420923233}]}, {"text": "Traditional representations in ASR such as hidden Markov models (HMMs) trained for speaker independence that achieve 84.8% word-level accuracy for non-dysarthric speakers might achieve less than 4.5% accuracy given severely dysarthric speech on short sentences.", "labels": [], "entities": [{"text": "ASR", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9883739948272705}, {"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.8547138571739197}, {"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9749497175216675}]}, {"text": "Our research group is currently developing new ASR models that incorporate empirical knowledge of dysarthric articulation for use in assistive applications.", "labels": [], "entities": [{"text": "ASR", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9931117296218872}]}, {"text": "Although these models have increased accuracy, the disparity is still high.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9993252754211426}, {"text": "disparity", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9778277277946472}]}, {"text": "Our aim is to understand why ASR fails for dysarthric speakers by understanding the acoustic and articulatory nature of their speech.", "labels": [], "entities": [{"text": "ASR", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9969615340232849}]}, {"text": "In this paper, we cast the speech-motor interface within the mathematical framework of the noisychannel model.", "labels": [], "entities": []}, {"text": "This is motivated by the charac-terization of dysarthria as a distortion of parallel biological pathways that corrupt motor signals before execution (), as in the examples cited above.", "labels": [], "entities": []}, {"text": "Within this information-theoretic framework, we aim to infer the nature of the motor signal distortions given appropriate measurements of the vocal tract.", "labels": [], "entities": []}, {"text": "That is, we ask the following question: Is dysarthric speech a distortion of typical speech, or are they both distortions of some common underlying representation?", "labels": [], "entities": []}], "datasetContent": [{"text": "First, in section 4.1, we ask whether the incorporation of articulatory data is theoretically useful in reducing uncertainty in dysarthric speech.", "labels": [], "entities": []}, {"text": "Second, in section 4.2, we ask which of the two noisy channel models in best describe the observed behaviour of dysarthric speech.", "labels": [], "entities": []}, {"text": "Data for this study are collected as described as in section 2.", "labels": [], "entities": []}, {"text": "Here, we use data from three dysarthric speakers with cerebral palsy (males M01 and M04, and female F03), as well as their age-and gendermatched counterparts from the general population (males MC01 and MC03, and female FC02).", "labels": [], "entities": []}, {"text": "For this study we restrict our analysis to 100 phrases uttered in common by all six speakers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Percentage of phoneme substitution (SUB) and  deletion (DEL) errors in word-initial (i), word-medial  (m), and word-final (f) positions across categories of  manner for dysarthric data.", "labels": [], "entities": [{"text": "Percentage of phoneme substitution (SUB) and  deletion (DEL) errors", "start_pos": 10, "end_pos": 77, "type": "METRIC", "confidence": 0.8489869695443374}]}, {"text": " Table 3: Differential entropy, in nats, across dysarthric  and control speakers for acoustic ac and articulatory ar  data.", "labels": [], "entities": []}, {"text": " Table 4: Mutual information I(Ac; Ar) of acoustics and  articulation for dysarthric and control subjects, across  phonological manners of articulation.", "labels": [], "entities": [{"text": "Mutual information I(Ac; Ar)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.6766405031085014}]}]}