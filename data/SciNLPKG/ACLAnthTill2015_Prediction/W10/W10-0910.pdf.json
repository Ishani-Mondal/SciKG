{"title": [{"text": "Unsupervised techniques for discovering ontology elements from Wikipedia article links", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an unsupervised and unrestricted approach to discovering an infobox like on-tology by exploiting the inter-article links within Wikipedia.", "labels": [], "entities": []}, {"text": "It discovers new slots and fillers that may not be available in the Wikipedia infoboxes.", "labels": [], "entities": [{"text": "Wikipedia infoboxes", "start_pos": 68, "end_pos": 87, "type": "DATASET", "confidence": 0.9468602240085602}]}, {"text": "Our results demonstrate that there are certain types of properties that are evident in the link structure of resources like Wikipedia that can be predicted with high accuracy using little or no linguistic analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9903139472007751}]}, {"text": "The discovered properties can be further used to discover a class hierarchy.", "labels": [], "entities": []}, {"text": "Our experiments have focused on analyzing people in Wikipe-dia, but the techniques can be directly applied to other types of entities in text resources that are rich with hyperlinks.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the biggest challenges faced by the Semantic Web vision is the availability of structured data that can be published as RDF.", "labels": [], "entities": []}, {"text": "One approach is to develop techniques to translate information in spreadsheets, databases, XML documents and other traditional data formats into RDF (.", "labels": [], "entities": []}, {"text": "Another is to refine the technology needed to extract structured information from unstructured free text).", "labels": [], "entities": []}, {"text": "For both approaches, there is a second problem that must be addressed: do we start with an ontology or small catalog of ontologies that will be used to encode the data or is extracting the right ontology part of the problem.", "labels": [], "entities": []}, {"text": "We describe exploratory work on a system that can discover ontological elements as well as data from a free text with embedded hyperlinks.", "labels": [], "entities": []}, {"text": "Wikipedia is a remarkable and rich online encyclopedia with a wealth of general knowledge about varied concepts, entities, events and facts in the world.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9237256050109863}]}, {"text": "Its size and coverage make it a valuable resource for extracting information about different entities and concepts.", "labels": [], "entities": [{"text": "coverage", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9609551429748535}]}, {"text": "Wikipedia contains both free text and structured information related to concepts in the form of infoboxes, category hierarchy and inter-article links.", "labels": [], "entities": []}, {"text": "Infoboxes are the most structured form and are composed of a set of subjectattribute-value triples that summarize or highlight the key features of the concept or subject of the article.", "labels": [], "entities": []}, {"text": "Resources like DBpedia ( and) have harvested this structured data and have made it available as triples for semantic querying.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9108147025108337}]}, {"text": "While infoboxes area readily available source of structured data, the free text of the article contains much more information about the entity.", "labels": [], "entities": []}, {"text": "unified the state of the art approaches in natural language processing and knowledge representation in their prototype system for understanding free text.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6593127648035685}, {"text": "knowledge representation", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.7440904080867767}]}, {"text": "Text resources which are rich in hyperlinks especially to knowledge based resources (such as encyclopedias or dictionaries) have additional information encoded in the form of links, which can be used to complement the existing systems for text understanding and knowledge discovery.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 239, "end_pos": 257, "type": "TASK", "confidence": 0.7432053983211517}, {"text": "knowledge discovery", "start_pos": 262, "end_pos": 281, "type": "TASK", "confidence": 0.7174478769302368}]}, {"text": "Furthermore, systems such as Wikify ( can be employed to link words in free text to knowledge resources like Wikipedia and thus enrich the free text with hyperlinks.", "labels": [], "entities": []}, {"text": "We describe an approach for unsupervised ontology discovery from links in the free text of the Wikipedia articles, without specifying a relation or set of relations in advance.", "labels": [], "entities": [{"text": "ontology discovery", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7343166768550873}]}, {"text": "We first identify candidate slots and fillers for an entity, then classify en-tities and finally derive a class hierarchy.", "labels": [], "entities": []}, {"text": "We have evaluated our approach for the Person class, but it can be easily generalized to other entity types such as organizations, places, and products.", "labels": [], "entities": []}, {"text": "The techniques we describe are not suggested as alternatives to natural language understanding or information extraction, but as a source for additional evidence that can be used to extract ontological elements and relations from the kind of text found in Wikipedia and other heavily-linked text collections.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.7094230651855469}, {"text": "information extraction", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.7416248619556427}]}, {"text": "This approach might be particularly useful in \"slot fillings\" tasks like the one in the Knowledge Base Population track at the 2009 Text Analysis Conference.", "labels": [], "entities": [{"text": "slot fillings\" tasks", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.810222752392292}, {"text": "Knowledge Base Population track at the 2009 Text Analysis Conference", "start_pos": 88, "end_pos": 156, "type": "DATASET", "confidence": 0.8312203466892243}]}, {"text": "We see several contributions that this work has to offer: \u2022 Unsupervised and unrestricted ontology discovery.", "labels": [], "entities": [{"text": "ontology discovery", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7478337585926056}]}, {"text": "We describe an automatic approach that does not require a predefined list of relations or training data.", "labels": [], "entities": []}, {"text": "The analysis uses inter-article links in the text and does not depend on existing infoboxes, enabling it to suggest slots and fillers that do not exist in any extant infoboxes.", "labels": [], "entities": []}, {"text": "We use WordNet) nodes to represent and label slots enabling us to exploit WordNet's hypernym and hyponym relations as a property hierarchy.", "labels": [], "entities": [{"text": "WordNet) nodes", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.9129698872566223}]}, {"text": "\u2022 Entity classification and class labeling.", "labels": [], "entities": [{"text": "Entity classification", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.8718386292457581}, {"text": "class labeling", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.6731470078229904}]}, {"text": "We introduce anew feature set for entity classification, i.e. the discovered ranked slots, which performs better than other feature sets extracted from Wikipedia.", "labels": [], "entities": [{"text": "entity classification", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.7174390405416489}]}, {"text": "We also present an approach for assigning meaningful class label vectors using WordNet nodes.", "labels": [], "entities": [{"text": "WordNet nodes", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9200826585292816}]}, {"text": "\u2022 Deriving a class hierarchy.", "labels": [], "entities": []}, {"text": "We have developed an approach for deriving a class hierarchy based on the ranked slot similarity between classes and the label vectors.", "labels": [], "entities": []}, {"text": "In the remainder of the paper we describe the details of the approach, mention closely related work, present and discuss preliminary results and provide some conclusions and possible next steps.", "labels": [], "entities": []}, {"text": "shows our ontology discovery framework and its major steps.", "labels": [], "entities": []}, {"text": "We describe each step in the rest of this section.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments and evaluation we used the Wikipedia dump from March 2008 and the DBpedia infobox ontology created from Wikipedia infoboxes using hand-generated mappings).", "labels": [], "entities": [{"text": "Wikipedia dump from March 2008", "start_pos": 47, "end_pos": 77, "type": "DATASET", "confidence": 0.9726601839065552}, {"text": "DBpedia infobox ontology", "start_pos": 86, "end_pos": 110, "type": "DATASET", "confidence": 0.9441678722699484}]}, {"text": "The Person class is a direct subclass of the owl:Thing class and has 21 immediate subclasses and 36 subclasses at the second level.", "labels": [], "entities": []}, {"text": "We used the persons in different classes in DBpedia ontology at level two to generate data sets for experiments.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.8801205158233643}]}, {"text": "There are several articles in Wikipedia that are very small and have very few out-links and inlinks.", "labels": [], "entities": []}, {"text": "Our approach is based on the out-links and availability of information about different related things on the article, therefore, in order to avoid data sparseness, we randomly select articles with greater than 100 in-links and out-links, at least 5KB page length and having at least five links to entities of the same type that link back (in our case persons).", "labels": [], "entities": []}, {"text": "We first compare our slot vector features with other features extracted from Wikipedia for entity classification task and then evaluate their accuracy.", "labels": [], "entities": [{"text": "entity classification", "start_pos": 91, "end_pos": 112, "type": "TASK", "confidence": 0.8465996086597443}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9985895752906799}]}, {"text": "We then discover the class hierarchy and compare the different similarity functions.", "labels": [], "entities": []}, {"text": "To evaluate our approach to finding slot fillers, we focused on DBpedia classes two levels below Person (e.g.,.", "labels": [], "entities": [{"text": "finding slot fillers", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.6331639885902405}]}, {"text": "We randomly selected 200 articles from each of these classes using the criteria defined earlier to avoid data sparseness.", "labels": [], "entities": []}, {"text": "Classes for which fewer than 20 articles were found were discarded.", "labels": [], "entities": []}, {"text": "The resulting dataset comprised 28 classes and 3810 articles . We used our ranked slots tf.idf feature set and ran a complete link clustering algorithm producing clusters at partition distance of 0.8.", "labels": [], "entities": []}, {"text": "The slots were re-scored based on the number of times they appeared in the cluster members normalized by the cluster size.", "labels": [], "entities": []}, {"text": "We applied slot selection over the rescored slots for each cluster.", "labels": [], "entities": [{"text": "slot selection", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.8588109910488129}]}, {"text": "In order to evaluate our slots and fillers we mapped each cluster to a DBpedia class based on the maximum number of members of a particular DBpedia class in our cluster.", "labels": [], "entities": []}, {"text": "This process predicted 124 unique properties for the classes.", "labels": [], "entities": []}, {"text": "Of these, we were able to manually align 46 to properties in either DBpedia or Free-base for the corresponding class.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.960929274559021}]}, {"text": "We initially tried to evaluate the discovered slots by comparing them with those found in the ontologies underlying DBpedia and Freebase, but were able to find an overlap in the subject and object pairs for very few properties.", "labels": [], "entities": []}, {"text": "We randomly selected 20 subject object pairs for each of the 46 properties from the corresponding classes and manually judged whether or not the relation was correct by consulting the correspond-   ing Wikipedia articles.", "labels": [], "entities": []}, {"text": "The average accuracy for the 46 relations was 81%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9985217452049255}]}], "tableCaptions": [{"text": " Table 3: Manual evaluation of discovered properties", "labels": [], "entities": []}, {"text": " Table 2: Comparison of the precision, recall and F- measure for different feature sets for entity classifi- cation. The k column shows the number of clusters  that maximized the F score.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9995168447494507}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9992595314979553}, {"text": "F- measure", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9959044257799784}, {"text": "F score", "start_pos": 179, "end_pos": 186, "type": "METRIC", "confidence": 0.9774365127086639}]}, {"text": " Table 4: Evaluation results for class hierarchy predic- tion using different similarity functions.", "labels": [], "entities": []}]}