{"title": [{"text": "Variable-Length Markov Models and Ambiguous Words in Portuguese *", "labels": [], "entities": []}], "abstractContent": [{"text": "Variable-Length Markov Chains (VLMCs) offer away of modeling contexts longer than trigrams without suffering from data sparsity and state space complexity.", "labels": [], "entities": []}, {"text": "However, in Historical Portuguese, two words show a high degree of ambiguity: que and a.", "labels": [], "entities": []}, {"text": "The number of errors tagging these words corresponds to a quarter of the total errors made by a VLMC-based tagger.", "labels": [], "entities": []}, {"text": "Moreover, these words seem to show two different types of ambiguity: one depending on non-local context and another on right context.", "labels": [], "entities": []}, {"text": "We searched ways of expanding the VLMC-based tagger with a number of different models and methods in order to tackle these issues.", "labels": [], "entities": [{"text": "VLMC-based tagger", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.5607767403125763}]}, {"text": "The methods showed variable degrees of success, with one particular method solving much of the ambiguity of a.", "labels": [], "entities": []}, {"text": "We explore reasons why this happened, and how everything we tried fails to improve the precision of que.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9992235898971558}]}], "introductionContent": [{"text": "In the Computational Linguistics area, the task of part-of-speech tagging (POS tagging) consists in assigning to words in a text the grammatical class they belong.", "labels": [], "entities": [{"text": "Computational Linguistics area", "start_pos": 7, "end_pos": 37, "type": "TASK", "confidence": 0.8672225475311279}, {"text": "part-of-speech tagging (POS tagging)", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.8408558120330175}]}, {"text": "Since the same word may belong to more than one class, models for POS tagging have to look at the context where each word occurs to try to solve the ambiguity.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8970112800598145}]}, {"text": "Previous and current work have developed a wide range of models and methods for tagging.", "labels": [], "entities": []}, {"text": "The vast majority uses supervised learning methods, which * During the course of this work Fabio received support from Brazilian funding agencies need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc.", "labels": [], "entities": []}, {"text": "Among the various models for tagging, there are Maximum Entropy models (dos, Hidden Markov Models (HMMs)), Transformation Based Learning, and other succesful approaches (.", "labels": [], "entities": [{"text": "tagging", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.965752363204956}]}, {"text": "Current state-of-the-art precision in tagging is achieved by supervised methods.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9943748712539673}, {"text": "tagging", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9651942849159241}]}, {"text": "Although precision is pretty high -less than 3% error rate for English -the disavantage is exactly the need of a tagged corpus, usually built manually.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9993252754211426}]}, {"text": "This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc.", "labels": [], "entities": []}, {"text": "The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources.", "labels": [], "entities": []}, {"text": "There have been initiatives both in Brazil and in Portugal, which include modern Brazilian Portuguese corpora, European Portuguese corpora, and historical Portuguese corpora (IEL-UNICAMP and IME-USP, 2010).", "labels": [], "entities": [{"text": "IEL-UNICAMP", "start_pos": 175, "end_pos": 186, "type": "METRIC", "confidence": 0.6533277034759521}]}, {"text": "Also, some supervised POS taggers have already been developed for Portuguese) with a good degree of success.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.8302148878574371}]}, {"text": "And finally, there has also been increasing effort and interest in Portuguese annotation tools, such as EDictor 1 (de.", "labels": [], "entities": []}, {"text": "Despite these advances, there is still lack of material and resources for Portuguese, as well as research in unsupervised methods to bootstrap text annotation.", "labels": [], "entities": [{"text": "bootstrap text annotation", "start_pos": 133, "end_pos": 158, "type": "TASK", "confidence": 0.727175235748291}]}, {"text": "Our work focuses on further improvement of the current state-of-the-art in Portuguese tagging.", "labels": [], "entities": [{"text": "Portuguese tagging", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.6363518238067627}]}, {"text": "For this, we focus on the Tycho Brahe (IEL-UNICAMP and IME-USP, 2010) corpus for testing and benchmarking, because of its great collaboration potential: it is easily accessible 2 ; is under continuous development; and has recently started using E-Dictor, which also offers a great collaboration potential.", "labels": [], "entities": [{"text": "Tycho Brahe (IEL-UNICAMP and IME-USP, 2010) corpus", "start_pos": 26, "end_pos": 76, "type": "DATASET", "confidence": 0.898122638463974}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision of VLMC-based taggers.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8877034187316895}, {"text": "VLMC-based taggers", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7234115600585938}]}, {"text": " Table 2: Results for words with the most number of errors  using the VLMM TAGGER with the normal corpus.", "labels": [], "entities": [{"text": "VLMM", "start_pos": 70, "end_pos": 74, "type": "DATASET", "confidence": 0.7442960143089294}, {"text": "TAGGER", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.6525074243545532}]}, {"text": " Table 3. We use the segmented corpus for  comparison because the constituents only use seg- mented tags. Even after many tries and variations in", "labels": [], "entities": []}, {"text": " Table 3: Comparison of precision using the VLMM TAG- GER (in italics) and the VLMM+SPANS-QUE TAGGER  (upcase) with the segmented corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9989063739776611}, {"text": "VLMM TAG- GER", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.5193634778261185}]}, {"text": " Table 4: Comparison of precision using the VLMM TAG- GER (in italics) and the VLMM+CHUNKS TAGGER (up- case) with the segmented corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9989619255065918}, {"text": "VLMM TAG- GER", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.5596686378121376}]}, {"text": " Table 5: Comparison of precision using the VLMM TAG- GER (in italics) and the VLMM+A-RIGHT TAGGER (up- case) with the normal corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9989854693412781}, {"text": "VLMM TAG- GER", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.5441493317484856}, {"text": "VLMM+A-RIGHT TAGGER", "start_pos": 79, "end_pos": 98, "type": "METRIC", "confidence": 0.6364313066005707}]}, {"text": " Table 6: Comparison of precision using the VLMM TAG- GER (in italics) and the VLMM+PERCEPTRON TAGGER  (upcase) with the normal corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9989700317382812}, {"text": "VLMM TAG- GER", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.5494103580713272}, {"text": "PERCEPTRON TAGGER", "start_pos": 84, "end_pos": 101, "type": "METRIC", "confidence": 0.7617270052433014}]}, {"text": " Table 7: Comparison of precision using the VLMM TAG- GER (in italics) and the GUIDED LEARNING TAGGER (up- case) with the normal corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9990758895874023}, {"text": "VLMM TAG- GER", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.6655765995383263}, {"text": "GUIDED LEARNING TAGGER", "start_pos": 79, "end_pos": 101, "type": "METRIC", "confidence": 0.8862837354342142}]}, {"text": " Table 8: Confusion matrix for a with the most common  tags in the normal corpus (line: reference; column: pre- dicted).", "labels": [], "entities": []}]}