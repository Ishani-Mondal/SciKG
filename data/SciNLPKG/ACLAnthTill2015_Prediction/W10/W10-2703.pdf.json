{"title": [{"text": "Is a Companion a distinctive kind of relationship with a machine?", "labels": [], "entities": []}], "abstractContent": [{"text": "I start from a perspective close to that of the EC COMPANIONS project, and set out its aim to model anew kind of human-computer relationship based on long-term interaction, with some tasks involved although a Companion should not be inherently task-based, since there need be no stopping point to its conversation.", "labels": [], "entities": [{"text": "EC COMPANIONS project", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.9135785301526388}]}, {"text": "Some demonstration of its functionality will be given but the main purpose here is an analysis of what it is people might want from such a relationship and what evidence we have for whatever we conclude.", "labels": [], "entities": []}, {"text": "Is an attempt at emotional sympathy important or achievable?", "labels": [], "entities": [{"text": "emotional sympathy", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7781299352645874}]}, {"text": "Does a user want a consistent personality in a Companion or a variety of personalities?", "labels": [], "entities": []}, {"text": "Should we be talking more in terms of a \"cognitive pros-thesis (or orthosis)?\"-something to extract, organize , and locate the user's knowledge or personal information-rather than attitudes?", "labels": [], "entities": []}], "introductionContent": [{"text": "It is convenient to distinguish Companions from both (a) conversational internet agents that carryout specific tasks, such as the train and plane scheduling and ticket ordering speech dialogue applications back to the MIT ATIS systems (, and also from (b) descendants of the early chatbots PARRY and ELIZA, the best of which compete annually in the Loebner competition (Loebner).", "labels": [], "entities": [{"text": "train and plane scheduling and ticket ordering speech dialogue", "start_pos": 130, "end_pos": 192, "type": "TASK", "confidence": 0.7264036933581034}]}, {"text": "These have essentially no memory or knowledge but are simple finite state response sets, although ELIZA had primitive \"scripts\" giving some context, and PARRY had parameters like FEAR and ANGER that changed with the conversation and determined which reply was selected at a given point.", "labels": [], "entities": [{"text": "ELIZA", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.85808265209198}, {"text": "FEAR", "start_pos": 179, "end_pos": 183, "type": "METRIC", "confidence": 0.9945778846740723}, {"text": "ANGER", "start_pos": 188, "end_pos": 193, "type": "METRIC", "confidence": 0.8989998698234558}]}, {"text": "But a Companion need not be a robot to act in the world in this way, and we may as well assume its internet agent status, with access to open internet knowledge sources.", "labels": [], "entities": []}, {"text": "Given this narrowing of focus in this paper, what questions then arise and what choices does that leave open?", "labels": [], "entities": []}, {"text": "We now discuss some obvious questions that have arisen in the literature:", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}