{"title": [{"text": "Reducing the False Alarm Rate of Chinese Character Error Detection and Correction", "labels": [], "entities": [{"text": "False Alarm Rate", "start_pos": 13, "end_pos": 29, "type": "METRIC", "confidence": 0.9269085923830668}, {"text": "Chinese Character Error Detection", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.5456443652510643}]}], "abstractContent": [{"text": "The main drawback of previous Chinese character error detection systems is the high false alarm rate.", "labels": [], "entities": [{"text": "Chinese character error detection", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.5609719008207321}, {"text": "false alarm rate", "start_pos": 84, "end_pos": 100, "type": "METRIC", "confidence": 0.8948748906453451}]}, {"text": "To solve this problem, we propose a system that combines a statistic method and template matching to detect Chinese character errors.", "labels": [], "entities": []}, {"text": "Error types include pronunciation-related errors and form-related errors.", "labels": [], "entities": []}, {"text": "Possible errors of a character can be collected to form a confusion set.", "labels": [], "entities": []}, {"text": "Our system automatically generates templates with the help of a dictionary and confusion sets.", "labels": [], "entities": []}, {"text": "The templates can be used to detect and correct errors in essays.", "labels": [], "entities": []}, {"text": "In this paper, we compare three methods proposed in previous works.", "labels": [], "entities": []}, {"text": "The experiment results show that our system can reduce the false alarm significantly and give the best performance on f-score.", "labels": [], "entities": [{"text": "false alarm", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.8890340924263}, {"text": "f-score", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.9592543244361877}]}], "introductionContent": [{"text": "Since many Chinese characters have similar forms and similar or identical pronunciation, improperly used characters in Chinese essays are hard to be detectted.", "labels": [], "entities": []}, {"text": "Previous works collected these hard-todistinguish characters and used them to form confusion sets.", "labels": [], "entities": []}, {"text": "Confusion sets are critical for detecting and correcting improperly used Chinese characters.", "labels": [], "entities": []}, {"text": "A confusion set of a Chinese character consists of characters with similar pronunciation, similar forms, and similar meaning.", "labels": [], "entities": []}, {"text": "Most Chinese character detection systems were built based on confusion sets and a language model.", "labels": [], "entities": [{"text": "Chinese character detection", "start_pos": 5, "end_pos": 32, "type": "TASK", "confidence": 0.5853918790817261}]}, {"text": "Ren et.al proposed a rule-based method that was also integrated with a language model to detect character errors in Chinese.", "labels": [], "entities": []}, {"text": "Chang used confusion sets to represent all possible errors to reduce the amount of computation.", "labels": [], "entities": []}, {"text": "A language model was also used to make decisions.", "labels": [], "entities": []}, {"text": "The confusion sets were edited manually.", "labels": [], "entities": []}, {"text": "proposed away to automatically generate confusion sets based on the Wubi input method (Zhang, Zhou,).", "labels": [], "entities": []}, {"text": "The basic assumption was that characters with similar input sequences must have similar forms.", "labels": [], "entities": []}, {"text": "Therefore, by replacing one code in the input sequence of a certain character, the system could generate characters with similar forms.", "labels": [], "entities": []}, {"text": "In the following work, Zhang et al. designed a Chinese character detection system based on the confusion sets (Zhang, Zhou,).", "labels": [], "entities": [{"text": "Chinese character detection", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.6865586141745249}]}, {"text": "Another input method was also used to generate confusion sets.", "labels": [], "entities": []}, {"text": "Lin et al. used the Cangjie input method to generate confusion sets).", "labels": [], "entities": []}, {"text": "The basic assumption was the same.", "labels": [], "entities": []}, {"text": "By replacing one code in the input sequence of a certain character, the system could generate characters with similar forms.", "labels": [], "entities": []}, {"text": "Since the two input methods have totally different representations of the same character, the confusion set of any given character will be completely different.", "labels": [], "entities": []}, {"text": "In recent years, new systems have been incorporating more NLP technology for Chinese character error detection.", "labels": [], "entities": [{"text": "Chinese character error detection", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.742358386516571}]}, {"text": "proposed that a word segmentation tool can be used to detect character error in Chinese.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7195521742105484}]}, {"text": "They used anew word detection function in the CKIP word segmentation toolkit to detect error candidates).", "labels": [], "entities": [{"text": "word detection", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.7174711972475052}, {"text": "CKIP word segmentation", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.823710560798645}]}, {"text": "With the help of a dictionary and confusion set, the system can decide whether anew word is a character error or not.", "labels": [], "entities": []}, {"text": "Hung et al. proposed a system that can detect character errors in student essays and then suggest corrections.", "labels": [], "entities": []}, {"text": "The system was based on common error templates which were manually edited.", "labels": [], "entities": []}, {"text": "The precision of this system is the highest, but the recall remains average.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997757077217102}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9997106194496155}]}, {"text": "The main drawback of this approach is the cost of editing common error templates.", "labels": [], "entities": []}, {"text": "Chen et al. proposed an automatic method for common error template generation.", "labels": [], "entities": [{"text": "common error template generation", "start_pos": 45, "end_pos": 77, "type": "TASK", "confidence": 0.725070632994175}]}, {"text": "The common errors were collected from a large corpus automatically.", "labels": [], "entities": []}, {"text": "The template is a short phrase with one error in it.", "labels": [], "entities": []}, {"text": "The assumption is the frequency of a correct phrase must be higher than the frequency of the corresponding template, with one error character.", "labels": [], "entities": []}, {"text": "Therefore, a statistical test can be used to decide weather there is a common error or not.", "labels": [], "entities": []}, {"text": "The main drawback of previous systems is the high false alarm rate.", "labels": [], "entities": [{"text": "false alarm rate", "start_pos": 50, "end_pos": 66, "type": "METRIC", "confidence": 0.9085451364517212}]}, {"text": "The drawback is found by comparing the systems with sentences without errors.", "labels": [], "entities": []}, {"text": "As we will show in our experiments, the systems in previous works tent to report more errors in an essay than the real ones, thus, cause false alarms.", "labels": [], "entities": []}, {"text": "In this paper, we will further improve upon the Chinese character checker using anew error model and a simplified common error template generation method.", "labels": [], "entities": []}, {"text": "The idea of error model is adopted from the noise channel model, which is used in many natural language processing applications, but never on Chinese character error detection.", "labels": [], "entities": [{"text": "Chinese character error detection", "start_pos": 142, "end_pos": 175, "type": "TASK", "confidence": 0.5758966952562332}]}, {"text": "With the help of error model, we can treat the error detection problem as a kind of translation, where a sentence with errors can be translated into a sentence without errors.", "labels": [], "entities": [{"text": "error detection", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.7079991400241852}]}, {"text": "The simplified template generation is based on given confusion sets and a lexicon.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We introduce briefly the methods in previous works in section 2.", "labels": [], "entities": []}, {"text": "Section 3 reports the necessary language resources used to build such systems.", "labels": [], "entities": []}, {"text": "Our approach is described in section 4.", "labels": [], "entities": []}, {"text": "In section 5, we report the experiment settings and results of our system, as well as give the comparison of our system to the three previous systems.", "labels": [], "entities": []}, {"text": "Finally, we give the conclusions in the final section.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since there is no open source system in previous works and the data in use is not available, we reproduced the systems with the same dictionary, the same confusion set, and the same language model.", "labels": [], "entities": []}, {"text": "Then we performed a test on the same test set.", "labels": [], "entities": []}, {"text": "Since the confusion sets are quite large, to reduce the number of combinations during the experiment, the size must be limited.", "labels": [], "entities": []}, {"text": "Since Liu's experiments show that it takes about 3 candidates to find the correct character, we use the top 1 to top 10 similar characters as the candidates only in our experiments.", "labels": [], "entities": []}, {"text": "That is, we take 1 to 10 characters from each of the SC1, SC2, SSST, and SSDT sets.", "labels": [], "entities": []}, {"text": "Thus, the size of each confusion set is limited to 4 for the top 1 mode and 40 for the top 10 mode.", "labels": [], "entities": []}, {"text": "The evaluation metrics is the same as.", "labels": [], "entities": []}, {"text": "We also define the precision rate, detection rate, and correction rate as follows: where A is the number of all spelling errors, B is the number of errors detected by be system, C is the number of errors detected correctly by the system, and Dis the number of spelling errors that is detected and corrected.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 19, "end_pos": 33, "type": "METRIC", "confidence": 0.9906649589538574}, {"text": "detection rate", "start_pos": 35, "end_pos": 49, "type": "METRIC", "confidence": 0.8763900101184845}, {"text": "correction rate", "start_pos": 55, "end_pos": 70, "type": "METRIC", "confidence": 0.9918318688869476}, {"text": "Dis", "start_pos": 242, "end_pos": 245, "type": "METRIC", "confidence": 0.9821621775627136}]}, {"text": "Note that some errors can be detected but cannot be corrected.", "labels": [], "entities": []}, {"text": "Since the correction is more important in an error detection and correction system, we define the corresponding f-score as: shows the initial results of the template module (TM), the translation module (LMM) and the combined results of the precision mode (PM) and detection mode (DM).", "labels": [], "entities": [{"text": "error detection and correction", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.8113414794206619}, {"text": "precision mode (PM)", "start_pos": 240, "end_pos": 259, "type": "METRIC", "confidence": 0.9415547013282776}]}, {"text": "We find that the precision mode gets the highest precision and f-score, while the detection mode gets the highest correction rate, as expected.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9992528557777405}, {"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9993419051170349}, {"text": "f-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9870914220809937}, {"text": "correction rate", "start_pos": 114, "end_pos": 129, "type": "METRIC", "confidence": 0.9903428256511688}]}, {"text": "The precision and detection rate improved dramatically.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995606541633606}]}, {"text": "The precision improved from 14.28% to 61.68% for the best setting and to 58.82% for the best f-score setting.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9998169541358948}]}, {"text": "The detection rate improved from 58.06% to around 72%.", "labels": [], "entities": [{"text": "detection rate", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9479676485061646}]}, {"text": "The f-score improved from 22.28% to 43.80%.", "labels": [], "entities": [{"text": "f-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9950363039970398}]}, {"text": "The result shows that combining two independent methods yield better performance than each single method does.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. There are less than two errors in  an essay on average. We find that most (about 97%)  of characters in the essays were among the 5,401 most  common characters, and most errors were characters  of similar forms or pronunciation. Therefore, the  5,401 confusion sets constructed according to form  and pronunciation were suitable for error detection.", "labels": [], "entities": [{"text": "error detection", "start_pos": 343, "end_pos": 358, "type": "TASK", "confidence": 0.6994917392730713}]}, {"text": " Table 1. Training set and test set statistics", "labels": [], "entities": []}, {"text": " Table 2. Error type analysis", "labels": [], "entities": [{"text": "Error type analysis", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8166829943656921}]}, {"text": " Table 3. An example of calculating perplexity  according the new error model", "labels": [], "entities": []}, {"text": " Table 4. Results of our initial system", "labels": [], "entities": []}, {"text": " Table 5. Results of our system after adding more knowledge and enlarged the train set", "labels": [], "entities": []}, {"text": " Table 6. Results of methods in previous works", "labels": [], "entities": []}, {"text": " Table 7. Results of methods in previous works on sentences with errors", "labels": [], "entities": []}]}