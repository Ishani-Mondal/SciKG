{"title": [{"text": "Assessing the Challenge of Fine-Grained Named Entity Recognition and Classification", "labels": [], "entities": [{"text": "Fine-Grained Named Entity Recognition", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.6118794679641724}, {"text": "Classification", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7908266186714172}]}], "abstractContent": [{"text": "Named Entity Recognition and Classification (NERC) is a well-studied NLP task typically focused on coarse-grained named entity (NE) classes.", "labels": [], "entities": [{"text": "Named Entity Recognition and Classification (NERC)", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8261238932609558}]}, {"text": "NERC for more fine-grained semantic NE classes has not been systematically studied.", "labels": [], "entities": []}, {"text": "This paper quantifies the difficulty of fine-grained NERC (FG-NERC) when performed at large scale on the people domain.", "labels": [], "entities": []}, {"text": "We apply unsupervised acquisition methods to construct a gold standard dataset for FG-NERC.", "labels": [], "entities": [{"text": "FG-NERC", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.920570969581604}]}, {"text": "This dataset is used to benchmark methods for classifying NEs at various levels of fine-grainedness using classical NERC techniques and global contex-tual information inspired from Word Sense Disambiguation approaches.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 181, "end_pos": 206, "type": "TASK", "confidence": 0.5748972992102305}]}, {"text": "Our results indicate high difficulty of the task and provide a 'strong' baseline for future research.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9639660716056824}]}], "introductionContent": [{"text": "Named Entity Recognition and Classification (cf.) is a well-established NLP task relevant for nearly all semantic processing and information access applications.", "labels": [], "entities": [{"text": "Entity Recognition and Classification (cf.)", "start_pos": 6, "end_pos": 49, "type": "TASK", "confidence": 0.8566048060144696}]}, {"text": "NERC has been investigated using supervised, unsupervised () and semi-supervised) learning methods.", "labels": [], "entities": [{"text": "NERC", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.6947474479675293}]}, {"text": "It has been investigated in multilingual settings) and special domains, e.g. biomedicine ().", "labels": [], "entities": []}, {"text": "The classical NERC task is confined to coarsegrained named entity (NE) classes established in the MUC or) competitions, typically PERS, LOC, ORG, MISC.", "labels": [], "entities": [{"text": "NERC task", "start_pos": 14, "end_pos": 23, "type": "TASK", "confidence": 0.9063546061515808}, {"text": "MUC", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.9203221201896667}, {"text": "MISC", "start_pos": 146, "end_pos": 150, "type": "DATASET", "confidence": 0.7857925891876221}]}, {"text": "While most recent work concentrates on feature engineering and robust statistical models for various domains, few researchers addressed the problem of recognizing and categorizing fine-grained NE classes (such as biologist, composer, or athlete) in an open-domain setting.", "labels": [], "entities": []}, {"text": "Fine-grained NERC is expected to be beneficial fora wide spectrum of applications, including Information Retrieval (), Information Extraction) or Question-Answering ().", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 93, "end_pos": 114, "type": "TASK", "confidence": 0.7712928056716919}, {"text": "Information Extraction", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.7313871383666992}]}, {"text": "However, manually compiling widecoverage gazetteers for fine-grained NE classes is time-consuming and error-prone.", "labels": [], "entities": []}, {"text": "Also, without an extrinsic evaluation, it is difficult to define a priori which classes are relevant fora particular domain or task.", "labels": [], "entities": []}, {"text": "Finally, prior research in FG-NERC is difficult to evaluate, due to the diversity of NE classes and datasets used.", "labels": [], "entities": [{"text": "FG-NERC", "start_pos": 27, "end_pos": 34, "type": "DATASET", "confidence": 0.8707780241966248}]}, {"text": "Accordingly, in the interest of a general approach, we address the challenge of capturing abroad range of NE classes at various levels of conceptual granularity.", "labels": [], "entities": []}, {"text": "By turning FG-NERC into a widely applicable task, applications are free to choose relevant NE categories for specific needs.", "labels": [], "entities": [{"text": "FG-NERC", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.7725486159324646}]}, {"text": "Also, establishing a gold standard dataset for this task enables comparative benchmarking of methods.", "labels": [], "entities": []}, {"text": "However, the envisaged task is far from trivial, given that the set of possible semantic classes fora given NE comprises the full space of NE classes, whereas descriptive nouns maybe ambiguous between a fixed set of meanings only.", "labels": [], "entities": []}, {"text": "The paper aims to establish a general framework for FG-NERC by addressing two goals: (i) we automatically build a gold standard dataset of NE instances classified in context with fine-grained semantic class labels; (ii) we develop strong baseline methods, to assess the aptness of standard NLP approaches for this task.", "labels": [], "entities": [{"text": "FG-NERC", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.7773175835609436}]}, {"text": "The two efforts are strongly interleaved: a standardized dataset is not only essential for (comparative) evaluation, but also a prerequisite for classification approaches based on supervised learning, the most successful techniques for sequential labeling problems.", "labels": [], "entities": [{"text": "sequential labeling problems", "start_pos": 236, "end_pos": 264, "type": "TASK", "confidence": 0.7560434341430664}]}], "datasetContent": [{"text": "We present an unsupervised method that simultaneously acquires NEs, their semantic class and contexts of occurrence from large textual resources.", "labels": [], "entities": []}, {"text": "In order to develop a clean resource of properly disambiguated NEs, we develop acquisition patterns fora grammatical construction that unambiguously associates proper names with their corresponding semantic class.", "labels": [], "entities": []}, {"text": "Pattern-based extraction of NE-concept pairs.", "labels": [], "entities": [{"text": "Pattern-based extraction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8059931993484497}]}, {"text": "NEs are often introduced by so-called appositional structures as in, which overtly express which semantic class (here, painter) the NE (Kandinsky) belongs to.", "labels": [], "entities": []}, {"text": "Appositions involving proper names can be captured by extraction patterns as given in (2).", "labels": [], "entities": []}, {"text": "writings of the abstract painter Kandinsky frequently explored similarities between . .", "labels": [], "entities": []}, {"text": "W. Kandinsky, a Russian-born painter, ..", "labels": [], "entities": []}, {"text": "Contexts like (2.a) provide a less noisy sequence for extraction, due to the class and instance labels being adjacent -in contrast to (2.b) where any number of modifiers can intervene between the two.", "labels": [], "entities": []}, {"text": "Accordingly, we apply in our experiments only a restricted version of (2.a) -with a determiner -to UKWAC, an English web-based corpus () that comes in a cleaned, PoS-tagged and lemmatized form.", "labels": [], "entities": [{"text": "UKWAC", "start_pos": 99, "end_pos": 104, "type": "DATASET", "confidence": 0.9888787269592285}]}, {"text": "Due to its size (>2 billion tokens) and mixed genres, the corpus is ideally suited for acquiring large quantities of NEs pertaining to abroad variety of open-domain semantic classes.", "labels": [], "entities": []}, {"text": "The apposition patterns are subject to noise, due to PoS-tagging errors, as well as special constructions, e.g. reduced relative clauses.", "labels": [], "entities": []}, {"text": "The former can be controlled by frequency filters, the latter can be circumvented by using chunk boundary information . A more challenging problem is to recognize whether an extracted nominal is in fact a valid semantic class for NEs.", "labels": [], "entities": []}, {"text": "Besides, class labels can be ambiguous, so there is uncertainty as to which class an extracted entity should be assigned to.", "labels": [], "entities": []}, {"text": "We apply two filtering strategies: we set a frequency threshold ft on the number of extracted NE tokens per class, to remove infrequent class label extractions; we then filter invalid semantic classes using information from WordNet: given the WordNet PERSON supersense, i.e. the lexicographer file for nouns denoting people, we check whether the first sense of the class label candidate is found in PERSON.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 224, "end_pos": 231, "type": "DATASET", "confidence": 0.9663713574409485}]}, {"text": "Mapping to the WordNet person domain.", "labels": [], "entities": [{"text": "WordNet person domain", "start_pos": 15, "end_pos": 36, "type": "DATASET", "confidence": 0.9769955078760783}]}, {"text": "In order to perform a hierarchical classification of people, we need a taxonomy for the domain at hand.", "labels": [], "entities": []}, {"text": "We achieve this by mapping the extracted class labels to WordNet synsets.", "labels": [], "entities": []}, {"text": "In our setting, we map against all synsets found under person#n#1, which are direct hypernyms of at least one instance in WordNet (C W N pers+Inst ).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.9655128121376038}]}, {"text": "Since our goal is to map class labels to synsets (i.e. our future NE classes), we check each class label candidate against all synonyms contained in the synset.", "labels": [], "entities": []}, {"text": "At this point we have to deal with two cases: two extracted class label candidates (synonyms such as doctor, physician) will map to a single synset, while ambiguous class labels (e.g. director) can be mapped to more than one synset.", "labels": [], "entities": []}, {"text": "In the latter case, we heuristically choose the synset which dominates the highest number of instances in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9682461619377136}]}, {"text": "We evaluated the coverage of our mapping for two sets of class labels extracted for two different frequency thresholds: ft = 40 and ft = 1.", "labels": [], "entities": []}, {"text": "For threshold ft = 40, we obtain 153 class labels which are mapped to 146 synsets.", "labels": [], "entities": []}, {"text": "Ten class labels are mapped to more than one synset.", "labels": [], "entities": []}, {"text": "Using our mapping heuristic based on the majority instance class, we successfully disambiguate all of them.", "labels": [], "entities": []}, {"text": "However, since we only map to C W N pers+Inst , we introduce errors for 5 classes.", "labels": [], "entities": [{"text": "Inst", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9667776823043823}]}, {"text": "E.g. 'manager' incorrectly gets mapped to manager#n#2, since the latter is the only synset containing instances.", "labels": [], "entities": []}, {"text": "For these cases we manually corrected the automatic mapping.", "labels": [], "entities": []}, {"text": "We create our gold standard taxonomy of semantic classes by starting with the 146 synsets obtained from the mapping, including the 5 classes that were manually corrected.", "labels": [], "entities": []}, {"text": "Since we concentrate on the people domain, we additionally remove 5 classes that can refer to other domains as well (e.g. carrier, guide).", "labels": [], "entities": []}, {"text": "Given the remaining 141 synsets, we select the portion of WordNet rooted at person#n#1 which contains them, together with any intervening synset found along the WordNet hierarchy.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9514056444168091}, {"text": "WordNet hierarchy", "start_pos": 161, "end_pos": 178, "type": "DATASET", "confidence": 0.9180968403816223}]}, {"text": "Given this WordNet excerpt, the extracted NE tokens are then appended to the respective synsets in the hierarchy.", "labels": [], "entities": [{"text": "WordNet excerpt", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.923691987991333}]}, {"text": "Statistics of the resulting WordNet fragment augmented with instances are given in.", "labels": [], "entities": [{"text": "WordNet fragment", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9541122317314148}]}, {"text": "The taxonomy has a maximum depth of 8, and contains 213 synsets, i.e. NE classes (see column 2).", "labels": [], "entities": []}, {"text": "83.5% of the 31,819 extracted instances (type-level) sit in leaf nodes.", "labels": [], "entities": []}, {"text": "The classes automatically refer back to the acquired appositional contexts.", "labels": [], "entities": []}, {"text": "gives statistics about the number of instances (token-level) acquired for classes at different embedding levels.", "labels": [], "entities": []}, {"text": "In total we have at our disposal 48,512 instances (token-level) in appositional contexts.", "labels": [], "entities": []}, {"text": "The type-token ratio is 1.52.", "labels": [], "entities": []}, {"text": "To create a gold standard dataset of entities in context labeled with fine-grained classes, we first randomly select 20 classes, as well as an additional 18 which are also found in the People Ontology (.", "labels": [], "entities": []}, {"text": "For each class, we randomly select 40 occurrences of instances in context, i.e. the words co-occurring in a window of 60 tokens before and after the instance.", "labels": [], "entities": []}, {"text": "We asked four annotators to label these extractions for correctness, and to provide the correct label for the incorrect cases, if one was available.", "labels": [], "entities": []}, {"text": "Only 52 contexts out of 1520 were labeled as incorrect, thus giving us 96.58% accuracy on our automatically extracted data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9994388222694397}]}, {"text": "The manually validated dataset is used to provide a ground-truth for FG-NERC.", "labels": [], "entities": [{"text": "FG-NERC", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9091544151306152}]}, {"text": "However, the noun (e.g. hunter) denoting the NE class is removed from these contexts for training and testing in all experiments.", "labels": [], "entities": []}, {"text": "This is because, due to the extraction method based on POS-patterns denoting appositions, class labels are known a priori to occur in the context of an instance and thus identify them with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 194, "end_pos": 203, "type": "METRIC", "confidence": 0.9775583148002625}]}], "tableCaptions": [{"text": " Table 1: Level-wise statistics of classes and in- stances across the FG-NERC person taxonomy.", "labels": [], "entities": [{"text": "FG-NERC person taxonomy", "start_pos": 70, "end_pos": 93, "type": "DATASET", "confidence": 0.9158877929051717}]}, {"text": " Table 2: Results on the CoNLL-2003 test data.", "labels": [], "entities": [{"text": "CoNLL-2003 test data", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.966719388961792}]}, {"text": " Table 3: Statistics for training, dev and test sets.", "labels": [], "entities": []}, {"text": " Table 4: Oversampling of positive samples.", "labels": [], "entities": []}, {"text": " Table 6: Level-wise NE recognition & classifica- tion evaluation (in %).", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.9584522843360901}]}, {"text": " Table 5: Level-wise evaluation of fine-grained NE classification techniques (in %).", "labels": [], "entities": [{"text": "NE classification", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.962189644575119}]}]}