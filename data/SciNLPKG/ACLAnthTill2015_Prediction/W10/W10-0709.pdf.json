{"title": [{"text": "Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Collected Using Amazon Mechanical Turk", "labels": [], "entities": [{"text": "Exploring Normalization Techniques for Human Judgments of Machine Translation Adequacy Collected", "start_pos": 0, "end_pos": 96, "type": "TASK", "confidence": 0.7098302759907462}]}], "abstractContent": [{"text": "This paper discusses a machine translation evaluation task conducted using Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "machine translation evaluation task", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.8724366128444672}, {"text": "Amazon Mechanical Turk", "start_pos": 75, "end_pos": 97, "type": "DATASET", "confidence": 0.9514788786570231}]}, {"text": "We present a translation adequacy assessment task for untrained Arabic-speaking annotators and discuss several techniques for normalizing the resulting data.", "labels": [], "entities": [{"text": "translation adequacy assessment", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.8705134789148966}]}, {"text": "We present a novel 2-stage normalization technique shown to have the best performance on this task and further discuss the results of all techniques and the usability of the resulting adequacy scores.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human judgments of translation quality play a vital role in the development of effective machine translation (MT) systems.", "labels": [], "entities": [{"text": "effective machine translation (MT)", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.8322140375773112}]}, {"text": "Such judgments can be used to measure system quality in evaluations ) and to tune automatic metrics such as METEOR () which act as stand-ins for human evaluators.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9379300475120544}]}, {"text": "However, collecting reliable human judgments often requires significant time commitments from expert annotators, leading to a general scarcity of judgments and a significant time lag when seeking judgments for new tasks or languages.", "labels": [], "entities": []}, {"text": "Amazon's Mechanical Turk (MTurk) service facilitates inexpensive collection of large amounts of data from users around the world.", "labels": [], "entities": []}, {"text": "However, Turkers are not trained to provide reliable annotations for natural language processing (NLP) tasks, and some Turkers attempt to game the system by submitting random answers.", "labels": [], "entities": []}, {"text": "For these reasons, NLP tasks must be designed to be accessible to untrained users and data normalization techniques must be employed to ensure that the data collected is usable.", "labels": [], "entities": [{"text": "data normalization", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7105140537023544}]}, {"text": "This paper describes a MT evaluation task for translations of English into Arabic conducted using MTurk and compares several data normalization techniques.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9093482494354248}, {"text": "translations of English into Arabic", "start_pos": 46, "end_pos": 81, "type": "TASK", "confidence": 0.8750348806381225}]}, {"text": "A novel 2-stage normalization technique is demonstrated to produce the highest agreement between Turkers and experts while retaining enough judgments to provide a robust tuning set for automatic evaluation metrics.", "labels": [], "entities": [{"text": "agreement", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9810328483581543}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Weights assigned to random data", "labels": [], "entities": []}, {"text": " Table 1: Performance of normalization techniques", "labels": [], "entities": [{"text": "normalization", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9622979164123535}]}]}