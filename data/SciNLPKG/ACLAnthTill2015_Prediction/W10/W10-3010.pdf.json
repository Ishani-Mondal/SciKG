{"title": [{"text": "A High-Precision Approach to Detecting Hedges and Their Scopes", "labels": [], "entities": [{"text": "Detecting Hedges and Their Scopes", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.9333342432975769}]}], "abstractContent": [{"text": "We extend our prior work on speculative sentence recognition and speculation scope detection in biomedical text to the CoNLL-2010 Shared Task on Hedge Detection.", "labels": [], "entities": [{"text": "speculative sentence recognition", "start_pos": 28, "end_pos": 60, "type": "TASK", "confidence": 0.601217637459437}, {"text": "speculation scope detection", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.6451903184254965}, {"text": "Hedge Detection", "start_pos": 145, "end_pos": 160, "type": "TASK", "confidence": 0.7489579916000366}]}, {"text": "In our participation, we sought to assess the extensibility and portability of our prior work, which relies on linguistic categorization and weighting of hedging cues and on syntactic patterns in which these cues play a role.", "labels": [], "entities": []}, {"text": "For Task 1B, we tuned our categorization and weight-ing scheme to recognize hedging in biological text.", "labels": [], "entities": []}, {"text": "By accommodating a small number of vagueness quantifiers, we were able to extend our methodology to detecting vague sentences in Wikipedia articles.", "labels": [], "entities": [{"text": "detecting vague sentences in Wikipedia articles", "start_pos": 100, "end_pos": 147, "type": "TASK", "confidence": 0.8263726433118185}]}, {"text": "We exploited constituent parse trees in addition to syntactic dependency relations in resolving hedging scope.", "labels": [], "entities": []}, {"text": "Our results are competitive with those of closed-domain trained systems and demonstrate that our high-precision oriented methodology is extensible and portable.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language is imbued with uncertainty, vagueness, and subjectivity.", "labels": [], "entities": []}, {"text": "However, information extraction systems generally focus on extracting factual information, ignoring the wealth of information expressed through such phenomena.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.7560281753540039}]}, {"text": "In recent years, the need for information extraction and text mining systems to identify and model such extra-factual information has increasingly become clear.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7626741826534271}, {"text": "text mining", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.8122001588344574}]}, {"text": "For example, online product and movie reviews have provided a rich context for analyzing sentiments and opinions in text (see fora recent survey), while tentative, speculative nature of scientific writing, particularly in biomedical literature, has provided impetus for recent research in speculation detection ().", "labels": [], "entities": [{"text": "speculation detection", "start_pos": 289, "end_pos": 310, "type": "TASK", "confidence": 0.8401636183261871}]}, {"text": "The term hedging is often used as an umbrella term to refer to an array of extra-factual phenomena in natural language and is the focus of the CoNLL-2010 Shared Task on Hedge Detection.", "labels": [], "entities": [{"text": "CoNLL-2010 Shared Task on Hedge Detection", "start_pos": 143, "end_pos": 184, "type": "TASK", "confidence": 0.6735552350680033}]}, {"text": "The CoNLL-2010 Shared Task on Hedge Detection ( follows in the steps of the recent BioNLP'09 Shared Task on Event Extraction (), in which one task (speculation and negation detection) was concerned with notions related to hedging in biomedical abstracts.", "labels": [], "entities": [{"text": "CoNLL-2010 Shared Task on Hedge Detection", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.7271249194939932}, {"text": "BioNLP'09 Shared Task on Event Extraction", "start_pos": 83, "end_pos": 124, "type": "TASK", "confidence": 0.5886416385571162}, {"text": "negation detection", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.9250665009021759}, {"text": "hedging in biomedical abstracts", "start_pos": 222, "end_pos": 253, "type": "TASK", "confidence": 0.8284274935722351}]}, {"text": "However, the CoNLL-2010 Shared Task differs in several aspects.", "labels": [], "entities": [{"text": "CoNLL-2010 Shared Task", "start_pos": 13, "end_pos": 35, "type": "DATASET", "confidence": 0.7174673676490784}]}, {"text": "It sheds light on the pervasiveness of hedging across genres and domains: in addition to biomedical abstracts, it is concerned with biomedical full text articles as well as with Wikipedia articles.", "labels": [], "entities": []}, {"text": "Both shared tasks have been concerned with scope resolution; however, their definitions of scope are fundamentally different: the BioNLP'09 Shared Task takes the scope of a speculation instance to bean abstract semantic object (an event), thus a normalized logical form.", "labels": [], "entities": [{"text": "scope resolution", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.7213547974824905}]}, {"text": "The CoNLL-2010 Shared Task, on the other hand, defines it as a textual unit based on syntactic considerations.", "labels": [], "entities": []}, {"text": "It is also important to note that hedging in scientific writing is a core aspect of the genre, while it is judged to be a flaw which has to be eradicated in Wikipedia articles.", "labels": [], "entities": [{"text": "hedging in scientific writing", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.8820637911558151}]}, {"text": "Therefore, hedge detection in these genres serves different purposes: explicitly encoding the factuality of a scientific claim (doubtful, probable, etc.) versus flagging unreliable text.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.845352053642273}]}, {"text": "We participated in both tasks of the CoNLL-2010 Shared Task: namely, detection of sentences with uncertainty (Task 1) and resolution of uncertainty scope (Task 2).", "labels": [], "entities": [{"text": "resolution of uncertainty scope", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.8095904737710953}]}, {"text": "Since we pursued both of these directions in prior work, one of our goals in participating in the shared task was to assess how our approach generalized to previously unseen texts, even genres.", "labels": [], "entities": []}, {"text": "Towards this goal, we adopted an open-domain approach, where we aimed to use previously developed techniques to the extent possible.", "labels": [], "entities": []}, {"text": "Among all participating groups, we distinguished ourselves as the one that fully worked in an open-domain setting.", "labels": [], "entities": []}, {"text": "This approach worked reasonably well for uncertainty detection (Task 1); however, for the scope resolution task, we needed to extend our work more substantially, since the notion of scope was fundamentally different than what we adopted previously.", "labels": [], "entities": [{"text": "uncertainty detection", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7618306577205658}, {"text": "scope resolution", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.8282707929611206}]}, {"text": "The performance of our system was competitive; in terms of Fmeasure, we were ranked near the middle in Task 1, while a more significant focus on scope resolution resulted in fourth place ranking among fifteen systems.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.4821152091026306}, {"text": "scope resolution", "start_pos": 145, "end_pos": 161, "type": "TASK", "confidence": 0.8290596604347229}]}, {"text": "We obtained the highest precision in tasks focusing on biological text.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9994679093360901}]}, {"text": "Considering that we chose not to exploit the training data provided to the full extent, we believe that our system is viable in terms of extensibility and portability.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2. These results were  achieved with the threshold 4, which was the opti- mal threshold on the training data.", "labels": [], "entities": [{"text": "opti- mal threshold", "start_pos": 75, "end_pos": 94, "type": "METRIC", "confidence": 0.8731884956359863}]}, {"text": " Table 3: Effect of scope resolution enhancements", "labels": [], "entities": [{"text": "scope resolution enhancements", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.8814207712809244}]}]}