{"title": [{"text": "Bigram HMM with Context Distribution Clustering for Unsupervised Chinese Part-of-Speech tagging", "labels": [], "entities": [{"text": "Bigram HMM", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.7271136343479156}, {"text": "Chinese Part-of-Speech tagging", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.5495307842890421}]}], "abstractContent": [{"text": "This paper presents an unsupervised Chinese Part-of-Speech (POS) tagging model based on the first-order HMM.", "labels": [], "entities": [{"text": "Chinese Part-of-Speech (POS) tagging", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.5016873131195704}]}, {"text": "Unlike the conventional HMM, the number of hidden states is not fixed and will be increased to fit the training data.", "labels": [], "entities": []}, {"text": "In favor of sparse distribution, the Dirich-let priors are introduced with variational inference method.", "labels": [], "entities": []}, {"text": "To reduce the emission variables, words are represented by their contexts and clustered based on the distributional similarities between contexts.", "labels": [], "entities": []}, {"text": "Experiment results show the output state sequence of HMM are highly correlated to the latent annotations of gold POS tags, in context of clustering similarity measures.", "labels": [], "entities": []}, {"text": "The other experiments on areal application, unsuper-vised dependency parsing, reveal that the output sequence can replace the manually annotated tags without loss of accuracies .", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.6952777802944183}]}], "introductionContent": [{"text": "Recently latent variable model has shown great potential in recovering the underlying structures.", "labels": [], "entities": []}, {"text": "For example, the task of POS tagging is to recover the appropriate sequence structure given the input word sequence.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.896893709897995}]}, {"text": "One of the most popular example of latent models is Hidden Markov Model (HMM), which has been extensively studied for many years.", "labels": [], "entities": []}, {"text": "The key problem of HMM is how to find an optimal hidden state number and the topology appropriately.", "labels": [], "entities": [{"text": "HMM", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9290491938591003}]}, {"text": "In most cases, the topology of HMM is predefined by exploiting the domain or empirical knowledge.", "labels": [], "entities": []}, {"text": "This topology will be fixed during the whole process.", "labels": [], "entities": []}, {"text": "Therefore how to select the optimal topology fora certain application or a set of training data is still a problem, because many researches show that varying the size of the state space greatly affects the performance of HMM.", "labels": [], "entities": []}, {"text": "Generally there are two ways to adjust the state number: top-down and bottom-up methods.", "labels": [], "entities": []}, {"text": "In the bottom-up methods, the state number is initialized with a relatively large number.", "labels": [], "entities": []}, {"text": "During the training, the states are merged or trimmed and ended with a small set of states.", "labels": [], "entities": []}, {"text": "On the other hand, the top-down methods) start from a small state set and split one or some states until no further improvement can be obtained.", "labels": [], "entities": []}, {"text": "The bottom-up approaches require huge computational cost in deciding the states to be merged, which makes it impractical for applications with large state space.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the latter approaches.", "labels": [], "entities": []}, {"text": "Another problem in HMM is that EM algorithm might yield local maximum value.", "labels": [], "entities": []}, {"text": "Johnson points out that training HMM with EM gives poor results because it leads to a fairly flat distribution of hidden states when the empirical distribution is highly skewed.", "labels": [], "entities": []}, {"text": "A multinomial prior, which favors sparse distribution, is a good choice for natural language tasks.", "labels": [], "entities": []}, {"text": "In this paper, we proposed anew procedure for inferring the HMM topology and estimating its parameters simultaneously.", "labels": [], "entities": []}, {"text": "Gibbs sampling has been used in infinite HMM (iHMM) () for inference.", "labels": [], "entities": []}, {"text": "Unfortunately Gibbs sampling is slow and difficult to be converged.", "labels": [], "entities": []}, {"text": "In this paper, we proposed the variational Bayesian inference for the adaptive HMM model with Dirichlet prior.", "labels": [], "entities": []}, {"text": "It involves a modification to the Baum-Welch algorithm.", "labels": [], "entities": []}, {"text": "In each iteration, we replaced only one hidden state with two new states until convergence.", "labels": [], "entities": []}, {"text": "To reduce the number of observation variables, the words are pre-clustered and represented by the exemplar within the same cluster.", "labels": [], "entities": []}, {"text": "It is a one-to-many clustering, because the same wordplay different roles under different contexts.", "labels": [], "entities": []}, {"text": "We evaluate the similarity between the distribution of contexts, with the assumption that the context distribution implies syntactic pattern of the given word.", "labels": [], "entities": []}, {"text": "With this clustering, more contextual information can be considered without increasing the model complexity.", "labels": [], "entities": []}, {"text": "A relatively simple model is important for unsupervised task in terms of computational burden and data sparseness.", "labels": [], "entities": []}, {"text": "This is the reason why we do not increase the order of HMM().", "labels": [], "entities": []}, {"text": "With unsupervised algorithms, there are two aspects to be evaluated (Van.", "labels": [], "entities": []}, {"text": "Fist one is how good the outcome clusters are.", "labels": [], "entities": []}, {"text": "We compare the HMM results with the manually POS tags and report the similarity measures based on information theory.", "labels": [], "entities": [{"text": "similarity", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9693013429641724}]}, {"text": "On the other hand, we test how good the outputs act as an intermediate results.", "labels": [], "entities": []}, {"text": "In many natural language tasks, the inputs are word class, not the actual lexical item, for reason of sparsity.", "labels": [], "entities": []}, {"text": "In this paper, we choose the unsupervised dependency parsing as the application to investigate whether our clusters can replace the manual labeled tags or not.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7097486406564713}]}, {"text": "The paper is organized as below: in section 2, we describe the definition of HMM and its variance inference.", "labels": [], "entities": []}, {"text": "We present our dynamic HMM in section 3.", "labels": [], "entities": [{"text": "HMM", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.8371307253837585}]}, {"text": "To overcome the context limitation in the first-order HMM, we present our distributional similarity clustering in section 4.", "labels": [], "entities": []}, {"text": "In section 5, we reported the results of the mentioned experiments while section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "As aforementioned, the outputs of our HMM model are evaluated in two ways, clustering metric and parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 97, "end_pos": 104, "type": "TASK", "confidence": 0.9652996063232422}]}, {"text": "The data used in all experiments are the Chinese data set in CoNLL-2007 shared task.", "labels": [], "entities": [{"text": "Chinese data set in CoNLL-2007 shared task", "start_pos": 41, "end_pos": 83, "type": "DATASET", "confidence": 0.8145722704274314}]}, {"text": "The number of tokens in training, development and test sets are 609,060, 49,620 and 73,153 respectively.", "labels": [], "entities": []}, {"text": "We use all training data set for training the model, whose maximum length is 242.", "labels": [], "entities": []}, {"text": "The hyper parameters of Dirichlet priors are initialized in a homogeneous way.", "labels": [], "entities": []}, {"text": "The initial hidden state is set to 40 in all experiments.", "labels": [], "entities": []}, {"text": "After several iterations, the hidden states number converged to 247, which is much larger than the size of the manually defined POS tags.", "labels": [], "entities": []}, {"text": "Our expectation is the refinement variables can reveal the deep granularity of the POS tags.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.7509778738021851}]}, {"text": "In this paper, we use information theoretic based metrics to quantify the information shared by two clusters.", "labels": [], "entities": []}, {"text": "The most common informationbased clustering metric is the variational of Information (VI).", "labels": [], "entities": [{"text": "variational of Information (VI)", "start_pos": 58, "end_pos": 89, "type": "METRIC", "confidence": 0.9531290431817373}]}, {"text": "Given the clustering result Cr and the gold clustering C g , VI sums up the conditional entropy of one cluster distribution given the other one: where H(C r ) is the entropy associated with the clustering Cr , and mutual information I(C r , C g ) quantifies the mutual dependence between two clusterings, or say the shared information between two variables.", "labels": [], "entities": []}, {"text": "It is easy to see that VI\u2208 [0, log(N)], where N is the number of data points.", "labels": [], "entities": [{"text": "VI", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9370234608650208}]}, {"text": "However, the standard VI is not normalized, which favors clusterings with a small number of clusters.", "labels": [], "entities": []}, {"text": "It can be normalized by dividing by log(N), because the number of training instances are fixed.", "labels": [], "entities": []}, {"text": "However the normalized VI score is misleadingly large, if the N is very large which is the casein our task.", "labels": [], "entities": [{"text": "VI score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9004049897193909}]}, {"text": "In this paper only un-normalized VI scores are reported to show the score ranking.", "labels": [], "entities": [{"text": "VI", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9693830013275146}]}, {"text": "To standardize the measures to have fixed bounds, () defined the normalized Mutual Information (NMI) as: N MI takes its lower bound of 0 if no information is shared by two clusters and the upper bound of 1 if two clusterings are identical.", "labels": [], "entities": []}, {"text": "The NMI however, still has problems, whose variation is sensitive to the choice of the number of clusters.", "labels": [], "entities": [{"text": "NMI", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9257850646972656}]}, {"text": "proposed V-measure to combine two desirable properties of clustering: homogeneity (h) and completeness (c) as follows: Generally homogeneity and completeness runs in opposite way, whose harmonic mean (i.e. V-measure) is a comprise score, just like F-score for the precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 264, "end_pos": 273, "type": "METRIC", "confidence": 0.9991519451141357}, {"text": "recall", "start_pos": 278, "end_pos": 284, "type": "METRIC", "confidence": 0.9937379360198975}]}, {"text": "Let us first examine the contextual word clustering performance.", "labels": [], "entities": [{"text": "contextual word clustering", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.608549952507019}]}, {"text": "The VI score between distributional word categories and gold standard is 2.39.", "labels": [], "entities": [{"text": "VI score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.973939836025238}]}, {"text": "The NMI and V-measure score are 0.53 and 0.48, respectively.", "labels": [], "entities": [{"text": "NMI", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.7246689200401306}, {"text": "V-measure score", "start_pos": 12, "end_pos": 27, "type": "METRIC", "confidence": 0.9641046226024628}]}, {"text": "The clustering performance of the HMM outputs are reported in.", "labels": [], "entities": []}, {"text": "The best VI score achieved was 3.9524, while V-measure was 62.09% and NMI reached 0.8051.", "labels": [], "entities": [{"text": "VI score", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9870283603668213}, {"text": "V-measure", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9946209192276001}, {"text": "NMI", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.49095332622528076}]}, {"text": "To our knowledge, this is the first work to report the distributional clustering similarity measures based on informatics view for Chinese . Similar works can be found on English of WSJ corpus (Van.", "labels": [], "entities": [{"text": "English of WSJ corpus", "start_pos": 171, "end_pos": 192, "type": "DATASET", "confidence": 0.8070472478866577}, {"text": "Van.", "start_pos": 194, "end_pos": 198, "type": "DATASET", "confidence": 0.8755062520503998}]}, {"text": "Their best results of VI, V-measure, achieved with Pitman-Yor prior, were 3.73 and 59%.", "labels": [], "entities": [{"text": "V-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9680219292640686}]}, {"text": "We believe the Chinese results are not good as English correspondences because of the rich unknown words in Chinese ().", "labels": [], "entities": []}, {"text": "The next experiment is to test the goodness of the outcome states of our model in the context of real tasks.", "labels": [], "entities": []}, {"text": "In this work, we consider unsupervised dependency parsing fora fully unsupervised system.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6842816323041916}]}, {"text": "The dependency parsing is to extract the dependency graph whose nodes are the words of the given sentence.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.834436684846878}]}, {"text": "The dependency graph is a directed acyclic graph in which every edge links from ahead word to its dependent.", "labels": [], "entities": []}, {"text": "Because we work on unsupervised methods in this paper, we choose a simple generative head-outward model (Dependency Model with Valence, DMV) () for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 148, "end_pos": 155, "type": "TASK", "confidence": 0.9768139719963074}]}, {"text": "The data through the experiment is restricted to the sentences up to length 10 (excluding punctuation).", "labels": [], "entities": []}, {"text": "Because the main purpose is to test the HMM output rather than to improve the parsing performance, we select the original DMV model without extensions or modifications.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9772665500640869}]}, {"text": "Starting from the root, DMV generates the head, and then each head recursively generates its left and right dependents.", "labels": [], "entities": []}, {"text": "In each direction, the possible dependents are repeatedly chosen until a STOP marker is seen.", "labels": [], "entities": [{"text": "STOP marker", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9062213599681854}]}, {"text": "DMV use inside-outside algorithm for re-estimation.", "labels": [], "entities": [{"text": "DMV", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9272700548171997}]}, {"text": "We choose the \"harmonic\" initializer proposed in () for initialization.", "labels": [], "entities": [{"text": "initialization", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.9776066541671753}]}, {"text": "The valence information is the simplest binary value indicating the adjacency.", "labels": [], "entities": []}, {"text": "For different HMM candidates with varied hidden state number, we directly use the outputs as the input of the DMV and trained a set of models.", "labels": [], "entities": []}, {"text": "Performing test on these individual models, we report the directed dependency accuracies (the fraction of words assigned the correct parent) in.", "labels": [], "entities": []}, {"text": "It is noted that the accuracy monotonically increases when the number of states increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.999431312084198}]}, {"text": "The most drastic increase happened when state changes from 40 to 120.", "labels": [], "entities": []}, {"text": "The accuracy increased from 38.56% to 50.60%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995928406715393}]}, {"text": "If the state number is larger than 180, the increase is not obvious.", "labels": [], "entities": []}, {"text": "The final best accuracy is 54.20%, which improve the standard DMV model by 5.6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999779999256134}]}, {"text": "Therefore we can see that the introduction of more annotations can help the parsing results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 76, "end_pos": 83, "type": "TASK", "confidence": 0.977538526058197}]}, {"text": "However, the improvement is limited and stable when the number of state number is large.", "labels": [], "entities": []}, {"text": "To further improve the parsing performance, one might turn to the extension of DMV model, e.g. introducing more knowledge (prior or lexical information) or more sophistical smoothing techniques.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9741984009742737}]}, {"text": "However, the development of parser is not the focus of this paper.", "labels": [], "entities": []}], "tableCaptions": []}