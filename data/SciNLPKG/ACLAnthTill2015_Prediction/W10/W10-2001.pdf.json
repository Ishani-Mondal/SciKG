{"title": [{"text": "Using Sentence Type Information for Syntactic Category Acquisition", "labels": [], "entities": [{"text": "Syntactic Category Acquisition", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.9058157801628113}]}], "abstractContent": [{"text": "In this paper we investigate anew source of information for syntactic category acquisition: sentence type (question, declarative, imperative).", "labels": [], "entities": [{"text": "syntactic category acquisition", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.733390212059021}]}, {"text": "Sentence type correlates strongly with intonation patterns inmost languages; we hypothesize that these intonation patterns area valuable signal to a language learner, indicating different syntactic patterns.", "labels": [], "entities": []}, {"text": "To test this hypothesis , we train a Bayesian Hidden Markov Model (and variants) on child-directed speech.", "labels": [], "entities": []}, {"text": "We first show that simply training a separate model for each sentence type decreases performance due to sparse data.", "labels": [], "entities": []}, {"text": "As an alternative, we propose two new models based on the BHMM in which sentence type is an observed variable which influences either emission or transition probabilities.", "labels": [], "entities": [{"text": "BHMM", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.7991266250610352}]}, {"text": "Both models outperform a standard BHMM on data from English, Cantonese, and Dutch.", "labels": [], "entities": [{"text": "BHMM", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.7408734560012817}]}, {"text": "This suggests that sentence type information available from intonational cues maybe helpful for syntactic acquisition cross-linguistically.", "labels": [], "entities": [{"text": "syntactic acquisition", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.7910225093364716}]}], "introductionContent": [{"text": "Children acquiring the syntax of their native language have access to a large amount of contextual information.", "labels": [], "entities": []}, {"text": "Acquisition happens on the basis of speech, and the acoustic signal carries rich prosodic and intonational information that children can exploit.", "labels": [], "entities": []}, {"text": "A key task is to separate the acoustic properties of a word from the underlying sentence intonation.", "labels": [], "entities": []}, {"text": "Infants become attuned to the pragmatic and discourse functions of utterances as signalled by intonation extremely early; in this they are helped by the fact that intonation contours of child and infant directed speech are especially well differentiated between sentence types (.", "labels": [], "entities": []}, {"text": "Children learn to use appropriate intonational melodies to communicate their own intentions at the one word stage, before overt syntax develops).", "labels": [], "entities": []}, {"text": "It follows that sentence type information (whether a sentence is declarative, imperative, or a question), as signaled by intonation, is readily available to children by the time they start to acquire syntactic categories.", "labels": [], "entities": []}, {"text": "Sentence type also has an effect on sentence structure in many languages (most notably on word order), so we hypothesise that sentence type is a useful cue for syntactic category learning.", "labels": [], "entities": [{"text": "Sentence type", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8454495072364807}, {"text": "syntactic category learning", "start_pos": 160, "end_pos": 187, "type": "TASK", "confidence": 0.7524361411730448}]}, {"text": "We test this hypothesis by incorporating sentence type information into an unsupervised model of part of speech tagging.", "labels": [], "entities": [{"text": "part of speech tagging", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.6371996998786926}]}, {"text": "We are unaware of previous work investigating the usefulness of this kind of information for syntactic category acquisition.", "labels": [], "entities": [{"text": "syntactic category acquisition", "start_pos": 93, "end_pos": 123, "type": "TASK", "confidence": 0.7882511417071024}]}, {"text": "In other domains, intonation has been used to identify sentence types as a means of improving speech recognition language models.", "labels": [], "entities": [{"text": "speech recognition language", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.757989893356959}]}, {"text": "Specifically, found that using intonation to recognize dialogue acts (which to a significant extent correspond to sentence types) and then using a specialized language model for each type of dialogue act led to a significant decrease in word error rate.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 237, "end_pos": 252, "type": "METRIC", "confidence": 0.6275091171264648}]}, {"text": "In the remainder of this paper, we first present the Bayesian Hidden Markov Model (BHMM;) that is used as the baseline model of category acquisition, as well as our extensions to the model, which incorporate sentence type information.", "labels": [], "entities": [{"text": "category acquisition", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.7868949770927429}]}, {"text": "We then discuss the distinctions in sentence type that we used and our evaluation measures, and finally our experimental results.", "labels": [], "entities": []}, {"text": "We perform experiments on corpora in four different languages: English, Spanish, Cantonese, and Dutch.", "labels": [], "entities": []}, {"text": "Our results on Spanish show no difference between the baseline and the models incorporating sentence type, possibly due to the small size of the Spanish corpus.", "labels": [], "entities": []}, {"text": "Results on all other corpora show a small improvement in performance when sentence type is included as a cue to the learner.", "labels": [], "entities": []}, {"text": "These crosslinguistic results suggest that sentence type maybe a useful source of information to children acquiring syntactic categories.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation of fully unsupervised part of speech tagging is known to be problematic, due to the fact that the part of speech clusters found by the model are unlabeled, and do not automatically correspond to any of the gold standard part of speech categories.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.7094103991985321}]}, {"text": "We report three evaluation measures in our experiments, in order to avoid the weaknesses inherent in any single measure and in an effort to be comparable to previous work.", "labels": [], "entities": []}, {"text": "Matched accuracy (MA), also called many-to-one accuracy, is a commonly used measure for evaluating unlabeled clusterings in part of speech tagging.", "labels": [], "entities": [{"text": "Matched accuracy (MA)", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.8758988618850708}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9025534391403198}, {"text": "speech tagging", "start_pos": 132, "end_pos": 146, "type": "TASK", "confidence": 0.6893223077058792}]}, {"text": "Each unlabeled cluster is given the label of the gold category with which it shares the most members.", "labels": [], "entities": []}, {"text": "Given these labels, accuracy can be measured as usual, as the percentage of tokens correctly labeled.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9993491768836975}]}, {"text": "Note that multiple clusters may have the same label if several clusters match the same gold standard category.", "labels": [], "entities": []}, {"text": "This can lead to a degenerate solution if the model is allowed an unbounded number of categories, in which each word is in a separate cluster.", "labels": [], "entities": []}, {"text": "In less extreme cases, it makes comparing MA across clustering results with different numbers of clusters difficult.", "labels": [], "entities": []}, {"text": "Another serious issue with MA is the \"problem of matching\": matched accuracy only evaluates whether or not the items in the cluster match the majority class label.", "labels": [], "entities": [{"text": "MA", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9782652854919434}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.6996318697929382}]}, {"text": "The non-matching items within a cluster might all be from a second gold class, or they might be from many different classes.", "labels": [], "entities": []}, {"text": "Intuitively, the former clustering should be evaluated as better, but matched accuracy is the same for both clusterings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9246931076049805}]}, {"text": "Variation of Information (VI)) is a clustering evaluation measure that avoids the matching problem.", "labels": [], "entities": []}, {"text": "It measures the amount of information lost and gained when moving between two clusterings.", "labels": [], "entities": []}, {"text": "More precisely: A lower score implies closer clusterings, since each clustering has less information not shared with the other: two identical clusterings have a VI of zero.", "labels": [], "entities": []}, {"text": "However, VI's upper bound is dependent on the maximum number of clusters in C or K, making it difficult to compare clustering results with different numbers of clusters.", "labels": [], "entities": []}, {"text": "As a third, and, in our view, most informative measure, we use V-measure (VM;).", "labels": [], "entities": []}, {"text": "Like VI, VM uses the conditional entropy of clusters and categories to evaluate clusterings.", "labels": [], "entities": []}, {"text": "However, it also has the useful characteristic of being analogous to the precision and recall measures commonly used in NLP.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.99932861328125}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9821402430534363}]}, {"text": "Homogeneity, the precision analogue, is defined as VH is highest when the distribution of categories within each cluster is highly skewed towards a small number of categories, such that the conditional entropy is low.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9989521503448486}, {"text": "VH", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9695265293121338}]}, {"text": "Completeness (recall) is defined symmetrically to VH as: VC measures the conditional entropy of the clusters within each gold standard category, and is highest if each category maps to a single cluster so that each 5 English experiments  Unsupervised models do not suffer from overfitting, so generally it is thought unnecessary to use separate training and testing data, with results being reported on the entire set of input data.", "labels": [], "entities": [{"text": "Completeness", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.9493009448051453}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9220880270004272}, {"text": "VC", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9640558958053589}]}, {"text": "However, there is still a danger, in the course of developing a model, of overfitting in the sense of becoming too finely attuned to a particular set of input data.", "labels": [], "entities": []}, {"text": "To avoid this, we use separate test and development sets.", "labels": [], "entities": []}, {"text": "The BHMM is trained on (train+dev) or (train+test), but evaluation scores are computed based on the dev or test portions of the data only.", "labels": [], "entities": [{"text": "BHMM", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.8502923250198364}]}, {"text": "We run the Gibbs sampler for 2000 iterations, with hyperparameter resampling and simulated annealing.", "labels": [], "entities": []}, {"text": "Each iteration produces an assignment of tags to the tokens in the corpus; the final iteration is used for evaluation purposes.", "labels": [], "entities": []}, {"text": "Since Gibbs sampling is a stochastic algorithm, we run all models multiple times (three, except where stated otherwise) and report average values for all evaluation measures, as well as confidence intervals.", "labels": [], "entities": []}, {"text": "We run our experiments using a variety of sentence type features, ranging from the coarse question/declarative (Q/D) distinction to the full five types.", "labels": [], "entities": []}, {"text": "For reasons of space we do not report all results here, instead confining ourselves to representative samples.", "labels": [], "entities": []}, {"text": "In the previous section we found that sentence type information improved syntactic categorisation in English.", "labels": [], "entities": []}, {"text": "In this section, we evaluate the BHMM's performance on a range of languages other than English, and investigate whether sentence type information is useful across languages.", "labels": [], "entities": [{"text": "BHMM", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.581056535243988}]}, {"text": "To our knowledge this is the first application of the BHMM to non-English data.", "labels": [], "entities": [{"text": "BHMM", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.47554638981819153}]}, {"text": "Nearly all human languages distinguish between yes/no-questions and declaratives in intonation; questions are most commonly marked by rising intonation.", "labels": [], "entities": []}, {"text": "wh-questions do not always have a distinct intonation type, but they are signalled by the presence of members of the small class of whwords.", "labels": [], "entities": []}, {"text": "The CHILDES collection includes tagged corpora for Spanish and Cantonese: the Ornat corpus and the Lee Wong Leung (LWL) corpus ( respectively.", "labels": [], "entities": [{"text": "CHILDES collection", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8164272904396057}, {"text": "Ornat corpus and the Lee Wong Leung (LWL) corpus", "start_pos": 78, "end_pos": 126, "type": "DATASET", "confidence": 0.7960622364824469}]}, {"text": "To cover a greater variety of word order patterns, a Dutch corpus of adult dialogue (not CDS) is also tested.", "labels": [], "entities": [{"text": "Dutch corpus of adult dialogue", "start_pos": 53, "end_pos": 83, "type": "DATASET", "confidence": 0.91463383436203}]}, {"text": "We describe each corpus in turn below;", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Counts of sentence types in the Eve and  Manchester training set. (Test and dev sets are approx- imately 10% of the size of training.) |w| is the average  length in words of utterances of this type. D: declar- atives, I: imperatives, F: fragments, Q: questions, wh:  wh-questions.", "labels": [], "entities": [{"text": "Manchester training set", "start_pos": 51, "end_pos": 74, "type": "DATASET", "confidence": 0.9228572845458984}]}]}