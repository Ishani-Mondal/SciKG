{"title": [{"text": "Handling Unknown Words in Statistical Latent-Variable Parsing Models for Arabic, English and French", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a study of the impact of using simple and complex morphological clues to improve the classification of rare and unknown words for parsing.", "labels": [], "entities": [{"text": "classification of rare and unknown words", "start_pos": 105, "end_pos": 145, "type": "TASK", "confidence": 0.8219649394353231}]}, {"text": "We compare this approach to a language-independent technique often used in parsers which is based solely on word frequencies.", "labels": [], "entities": []}, {"text": "This study is applied to three languages that exhibit different levels of morphological expressiveness: Ara-bic, French and English.", "labels": [], "entities": []}, {"text": "We integrate information about Arabic affixes and morphotac-tics into a PCFG-LA parser and obtain state-of-the-art accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9985478520393372}]}, {"text": "We also show that these morphological clues can be learnt automatically from an annotated corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "For a parser to do a reasonable job of analysing free text, it must have a strategy for assigning part-ofspeech tags to words which are not in its lexicon.", "labels": [], "entities": []}, {"text": "This problem, also known as the problem of unknown words, has received relatively little attention in the vast literature on Wall-Street-Journal (WSJ) statistical parsing.", "labels": [], "entities": [{"text": "Wall-Street-Journal (WSJ) statistical parsing", "start_pos": 125, "end_pos": 170, "type": "TASK", "confidence": 0.8262574871381124}]}, {"text": "This is likely due to the fact that the proportion of unknown words in the standard English test set, Section 23 of the WSJ section of Penn Treebank, is quite small.", "labels": [], "entities": [{"text": "English test set, Section 23 of the WSJ section of Penn Treebank", "start_pos": 84, "end_pos": 148, "type": "DATASET", "confidence": 0.7792317156608288}]}, {"text": "The problem manifests itself when the text to be analysed comes from a different domain to the text upon which the parser has been trained, when the treebank upon which the parser has been trained is limited in size and when the language to be parsed is heavily inflected.", "labels": [], "entities": []}, {"text": "We concentrate on the latter case, and examine the problem of unknown words for two languages which lie on opposite ends of the spectrum of morphological expressiveness and for one language which lies somewhere in between: Arabic, English and French.", "labels": [], "entities": []}, {"text": "In our experiments we use a Berkeley-style latentvariable PCFG parser and we contrast two techniques for handling unknown words within the generative parsing model: one in which no languagespecific information is employed and one in which morphological clues (or signatures) are exploited.", "labels": [], "entities": [{"text": "generative parsing", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.9221765995025635}]}, {"text": "We find that the improvement accrued from looking at a word's morphology is greater for Arabic and French than for English.", "labels": [], "entities": []}, {"text": "The morphological clues we use for English are taken directly from the Berkeley parser () and those for French from recent work on French statistical parsing with the Berkeley parser).", "labels": [], "entities": []}, {"text": "For Arabic, we present our own set of heuristics to extract these signatures and demonstrate a statistically significant improvement of 3.25% over the baseline model which does not employ morphological information.", "labels": [], "entities": []}, {"text": "We next try to establish to what extent these clues can be learnt automatically by extracting affixes from the words in the training data and ranking these using information gain.", "labels": [], "entities": []}, {"text": "We show that this automatic method performs quite well for all three languages.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: In Section 2 we describe latent variable PCFG parsing models.", "labels": [], "entities": [{"text": "latent variable PCFG parsing", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.5936552584171295}]}, {"text": "This is followed in Section 3 by a description of our three datasets, including statistics on the extent of the unknown word problem in each.", "labels": [], "entities": []}, {"text": "In Section 4, we present results on applying aversion of the parser which uses a simple, language-agnostic, unknownword handling technique to our three languages.", "labels": [], "entities": [{"text": "unknownword handling", "start_pos": 108, "end_pos": 128, "type": "TASK", "confidence": 0.7365787327289581}]}, {"text": "In Section 5, we show how this technique is extended to include morphological information and present parsing results for English and French.", "labels": [], "entities": []}, {"text": "In Section 6, we describe the Arabic morphological system and explain how we used heuristic rules to cluster words into word-classes or signatures.", "labels": [], "entities": []}, {"text": "We present parsing results for the version of the parser which uses this information.", "labels": [], "entities": []}, {"text": "In Section 7, we describe our attempts to automatically determine the signatures fora language and present parsing results for the three languages.", "labels": [], "entities": []}, {"text": "Finally, in Section 8, we discuss how this work might be fruitfully extended.", "labels": [], "entities": []}, {"text": "showed that refining treebank categories with parent information leads to more accurate grammars.", "labels": [], "entities": []}, {"text": "This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (.", "labels": [], "entities": []}, {"text": "In PCFG-LAs, first introduced by, the refined categories are learnt from the treebank using unsupervised techniques.", "labels": [], "entities": [{"text": "PCFG-LAs", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.8901993036270142}]}, {"text": "Each base category -and this includes part-of-speech tags -is augmented with an annotation that refines its distributional properties.", "labels": [], "entities": []}], "datasetContent": [{"text": "Arabic We use the the Penn Arabic Treebank (ATB) ().", "labels": [], "entities": [{"text": "Penn Arabic Treebank (ATB)", "start_pos": 22, "end_pos": 48, "type": "DATASET", "confidence": 0.9668256342411041}]}, {"text": "The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn-II treebank.", "labels": [], "entities": [{"text": "ATB", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.7820914387702942}, {"text": "Modern Standard Arabic newswire", "start_pos": 26, "end_pos": 57, "type": "DATASET", "confidence": 0.6697281748056412}, {"text": "Penn-II treebank", "start_pos": 110, "end_pos": 126, "type": "DATASET", "confidence": 0.8303043842315674}]}, {"text": "We use the part-of-speech tagset defined by).", "labels": [], "entities": []}, {"text": "We employ the usual treebank split (80% training, 10% development and 10% test).", "labels": [], "entities": []}, {"text": "English We use the Wall Street Journal section of the Penn-II.", "labels": [], "entities": [{"text": "Wall Street Journal section of the Penn-II", "start_pos": 19, "end_pos": 61, "type": "DATASET", "confidence": 0.9668024097170148}]}, {"text": "We train our parser on sections 2-21 and use section 22 concatenated with section 24 as our development set.", "labels": [], "entities": []}, {"text": "Final testing is carried out on Section 23.", "labels": [], "entities": [{"text": "Section 23", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.9655376672744751}]}, {"text": "French We use the French Treebank () and divide it into 80% for training, 10% for development and 10% for final results.", "labels": [], "entities": [{"text": "French", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.933024525642395}, {"text": "French Treebank", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.9823629856109619}]}, {"text": "We follow the methodology defined by: compound words are merged and the tagset consists of base categories augmented with morphological information in some cases 2 . gives basic unknown word statistics for our three datasets.", "labels": [], "entities": []}, {"text": "We calculate the proportion of words in our development sets which are unknown or rare (specified by the cutoff value) in the corresponding training set.", "labels": [], "entities": []}, {"text": "To control for training set size, we also provide statistics when the English training set is reduced to the size of the Arabic and French training sets and when the Arabic training set is reduced to the size of the French training set.", "labels": [], "entities": [{"text": "English training set", "start_pos": 70, "end_pos": 90, "type": "DATASET", "confidence": 0.7838165760040283}]}, {"text": "In an ideal world where training set sizes are the same for all languages, the problem of unknown words will be greatest for Arabic and smallest for English.", "labels": [], "entities": []}, {"text": "It is reasonable to assume that the levels of inflectional richness have a role to play in these differences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Basic Unknown Word Statistics for Arabic, French and English", "labels": [], "entities": []}, {"text": " Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model", "labels": [], "entities": [{"text": "Varying the Unknown Threshold", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7781357020139694}]}, {"text": " Table 3: Baseline Signatures for Arabic, French and English", "labels": [], "entities": []}, {"text": " Table 5: Baseline Signatures for Arabic", "labels": [], "entities": []}, {"text": " Table 7: Information Gain Signature Results", "labels": [], "entities": [{"text": "Information Gain Signature", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.716042677561442}]}, {"text": " Table 8: F-Scores on Test Sets", "labels": [], "entities": [{"text": "F-Scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.997088611125946}]}]}