{"title": [{"text": "Extracting Medication Information from Discharge Summaries", "labels": [], "entities": [{"text": "Extracting Medication", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8868223428726196}, {"text": "Discharge Summaries", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.6648316234350204}]}], "abstractContent": [{"text": "Extracting medication information from clinical records has many potential applications and was the focus of the i2b2 challenge in 2009.", "labels": [], "entities": [{"text": "Extracting medication information from clinical", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8879971265792846}]}, {"text": "We present a hybrid system, comprised of machine learning and rule-based modules, for medication information extraction.", "labels": [], "entities": [{"text": "medication information extraction", "start_pos": 86, "end_pos": 119, "type": "TASK", "confidence": 0.6523246566454569}]}, {"text": "With only a handful of template-filling rules, the system's core is a cascade of statistical classifiers for field detection.", "labels": [], "entities": [{"text": "field detection", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.7333309352397919}]}, {"text": "It achieved good performance that was comparable to the top systems in the i2b2 challenge, demonstrating that a heavily statistical approach can perform as well or better than systems with many sophisticated rules.", "labels": [], "entities": []}, {"text": "The system can easily incorporate additional resources such as medication name lists to further improve performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Narrative clinical records store patient medical information, and extracting this information from these narratives supports data management and enables many applications (.", "labels": [], "entities": []}, {"text": "Informatics for Integrating the Biology and the Bedside (i2b2) is an NIH-funded National Center for Biomedical Computing based at Partners HealthCare System, and it has organized annual NLP shared tasks and challenges since 2006 (https://www.i2b2.org/).", "labels": [], "entities": []}, {"text": "The Third i2b2 Workshop on NLP Challenges for Clinical Records in 2009 studied the extraction of medication information from hospital discharge summaries (https://www.i2b2.org/NLP/Medication/), a task we refer to as the i2b2 challenge in this paper.", "labels": [], "entities": [{"text": "extraction of medication information from hospital discharge summaries", "start_pos": 83, "end_pos": 153, "type": "TASK", "confidence": 0.8456925749778748}]}, {"text": "In the past decade, there has been extensive research on information extraction in both the general and biomedical domains.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8847667872905731}]}, {"text": "Interestingly, despite the recent prevalence of statistical approaches inmost NLP tasks (including information extraction), most of the systems developed for the i2b2 challenge were rulebased.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.7806425988674164}]}, {"text": "In this paper we present our hybrid system, whose core is a cascade of statistical classifiers that identify medication fields such as medication names and dosages.", "labels": [], "entities": []}, {"text": "The fields are then assembled to form medication entries.", "labels": [], "entities": []}, {"text": "While our system did not participate in the i2b2 challenge (as we were part of the organizing team), it achieved good results that matched the top i2b2 systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "The i2b2 challenge used two sets of evaluation metrics: horizontal and vertical metrics.", "labels": [], "entities": []}, {"text": "Horizontal metrics measured system performance at the entry level, whereas vertical metrics measured system performance at the field level.", "labels": [], "entities": []}, {"text": "Both sets of metrics compared the system output and the gold standard at the span level for exact match and at the token level for inexact match, using precision, recall, and F-score ().", "labels": [], "entities": [{"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9996042847633362}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9991275668144226}, {"text": "F-score", "start_pos": 175, "end_pos": 182, "type": "METRIC", "confidence": 0.9989860653877258}]}, {"text": "The primary metric for the challenge is exact horizontal Fscore, which is the metric we use to evaluate our system.: The data sets used in our experiments.", "labels": [], "entities": [{"text": "exact horizontal Fscore", "start_pos": 40, "end_pos": 63, "type": "METRIC", "confidence": 0.8122490644454956}]}, {"text": "The numbers in parentheses are the average numbers of entries or fields per discharge summary.", "labels": [], "entities": []}, {"text": "In this section, we report the performance of our system on the development set (Section 4.1-4.3) and the test set (Section 4.4).", "labels": [], "entities": []}, {"text": "The data sets are described in.", "labels": [], "entities": []}, {"text": "For all the experiments in this section, unless specified otherwise, we report exact horizontal precision/recall/F-score, the primary metrics for the i2b2 challenge.", "labels": [], "entities": [{"text": "exact horizontal precision/recall/", "start_pos": 79, "end_pos": 113, "type": "METRIC", "confidence": 0.6919313569863638}, {"text": "F-score", "start_pos": 113, "end_pos": 120, "type": "METRIC", "confidence": 0.596545398235321}]}, {"text": "For the three modules in the field detection step, we use the Maximum Entropy (MaxEnt) learner in the Mallet package) because, in general, MaxEnt produces good results without much parameter tuning and the training time for MaxEnt is much faster than more sophisticated algorithms such as CRF ().", "labels": [], "entities": [{"text": "field detection", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.7476424872875214}]}, {"text": "To determine whether the difference between two systems' performances is statistically significant, we use approximate randomization tests) as follows.", "labels": [], "entities": []}, {"text": "Given two systems that we would like to compare, we first calculate the difference between exact horizontal F-scores.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.7386229038238525}]}, {"text": "Then two pseudo-system outputs are generated by randomly swapping (at 0.5 probability) the two system outputs for each discharge summary.", "labels": [], "entities": []}, {"text": "If the difference between F-scores of these pseudooutputs is no less than the original F-score difference, a counter, cnt, is increased by one.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9619965553283691}, {"text": "F-score difference", "start_pos": 87, "end_pos": 105, "type": "METRIC", "confidence": 0.9513511061668396}]}, {"text": "This process was repeated n=10,000 times, and the pvalue of the significance is equal to (cnt+1)/(n+1).", "labels": [], "entities": []}, {"text": "If the p-value is smaller than a predefined threshold (e.g., 0.05), we conclude that the difference between the two systems is statistically significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The data sets used in our experiments. The numbers in parentheses are the average numbers  of entries or fields per discharge summary.", "labels": [], "entities": []}, {"text": " Table 3.  Among them, only the top system, developed by  the University of Sydney, used a hybrid approach,  whereas the rest were rule-based.", "labels": [], "entities": []}, {"text": " Table 3: The performance (exact horizontal preci- sion/recall/F-score) of the top five i2b2 systems on  the test set.", "labels": [], "entities": [{"text": "exact horizontal preci- sion/recall/", "start_pos": 27, "end_pos": 63, "type": "METRIC", "confidence": 0.7466325610876083}, {"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.5960912704467773}]}, {"text": " Table 4: System performance on the development  set with different feature sets", "labels": [], "entities": []}, {"text": " Table 5: The performance (exact preci- sion/recall/F-score) of field detection on the devel- opment set.", "labels": [], "entities": [{"text": "exact preci- sion/recall/", "start_pos": 27, "end_pos": 52, "type": "METRIC", "confidence": 0.8077524048941476}, {"text": "F-score", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.5573844909667969}, {"text": "field detection", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.6215125471353531}]}, {"text": " Table 6: The performance of the field linking step  on the development set (cheating: assuming perfect  field input; non-cheating: using the output of the  field detection step)", "labels": [], "entities": [{"text": "cheating", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9934914708137512}]}, {"text": " Table 7: System performance on the test set when  trained on the union of the training and the devel- opment sets with F1-F4b features.", "labels": [], "entities": []}]}