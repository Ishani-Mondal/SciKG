{"title": [{"text": "Comparing Local and Sequential Models for Statistical Incremental Natural Language Understanding", "labels": [], "entities": [{"text": "Statistical Incremental Natural Language Understanding", "start_pos": 42, "end_pos": 96, "type": "TASK", "confidence": 0.8066979646682739}]}], "abstractContent": [{"text": "Incremental natural language understanding is the task of assigning semantic representations to successively larger prefixes of utterances.", "labels": [], "entities": [{"text": "Incremental natural language understanding", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7808699309825897}]}, {"text": "We compare two types of statistical models for this task: a) local models, which predict a single class for an input; and b), sequential models, which align a sequence of classes to a sequence of input tokens.", "labels": [], "entities": []}, {"text": "We show that, with some modifications, the first type of model can be improved and made to approximate the output of the second, even though the latter is more informative.", "labels": [], "entities": []}, {"text": "We show on two different data sets that both types of model achieve comparable performance (signifi-cantly better than a baseline), with the first type requiring simpler training data.", "labels": [], "entities": []}, {"text": "Results for the first type of model have been reported in the literature; we show that for our kind of data our more sophisticated variant of the model performs better.", "labels": [], "entities": []}], "introductionContent": [{"text": "Imagine being at a dinner, when your friend Bert says \"My friend, can you pass me the salt over there, please?\".", "labels": [], "entities": []}, {"text": "It is quite likely that you get the idea that something is wanted of you fairly early into the utterance, and understand what exactly it is that is wanted even before the utterance is over.", "labels": [], "entities": []}, {"text": "This is possible only because you form an understanding of the meaning of the utterance even before it is complete; an understanding which you refine-and possibly revise-as the utterance goes on.", "labels": [], "entities": []}, {"text": "You understand the utterance incrementally.", "labels": [], "entities": []}, {"text": "This is something that is out of reach for most current dialogue systems, which process utterances non-incrementally, en bloc (cf. , inter alia).", "labels": [], "entities": []}, {"text": "Enabling incremental processing in dialogue systems poses many challenges (; ; we focus hereon the sub-problem of modelling incremental understanding-a precondition for enabling truly interactive behaviour.", "labels": [], "entities": []}, {"text": "More specifically, we look at statistical methods for learning mappings between (possibly partial) utterances and meaning representations.", "labels": [], "entities": [{"text": "learning mappings between (possibly partial) utterances and meaning representations", "start_pos": 54, "end_pos": 137, "type": "TASK", "confidence": 0.6069287197156386}]}, {"text": "We distinguish between two types of understanding, which were sketched in the first paragraph above: a) forming a partial understanding, and b) predicting a complete understanding.", "labels": [], "entities": [{"text": "predicting a complete understanding", "start_pos": 144, "end_pos": 179, "type": "TASK", "confidence": 0.7604640126228333}]}, {"text": "Recently, some results have been published on b), predicting utterance meanings, ( ).", "labels": [], "entities": [{"text": "predicting utterance meanings", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.8607653776804606}]}, {"text": "We investigate here how well this predictive approach works in two other domains, and how a simple extension of techniques (ensembles of slot-specific classifiers vs. one frame-specific one) can improve performance.", "labels": [], "entities": []}, {"text": "To our knowledge, task a), computing partial meanings, has so far only been tackled with symbolic methods (e.g.,); we present here some first results on approaching it with statistical models.", "labels": [], "entities": []}, {"text": "Plan of the paper: First, we discuss relevant previous work.", "labels": [], "entities": []}, {"text": "We then define the task of incremental natural language understanding and its two variants in more detail, also looking at how models can be evaluated.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.7065017422040304}]}, {"text": "Finally, we present and discuss the results of our experiments, and close with a conclusion and some discussion of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Whole-Frame Output A straightforward metric is Correctness, which can take the values 1 (output is exactly as expected) or 0 (output is not exactly as expected).", "labels": [], "entities": [{"text": "Correctness", "start_pos": 47, "end_pos": 58, "type": "METRIC", "confidence": 0.9794616103172302}]}, {"text": "Processing a test corpus in this way, we get one number for each utterance prefix, and, averaging this number, one measurement for the whole corpus.", "labels": [], "entities": []}, {"text": "This can give us a first indication of the general quality of the model, but because it weighs the results for prefixes of all lengths equally, it cannot tell us much about how well the incremental processing worked.", "labels": [], "entities": []}, {"text": "In actual applications, we presumably do not expect the model to be correct from the very first word on, but do expect it to get better the longer the available utterance prefix becomes.", "labels": [], "entities": []}, {"text": "To capture this, we define two more metrics: first occurrence (FO), as the position (relative to the eventual length of the full utterance) where the response was correct first; and final decision (FD) as the position from which on the response stayed correct (which consequently can only be measured if indeed the response stays correct).", "labels": [], "entities": [{"text": "first occurrence (FO)", "start_pos": 45, "end_pos": 66, "type": "METRIC", "confidence": 0.8424742102622986}, {"text": "final decision (FD)", "start_pos": 182, "end_pos": 201, "type": "METRIC", "confidence": 0.7885496258735657}]}, {"text": "The difference between FO and FD then tells us something about the stability of hypotheses of the model.", "labels": [], "entities": [{"text": "FO", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9965360164642334}, {"text": "FD", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.9611384868621826}]}, {"text": "In some applications, we may indeed only be able to do further processing with fully corrector at least correctly typed-frames; in which case correctness and FO/FD on frames are appropriate metrics.", "labels": [], "entities": [{"text": "correctness", "start_pos": 142, "end_pos": 153, "type": "METRIC", "confidence": 0.9796161651611328}, {"text": "FO/FD", "start_pos": 158, "end_pos": 163, "type": "METRIC", "confidence": 0.7837408185005188}]}, {"text": "However, sometimes even frames that are only partially correct can be of use, for example if specific system reactions can be tied to individual slots.", "labels": [], "entities": []}, {"text": "To give us more insight about the quality of a model in such cases, we need a metric that is finergrained than binary correctness.", "labels": [], "entities": []}, {"text": "Following ), we can conceptualise our task as one of retrieval of slot/value pairs, and use precision and recall (and, as their combination, f-score) as metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9989898800849915}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9945974349975586}]}, {"text": "As we will see, it will be informative to plot the development of this score over the course of processing the utterance.", "labels": [], "entities": []}, {"text": "For these kinds of evaluations, we need as a gold standard only one annotation per utterance, namely the final frame.", "labels": [], "entities": []}, {"text": "Aligned Output As sequence alignments have more structure-there is a linear order between the tags, and there is exactly one tag per input tokencorrectness is a more fine-grained, and hence more informative, metric here; we define it as the proportion of tags that are correct in a sequence.", "labels": [], "entities": []}, {"text": "We can also use precision and recall here, looking at each position in the sequence individually: Has the tag been recalled (true positive), or has something else been predicted instead (false negative, and false positive)?", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9994982481002808}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9990200996398926}]}, {"text": "Lastly, we can also reconstruct frames from the tag sequences, where sequences of the same tag are interpreted as segmenting off the slot value.", "labels": [], "entities": []}, {"text": "(And hence, what was several points for being right or wrong, one for each tag, becomes one, being either the correct slot value or not.", "labels": [], "entities": []}, {"text": "We will discuss these differences when we show evaluations of aligned output.)", "labels": [], "entities": []}, {"text": "For this type of evaluation, we need goldstandard information of the same kind, that is, we need aligned tag sequences.", "labels": [], "entities": []}, {"text": "This information is potentially more costly to create than the one final semantic representation needed for the wholeframe setting.", "labels": [], "entities": []}, {"text": "Hybrid Output As we will see below, the hybrid form of output ('growing' frames) is produced by ensembles of local classifiers, with one classifier for each possible slot.", "labels": [], "entities": []}, {"text": "How this output can be evaluated depends on what type of information is available.", "labels": [], "entities": []}, {"text": "If we only have the final frame, we can calculate f-score (in the hope that precision will be better than for the whole-frame classifier, as such a classifier ensemble can focus on predicting slots/value pairs for which there is direct evidence); if we do have sequence information, we can convert it to growing frames and evaluate against that.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9995436072349548}]}, {"text": "We use Conditional Random Fields () as our representative of the class of sequential models, as implemented in CRF++.", "labels": [], "entities": []}, {"text": "We use a simple template file that creates features based on a left context of three words.", "labels": [], "entities": []}, {"text": "Even though sequential models have the potential to be truly incremental (in the sense that they could produce anew output when fed anew increment, rather than needing to process the whole prefix again), CRF++ is targeted at tagging applications, and expects full sequences.", "labels": [], "entities": []}, {"text": "We hence test in the same way as the SVMs from the previous section, by computing anew tag sequence for each prefix.", "labels": [], "entities": []}, {"text": "Training again is done only on full utterances / tag sequences.", "labels": [], "entities": []}, {"text": "We compare the CRF results against two baselines.", "labels": [], "entities": []}, {"text": "The simplest consists of just always choosing the most frequent tag, which is \"O\" (for other, marking material that does not contribute directly to the relevant meaning of the utterance, such as \"please\" in \"I'd like to return on Monday, please.\": Results of CRF models its most frequent training data tag.", "labels": [], "entities": [{"text": "O", "start_pos": 79, "end_pos": 80, "type": "METRIC", "confidence": 0.9805262684822083}]}], "tableCaptions": [{"text": " Table 2: FO/FD/EO for some selected slots; averaged over utterances of all lengths", "labels": [], "entities": [{"text": "FO/FD/EO", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.7676225781440735}]}, {"text": " Table 3: Results of CRF models", "labels": [], "entities": [{"text": "CRF", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9174447059631348}]}]}