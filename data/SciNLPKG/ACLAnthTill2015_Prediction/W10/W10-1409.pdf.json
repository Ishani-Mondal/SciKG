{"title": [], "abstractContent": [{"text": "We present and discuss experiments in statistical parsing of French, where terminal forms used during training and parsing are replaced by more general symbols, particularly clusters of words obtained through un-supervised linear clustering.", "labels": [], "entities": [{"text": "statistical parsing of French", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.8181194812059402}]}, {"text": "We build on the work of Candito and Crabb\u00e9 (2009) who proposed to use clusters built over slightly coars-ened French inflected forms.", "labels": [], "entities": []}, {"text": "We investigate the alternative method of building clusters over lemma/part-of-speech pairs, using a raw corpus automatically tagged and lemmatized.", "labels": [], "entities": []}, {"text": "We find that both methods lead to comparable improvement over the baseline (we obtain F 1 =86.20% and F 1 =86.21% respectively, compared to a baseline of F 1 =84.10%).", "labels": [], "entities": [{"text": "F 1", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9830281138420105}, {"text": "F 1", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9867050051689148}]}, {"text": "Yet, when we replace gold lemma/POS pairs with their corresponding cluster, we obtain an upper bound (F 1 =87.80) that suggests room for improvement for this technique, should tag-ging/lemmatisation performance increase for French.", "labels": [], "entities": [{"text": "F 1", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9867711067199707}]}, {"text": "We also analyze the improvement in performance for both techniques with respect to word frequency.", "labels": [], "entities": []}, {"text": "We find that replacing word forms with clusters improves attachment performance for words that are originally either unknown or low-frequency, since these words are replaced by cluster symbols that tend to have higher frequencies.", "labels": [], "entities": []}, {"text": "Furthermore, clustering also helps significantly for medium to high frequency words, suggesting that training on word clusters leads to better probability estimates for these words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical parsing techniques have dramatically improved over the last 15 years, yet lexical data sparseness remains a critical problem.", "labels": [], "entities": [{"text": "Statistical parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.790901243686676}]}, {"text": "And the richer the morphology of a language, the sparser the treebankdriven lexicons will be for that language.", "labels": [], "entities": []}, {"text": "have proposed to use word clusters as features to improve graph-based statistical dependency parsing for English and Czech.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.6191578606764475}]}, {"text": "Their clusters are obtained using unsupervised clustering, which makes it possible to use a raw corpus containing several million words.", "labels": [], "entities": []}, {"text": "applied clustering to generative constituency parsing for French.", "labels": [], "entities": [{"text": "generative constituency parsing", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.9350084662437439}]}, {"text": "They use a desinflection step that removes some inflection marks from word forms and then replaces them with word clusters, resulting in a significant improvement in parsing performance.", "labels": [], "entities": []}, {"text": "Clustering words seems useful as away of addressing the lexical data sparseness problem, since counts on clusters are more reliable and lead to better probability estimates.", "labels": [], "entities": []}, {"text": "Clustering also appears to address the mismatch of vocabularies between the original treebank and any external, potentially out-of-domain corpus: clusters operate as an intermediary between words from the treebank and words from the external corpus used to compute clusters.", "labels": [], "entities": []}, {"text": "Furthermore, parsing word clusters instead of word forms augments the known vocabulary.", "labels": [], "entities": [{"text": "parsing word clusters", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.8543010354042053}]}, {"text": "However, depending on the clustering method, clusters are either not very reliable or are available only for very frequent words.", "labels": [], "entities": []}, {"text": "In order to parse word clusters one needs to determine which word clusters are reliable enough to be beneficial, so the tuning of parameters such as cluster granularity and cluster reliability becomes very important.", "labels": [], "entities": []}, {"text": "The aim of this paper is to give an in-depth study of the \"parsing word clusters\" technique.", "labels": [], "entities": [{"text": "parsing word clusters", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.8867417772610983}]}, {"text": "In particular, starting from the  experiments, we investigate the use of clustering lem-mas instead of desinflected forms.", "labels": [], "entities": []}, {"text": "We also provide an analysis of the performance gains obtained with respect to word frequency (frequent words, rare words, unknown words).", "labels": [], "entities": []}, {"text": "In the next section, we describe the French treebank used as the basis for all of our experiments.", "labels": [], "entities": [{"text": "French treebank", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9777922332286835}]}, {"text": "We describe in section 3 the statistical parser used for training and testing.", "labels": [], "entities": []}, {"text": "We then describe the desinflection process used prior to unsupervised clustering (section 4), and the Brown algorithm we use for unsupervised clustering (section ).", "labels": [], "entities": []}, {"text": "We describe our experiments and results in section 6, and provide a discussion in section 7.", "labels": [], "entities": []}, {"text": "We then point out some related work and conclude in section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "We then tested several settings differing only in the terminal symbols used in the training set, and in the dev and test sets.", "labels": [], "entities": []}, {"text": "We list these settings in table 2.", "labels": [], "entities": []}, {"text": "For the settings involving unsupervised linear clustering: DFL+CLUST>X: Each desinflected form df is replaced by Cluster 1 (df ) : if df occurred more than X times in the L'Est R\u00e9publicain corpus, it is replaced by its cluster id, otherwise, a special cluster UNKC is used.", "labels": [], "entities": [{"text": "L'Est R\u00e9publicain corpus", "start_pos": 171, "end_pos": 195, "type": "DATASET", "confidence": 0.7137268384297689}, {"text": "UNKC", "start_pos": 260, "end_pos": 264, "type": "DATASET", "confidence": 0.9509589672088623}]}, {"text": "Further, a _c suffix is added if lemmatization renders this step obsolete.", "labels": [], "entities": []}, {"text": "the desinflected form starts with a capital letter, and additional features are appended, capturing whether the form is all digits, ends with ant, or r, or ez (cf. this is the ending of the desinflected forms of unambiguous finite verbs).", "labels": [], "entities": []}, {"text": "showed that these additional features are needed because clusters are noisy: linear context clustering sometimes groups together items that belong to different parts-of-speech.", "labels": [], "entities": [{"text": "linear context clustering", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.6167262693246206}]}, {"text": "GOLDCATLEMMA+CLUST>X: The terminal form used is the gold part-of-speech concatenated to the cluster id of the gold POS+lemma, or UNKC if that pair did not occur more than X times in the L'Est R\u00e9publicain corpus.", "labels": [], "entities": [{"text": "L'Est R\u00e9publicain corpus", "start_pos": 186, "end_pos": 210, "type": "DATASET", "confidence": 0.8458094994227091}]}, {"text": "We evaluate parsing performance using labeled FMeasure (combining labeled precision and labeled: Parsing performance on the dev set/test set when training and parsing make use of clustered terminal symbols.", "labels": [], "entities": [{"text": "parsing", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.9687824845314026}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.756201446056366}]}, {"text": "F 1 <40 is the F-Measure combining labeled precision and labeled recall for sentences of less than 40 words.", "labels": [], "entities": [{"text": "F 1 <40", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9457817226648331}, {"text": "F-Measure", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9532690048217773}, {"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.7867687344551086}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9112616181373596}]}, {"text": "All other metrics are for all sentences of the dev set/test set.", "labels": [], "entities": []}, {"text": "UAS = Unlabeled attachement score of converted constituency trees into surface dependency trees.", "labels": [], "entities": [{"text": "UAS", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.971279501914978}]}, {"text": "All metrics ignore punctuation tokens.", "labels": [], "entities": []}, {"text": "recall) both for sentences of less than 40 words, and for all sentences . We also use the unlabeled attachment score (UAS), obtained when converting the constituency trees output by the BKY parsers into surface dependency trees, using the conversion procedure and software of 8 . Punctuation tokens are ignored in all metrics.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 90, "end_pos": 122, "type": "METRIC", "confidence": 0.8403512338797251}]}], "tableCaptions": [{"text": " Table 1: MORFETTE performance on the FTB-UC dev  and test sets (with and without punctuation)", "labels": [], "entities": [{"text": "MORFETTE", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8869363069534302}, {"text": "FTB-UC dev  and test sets", "start_pos": 38, "end_pos": 63, "type": "DATASET", "confidence": 0.8572255730628967}]}, {"text": " Table 3: Parsing performance on the dev set/test set when training and parsing make use of clustered terminal symbols.  F 1 <40 is the F-Measure combining labeled precision and labeled recall for sentences of less than 40 words. All other  metrics are for all sentences of the dev set/test set. UAS = Unlabeled attachement score of converted constituency  trees into surface dependency trees. All metrics ignore punctuation tokens.", "labels": [], "entities": [{"text": "F 1", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9880172908306122}, {"text": "recall", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.7150577902793884}, {"text": "UAS", "start_pos": 296, "end_pos": 299, "type": "METRIC", "confidence": 0.960753321647644}]}, {"text": " Table 4: Tagging accuracy and UAS scores for words in the dev set, grouped by ranges of frequencies in the original  training set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9616617560386658}, {"text": "UAS scores", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9699671566486359}]}, {"text": " Table 5: Tagging accuracy and UAS scores for modified terminal symbols in the dev set, grouped by ranges of fre- quencies in the modified training sets. The \"replaced by UNKC*\" line corresponds to the case where the desinflected  form or the POS+lemma pair does not appear more than 200 times in the L'est R\u00e9publicain corpus.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9458439946174622}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9781894087791443}, {"text": "UAS", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9717430472373962}, {"text": "L'est R\u00e9publicain corpus", "start_pos": 301, "end_pos": 325, "type": "DATASET", "confidence": 0.720329761505127}]}]}