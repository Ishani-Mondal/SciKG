{"title": [{"text": "How to Drink from a Fire Hose: One Person Can Annoscribe 693 Thousand Utterances in One Month", "labels": [], "entities": [{"text": "Drink from a Fire Hose", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.7135761976242065}]}], "abstractContent": [{"text": "Transcription and semantic annotation (annoscription) of utterances is crucial part of speech performance analysis and tuning of spoken dialog systems and other natural language processing disciplines.", "labels": [], "entities": [{"text": "Transcription and semantic annotation (annoscription) of utterances", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.7758865853150686}, {"text": "speech performance analysis", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.6341321070988973}]}, {"text": "However, the fact that these are manual tasks makes them expensive and slow.", "labels": [], "entities": []}, {"text": "In this paper, we will discuss how anno-scription can be partially automated.", "labels": [], "entities": []}, {"text": "We will show that annoscription can reach a throughput of 693 thousand utterances per person month under certain assumptions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ever since spoken dialog systems entered the commercial market in the mid 1990s, the caller's speech input is subject to collection, transcription, and often also semantic annotation.", "labels": [], "entities": []}, {"text": "Utterance transcriptions and annotations (annoscriptions) are used to measure speech recognition and spoken language understanding performance of the application.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.7501383125782013}]}, {"text": "Furthermore, they are used to improve speech recognition and application functionality by tuning grammars, introducing new transitions in the call flow to cover more of the callers' demands, or changing prompt wording or application logic to influence the speech input.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7211229056119919}]}, {"text": "Annoscriptions are also crucial for training statistical language models and utterance classifiers for call routing or other unconstrained speech input contexts ().", "labels": [], "entities": [{"text": "call routing", "start_pos": 103, "end_pos": 115, "type": "TASK", "confidence": 0.7608026564121246}]}, {"text": "Since very recently, statistical methods are used to replace conventional rule-based grammars in every recognition context of commercial spoken dialog systems).", "labels": [], "entities": []}, {"text": "This replacement is only possible by collecting massive amounts of annoscribed data from all contexts of an application.", "labels": [], "entities": []}, {"text": "To give the reader an idea of what massive means in this case, in (), we used 2,184,203 utterances to build a complex call routing system.", "labels": [], "entities": [{"text": "call routing", "start_pos": 118, "end_pos": 130, "type": "TASK", "confidence": 0.7662637531757355}]}, {"text": "In (), 4,293,898 utterances were used to localize an English Internet troubleshooting application to Spanish.", "labels": [], "entities": []}, {"text": "Considering that professional service providers may charge as much as 50 US cents for annoscribing a single utterance, the usage of these amounts of data seems prohibitive since costs for such a project could potentially add up to several million US dollars.", "labels": [], "entities": []}, {"text": "Furthermore, one has to consider the average speed of annoscription which rarely exceeds 1000 utterances per hour and person.", "labels": [], "entities": []}, {"text": "This means that the turn-around of a project as mentioned above would be several years unless teams of many people work simultaneously.", "labels": [], "entities": []}, {"text": "However, the integration of the work of a large team becomes the more tricky the more people are involved.", "labels": [], "entities": []}, {"text": "This is especially true for the annotation portion since it requires a thorough understanding of the spoken dialog system's domain and design and very often can only be conducted under close supervision by the interaction designer in charge of the project.", "labels": [], "entities": []}, {"text": "Furthermore, there are crucial issues related to intra-and inter-labeler inconsistency becoming more critical the more people work on the same or similar recognition contexts of a given project.", "labels": [], "entities": []}, {"text": "This paper is to show how it is possible to automate large portions of both transcription and annotation while meeting human performance 1 standards.", "labels": [], "entities": []}, {"text": "As an example case, we show how the proposed automation techniques can increase annoscription speed to nearly 693 thousand utterances per person and month.", "labels": [], "entities": [{"text": "speed", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.516601026058197}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Annotation automation rates for three dif- ferent recognition contexts based on Rule (B)  .", "labels": [], "entities": []}]}