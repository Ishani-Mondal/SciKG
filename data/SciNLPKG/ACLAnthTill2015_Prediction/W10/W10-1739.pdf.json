{"title": [{"text": "MANY : Open Source MT System Combination at WMT'10", "labels": [], "entities": [{"text": "MT System Combination", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.8050572673479716}, {"text": "WMT'10", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.8051820993423462}]}], "abstractContent": [{"text": "LIUM participated in the System Combination task of the Fifth Workshop on Statistical Machine Translation (WMT 2010).", "labels": [], "entities": [{"text": "System Combination task", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.8063031832377116}, {"text": "Statistical Machine Translation (WMT 2010)", "start_pos": 74, "end_pos": 116, "type": "TASK", "confidence": 0.8177413259233747}]}, {"text": "Hypotheses from 5 French/English MT systems were combined with MANY, an open source system combination software based on confusion networks currently developed at LIUM.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.5553162693977356}, {"text": "MANY", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.6797842383384705}, {"text": "LIUM", "start_pos": 163, "end_pos": 167, "type": "DATASET", "confidence": 0.944462776184082}]}, {"text": "The system combination yielded significant improvements in BLEU score when applied on WMT'09 data.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9652978479862213}, {"text": "WMT'09 data", "start_pos": 86, "end_pos": 97, "type": "DATASET", "confidence": 0.9749633073806763}]}, {"text": "The same behavior has been observed when tuning is performed on development data of this year evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "This year, the LIUM computer science laboratory has participated in the French-English system combination task at WMT'10 evaluation campaign.", "labels": [], "entities": [{"text": "WMT'10 evaluation campaign", "start_pos": 114, "end_pos": 140, "type": "DATASET", "confidence": 0.7886266907056173}]}, {"text": "The system used for this task is MANY 1, an open source system combination software based on Confusion Networks (CN).", "labels": [], "entities": []}, {"text": "Several improvements have been made in order to being able to combine many systems outputs in a decent time.", "labels": [], "entities": []}, {"text": "The focus has been put on the tuning step, and more precisely how to perform system parameter tuning.", "labels": [], "entities": [{"text": "system parameter tuning", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.642586867014567}]}, {"text": "Two methods have been experimented corresponding to two different representations of system combination.", "labels": [], "entities": []}, {"text": "In the first one, system combination is considered as a whole : fed by system hypotheses as input and generating anew hypothesis as output.", "labels": [], "entities": []}, {"text": "The second method considers that the alignment module is independent from the decoder, so that the parameters from each module can be tuned separately.", "labels": [], "entities": []}, {"text": "Those tuning approaches are described in section 3.", "labels": [], "entities": []}, {"text": "Before that, a quick description of MANY, including recent developments, can be found in section 2.", "labels": [], "entities": [{"text": "MANY", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.3667781352996826}]}, {"text": "Results on WMT'09 data are presented in section 4 along results of tuning on newssyscombtune2010.", "labels": [], "entities": [{"text": "WMT'09 data", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.9812212884426117}, {"text": "newssyscombtune2010", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.9390457272529602}]}, {"text": "2 System description MANY is a system combination software) based on the decoding of a lattice made of several Confusion Networks (CN).", "labels": [], "entities": []}, {"text": "This is a widespread approach in MT system combination (;;).", "labels": [], "entities": [{"text": "MT system combination", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.9022225340207418}]}, {"text": "MANY can be decomposed in two main modules.", "labels": [], "entities": [{"text": "MANY", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8503220081329346}]}, {"text": "The first one is the alignment module which actually is a modified version of TERp (.", "labels": [], "entities": [{"text": "alignment", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9720208644866943}, {"text": "TERp", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.47321465611457825}]}, {"text": "Its role is to incrementally align the hypotheses against a backbone in order to create a confusion network.", "labels": [], "entities": []}, {"text": "Those confusion networks are then connected together to create a lattice.", "labels": [], "entities": []}, {"text": "This module uses different costs (which corresponds to a match, an insertion, a deletion, a substitution, a shift, a synonym and a stem) to compute the best alignment and incrementally build a confusion network.", "labels": [], "entities": []}, {"text": "In the case of confusion network, the match (substitution, synonyms, and stems) costs are considered when the word in the hypothesis matches (is a substitution, a synonyms or a stems of) at least one word of the considered confusion sets in the CN, as shown in.", "labels": [], "entities": []}, {"text": "The second module is the decoder.", "labels": [], "entities": []}, {"text": "This decoder is based on the token pass algorithm and it accepts as input the lattice previously created.", "labels": [], "entities": []}, {"text": "The probabilities computed in the decoder can be expressed as follow : where Len(W ) is the length of the hypothesis, P ws (n) is the score of then th word in the lattice, P lm (n) is its LM probability, L pen (n) is the length penalty (which apply when W n is not a null-arc), N pen (n) is the penalty applied when crossing a null-arc, and the \u03b1 i are the features weights.", "labels": [], "entities": [{"text": "length penalty", "start_pos": 221, "end_pos": 235, "type": "METRIC", "confidence": 0.9690146744251251}]}], "datasetContent": [{"text": "During experiments, data from last year evaluation campaign are used for testing the tuning approach.", "labels": [], "entities": []}, {"text": "news-dev2009a is used as development set, and news-dev2009b as internal test, these corpora are described in For the sake of speed and simplicity, the five best systems (ranking given by score on dev) are considered only.", "labels": [], "entities": [{"text": "speed", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.9840376377105713}]}, {"text": "Baseline systems performances on dev and test are presented in  When tuning all parameters together, the set obtained is presented in: Parameters obtained with 1-step tuning.", "labels": [], "entities": []}, {"text": "protocol applied on news-dev2009a provides the set of parameters presented in: Parameters obtained with 2-step tuning.", "labels": [], "entities": []}, {"text": "Results on development corpus of WMT'09 (used as test set) are presented in  can observe that 2-step tuning provides almost 0.9 BLEU point improvement on development corpus which is well reflected on test set with again of more than 0.7 BLEU.", "labels": [], "entities": [{"text": "WMT'09", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.8122655749320984}, {"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9978052973747253}, {"text": "BLEU", "start_pos": 237, "end_pos": 241, "type": "METRIC", "confidence": 0.990506112575531}]}, {"text": "The best results are obtain when tuning all parameters together, which give more than 1 BLEU point improvement on dev and more than 0.9 on test.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9994142055511475}]}, {"text": "For this year system combination tasks, a development corpus (syscombtune) and the test (syscombtest), described in   The result provided by the system with this configuration can be compared to the single systems in  A behavior comparable to WMT'09 evaluation campaign is observed, which suggests that the approach is correct.", "labels": [], "entities": [{"text": "WMT'09", "start_pos": 243, "end_pos": 249, "type": "DATASET", "confidence": 0.7403555512428284}]}], "tableCaptions": [{"text": " Table 1: WMT'09 corpora : number of sentences,  words and tokens calculated on the reference.", "labels": [], "entities": [{"text": "WMT'09", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.7389494180679321}]}, {"text": " Table 3. The 2-step tuning", "labels": [], "entities": []}, {"text": " Table 3: Parameters obtained with 1-step tuning.", "labels": [], "entities": []}, {"text": " Table 4: Parameters obtained with 2-step tuning.", "labels": [], "entities": []}, {"text": " Table 5: System Combination results on WMT'09  data.", "labels": [], "entities": [{"text": "WMT'09  data", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.9659074544906616}]}, {"text": " Table 6: Description of WMT'10 corpora.", "labels": [], "entities": [{"text": "WMT'10 corpora", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7952333092689514}]}, {"text": " Table 7: Parameters obtained with tuning.", "labels": [], "entities": []}, {"text": " Table 8: Baseline systems performance on  WMT'10 development data (%BLEU).", "labels": [], "entities": [{"text": "WMT'10 development data", "start_pos": 43, "end_pos": 66, "type": "DATASET", "confidence": 0.9022579193115234}, {"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.999047577381134}]}]}