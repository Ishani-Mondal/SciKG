{"title": [{"text": "A Hedgehop over a Max-Margin Framework Using Hedge Cues", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe the experimental settings we adopted in the context of the 2010 CoNLL shared task for detecting sentences containing uncertainty.", "labels": [], "entities": [{"text": "detecting sentences containing uncertainty", "start_pos": 113, "end_pos": 155, "type": "TASK", "confidence": 0.79686638712883}]}, {"text": "The classification results reported on are obtained using discriminative learning with features essentially incorporating lexical information.", "labels": [], "entities": []}, {"text": "Hyper-parameters are tuned for each domain: using BioScope training data for the biomedical domain and Wikipedia training data for the Wikipedia test set.", "labels": [], "entities": [{"text": "BioScope training data", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.8372908631960551}, {"text": "Wikipedia training data", "start_pos": 103, "end_pos": 126, "type": "DATASET", "confidence": 0.8461578090985616}, {"text": "Wikipedia test set", "start_pos": 135, "end_pos": 153, "type": "DATASET", "confidence": 0.9587960044542948}]}, {"text": "By allowing an efficient handling of combinations of large-scale input features, the discriminative approach we adopted showed highly competitive empirical results for hedge detection on the Wikipedia dataset: our system is ranked as the first with an F-score of 60.17%.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 168, "end_pos": 183, "type": "TASK", "confidence": 0.8208714425563812}, {"text": "Wikipedia dataset", "start_pos": 191, "end_pos": 208, "type": "DATASET", "confidence": 0.9675764739513397}, {"text": "F-score", "start_pos": 252, "end_pos": 259, "type": "METRIC", "confidence": 0.9988759160041809}]}], "introductionContent": [], "datasetContent": [{"text": "In our work for the CoNLL shared task, we used Support Vector Machine classification) based on the Gaussian Radial Basis kernel function (RBF).", "labels": [], "entities": [{"text": "Support Vector Machine classification", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.537693627178669}]}, {"text": "We tuned the width of the RBF kernel (denoted by gamma) and the regularization parameter (denoted by C) via grid search over the following range of values: {2 -8 , 2 -7 , 2 -6 , \u20262 4 } for gamma and {1, 10..200 step 10, 200..500 step 100} for C.", "labels": [], "entities": []}, {"text": "During parameter tuning, we performed 10-fold cross validation for each possible value of these parameters.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 7, "end_pos": 23, "type": "TASK", "confidence": 0.7492364346981049}]}, {"text": "Since the training data are unbalanced (e.g. 18% of the total number of sentences in the BioScope training data are labeled as \"uncertain\"), for SVM training we used the following class weights: \u2022 0.1801 for the \"certain\" class and 0.8198 for the \"uncertain\" class on the BioScope dataset; \u2022 0.2235 for the \"certain\" class and 0.7764 for the \"uncertain\" class on the Wikipedia dataset.", "labels": [], "entities": [{"text": "BioScope training data", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.9092315038045248}, {"text": "SVM training", "start_pos": 145, "end_pos": 157, "type": "TASK", "confidence": 0.8744990527629852}, {"text": "BioScope dataset", "start_pos": 272, "end_pos": 288, "type": "DATASET", "confidence": 0.9838367402553558}, {"text": "Wikipedia dataset", "start_pos": 367, "end_pos": 384, "type": "DATASET", "confidence": 0.9861485064029694}]}, {"text": "The system was trained on the training set provided by the CoNLL shared task organizers and tested on the test set provided.", "labels": [], "entities": [{"text": "CoNLL shared task organizers", "start_pos": 59, "end_pos": 87, "type": "DATASET", "confidence": 0.8512818366289139}]}, {"text": "As input features in our max-margin framework, we simply used the frequency of each hedge cue provided with the training corpus in each sentence.", "labels": [], "entities": []}, {"text": "We also used as input features during the tuning phase of our system 2-grams and 3-grams extracted from the list of hedge cues provided with the training corpus.", "labels": [], "entities": []}, {"text": "shows the variability of hedge detection results on Wikipedia training data when changing the RBF-specific kernel parameter and the regularization parameter C.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8653132021427155}, {"text": "Wikipedia training data", "start_pos": 52, "end_pos": 75, "type": "DATASET", "confidence": 0.8491911292076111}]}, {"text": "The contour plot shows that there are three regions (represented in the figure by the darkest landscape color) for parameter values where the cross validation error is lower than 18.2%.", "labels": [], "entities": []}, {"text": "One of these optimal settings for parameter values was used for the results submitted to the CoNLL shared task and we obtained an F-score of 60.17%.", "labels": [], "entities": [{"text": "CoNLL shared task", "start_pos": 93, "end_pos": 110, "type": "DATASET", "confidence": 0.7651183803876241}, {"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9994434714317322}]}, {"text": "When the CoNLL test data containing: The performance of our system corresponding to the best parameter values.", "labels": [], "entities": [{"text": "CoNLL test data", "start_pos": 9, "end_pos": 24, "type": "DATASET", "confidence": 0.917875071366628}]}, {"text": "The performance is denoted in terms of true positives (TP), false positives (FP), false negatives (FN), precision (P), recall (R) and F-score (F) . the reference labels were made available, we also did tests with our system using the other two optimal settings for parameter values.", "labels": [], "entities": [{"text": "true positives (TP), false positives (FP), false negatives (FN)", "start_pos": 39, "end_pos": 102, "type": "METRIC", "confidence": 0.7021940893986646}, {"text": "precision (P)", "start_pos": 104, "end_pos": 117, "type": "METRIC", "confidence": 0.961769163608551}, {"text": "recall (R)", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9604721665382385}, {"text": "F-score (F)", "start_pos": 134, "end_pos": 145, "type": "METRIC", "confidence": 0.9640344828367233}]}], "tableCaptions": [{"text": " Table 1: The percentage of \"uncertain\" sentences (% uncertain sentences) given the total number of  available sentences (#sentences) together with the number of distinct cues in the training corpus and  the performance of the baseline algorithm based on the list of cues extracted from the training corpus.", "labels": [], "entities": []}, {"text": " Table 2: The performance of our system corresponding to the best parameter values. The performance  is denoted in terms of true positives (TP), false positives (FP), false negatives (FN), precision (P),  recall (R) and F-score (F)  .  the reference labels were made available, we also  did  tests  with  our  system  using the other two optimal settings for  parameter values.", "labels": [], "entities": [{"text": "true positives (TP), false positives (FP), false negatives (FN)", "start_pos": 124, "end_pos": 187, "type": "METRIC", "confidence": 0.7075996539172005}, {"text": "precision (P)", "start_pos": 189, "end_pos": 202, "type": "METRIC", "confidence": 0.9616382718086243}, {"text": "recall (R)", "start_pos": 205, "end_pos": 215, "type": "METRIC", "confidence": 0.9583208113908768}, {"text": "F-score (F)", "start_pos": 220, "end_pos": 231, "type": "METRIC", "confidence": 0.9582093358039856}]}]}