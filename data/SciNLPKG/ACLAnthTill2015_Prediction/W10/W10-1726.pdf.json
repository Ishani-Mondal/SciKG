{"title": [], "abstractContent": [{"text": "We present the Johns Hopkins University submission to the 2010 WMT shared translation task.", "labels": [], "entities": [{"text": "Johns Hopkins University submission to the 2010", "start_pos": 15, "end_pos": 62, "type": "DATASET", "confidence": 0.8789646284920829}, {"text": "WMT shared translation task", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.7831871956586838}]}, {"text": "We describe processing steps using open data and open source software used in our submission, and provide the scripts and configurations required to train, tune, and test our machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.7072934359312057}]}], "introductionContent": [{"text": "Research investigating natural language processing and computational linguistics can and should have an extremely low barrier to entry.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.6591677566369375}]}, {"text": "The data with which we work is customarily available in common electronic formats.", "labels": [], "entities": []}, {"text": "The computational techniques which we apply can typically be performed on commodity computing resources which are widely available.", "labels": [], "entities": []}, {"text": "In short, there should be no reason why small research groups and even lone researchers should not be able to join and make substantive contributions furthering our field.", "labels": [], "entities": []}, {"text": "The reality is less encouraging.", "labels": [], "entities": []}, {"text": "Many published articles describe novel techniques and provide interesting results, yet fail to describe technical details in sufficient detail to allow their results to be reproduced by other researchers.", "labels": [], "entities": []}, {"text": "While there are notable and laudable exceptions, many publications fail to provide the source code and scripts necessary to reproduce results.", "labels": [], "entities": []}, {"text": "The use of restricted data, not freely available for download by any interested researcher only compounds these problems.", "labels": [], "entities": []}, {"text": "rightly argues that the implementation details so often ignored in publications are in fact essential for our research to be reproducible science.", "labels": [], "entities": []}, {"text": "Reproducibility in machine translation is made more challenging by the complexity of experimental workflows.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7548016607761383}]}, {"text": "Results in machine translation tasks are dependent on a cascade of processing steps and configurations.", "labels": [], "entities": [{"text": "machine translation tasks", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.8348139723141988}]}, {"text": "While interesting subsets of these usually appear in experimental descriptions, many steps (preprocessing techniques, alignment parameters, translation rule extraction parameters, language model parameters, list of features used) are invariably omitted, even though these configurations are often critical to reproducing results.", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.8514004945755005}]}, {"text": "This paper describes the Johns Hopkins University submission to the 2010 Workshop on Statistical Machine Translation shared translation task.", "labels": [], "entities": [{"text": "Statistical Machine Translation shared translation task", "start_pos": 85, "end_pos": 140, "type": "TASK", "confidence": 0.7896880904833475}]}, {"text": "Links to the software, scripts, and configurations used to run the experiments described herein are provided.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 lists the major examples of publicly available open source machine translation systems, parallel corpora, and machine translation workflow management systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7048010230064392}, {"text": "machine translation workflow management", "start_pos": 120, "end_pos": 159, "type": "TASK", "confidence": 0.8043038249015808}]}, {"text": "Section 3 describes the experimental workflow used to run the shared task translations, with the corresponding experimental design in section 4.", "labels": [], "entities": []}, {"text": "Section 5 presents the shared task results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Running a statistical machine translation system to achieve state-of-the-art performance involves the configuration and execution of numerous interdependent intermediate tools.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6288953125476837}]}, {"text": "To manage task dependencies and tool configuration, our shared task workflow consists of a set of dependency scripts written for GNU Make ().", "labels": [], "entities": []}, {"text": "shows a graph depicting the steps in our experimental workflow, and the dependencies between steps.", "labels": [], "entities": []}, {"text": "Each node in the graph represents a step in the workflow; each step is implemented as a Make script that defines how to run the tools required in that step.", "labels": [], "entities": []}, {"text": "In each experiment, an additional configuration script is provided for each experimental step, defining the parameters to be used when running that step in the current experiment.", "labels": [], "entities": []}, {"text": "Optional front-end wrapper scripts can also be provided, allowing fora complete experiment to be run -from downloading data and software through truecasing translated results -by executing a single make file.", "labels": [], "entities": []}, {"text": "This framework is also conducive to parallelization.", "labels": [], "entities": [{"text": "parallelization", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.9595935940742493}]}, {"text": "Many tasks, such as preprocessing numerous training files, are not dependent on one another.", "labels": [], "entities": []}, {"text": "In such cases make can be configured to execute multiple processes simultaneously on a single multi-processor machine.", "labels": [], "entities": []}, {"text": "In cases where scheduled distributed computing environments such as the Sun Grid Engine are configured, make files can be processed by scheduler-aware make variants (distmake, SGE qmake, Sun Studio dmake) which distribute outstanding tasks to available distributed machines using the relevant distributed scheduler.", "labels": [], "entities": []}, {"text": "Experimental workflows were configured In all experiments, only data freely available for download was used.", "labels": [], "entities": []}, {"text": "No restricted data from the LDC or other sources was used.", "labels": [], "entities": [{"text": "LDC", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.8946402668952942}]}, {"text": "lists the parallel corpora used in training the translation model for each experiment.", "labels": [], "entities": []}, {"text": "The monolingual corpora used in training each target language model are listed in table 2.", "labels": [], "entities": []}, {"text": "In all experiments, newstest2008 was used as a development tuning corpus during minimum error rate training; newstest2009 was used as a development test set.", "labels": [], "entities": []}, {"text": "The shared task data set newstest2010 was used as a final blind test set.", "labels": [], "entities": [{"text": "shared task data set newstest2010", "start_pos": 4, "end_pos": 37, "type": "DATASET", "confidence": 0.6762553930282593}]}, {"text": "All data was automatically downloaded, unzipped, and preprocessed prior to use.", "labels": [], "entities": []}, {"text": "Files provided in XML format were converted to plain text by selecting lines with <seg> tags, then removing the beginning and end tags for each segment; this processing was applied using GNU grep and sed.", "labels": [], "entities": []}, {"text": "The tokenize.perl and lowercase.perl scripts provided for the shared task 2 were applied to all data.", "labels": [], "entities": []}, {"text": "Interpolated n-gram language models for the four target languages were built using the SRI Language Model Toolkit 3 , with n-gram order set to 5.", "labels": [], "entities": [{"text": "SRI Language Model Toolkit 3", "start_pos": 87, "end_pos": 115, "type": "DATASET", "confidence": 0.9062317609786987}]}, {"text": "The Chen and Goodman (1998) technique for modified Kneser-Ney discounting was applied during language model training.", "labels": [], "entities": []}, {"text": "Following, a subset of the available training sentences was selected via subsam-  The experiments described in sections 3 and 4 above provided truecased translations for six language pairs in the translation shared task: English-French, English-German, EnglishSpanish, French-English, German-English, and Spanish-English.: Automatic metric scores for the test set newstest2010 The submitted system ranked highest among shared task participants for the German-English task, according to TER.", "labels": [], "entities": [{"text": "TER", "start_pos": 486, "end_pos": 489, "type": "METRIC", "confidence": 0.8049091696739197}]}, {"text": "In order to provide points of comparison with the 2009 Workshop on Statistical Machine Translation shared translation task participants, table 4 lists automatic metric scores for our systems' translations of the newstest2009 test set, which we used as a development test set.", "labels": [], "entities": [{"text": "Statistical Machine Translation shared translation task", "start_pos": 67, "end_pos": 122, "type": "TASK", "confidence": 0.781033014257749}, {"text": "newstest2009 test set", "start_pos": 212, "end_pos": 233, "type": "DATASET", "confidence": 0.9433939854303995}]}], "tableCaptions": [{"text": " Table 3: Automatic metric scores for the test set  newstest2010", "labels": [], "entities": [{"text": "Automatic metric scores", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.903809646765391}, {"text": "newstest2010", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.47133907675743103}]}, {"text": " Table 4: Automatic metric scores for the develop- ment test set newstest2009", "labels": [], "entities": [{"text": "Automatic metric scores", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.8439304232597351}, {"text": "develop- ment test set newstest2009", "start_pos": 42, "end_pos": 77, "type": "DATASET", "confidence": 0.7669738133748373}]}]}