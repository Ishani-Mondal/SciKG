{"title": [{"text": "Scientific Authoring Support: A Tool to Navigate in Typed Citation Graphs", "labels": [], "entities": []}], "abstractContent": [{"text": "Scientific authors urgently need help in managing the fast increasing number of publications.", "labels": [], "entities": []}, {"text": "We describe and demonstrate a tool that supports authors in browsing graphically through electronically available publications, thus allowing them to quickly adapt to new domains and publish faster.", "labels": [], "entities": []}, {"text": "Navigation is assisted by means of typed citation graphs, i.e. we use methods and resources from computational linguistics to compute the kind of citation that is made from one paper to another (refutation, use, confirmation etc.).", "labels": [], "entities": [{"text": "Navigation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9588621258735657}]}, {"text": "To verify the computed citation type, the user can inspect the highlighted citation sentence in the original PDF document.", "labels": [], "entities": []}, {"text": "While our classification methods used to generate a realistic test data set are relatively simple and could be combined with other proposed approaches, we put a strong focus on usability and quick navigation in the potentially huge graphs.", "labels": [], "entities": []}, {"text": "In the outlook, we argue that our tool could be made part of a community approach to overcome the sparseness and correctness dilemma in citation classification.", "labels": [], "entities": [{"text": "citation classification", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.9209422171115875}]}], "introductionContent": [], "datasetContent": [{"text": "These pattern where then used for the classification algorithm and applied to the extracted citation sentences.", "labels": [], "entities": []}, {"text": "In case of multiple citations with different classes, a voting mechanism was applied were the 'stronger' classes (Agree, Negative, PRecycle) won in standoff cases.", "labels": [], "entities": []}, {"text": "For the total of 91419 citations we obtained the results shown in The numbers reflect a careful classification approach where uncertain citations are classified as Undef.", "labels": [], "entities": []}, {"text": "In case of multiple matches, the first (leftmost) was taken to achieve a unique result.", "labels": [], "entities": []}, {"text": "The results also confirm obervations made in other works: (1) citation classification is a hard task, (2) there are only a few strongly negative citations which coincides with observations made by), (Pendlebury, 2009) and others, (3) the majority of citations is neutral or of unknown type.", "labels": [], "entities": [{"text": "obervations", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.8996716737747192}, {"text": "citation classification", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.9699621498584747}, {"text": "Pendlebury, 2009)", "start_pos": 200, "end_pos": 217, "type": "DATASET", "confidence": 0.8618354946374893}]}, {"text": "An evaluation on a test set of 100 citations spread across all the types of papers with a manual check of the accuracy of the computed labels showed an overall accuracy of 30% mainly caused by the fact that 90% of undefined hits were in fact neutral (i.e., labeling all undefs neutral would increase accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9939892292022705}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9992228746414185}, {"text": "accuracy", "start_pos": 300, "end_pos": 308, "type": "METRIC", "confidence": 0.9980545043945312}]}, {"text": "Negative citations are sparse and unreliable (33%), neutral ones are about 60% accurate, PRecycle: 33%, Agree: 25%.", "labels": [], "entities": [{"text": "accurate", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9690686464309692}, {"text": "PRecycle", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.67501300573349}, {"text": "Agree", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.6478594541549683}]}, {"text": "To sum up, our automatic classification approach based on only local citation information could surely be improved by applying methods described in the literature, but it helped us to quickly (without annotation effort) generate a plausible data set for the main task, visualization and navigation in the typed citation graphs.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.5927601158618927}]}], "tableCaptions": [{"text": " Table 1: Citation classification result", "labels": [], "entities": [{"text": "Citation classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.895758330821991}]}]}