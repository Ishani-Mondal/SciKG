{"title": [{"text": "Large Corpus-based Semantic Feature Extraction for Pronoun Coreference", "labels": [], "entities": [{"text": "Semantic Feature Extraction", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.5972885092099508}, {"text": "Pronoun Coreference", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7453543245792389}]}], "abstractContent": [{"text": "Semantic information is a very important factor in coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.9837805926799774}]}, {"text": "The combination of large corpora and 'deep' analysis procedures has made it possible to acquire a range of semantic information and apply it to this task.", "labels": [], "entities": []}, {"text": "In this paper , we generate two statistically-based semantic features from a large corpus and measure their influence on pronoun coreference.", "labels": [], "entities": [{"text": "pronoun coreference", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.736823320388794}]}, {"text": "One is contextual compatibility , which decides if the antecedent can be used in the anaphor's context; the other is role pair, which decides if the actions asserted of the antecedent and the anaphor are likely to apply to the same entity.", "labels": [], "entities": []}, {"text": "We apply a semantic labeling system and a baseline coreference system to a large corpus to generate semantic patterns and convert them into features in a MaxEnt model.", "labels": [], "entities": []}, {"text": "These features produce an absolute gain of 1.5% to 1.7% in resolution accuracy (a 6% reduction in errors).", "labels": [], "entities": [{"text": "resolution", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9729930758476257}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.8966254591941833}, {"text": "errors", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9896448850631714}]}, {"text": "To understand the limitations of these features, we also extract patterns from the test corpus, use these patterns to train a coreference model, and examine some of the cases where coreference still fails.", "labels": [], "entities": []}, {"text": "We also compare the performance of patterns extracted from semantic role labeling and syntax.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.6375059485435486}]}], "introductionContent": [{"text": "Coreference resolution is the task of determining whether two phrases refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9191957116127014}]}, {"text": "Coreference is critical to most NLP tasks, yet even the sub-problem of pronoun coreference remains very challenging.", "labels": [], "entities": []}, {"text": "In principle, we need several types of information to identify the right antecedent.", "labels": [], "entities": []}, {"text": "First, number and gender agreement constraints can narrow the candidate set.", "labels": [], "entities": []}, {"text": "If multiple candidates remain, we would next use some sequence or syntactic features, like position, word, word salience and discourse focus.", "labels": [], "entities": []}, {"text": "For example, whether an antecedent is in subject position might be helpful because the subject is more likely to be referred to; or an entity that has been referred to repeatedly is more likely to be referred to again.", "labels": [], "entities": []}, {"text": "However, these features do not suffice to pick the correct antecedent, and sometimes similar syntactic structures might have quite different coreference solutions.", "labels": [], "entities": []}, {"text": "For example, for the following two sentences: (1) The terrorist shot a 13-year-old boy; he was arrested after the attack.", "labels": [], "entities": []}, {"text": "(2) The terrorist shot a 13-year-old boy; he was fatally wounded in the attack.", "labels": [], "entities": []}, {"text": "it is likely that \"he\" refers to \"terrorist\" in (1) and \"boy\" in (2).", "labels": [], "entities": []}, {"text": "However, we cannot get the right antecedent using the features we mentioned above because the examples share the same antecedent words and syntactic structure.", "labels": [], "entities": []}, {"text": "People can still resolve these correctly because \"terrorist\" is more likely to be arrested than \"boy\", and because the one shooting is more likely to be arrested than the one being shot.", "labels": [], "entities": []}, {"text": "In such cases, semantic constraints and preferences are required for correct coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.8547694981098175}]}, {"text": "Methods for acquiring and using such knowledge are receiving increasing attention in recent work on anaphora resolution.,,, and all explored this task.", "labels": [], "entities": [{"text": "anaphora resolution.", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.8651233017444611}]}, {"text": "However, this task is difficult because it requires the acquisition of a large amount of semantic information.", "labels": [], "entities": []}, {"text": "Furthermore, there is not universal agreement on the value of these semantic preferences for pronoun coreference.", "labels": [], "entities": [{"text": "pronoun coreference", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7353633046150208}]}, {"text": "reported that such information did not produce apparent improvement in overall pronoun resolution.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7475691139698029}]}, {"text": "In this paper, we will extract semantic features from a semantic role labeling system instead of a parse tree, and explore whether pronoun coreference resolution can benefit from such knowledge, which is automatically extracted from a large corpus.", "labels": [], "entities": [{"text": "pronoun coreference resolution", "start_pos": 131, "end_pos": 161, "type": "TASK", "confidence": 0.7874723076820374}]}, {"text": "We studied two features: the contextual compatibility feature which has been demonstrated to work at the syntactic level by previous work; and the role pair feature, which has not previously been applied to general domain pronoun co-reference.", "labels": [], "entities": []}, {"text": "In addition, to obtain a rough upper bound on the benefits of our approach and understand its limitations, we conducted a second experiment in which the semantic knowledge is extracted from the evaluation corpus.", "labels": [], "entities": []}, {"text": "We will use the term mention to describe an individual referring phrase.", "labels": [], "entities": []}, {"text": "For most studies of coreference, mentions are noun phrases and maybe headed by a name, a common noun, or a pronoun.", "labels": [], "entities": [{"text": "coreference", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.9802592992782593}]}, {"text": "We will use the term entity to refer to a set of coreferential mentions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our coreference solution system uses ACE annotated data and follows the ACE 2005 English entity guidelines.", "labels": [], "entities": [{"text": "ACE annotated data", "start_pos": 37, "end_pos": 55, "type": "DATASET", "confidence": 0.8967247804005941}, {"text": "ACE 2005 English entity", "start_pos": 72, "end_pos": 95, "type": "DATASET", "confidence": 0.9610951989889145}]}, {"text": "The baseline coreference system to compare with is the same one used for extracting semantic features from the large corpus.", "labels": [], "entities": []}, {"text": "It employs an entity-mention (rather than a mention-pair) model.", "labels": [], "entities": []}, {"text": "Besides entity and mention information, which (as mentioned above) is system output, the semantic information is also automatically extracted by a semantic labeling system.", "labels": [], "entities": []}, {"text": "As a result, we report results in section 5.4 which involve no information from the reference (key) annotation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Accuracy of 5-fold cross-validation with sta- tistics-based semantic features", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9909075498580933}]}, {"text": " Table 4. Accuracy of 5-fold cross-validation with self- extracted semantic features", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9901648163795471}]}, {"text": " Table 5. Accuracy of 5-fold cross-validation with self- extracted semantic features based on different levels  of syntactic/semantic relations", "labels": [], "entities": []}]}