{"title": [{"text": "Constructing Large-Scale Person Ontology from Wikipedia", "labels": [], "entities": [{"text": "Constructing Large-Scale Person Ontology", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8684588968753815}]}], "abstractContent": [{"text": "This paper presents a method for constructing a large-scale Person Ontology with category hierarchy from Wikipe-dia.", "labels": [], "entities": []}, {"text": "We first extract Wikipedia category labels which represent person (hereafter, Wikipedia Person Category, WPC) by using a machine learning classifier.", "labels": [], "entities": [{"text": "Wikipedia Person Category", "start_pos": 78, "end_pos": 103, "type": "DATASET", "confidence": 0.8883474667867025}]}, {"text": "We then construct a WPC hierarchy by detecting is-a relations in the Wikipedia category network.", "labels": [], "entities": [{"text": "Wikipedia category network", "start_pos": 69, "end_pos": 95, "type": "DATASET", "confidence": 0.8743156393369039}]}, {"text": "We then extract the titles of Wikipedia articles which represent person (hereafter, Wikipedia person instance, WPI).", "labels": [], "entities": []}, {"text": "Experiments show that the accuracy of WPC extraction is 99.3% precision and 98.4% recall , while that of WPI extraction is 98.2% and 98.6%, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9997310042381287}, {"text": "WPC extraction", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.9248140156269073}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9995985627174377}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9980670809745789}, {"text": "WPI extraction", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.6905778050422668}]}, {"text": "The accuracies are significantly higher than the previous methods.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9978510141372681}]}], "introductionContent": [{"text": "In recent years, we have become increasingly aware of the need for, up-to-date knowledge bases offering broad coverage in order to implement practical semantic inference engines for advanced applications such as question answering, summarization and textual entailment recognition.", "labels": [], "entities": [{"text": "question answering", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.884864866733551}, {"text": "summarization", "start_pos": 232, "end_pos": 245, "type": "TASK", "confidence": 0.9618926644325256}, {"text": "textual entailment recognition", "start_pos": 250, "end_pos": 280, "type": "TASK", "confidence": 0.7770613531271616}]}, {"text": "General ontologies, such as WordNet (, and Nihongo Goi-Taikei (), contain general knowledge of wide range of fields.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9669579863548279}, {"text": "Nihongo Goi-Taikei", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.8598343729972839}]}, {"text": "However, it is difficult to instantly add new knowledge, particularly proper nouns, to these general ontologies.", "labels": [], "entities": []}, {"text": "Therefore, Wikipedia has come to be used as a useful corpus for knowledge extraction because it is a free and largescale online encyclopedia that continues to be actively developed.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7487532794475555}]}, {"text": "For example, in DBpedia (), RDF triples are extracted from the Infobox templates within Wikipedia articles.", "labels": [], "entities": []}, {"text": "In YAGO (), an appropriate WordNet synset (most likely category) is assigned to a Wikipedia category as a super-category, and Wikipedia articles are extracted as instances of the category.", "labels": [], "entities": []}, {"text": "As a first step to make use of proper noun and related up-to-date information in Wikipedia, we focus on person names and the articles and categories related to them because it contains a large number of articles and categories that indicate person, and because large-scale person ontology is useful for applications such as person search and named entity recognition.", "labels": [], "entities": [{"text": "person search", "start_pos": 324, "end_pos": 337, "type": "TASK", "confidence": 0.7287897169589996}, {"text": "named entity recognition", "start_pos": 342, "end_pos": 366, "type": "TASK", "confidence": 0.6294029454390208}]}, {"text": "Examples of a person article are personal name and occupational title such as \"Ichiro\" and \"Financial planner,\" while an example of a person category is occupational title such as \"Sportspeople.\"", "labels": [], "entities": []}, {"text": "The goal of this study is to construct a largescale and comprehensive person ontology by extracting person categories and is-a relations 1 among them.", "labels": [], "entities": []}, {"text": "We first apply a classifier based on machine learning to all Wikipedia categories to extract categories that represent person.", "labels": [], "entities": []}, {"text": "If both of the linked Wikipedia categories are person categories, the category link is labeled as an is-a relation.", "labels": [], "entities": []}, {"text": "We then use a heuristic-based rule to extract the title of articles that represent person as person instance from the person categories.", "labels": [], "entities": []}, {"text": "In the following sections, we first describe the language resources and the previous works.", "labels": [], "entities": []}, {"text": "We then introduce our method for constructing the person ontology and report our experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the XML file of the Japanese Wikipedia as of July 24, 2008.", "labels": [], "entities": [{"text": "XML file of the Japanese Wikipedia as of July 24", "start_pos": 12, "end_pos": 60, "type": "DATASET", "confidence": 0.8233075797557831}]}, {"text": "We removed irrelevant pages by using keywords (e.g., \"image:,\" \"Help:\") in advance.", "labels": [], "entities": []}, {"text": "This cleaning yielded 477,094 Wikipedia articles and 39,782 Wikipedia categories.", "labels": [], "entities": []}, {"text": "We manually annotated each category to indicate whether it represents person (positive) or not (negative).", "labels": [], "entities": []}, {"text": "For ambiguous cases, we used the following criteria: \uff0aPersonal name by itself (e.g., Michael Jackson) is not regarded as WPC because usually it does not have instances.", "labels": [], "entities": []}, {"text": "(Note: personal name as article title is regarded as WPI.", "labels": [], "entities": [{"text": "WPI", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.7034114003181458}]}, {"text": ") \uff0aOccupational title (e.g., Lawyers) is regarded as WPC because it represents a person.", "labels": [], "entities": []}, {"text": "\uff0aFamily (e.g., Brandenburg family) and Ethnic group (e.g., Sioux) are regarded as WPC.", "labels": [], "entities": [{"text": "WPC", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.7210391759872437}]}, {"text": "\uff0aGroup name (e.g., The Beatles) is not regarded as WPC.", "labels": [], "entities": [{"text": "WPC", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.5748005509376526}]}, {"text": "In order to develop a person category classifier, we randomly selected 2,000 Wikipedia categories (positive:435, negative:1,565) from all categories for training . We used the remaining 37,767 categories for evaluation.", "labels": [], "entities": []}, {"text": "To evaluate WPI extraction accuracy, we used Wikipedia articles not listed on the Wikipedia categories used for training.", "labels": [], "entities": [{"text": "WPI extraction", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.9676626026630402}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8932170867919922}]}, {"text": "417,476 Wikipedia articles were used in the evaluation.", "labels": [], "entities": []}, {"text": "To evaluate our method, we used TinySVM-0.09 7 with a linear kernel for classification, and the Japanese morphological analyzer JU-MAN-6.0 8 for word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 145, "end_pos": 162, "type": "TASK", "confidence": 0.7517054975032806}]}, {"text": "The comparison methods are Kobayashi's method and Yamashita's method under the same conditions as our method.", "labels": [], "entities": []}, {"text": "shows the WPCs extraction accuracy.", "labels": [], "entities": [{"text": "WPCs extraction", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7822963893413544}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.973136305809021}]}, {"text": "Precision and recall of proposed method are 6.5 points and 14.8 points better than those of Kobayashi's method, respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9803588390350342}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9996230602264404}]}], "tableCaptions": []}