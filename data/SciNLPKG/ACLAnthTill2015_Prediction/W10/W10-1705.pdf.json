{"title": [{"text": "2010 Failures in English-Czech Phrase-Based MT *", "labels": [], "entities": [{"text": "Phrase-Based MT", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.4978882521390915}]}], "abstractContent": [{"text": "The paper describes our experiments with English-Czech machine translation for WMT10 1 in 2010.", "labels": [], "entities": [{"text": "English-Czech machine translation", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.6672754983107249}, {"text": "WMT10 1 in 2010", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.9217767268419266}]}, {"text": "Focusing primarily on the translation to Czech, our additions to the standard Moses phrase-based MT pipeline include two-step translation to overcome target-side data sparseness and optimization towards SemPOS, a metric better suited for evaluating Czech.", "labels": [], "entities": [{"text": "translation to Czech", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.8873082002003988}, {"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.9132640361785889}]}, {"text": "Unfortunately , none of the approaches bring a significant improvement over our standard setup.", "labels": [], "entities": []}], "introductionContent": [{"text": "Czech is a flective language with very rich morphological system.", "labels": [], "entities": []}, {"text": "Translation between Czech and English poses different challenges for each of the directions.", "labels": [], "entities": [{"text": "Translation between Czech and English", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8632148027420044}]}, {"text": "When translating from Czech, the word order usually needs only minor changes (despite the issue of non-projectivity, a phenomenon occurring at 2% of words but in 23% of Czech sentences, see and).", "labels": [], "entities": []}, {"text": "A much more severe issue is caused by the Czech vocabulary size.", "labels": [], "entities": []}, {"text": "Fortunately, this can be to a certain extent mitigated by backing-off to Czech lemmas if the exact forms are not available.", "labels": [], "entities": []}, {"text": "We are primarily interested in the harder task of translating to Czech and most of the paper deals with this direction.", "labels": [], "entities": [{"text": "translating to Czech", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.9083815217018127}]}, {"text": "After a brief specification of data sets, pre-processing and evaluation method in this section, we provide details on the issue of Czech vocabulary size (Section 2).", "labels": [], "entities": [{"text": "Czech vocabulary size", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.6946419278780619}]}, {"text": "We describe our current attempts at generating Czech * The work on this project was supported by the grants EuroMatrixPlus (FP7-ICT-2007-3-231720 of the EU and 7E09003 of the Czech Republic), GA\u010cRGA\u02c7GA\u010cR P406/10/P259, and MSM 0021620838.", "labels": [], "entities": [{"text": "EuroMatrixPlus", "start_pos": 108, "end_pos": 122, "type": "DATASET", "confidence": 0.9174199104309082}, {"text": "GA\u010cRGA\u02c7GA\u010cR P406/10/P259", "start_pos": 192, "end_pos": 216, "type": "DATASET", "confidence": 0.6614571809768677}, {"text": "MSM 0021620838", "start_pos": 222, "end_pos": 236, "type": "DATASET", "confidence": 0.8805611431598663}]}, {"text": "Thanks to David Kolovratn\u00edk for the help with manual evaluation.", "labels": [], "entities": [{"text": "manual evaluation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.4835205078125}]}, {"text": "1 http://www.statmt.org/wmt10/ word forms in Section 3.", "labels": [], "entities": []}, {"text": "Partly due to the large vocabulary size of Czech, BLEU score () correlates rather poorly with human judgments.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9845705628395081}]}, {"text": "We summarize our efforts to use a better metric in the model optimization in Section 4.", "labels": [], "entities": [{"text": "model optimization", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.775170773267746}]}, {"text": "The final Section 5 lists the exact configurations of our English\u2194Czech primary submissions for WMT10, including the back-off to lemmas we use for Czech-to-English.", "labels": [], "entities": [{"text": "WMT10", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.8458303809165955}]}], "datasetContent": [{"text": "We use WMT10 development sets for tuning (news-test2008) and evaluation (news-test2009).", "labels": [], "entities": [{"text": "WMT10 development sets", "start_pos": 7, "end_pos": 29, "type": "DATASET", "confidence": 0.9491119980812073}]}, {"text": "The official scores on news-test2010 are given only in the main WMT10 paper and not here.", "labels": [], "entities": [{"text": "WMT10 paper", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9836570620536804}]}, {"text": "The BLEU scores reported in this paper are based on truecased word forms in the original tokenization as provided by the decoder.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9981691837310791}]}, {"text": "Therefore they are likely to differ from figures reported elsewhere.", "labels": [], "entities": []}, {"text": "The \u00b1 value given with each BLEU score is the average of the distances to the lower and upper empirical 95% confidence bounds estimated using bootstrapping).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.997409999370575}]}, {"text": "summarizes the differences of Czech and English vocabulary sizes in our parallel corpora.", "labels": [], "entities": []}, {"text": "We see that the vocabulary size of Czech forms (truecased) is more than double compared to English in the Small dataset and significantly larger in the Large dataset as well.", "labels": [], "entities": [{"text": "Small dataset", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.8644543588161469}, {"text": "Large dataset", "start_pos": 152, "end_pos": 165, "type": "DATASET", "confidence": 0.9175208210945129}]}, {"text": "On the other hand, the number of distinct Czech and English lemmas is nearly identical.", "labels": [], "entities": []}, {"text": "40 1 0.2 0.3 0.3 0.3 0.3 5 0.8 0.9 1.0 1.0 1.0 10 1.1 1.3 1.5 1.5 1.5 20 1.2 1.5 1.7 1.7 1.7 50 1.2 1.5 1.7 1.7 1.7 100 1.2 1.5 1.7 1.7 1.7: Percentage of sentences reachable in Czech-to-English small setting with various distortion limits and translation options per coverage (TOpts) (BLEU score 14.76\u00b10.44).", "labels": [], "entities": [{"text": "TOpts", "start_pos": 278, "end_pos": 283, "type": "METRIC", "confidence": 0.9394352436065674}, {"text": "BLEU", "start_pos": 286, "end_pos": 290, "type": "METRIC", "confidence": 0.9947559833526611}]}, {"text": "lists out-of-vocabulary (OOV) rates of our Small and Large data setting given the development corpus.", "labels": [], "entities": [{"text": "out-of-vocabulary (OOV) rates", "start_pos": 6, "end_pos": 35, "type": "METRIC", "confidence": 0.8781926393508911}]}, {"text": "We calculate the rates for both the complete corpus and the restricted set of phrases extracted from the corpus.", "labels": [], "entities": []}, {"text": "(Note that higher-order n-gram rates are estimated using phrases as independent units, no combination of phrases is performed.)", "labels": [], "entities": []}, {"text": "We also list the effective OOV rate for English-to-Czech translation where all (English) words from each source sentence can be also produced in the hypothesis.", "labels": [], "entities": [{"text": "OOV", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9978106617927551}]}], "tableCaptions": [{"text": " Table 4: Percentage of sentences reachable in  Czech-to-English large setting, two alternative de- coding paths to translate from Czech lemma if  the form is not available in the translation table  (BLEU score 18.70\u00b10.46).", "labels": [], "entities": [{"text": "BLEU score 18.70", "start_pos": 200, "end_pos": 216, "type": "METRIC", "confidence": 0.9571154713630676}]}, {"text": " Table 5: Performance of direct (Simple) and two-step factored translation in small and large data setting.", "labels": [], "entities": []}, {"text": " Table 6: Manual micro-evaluation of Simple  (12.50\u00b10.44) vs. Two-step (12.29\u00b10.47) model  in the Small-Large setting.", "labels": [], "entities": [{"text": "Simple", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9656806588172913}]}, {"text": " Table 7: Five independent MERT runs optimizing  towards SemPOS with semantic parts of speech  and lemmas provided either by TectoMT on the  fly or by Moses factored translation.", "labels": [], "entities": [{"text": "MERT", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.8442002534866333}]}, {"text": " Table 8: Optimizing towards a linear combina- tion of BLEU and SemPOS (weights in this order),  small data setting.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9965490102767944}]}, {"text": " Table 9: Optimizing towards BLEU and/or Sem- POS in large data setting.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9924192428588867}]}, {"text": " Table 10: Translation from Czech better when  backed-off by source lemmas.", "labels": [], "entities": []}]}