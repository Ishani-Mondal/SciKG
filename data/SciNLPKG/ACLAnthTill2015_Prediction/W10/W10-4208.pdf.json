{"title": [], "abstractContent": [{"text": "In this paper, we propose a general way of constructing an NLG system that permits the systematic exploration of the effects of particular system choices on output quality.", "labels": [], "entities": []}, {"text": "We calla system developed according to this model a Programmable In-strumented Generator (PIG).", "labels": [], "entities": []}, {"text": "Although a PIG could be designed and implemented from scratch, it is likely that researchers would also want to create PIGs based on existing systems.", "labels": [], "entities": []}, {"text": "We therefore propose an approach to \"instrumenting\" an NLG system so as to make it PIG-like.", "labels": [], "entities": []}, {"text": "To experiment with the idea, we have produced code to support the \"instrumenting\" of any NLG system written in Java.", "labels": [], "entities": []}, {"text": "We report on initial experiments with \"in-strumenting\" two existing systems and attempting to \"tune\" them to produce text satisfying complex stylistic constraints.", "labels": [], "entities": []}], "introductionContent": [{"text": "Existing NLG systems are often fairly impenetrable pieces of code.", "labels": [], "entities": []}, {"text": "It is hard to see what an NLG system is doing and usually impossible to drive it in anyway other than what was originally envisaged.", "labels": [], "entities": []}, {"text": "This is particularly unfortunate if the system is supposed to produce text satisfying complex stylistic requirements.", "labels": [], "entities": []}, {"text": "Even when an NLG system actually performs very well, it is hard to see why this is or how particular generator decisions produce the overall effects.", "labels": [], "entities": []}, {"text": "We propose away of building systems that will permit more systematic exploration of decisions and their consequences, as well as better exploitation of machine learning to make these decisions better.", "labels": [], "entities": []}, {"text": "We calla system builtin this way a Programmable Instrumented Generator (PIG).", "labels": [], "entities": []}, {"text": "As an initial exploration of the PIG idea, we have developed a general way of partially instrumenting any NLG system written in Java and have carried out two short experiments with existing NLG systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "For this experiment, we took an NLG system that produces pollen forecasts and was written by Ross Turner.", "labels": [], "entities": [{"text": "pollen forecasts", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.6331249624490738}]}, {"text": "Turner collected 68 examples of pollen prediction data for Scotland (each consisting of 6 small integers and a characterisation of the previous trend) with humanwritten forecasts, which we took as both our training and test data.", "labels": [], "entities": [{"text": "pollen prediction", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.8274920880794525}, {"text": "Scotland", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9113268852233887}]}, {"text": "We evaluated text quality by similarity to the human text, as measured by the Meteor metric (.", "labels": [], "entities": [{"text": "Meteor metric", "start_pos": 78, "end_pos": 91, "type": "DATASET", "confidence": 0.8866069912910461}]}, {"text": "Note that the human forecasters had access to more background knowledge than the system, and so this is not a task that the system would be expected to do particularly well on.", "labels": [], "entities": []}, {"text": "The notion of program \"state\" that the oracle logged took the form of the 6 input values, together with the values of 7 choices made by the system (relating to the inclusion of trend information, thresholds for the words \"high\" and \"low\", whether to segment the data and whether to include hay fever information).", "labels": [], "entities": []}, {"text": "The system was trained by generating about 10000 random texts (making random decisions for randomly selected examples).", "labels": [], "entities": []}, {"text": "For each, the numerical outcome (Meteor score) and state information was recorded.", "labels": [], "entities": [{"text": "numerical outcome (Meteor score)", "start_pos": 14, "end_pos": 46, "type": "METRIC", "confidence": 0.7255175213019053}]}, {"text": "The half of the resulting data with highest outcomes was extracted and used to predict rules for the 7 choices, given the 6 input parameters (we used Weka (Hall et al 2009) with the JRip algorithm).", "labels": [], "entities": []}, {"text": "The resulting rules were transcribed into a specific \"policy\" (Java class) for the oracle.", "labels": [], "entities": []}, {"text": "Applied to the 68 examples, trying random generation for 3 times on each, the system obtained an average Meteor score of 0.265.", "labels": [], "entities": [{"text": "Meteor score", "start_pos": 105, "end_pos": 117, "type": "METRIC", "confidence": 0.6377051174640656}]}, {"text": "Following the original system's suggestions produced an average score of 0.279.", "labels": [], "entities": []}, {"text": "Following the learned policy, the system also obtained an average of 0.279.", "labels": [], "entities": []}, {"text": "The difference between the learned behaviour and random generation is significant (p =0.002) according to at test.", "labels": [], "entities": []}, {"text": "A challenging stylistic requirement for NLG is that of producing a text satisfying precise length requirements.", "labels": [], "entities": []}, {"text": "For this experiment, we took the EleonPlus NLG system developed by Hien Nguyen.", "labels": [], "entities": [{"text": "EleonPlus NLG system", "start_pos": 33, "end_pos": 53, "type": "DATASET", "confidence": 0.8144517143567404}]}, {"text": "This combines the existing Eleon user interface for domain authoring (Bilidas et al 2007) with anew NLG system that incorporates the SimpleNLG realiser (Gatt and Reiter 2009).", "labels": [], "entities": [{"text": "domain authoring", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.68742536008358}, {"text": "SimpleNLG realiser", "start_pos": 133, "end_pos": 151, "type": "DATASET", "confidence": 0.8178277611732483}]}, {"text": "The system was used fora simple domain of texts about university buildings.", "labels": [], "entities": []}, {"text": "The data used was the authored information about 7 university buildings and associated objects.", "labels": [], "entities": []}, {"text": "We evaluated texts using a simple (character) length criterion, where the ideal text was 250 characters, with a steeply increasing penalty for texts longer than this and a slowly increasing penalty for texts that are shorter.", "labels": [], "entities": []}, {"text": "The notion of \"state\" that was logged took account of the depth of the traversal of the domain data, the maximum number of facts per sentence and an aggregation decision.", "labels": [], "entities": []}, {"text": "Following the previous successful demonstration of reinforcement learning for NLG decisions, we decided to use the SARSA approach (though without function approximation) for the training.", "labels": [], "entities": []}, {"text": "This involves rewarding individual states for their (direct or indirect) influence on outcome quality as the system actually performs.", "labels": [], "entities": []}, {"text": "The policy is a mixture of random exploration and the choosing of the currently most promising states, according to the value of a numerical parameter \u03b5.", "labels": [], "entities": []}, {"text": "Running the system on the 7 examples with 3 random generations for each produced an average text quality of -2514.", "labels": [], "entities": []}, {"text": "We tried a SARSA training regime with 3000 random examples at \u03b5=0.1, followed by 2000 random examples at \u03b5=0.001.", "labels": [], "entities": []}, {"text": "Following this, we looked at performance on the 7 examples with \u03b5=0.", "labels": [], "entities": []}, {"text": "The average text quality was -149.", "labels": [], "entities": [{"text": "text quality", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.7823311984539032}]}, {"text": "This was exactly the same quality as that achieved by following the original NLG system's policy.", "labels": [], "entities": [{"text": "NLG system", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.8779377341270447}]}, {"text": "Even though there is a large difference in average quality between random generation and the learned policy, this is, however, not statistically significant (p = 0.12) because of the small number of examples and large variation between text qualities.", "labels": [], "entities": []}], "tableCaptions": []}