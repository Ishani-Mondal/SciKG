{"title": [{"text": "Towards Identifying Unresolved Discussions in Student Online Forums \ud97b\udf59", "labels": [], "entities": [{"text": "Identifying Unresolved Discussions in Student Online Forums", "start_pos": 8, "end_pos": 67, "type": "TASK", "confidence": 0.8823802896908352}]}], "abstractContent": [{"text": "Automatic tools for analyzing student online discussions are highly desirable for providing better assistance and promoting discussion participation.", "labels": [], "entities": []}, {"text": "This paper presents an approach for identifying student discussions with unre-solved issues or unanswered questions.", "labels": [], "entities": [{"text": "identifying student discussions with unre-solved issues or unanswered questions", "start_pos": 36, "end_pos": 115, "type": "TASK", "confidence": 0.7824113898807101}]}, {"text": "In order to handle highly incoherent data, we perform several data processing steps.", "labels": [], "entities": []}, {"text": "We then apply a two-phase classification algorithm.", "labels": [], "entities": []}, {"text": "First, we classify \"speech acts\" of individual messages to identify the roles that the messages play, such as question, issue raising, and answers.", "labels": [], "entities": [{"text": "question, issue raising, and answers", "start_pos": 110, "end_pos": 146, "type": "TASK", "confidence": 0.7032115203993661}]}, {"text": "We then use the resulting speech acts as features for classifying discussion threads with unanswered questions or unre-solved issues.", "labels": [], "entities": []}, {"text": "We performed a preliminary analysis of the classifiers and the system shows an average F score of 0.76 in discussion thread classification.", "labels": [], "entities": [{"text": "F score", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9869256019592285}, {"text": "discussion thread classification", "start_pos": 106, "end_pos": 138, "type": "TASK", "confidence": 0.5835408667723337}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2. Statistics for each Speech Act Category", "labels": [], "entities": [{"text": "Speech Act Category", "start_pos": 30, "end_pos": 49, "type": "DATASET", "confidence": 0.8205473025639852}]}, {"text": " Table 5. SA classification results", "labels": [], "entities": [{"text": "SA classification", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7900455892086029}]}, {"text": " Table 6. Thread Classification Results  Precision  Recall  F score  Q1 0.93  0.93  0.93  Q2 0.93  0.93  0.93  Q3 0.89  0.89  0.89  (a) Classification results with human annotated SAs", "labels": [], "entities": [{"text": "Thread Classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7457934319972992}, {"text": "Precision  Recall  F score  Q1 0.93  0.93  0.93  Q2 0.93  0.93  0.93  Q3", "start_pos": 41, "end_pos": 113, "type": "METRIC", "confidence": 0.8345033526420593}]}, {"text": " Table 7. Results from Direct Thread Classification", "labels": [], "entities": [{"text": "Direct Thread Classification", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.5458923876285553}]}]}