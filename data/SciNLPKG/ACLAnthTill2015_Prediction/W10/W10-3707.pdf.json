{"title": [{"text": "Handling Named Entities and Compound Verbs in Phrase-Based Statistical Machine Translation", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation", "start_pos": 46, "end_pos": 90, "type": "TASK", "confidence": 0.6546708568930626}]}], "abstractContent": [{"text": "Data preprocessing plays a crucial role in phrase-based statistical machine translation (PB-SMT).", "labels": [], "entities": [{"text": "Data preprocessing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6621509492397308}, {"text": "phrase-based statistical machine translation (PB-SMT)", "start_pos": 43, "end_pos": 96, "type": "TASK", "confidence": 0.6488521482263293}]}, {"text": "In this paper, we show how single-tokenization of two types of multi-word expressions (MWE), namely named entities (NE) and compound verbs, as well as their prior alignment can boost the performance of PB-SMT.", "labels": [], "entities": []}, {"text": "Single-tokenization of compound verbs and named entities (NE) provides significant gains over the baseline PB-SMT system.", "labels": [], "entities": [{"text": "Single-tokenization of compound verbs and named entities (NE)", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.6120498478412628}]}, {"text": "Automatic alignment of NEs substantially improves the overall MT performance, and thereby the word alignment quality indirectly.", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9855613112449646}, {"text": "word alignment", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.7432022094726562}]}, {"text": "For establishing NE alignments, we transliterate source NEs into the target language and then compare them with the target NEs.", "labels": [], "entities": []}, {"text": "Target language NEs are first converted into a canonical form before the comparison takes place.", "labels": [], "entities": []}, {"text": "Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an Eng-lish-Bangla translation task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9966576099395752}, {"text": "Eng-lish-Bangla translation task", "start_pos": 126, "end_pos": 158, "type": "TASK", "confidence": 0.7564030488332113}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) heavily relies on good quality word alignment and phrase alignment tables comprising translation knowledge acquired from a bilingual corpus.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8309674859046936}, {"text": "word alignment", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7558177709579468}, {"text": "phrase alignment", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7214244455099106}]}, {"text": "Multi-word expressions (MWE) are defined as \"idiosyncratic interpretations that crossword boundaries (or spaces)\" ().", "labels": [], "entities": [{"text": "Multi-word expressions (MWE)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6557528376579285}]}, {"text": "Traditional approaches to word alignment following IBM Models ( do notwork well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.7988742589950562}]}, {"text": "Firstly, they only carryout alignment between words and do not consider the case of complex expressions, such as multiword NEs.", "labels": [], "entities": []}, {"text": "Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language.", "labels": [], "entities": [{"text": "IBM Models", "start_pos": 14, "end_pos": 24, "type": "DATASET", "confidence": 0.9023847877979279}]}, {"text": "In another well-known word alignment approach, Hidden Markov Model (HMM:, the alignment probabilities depend on the alignment position of the previous word.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7539156079292297}]}, {"text": "It does not explicitly consider many-to-many alignment either.", "labels": [], "entities": []}, {"text": "We address this many-to-many alignment problem indirectly.", "labels": [], "entities": []}, {"text": "Our objective is to see how to best handle the MWEs in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.8394561409950256}]}, {"text": "In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus.", "labels": [], "entities": []}, {"text": "Then, source and target language NEs are aligned using a statistical transliteration method.", "labels": [], "entities": []}, {"text": "We rely on these automatically aligned NEs and treat them as translation examples.", "labels": [], "entities": []}, {"text": "Adding bilingual dictionaries, which in effect are instances of atomic translation pairs, to the parallel corpus is a well-known practice in domain adaptation in SMT (.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 141, "end_pos": 158, "type": "TASK", "confidence": 0.7411574423313141}, {"text": "SMT", "start_pos": 162, "end_pos": 165, "type": "TASK", "confidence": 0.960831344127655}]}, {"text": "We modify the parallel corpus by converting the MWEs into single tokens and adding the aligned NEs in the parallel corpus in a bid to improve the word alignment, and hence the phrase alignment quality.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 176, "end_pos": 192, "type": "TASK", "confidence": 0.7244396209716797}]}, {"text": "This preprocessing results in improved MT quality in terms of automatic MT evaluation metrics.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9871246814727783}, {"text": "MT evaluation", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.9143153429031372}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we discuss related work.", "labels": [], "entities": []}, {"text": "The System is described in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 includes the results obtained, together with some analysis.", "labels": [], "entities": []}, {"text": "Section 5 concludes, and provides avenues for further work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We randomly extracted 500 sentences each for the development set and testset from the initial parallel corpus, and treated the rest as the training corpus.", "labels": [], "entities": []}, {"text": "After filtering on maximum allowable sentence length of 100 and sentence length ratio of 1:2 (either way), the training corpus contained 13,176 sentences.", "labels": [], "entities": [{"text": "sentence length ratio", "start_pos": 64, "end_pos": 85, "type": "METRIC", "confidence": 0.7046500444412231}]}, {"text": "In addition to the target side of the parallel corpus, a monolingual Bangla corpus containing 293,207 words from the tourism domain was used for the target language model.", "labels": [], "entities": []}, {"text": "We experimented with different n-gram settings for the language model and the maximum phrase length, and found that a 4-gram language model and a maximum phrase length of 4 produced the optimum baseline result.", "labels": [], "entities": []}, {"text": "We therefore carried out the rest of the experiments using these settings.", "labels": [], "entities": []}, {"text": "Of the 13,676 sentences in the training and development set, 13,675 sentences had at least one NE on both sides, only 22 sentences had equal number of NEs on both sides, and 13,654 sentences had an unequal number of NEs.", "labels": [], "entities": [{"text": "NE", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.9536651968955994}]}, {"text": "Similarly, for the testset, all the sentences had at least one NE on both sides, and none had an equal number of NEs on both sides.", "labels": [], "entities": [{"text": "NE", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9805178642272949}, {"text": "NEs", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9250554442405701}]}, {"text": "It gives an indication of the relative performance differences of the NERs.", "labels": [], "entities": []}, {"text": "6.6% and 6.58% of the source tokens belong to NEs in the training and testset respectively.", "labels": [], "entities": []}, {"text": "These statistics reveal the high degree of NEs in the tourism domain data that demands special treatment.", "labels": [], "entities": [{"text": "NEs", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.7689422369003296}]}, {"text": "Of the 225 unique NEs appearing on the source side of the testset, only 65 NEs are found in the training set..", "labels": [], "entities": []}, {"text": "Evaluation results for different experimental setups (The ' \u2020' marked systems produce statistically significant improvements on BLEU over the baseline system).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9984626770019531}]}, {"text": "shows the MWE statistics of the parallel corpus as identified by the NERs.", "labels": [], "entities": [{"text": "NERs", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.8780083656311035}]}, {"text": "The average NE length in the training corpus is 2.16 for English and 1.61 for Bangla.", "labels": [], "entities": [{"text": "NE length", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.951440155506134}]}, {"text": "As can be seen from, 44.5% and 47.8% of the NEs are single-word NEs in English and Bangla respectively, which suggests that prior alignment of the single-word NEs, in addition to multi-word NE alignment, should also be beneficial to word and phrase alignment.", "labels": [], "entities": [{"text": "word and phrase alignment", "start_pos": 233, "end_pos": 258, "type": "TASK", "confidence": 0.6384224221110344}]}, {"text": "Of all the NEs in the training and development sets, the transliteration-based alignment process was able to establish alignments of 4,711 single-word NEs, 4,669 two-word NEs and 1,745 NEs having length more than two.", "labels": [], "entities": []}, {"text": "It is to be noted that, some of the single-word NE alignments, as well as two-word NE alignments, result from multi-word NE alignment.", "labels": [], "entities": []}, {"text": "We analyzed the output of the NE alignment module and observed that longer NEs were aligned better than the shorter ones, which is quite intuitive, as longer NEs have more tokens to be considered for intra-NE alignment.", "labels": [], "entities": []}, {"text": "Since the NE alignment process is based on transliteration, the alignment method does notwork where NEs involve translation or acronyms.", "labels": [], "entities": [{"text": "NE alignment process", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.9353123704592387}]}, {"text": "We also observed that English multi-word NEs are sometimes fused together into single-word NEs.", "labels": [], "entities": []}, {"text": "We performed three sets of experiments: treating compound verbs as single tokens, treating NEs as single tokens, and the combination thereof.", "labels": [], "entities": []}, {"text": "Again for NEs, we carried out three types of preprocessing: singletokenization of (i) two-word NEs, (ii) more than two-word NEs, and (iii) NEs of any length.", "labels": [], "entities": []}, {"text": "We make distinctions among these three to see their relative effects.", "labels": [], "entities": []}, {"text": "The development and test sets, as well as the target language monolingual corpus (for language modeling), are also subjected to the same preprocessing of single-tokenizing the MWEs.", "labels": [], "entities": []}, {"text": "For NE alignment, we performed experiments using 4 different settings: alignment of (i) NEs of length up to two, (ii) NEs of length two, (iii) NEs of length greater than two, and (iv) NEs of any length.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.962148904800415}]}, {"text": "Before evaluation, the single-token (target language) underscored MWEs are expanded back to words comprising the MWEs.", "labels": [], "entities": []}, {"text": "Since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment.", "labels": [], "entities": []}, {"text": "Instead we carryout extrinsic evaluation on the MT quality using the well known automatic MT evaluation metrics: BLEU (), METEOR (Banerjee and), NIST), WER, PER and TER ().", "labels": [], "entities": [{"text": "MT", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9904216527938843}, {"text": "MT evaluation", "start_pos": 90, "end_pos": 103, "type": "TASK", "confidence": 0.8944166600704193}, {"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9989206790924072}, {"text": "METEOR", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9950737357139587}, {"text": "NIST", "start_pos": 145, "end_pos": 149, "type": "DATASET", "confidence": 0.8376893997192383}, {"text": "WER", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.9848572015762329}, {"text": "PER", "start_pos": 157, "end_pos": 160, "type": "METRIC", "confidence": 0.9494891166687012}, {"text": "TER", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.9928233623504639}]}, {"text": "As can be seen from the evaluation results reported in, baseline Moses without any preprocessing of the dataset produces a BLEU score of 8.74.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9824389517307281}]}, {"text": "The low score can be attributed to the fact that Bangla, a morphologically rich language, is hard to translate into.", "labels": [], "entities": [{"text": "Bangla", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9061765670776367}]}, {"text": "Moreover, Bangla being a relatively free phrase order language) ideally requires multiple set of references for proper evaluation.", "labels": [], "entities": []}, {"text": "Hence using a single reference set does not justify evaluating translations in Bangla.", "labels": [], "entities": []}, {"text": "Also the training set was not sufficiently large enough for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.99222731590271}]}, {"text": "Treating only longer than 2-word NEs as single tokens does not help improve the overall performance much, while single tokenization of two-word NEs as single tokens produces some improvements (.39 BLEU points absolute, 4.5% relative).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 197, "end_pos": 201, "type": "METRIC", "confidence": 0.9992923736572266}]}, {"text": "Considering compound verbs as single tokens (CVaST) produces a .82 BLEU point improvement (9.4% relative) over the baseline.", "labels": [], "entities": [{"text": "BLEU point", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9783750474452972}]}, {"text": "Strangely, when both compound verbs and NEs together are counted as single tokens, there is hardly any improvement.", "labels": [], "entities": []}, {"text": "By contrast, automatic NE alignment (NEA) gives a huge impetus to system performance, the best of them (4.59 BLEU points absolute, 52.5% relative improvement) being the alignment of NEs of any length that produces the best scores across all metrics.", "labels": [], "entities": [{"text": "NE alignment (NEA)", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.901791775226593}, {"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9950113296508789}]}, {"text": "When NEA is combined with CVaST, the improvements are substantial, but it cannot beat the individual improvement on NEA.", "labels": [], "entities": [{"text": "NEA", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.7701165676116943}, {"text": "NEA", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.9475571513175964}]}, {"text": "The ( \u2020) marked systems produce statistically significant improvements as measured by bootstrap resampling method) on BLEU over the baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9948101043701172}]}, {"text": "Metric-wise individual best scores are shown in bold in used as anchor words to directly influence the word alignment process.", "labels": [], "entities": [{"text": "word alignment process", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7941404183705648}]}, {"text": "We will look into whether similar kinds of improvements can be achieved for larger datasets, corpora from different domains and for other language pairs.", "labels": [], "entities": []}, {"text": "We will also investigate how NE alignment quality can be improved, especially where NEs involve translation and acronyms.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9463675618171692}]}, {"text": "We will also try to perform morphological analysis or stemming on the Bangla side before NE alignment.", "labels": [], "entities": [{"text": "Bangla side", "start_pos": 70, "end_pos": 81, "type": "DATASET", "confidence": 0.9696220755577087}, {"text": "NE alignment", "start_pos": 89, "end_pos": 101, "type": "TASK", "confidence": 0.6715370118618011}]}, {"text": "We will also explore whether discriminative approaches to word alignment can be employed to improve the precision of the NE alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7968486547470093}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9989853501319885}]}], "tableCaptions": [{"text": " Table 1. MWE statistics (T -Total occur- rence, U -Unique).", "labels": [], "entities": [{"text": "T -Total occur- rence", "start_pos": 26, "end_pos": 47, "type": "METRIC", "confidence": 0.9375561773777008}, {"text": "U -Unique)", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9078604876995087}]}, {"text": " Table 2. Evaluation results for different experimental setups (The ' \u2020' marked systems produce  statistically significant improvements on BLEU over the baseline system).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.9981254935264587}]}]}