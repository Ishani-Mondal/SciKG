{"title": [{"text": "Machine Reading as a Process of Partial Question-Answering \ud97b\udf59 \ud97b\udf59", "labels": [], "entities": [{"text": "Machine Reading", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7808746695518494}]}], "abstractContent": [{"text": "This paper explores the close relationship between question answering and machine reading , and how the active use of reasoning to answer (and in the process, disambiguate) questions can also be applied to reading declarative texts, where a substantial proportion of the text's contents is already known to (rep-resented in) the system.", "labels": [], "entities": [{"text": "question answering", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.8081516623497009}, {"text": "machine reading", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.7302657514810562}]}, {"text": "In question answering , a question maybe ambiguous, and it may only be in the process of trying to answer it that the \"right\" way to disambiguate it becomes apparent.", "labels": [], "entities": [{"text": "question answering", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.836799681186676}]}, {"text": "Similarly in machine reading, a text maybe ambiguous, and may require some process to relate it to what is already known.", "labels": [], "entities": [{"text": "machine reading", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7753309011459351}]}, {"text": "Our conjecture in this paper is that these two processes are similar, and that we can modify a question answering tool to help \"read\" new text that augments existing system knowledge.", "labels": [], "entities": [{"text": "question answering", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7233579605817795}]}, {"text": "Specifically, interpreting anew text T can be recast as trying to answer, or partially answer, the question \"Is it true that T?\", resulting in both appropriate disambigua-tion and connection of T to existing knowledge.", "labels": [], "entities": [{"text": "interpreting anew text T", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.8124885559082031}]}, {"text": "Some preliminary investigation suggests this might be useful for proposing knowledge base extensions, extracted from text, to a knowledge engineer.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine reading is not just a task of language processing, but an active interplay between knowledge and language; Prior knowledge should guide interpretation of new text, and new interpretations should augment that prior knowledge.", "labels": [], "entities": [{"text": "Machine reading", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7869485318660736}]}, {"text": "Such interaction is essential if ambiguities in language are to be resolved \"correctly\" (with respect to what is known), and if the resulting interpretations are to be integrated with existing knowledge.", "labels": [], "entities": []}, {"text": "The main insight of this paper is that this interaction is similar to that required for knowledge-based question answering, which also requires searching a knowledge base (KB) fora valid interpretation of the question.", "labels": [], "entities": [{"text": "knowledge-based question answering", "start_pos": 88, "end_pos": 122, "type": "TASK", "confidence": 0.637373298406601}]}, {"text": "In our earlier work on question answering, we found that some disambiguation decisions for question interpretation could be deferred, to be resolved during question answering, guided by what was found in the KB.", "labels": [], "entities": [{"text": "question answering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9262800514698029}, {"text": "question interpretation", "start_pos": 91, "end_pos": 114, "type": "TASK", "confidence": 0.7803379595279694}, {"text": "question answering", "start_pos": 156, "end_pos": 174, "type": "TASK", "confidence": 0.8499107956886292}]}, {"text": "In this paper, we show how a similar approach can be applied to interpreting declarative text, so that a similar interplay between language and knowledge is achieved.", "labels": [], "entities": [{"text": "interpreting declarative text", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.882413923740387}]}, {"text": "\"Machine reading\" itself is a loosely-defined notion, ranging from extracting selective facts to constructing complex, inference-supporting representations of text.", "labels": [], "entities": [{"text": "Machine reading\"", "start_pos": 1, "end_pos": 17, "type": "TASK", "confidence": 0.78143709897995}]}, {"text": "One approach for selective extraction is the use of semantic templates (\"scripts\", \"frames\") to provide a set of roles (slots) and constraints on objects playing those roles (fillers) to be expected in text, and might be filled by methods ranging from simply skimming text, e.g., FRUMP, to full language processing, e.g.,.", "labels": [], "entities": [{"text": "selective extraction", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7590776085853577}]}, {"text": "Other work has looked at techniques for learning phrasal patterns likely to contain slot fillers) or contain information semantically similar to a set of seed examples).", "labels": [], "entities": []}, {"text": "At the other end of the spectrum, some systems attempt a full understanding of text, i.e., have the ambitious goal of building a complete representation of the text's contents (e.g.,.", "labels": [], "entities": []}, {"text": "A common thread of these approaches is to search a space of alternative disambiguations and elaborations and select the most \"coherent\", based on criteria such as maximizing coreference, minimizing redundancy, and avoiding contradictions.", "labels": [], "entities": []}, {"text": "For example, search fora set of abductive inferences on the (logical form of the) text that minimizes cost (maximizes coherence) of the result, where an abductive inference might be a word sense or coreference decision with an associated cost.", "labels": [], "entities": []}, {"text": "Similarly, search a space of disambiguations when interpreting paragraphs by elaborating each alternative (using dictionary definitions) and selecting the most coherent based on similar criteria.", "labels": [], "entities": []}, {"text": "Work on model building is inspiring but also challenging due to the lack of constraint on the final models (even with substantial domain knowledge) and the difficulty of quantifying \"coherence\".", "labels": [], "entities": [{"text": "model building", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.7566963136196136}]}, {"text": "Our work falls somewhere between these two.", "labels": [], "entities": []}, {"text": "We do not use templates for new knowledge, but rather use inference at run-time to identify what is known and thus what to expect that the text might be saying.", "labels": [], "entities": []}, {"text": "However, unlike full model building approaches, we assume that the majority of what is being read is already known (represented) in the KB, and thus the reading task is primarily one of recognizing that knowledge in the text, and extending it with any new facts that are encountered.", "labels": [], "entities": []}, {"text": "We might term this a \"model extension\" approach; it corresponds to challenge of, given the representation of a book, have a machine read a second book (about the same topic) and integrate the new knowledge contained in that text.", "labels": [], "entities": []}], "datasetContent": [{"text": "To make a preliminary assessment of how much useful information the system is producing, we conducted a small study.", "labels": [], "entities": []}, {"text": "10 paragraphs about prophase (from different Web sources) were run through the system (110 sentences in total).", "labels": [], "entities": []}, {"text": "For the statements that mix old and new knowledge, 70% were judged correct, and for completely new statements, 39% were judged correct.", "labels": [], "entities": []}, {"text": "5 This suggests the system is at least producing some useful suggestions, and for the statements that mix old and new knowledge, has identified the connection points in the KB for the new facts.", "labels": [], "entities": []}, {"text": "Although this level of accuracy is too low for automation, it suggests the system might be a useful tool for helping a knowledge engineer check that he/she has fully encoded the contents of a passage when building the KB, and performing those approved additions automatically.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.999107301235199}]}], "tableCaptions": [{"text": " Table 1: Correctness of axioms proposed by the  system.", "labels": [], "entities": [{"text": "Correctness", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9716273546218872}]}]}