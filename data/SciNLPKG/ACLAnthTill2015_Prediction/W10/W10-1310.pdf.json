{"title": [{"text": "State-Transition Interpolation and MAP Adaptation for HMM-based Dysarthric Speech Recognition", "labels": [], "entities": [{"text": "MAP Adaptation", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7971177399158478}, {"text": "HMM-based Dysarthric Speech Recognition", "start_pos": 54, "end_pos": 93, "type": "TASK", "confidence": 0.7276769876480103}]}], "abstractContent": [{"text": "This paper describes the results of our experiments in building speaker-adaptive recogniz-ers for talkers with spastic dysarthria.", "labels": [], "entities": []}, {"text": "We study two modifications-(a) MAP adaptation of speaker-independent systems trained on normal speech and, (b) using a transition probability matrix that is a linear interpolation between fully ergodic and (exclusively) left-to-right structures, for both speaker-dependent and speaker-adapted systems.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.756745845079422}]}, {"text": "The experiments indicate that (1) for speaker-dependent systems, left-to-right HMMs have lower word error rate than transition-interpolated HMMs, (2) adapting all parameters other than transition probabilities results in the highest recognition accuracy compared to adapting any subset of these parameters or adapting all parameters including transition probabilities, (3) performing both transition-interpolation and adaptation gives higher word error rate than performing adaptation alone and, (4) dysarthria severity is not a sufficient indicator of the relative performance of speaker-dependent and speaker-adapted systems.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 95, "end_pos": 110, "type": "METRIC", "confidence": 0.7780276735623678}, {"text": "accuracy", "start_pos": 245, "end_pos": 253, "type": "METRIC", "confidence": 0.8713060617446899}]}], "introductionContent": [{"text": "After more than two decades of research, speech recognition is a well-established and reliable human-computer interaction technology.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8920254409313202}]}, {"text": "The accuracy of the newest generation of large vocabulary speech recognizers, after adaptation to a user without speech pathology, is high enough to provide a useful human-computer interface especially for people who find it difficult to type with a keyboard.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996422529220581}, {"text": "large vocabulary speech recognizers", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.6979149058461189}]}, {"text": "Automatic speech recognition (ASR) systems generally assume that the speech signal is a realisation of some message encoded as a sequence of one or more symbols.", "labels": [], "entities": [{"text": "Automatic speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8381307224432627}]}, {"text": "To effect the reverse operation of recognising the underlying symbol sequence given a spoken utterance, the continuous speech waveform is first converted to a sequence of equally spaced discrete parameter vectors.", "labels": [], "entities": []}, {"text": "The role of the recogniser is to effect a mapping between sequences of speech vectors and the wanted underlying symbol sequences.", "labels": [], "entities": []}, {"text": "Most speech recognizers today are based on the hidden Markov model (HMM) paradigm: it is assumed that the sequence of observed speech vectors is generated by a Markov model as shown in.", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.6992351114749908}]}, {"text": "A Markov model is a finite state machine which changes state once every time unit and each time t that a state j is entered, a speech vector o t is generated from the probability density b j (o t ) which a a  Figure 1: The Markov generation model. is a mixture-Gaussian density for most standard systems.", "labels": [], "entities": []}, {"text": "The transition from state i to state j is also probabilistic and is governed by the discrete probability a ij . shows an example of this process where the five state model moves through the state sequence X = 1, 2, 2, 3, 3, 4, 4, 4, 5 in order to generate the sequence o 1 too 7 . The entry and exit states (1, 5) are non-emitting.", "labels": [], "entities": []}, {"text": "This is to facilitate the construction of composite models: most systems use HMMs to perform modeling at the phone-level rather than word-level; as such, word-level models are constructed by stringing together phone-level HMMs for the constituent phones.", "labels": [], "entities": []}, {"text": "shows how HMMs can be used for isolated word recognition.", "labels": [], "entities": [{"text": "isolated word recognition", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.609391967455546}]}, {"text": "Firstly, an HMM is trained for each vocabulary word using a number of examples of that word -given a set of training examples corresponding to a particular model, the parameters of that model ({a ij } and {b j (o t )}) are determined by a robust and efficient re-estimation procedure.", "labels": [], "entities": []}, {"text": "In this example, the vocabulary consists of just three words: \"one\", \"two\" and \"three\".", "labels": [], "entities": []}, {"text": "Secondly, to recognise some unknown word, the likelihood (probability) of each model generating that word is calculated and the most likely model identifies the word.", "labels": [], "entities": [{"text": "likelihood (probability)", "start_pos": 46, "end_pos": 70, "type": "METRIC", "confidence": 0.928399845957756}]}, {"text": "For creating a speech recognizer fora particular speaker, there are two approaches: one is to create a speaker-dependent (SD) system by utlizing speech of that speaker alone to train the HMMs; the other is to create a speaker-adapted (SA) system by first training the HMMs in a speaker-independent fashion by utlizing speech of several speakers, and then customising the HMMs to the characteristics of the particular speaker by using training examples of their speech to modify the HMM parameters.", "labels": [], "entities": []}, {"text": "The parameter values do not get overwritten; they are adjusted using a regularized or constrained machine learning algorithm.", "labels": [], "entities": []}, {"text": "Regularization (e.g., using Maximum A Posteriori learning) or constraints (e.g., using linear transformations) allow the SA model to use far more trainable parameters per minute of training data without over-training the system.", "labels": [], "entities": []}, {"text": "Despite the advances in speech technology, their benefits have not been available to people with gross motor impairments mainly because these impairments include a component of dysarthria -a group of motor speech disorders resulting from disturbed muscular control of the speech mechanism due to damage of the peripheral or central nervous system.", "labels": [], "entities": []}, {"text": "Dysarthria is often a symptom of a gross motor disorder, whose other symptoms usually make it hard to use a keyboard and mouse.", "labels": [], "entities": [{"text": "Dysarthria", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9858954548835754}]}, {"text": "Published case studies have shown that some dysarthric users may find it easier to use an ASR system instead of a keyboard.", "labels": [], "entities": []}, {"text": "Polur and Miller studied the development of HMM-based small vocabulary (eight repetitions each often digits and fifteen 'command' words in English) SD systems for three male subjects subjectively classified by a trained clinician as moderately dysarthric.", "labels": [], "entities": []}, {"text": "They found that an ergodic HMM with a slight left-to-right character (called a transition-interpolated HMM from hereon) provides higher word recognition accuracy (WRA) than a standard left-to-right HMM, apparently because the transition-interpolated HMM is able to capture outlier events as a backward or nonlinear progress through the intended word.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 136, "end_pos": 152, "type": "TASK", "confidence": 0.6450535207986832}, {"text": "accuracy (WRA)", "start_pos": 153, "end_pos": 167, "type": "METRIC", "confidence": 0.930557370185852}]}, {"text": "The benefit of using ergodic modeling over left-to-right modeling in distorted speech applications with disruption events, pause events, and limited training data has also been noted earlier by Deller,.", "labels": [], "entities": []}, {"text": "Section 2.1.2 explains in more detail the difference between these HMM topologies.", "labels": [], "entities": []}, {"text": "Speaking for long periods of time is tiring, especially fora person with dysarthria, therefore it is difficult fora person with dysarthria to train a speakerdependent ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 167, "end_pos": 170, "type": "TASK", "confidence": 0.7437543272972107}]}, {"text": "Speaker adaptation then seems a useful method to overcome this obstacle in developing dysarthric speech recognizers.) have compared recognition accuracies of an SA system and an SD system.", "labels": [], "entities": [{"text": "Speaker adaptation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8311471939086914}]}, {"text": "They found that the SA system adapted well to the speech of talkers with mild or moderate dysarthria, but the recognition scores were lower than for an unimpaired speaker.", "labels": [], "entities": [{"text": "recognition", "start_pos": 110, "end_pos": 121, "type": "METRIC", "confidence": 0.867956817150116}]}, {"text": "The subject with severe dysarthria was able to achieve better performance with the SD system than with the SA system.", "labels": [], "entities": []}, {"text": "These findings were also supported by) who compared the performance of SD and \"SA\" systems on the Nemours database () by varying independently the amount of data for training and the number of Gaussian components used for modeling the output probability distributions.", "labels": [], "entities": [{"text": "Nemours database", "start_pos": 98, "end_pos": 114, "type": "DATASET", "confidence": 0.9738388359546661}]}, {"text": "The \"SA\" technique implemented is not speaker-adaptation in the conventional sense: it uses the parameter values for the speaker-independent system as the starting point to train HMMs fora particular dysarthric speaker.", "labels": [], "entities": []}, {"text": "Ina training algorithm without regularization or constraint terms, it is possible fora system of this type to over-train, resulting in loss of accuracy on test data from the same speaker, and Rudzicz's results suggest that such over-training may have occurred in some cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9976564645767212}]}, {"text": "He further concluded that there was not enough data in the database to represent intraspeaker variation.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 lists the speakers whose  speech materials from the UA-Speech database were  used, along with their human listener intelligibility  ratings. The first letter of the speaker code ('M' or  'F') indicates their gender.", "labels": [], "entities": [{"text": "UA-Speech database", "start_pos": 61, "end_pos": 79, "type": "DATASET", "confidence": 0.8633442521095276}]}, {"text": " Table 3: PWC scores for each speaker's configurations  C00-C12.", "labels": [], "entities": []}, {"text": " Table 4: PWC scores for each speaker's configurations  C00,C13-C15.", "labels": [], "entities": []}]}