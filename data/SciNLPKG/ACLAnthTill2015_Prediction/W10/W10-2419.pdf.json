{"title": [{"text": "Rule-based Named Entity Recognition in Urdu", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.6536401112874349}]}], "abstractContent": [{"text": "Named Entity Recognition or Extraction (NER) is an important task for automated text processing for industries and academia engaged in the field of language processing, intelligence gathering and Bioinformatics.", "labels": [], "entities": [{"text": "Named Entity Recognition or Extraction (NER)", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8269715793430805}, {"text": "text processing", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.6763095110654831}, {"text": "language processing", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.7214312106370926}, {"text": "intelligence gathering", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.7610791623592377}, {"text": "Bioinformatics", "start_pos": 196, "end_pos": 210, "type": "TASK", "confidence": 0.9015081524848938}]}, {"text": "In this paper we discuss the general problem of Named Entity Recognition, more specifically the challenges in NER in languages that do not have language resources e.g. large annotated corpora.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6443697114785513}, {"text": "NER", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.9628503918647766}]}, {"text": "We specifically address the challenges for Urdu NER and differentiate it from other South Asian (Indic) languages.", "labels": [], "entities": [{"text": "Urdu NER", "start_pos": 43, "end_pos": 51, "type": "TASK", "confidence": 0.4726867079734802}]}, {"text": "We discuss the differences between Hindi and Urdu and conclude that the NER computational models for Hindi cannot be applied to Urdu.", "labels": [], "entities": []}, {"text": "A rule-based Urdu NER algorithm is presented that outperforms the models that use statistical learning.", "labels": [], "entities": [{"text": "NER", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.7850655317306519}]}], "introductionContent": [{"text": "Text processing applications, such as machine translation, information extraction, information retrieval or natural language understanding systems need to recognize multiple word expressions that refer to people names, organizational names, geographical locations, and other named entities.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7559632658958435}, {"text": "information extraction", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.8100797832012177}, {"text": "information retrieval or natural language understanding", "start_pos": 83, "end_pos": 138, "type": "TASK", "confidence": 0.7363104522228241}]}, {"text": "Proper Names play a crucial role in information management, both in specific applications and in underlying technologies that drive the application.", "labels": [], "entities": [{"text": "information management", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8128176331520081}]}, {"text": "Name Recognition becomes important in situations when the person or the organization is more important than the action it performed, for example, bankruptcy of the corner shop John & Sons is not as interesting as the bankruptcy of General Motors, an American car manufacturer.", "labels": [], "entities": [{"text": "Name Recognition", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8305213153362274}, {"text": "John & Sons", "start_pos": 176, "end_pos": 187, "type": "DATASET", "confidence": 0.7388009627660116}]}, {"text": "In this particular example, latter event will be of much interest for the financial markets and investors to track.", "labels": [], "entities": []}, {"text": "The proper name identification depends upon the domain, and the applications in that domain.", "labels": [], "entities": [{"text": "name identification", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7595618665218353}]}, {"text": "For the purpose of this study we have limited the scope of names to entities proposed by, i.e. times, numbers, personal names, organizations, and geographical areas.", "labels": [], "entities": []}, {"text": "The goal of a named entity finder is to find these entities.", "labels": [], "entities": []}, {"text": "In this paper we study the challenges of named entity recognition for resource scarce languages among South Asian languages.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.6287402311960856}]}, {"text": "Urdu is used as an example language because of its large number of speakers, the only language in the region with Arabic script orthography, and interesting assumptions about its similarity with Hindi.", "labels": [], "entities": []}, {"text": "Section 2 describes the characteristics and computational processing for Urdu.", "labels": [], "entities": []}, {"text": "Section 3 motivates the named entity recognition task by outlining the challenges in NER in any language along with some of the approaches that have been used by well known NER systems.", "labels": [], "entities": [{"text": "named entity recognition task", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.6953863948583603}]}, {"text": "Section 4 discusses some previous work related to NER in South Asian languages.", "labels": [], "entities": [{"text": "NER", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9857252836227417}]}, {"text": "Section 5 describes challenges of NER in Urdu.", "labels": [], "entities": [{"text": "NER", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9943976402282715}]}, {"text": "Section 6 describes the complex relationship between Hindi and Urdu and asserts that NER computation models for Hindi cannot be used for Urdu NER.", "labels": [], "entities": []}, {"text": "Section 7 presents a rule-based NER algorithm for Urdu NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9279162883758545}, {"text": "Urdu NER", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.5181881040334702}]}, {"text": "Section 8 presents the conclusion and future work.", "labels": [], "entities": []}, {"text": "It is assumed that the reader knows the history, orthography and some characteristics of Urdu in general.", "labels": [], "entities": []}, {"text": "We give a brief introduction to Urdu and Urdu processing in section 1.1.", "labels": [], "entities": [{"text": "Urdu and Urdu processing", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6335227116942406}]}, {"text": "For a detailed explanation refer to that describe computational challenges for Urdu processing.", "labels": [], "entities": [{"text": "Urdu processing", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.8414357304573059}]}, {"text": "As a convention, Urdu words written in Arabic orthography are followed by English translation in parenthesis and are italicized.", "labels": [], "entities": []}], "datasetContent": [{"text": "Although rules are designed to recognize the above named entities, the current implementation recognizes all of them as simple named-entities.", "labels": [], "entities": []}, {"text": "While crafting rules for named entities a number of interesting rule patterns, heuristics and challenges were discovered that play important role when discovering a named entity.", "labels": [], "entities": []}, {"text": "We mention some interesting ones below: \uf0b7 Punctuation marks like \":\" are useful but the position of their occurrence in text is important. and Muhammad Yousaf are problematic for our NER system since there is no capitalization in Urdu and they occur without any prefix or suffix cues.", "labels": [], "entities": [{"text": "NER", "start_pos": 183, "end_pos": 186, "type": "TASK", "confidence": 0.8648390173912048}]}, {"text": "\uf0b7 Co-reference resolution for names will be nontrivial since they have multiple spellings, only context can be used to resolve them.", "labels": [], "entities": [{"text": "Co-reference resolution", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.7023654580116272}]}, {"text": "For example, Milosevic is spelled at least with three different spellings.", "labels": [], "entities": []}, {"text": "\uf0b7 Honorific titles are very important but a title like Sadr (President) can occasionally lead to incorrect recognition because Sadr is the location of a well known neighborhood of Karachi (largest city in Pakistan).", "labels": [], "entities": []}, {"text": "\uf0b7 Honorific titles are sometimes transliterated into Urdu from English and other times they are scribed in indigenous from in another article to refer to the same person e.g. \u202b\u06a9\u064a\u067e\u0679\u0647\u202c is the transliteration of captain and \u202b\u06a9\u067e\u062a\u0628\u0646\u202cmeans captain in indigenous Urdu form.", "labels": [], "entities": []}, {"text": "\uf0b7 Anchoring around the named entities is a useful heuristic.", "labels": [], "entities": []}, {"text": "The anchor text choice is one of the most challenging tasks for our system.", "labels": [], "entities": [{"text": "anchor text choice", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7182727257410685}]}, {"text": "The rule sets were created from 200 documents of Becker-Riaz corpus and the experiment were run on 2,262 documents.", "labels": [], "entities": [{"text": "Becker-Riaz corpus", "start_pos": 49, "end_pos": 67, "type": "DATASET", "confidence": 0.8142677545547485}]}, {"text": "Each of these documents is evaluated to create relevance judgments.", "labels": [], "entities": []}, {"text": "The relevance judgments are created by two native speakers of Urdu who are avid news readers.", "labels": [], "entities": [{"text": "relevance judgments", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7444398701190948}]}, {"text": "The results of experiment runs were hard to grade on such a large set of documents so we chose 600 documents for evaluation.", "labels": [], "entities": []}, {"text": "Two judges were chosen who are fluent in Urdu but required some coaching to recognize the named entities.", "labels": [], "entities": []}, {"text": "At first judges were expecting terms like Palestinian and elections to be named entities but after some coaching all evaluation was done correctly.", "labels": [], "entities": []}, {"text": "There were very few disagreements among the judges after coaching.", "labels": [], "entities": []}, {"text": "A third native speaker was used to address instances of disagreements between the two initial judges.", "labels": [], "entities": []}, {"text": "The evaluation set was chosen where all the judges agreed upon the named entities.", "labels": [], "entities": []}, {"text": "The total numbers of unique named entities are 206.", "labels": [], "entities": []}, {"text": "The algorithm matched about 2819 total named entities.", "labels": [], "entities": []}, {"text": "While creating the rules and the evaluation set it looked as the number of documents grows the unique named-entities will level out gradually, but we found a lot of repetitions as the number of documents increased but new names consistently were added to the unique list but at a very low rate.", "labels": [], "entities": []}, {"text": "Although, the corpus domain is news text, the genre of the documents spans over almost any newsworthy information in South Asia, this results in increase of non-unique names.", "labels": [], "entities": []}, {"text": "The algorithm execution resulted in 187 namedentities and 171 of those were true named entities.", "labels": [], "entities": []}, {"text": "The results show the recall of 90.7% and precision of 91.5%.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9997475743293762}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9998898506164551}]}, {"text": "This gives the \u00ed \u00b5\u00ed\u00b1\u0093 1 \u2212 \u00ed \u00b5\u00ed\u00b1\u009a\u00ed \u00b5\u00ed\u00b1\u0092\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u00a2\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0092 value of 91.1%.", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed\u00b1\u0093 1 \u2212 \u00ed \u00b5\u00ed\u00b1\u009a\u00ed \u00b5\u00ed\u00b1\u0092\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u00a2\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0092 value", "start_pos": 15, "end_pos": 74, "type": "METRIC", "confidence": 0.797845908889064}]}, {"text": "We found that, suffixes cues and anchor text features were very useful feature but at the same time anchor text feature was the cause of most false positives.", "labels": [], "entities": []}, {"text": "Almost all false positives were noun phrases.", "labels": [], "entities": []}, {"text": "We ran our rule set on the 36,000 token Urdu data provided for IJCNLP 2008 NER Workshop.", "labels": [], "entities": [{"text": "IJCNLP 2008 NER Workshop", "start_pos": 63, "end_pos": 87, "type": "DATASET", "confidence": 0.819562703371048}]}, {"text": "Without tuning any of the rules \u00ed \u00b5\u00ed\u00b1\u0093 1 \u2212 \u00ed \u00b5\u00ed\u00b1\u009a\u00ed \u00b5\u00ed\u00b1\u0092\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u00a2\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0092 was 72.4% and after adding a few rules after looking at the training set \u00ed \u00b5\u00ed\u00b1\u0093 1 \u2212 \u00ed \u00b5\u00ed\u00b1\u009a\u00ed \u00b5\u00ed\u00b1\u0092\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u00a2\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0092 was increased to 81.6% on the test set.", "labels": [], "entities": []}, {"text": "A close analysis of this data showed considerable lack of named entities in contrast to the Becker-Riaz corpus.", "labels": [], "entities": []}, {"text": "Therefore major results are drawn from the Becker-Riaz corpus.", "labels": [], "entities": [{"text": "Becker-Riaz corpus", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.7288067936897278}]}, {"text": "The results of rule execution on IJCNLP 2008 data for Urdu are better than any of the results reported in IJCNLP 2008 NER workshop for Urdu data.", "labels": [], "entities": [{"text": "IJCNLP 2008 data", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.9479625821113586}, {"text": "IJCNLP 2008 NER workshop for Urdu data", "start_pos": 106, "end_pos": 144, "type": "DATASET", "confidence": 0.7357537405831474}]}], "tableCaptions": []}