{"title": [{"text": "Reference reversibility with Reference Domain Theory", "labels": [], "entities": [{"text": "Reference reversibility", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8251965641975403}]}], "abstractContent": [{"text": "In this paper we present a reference model based on Reference Domain Theory that can work both in interpretation and generation.", "labels": [], "entities": [{"text": "interpretation and generation", "start_pos": 98, "end_pos": 127, "type": "TASK", "confidence": 0.660453995068868}]}, {"text": "We introduce a formalization of key concepts of RDT, the interpretation and generation algorithms and show an example of behavior in the dynamic, asymmetric and multimodal GIVE environment.", "labels": [], "entities": []}], "introductionContent": [{"text": "The reference task in a dialogue system is two-fold.", "labels": [], "entities": []}, {"text": "On the one hand the system has to interpret the referring expressions (RE) produced by the user in his utterances.", "labels": [], "entities": []}, {"text": "On the other hand the system has to generate the REs for the objects it aims to refer to.", "labels": [], "entities": []}, {"text": "We present in this paper a framework that considers that reference interpretation and generation are two sides of the same coin, hence avoiding any potential misunderstanding arising from the two modules discrepancies.", "labels": [], "entities": [{"text": "reference interpretation", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.7218100130558014}]}, {"text": "Reference Domain Theory (RDT) proposes to represent the diversity of referring acts by the diversity of constraints they impose on their context of use.", "labels": [], "entities": [{"text": "Reference Domain Theory (RDT)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7894732554753622}]}, {"text": "The reversibility then lies in the possibility to express these constraints independently of the considered task.", "labels": [], "entities": []}, {"text": "In (Denis, 2010) we described the generation side of RDT in the context of the GIVE-2 challenge ( which is an evaluation of instruction generation systems in a 3D maze.", "labels": [], "entities": []}, {"text": "In this paper we propose the interpretation counterpart and show the required modeling to consider the dynamic, asymmetric and multimodal context of GIVE.", "labels": [], "entities": [{"text": "GIVE", "start_pos": 149, "end_pos": 153, "type": "DATASET", "confidence": 0.7550042271614075}]}, {"text": "We first present the reference model in section 2 and 3, discuss the interpretation problems in GIVE in section 4, detail an example in section 5 and present evaluation results in section 6.", "labels": [], "entities": [{"text": "GIVE", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.8242095112800598}]}], "datasetContent": [{"text": "Only the generation direction has been evaluated in the GIVE challenge.", "labels": [], "entities": [{"text": "GIVE challenge", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.5241988748311996}]}, {"text": "The results ( show that the system embedding Reference Domain Theory proves to rely on less instructions than other systems (224) and proves to be the most successful (47% of task success) while being the fastest (344 seconds).", "labels": [], "entities": []}, {"text": "We conjecture that the good results of RDT can be explained by the low cognitive load resulting from the use of demonstrative NPs and one-anaphoras, but the role of the overall generation strategy has also to betaken into account in these good results.", "labels": [], "entities": [{"text": "RDT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8979593515396118}]}, {"text": "Although it would be very interesting, the interpretation side has not yet been evaluated in the GIVE setting, but only in the MEDIA campaign which is an unimodal setting.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.9842391014099121}]}, {"text": "The results show that the interpretation side of RDT achieves a fair precision in identification (75.2%) but a low recall (44.7%).", "labels": [], "entities": [{"text": "interpretation", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.9467533826828003}, {"text": "RDT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.7224048972129822}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9993153810501099}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.999634861946106}]}, {"text": "We assume that the low recall of the module is caused by the cascade of errors, one error at the start of a reference chain leading to several other errors.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9990078806877136}]}, {"text": "Nonetheless, we estimate that error cascading would be less problematic in the GIVE setting because of its dynamicity.", "labels": [], "entities": [{"text": "error cascading", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.6649261564016342}]}], "tableCaptions": []}