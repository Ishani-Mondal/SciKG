{"title": [{"text": "Contextually-Mediated Semantic Similarity Graphs for Topic Segmentation", "labels": [], "entities": [{"text": "Topic Segmentation", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8442904055118561}]}], "abstractContent": [{"text": "We present a representation of documents as directed, weighted graphs, modeling the range of influence of terms within the document as well as contextually determined semantic relatedness among terms.", "labels": [], "entities": []}, {"text": "We then show the usefulness of this kind of representation in topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.754407525062561}]}, {"text": "Our boundary detection algorithm uses this graph to determine topical coherence and potential topic shifts, and does not require labeled data or training of parameters.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7329436242580414}]}, {"text": "We show that this method yields improved results on both concatenated pseudo documents and on closed-captions for television programs.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present in this paper a graph-based representation of documents that models both the longrange scope \"influence\" of terms and the semantic relatedness of terms in a local context.", "labels": [], "entities": []}, {"text": "In these graphs, each term is represented by a series of nodes.", "labels": [], "entities": []}, {"text": "Each node in the series corresponds to a sentence within the span of that term's influence, and the weights of the edges are proportional to the semantic relatedness among terms in the context.", "labels": [], "entities": []}, {"text": "Semantic relatedness between terms is reinforced by the presence of nearby, closely related terms, reflected in increased connection strength between their nodes.", "labels": [], "entities": []}, {"text": "We demonstrate the usefulness of our representation by applying it to partitioning of documents into topically coherent segments.", "labels": [], "entities": [{"text": "partitioning of documents into topically coherent segments", "start_pos": 70, "end_pos": 128, "type": "TASK", "confidence": 0.8491291914667402}]}, {"text": "Our segmentation method finds locations in the graph of a document where one group of strongly connected nodes ends and another begins, signaling a shift in topicality.", "labels": [], "entities": []}, {"text": "We test this method both on concatenated news articles, and on a more realistic segmentation task, closed-captions from commercial television programs, in which topic transitions are more subjective and less distinct.", "labels": [], "entities": []}, {"text": "Our methods are unsupervised and require no training; thus they do not require any labeled instances of segment boundaries.", "labels": [], "entities": []}, {"text": "Our method attains results significantly superior to that of, and approaches human performance on segmentation of television closed-captions, where inter-annotator disagreement is high.", "labels": [], "entities": [{"text": "segmentation of television closed-captions", "start_pos": 98, "end_pos": 140, "type": "TASK", "confidence": 0.8487440496683121}]}], "datasetContent": [{"text": "We compute precision, recall, and F-measure based on exact boundary matches between the system and the reference segmentation.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9994334578514099}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.999582827091217}, {"text": "F-measure", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9994171857833862}]}, {"text": "As numerous researchers have pointed out, this alone is not a perspicacious way to evaluate a segmentation algorithm, as a system that misses a goldstandard boundary by one sentence would be treated just like one that misses it by ten.", "labels": [], "entities": []}, {"text": "We therefore computed two additional, widely used measures, P k) and WindowDiff (.", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.7735241055488586}]}, {"text": "P k assesses a penalty against a system for each position of a sliding window across a document in which the system and the gold standard differ on the presence or absence of (at least one) segment boundary.", "labels": [], "entities": []}, {"text": "WindowDiff is similar, but where the system differs from the gold standard, the penalty is equal to the difference in the number of boundaries between the two.", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9132764935493469}]}, {"text": "This penalizes missed boundaries and -near-misses\u2016 less than P k (but see for further analysis and some criticism of WindowDiff).", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 117, "end_pos": 127, "type": "DATASET", "confidence": 0.884523332118988}]}, {"text": "For both P k and WindowDiff, we used a window size of half the average reference segment length, as suggested by.", "labels": [], "entities": []}, {"text": "P k and WindowDiff values range between 0 and 1, with lower values indicating better performance in detecting segment boundaries.", "labels": [], "entities": [{"text": "detecting segment boundaries", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.8280746539433798}]}, {"text": "Note that both P k and WindowDiff are asymmetrical measures; different values will result if the system's and the gold-standard's boundaries are switched.", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.8807248473167419}]}], "tableCaptions": [{"text": " Table 2. Performance of C99 and SS on segmen- tation of concatenated New York Times articles,  without specifying a number of boundaries", "labels": [], "entities": [{"text": "SS", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9593371152877808}, {"text": "segmen- tation of concatenated New York Times articles", "start_pos": 39, "end_pos": 93, "type": "TASK", "confidence": 0.8187625143263075}]}, {"text": " Table 3. Performance of C99 and SS on segmen- tation of concatenated New York Times articles,  selecting the 20 best-scoring boundaries", "labels": [], "entities": [{"text": "SS", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9825871586799622}, {"text": "segmen- tation of concatenated New York Times articles", "start_pos": 39, "end_pos": 93, "type": "TASK", "confidence": 0.8002223438686795}]}, {"text": " Table 4. P k values for the segmentations pro- duced by each pair of annotators (A-E) and for  the combined annotation described in section  4.5; upper values are for all boundaries and low- er values are for boundaries of segments scored 3  or higher", "labels": [], "entities": []}, {"text": " Table 5. Performance of C99 and SS+C on seg- mentation of closed-captions for twelve televi- sion programs, with the two reference segmenta- tions using -all topic boundaries\u2016 and -major  topic boundaries only\u2016", "labels": [], "entities": []}]}