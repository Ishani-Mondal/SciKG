{"title": [{"text": "Towards multi-lingual summarization: A comparative analysis of sentence extraction methods on English and Hebrew corpora", "labels": [], "entities": [{"text": "multi-lingual summarization", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.598316490650177}, {"text": "sentence extraction", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7148873060941696}]}], "abstractContent": [{"text": "The trend toward the growing multi-linguality of the Internet requires text summarization techniques that work equally well in multiple languages.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7170421183109283}]}, {"text": "Only some of the automated summarization methods proposed in the literature, however , can be defined as \"language-independent\", as they are not based on any morphological analysis of the summarized text.", "labels": [], "entities": []}, {"text": "In this paper, we perform an in-depth comparative analysis of language-independent sentence scoring methods for extractive single-document summarization.", "labels": [], "entities": [{"text": "language-independent sentence scoring", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.5970130960146586}, {"text": "extractive single-document summarization", "start_pos": 112, "end_pos": 152, "type": "TASK", "confidence": 0.5790731807549795}]}, {"text": "We evaluate 15 published summarization methods proposed in the literature and 16 methods introduced in (Litvak et al., 2010).", "labels": [], "entities": []}, {"text": "The evaluation is performed on English and He-brew corpora.", "labels": [], "entities": []}, {"text": "The results suggest that the performance ranking of the compared methods is quite similar in both languages.", "labels": [], "entities": []}, {"text": "The top ten bilingual scoring methods include six methods introduced in (Litvak et al., 2010).", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatically generated summaries can significantly reduce the information overload on professionals in a variety of fields, could prove beneficial for the automated classification and filtering of documents, the search for information over the Internet and applications that utilize large textual databases.", "labels": [], "entities": [{"text": "automated classification and filtering of documents", "start_pos": 156, "end_pos": 207, "type": "TASK", "confidence": 0.7694755891958872}]}, {"text": "Document summarization methodologies include statistic-based, using either the classic vector space model or a graph representation, and semantic-based, using ontologies and languagespecific knowledge.", "labels": [], "entities": [{"text": "Document summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7598590552806854}]}, {"text": "Although the use of language-specific knowledge can potentially improve the quality of automated summaries generated in a particular language, its language specificity ultimately restricts the use of such a summarizer to a single language.", "labels": [], "entities": [{"text": "summaries generated", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.8967362344264984}]}, {"text": "Only systems that perform equally well on different languages in the absence of any language-specific knowledge can be considered language-independent summarizers.", "labels": [], "entities": []}, {"text": "As the number of languages used on the Internet increases continiously (there are at least 75 different languages according to a estimate performed by A. Gulli and A. Signorini 1 in the end of January 2005), there is a growing need for language-independent statistical summarization techniques that can be readily applied to text in any language without using language-specific morphological tools.", "labels": [], "entities": []}, {"text": "In this work, we perform an in-depth comparative analysis of 16 methods for languageindependent extractive summarization introduced in () that utilize either vector or graph-based representations of text documents computed from word segmentation and 15 state-of-the art language-independent scoring methods.", "labels": [], "entities": [{"text": "languageindependent extractive summarization", "start_pos": 76, "end_pos": 120, "type": "TASK", "confidence": 0.8017837007840475}]}, {"text": "The main goal of the evaluation experiments, which focused on English and Hebrew corpora, is to find the most efficient language-independent sentence scoring methods in terms of summarization accuracy and computational complexity across two different languages.", "labels": [], "entities": [{"text": "summarization", "start_pos": 178, "end_pos": 191, "type": "TASK", "confidence": 0.9607701301574707}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.7638165950775146}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section describes related work in extractive summarization.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.8205555081367493}]}, {"text": "Section 3 reviews the evaluated language-independent sentence scoring approaches.", "labels": [], "entities": [{"text": "language-independent sentence scoring", "start_pos": 32, "end_pos": 69, "type": "TASK", "confidence": 0.5769599874814352}]}, {"text": "Section 4 contains our experimental results on English and Hebrew corpora.", "labels": [], "entities": []}, {"text": "The last section comprises conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For English texts, we used the corpus of summarized documents provided for the single doc-ument summarization task at the Document Understanding Conference 2002.", "labels": [], "entities": [{"text": "summarization task at the Document Understanding Conference 2002", "start_pos": 96, "end_pos": 160, "type": "TASK", "confidence": 0.62612559273839}]}, {"text": "This benchmark dataset contains 533 news articles, each of which is at least ten sentences long and has two to three human-generated abstracts of approximately 100 words apiece.", "labels": [], "entities": []}, {"text": "However, to the best of our knowledge, no summarization benchmarks exist for the Hebrew language texts.", "labels": [], "entities": []}, {"text": "To collect summarized texts in Hebrew, we setup an experiment 7 in which 50 news articles of 250 to 830 words each from the Haaretz 8 newspaper internet site were summarized by human assessors by extracting the most salient sentences.", "labels": [], "entities": [{"text": "Haaretz 8 newspaper internet site", "start_pos": 124, "end_pos": 157, "type": "DATASET", "confidence": 0.8704362273216247}]}, {"text": "In total, 70 undergraduate students from the Department of Information Systems Engineering, Ben Gurion University of the Negev participated in the experiment.", "labels": [], "entities": [{"text": "Information Systems Engineering", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.6744262476762136}]}, {"text": "Ten documents were randomly assigned to each of the 70 study participants who were instructed (1) To dedicate at least five minutes to each document, (2) To ignore dialogs and citations, (3) To read the whole document before starting sentence extraction, (4) To ignore redundant, repetitive, or overly detailed information, (5) To obey the minimal and maximal summary constraints of 95 and 100 words, respectively.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 234, "end_pos": 253, "type": "TASK", "confidence": 0.7184523195028305}]}, {"text": "Summaries were assessed for quality by procedure described in ().", "labels": [], "entities": []}, {"text": "We evaluated English and Hebrew summaries using the ROUGE-1, 2, 3, 4, L, SU and W metrics 9 , described in Lin (2004).", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9713936448097229}]}, {"text": "Our results were not statistically distinguishable and matched the conclusion of.", "labels": [], "entities": []}, {"text": "However, because ROUGE-1 showed the largest variation across the methods, all results in the following comparisons are presented in terms of ROUGE-1 metric.", "labels": [], "entities": []}, {"text": "Similar to the approach described in, we performed multiple comparisons between the sentence scoring methods.", "labels": [], "entities": []}, {"text": "The Friedman test was used to reject the null hy- The software enabling easy selection and storage of sentences to be included in the document extract, can be provided upon request.", "labels": [], "entities": []}, {"text": "8 http://www.haaretz.co.il 9 ROUGE toolkit was adapted to Hebrew by specifying \"token\" using Hebrew alphabet pothesis (all methods perform the same) at the 0.0001 significance level, after which we ran the Bonferroni-Dunn test) for pairwise comparisons.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9759004712104797}]}, {"text": "show the results of multiple comparisons and are arranged in descending order with the best approaches on top.", "labels": [], "entities": []}, {"text": "Methods not sharing any common letter were significantly different at the 95% confidence level.", "labels": [], "entities": []}, {"text": "The Pearson correlation between methods ranking in English and Hebrew was 0.775, which was larger than zero at a significance level of 0.0001.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.9654620587825775}]}, {"text": "In other words, most of the methods were ranked in nearly the same relative positions in both corpora, and the top ranked methods performed equally well in both languages.", "labels": [], "entities": []}, {"text": "The differences in ranking were caused by morphological differences between two languages.", "labels": [], "entities": []}, {"text": "To determine which approaches performed best in both languages, we analyzed the clustering results of the methods in both corpora and found the intersection of the top clusters from the two clustering results.", "labels": [], "entities": []}, {"text": "For each language, a document-method matrix of ROUGE scores was created with methods represented by vectors of their ROUGE scores for each document in a corpora.", "labels": [], "entities": []}, {"text": "Since most scores are not normally  distributed, we chose the K-means algorithm, which does not assume normal distribution of data, for clustering.", "labels": [], "entities": []}, {"text": "We ran the algorithm with different numbers of clusters (2 \u2264 K \u2264 10), and for each K, we measured two parameters: the minimal distance between neighboring clusters in the clustered data for each language and the level of similarity between the clustering results for the two languages.", "labels": [], "entities": []}, {"text": "For both parameters, we used the regular Euclidean distance.", "labels": [], "entities": []}, {"text": "For K \u2265 6, the clusters were highly similar for each language, and the distance between English and Hebrew clustering data was maximal.", "labels": [], "entities": []}, {"text": "Based on the obtained results, we left results only for 2 \u2264 K \u2264 5 for each corpus.", "labels": [], "entities": []}, {"text": "Then, we ordered the clusters by the average ROUGE score of each cluster's instances (methods) and identified the methods appearing in the top clusters for all K values in both corpora.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 45, "end_pos": 56, "type": "METRIC", "confidence": 0.9770219922065735}]}, {"text": "shows the resulting top ten scoring methods with their rank in each corpus.", "labels": [], "entities": []}, {"text": "Six methods intro-  Neither vector-nor graph-based text representation models, however, can claim ultimate superiority, as methods based on both models prominently in the top-evaluated cluster.", "labels": [], "entities": []}, {"text": "Moreover, highly-correlated methods (see for highly-correlated pairs of methods in English and Hebrew corpora, respectively) appear in the same cluster inmost cases.", "labels": [], "entities": []}, {"text": "As a result, some pairs from among the top ten methods are highlycorrelated in at least one language, and only one from each pair can be considered.", "labels": [], "entities": []}, {"text": "For example, LEN W and LEN CH have high correlation coefficients (0.909 and 0.954 in English and Hebrew, respectively).", "labels": [], "entities": [{"text": "correlation", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.9761139154434204}]}, {"text": "Since LEN CH is more appropriate for multilingual processing due to variations in the rules of tokenization between languages (e.g., English vs. German), it maybe considered a preferable multilingual metric.", "labels": [], "entities": [{"text": "LEN CH", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9412749409675598}]}, {"text": "In terms of summarization quality and computational complexity, all scoring functions presented in can be considered to perform equally well for bilingual extractive summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.9875569343566895}, {"text": "bilingual extractive summarization", "start_pos": 145, "end_pos": 179, "type": "TASK", "confidence": 0.5915327966213226}]}, {"text": "Assuming their efficient implementation, all methods have a linear computational complexity, O(n), relative to the total number of words in a document.", "labels": [], "entities": [{"text": "O", "start_pos": 93, "end_pos": 94, "type": "METRIC", "confidence": 0.9951992630958557}]}, {"text": "KEY PR and COV PR re-quire additional O(c(|E|+|V |)) time for running PageRank, where c is the number of iterations it needs to converge, |E| is the number of edges, and |V | is the number of nodes (distinct words) in a document graph.", "labels": [], "entities": [{"text": "KEY PR", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.563744381070137}, {"text": "O", "start_pos": 38, "end_pos": 39, "type": "METRIC", "confidence": 0.9975382089614868}]}, {"text": "Since neither |E| nor |V | in our graph representation can be as large as n, the total computation time for KEY PR and COV PR metrics is also linear relative to the document size.", "labels": [], "entities": [{"text": "KEY PR", "start_pos": 108, "end_pos": 114, "type": "TASK", "confidence": 0.4961351901292801}]}, {"text": "In terms of implementation complexity, LEN W and LEN CH are simpliest, since they even do not require any preprocessing and representation building; KEY and COV require keywords identification; D COV C, and D COV J require vector space model building; KEY DEG and COV DEG need graphs building (order of words); whereas KEY PR and COV PR, in addition, require PageRank implementation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Selected thresholds for threshold-based  scoring methods", "labels": [], "entities": []}, {"text": " Table 5: Hebrew: Correlation between sentence  ranking approaches using Pearson", "labels": [], "entities": [{"text": "sentence  ranking", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7031708806753159}]}, {"text": " Table 6: Ranking of the best bilingual scores", "labels": [], "entities": []}]}