{"title": [{"text": "Comparing Spoken Language Route Instructions for Robots across Environment Representations", "labels": [], "entities": [{"text": "Comparing Spoken Language Route Instructions", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6649654567241668}]}], "abstractContent": [{"text": "Spoken language interaction between humans and robots in natural environments will necessarily involve communication about space and distance.", "labels": [], "entities": []}, {"text": "The current study examines people's close-range route instructions for robots and how the presentation format (schematic, virtual or natural) and the complexity of the route affect the content of instructions.", "labels": [], "entities": []}, {"text": "We find that people have a general preference for providing metric-based instructions.", "labels": [], "entities": []}, {"text": "At the same time, presentation format appears to have less impact on the formulation of these instructions.", "labels": [], "entities": []}, {"text": "We conclude that understanding of spatial language requires handling both landmark-based and metric-based expressions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken language interaction between humans and robots in natural environments will necessarily involve communication about space and distance.", "labels": [], "entities": []}, {"text": "It is consequently useful to understand the nature of the language that humans would use for this purpose.", "labels": [], "entities": []}, {"text": "In the present study we examine this question in the context of formulating route instructions given to robots.", "labels": [], "entities": []}, {"text": "For practical purposes, we are also interested in understanding how presentation format affects such language.", "labels": [], "entities": []}, {"text": "Instructions given in a physical space might differ from those given in a virtual world, which in turn may differ from those given when only a schematic representation (e.g., a map or drawing) is available.", "labels": [], "entities": []}, {"text": "There is general agreement that landmarks play an important role in spatial language).", "labels": [], "entities": []}, {"text": "However, landmarks might not necessarily be used uniformly in instructions across presentation formats.", "labels": [], "entities": []}, {"text": "For example, people may use objects in the environment as landmarks more often when they do not have a good sense of distance in the environment.", "labels": [], "entities": []}, {"text": "Behaviors related to spatial language may change based on the complexity of the route that a robot must take.", "labels": [], "entities": []}, {"text": "This could be due to a combination of factors, including ease of use and personal assessment of a robot's ability to interpret specific distances over landmarks.", "labels": [], "entities": []}, {"text": "Several studies have investigated written or typed spatial language (e.g.,;.", "labels": [], "entities": []}, {"text": "In addition, Ross (2008) studied models of spoken language interpretation in schematic views of areas.", "labels": [], "entities": [{"text": "spoken language interpretation", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.7647293210029602}]}, {"text": "In the current study we focus on close-range spoken language route instructions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Participants observed two-dimensional configurations of schematics that contained two robots (Mok and Aki) and a destination marker in this experiment.", "labels": [], "entities": []}, {"text": "Each participant viewed a single monitor displaying a recording interface overlaid by static slides that contained the stimuli.", "labels": [], "entities": []}, {"text": "After each participant was shown the speech recording interface and had tried it out, they proceeded through a randomly ordered slide set.", "labels": [], "entities": []}, {"text": "In this experiment, participants viewed an overhead perspective of the scene, with the robots represented as arrows and the destination marked by purple circles (see).", "labels": [], "entities": []}, {"text": "The robots were represented by arrows that were meant to indicate their orientations in the scene.", "labels": [], "entities": []}, {"text": "In this experiment, we crafted stimuli with a three-dimensional map builder and USARSim, a virtual simulation platform designed for conducting experiments with robots).", "labels": [], "entities": [{"text": "USARSim", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.8970402479171753}]}, {"text": "The map was designed such that trials were \"rooms\" in a multi-room environment.", "labels": [], "entities": []}, {"text": "Participants did not walk through the environment; they only viewed static configurations.", "labels": [], "entities": []}, {"text": "Included in the map were instances of two Pioneer P2AT robots.", "labels": [], "entities": []}, {"text": "All visual stimuli were presented at an eye-level view, with eyes at a height of 5'10\" (see).", "labels": [], "entities": []}, {"text": "The room was designed such that walls would be too faraway to serve as landmarks.", "labels": [], "entities": []}, {"text": "Visual stimuli for this experiment required fullscreen access to the game engine, so the recording interface was moved to an adjoining monitor.", "labels": [], "entities": []}, {"text": "We included an additional condition: informing participants (or not) of the distance between the two robots.", "labels": [], "entities": []}, {"text": "We recruited fourteen participants for this study, seven in each of two conditions.", "labels": [], "entities": []}, {"text": "In one condition (no-dist), participants were not given any information related to the scale of the robots and area in the stimuli.", "labels": [], "entities": []}, {"text": "This is equivalent to what participants experienced in the schematic scene experiment.", "labels": [], "entities": []}, {"text": "In the second condition (dist), the instructions indicated that the two robots, Mok and Aki, were seven feet apart.", "labels": [], "entities": []}, {"text": "However, no scale information (e.g., a ruler) was provided in the scene itself.", "labels": [], "entities": []}, {"text": "This would provide the option to cast instructions in terms of absolute distances.", "labels": [], "entities": []}, {"text": "The option to use Aki as a landmark reference point remained the same as in the first experiment.", "labels": [], "entities": []}, {"text": "We hypothesize that participants that are not given a sense of scale will use landmarks much more often than those participants that are provided distance information.", "labels": [], "entities": []}, {"text": "In natural environments, it can be assumed that people generally have a good sense of scale.", "labels": [], "entities": []}, {"text": "In this experiment, participants viewed similar stimuli to the virtual scenarios (eye-level view), but in-person (see).", "labels": [], "entities": []}, {"text": "Bins were used to represent the two robots, with two eyes placed on top of each bin to indicate orientation.", "labels": [], "entities": []}, {"text": "As in the previous experiments, participants were told to give instructions to one robot (Mok) so that it would arrive at the destination.", "labels": [], "entities": []}, {"text": "We recorded participant instructions for 8 different configurations of the two robots (destination varied four ways, Mok's orientation varied two ways, right and left; Aki's orientation did not change).", "labels": [], "entities": []}, {"text": "We simplified the number of orientations because we found that orientations of Mok and Aki did not influence landmark use in the previous experiments.", "labels": [], "entities": []}, {"text": "After each instruction, participants were asked to close their eyes as the experimenter changed the orientations.", "labels": [], "entities": []}, {"text": "Since they were not at a computer screen for this experiment, only verbal instructions were recorded, with no task times.", "labels": [], "entities": []}], "tableCaptions": []}