{"title": [{"text": "Uncertainty Detection as Approximate Max-Margin Sequence Labelling", "labels": [], "entities": [{"text": "Uncertainty Detection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6520429849624634}, {"text": "Approximate", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9465360045433044}, {"text": "Max-Margin Sequence Labelling", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.632597009340922}]}], "abstractContent": [{"text": "This paper reports experiments for the CoNLL-2010 shared task on learning to detect hedges and their scope in natural language text.", "labels": [], "entities": []}, {"text": "We have addressed the experimental tasks as supervised linear maximum margin prediction problems.", "labels": [], "entities": [{"text": "linear maximum margin prediction", "start_pos": 55, "end_pos": 87, "type": "TASK", "confidence": 0.6444862931966782}]}, {"text": "For sentence level hedge detection in the biological domain we use an L 1-regularised binary support vector machine, while for sentence level weasel detection in the Wikipedia domain, we use an L 2-regularised approach.", "labels": [], "entities": [{"text": "sentence level hedge detection", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.73006971180439}, {"text": "sentence level weasel detection", "start_pos": 127, "end_pos": 158, "type": "TASK", "confidence": 0.682599201798439}]}, {"text": "We model the in-sentence uncertainty cue and scope detection task as an L 2-regularised approximate maximum margin sequence labelling problem, using the BIO-encoding.", "labels": [], "entities": [{"text": "scope detection task", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.807810107866923}, {"text": "BIO-encoding", "start_pos": 153, "end_pos": 165, "type": "DATASET", "confidence": 0.7382728457450867}]}, {"text": "In addition to surface level features, we use a variety of linguistic features based on a functional dependency analysis.", "labels": [], "entities": []}, {"text": "A greedy forward selection strategy is used in exploring the large set of potential features.", "labels": [], "entities": []}, {"text": "Our official results for Task 1 for the biological domain are 85.2 F 1-score, for the Wikipedia set 55.4 F 1-score.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9861025512218475}, {"text": "Wikipedia set", "start_pos": 86, "end_pos": 99, "type": "DATASET", "confidence": 0.9045226573944092}, {"text": "F 1-score", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.8912018835544586}]}, {"text": "For Task 2, our official results are 2.1 for the entire task with a score of 62.5 for cue detection.", "labels": [], "entities": [{"text": "cue detection", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.8612866997718811}]}, {"text": "After resolving errors and final bugs, our final results are for Task 1, biological: 86.0, Wikipedia: 58.2; Task 2, scopes: 39.6 and cues: 78.5.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper reports experiments to detect uncertainty in text.", "labels": [], "entities": []}, {"text": "The experiments are part of the two shared tasks given by.", "labels": [], "entities": []}, {"text": "The first task is to identify uncertain sentences; the second task is to detect the cue phrase which makes the sentence uncertain and to mark its scope or span in the sentence.", "labels": [], "entities": []}, {"text": "Uncertainty as a target category needs to be addressed with some care.", "labels": [], "entities": []}, {"text": "Sentences, utterances, statements are not uncertain -their producer, the speaker or author, is.", "labels": [], "entities": []}, {"text": "Statements may explicitly indicate this uncertainty, employing several different linguistic and textual mechanisms to encode the speaker's attitude with respect to the veracity of an utterance.", "labels": [], "entities": []}, {"text": "The absence of such markers does not necessarily indicate certainty -the opposition between certain and uncertain is not clearly demarkable, but more of a dimensional measure.", "labels": [], "entities": [{"text": "certainty", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9964607357978821}]}, {"text": "Uncertainty on the part of the speaker maybe difficult to differentiate from a certain assessment of an uncertain situation, It is unclear whether this specimen is an X or a Y vs. The difference between X and Y is unclear.", "labels": [], "entities": []}, {"text": "In this task, the basis for identifying uncertainty in utterances is almost entirely lexical.", "labels": [], "entities": [{"text": "identifying uncertainty in utterances", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.8883309662342072}]}, {"text": "Hedges, the main target of this experiment, are an established category in lexical grammar analyses -see e.g., for examples of English language constructions.", "labels": [], "entities": []}, {"text": "Most languages use various verbal markers or modifiers for indicating the speaker's beliefs in what is being said, most prototypically using conditional or optative verb forms, Six Parisiens seraient morts, or auxiliaries, This mushroom maybe edible, but aspectual markers may also be recruited for this purpose, more indirectly, I'm hoping you will help vs. I hope you will help; Do you want to see me now vs. Did you want to see me now.", "labels": [], "entities": []}, {"text": "Besides verbs, there are classes of terms that through their presence, typically in an adverbial role, in an utterance make explicit its tentativeness: possibly, perhaps... and more complex constructions with some reservation, especially such that explicitly mention the speaker and the speaker's beliefs or doubts, I suspect that X.", "labels": [], "entities": []}, {"text": "Weasels, the other target of this experiment, on the other hand, do not indicate uncertainty.", "labels": [], "entities": [{"text": "uncertainty", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9536087512969971}]}, {"text": "Weasels are employed when speakers attempt to convince the listener of something they most likely are certain of themselves, by anchoring the truthfulness of the utterance to some outside factor authority (Most linguists believe in the existence of an autonomous linguistic processing component), but where the authority in question is so unspecific as not to be verifiable when scrutinised.", "labels": [], "entities": []}, {"text": "We address both CoNLL-2010 shared tasks (.", "labels": [], "entities": [{"text": "CoNLL-2010", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.7803824543952942}]}, {"text": "The first, detecting uncertain information on a sentence level, we solve by using an L 1 -regularised support vector machine with hinge loss for the biological domain, and an L 2 -regularised maximum margin model for the Wikipedia domain.", "labels": [], "entities": [{"text": "Wikipedia domain", "start_pos": 221, "end_pos": 237, "type": "DATASET", "confidence": 0.9470451176166534}]}, {"text": "The second task, resolution of in-sentence scopes of hedge cues, we approach as an approximate L 2 -regularized maximum margin structured prediction problem.", "labels": [], "entities": [{"text": "resolution of in-sentence scopes of hedge cues", "start_pos": 17, "end_pos": 63, "type": "TASK", "confidence": 0.8264543328966413}]}, {"text": "Our official results for Task 1 for the biological domain are 85.2 F 1 -score, for the Wikipedia set 55.4 F 1 -score.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9860449582338333}, {"text": "Wikipedia set", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.8956685364246368}, {"text": "F 1 -score", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.9617372900247574}]}, {"text": "For Task 2, our official results were 2.1 for the entire task with a score of 62.5 for cue detection.", "labels": [], "entities": [{"text": "cue detection", "start_pos": 87, "end_pos": 100, "type": "TASK", "confidence": 0.8770060539245605}]}, {"text": "After resolving errors and unfortunate bugs, our final results are for Task 1, biological: 86.0, Wikipedia: 58.2; Task 2: 39.6 and 78.5 for cues.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Top feature templates for sentence level  hedge and weasel detection.", "labels": [], "entities": [{"text": "weasel detection", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.7387633621692657}]}, {"text": " Table 2: Top feature templates for in-sentence de- tection of hedge cues and scopes.", "labels": [], "entities": []}]}