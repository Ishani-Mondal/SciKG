{"title": [{"text": "UDel: Named Entity Recognition and Reference Regeneration from Surface Text", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.5865083932876587}]}], "abstractContent": [{"text": "This report describes the methods and results of a system developed for the GREC Named Entity Recognition and GREC Named Entity Regeneration Challenges 2010.", "labels": [], "entities": [{"text": "GREC Named Entity Recognition", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.7880653738975525}, {"text": "GREC Named Entity Regeneration Challenges 2010", "start_pos": 110, "end_pos": 156, "type": "DATASET", "confidence": 0.780724416176478}]}, {"text": "We explain our process of automatically annotating surface text, as well as how we use this output to select improved referring expressions for named entities.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generation of References in Context (GREC) is a set of shared task challenges in NLG involving a corpus of introductory sentences from Wikipedia articles.", "labels": [], "entities": [{"text": "Generation of References in Context (GREC)", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7379198223352432}]}, {"text": "The Named Entity Recognition (GREC-NER) task requires participants to recognize all mentions of people in a document and indicate which mentions corefer.", "labels": [], "entities": [{"text": "Named Entity Recognition (GREC-NER) task", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.7709068357944489}]}, {"text": "In the Named Entity Regeneration (GREC-Full) task, submitted systems attempt to improve the clarity and fluency of a text by generating improved referring expressions (REs) for all references to people.", "labels": [], "entities": [{"text": "Named Entity Regeneration (GREC-Full) task", "start_pos": 7, "end_pos": 49, "type": "TASK", "confidence": 0.7330447350229535}, {"text": "clarity", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9563724994659424}]}, {"text": "Participants are encouraged to use the output from GREC-NER as input for the GREC-Full task.", "labels": [], "entities": [{"text": "GREC-NER", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9048879146575928}]}, {"text": "To provide ample opportunities for improvement, a certain portion of REs in the corpus have been replaced by morespecified named references.", "labels": [], "entities": []}, {"text": "Ideally, the GRECFull output will be more fluent and have greater referential clarity than the GREC-NER input.", "labels": [], "entities": [{"text": "clarity", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.8028773069381714}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Self-evaluation scores for GREC-NER.", "labels": [], "entities": [{"text": "GREC-NER", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.5321717858314514}]}, {"text": " Table 2: Self-evaluation scores for GREC-Full.", "labels": [], "entities": [{"text": "GREC-Full", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.5050415992736816}]}]}