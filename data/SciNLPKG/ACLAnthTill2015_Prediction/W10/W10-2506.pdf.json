{"title": [], "abstractContent": [{"text": "We derive and implement an algorithm similar to (Huang and Chiang, 2005) for finding then best derivations in a weighted hypergraph.", "labels": [], "entities": []}, {"text": "We prove the correctness and termination of the algorithm and we show experimental results concerning its run-time.", "labels": [], "entities": [{"text": "termination", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9566393494606018}]}, {"text": "Our work is different from the afore-mentioned one in the following respects: we consider labeled hypergraphs, allowing for tree-based language models (Maletti and Satta, 2009); we specifically handle the case of cyclic hypergraphs; we admit structured weight domains, allowing for multiple features to be processed; we use the paradigm of functional programming together with lazy evaluation, achieving concise algorithmic descriptions.", "labels": [], "entities": []}], "introductionContent": [{"text": "In statistical natural language processing, probabilistic models play an important role which can be used to assign to some input sentence a set of analyses, each carrying a probability.", "labels": [], "entities": [{"text": "statistical natural language processing", "start_pos": 3, "end_pos": 42, "type": "TASK", "confidence": 0.6716093719005585}]}, {"text": "For instance, an analysis can be a parse tree or a possible translation.", "labels": [], "entities": []}, {"text": "Due to the ambiguity of natural language, the number of analyses for one input sentence can be very large.", "labels": [], "entities": []}, {"text": "Some models even assign an infinite number of analyses to an input sentence.", "labels": [], "entities": []}, {"text": "In many cases however, the set of analyses can in fact be represented in a finite and compact way.", "labels": [], "entities": []}, {"text": "While such a representation is space-efficient, it maybe incompatible with subsequent operations.", "labels": [], "entities": []}, {"text": "In these cases a finite subset is used as an approximation, consisting of n best analyses, i. e. n analyses with highest probability.", "labels": [], "entities": []}, {"text": "For example, this approach has the following two applications.", "labels": [], "entities": []}, {"text": "(1) Reranking: when log-linear models) are employed, some features may not permit an efficient evaluation during the computation of the analyses.", "labels": [], "entities": [{"text": "Reranking", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9054619669914246}]}, {"text": "These features are computed using individual analyses from said approximation, leading to a reranking amongst them.", "labels": [], "entities": []}, {"text": "(2) Spurious ambiguity: many models produce analyses which maybe too fine-grained for further processing (.", "labels": [], "entities": []}, {"text": "As an example, consider context-free grammars, where several leftmost derivations may exist for the same terminal string.", "labels": [], "entities": []}, {"text": "The weight of the terminal string is obtained by summing over these derivations.", "labels": [], "entities": []}, {"text": "The n best leftmost derivations maybe used to approximate this sum.", "labels": [], "entities": []}, {"text": "In this paper, we consider the case where the finite, compact representation has the form of a weighted hypergraph (with labeled hyperedges) and the analyses are derivations of the hypergraph.", "labels": [], "entities": []}, {"text": "This covers many parsing applications), including weighted deductive systems, and also applications in machine translation).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7936407923698425}]}, {"text": "In the nomenclature of), which we adopt here, a derivation of a hypergraph is a tree which is obtained in the following way.", "labels": [], "entities": []}, {"text": "Starting from some node, an ingoing hyperedge is picked and recorded as the label of the root of the tree.", "labels": [], "entities": []}, {"text": "Then, for the subtrees, one continues with the source nodes of said hyperedge in the same way.", "labels": [], "entities": []}, {"text": "In other words, a derivation can be understood as an unfolding of the hypergraph.", "labels": [], "entities": []}, {"text": "The n-best-derivations problem then amounts to finding n derivations which are best with respect to the weights induced by the weighted hypergraph.", "labels": [], "entities": []}, {"text": "Among others, weighted hypergraphs with labeled hyperedges subsume the following two concepts.", "labels": [], "entities": []}, {"text": "(I) probabilistic context-free grammars (pcfgs).", "labels": [], "entities": []}, {"text": "In this case, nodes correspond to nonterminals, hyperedges are labeled with productions, and the derivations are exactly the abstract syntax trees (ASTs) of the grammar (which are closely related the parse trees).", "labels": [], "entities": []}, {"text": "Note that, unless the pcfg is unambiguous, a given word may have several corresponding ASTs, and its weight is obtained by summing over the weights of the ASTs.", "labels": [], "entities": []}, {"text": "Hence, then best derivations need not coincide with then best words (cf. application (2) above).", "labels": [], "entities": []}, {"text": "(II) weighted tree automata (wta).", "labels": [], "entities": []}, {"text": "These automata serve both as a tree-based language model and as a data structure for the parse forests obtained from that language model by applying the Bar-Hillel construction.", "labels": [], "entities": []}, {"text": "It is well known that context-free grammars and tree automata are weakly equivalent.", "labels": [], "entities": []}, {"text": "However, unlike the former formalism, the latter one has the ability to model non-local dependencies in parse trees.", "labels": [], "entities": []}, {"text": "In the case of wta, nodes correspond to states, hyperedges are labeled with input symbols, and the derivations are exactly the runs of the automaton.", "labels": [], "entities": []}, {"text": "Since, due to ambiguity, a given tree may have several accepting runs, then best derivations need not coincide with then best trees.", "labels": [], "entities": []}, {"text": "As for the pcfgs, this is an example of spurious ambiguity, which can be tackled as indicated by application (2) above.", "labels": [], "entities": []}, {"text": "Alternatively, one can attempt to find an equivalent deterministic wta.", "labels": [], "entities": []}, {"text": "Next, we briefly discuss four known algorithms which solve the n-best-derivations problem or subproblems thereof.", "labels": [], "entities": []}, {"text": "\u2022 The Viterbi algorithm solves the 1-bestderivation problem for acyclic hypergraphs.", "labels": [], "entities": []}, {"text": "It is based on a topological sort of the hypergraph.", "labels": [], "entities": []}, {"text": "\u2022 generalizes Dijkstra's algorithm (for finding the single-source shortest paths in a graph) to hypergraphs, thus solving the case n = 1 even if the hypergraph contains cycles.", "labels": [], "entities": []}, {"text": "Knuth assumes the weights to be real numbers, and he requires weight functions to be monotone and superior in order to guarantee that a best derivation exists.", "labels": [], "entities": []}, {"text": "(The superiority property corresponds to Dijkstra's requirement that edge weights-or, more generally, cycle weights-are nonnegative.)", "labels": [], "entities": []}, {"text": "\u2022 Huang and show that the nbest-derivations problem can be solved efficiently by first solving the 1-best-derivation problem and then extending that solution in a lazy manner.", "labels": [], "entities": []}, {"text": "Huang and Chiang assume weighted unlabeled hypergraphs with weights computed in the reals, and they require the weight functions to be monotone.", "labels": [], "entities": []}, {"text": "Moreover they assume that the 1-bestderivation problem be solved using the Viterbi algorithm, which implies that the hypergraph must be acyclic.", "labels": [], "entities": []}, {"text": "However they conjecture that their second phase also works for cyclic hypergraphs.", "labels": [], "entities": []}, {"text": "\u2022 Pauls and propose a variation of the algorithm of in which the 1-best-derivation problem is computed via an A * -based exploration of the 1-best charts.", "labels": [], "entities": []}, {"text": "In this paper, we also present an algorithm for solving the n-best-derivations problem.", "labels": [], "entities": []}, {"text": "Ultimately it uses the same algorithmic ideas as the one of; however, it is different in the following sense: 1.", "labels": [], "entities": []}, {"text": "we consider labeled hypergraphs, allowing for wta to be used in parsing; 2.", "labels": [], "entities": [{"text": "parsing", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.9623327255249023}]}, {"text": "we specifically handle the case of cyclic hypergraphs, thus supporting the conjecture of Huang and Chiang; for this we impose on the weight functions the same requirements as Knuth and use his algorithm; 3. by using the concept of linear pre-orders (and not only linear orders on the set of reals) our approach can handle structured weights such as vectors over frequencies, probabilities, and reals; 4.", "labels": [], "entities": []}, {"text": "we present our algorithm in the framework of functional programming (and not in that of imperative programming); this framework allows to decribe algorithms in a more abstract and concise, yet natural way; 5.", "labels": [], "entities": []}, {"text": "due to the lazy evaluation paradigm often found in functional programming, we obtain the laziness on which the algorithm of Huang and Chiang (2005) is based for free; 6.", "labels": [], "entities": []}, {"text": "exploiting the abstract level of description (see point 4) we are able to prove the correctness and termination of our algorithm.", "labels": [], "entities": []}, {"text": "At the end of this paper, we will discuss experiments which have been performed with an implementation of our algorithm in the functional programming language HASKELL. example.", "labels": [], "entities": []}, {"text": "First, we introduce some basic notions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have implemented the algorithm (consisting of Figs. 3 and 4 and the auxiliary functions of) in HASKELL.", "labels": [], "entities": [{"text": "HASKELL", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.9026106595993042}]}, {"text": "The implementation is rather straightforward except for the following three points.", "labels": [], "entities": []}, {"text": "(1) Weights: we assume that is defined by means of weights (cf., and that comparing these weights is in O(1) (which often holds because of limited precision).", "labels": [], "entities": [{"text": "O", "start_pos": 104, "end_pos": 105, "type": "METRIC", "confidence": 0.9897151589393616}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9967562556266785}]}, {"text": "Hence, we store with each derivation its weight so that comparison according to is in O(1) as well.", "labels": [], "entities": [{"text": "O", "start_pos": 86, "end_pos": 87, "type": "METRIC", "confidence": 0.8862282037734985}]}, {"text": "(2) Memoization: we use a memoization technique to ensure that no derivation occurring in p v is computed twice.", "labels": [], "entities": []}, {"text": "(3) Merge: the merge operation deserves some consideration because it is used in a nested fashion, yielding trees of merge applications.", "labels": [], "entities": []}, {"text": "This leads to an undesirable runtime complexity because these trees need not be balanced.", "labels": [], "entities": []}, {"text": "Thus, instead of actually computing the merge in p and in the top-concatenation, we just return a data structure describing what should be merged.", "labels": [], "entities": []}, {"text": "That data structure consists of a best element and a list of lists of derivations to be merged (cf. lines 06 and 09 in).", "labels": [], "entities": []}, {"text": "We use a higher-order function to manage these data structures on a heap, performing the merge in a nonnested way.", "labels": [], "entities": []}, {"text": "Runtime Here we consider the n-best part of the algorithm, i. e. we assume the computation of the mapping b to take constant time.", "labels": [], "entities": []}, {"text": "Note however that due to memoization, b is only computed once.", "labels": [], "entities": []}, {"text": "Then the runtime complexity of our implementation is in O |E| + |V | \u00b7 n \u00b7 log(|E| + n) . This can be seen as follows.", "labels": [], "entities": []}, {"text": "By line 02 in, the initial heaps in the higher-order merge described under (3) have a total of |E| elements.", "labels": [], "entities": []}, {"text": "Building these heaps is thus in O(|E|).", "labels": [], "entities": [{"text": "O", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9859241843223572}]}, {"text": "By line 09 in, each newly found derivation spawns at most as many new candidates n total time: Experimental results on the heap as the maximum rank in \u03a3.", "labels": [], "entities": []}, {"text": "We assume this to be constant.", "labels": [], "entities": []}, {"text": "Moreover, at most n derivations are computed for each node, that is, at most |V |\u00b7n in total.", "labels": [], "entities": []}, {"text": "Hence, the size of the heap of anode is in O(|E| + n).", "labels": [], "entities": [{"text": "O", "start_pos": 43, "end_pos": 44, "type": "METRIC", "confidence": 0.9624106287956238}]}, {"text": "For each derivation we compute, we have to pop the minimal element off the heap (cf. line 07 in), which is in O log(|E|+n) , and we have to compute the union of the remaining heap with the newly spawned candidates, which has the same complexity.", "labels": [], "entities": []}, {"text": "We give another estimate for the total number of derivations computed by the algorithm, which is based on the following observation.", "labels": [], "entities": []}, {"text": "When popping anew derivation \u03be off the heap, new next best candidates are computed.", "labels": [], "entities": []}, {"text": "This involves computing at most as many new derivations as the number of nodes of \u03be, because for each hyperedge occurring in \u03be we have to consider the next best alternative.", "labels": [], "entities": []}, {"text": "Since we pop off at most n elements from the heap belonging to the target node, we arrive at the estimate d \u00b7 n, where dis the size of the biggest derivation of said node.", "labels": [], "entities": []}, {"text": "A slight improvement of the runtime complexity can be obtained by restricting the heap size ton best elements, as argued by.", "labels": [], "entities": []}, {"text": "This way, they are able to obtain the complexity O(|E| + d \u00b7 n \u00b7 log n).", "labels": [], "entities": [{"text": "O", "start_pos": 49, "end_pos": 50, "type": "METRIC", "confidence": 0.5840618014335632}]}, {"text": "We have conducted experiments on an Intel Core Duo 1200 MHz with 2 GB of RAM using a cyclic hypergraph containing 671 vertices and 12136 edges.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "This table indicates that the runtime of the n-best part is roughly linear inn.", "labels": [], "entities": []}], "tableCaptions": []}