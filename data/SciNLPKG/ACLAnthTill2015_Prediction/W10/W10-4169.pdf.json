{"title": [{"text": "Chinese Word Sense Induction based on Hierarchical Clustering Algorithm", "labels": [], "entities": [{"text": "Chinese Word Sense Induction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6163002699613571}]}], "abstractContent": [{"text": "Sense induction seeks to automatically identify word senses of polysemous words encountered in a corpus.", "labels": [], "entities": [{"text": "Sense induction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8191565573215485}]}, {"text": "Unsupervised word sense induction can be viewed as a clustering problem.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.739561140537262}]}, {"text": "In this paper, we used the Hierarchical Clustering Algorithm as the classifier for word sense induction.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.8101924061775208}]}, {"text": "Experiments show the system can achieve 72% F-score about train-corpus and 65% F-score about test-corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9990768432617188}, {"text": "F-score", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.9982719421386719}]}], "introductionContent": [{"text": "Word sense induction is a central problem in many natural language processing tasks such as information extraction, information retrieval, and machine translation.", "labels": [], "entities": [{"text": "Word sense induction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7361955245335897}, {"text": "information extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7970093488693237}, {"text": "information retrieval", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.8068813979625702}, {"text": "machine translation", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.8094309568405151}]}, {"text": "Clp 2010 launches totally 4 tasks for evaluation exercise, these are: Chinese word segmentation, Chinese parsing, Chinese Personal Name disambiguation and Chinese Word Sense Induction.", "labels": [], "entities": [{"text": "Clp 2010", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9682840406894684}, {"text": "Chinese word segmentation", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6520026326179504}, {"text": "Chinese parsing", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.7993224561214447}, {"text": "Chinese Personal Name disambiguation", "start_pos": 114, "end_pos": 150, "type": "TASK", "confidence": 0.5392010062932968}, {"text": "Chinese Word Sense Induction", "start_pos": 155, "end_pos": 183, "type": "TASK", "confidence": 0.5928814932703972}]}, {"text": "We participated in task 4, which is Chinese Word Sense Induction..", "labels": [], "entities": [{"text": "Chinese Word Sense Induction.", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.6684952229261398}]}, {"text": "Because the contents surround an ambiguous word is related to its meaning, we solve the sense problem by grouping the instances of the target word into the supposed number of clusters according to the similarity of contexts of the instance.", "labels": [], "entities": []}, {"text": "In this paper we used the hierarchical clustering algorithm to accomplish the problem.", "labels": [], "entities": []}, {"text": "The task can be defined as two stage process: Feature selection and word clustering.", "labels": [], "entities": [{"text": "Feature selection", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.722831130027771}, {"text": "word clustering", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7649334371089935}]}, {"text": "Researchers have proposed much approach to the sense induction task which involved the use of basic word co-occurrence features and application of classical clustering algorithms.", "labels": [], "entities": [{"text": "sense induction task", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.872429351011912}]}, {"text": "Because the meanings of unknown words can be inferred from the contexts in which they appear, map the senses to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.9726813435554504}]}, {"text": "More recently, the mapping has been used to test the system on publicly available benchmarks ().", "labels": [], "entities": []}, {"text": "However, this approach does not generalize to multiple-sense words.", "labels": [], "entities": []}, {"text": "Each sense of a polysemous word can appear in a different context, there have been many attempts in recent years to apply classical clustering algorithms to this problem.", "labels": [], "entities": []}, {"text": "Clustering algorithms have been employed ranging from k-means (), to agglomerative clustering, and the Information Bottleneck ().", "labels": [], "entities": []}, {"text": "Senses are induced by identifying highly dense subgraphs (hubs) in the co-occurrence graph).The sIB algorithm was used to estimate cluster structure, which measures the similarity of contexts of instances according to the similarity of their feature conditional distribution).", "labels": [], "entities": []}, {"text": "Each algorithm treats words as feature vectors, using the same similarity function based on context information.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 the Featured set and word similarity definition is introduced.", "labels": [], "entities": []}, {"text": "The hierarchical clustering algorithm is presented in section 3.", "labels": [], "entities": []}, {"text": "Section 4 provides the experimental results and conclusion is drawn in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The test data includes totally 100 ambiguous Chinese words, every word have 50 untagged instances.", "labels": [], "entities": []}, {"text": "Table3 show the best/worst/average F-Score of our system about train-corpus and test-corpus.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9976512789726257}]}], "tableCaptions": [{"text": " Table 4 Model performance with deferent windows", "labels": [], "entities": []}, {"text": " Table 5 Model performance with deferent similarity definition", "labels": [], "entities": []}]}