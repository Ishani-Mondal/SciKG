{"title": [{"text": "Online Error Detection of Barge-In Utterances by Using Individual Users' Utterance Histories in Spoken Dialogue System", "labels": [], "entities": [{"text": "Online Error Detection of Barge-In Utterances", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7564739386240641}]}], "abstractContent": [{"text": "We develop a method to detect erroneous interpretation results of user utterances by exploiting utterance histories of individual users in spoken dialogue systems that were deployed for the general public and repeatedly utilized.", "labels": [], "entities": []}, {"text": "More specifically , we classify barge-in utterances into correctly and erroneously interpreted ones by using features of individual users' utterance histories such as their barge-in rates and estimated automatic speech recognition (ASR) accuracies.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 202, "end_pos": 236, "type": "TASK", "confidence": 0.7354156772295634}]}, {"text": "Online detection is enabled by making these features obtainable without any manual annotation or labeling.", "labels": [], "entities": [{"text": "Online detection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6832706481218338}]}, {"text": "We experimentally compare classification accuracies for several cases when an ASR confidence measure is used alone or in combination with the features based on the user's utterance history.", "labels": [], "entities": [{"text": "ASR", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.8653960227966309}]}, {"text": "The error reduction rate was 15% when the utterance history was used.", "labels": [], "entities": [{"text": "error reduction rate", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.9579339226086935}]}], "introductionContent": [{"text": "Many researchers have tackled the problem of automatic speech recognition (ASR) errors by developing ASR confidence measures based on utterance-level) or dialogue-level information ().", "labels": [], "entities": [{"text": "automatic speech recognition (ASR) errors", "start_pos": 45, "end_pos": 86, "type": "TASK", "confidence": 0.8123081837381635}]}, {"text": "Especially in systems deployed for the general public such as those of (), the systems need to correctly detect interpretation errors caused by various utterances made by various users, including novices.", "labels": [], "entities": []}, {"text": "Error detection using individual user models would be a promising way of improving performance in such systems * Currently with Graduate School of Engineering, Nagoya University, Furo-cho, Chikusa-ku, Nagoya 464-8603, Japan.", "labels": [], "entities": [{"text": "Error detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7175000011920929}]}, {"text": "komatani@nuee.nagoya-u.ac.jp because users often access them repeatedly.", "labels": [], "entities": []}, {"text": "We choose to detect interpretation errors of barge-in utterances, mostly caused by ASR errors, as a task for showing the effectiveness of the user's utterance histories.", "labels": [], "entities": [{"text": "ASR", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9130889773368835}]}, {"text": "We try to improve the accuracy of classifying barge-in utterances into correctly and erroneously interpreted ones without any manual labeling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9984316229820251}, {"text": "classifying barge-in utterances", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.8462144335110983}]}, {"text": "By classifying utterances accurately, the system can reduce erroneous responses caused by the errors and unnecessary confirmations.", "labels": [], "entities": []}, {"text": "Here, a \"barge-in utterance\" is a user utterance that interrupts the system's prompt.", "labels": [], "entities": []}, {"text": "In this situation, the system stops its prompt and starts recognizing the user utterance.", "labels": [], "entities": []}, {"text": "In this study, we combine the ASR confidence measure with features obtained from the user's utterance history, i.e., the estimated ASR accuracy and the barge-in rate, to detect interpretation errors of barge-in utterances.", "labels": [], "entities": [{"text": "ASR confidence measure", "start_pos": 30, "end_pos": 52, "type": "METRIC", "confidence": 0.8275049328804016}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.6329296827316284}]}, {"text": "We show that the features are still effective when they are used together with the ASR confidence measure, which is usually used to detect erroneous ASR results.", "labels": [], "entities": [{"text": "ASR confidence measure", "start_pos": 83, "end_pos": 105, "type": "METRIC", "confidence": 0.8202340801556905}, {"text": "ASR", "start_pos": 149, "end_pos": 152, "type": "TASK", "confidence": 0.8835565447807312}]}, {"text": "The characteristics of our method are summarized as follows: 1.", "labels": [], "entities": []}, {"text": "The user's utterance history used as his/her profile: The user's current barge-in rate and ASR accuracy are used for error detection.", "labels": [], "entities": [{"text": "ASR", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.8846425414085388}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.6169764399528503}, {"text": "error detection", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.6713975518941879}]}, {"text": "2. Online user modeling: We try to obtain the user profiles listed above without any manual labeling after the dialogue has been completed.", "labels": [], "entities": [{"text": "Online user modeling", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.5992550651232401}]}, {"text": "This means that the system can improve its performance while it is deployed.", "labels": [], "entities": []}, {"text": "In our earlier report, we defined the estimated ASR accuracy and showed that it is helpful in improving the accuracy of classifying barge-in utterances into correctly and erroneously interpreted ones, by using it in conjunction with the user's barge-in rate.", "labels": [], "entities": [{"text": "ASR", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9356188774108887}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.8057006597518921}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9986026883125305}]}, {"text": "In this report, we verify our approach when the ASR confidence measure is also incorporated into it.", "labels": [], "entities": [{"text": "ASR confidence measure", "start_pos": 48, "end_pos": 70, "type": "METRIC", "confidence": 0.7888269027074178}]}, {"text": "Thus, we show the individual user's utterance history is helpful as a user profile and works as prior information for the ASR confidence.", "labels": [], "entities": [{"text": "ASR", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9255185723304749}]}], "datasetContent": [{"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "First, we can see that the classification accuracies for Conditions (1) to (6) are high because the ASR confidence measure (CM) works well ().", "labels": [], "entities": [{"text": "ASR confidence measure (CM)", "start_pos": 100, "end_pos": 127, "type": "METRIC", "confidence": 0.8842561344305674}]}, {"text": "The MAEs are also small, which means the outputs of the logistic regression functions are good indicators of the reliability of the interpretation result.", "labels": [], "entities": [{"text": "MAEs", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9304940700531006}]}, {"text": "Upon comparing Condition (6) with Conditions (1) to (5), we can see that the classification accuracies improve as a result of incorporating the user's utterance histories such as barge-in rates and ASR accuracies.", "labels": [], "entities": []}, {"text": "lists p-values of the differences when the barge-in rate and the estimated ASR accuracy were used in addition to the CM.", "labels": [], "entities": [{"text": "ASR", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.7079002857208252}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.6892833113670349}]}, {"text": "The significance test was based on the McNemar test.", "labels": [], "entities": [{"text": "significance", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9886518120765686}, {"text": "McNemar test", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.8461872041225433}]}, {"text": "As shown in the table, all the differences were statistically significant (p < 0.01).", "labels": [], "entities": []}, {"text": "That is, it was experimentally shown that these utterance histories of users are different information sources from those of single utterances and that they contribute to improving the classification accuracy even when used together with ASR confidence measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9433057904243469}, {"text": "ASR", "start_pos": 238, "end_pos": 241, "type": "TASK", "confidence": 0.7844576239585876}]}, {"text": "The relative improvement in the error reduction rate was 15.2% between Conditions (2) and (6), that is, by adding the barge-in rate and the estimated ASR accuracy, both of which can be obtained without manual labeling.", "labels": [], "entities": [{"text": "error reduction rate", "start_pos": 32, "end_pos": 52, "type": "METRIC", "confidence": 0.9537366032600403}, {"text": "Conditions", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.7885386943817139}, {"text": "ASR", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.711547315120697}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.7186792492866516}]}, {"text": "0.00003 (4) vs 0.00017 (5) vs 0.00876 shows the results in more detail; the classification accuracies for Conditions (1), (2), (4), and (6) are shown for various window widths.", "labels": [], "entities": []}, {"text": "Under Condition (6), the classification accuracy does not depend on the window width because the barge-in rate is not used.", "labels": [], "entities": [{"text": "classification", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.9325857758522034}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9559695720672607}]}, {"text": "Under Conditions (1), (2), and (4), the accuracies depend on the window width for the barge-in rate and are highest when the width is 30 or 40.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9974884986877441}]}, {"text": "These results show the effectiveness of the window, which indicates that temporal changes in user behaviors should betaken into consideration, and match those of our earlier reports (: the user's utterance history becomes effective after he/she uses the system about ten times because the average number of utterances per dialogue is around five.", "labels": [], "entities": []}, {"text": "By comparing Conditions (2) and (4), we can see that the classification accuracy improves after adding the estimated ASR accuracy to Condition (4).", "labels": [], "entities": [{"text": "classification", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.8887182474136353}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9615587592124939}, {"text": "ASR accuracy", "start_pos": 117, "end_pos": 129, "type": "METRIC", "confidence": 0.6578476428985596}]}, {"text": "This shows that the estimated ASR accuracy also contributes to improving the classification accuracy.", "labels": [], "entities": [{"text": "ASR", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8148168325424194}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8694210648536682}, {"text": "classification", "start_pos": 77, "end_pos": 91, "type": "TASK", "confidence": 0.9687610864639282}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.8779969215393066}]}, {"text": "By comparing Conditions (1) and (2), we can see that Condition (1), in which the actual ASR accuracy is used, outperforms Condition (2), in which the estimated one is used.", "labels": [], "entities": [{"text": "Condition", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9653383493423462}, {"text": "ASR accuracy", "start_pos": 88, "end_pos": 100, "type": "METRIC", "confidence": 0.5732969045639038}]}, {"text": "This suggests that the classification accuracy, whose upper limit is Condition (1), can be improved by making the ASR accuracy estimation shown in Section 3.2 more accurate.", "labels": [], "entities": [{"text": "classification", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.9499973654747009}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9666309356689453}, {"text": "Condition", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9893131852149963}, {"text": "ASR", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.8558517098426819}, {"text": "accuracy estimation", "start_pos": 118, "end_pos": 137, "type": "METRIC", "confidence": 0.820789635181427}]}], "tableCaptions": [{"text": " Table 1: ASR accuracy per barge-in", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7620230317115784}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9552002549171448}]}, {"text": " Table 2: ASR accuracy of barge-in utterances for  different barge-in rates", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9215818047523499}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9853447079658508}]}, {"text": " Table 3: Distribution of ASR confidence measures  for barge-in utterances", "labels": [], "entities": [{"text": "ASR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.7515618801116943}]}, {"text": " Table 4: ASR accuracy by user response type", "labels": [], "entities": [{"text": "ASR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8912608623504639}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9711262583732605}]}]}