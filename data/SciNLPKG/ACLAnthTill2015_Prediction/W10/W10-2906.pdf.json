{"title": [{"text": "Learning Better Monolingual Models with Unannotated Bilingual Text", "labels": [], "entities": []}], "abstractContent": [{"text": "This work shows how to improve state-of-the-art monolingual natural language processing models using unannotated bilingual text.", "labels": [], "entities": []}, {"text": "We build a mul-tiview learning objective that enforces agreement between monolingual and bilingual models.", "labels": [], "entities": []}, {"text": "In our method the first, monolingual view consists of supervised predictors learned separately for each language.", "labels": [], "entities": []}, {"text": "The second, bilingual view consists of log-linear predictors learned over both languages on bilingual text.", "labels": [], "entities": []}, {"text": "Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model, and we show how to combine the two models to account for dependence between views.", "labels": [], "entities": []}, {"text": "For the task of named entity recognition, using bilingual predictors increases F1 by 16.1% absolute over a supervised monolingual model, and retraining on bilingual predictions increases monolingual model F1 by 14.6%.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6575075884660085}, {"text": "F1", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9997648596763611}, {"text": "F1", "start_pos": 205, "end_pos": 207, "type": "METRIC", "confidence": 0.9433490633964539}]}, {"text": "For syntactic parsing, our bilingual predictor increases F1 by 2.1% absolute, and retraining a monolingual model on its output gives an improvement of 2.0%.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7887082993984222}, {"text": "F1", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9996466636657715}]}], "introductionContent": [{"text": "Natural language analysis in one language can be improved by exploiting translations in another language.", "labels": [], "entities": [{"text": "Natural language analysis", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6764204303423563}]}, {"text": "This observation has formed the basis for important work on syntax projection across languages () and unsupervised syntax induction in multiple languages (, as well as other tasks, such as cross-lingual named entity recognition ( and information retrieval).", "labels": [], "entities": [{"text": "syntax projection", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7419158816337585}, {"text": "unsupervised syntax induction", "start_pos": 102, "end_pos": 131, "type": "TASK", "confidence": 0.7102733055750529}, {"text": "cross-lingual named entity recognition", "start_pos": 189, "end_pos": 227, "type": "TASK", "confidence": 0.6501310765743256}, {"text": "information retrieval", "start_pos": 234, "end_pos": 255, "type": "TASK", "confidence": 0.795153021812439}]}, {"text": "In all of these cases, multilingual models yield increased accuracy because different languages present different ambiguities and therefore offer complementary constraints on the shared underlying labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9978755712509155}]}, {"text": "In the present work, we consider a setting where we already possess supervised monolingual models, and wish to improve these models using unannotated bilingual parallel text (bitext).", "labels": [], "entities": []}, {"text": "We cast this problem in the multiple-view (multiview) learning framework (.", "labels": [], "entities": []}, {"text": "Our two views area monolingual view, which uses the supervised monolingual models but not bilingual information, and a bilingual view, which exploits features that measure agreement across languages.", "labels": [], "entities": []}, {"text": "The parameters of the bilingual view are trained to reproduce the output of the monolingual view.", "labels": [], "entities": []}, {"text": "We show that by introducing weakened monolingual models into the bilingual view, we can optimize the parameters of the bilingual model to improve monolingual models.", "labels": [], "entities": []}, {"text": "At prediction time, we automatically account for the between-view dependence introduced by the weakened monolingual models with a simple but effective view-combination heuristic.", "labels": [], "entities": []}, {"text": "We demonstrate the performance of this method on two problems.", "labels": [], "entities": []}, {"text": "The first is named entity recognition (NER).", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.7646697560946146}]}, {"text": "For this problem, our method automatically learns (a variation on) earlier hand-designed rule-based bilingual NER predictors (, resulting in absolute performance gains of up to 16.1% F 1 . The second task we consider is statistical parsing.", "labels": [], "entities": [{"text": "NER predictors", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.7807427048683167}, {"text": "statistical parsing", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.730423778295517}]}, {"text": "For this task, we follow the setup of, who improved Chinese and English monolingual parsers using parallel, hand-parsed text.", "labels": [], "entities": []}, {"text": "We achieve nearly identical improvements using a purely unlabeled bitext.", "labels": [], "entities": []}, {"text": "These results carryover to machine translation, where we can achieve slightly better BLEU improvements than the supervised model of Burkett and Klein (2008) since we are able to train our model directly on the parallel data where we perform rule extraction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.807164877653122}, {"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9993128776550293}, {"text": "rule extraction", "start_pos": 241, "end_pos": 256, "type": "TASK", "confidence": 0.7572519183158875}]}, {"text": "Finally, for both of our tasks, we use our bilingual model to generate additional automatically labeled monolingual training data.", "labels": [], "entities": []}, {"text": "We compare this approach to monolingual self-training and show an improvement of up to 14.4% F 1 for entity recognition.", "labels": [], "entities": [{"text": "F 1", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9964386522769928}, {"text": "entity recognition", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.8442304730415344}]}, {"text": "Even for parsing, where the bilingual portion of the treebank is much smaller than the monolingual, our technique still can improve over purely monolingual self-training by 0.7% F 1 .", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9901358485221863}]}], "datasetContent": [{"text": "We demonstrate the utility of multiview learning for named entity recognition (NER) on English/German sentence pairs.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.811313807964325}]}, {"text": "We built both our full and weakened monolingual English and German models from the CoNLL 2003 shared task training data.", "labels": [], "entities": [{"text": "CoNLL 2003 shared task training data", "start_pos": 83, "end_pos": 119, "type": "DATASET", "confidence": 0.9353085358937582}]}, {"text": "The bilingual model parameters were trained on 5,000 parallel sentences extracted from the Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 91, "end_pos": 106, "type": "DATASET", "confidence": 0.9917157888412476}]}, {"text": "For the retraining experiments, we added an additional 5,000 sentences, for 10,000 in all.", "labels": [], "entities": [{"text": "retraining", "start_pos": 8, "end_pos": 18, "type": "TASK", "confidence": 0.9719735383987427}]}, {"text": "For testing, we used the Europarl 2006 development set and the 2007 newswire test set.", "labels": [], "entities": [{"text": "Europarl 2006 development set", "start_pos": 25, "end_pos": 54, "type": "DATASET", "confidence": 0.986358255147934}, {"text": "newswire test set", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.935052494208018}]}, {"text": "Neither of these data sets were annotated with named entities, so we manually annotated 200 sentences from each of them.", "labels": [], "entities": []}, {"text": "We used the Stanford NER tagger () with its default configuration as our full monolingual model for each language.", "labels": [], "entities": [{"text": "Stanford NER tagger", "start_pos": 12, "end_pos": 31, "type": "DATASET", "confidence": 0.8350683450698853}]}, {"text": "We weakened both the English and German models by removing several non-lexical and word-shape features.", "labels": [], "entities": []}, {"text": "We made one more crucial change to our monolingual German model.", "labels": [], "entities": []}, {"text": "The German entity recognizer has extremely low recall (44 %) when out of domain, so we chos\u00ea y x from to be the label in the top five which had the largest number of named entities.", "labels": [], "entities": [{"text": "German entity recognizer", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6079092820485433}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9992445707321167}]}, {"text": "gives results for named entity recognition.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.6535914142926534}]}, {"text": "The first two rows are the full and weakened monolingual models alone.", "labels": [], "entities": []}, {"text": "The second two are the multiview trained bilingual models.", "labels": [], "entities": []}, {"text": "We first note that for English, using the full bilingual model yields only slight improvements over the baseline full monolingual model, and in practice the predictions were almost identical.", "labels": [], "entities": []}, {"text": "For this problem, the monolingual German model is much worse than the monolingual English model, and so the bilingual model doesn't offer significant improvements in English.", "labels": [], "entities": []}, {"text": "The bilingual model does show significant German improvements, however, including a 16.1% absolute gain in F 1 over the baseline for parliamentary proceedings.", "labels": [], "entities": [{"text": "F 1", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9881888329982758}]}, {"text": "The last two rows of give results for monolingual models which are trained on data that was automatically labeled using the our models.", "labels": [], "entities": []}, {"text": "English results were again mixed, due to the relatively weak English performance of the bilingual model.", "labels": [], "entities": []}, {"text": "For German, though, the \"BilingualRetrained\" model improves 14.4% F 1 over the \"Self-Retrained\" baseline.", "labels": [], "entities": [{"text": "F 1", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9932788908481598}]}, {"text": "Our next set of experiments are on syntactic parsing of English and Chinese.", "labels": [], "entities": [{"text": "syntactic parsing of English and Chinese", "start_pos": 35, "end_pos": 75, "type": "TASK", "confidence": 0.8723752895991007}]}, {"text": "We trained both our full and weakened monolingual English models on the Penn Wall Street Journal corpus, as described in Section 4.", "labels": [], "entities": [{"text": "Penn Wall Street Journal corpus", "start_pos": 72, "end_pos": 103, "type": "DATASET", "confidence": 0.9726726770401001}]}, {"text": "Our full and weakened Chinese models were trained on    , which also includes manually parsed English translations of each Chinese sentence (.", "labels": [], "entities": []}, {"text": "Only the Chinese sentences and their English translations were used to train the bilingual models -the gold trees were ignored.", "labels": [], "entities": []}, {"text": "For retraining, we used the same data, but weighted it to match the sizes of the original monolingual treebanks.", "labels": [], "entities": []}, {"text": "We tested on the standard Chinese treebank development set, which also includes English translations.", "labels": [], "entities": [{"text": "Chinese treebank development set", "start_pos": 26, "end_pos": 58, "type": "DATASET", "confidence": 0.9010554105043411}]}, {"text": "gives results for syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.879883885383606}]}, {"text": "For comparison, we also show results for the supervised bilingual model of.", "labels": [], "entities": []}, {"text": "This model uses the same features at prediction time as the multiview trained \"Bilingual w/ Full\" model, but it is trained on hand-annotated parses.", "labels": [], "entities": []}, {"text": "We first examine the first four rows of  only slightly worse than the supervised model.", "labels": [], "entities": []}, {"text": "The last two rows of are the results of monolingual parsers trained on automatically labeled data.", "labels": [], "entities": []}, {"text": "In general, gains in English, which is out of domain relative to the Penn Treebank, are larger than those in Chinese, which is in domain.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.9953493475914001}]}, {"text": "We also emphasize that, unlike our NER data, this bitext was fairly small relative to the annotated monolingual data.", "labels": [], "entities": [{"text": "NER data", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.8077066540718079}, {"text": "bitext", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9163249135017395}]}, {"text": "Therefore, while we still learn good bilingual model parameters which give a sizable agreement-based boost when doing bilingual prediction, we don't expect retraining to result in a coverage-based boost in monolingual performance.", "labels": [], "entities": [{"text": "bilingual prediction", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.7408875823020935}]}, {"text": "Although we don't have hand-labeled data for our largest Chinese-English parallel corpora, we can still evaluate our parsing results via our performance on a downstream machine translation (MT) task.", "labels": [], "entities": [{"text": "machine translation (MT) task", "start_pos": 169, "end_pos": 198, "type": "TASK", "confidence": 0.8452506164709727}]}, {"text": "Our experimental setup is as follows: first, we used the first 100,000 sentences of the EnglishChinese bitext from to train Moses (), a phrase-based MT system that we use as a baseline.", "labels": [], "entities": [{"text": "MT", "start_pos": 149, "end_pos": 151, "type": "TASK", "confidence": 0.8724106550216675}]}, {"text": "We then used the same sentences to extract tree-to-string transducer rules from target-side (English) trees ().", "labels": [], "entities": []}, {"text": "We compare the single-reference BLEU scores of syntactic MT systems that result from using different parsers to generate these trees.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9929197430610657}, {"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.826251208782196}]}, {"text": "For our syntactic baseline, we used the monolingual English parser.", "labels": [], "entities": []}, {"text": "For our remaining experiments, we parsed both English and Chinese simultaneously.", "labels": [], "entities": []}, {"text": "The supervised model and the first multiview trained model are the same Chinese treebank trained models for which we reported parsing results.", "labels": [], "entities": []}, {"text": "We also used our multiview method to train an additional bilingual model on part of the bitext we used to extract translation rules.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Once again, our multiview trained model yields comparable results to the supervised model.", "labels": [], "entities": []}, {"text": "Furthermore, while the differences are small, our best performance comes from the model trained on in-domain data, for which no gold trees exist.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: NER Results. Rows are grouped by data condition. We bold all entries that are best in their  group and beat the strongest monolingual baseline.", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8128859996795654}]}, {"text": " Table 4: Parsing results. Rows are grouped by data  condition. We bold entries that are best in their  group and beat the the Full Monolingual baseline.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9407035112380981}, {"text": "Full Monolingual baseline", "start_pos": 127, "end_pos": 152, "type": "DATASET", "confidence": 0.7146925330162048}]}, {"text": " Table 4. The  \"Bilingual w/ Full\" model significantly improves  performance in both English and Chinese relative  to the monolingual baseline. Indeed, it performs", "labels": [], "entities": []}, {"text": " Table 5: Machine translation results.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8295814394950867}]}]}