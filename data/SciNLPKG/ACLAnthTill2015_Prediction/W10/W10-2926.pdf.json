{"title": [{"text": "On Reverse Feature Engineering of Syntactic Tree Kernels", "labels": [], "entities": [{"text": "Reverse Feature Engineering of Syntactic Tree Kernels", "start_pos": 3, "end_pos": 56, "type": "TASK", "confidence": 0.8488650747707912}]}], "abstractContent": [{"text": "In this paper, we provide a theoretical framework for feature selection in tree kernel spaces based on gradient-vector components of kernel-based machines.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.738586813211441}]}, {"text": "We show that a huge number of features can be discarded without a significant decrease inaccuracy.", "labels": [], "entities": []}, {"text": "Our selection algorithm is as accurate as and much more efficient than those proposed in previous work.", "labels": [], "entities": []}, {"text": "Comparative experiments on three interesting and very diverse classification tasks, i.e.", "labels": [], "entities": []}], "introductionContent": [{"text": "Kernel functions are very effective at modeling diverse linguistic phenomena by implicitly representing data in high dimensional spaces, e.g. (. However, the implicit nature of the kernel space causes two major drawbacks: (1) high computational costs for learning and classification, and (2) the impossibility to identify the most important features.", "labels": [], "entities": []}, {"text": "A solution to both problems is the application of feature selection techniques.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7666729688644409}]}, {"text": "In particular, the problem of feature selection in Tree Kernel (TK) spaces has already been addressed by previous work in NLP, e.g. ().", "labels": [], "entities": [{"text": "feature selection in Tree Kernel (TK) spaces", "start_pos": 30, "end_pos": 74, "type": "TASK", "confidence": 0.7694246967633566}]}, {"text": "However, these approaches lack a theoretical characterization of the problem that could support and justify the design of more effective algorithms.", "labels": [], "entities": []}, {"text": "In and) (P&M), we presented a heuristic framework for feature selection in kernel spaces that selects features based on the components of the weight vector, w, optimized by Support Vector Machines (SVMs).", "labels": [], "entities": []}, {"text": "This method appears to be very effective, as the model accuracy does not significantly decrease even when a large number of features are filtered out.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9979342222213745}]}, {"text": "Unfortunately, we could not provide theoretical or intuitive motivations to justify our proposed apporach.", "labels": [], "entities": []}, {"text": "In this paper, we present and empirically validate a theory which aims at filling the abovementioned gaps.", "labels": [], "entities": []}, {"text": "In particular we provide: (i) a proof of the equation for the exact computation of feature weights induced by TK functions); (ii) a theoretical characterization of feature selection based on w.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 164, "end_pos": 181, "type": "TASK", "confidence": 0.6952718496322632}]}, {"text": "We show that if feature selection does not sensibly reduces w, the margin associated with w does not sensibly decrease as well.", "labels": [], "entities": []}, {"text": "Consequently, the theoretical upperbound to the probability error does not sensibly increases; (iii) a proof that the convolutive nature of TK allows for filtering out an exponential number of features with a small w decrease.", "labels": [], "entities": []}, {"text": "The combination of (ii) with (iii) suggests that an extremely aggressive feature selection can be applied.", "labels": [], "entities": []}, {"text": "We describe a greedy algorithm that exploits these results.", "labels": [], "entities": []}, {"text": "Compared to the one proposed in P&M, the new version of the algorithm has only one parameter (instead of 3), it is more efficient and can be more easily connected with the amount of gradient norm that is lost after feature selection.", "labels": [], "entities": [{"text": "P&M", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.46953798333803815}]}, {"text": "In the remainder: Section 2 briefly reviews SVMs and TK functions; Section 3 describes the problem of selecting and projecting features from very high onto lower dimensional spaces, and provides the theoretical foundation to our approach; Section 4 presents a selection of related work; Section 5 describes our approach to tree fragment selection; Section 6 details the outcome of our experiments; finally, in Section 7 we draw our conclusions.", "labels": [], "entities": [{"text": "tree fragment selection", "start_pos": 323, "end_pos": 346, "type": "TASK", "confidence": 0.6181561152140299}]}], "datasetContent": [{"text": "We ran a set of thorough experiments to support our claims with empirical evidence.", "labels": [], "entities": []}, {"text": "We show our results on three very different benchmarks: Question Classification (QC) using TREC 10 data, Relation Extraction (RE) based on the newswire and broadcast news domain of the ACE 2004 English corpus) and Semantic Role Labeling (SRL) on the CoNLL 2005 shared task data).", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.6809127777814865}, {"text": "TREC 10 data", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.6578360696633657}, {"text": "Relation Extraction (RE)", "start_pos": 105, "end_pos": 129, "type": "METRIC", "confidence": 0.8169988870620728}, {"text": "ACE 2004 English corpus", "start_pos": 185, "end_pos": 208, "type": "DATASET", "confidence": 0.8713104128837585}, {"text": "Semantic Role Labeling (SRL", "start_pos": 214, "end_pos": 241, "type": "TASK", "confidence": 0.710555124282837}, {"text": "CoNLL 2005 shared task data", "start_pos": 250, "end_pos": 277, "type": "DATASET", "confidence": 0.9594975113868713}]}, {"text": "In the next sections we elaborate on the setup and outcome of each set of experiments.", "labels": [], "entities": []}, {"text": "As a supervised learning framework we used SVM-Light-TK 5 , which extends the SVM-Light optimizer) with support for tree kernel functions.", "labels": [], "entities": []}, {"text": "Unless differently stated, all the classifiers are parametrized for optimal Precision and Recall on a development set, obtained by selecting one example in ten from the training set with the same positive-to-negative example ratio.", "labels": [], "entities": [{"text": "Precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9839168190956116}, {"text": "Recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9666250348091125}]}, {"text": "The results that we show are obtained on the test sets by using all the available data for training.", "labels": [], "entities": []}, {"text": "For multi-class scenarios, the classifiers are arranged in a one vs. all configuration, where each sentence is a positive example for one of the classes, and negative for the others.", "labels": [], "entities": []}, {"text": "While binary classifiers are evaluated in terms of F 1 measure, for multi-class classifiers we show the final accuracy.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.9576042095820109}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9867228865623474}]}, {"text": "The next paragraphs describe the datasets used for the experiments.", "labels": [], "entities": []}, {"text": "Question Classification (QC) Given a question, the task consists in selecting the most appropriate expected answer type from a given set of possibilities.", "labels": [], "entities": [{"text": "Question Classification (QC)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8041361331939697}]}, {"text": "We adopted the question taxonomy known as coarse grained, which has been described in and (), consisting of six non overlapping classes: Abbreviations (ABBR), Descriptions (DESC, e.g. definitions or explanations), Entity (ENTY, e.g. animal, body or color), Human (HUM, e.g. group or individual), Location (LOC, e.g. cities or countries) and Numeric (NUM, e.g. amounts or dates).", "labels": [], "entities": [{"text": "Abbreviations (ABBR)", "start_pos": 137, "end_pos": 157, "type": "METRIC", "confidence": 0.8813432902097702}]}, {"text": "The TREC 10 QA data set accounts for 6,000 questions.", "labels": [], "entities": [{"text": "TREC 10 QA data set", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.8414183378219604}]}, {"text": "For each question, we generate the full parse of the sentence and use it to train our models.", "labels": [], "entities": []}, {"text": "Automatic parses are obtained with the Stanford parser 6 (, and we actually have only 5,953 sentences in our data set due to parsing issues.", "labels": [], "entities": [{"text": "Stanford parser 6", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.8840964833895365}]}, {"text": "During preliminary experiments, we observed an uneven distribution of examples in the traditional training/test split (the same used in P&M).", "labels": [], "entities": [{"text": "P&M", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.7807613213857015}]}, {"text": "Therefore, we used a random selection to generate an unbiased split, with 5,468 sentences for training and 485 for testing.", "labels": [], "entities": []}, {"text": "The resulting data set is available for download at http://danielepighin.net/cms/research/ QC_dataset.tgz.", "labels": [], "entities": [{"text": "QC_dataset.tgz", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.8085200587908427}]}], "tableCaptions": [{"text": " Table 1: Per-class comparison between STK and  the LIN/Grad and OPT/Grad models on the QC  task. Each class is identified by its initial (e.g.  A=ABBR). For each class, we considered a value  of the threshold factor parameter L so as to retain  at least 60% of the gradient norm after feature se- lection.", "labels": [], "entities": [{"text": "ABBR", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.8763136863708496}]}, {"text": " Table 2: Multiclass classification accuracy on  three benchmarks.", "labels": [], "entities": [{"text": "Multiclass classification", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8103652894496918}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9890921115875244}]}]}