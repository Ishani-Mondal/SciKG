{"title": [{"text": "Towards the Automatic Creation of a Wordnet from a Term-based Lexical Network", "labels": [], "entities": []}], "abstractContent": [{"text": "The work described here aims to create a wordnet automatically from a semantic network based on terms.", "labels": [], "entities": []}, {"text": "So, a clustering procedure is ran over a synonymy network , in order to obtain synsets.", "labels": [], "entities": []}, {"text": "Then, the term arguments of each relational triple are assigned to the latter, originating a wordnet.", "labels": [], "entities": []}, {"text": "Experiments towards our goal are reported and their results validated.", "labels": [], "entities": []}], "introductionContent": [{"text": "In order perform tasks where understanding the information conveyed by natural language is critical, today's applications demand better access to semantic knowledge.", "labels": [], "entities": []}, {"text": "Knowledge about words and their meanings is typically structured in lexical ontologies, such as Princeton WordNet), but this kind of resources is most of the times handcrafted, which implies much timeconsuming human effort.", "labels": [], "entities": [{"text": "Princeton WordNet", "start_pos": 96, "end_pos": 113, "type": "DATASET", "confidence": 0.8988664150238037}]}, {"text": "So, the automatic construction of such resources arises as an alternative, providing less intensive labour, easier maintenance and allowing for higher coverage, as a tradeoff for lower, but still acceptable, precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 208, "end_pos": 217, "type": "METRIC", "confidence": 0.997442364692688}]}, {"text": "This paper is written in the scope of a project where several textual resources are being exploited for the construction of a lexical ontology for Portuguese.", "labels": [], "entities": []}, {"text": "We have already made a first approach on the extraction of relational triples from text, where, likewise Hearst (1992), we take advantage of textual patterns indicating semantic relations.", "labels": [], "entities": [{"text": "extraction of relational triples from text", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.8394517799218496}]}, {"text": "However, the extracted triples are held between two terms, which is not enough to build a lexical ontology capable of dealing with ambiguity.", "labels": [], "entities": []}, {"text": "Therefore, we present our current approach towards the automatic integration of lexico-semantic knowledge into a single independent lexical ontology, which will be structured on concepts and * supported by FCT scholarship SFRH/BD/ adopt a model close to WordNet's.", "labels": [], "entities": [{"text": "FCT scholarship SFRH/BD", "start_pos": 206, "end_pos": 229, "type": "DATASET", "confidence": 0.8667162775993347}]}, {"text": "The task of establishing synsets and mapping term-based triples to them is closely related to word sense disambiguation, where the only available context consists of the connections in the term-base network.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.6791093051433563}]}, {"text": "After contextualising this work, our approach is described.", "labels": [], "entities": []}, {"text": "It involves (i) a clustering procedure for obtaining a thesaurus from a synonymy network, (ii) the augmentation of the later with manually created thesaurus, and (iii) mapping term-based relational triples to the thesaurus, to obtain a wordnet.", "labels": [], "entities": []}, {"text": "Then, our experimentation results, as well as their validation, are presented.", "labels": [], "entities": []}, {"text": "Briefly, we have tested the proposed approach on a term-based lexical network, extracted automatically from a dictionary.", "labels": [], "entities": []}, {"text": "Synsets were validated manually while the attached triples were validated with the help of a web search engine.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we report experimental results obtained after applying our procedure to part of the lexical network of PAPEL ).", "labels": [], "entities": [{"text": "PAPEL", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.8485412001609802}]}, {"text": "The clustering procedure was first ran over PAPEL's noun synonymy network in order to obtain the synsets which were later merged with two manually created thesaurus.", "labels": [], "entities": [{"text": "PAPEL's noun synonymy network", "start_pos": 44, "end_pos": 73, "type": "DATASET", "confidence": 0.8138162732124329}]}, {"text": "Finally, hypernymof, member-of and part-of triples of PAPEL were mapped to the thesaurus by assigning a synset to each term argument.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: (Noun) thesaurus in numbers.", "labels": [], "entities": []}, {"text": " Table 2: Results of triples mapping", "labels": [], "entities": []}, {"text": " Table 3: Results of manual synset validation.", "labels": [], "entities": [{"text": "synset validation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7265125513076782}]}]}