{"title": [{"text": "Discriminative Parse Reranking for Chinese with Homogeneous and Heterogeneous Annotations", "labels": [], "entities": [{"text": "Discriminative Parse Reranking", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5909837881724039}]}], "abstractContent": [{"text": "Discriminative parse reranking has been shown to bean effective technique to improve the generative parsing models.", "labels": [], "entities": [{"text": "Discriminative parse reranking", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8132329185803732}, {"text": "generative parsing", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.9782274067401886}]}, {"text": "In this paper, we present a series of experiments on parsing the Tsinghua Chinese Treebank with hierarchically split-merge grammars and reranked with a perceptron-based discriminative model.", "labels": [], "entities": [{"text": "Tsinghua Chinese Treebank", "start_pos": 65, "end_pos": 90, "type": "DATASET", "confidence": 0.6458296477794647}]}, {"text": "In addition to the homogeneous annotation on TCT, we also incorporate the PCTB-based parsing result as heterogeneous annotation into the reranking feature model.", "labels": [], "entities": [{"text": "PCTB-based parsing", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.6925643086433411}]}, {"text": "The rerank-ing model achieved 1.12% absolute improvement on F1 over the Berkeley parser on a development set.", "labels": [], "entities": [{"text": "absolute", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9713863730430603}, {"text": "F1", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.995506763458252}]}, {"text": "The head labels in Task 2.1 are annotated with a sequence labeling model.", "labels": [], "entities": []}, {"text": "The system achieved 80.32 (B+C+H F1) in CIPS-SIGHAN-2010 Task 2.1 (Open Track) and 76.11 (Overall F1) in Task 2.2 (Open Track) 1 .", "labels": [], "entities": [{"text": "B+C+H F1)", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.8991523385047913}, {"text": "CIPS-SIGHAN-2010 Task 2.1", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.7695514957110087}, {"text": "Overall F1)", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.6775335868199667}]}], "introductionContent": [{"text": "The data-driven approach to syntactic analysis of natural language has undergone revolutionary development in the last 15 years, ever since the first few large scale syntactically annotated corpora, i.e. treebanks, became publicly available in the mid-90s of the last century.", "labels": [], "entities": [{"text": "syntactic analysis of natural language", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.9025515913963318}]}, {"text": "One and a half decades later, treebanks remain to bean expensive type of language resources and only available fora small number of languages.", "labels": [], "entities": []}, {"text": "The main issue that hinders large treebank development projects is the difficulties in creating a complete and consistent annotation guideline which then constitutes the very basis for sustainable parallel annotation and quality assurance.", "labels": [], "entities": []}, {"text": "While traditional linguistic studies typically focus on either isolated language phenomena or limited interaction among a small groups of phenomena, the annotation scheme in treebanking project requires full coverage of language use in the source media, and proper treatment with an uniformed annotation format.", "labels": [], "entities": []}, {"text": "Such high demand from the practical application of linguistic theory has given rise to a countless number of attempts and variations in the formalization frameworks.", "labels": [], "entities": []}, {"text": "While the harsh natural selection set the bar high and many attempts failed to even reach the actual annotation phase, a handful highly competent grammar frameworks have given birth to several large scale treebanks.", "labels": [], "entities": []}, {"text": "The co-existence of multiple treebanks with heterogeneous annotation presents anew challenge to the consumers of such resources.", "labels": [], "entities": []}, {"text": "The immediately relevant task is the automated syntactic analysis, or parsing.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7450469434261322}]}, {"text": "While many state-of-the-art statistical parsing systems are not bound to specific treebank annotation (assuming the formalism is predetermined independently), almost all of them assume homogeneous annotation in the training corpus.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.6783163845539093}]}, {"text": "Therefore, such treebanks cannot be simply put together when training the parser.", "labels": [], "entities": []}, {"text": "One approach would be to convert them into an uniformed representation, although such conversion is usually difficult and by its nature errorprune.", "labels": [], "entities": []}, {"text": "The differences in annotations constitute different generative stories: i.e., when the parsing models are viewed as mechanisms to produce structured sentences, each treebank model will associate its own structure with the surface string independently.", "labels": [], "entities": []}, {"text": "On the other hand, if the discriminative view is adopted, it is possible to use annotations in different treebanks as indication of goodness of the tree in the original annotation.", "labels": [], "entities": []}, {"text": "In this paper, we present a series of experiments to improve the Chinese parsing accuracy on the Tsinghua Chinese Treebank.", "labels": [], "entities": [{"text": "Chinese parsing", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.5175280869007111}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9559358954429626}, {"text": "Tsinghua Chinese Treebank", "start_pos": 97, "end_pos": 122, "type": "DATASET", "confidence": 0.7691676815350851}]}, {"text": "First, we use coarse-to-fine parsing with hierarchically splitmerge generative grammars to obtain a list of candidate trees in TCT annotation.", "labels": [], "entities": [{"text": "TCT annotation", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.8126621544361115}]}, {"text": "A discriminative parse selection model is then used to rerank the list of candidates.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.8345826864242554}]}, {"text": "The reranking model is trained with both homogeneous (TCT) and heterogeneous (PCTB) data.", "labels": [], "entities": []}, {"text": "A sequence labeling system is used to annotate the heads in Task 2-1.", "labels": [], "entities": []}, {"text": "The remaining part of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews the relevant previous study on generative split-merge parsing and discriminative reranking models.", "labels": [], "entities": [{"text": "generative split-merge parsing", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.9013940095901489}]}, {"text": "Section 3 describes the workflow of our system participated in the CIPS-SIGHAN-2010 bake-off Task 2.", "labels": [], "entities": [{"text": "CIPS-SIGHAN-2010 bake-off Task 2", "start_pos": 67, "end_pos": 99, "type": "DATASET", "confidence": 0.8660923987627029}]}, {"text": "Section 4 describes the detailed settings for the evaluation and the empirical results.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset used in the CIPS-ParsEval-2010 evaluation is converted from the Tsinghua Chinese Treebank (TCT).", "labels": [], "entities": [{"text": "CIPS-ParsEval-2010 evaluation", "start_pos": 24, "end_pos": 53, "type": "DATASET", "confidence": 0.9112303853034973}, {"text": "Chinese Treebank (TCT)", "start_pos": 85, "end_pos": 107, "type": "DATASET", "confidence": 0.8400137603282929}]}, {"text": "There are two subtasks: (1) event description sub-sentence analysis and complete sentence parsing.", "labels": [], "entities": [{"text": "event description sub-sentence analysis", "start_pos": 28, "end_pos": 67, "type": "TASK", "confidence": 0.8075079917907715}, {"text": "complete sentence parsing", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.6380242307980856}]}, {"text": "On the assumption that the boundaries and relations between these event description units are determined separately, the first task aims to identify the local fine-grained syntactic structures.", "labels": [], "entities": []}, {"text": "The goal of the second task is to evaluate the performance of the automatic parsers on complete sentences in real texts.", "labels": [], "entities": []}, {"text": "The training dataset is a mixture of several genres, including newspaper texts, encyclopedic texts and novel texts.", "labels": [], "entities": []}, {"text": "The annotation in the dataset is different to the other frequently used Chinese treebank (i.e. PCTB) Whereas TCT annotation strongly reflects early descriptive linguistics, PCTB draws primarily on Government-Binding (GB) theory from 1980s.", "labels": [], "entities": []}, {"text": "PCTB annotation differs from TCT annotation from many perspectives: \u2022 TCT and PCTB have different segmentation standards.", "labels": [], "entities": [{"text": "PCTB", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9105047583580017}]}, {"text": "\u2022 TCT is somehow branching-rich annotation, while PCTB annotation is categoryrich.", "labels": [], "entities": []}, {"text": "Specifically the topological tree structures is more detailed in TCT, and there are not many flat structures.", "labels": [], "entities": [{"text": "TCT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.783168613910675}]}, {"text": "However constituents are detailed classified, namely the number of phrasal categories is small.", "labels": [], "entities": []}, {"text": "On the contrary, though flat structures are very common in PCTB, the categorization of phrases is fine-grained.", "labels": [], "entities": []}, {"text": "In addition, PCTB contains functional information.", "labels": [], "entities": [{"text": "PCTB", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7563037276268005}]}, {"text": "Function tags appended to constituent labels are used to indicate additional syntactic or semantic information.", "labels": [], "entities": []}, {"text": "\u2022 TCT contains head indices, making head identification of each constituent an important goal of task 1.", "labels": [], "entities": [{"text": "head identification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.6998939365148544}]}, {"text": "\u2022 Following the GB theory, PCTB assume there are movements, so there are empty category annotation.", "labels": [], "entities": [{"text": "PCTB", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.7906274795532227}]}, {"text": "Because of different theoretical foundations, there are different explanations fora series of linguistic phenomena such as the usage of function word \"\u7684\".", "labels": [], "entities": []}, {"text": "In the reranking experiments, we also use a parser trained on PCTB to provide more syntactic clues.", "labels": [], "entities": [{"text": "PCTB", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.9303447604179382}]}], "tableCaptions": [{"text": " Table 1: Upper bound of f-score as a function of number n of n-best parses.", "labels": [], "entities": []}, {"text": " Table 1. From the 1-best result we see  that the base accuracy of the parser is 79.97. 2- best and 10-best show promising oracle-rate im- provements. After that things start to slow down,  and we achieve an oracle rate of 86.60 at 50-best.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9294878244400024}]}, {"text": " Table 2: Reranking performance with different  number of parse candidates on the sentences that  contain no more than 40 words in the development  data.", "labels": [], "entities": [{"text": "Reranking", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.5637726783752441}]}, {"text": " Table 3: Reranking performance with different  number of parse candidates on the sentences that  contain no more than 40 words in the development  data.", "labels": [], "entities": []}, {"text": " Table 4: Final results of task 1.", "labels": [], "entities": []}, {"text": " Table 5: Final results of task 2.", "labels": [], "entities": []}]}