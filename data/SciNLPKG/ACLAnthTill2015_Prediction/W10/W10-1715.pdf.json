{"title": [{"text": "More Linguistic Annotation for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.8660606741905212}]}], "abstractContent": [{"text": "We report on efforts to build large-scale translation systems for eight European language pairs.", "labels": [], "entities": []}, {"text": "We achieve most gains from the use of larger training corpora and basic modeling, but also show promising results from integrating more linguistic annotation .", "labels": [], "entities": []}], "introductionContent": [{"text": "We participated in the shared translation task of the ACL Workshop for Statistical Machine Translation 2010 in all language pairs.", "labels": [], "entities": [{"text": "shared translation task of the ACL Workshop for Statistical Machine Translation 2010", "start_pos": 23, "end_pos": 107, "type": "TASK", "confidence": 0.6308683529496193}]}, {"text": "We continued our efforts to integrate linguistic annotation into the translation process, using factored and treebased translation models.", "labels": [], "entities": []}, {"text": "On average we outperformed our submission from last year by 2.16 BLEU points on the same newstest2009 test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9993940591812134}, {"text": "newstest2009 test set", "start_pos": 89, "end_pos": 110, "type": "DATASET", "confidence": 0.9671176870663961}]}, {"text": "While the submitted system follows the factored phrase-based approach, we also built hierarchical and syntax-based models for the English-German language pair and report on its performance on the development test sets.", "labels": [], "entities": []}, {"text": "All our systems are based on the Moses toolkit ( . We achieved gains over the systems from last year by consistently exploiting all available training data, using large-scale domain-interpolated, and consistent use of the factored translation model to integrate n-gram models over speech tags.", "labels": [], "entities": []}, {"text": "We also experimented with novel domain adaptation methods, with mixed results.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7815138101577759}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overview of results: baseline system and extensions. On average we outperformed our sub- mission from last year by 1.87 BLEU points on the same newstest2009 test set. For additional gains for  French-English and German-English, please see Tables 7 and 8.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9986544847488403}, {"text": "newstest2009 test set", "start_pos": 154, "end_pos": 175, "type": "DATASET", "confidence": 0.9392969210942587}]}, {"text": " Table 2: English LM interpolation: number of to- kens, perplexity, and interpolation weight for the  different corpora", "labels": [], "entities": []}, {"text": " Table 3: Effect of truecasing: cased and uncased  BLEU scores", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9951490759849548}]}, {"text": " Table 4: Good Turing smoothing, as in the  French-English model: counts, counts of counts,  discounting factor and discounted count", "labels": [], "entities": [{"text": "Turing smoothing", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7543731927871704}]}, {"text": " Table 6: English-German: use of morphological  and part-of-speech n-gram models", "labels": [], "entities": []}, {"text": " Table 7: Use of large French-English corpus", "labels": [], "entities": []}, {"text": " Table 8: Special handling of German-English", "labels": [], "entities": []}, {"text": " Table 9: Interpolating the translation model with  language model weights", "labels": [], "entities": []}, {"text": " Table 10: Tree-based models for English-German", "labels": [], "entities": []}]}