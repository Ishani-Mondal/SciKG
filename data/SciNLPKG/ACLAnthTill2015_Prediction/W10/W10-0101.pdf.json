{"title": [{"text": "Using Variance as a Stopping Criterion for Active Learning of Frame Assignment", "labels": [], "entities": [{"text": "Active Learning of Frame Assignment", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.5663235664367676}]}], "abstractContent": [{"text": "Active learning is a promising method to reduce human's effort for data annotation in different NLP applications.", "labels": [], "entities": [{"text": "data annotation", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.7250794470310211}]}, {"text": "Since it is an iterative task, it should be stopped at some point which is optimum or near-optimum.", "labels": [], "entities": []}, {"text": "In this paper we propose a novel stopping criterion for active learning of frame assignment based on the variability of the classifier's confidence score on the unlabeled data.", "labels": [], "entities": [{"text": "learning of frame assignment", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.5721399411559105}]}, {"text": "The important advantage of this criterion is that we rely only on the unlabeled data to stop the data annotation process; as a result there are no requirements for the gold standard data and testing the clas-sifier's performance in each iteration.", "labels": [], "entities": []}, {"text": "Our experiments show that the proposed method achieves 93.67% of the classifier maximum performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Using supervised machine learning methods is very popular in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.7351674735546112}]}, {"text": "However, these methods are not applicable for most of the NLP tasks due to the lack of labeled data.", "labels": [], "entities": []}, {"text": "Although a huge amount of unlabeled data is freely available, labeling them for supervised learning techniques is very tedious, expensive, time consuming, and error prone.", "labels": [], "entities": []}, {"text": "Active learning is a supervised machine learning method in which informative instances are chosen by the classifier for labeling.", "labels": [], "entities": [{"text": "Active learning", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.771547257900238}]}, {"text": "Unlike the normal supervised set-up where data annotation and learning are completely independent, active learning is a sequential process.", "labels": [], "entities": []}, {"text": "This learning method is used in a variety of NLP tasks such as information extraction), semantic role labeling), machine translation (, and name entity recognition.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.7972446084022522}, {"text": "semantic role labeling", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.6664826273918152}, {"text": "machine translation", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.848433643579483}, {"text": "name entity recognition", "start_pos": 140, "end_pos": 163, "type": "TASK", "confidence": 0.7620238463083903}]}, {"text": "In our study, we apply this method for the frame assignment task as a kind of semantic analysis.", "labels": [], "entities": [{"text": "frame assignment task", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.8088982105255127}, {"text": "semantic analysis", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7850007116794586}]}, {"text": "The process of active learning is as follows: the learner takes a set of labeled instances, called seed data, as an input for initial training of the classifier; and then a larger set of unlabeled instances will be selected by the classifier to be labeled with the human interaction.", "labels": [], "entities": []}, {"text": "Even a small set of well selected samples for labeling can achieve the same level of performance of a large labeled data set; and the oracle's effort will be reduced as a result.", "labels": [], "entities": []}, {"text": "The motivation behind active learning is selecting the most useful examples for the classifier and thereby minimizing the annotation effort while still keeping up the performance level ().", "labels": [], "entities": []}, {"text": "There are two major learning scenarios in active learning which are very popular among researchers and frequently used in various NLP tasks: stream-based sampling and poolbased sampling.", "labels": [], "entities": []}, {"text": "The samples that are selected should be hard and very informative.", "labels": [], "entities": []}, {"text": "There are different query methods for sample selection which are independent of the active learning scenarios).", "labels": [], "entities": []}, {"text": "Among them, uncertainty sampling ( is the most well-known and the simplest sample selection method which only needs one classifier ().", "labels": [], "entities": [{"text": "uncertainty sampling", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.828163355588913}]}, {"text": "In this query method, the samples that the classifier is least con-", "labels": [], "entities": []}], "datasetContent": [{"text": "What we aim to do in our study is assigning frames with active learning.", "labels": [], "entities": []}, {"text": "We have chosen the pool-based scenario by using the uncertainty sampling method.", "labels": [], "entities": []}, {"text": "In our task, since we have a small data set, 5 instances (K=5) with the lowest confidence score of the predited labels will be selected in each iteration from the pool of data and handed out to the oracle to be labeled.", "labels": [], "entities": []}, {"text": "We have used a toolkit for the supervised word sense disambiguation task called Majo ( which has a graphical user interface (GUI) for semantic annotation based on active learning.", "labels": [], "entities": [{"text": "word sense disambiguation task", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.7628423422574997}]}, {"text": "The toolkit supports German and English; and it uses the openNLP MAXENT package 1 to build the model.", "labels": [], "entities": [{"text": "openNLP MAXENT package 1", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.5893481075763702}]}, {"text": "In this toolkit, the confidence score of the classifier is the posterior probability of the most probable label assigned to each sample.", "labels": [], "entities": []}, {"text": "In addition, there are some built-in plugins in the tool for syntactic and semantic pre-processing to provide the relevant features for the classifier.", "labels": [], "entities": []}, {"text": "We utilized the following plugins that support English: 1 http://maxent.sourceforge.net/ \u2022 Stanford Word Range Plugin provides features based on the local context of the surface string for the target.", "labels": [], "entities": [{"text": "Stanford Word Range Plugin", "start_pos": 91, "end_pos": 117, "type": "DATASET", "confidence": 0.9024010896682739}]}, {"text": "The window size of the local context can beset manually in the GUI.", "labels": [], "entities": []}, {"text": "Based on initial experiments for the target verbs, we found out that a window \u00b13 performs the best.", "labels": [], "entities": []}, {"text": "\u2022 Stanford POS Tag Word Range Plugin provides the POS tags of the words within a sentence by using Stanford POS Tagger.", "labels": [], "entities": [{"text": "Stanford POS Tag Word Range Plugin", "start_pos": 2, "end_pos": 36, "type": "DATASET", "confidence": 0.8407033383846283}]}, {"text": "In this plugin, the window size could also beset manually to extract the POS local context of the target word.", "labels": [], "entities": []}, {"text": "Based on initial experiments, a window of \u00b13 achieved the best performance.", "labels": [], "entities": []}, {"text": "\u2022 Berkley Sentence Phrase Plugin utilizes the Berkley Parser and provides the syntactic analysis of the sentence.", "labels": [], "entities": []}, {"text": "This plugin is used to extract all word forms of the children nodes from a particular syntactic mother node (VP in our study) and add them to the feature set.", "labels": [], "entities": []}, {"text": "\u2022 Berkley Sentence Phrase POS Tag Plugin uses the Berkley POS tagger such that we define the mother node of the target word in the parse tree (VP in our study) and it identifies and extracts all children of this mother node and uses their POS as features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data distribution of the targets", "labels": [], "entities": []}, {"text": " Table 2: The comparison of the average performance of  the classifier (F-score) on the stopping point with the  maximum performance in uncertainty sampling", "labels": [], "entities": [{"text": "F-score)", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9730425775051117}]}, {"text": " Table 3: The comparison of the number of the annotated  data for all data, at the maximum performance, and at the  stopping point", "labels": [], "entities": []}, {"text": " Table 4. To ease the comparison,  the performance of our original model is repeated  in this table. As presented in the table, the average  performance in the extended model has a 13.70%  relative improvement compared to the average per- formance in the original variance model.", "labels": [], "entities": []}, {"text": " Table 4: The comparison of the average performance of  the classifier (F-score) on the variance model and the ex- tended variance model  Verb  VM  EM  Bend  53.00 52.00  Follow  70.00 70.00  Forget  41.00 46.00  Hit  63.56 63.56  Rush  89.03 89.03  Scream  62.85 63.56  Strike  53.00 53.00  Average 61.78 62.45", "labels": [], "entities": [{"text": "F-score)", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9645900130271912}, {"text": "Verb  VM  EM  Bend  53.00 52.00", "start_pos": 138, "end_pos": 169, "type": "DATASET", "confidence": 0.6535705129305521}, {"text": "Follow", "start_pos": 171, "end_pos": 177, "type": "METRIC", "confidence": 0.4927351474761963}, {"text": "Forget", "start_pos": 192, "end_pos": 198, "type": "METRIC", "confidence": 0.534950315952301}, {"text": "Strike", "start_pos": 271, "end_pos": 277, "type": "METRIC", "confidence": 0.877031147480011}, {"text": "Average", "start_pos": 292, "end_pos": 299, "type": "METRIC", "confidence": 0.6377046704292297}]}]}