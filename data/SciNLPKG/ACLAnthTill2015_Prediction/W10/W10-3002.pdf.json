{"title": [{"text": "A Cascade Method for Detecting Hedges and their Scope in Natural Language Text", "labels": [], "entities": [{"text": "Detecting Hedges and their Scope", "start_pos": 21, "end_pos": 53, "type": "TASK", "confidence": 0.9401794314384461}]}], "abstractContent": [{"text": "Detecting hedges and their scope in natural language text is very important for information inference.", "labels": [], "entities": [{"text": "Detecting hedges", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8936549425125122}, {"text": "information inference", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.8586000204086304}]}, {"text": "In this paper, we present a system based on a cascade method for the CoNLL-2010 shared task.", "labels": [], "entities": [{"text": "CoNLL-2010 shared task", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.7010853091875712}]}, {"text": "The system composes of two components: one for detecting hedges and another one for detecting their scope.", "labels": [], "entities": [{"text": "detecting their scope", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.8728455503781637}]}, {"text": "For detecting hedges, we build a cascade subsystem.", "labels": [], "entities": []}, {"text": "Firstly, a conditional random field (CRF) model and a large margin-based model are trained respectively.", "labels": [], "entities": []}, {"text": "Then, we train another CRF model using the result of the first phase.", "labels": [], "entities": []}, {"text": "For detecting the scope of hedges, a CRF model is trained according to the result of the first subtask.", "labels": [], "entities": []}, {"text": "The experiments show that our system achieves 86.36% F-measure on biological corpus and 55.05% F-measure on Wikipedia corpus for hedge detection, and 49.95% F-measure on biological corpus for hedge scope detection.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9980952143669128}, {"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9973234534263611}, {"text": "Wikipedia corpus", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9464385211467743}, {"text": "hedge detection", "start_pos": 129, "end_pos": 144, "type": "TASK", "confidence": 0.8048888146877289}, {"text": "F-measure", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9935047626495361}, {"text": "hedge scope detection", "start_pos": 192, "end_pos": 213, "type": "TASK", "confidence": 0.6870934267838796}]}, {"text": "Among them, 86.36% is the best result on biological corpus for hedge detection.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.9032033383846283}]}], "introductionContent": [{"text": "Hedge cues are very common in natural language text.", "labels": [], "entities": []}, {"text": "report that 17.70% of the sentences in the abstract section and 19.94% of sentences in the full paper section contain hedges on BioScope corpus.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 128, "end_pos": 143, "type": "DATASET", "confidence": 0.9438302516937256}]}, {"text": "As suggest that information that falls in the scope of hedges cannot be presented as factual information.", "labels": [], "entities": []}, {"text": "Detecting hedges and their scope in natural language text is very important for information inference.", "labels": [], "entities": [{"text": "Detecting hedges", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8936549425125122}, {"text": "information inference", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.8586000204086304}]}, {"text": "Recently, relative research has received considerable interest in the biomedical NLP community, including detecting hedges and their in-sentence scope in biomedical texts).", "labels": [], "entities": []}, {"text": "The CoNLL-2010 has launched a shared task for exploiting the hedge scope annotated in the BioScope () and publicly available Wikipedia () weasel annotations.", "labels": [], "entities": [{"text": "CoNLL-2010", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.9472037553787231}, {"text": "BioScope", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.8882839679718018}]}, {"text": "The shared task contains two subtasks): 1.", "labels": [], "entities": []}, {"text": "learning to detect hedges in sentences on BioScope and Wikipedia; 2.", "labels": [], "entities": []}, {"text": "learning to detect the in-sentence scope of these hedges on BioScope.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 60, "end_pos": 68, "type": "DATASET", "confidence": 0.8785777688026428}]}, {"text": "In this paper, we present a system based on a cascade method for the CoNLL-2010 shared task.", "labels": [], "entities": [{"text": "CoNLL-2010 shared task", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.7010853091875712}]}, {"text": "The system composes of two components: one for detecting hedges and another one for detecting their scope.", "labels": [], "entities": [{"text": "detecting their scope", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.8728455702463785}]}, {"text": "For detecting hedges, we build a cascade subsystem.", "labels": [], "entities": []}, {"text": "Firstly, conditional random field (CRF) model and a large margin-based model are trained respectively.", "labels": [], "entities": []}, {"text": "Then, we train another CRF model using the result of the first phase.", "labels": [], "entities": []}, {"text": "For detecting the scope of hedges, a CRF model is trained according to the result of the first subtask.", "labels": [], "entities": []}, {"text": "The experiments show that our system achieves 86.36% F-measure on biological corpus and 55.05% F-measure on Wikipedia corpus for hedge detection, and 49.95% F-measure on biological corpus for hedge scope detection.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9980952143669128}, {"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9973233342170715}, {"text": "Wikipedia corpus", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9464385211467743}, {"text": "hedge detection", "start_pos": 129, "end_pos": 144, "type": "TASK", "confidence": 0.8048887550830841}, {"text": "F-measure", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9935047626495361}, {"text": "hedge scope detection", "start_pos": 192, "end_pos": 213, "type": "TASK", "confidence": 0.6870934267838796}]}, {"text": "Among them, 86.36% is the best result on biological corpus for hedge detection.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.9032033383846283}]}], "datasetContent": [{"text": "Two annotated corpus: BioScope and Wikipedia are supplied for the CoNLL-2010 shared task.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.9011842608451843}, {"text": "Wikipedia", "start_pos": 35, "end_pos": 44, "type": "DATASET", "confidence": 0.9369791746139526}]}, {"text": "The BioScope corpus consists of two parts: biological paper abstracts and biological full papers, and it is used for two subtasks.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.7640954554080963}]}, {"text": "The Wikipedia corpus is only used for hedge detection.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9761618673801422}, {"text": "hedge detection", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8997710049152374}]}, {"text": "The detailed information of these two corpora is shown in and  In our experiments, CRF++-0.53 3 implemen-tation is employed to CRF, and svm hmm 3.10 4 implementation is employed to the large margin method.", "labels": [], "entities": [{"text": "CRF", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.6647105813026428}]}, {"text": "All parameters are default except C (the trade-off between training error and margin, C=8000, for selecting C, the training corpus is partitioned into three parts, two of them are used for training and the left one is used as a development dataset) in svm hmm.", "labels": [], "entities": [{"text": "training error", "start_pos": 59, "end_pos": 73, "type": "METRIC", "confidence": 0.847668468952179}, {"text": "margin", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.872242271900177}]}, {"text": "Both of them are state-ofthe-art toolkits for the sequence labeling problem.", "labels": [], "entities": [{"text": "sequence labeling problem", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.8189185460408529}]}], "tableCaptions": [{"text": " Table 2: The detail information of Wikipedia cor- pus. \"AvL.\" stands for average length.", "labels": [], "entities": [{"text": "detail", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9823450446128845}, {"text": "Wikipedia cor- pus", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.793424054980278}, {"text": "AvL.", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9643706679344177}, {"text": "average length", "start_pos": 74, "end_pos": 88, "type": "METRIC", "confidence": 0.8474369049072266}]}, {"text": " Table 3: In-sentence performance of the hedge  detection subsystem for in-domain test. \"Prec.\"  stands for precision, \"LM\" stands for large mar- gin, and \"CAS\" stands for cascaded system.", "labels": [], "entities": [{"text": "hedge  detection", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.739970475435257}, {"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9952369928359985}]}, {"text": " Table 4: Results of the hedge detection for cross- domain test. \"LM\" stands for large margin, and  \"CAS\" stands for cascaded system.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7705783843994141}]}, {"text": " Table 5: Results of the hedge scope tag. \"HD\"  stands for hedge detection subsystem we used,  \"LM\" stands for large margin, and \"CAS\" stands  for cascaded system.", "labels": [], "entities": [{"text": "hedge detection subsystem", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.7639738023281097}]}, {"text": " Table 6: Results of the hedge scope in-sentence.  \"HD\" stands for hedge detection subsystem we  used, \"LM\" stands for large margin, and \"CAS\"  stands for cascaded system.", "labels": [], "entities": [{"text": "hedge detection subsystem", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.7730915347735087}]}]}