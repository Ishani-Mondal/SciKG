{"title": [{"text": "Using collocation segmentation to augment the phrase table", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the 2010 phrase-based statistical machine translation system developed at the TALP Research Center of the UPC 1 in cooperation with BMIC 2 and VMU 3.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 30, "end_pos": 74, "type": "TASK", "confidence": 0.5443262308835983}, {"text": "TALP Research Center", "start_pos": 99, "end_pos": 119, "type": "DATASET", "confidence": 0.8543991049130758}, {"text": "UPC 1", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.8064864277839661}, {"text": "BMIC", "start_pos": 153, "end_pos": 157, "type": "DATASET", "confidence": 0.853823184967041}, {"text": "VMU", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.8351507186889648}]}, {"text": "In phrase-based SMT, the phrase table is the main tool in translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.697828471660614}]}, {"text": "It is created extracting phrases from an aligned parallel corpus and then computing translation model scores with them.", "labels": [], "entities": []}, {"text": "Performing a collocation segmentation over the source and target corpus before the alignment causes that dierent and larger phrases are extracted from the same original documents.", "labels": [], "entities": []}, {"text": "We performed this segmentation and used the union of this phrase set with the phrase set extracted from the non-segmented corpus to compute the phrase table.", "labels": [], "entities": []}, {"text": "We present the congurations considered and also report results obtained with internal and ocial test sets.", "labels": [], "entities": []}, {"text": "1 Introduction The TALP Research Center of the UPC 1 in cooperation with BMIC 2 and VMU 3 participated in the Spanish-to-English WMT task.", "labels": [], "entities": [{"text": "TALP Research Center", "start_pos": 19, "end_pos": 39, "type": "DATASET", "confidence": 0.8378398418426514}, {"text": "UPC 1", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.8665348291397095}, {"text": "BMIC", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.747630774974823}, {"text": "VMU", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.8418455719947815}, {"text": "WMT task", "start_pos": 129, "end_pos": 137, "type": "TASK", "confidence": 0.7838488519191742}]}, {"text": "Our primary submission was a phrase-based SMT system enhanced with POS tags and our contrastive submission was an augmented phrase-based system using colloca-tion segmentation (Costa-juss\u00e0 et al., 2010), which mainly is away of introducing new phrases in the translation table.", "labels": [], "entities": [{"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8405117988586426}]}, {"text": "This paper presents the description of both systems together with the results that we obtained in the evaluation task and is organized as follows: rst, Section 2 and 3 present a brief description of a phrase-based SMT, followed by a general explanation of collocation segmentation.", "labels": [], "entities": [{"text": "rst", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.9843965172767639}, {"text": "SMT", "start_pos": 214, "end_pos": 217, "type": "TASK", "confidence": 0.7573153972625732}]}, {"text": "Section 4 presents the experimental framework, corpus used and a description of the dierent systems built for the translation task; the section ends showing the results we obtained over the ocial test set.", "labels": [], "entities": [{"text": "translation task", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.929603099822998}, {"text": "ocial test set", "start_pos": 190, "end_pos": 204, "type": "DATASET", "confidence": 0.7167027294635773}]}, {"text": "Finally , section 5 presents the conclusions obtained from the experiments.", "labels": [], "entities": []}, {"text": "2 Phrase-based SMT This approach to SMT performs the translation splitting the source sentence in segments and assigning to each segment a bilingual phrase from a phrase-table.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.7179796099662781}, {"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9900199174880981}, {"text": "translation splitting the source sentence", "start_pos": 53, "end_pos": 94, "type": "TASK", "confidence": 0.9003744006156922}]}, {"text": "Bilingual phrases are translation units that contain source words and target words, e.g. < unidad de traducci\u00f3n | translation unit >, and have dierent scores associated to them.", "labels": [], "entities": []}, {"text": "These bilingual phrases are then sorted in order to maximize a linear combination of feature functions.", "labels": [], "entities": []}, {"text": "Such strategy is known as the log-linear model (Och and Ney, 2003) and it is formally dened as: \u02c6 e = arg max e M m=1 \u03bb m h m (e, f) (1) where h mare dierent feature functions with weights \u03bb m.", "labels": [], "entities": []}, {"text": "The two main feature functions are the translation model (TM) and the target language model (LM).", "labels": [], "entities": []}, {"text": "Additional models include POS target language models, lexical weights, word penalty and reordering models among others.", "labels": [], "entities": []}], "introductionContent": [{"text": "The TALP Research Center of the UPC 1 in cooperation with BMIC 2 and VMU 3 participated in the Spanish-to-English WMT task.", "labels": [], "entities": [{"text": "TALP Research Center", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.8183432022730509}, {"text": "UPC 1", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.8456868827342987}, {"text": "BMIC", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.7180997133255005}, {"text": "VMU", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.8523868322372437}, {"text": "WMT task", "start_pos": 114, "end_pos": 122, "type": "TASK", "confidence": 0.7723393738269806}]}, {"text": "Our primary submission was a phrase-based SMT system enhanced with POS tags and our contrastive submission was an augmented phrase-based system using collocation segmentation, which mainly is away of introducing new phrases in the translation table.", "labels": [], "entities": [{"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8483259677886963}]}, {"text": "This paper presents the description of both systems together with the results that we obtained in the evaluation task and is organized as follows: rst, Section 2 and 3 present a brief description of a phrase-based SMT, followed by a gen- e.g. < unidad de traducci\u00f3n | translation unit >, and have dierent scores associated to them.", "labels": [], "entities": [{"text": "rst", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.9893516898155212}, {"text": "SMT", "start_pos": 214, "end_pos": 217, "type": "TASK", "confidence": 0.7339003086090088}]}, {"text": "These bilingual phrases are then sorted in order to maximize a linear combination of feature functions.", "labels": [], "entities": []}, {"text": "Such strategy is known as the log-linear model and it is formally dened as: where h mare dierent feature functions with weights \u03bb m . The two main feature functions are the translation model (TM) and the target language model (LM).", "labels": [], "entities": []}, {"text": "Additional models include POS target language models, lexical weights, word penalty and reordering models among others.", "labels": [], "entities": []}], "datasetContent": [{"text": "All systems were built using Moses (), a state-of-the-art software for phrase-based SMT.", "labels": [], "entities": [{"text": "phrase-based SMT", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.6025473475456238}]}, {"text": "For preprocessing Spanish, we used Freeling (), an open source library of natural language analyzers.", "labels": [], "entities": []}, {"text": "For English, we used TnT) and Moses' tokenizer.", "labels": [], "entities": []}, {"text": "The language models were built using SRILM).", "labels": [], "entities": [{"text": "SRILM", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.8327940702438354}]}], "tableCaptions": [{"text": " Table 1: Statistics for the training, development", "labels": [], "entities": [{"text": "development", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.6398839354515076}]}, {"text": " Table 2: Unknown words found in internal and", "labels": [], "entities": []}, {"text": " Table 3: Internal test results.", "labels": [], "entities": []}, {"text": " Table 4: Results from translation task", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9826610684394836}]}]}