{"title": [{"text": "Improving Chinese Word Segmentation by Adopting Self-Organized Maps of Character N-gram", "labels": [], "entities": [{"text": "Improving Chinese Word Segmentation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8570641428232193}]}], "abstractContent": [{"text": "Character-based tagging method has achieved great success in Chinese Word Segmentation (CWS).", "labels": [], "entities": [{"text": "Character-based tagging", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6105393618345261}, {"text": "Chinese Word Segmentation (CWS)", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.7532185812791189}]}, {"text": "This paper proposes anew approach to improve the CWS tagging accuracy by combining Self-Organizing Map (SOM) with structured support vector machine (SVM) for utilization of enormous unlabeled text corpus.", "labels": [], "entities": [{"text": "CWS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.9248134791851044}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.8988444805145264}]}, {"text": "First, character N-grams are clustered and mapped into a low-dimensional space by adopting SOM algorithm.", "labels": [], "entities": []}, {"text": "Two different maps are built based on the N-gram's preceding and succeeding context respectively.", "labels": [], "entities": []}, {"text": "Then new features are extracted from these maps and integrated into the structured SVM methods for CWS.", "labels": [], "entities": []}, {"text": "Experimental results on Bakeoff-2005 database show that SOM-based features can contribute more than 7% relative error reduction, and the structured SVM method for CWS proposed in this paper also outperforms traditional conditional random field (CRF) method.", "labels": [], "entities": [{"text": "Bakeoff-2005 database", "start_pos": 24, "end_pos": 45, "type": "DATASET", "confidence": 0.8072496056556702}, {"text": "relative error reduction", "start_pos": 103, "end_pos": 127, "type": "METRIC", "confidence": 0.7372688253720602}]}], "introductionContent": [{"text": "It is well known that there is no space or any other separators to indicate the word boundary in Chinese.", "labels": [], "entities": []}, {"text": "But word is the basic unit for most of Chinese natural language process tasks, such as Machine Translation, Information Extraction, Text Categorization and soon.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.829352468252182}, {"text": "Information Extraction", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.7937478125095367}, {"text": "Text Categorization", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.7683643996715546}]}, {"text": "As a result, Chinese word segmentation (CWS) becomes one of the most fundamental technologies in Chinese natural language process.", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.7526160726944605}]}, {"text": "In the last decade, many statistics-based methods for automatic CWS have been proposed with development of machine learning and statistical method.", "labels": [], "entities": []}, {"text": "Especially, the character-based tagging method which was proposed by Nianwen Xue achieves great success in the second International Chinese word segmentation).", "labels": [], "entities": [{"text": "character-based tagging", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.5780312418937683}, {"text": "International Chinese word segmentation", "start_pos": 118, "end_pos": 157, "type": "TASK", "confidence": 0.8134499490261078}]}, {"text": "The character-based tagging method formulates the CWS problem as a task of predicting a tag for each character in the sentence, i.e. every character is considered as one of four different types in 4-tag set: B (begin of word), M (middle of word), E (end of word), and S (singlecharacter word).", "labels": [], "entities": []}, {"text": "Most of these works train tagging models only on limited labeled training sets, without using any unsupervised learning outcomes from innumerous unlabeled text.", "labels": [], "entities": []}, {"text": "But in recent years, researchers begin to exploit the value of enormous unlabeled corpus for CWS.", "labels": [], "entities": []}, {"text": "Some statistics information on co-occurrence of subsequences in the whole text has been extracted from unlabeled data and been employed as input features for tagging model training.", "labels": [], "entities": [{"text": "tagging model", "start_pos": 158, "end_pos": 171, "type": "TASK", "confidence": 0.896134614944458}]}, {"text": "Word clustering is a common method to utilize unlabeled corpus in language processing research to enhance the generalization ability, such as part-of-speech clustering and semantic clustering ( and B).", "labels": [], "entities": [{"text": "Word clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7019922733306885}, {"text": "part-of-speech clustering", "start_pos": 142, "end_pos": 167, "type": "TASK", "confidence": 0.70562744140625}, {"text": "semantic clustering", "start_pos": 172, "end_pos": 191, "type": "TASK", "confidence": 0.7114611715078354}]}, {"text": "Character-based tagging method usually employs N-gram features, where an Ngram is an N-character segment of a string.", "labels": [], "entities": [{"text": "Character-based tagging", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6929623186588287}]}, {"text": "We believe that there are also semantic or grammatical relationships between most of Ngrams and these relationships will be useful in CWS.", "labels": [], "entities": [{"text": "CWS", "start_pos": 134, "end_pos": 137, "type": "TASK", "confidence": 0.8749447464942932}]}, {"text": "So we investigate how to apply clustering method onto unlabeled data for the purpose of improving CWS accuracy in this paper.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9267967343330383}]}, {"text": "This paper proposes a novel method of using unlabeled data for CWS, which employs SelfOrganizing Map (SOM) to organize Chinese character N-grams on a twodimensional array, named as \"N-gram cluster map\" (NGCM), in which the character N-grams similar in grammatical structure and semantic meaning are organized in the same or adjacent position.", "labels": [], "entities": []}, {"text": "Two different arrays are built based on the N-gram's preceding context and succeeding context respectively because sometimes N-gram is just apart of Chinese word and does not share similar preceding and succeeding context in the same time.", "labels": [], "entities": []}, {"text": "Then NGCM-based features are extracted and applied to tagging model of CWS.", "labels": [], "entities": []}, {"text": "Two tagging models are investigated, which are structured support vector machine (SVM) () model and Confidential Random Fields (CRF) ().", "labels": [], "entities": []}, {"text": "The experimental results show that NGCM is really helpful to CWS.", "labels": [], "entities": [{"text": "CWS", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9052472710609436}]}, {"text": "In addition, we find that the structured SVM achieves better performance than CRF.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 presents self-organizing map and the idea of N-gram cluster maps.", "labels": [], "entities": []}, {"text": "Section 3 describes structured SVM and how to use the NGCMs based features in CWS.", "labels": [], "entities": [{"text": "SVM", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8702839016914368}]}, {"text": "Section 4 shows experimental results on database and Section 5 gives our conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The F-measure is employed for evaluation, which is defined as follows: num of correctly segmented words Precision: P num of the system output words = num of correctly segmented words Recall: R num of total words in test data = 2 PR F-measure: F PR", "labels": [], "entities": [{"text": "Precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.963690996170044}, {"text": "PR F-measure", "start_pos": 229, "end_pos": 241, "type": "METRIC", "confidence": 0.8094696402549744}]}], "tableCaptions": [{"text": " Table 1: Corpus size of Bakeoff-2005 in  number of words", "labels": [], "entities": [{"text": "Bakeoff-2005", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.5750555396080017}]}, {"text": " Table 2: The results of our systems", "labels": [], "entities": []}]}