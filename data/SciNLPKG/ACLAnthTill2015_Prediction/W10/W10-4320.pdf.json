{"title": [{"text": "The Impact of Dimensionality on Natural Language Route Directions in Unconstrained Dialogue", "labels": [], "entities": [{"text": "Natural Language Route Directions", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.7476120740175247}]}], "abstractContent": [{"text": "In this paper we examine the influence of dimensionality on natural language route directions in dialogue.", "labels": [], "entities": []}, {"text": "Specifically, we show that giving route instructions in a quasi-3d environment leads to experiential descriptive accounts, as manifested by a higher proportion of location descriptions, lack of chunking, use of 1st person singular personal pronouns, and more frequent use of temporal and spatial deictic terms.", "labels": [], "entities": []}, {"text": "2d scenarios lead to informative instructions, as manifested by a frequent use of motion expressions , chunking of route elements, and use of mainly 2nd person singular personal pronouns.", "labels": [], "entities": []}], "introductionContent": [{"text": "In order to build artificial agents that are competent in creating and understanding natural language route directions in situated discourse, it is necessary to explore how situatedness affects the communication of humans about routes.", "labels": [], "entities": []}, {"text": "The current study aims at exploring in which ways dimensionality influences the choice of communicative strategies for route directions in discourse.", "labels": [], "entities": []}, {"text": "Previous research about route directions mostly deals with monologues or pretend dialogue (e.g., and concerns two-dimensional stimuli, such as map-based tasks (.", "labels": [], "entities": [{"text": "route directions", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.759475827217102}]}, {"text": "The study presented here examines pairs of participants collaborating on a route instruction task in a naturalistic discourse setting under two conditions: In the 2d condition, the instructor was shown a two-dimensional map with the route drawn into it.", "labels": [], "entities": []}, {"text": "In the 3d condition however, the instructor navigated along a preset route in Google Maps Street View.", "labels": [], "entities": [{"text": "Google Maps Street View", "start_pos": 78, "end_pos": 101, "type": "DATASET", "confidence": 0.9531201273202896}]}], "datasetContent": [{"text": "22 students (average age 25, 14 male and 8 female) volunteered to participate in the experiment.", "labels": [], "entities": []}, {"text": "They formed 11 pairs that each completed one test run and three permuted critical trials.", "labels": [], "entities": []}, {"text": "Instructor and follower were placed in different rooms and interacted via telephone software.", "labels": [], "entities": []}, {"text": "The four predetermined routes were identical for all participants, and they differed mildly in complexity, ranging from 9 to 14 decision points.", "labels": [], "entities": [{"text": "complexity", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9909693598747253}]}, {"text": "All routes were located in San Francisco and were specifically designed such that, at most decision points, descriptions would be unambiguous with respect to perspective use.", "labels": [], "entities": []}, {"text": "In the 2d condition (5 pairs), instructors were given a map that showed mostly street names and major landmarks such as parks, schools, restaurants, etc., as they appear in the standard Google Maps map view.", "labels": [], "entities": []}, {"text": "The route consisted of a marked starting and endpoint, and was signaled by a thick blue line with arrows indicating the direction.", "labels": [], "entities": []}, {"text": "In the 3d condition (6 pairs), instructors interacted directly with Google Street View which had a photographic quasi-3d view and allowed them to observe the surroundings as if navigating on the roads, seeing avast amount of details of the environment.", "labels": [], "entities": [{"text": "Google Street View", "start_pos": 68, "end_pos": 86, "type": "DATASET", "confidence": 0.8972335060437521}]}, {"text": "Street names were clearly readable as an overlay on top of the photographic imagery.", "labels": [], "entities": []}, {"text": "The route was indicated by fat blue arrows that the instructors could click on, in order to move in the given direction.", "labels": [], "entities": []}, {"text": "In both conditions, the followers were asked to draw the route on a map that only contained the starting point.", "labels": [], "entities": []}, {"text": "The task instruction was the same for both conditions, priming for procedural discourse yet ambiguous with respect to perspective use: \"Now you have to tell your partner where you are going.", "labels": [], "entities": []}, {"text": "Please do this by giving instructions via the microphone.\"", "labels": [], "entities": []}, {"text": "(translated from German).", "labels": [], "entities": []}, {"text": "In the 3d condition instructors were informed that the follower had a different view of the same surroundings.", "labels": [], "entities": []}, {"text": "Taken together this setup differs from previous studies in that it features unconstrained spoken dialogue and is set in a realistic usecase with a three-dimensional setting.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Use of perspective expressions in 2d  and 3d conditions (absolute values in paren- theses).", "labels": [], "entities": []}, {"text": " Table 2. Location and motion descriptions by  instructor (means per trial).", "labels": [], "entities": [{"text": "Location and motion descriptions", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.5797104462981224}]}]}