{"title": [{"text": "The University of Maryland Statistical Machine Translation System for the Fifth Workshop on Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.618951678276062}, {"text": "Machine Translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.6867875456809998}]}], "abstractContent": [{"text": "This paper describes the system we developed to improve German-English translation of News text for the shared task of the Fifth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "German-English translation of News text", "start_pos": 56, "end_pos": 95, "type": "TASK", "confidence": 0.7723422408103943}, {"text": "Statistical Machine Translation", "start_pos": 141, "end_pos": 172, "type": "TASK", "confidence": 0.695335845152537}]}, {"text": "Working within cdec, an open source modular framework for machine translation, we explore the benefits of several modifications to our hierarchical phrase-based model, including segmenta-tion lattices, minimum Bayes Risk decoding , grammar extraction methods, and varying language models.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7367795705795288}, {"text": "grammar extraction", "start_pos": 232, "end_pos": 250, "type": "TASK", "confidence": 0.7053434997797012}]}, {"text": "Furthermore, we analyze decoder speed and memory performance across our set of models and show there is an important trade-off that needs to be made.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the shared translation task of the Fifth Workshop on Machine Translation (WMT10), we participated in German to English translation under the constraint setting.", "labels": [], "entities": [{"text": "Machine Translation (WMT10)", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.7490361332893372}, {"text": "German to English translation", "start_pos": 105, "end_pos": 134, "type": "TASK", "confidence": 0.66303950548172}]}, {"text": "We were especially interested in translating from German due to set of challenges it poses for translation.", "labels": [], "entities": [{"text": "translating from German", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.9230135281880697}, {"text": "translation", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.9701199531555176}]}, {"text": "Namely, German possesses a rich inflectional morphology, productive compounding, and significant word reordering with respect to English.", "labels": [], "entities": []}, {"text": "Therefore, we directed our system design and experimentation toward addressing these complications and minimizing their negative impact on translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 139, "end_pos": 150, "type": "TASK", "confidence": 0.9604712724685669}]}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "After a brief description of the baseline system in Section 2, we detail the steps taken to improve upon it in Section 3, followed by experimental results and analysis of decoder performance metrics.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the experiments we performed in attempting to assess the challenges posed by current methods and our exploration of new ones.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of maximum derivation ver- sus MBR decoding", "labels": [], "entities": []}, {"text": " Table 3: Decoding memory and speed requirements for language model and grammar extraction varia- tions", "labels": [], "entities": [{"text": "grammar extraction varia- tions", "start_pos": 72, "end_pos": 103, "type": "TASK", "confidence": 0.7776499032974243}]}]}