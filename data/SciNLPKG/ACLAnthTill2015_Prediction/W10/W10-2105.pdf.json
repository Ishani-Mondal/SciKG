{"title": [{"text": "Grammar-driven versus Data-driven: Which Parsing System is More Affected by Domain Shifts?", "labels": [], "entities": []}], "abstractContent": [{"text": "In the past decade several parsing systems for natural language have emerged, which use different methods and formalisms.", "labels": [], "entities": []}, {"text": "For instance, systems that employ a hand-crafted grammar and a statistical disam-biguation component versus purely statistical data-driven systems.", "labels": [], "entities": []}, {"text": "What they have in common is the lack of portabil-ity to new domains: their performance might decrease substantially as the distance between test and training domain increases.", "labels": [], "entities": []}, {"text": "Yet, to which degree do they suffer from this problem, i.e. which kind of parsing system is more affected by domain shifts?", "labels": [], "entities": []}, {"text": "Intuitively, grammar-driven systems should be less affected by domain changes.", "labels": [], "entities": []}, {"text": "To investigate this hypothesis, an empirical investigation on Dutch is carried out.", "labels": [], "entities": []}, {"text": "The performance variation of a grammar-driven versus two data-driven systems across domains is evaluated, and a simple measure to quantify domain sensitivity proposed.", "labels": [], "entities": []}, {"text": "This will give an estimate of which parsing system is more affected by domain shifts, and thus more in need for adaptation techniques.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9759641289710999}]}], "introductionContent": [{"text": "Most modern Natural Language Processing (NLP) systems are subject to the wellknown problem of lack of portability to new domains: there is a substantial drop in their performance when the system gets input from another text domain.", "labels": [], "entities": []}, {"text": "This is the problem of domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7628768384456635}]}, {"text": "Although the problem exists ever since the emergence of supervised Machine Learning, it has started to get attention only in recent years.", "labels": [], "entities": []}, {"text": "Studies on supervised domain adaptation (where there are limited amounts of annotated resources in the new domain) have shown that straightforward baselines (e.g. models based on source only, target only, or the union of the data) achieve a relatively high performance level and are \"surprisingly difficult to beat\".", "labels": [], "entities": [{"text": "supervised domain adaptation", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.6923426389694214}]}, {"text": "In contrast, semi-supervised adaptation (i.e. no annotated resources in the new domain) is a much more realistic situation but is clearly also considerably more difficult.", "labels": [], "entities": []}, {"text": "Current studies on semisupervised approaches show very mixed results.", "labels": [], "entities": []}, {"text": "report on \"frustrating\" results on the CoNLL 2007 semi-supervised adaptation task for dependency parsing, i.e. \"no team was able to improve target domain performance substantially over a state-of-the-art baseline\".", "labels": [], "entities": [{"text": "CoNLL 2007 semi-supervised adaptation task", "start_pos": 39, "end_pos": 81, "type": "TASK", "confidence": 0.7477510690689086}, {"text": "dependency parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8863975405693054}]}, {"text": "On the other hand, there have been positive results as well.", "labels": [], "entities": []}, {"text": "For instance, improved a statistical parser by self-training.", "labels": [], "entities": []}, {"text": "Structural Correspondence) was effective for PoS tagging and Sentiment Analysis (, while only modest gains were obtained for structured output tasks like parsing.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.8886447548866272}, {"text": "Sentiment Analysis", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.9137832820415497}]}, {"text": "For parsing, most previous work on domain adaptation has focused on data-driven systems, i.e. systems employing (constituent or dependency based) treebank grammars.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9853391647338867}, {"text": "domain adaptation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7339523881673813}]}, {"text": "Only few studies examined the adaptation of grammar-based systems (, i.e. systems employing a hand-crafted grammar with a statistical disambiguation component.", "labels": [], "entities": []}, {"text": "This maybe motivated by the fact that potential gains for this task are inherently bound by the grammar.", "labels": [], "entities": []}, {"text": "Yet, domain adaptation poses a challenge for both kinds of parsing systems.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.7366392016410828}, {"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9642056822776794}]}, {"text": "But to what extent do these different kinds of systems suffer from the problem?", "labels": [], "entities": []}, {"text": "We test the hypothesis that grammar-driven systems are less affected by domain changes.", "labels": [], "entities": []}, {"text": "We empirically investigate this in a case-study on Dutch.", "labels": [], "entities": []}], "datasetContent": [{"text": "The source domain on which all parsers are trained is cdb, the Alpino Treebank).", "labels": [], "entities": [{"text": "Alpino Treebank", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.9380682408809662}]}, {"text": "For our cross-domain evaluation, we consider Wikipedia and DPC (Dutch Parallel Corpus) as target data.", "labels": [], "entities": [{"text": "Wikipedia and DPC (Dutch Parallel Corpus)", "start_pos": 45, "end_pos": 86, "type": "DATASET", "confidence": 0.7821995839476585}]}, {"text": "All datasets are described next.", "labels": [], "entities": []}, {"text": "Source: Cdb The cdb (Alpino Treebank) consists of 140,000 words (7,136 sentences) from the Eindhoven corpus (newspaper text).", "labels": [], "entities": [{"text": "Cdb The cdb (Alpino Treebank) consists of 140,000 words (7,136 sentences) from the Eindhoven corpus (newspaper text)", "start_pos": 8, "end_pos": 124, "type": "DATASET", "confidence": 0.7856363511603811}]}, {"text": "It is a collection of text fragments from 6 Dutch newspapers.", "labels": [], "entities": []}, {"text": "The collection has been annotated according to the guidelines of CGN) and stored in XML format.", "labels": [], "entities": [{"text": "CGN", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9404159188270569}]}, {"text": "It is the standard treebank used to train the disambiguation component of the Alpino parser.", "labels": [], "entities": []}, {"text": "Note that cdb is a subset of the training corpus used in the CoNLL 2006 shared task ().", "labels": [], "entities": [{"text": "CoNLL 2006 shared task", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.9167304635047913}]}, {"text": "The CoNLL training data additionally contained a mix of nonnewspaper text, 1 which we exclude hereon purpose to keep a clean baseline.", "labels": [], "entities": [{"text": "CoNLL training data", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9626742601394653}]}, {"text": "Target: Wikipedia and DPC We use the Wikipedia and DPC subpart of the LASSY cor-1 Namely, a large amount of questions (from CLEF, roughly 4k sentences) and hand-crafted sentences used during the development of the grammar (1.5k).) with 1000 random shuffles.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.9451521635055542}]}], "tableCaptions": [{"text": " Table 1: Overview Wikipedia and DPC corpus (#a  articles, #w words, ASL average sentence length)", "labels": [], "entities": [{"text": "Wikipedia and DPC corpus", "start_pos": 19, "end_pos": 43, "type": "DATASET", "confidence": 0.6291922330856323}]}, {"text": " Table 2: Performance of data-driven parsers ver- sus state-of-the-art on the CoNLL 2006 testset (in  Labeled/Unlabeled Attachment Score).", "labels": [], "entities": [{"text": "CoNLL 2006 testset", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.9692457516988119}]}, {"text": " Table 3: Baseline (5-fold cross-validation). All  differences are significant at p < 0.001.", "labels": [], "entities": []}]}