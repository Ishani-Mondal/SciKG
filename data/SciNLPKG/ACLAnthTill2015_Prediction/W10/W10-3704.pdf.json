{"title": [{"text": "Automatic Extraction of Arabic Multiword Expressions", "labels": [], "entities": [{"text": "Automatic Extraction of Arabic Multiword Expressions", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7662946383158366}]}], "abstractContent": [{"text": "In this paper we investigate the automatic acquisition of Arabic Multiword Expressions (MWE).", "labels": [], "entities": [{"text": "automatic acquisition of Arabic Multiword Expressions (MWE)", "start_pos": 33, "end_pos": 92, "type": "TASK", "confidence": 0.7435157166586982}]}, {"text": "We propose three complementary approaches to extract MWEs from available data resources.", "labels": [], "entities": []}, {"text": "The first approach relies on the correspondence asymmetries between Arabic Wikipedia titles and titles in 21 different languages.", "labels": [], "entities": []}, {"text": "The second approach collects English MWEs from Princeton WordNet 3.0, translates the collection into Arabic using Google Translate, and utilizes different search engines to validate the output.", "labels": [], "entities": [{"text": "Princeton WordNet 3.0", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.8546578486760458}]}, {"text": "The third uses lexical association measures to extract MWEs from a large unan-notated corpus.", "labels": [], "entities": []}, {"text": "We experimentally explore the feasibility of each approach and measure the quality and coverage of the output against gold standards.", "labels": [], "entities": [{"text": "coverage", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9545808434486389}]}], "introductionContent": [{"text": "A lexicon of multiword expressions (MWEs) has a significant importance as a linguistic resource because MWEs cannot usually be analyzed literally, or word-for-word.", "labels": [], "entities": [{"text": "multiword expressions (MWEs)", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.6967005133628845}]}, {"text": "In this paper we apply three approaches to the extraction of Arabic MWEs from multilingual, bilingual, and monolingual data sources.", "labels": [], "entities": [{"text": "extraction of Arabic MWEs", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7920058220624924}]}, {"text": "We rely on linguistic information, frequency counts, and statistical measures to create a refined list of candidates.", "labels": [], "entities": []}, {"text": "We validate the results with manual and automatic testing.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: in this introduction we describe MWEs and provide a summary of previous related research.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 68, "end_pos": 72, "type": "TASK", "confidence": 0.8642755746841431}]}, {"text": "Section 2 gives a brief description of the data sources used.", "labels": [], "entities": []}, {"text": "Section 3 presents the three approaches used in our experiments, and each approach is tested and evaluated in its relevant sub-section.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss the results of the experiments.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "It is an underestimation to view MWEs as a single phenomenon.", "labels": [], "entities": []}, {"text": "In fact MWEs encompass a set of diverse and related phenomena that include idioms, proper nouns, compounds, collocations, institutionalised phrases, etc.", "labels": [], "entities": []}, {"text": "They can also be of any degree of compositionality, idiosyncrasy and lexical and syntactic flexibility.", "labels": [], "entities": []}, {"text": "This complicates the task of MWE identification.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9848636984825134}]}, {"text": "Moreover, we have used three data sources with a large degree of discrepancy: (a) titles of articles in the AWK, (b) induced translation of English MWEs collected from PWN, and (b) Arabic Gigaword, which is a collection of free texts.", "labels": [], "entities": [{"text": "AWK", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.9593036770820618}, {"text": "PWN", "start_pos": 168, "end_pos": 171, "type": "DATASET", "confidence": 0.6903766989707947}]}, {"text": "For each of the data types we apply a different technique that we deem suitable for the task at hand.", "labels": [], "entities": []}, {"text": "The results of the experiments have been subjected to testing and evaluation in their respective sections.", "labels": [], "entities": []}, {"text": "combines and compares the outcomes of the experiments.", "labels": [], "entities": []}, {"text": "The column \"Intersection\" refers to how many MWE candidates are already found through the other methods.", "labels": [], "entities": [{"text": "Intersection", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.9713670015335083}, {"text": "MWE", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9434515833854675}]}, {"text": "We notice that the heterogeneity of the data sources which we used for the task of MWE extraction, helped to enrich our MWE lexicon, as they are complementary to each other.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.9757922291755676}]}, {"text": "We also notice that the intersection between the corpusbased approach and the other approaches is very low.", "labels": [], "entities": [{"text": "intersection", "start_pos": 24, "end_pos": 36, "type": "METRIC", "confidence": 0.9831557273864746}]}, {"text": "On examining the results, we assume that the reasons for the low intersection are: 1.", "labels": [], "entities": []}, {"text": "A lot of named entities in the news corpus are not famous enough to be included in standard Arabic lexical resources (Wikipedia and WordNet), such as, A 5 } | ~ min\u00af ah . im m\u00af azuwz, \"Menachem Mazuz\".", "labels": [], "entities": [{"text": "WordNet", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.9107965230941772}]}, {"text": "2. We lemmatize according to clitics and ignore inflection.", "labels": [], "entities": []}, {"text": "If we include morphological inflection in the lemmatization this may produce a less marked list and allow better matching, such as,", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size and distribution of MWEs in PWN.", "labels": [], "entities": [{"text": "PWN", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.9232387542724609}]}, {"text": " Table 3: MWE identification through correspondence", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9809006452560425}]}, {"text": " Table 4. The best f-measure  achieved is when we accept a candidate transla- tion if it is found only once. The reason for this  is that when Google Translate does not know the  correct translation of an MWE, it produces an un- grammatical sequence of words that does not re- turn any matches by the search engines. This  process gives 13,656 successful MWE candidates  from the list of 60,292 translations.", "labels": [], "entities": []}, {"text": " Table 4: Automatic evaluation (in percent) of the", "labels": [], "entities": [{"text": "Automatic", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9431145787239075}]}, {"text": " Table 5: Bigram and trigram experiment statistics.", "labels": [], "entities": []}, {"text": " Table 6: Bigram and trigram experiment results.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of outcomes from each approach.", "labels": [], "entities": []}]}