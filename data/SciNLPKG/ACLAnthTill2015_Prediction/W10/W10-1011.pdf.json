{"title": [{"text": "A Human-Computer Collaboration Approach to Improve Accuracy of an Automated English Scoring System \ud97b\udf59", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper explores an issue of redundant errors reported while automatically scoring English learners' sentences.", "labels": [], "entities": []}, {"text": "We use a human-computer collaboration approach to eliminate redundant errors.", "labels": [], "entities": []}, {"text": "The first step is to automatically select candidate redundant errors using PMI and RFC.", "labels": [], "entities": [{"text": "RFC", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.9081814885139465}]}, {"text": "Since those errors are detected with different IDs although they represent the same error, the candidacy cannot be confirmed automatically.", "labels": [], "entities": []}, {"text": "The errors are then handed over to human experts to determine the candidacy.", "labels": [], "entities": []}, {"text": "The final candidates are provided to the system and trained with a decision tree.", "labels": [], "entities": []}, {"text": "With those redundant errors eliminated , the system accuracy has been improved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9982678890228271}]}], "introductionContent": [{"text": "An automated English scoring system analyzes a student sentence and provides a score and feedback to students.", "labels": [], "entities": []}, {"text": "The performance of a system is evaluated based on the accuracy of the score and the relevance of the feedback.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9990909099578857}]}, {"text": "The system described in this paper scores English sentences composed by Korean students learning English.", "labels": [], "entities": []}, {"text": "A detailed explanation of the system is given in ().", "labels": [], "entities": []}, {"text": "The scores are calculated from three different phases including word, syntax and mapping, each of which is designed to assign 0~2 points.", "labels": [], "entities": []}, {"text": "Three scores are added up to generate the final score.", "labels": [], "entities": []}, {"text": "A spelling error, a plural form error, and a confusable word error are considered as typical word errors.", "labels": [], "entities": []}, {"text": "A subject verb agreement error, a word order error and relative clause error are typical examples of syntactic errors.", "labels": [], "entities": []}, {"text": "Even when a student sentence is perfectly correct in lexical and syntactic level, it may fail to convey what is meant by the question.", "labels": [], "entities": []}, {"text": "Such sentences are evaluated as grammatical, but cannot be a correct answer for the question.", "labels": [], "entities": []}, {"text": "In this case, the errors can only be recognized by comparing a student sentence with its correct answers.", "labels": [], "entities": []}, {"text": "The differences between a student answer and one of the answers can be considered as mapping errors.", "labels": [], "entities": []}, {"text": "These three phases are independent from one another since they use different processing method, and refer different information.", "labels": [], "entities": []}, {"text": "Independency of three phases causes some problems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the accuracy of determining redundant errors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.999546229839325}]}, {"text": "The evaluation was performed on 200 sentences which were not included in the training data.", "labels": [], "entities": []}, {"text": "Even though the redundancy of the pairs of errors in Class A and Class B are determined by the human expert, the accuracies of both classes did not reach 100% because the errors detected by the system were incorrect.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.9950695037841797}]}, {"text": "The total accuracy including Class A, B, and C was 90.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9997885823249817}]}], "tableCaptions": []}