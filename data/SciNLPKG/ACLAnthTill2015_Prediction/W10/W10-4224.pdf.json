{"title": [{"text": "Anchor-Progression in Spatially Situated Discourse: a Production Experiment", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents two models for producing and understanding situationally appropriate referring expressions (REs) during a discourse about large-scale space.", "labels": [], "entities": [{"text": "understanding situationally appropriate referring expressions (REs)", "start_pos": 48, "end_pos": 115, "type": "TASK", "confidence": 0.6776926480233669}]}, {"text": "The models are evaluated against an empirical production experiment.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We are interested in the way the disambiguation strategies change when producing REs during a discourse about large-scale space versus discourse about small-scale space.", "labels": [], "entities": []}, {"text": "In our experiment, we gathered a corpus of spoken instructions in two different situations: small-scale space (SSS) and large-scale space (LSS).", "labels": [], "entities": []}, {"text": "We use the data to evaluate the utility of the A and R models.", "labels": [], "entities": []}, {"text": "We specifically evaluate them against the traditional (global) model G in which the indented referent must be singled out from all entities in the domain.", "labels": [], "entities": []}, {"text": "The cover story for the experiment was to record spoken instructions to help improve a speech recognition system for robots.", "labels": [], "entities": []}, {"text": "The participants were asked to imagine an intelligent service robot capable of understanding natural language and familiar with its environment.", "labels": [], "entities": []}, {"text": "The task of the participants was to instruct the robot to cleanup a working space, i.e., a table-top (SSS) and an indoor environment (LSS) by placing target objects (cookies or balls) in boxes of the same color.", "labels": [], "entities": []}, {"text": "The use of color terms to identify objects was discouraged by telling the participants that the robot is unable to perceive color.", "labels": [], "entities": []}, {"text": "The stimuli consisted of 8 corresponding scenes of the table-top and the domestic setting (cf..", "labels": [], "entities": []}, {"text": "In order to preclude the specific phenomena of collaborative, task-oriented dialogue (cf., e.g., ()), the participants had to instruct an imaginary recipient of orders.", "labels": [], "entities": []}, {"text": "The choice of a robot was made to rule out potential social implications when imagining, e.g., talking to a child, a butler, or a friend.", "labels": [], "entities": []}, {"text": "The SSS scenes show a bird's-eye view of the table including the robot's position (similar to ().", "labels": [], "entities": [{"text": "SSS", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8887312412261963}]}, {"text": "The way the objects are arranged allows to refer to their location with respect to the corners of the table, with plates as additional landmarks.", "labels": [], "entities": []}, {"text": "The LSS scenes depict an indoor environment with a corridor and, parallel to SSS, four rooms with tables as landmarks.", "labels": [], "entities": [{"text": "SSS", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.7991596460342407}]}, {"text": "The scenes show: Example from the small-scale (1-2) and large-scale space (3-4) scenes in 'and take the ball and bring it to the kitchen and put it into the box on the floor' (a) Small-scale space: squares represent small boxes, stars cookies, and white circles plates.", "labels": [], "entities": []}, {"text": "the robot and the participant in the corridor.", "labels": [], "entities": []}, {"text": "In order to gather more comparable data we opted fora within-participants approach.", "labels": [], "entities": []}, {"text": "Each person participated in the SSS treatment and in the LSS treatment.", "labels": [], "entities": [{"text": "SSS", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9564708471298218}, {"text": "LSS treatment", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.658187985420227}]}, {"text": "To counterbalance potential carryover effects, half of the participants were shown the treatments in inverse order, and the sequence of the 8 scenes in each treatment was varied in a principled way.", "labels": [], "entities": []}, {"text": "In order to make the participants produce multi-utterance discourses, they were required to refer to all target object pairs.", "labels": [], "entities": []}, {"text": "The exact wording of their instructions was up to them.", "labels": [], "entities": []}, {"text": "Participants were placed in front of a screen and a microphone into which they spoke their orders to the imaginary robot, followed by a self-paced keyword after which the experimenter showed the next scene.", "labels": [], "entities": []}, {"text": "The experiment was conducted in German and consisted of a pilot study (10 participants) and the main part (19 female and 14 male students, aged 19-53, German native speakers).", "labels": [], "entities": []}, {"text": "The data of three participants who did not behave according to the instructions was discarded.", "labels": [], "entities": []}, {"text": "The individual sessions took 20-35 min., and the participants were paid for their efforts.", "labels": [], "entities": []}, {"text": "Using the UAM CorpusTool software, transcriptions of the recorded spoken instructions were annotated for occurrences of the linguistic phenomenon we are interested in, i.e., REs.", "labels": [], "entities": [{"text": "UAM CorpusTool", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.9149853885173798}]}, {"text": "Samples were cross-checked by a second annotator.", "labels": [], "entities": []}, {"text": "REs were marked as shallow 'refex' segments, i.e., complex NPs were not decomposed into their constituents.", "labels": [], "entities": []}, {"text": "Only definite NPs representing exophoric REs (cf. Sec. 2) qualify as 'refex' segments.", "labels": [], "entities": []}, {"text": "If a turn contained an indefinite NP, the whole turn was discarded.", "labels": [], "entities": []}, {"text": "The 'refex' segments were coded according to the amount of information they contain, and under which disambiguation model M \u2208 {G, A, R} (R only for LSS) they succeed in singling out the described referent.", "labels": [], "entities": []}, {"text": "Following, we distinguish three types of semantic specificity.", "labels": [], "entities": []}, {"text": "A RE is an over-description with respect to M (over M ) if it contains redundant information, and it is an under-description (under M ) if it is ambiguous according to M . Minimal descriptions (min M ) contain just enough information to uniquely identify the referent.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Mean frequencies (with standard deviation in italics) of minimal (min), over-descriptions  (over), and under-descriptions (under) with respect to the models (A, R, G) in both treatments.", "labels": [], "entities": [{"text": "Mean frequencies", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9779035747051239}]}]}