{"title": [{"text": "Standardizing Complex Functional Expressions in Japanese Predicates: Applying Theoretically-Based Paraphrasing Rules", "labels": [], "entities": [{"text": "Standardizing Complex Functional Expressions in Japanese Predicates", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.7351648041180202}, {"text": "Applying", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9838671684265137}]}], "abstractContent": [{"text": "In order to accomplish the deep semantic understanding of a language, it is essential to analyze the meaning of predicate phrases, a content word plus functional expressions.", "labels": [], "entities": []}, {"text": "In agglutinating languages such as Japanese, however, sentential predicates are multi-morpheme expressions and all the functional expressions including those unnecessary to the meaning of the predicate are merged into one phrase.", "labels": [], "entities": []}, {"text": "This triggers an increase in surface forms, which is problematic for NLP systems.", "labels": [], "entities": []}, {"text": "We solve this by introducing simplified surface forms of predicates that retain only the crucial meaning of the functional expressions.", "labels": [], "entities": []}, {"text": "We construct paraphrasing rules based on syntactic and semantic theories in linguistics.", "labels": [], "entities": []}, {"text": "The results of experiments show that our system achieves the high accuracy of 77% while reducing the differences in surface forms by 44%, which is quite close to the performance of manually simplified predicates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9994138479232788}]}], "introductionContent": [{"text": "The growing need for text mining systems such as opinion mining and sentiment analysis requires the deep semantic understanding of languages.", "labels": [], "entities": [{"text": "text mining", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.7236416190862656}, {"text": "opinion mining", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.8616332411766052}, {"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9438798725605011}]}, {"text": "In order to accomplish this, one needs to not only focus on the meaning of a single content word such as buy but also the meanings conveyed by function words or functional expressions such as not and would like to.", "labels": [], "entities": []}, {"text": "In other words, to extract and analyze a predicate, it is critical to consider both the content word and the functional expressions.", "labels": [], "entities": []}, {"text": "For example, the functional expressions would like to as in the predicate \"would like to buy\" and can't as in \"can't install\" are key expressions in detecting the customer's needs and complaints, providing valuable information to marketing research applications, consumer opinion analysis etc.", "labels": [], "entities": [{"text": "consumer opinion analysis", "start_pos": 263, "end_pos": 288, "type": "TASK", "confidence": 0.6173169314861298}]}, {"text": "Although these functional expressions are important, there have been very few studies that extensively deal with these functional expressions for use in natural language processing (NLP) systems (e.g.,.", "labels": [], "entities": []}, {"text": "This is due to the fact that functional expressions are syntactically complicated and semantically abstract and so are poorly handled by NLP systems.", "labels": [], "entities": []}, {"text": "In agglutinating languages such as Japanese, functional expressions appear in the form of suffixes or auxiliary verbs that follow the content word without any space.", "labels": [], "entities": []}, {"text": "This sequence of a content word (c for short) plus several of functional expressions (f for short) forms a predicate in Japanese (COMP for completive aspect marker, NOM for nominalizer, COP for copular verb).", "labels": [], "entities": [{"text": "COMP", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9374406337738037}, {"text": "NOM", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.9279144406318665}]}, {"text": "(1) kat -chai -takat -ta -n -da buy -COMP -want -PAST -NOM -COP c -f 1 -f 2 -f 3 -f 4 -f 5 \"(I) wanted to buy (it)\" The meaning of \"want to\" is expressed by -tai (f 2 ) and the past tense is expressed by -ta (f 3 ).", "labels": [], "entities": [{"text": "COMP -want -PAST -NOM -COP c -f 1", "start_pos": 37, "end_pos": 70, "type": "METRIC", "confidence": 0.8704783549675574}]}, {"text": "The other functional expressions, -chai(f 1 ), -n(f 4 ), and -da(f 5 ), only slightly alter the predicative meaning of \"wanted to buy,\" as there is no direct English translation.", "labels": [], "entities": []}, {"text": "Therefore, (1) expresses the same fact as. kai -takat -ta buy -want -PAST \"(I) wanted to buy (it).\"", "labels": [], "entities": []}, {"text": "As shown, in Japanese, once one extracts a predicate phrase, the number of differences in surface forms increases drastically regardless of their similarities in meaning.", "labels": [], "entities": []}, {"text": "This is because sentential predicates are multi-word or multimorpheme expressions and there are two different types of functional expressions, one which is crucial for the extraction of predicative meaning and the other, which is almost unnecessary for NLP applications.", "labels": [], "entities": []}, {"text": "This increase in surface forms complicates NLP systems including text mining because they are unable to recognize that these seemingly different predicates actually express the same fact.", "labels": [], "entities": [{"text": "text mining", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.8324591219425201}]}, {"text": "In this study, we introduce paraphrasing rules to transform a predicate with complex functional expressions into a simple predicate.", "labels": [], "entities": []}, {"text": "We use the term standardize to refer to this procedure.", "labels": [], "entities": []}, {"text": "Based on syntactic and semantic theories in linguistics, we construct a simple predicate structure and categorize functional expressions as either necessary or unnecessary.", "labels": [], "entities": []}, {"text": "We then paraphrase a predicate into one that only retains the crucial meaning of the functional expression by deleting unnecessary functional expressions while adding necessary ones.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we provide related work on Japanese functional expressions in NLP systems as well as problems that need to be solved.", "labels": [], "entities": []}, {"text": "Section 3 introduces several linguistic theories and our standardizing rules that we constructed based on these theories.", "labels": [], "entities": []}, {"text": "Section 4 describes the experiments conducted on our standardization system and the results.", "labels": [], "entities": [{"text": "standardization", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.9690110087394714}]}, {"text": "Section 5 discusses the results and concludes the paper.", "labels": [], "entities": []}, {"text": "Throughout this paper, we use the term functional expressions to indicate not only a single function word but also compounds (e.g., would like to).", "labels": [], "entities": []}, {"text": "construct abstract semantic rules for functional expressions and use them in order to find whether two different predicates mean the same.", "labels": [], "entities": []}, {"text": "construct an exhaustive dictionary of functional expressions, which are hierarchically organized, and use it to produce different functional expressions that are semantically equivalent to the original one.", "labels": [], "entities": []}], "datasetContent": [{"text": "Based on the standardization rules discussed in Section 3, our system automatically paraphrased functional expressions of test predicates into simple forms.", "labels": [], "entities": []}, {"text": "We excluded instances that had segmentation errors and those that were judged as inappropriate as a predicate.", "labels": [], "entities": []}, {"text": "A total of 1,501 intermediate predicates (287 for development and 1,214 for test) and 1,958 last predicates (391 for development and 1,567 for test) were transformed into simple predicates.", "labels": [], "entities": []}, {"text": "The accuracy was measured based on the exact match in surface forms with the manually constructed paraphrases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995143413543701}]}, {"text": "For comparison, we used the following baseline methods.", "labels": [], "entities": []}, {"text": "We also measured the reduced rate of differences in surface forms.", "labels": [], "entities": []}, {"text": "We counted the number of types of functional expressions in the last predicates (a sequence off 1 -f 2 -f 3 is counted as one) before and after the standardization.", "labels": [], "entities": []}, {"text": "For comparison, we also counted the number of functional expressions of the manually paraphrased predicates.", "labels": [], "entities": []}, {"text": "As shown, our standardizing system succeeded in reducing surface differences in predicates from the original ones at the rate of 44.0%, which is quite close to the rate achieved by the human annotators (52.0%).", "labels": [], "entities": []}], "tableCaptions": []}