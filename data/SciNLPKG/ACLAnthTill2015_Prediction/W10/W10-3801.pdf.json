{"title": [{"text": "Intersecting Hierarchical and Phrase-Based Models of Translation: Formal Aspects and Algorithms", "labels": [], "entities": [{"text": "Intersecting Hierarchical and Phrase-Based Models of Translation", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.5344909514699664}]}], "abstractContent": [{"text": "We address the problem of constructing hybrid translation systems by intersecting a Hiero-style hierarchical system with a phrase-based system and present formal techniques for doing so.", "labels": [], "entities": []}, {"text": "We model the phrase-based component by introducing a variant of weighted finite-state automata, called \u03c3-automata, provide a self-contained description of a general algorithm for intersecting weighted synchronous context-free grammars with finite-state automata, and extend these constructs to \u03c3-automata.", "labels": [], "entities": []}, {"text": "We end by briefly discussing complexity properties of the presented algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Phrase-based ( and Hierarchical (Hiero-style)) models are two mainstream approaches for building Statistical Machine Translation systems, with different characteristics.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 97, "end_pos": 128, "type": "TASK", "confidence": 0.8018992940584818}]}, {"text": "While phrase-based systems allow a direct capture of correspondences between surface-level lexical patterns, but at the cost of a simplistic handling of re-ordering, hierarchical systems are better able to constrain re-ordering, especially for distant language pairs, but tend to produce sparser rules and often lag behind phrase-based systems for less distant language pairs.", "labels": [], "entities": []}, {"text": "It might therefore make sense to capitalize on the complementary advantages of the two approaches by combining them in someway.", "labels": [], "entities": []}, {"text": "This paper attempts to layout the formal prerequisites for doing so, by developing techniques for intersecting a hierarchical model and a phrase-based model.", "labels": [], "entities": []}, {"text": "In order to do so, one first difficulty has to be overcome: while hierarchical systems are based on the mathematically wellunderstood formalism of weighted synchronous CFG's, phrase-based systems do not correspond to any classical formal model, although they are loosely connected to weighted finite state transducers, but crucially go beyond these by allowing phrase re-orderings.", "labels": [], "entities": []}, {"text": "One might try to address this issue by limiting a priori the amount of re-ordering, in the spirit of, which would allow to approximate a phrase-based model by a standard transducer, but this would introduce further issues.", "labels": [], "entities": []}, {"text": "First, limiting the amount of reordering in the phrase-based model runs contrary to the underlying intuitions behind the intersection, namely that the hierarchical model should be mainly responsible for controlling re-ordering, and the phrase-based model mainly responsible for lexical choice.", "labels": [], "entities": []}, {"text": "Second, the transducer resulting from the operation could be large.", "labels": [], "entities": []}, {"text": "Third, even if we could represent the phrase-based model through a finite-state transducer, intersecting this transducer with the synchronous CFG would actually be intractable in the general case, as we indicate later.", "labels": [], "entities": [{"text": "CFG", "start_pos": 142, "end_pos": 145, "type": "DATASET", "confidence": 0.9339159727096558}]}, {"text": "We then take another route.", "labels": [], "entities": []}, {"text": "For a fixed source sentence x, we show how to construct an automaton that represents all the (weighted) target sentences that can be produced by applying the phrase based model to x.", "labels": [], "entities": []}, {"text": "However, this \"\u03c3-automaton\" is non-standard in the sense that each transition is decorated with a set of source sentence tokens and that the only valid paths are those that do not traverse two sets containing the same token (in other words, valid paths cannot \"consume\" the same source token twice).", "labels": [], "entities": []}, {"text": "The reason we are interested in \u03c3-automata is the following.", "labels": [], "entities": []}, {"text": "First, it is known that intersecting asynchronous grammar simultaneously with the source sentence x and a (standard) target automaton results in another synchronous grammar; we provide a self-contained description of an algorithm for performing this intersection, in the general weighted case, and where x is generalized to an arbitrary source automaton.", "labels": [], "entities": []}, {"text": "Second, we extend this algorithm to \u03c3-automata.", "labels": [], "entities": []}, {"text": "The resulting weighted synchronous grammar represents, as in Hiero, the \"parse forest\" (or \"hypergraph\") of all weighted derivations (that is of all translations) that can be built over x, but where the weights incorporate knowledge of the phrase-based component; it can therefore form the basis of a variety of dynamic programming or sampling algorithms, as is the case with standard Hiero-type representations.", "labels": [], "entities": []}, {"text": "While in the worst case the intersected grammar can contain an exponential number of nonterminals, we argue that such combinatorial explosion will not happen in practice, and we also briefly indicate formal conditions under which it will not be allowed to happen.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}