{"title": [{"text": "A Multi-layer Chinese Word Segmentation System Optimized for Out-of-domain Tasks", "labels": [], "entities": [{"text": "Multi-layer Chinese Word Segmentation", "start_pos": 2, "end_pos": 39, "type": "TASK", "confidence": 0.5760870724916458}]}], "abstractContent": [{"text": "State-of-the-art Chinese word segmenta-tion systems have achieved high performance when training data and testing data are from the same domain.", "labels": [], "entities": []}, {"text": "However, they suffer from the generalizability problem when applied on test data from different domains.", "labels": [], "entities": []}, {"text": "We introduce a multi-layer Chi-nese word segmentation system which can integrate the outputs from multiple heterogeneous segmentation systems.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7331604957580566}]}, {"text": "By training a second layer of large margin clas-sifier on top of the outputs from several Conditional Random Fields classifiers, it can utilize a small amount of in-domain training data to improve the performance.", "labels": [], "entities": []}, {"text": "Experimental results show consistent improvement on F1 scores and OOV recall rates by applying the approach.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9851795732975006}, {"text": "OOV", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9921348094940186}, {"text": "recall rates", "start_pos": 70, "end_pos": 82, "type": "METRIC", "confidence": 0.9423772692680359}]}], "introductionContent": [{"text": "The Chinese word segmentation problem has been intensively investigated in the past two decades.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5786249041557312}]}, {"text": "From lexicon-based methods such as Bi-Directed Maximum Match (BDMM)) to statistical models such as Hidden Markove Model (HMM) (), abroad spectrum of approaches have been experimented.", "labels": [], "entities": [{"text": "Bi-Directed Maximum Match (BDMM", "start_pos": 35, "end_pos": 66, "type": "METRIC", "confidence": 0.7075028419494629}]}, {"text": "By casting the problem as a character labeling task, sequence labeling models such as Conditional Random Fields can be applied on the problem.", "labels": [], "entities": [{"text": "character labeling task", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7947870890299479}]}, {"text": "State-of-the-art CRF-based systems have achieved good performance.", "labels": [], "entities": []}, {"text": "However, like many machine learning problems, generalizability is crucial fora domain-independent segmentation system.", "labels": [], "entities": []}, {"text": "Because the training data usually come from limited domains, when the domain of test data is different from the training data, the results are still not satisfactory.", "labels": [], "entities": []}, {"text": "A straight-forward solution is to obtain more labeled data in the domain we want to test.", "labels": [], "entities": []}, {"text": "However this is not easily achievable because the amount of data needed to train a segmentation system are large.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 83, "end_pos": 95, "type": "TASK", "confidence": 0.9684122800827026}]}, {"text": "In this paper, we focus on improving the system performance by using a relatively small amount of manually labeled in-domain data together with larger out-of-domain corpus . The effect of mingling the small in-domain data into large out-of-domain data maybe neglectable due to the difference in data size.", "labels": [], "entities": []}, {"text": "Hence, we try to explore an alternative way that put a second layer of classifier on top of the segmentation systems built on out-of-domain corpus (we will call them sub-systems).", "labels": [], "entities": []}, {"text": "The classifier should be able to utilize the information from the sub-systems and optimize the performance with a small amount of indomain data.", "labels": [], "entities": []}, {"text": "The basic idea of our method is to integrate a number of different sub-systems whose performance varies on the new domain.", "labels": [], "entities": []}, {"text": "There are two layers in the system.", "labels": [], "entities": []}, {"text": "In the lower layer, the out-of-domain corpora are used, together with other resources to produce heterogeneous subsystems.", "labels": [], "entities": []}, {"text": "In the second layer the outputs of the sub-systems in the first layer are treated as input to the classifier.", "labels": [], "entities": []}, {"text": "We train the classifier with small in-domain data.", "labels": [], "entities": []}, {"text": "All the sub-systems should have reasonable performance on all domains, but their performance on different domains may vary.", "labels": [], "entities": []}, {"text": "The job of the second layer is to find the best decision boundary on the target domain, in presence of all the decisions made by the sub-systems.", "labels": [], "entities": []}, {"text": "Figure 1: The architecture of the system, the first layer (sub-systems) is trained on general out-ofdomain corpus and various resources, while the second layer of the classifier is trained on indomain corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effectiveness of the proposed system combination method, we performed two experiments.", "labels": [], "entities": []}, {"text": "First, we evaluate the system combination method on provided training data in the way that is similar to cross-validation.", "labels": [], "entities": []}, {"text": "Second, we experimented with training the SVM-HMM model with the manually labeled data come from cor-: The performance of individual systems and system combination on Bake-off test data, CB1, CB2, and CB3 are system combination trained on labeled data from domain A, B, and the concatenation of the data from both domains.", "labels": [], "entities": [{"text": "Bake-off test data", "start_pos": 167, "end_pos": 185, "type": "DATASET", "confidence": 0.8987811207771301}]}, {"text": "responding domains, and tested the resulting systems on the Bake-off test data.", "labels": [], "entities": [{"text": "Bake-off test data", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.9577259023984274}]}, {"text": "For experiment 1, We divide the training set into 11 segments, segment 0 through 9 contains 1733 sentences, and segment 10 has 1724 sentence.", "labels": [], "entities": []}, {"text": "We perform 10-fold cross-validation on segment 0 to 9.", "labels": [], "entities": []}, {"text": "Every time we pick one segment from segment 0 to 9 as test set and the remaining 9 segments are used to train CRF-based subsystems.", "labels": [], "entities": []}, {"text": "Segment 10 is used as the training set for SVM-HMM model.", "labels": [], "entities": [{"text": "SVM-HMM", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.7605248689651489}]}, {"text": "The sub-systems we used is listed in.", "labels": [], "entities": []}, {"text": "In we provide the micro-level and macro-level average of performance the ten-fold evaluation, including both the combined system and all the individual sub-systems.", "labels": [], "entities": []}, {"text": "Because the system combination uses more data than its sub-systems (segment 10), in order to have a fair comparison, when evaluating individual subsystems, segment 10 is appended to the training data of CRF model.", "labels": [], "entities": []}, {"text": "Therefore, the individual subsystems and system combination have exactly the same set of training data.", "labels": [], "entities": []}, {"text": "As we can see in the results in, the system combination method (Row CB) has improvement over the best sub-system (S4) on both F1 and OOV recall rate, and the OOV recall rate improved by 1%.", "labels": [], "entities": [{"text": "F1", "start_pos": 126, "end_pos": 128, "type": "METRIC", "confidence": 0.9964815378189087}, {"text": "OOV", "start_pos": 133, "end_pos": 136, "type": "METRIC", "confidence": 0.8534451723098755}, {"text": "recall rate", "start_pos": 137, "end_pos": 148, "type": "METRIC", "confidence": 0.9067864716053009}, {"text": "OOV", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.9458615779876709}, {"text": "recall rate", "start_pos": 162, "end_pos": 173, "type": "METRIC", "confidence": 0.9267207980155945}]}, {"text": "We should notice that in this experiment we actually did not deal with any data from different domains, the advantage of the proposed method is therefore not prominent.", "labels": [], "entities": []}, {"text": "We continue to present the experiment results of the second experiment.", "labels": [], "entities": []}, {"text": "In the experiment we labeled 200 sentences from each of the unlabeled bake-off training set A and B, and trained the SVM-HMM model on the labeled data.", "labels": [], "entities": []}, {"text": "We compare the performance of the four sub-systems and the performance of the system combination method trained on: 1) 200 sentences from A, 2) 200 sentences from B, and 3) the concatenation of the 400 sentences from both A and B.", "labels": [], "entities": []}, {"text": "We show the scores on the bake-off test set A and B in.", "labels": [], "entities": [{"text": "bake-off test set A", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.7659741342067719}]}, {"text": "As we can see from the results in, the system combination method outperforms all the individual systems, and the best performance is observed when using both of the labeled data from domain A and B, which indicates the potential of further improvement by increasing the amount of in-domain training data.", "labels": [], "entities": []}, {"text": "Also, the individual subsystems with the best performance on the two domains are different.", "labels": [], "entities": []}, {"text": "System 1 performs well on Set B but not on Set A, so does System 4, which tops on Set A but not as good as System 1 on Set B. The system combination results appear to be much more stable on the two domains, which is a preferable characteristic if the segmentation system needs to deal with data from various domains.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The performance of individual systems and system combination on Bake-off test data, CB1,  CB2, and CB3 are system combination trained on labeled data from domain A, B, and the concatenation  of the data from both domains.", "labels": [], "entities": [{"text": "Bake-off test data", "start_pos": 74, "end_pos": 92, "type": "DATASET", "confidence": 0.9205881754557291}]}]}