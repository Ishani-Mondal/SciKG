{"title": [{"text": "Generating Quantifiers and Negation to Explain Homework Testing", "labels": [], "entities": [{"text": "Negation to Explain Homework", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.7371138632297516}]}], "abstractContent": [{"text": "We describe Prograder, a software package for automatic checking of requirements for programming homework assignments.", "labels": [], "entities": [{"text": "Prograder", "start_pos": 12, "end_pos": 21, "type": "DATASET", "confidence": 0.8669872283935547}]}, {"text": "Prograder lets instructors specify requirements in natural language as well as explains grading results to students in natural language.", "labels": [], "entities": []}, {"text": "It does so using a grammar that generates as well as parses to translate between a small fragment of English and a first-order logical specification language that can be executed directly in Python.", "labels": [], "entities": []}, {"text": "This execution embodies multiple semantics-both to check the requirement and to search for evidence that proves or disproves the requirement.", "labels": [], "entities": []}, {"text": "Such a checker needs to interpret and generate sentences containing quantifiers and negation.", "labels": [], "entities": []}, {"text": "To handle quantifier and negation scope, we systematically simulate continuation grammars using record structures in the Grammatical Framework.", "labels": [], "entities": [{"text": "negation scope", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8963335454463959}]}], "introductionContent": [{"text": "The typical programming assignment in a computerscience course comes with not only a problem description but also correctness and stylistic requirements such as (1) Every source file compiles and has comments, and a text file mentions every source file and every header file.", "labels": [], "entities": []}, {"text": "Although the requirements do not usually specify exactly how the students' work will be judged, they make it much easier to grade and respond to the submitted work.", "labels": [], "entities": []}, {"text": "Many requirements can be checked automatically by computer, and often they areperhaps even right after each student uploads their work so that the student can revise their work using the immediate feedback.", "labels": [], "entities": []}, {"text": "This common workflow is wanting in two aspects.", "labels": [], "entities": []}, {"text": "First, the requirements are both specified to the students in English and coded into a testing harness by the course staff.", "labels": [], "entities": []}, {"text": "Keeping the two versions is a hassle that involves much boilerplate text as well as boilerplate code.", "labels": [], "entities": []}, {"text": "Second, students rightfully demand comprehensible explanations when their work is rejected by the requirement tester.", "labels": [], "entities": []}, {"text": "It is tricky to code up a tester that produces error messages neither too terse nor too verbose, when one student might forget to comment just one file and another might not know the lexical syntax of comments at all.", "labels": [], "entities": []}, {"text": "A natural approach to improve this workflow, then, is to specify the requirements in a formal language and to implement an interpreter for the language that produces explanations.", "labels": [], "entities": []}, {"text": "Because many instructors, like students, are averse to learning new languages, we pursue the use of a controlled subset of English as that formal language.", "labels": [], "entities": []}, {"text": "In short, we aim to produce a programming-assignment tester that allows instructors to specify requirements for programming assignments in natural language, checks those requirements automatically by executing commands on the submitted assignment files, and generates for the student a natural-language explanation of the results.", "labels": [], "entities": []}, {"text": "For example, in an introductory programming class, a professor may write the specification sentence (1).", "labels": [], "entities": []}, {"text": "The system would then grade all students' programming assignments according to these criteria, and return individualized explanations 57 to students like (2) Credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h.", "labels": [], "entities": [{"text": "Credit", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.9865228533744812}]}, {"text": "As this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation.", "labels": [], "entities": []}, {"text": "Although the interpretation of quantifiers and negation is a traditional research area in computational linguistics, their generation is much less studied.", "labels": [], "entities": [{"text": "interpretation of quantifiers and negation", "start_pos": 13, "end_pos": 55, "type": "TASK", "confidence": 0.8179615616798401}]}, {"text": "Even if our system were to compose explanations entirely from the input specification sentences and their negation, it cannot negate a specification sentence merely by adding or removing verbal auxiliaries: the negation of \"a source file defines main()\" is not \"a source file does not define main()\".", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}