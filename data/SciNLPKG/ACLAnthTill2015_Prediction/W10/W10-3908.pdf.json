{"title": [{"text": "Utilizing Citations of Foreign Words in Corpus-Based Dictionary Generation", "labels": [], "entities": [{"text": "Utilizing Citations of Foreign Words", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.811214292049408}]}], "abstractContent": [{"text": "Previous work concerned with the identification of word translations from text collections has been either based on parallel or on comparable corpora of the respective languages.", "labels": [], "entities": [{"text": "identification of word translations from text collections", "start_pos": 33, "end_pos": 90, "type": "TASK", "confidence": 0.8758714709963117}]}, {"text": "In the case of comparable corpora basic dictionaries have been necessary to form abridge between the languages under consideration.", "labels": [], "entities": []}, {"text": "We present here a novel approach to identify word translations from a single mono-lingual corpus without necessarily requiring dictionaries, although, as will be shown, a dictionary can still be useful for improving the results.", "labels": [], "entities": [{"text": "identify word translations", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.7690656979878744}]}, {"text": "Our approach is based on the observation that for various reasons monolingual corpora typically contain many foreign words (for example citations).", "labels": [], "entities": []}, {"text": "Relying on standard news-ticker texts, we will show that their co-occurrence-based associations can be successfully used to identify word translations .", "labels": [], "entities": [{"text": "identify word translations", "start_pos": 124, "end_pos": 150, "type": "TASK", "confidence": 0.7113356590270996}]}], "introductionContent": [{"text": "The web has popularized information access.", "labels": [], "entities": [{"text": "information access", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.831103652715683}]}, {"text": "As a consequence, the information put on the web evolved, expanding from mainly technical documents in one language (English) to topics concerning nearly any aspect of life in many languages.", "labels": [], "entities": []}, {"text": "For this reason it cannot be expected anymore that all web users speak English.", "labels": [], "entities": []}, {"text": "Yet users speaking only one of the minority languages will be penalized, finding only a small fraction of web content accessible.", "labels": [], "entities": []}, {"text": "Hence they can make only very limited use of what is available.", "labels": [], "entities": []}, {"text": "In order to increase information access independently of the users' mother tongue, automatic translation is desirable.", "labels": [], "entities": [{"text": "automatic translation", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.5617925673723221}]}, {"text": "Recognizing this need, Google, among others, is providing free machine translation services for any pair of currently 50 languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7197406440973282}]}, {"text": "1 However, with 6800 living languages, of which 600 also use a written form, offering comprehensive translation services remains a challenge.", "labels": [], "entities": []}, {"text": "The statistical approach to machine translation (SMT), as adopted by Google, relies on parallel corpora, i.e. large collections of existing translations.", "labels": [], "entities": [{"text": "machine translation (SMT)", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8650426983833313}]}, {"text": "But it is a daunting task trying to acquire parallel corpora for all possible language pairs.", "labels": [], "entities": []}, {"text": "Therefore, it appears that for some languages Google has combined SMT with an interlingua approach.", "labels": [], "entities": [{"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9899498224258423}]}, {"text": "This allows optimal exploitation of languages for which parallel corpora are easily obtained.", "labels": [], "entities": []}, {"text": "These languages are then used as pivots.", "labels": [], "entities": []}, {"text": "Note that in phrase-based SMT an interlingua approach may operate at the level of the phrase table, which facilitates matters while speeding up the process.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.6731829643249512}]}, {"text": "At the downside it must be noted that a phrase table derived via a pivot language is generally of lower quality than a phrase table directly compiled from parallel texts (provided the corpus size is similar).", "labels": [], "entities": []}, {"text": "Hence, just as for other interlingua approaches, translation quality is severely compromised.", "labels": [], "entities": [{"text": "translation", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.9657666683197021}]}, {"text": "An alternative approach that has been suggested is to try to generate the required dictionaries from other sources than parallel corpora.", "labels": [], "entities": []}, {"text": "Bear in mind that statistical machine translation requires a language model and a translation model.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.7036370237668356}]}, {"text": "To generate the language model only monolingual corpora of the target language are required which, for example, can be acquired from the web.", "labels": [], "entities": []}, {"text": "If only few such documents exist, one may well conclude that there is probably no real need for translation involving this particular language.", "labels": [], "entities": [{"text": "translation", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.9706564545631409}]}, {"text": "So the main bottleneck are the parallel corpora required to generate a translation model.", "labels": [], "entities": []}, {"text": "But the purpose of the translation model is in essence the creation of a bilingual dictionary, be it a dictionary of individual words or a dictionary of phrases.", "labels": [], "entities": []}, {"text": "For this reason, if we can find other ways to generate dictionaries for lesser used languages, this will be beneficial not only for the users of these languages but also for the solution of the overall problem of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 213, "end_pos": 232, "type": "TASK", "confidence": 0.8154155015945435}]}, {"text": "In other words, an important challenge is the generation of dictionaries.", "labels": [], "entities": []}, {"text": "Since comparable corpora area far more common resource than parallel corpora, attempts to exploit them for dictionary construction have received considerable attention recently.", "labels": [], "entities": [{"text": "dictionary construction", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.8771000504493713}]}, {"text": "One approach is to mine parallel sentences from comparable corpora.", "labels": [], "entities": []}, {"text": "Roughly speaking, this can be done by automatically translating a corpus from one language (source language) to another (target language), and then searching in a large corpus of the target language for sentences similar to the translations.", "labels": [], "entities": []}, {"text": "The advantage of this procedure is that the sentences retrieved this way are correct sentences as they were produced by humans, whereas the sentences translated by a machine tend to be garbled and of lower quality.", "labels": [], "entities": []}, {"text": "However, the big problem with this approach is to ensure that the retrieved sentence pairs are indeed translations of each other.", "labels": [], "entities": []}, {"text": "While there is no perfect solution to this problem, several studies have shown that such data can be useful for building or supplementing translation models in SMT (see e. g..", "labels": [], "entities": [{"text": "SMT", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.9878137111663818}]}, {"text": "Another approach for exploiting comparable corpora in dictionary generation is based on the observation that word co-occurrence patterns between languages tend to be similar).", "labels": [], "entities": [{"text": "dictionary generation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7236140221357346}]}, {"text": "If, for example, two words X and Y cooccur more often than expected by chance in a corpus of language A, then their translated equi-2 There is also the approach of identifying orthographically similar words) which does not even require a corpus as simple word lists will suffice.", "labels": [], "entities": [{"text": "equi-2", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9209348559379578}]}, {"text": "However, this approach is promising only for closely related languages but appears to have limited scope otherwise.", "labels": [], "entities": []}, {"text": "For this reason we will not further discuss it here.", "labels": [], "entities": []}, {"text": "valents should also co-occur more frequently than expected in a corpus of language B.", "labels": [], "entities": []}, {"text": "A great number of variants of this approach has been proposed, e.g. emphasizing aspects of corpus selection or expanding it to collocations or short phrases (.", "labels": [], "entities": [{"text": "corpus selection", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.7116361409425735}]}, {"text": "What is common to these studies is that they consider the source and the target language as two distinct semantic spaces, without any links at the beginning.", "labels": [], "entities": []}, {"text": "Therefore, in order to connect the two, abase dictionary is required, and the purpose of the system is to expand this base dictionary.", "labels": [], "entities": []}, {"text": "Building a dictionary from scratch is not possible this way or at least computationally unfeasible (see.", "labels": [], "entities": []}, {"text": "Whether the assumption of two completely distinct semantic spaces is realistic remains an open issue.", "labels": [], "entities": []}, {"text": "Are separate lexical networks really a reasonable model for the processing of different languages by people?", "labels": [], "entities": []}, {"text": "One could say this is a plausible model, assuming a person lived for some years in one country, and then for some more years in another country, assuming further that this person never looked at a dictionary or another multilingual document and never communicated with a person mixing both languages.", "labels": [], "entities": []}, {"text": "It is known that this can work.", "labels": [], "entities": []}, {"text": "The reason is probably the following: Many words of the basic dictionary assumed above correspond to items of the physical world.", "labels": [], "entities": []}, {"text": "These items generally have names in natural languages which can serve as mediators.", "labels": [], "entities": []}, {"text": "That the extrapolation to more abstract notions is possible has been claimed by.", "labels": [], "entities": []}, {"text": "Still, although persons proceeding this way can easily understand and, after some years, even think in each of the two languages, experience shows that they tend to have some difficulties when making translations, especially literal translations.", "labels": [], "entities": []}, {"text": "So, although the above scenario is possible, we do not think that it is atypical one for our modern times.", "labels": [], "entities": []}, {"text": "There are certainly good reasons why there are so many language courses, and why there is such an abundance of dictionaries.", "labels": [], "entities": []}, {"text": "It is a matter of commonsense that the person trying to acquire anew language will look at a multilingual dictionary.", "labels": [], "entities": []}, {"text": "He or she will also communicate with other persons who mix languages, for example, relatives, other people from the com-munity of foreigners coming from the same country, teachers in language classes, etc.", "labels": [], "entities": []}, {"text": "In many cases there will also be multilingual documents around: leaflets, explanations in a museum, or signs in a public area (e.g. airport).", "labels": [], "entities": []}, {"text": "Hence the spoken and written \"corpus\" (input) on which such a person's language acquisition process is based is not solely monolingual.", "labels": [], "entities": []}, {"text": "While the corpus maybe mainly monolingual, it surely will contain some multilingual elements.", "labels": [], "entities": []}, {"text": "If we agree on this, our next step could be to acquire transcripts of language teaching classes with bilingual teachers and try to exploit these for dictionary generation.", "labels": [], "entities": [{"text": "dictionary generation", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.787868469953537}]}, {"text": "Since obtaining such transcripts in large enough quantities should be much more difficult than obtaining parallel corpora, this approach will probably not solve the data acquisition bottleneck which is the practical problem we were about to solve in the first place.", "labels": [], "entities": [{"text": "data acquisition", "start_pos": 165, "end_pos": 181, "type": "TASK", "confidence": 0.7501854300498962}]}, {"text": "The current study is therefore based on newsticker texts which is a text type very similar to standard newspaper texts.", "labels": [], "entities": []}, {"text": "At least for some languages it is available in large quantities.", "labels": [], "entities": []}, {"text": "However, this type of text is probably not ideally suited for our purpose.", "labels": [], "entities": []}, {"text": "Surprisingly, the reason is that newsticker and newspaper texts tend to be very well edited.", "labels": [], "entities": []}, {"text": "This means that the author will typically avoid foreign words, and if ever some remain the respective passages are likely be rephrased in order to make sure that the text uses familiar vocabulary, easily understandable by the readers.", "labels": [], "entities": []}, {"text": "However, this is problematic for our approach which is based on the occurrences of foreign words in a monolingual text.", "labels": [], "entities": []}, {"text": "So this is one of the rare cases where noisy corpora should yield better results than perfectly clean data.", "labels": [], "entities": []}, {"text": "On the other hand, as this study suggests a (to our knowledge) novel approach, we consider it important to use a corpus that is generally known and available, and which has not been compiled with this particular purpose in mind.", "labels": [], "entities": []}, {"text": "Only this way our results can convincingly give an idea concerning the baseline performance of the suggested algorithm.", "labels": [], "entities": []}, {"text": "At this stage we consider this more important than optimizing results by compiling corpora specifically suited for the purpose, even though this will be a logical next step.", "labels": [], "entities": []}], "datasetContent": [{"text": "Let us first try to see whether the basic assumption underlying our approach is sound, namely that we will find a sufficient number of foreign words in our corpus.", "labels": [], "entities": []}, {"text": "To check this claim, we have listed in for each of the four languages the number of words from the gold standard falling into particular frequency categories.", "labels": [], "entities": []}, {"text": "For example, the value of 70 in the field belonging to the row 6-10 and the column Spanish means that out of the 1079 Spanish words in our gold standard 70 have a corpus frequency between 6 and 10 in the 4th edition of the English Gigaword Corpus.", "labels": [], "entities": [{"text": "English Gigaword Corpus", "start_pos": 223, "end_pos": 246, "type": "DATASET", "confidence": 0.8973201115926107}]}, {"text": "Apparently, words with zero occurrences or with a very low corpus frequency are problematic because of data sparseness.", "labels": [], "entities": []}, {"text": "Yet words with very high frequencies are not less problematic, as they may turnout to have homographs in the target language.", "labels": [], "entities": []}, {"text": "As there is no generally accepted definition of what the vocabulary of a given language is, we cannot give precise figures concerning the number of homographs in our gold standard for each language pair.", "labels": [], "entities": []}, {"text": "Never-theless, we believe that gives a fair impression.", "labels": [], "entities": []}, {"text": "By taking a look at the high frequency source language words one can see that the pair French-English has the greatest number of homographs, followed by German-English, and finally Spanish-English.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus frequencies of the words occurring in  the gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 60, "end_pos": 73, "type": "DATASET", "confidence": 0.8231359720230103}]}, {"text": " Table 3. As can be seen, apart from  the usual statistical fluctuations the difference is  hardly noticeable.", "labels": [], "entities": []}, {"text": " Table 3: Ranks of the expected translations when all  three source languages are combined.", "labels": [], "entities": []}]}