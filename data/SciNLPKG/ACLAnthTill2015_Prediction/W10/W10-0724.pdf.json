{"title": [{"text": "Evaluation of Commonsense Knowledge with Mechanical Turk", "labels": [], "entities": []}], "abstractContent": [{"text": "Efforts to automatically acquire world knowledge from text suffer from the lack of an easy means of evaluating the resulting knowledge.", "labels": [], "entities": []}, {"text": "We describe initial experiments using Mechanical Turk to crowdsource evaluation to non-experts for little cost, resulting in a collection of factoids with associated quality judgements.", "labels": [], "entities": []}, {"text": "We describe the method of acquiring usable judgements from the public and the impact of such large-scale evaluation on the task of knowledge acquisition.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.7597719132900238}]}], "introductionContent": [{"text": "The creation of intelligent artifacts that can achieve human-level performance at problems like questionanswering ultimately depends on the availability of considerable knowledge.", "labels": [], "entities": []}, {"text": "Specifically, what is needed is commonsense knowledge about the world in a form suitable for reasoning.", "labels": [], "entities": []}, {"text": "Open knowledge extraction (Van Durme and Schubert, 2008) is the task of mining text corpora to create useful, high-quality collections of such knowledge.", "labels": [], "entities": [{"text": "Open knowledge extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7298773527145386}]}, {"text": "Efforts to encode knowledge by hand, such as Cyc, require expensive man-hours of labor by experts.", "labels": [], "entities": []}, {"text": "Indeed, results from Project Halo) suggest that properly encoding the (domain-specific) knowledge from just one page of a textbook can cost $10,000.", "labels": [], "entities": []}, {"text": "OKE, on the other hand, creates logical formulas automatically from existing stores of human knowledge, such as books, newspapers, and the Web.", "labels": [], "entities": [{"text": "OKE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.92795729637146}]}, {"text": "And while crowdsourced efforts to gather knowledge, such as Open Mind), learn factoids people come up with off the tops of their heads to contribute, OKE learns from what people normally write about and thus consider important.", "labels": [], "entities": []}, {"text": "Open knowledge extraction differs from open information extraction () in the focus on everyday, commonsense knowledge rather than specific facts, and on the logical interpretability of the outputs.", "labels": [], "entities": [{"text": "Open knowledge extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7561463912328085}, {"text": "open information extraction", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.7197182973225912}]}, {"text": "While an OIE system might learn that Tolstoy wrote using a dip pen, an OKE system would prefer to learn that an author may write using a pen.", "labels": [], "entities": []}, {"text": "An example of an OKE effort is the KNEXT system 1, which uses compositional semantic interpretation rules to produce logical formulas from the knowledge implicit in parsed text.", "labels": [], "entities": [{"text": "KNEXT system 1", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.819185713926951}]}, {"text": "These formulas are then automatically expressed as Englishlike \"factoids\", such as 'A PHILOSOPHER MAY HAVE A CONVICTION' or 'NEGOTIATIONS CAN BE LIKELY TO GO ON FOR SOME HOURS'.", "labels": [], "entities": [{"text": "A PHILOSOPHER MAY HAVE A CONVICTION", "start_pos": 84, "end_pos": 119, "type": "METRIC", "confidence": 0.840490072965622}, {"text": "NEGOTIATIONS CAN BE LIKELY TO GO ON FOR SOME HOURS", "start_pos": 125, "end_pos": 175, "type": "METRIC", "confidence": 0.7533573299646378}]}, {"text": "While it is expected that eventually sufficiently clean knowledge bases will be produced for inferences to be made about everyday things and events, currently the average quality of automatically acquired knowledge is not good enough to be used in traditional reasoning systems.", "labels": [], "entities": []}, {"text": "An obstacle for knowledge extraction is the lack of an easy method for evaluating -and thus improving -the quality of results.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.739226758480072}]}, {"text": "Evaluation in acquisition systems is typically done by human judging of random samples of output, usually by the reporting authors themselves (e.g.,.", "labels": [], "entities": []}, {"text": "This is time-consuming, and it has the potential for bias: it would be preferable to have people other than AI researchers label whether an output is commonsense knowledge or not.", "labels": [], "entities": []}, {"text": "We explore the use of Amazon's Mechanical Turk service, an online labor market, as a means of acquiring many non-expert judgements for little cost.", "labels": [], "entities": []}], "datasetContent": [{"text": "Previous evaluations of KNEXT output have tried to judge the relative quality of knowledge learned from different sources and by different techniques.", "labels": [], "entities": [{"text": "KNEXT output", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.7274172604084015}]}, {"text": "Here the goal is simply to see whether the means of evaluation can be made to work reasonably, including at what scale it can be done for limited cost.", "labels": [], "entities": []}, {"text": "For these experiments, we relied on $100 in credit provided by Amazon as part of the workshop shared task.", "labels": [], "entities": []}, {"text": "This amount was used for several small experiments in order to empirically estimate what $100 could achieve, given a tuned method of presentation and evaluation.", "labels": [], "entities": []}, {"text": "We took a random selection of factoids generated from the British National Corpus (), split into sets of 20, and removed those most easily filtered out as probably being of low quality or malformed.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 58, "end_pos": 81, "type": "DATASET", "confidence": 0.9119609594345093}]}, {"text": "We skipped the more stringent filters (originally created for dealing with noisy Web text), leaving more variety in the quality of the factoids Turkers were asked to rate.", "labels": [], "entities": []}, {"text": "The first evaluation followed the format of previous, offline ratings.", "labels": [], "entities": []}, {"text": "For each factoid, Turkers were given the instructions and choices in, where the options correspond in our analysis to the numbers 1-5, with 1 being agreement.", "labels": [], "entities": []}, {"text": "To help Turkers make such judgements, they were given a brief background statement: \"We're gathering the sort of everyday, commonsense knowledge an intelligent computer system should know.", "labels": [], "entities": []}, {"text": "You're asked to rate several possible statements based on how well you think they meet this goal.\" suggest that while money may increase the number and speed of responses, other motivations such as wanting to help with something worthwhile or interesting are more likely to lead to high-quality responses.", "labels": [], "entities": []}, {"text": "Participants were then shown the examples and explanations in.", "labels": [], "entities": []}, {"text": "Note that while they are told some categories that bad factoids can fall into, the Turkers are not asked to make such classifications  themselves, as this is a task where even experts have low agreement).", "labels": [], "entities": [{"text": "Turkers", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.8486867547035217}]}, {"text": "An initial experiment (Round 1) only required Turkers to have a high (90%) approval rate.", "labels": [], "entities": [{"text": "Turkers", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.670635461807251}]}, {"text": "Under these conditions, out of 100 HITs 2 , 60 were completed by participants whose IP addresses indicated they were in India, 38 from the United States, and 2 from Australia.", "labels": [], "entities": []}, {"text": "The average Pearson correlation between the ratings of different Indian Turkers answering the same questions was a very weak 0.065, and between the Indian responders and those from the US and Australia was 0.132.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 12, "end_pos": 31, "type": "METRIC", "confidence": 0.9649659097194672}]}, {"text": "On the other hand, the average correlation among non-Indian Turkers was 0.508, which is close to the 0.6-0.8 range seen between the authors in the past, and which can betaken as an upper bound on agreement for the task.", "labels": [], "entities": []}, {"text": "Given the sometimes subtle judgements of meaning required, being a native English speaker has previously been assumed to be a prerequisite.", "labels": [], "entities": []}, {"text": "This difference in raters' agreements may thus be due to levels of language understanding, or perhaps to different levels of attentiveness to the task.", "labels": [], "entities": []}, {"text": "However, it does not seem to be the case that the Indian respondents rushed: They took a median time of 201.5 seconds (249.18 avg. with a high standard deviation of 256.3 s -some took more than a minute per factoid).", "labels": [], "entities": []}, {"text": "The nonIndian responders took a median time of just 115.5 s (124.5 avg., 49.2 std dev.).", "labels": [], "entities": []}, {"text": "Regardless of the cause, given these results, we restricted the availability of all following experiments to Turkers in the US.Ideally we would include other English-speaking countries, but there is no straight- forward way to set multiple allowable countries on Mechanical Turk.When Round 2 was posted with a larger set of factoids to be rated and the location requirement, responses fell off sharply, leading us to abort and repost with a higher payrate (7\u00a2 for 20 factoids vs 5\u00a2 originally) in Round 3.", "labels": [], "entities": []}, {"text": "To avoid inaccurate ratings, we rejected submissions that were improbably quick or were strongly uncorrelated with other Turkers' responses.", "labels": [], "entities": []}, {"text": "We collected five Turkers' ratings for each set of factoids, and for each persons' response to a HIT computed the average of their three highest correlations with others' responses.", "labels": [], "entities": []}, {"text": "We then rejected if the correlations were so low as to indicate random responses.", "labels": [], "entities": []}, {"text": "The scores serve a second purpose of identifying a more trustworthy subset of the responses.", "labels": [], "entities": []}, {"text": "(A cut-off score of 0.3 was chosen based on hand-examination.)", "labels": [], "entities": [{"text": "cut-off score", "start_pos": 3, "end_pos": 16, "type": "METRIC", "confidence": 0.9534674882888794}]}, {"text": "In, we can see that these more strongly correlated responses rate factoids as slightly worse overall, possibly because those who either casual or uncertain are more likely to judge favorably on the assumption that this is what the task authors would prefer, or they are simply more likely to select the top-most option, which was \"I agree\".", "labels": [], "entities": []}, {"text": "An example of a factoid that was labeled incorrectly by one of the filtered out users is 'A PER-SON MAY LOOK AT SOME THING-REFERRED-TO OF PRESS RELEASES', for which a Turker from Madras in Round 1 selected \"I agree\".", "labels": [], "entities": [{"text": "A PER-SON MAY LOOK AT SOME THING-REFERRED-TO OF PRESS RELEASES", "start_pos": 90, "end_pos": 152, "type": "METRIC", "confidence": 0.8175037682056427}]}, {"text": "Factoids containing the vague 'THING-REFERRED-TO' are often filtered out of our results automatically, but leaving them in gave us some obviously bad inputs for checking Turkers' responses.", "labels": [], "entities": [{"text": "THING-REFERRED-TO", "start_pos": 31, "end_pos": 48, "type": "METRIC", "confidence": 0.9798035621643066}]}, {"text": "Another (US) Turker chose \"I agree\" when told 'TES MAY HAVE 1991ES' but \"I disagree\" when shown 'A TRIP CAN BE TO A SUPERMARKET'.", "labels": [], "entities": [{"text": "TES MAY HAVE 1991ES", "start_pos": 47, "end_pos": 66, "type": "METRIC", "confidence": 0.8275042325258255}, {"text": "A TRIP CAN BE TO A", "start_pos": 97, "end_pos": 115, "type": "METRIC", "confidence": 0.7364239444335302}]}, {"text": "We are interested not only in whether there is a general consensus to be found among the Turkers but also how that consensus correlates with the judgements of AI researchers.", "labels": [], "entities": []}, {"text": "To this end, one of the authors rated five sets (100 factoids) presented in Round 3, which yielded an average correlation between all the Turkers and the author of 0.507, which rises slightly to 0.532 if we only count those Turkers considered \"highly correlated\" as described above.", "labels": [], "entities": []}, {"text": "As another test of agreement, for ten of the sets in Round 3, two factoids were designated as fixpointsthe single best and worst factoid in the set, assigned ratings 1 and 5 respectively.", "labels": [], "entities": []}, {"text": "From the Turkers who rated these factoids, 65 of the 100 ratings matched the researchers' designations and 77 were within one point of the chosen rating.", "labels": [], "entities": [{"text": "Turkers", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.858704686164856}]}, {"text": "A few of the Turkers who participated had fairly strong negative correlations to the other Turkers, suggesting that they may have misunderstood the task and were rating backwards.", "labels": [], "entities": []}, {"text": "Furthermore, one Turker commented that she was unsure whether the statement she was being asked to agree with ( \"was a positive or negative\".", "labels": [], "entities": []}, {"text": "To see how it would affect the results, we ran (as Round 4) twenty sets of factoids, asking simplified question \"Do you agree this is a good statement of general knowledge?\"", "labels": [], "entities": []}, {"text": "The choices were also reversed in order, running from \"I disagree\" to \"I agree\" and color-coded, with agree being green and disagree red.", "labels": [], "entities": []}, {"text": "This corresponded to the coloring of the good and bad examples at the top of the page, which the Turkers were told to reread when they were halfway through the HIT.", "labels": [], "entities": [{"text": "HIT", "start_pos": 160, "end_pos": 163, "type": "DATASET", "confidence": 0.8255078792572021}]}, {"text": "The average correlation for responses in Round 4 was 0.47, which is an improvement over the 0.34 avg.", "labels": [], "entities": [{"text": "correlation", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9685214161872864}]}, {"text": "Using the same format as Round 4, we ran factoids from two other corpora.", "labels": [], "entities": []}, {"text": "Round 6 consisted of 300 random factoids taken from running KNEXT on weblog data () and Round 7 300 random factoids taken from running KNEXT on Wikipedia.", "labels": [], "entities": []}, {"text": "The average ratings for factoids from these sources are lower than for the BNC, reflecting the noisy nature of much writing on weblogs and the many overly specific or esoteric factoids learned from Wikipedia.", "labels": [], "entities": [{"text": "BNC", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8528617024421692}]}, {"text": "The results achieved can be quite sensitive to the display of the task.", "labels": [], "entities": []}, {"text": "For instance, the frequency of ratings in shows that Turkers tended toward the extremes: \"I agree\" and \"I disagree\" but rarely \"I'm not sure\".", "labels": [], "entities": [{"text": "frequency", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9617829322814941}]}, {"text": "This option might have a negative connotation (\"Waffling is undesirable\") that another phrasing would not.", "labels": [], "entities": []}, {"text": "As an alternative presentation of the task (Round 5), for 300 factoids, we asked Turkers to first decide whether a factoid was \"incoherent (not understandable)\" and, otherwise, whether it was \"bad\", \"not very good\", \"so-so\", \"not so bad\", or \"good\" commonsense knowledge.", "labels": [], "entities": []}, {"text": "Turkers indicated factoids were incoherent 14% of the time, with a corresponding reduction in the number rated as \"bad\", but no real increase in middle ratings.", "labels": [], "entities": [{"text": "middle ratings", "start_pos": 145, "end_pos": 159, "type": "METRIC", "confidence": 0.9587990939617157}]}, {"text": "The average ratings for the \"coherent\" factoids are in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average ratings for all responses and for highly  correlated responses. to other responses. Lower numbers  are more positive. Round 2 was withdrawn without being  completed.", "labels": [], "entities": []}]}