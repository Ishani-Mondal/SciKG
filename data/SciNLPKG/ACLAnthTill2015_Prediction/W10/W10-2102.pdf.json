{"title": [], "abstractContent": [{"text": "Evidentiality is the linguistic representation of the nature of evidence fora statement.", "labels": [], "entities": []}, {"text": "In other words, it is the linguistically encoded evidence for the trustworthiness of a statement.", "labels": [], "entities": []}, {"text": "In this paper, we aim to explore how linguistically encoded information of eviden-tiality can contribute to the prediction of trustworthiness in natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 145, "end_pos": 178, "type": "TASK", "confidence": 0.6347420513629913}]}, {"text": "We propose to incorporate evidential-ity into a framework of machine learning based text classification.", "labels": [], "entities": [{"text": "machine learning based text classification", "start_pos": 61, "end_pos": 103, "type": "TASK", "confidence": 0.6391966283321381}]}, {"text": "We first construct a taxonomy of evidentials.", "labels": [], "entities": []}, {"text": "Then experiments involving collaborative question answering (CQA) are designed and implemented using this taxonomy.", "labels": [], "entities": [{"text": "question answering (CQA)", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.8264229774475098}]}, {"text": "The experimental results confirm that evidentiality is an important clue for text trustworthiness detection.", "labels": [], "entities": [{"text": "text trustworthiness detection", "start_pos": 77, "end_pos": 107, "type": "TASK", "confidence": 0.8292974432309469}]}, {"text": "With the bi-narized vector setting, evidential based text representation model has considerably per-formaned better than both the bag-of-word model and the content word based model.", "labels": [], "entities": []}, {"text": "Most crucially, we show that the best trust-worthiness detection result is achieved when evidentiality is incorporated in a linguistically sophisticated model where their meanings are interpreted in both semantic and pragmatic terms.", "labels": [], "entities": [{"text": "trust-worthiness detection", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.6987712681293488}]}], "introductionContent": [{"text": "With the exponential increase in web sites and documents, the amount of information is no longer a main concern for automatic knowledge acquisition.", "labels": [], "entities": [{"text": "automatic knowledge acquisition", "start_pos": 116, "end_pos": 147, "type": "TASK", "confidence": 0.6143437127272288}]}, {"text": "This trend raises, however, at least two new issues.", "labels": [], "entities": []}, {"text": "The first is how to locate the information which exactly meets our needs among the vast web content.", "labels": [], "entities": []}, {"text": "Efforts to address this issue can be exemplified by advanced research in information retrieval, information extraction, etc.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.8275105655193329}, {"text": "information extraction", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.8452158570289612}]}, {"text": "The second is how to judge the validity of the acquired information, that is, the trustworthiness of information.", "labels": [], "entities": []}, {"text": "This issue has attracted considerable interest in some related research areas recently.", "labels": [], "entities": []}, {"text": "Taking the specific information retrieval task, question answering (QA) as an example, a QA system attempts to retrieve the most appropriate answers to questions from web resources.", "labels": [], "entities": [{"text": "information retrieval task", "start_pos": 20, "end_pos": 46, "type": "TASK", "confidence": 0.78424072265625}, {"text": "question answering (QA)", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.8495184421539307}]}, {"text": "To determine the trustworthiness of the extracted candidate answers, a common approach is to exploit the cooccurrence frequency of questions and candidate answers.", "labels": [], "entities": []}, {"text": "That is, if a candidate answer co-occurs more frequently with the question than other candidates, the QA system may judge it as the best answer).", "labels": [], "entities": []}, {"text": "This approach presupposes and relies crucially on information redundancy.", "labels": [], "entities": [{"text": "information redundancy", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7319810688495636}]}, {"text": "Although this heuristic method is simple and straightforward, it is not applicable to all cases.", "labels": [], "entities": []}, {"text": "For the applications which don't involve much information redundancy, the heuristic could cease to be effective.", "labels": [], "entities": [{"text": "information redundancy", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.7178616225719452}]}, {"text": "The task of collaborative question answering (CQA) which we will address in this paper is just one of such examples.", "labels": [], "entities": [{"text": "question answering (CQA)", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.8420097708702088}]}, {"text": "For a user posted question, there are usually only few answers provided.", "labels": [], "entities": []}, {"text": "So, the heuristic is not useful in providing the best answer.", "labels": [], "entities": []}, {"text": "In addition, since the spread of unsubstantiated rumors on the Internet is so pervasive, the highfrequency information on the Web sometimes may mislead the judgment of trustworthiness.", "labels": [], "entities": []}, {"text": "In terms of the above consideration, it is essential to look for other approaches which allow directly modeling of the trustworthiness of a text.", "labels": [], "entities": []}, {"text": "Given that non-textual features (such as user's Web behavior) used in text trustworthiness detection are often manipulated by information providers, as well as no directly related textual features for the task has been proposed up to date, we need a more felicitous model for detecting the trustworthiness of statements.", "labels": [], "entities": [{"text": "text trustworthiness detection", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.6895036896069845}]}, {"text": "Noting that evidentiality is often linguistically encoded and hence provides inherent information on trustworthiness fora statement, we propose to incorporate the linguistic model of evidentiality in our study.", "labels": [], "entities": []}, {"text": "Specifically, we incorporate evidentiality into a machine learning based text classification framework, and attempt to verify the validity of evidentiality in trustworthiness prediction of text information in the context of collaborative question answering.", "labels": [], "entities": [{"text": "text classification", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7014677077531815}, {"text": "trustworthiness prediction of text information", "start_pos": 159, "end_pos": 205, "type": "TASK", "confidence": 0.8140894532203674}, {"text": "question answering", "start_pos": 238, "end_pos": 256, "type": "TASK", "confidence": 0.7282165139913559}]}, {"text": "The experimental results show that evidentials are important clues in predicting the trustworthiness of text.", "labels": [], "entities": []}, {"text": "Since none of the task-specific heuristics has been incorporated, the current approach could also be easily adapted to fit other natural language processing applications.", "labels": [], "entities": []}, {"text": "The paper proceeds as follows.", "labels": [], "entities": []}, {"text": "In section 2 we discuss related work on text trustworthiness detection.", "labels": [], "entities": [{"text": "text trustworthiness detection", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.838340143362681}]}, {"text": "The section is divided into two parts: the current methodology and the textual features for analysis in the task.", "labels": [], "entities": []}, {"text": "Section 3 introduces the linguistic researches on evidentiality and our taxonomy of evidentials based on the trustworthiness indication.", "labels": [], "entities": []}, {"text": "Section 4 presents the experiment settings and results.", "labels": [], "entities": []}, {"text": "Finally, in section 5 we discuss the experiment results and conclude the current research.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the experiments, we use the snapshot of Yahoo!", "labels": [], "entities": [{"text": "snapshot of Yahoo!", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.7067355662584305}]}, {"text": "Answers dataset which is crawled by Emory University . Since our experiments only involve text features, we use the answer parts from it without considering the question sets and user profiles.", "labels": [], "entities": [{"text": "Answers dataset", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.6934046447277069}, {"text": "Emory University", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.9796226322650909}]}, {"text": "Such information could be incorporated to achieve a higher performance in the future.", "labels": [], "entities": []}, {"text": "With regard to the text classification problems, there is typically a substantial class distribution skew.", "labels": [], "entities": [{"text": "text classification", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8043870031833649}]}, {"text": "Answers dataset, a question only has one best answer and accordingly all the other answers will be marked as non-best answers.", "labels": [], "entities": [{"text": "Answers dataset", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.7597671747207642}]}, {"text": "Thus the class of best answer contains much fewer texts than the class of non-best answers.", "labels": [], "entities": []}, {"text": "In our dataset (a proportion of the overall CQA dataset provided by Emory University), the number of best answers is 2,165, and the number of non-best answers is 17,654.", "labels": [], "entities": [{"text": "CQA dataset", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.9667475819587708}, {"text": "Emory University", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.9726783931255341}]}, {"text": "The proportion of the size of the two answer sets is around 1:8.15, showing a significant skews.", "labels": [], "entities": []}, {"text": "For a better comparison of experimental results, we use a balanced dataset which is generated from a normal distribution dataset.", "labels": [], "entities": []}, {"text": "A 10-fold validation is used for the evaluation, where the datasets of best and non-best answers are divided into 10 subsets of approximately equal size respectively.", "labels": [], "entities": []}, {"text": "In the normally distributed dataset, we use one of the ten subsets as the test set, while the other nine are combined together to from the training set.", "labels": [], "entities": []}, {"text": "In the balanced dataset, for each subset of the non-best answers, we only use the first k answers, in which k is the size of each subset of best answers.", "labels": [], "entities": []}, {"text": "The training data and test data used in the machine learning process are shown in  To conduct a machine learning based classification for best answers and non-best answers, we first need to construct the feature vectors.", "labels": [], "entities": []}, {"text": "The representation of text is the core issue in the ma-3 http://ir.mathcs.emory.edu/shared chine learning model for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7719579637050629}]}, {"text": "In text domains, feature selection plays an essential role to make the learning task efficient and more accurate.", "labels": [], "entities": []}, {"text": "As the baseline comparison, we use the following feature vector settings.", "labels": [], "entities": []}, {"text": "\u00b7Baseline1 represents using all the words in the text as features (when the frequency of the word in the dataset is bigger than a predefined threshold j).", "labels": [], "entities": []}, {"text": "\u00b7 Baseline2 represents using all the content words (here we include the four main categories of content words -nouns, verbs, adjectives and adverbs identified by a POS tagger) in the dataset as features.", "labels": [], "entities": []}, {"text": "We use both the above two baselines.", "labels": [], "entities": []}, {"text": "The bag-of-word model of Baseline1 is a conventional method in text representation.", "labels": [], "entities": [{"text": "text representation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7648098170757294}]}, {"text": "However, since not all the words are linguistically significant, in Baseline2, we consider only the content words in the dataset, since content words convey the core meaning of a sentence.", "labels": [], "entities": []}, {"text": "For the evidentiality-based classification, we adopt the following feature vector settings.", "labels": [], "entities": [{"text": "evidentiality-based classification", "start_pos": 8, "end_pos": 42, "type": "TASK", "confidence": 0.8187945783138275}]}, {"text": "\u00b7Evidential represents using all the evidentials in text as features.", "labels": [], "entities": []}, {"text": "\u00b7Evidential' represents using all the evidentials except for those in the category of Moderate as features.", "labels": [], "entities": []}, {"text": "\u00b7Evid.cat4 represents using the four evidentiality categories of Absolute, High, Moderate and Low from.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9659280776977539}]}, {"text": "\u00b7Evid.cat2 represents using the two categories of Absolute and High as the positive evidential and Moderate and Low as the negative evidential.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9721460938453674}, {"text": "Moderate", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9749417901039124}]}, {"text": "\u00b7Evid.cat2' omits the evidential category of Moderate, and represents using the two categories of Absolute and High as the positive evidential and only the category of Low as the negative evidential feature.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9218124151229858}]}, {"text": "Some researchers have proved that usually a Boolean indicator of whether the feature item occurred in the document is sufficient for classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 133, "end_pos": 147, "type": "TASK", "confidence": 0.969411313533783}]}, {"text": "Although there are also some other feature weighting schemes such as term frequency (TF), document frequency (DF), etc, comparison of these different weighting schemes is not the object of the current research.", "labels": [], "entities": [{"text": "term frequency (TF)", "start_pos": 69, "end_pos": 88, "type": "METRIC", "confidence": 0.9184219360351562}, {"text": "document frequency (DF)", "start_pos": 90, "end_pos": 113, "type": "METRIC", "confidence": 0.8570886254310608}]}, {"text": "So in this paper, we only consider Boolean weighting.", "labels": [], "entities": [{"text": "Boolean weighting", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.4785204231739044}]}, {"text": "In the Boolean text representation model, each feature represents the Boolean occurrence of a word, evidential, or evidential category according to the different feature settings.", "labels": [], "entities": [{"text": "Boolean text representation", "start_pos": 7, "end_pos": 34, "type": "TASK", "confidence": 0.6979236205418905}]}, {"text": "By the experimental settings, we want to verify the hypothesis that incorporating the knowledge of evidentiality into text representation can lead to improvement in classification performance.", "labels": [], "entities": []}, {"text": "In our experiment, we perform text preprocessing including word segmentation and part-ofspeech (POS) tagging.", "labels": [], "entities": [{"text": "text preprocessing", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.719281405210495}, {"text": "word segmentation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7367528080940247}, {"text": "part-ofspeech (POS) tagging", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6002933263778687}]}, {"text": "The Stanford Log-linear Part-Of-Speech Tagger (http://nlp.stanford.edu/ software/tagger.shtml) is used for POS tagging.", "labels": [], "entities": [{"text": "Log-linear Part-Of-Speech Tagger", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.6166485647360483}, {"text": "POS tagging", "start_pos": 107, "end_pos": 118, "type": "TASK", "confidence": 0.9416176080703735}]}, {"text": "We adopt support vector machine (SVM) as the machine learning model to classify best answers from non-best ones, and use the SVMlight package (http://svmlight.joachims.org) as the classifier with the default parameters and a linear kernel.", "labels": [], "entities": []}, {"text": "For the evaluation, we use the metrics of precision (Prec. as in table 3), recall (Rec. as in table 3), accuracy (Acc.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9994000196456909}, {"text": "Prec.", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.8913076519966125}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9995406866073608}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9994193315505981}, {"text": "Acc", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.9750295281410217}]}, {"text": "as in table 3) and F1: F 1 -measure, the harmonic mean of the precision and recall.", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9994701743125916}, {"text": "F 1 -measure", "start_pos": 23, "end_pos": 35, "type": "METRIC", "confidence": 0.9767477810382843}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.99925297498703}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9979605674743652}]}, {"text": "shows the experimental results using the balanced dataset with Boolean weighting.", "labels": [], "entities": []}, {"text": "The focus of the experiment evaluation is on identifying the best answers, so the evaluation metrics are all for the best answers collection.", "labels": [], "entities": []}, {"text": "From the table, we see increases of the two feature vector setting of evidentials over both baseline results.", "labels": [], "entities": []}, {"text": "The highest improvement is 14.85%, achieved by the feature set of Evidential'.", "labels": [], "entities": [{"text": "feature set of Evidential'", "start_pos": 51, "end_pos": 77, "type": "DATASET", "confidence": 0.7912334382534028}]}, {"text": "However, there is no increase found in the settings of using evidential categories.", "labels": [], "entities": []}, {"text": "This means that although the category of evidentials in indicating text trustworthiness is obvious for human, it is not necessary a preferred feature for machine learning.", "labels": [], "entities": []}, {"text": "To eliminate the potential effect of term weighting scheme on performance trend among different text representation models, we also conduct experiments using TF weighting.", "labels": [], "entities": []}, {"text": "By the experiments, we aim to compare the relative performances of different feature vectors constructed with evidentials, and the results are demonstrated in  From the table, it can be observed that using evidentials as features shows better improvement in the performance than the category of evidentials as a feature.", "labels": [], "entities": []}, {"text": "A similar performance has been summarized in.", "labels": [], "entities": []}, {"text": "Finally, but not the least, to better understand the effect of evidential category on the machine learning performance, we design additional experiments as follows.", "labels": [], "entities": []}, {"text": "\u00b7Evid_cat1 stands for combining the four evidential categories into one, and uses only this one category of evidential as a feature.", "labels": [], "entities": []}, {"text": "The approach of Boolean weighting is actually the same as a rule-based approach that classifies the test dataset according to whether evidential occurs or not.", "labels": [], "entities": [{"text": "Boolean weighting", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.6238377690315247}]}], "tableCaptions": [{"text": " Table 2. The Dataset Used for the Experiments", "labels": [], "entities": []}, {"text": " Table 3. Experimental Results Using the Bal- anced Training/Test Dataset (with Boolean  Weighting)", "labels": [], "entities": [{"text": "Bal- anced Training/Test Dataset", "start_pos": 41, "end_pos": 73, "type": "DATASET", "confidence": 0.7180918114525932}, {"text": "Boolean  Weighting", "start_pos": 80, "end_pos": 98, "type": "METRIC", "confidence": 0.8619653284549713}]}, {"text": " Table 4. Experimental Results Using the Bal- anced Training/Test Dataset (with TF Weighting)", "labels": [], "entities": [{"text": "Bal- anced Training/Test Dataset", "start_pos": 41, "end_pos": 73, "type": "DATASET", "confidence": 0.6567432624953133}, {"text": "TF Weighting", "start_pos": 80, "end_pos": 92, "type": "METRIC", "confidence": 0.9059427082538605}]}]}