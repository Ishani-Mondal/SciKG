{"title": [], "abstractContent": [], "introductionContent": [{"text": "There are two main approaches toward automatically producing dialogue utterances.", "labels": [], "entities": []}, {"text": "One is the selection approach, in which the task is to pick the appropriate output from a corpus of possible outputs.", "labels": [], "entities": []}, {"text": "The other is the generation approach, in which the output is dynamically assembled using some composition procedure, e.g. grammar rules used to convert information from semantic representations and/or context to text.", "labels": [], "entities": []}, {"text": "The generation approach has the advantage of a more compact representation fora given generative capacity.", "labels": [], "entities": []}, {"text": "But for any finite set of sentences produced, the selection approach could perfectly simulate the generation approach.", "labels": [], "entities": []}, {"text": "The generation approach generally requires more analytical effort to devise a good set of grammar rules that cover the range of desired sentences but do not admit undesirable or unnatural sentences.", "labels": [], "entities": []}, {"text": "Whereas, in the selection approach, outputs can be limited to those that have been observed inhuman speech.", "labels": [], "entities": []}, {"text": "This affords complex and human-like sentences without much detailed analysis.", "labels": [], "entities": []}, {"text": "Moreover, when the output is not just text but presented as speech, the system may easily use recorded audio clips rather than speech synthesis.", "labels": [], "entities": []}, {"text": "This argument also extends to multi-modal performances, e.g. using artist animation motion capture or recorded video for animating virtual human dialogue characters.", "labels": [], "entities": []}, {"text": "Often one is willing to sacrifice some generality in order to achieve more human-like behavior than is currently possible from generation approaches.", "labels": [], "entities": []}, {"text": "The selection approach has been used fora number of dialogue agents, including questionanswering characters at ICT (, FAQ bots () and web-site information characters.", "labels": [], "entities": []}, {"text": "It is also possible to use the selection approach as apart of the process, e.g. from words to a semantic representation or from a semantic representation to words, while using other approaches for other parts of dialogue processing.", "labels": [], "entities": []}, {"text": "The selection approach presents two challenges for finding an appropriate utterance: \u2022 Is there a good enough utterance to select?", "labels": [], "entities": []}, {"text": "\u2022 How good is the selection algorithm at finding this utterance?", "labels": [], "entities": []}, {"text": "We have previously attempted to address the second question, by proposing the information ordering task for evaluating dialogue coherence (.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.6963473260402679}]}, {"text": "Here we try to address the first question, which would provide a theoretical upper bound in quality for any selection approach.", "labels": [], "entities": []}, {"text": "We examine a number of different dialogue corpora as to their suitability for the selection approach.", "labels": [], "entities": []}, {"text": "We make the following assumptions to allow automatic evaluation across a range of corpora.", "labels": [], "entities": []}, {"text": "Actual human dialogues represent a gold-standard for computer systems to emulate; i.e. choosing an actual utterance in the correct place is the best possible result.", "labels": [], "entities": []}, {"text": "Other utterances can be evaluated as to how close they come to the original utterance, using a similarity metric.", "labels": [], "entities": []}, {"text": "Our methodology is to examine a test corpus of human dialogue utterances to see how well a selection approach could approximate these, given a training corpus of utterances in that domain.", "labels": [], "entities": []}, {"text": "We look at exact matches as well as utterances having their similarity score above a threshold.", "labels": [], "entities": []}, {"text": "We investigate the effect of the size of training corpora, which lets us know how much data we might need to achieve a certain level of performance.", "labels": [], "entities": []}, {"text": "We also investigate the effect of domain of training corpora.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Corpus details and within domain results", "labels": [], "entities": []}, {"text": " Table 2: Mean of maxsim M eteor for comparing different dialogue domains. The bold-faced values are  the highest in the corresponding row.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9925777316093445}]}]}