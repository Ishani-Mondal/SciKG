{"title": [{"text": "Improved Language Modeling for English-Persian Statistical Machine Translation", "labels": [], "entities": [{"text": "Improved Language Modeling", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9067733883857727}, {"text": "Statistical Machine Translation", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.6521112223466238}]}], "abstractContent": [{"text": "As interaction between speakers of different languages continues to increase, the ever-present problem of language barriers must be overcome.", "labels": [], "entities": []}, {"text": "For the same reason, automatic language translation (Machine Translation) has become an attractive area of research and development.", "labels": [], "entities": [{"text": "automatic language translation (Machine Translation)", "start_pos": 21, "end_pos": 73, "type": "TASK", "confidence": 0.7043397384030479}]}, {"text": "Statistical Machine Translation (SMT) has been used for translation between many language pairs, the results of which have shown considerable success.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8171004056930542}]}, {"text": "The focus of this research is on the English/Persian language pair.", "labels": [], "entities": []}, {"text": "This paper investigates the development and evaluation of the performance of a statistical machine translation system by building a baseline system using subtitles from Persian films.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.6348729133605957}]}, {"text": "We present an overview of previous related work in English/Persian machine translation, and examine the available corpora for this language pair.", "labels": [], "entities": [{"text": "English/Persian machine translation", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.6024557411670685}]}, {"text": "We finally show the results of the experiments of our system using an in-house corpus and compare the results we obtained when building a language model with different sized monolingual corpora.", "labels": [], "entities": []}, {"text": "Different automatic evaluation metrics like BLEU, NIST and IBM-BLEU were used to evaluate the performance of the system on half of the corpus built.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9976943135261536}, {"text": "NIST", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.8224155306816101}, {"text": "IBM-BLEU", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.5440832376480103}]}, {"text": "Finally, we look at future work by outlining ways of getting highly accurate translations as fast as possible.", "labels": [], "entities": [{"text": "translations", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.9369697570800781}]}], "introductionContent": [{"text": "Over the 20 th century, international interaction, travel and business relationships have increased enormously.", "labels": [], "entities": []}, {"text": "With the entrance of the World Wide Web effectively connecting countries together over a giant network, this interaction reached anew peak.", "labels": [], "entities": []}, {"text": "In the area of business and commerce, the vast majority of companies simply would notwork without this global connection.", "labels": [], "entities": []}, {"text": "However, with this vast global benefit comes a global problem: the language barrier.", "labels": [], "entities": []}, {"text": "As the international connection barriers continually breakdown, the language barrier becomes a greater issue.", "labels": [], "entities": []}, {"text": "The English language is now the world's lingua franca, and nonEnglish speaking people are faced with the problem of communication, and limited access to resources in English.", "labels": [], "entities": []}, {"text": "Machine translation is the process of using computers for translation from one human language to another.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7974419593811035}]}, {"text": "This is not a recent area of research and development.", "labels": [], "entities": []}, {"text": "In fact, machine translation was one of the first applications of natural language processing, with research work dating back to the 1950s.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.8197501003742218}, {"text": "natural language processing", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6483995219071707}]}, {"text": "However, due to the complexity and diversity of human language, automated translation is one of the hardest problems in computer science, and significantly successful results are uncommon.", "labels": [], "entities": [{"text": "automated translation", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.6577952206134796}]}, {"text": "There area number of different approaches to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7879477739334106}]}, {"text": "Statistical Machine Translation (SMT) however, seems to be the preferred approach of many industrial and academic research laboratories.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8739396830399832}]}, {"text": "The advantages of SMT compared to rule-based approaches lie in their adaptability to different domains and languages: once a functional", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9877945184707642}]}], "datasetContent": [{"text": "We used Moses a phrase-based SMT development tool for constructing our machine translation system.", "labels": [], "entities": [{"text": "SMT development", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.9237669408321381}, {"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7458742558956146}]}, {"text": "This included n-gram language models trained with the SRI language modeling tool, GIZA++ alignment tool, Moses decoder and the script to induce phrase-based translation models from word-based ones.", "labels": [], "entities": [{"text": "SRI language modeling", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.6389283041159312}, {"text": "GIZA++ alignment", "start_pos": 82, "end_pos": 98, "type": "TASK", "confidence": 0.6565501987934113}, {"text": "phrase-based translation", "start_pos": 144, "end_pos": 168, "type": "TASK", "confidence": 0.6665411591529846}]}, {"text": "A lot of research has been done in the field of automatic machine translation evaluation.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.8043346405029297}]}, {"text": "Human evaluations of machine translation are extensive but expensive.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7974711358547211}]}, {"text": "Human evaluations can take months to finish and involve human labor that cannot be reused which is the main idea behind the method of automatic machine translation evaluation that is quick, inexpensive, and language independent.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 144, "end_pos": 174, "type": "TASK", "confidence": 0.7695816854635874}]}, {"text": "One of the most popular metrics is called BLEU (BiLingual Evaluation Understudy) developed at IBM.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9980385899543762}]}, {"text": "The closer a MT is to a professional human translation, the better it is.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9856688976287842}]}, {"text": "This is the central idea behind the BLEU metric.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.8482570052146912}]}, {"text": "NIST is another automatic evaluation metric with the following primary differences compared to BLEU such as Text pre-processing, gentler length penalty, information-weighted Ngram counts and selective use of N-grams;).", "labels": [], "entities": [{"text": "NIST", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9496997594833374}, {"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9831621646881104}, {"text": "gentler length penalty", "start_pos": 129, "end_pos": 151, "type": "METRIC", "confidence": 0.9345030387242635}, {"text": "information-weighted Ngram counts", "start_pos": 153, "end_pos": 186, "type": "METRIC", "confidence": 0.6071975926558176}]}], "tableCaptions": [{"text": " Table 1. Size of test set and train set (language  Model) En: English, FA: Farsi", "labels": [], "entities": [{"text": "FA", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.9624477624893188}]}, {"text": " Table 2. Result obtained using Language Model  size=864", "labels": [], "entities": []}, {"text": " Table 3. Result obtained using Language Model  size=1066", "labels": [], "entities": []}, {"text": " Table 4. Result obtained using Language Model  size=7005", "labels": [], "entities": []}]}