{"title": [{"text": "The Parameter-optimized ATEC Metric for MT Evaluation", "labels": [], "entities": [{"text": "Parameter-optimized", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.6723533272743225}, {"text": "ATEC", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.4018702507019043}, {"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9875897169113159}]}], "abstractContent": [{"text": "This paper describes the latest version of the ATEC metric for automatic MT evaluation, with parameters optimized for word choice and word order, the two fundamental features of language that the metric relies on.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.9675067067146301}]}, {"text": "The former is assessed by matching at various linguistic levels and weighting the informa-tiveness of both matched and unmatched words.", "labels": [], "entities": []}, {"text": "The latter is quantified in term of word position and information flow.", "labels": [], "entities": []}, {"text": "We also discuss those aspects of language not yet covered by other existing evaluation metrics but carefully considered in the formulation of our metric.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is recognized that the proposal of the BLEU metric () has piloted a paradigm evolution to MT evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9923765063285828}, {"text": "MT evaluation", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.9543832242488861}]}, {"text": "It provides a computable solution to the task and turns it into an engineering problem of measuring text similarity and simulating human judgments of translation quality.", "labels": [], "entities": []}, {"text": "Related studies in recent years have extensively revealed more essential characteristics of BLEU, including its strengths and weaknesses.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.7799619436264038}]}, {"text": "This has aroused the proposal of different new evaluation metrics aimed at addressing such weaknesses so as to find some other hopefully better alternatives for the task.", "labels": [], "entities": []}, {"text": "Effort in this direction brings up some advanced metrics such as METEOR () and TERp () that seem to have already achieved considerably strong correlations with human judgments.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9652072191238403}, {"text": "TERp", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9964966177940369}]}, {"text": "Nevertheless, few metrics have really nurtured our understanding of possible parameters involved in our language comprehension and text quality judgment.", "labels": [], "entities": [{"text": "text quality judgment", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.6895404855410258}]}, {"text": "This inadequacy limits, inevitably, the application of the existing metrics.", "labels": [], "entities": []}, {"text": "The ATEC metric) was developed as a response to this inadequacy, with a focus to account for the process of human comprehension of sentences via two fundamental features of text, namely word choice and word order.", "labels": [], "entities": [{"text": "ATEC", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9129469990730286}]}, {"text": "It integrates various explicit measures for these two features in order to provide an intuitive and informative evaluation result.", "labels": [], "entities": []}, {"text": "Its previous version) has already illustrated a highly comparable performance to the few state-of-the-art evaluation metrics, showing a great improvement over its initial version for participation in MetricsMATR08 . It is also applied to evaluate online MT systems for legal translation, to examine its applicability for lay users' use to select appropriate MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 254, "end_pos": 256, "type": "TASK", "confidence": 0.9721384644508362}, {"text": "legal translation", "start_pos": 269, "end_pos": 286, "type": "TASK", "confidence": 0.78631591796875}, {"text": "MT", "start_pos": 358, "end_pos": 360, "type": "TASK", "confidence": 0.9737563133239746}]}, {"text": "In this paper we describe the formulation of ATEC, including its new features and optimization of parameters.", "labels": [], "entities": [{"text": "ATEC", "start_pos": 45, "end_pos": 49, "type": "TASK", "confidence": 0.48022687435150146}]}, {"text": "In particular we will discuss how the design of this metric can complement the inadequacies of other metrics in terms of its treatment of word choice and word order and its utilization of multiple references in the evaluation process.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}