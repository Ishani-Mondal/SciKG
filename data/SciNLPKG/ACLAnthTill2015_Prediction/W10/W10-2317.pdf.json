{"title": [{"text": "Computing Word Senses by Semantic Mirroring and Spectral Graph Partitioning", "labels": [], "entities": [{"text": "Computing Word Senses", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7094223201274872}, {"text": "Spectral Graph Partitioning", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.7957870165506998}]}], "abstractContent": [{"text": "Using the technique of \"semantic mirror-ing\" a graph is obtained that represents words and their translations from a parallel corpus or a bilingual lexicon.", "labels": [], "entities": []}, {"text": "The con-nectedness of the graph holds information about the different meanings of words that occur in the translations.", "labels": [], "entities": []}, {"text": "Spectral graph theory is used to partition the graph, which leads to a grouping of the words according to different senses.", "labels": [], "entities": [{"text": "Spectral graph theory", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7474503517150879}]}, {"text": "We also report results from an evaluation using a small sample of seed words from a lexicon of Swedish and English adjectives.", "labels": [], "entities": []}], "introductionContent": [{"text": "A great deal of linguistic knowledge is encoded implicitly in bilingual resources such as parallel texts and bilingual dictionaries.) has provided a knowledge discovery method based on the semantic relationship between words in a source language and words in a target language, as manifested in parallel texts.", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.7296753525733948}]}, {"text": "His method is called Semantic mirroring and the approach utilizes the way that different languages encode lexical meaning by mirroring source words and target words back and forth, in order to establish semantic relations like synonymy and hyponymy.", "labels": [], "entities": [{"text": "Semantic mirroring", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.9091102480888367}]}, {"text": "Work in this area is strongly related to work within Word Sense Disambiguation (WSD) and the observation that translations area good source for detecting such distinctions.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.7660263379414877}]}, {"text": "A word that has multiple meanings in one language is likely to have different translations in other languages.", "labels": [], "entities": []}, {"text": "This means that translations serve as sense indicators fora particular source word, and make it possible to divide a given word into different senses.", "labels": [], "entities": []}, {"text": "In this paper we propose anew graph-based approach to the analysis of semantic mirrors.", "labels": [], "entities": [{"text": "analysis of semantic mirrors", "start_pos": 58, "end_pos": 86, "type": "TASK", "confidence": 0.8038236945867538}]}, {"text": "The objective is to find a viable way to discover synonyms and group them into different senses.", "labels": [], "entities": []}, {"text": "The method has been applied to a bilingual dictionary of English and Swedish adjectives.", "labels": [], "entities": []}], "datasetContent": [{"text": "A small evaluation was performed using a random sample of 10 Swedish adjectives.", "labels": [], "entities": []}, {"text": "We generated sets under four different conditions.", "labels": [], "entities": []}, {"text": "For the first, using conductance (5).", "labels": [], "entities": []}, {"text": "For the second, using sparsity (6).", "labels": [], "entities": [{"text": "sparsity", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9735777974128723}]}, {"text": "For the third and fourth, we set the diagonal entries in the adjacency matrix to zero.", "labels": [], "entities": []}, {"text": "These entries tell us very little of how the words are connected to each other, but they may effect how the partitioning is made.", "labels": [], "entities": []}, {"text": "So for the third, we used conductance and no vertex weights, and for the fourth we used sparsity and no vertex weights.", "labels": [], "entities": []}, {"text": "There were only small differences in results due to the conditions, so we report results only for one of them, the one using vertex weights and sparsity.", "labels": [], "entities": []}, {"text": "Generated sets, with singletons removed, were evaluated from two perspectives: consistency and synonymy with the seed word.", "labels": [], "entities": [{"text": "consistency", "start_pos": 79, "end_pos": 90, "type": "METRIC", "confidence": 0.9975910186767578}]}, {"text": "For consistency a three-valued scheme was used: (i) the set forms a single synset, (ii) at least two thirds of the words form a single synset, and (iii) none of these.", "labels": [], "entities": []}, {"text": "Synonymy with the seed word was judged as either yes or no.", "labels": [], "entities": []}, {"text": "Two evaluators first judged all sets independently and then coordinated their judgements.", "labels": [], "entities": []}, {"text": "The criterion for consistency was that at least one domain, such as personality, taste, manner, can be found where all adjectives in the set are interchangeable.", "labels": [], "entities": [{"text": "consistency", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9587904214859009}]}, {"text": "Depending on how we count partially consistent groups this gives a precision in the range 0.57 to 0.78.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9991419315338135}]}, {"text": "We have made no attempt to measure recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9891926646232605}]}, {"text": "It maybe noted that group size varies.", "labels": [], "entities": []}, {"text": "There are often several small groups with just 2 or 3 words, but sometimes as many as 10-15 words makeup a group.", "labels": [], "entities": []}, {"text": "For large groups, even though they are not fully consistent, the words tend to be drawn from two or three synsets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Classified output with frequencies from  one type of partition", "labels": [], "entities": []}]}