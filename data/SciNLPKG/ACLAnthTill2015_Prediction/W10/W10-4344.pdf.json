{"title": [{"text": "Validation of a Dialog System for Language Learners", "labels": [], "entities": [{"text": "Validation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9581182599067688}]}], "abstractContent": [{"text": "In this paper we present experiments related to the validation of spoken language understanding capabilities in a language and culture training system.", "labels": [], "entities": [{"text": "validation of spoken language understanding", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.6309128046035767}]}, {"text": "In this application, word-level recognition rates are insufficient to characterize how well the system serves its users.", "labels": [], "entities": [{"text": "word-level recognition", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7358487546443939}]}, {"text": "We present the results of an annotation exercise that distinguishes instances of non-recognition due to learner error from instances due to poor system coverage.", "labels": [], "entities": []}, {"text": "These statistics give a more accurate and interesting description of system performance, showing how the system could be improved without sacrificing the instructional value of rejecting learner utterances when they are poorly formed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conversational practice in real-time dialogs with virtual humans is a compelling element of training systems for communicative competency, helping learners acquire procedural skills in addition to declarative knowledge (Johnson,).", "labels": [], "entities": []}, {"text": "Alelo's language and culture training systems allow language learners to engage in such dialogs in a serious game environment, where they practice task-based missions in new linguistic and cultural settings.", "labels": [], "entities": []}, {"text": "To support this capability, Alelo products apply a variety of spoken dialog technologies, including automatic speech recognition (ASR) and agent-based models of dialog that capture theories of politeness (, and cultural expectations).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 100, "end_pos": 134, "type": "TASK", "confidence": 0.760420044263204}]}, {"text": "To properly assess these dialog systems, we must take several issues into account.", "labels": [], "entities": []}, {"text": "First, users who interact with these systems are language learners, who can be expected occasionally to produce invalid speech, and who may benefit from the corrective signal of recognizer rejection.", "labels": [], "entities": []}, {"text": "Second, word recognition is one step in asocial simulation pipeline that allows virtual humans to respond to learner input).", "labels": [], "entities": [{"text": "word recognition", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.8754822611808777}]}, {"text": "Consequently, the system goals extend beyond word-level decoding into meaning interpretation and response planning.", "labels": [], "entities": [{"text": "meaning interpretation", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.7203686088323593}, {"text": "response planning", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7641304731369019}]}, {"text": "As a result, Word Error Rate (WER) and related metrics, such as those described by Hunt (1990) for evaluating ASR performance, are insufficient to characterize how well the speech understanding component of the dialog system performs.", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.8727226555347443}, {"text": "ASR", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.993543267250061}]}, {"text": "We need a meaningful way to account for the performance of the dialog system as a whole, which can distinguish acceptable interpretation failures from unacceptable ones.", "labels": [], "entities": []}, {"text": "We present a validation process for assessing speech understanding in dialog systems for language training applications.", "labels": [], "entities": [{"text": "assessing speech understanding", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.6760758558909098}]}, {"text": "The process involves annotation of historical user data acquired from learner interaction with the Tactical Language and Culture Training System (Johnson and Valente 2009).", "labels": [], "entities": [{"text": "Tactical Language and Culture Training System", "start_pos": 99, "end_pos": 144, "type": "DATASET", "confidence": 0.5477466185887655}]}, {"text": "The results indicate that learner mistakes makeup the majority of nonrecognitions, confirming the hypothesis that \"recognition failures\" area complex category of events that are only partly explained by lack of coverage in speech understanding components such as ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 263, "end_pos": 266, "type": "TASK", "confidence": 0.9229772686958313}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Distinguishing meaningful utterances  (corresponding to an Act) from non-meaningful  attempts (Garbage).", "labels": [], "entities": [{"text": "Distinguishing meaningful utterances", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.91867729028066}]}, {"text": " Table 2. System mis-understandings over all mea- ningful utterances.", "labels": [], "entities": []}, {"text": " Table 3. Classification of non-understandings.  Inter-annotator agreement (\u03ba) is substantial  over all classes.", "labels": [], "entities": [{"text": "Classification of non-understandings", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.857258160909017}, {"text": "Inter-annotator agreement (\u03ba)", "start_pos": 49, "end_pos": 78, "type": "METRIC", "confidence": 0.9287260293960571}]}]}