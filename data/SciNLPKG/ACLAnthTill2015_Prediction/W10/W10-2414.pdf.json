{"title": [{"text": "Classifying Wikipedia Articles into NE's using SVM's with Threshold Adjustment", "labels": [], "entities": [{"text": "Threshold Adjustment", "start_pos": 58, "end_pos": 78, "type": "METRIC", "confidence": 0.9004619419574738}]}], "abstractContent": [{"text": "In this paper, a method is presented to recognize multilingual Wikipedia named entity articles.", "labels": [], "entities": [{"text": "recognize multilingual Wikipedia named entity articles", "start_pos": 40, "end_pos": 94, "type": "TASK", "confidence": 0.6758556167284647}]}, {"text": "This method classifies multilingual Wikipedia articles using a variety of structured and unstructured features and is aided by cross-language links and features in Wikipedia.", "labels": [], "entities": []}, {"text": "Adding multilingual features helps boost classification accuracy and is shown to effectively classify multilingual pages in a language independent way.", "labels": [], "entities": [{"text": "classification", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.9479973912239075}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9384385347366333}]}, {"text": "Classification is done using Support Vectors Machine (SVM) classifier at first, and then the threshold of SVM is adjusted in order to improve the recall scores of classification.", "labels": [], "entities": [{"text": "Classification", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9421337246894836}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9989835619926453}]}, {"text": "Threshold adjustment is performed using beta-gamma threshold adjustment algorithm which is a post learning step that shifts the hyperplane of SVM.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9721141457557678}]}, {"text": "This approach boosted recall with minimal effect on precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9993409514427185}, {"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9978680610656738}]}], "introductionContent": [{"text": "Since its launch in 2001, Wikipedia has grown to be the largest and most popular knowledge base on the web.", "labels": [], "entities": []}, {"text": "The collaboratively authored content of Wikipedia has grown to include more than 13 million articles in 240 languages.", "labels": [], "entities": []}, {"text": "Of these, there are more than 3 million English articles covering a wide range of subjects, supported by 15 million discussion, disambiguation, and redirect pages.", "labels": [], "entities": []}, {"text": "Wikipedia provides a variety of structured, semi-structured and unstructured resources that can be valuable in areas such information retrieval, information extraction, and natural language processing.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 122, "end_pos": 143, "type": "TASK", "confidence": 0.7417984902858734}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.8177409768104553}, {"text": "natural language processing", "start_pos": 173, "end_pos": 200, "type": "TASK", "confidence": 0.6568589309851328}]}, {"text": "As shown in, these resources include page redirects, disambiguation pages, informational summaries (infoboxes), cross-language links between articles covering the same topic, and a 1 http://en.wikipedia.org/wiki/Wikipedia 2 http://en.wikipedia.org/wiki/Special:Statistics hierarchical tree of categories and their mappings to articles.", "labels": [], "entities": []}, {"text": "Many of the Wikipedia pages provide information about concepts and named entities (NE).", "labels": [], "entities": [{"text": "concepts and named entities (NE)", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.7684222459793091}]}, {"text": "Identifying pages that provide information about different NE's can be of great help in a variety of NLP applications such as named entity recognition, question answering, information extraction, and machine translation (.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 126, "end_pos": 150, "type": "TASK", "confidence": 0.6531586845715841}, {"text": "question answering", "start_pos": 152, "end_pos": 170, "type": "TASK", "confidence": 0.9079899489879608}, {"text": "information extraction", "start_pos": 172, "end_pos": 194, "type": "TASK", "confidence": 0.8233902156352997}, {"text": "machine translation", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.8088715076446533}]}, {"text": "This paper attempts to identify multilingual Wikipedia pages that provide information about different types of NE, namely persons, locations, and organizations.", "labels": [], "entities": []}, {"text": "The identification is done using a Support Vector Machines (SVM) classifier that is trained on a variety of Wikipedia features such as infobox attributes, tokens in text, and category links for different languages aided by crosslanguage links in pages.", "labels": [], "entities": []}, {"text": "Using features from different languages helps in two ways, namely: clues such infobox attributes may exist in one language, but not in the other, and this allows for tagging pages in multiple languages simultaneously.", "labels": [], "entities": []}, {"text": "To improve SVM classification beta-gamma threshold adjustment was used to improve recall of different NE classes and consequently overall F measure.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.8239125311374664}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9985098242759705}, {"text": "F measure", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9888213574886322}]}, {"text": "The separating hyperplane suggested by the SVM typically favors precision at the cost of recall and needs to be translated (via threshold adjustment) to tune for the desired evaluation metric.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9991294741630554}, {"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9986017346382141}]}, {"text": "Beta-gamma threshold adjustment was generally used when certain classes do not have a sufficient number of training examples, which may lead to poor SVM recall scores).", "labels": [], "entities": [{"text": "Beta-gamma threshold adjustment", "start_pos": 0, "end_pos": 31, "type": "METRIC", "confidence": 0.8862123688062032}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9750869870185852}]}, {"text": "It was used by to binary classify a set of articles and proved to improve recall with little effect on precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9993971586227417}, {"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.998289167881012}]}, {"text": "However, the technique seems to generalize beyond cases where very few training examples are present, and it is shown in this paper to yield improvements in recall and overall F-measure in the presence of hundreds of training examples, performing better than threshold adjustment using cross validation for the specific task at hand.", "labels": [], "entities": [{"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9994935989379883}, {"text": "F-measure", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9735504388809204}]}, {"text": "The contribution of this paper lies in: introducing a language independent system that utilizes multilingual features from Wikipedia articles in different languages and can be used to effectively classify Wikipedia articles written in any language to the NE classes of types person, location, and organization; and modifying betagamma threshold adjustment to improve overall classification quality even when many training examples are available.", "labels": [], "entities": [{"text": "betagamma threshold adjustment", "start_pos": 325, "end_pos": 355, "type": "METRIC", "confidence": 0.7597110470136007}]}, {"text": "The features and techniques proposed in this paper are compared to previous work in the literature.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 provides information about the structure and feature of Wikipedia; Section 3 surveys prior work on the problem; Section 4 describes the classification approach including features and threshold adjustment algorithm; Section 5 describes the datasets used for evaluation; Section 6 presents the results of the experiments; and Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The results of classifying Wikipedia articles using SVM and threshold adjustment for MAIN-E, MAIN-EM, and MAIN-M are reported in, and 5 respectively., 8, 9, and 10 report results for SUB-E, SUB-EM, SUB-M, SUB-EM+, and SUB-M+ respectively.", "labels": [], "entities": []}, {"text": "In all, n is the number of cross folds used to calculate , with n ranging between 3 and 10.", "labels": [], "entities": []}, {"text": "The first row is the baseline scores of SVM classification without threshold adjustment.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8841050267219543}]}, {"text": "The remaining rows are the scores of SVM classification after adjusting threshold.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.9261752665042877}]}, {"text": "The adjustment is performed by adding to the bias value b learned by the SVM.", "labels": [], "entities": [{"text": "bias value b learned", "start_pos": 45, "end_pos": 65, "type": "METRIC", "confidence": 0.8619190007448196}]}, {"text": "A t-test with 95% confidence (p-value < 0.05) is used to determine statistical significance.", "labels": [], "entities": []}, {"text": "For the MAIN-E dataset, SVM threshold relaxation yielded statistically significant improvement over the baseline of using an SVM directly for location named entity.", "labels": [], "entities": [{"text": "MAIN-E dataset", "start_pos": 8, "end_pos": 22, "type": "DATASET", "confidence": 0.9324349164962769}]}, {"text": "For other types of named entities improvements were not statistically significant.", "labels": [], "entities": []}, {"text": "Threshold adjustment led to statistically significant improvement for: all NE types for SUB-EM and SUB-EM+; for organizations for SUB-E and SUB-M+; and for locations and organization for SUB-EM.", "labels": [], "entities": []}, {"text": "The improvements were most pronounced when recall was very low.", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9997298121452332}]}, {"text": "For example, F1 measure for organization in the SUB-M dataset improved by 18 points due to a 26 point improvement in recall -though at the expense of precision.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9717207551002502}, {"text": "SUB-M dataset", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.8227494359016418}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9993915557861328}, {"text": "precision", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.9986792206764221}]}, {"text": "It seems that threshold adjustment tends to benefit classification more when: using smaller training sets -as is observed when comparing the results for MAIN and SUB datasets, and when classification leads to very low recall -as indicated by organization NE for SUB datasets.", "labels": [], "entities": [{"text": "MAIN and SUB datasets", "start_pos": 153, "end_pos": 174, "type": "DATASET", "confidence": 0.6294217854738235}, {"text": "recall", "start_pos": 218, "end_pos": 224, "type": "METRIC", "confidence": 0.9988083839416504}]}, {"text": "language pages with English led to improved classification with consistent improvements in precision and recall for MAIN and consistent improvements in precision for SUB.", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9993520379066467}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9981613755226135}, {"text": "MAIN", "start_pos": 116, "end_pos": 120, "type": "DATASET", "confidence": 0.7316428422927856}, {"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9990812540054321}]}, {"text": "For the SUB-M and SUB-M+ datasets, the exclusion of English led to degradation on F1 measure, with the degradation being particularly pronounced for organizations.", "labels": [], "entities": [{"text": "SUB-M+ datasets", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.6336349844932556}, {"text": "F1 measure", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9354758858680725}]}, {"text": "The drop can be attributed to the loss of much valuable training examples, because there are more English pages compared to other languages.", "labels": [], "entities": []}, {"text": "Despite the loss, proper identification of persons and locations remained high enough for many practical applications.", "labels": [], "entities": [{"text": "identification of persons and locations", "start_pos": 25, "end_pos": 64, "type": "TASK", "confidence": 0.8715185165405274}]}, {"text": "Further, the results suggest that given more training data in the other languages, the features suggested in the paper would likely yield good classification results.", "labels": [], "entities": []}, {"text": "Unlike the MAIN datasets, the inclusion of more languages for training and testing (from SUB-M to SUB-M+ & from SUB-EM to SUB-EM+) did not yield any improvements except for location and organization types from SUB-EM to SUB-EM+.", "labels": [], "entities": [{"text": "MAIN datasets", "start_pos": 11, "end_pos": 24, "type": "DATASET", "confidence": 0.9253124594688416}]}, {"text": "report the results of using term frequency representation of the entire page as features -a bag of words (BOWs)-as in.", "labels": [], "entities": []}, {"text": "Using semi-structured data as classification features is better than using BOW representation.", "labels": [], "entities": [{"text": "BOW representation", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.44815607368946075}]}, {"text": "This could be due to the smaller number of features of higher value.", "labels": [], "entities": []}, {"text": "In the BOW results with multilingual page inclusion, except for location NE type only in the SUB dataset, the use of term frequencies of multilingual words hurt F1-measure for the SUB and MAIN datasets.", "labels": [], "entities": [{"text": "SUB dataset", "start_pos": 93, "end_pos": 104, "type": "DATASET", "confidence": 0.9081776738166809}, {"text": "F1-measure", "start_pos": 161, "end_pos": 171, "type": "METRIC", "confidence": 0.9989041090011597}, {"text": "MAIN datasets", "start_pos": 188, "end_pos": 201, "type": "DATASET", "confidence": 0.9219058454036713}]}, {"text": "This can be attributed to the increased sparseness of the training and test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Characteristics of MAIN dataset: the number  of Wikipedia pages in the dataset", "labels": [], "entities": [{"text": "MAIN dataset", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.9548121690750122}]}, {"text": " Table 2. Characteristics of SUB dataset: the number  of Wikipedia pages in the dataset", "labels": [], "entities": [{"text": "SUB dataset", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.7703150510787964}]}, {"text": " Table 3. Results for MAIN-E: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "MAIN-E", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.7998298406600952}, {"text": "F1", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9738972187042236}]}, {"text": " Table 4. Results for MAIN-EM: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "MAIN-EM", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.828839123249054}, {"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9768696427345276}]}, {"text": " Table 5. Results for MAIN-EM+: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "MAIN-EM", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.8777573704719543}, {"text": "F1", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9841161370277405}]}, {"text": " Table 6. Results for SUB-E: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "SUB-E", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.9599912762641907}, {"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9854068756103516}]}, {"text": " Table 7. Results for SUB-EM: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "SUB-EM", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.9357197880744934}, {"text": "F1", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9762335419654846}]}, {"text": " Table 8. Results for SUB-EM+: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "SUB-EM+", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9045088589191437}, {"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9838849306106567}]}, {"text": " Table 9. Results for SUB-M: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "SUB-M", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.9422969222068787}, {"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9872052669525146}]}, {"text": " Table 10. Results for SUB-M+: Best F1 bolded and  italicized if significantly better than baseline.", "labels": [], "entities": [{"text": "SUB-M+", "start_pos": 23, "end_pos": 29, "type": "TASK", "confidence": 0.8815407752990723}, {"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.985721230506897}]}, {"text": " Table 11. Comparing results for MAIN-{E, EM, and  EM+}: Best F1 bolded and italicized if significantly  better than MAIN-E", "labels": [], "entities": [{"text": "MAIN-{E", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.7660222848256429}, {"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9755715131759644}, {"text": "MAIN-E", "start_pos": 117, "end_pos": 123, "type": "DATASET", "confidence": 0.6713950037956238}]}]}