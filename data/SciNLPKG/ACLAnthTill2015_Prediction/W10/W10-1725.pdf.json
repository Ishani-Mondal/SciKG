{"title": [], "abstractContent": [{"text": "In this paper, the system submitted by the PRHLT group for the Fifth Workshop on Statistical Machine Translation of ACL2010 is presented.", "labels": [], "entities": [{"text": "PRHLT", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.8769046068191528}, {"text": "Statistical Machine Translation of ACL2010", "start_pos": 81, "end_pos": 123, "type": "TASK", "confidence": 0.7386332035064698}]}, {"text": "On this evaluation campaign, we have worked on the English-Spanish language pair, putting special emphasis on two problems derived from the large amount of data available.", "labels": [], "entities": []}, {"text": "The first one, how to optimize the use of the monolingual data within the language model, and the second one, how to make good use of all the bilingual data provided without making use of unnecessary computational resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "For this year's translation shared task, the Pattern Recognition and Human Language Technologies (PRHLT) research group of the Universidad Polit\u00e9cnica de Valencia submitted runs for the English-Spanish translation task.", "labels": [], "entities": [{"text": "translation shared task", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.916019340356191}, {"text": "Pattern Recognition and Human Language Technologies (PRHLT)", "start_pos": 45, "end_pos": 104, "type": "TASK", "confidence": 0.7688192062907748}, {"text": "English-Spanish translation task", "start_pos": 186, "end_pos": 218, "type": "TASK", "confidence": 0.7320535182952881}]}, {"text": "In this paper, we report the configuration of such a system, together with preliminary experiments performed to establish the final setup.", "labels": [], "entities": []}, {"text": "As in 2009, the central focus of the Shared Task is on Domain Adaptation, where a system typically trained using out-of-domain data is adjusted to translate news commentaries.", "labels": [], "entities": [{"text": "Shared Task", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.8904112577438354}, {"text": "Domain Adaptation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7158562242984772}]}, {"text": "For the preliminary experiments, we used only a small amount of the largest available bilingual corpus, i.e. the United Nations corpus, by including into our system only those sentences which were considered similar.", "labels": [], "entities": [{"text": "United Nations corpus", "start_pos": 113, "end_pos": 134, "type": "DATASET", "confidence": 0.8903735876083374}]}, {"text": "Language model interpolation using a development set was explored in this work, together with a technique to cope with the problem of \"out of vocabulary words\".", "labels": [], "entities": [{"text": "Language model interpolation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5603969097137451}]}, {"text": "Finally, a reordering constraint using walls and zones was used in order to improve the performance of the submitted system.", "labels": [], "entities": []}, {"text": "In the final evaluation, our system was ranked fifth, considering only primary runs.", "labels": [], "entities": []}], "datasetContent": [{"text": "For building our SMT systems, the open-source SMT toolkit Moses () was used in its standard setup.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9816199541091919}, {"text": "SMT toolkit Moses", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7421185175577799}]}, {"text": "The decoder includes a loglinear model comprising a phrase-based translation model, a language model, a lexicalised distortion model and word and phrase penalties.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7028126418590546}]}, {"text": "The weights of the log-linear interpolation were optimised by means of MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.7053936719894409}]}, {"text": "In addition, a 5-gram LM with Kneser-Ney () smoothing and interpolation was built by means of the SRILM) toolkit.", "labels": [], "entities": [{"text": "SRILM) toolkit", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.8890319466590881}]}, {"text": "For building our baseline system, the NewsCommentary and Europarl v5 () data were employed, with maximum sentence length set to 40 in the case of the data used to build the translation models, and without restriction in the case of the LM.", "labels": [], "entities": [{"text": "NewsCommentary", "start_pos": 38, "end_pos": 52, "type": "DATASET", "confidence": 0.9791009426116943}, {"text": "Europarl v5 () data", "start_pos": 57, "end_pos": 76, "type": "DATASET", "confidence": 0.8757717609405518}]}, {"text": "Statistics of the bilingual data can be seen in.", "labels": [], "entities": []}, {"text": "In all the experiments reported, MERT was run on the 2008 test set, whereas the test set 2009 was considered as test set as such.", "labels": [], "entities": [{"text": "MERT", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.7544088363647461}, {"text": "2008 test set", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.822129487991333}]}, {"text": "In addition, all the experiments described below were performed in lowercase and tokenised conditions.", "labels": [], "entities": []}, {"text": "For the final run, the detokenisation and recasing was performed according to the technique described in the Workshop baseline description.: Main figures of the Spanish resources provided: Europarl v5, News-Commentary (NC), United Nations (UN) and News-shuffled (News).", "labels": [], "entities": [{"text": "detokenisation", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.9608095288276672}, {"text": "Europarl", "start_pos": 189, "end_pos": 197, "type": "DATASET", "confidence": 0.9217875003814697}, {"text": "News-Commentary (NC)", "start_pos": 202, "end_pos": 222, "type": "DATASET", "confidence": 0.820093423128128}, {"text": "United Nations (UN)", "start_pos": 224, "end_pos": 243, "type": "DATASET", "confidence": 0.8763637661933898}, {"text": "News-shuffled (News)", "start_pos": 248, "end_pos": 268, "type": "DATASET", "confidence": 0.8601460158824921}]}], "tableCaptions": [{"text": " Table 3: Effect of considering different LMs  LM used  BLEU  NC data  21.86  pooled  23.53  interpolated 24.97  news  24.79", "labels": [], "entities": [{"text": "BLEU  NC data  21.86  pooled  23.53  interpolated 24.97  news  24.79", "start_pos": 56, "end_pos": 124, "type": "DATASET", "confidence": 0.8752846658229828}]}, {"text": " Table 4: Effect of including selected sentences  system  BLEU  baseline  24.97  + oovs  25.08  + Level 1 24.98  + Level 2 25.07  + Level 3 25.13", "labels": [], "entities": [{"text": "BLEU  baseline  24.97  + oovs", "start_pos": 58, "end_pos": 87, "type": "METRIC", "confidence": 0.8604373097419739}]}]}