{"title": [{"text": "Using the Amazon Mechanical Turk to Transcribe and Annotate Meeting Speech for Extractive Summarization", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.9035325646400452}, {"text": "Extractive Summarization", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.6923837661743164}]}], "abstractContent": [{"text": "Due to its complexity, meeting speech provides a challenge for both transcription and annotation.", "labels": [], "entities": []}, {"text": "While Amazon's Mechanical Turk (MTurk) has been shown to produce good results for some types of speech, its suitability for transcription and annotation of spontaneous speech has not been established.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk (MTurk)", "start_pos": 6, "end_pos": 38, "type": "DATASET", "confidence": 0.8845145276614598}]}, {"text": "We find that MTurk can be used to produce high-quality transcription and describe two techniques for doing so (voting and corrective).", "labels": [], "entities": [{"text": "corrective", "start_pos": 122, "end_pos": 132, "type": "METRIC", "confidence": 0.914939284324646}]}, {"text": "We also show that using a similar approach, high quality annotations useful for summari-zation systems can also be produced.", "labels": [], "entities": []}, {"text": "In both cases, accuracy is comparable to that obtained using trained personnel.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999584972858429}]}], "introductionContent": [{"text": "Recently, Amazon's Mechanical Turk (MTurk) has been shown to produce useful transcriptions of speech data; have successfully used MTurk to correct the transcription output from a speech recognizer, while used MTurk for transcribing a corpus of conversational speech.", "labels": [], "entities": []}, {"text": "These studies suggest that transcription, formerly considered to bean exacting task requiring at least some training, could be carried out by casual workers.", "labels": [], "entities": [{"text": "transcription", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9280471801757812}]}, {"text": "However, only fairly simple transcription tasks were studied.", "labels": [], "entities": []}, {"text": "We propose to assess the suitability of MTurk for processing more challenging material, specifically recordings of meeting speech.", "labels": [], "entities": []}, {"text": "Spontaneous speech can be difficult to transcribe because it may contain false starts, disfluencies, mispronunciations and other defects.", "labels": [], "entities": []}, {"text": "Similarly for annotation, meeting content maybe difficult to follow and conventions difficult to apply consistently.", "labels": [], "entities": []}, {"text": "Our first goal is to ascertain whether MTurk transcribers can accurately transcribe spontaneous speech, containing speech errors and of variable utterance length.", "labels": [], "entities": [{"text": "MTurk transcribers", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7427564263343811}]}, {"text": "Our second goal is to use MTurk for creating annotations suitable for extractive summarization research, specifically labeling each utterance as either \"in-summary\" or \"not in-summary\".", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6163066923618317}]}, {"text": "Among other challenges, this task cannot be decomposed into small independent sub-tasks-for example, annotators cannot be asked to annotate a single utterance independent of other utterances.", "labels": [], "entities": []}, {"text": "To our knowledge, MTurk has not been previously explored for the purpose of summarization annotation.", "labels": [], "entities": [{"text": "MTurk", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.7097504734992981}, {"text": "summarization annotation", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.9609039723873138}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 presents word count information  related to the utterances in each length category.", "labels": [], "entities": []}, {"text": " Table 2. WER across transcription iterations.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.983126699924469}]}, {"text": " Table 3. WER across transcription iterations based on  speaker background.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9850136637687683}]}]}