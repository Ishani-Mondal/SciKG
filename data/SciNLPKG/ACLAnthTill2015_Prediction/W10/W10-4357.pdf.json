{"title": [{"text": "Hand Gestures in Disambiguating Types of You Expressions in Multiparty Meetings", "labels": [], "entities": [{"text": "Hand Gestures", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6597928702831268}]}], "abstractContent": [{"text": "The second person pronoun you serves different functions in English.", "labels": [], "entities": []}, {"text": "Each of these different types often corresponds to a different term when translated into another language.", "labels": [], "entities": []}, {"text": "Correctly identifying different types of you can be beneficial to machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.809736967086792}]}, {"text": "To address this issue , we investigate disambiguation of different types of you occurrences in multi-party meetings with anew focus on the role of hand gesture.", "labels": [], "entities": []}, {"text": "Our empirical results have shown that incorporation of gesture improves performance on differentiating between the generic use of you (e.g., refer to people in general) and the referen-tial use of you (e.g., refer to a specific person or a group of people).", "labels": [], "entities": []}, {"text": "Incorporation of gesture can also compensate for limitations in automated language processing (e.g., reliable recognition of dialogue acts) and achieve comparable results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The second person pronoun you is one of the most prevalent words in conversation and it serves several different functions.", "labels": [], "entities": []}, {"text": "For example, it can be used to refer to a single addressee (i.e., the singular case) or multiple addressees (i.e., the plural case).", "labels": [], "entities": []}, {"text": "It can also be used to represent people in general (i.e., the generic case) or be used idiomatically in the phrase \"you know\".", "labels": [], "entities": []}, {"text": "For machine translation systems, these different types of you often correspond to different translations in another language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7940381169319153}]}, {"text": "For example, in German, there are different second-person pronouns for singular vs. plural you (viz.", "labels": [], "entities": []}, {"text": "du vs. ihr); in addition there are different forms for formal vs. informal forms of address (du vs. Sie) and for the generic use (man).", "labels": [], "entities": []}, {"text": "The following examples demonstrate different translations of you from English (EN) into German (DE): \u2022 Generic you EN: Sometimes you have meetings where the decision is already taken.", "labels": [], "entities": [{"text": "DE", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.8958605527877808}, {"text": "Generic you EN", "start_pos": 103, "end_pos": 117, "type": "METRIC", "confidence": 0.7297715942064921}]}, {"text": "DE: Manchmal hat man Meetings wo die Entscheidung schon gefallen ist.", "labels": [], "entities": []}, {"text": "To address this issue, this paper investigates the role of hand gestures in disambiguating different usages of you in multiparty meetings.", "labels": [], "entities": []}, {"text": "Although identification of you type has been investigated before in the context of addressee identification, our work here focuses on two new angles.", "labels": [], "entities": [{"text": "identification of you type", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.8726634383201599}, {"text": "addressee identification", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.7228982746601105}]}, {"text": "First, because of our different application on machine translation, rather than processing you at an utterance level to identify addressee, our work here concerns each occurrence of you within each utterance.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7352217733860016}]}, {"text": "Second and more importantly, our work investigates the role of corresponding hand gestures in the disambiguation process.", "labels": [], "entities": [{"text": "disambiguation process", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.9128379821777344}]}, {"text": "This aspect has not been examined in previous work.", "labels": [], "entities": []}, {"text": "When several speakers are conversing in a situated environment, they often overtly gesture atone another to help manage turn order or explicitly direct a statement toward a particular participant.", "labels": [], "entities": []}, {"text": "For example, consider the following snippet from a multiparty meeting: A: \"Why is that?\"", "labels": [], "entities": []}, {"text": "B: \"Because, um, based on what ev-erybody's saying, right, [gestures at Speaker D] you want something simple.", "labels": [], "entities": []}, {"text": "You [gestures at Speaker C]want basic stuff and [gestures at Speaker A] you want something that is easy to use.", "labels": [], "entities": []}, {"text": "Speech recognition might not be the simplest thing.\"", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.911324143409729}]}, {"text": "The use of gesture in this example indicates that each instance of the pronoun you is intended to be referential, and gives some indication of the indented addressee.", "labels": [], "entities": []}, {"text": "Without the aid of gesture, it would be difficult even fora human listener to be able to interpret each instance correctly.", "labels": [], "entities": []}, {"text": "Therefore, we conducted an empirical study on several meeting segments from the AMI meeting corpus.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 80, "end_pos": 98, "type": "DATASET", "confidence": 0.8469401001930237}]}, {"text": "We formulated our problem as a classification problem for each occurrence of you, whether it is a generic, singular, or plural type.", "labels": [], "entities": []}, {"text": "We combined gesture features with several linguistic and discourse features identified by previous work and evaluated the role of gesture in two different settings: (1) a two stage classification that first differentiates the generic type from the referential type and then within the referential type distinguishes singular and plural usages; (2) a three way classification between generic, singular, or plural types.", "labels": [], "entities": []}, {"text": "Our empirical results have shown that incorporation of gesture improves performance on differentiating between the generic and the referential type.", "labels": [], "entities": []}, {"text": "Incorporation of gesture can also compensate for limitations in automated language processing (e.g., reliable recognition of dialogue acts) and achieve comparable results.", "labels": [], "entities": []}, {"text": "These findings have important implications for machine translation of you expressions from multiparty meetings.", "labels": [], "entities": [{"text": "machine translation of you expressions", "start_pos": 47, "end_pos": 85, "type": "TASK", "confidence": 0.8456714630126954}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy values for Generic vs. Referen- tial Classification", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991588592529297}, {"text": "Generic vs. Referen- tial Classification", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.5040606558322906}]}, {"text": " Table 4: Precision, recall, and F-measure results for each you type based on three class classification.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9981064796447754}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.998408854007721}, {"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9986961483955383}]}, {"text": " Table 5: Accuracy for 3-way classification by combining gesture information with automatically ex- tracted features based on the Decision Tree model", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9576747417449951}, {"text": "3-way classification", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.6294130980968475}]}]}