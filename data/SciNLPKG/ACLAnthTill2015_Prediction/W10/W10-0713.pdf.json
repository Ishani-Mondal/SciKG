{"title": [{"text": "Annotating Named Entities in Twitter Data with Crowdsourcing", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe our experience using both Amazon Mechanical Turk (MTurk) and Crowd-Flower to collect simple named entity annotations for Twitter status updates.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (MTurk)", "start_pos": 38, "end_pos": 68, "type": "DATASET", "confidence": 0.8158045609792074}]}, {"text": "Unlike most genres that have traditionally been the focus of named entity experiments, Twitter is far more informal and abbreviated.", "labels": [], "entities": []}, {"text": "The collected annotations and annotation techniques will provide a first step towards the full study of named entity recognition in domains like Facebook and Twitter.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.6257302761077881}]}, {"text": "We also briefly describe how to use MTurk to collect judgements on the quality of \"word clouds.\"", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Information extraction researchers commonly work on popular formal domains, such as news articles.", "labels": [], "entities": [{"text": "Information extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8557525873184204}]}, {"text": "More diverse studies have included broadcast news transcripts, blogs and emails (.", "labels": [], "entities": []}, {"text": "However, extremely informal domains, such as Facebook, Twitter, YouTube or Flickr are starting to receive more attention.", "labels": [], "entities": []}, {"text": "Any effort aimed at studying these informal genres will require at least a minimal amount of labeled data for evaluation purposes.", "labels": [], "entities": []}, {"text": "This work details how to efficiently annotate large volumes of data, for information extraction tasks, at low cost using MTurk (.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7982263565063477}, {"text": "MTurk", "start_pos": 121, "end_pos": 126, "type": "DATASET", "confidence": 0.8510546088218689}]}, {"text": "This paper describes a case study for information extraction tasks involving short, informal messages from Twitter.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.8526177406311035}]}, {"text": "Twitter is a large multiuser site for broadcasting short informal messages.", "labels": [], "entities": []}, {"text": "Twitter is an extreme example of an informal genre ( as users frequently abbreviate their posts to fit within the specified limit.", "labels": [], "entities": []}, {"text": "Twitter is a good choice because it is very popular: Twitter users generate a tremendous number of status updates (tweets) everyday . This is a good genre to work on named entity extraction since many tweets refer to and contain updates about named entities.", "labels": [], "entities": [{"text": "named entity extraction", "start_pos": 166, "end_pos": 189, "type": "TASK", "confidence": 0.6941733360290527}]}, {"text": "Our Twitter data set has over 150 million tweets from 1.5 million users collected over a period of three years.", "labels": [], "entities": [{"text": "Twitter data set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.817667285601298}]}, {"text": "Tweets are unlike formal text.", "labels": [], "entities": []}, {"text": "They are limited to a maximum of 140 characters, a limit originally set to allow them to fit into an SMS message.", "labels": [], "entities": []}, {"text": "Consequently, the use of acronyms and both standard and non-standard abbreviations (e.g., b4 for before and ur for your) are very common.", "labels": [], "entities": []}, {"text": "Tweets tend to be telegraphic and often consist of sentence fragments or other ungrammatical sequences.", "labels": [], "entities": []}, {"text": "Normal capitalization rules (e.g., for proper names, book titles, etc.) are commonly ignored.", "labels": [], "entities": []}, {"text": "Furthermore, users have adopted numerous conventions including hashtags, user mentions, and retweet markers.", "labels": [], "entities": []}, {"text": "A hashtag (e.g., #earthquake) is a token beginning with a '#' character that denotes one of the topic of a status.", "labels": [], "entities": []}, {"text": "Hashtags can be used as pure metadata or serve both as a word and as metadata, as the following two examples show.", "labels": [], "entities": []}, {"text": "\u2022 EvanEcullen: #chile #earthquake #tsunami They heard nothing of a tsunami until it slammed into their house with an unearthly http://tl.gd/d798d \u2022 LarsVonD: Know how to help #Chile after the #Earthquake (1) report from the economist: #chile counts the cost of a devastating earthquake and makes plans for recovery.", "labels": [], "entities": []}, {"text": "http://bit.ly/dwoQMD Note: \"the economist\" was not recognized as an ORG.", "labels": [], "entities": [{"text": "ORG", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9063951373100281}]}, {"text": "(2) how come when george bush wanted to takeout millions for the war congress had no problem...but whe obama wants money for healthcare the ...", "labels": [], "entities": []}, {"text": "Note: Both \"george bush\" and \"obama\" were missed as PERs.", "labels": [], "entities": [{"text": "missed", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9750548005104065}, {"text": "PERs", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.8400072455406189}]}, {"text": "(3) RT @woodmuffin: jay leno interviewing sarah palin: the seventh seal starts to show a few cracks Note: RT (code fora re-tweet) was mistaken as a position and sarah palin missed as a person.", "labels": [], "entities": [{"text": "RT", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.8876672983169556}]}, {"text": "The Twitter community also has a convention where user names preceded by an @ character (known as \"mentions\") at the beginning of a status indicate that it is a message directed at that user.", "labels": [], "entities": []}, {"text": "A user mention in the middle of a message is interpreted as a general reference to that user.", "labels": [], "entities": []}, {"text": "Both uses are shown in this status: \u2022 paulasword: @obama quit calling @johnboener a liar, you liar The token RT is used as a marker that a person is forwarding a tweet originally sent by another user.", "labels": [], "entities": []}, {"text": "Normally the re-tweet symbol begins the message and is immediately followed by the user mention of the original author or sometimes a chain of re-tweeters ending with the original author, as in Finally, \"smileys\" are common in Twitter statuses to signal the users' sentiment, as in the following.", "labels": [], "entities": []}, {"text": "\u2022 sallytherose: Just wrote a 4-page paper in an hour and a half.", "labels": [], "entities": []}, {"text": "BOiiiiii I'm getting good at this.", "labels": [], "entities": [{"text": "BOiiiiii", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8396519422531128}]}, {"text": ":) Leftover Noodles for dinner as a reward.", "labels": [], "entities": []}, {"text": ":D The Twitter search service also uses these to retrieve tweets matching a query with positive or negative sentiment.", "labels": [], "entities": []}, {"text": "Typical named entity recognition systems have been trained on formal documents, such as news wire articles.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.6350674827893575}]}, {"text": "Their performance on text from very different sources, especially informal genres such as Twitter tweets or Facebook status updates, is poor.", "labels": [], "entities": []}, {"text": "In fact, \"Systems analyzing correctly about 90% of the sequences from a journalistic corpus can have a decrease of performance of up to 50% on more informal texts.\")", "labels": [], "entities": []}, {"text": "However, many large scale information extraction systems require extracting and integrating useful information from online social networking sources that are informal such as Twitter, Facebook, Blogs, YouTube and Flickr.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7259034663438797}]}, {"text": "To illustrate the problem we applied both the NLTK () and the Stanford named entity recognizers () without retraining to a sample Twitter dataset with mixed results.", "labels": [], "entities": [{"text": "NLTK", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.8457872271537781}, {"text": "Stanford named entity recognizers", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.5476491004228592}]}, {"text": "We have observed many failures, both false positives and false negatives.", "labels": [], "entities": []}, {"text": "shows some examples of these.", "labels": [], "entities": []}], "tableCaptions": []}