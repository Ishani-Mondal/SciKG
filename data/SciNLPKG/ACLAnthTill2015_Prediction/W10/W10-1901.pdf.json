{"title": [{"text": "Two strong baselines for the BioNLP 2009 event extraction task", "labels": [], "entities": [{"text": "BioNLP 2009 event extraction", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.7240224629640579}]}], "abstractContent": [{"text": "This paper presents two strong baselines for the BioNLP 2009 shared task on event extraction.", "labels": [], "entities": [{"text": "BioNLP 2009 shared task", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.5275640785694122}, {"text": "event extraction", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7395819872617722}]}, {"text": "First we re-implement a rule-based approach which allows us to explore the task and the effect of domain-adapted parsing on it.", "labels": [], "entities": []}, {"text": "We then replace the rule-based component with support vector machine classifiers and achieve performance near the state-of-the-art without using any external resources.", "labels": [], "entities": []}, {"text": "The good performances achieved and the relative simplicity of both approaches make them reproducible baselines.", "labels": [], "entities": []}, {"text": "We conclude with suggestions for future work with respect to the task representation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The term biomedical event extraction is used to refer to tasks whose aim is the extraction of information beyond the entity level.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.641851951678594}]}, {"text": "It commonly involves recognizing actions and relations between one or more entities.", "labels": [], "entities": []}, {"text": "The recent BioNLP 2009 shared task on event extraction () focused on a number of relations of varying complexity in which an event consisted of a trigger and one or more arguments.", "labels": [], "entities": [{"text": "BioNLP 2009 shared task", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.6811943054199219}, {"text": "event extraction", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.6296217143535614}]}, {"text": "It attracted 24 submissions and provided a basis for system development.", "labels": [], "entities": [{"text": "system development", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9045892357826233}]}, {"text": "The performances ranged from 16% to 52% in F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9981067180633545}]}, {"text": "In this paper we describe two strong baseline approaches for the main task (described in Sec.", "labels": [], "entities": []}, {"text": "2) with a focus on annotation costs and reproducibility.", "labels": [], "entities": []}, {"text": "Both approaches rely on a dictionary of lemmas associated with event types (Sec. 3).", "labels": [], "entities": []}, {"text": "First we re-implement the rule-based approach of using resources provided in the shared task.", "labels": [], "entities": []}, {"text": "While it is unlikely to reach the performance of approaches combining supervised machine learning, exploring its potential can highlight what annotated data is useful and its potential contribution to performance.", "labels": [], "entities": []}, {"text": "Also, given its reliance on syntax, it allows us to assess the importance of syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.7373088896274567}]}, {"text": "Nevertheless, the performance achieved (35.39% F-score) is competitive with systems that used more annotated data and/or other resources (Sec. 5).", "labels": [], "entities": [{"text": "F-score", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.998711347579956}]}, {"text": "Building on the error analysis of the rule-based approach, we replace the rule-based component with support vector machine (SVM) classifiers trained on partial event annotation in the form of trigger-argument associations (Sec. 6).", "labels": [], "entities": []}, {"text": "The use of a trainable classifier highlights issues concerning the suitability of the annotated data as training material.", "labels": [], "entities": []}, {"text": "Using a simple feature representation and no external resources, the performance rises to 47.89% in F-score, which would have been second best in the shared task (Sec. 7).", "labels": [], "entities": [{"text": "F-score", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9986289739608765}]}, {"text": "The error analysis suggests that future work on event extraction should look into different task representations which will allow more advanced models to demonstrate their potential (Sec. 8).", "labels": [], "entities": [{"text": "event extraction", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.7476931810379028}]}, {"text": "Both systems shall become publically available.", "labels": [], "entities": []}], "datasetContent": [{"text": "The BioNLP 2009 shared task focused on extraction of events involving proteins.", "labels": [], "entities": [{"text": "BioNLP 2009 shared task", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.7958839237689972}]}, {"text": "Protein recognition was considered a given in order to focus the research efforts on the novel aspects of the task.", "labels": [], "entities": [{"text": "Protein recognition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8715247511863708}]}, {"text": "Nine event types were defined in the main task, which can be broadly classified in two classes.", "labels": [], "entities": []}, {"text": "Simple events, namely Gene expression, Transcription, Protein catabolism, Phosphorylation, Localization and Binding, which have proteins as their Theme argument and Regulation events, namely Positive regulation, Negative regulation and (unspecified) Regulation which have an obligatory Theme argument and an optional Cause argument which can be either a protein or another event.", "labels": [], "entities": []}, {"text": "Every event has a trigger which is a contiguous textual string that can span over one or more tokens, as well as apart of a token.", "labels": [], "entities": []}, {"text": "Triggers and arguments can be shared across events and the same textual string can be a trigger for events of different types.", "labels": [], "entities": []}, {"text": "In an example demonstrating the complexity of the task: \".", "labels": [], "entities": []}, {"text": "SQ 22536 suppressed gp41-induced IL-10 production in monocytes.\"", "labels": [], "entities": [{"text": "SQ 22536", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6842613816261292}]}, {"text": "Participating systems, given the two proteins (in bold), need to generate the three appropriately nested events of.", "labels": [], "entities": []}, {"text": "While event components can reside in different sentences, we focus on events that are contained in a single sentence.", "labels": [], "entities": []}, {"text": "Participants were not provided with resources to develop anaphora resolution components and the anaphoric phenomena involved were rather complex, as we observed in.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7584001421928406}]}, {"text": "Extraction of events involving anaphoric relations inside a single sentence is still possible but it is likely to require rather complex patterns to be extracted.", "labels": [], "entities": [{"text": "Extraction of events involving anaphoric relations", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8698414067427317}]}, {"text": "The shared task involved three datasets, training, development and test, which consisted of 800, 150 and 260 abstracts respectively taken from the GENIA event corpus.", "labels": [], "entities": [{"text": "GENIA event corpus", "start_pos": 147, "end_pos": 165, "type": "DATASET", "confidence": 0.9478866457939148}]}, {"text": "Their annotation was tailored to the shared task definition.", "labels": [], "entities": []}, {"text": "A resource made available and used by the majority of the systems was the output of four syntactic parsers: parsing model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 108, "end_pos": 115, "type": "TASK", "confidence": 0.9680646061897278}]}, {"text": "This parser was trained on newswire data exclusively.", "labels": [], "entities": []}, {"text": "\u2022 The re-ranking parser of Charniak & Johnson adapted to the biomedical domain.", "labels": [], "entities": []}, {"text": "The in-domain, part-ofspeech (PoS) tagger was trained on the GENIA corpus () and the self-training of the re-ranking module used apart of the GE-NIA treebank as development data.", "labels": [], "entities": [{"text": "GENIA corpus", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.9622249007225037}, {"text": "GE-NIA treebank", "start_pos": 142, "end_pos": 157, "type": "DATASET", "confidence": 0.9800600707530975}]}, {"text": "\u2022 The C&C Combinatory Categorial Grammar (CCG) parser adapted to the biomedical domain ().", "labels": [], "entities": [{"text": "C&C Combinatory Categorial Grammar (CCG) parser", "start_pos": 6, "end_pos": 53, "type": "TASK", "confidence": 0.6927951127290726}]}, {"text": "The PoS tagger was trained on the GENIA corpus, while 1,000 sentences were annotated with lexical categories and added to the training data of the CCG supertagger and 600 sentences of the BioInfer corpus ( were used for parameter tuning.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.5845827162265778}, {"text": "GENIA corpus", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9842047691345215}, {"text": "CCG supertagger", "start_pos": 147, "end_pos": 162, "type": "DATASET", "confidence": 0.9404653012752533}, {"text": "BioInfer corpus", "start_pos": 188, "end_pos": 203, "type": "DATASET", "confidence": 0.9434792399406433}, {"text": "parameter tuning", "start_pos": 220, "end_pos": 236, "type": "TASK", "confidence": 0.7466861605644226}]}, {"text": "\u2022 The GDep dependency parser trained for the biomedical domain in the experiments of.", "labels": [], "entities": [{"text": "GDep dependency parser", "start_pos": 6, "end_pos": 28, "type": "TASK", "confidence": 0.5989321569601694}]}, {"text": "This parser was trained for the biomedical domain using the GENIA treebank.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.9875531792640686}]}, {"text": "The native Penn TreeBank output of Bikel's and McClosky's parser was converted to the Stanford Dependency (SD) collapsed dependency format (.", "labels": [], "entities": [{"text": "Penn TreeBank output", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.9834959109624227}]}, {"text": "The output of the CCG parser was also converted to the same dependency format, while the output of GDep was provided in a different dependency format used for the dependency parsing CoNLL 2007 shared task.", "labels": [], "entities": [{"text": "GDep", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8664801120758057}, {"text": "dependency parsing CoNLL 2007 shared task", "start_pos": 163, "end_pos": 204, "type": "TASK", "confidence": 0.6582565009593964}]}, {"text": "From the description above, it is clear that the various parsers have different levels of adaptation to the biomedical domain.", "labels": [], "entities": []}, {"text": "While it is difficult to assess quantitatively the actual annotation effort involved, it is possible to make some comparisons.", "labels": [], "entities": []}, {"text": "Bikel's parser was not adapted to the domain, therefore it would be the cheapest one to deploy.", "labels": [], "entities": []}, {"text": "McClosky and CCG used in-domain corpora annotated with PoS tags for training, while the latter using some additional annotation for lexical categories.", "labels": [], "entities": []}, {"text": "Furthermore, they were tuned using in-domain syntactic treebanks.", "labels": [], "entities": []}, {"text": "Therefore, they represent a more expensive option in terms of annotation cost.", "labels": [], "entities": []}, {"text": "Finally, GDep was trained using an in-domain treebanked corpus, thus representing the alternative with the highest annotation cost.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of the rule-based and the SVM-based systems on the test data. Each horizontal  corresponds to an event type or class. Binding events are not included in the Simple class aggregate  performance because they can have multiple Themes.", "labels": [], "entities": []}]}