{"title": [{"text": "Easy First Dependency Parsing of Modern Hebrew", "labels": [], "entities": [{"text": "Parsing of Modern Hebrew", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8861586898565292}]}], "abstractContent": [{"text": "We investigate the performance of an easy-first, non-directional dependency parser on the Hebrew Dependency treebank.", "labels": [], "entities": [{"text": "Hebrew Dependency treebank", "start_pos": 90, "end_pos": 116, "type": "DATASET", "confidence": 0.9311764438947042}]}, {"text": "We show that with a basic feature set the greedy parser's accuracy is on a par with that of a first-order globally optimized MST parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.999535322189331}, {"text": "MST parser", "start_pos": 125, "end_pos": 135, "type": "TASK", "confidence": 0.7746610045433044}]}, {"text": "The addition of morphological-agreement feature improves the parsing accuracy, making it on-par with a second-order globally optimized MST parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.975939154624939}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9697120189666748}]}, {"text": "The improvement due to the morphological agreement information is persistent both when gold-standard and automatically-induced morphological information is used.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven Dependency Parsing algorithms are broadly categorized into two approaches.", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7448374629020691}]}, {"text": "Transition based parsers traverse the sentence from left to right 1 using greedy, local inference.", "labels": [], "entities": []}, {"text": "Graph based parsers use global inference and seek a tree structure maximizing some scoring function defined over trees.", "labels": [], "entities": []}, {"text": "This scoring function is usually decomposed over tree edges, or pairs of such edges.", "labels": [], "entities": []}, {"text": "In recent work, we proposed another dependency parsing approach: Easy First, Non-Directional dependency * Supported by the Lynn and William Frankel Center for Computer Sciences, Ben Gurion University 1 Strictly speaking, the traversal order is from start to end.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8114528059959412}, {"text": "Easy", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9404770731925964}]}, {"text": "This distinction is important when discussing Hebrew parsing, as the Hebrew language is written from right-to-left.", "labels": [], "entities": [{"text": "Hebrew parsing", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.6550356149673462}]}, {"text": "We keep the left-to-right terminology throughout this paper, as this is the common terminology.", "labels": [], "entities": []}, {"text": "However, \"left\" and \"right\" should be interpreted as \"start\" and \"end\" respectively.", "labels": [], "entities": [{"text": "end", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.951851487159729}]}, {"text": "Similarly, \"a token to the left\" should be interpreted as \"the previous token\". parsing.", "labels": [], "entities": []}, {"text": "Like transition based methods, the easyfirst method adopts a local, greedy policy.", "labels": [], "entities": []}, {"text": "However, it abandons the strict left-to-right processing order, replacing it with an alternative order, which attempts to make easier attachments decisions prior to harder ones.", "labels": [], "entities": []}, {"text": "The model was applied to English dependency parsing.", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.601252406835556}]}, {"text": "It was shown to be more accurate than MALTPARSER, a state-of-the-art transition based parser (), and near the performance of the first-order MSTPARSER, a graph based parser which decomposes its score over tree edges), while being more efficient.", "labels": [], "entities": []}, {"text": "The easy-first parser works by making easier decisions before harder ones.", "labels": [], "entities": []}, {"text": "Each decision can be conditioned by structures created by previous decisions, allowing harder decisions to be based on relatively rich syntactic structure.", "labels": [], "entities": []}, {"text": "This is in contrast to the globally optimized parsers, which cannot utilize such rich syntactic structures.", "labels": [], "entities": []}, {"text": "It was hypothesized in) that this rich conditioning can be especially beneficial in situations where informative structural information is available, such as in morphologically rich languages.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the non-directional easy-first parser performance on Modern Hebrew, a semitic language with rich morphology, relatively free constituent order, and a small treebank compared to English.", "labels": [], "entities": []}, {"text": "We are interested in two main questions: (a) how well does the non-directional parser perform on Hebrew data? and (b) can the parser make effective use of morphological features, such as agreement?", "labels": [], "entities": []}, {"text": "In (, we describe a newly created Hebrew dependency treebank, and report results on parsing this corpus with both MALTPARSER and first-and second-order variants of MSTPARSER.", "labels": [], "entities": [{"text": "MALTPARSER", "start_pos": 114, "end_pos": 124, "type": "METRIC", "confidence": 0.739877462387085}]}, {"text": "We find that the secondorder MSTPARSER outperforms the first order MST-PARSER, which in turn outperforms the transition based MALTPARSER.", "labels": [], "entities": [{"text": "MSTPARSER", "start_pos": 29, "end_pos": 38, "type": "DATASET", "confidence": 0.6219446659088135}]}, {"text": "In addition, adding morphological information to the default configurations of these parsers does not improve parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.9756301045417786}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.8954420685768127}]}, {"text": "Interestingly, when using automatically induced (rather than gold-standard) morphological information, the transition based MALTPARSER's accuracy improves with the addition of the morphological information, while the scores of both globally optimized parsers drop with the addition of the morphological information.", "labels": [], "entities": [{"text": "MALTPARSER", "start_pos": 124, "end_pos": 134, "type": "METRIC", "confidence": 0.7873015403747559}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9932333827018738}]}, {"text": "Our experiments in this paper show that the accuracy of the non-directional parser on the same dataset outperforms the first-order MSTPARSER.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9995211362838745}]}, {"text": "With the addition of morphological agreement features, the parser accuracy improves even further, and is on-par with the performance of the second-order MSTPARSER.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9925307631492615}]}, {"text": "The improvement due to the morphological information persists also when automatically induced morphological information is used.", "labels": [], "entities": []}], "datasetContent": [{"text": "We follow the setup of).", "labels": [], "entities": []}, {"text": "Data We use the Hebrew dependency treebank described in).", "labels": [], "entities": []}, {"text": "We use Sections 2-12 (sentences 484-5724) as our training set, and report results on parsing the development set, Section 1 (sentences 0-483).", "labels": [], "entities": [{"text": "parsing", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.962317168712616}]}, {"text": "As in), we do not evaluate on the test set in this work.", "labels": [], "entities": []}, {"text": "The data in the treebank is segmented and POStagged.", "labels": [], "entities": []}, {"text": "Both the parsing models were trained on the gold-standard segmented and tagged data.", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9669285416603088}]}, {"text": "When evaluating the parsing models, we perform two sets of evaluations.", "labels": [], "entities": []}, {"text": "The first one is an oracle experiment, assuming gold segmentation and tagging is available.", "labels": [], "entities": [{"text": "gold segmentation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.6370687484741211}]}, {"text": "The second one is a real-world experiment, in which we segment and POS-tag the testset sentences using the morphological disambiguator described in prior to parsing.", "labels": [], "entities": [{"text": "POS-tag", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.9510398507118225}]}, {"text": "Parsers and parsing models We use our freely available implementation 3 of the non-directional parser.", "labels": [], "entities": []}, {"text": "Evaluation Measure We evaluate the resulting parses in terms of unlabeled accuracy -the percent of correctly identified (child,parent) pairs . To be precise, we calculate: number of correctly identified pairs number of pairs in gold parse For the oracle casein which the gold-standard token segmentation is available for the parser, this is the same as the traditional unlabeled-accuracy evaluation metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.885607123374939}]}, {"text": "However, in the real-word setting in which the token segmentation is done automatically, the yields of the gold-standard and the automatic parse may differ, and one needs to decide how to handle the cases in which one or more elements in the identified (child,parent) pair are not present in the gold-standard parse.", "labels": [], "entities": []}, {"text": "Our evaluation metric penalizes these cases by regarding them as mistakes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Unlabeled dependency accuracy of the various  parsing models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.8775011301040649}]}]}