{"title": [{"text": "LIUM SMT Machine Translation System for WMT 2010", "labels": [], "entities": [{"text": "SMT Machine Translation", "start_pos": 5, "end_pos": 28, "type": "TASK", "confidence": 0.7969506780306498}, {"text": "WMT", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.7130579948425293}]}], "abstractContent": [{"text": "This paper describes the development of French-English and English-French machine translation systems for the 2010 WMT shared task evaluation.", "labels": [], "entities": [{"text": "English-French machine translation", "start_pos": 59, "end_pos": 93, "type": "TASK", "confidence": 0.6786298751831055}, {"text": "WMT shared task evaluation", "start_pos": 115, "end_pos": 141, "type": "TASK", "confidence": 0.8259149640798569}]}, {"text": "These systems were standard phrase-based statistical systems based on the Moses decoder, trained on the provided data only.", "labels": [], "entities": []}, {"text": "Most of our efforts were devoted to the choice and extraction of bilingual data used for training.", "labels": [], "entities": []}, {"text": "We filtered out some bilingual corpora and pruned the phrase table.", "labels": [], "entities": []}, {"text": "We also investigated the impact of adding two types of additional bilingual texts, extracted automatically from the available monolingual data.", "labels": [], "entities": []}, {"text": "We first collected bilingual data by performing automatic translations of monolingual texts.", "labels": [], "entities": []}, {"text": "The second type of bilingual text was harvested from comparable corpora with Information Retrieval techniques.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the machine translation systems developed by the Computer Science laboratory at the University of Le Mans (LIUM) for the 2010 WMT shared task evaluation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.748714029788971}, {"text": "WMT shared task evaluation", "start_pos": 147, "end_pos": 173, "type": "TASK", "confidence": 0.8587696850299835}]}, {"text": "We only considered the translation between French and English (in both directions).", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9663333892822266}]}, {"text": "The main differences with respect to previous year's system ( ) are as follows: restriction to the data recommended for the workshop, usage of the (filtered) French-English gigaword bitext, pruning of the phrase table, and usage of automatic translations of the monolingual news corpus to improve the translation model.", "labels": [], "entities": []}, {"text": "We also used a larger amount of bilingual data extracted from comparable corpora than was done in 2009.", "labels": [], "entities": []}, {"text": "These different points are described in the rest of the paper, together with a summary of the experimental results showing the impact of each component.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: French-English results: number of French words (in million), number of entries in the phrase- table (in million), memory needed during decoding (in gigabytes) and BLEU scores in the development  (news-test2008) and internal test (newstest2009) sets for the different systems developped. The BLEU  scores and the number in parentheses are the average and standard deviation over 3 values (see Section 3.)", "labels": [], "entities": [{"text": "memory", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.96107017993927}, {"text": "BLEU", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.9993970394134521}, {"text": "BLEU", "start_pos": 301, "end_pos": 305, "type": "METRIC", "confidence": 0.9989500641822815}]}]}