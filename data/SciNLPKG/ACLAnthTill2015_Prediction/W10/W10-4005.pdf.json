{"title": [{"text": "The Noisier the Better: Identifying Multilingual Word Translations Using a Single Monolingual Corpus", "labels": [], "entities": [{"text": "Identifying Multilingual Word Translations", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.8619050830602646}]}], "abstractContent": [{"text": "The automatic generation of dictionaries from raw text has previously been based on parallel or comparable corpora.", "labels": [], "entities": []}, {"text": "Here we describe an approach requiring only a single monolingual corpus to generate bilingual dictionaries for several language pairs.", "labels": [], "entities": []}, {"text": "A constraint is that all language pairs have their target language in common, which needs to be the language of the underlying corpus.", "labels": [], "entities": []}, {"text": "Our approach is based on the observation that monolingual corpora usually contain a considerable number of foreign words.", "labels": [], "entities": []}, {"text": "As these are often explained via translations typically occurring close by, we can identify these translations by looking at the contexts of a foreign word and by computing its strongest associations from these.", "labels": [], "entities": []}, {"text": "In this work we focus on the question what results can be expected for 20 language pairs involving five major European languages.", "labels": [], "entities": []}, {"text": "We also compare the results for two different types of corpora, namely newsticker texts and web corpora.", "labels": [], "entities": []}, {"text": "Our findings show that results are best if English is the source language, and that noisy web corpora are better suited for this task than well edited newsticker texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Established methods for the identification of word translations are based on parallel () or comparable corpora).", "labels": [], "entities": [{"text": "identification of word translations", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.8598559349775314}]}, {"text": "The work using parallel corpora such as Europarl () or JRC Acquis () typically performs a length-based sentence alignment of the translated texts, and then tries to conduct a word alignment within sentence pairs by determining word correspondences that get support from as many sentence pairs as possible.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9862765073776245}, {"text": "JRC Acquis", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.7829758524894714}, {"text": "word alignment", "start_pos": 175, "end_pos": 189, "type": "TASK", "confidence": 0.6846844106912613}]}, {"text": "This approach works very well and can easily be put into practice using a number of freely available open source tools such as Moses ( and Giza++.", "labels": [], "entities": []}, {"text": "However, parallel texts area scarce resource for many language pairs, which is why methods based on comparable corpora have come into focus.", "labels": [], "entities": []}, {"text": "One approach is to extract parallel sentences from comparable corpora).", "labels": [], "entities": []}, {"text": "Another approach relates co-occurrence patterns between languages.", "labels": [], "entities": []}, {"text": "Hereby the underlying assumption is that across languages there is a correlation between the cooccurrences of words which are translations of each other.", "labels": [], "entities": []}, {"text": "If, for example, in a text of one language two words A and B co-occur more often than expected by chance, then in a text of another language those words which are the translations of A and B should also co-occur more frequently than expected.", "labels": [], "entities": []}, {"text": "However, to exploit this observation some bridge needs to be built between the two languages.", "labels": [], "entities": []}, {"text": "This can be done via a basic dictionary comprising some essential vocabulary.", "labels": [], "entities": []}, {"text": "To put it simply, this kind of dictionary allows a (partial) word-by-word translation from the source to the target language, 1 so that the result can be considered as a pair of monolingual corpora.", "labels": [], "entities": []}, {"text": "Note that this translation can also be conducted at the level of co-occurrence vectors rather than at the text level.", "labels": [], "entities": []}, {"text": "ing only with monolingual corpora means that the established methodology for computing similar words (see e.g.), which is based on Harris' (1954) distributional hypothesis, can be applied.", "labels": [], "entities": []}, {"text": "It turns out that the most similar words between the two corpora effectively identify the translations of words.", "labels": [], "entities": []}, {"text": "This approach based on comparable corpora considerably relieves the data acquisition bottleneck, but has the disadvantage that the results tend to lack accuracy in practice.", "labels": [], "entities": [{"text": "data acquisition", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.7749403715133667}, {"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9982205033302307}]}, {"text": "As an alternative, there is also the approach of identifying orthographically similar words) which has the advantage that it does not even require a corpus.", "labels": [], "entities": []}, {"text": "A simple word list will suffice.", "labels": [], "entities": []}, {"text": "However, this approach works only for closely related languages, and has limited potential otherwise.", "labels": [], "entities": []}, {"text": "We propose hereto generate dictionaries on the basis of foreign word occurrences in texts.", "labels": [], "entities": []}, {"text": "As far as we know, this is a method which has not been tried before.", "labels": [], "entities": []}, {"text": "When doing so, a single monolingual corpus can be used for all source languages for which it contains a sufficient number of foreign words.", "labels": [], "entities": []}, {"text": "A constraint is that the target language must always be the language of the monolingual corpus, 2 which therefore all dictionaries have in common.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied the following procedure on each of the five corpora: The language of the respective corpus was considered the target language, and the vocabulary of the respective column in the gold standard was taken to be the target language vocabulary.", "labels": [], "entities": []}, {"text": "The other languages are referred to as the source languages, and the corresponding columns of the gold standard contain the respective vocabularies.", "labels": [], "entities": []}, {"text": "Using the algorithm described in the previous section, for each source vocabulary the following procedure was conducted: For every source language word the target vocabulary was sorted according to the respective scores.", "labels": [], "entities": []}, {"text": "The word obtaining the first rank was considered to be the predicted translation.", "labels": [], "entities": []}, {"text": "This predicted translation was compared to the translation listed in the gold standard.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9511695504188538}]}, {"text": "If it matched, the prediction was counted as correct, otherwise as wrong.", "labels": [], "entities": []}, {"text": "lists the number of correct predictions for each corpus and for each source language.", "labels": [], "entities": []}, {"text": "These results lead us to the following three conclusions:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of correctly predicted translations  for various corpora and source languages. Column  all refers to the parallel use of all four source lan- guages using the product-of-ranks algorithm.", "labels": [], "entities": []}]}