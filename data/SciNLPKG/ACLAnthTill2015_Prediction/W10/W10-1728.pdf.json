{"title": [{"text": "To Cache or not to Cache? Experiments with Adaptive Models in Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.7633424003918966}]}], "abstractContent": [{"text": "We report results of our submissions to the WMT 2010 shared translation task in which we applied a system that includes adaptive language and translation models.", "labels": [], "entities": [{"text": "WMT 2010 shared translation task", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.7330227971076966}]}, {"text": "Adaptation is implemented using exponentially decaying caches storing previous translations as the history for new predictions.", "labels": [], "entities": [{"text": "Adaptation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.933495819568634}]}, {"text": "Evidence from the cache is then mixed with the global background model.", "labels": [], "entities": []}, {"text": "The main problem in this setup is error propagation and our submissions essentially failed to improve over the competitive baseline.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7078155428171158}]}, {"text": "There are slight improvements in lexical choice but the global performance decreases in terms of BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.999340832233429}]}, {"text": "1 Motivation The main motivation of our submission was to test the use of adaptive language and translation models in a standard phrase-based SMT setting for the adaptation to wider context beyond sentence boundaries.", "labels": [], "entities": [{"text": "SMT setting", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.8729992210865021}]}, {"text": "Adaptive language models have along tradition in the speech recognition community and various approaches have been proposed to reduce model perplexity in this way.", "labels": [], "entities": [{"text": "speech recognition community", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.8352666099866232}]}, {"text": "The general task is to adjust statistical models to essential properties of natural language which are usually not captured by standard n-gram models or other local dependency models.", "labels": [], "entities": []}, {"text": "First of all, it is known that repetition is very common especially among content words (see, for example, words like \"honey\", \"milk\", \"land\" and \"flowing\" in figure 1).", "labels": [], "entities": []}, {"text": "In most cases a repeated occurrence of a content word is much more likely than its first appearance , which is not predicted in this way by a static language model.", "labels": [], "entities": []}, {"text": "Secondly, the use of expressions is related to the topic in the current discourse and the chance of using the same topic-related expressions again in running text is higher than a mixed-topic model would predict.", "labels": [], "entities": []}, {"text": "In translation another phenomenon can be observed , namely the consistency of translations.", "labels": [], "entities": [{"text": "consistency", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9682936668395996}]}, {"text": "Polysemous terms are usually not ambiguous in their context and, hence, their translations become consistent according to the contextual sense.", "labels": [], "entities": []}, {"text": "Even the choice between synonymous translations is rather consistent in translated texts as we can see in the example of subtitle translations in figure 1 (taken from the OPUS corpus (Tiedemann, 2009)).", "labels": [], "entities": [{"text": "OPUS corpus (Tiedemann, 2009))", "start_pos": 171, "end_pos": 201, "type": "DATASET", "confidence": 0.9304128544671195}]}, {"text": "The 10 commandments Kerd ma lui To some land flowing with milk and honey!", "labels": [], "entities": []}, {"text": "Till ett land fullt av mj\u00f6lk och honung.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We followed the setup proposed in the shared translation task.", "labels": [], "entities": [{"text": "shared translation task", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7093420128027598}]}, {"text": "Primarily we concentrated our efforts on German-English (de-en) and EnglishGerman (en-de) using the constrained track, i.e. using the provided training and development data from Europarl and the News domain.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 178, "end_pos": 186, "type": "DATASET", "confidence": 0.9843919277191162}, {"text": "News domain", "start_pos": 195, "end_pos": 206, "type": "DATASET", "confidence": 0.9397212862968445}]}, {"text": "Later we also added experiments for Spanish (es) and English using a similar setup.", "labels": [], "entities": []}, {"text": "Our baseline system incorporates the following components: We trained two separate 5-gram language models for each language with the standard smoothing strategies (interpolation and KneserNey discounting), one for Europarl and one for the News data.", "labels": [], "entities": [{"text": "KneserNey discounting", "start_pos": 182, "end_pos": 203, "type": "METRIC", "confidence": 0.8147892355918884}, {"text": "Europarl", "start_pos": 214, "end_pos": 222, "type": "DATASET", "confidence": 0.990260660648346}, {"text": "News data", "start_pos": 239, "end_pos": 248, "type": "DATASET", "confidence": 0.9406406879425049}]}, {"text": "All of them were estimated using the SRILM toolkit except the English News LM for which we applied RandLM ( to cope with the large amount of training data.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.8729022443294525}, {"text": "English News LM", "start_pos": 62, "end_pos": 77, "type": "DATASET", "confidence": 0.960523267587026}, {"text": "RandLM", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.8758949637413025}]}, {"text": "We also included two separate translation models, one for the combined Europarl and News data and one for the News data only.", "labels": [], "entities": [{"text": "Europarl and News data", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.8214021027088165}, {"text": "News data", "start_pos": 110, "end_pos": 119, "type": "DATASET", "confidence": 0.9465234875679016}]}, {"text": "They were estimated using the standard tools GIZA++ (Och and Ney, 2003) and Moses ( applying default settings and lowercased training data.", "labels": [], "entities": []}, {"text": "Lexicalized reordering was trained on the combined data set.", "labels": [], "entities": [{"text": "Lexicalized reordering", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7010253965854645}]}, {"text": "All baseline models were then tuned on the News test data from 2008 using minimum error rate training (MERT): Results on the WMT10 test set.", "labels": [], "entities": [{"text": "News test data from 2008", "start_pos": 43, "end_pos": 67, "type": "DATASET", "confidence": 0.9729047060012818}, {"text": "minimum error rate training (MERT)", "start_pos": 74, "end_pos": 108, "type": "METRIC", "confidence": 0.8644596934318542}, {"text": "WMT10 test set", "start_pos": 125, "end_pos": 139, "type": "DATASET", "confidence": 0.9860411485036215}]}, {"text": "In the adaptation experiments we applied exactly the same models using the feature weights from the baseline with the addition of the caching components in both, language models and translation models.", "labels": [], "entities": []}, {"text": "Cache parameters are not particularly tuned for the task in our initial experiments which could be one reason for the disappointing results we obtained.", "labels": [], "entities": []}, {"text": "Some of them can be integrated in the MERT procedure, for example, the interpolation weight of the translation cache.", "labels": [], "entities": []}, {"text": "However, tuning these parameters with the standard procedures appears to be difficult as we will see in later experiments presented in section 3.2.", "labels": [], "entities": []}, {"text": "Initially we used settings that appeared to be useful in previous experiments.", "labels": [], "entities": []}, {"text": "In particular, we used a language model cache of 10,000 words with a decay of \u03b1 = 0.0005 and an interpolation weight of 0.001.", "labels": [], "entities": []}, {"text": "A cache was used in all language models except the English News model for which caching was not available (because we did not implement this feature for RandLM).", "labels": [], "entities": [{"text": "RandLM", "start_pos": 153, "end_pos": 159, "type": "TASK", "confidence": 0.6705167293548584}]}, {"text": "The translation cache size was set to 5,000 with a decay factor of 0.001.", "labels": [], "entities": []}, {"text": "The weight for the translation cache was set to 0.001.", "labels": [], "entities": []}, {"text": "Furthermore, we filtered items for the translation cache using a length constraint of 4 characters or more and a transition cost threshold (log score) of -4.", "labels": [], "entities": [{"text": "transition cost threshold (log score)", "start_pos": 113, "end_pos": 150, "type": "METRIC", "confidence": 0.8056796874318805}]}, {"text": "The final results of the adaptive runs are shown in table 1.", "labels": [], "entities": []}, {"text": "In all but one case the cache-based result is below the baseline which is, of course, quite disappointing.", "labels": [], "entities": []}, {"text": "For German-English a small improvement can be observed.", "labels": [], "entities": []}, {"text": "However, this maybe rather accidental.", "labels": [], "entities": []}, {"text": "In general, it seems that the adaptive approach cannot cope with the noise added to the cache.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the WMT10 test set.", "labels": [], "entities": [{"text": "WMT10 test set", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.9360026319821676}]}, {"text": " Table 3: Results for English to German with vary- ing mixture weights.", "labels": [], "entities": [{"text": "vary- ing mixture weights", "start_pos": 45, "end_pos": 70, "type": "METRIC", "confidence": 0.9308920741081238}]}, {"text": " Table 4: Tuning cache parameters.", "labels": [], "entities": []}]}