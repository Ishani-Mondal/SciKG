{"title": [{"text": "Chunk-based Verb Reordering in VSO Sentences for Arabic-English Statistical Machine Translation", "labels": [], "entities": [{"text": "Verb Reordering", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.638902559876442}, {"text": "VSO Sentences", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.5960169583559036}, {"text": "Statistical Machine Translation", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.7416424751281738}]}], "abstractContent": [{"text": "In Arabic-to-English phrase-based statistical machine translation, a large number of syntactic disfluencies are due to wrong long-range reordering of the verb in VSO sentences, where the verb is anticipated with respect to the English word order.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 21, "end_pos": 65, "type": "TASK", "confidence": 0.6103629916906357}]}, {"text": "In this paper, we propose a chunk-based reordering technique to automatically detect and displace clause-initial verbs in the Arabic side of a word-aligned parallel corpus.", "labels": [], "entities": []}, {"text": "This method is applied to preprocess the training data, and to collect statistics about verb movements.", "labels": [], "entities": []}, {"text": "From this analysis , specific verb reordering lattices are then built on the test sentences before decoding them.", "labels": [], "entities": []}, {"text": "The application of our reordering methods on the training and test sets results in consistent BLEU score improvements on the NIST-MT 2009 Arabic-English benchmark.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.9721861779689789}, {"text": "NIST-MT 2009 Arabic-English benchmark", "start_pos": 125, "end_pos": 162, "type": "DATASET", "confidence": 0.9400518983602524}]}], "introductionContent": [{"text": "Shortcomings of phrase-based statistical machine translation (PSMT) with respect to word reordering have been recently shown on the ArabicEnglish pair by.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (PSMT)", "start_pos": 16, "end_pos": 67, "type": "TASK", "confidence": 0.7007703695978437}, {"text": "word reordering", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.7136001586914062}, {"text": "ArabicEnglish pair", "start_pos": 132, "end_pos": 150, "type": "DATASET", "confidence": 0.912460207939148}]}, {"text": "An empirical investigation of the output of a strong baseline we developed with the Moses toolkit () for the NIST 2009 evaluation, revealed that an evident cause of syntactic disfluency is the anticipation of the verb in Arabic Verb-SubjectObject (VSO) sentences -a class that is highly represented in the news genre . shows two examples where the Arabic main verb phrase comes before the subject.", "labels": [], "entities": [{"text": "NIST 2009 evaluation", "start_pos": 109, "end_pos": 129, "type": "DATASET", "confidence": 0.9448019862174988}]}, {"text": "In such sentences, the subject can be followed by adjectives, adverbs, coordinations, or appositions that further increase the distance between the verb In fact, Arabic syntax admits both SVO and VSO orders. and its object.", "labels": [], "entities": []}, {"text": "When translating into English -a primarily SVO language -the resulting long verb reorderings are often missed by the PSMT decoder either because of pure modeling errors or because of search errors (): i.e. their span is longer than the maximum allowed distortion distance, or the correct reordering hypothesis does not emerge from the explored search space because of a low score.", "labels": [], "entities": []}, {"text": "In the two examples, the missed verb reorderings result in different translation errors by the decoder, respectively, the introduction of a subject pronoun before the verb and, even worse, a verbless sentence.", "labels": [], "entities": []}, {"text": "In Arabic-English machine translation, other kinds of reordering are of course very frequent: for instance, adjectival modifiers following their noun and head-initial genitive constructions (Idafa).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7257807552814484}]}, {"text": "These, however, appear to be mostly local, therefore more likely to be modeled through phrase internal alignments, or to be captured by the reordering capabilities of the decoder.", "labels": [], "entities": []}, {"text": "In general there is a quite uneven distribution of word-reordering phenomena in Arabic-English, and long-range movements concentrate on few patterns.", "labels": [], "entities": []}, {"text": "Reordering in PSMT is typically performed by (i) constraining the maximum allowed word movement and exponentially penalizing long reorderings (distortion limit and penalty), and (ii) through so-called lexicalized orientation models.", "labels": [], "entities": [{"text": "Reordering", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9475151300430298}]}, {"text": "While the former is mainly aimed at reducing the computational complexity of the decoding algorithm, the latter assigns at each decoding step a score to the next source phrase to cover, according to its orientation with respect to the last translated phrase.", "labels": [], "entities": []}, {"text": "In fact, neither method discriminates among different reordering distances fora specific word or syntactic class.", "labels": [], "entities": []}, {"text": "To our view, this could be a reason for their inadequacy to properly deal with the reordering peculiarities of the Arabic-English language pair.", "labels": [], "entities": []}, {"text": "In: Examples of problematic SMT outputs due to verb anticipation in the Arabic source.", "labels": [], "entities": [{"text": "SMT outputs", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.936062753200531}]}, {"text": "this work, we introduce a reordering technique that addresses this limitation.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "2 we describe our verb reordering technique and in Sect.", "labels": [], "entities": []}, {"text": "3 we present statistics about verb movement collected through this technique.", "labels": [], "entities": []}, {"text": "We then discuss the results of preliminary MT experiments involving verb reordering of the training based on these findings (Sect. 4).", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9951007962226868}, {"text": "verb reordering", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7244692742824554}]}, {"text": "Afterwards, we explain our lattice approach to verb reordering in the test and provide evaluation on a well-known MT benchmark (Sect. 5).", "labels": [], "entities": [{"text": "verb reordering", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.6938339918851852}, {"text": "MT", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.9585237503051758}]}, {"text": "In the last two sections we review some related work and draw the final conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we investigate how verb reordering on the source language can affect translation quality.", "labels": [], "entities": []}, {"text": "We apply verb reordering both on the training and the test data.", "labels": [], "entities": []}, {"text": "However, while the parallel corpus used for training can be reordered by exploiting word alignments, for the test corpus we need a verb reordering \"prediction model\".", "labels": [], "entities": []}, {"text": "For these preliminary experiments, we assumed that optimal verb-reordering of the test data is provided by an oracle that has access to the word alignments with the reference translations.", "labels": [], "entities": []}, {"text": "For the experiments, we relied on the existing Moses-implementation of non-monotonic decoding for word lattices) with some fixes concerning the computation of reordering distance.", "labels": [], "entities": []}, {"text": "The translation system is the same as the one presented in Sect.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.966033935546875}]}, {"text": "4, to which we added an additional feature function evaluating the lattice weights (weight-i).", "labels": [], "entities": []}, {"text": "Instead of rerunning MERT, we directly estimated the additional feature-function weight over a suitable interval (0.002 to 0.5), by running the decoder several times on the development set.", "labels": [], "entities": []}, {"text": "The resulting optimal weight was 0.05.", "labels": [], "entities": []}, {"text": "presents results on three test sets: Eval08-NW which was used to calibrate the reordering rules, Reo08-NW a specific test set consisting of the 33% of Eval08-NW sentences that actually require verb reordering, and Eval09-NW a yet unseen dataset (newswire section of the NIST-MT09 evaluation set, 586 sentences).", "labels": [], "entities": [{"text": "Reo08-NW", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.7368978261947632}, {"text": "NIST-MT09 evaluation set", "start_pos": 270, "end_pos": 294, "type": "DATASET", "confidence": 0.9294523398081461}]}, {"text": "Best results with lattice decoding were obtained with a distortion limit (DL) of 4, while best performance of text decoding was obtained with a DL of 6.", "labels": [], "entities": [{"text": "distortion limit (DL)", "start_pos": 56, "end_pos": 77, "type": "METRIC", "confidence": 0.9532977223396302}, {"text": "DL", "start_pos": 144, "end_pos": 146, "type": "METRIC", "confidence": 0.950863242149353}]}, {"text": "As we hoped, translating a verb reordering lattice yields an additional improvement to the reordering of the training corpus: from 43.67% to 44.04% on Eval08-NW and from 48.53% to 48.96% on Eval09-NW.", "labels": [], "entities": [{"text": "Eval08-NW", "start_pos": 151, "end_pos": 160, "type": "DATASET", "confidence": 0.9526678323745728}, {"text": "Eval09-NW", "start_pos": 190, "end_pos": 199, "type": "DATASET", "confidence": 0.974024772644043}]}, {"text": "The gap between the baseline and the score obtainable by oracle verb reordering, as estimated in the preliminary experiments on Eval08-NW (44.36%), has been largely filled.", "labels": [], "entities": [{"text": "Eval08-NW", "start_pos": 128, "end_pos": 137, "type": "DATASET", "confidence": 0.891061007976532}]}, {"text": "On the specific test set -Reo08-NW -we observe a performance drop when reordered models are applied to non-reordered (plain) input: from 46.90% to 46.64%.", "labels": [], "entities": [{"text": "Reo08-NW", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.7914786338806152}]}, {"text": "Hence it seems that the mismatch between training and test data is significantly impacting on the reordering capabilities of the system with respect to verbs.", "labels": [], "entities": []}, {"text": "We speculate that such negative effect is diluted in the full test set (Eval08-NW) and compensated by the positive influence of verb reordering on phrase extraction.", "labels": [], "entities": [{"text": "Eval08-NW", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.7681149840354919}, {"text": "phrase extraction", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.7543545365333557}]}, {"text": "Indeed, when the lattice technique is applied we get an improvement of about 0.6 point over the baseline, which is still a fair result, but not as good as the one obtained on the general test sets.", "labels": [], "entities": []}, {"text": "Finally, our approach led to an overall gain of 0.8 point BLEU over the baseline, on Eval09-NW.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9993921518325806}, {"text": "Eval09-NW", "start_pos": 85, "end_pos": 94, "type": "DATASET", "confidence": 0.9889357686042786}]}, {"text": "We believe this is a satisfactory result, given the fairly good starting performance, and given that the BLEU metric is known not to be very sensitive to word order variations).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9963558912277222}]}, {"text": "For the future, we plan to also use specific evaluation metrics that will allow us to isolate the impact of our approach on reordering, like the ones by: BLEU scores of baseline and reordered system on plain test and on reordering lattices.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.999240517616272}]}], "tableCaptions": [{"text": " Table 1: BLEU scores of baseline and reordered  system on plain test and on reordering lattices.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989185333251953}]}]}