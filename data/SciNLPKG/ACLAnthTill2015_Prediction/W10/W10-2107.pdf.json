{"title": [{"text": "You talking to me? A predictive model for zero auxiliary constructions", "labels": [], "entities": []}], "abstractContent": [{"text": "As a consequence of the established practice to prefer training data obtained from written sources, NLP tools encounter problems in handling data from the spoken domain.", "labels": [], "entities": []}, {"text": "However, accurate models of spoken data are increasingly in demand for naturalistic speech generation and machine translations in speech-like contexts (such as chat windows and SMS).", "labels": [], "entities": [{"text": "naturalistic speech generation", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.7818387349446615}, {"text": "machine translations", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.7308655977249146}]}, {"text": "There is a widely held assumption in the linguistic field that spoken language is an impoverished form of written language.", "labels": [], "entities": []}, {"text": "However, we show that spoken data is not unpredictably irregular and that language models can benefit from detailed consideration of spoken language features.", "labels": [], "entities": []}, {"text": "This paper considers one specific construction which is largely restricted to the spoken domain-the ZERO AUXILIARY-and makes a predictive model of that construction for native speakers of British En-glish.", "labels": [], "entities": [{"text": "ZERO", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.41572892665863037}, {"text": "AUXILIARY-and", "start_pos": 105, "end_pos": 118, "type": "METRIC", "confidence": 0.4273223280906677}, {"text": "British En-glish", "start_pos": 188, "end_pos": 204, "type": "DATASET", "confidence": 0.9042471349239349}]}, {"text": "The model can predict zero auxiliary occurrence in the BNC with 96.9% accuracy.", "labels": [], "entities": [{"text": "BNC", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8685369491577148}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9986979961395264}]}, {"text": "We will demonstrate how this model can be integrated into existing parsing tools, increasing the number of successful parses for this zero auxiliary construction by around 30%, and thus improving the performance of NLP applications which rely on parsing.", "labels": [], "entities": []}], "introductionContent": [{"text": "Up to this point, statistical Natural Language Processing (NLP) tools have generally been trained on corpora that are representative of written rather than spoken language.", "labels": [], "entities": [{"text": "statistical Natural Language Processing (NLP)", "start_pos": 18, "end_pos": 63, "type": "TASK", "confidence": 0.685528039932251}]}, {"text": "A major factor behind this decision to use written data is that it is far easier to collect than spoken data.", "labels": [], "entities": []}, {"text": "Newswire, for instance, maybe harvested readily and in abundance.", "labels": [], "entities": [{"text": "Newswire", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9205958843231201}]}, {"text": "Once collected, written language requires relatively little processing before it can be used for training a statistical model.", "labels": [], "entities": []}, {"text": "Processing of spoken data, on the other hand, involves at the very least transcription -which usually requires a human transcriber.", "labels": [], "entities": []}, {"text": "Since transcription is a slow and laborious task, the collection of spoken data is highly resource intensive.", "labels": [], "entities": []}, {"text": "But this relative difficulty in collection is not the only reason that spoken language data has been sidelined.", "labels": [], "entities": []}, {"text": "Had spoken data been considered to be crucial to the production of NLP applications greater efforts might have been made to obtain it.", "labels": [], "entities": []}, {"text": "However, on account of some of its characteristic features such as hesitations, interruptions and ellipsis, spoken language is often dismissed as nothing more than a noisy approximation to 'real' or 'intended' language.", "labels": [], "entities": []}, {"text": "In some forums, written language is held up as an idealised form of language toward which speakers aspire and onto which spoken language should be retrofitted.", "labels": [], "entities": []}, {"text": "This is an artefact of the theoretical notion of a 'competence'-'performance' dichotomy) with the latter deemed irrelevant and ignored in mainstream linguistic research.", "labels": [], "entities": []}, {"text": "The consequence of the established practice to sideline spoken data is that NLP tools are inherently error prone when handling data from the spoken domain.", "labels": [], "entities": []}, {"text": "With increasing calls for speech to be considered the primary form of language and to be treated as such (Sampson 2001: 7 1 ; Cerm\u00e1k 2009: 115 2 ; Haugh 2009: 74 3 ) and a growing trend for NLP techniques to be integrated into cognitive and neurolinguistic research as well as forensic appli-1 Speech is \"unquestionably the more natural, basic mode of language behaviour\".", "labels": [], "entities": []}, {"text": "2 \"From a linguistic point of view, spoken corpora should be primary for research but that has not been the case so far\".", "labels": [], "entities": []}, {"text": "3 Haugh observes that \"spoken language and interaction lie at the core of human experience\" but bemoans the \"relative neglect of spoken language in corpora to date\".", "labels": [], "entities": []}, {"text": "cations, there are now compelling reasons to examine spoken data more closely.", "labels": [], "entities": []}, {"text": "Accurate models of spoken data are increasingly in demand for naturalistic speech generation and machine translations in speech-like contexts (such as humanmachine dialogue, chat windows and SMS).", "labels": [], "entities": [{"text": "naturalistic speech generation", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.7984619140625}]}, {"text": "The main research aim of our work is to show that spoken data should not be considered error prone and therefore unpredictably irregular.", "labels": [], "entities": []}, {"text": "We show that language models can be improved in increments as we deepen our understanding of spoken language features.", "labels": [], "entities": []}, {"text": "We investigate ZERO AUX-ILIARY progressive aspect constructions -those which do not feature the supposedly obligatory auxiliary verb, as in  The zero auxiliary is a non-standard feature which for the most part is known to be restricted to speech.", "labels": [], "entities": [{"text": "ZERO AUX-ILIARY progressive aspect constructions", "start_pos": 15, "end_pos": 63, "type": "TASK", "confidence": 0.5899788618087769}]}, {"text": "A corpus study of spoken British English indicates that in progressive aspect interrogatives with second person subjects (as in (1) above) the auxiliary occurs in zero form in 27% of constructions found.", "labels": [], "entities": []}, {"text": "The equivalent figure from the written section of the corpus is just 5.4%.", "labels": [], "entities": [{"text": "written section of the corpus", "start_pos": 31, "end_pos": 60, "type": "DATASET", "confidence": 0.7192896127700805}]}, {"text": "Consequently, existing NLP techniques -since they are based on written training data -are unlikely to deal appropriately with zero auxiliary constructions.", "labels": [], "entities": []}, {"text": "We report below on the corpus study in full and use the results of logistic regression to design a predictive model of zero auxiliary occurrence in spoken English.", "labels": [], "entities": []}, {"text": "The model is based on contextual grammatical features and can predict zero auxiliary occurrence in the British National Corpus (BNC; 2007) with 96.9% accuracy.", "labels": [], "entities": [{"text": "British National Corpus (BNC; 2007)", "start_pos": 103, "end_pos": 138, "type": "DATASET", "confidence": 0.9674024805426598}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9969210624694824}]}, {"text": "Finally, we discuss how this model can be used to improve the performance of NLP techniques in the spoken domain, demonstrating its implementation in the RASP system (Robust Accurate Statistical Parsing;).", "labels": [], "entities": []}, {"text": "This paper underlines why awareness of nonstandard linguistic features matters.", "labels": [], "entities": []}, {"text": "Targeted data extraction from large corpus resources allows the construction of more informed language models which have been trained on naturalistic spoken usage rather than standard and restricted rules of written language.", "labels": [], "entities": []}, {"text": "Such work has only been made possible with the advent of large spoken language corpora such as the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 99, "end_pos": 102, "type": "DATASET", "confidence": 0.9584958553314209}]}, {"text": "Even so, the resourceheavy nature of spoken data collection means that speech transcriptions constitute only one tenth of this 100 million word corpus . Nevertheless, it is an invaluable resource made up of a range of speech genres including spontaneous face-to-face conversation, a fact which makes it unique among corpora.", "labels": [], "entities": []}, {"text": "Since conversational dialogue is the predominant language medium, the BNC offers the best chance of modelling speech as it occurs naturally.", "labels": [], "entities": [{"text": "BNC", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.8344600200653076}]}, {"text": "This work has important implications for both computational and theoretical linguistics.", "labels": [], "entities": []}, {"text": "On the one hand, we can improve various NLP techniques with more informed language models, and on the other hand we are reminded that the space of grammatical possibility is not restricted and that continued empirical investigation is key in order to arrive at the fullest possible description of language use.", "labels": [], "entities": []}], "datasetContent": [{"text": "The logistic function is defined by: The variable z is representative of the set of predictors and is defined by: where \u03b2 0 , \u03b2 1 , \u03b2 2 ...", "labels": [], "entities": []}, {"text": "\u03b2 k are the regression coefficients of predictors x 1 , x 2 ..", "labels": [], "entities": []}, {"text": "The predictors explored in this paper are encodings of the syntactic properties of the annotated sentences.", "labels": [], "entities": []}, {"text": "The predictors and their encodings are indicated in.", "labels": [], "entities": []}, {"text": "The logistic function is constrained to values between 0 and 1 and represents the probability of membership of one of the two categories (zero auxiliary or auxiliary supplied).", "labels": [], "entities": []}, {"text": "In our case an f (z) > 0.5 indicates that there is likely to be a zero auxiliary.", "labels": [], "entities": []}, {"text": "The logistic function defined by the coefficients in is able to predict correct category membership for 96.9% of the sentences in the annotated corpus.", "labels": [], "entities": []}, {"text": "All coefficients are highly significant to the logistic function (p<0.001) with the exception of perfect aspect and first person subject -which are both significant nevertheless (p<0.05).", "labels": [], "entities": []}, {"text": "For this model, positive coefficients indicate that the associated syntactic properties raise the probability of a zero auxiliary occurring.", "labels": [], "entities": []}, {"text": "Large coefficients more strongly influence the probability of the zero auxiliary whereas near-zero coefficients have little influence.", "labels": [], "entities": []}, {"text": "From the coefficients in we see that the strongest predictor of a zero auxiliary is the occurrence of a zero subject (as in the utterance, 'leaving now.').", "labels": [], "entities": []}, {"text": "An interrogative utterance is also a good candidate, as is the second person subject (e.g. 'you eating those olives?').", "labels": [], "entities": []}, {"text": "However, a past tense utterance is an unlikely candidate fora zero auxiliary construction, as is a negated utterance.", "labels": [], "entities": []}, {"text": "6 Discussion -using the predictive model to aid parsing As mentioned above, since parsers are trained on written data they can often display poor performance on text transcribed from the spoken domain.", "labels": [], "entities": [{"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9647359848022461}]}, {"text": "From the results of our corpus study we know that the zero auxiliary occurs in approximately 4.2% of progressive constructions in spoken language and we can extrapolate that it will occur in less than 1% (approximately 0.8%) of all progressive constructions in written language.", "labels": [], "entities": []}, {"text": "A statistical parser trained on written language will therefore be prone to undergo parsing failure for everyone in twenty-five progressive sentences.", "labels": [], "entities": []}, {"text": "This is no insignificant problem, especially when it is remarked that the progressive is in high frequency usage (there are one thousand ING-forms featuring in progressive constructions for everyone million words of sBNC) and that its use is known to be spreading ().", "labels": [], "entities": []}, {"text": "Compounded with those parser breakdowns caused by other speech phenomena (for instance, repetition and elision), high numbers of parse failures on progressive constructions will render NLP accuracy on spoken language intolerable for any applications which rely on accurate parsing as a foundation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9398478269577026}]}, {"text": "However, we have shown above that features of spoken language such as the zero auxiliary should not bethought of as errors or as unpredictable deviations from the written form, but rather can be considered to be consistent and predictable events.", "labels": [], "entities": []}, {"text": "In this section we illustrate how our predictive model for zero auxiliary occurrence maybe integrated into a parser pipeline in order to aid the parsing of spoken language.", "labels": [], "entities": [{"text": "parsing of spoken language", "start_pos": 145, "end_pos": 171, "type": "TASK", "confidence": 0.8909361809492111}]}, {"text": "In this way we build on the increasingly robust engineering of statistical NLP tools trained on written language by allowing them to adapt to the spoken domain on the basis of the linguistic study of speech phenomena.", "labels": [], "entities": []}, {"text": "In general the notion of 'parsing' an utterance involves a chain of several processes: utterance boundary detection, tokenization, part-of-speech tagging, and then parsing.", "labels": [], "entities": [{"text": "parsing' an utterance", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.874643549323082}, {"text": "utterance boundary detection", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.6893195907274882}, {"text": "part-of-speech tagging", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.6703477799892426}]}, {"text": "We suggest that when it is known that the language to be parsed is from the spoken domain the pipeline of processes should be run in a SPEECH AWARE MODE.", "labels": [], "entities": [{"text": "SPEECH AWARE MODE", "start_pos": 135, "end_pos": 152, "type": "METRIC", "confidence": 0.7273178497950236}]}, {"text": "Extra functionality would be incorporated into each of the stages according to the findings of linguistic research into spoken language.", "labels": [], "entities": []}, {"text": "In other work we have adapted the tokenization and tagging stages of the pipeline based on predictors that indicate when interjections (e.g. 'umm', 'err' and 'ah') have been 'used' as punctuation or lexical items.", "labels": [], "entities": []}, {"text": "We also incorporate intonation phrases as predictors for utterance boundary detection.", "labels": [], "entities": [{"text": "utterance boundary detection", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.8203802704811096}]}, {"text": "Here, we augment the parsing stage of the pipeline by allowing an informed re-parse of utterances in which a parse failure is likely to have been caused by a zero auxiliary.", "labels": [], "entities": [{"text": "parsing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9603800773620605}]}, {"text": "We present this section with reference to the specific mechanics and output formats of the RASP system but our algorithm is by no means parser specific and could be adapted for other parsers quite easily.", "labels": [], "entities": []}, {"text": "Utterances parsed with RASP maybe expressed as 'grammatical relations'.", "labels": [], "entities": [{"text": "RASP", "start_pos": 23, "end_pos": 27, "type": "TASK", "confidence": 0.8809933662414551}]}, {"text": "RASP's grammatical relations are theorygeneral, binary relations between lexical terms and are expressed in the form of head-dependancy relations as shown in (3),.", "labels": [], "entities": [{"text": "RASP", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8429142236709595}]}, {"text": "Consider the utterance 'what are you playing?'.", "labels": [], "entities": []}, {"text": "When we parse this with RASP we get grammatical relations (4), (5) and (6) in.", "labels": [], "entities": [{"text": "RASP", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.5039920806884766}]}, {"text": "The capital letter codes following the ':' symbols are partof-speech tags (from the CLAWS-2 tagset) which have been assigned to the lexical tokens by the tagger of the RASP system.", "labels": [], "entities": [{"text": "CLAWS-2 tagset", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.8895387351512909}]}, {"text": "Here PPY indicates the pronoun 'you'; VVG indicates the ING-form of lexical verb; VBR indicates 'be' in 3rd person present tense; and DDQ indicates a wh-determiner.", "labels": [], "entities": [{"text": "VVG", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.8527170419692993}, {"text": "ING-form", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.8934618830680847}, {"text": "VBR", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9154066443443298}]}, {"text": "The relation (4) tells us that 'you' is the subject of 'playing'; relation (5) tells us that 'what' is taking the place of the object being played; and relation (6) tells us that there is an auxiliary relationship between 'are' and 'playing'.", "labels": [], "entities": []}, {"text": "This is much as we would expect.", "labels": [], "entities": []}, {"text": "However, if we try to parse 'what you playing?'", "labels": [], "entities": []}, {"text": "The single relation is returned where ideally we would like both and, as we did when the auxiliary was present.", "labels": [], "entities": []}, {"text": "For the utterance, 'you playing?'", "labels": [], "entities": []}, {"text": "RASP returns the under-specified grammatical relation which is simply indicating that 'you' is an argument of 'playing' but not which type of argument (whether a subject, direct object, etc).", "labels": [], "entities": [{"text": "RASP", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.907524585723877}]}, {"text": "Ideally we would like to retrieve at least (4) as we would have if we parsed the utterance 'are you playing?'.", "labels": [], "entities": []}, {"text": "For these examples, we shall consider the failure to identify the correct subject and object of the progressive verb to be a parsing failure.", "labels": [], "entities": []}, {"text": "We integrate the zero auxiliary predictive model with parsing technology to improve the parsing of zero auxiliaries in spoken language.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9661974310874939}, {"text": "parsing of zero auxiliaries", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.8354846239089966}]}, {"text": "Note that we use the RASP system but our algorithm is by no means parser specific.", "labels": [], "entities": []}, {"text": "The only prerequisite is that the parser must be able to identify relations of some kind between the subject noun and INGform (possibly via a parsing rule) and also be able extract values for the predictors (through either a rich tagset or from the identification of key speech tokens).", "labels": [], "entities": []}, {"text": "The illustrative method we discuss here is integrated into the parsing pipeline in the event of a parse failure but there are several alternative methods that might also be considered.", "labels": [], "entities": [{"text": "parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9828636050224304}]}, {"text": "For instance, by using the predictive model earlier in the parsing system pipeline a modified tagset could be used which updates the ING-form tag with anew tag to indicate that there is also a missing auxiliary.", "labels": [], "entities": []}, {"text": "Another method might involve altering rule probabilities or adding extra parser rules so that parsing only has to occur once.", "labels": [], "entities": []}, {"text": "Our other work in this area suggests that the final deci-sion on whereto add the spoken language modifications within the parsing pipeline will largely depend on the interaction of the phenomena in question with other speech phenomena.", "labels": [], "entities": []}, {"text": "With the proviso that it is a preliminary integration of the predictive model into a parsing system, we propose the following algorithm for zero auxiliaries in spoken language.", "labels": [], "entities": []}, {"text": "When 'speech aware mode' is activated, if we encounter a parse failure then we first check the part-of-speech tags of the utterance to ascertain if the sentence contains the ING-form requisite fora progressive construction: \u2022 IF no ING-form is found: STOP.", "labels": [], "entities": [{"text": "STOP", "start_pos": 251, "end_pos": 255, "type": "METRIC", "confidence": 0.9567060470581055}]}, {"text": "Our model predicts zero auxiliaries in progressive constructions-there is nothing more we can do with the input.", "labels": [], "entities": []}, {"text": "\u2022 ELSE: An ING-form is found.", "labels": [], "entities": [{"text": "ELSE", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9939396381378174}, {"text": "ING-form", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9686693549156189}]}, {"text": "Extract all grammatical relations that were obtained by the parse which contained the ING-form in the head position (these would be grammatical relations that have the general format of (8) in).", "labels": [], "entities": []}, {"text": "We will refer to this set of grammatical relations as GRS.", "labels": [], "entities": [{"text": "GRS", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.5785214304924011}]}, {"text": "-IF there is an auxiliary relation present in GRS: STOP.", "labels": [], "entities": [{"text": "GRS", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.5904920101165771}, {"text": "STOP", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.912558376789093}]}, {"text": "If at least one of the extracted grammatical relations is an auxiliary relation, similar to (6) in, an auxiliary is present-we do not have a zero auxiliary construction.", "labels": [], "entities": []}, {"text": "7 -ELSE: The utterance is a candidate for zero auxiliary.", "labels": [], "entities": [{"text": "ELSE", "start_pos": 3, "end_pos": 7, "type": "METRIC", "confidence": 0.9586854577064514}]}, {"text": "Having determined a possible candidate for zero auxiliary we carryout the following steps: 1.", "labels": [], "entities": []}, {"text": "Ascertain values for the zero auxiliary predictors (explained in more detail below).", "labels": [], "entities": []}, {"text": "2. Calculate the value of the logistic function f (z) using the obtained predictor values with their coefficients (shown in).", "labels": [], "entities": []}, {"text": "4. Add the auxiliary to the sentence (choosing which auxiliary based on the predictor values-see below).", "labels": [], "entities": []}, {"text": "6. Remove (or flag) the auxiliary grammatical relation from the newly obtained parser output.", "labels": [], "entities": []}, {"text": "8 For step 1 above properties of the current utterance have to be obtained.", "labels": [], "entities": []}, {"text": "The subject person, plural subject, zero subject and pronoun subject properties are ascertained by looking at the part-ofspeech of the dependant noun/pronoun within any subject relations occurring in the set GRS (grammatical relations headed by the ING-form).", "labels": [], "entities": []}, {"text": "Subject relations would look similar to (4) in.", "labels": [], "entities": []}, {"text": "If there is no subject grammatical relation, any underspecified 'arg' relation (such as (7) in) are considered.", "labels": [], "entities": []}, {"text": "If neither of these relations are present in GRS then a zero subject is inferred.", "labels": [], "entities": [{"text": "GRS", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.8568629026412964}]}, {"text": "The person and plurality of the subject noun is encoded within its CLAWS2 part-of-speech tag.", "labels": [], "entities": [{"text": "CLAWS2 part-of-speech tag", "start_pos": 67, "end_pos": 92, "type": "DATASET", "confidence": 0.8182663917541504}]}, {"text": "For instance, a PPHS1 tag, which is used to indicate 'him' or 'her' would tell us we have a third person, singular pronoun.", "labels": [], "entities": []}, {"text": "Once extracted the properties are encoded as shown in for use as the predictor values in the logistic function.", "labels": [], "entities": []}, {"text": "In order to select the correct auxiliary and location for insertion in step 4 the utterance values are consulted.", "labels": [], "entities": []}, {"text": "For instance, an interrogative utterance in the present tense, not in perfect aspect, with a second person singular subject will require insertion of the auxiliary 'are' after the subject.", "labels": [], "entities": []}, {"text": "A zero subject zero auxiliary, on the other hand, requires restoration of both subject and auxiliary.", "labels": [], "entities": []}, {"text": "Where a question mark indicates it has been used in an interrogative clause the subject is assumed to be sec- We also remove (or flag) the subject relation in cases where a subject also had to be added in step 4.", "labels": [], "entities": []}, {"text": "This would occur when the original utterance exhibited a zero subject.", "labels": [], "entities": []}, {"text": "All common nouns are assumed to be 3rd person and all instances of 'you' were considered to be singular (as was the case during corpus annotation).", "labels": [], "entities": []}, {"text": "ond person -as is the casein most questions -and so the auxiliary-subject combination 'are you' is restored before the ING-form.", "labels": [], "entities": [{"text": "ING-form", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.6650532484054565}]}, {"text": "Without a question mark, the clause is assumed to be declarative and so the first person singular subject-auxiliary combination 'I am' is restored before the ING-form . We withheld 10% of the zero auxiliary corpus for test purposes.", "labels": [], "entities": [{"text": "ING-form", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.5321035385131836}]}, {"text": "The integration of the predictive model into the parser allowed us to successfully parse 31.4% of previously unparsable zeroauxilaries.", "labels": [], "entities": []}, {"text": "On cleaned spoken transcripts (i.e. with speech phenomena other than the zero auxiliary, such as repetitions, removed) this algorithm allows us to retrieve the correct subject-object relations for an extra 1238 utterances within our annotated corpus (which again accounts for approximately one third of the previously unparsable zero-auxilaries).", "labels": [], "entities": []}, {"text": "This is a significant step forward for any applications building on top of a parsing infrastructure.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Auxiliary realisation in second person  progressive interrogatives in the BNC.", "labels": [], "entities": [{"text": "Auxiliary realisation in second person  progressive interrogatives", "start_pos": 10, "end_pos": 76, "type": "TASK", "confidence": 0.6491563107286181}, {"text": "BNC", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9387900233268738}]}]}