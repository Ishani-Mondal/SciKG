{"title": [{"text": "Generating and Validating Abstracts of Meeting Conversations: a User Study", "labels": [], "entities": [{"text": "Generating and Validating Abstracts of Meeting Conversations", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.7907987577574593}]}], "abstractContent": [{"text": "In this paper we present a complete system for automatically generating natural language abstracts of meeting conversations.", "labels": [], "entities": []}, {"text": "This system is comprised of components relating to interpretation of the meeting documents according to a meeting ontology, transformation or content selection from that source representation to a summary representation, and generation of new summary text.", "labels": [], "entities": []}, {"text": "Ina formative user study, we compare this approach to gold-standard human abstracts and extracts to gauge the usefulness of the different summary types for browsing meeting conversations.", "labels": [], "entities": []}, {"text": "We find that our automatically generated summaries are ranked significantly higher than human-selected extracts on coherence and usability criteria.", "labels": [], "entities": []}, {"text": "More generally, users demonstrate a strong preference for abstract-style summaries over extracts.", "labels": [], "entities": []}], "introductionContent": [{"text": "The most common solution to the task of summarizing spoken and written data is sentence (or utterance) extraction, where binary sentence classification yields a cut-and-paste summary comprising informative sentences from the document concatenated in anew, condensed document.", "labels": [], "entities": [{"text": "summarizing spoken and written data", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.8819162726402283}, {"text": "sentence (or utterance) extraction", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.633439893523852}]}, {"text": "Such extractive approaches have dominated the field of automatic summarization for decades, in large part because extractive systems do not require a natural language generation (NLG) component since the summary sentences are simply lifted from the source document.", "labels": [], "entities": [{"text": "summarization", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.7141978740692139}]}, {"text": "Extrinsic evaluations have shown that, while extractive summaries maybe less coherent than human abstracts, users still find them to be valuable tools for browsing documents.", "labels": [], "entities": []}, {"text": "However, these previous evaluations also illustrate that concise abstracts are generally preferred by users and lead to higher objective task scores.", "labels": [], "entities": []}, {"text": "A weakness of typical extractive summaries is that the end user does not know why the extracted sentences are important; exploring the original sentence context maybe the only way to resolve this uncertainty.", "labels": [], "entities": []}, {"text": "And if the input source document consists of noisy, unstructured text such as ungrammatical, disfluent multi-party speech, then the resultant extract is likely to be noisy and unstructured as well.", "labels": [], "entities": []}, {"text": "Herein we describe a complete and fully automatic system for generating abstract summaries of meeting conversations.", "labels": [], "entities": [{"text": "generating abstract summaries of meeting conversations", "start_pos": 61, "end_pos": 115, "type": "TASK", "confidence": 0.6910329212745031}]}, {"text": "Our abstractor maps input sentences to a meeting ontology, generates messages that abstract over multiple sentences, selects the most informative messages, and ultimately generates new text to describe these relevant messages at a high level.", "labels": [], "entities": []}, {"text": "We conduct a user study where participants must browse a meeting conversation within a very constrained timeframe, having a summary at their disposal.", "labels": [], "entities": []}, {"text": "We compare our automatic abstracts with human abstracts and extracts and find that our abstract summaries significantly outperform extracts in terms of coherence and usability according to human ratings.", "labels": [], "entities": []}, {"text": "In general, users rate abstract-style summaries much more highly than extracts for these conversations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}