{"title": [{"text": "Investigating Clarification Strategies in a Hybrid POMDP Dialog Manager", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate the clarification strategies exhibited by a hybrid POMDP dialog manager based on data obtained from a phone-based user study.", "labels": [], "entities": []}, {"text": "The dialog manager combines task structures with a number of POMDP policies each optimized for obtaining an individual concept.", "labels": [], "entities": []}, {"text": "We investigate the relationship between dialog length and task completion.", "labels": [], "entities": []}, {"text": "In order to measure the effectiveness of the clarification strategies, we compute concept pre-cisions for two different mentions of the concept in the dialog: first mentions and final values after clarifications and similar strategies, and compare this to a rule-based system on the same task.", "labels": [], "entities": []}, {"text": "We observe an improvement in concept precision of 12.1% for the hybrid POMDP compared to 5.2% for the rule-based system.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9625350832939148}, {"text": "POMDP", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.6513353586196899}]}], "introductionContent": [{"text": "In recent years, probabilistic models of dialog have been introduced into dialog management, the part of the spoken dialog system that takes the action decision.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7791524231433868}]}, {"text": "A major motivation is to improve robustness in the face of uncertainty, in particular due to speech recognition errors.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7180567979812622}]}, {"text": "The interaction is characterized as a dynamic system that manipulates its environment by performing dialog actions and perceives feedback from the environment through its sensors.", "labels": [], "entities": []}, {"text": "The original sensory information is obtained from the speech recognition (ASR) results which are typically processed by a spoken language understanding module (SLU) before being passed onto the dialog manager (DM).", "labels": [], "entities": [{"text": "speech recognition (ASR)", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.852231478691101}]}, {"text": "The seminal work of () modeled dialog management as a Markov Decision Process (MDP).", "labels": [], "entities": [{"text": "dialog management", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.9151970744132996}]}, {"text": "Using reinforcement learning as the general learning paradigm, an MDP-based dialog manager incrementally acquires a policy by obtaining rewards about actions it performed in specific dialog states.", "labels": [], "entities": []}, {"text": "As we found in earlier experiments, an MDP can learn to gradually drop the use of clarification questions if there is no noise.", "labels": [], "entities": []}, {"text": "This is due to the fact that clarifications do not improve the outcome of the dialog, i.e. the reward.", "labels": [], "entities": []}, {"text": "However, with extremely high levels of noise, the learner prefers to end the dialog immediately (.", "labels": [], "entities": []}, {"text": "In contrast to deliberate decision making in the pragmatist tradition of dialog processing, reinforcement learning can be regarded as low-level decision making.", "labels": [], "entities": [{"text": "dialog processing", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7702308595180511}]}, {"text": "MDPs do not account for the observational uncertainty of the speech recognition results, a key challenge in spoken dialog systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.6939965933561325}]}, {"text": "Partially Observable Markov Decision Process (POMDPs) address this issue by explicitly modeling how the distribution of observations is governed by states and actions.", "labels": [], "entities": []}, {"text": "In this work, we describe the evaluation of a divide-and-conquer approach to dialog management with POMDPs that optimizes policies for acquiring individual concepts separately.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.8647348284721375}]}, {"text": "This makes optimization much easier and allows us to model the confusability of concrete concept values explicitly.", "labels": [], "entities": []}, {"text": "This also means that different clarification strategies are learned for individual concepts and even individual concept values.", "labels": [], "entities": []}, {"text": "The use of the POMDP policies is orchestrated by an explicit task structure, resulting in a hybrid approach to dialog management.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.8473560810089111}]}, {"text": "The evaluation involved a user study of 20 subjects in a tourist information domain.", "labels": [], "entities": []}, {"text": "The system is compared against a rule-based baseline system in the same domain that was also evaluated with 20 subjects.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted user studies with two systems involving 20 subjects and 8 tasks in each study.: Task completion and length metrics based on statistical language models for the opening prompt, and is grammar-based otherwise.", "labels": [], "entities": []}, {"text": "One system used the hybrid POMDP-DM, the other is a rule-based dialog manager that uses explicit, heuristically set confidence thresholds to trigger the use of clarification questions ().", "labels": [], "entities": []}, {"text": "Dialog length and task completion shows task completion rates ('TCR') and durations ('#turns') for the POMDP and rule-based systems.", "labels": [], "entities": [{"text": "task completion rates ('TCR')", "start_pos": 40, "end_pos": 69, "type": "METRIC", "confidence": 0.7519397685925165}, {"text": "durations", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.8929028511047363}]}, {"text": "Task completion in this metric is defined as the number of tasks of a certain type that were successfully concluded.", "labels": [], "entities": []}, {"text": "Duration is measured in the number of turn pairs consisting of a system action followed by a user action.", "labels": [], "entities": [{"text": "Duration", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9254098534584045}]}, {"text": "We combine the counts for two closely related lodging tasks.", "labels": [], "entities": []}, {"text": "The number of tasks is shown in brackets.", "labels": [], "entities": []}, {"text": "shows that the POMDP-DM successfully concludes more and longer lodging tasks and almost as many event tasks.", "labels": [], "entities": []}, {"text": "In general, the POMDP policies can be described as more cautious although obviously the dialog length of the rule system depends on the chosen thresholds.", "labels": [], "entities": []}, {"text": "Concept precision at the value level In order to measure the effect of the clarification strategies in both systems, we computed concept precisions for two different mentions of a concept in a dialog: first mentions and final values after clarifications and similar strategies.", "labels": [], "entities": []}, {"text": "The actual precision of a concept C is calculated by comparing SLU results to annotations and counting true positives (matches M ) and false positives (separated into mismatches N and entirely un-annotated concepts U ): P rec(C) = MM +N +U . Unrecognized concepts, on the other hand, are recall related and not counted since they cannot be part of any system belief.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.997285008430481}]}, {"text": "As table 2 clearly shows, the use of clarification strategies has a positive effect on concept precision in both systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9737629890441895}]}, {"text": "The exception is the precision of concept activity in the rule-based system for which the system reprompted rather than verified.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9965255856513977}]}, {"text": "In table 2, row 'All' refers to the average weighted precision of the five concepts.", "labels": [], "entities": [{"text": "All", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.6195188760757446}, {"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9442399740219116}]}, {"text": "Both systems start from a similar level of overall precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9988133907318115}]}, {"text": "The relative improvement of the POMDP-DM for all concepts is 12.1%, compared to 5.2% of the rule-based DM.", "labels": [], "entities": []}, {"text": "We conducted a statistical significance test by computing the delta in the form of three values for individual data points, i.e. dialogs, and assigned +1 for all changes from non-match to match, -1 fora change in the opposite direction and 0 for everything else (e.g. from mismatch to mismatch).", "labels": [], "entities": []}, {"text": "We found that, although there is a tendency for the POMDP-DM to perform better, the difference is not statistically significant at p=0.05 (a possible explanation is the data size since we are using human subjects).", "labels": [], "entities": []}, {"text": "We furthermore measured the precision of recognizing 'yes/no' answers to clarification questions.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.999210000038147}, {"text": "recognizing 'yes/no' answers to clarification questions", "start_pos": 41, "end_pos": 96, "type": "TASK", "confidence": 0.7073152542114258}]}, {"text": "In contrast to actual concepts, there is no belief distribution for these in the DM since clarification actions are part of the concept POMDP models.", "labels": [], "entities": []}, {"text": "We are thus dealing with individual one-off recognition results that should be entirely independent of each other.", "labels": [], "entities": [{"text": "one-off recognition", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.6251152455806732}]}, {"text": "However, as table 2 (bottom) shows, the precision of verifications decreases for the hybrid POMDP system.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9994803071022034}]}, {"text": "A plausible explanation for this is the increasing impatience of the users due to the longer dialog duration.", "labels": [], "entities": []}, {"text": "Characterization of dialog strategies For some concepts, the best policy is to ask the concept question once and then verify once before committing to the value (assuming the answer is positive).", "labels": [], "entities": []}, {"text": "Other policies verify the same value twice.", "labels": [], "entities": []}, {"text": "Another learned strategy is to ask the original concept question twice and then only verify the value once (assuming that the understood value was the same in both concept questions).", "labels": [], "entities": []}, {"text": "In other words, the individual concept policies show different types of strategies regarding uncertainty handling.", "labels": [], "entities": [{"text": "uncertainty handling", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.7141683995723724}]}, {"text": "This is in marked contrast to the manually programmed DM that always asks the concept question once and verifies it if needed (concept activity being the exception).", "labels": [], "entities": []}, {"text": "HCI and language generation The domain is sufficiently simple to use template-based generation techniques to produce the surface forms of the responses.", "labels": [], "entities": [{"text": "language generation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7221750319004059}]}, {"text": "However, the experiments with the POMDP-DM highlight some new challenges regarding HCI aspects of spoken dialog systems: the choice of actions may not be 'natural' from the user's perspective, for example if the system asks fora concept twice.", "labels": [], "entities": []}, {"text": "However, it should be possible to better communicate the (change in the) belief to the user.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Task completion and length metrics", "labels": [], "entities": []}, {"text": " Table 2: Concept precision of first vs final value", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.7726098895072937}]}]}