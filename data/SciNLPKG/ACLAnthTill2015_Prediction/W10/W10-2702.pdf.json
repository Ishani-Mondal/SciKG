{"title": [], "abstractContent": [{"text": "We present a family of Embodied Conversational Agents (ECAs) using Talking Head technology, along with a program of associated research and user trials.", "labels": [], "entities": []}, {"text": "Whilst antecedents of our current ECAs include \"chatbots\" desgined to pass the Turing Test (TT) or win a Loebner Prize (LP), our current agents are task-oriented Teaching Agents and Social Companions.", "labels": [], "entities": []}, {"text": "The current focus for our research includes the role of emotion, expression and gesture in our agents/companions, the explicit teaching of such social skills as recognizing and displaying appropriate ex-pressions/gestures, and the integration of template/database-based dialogue managers with more conversational TT/LP systems as well as with audiovisual speech/gesture rec-ognition/synthesis technologies.", "labels": [], "entities": [{"text": "audiovisual speech/gesture rec-ognition/synthesis", "start_pos": 343, "end_pos": 392, "type": "TASK", "confidence": 0.6387643899236407}]}], "introductionContent": [{"text": "Embodied Conversational Agents (ECAs) are animated or robotic agents that engage users in real-time dialogue.", "labels": [], "entities": []}, {"text": "As a development of the Chatterbot TT/LP system, they address a fundamental criticism of the Turing Test (TT) as incarnated in the Loebner Prize (LP), viz.", "labels": [], "entities": []}, {"text": "the lack of understanding of the world, the lack of understanding people, the lack of personality.", "labels": [], "entities": []}, {"text": "This has in fact been acknowledge by Loebner who has insisted that more than \"pen pal\" conversation is necessary to win his $100K prize and Gold medal, and arranged design of a multimodal test.", "labels": [], "entities": []}, {"text": "At a technological level ECAs area showcase fora large variety of language and human interface technologies including speech and face recognition and synthesis, speech understanding and generation, and dialogue management.", "labels": [], "entities": [{"text": "speech and face recognition and synthesis", "start_pos": 118, "end_pos": 159, "type": "TASK", "confidence": 0.7089741627375284}, {"text": "speech understanding and generation", "start_pos": 161, "end_pos": 196, "type": "TASK", "confidence": 0.8513039201498032}, {"text": "dialogue management", "start_pos": 202, "end_pos": 221, "type": "TASK", "confidence": 0.8756555020809174}]}, {"text": "However, at a deeper level they area platform for exploring affect -the effect of multimodal features, including in particular expression and gesture on the human user.", "labels": [], "entities": []}, {"text": "Our aim is not to pass the Turing Test, although perhaps some descendant of our system will eventually do so.", "labels": [], "entities": []}, {"text": "Rather our focus is to provide an effective agent for specific tasks where the limitations of current conversational companions, or dialog technologies, serve to match rather than conflict with the application constraints.", "labels": [], "entities": []}, {"text": "Whereas limiting the topic was seen as a trick and a cheat in the Loebner Prize, our aim is to demonstrate and develop useful technologies and we are not interested in philosophical debates about intelligence.", "labels": [], "entities": []}, {"text": "For these naturally constrained applications human level grammatical and syntactic understanding is not required, and the simple ELIZA-like approach of template matching is perfectly adequate as a first step.", "labels": [], "entities": [{"text": "grammatical and syntactic understanding", "start_pos": 57, "end_pos": 96, "type": "TASK", "confidence": 0.7238079011440277}, {"text": "template matching", "start_pos": 152, "end_pos": 169, "type": "TASK", "confidence": 0.7226091176271439}]}, {"text": "Our initial Talking Head was based around the Stelarc Prosthetic Head 1 which combines multiple off-the-shelf components: keyboard input to a chatbot (AliceBot 2 ) is linked to speech synthesis (IBM ViaVoice 3 ) and 3D face rendering (Eyematic 4 ).", "labels": [], "entities": [{"text": "face rendering", "start_pos": 219, "end_pos": 233, "type": "TASK", "confidence": 0.6922901570796967}]}, {"text": "More recently we have adopted Head X 5 which is capable of generating a continuous, synchronized, optionally subtitled audiovisual speech stream in many different languages, with the ability to switch and modify voices and morph different faces at the same time as interacting with the user.", "labels": [], "entities": []}, {"text": "The system is designed to be able to use different speech and face technologies, and we in general use Microsoft's SAPI for speech recognition and generation plus the FaceGen face generation technology 7 .", "labels": [], "entities": [{"text": "speech recognition and generation", "start_pos": 124, "end_pos": 157, "type": "TASK", "confidence": 0.7061656191945076}]}], "datasetContent": [], "tableCaptions": []}