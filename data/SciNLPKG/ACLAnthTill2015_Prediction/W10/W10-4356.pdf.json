{"title": [{"text": "Dialogue Act Modeling in a Complex Task-Oriented Domain", "labels": [], "entities": [{"text": "Dialogue Act Modeling", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7097090085347494}]}], "abstractContent": [{"text": "Classifying the dialogue act of a user utterance is a key functionality of a dialogue management system.", "labels": [], "entities": [{"text": "Classifying the dialogue act of a user utterance", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8220990523695946}]}, {"text": "This paper presents a data-driven dialogue act classifier that is learned from a corpus of human textual dialogue.", "labels": [], "entities": []}, {"text": "The task-oriented domain involves tutoring in computer programming exercises.", "labels": [], "entities": []}, {"text": "While engaging in the task, students generate a task event stream that is separate from and in parallel with the dialogue.", "labels": [], "entities": []}, {"text": "To deal with this complex task-oriented dialogue, we propose a vector-based representation that encodes features from both the dialogue and the hierarchically structured task for training a maximum likelihood classifier.", "labels": [], "entities": []}, {"text": "This classifier also leverages knowledge of the hidden dialogue state as learned separately by an HMM, which in previous work has increased the accuracy of models for predicting tutorial moves and is hypothesized to improve the accuracy for classifying student utterances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9988466501235962}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9984279870986938}]}, {"text": "This work constitutes a step toward learning a fully data-driven dialogue management model that leverages knowledge of the user-generated task event stream.", "labels": [], "entities": []}], "introductionContent": [{"text": "Two central challenges for dialogue systems are interpreting user utterances and selecting system dialogue moves.", "labels": [], "entities": [{"text": "interpreting user utterances", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.8667920430501302}]}, {"text": "Recent years have seen an increased focus on data-driven techniques for addressing these challenging tasks ().", "labels": [], "entities": []}, {"text": "Much of this work utilizes dialogue acts, built on the notion of speech acts, which provide a valuable intermediate representation that can be used for dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.8817974627017975}]}, {"text": "Data-driven approaches to dialogue act interpretation have included models that take into account a variety of lexical, syntactic, acoustic, and prosodic features for dialogue act tagging ().", "labels": [], "entities": [{"text": "dialogue act interpretation", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.7628454566001892}, {"text": "dialogue act tagging", "start_pos": 167, "end_pos": 187, "type": "TASK", "confidence": 0.7022398710250854}]}, {"text": "In task-oriented domains, recent work has approached dialogue act classification by learning dialogue management models entirely from human-human corpora ().", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.8594243923823038}]}, {"text": "Our work adopts this approach fora corpus of human-human dialogue in a task-oriented tutoring domain.", "labels": [], "entities": []}, {"text": "Unlike the majority of taskoriented domains that have been studied to date, our domain involves the separate creation of a persistent artifact, in our case a computer program, by the user during the course of the dialogue.", "labels": [], "entities": []}, {"text": "Our corpus consists of human-human textual dialogue utterances and a separate, parallel stream of user-generated task actions.", "labels": [], "entities": []}, {"text": "We utilize structural features including task/subtask, speaker, and hidden dialogue state along with lexical and syntactic features to interpret user (student) utterances.", "labels": [], "entities": []}, {"text": "This paper makes three contributions.", "labels": [], "entities": []}, {"text": "First, it addresses representational issues in creating a dialogue model that integrates task actions with hierarchical task/subtask structure.", "labels": [], "entities": []}, {"text": "The task is captured within a separate synchronous event stream that exists in parallel with the dialogue.", "labels": [], "entities": []}, {"text": "Second, this paper explores the performance of dialogue act classifiers using different lexical/syntactic and structural feature sets.", "labels": [], "entities": [{"text": "dialogue act classifiers", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.6506035725275675}]}, {"text": "This comparison includes one model trained entirely on lexical/syntactic features, an important step toward robust unsupervised dialogue act tagging).", "labels": [], "entities": [{"text": "dialogue act tagging", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.6771428386370341}]}, {"text": "Finally, it investigates whether the addition of HMM and task/subtask features improves the performance of the dialogue act classifiers.", "labels": [], "entities": []}, {"text": "The findings support this hypothesis for three student dialogue moves, each with important implications for tutorial dialogue.", "labels": [], "entities": [{"text": "tutorial dialogue", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7894622087478638}]}], "datasetContent": [{"text": "This section describes the learning of maximum likelihood vector-based models for classification of user dialogue acts.", "labels": [], "entities": [{"text": "classification of user dialogue acts", "start_pos": 82, "end_pos": 118, "type": "TASK", "confidence": 0.832161295413971}]}, {"text": "In addition to investigating the accuracy of the overall model, we also performed experiments regarding the utility of feature types for discriminating between particular dialogue acts of interest.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.998843789100647}]}, {"text": "The classifiers are based on logistic regression, which learns a discriminant for each pair of dialogue acts by assigning weights in a maximum likelihood fashion.", "labels": [], "entities": []}, {"text": "The logistic regression models were learned using the Weka machine learning toolkit ().", "labels": [], "entities": [{"text": "Weka machine learning toolkit", "start_pos": 54, "end_pos": 83, "type": "DATASET", "confidence": 0.8927052170038223}]}, {"text": "For In general, the model that maximizes likelihood also maximizes entropy under the same constraints).", "labels": [], "entities": []}, {"text": "feature selection, we performed attribute subset evaluation with a best-first approach that greedily searched the space of possible features using a hill climbing approach with backtracking.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6938425600528717}]}, {"text": "The prediction accuracy of the classifiers was determined through ten-fold cross-validation on the corpus, and the results below are presented in terms of prediction accuracy (number of correct classifications divided by total number of classifications) as well as by the kappa statistic, which adjusts for expected agreement by chance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.8662796020507812}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.6844463348388672}]}, {"text": "Three steps of subtask history (each level of hierarchy represented as a separate feature) [c task(t-1) , c task(t-2) , c task(t-3) ] Three steps of task correctness history", "labels": [], "entities": [{"text": "task correctness", "start_pos": 149, "end_pos": 165, "type": "TASK", "confidence": 0.6713794767856598}]}], "tableCaptions": [{"text": " Table 1. Student dialogue acts", "labels": [], "entities": []}, {"text": " Table 4. Binary DA classifiers", "labels": [], "entities": [{"text": "Binary DA classifiers", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.644880602757136}]}]}