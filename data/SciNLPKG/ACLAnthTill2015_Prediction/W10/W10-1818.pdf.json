{"title": [{"text": "Identifying Sources of Inter-Annotator Variation: Evaluating Two Models of Argument Analysis", "labels": [], "entities": [{"text": "Argument Analysis", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.710767924785614}]}], "abstractContent": [{"text": "This paper reports on a pilot study where two Models of argument were applied to the Discussion sections of a corpus of biomedical research articles.", "labels": [], "entities": []}, {"text": "The goal was to identify sources of systematic inter-annotator variation as diagnostics for improving the Models.", "labels": [], "entities": []}, {"text": "In addition to showing a need to revise both Models, the results identified problems resulting from limitations in annotator expertise.", "labels": [], "entities": []}, {"text": "In future work two types of annotators are required: those with biomedical domain expertise and those with an understanding of rhetorical structure.", "labels": [], "entities": [{"text": "rhetorical structure", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.8424210250377655}]}], "introductionContent": [{"text": "Given the vast and growing body of biomedical research literature being published there is a need to develop automated text mining tools that will assist in filtering out the information most useful to researchers.", "labels": [], "entities": [{"text": "text mining", "start_pos": 119, "end_pos": 130, "type": "TASK", "confidence": 0.7318931818008423}]}, {"text": "Previous studies applying Argumentative Zoning (AZ) () and Zone Analysis (ZA) ( have shown that an analysis of the argumentative structure of a text can be of use in Information Extraction (IE).", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 166, "end_pos": 193, "type": "TASK", "confidence": 0.8456631541252136}]}, {"text": "As an alternative approach, it was believed that Toulmin's work on informal logic and argument structure could reflect the rhetorical strategies used by the authors of biomedical research articles.", "labels": [], "entities": []}, {"text": "In order to compare and evaluate these approaches two Models of argument were applied to the same set of biomedical research articles.", "labels": [], "entities": []}, {"text": "Inter-annotator agreement/disagreement between and within Models was examined.", "labels": [], "entities": []}, {"text": "Given that human-annotated data are ultimately to be used for machine learning purposes, there is growing recognition of the need to analyze coder disagreements in order to differentiate between systematic variation and noise (e.g..", "labels": [], "entities": []}, {"text": "The goal of this study was to identify systematic disagreements as diagnostics for improving the Models of argument.", "labels": [], "entities": [{"text": "Models of argument", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.6626317699750265}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3 Number of sentences in agreement  groups", "labels": [], "entities": []}, {"text": " Table 4 Overall distribution by category - Model 1", "labels": [], "entities": []}, {"text": " Table 5 Overall distribution by category - Model 2", "labels": [], "entities": []}, {"text": " Table 6 Category distribution by annotator - Model 1", "labels": [], "entities": []}]}