{"title": [], "abstractContent": [{"text": "We present a sequential labeling approach to hedge cue detection submitted to the biological portion of task 1 for the CoNLL-2010 shared task.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7633134524027506}, {"text": "CoNLL-2010 shared task", "start_pos": 119, "end_pos": 141, "type": "DATASET", "confidence": 0.7514787316322327}]}, {"text": "Our main approach is as follows.", "labels": [], "entities": []}, {"text": "We make use of partial syntactic information together with features obtained from the unlabeled corpus, and convert the task into one of sequential BIO-tagging.", "labels": [], "entities": []}, {"text": "If a cue is found, a sentence is classified as uncertain and certain otherwise.", "labels": [], "entities": []}, {"text": "To examine a large number of feature combinations, we employ a genetic algorithm.", "labels": [], "entities": []}, {"text": "While some features obtained by this method are difficult to interpret, they were shown to improve the performance of the final system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Research on automatically extracting factual information from biomedical texts has become popular in recent years.", "labels": [], "entities": [{"text": "automatically extracting factual information from biomedical texts", "start_pos": 12, "end_pos": 78, "type": "TASK", "confidence": 0.8901476093700954}]}, {"text": "Since these texts are abundant with hypotheses postulated by researchers, one hurdle that an information extraction system must overcome is to be able to determine whether or not the information is part of a hypothesis or a factual statement.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.7271561324596405}]}, {"text": "Thus, detecting hedge cues that indicate the uncertainty of the statement is an important subtask of information extraction (IE).", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.8404849171638489}]}, {"text": "Hedge cues include words such as \"may\", \"might\", \"appear\", \"suggest\", \"putative\" and \"or\".", "labels": [], "entities": []}, {"text": "They also includes phrases such as \".", "labels": [], "entities": []}, {"text": ".raising an intriguing question that.", "labels": [], "entities": []}, {"text": "As these expressions are sparsely scattered throughout the texts, it is not easy to generalize results of machine learning from a training set to a test set.", "labels": [], "entities": []}, {"text": "Furthermore, simply finding the expressions listed above does not guarantee that a sentence contains a hedge.", "labels": [], "entities": []}, {"text": "Their function as a hedge cue depends on the surrounding context.", "labels": [], "entities": []}, {"text": "The primary objective of the CoNLL-2010 shared task) is to detect hedge cues and their scopes as are present in biomedical texts.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the biological portion of task 1, and present a sequential labeling approach to hedge cue detection.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7845131556193033}]}, {"text": "The following summarizes the steps we took to achieve this goal.", "labels": [], "entities": []}, {"text": "Similarly to previous work in hedge cue detection, we first convert the task into a sequential labeling task based on the BIO scheme, where each word in a hedge cue is labeled as B-CUE, I-CUE, or O, indicating respectively the labeled word is at the beginning of a cue, inside of a cue, or outside of a hedge cue; this is similar to the tagging scheme from the CoNLL-2001 shared task.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7980315287907919}, {"text": "BIO", "start_pos": 122, "end_pos": 125, "type": "METRIC", "confidence": 0.9573945999145508}]}, {"text": "We then prepared features, and fed the training data to a sequential labeling system, a discriminative Markov model much like Conditional Random Fields (CRF), with the difference being that the model parameters are tuned using Bayes Point Machines (BPM), and then compared our model against an equivalent CRF model.", "labels": [], "entities": []}, {"text": "To convert the result of sequential labeling to sentence classification, we simply used the presence of a hedge cue, i.e. if a cue is found, a sentence is classified as uncertain and certain otherwise.", "labels": [], "entities": [{"text": "sequential labeling", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7373002469539642}, {"text": "sentence classification", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.7231961786746979}]}, {"text": "To prepare features, we ran the GENIA tagger to add partial syntactic parse and named entity information.", "labels": [], "entities": [{"text": "GENIA tagger", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.7725144326686859}]}, {"text": "We also applied Porter's stemmer) to each word in the corpus.", "labels": [], "entities": []}, {"text": "For each stem, we acquired the distribution of surrounding words from the unlabeled corpus, and calculated the similarity between these distributions and the distribution of hedge cues in the training corpus.", "labels": [], "entities": []}, {"text": "Given a stem and its similarities to different hedge cues, we took the maximum similarity and discretized it.", "labels": [], "entities": []}, {"text": "All these features are passed onto a sequential labeling system.", "labels": [], "entities": []}, {"text": "Using these base features, we then evaluated the effects of feature combinations by repeatedly training the system and selecting feature combinations that increased the performance on a heldout set.", "labels": [], "entities": []}, {"text": "To au-tomate this process, we employed a genetic algorithm.", "labels": [], "entities": []}, {"text": "The contribution of this paper is two-fold.", "labels": [], "entities": []}, {"text": "First, we describe our system, outlined above, that we submitted to the CoNLL-2010 shared task in more detail.", "labels": [], "entities": [{"text": "CoNLL-2010 shared task", "start_pos": 72, "end_pos": 94, "type": "DATASET", "confidence": 0.7705182035764059}]}, {"text": "Second, we analyze the effects of particular choices we made when building our system, especially the feature combinations and learning methods.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we detail how the task of sequential labeling is formalized in terms of linear classification, and explain the Viterbi algorithm required for prediction.", "labels": [], "entities": [{"text": "sequential labeling", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7103072702884674}, {"text": "linear classification", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.7089393138885498}]}, {"text": "We next present several algorithms for optimizing the weight vector in a linear classifier in Section 3.", "labels": [], "entities": []}, {"text": "We then detail the complete list of feature templates we used for the task of hedge cue detection in Section 4.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7999628583590189}]}, {"text": "In order to evaluate the effects of feature templates, in Section 5, we remove each feature template and find that several feature templates overfit the training set.", "labels": [], "entities": []}, {"text": "We finally conclude with Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to examine the effects of learning parameters, we conducted experiments on the test data after it was released to the participants of the shared task.", "labels": [], "entities": []}, {"text": "While BPM has two parameters, K and T , we fixed T = 5 and varied K, the number of perceptrons.", "labels": [], "entities": [{"text": "BPM", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.5240030288696289}]}, {"text": "As increasing the number of perceptrons results in more thorough exploration of the version space V (D), we expect that the performance of the classifier would improve as K increases.", "labels": [], "entities": []}, {"text": "Table 2 shows how the number of perceptrons affects the performance.", "labels": [], "entities": []}, {"text": "T P stands for True Positive, F P for False Positive, and F N for False Negative.", "labels": [], "entities": []}, {"text": "The evaluation metrics were precision P (the number of true pos-  itives divided by the total number of elements labeled as belonging to the positive class) recall R (the number of true positives divided by the total number of elements that actually belong to the positive class) and their harmonic mean, the F 1 score (F 1 = 2P R/(P + R)).", "labels": [], "entities": [{"text": "precision P", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9702568650245667}, {"text": "F 1 score", "start_pos": 309, "end_pos": 318, "type": "METRIC", "confidence": 0.9511252045631409}]}, {"text": "All figures in this paper measure hedge cue detection performance at the sentence classification level, not word/phrase classification level.", "labels": [], "entities": [{"text": "hedge cue detection", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.741570512453715}, {"text": "word/phrase classification", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.6216648146510124}]}, {"text": "From the results, once the number of perceptrons hits 20, the performance stabilizes and does not seem to show any improvement.", "labels": [], "entities": []}, {"text": "Next, in order to examine whether or not we have overfitted to the training/heldout set, we removed each row of and reevaluated the performance of the system.", "labels": [], "entities": []}, {"text": "Reevaluation was conducted on the labeled test set released by the shared task organizers after our system's output had been initially evaluated.", "labels": [], "entities": [{"text": "labeled test set released", "start_pos": 34, "end_pos": 59, "type": "DATASET", "confidence": 0.783726692199707}]}, {"text": "Thus, these figures are comparable to the sentence classification results reported in. or, or both shows the effect of removing (1), (2), or both (1) and (2), showing that they overfit the training data.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.6982628852128983}]}, {"text": "Removing any other rows in Table 1 resulted in decreased classification performance.", "labels": [], "entities": []}, {"text": "While there are other large combination features such as ones involving F 4 , F 9 , F 12 , F 15 and F 19 , we find that they do help improving the performance of the classifier.", "labels": [], "entities": []}, {"text": "Since these features seem unintuitive to the authors, it is likely that they would not have been found without the genetic algorithm we employed.", "labels": [], "entities": []}, {"text": "Error analysis shows that inclusion of features involving F 9 affects prediction of \"believe\", \"possible\", \"putative\", \"assumed\", \"seemed\", \"if\", \"presumably\", \"perhaps\", \"suggestion\", \"suppose\" and \"intriguing\".", "labels": [], "entities": [{"text": "F", "start_pos": 58, "end_pos": 59, "type": "METRIC", "confidence": 0.6059054136276245}]}, {"text": "However, as this feature template is unfolded into a large number of features, we were unable to obtain further linguistic insights.", "labels": [], "entities": []}, {"text": "In the following experiments, we used the currently best performing features, that is, all features except (1) in, and trained the classifiers using the formalism of Perceptron and Conditional Random Fields besides Bayes Point Ma-chines as we have been using.", "labels": [], "entities": []}, {"text": "The results in shows that BPM performs better than Perceptron or Conditional Random Fields.", "labels": [], "entities": [{"text": "BPM", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.5516107678413391}]}, {"text": "As the training time for BPM is better than CRF, our choice of BPM helped us to run the genetic algorithm repeatedly as well.", "labels": [], "entities": [{"text": "BPM", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8342649340629578}]}, {"text": "After several runs of empirical tuning and tweaking, the hyper-parameters of the algorithms were set as follows.", "labels": [], "entities": []}, {"text": "Perceptron was stopped at 40 iterations (T = 40).", "labels": [], "entities": [{"text": "T", "start_pos": 41, "end_pos": 42, "type": "METRIC", "confidence": 0.9872960448265076}]}, {"text": "For BPM, we fixed T = 5 and K = 20.", "labels": [], "entities": [{"text": "BPM", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.47666895389556885}, {"text": "T", "start_pos": 18, "end_pos": 19, "type": "METRIC", "confidence": 0.9923882484436035}]}, {"text": "For Conditional Random Fields, we compared the penalized version with C = 1 and the unpenalized version (C = 0).", "labels": [], "entities": []}, {"text": "The results in is that of the unpenalized version, as it performed better than the penalized version.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Effects of K in Bayes Point Machines", "labels": [], "entities": []}, {"text": " Table 4: Performance of different optimization  strategies", "labels": [], "entities": []}]}