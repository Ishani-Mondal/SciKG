{"title": [{"text": "Capturing the stars: predicting ratings for service and product reviews", "labels": [], "entities": [{"text": "Capturing", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9424067139625549}, {"text": "predicting", "start_pos": 21, "end_pos": 31, "type": "TASK", "confidence": 0.9487351179122925}]}], "abstractContent": [{"text": "Bloggers, professional reviewers, and consumers continuously create opinion-rich web reviews about products and services, with the result that textual reviews are now abundant on the web and often convey a useful overall rating (number of stars).", "labels": [], "entities": []}, {"text": "However, an overall rating cannot express the multiple or conflicting opinions that might be contained in the text, or explicitly rate the different aspects of the evaluated entity.", "labels": [], "entities": []}, {"text": "This work addresses the task of automatically predicting ratings, forgiven aspects of a textual review, by assigning a numerical score to each evaluated aspect in the reviews.", "labels": [], "entities": []}, {"text": "We handle this task as both a regression and a classification modeling problem and explore several combinations of syntactic and semantic features.", "labels": [], "entities": [{"text": "classification modeling", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.9509965777397156}]}, {"text": "Our results suggest that classification techniques perform better than ranking modeling when handling eval-uative text.", "labels": [], "entities": []}], "introductionContent": [{"text": "An abundance of service and products reviews are today available on the Web.", "labels": [], "entities": []}, {"text": "Bloggers, professional reviewers, and consumers continuously contribute to this rich content both by providing text reviews and often by assigning useful overall ratings (number of stars) to their overall experience.", "labels": [], "entities": []}, {"text": "However, the overall rating that usually accompanies online reviews cannot express the multiple or conflicting opinions that might be contained in the text, or explicitly rate the different aspects of the evaluated entity.", "labels": [], "entities": []}, {"text": "For example, a restaurant might receive an overall great evaluation, while the service might be rated below average due to slow and discourteous waitstaff.", "labels": [], "entities": []}, {"text": "Pinpointing opinions in documents, and the entities being referenced, would provide a finer-grained sentiment analysis and a solid foundation to automatically summarize evaluative text, but such a task becomes even more challenging when applied to a generic domain and with unsupervised methods.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.8069777488708496}, {"text": "summarize evaluative text", "start_pos": 159, "end_pos": 184, "type": "TASK", "confidence": 0.8762311339378357}]}, {"text": "Some significant contributions by,, and illustrate different techniques to find and measure opinion orientation in text documents.", "labels": [], "entities": [{"text": "opinion orientation in text documents", "start_pos": 92, "end_pos": 129, "type": "TASK", "confidence": 0.8254731297492981}]}, {"text": "Other work in sentiment analysis (often referred as opinion mining) has explored several facets of the problem, ranging from predicting binary ratings (e.g., thumbs up/down)), to more detailed opinion analysis methods predicting multi-scale ratings (e.g., number of stars) (Pang and).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9491609632968903}, {"text": "opinion mining", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7358145117759705}, {"text": "Pang", "start_pos": 274, "end_pos": 278, "type": "DATASET", "confidence": 0.8993335962295532}]}, {"text": "This paper focuses on multi-scale multi-aspect rating prediction for textual reviews.", "labels": [], "entities": [{"text": "multi-scale multi-aspect rating prediction", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.6340352967381477}]}, {"text": "As mentioned before, textual reviews are abundant, but when trying to make a buy decision on a specific product or service, getting sufficient and reliable information can be a daunting and time consuming task.", "labels": [], "entities": []}, {"text": "On one hand, a single overall rating does not provide enough information and could be unreliable, if not supported over a large number of independent reviews/ratings.", "labels": [], "entities": []}, {"text": "From another standpoint, reading through a large number of textual reviews in order to infer the aspect ratings could be quite time con-36 suming, and, at the same time, the outcome of the evaluation could be biased by the reader's interpretation.", "labels": [], "entities": []}, {"text": "In this work, instead of a single overall rating, we propose to provide ratings for multiple aspects of the product/service.", "labels": [], "entities": []}, {"text": "For example, in the case of restaurant reviews, we consider ratings for five aspects: food, atmosphere, value, service and overall experience.", "labels": [], "entities": []}, {"text": "In such aspect ratings are called rated aspect summaries, in Shimada and Endo (2008) they have been referred to as seeing stars and in they are referred to as multi-aspect ranking.", "labels": [], "entities": []}, {"text": "We use supervised learning methods to train predictive models and use a specific decoding method to optimize the aspect rating assignment to a review.", "labels": [], "entities": []}, {"text": "In the rest of this paper, we overview the previous work in this research area in Section 2.", "labels": [], "entities": []}, {"text": "We describe the corpus used in the experiments in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4 we present various learning algorithms we experimented with.", "labels": [], "entities": []}, {"text": "Section 5 explains our experimental setup, while in Section 6 we provide analysis of our experimental results.", "labels": [], "entities": []}, {"text": "Section 7 presents details of modeling and exploiting interdependence among aspect ratings to boost the predictive performance.", "labels": [], "entities": []}, {"text": "Finally, we describe the future work in Section 8 and report the concluding remarks in Section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "To predict aspect ratings of restaurants from their textual reviews we used the reviews mined from the we8there.com website to train different regression and classification models as outlined in Section 4.", "labels": [], "entities": []}, {"text": "In each of our experiments, we randomly partitioned the data into 90% for training and 10% for testing.", "labels": [], "entities": []}, {"text": "This ensures that the distributions in training and test data are identical.", "labels": [], "entities": []}, {"text": "All the results quoted in this paper are averages of 10-fold crossvalidation over 6,823 review examples.", "labels": [], "entities": []}, {"text": "We conducted repeatedly the same experiment on 10 different training/test partitions and computed the average rank loss overall the test partitions.", "labels": [], "entities": []}, {"text": "38 illustrates the training process where each aspect is described by a separate predictive model.", "labels": [], "entities": []}, {"text": "We introduce the following notation that will be helpful in further discussion.", "labels": [], "entities": []}, {"text": "For our data m is 5.", "labels": [], "entities": []}, {"text": "Each aspect can have an integer rating from 1 to k.", "labels": [], "entities": []}, {"text": "Once again, for our data k is 5.", "labels": [], "entities": []}, {"text": "Each review text document t can have ratings r, which is a vector of m integers ranging 1 to k (bold faced letters indicate vectors).", "labels": [], "entities": []}, {"text": "Using the training data (t 1 , r 1 )..(t i , r i )..(t n , r n ) we train m rating predictors R j (t i ), one for each aspect j.", "labels": [], "entities": []}, {"text": "Given text ti predictor R j outputs the most likely rating l for the aspect j.", "labels": [], "entities": []}, {"text": "In these experiments, we treated aspect rating predictors as independent of each other.", "labels": [], "entities": []}, {"text": "For each rated aspect, predictor models were trained independently and were used independently to predict ratings for each aspect.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Restaurant review corpus", "labels": [], "entities": [{"text": "Restaurant review", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.5875084698200226}]}, {"text": " Table 2: Restaurant review ratings distribution per aspect", "labels": [], "entities": []}, {"text": " Table 3: Average ranking losses using MaxEnt classifier  with different feature sets", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.8803005218505859}]}, {"text": " Table 5: Average ranking losses using different predictive  models", "labels": [], "entities": []}, {"text": " Table 6: Comparison of rank loss obtained from MaxEnt  classification and those reported in Snyder and Barzilay  (2007)", "labels": [], "entities": [{"text": "rank loss", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.8404056131839752}, {"text": "MaxEnt  classification", "start_pos": 48, "end_pos": 70, "type": "DATASET", "confidence": 0.9079874753952026}]}, {"text": " Table 7: Improved rank loss obtained by using difference  predictors and polarity word features", "labels": [], "entities": [{"text": "Improved rank loss", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.72589244445165}]}]}