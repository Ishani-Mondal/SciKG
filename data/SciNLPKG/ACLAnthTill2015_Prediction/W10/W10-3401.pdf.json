{"title": [{"text": "INVITED KEYNOTE PRESENTATION Distributional Semantics and the Lexicon", "labels": [], "entities": [{"text": "INVITED KEYNOTE PRESENTATION Distributional Semantics", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.4797070860862732}]}], "abstractContent": [{"text": "The lexicons used in computational linguistics systems contain morphological, syntactic, and occasionally also some semantic information (such as definitions, pointers to an ontology, verb frame filler preferences, etc.).", "labels": [], "entities": [{"text": "verb frame filler preferences", "start_pos": 184, "end_pos": 213, "type": "TASK", "confidence": 0.6009480357170105}]}, {"text": "But the human cognitive lexicon contains a great deal more, crucially, expectations about how a word tends to combine with others: not just general information-extraction-like patterns, but specific instantial expectations.", "labels": [], "entities": []}, {"text": "Such information is very useful when it comes to listening in bad aural conditions and reading texts in which background information is taken for granted; without such specific expectation , one would be hard-pressed (and computers are completely unable) to form coherent and richly connected multi-sentence interpretations.", "labels": [], "entities": []}, {"text": "Over the past few years, NLP work has increasingly treated topic signature word distributions (also called 'context vectors', 'topic models', etc.) as a de facto replacement for semantics.", "labels": [], "entities": []}, {"text": "Whether the task is wordsense dis-ambiguation, certain forms of textual entail-ment, information extraction, paraphrase learning, and soon, it turns out to be very useful to consider a word(sense) as being defined by the distribution of word(senses) that regularly accompany it (in the classic words of Firth, \"you shall know a word by the company it keeps\").", "labels": [], "entities": [{"text": "information extraction", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.8300961256027222}, {"text": "paraphrase learning", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.7811067700386047}, {"text": "Firth", "start_pos": 303, "end_pos": 308, "type": "DATASET", "confidence": 0.8733277320861816}]}, {"text": "And this is true not only for individual wordsenses, but also for larger units such as topics: the product of LDA and similar topic characterization engines is similar.", "labels": [], "entities": [{"text": "topic characterization", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.735045850276947}]}, {"text": "In this talk I argue fora new kind of semantics , which is being called Distributional Semantics.", "labels": [], "entities": []}, {"text": "It combines traditional symbolic logic-based semantics with (computation-based) statistical word distribution information.", "labels": [], "entities": []}, {"text": "The core resource is a single lexico-semantic lexicon that can be used fora variety of tasks, provided that it is reformulated accordingly.", "labels": [], "entities": []}, {"text": "I show how to define such a semantics, how to build the appropriate lexicon, how to format it, and how to use it for various tasks.", "labels": [], "entities": []}, {"text": "The talk pulls together a wide range of related topics, including Pantel-style resources like DIRT, inferences / expectations such as those used in Schank-style expectation-based parsing and expectation-driven NLU, PropBank-style word valence lexical items, and the treatment of negation and modalities.", "labels": [], "entities": [{"text": "Pantel-style", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.8814963102340698}, {"text": "Schank-style expectation-based parsing", "start_pos": 148, "end_pos": 186, "type": "TASK", "confidence": 0.5639821588993073}]}, {"text": "I conclude by arguing that the human cognitive lexicon has to have the same kinds of properties as the Distributional Semantics lexicon, given the ways people do things with words.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}