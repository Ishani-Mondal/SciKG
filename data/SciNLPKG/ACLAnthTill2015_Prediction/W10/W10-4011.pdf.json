{"title": [{"text": "More Languages, More MAP?: A Study of Multiple Assisting Languages in Multilingual PRF", "labels": [], "entities": [{"text": "PRF", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.4998023808002472}]}], "abstractContent": [{"text": "Multilingual Pseudo-Relevance Feedback (MultiPRF) is a framework to improve the PRF of a source language by taking the help of another language called assisting language.", "labels": [], "entities": []}, {"text": "In this paper, we extend the MultiPRF framework to include multiple assisting languages.", "labels": [], "entities": []}, {"text": "We consider three different configurations to incorporate multiple assisting languages-a) Parallel all assisting languages combined simultaneously b) Serial-assisting languages combined in sequence one after another and c) Selective-dynamically selecting the best feedback model for each query.", "labels": [], "entities": []}, {"text": "We study their effect on MultiPRF performance.", "labels": [], "entities": []}, {"text": "Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9056307077407837}]}, {"text": "We also observe that MultiPRF becomes more robust with increase in number of assisting languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Pseudo-Relevance Feedback (PRF)) is known to bean effective technique to improve the effectiveness of Information Retrieval (IR) systems.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 102, "end_pos": 128, "type": "TASK", "confidence": 0.8035654067993164}]}, {"text": "In PRF, the top 'k' documents from the ranked list retrieved using the initial keyword query are assumed to be relevant.", "labels": [], "entities": []}, {"text": "Later, these documents are used to refine the user query and the final ranked list is obtained using the above refined query.", "labels": [], "entities": []}, {"text": "Although PRF has been shown to improve retrieval, it suffers from the following drawbacks: (a) Lexical and Semantic Non-Inclusion: the type of term associations obtained for query expansion is restricted to only co-occurrence based relationships in the feedback documents and (b) Lack of Robustness: due to the inherent assumption in PRF, i.e., relevance of top k documents, performance is sensitive to that of the initial retrieval algorithm and as a result is not robust.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 174, "end_pos": 189, "type": "TASK", "confidence": 0.7061732560396194}]}, {"text": "Typically, larger coverage ensures higher proportion of relevant documents in the top k retrieval ().", "labels": [], "entities": [{"text": "coverage", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9522423148155212}]}, {"text": "However, some resource-constrained languages do not have adequate information coverage in their own language.", "labels": [], "entities": []}, {"text": "For example, languages like Hungarian and Finnish have meager online content in their own languages.", "labels": [], "entities": []}, {"text": "Multilingual Pseudo-Relevance Feedback (MultiPRF) () is a novel framework for PRF to overcome the above limitations of PRF.", "labels": [], "entities": [{"text": "PRF", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9782840013504028}]}, {"text": "It does so by taking the help of a different language called the assisting language.", "labels": [], "entities": []}, {"text": "Thus, the performance of a resource-constrained language could be improved by harnessing the good coverage of another language.", "labels": [], "entities": []}, {"text": "MulitiPRF showed significant improvements on standard CLEF collections) over state-of-art PRF system.", "labels": [], "entities": [{"text": "MulitiPRF", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8804263472557068}, {"text": "CLEF collections", "start_pos": 54, "end_pos": 70, "type": "DATASET", "confidence": 0.8355068266391754}]}, {"text": "On the web, each language has its own exclusive topical coverage besides sharing a large number of common topics with other languages.", "labels": [], "entities": []}, {"text": "For example, information about Saudi Arabia government policies and regulations is more likely to be found in Arabic language web and also information about a local event in Spain is more likely to be covered in Spanish web than in English.", "labels": [], "entities": []}, {"text": "Hence, using multiple languages in conjunction is more likely to ensure satisfaction of the user information need and hence will be more robust.", "labels": [], "entities": []}, {"text": "In this paper, we extend the MultiPRF framework to multiple assisting languages.", "labels": [], "entities": []}, {"text": "We study the various possible ways of combining the models learned from multiple assisting languages.", "labels": [], "entities": []}, {"text": "We propose three different configurations for including multiple assisting languages in MultiPRF -a) Parallel b) Serial and c) Selective.", "labels": [], "entities": []}, {"text": "In Parallel combination, all the assisting languages are combined simultaneously using interpolation.", "labels": [], "entities": []}, {"text": "In Serial configuration, the assisting languages are applied in sequence one after another and finally, in Selective configuration, the best feedback model is dynamically chosen for each query.", "labels": [], "entities": []}, {"text": "We experiment with each of the above configurations and present both quantitative and qualitative analysis of the results.", "labels": [], "entities": []}, {"text": "Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9056307077407837}]}, {"text": "We also observe that MultiPRF becomes more robust with increase in number of assisting languages.", "labels": [], "entities": []}, {"text": "Besides, we also study the relation between number of assisting languages, coverage and the MultiPRF accuracy.", "labels": [], "entities": [{"text": "coverage", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9623634815216064}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.7790217399597168}]}, {"text": "The paper is organized as follows: Section 2, explains the Language Modeling (LM) based PRF approach.", "labels": [], "entities": [{"text": "Language Modeling (LM) based PRF", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.7457446668829236}]}, {"text": "Section 3, describes the MultiPRF approach.", "labels": [], "entities": []}, {"text": "Section 4 explains the various configurations to extend MultiPRF for multiple assisting languages.", "labels": [], "entities": []}, {"text": "Section 6 presents the results and discussions.", "labels": [], "entities": []}, {"text": "Finally, Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the performance of our system using the standard CLEF evaluation data in six languages, widely varying in their familial relationships -Dutch, German, English, French, Spanish and Finnish.", "labels": [], "entities": [{"text": "CLEF evaluation data", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.8339948852856954}]}, {"text": "The details of the collections and their corresponding topics used for MultiPRF are given in.", "labels": [], "entities": []}, {"text": "Note that, in each experiment, we choose assisting collections such that the topics in the source language are covered in the assisting collection so as to get meaningful feedback terms.", "labels": [], "entities": []}, {"text": "In all the topics, we only use the title field.", "labels": [], "entities": []}, {"text": "We ignore the topics which have no relevant documents as the true performance on those topics cannot be evaluated.", "labels": [], "entities": []}, {"text": "We use the Terrier IR platform () for indexing the documents.", "labels": [], "entities": []}, {"text": "We perform standard tokenization, stop word removal and stemming.", "labels": [], "entities": [{"text": "stop word removal", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.5922597249348959}]}, {"text": "We use the Porter Stemmer for English and the stemmers available through the Snowball package for other languages.", "labels": [], "entities": [{"text": "Snowball package", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.9861415922641754}]}, {"text": "Other than these, we do not perform any language-specific processing on the languages.", "labels": [], "entities": []}, {"text": "In case of French, since some function words like l', d' etc., occur as prefixes to a word, we strip them off during indexing and query processing, since it significantly improves the baseline performance.", "labels": [], "entities": []}, {"text": "We use standard evaluation measures like MAP, P@5 and P@10 for evaluation.", "labels": [], "entities": [{"text": "MAP", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9672858119010925}, {"text": "P@5", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.8929304281870524}]}, {"text": "Additionally, for assessing robustness, we use the Geometric Mean Average Precision (GMAP) metric) which is also used in the TREC Robust Track).", "labels": [], "entities": [{"text": "Geometric Mean Average Precision (GMAP) metric", "start_pos": 51, "end_pos": 97, "type": "METRIC", "confidence": 0.9566617012023926}, {"text": "TREC Robust Track", "start_pos": 125, "end_pos": 142, "type": "DATASET", "confidence": 0.681296189626058}]}, {"text": "The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool) on a parallel sentence aligned corpora.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.6653624773025513}]}, {"text": "For all the above language pairs we used the Europarl Corpus ().", "labels": [], "entities": [{"text": "Europarl Corpus", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.9924556910991669}]}, {"text": "We use Google Translate as the query translation system as it has been shown to perform well for the task ().", "labels": [], "entities": [{"text": "query translation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7790241539478302}]}, {"text": "We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection ().", "labels": [], "entities": []}, {"text": "We tune the parameters of MBF, specifically \u03bb and \u03b1, and choose the values which give the optimal performance on a given collection.", "labels": [], "entities": []}, {"text": "We observe that the optimal parameters \u03b3 and \u03b2 are uniform across collections and vary in the range 0.", "labels": [], "entities": []}, {"text": "uniformly choose the top ten documents for feedback.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Details of the CLEF Datasets used for Evaluating the MultiPRF approach. The number shown in brackets of the final  column CLEF Topics indicate the actual number of topics used during evaluation.", "labels": [], "entities": [{"text": "CLEF Datasets", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.8555296361446381}, {"text": "Evaluating", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.9602950811386108}]}, {"text": " Table 3: Comparison of MultiPRF Multiple Assisting Lan- guages using parallel assistance framework with MultiPRF  with single assisting language. Only language pairs where  positive improvements were obtained are reported here. Re- sults marked as  \u2021 indicate that the improvement was sta- tistically significant over baseline (Maximum of MultiPRF  with single assisting language) at 90% confidence level (\u03b1 =  0.01) when tested using a paired two-tailed t-test.", "labels": [], "entities": [{"text": "Re- sults", "start_pos": 229, "end_pos": 238, "type": "METRIC", "confidence": 0.9403473933537801}]}, {"text": " Table 4: Results showing the positive improvements of Mul- tiPRF with selective assistance framework over MultiPRF  with parallel assistance framework.", "labels": [], "entities": []}, {"text": " Table 5: Qualitative Comparison of MultiPRF Results using two assisting languages with single assisting language.", "labels": [], "entities": []}]}