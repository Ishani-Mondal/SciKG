{"title": [{"text": "Report of NEWS 2010 Transliteration Generation Shared Task", "labels": [], "entities": [{"text": "NEWS 2010 Transliteration Generation Shared", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.6095936179161072}]}], "abstractContent": [{"text": "This report documents the Translitera-tion Generation Shared Task conducted as apart of the Named Entities Workshop (NEWS 2010), an ACL 2010 workshop.", "labels": [], "entities": [{"text": "Translitera-tion Generation Shared Task", "start_pos": 26, "end_pos": 65, "type": "TASK", "confidence": 0.7801322638988495}]}, {"text": "The shared task features machine translit-eration of proper names from English to 9 languages and from 3 languages to En-glish.", "labels": [], "entities": []}, {"text": "In total, 12 tasks are provided.", "labels": [], "entities": []}, {"text": "7 teams from 5 different countries participated in the evaluations.", "labels": [], "entities": []}, {"text": "Finally, 33 standard and 8 non-standard runs are submitted , where diverse transliteration method-ologies are explored and reported on the evaluation data.", "labels": [], "entities": []}, {"text": "We report the results with 4 performance metrics.", "labels": [], "entities": []}, {"text": "We believe that the shared task has successfully achieved its objective by providing a common bench-marking platform for the research community to evaluate the state-of-the-art technologies that benefit the future research and development.", "labels": [], "entities": []}], "introductionContent": [{"text": "Names play a significant role in many Natural Language Processing (NLP) and Information Retrieval (IR) systems.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.8112572431564331}]}, {"text": "They are important in Cross Lingual Information Retrieval (CLIR) and Machine Translation (MT) as the system performance has been shown to positively correlate with the correct conversion of names between the languages in several studies).", "labels": [], "entities": [{"text": "Cross Lingual Information Retrieval (CLIR)", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.7206003708498818}, {"text": "Machine Translation (MT)", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.8465173006057739}]}, {"text": "The traditional source for name equivalence, the bilingual dictionaries -whether handcrafted or statistical -offer only limited support because new names always emerge.", "labels": [], "entities": [{"text": "name equivalence", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7461422085762024}]}, {"text": "All of the above point to the critical need for robust Machine Transliteration technology and systems.", "labels": [], "entities": []}, {"text": "Much research effort has been made to address the transliteration issue in the research community (;).", "labels": [], "entities": []}, {"text": "These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods.", "labels": [], "entities": []}, {"text": "Graphemebased method () treats transliteration as a direct orthographic mapping and only uses orthography-related features while phonemebased method) makes use of phonetic correspondence to generate the transliteration.", "labels": [], "entities": []}, {"text": "Hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation.", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 104, "end_pos": 130, "type": "TASK", "confidence": 0.8554128706455231}]}, {"text": "The first machine transliteration shared task ( The rest of the report is organised as follows.", "labels": [], "entities": [{"text": "machine transliteration shared", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.716201255718867}]}, {"text": "Section 2 outlines the machine transliteration task and the corpora used and Section 3 discusses the metrics chosen for evaluation, along with the rationale for choosing them.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present the participation in the shared task and the results with their analysis, respectively.", "labels": [], "entities": []}, {"text": "Section 6 concludes the report.", "labels": [], "entities": []}], "datasetContent": [{"text": "The participants have been asked to submit results of up to four standard and four non-standard runs.", "labels": [], "entities": []}, {"text": "One standard run must be named as the primary submission and is used for the performance summary.", "labels": [], "entities": []}, {"text": "Each run contains a ranked list of up to 10 candidate transliterations for each source name.", "labels": [], "entities": []}, {"text": "The submitted results are compared to the ground truth (reference transliterations) using 4 evaluation metrics capturing different aspects of transliteration performance.", "labels": [], "entities": []}, {"text": "We have dropped two M AP metrics used in NEWS 2009 because they don't offer additional information to M AP ref . Since a name may have multiple correct transliterations, all these alternatives are treated equally in the evaluation, that is, any of these alternatives is considered as a correct transliteration, and all candidates matching any of the reference transliterations are accepted as correct ones.", "labels": [], "entities": [{"text": "NEWS 2009", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.9380549192428589}]}, {"text": "The following notation is further assumed: N : Total number of names (source words) in the test set n i : Number of reference transliterations for i-th name in the test set (n i \u2265 1) r i,j : j-th reference transliteration for i-th name in the test set c i,k : k-th candidate transliteration (system output) for i-th name in the test set (1 \u2264 k \u2264 10) K i : Number of candidate transliterations produced by a transliteration system", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of runs submitted for each task. Number of participants coincides with the number of  standard runs submitted.", "labels": [], "entities": []}, {"text": " Table 3: Participation of teams in different tasks.  *  Participation without a system paper.", "labels": [], "entities": []}, {"text": " Table 4: Runs submitted for English to Chinese task.", "labels": [], "entities": []}, {"text": " Table 5: Runs submitted for Chinese to English back-transliteration task.", "labels": [], "entities": []}, {"text": " Table 6: Runs submitted for English to Thai task.", "labels": [], "entities": []}, {"text": " Table 7: Runs submitted for Thai to English back-transliteration task.", "labels": [], "entities": [{"text": "Thai to English back-transliteration task", "start_pos": 29, "end_pos": 70, "type": "TASK", "confidence": 0.6223307490348816}]}, {"text": " Table 8: Runs submitted for English to Hindi task.", "labels": [], "entities": []}, {"text": " Table 9: Runs submitted for English to Tamil task.", "labels": [], "entities": []}, {"text": " Table 10: Runs submitted for English to Kannada task.", "labels": [], "entities": []}, {"text": " Table 11: Runs submitted for English to Japanese Katakana task.", "labels": [], "entities": [{"text": "Japanese Katakana task", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.6989739040533701}]}, {"text": " Table 12: Runs submitted for English to Korean task.", "labels": [], "entities": [{"text": "English to Korean task", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.5033109933137894}]}, {"text": " Table 13: Runs submitted for English to Japanese Kanji back-transliteration task.", "labels": [], "entities": []}, {"text": " Table 14: Runs submitted for Arabic to English task.", "labels": [], "entities": []}]}