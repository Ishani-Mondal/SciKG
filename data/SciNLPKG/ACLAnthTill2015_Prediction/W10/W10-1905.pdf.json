{"title": [{"text": "A Comparative Study of Syntactic Parsers for Event Extraction", "labels": [], "entities": [{"text": "Event Extraction", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7585946321487427}]}], "abstractContent": [{"text": "The extraction of bio-molecular events from text is an important task fora number of domain applications such as pathway construction.", "labels": [], "entities": [{"text": "pathway construction", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.7731735110282898}]}, {"text": "Several syntactic parsers have been used in Biomedical Natural Language Processing (BioNLP) applications , and the BioNLP 2009 Shared Task results suggest that incorporation of syntactic analysis is important to achieving state-of-the-art performance.", "labels": [], "entities": [{"text": "BioNLP 2009 Shared Task", "start_pos": 115, "end_pos": 138, "type": "DATASET", "confidence": 0.8771631568670273}]}, {"text": "Direct comparison of parsers is complicated by to differences in the such as the division between phrase structure-and dependency-based analyses and the variety of output formats, structures and representations applied.", "labels": [], "entities": []}, {"text": "In this paper, we present a task-oriented comparison of five parsers, measuring their contribution to bio-molecular event extraction using a state-of-the-art event extraction system.", "labels": [], "entities": [{"text": "bio-molecular event extraction", "start_pos": 102, "end_pos": 132, "type": "TASK", "confidence": 0.6082050402959188}, {"text": "event extraction", "start_pos": 158, "end_pos": 174, "type": "TASK", "confidence": 0.7662668824195862}]}, {"text": "The results show that the parsers with domain models using dependency formats provide very similar performance, and that an ensemble of different parsers in different formats can improve the event extraction system.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 191, "end_pos": 207, "type": "TASK", "confidence": 0.7340533882379532}]}], "introductionContent": [{"text": "Bio-molecular events are useful for modeling and understanding biological systems, and their automatic extraction from text is one of the key tasks in Biomedical Natural Language Processing (BioNLP).", "labels": [], "entities": [{"text": "Biomedical Natural Language Processing (BioNLP)", "start_pos": 151, "end_pos": 198, "type": "TASK", "confidence": 0.6399814827101571}]}, {"text": "In the BioNLP 2009 Shared Task on event extraction, participants constructed event extraction systems using a variety of different parsers, and the results indicated that the use of a parser was correlated with high ranking in the task (.", "labels": [], "entities": [{"text": "BioNLP 2009 Shared Task on event extraction", "start_pos": 7, "end_pos": 50, "type": "TASK", "confidence": 0.7207543339048114}]}, {"text": "By contrast, the results did not indicate a clear preference fora particular parser, and there has so far been no direct comparison of different parsers for event extraction.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 157, "end_pos": 173, "type": "TASK", "confidence": 0.7697783410549164}]}, {"text": "While the outputs of parsers applying the same out format can be compared using a gold standard corpus, it is difficult to perform meaningful comparison of parsers applying different frameworks.", "labels": [], "entities": []}, {"text": "Additionally, it is still an open question to what extent high performance on a gold standard treebank correlates with usefulness at practical tasks.", "labels": [], "entities": []}, {"text": "Taskbased comparisons of parsers provide not only away to asses parsers across frameworks but also a necessary measure of their practical applicability.", "labels": [], "entities": []}, {"text": "In this paper, five different parsers are compared on the bio-molecular event extraction task defined in the BioNLP 2009 Shared Task using a state-of-the-art event extraction system.", "labels": [], "entities": [{"text": "bio-molecular event extraction task", "start_pos": 58, "end_pos": 93, "type": "TASK", "confidence": 0.6705439388751984}, {"text": "BioNLP 2009 Shared Task", "start_pos": 109, "end_pos": 132, "type": "DATASET", "confidence": 0.8727956563234329}]}, {"text": "The data sets share abstracts with GENIA treebank, and the treebank is used as an evaluation standard.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.9771111905574799}]}, {"text": "The outputs of the parsers are converted into two dependency formats with the help of existing conversion methods, and the outputs are compared in the two dependency formats.", "labels": [], "entities": []}, {"text": "The evaluation results show that different syntactic parsers with domain models in the same dependency format achieve closely similar performance, and that an ensemble of different syntactic parsers in different formats can improve the performance of an event extraction system.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 254, "end_pos": 270, "type": "TASK", "confidence": 0.7358400225639343}]}], "datasetContent": [{"text": "Event extraction performance is evaluated using the evaluation script provided by the BioNLP'09 shared task organizers 9 for the development data set, and the online evaluation system of the task for the test data set.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7659724354743958}, {"text": "BioNLP'09 shared task organizers 9", "start_pos": 86, "end_pos": 120, "type": "DATASET", "confidence": 0.8961622476577759}]}, {"text": "Results are reported under the official evaluation criterion of the task, i.e. the \"Approximate Span Matching/Approximate Recursive Matching\" criterion.", "labels": [], "entities": [{"text": "Approximate Span Matching/Approximate Recursive Matching\" criterion", "start_pos": 84, "end_pos": 151, "type": "METRIC", "confidence": 0.7174340685208639}]}, {"text": "Task 1 and Task 2 are solved at once for the evaluation.", "labels": [], "entities": []}, {"text": "As discussed in Section 2.2, the texts of the GE-NIA treebank are shared with the shared task data sets, which allows the gold annotations of the treebank to be used for reference.", "labels": [], "entities": [{"text": "GE-NIA treebank", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.9774189293384552}]}, {"text": "The GENIA treebank is converted into the Enju format with Enju.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9606684744358063}, {"text": "Enju format", "start_pos": 41, "end_pos": 52, "type": "DATASET", "confidence": 0.8858261108398438}, {"text": "Enju", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9556439518928528}]}, {"text": "When the trees in the treebank cannot be converted into the Enju format, parse results are used instead.", "labels": [], "entities": []}, {"text": "The GENIA treebank is also converted into PTB format . The treebank is then converted into the dependency formats with the conversions described in Section 2.2.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9692718088626862}, {"text": "PTB", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8976795673370361}]}, {"text": "While based on manually annotated gold data, the converted treebanks are not always correct due to conversion errors.", "labels": [], "entities": []}, {"text": "The event extraction system described in Section 2.3 is used with the default settings shown in (: Comparison of the F-score results with different Stanford dependency variants on the development data set with the MC parser.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7239357531070709}, {"text": "F-score", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.9876206517219543}]}, {"text": "Results for basic dependencies (BD), collapsed dependencies (CD), collapsed dependencies with propagation of conjunct dependencies (CDP), and collapsed tree dependencies (CTD) are shown.", "labels": [], "entities": []}, {"text": "The best score in each task is shown in bold.", "labels": [], "entities": []}, {"text": "Some of the parse results do not include word base forms or part-of-speech (POS) tags, which are required by the event extraction system.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.7121831029653549}]}, {"text": "To apply these parsers, the GENIA Tagger () output is adopted to add this information to the results.", "labels": [], "entities": [{"text": "GENIA Tagger", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.6230486929416656}]}, {"text": "Except for BD, these variants do not necessarily connect all the words in the sentence, and CD and CDP do not necessarily form a tree structure.", "labels": [], "entities": []}, {"text": "shows an example of CDP converted from the tree in.", "labels": [], "entities": []}, {"text": "To select a suitable alternative for the comparative experiments, we first compared these variants as a preliminary experiment.", "labels": [], "entities": []}, {"text": "shows the comparison results with the MC parser.", "labels": [], "entities": []}, {"text": "Dependencies are generalized by removing expressions after \" \" of the dependencies (e.g. \" with\" in prep with) for better performance.", "labels": [], "entities": []}, {"text": "We find that basic dependencies give the best performance to event extraction, with little difference between the other variants.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.8539614379405975}]}, {"text": "This result is surprising, as variants other than basic have features such as the resolution of conjunctions that are specifically designed for practical applications.", "labels": [], "entities": []}, {"text": "However, basic dependendencies were found to consistently provide best performance also for the other parsers .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of the F-score results with  different Stanford dependency variants without  dependency types.", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9844703674316406}]}, {"text": " Table 4: Comparison of the F-score results with parser ensembles on the development data set. C&C  with Stanford basic Dependency format, MC with CoNLL-X format, Enju with CoNLL-X format, and  Enju with Predicate Argument Structure in Enju format are used for the parser ensemble. The changes  from single-parser results are shown in parentheses. The best score in each task is shown in bold.", "labels": [], "entities": [{"text": "development data set", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.8050272464752197}]}]}