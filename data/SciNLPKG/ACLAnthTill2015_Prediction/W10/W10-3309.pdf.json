{"title": [{"text": "Ontolexical resources for feature based opinion mining : a case-study", "labels": [], "entities": [{"text": "feature based opinion mining", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.6276846155524254}]}], "abstractContent": [{"text": "Opinion mining is a growing research area both at the natural language processing and the information retrieval communities.", "labels": [], "entities": [{"text": "Opinion mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.899488776922226}, {"text": "natural language processing", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.6586997012297312}]}, {"text": "Companies, politicians, as well as customers need powerful tools to track opinions, sentiments, judgments and beliefs that people may express in blogs, reviews, audios and videos data regarding a prod-uct/service/person/organisation/etc.", "labels": [], "entities": [{"text": "track opinions, sentiments, judgments and beliefs that people may express in blogs, reviews, audios and videos data regarding a prod-uct/service/person/organisation/etc", "start_pos": 68, "end_pos": 236, "type": "Description", "confidence": 0.7350454609841108}]}, {"text": "This work describes our contribution to feature based opinion mining where opinions expressed towards each feature of an objector a product are extracted and summarized.", "labels": [], "entities": [{"text": "feature based opinion mining", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.6318111196160316}]}, {"text": "The state of the art has shown that the hierarchical organization of features is a key step.", "labels": [], "entities": []}, {"text": "In this context, our goal is to study the role of a domain ontology to structure and extract object features as well as to produce a comprehensive summary.", "labels": [], "entities": []}, {"text": "This paper presents the developed system and the experiments we carried out on a case study: French restaurant reviews.", "labels": [], "entities": []}, {"text": "Our results show that our approach outperforms standard baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Opinion mining is a growing research area both in natural language processing and information retrieval communities.", "labels": [], "entities": [{"text": "Opinion mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8996349275112152}, {"text": "natural language processing", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.6412375569343567}]}, {"text": "Companies, politicians, as well as customers need powerful tools to track opinions, sentiments, judgments and beliefs that people may express in blogs, reviews, audios and videos data regarding a product/service/person/organisation/etc.", "labels": [], "entities": [{"text": "track opinions, sentiments, judgments and beliefs that people may express in blogs, reviews, audios and videos data regarding a product/service/person/organisation/etc", "start_pos": 68, "end_pos": 235, "type": "Description", "confidence": 0.7381869154050946}]}, {"text": "The importance of emotion-oriented computing in the Web 2.0 has encouraged the creation of new search engines (like Tweetfeel (www.tweetfeel.com)) as well as the creation of anew research group within the W3C, namely the Emotion Markup Language, that aims to develop a representation language of the emotional states of a user or the emotional states to be simulated by a user interface.", "labels": [], "entities": []}, {"text": "In addition, most information retrieval evaluation campaigns (TREC, NTCI, etc.) have already integrated an opinion track.", "labels": [], "entities": [{"text": "information retrieval evaluation", "start_pos": 18, "end_pos": 50, "type": "TASK", "confidence": 0.7920031547546387}, {"text": "NTCI", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.8143348097801208}]}, {"text": "Computational approaches to sentiment analysis focus on extracting the affective content of a text from the detection of expressions of \"bag of sentiment words\" at different levels of granularity.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.9623398184776306}]}, {"text": "These expressions are assigned a positive or a negative scalar value, representing a positive, a negative or neutral sentiment towards some topic.", "labels": [], "entities": []}, {"text": "\u2022 Feature based opinion mining ( where opinions expressed towards the features of an objector a product are exacted and summarized.", "labels": [], "entities": [{"text": "Feature based opinion mining", "start_pos": 2, "end_pos": 30, "type": "TASK", "confidence": 0.5893643796443939}]}, {"text": "The work described in this paper feats into the last category.", "labels": [], "entities": []}, {"text": "The aim is not to compute the general orientation of a document or a sentence, since a positive sentiment towards an object does not imply a positive sentiment towards all the aspects of this object, as in: I like this restaurant even if the service is slow.", "labels": [], "entities": []}, {"text": "In feature based opinion mining, a holder (the person who posts the review) expresses a positive/negative or neutral opinions towards a main topic (the objector the product on which the holder expresses his opinions) and its associated features.", "labels": [], "entities": [{"text": "feature based opinion mining, a holder (the person who posts the review) expresses a positive/negative or neutral opinions towards a main topic (the objector the product on which the holder expresses his opinions) and its associated features", "start_pos": 3, "end_pos": 244, "type": "Description", "confidence": 0.8017928539351984}]}, {"text": "As defined in (), a feature can be a \"part-of\" of a topic (such as the screen of a camera) or a property of the \"part-of\" of the topic (such as the size of the screen).", "labels": [], "entities": []}, {"text": "The expressed opinion can be explicit, as in \"the screen of this camera is great\", or implicit, as in \"the camera is heavy\", that expresses a negative opinion towards the weight of the camera.", "labels": [], "entities": []}, {"text": "Same features can also be expressed differently, for example, \"drink\" and \"beverage\" refer to the same restaurant feature.", "labels": [], "entities": []}, {"text": "Having, for an object/product, the set of its associated features F={f1,\u2026fn}, research in feature based opinion mining mostly focus on extracting the set F from reviews, and then, for each feature fi of F, extract the set of its associated opinion expressions OE={OE1,\u2026OEj}.", "labels": [], "entities": [{"text": "feature based opinion mining", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.6909076496958733}, {"text": "OE", "start_pos": 260, "end_pos": 262, "type": "METRIC", "confidence": 0.9567530751228333}, {"text": "OE1", "start_pos": 264, "end_pos": 267, "type": "METRIC", "confidence": 0.8291634321212769}]}, {"text": "Once the set of couples (fi, OE) were extracted, a summary of the review is generally produced.", "labels": [], "entities": []}, {"text": "During this process, the key questions are: how the set F of features can be obtained?", "labels": [], "entities": []}, {"text": "How they are linguistically expressed?", "labels": [], "entities": []}, {"text": "How they are related to each other ? Which knowledge representation model can be used to better organize product features and to produce a comprehensive summary?", "labels": [], "entities": []}, {"text": "To answer these questions, we propose in this paper to study the role of an ontology in feature based opinion mining.", "labels": [], "entities": [{"text": "feature based opinion mining", "start_pos": 88, "end_pos": 116, "type": "TASK", "confidence": 0.6548651158809662}]}, {"text": "More precisely, our aim is to study how a domain ontology can be used to: \u2022 structure features: we show that an ontology is more suitable than a simple hierarchy where features are grouped using only the \"is-a\" relation ( \u2022 extract explicit and implicit features from texts: we show how the lexical component as well as the set of properties of the ontology can help to extract, for each feature, the set of the associated opinion expressions.", "labels": [], "entities": []}, {"text": "\u2022 produce a discourse based summary of the review: we show how the ontology can guide the process of identifying the most relevant discourse relations that may hold between elementary discourse units.", "labels": [], "entities": []}, {"text": "The paper is organised as follows.", "labels": [], "entities": []}, {"text": "We give in section 2, a state of the art of the main approaches used in the field as well as the motivations of our work.", "labels": [], "entities": []}, {"text": "We present in the next section, our approach.", "labels": [], "entities": []}, {"text": "Finally, in section 4, we describe the experiments we carried out on a case study: French restaurant reviews 2 Feature based Opinion mining", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct three types of experiment: the evaluation of the extraction of elementary opinion units (cf. section 3.1), the evaluation of the features extraction step (cf. section 3.2) and finally, the evaluation of the link between the retrieved opinion expressions and the retrieved object features (cf. section 3.3).", "labels": [], "entities": []}, {"text": "These experiments are carried out using GATE 6 toolkit.", "labels": [], "entities": [{"text": "GATE 6 toolkit", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9026666084925333}]}, {"text": "To evaluate our system, we create a gold standard by manually annotate in the corpus implicit and explicit elementary opinion units, implicit and explicit object features as well as for each opinion expression its associated feature.", "labels": [], "entities": []}, {"text": "The table below shows our results.", "labels": [], "entities": []}, {"text": "Our system misses some EOU for two main reasons.", "labels": [], "entities": [{"text": "EOU", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9915202260017395}]}, {"text": "The first one is due to missed opinion words in the lexicon and to implicit opinion expressions, such as breathtaking, since our extraction rules do not manage these cases (note that implicit opinion detection is still an open research problem in opinion mining).", "labels": [], "entities": [{"text": "implicit opinion detection", "start_pos": 183, "end_pos": 209, "type": "TASK", "confidence": 0.7205227017402649}, {"text": "opinion mining", "start_pos": 247, "end_pos": 261, "type": "TASK", "confidence": 0.8228800594806671}]}, {"text": "The second reason is the errors that come from the syntactic parser mainly because of typos and dependency link errors.", "labels": [], "entities": []}, {"text": "Concerning precision, false positives are mainly due to some opinion words that are in our lexicon but they do not express opinions in the restaurant domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9986603260040283}]}, {"text": "In addition, some of our extraction rules, especially those that extract expression of recommendations, do not perform very well which imply a loss of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.998256504535675}]}, {"text": "Since the corpus is in the restaurant domain, the precision of this task is very good because most of the extracted features are relevant.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9996033310890198}]}, {"text": "However, recall is not as good as precision because the set of ontology labels do not totally cover the terms of the corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9984833598136902}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9994862079620361}]}, {"text": "Another limitation of our system is that we do not take into account the cases where a term can be a linguistic realization of many concepts (ex. caf\u00e9 can be a drink or a place to drink).", "labels": [], "entities": []}, {"text": "shows an example of the result we obtain for this step.", "labels": [], "entities": []}, {"text": "In this example, the system is able to extract opinion expressions which do not contain words present in the lexicon.", "labels": [], "entities": []}, {"text": "It is the case with \"sympa (nice)\" which has been correctly associated to \"resto (restaurant)\" and \"deco (interior design)\" even if the word nice was not in the lexicon.", "labels": [], "entities": []}, {"text": "In the Hu and Liu approach, features are nominal groups.", "labels": [], "entities": []}, {"text": "We first extract all frequent features from our corpus that appear in more than 1% of the sentences.", "labels": [], "entities": []}, {"text": "Then we extract EOU from those sentences (note that contrary to Hu and Liu, we do not extract only adjectives, but also nouns, verbs and adverbs).", "labels": [], "entities": [{"text": "EOU", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9851074814796448}]}, {"text": "Non frequent features are finally removed as described in ().", "labels": [], "entities": []}, {"text": "In order to improve the extraction of relevant features, we extract features that have a good point mutual information value with the word restaurant, as described in ().", "labels": [], "entities": []}, {"text": "The precision of our system is better compared to the approach of Hu and Liu that extracts too many irrelevant features (such as any doubt, whole word).", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9993129968643188}]}, {"text": "Our system is also better compared to the PMI approach even if it performs better than Hu and Liu's approach.", "labels": [], "entities": []}, {"text": "Recall is also better because our system can extract implicit features such as well eating, lot of noise, thanks to the use of ontology properties.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9254672527313232}]}, {"text": "Finally, when using only taxonomy of concepts instead of the ontology, we observe that the Fmeasure is slightly better because actually fea-tures related to object properties represent only 1,6% of feature cases in our corpus.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.700681746006012}]}, {"text": "Using, the ontology, our approach is able to extract from sentences like \"we eat good and healthy\" the couples (eat, good) and (eat, healthy) and then to link the opinion expressions to the concept dish whereas when using only the taxonomy, these opinion expressions are related to any feature.", "labels": [], "entities": []}], "tableCaptions": []}