{"title": [{"text": "Improved Natural Language Learning via Variance-Regularization Support Vector Machines", "labels": [], "entities": [{"text": "Improved Natural Language Learning", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8707773089408875}]}], "abstractContent": [{"text": "We present a simple technique for learning better SVMs using fewer training examples.", "labels": [], "entities": []}, {"text": "Rather than using the standard SVM regularization, we regularize toward low weight-variance.", "labels": [], "entities": []}, {"text": "Our new SVM objective remains a convex quadratic function of the weights, and is therefore com-putationally no harder to optimize than a standard SVM.", "labels": [], "entities": []}, {"text": "Variance regularization is shown to enable dramatic improvements in the learning rates of SVMs on three lexical disambiguation tasks.", "labels": [], "entities": [{"text": "Variance regularization", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6473331153392792}]}], "introductionContent": [{"text": "Discriminative training is commonly used in NLP and speech to scale the contribution of different models or systems in a combined predictor.", "labels": [], "entities": []}, {"text": "For example, discriminative training can be used to scale the contribution of the language model and translation model in machine translation).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7568528056144714}]}, {"text": "Without training data, it is often reasonable to weight the different models equally.", "labels": [], "entities": []}, {"text": "We propose a simple technique that exploits this intuition for better learning with fewer training examples.", "labels": [], "entities": []}, {"text": "We regularize the feature weights in a Support Vector Machine ( toward a low-variance solution.", "labels": [], "entities": []}, {"text": "Since the new SVM quadratic program is convex, it is no harder to optimize than the standard SVM objective.", "labels": [], "entities": []}, {"text": "When training data is generated through human effort, faster learning saves time and money.", "labels": [], "entities": []}, {"text": "When examples are labeled automatically, through user feedback) or from textual pseudo-examples (, faster learning can reduce the lag before anew system is useful.", "labels": [], "entities": []}, {"text": "We demonstrate faster learning on lexical disambiguation tasks.", "labels": [], "entities": []}, {"text": "For these tasks, a system predicts a label fora word in text, based on the word's context.", "labels": [], "entities": []}, {"text": "Possible labels include part-ofspeech tags, named-entity types, and word senses.", "labels": [], "entities": []}, {"text": "A number of disambiguation systems make predictions with the help of N-gram counts from a web-scale auxiliary corpus, typically via a searchengine () or N-gram corpus (.", "labels": [], "entities": []}, {"text": "When discriminative training is used to weigh the counts for classification, many of the learned feature weights have similar values.", "labels": [], "entities": [{"text": "classification", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.9652284979820251}]}, {"text": "Good weights have low variance.", "labels": [], "entities": [{"text": "variance", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9737372398376465}]}, {"text": "For example, consider the task of preposition selection.", "labels": [], "entities": [{"text": "preposition selection", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.8641593158245087}]}, {"text": "A system selects the most likely preposition given the context, and flags a possible error if it disagrees with the user's choice: \u2022 I worked in Russia from 1997 to 2001.", "labels": [], "entities": []}, {"text": "\u2022 I worked in Russia *during 1997 to 2001.", "labels": [], "entities": []}, {"text": "use a variety of web counts to predict the correct preposition.", "labels": [], "entities": []}, {"text": "They have features for COUNT(in Russia from), COUNT(Russia from 1997), COUNT(from 1997 to), etc.", "labels": [], "entities": [{"text": "COUNT", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8996200561523438}, {"text": "COUNT", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.9103032946586609}, {"text": "COUNT", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.8574461936950684}]}, {"text": "If these are high, from is predicted.", "labels": [], "entities": []}, {"text": "Similarly, they have features for COUNT(in Russia during), COUNT(Russia during 1997),.", "labels": [], "entities": [{"text": "COUNT", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.8854236602783203}, {"text": "COUNT(Russia during 1997)", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.8212110996246338}]}, {"text": "All counts are in the log domain.", "labels": [], "entities": []}, {"text": "The task has thirty-four different prepositions to choose from.", "labels": [], "entities": []}, {"text": "A 34-way classifier is trained on examples of correct preposition usage; it learns which context positions and sizes are most reliable and assigns feature weights accordingly.", "labels": [], "entities": []}, {"text": "Avery strong unsupervised baseline, however, is to simply weight all the count features equally.", "labels": [], "entities": []}, {"text": "In fact, in, the supervised approach requires over 30,000 training examples before it outperforms this baseline.", "labels": [], "entities": []}, {"text": "In contrast, we show that by regularizing a classifier toward equal weights, a supervised predictor outperforms the unsupervised approach after only ten examples, and does as well with 1000 examples as the standard classifier does with 100,000.", "labels": [], "entities": []}, {"text": "Section 2 first describes a general multi-class SVM.", "labels": [], "entities": []}, {"text": "We call the base vector of information used by the SVM the attributes.", "labels": [], "entities": []}, {"text": "A standard multi-class SVM creates features for the crossproduct of attributes and classes.", "labels": [], "entities": []}, {"text": "E.g., the attribute COUNT(Russia during 1997) is not only a feature for predicting the preposition during, but also for predicting the 33 other prepositions.", "labels": [], "entities": [{"text": "COUNT", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.9194891452789307}, {"text": "Russia during 1997)", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.7690143138170242}]}, {"text": "The SVM must therefore learn to disregard many irrelevant features.", "labels": [], "entities": []}, {"text": "We observe that this is not necessary, and develop an SVM that only uses the relevant attributes in the score for each class.", "labels": [], "entities": []}, {"text": "Building on this efficient framework, we incorporate variance regularization into the SVM's quadratic program.", "labels": [], "entities": []}, {"text": "We apply our algorithms to three tasks: preposition selection, context-sensitive spelling correction, and non-referential pronoun detection (Section 4).", "labels": [], "entities": [{"text": "preposition selection", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.8411434888839722}, {"text": "context-sensitive spelling correction", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.5896784961223602}, {"text": "non-referential pronoun detection", "start_pos": 106, "end_pos": 139, "type": "TASK", "confidence": 0.7075124581654867}]}, {"text": "We reproduce's results using a multi-class SVM.", "labels": [], "entities": []}, {"text": "Our new models achieve much better accuracy with fewer training examples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9987370371818542}]}, {"text": "We also exceed the accuracy of a reasonable alternative technique for increasing the learning rate: including the output of the unsupervised system as a feature in the SVM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9996862411499023}]}, {"text": "Variance regularization is an elegant addition to the suite of methods in NLP that improve performance when access to labeled data is limited.", "labels": [], "entities": [{"text": "Variance regularization", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7003910541534424}]}, {"text": "Section 5 discusses some related approaches.", "labels": [], "entities": []}, {"text": "While we motivate our algorithm as away to learn better weights when the features are counts from an auxiliary corpus, there are other potential uses of our method.", "labels": [], "entities": []}, {"text": "We outline some of these in Section 6, and note other directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the data sets from.", "labels": [], "entities": []}, {"text": "These are the three tasks where web-scale N-gram counts were previously used as features in a standard K-SVM.", "labels": [], "entities": []}, {"text": "In each case a classifier makes a decision fora particular word based on the word's surrounding context.", "labels": [], "entities": []}, {"text": "The attributes of the classifier are the log counts of different fillers occurring in the context patterns.", "labels": [], "entities": []}, {"text": "We retrieve counts from the web-scale Google Web 5-gram Corpus (), which includes N-grams of length one to five.", "labels": [], "entities": [{"text": "Google Web 5-gram Corpus", "start_pos": 38, "end_pos": 62, "type": "DATASET", "confidence": 0.8846270143985748}]}, {"text": "We apply add-one smoothing to all counts.", "labels": [], "entities": []}, {"text": "Every classifier also has bias features (for every class).", "labels": [], "entities": []}, {"text": "We simply include, where appropriate, attributes that are always unity.", "labels": [], "entities": []}, {"text": "We use LIBLINEAR) to train K-SVM and OvA-SVM, and SVM rank) to train CS-SVM.", "labels": [], "entities": [{"text": "LIBLINEAR", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9881163835525513}]}, {"text": "For VAR-SVM, we solve the primal form of the quadratic program directly in, a general optimization package.", "labels": [], "entities": [{"text": "VAR-SVM", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.5933655500411987}]}, {"text": "We vary the number of training examples for each classifier.", "labels": [], "entities": []}, {"text": "The C-parameters of all SVMs are tuned on development data.", "labels": [], "entities": [{"text": "SVMs", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.8884962797164917}]}, {"text": "We evaluate using accuracy: the percentage of test examples that are classified correctly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9993937015533447}]}, {"text": "We also provide the accuracy of the majority-class baseline and best unsupervised system, as defined in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9995611310005188}]}, {"text": "As an alternative way to increase the learning rate, we augment a classifier's features using the output of the unsupervised system: For each class, we include one feature for the sum of all counts (in the unsupervised system) that predict that class.", "labels": [], "entities": []}, {"text": "We denote these augmented systems with a + as in K-SVM + and CS-SVM + .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy (%) of preposition-selection  SVMs. Unsupervised accuracy is 73.7%.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990572333335876}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9687519073486328}]}, {"text": " Table 2: Accuracy (%) of spell-correction SVMs.  Unsupervised accuracy is 94.8%.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991344809532166}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9724829792976379}]}, {"text": " Table 3: Accuracy (%) of non-referential detection  SVMs. Unsupervised accuracy is 80.1%.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991814494132996}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9752174615859985}]}]}