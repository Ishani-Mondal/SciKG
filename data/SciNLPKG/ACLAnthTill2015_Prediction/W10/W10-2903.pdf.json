{"title": [{"text": "Driving Semantic Parsing from the World's Response", "labels": [], "entities": [{"text": "Driving Semantic Parsing from the World's Response", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7060295641422272}]}], "abstractContent": [{"text": "Current approaches to semantic parsing, the task of converting text to a formal meaning representation, rely on annotated training data mapping sentences to logical forms.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7974966466426849}]}, {"text": "Providing this supervision is a major bottleneck in scaling semantic parsers.", "labels": [], "entities": [{"text": "scaling semantic parsers", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7604837814966837}]}, {"text": "This paper presents anew learning paradigm aimed at alleviating the supervision burden.", "labels": [], "entities": []}, {"text": "We develop two novel learning algorithms capable of predicting complex structures which only rely on a binary feedback signal based on the context of an external world.", "labels": [], "entities": [{"text": "predicting complex structures", "start_pos": 52, "end_pos": 81, "type": "TASK", "confidence": 0.8693822622299194}]}, {"text": "In addition we reformulate the semantic parsing problem to reduce the dependency of the model on syntactic patterns, thus allowing our parser to scale better using less supervision.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7165081650018692}]}, {"text": "Our results surprisingly show that without using any annotated meaning representations learning with a weak feedback signal is capable of producing a parser that is competitive with fully supervised parsers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Parsing, the process of converting text into a formal meaning representation (MR), is one of the key challenges in natural language processing.", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8293589651584625}, {"text": "converting text into a formal meaning representation (MR)", "start_pos": 33, "end_pos": 90, "type": "TASK", "confidence": 0.6489574491977692}, {"text": "natural language processing", "start_pos": 124, "end_pos": 151, "type": "TASK", "confidence": 0.6384889086087545}]}, {"text": "Unlike shallow approaches for semantic interpretation (e.g., semantic role labeling and information extraction) which often result in an incomplete or ambiguous interpretation of the natural language (NL) input, the output of a semantic parser is a complete meaning representation that can be executed directly by a computer program.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7581305503845215}, {"text": "semantic role labeling", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.6310878197352091}, {"text": "information extraction)", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.8061827917893728}]}, {"text": "Semantic parsing has mainly been studied in the context of providing natural language interfaces to computer systems.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8648158311843872}]}, {"text": "In these settings the target meaning representation is defined by the semantics of the underlying task.", "labels": [], "entities": []}, {"text": "For example, providing access to databases: a question posed in natural language is converted into a formal database query that can be executed to retrieve information.", "labels": [], "entities": []}, {"text": "Example 1 shows a NL input query and its corresponding meaning representation.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe our experimental setup, which includes the details of the domain, resources and parameters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of learned models on R250 data and", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9971389770507812}, {"text": "R250 data", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9677912592887878}]}, {"text": " Table 2: Comparison against previously published results.", "labels": [], "entities": [{"text": "Comparison", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8819776177406311}]}]}