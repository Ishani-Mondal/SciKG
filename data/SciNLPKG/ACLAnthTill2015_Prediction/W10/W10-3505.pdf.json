{"title": [{"text": "Pruning Non-Informative Text Through Non-Expert Annotations to Improve Aspect-Level Sentiment Classification", "labels": [], "entities": [{"text": "Improve Aspect-Level Sentiment Classification", "start_pos": 63, "end_pos": 108, "type": "TASK", "confidence": 0.6336178407073021}]}], "abstractContent": [{"text": "Sentiment analysis attempts to extract the author's sentiments or opinions from un-structured text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9539903998374939}]}, {"text": "Unlike approaches based on rules, a machine learning approach holds the promise of learning robust, high-coverage sentiment classifiers from labeled examples.", "labels": [], "entities": []}, {"text": "However, people tend to use different ways to express the same sentiment due to the richness of natural language.", "labels": [], "entities": []}, {"text": "Therefore, each sentiment expression normally does not have many examples in the training corpus.", "labels": [], "entities": []}, {"text": "Furthermore , sentences extracted from unstruc-tured text (e.g., I filmed my daughter's ballet recital and could not believe how the auto focus kept blurring then focus-ing) often contain both informative (e.g., the auto focus kept blurring then focus-ing) and extraneous non-informative text regarding the author's sentiment towards a certain topic.", "labels": [], "entities": []}, {"text": "When there are few examples of any given sentiment expression, extraneous non-sentiment information cannot be identified as noise by the learning algorithm and can easily become correlated with the sentiment label, thereby confusing sentiment classifiers.", "labels": [], "entities": []}, {"text": "In this paper , we present a highly effective procedure for using crowd-sourcing techniques to label informative and non-informative information regarding the sentiment expressed in a sentence.", "labels": [], "entities": []}, {"text": "We also show that pruning non-informative information using non-expert annotations during the training phase can result in classifiers with better performance even when the test data includes non-informative information.", "labels": [], "entities": []}], "introductionContent": [{"text": "Noise in training data can be derived either from noisy labeling or from noisy features.", "labels": [], "entities": []}, {"text": "It has been shown that labeling quality is one of the important factors that impacts the performance of a learned model, and that this quality can be improved by approaches such as using multiple labelers.", "labels": [], "entities": []}, {"text": "However, noisy features can bean inherent characteristic for some text mining tasks, and it is unclear how they should be handled.", "labels": [], "entities": [{"text": "text mining tasks", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.8619779745737711}]}, {"text": "For example, sentiment analysis/opinion mining from unstructured user generated content such as online reviews and blogs often relies on learning sentiments from word-based features extracted from the training sentences and documents).", "labels": [], "entities": [{"text": "sentiment analysis/opinion mining from unstructured user generated content such as online reviews and blogs", "start_pos": 13, "end_pos": 120, "type": "TASK", "confidence": 0.8328686468303204}]}, {"text": "However, not all words in the training data carry information about sentiment.", "labels": [], "entities": []}, {"text": "For example, in sentence (1), (1)I filmed my daughter's ballet recital and could not believe how the auto focus kept blurring then focusing.", "labels": [], "entities": []}, {"text": "although words such as auto focus, blurring and focusing are informative for learning sentiment regarding the auto focus capability of the camera, words such as film, daughter and ballet recital are not informative for that type of sentiment, and they form noise if included as training data.", "labels": [], "entities": []}, {"text": "If the training data contain a lot of examples such as (2) in which words such as film, daughter and ballet recital also appear, but the sentence is not labelled as invoking sentiment regarding auto focus, a machine learning algorithm might learn that such words are not informative for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 287, "end_pos": 311, "type": "TASK", "confidence": 0.8595010340213776}]}, {"text": "(2)I filmed my daughter's ballet recital and could not believe how good the picture quality was.", "labels": [], "entities": []}, {"text": "However, due to the richness of natural language, people tend to use different ways to describe a similar event or to express a similar opinion.", "labels": [], "entities": []}, {"text": "Consequently, repeated use of the same expression is not common in the training data for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.9576342403888702}]}, {"text": "Note that this difficulty cannot be simply overcome by increasing the size of the training data.", "labels": [], "entities": []}, {"text": "For example, a search on the completely natural phrase \"I filmed my daughter's ballet recital\" in Google and Bing returns the same exact sentence as shown in.", "labels": [], "entities": []}, {"text": "In other words, there appears to be only one sentence containing that exact phrase, which implies that even if we use the entire web as our training data set we would not find an example such as (2) to help the learning algorithm to determine which feature words in (1) are informative and which are not.", "labels": [], "entities": []}, {"text": "Therefore, data sparsity is an inherent problem fora task such as sentiment analysis, and if we adopt the bag-of-words approach for sentiment classification (), which uses the words that appear in sentences as training features, our training data will unavoidably include many noisy non-informative features.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.9660429358482361}, {"text": "sentiment classification", "start_pos": 132, "end_pos": 156, "type": "TASK", "confidence": 0.8582400679588318}]}, {"text": "This paper presents a crowd-sourcing technique to identify and prune the non-informative features.", "labels": [], "entities": []}, {"text": "We explore the effect of using non-expert annotations to gain low-noise training data for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.9651972949504852}]}, {"text": "We show that the cleaner training data obtained from non-expert annotations significantly improve the performance of the sentiment classifier.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 121, "end_pos": 141, "type": "TASK", "confidence": 0.8570646047592163}]}, {"text": "We also present evidence that this improvement is due to reduction in confusion between classes due to noise words.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our approach for pruning noninformative features.", "labels": [], "entities": []}, {"text": "Section 4 presents an empirical study on the effect of training on informative features in the domain of sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.9337897598743439}]}, {"text": "Conclusions are summarized in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Class Distribution in Experiment 1", "labels": [], "entities": [{"text": "Class Distribution", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.746593713760376}]}, {"text": " Table 3: Automatic Feature Selection Results", "labels": [], "entities": [{"text": "Automatic Feature Selection", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.5627176761627197}]}]}