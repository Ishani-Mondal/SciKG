{"title": [{"text": "Transliteration Generation and Mining with Limited Training Resources", "labels": [], "entities": [{"text": "Transliteration Generation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9119845628738403}]}], "abstractContent": [{"text": "We present DIRECTL+: an online dis-criminative sequence prediction model based on many-to-many alignments, which is further augmented by the incorporation of joint n-gram features.", "labels": [], "entities": [{"text": "dis-criminative sequence prediction", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.6032650669415792}]}, {"text": "Experimental results show improvement over the results achieved by DIRECTL in 2009.", "labels": [], "entities": [{"text": "DIRECTL", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.8453558087348938}]}, {"text": "We also explore a number of diverse resource-free and language-independent approaches to transliteration mining, which range from simple to sophisticated.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.9161247611045837}]}], "introductionContent": [{"text": "Many out-of-vocabulary words in statistical machine translation and cross-language information retrieval are named entities.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6857997477054596}, {"text": "cross-language information retrieval", "start_pos": 68, "end_pos": 104, "type": "TASK", "confidence": 0.702360471089681}]}, {"text": "If the languages in question use different writing scripts, such names must be transliterated.", "labels": [], "entities": []}, {"text": "Transliteration can be defined as the conversion of a word from one writing script to another, which is usually based on the phonetics of the original word.", "labels": [], "entities": []}, {"text": "DIRECTL+ is our current approach to name transliteration which is an extension of the DI-RECTL system).", "labels": [], "entities": [{"text": "name transliteration", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.8869630396366119}]}, {"text": "We augmented the feature set with joint n-gram features which allow the discriminative model to utilize long dependencies of joint information of source and target substrings (.", "labels": [], "entities": []}, {"text": "Experimental results suggest an improvement over the results achieved by DIRECTL in 2009.", "labels": [], "entities": [{"text": "DIRECTL in 2009", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.8847435911496481}]}, {"text": "Transliteration mining aims at automatically obtaining bilingual lists of names written in different scripts.", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9000023007392883}]}, {"text": "We explore a number of different approaches to transliteration mining in the context of the NEWS 2010 Shared Task.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.9090400338172913}, {"text": "NEWS 2010 Shared Task", "start_pos": 92, "end_pos": 113, "type": "DATASET", "confidence": 0.8532117009162903}]}, {"text": "The sole resource that is provided for each language pair is a \"seed\" dataset that contains 1K transliteration word pairs.", "labels": [], "entities": []}, {"text": "The objective is then to mine transliteration pairs from a collection of Wikipedia titles/topics that are given in both languages.", "labels": [], "entities": []}, {"text": "We explore a number of diverse resource-free and language-independent approaches to transliteration mining.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.8927807807922363}]}, {"text": "One approach is to bootstrap the seed data by generating pseudo-negative examples, which are combined with the positives to form a dataset that can be used to train a classifier.", "labels": [], "entities": []}, {"text": "We are particularly interested in achieving good performance without utilizing languagespecific resources, so that the same approach can be applied with minimal or no modifications to an array of diverse language pairs.", "labels": [], "entities": []}, {"text": "This paper is divided in two main parts that correspond to the two tasks of transliteration generation and transliteration mining.", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.8816354274749756}, {"text": "transliteration mining", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8965176641941071}]}], "datasetContent": [{"text": "In the context of the NEWS 2010 Machine Transliteration Shared Task we tested our system on all twelve datasets: from English to Chinese (EnCh), Thai (EnTh), Hindi (EnHi), Tamil (EnTa), Bangla (EnBa), Kannada (EnKa), Korean Hangul (EnKo), Japanese Katakana (EnJa), Japanese Kanji (JnJk); and, in the opposite direction, to English from Arabic (ArAe), Chinese (ChEn), and Thai (ThEn).", "labels": [], "entities": [{"text": "NEWS 2010 Machine Transliteration Shared Task", "start_pos": 22, "end_pos": 67, "type": "TASK", "confidence": 0.608175535996755}]}, {"text": "For all datasets, we trained transliteration models on the provided training and development sets without additional resources.", "labels": [], "entities": []}, {"text": "shows our best results obtained on the datasets in terms of top-1 accuracy and mean Fscore.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9791175127029419}, {"text": "mean", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9677976965904236}, {"text": "Fscore", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9104962944984436}]}, {"text": "We also include the rank in standard runs ordered by top-1 word accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9008793234825134}]}, {"text": "The EnCh result presented in the table refers to the output of the three-system combination, using the combination algorithm described in Section 2.4.3.", "labels": [], "entities": []}, {"text": "The respective results for the three component EnCh systems were: 0.357, 0.360, and 0.363.", "labels": [], "entities": [{"text": "EnCh", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.8076817989349365}]}, {"text": "The EnJa result in the table refers the system described in Section 2.4.2 that applied specific treatment to Japanese Katakana.", "labels": [], "entities": [{"text": "EnJa", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.6547409296035767}]}, {"text": "Based on our development results, this specific treatment improves as much as 2% top-1 accuracy over the languageindependent model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9911682605743408}]}, {"text": "The EnHi system that incorporates language identification obtained exactly the same top-1 accuracy as the languageindependent model.", "labels": [], "entities": [{"text": "language identification", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.738095298409462}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9917123317718506}]}, {"text": "However, the EnKo system with Jaso correction produced the top-1 accu-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Transliteration generation results", "labels": [], "entities": [{"text": "Transliteration generation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.924167811870575}]}, {"text": " Table 3: Transliteration mining results. An aster- isk (*) indicates an unofficial result.", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9090932011604309}]}]}