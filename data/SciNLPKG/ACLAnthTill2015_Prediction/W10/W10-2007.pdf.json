{"title": [{"text": "Predicting Cognitively Salient Modifiers of the Constitutive Parts of Concepts", "labels": [], "entities": [{"text": "Predicting Cognitively Salient Modifiers of the Constitutive Parts of Concepts", "start_pos": 0, "end_pos": 78, "type": "TASK", "confidence": 0.8235457539558411}]}], "abstractContent": [{"text": "When subjects describe concepts in terms of their characteristic properties, they often produce composite properties, e. g., rabbits are said to have long ears, not just ears.", "labels": [], "entities": []}, {"text": "We present a set of simple methods to extract the modifiers of composite properties (in particular: parts) from corpora.", "labels": [], "entities": []}, {"text": "We achieve our best performance by combining evidence about the association between the modifier and the part both within the context of the target concept and independently of it.", "labels": [], "entities": []}, {"text": "We show that this performance is relatively stable across languages (Italian and German) and for production vs. perception of properties.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subject-generated concept descriptions in terms of properties of different kinds (category: rabbits are mammals, parts: they have long ears, behaviour: they jump, . .", "labels": [], "entities": []}, {"text": ") are widely used in cognitive science as proxies to feature-based representations of concepts in the mind (.", "labels": [], "entities": []}, {"text": "These feature norms (as collections of subject-elicited properties are called in the relevant literature) are used in simulations of cognitive tasks and experimental design.", "labels": [], "entities": []}, {"text": "Moreover, vector spaces that have subject-generated properties as dimensions have been shown to be a good complement or alternative to traditional semantic models based on corpus collocates (.", "labels": [], "entities": []}, {"text": "Since the concept-property pairs in feature norms resemble the tuples that relation extraction algorithms extract from corpora), recent research has attempted to extract feature-norm-like concept descriptions from corpora.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.720855712890625}]}, {"text": "From a practical point of view, the success of this enterprise would mean being able to produce much larger norms without the need to resort to expensive and time-consuming elicitation experiments, leading to wider cognitive simulations and possibly better vector space models of semantics.", "labels": [], "entities": []}, {"text": "From a theoretical point of view, a corpus-based system that produces human-like concept descriptions might provide cues of how humans themselves come up with such descriptions.", "labels": [], "entities": []}, {"text": "However, the corpus-based models proposed for this task up to this point overlook the fact that subjects very often produce composite properties: Subjects state that rabbits have long ears, not just ears; cars have four wheels; a calf is a baby cow, etc.", "labels": [], "entities": []}, {"text": "Composite properties are not multi-word expressions in the usual sense.", "labels": [], "entities": []}, {"text": "There is nothing special or idiomatic about long ears.", "labels": [], "entities": []}, {"text": "It is just that we find it to be a remarkable fact about rabbits, worth stating in their description, that their ears are long.", "labels": [], "entities": []}, {"text": "In the norms described in section 3, around one third of the part descriptions are composite.", "labels": [], "entities": []}, {"text": "Note that while our focus is on feature norms, a similar point about the importance of composite properties could be made for other knowledge repositories of importance to computational linguistics, such as WordNet and ConceptNet (), approximately 68,000 (36%) of the entries and 1,300 (32%) of the part entries being composites, respectively.", "labels": [], "entities": []}, {"text": "In this paper, we tackle the problem of generating composite properties from corpus data by simplifying it in various ways.", "labels": [], "entities": []}, {"text": "First, we focus on part properties only, because they are commonly encountered in feature norms, and because they are are commonly composite (cf. section 3).", "labels": [], "entities": []}, {"text": "Second, we assume that an early step in the process of property extraction has already generated a list of simple parts, perhaps using an existing whole-part relation extraction algorithm ().", "labels": [], "entities": [{"text": "property extraction", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7461527585983276}]}, {"text": "Finally, we focus on composite parts with an adjective-noun structure -together with numeral-noun cases, these constitute the near totality of composite parts in the norms described in section 3.", "labels": [], "entities": []}, {"text": "Having thus delimited the scope of our exploration, we will adopt the following terminology: concept for the target nominal concept (rabbit), part for the (nominal) part property (ear) and modifier for the adjective that makes the part composite (long).", "labels": [], "entities": []}, {"text": "We present simple methods that, given a list of concept-part pairs and a POS-tagged and lemmatised corpus, rank and extract candidate modifiers for the parts when predicated of the concepts.", "labels": [], "entities": []}, {"text": "We exploit the co-occurrence patterns of the part with the modifier both near the concept and in other contexts (both kinds of co-occurrences turnout to be helpful).", "labels": [], "entities": []}, {"text": "We first test our methods on German feature norms, and then we show that they generalise well by applying them to similar data in Italian, and to the same set of German concept-part pairs when evaluated by asking new subjects to rate the top ranked modifiers generated by the ranking methods.", "labels": [], "entities": []}, {"text": "This also leads to a more general discussion of differences between modifiers produced by subjects in the elicitation experiment and those that are rated acceptable in perception, and the significance of this for corpus-based property generation.", "labels": [], "entities": [{"text": "corpus-based property generation", "start_pos": 213, "end_pos": 245, "type": "TASK", "confidence": 0.7124938170115153}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "After shortly reviewing some related work in section 2, in section 3, we describe our feature norms focusing in particular on composite properties.", "labels": [], "entities": []}, {"text": "In section 4, we describe our methods to harvest modifiers from a corpus and report the extraction experiments, whereas section 5 concludes by discussing directions for further work.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the approach we explored for ranking and extracting modifiers of composite parts and evaluates the performance of 6 different extraction methods in terms of the production norms.", "labels": [], "entities": []}, {"text": "Acceptance rate data from a follow-up judgement experiment complete the evaluation.", "labels": [], "entities": [{"text": "Acceptance rate", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9480535387992859}]}, {"text": "The purpose of this judgement experiment was to see which concept-modifier-part triples the majority of participants would rate as acceptable.", "labels": [], "entities": []}, {"text": "It allows us to investigate two topics: (i) the comparison of what people produce and what they perceive as being a prominent modifier fora concept-part pair (our algorithm might actually provide good candidates which were just not produced, as we just said) and (ii) a re-evaluation of the cosine-based re-ranking method (it could be in fact better than we thought because we only evaluated what was produced, but did not have a definite plausibility rating of the candidates missing in the norms).", "labels": [], "entities": []}, {"text": "The tested set contained the triples yielded by our two best performing methods (productwise combination and cosine-based re-ranking), which were applied to the German feature norms (692 triples, comprising 41 concepts and 71 parts).", "labels": [], "entities": []}, {"text": "From this set, a set of triples was chosen randomly for each of the 46 participants (recruited by e-mail among acquaintances of the first author).", "labels": [], "entities": []}, {"text": "The triples were presented to participants embedded into a natural-sounding sentence of the form \"The [part] of a is\".", "labels": [], "entities": []}, {"text": "Each participant rated 333 sentences, presented on separate lines of a text file (this set of sentences presented comprised additional triples which were intended for other purposes -for the current evaluation, we used a subset of 110 of these from each participant, on the average).", "labels": [], "entities": []}, {"text": "Participants were instructed to read the sentences as general statements about a concept's part and mark them by typing a letter (\"w\" for wonderful and \"d\" for dubious -to facilitate one-handed typing and easy memorisation) at the beginning of the line, if they thought it plausible/unlikely that someone used the sentence to explain an aspect of the relevant part.", "labels": [], "entities": []}, {"text": "In total, 5,525 judgements were collected; each sentence in the set was judged on the average by 8 persons.", "labels": [], "entities": []}, {"text": "The performance evaluation is based on the acceptance rate of the participants: Modifiers accepted by at least 75% of the raters are considered plausible.", "labels": [], "entities": []}, {"text": "shows the recall-precision graph for the methods tested on the concept-part pairs from the German norms.", "labels": [], "entities": [{"text": "recall-precision", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9981241822242737}, {"text": "German norms", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.886938601732254}]}, {"text": "From the 692 triples judged, around 13% were accepted by the majority of speakers.", "labels": [], "entities": []}, {"text": "The precision rate is comparable with the evaluation on the basis of the modifiers produced by participants (highest recall is 1, of course, because all modifiers to be judged were exclusively from the data set selected by our methods).", "labels": [], "entities": [{"text": "precision rate", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9857761263847351}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9959595799446106}]}, {"text": "Again, the performance of the cosine-based reranking method is similar to the performance of the productwise-combination method.", "labels": [], "entities": []}, {"text": "For a more exact evaluation of the difference between these two, a last test was conducted: Instead of measuring the performance in the form of counts of modifiers that were accepted by the majority of participants, we used the acceptance rates of all modifiers: The acceptance rates of all judged triples were summed up if they contained the same concept-part pair.", "labels": [], "entities": []}, {"text": "This means that each concept-part pair received a score reflecting the overall acceptance of the set of modifiers for that pair (e. g., for bear: fur, all acceptance rates for bear: brown fur, bear: soft fur, . .", "labels": [], "entities": []}, {"text": ". were summed up).", "labels": [], "entities": []}, {"text": "Then, the score of each concept-part pair in the productwise-combined list was compared against the score of the same pair for the cosine-based re-ranking method, using a pairwise t-test (this procedure is sound because the modifiers per pair are the same for the two methods).", "labels": [], "entities": []}, {"text": "The test showed a significant difference (p = 0.008), but in favour of the productwise-combination method (score means were slightly higher).", "labels": [], "entities": []}, {"text": "That is, cosinebased re-ranking in the current form brings no advantage over the simpler productwise combination of the frequency lists.", "labels": [], "entities": []}, {"text": "Finally, turning to the qualitative comparison of production and perception, there was a relatively small overlap of triples (46) contrasting with modifiers only produced but not accepted (53), and modifiers accepted but not produced (42).", "labels": [], "entities": []}, {"text": "Intuitively, we would have expected that what was produced will be also accepted by the majority of people.", "labels": [], "entities": []}, {"text": "Possibly, some participants in the judgement experiment found a few of the triples produced questionable (goose: long beak) -such triples were in our gold standard because we deliberately did not want to exclude composite parts even if produced by only one speaker -whereas participants producing parts forgiven concepts probably just did not think of specific parts or modifiers (e. g., aeroplane: small windows and bear: dense fur).", "labels": [], "entities": []}, {"text": "The important fact regarding this difference is, however, that our method captures both kinds of modifiers.", "labels": [], "entities": []}], "tableCaptions": []}