{"title": [{"text": "Non-humanlike Spoken Dialogue: A Design Perspective", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a non-humanlike spoken dialogue design, which consists of two elements: non-humanlike turn-taking and non-humanlike acknowledgment.", "labels": [], "entities": []}, {"text": "Two experimental studies are reported in this paper.", "labels": [], "entities": []}, {"text": "The first study shows that the proposed non-humanlike spoken dialogue design is effective for reducing speech collisions.", "labels": [], "entities": [{"text": "speech collisions", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7014570087194443}]}, {"text": "It also presents pieces of evidence that show quick humanlike turn-taking is less important in spoken dialogue system design.", "labels": [], "entities": []}, {"text": "The second study supports a hypothesis found in the first study that user preference on response timing varies depending on interaction patterns.", "labels": [], "entities": []}, {"text": "Upon receiving these results, this paper suggests a practical design guideline for spoken dialogue systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speech and language are owned by humans.", "labels": [], "entities": []}, {"text": "Therefore, spoken dialogue researchers tend to pursue a humanlike spoken dialogue.", "labels": [], "entities": []}, {"text": "Only a few researchers positively investigate restricted (i.e., non-humanlike) spoken dialogue design such as.", "labels": [], "entities": []}, {"text": "Humanlikeness is a very important concept and sometimes it is really useful to design machines / interactions.", "labels": [], "entities": []}, {"text": "Machines are, however, not humans.", "labels": [], "entities": []}, {"text": "We believe humanlikenss cannot be the dominant factor, or gold-standard, for designing spoken dialogues.", "labels": [], "entities": []}, {"text": "Pursuing humanlikeness has at least five critical problems.", "labels": [], "entities": []}, {"text": "(1) Cost: in general, humanlikeness demands powerful and highly functional hardware and software, and highly integrated systems requiring top-grade experts both for development and maintenance.", "labels": [], "entities": []}, {"text": "All of them lead to cost overrun.", "labels": [], "entities": []}, {"text": "(2) Performance: sometimes, humanlikeness forces performance to be compromised.", "labels": [], "entities": []}, {"text": "For example, achieving quick turn-taking which humans do in daily conversations forces automatic speech recognizers, reasoners, etc.", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7268263399600983}]}, {"text": "to be compromised to enable severe real-time processing.", "labels": [], "entities": []}, {"text": "(3) Applicability: differences in cultures, genders, generations, situations limit the applicability of a humanlike design because it often accompanies a rigid character.", "labels": [], "entities": [{"text": "Applicability", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9894120097160339}]}, {"text": "For example, succeeded in improving users' impression for slow responses from a robot by using a filler but obviously use of such a filler is limited by social appropriateness.", "labels": [], "entities": []}, {"text": "(4) Expectancy: humanlike systems induce too much expectancy of users that they are as intelligent as humans.", "labels": [], "entities": [{"text": "Expectancy", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.971861720085144}]}, {"text": "It will result in disappointments (  and may reduce users' willingness to use systems.", "labels": [], "entities": []}, {"text": "Keeping high willingness is quite important from the viewpoint of both research (for collecting data from users to improve systems) and business (for continuously selling systems with limited functionality).", "labels": [], "entities": []}, {"text": "(5) Risk: Although it is not verified, what is called the uncanny valley ( probably exists.", "labels": [], "entities": [{"text": "Risk", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9972688555717468}]}, {"text": "It is commonly observed that people hate imperfect humanlike systems.", "labels": [], "entities": []}, {"text": "We try to avoid these problems rather than overcome them.", "labels": [], "entities": []}, {"text": "Our position is positively exploring non-humanlike spoken dialogue design.", "labels": [], "entities": [{"text": "non-humanlike spoken dialogue design", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.7418394088745117}]}, {"text": "This pa-per focuses on its two elements, i.e., decelerated dialogues as non-humanlike turn-taking and an artificial subtle expression (ASE) as non-humanlike acknowledgment 1 , and presents two experimental studies regarding these two elements.", "labels": [], "entities": []}, {"text": "ASEs, defined by the authors in ( , are simple expressions suitable for artifacts, which intuitively notify users about artifacts' internal states while avoiding the above five problems.", "labels": [], "entities": []}, {"text": "In Section 2, the first study, which was previously reported in ( , is summarized and shows that the proposed nonhumanlike spoken dialogue design is effective for reducing speech collisions.", "labels": [], "entities": [{"text": "reducing speech collisions", "start_pos": 163, "end_pos": 189, "type": "TASK", "confidence": 0.6665225227673849}]}, {"text": "It also presents pieces of evidence that shows quick humanlike turntaking is less important in designing spoken dialogue systems (SDSs).", "labels": [], "entities": [{"text": "spoken dialogue systems (SDSs)", "start_pos": 105, "end_pos": 135, "type": "TASK", "confidence": 0.6664217710494995}]}, {"text": "In Section 3, the second study, which is newly reported in this paper, shows a tendency supporting a hypothesis found in the first study that user preference on response timing varies depending on interaction patterns.", "labels": [], "entities": []}, {"text": "Upon receiving the results of the two experiments, a design guideline for SDSs is suggested in Section 4.", "labels": [], "entities": [{"text": "SDSs", "start_pos": 74, "end_pos": 78, "type": "TASK", "confidence": 0.9656375050544739}]}], "datasetContent": [{"text": "To validate the hypothesis described above, we conducted a Wizard-of-Oz experiment using fixed scenarios.", "labels": [], "entities": []}, {"text": "Participants engaged in short interactions with an interface robot and evaluated response timing of the robot.", "labels": [], "entities": []}, {"text": "Three experimental factors were interaction patterns, response timing (wait interval), and existence of a blinking light.", "labels": [], "entities": [{"text": "response timing (wait interval)", "start_pos": 54, "end_pos": 85, "type": "METRIC", "confidence": 0.6270272334416708}]}, {"text": "Interaction patterns Five interaction patterns were setup to seethe differences between situations.", "labels": [], "entities": []}, {"text": "Each pattern consisted of three utterances.", "labels": [], "entities": []}, {"text": "The first utterance was from the system.", "labels": [], "entities": []}, {"text": "Upon receiving the utterance, a participant as a user of the system replied with the second utterance.", "labels": [], "entities": []}, {"text": "Then the system responded after the given wait interval (1 sec or 4 sec) with the third utterance.", "labels": [], "entities": []}, {"text": "Participants evaluated this interval between the second utterance and the third utterance in a measure of comfortableness.", "labels": [], "entities": []}, {"text": "The patterns with scenarios are shown in 3.", "labels": [], "entities": []}, {"text": "They will be referred to by abbreviations (PGG, QYQ, QNQ, PSQ, PLQ) in what follows.", "labels": [], "entities": []}, {"text": "Note that the scenarios are originally in Japanese.", "labels": [], "entities": []}, {"text": "Here, RequestS and RequestL mean a short request and along request, respectively.", "labels": [], "entities": []}, {"text": "YNQuestion and WhQuestion mean a yes-no-question and a wh-question, respectively.", "labels": [], "entities": [{"text": "YNQuestion", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.7325301766395569}, {"text": "WhQuestion", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.6527794599533081}]}, {"text": "According to the hypothesis, we can predict that the reported comfortableness for the longer wait interval (4 sec) are worse for short and formulaic cases such as PGG and QYQ than for the long request case (i.e., PLQ).", "labels": [], "entities": []}, {"text": "In addition, we can predict that the reported comfortableness for longer intervals improves for PLQ if the robot's light blinks, while that does not improve for PGG and QYQ.", "labels": [], "entities": []}, {"text": "System We used the same interface robot and the LCD monitor as study 1.", "labels": [], "entities": []}, {"text": "The experiment in this study, however, was conducted using a WOZ system.", "labels": [], "entities": []}, {"text": "First the WOZ system presents an instruction to the participant on the LCD monitor, which reveals the robot's first utterance of the given scenario (e.g., \"Welcome to our Hotel. May I help you?\") and indicates the participant's second utterance (e.g., \"Hello.\").", "labels": [], "entities": []}, {"text": "Two seconds after the participant clicks the OK button on the monitor with a computer mouse, the system makes the robot utter the first utterance.", "labels": [], "entities": []}, {"text": "Then, the participant replies, and the operator of the system end-points the end of participant's speech by clicking a button shown in another monitor for the operator in the room next to the participant's room.", "labels": [], "entities": []}, {"text": "After the end-pointing, the system waits for the wait interval (one second or four seconds) and makes the robot utter the third utterance of the scenario.", "labels": [], "entities": []}, {"text": "One second after, the system asks the participant to evaluate the comfortableness of the response timing of the robot's third utterance on a scale from 1 to 7 (1:very uncomfortable, 4:neutral, 7:very comfortable) on the LCD monitor.", "labels": [], "entities": []}, {"text": "Conditions and participants Forty participants (mean age 28.8, 20 males and 20 females) engaged in the experiment.", "labels": [], "entities": []}, {"text": "No participant had engaged in study 1.", "labels": [], "entities": []}, {"text": "They were randomly assigned to one of two groups (gender was balanced).", "labels": [], "entities": []}, {"text": "The groups correspond to one of two levels of the experimental factor of the existence of a blinking light.", "labels": [], "entities": []}, {"text": "For one group, the robot blinked its LED when it was waiting.", "labels": [], "entities": []}, {"text": "For the other group, the robot did not blink the LED.", "labels": [], "entities": []}, {"text": "We refer to the former group (condition) as BL (Blinking Light, n=20) and the later as NL (No Light, n=20).", "labels": [], "entities": [{"text": "BL", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.986838161945343}, {"text": "NL", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.9403061866760254}]}, {"text": "In summary, this experiment is within-subjects design with regard to interaction patterns and response timing and is between-subjects design with regard to the blinking light.", "labels": [], "entities": []}, {"text": "Method The experiment was conducted in a room for one participant atone time.", "labels": [], "entities": []}, {"text": "Participants entered the room and sat on a chair in front of a desk as shown in, but they did not wear headphones this time.", "labels": [], "entities": []}, {"text": "The experimenter gave the participants instructions so as to engage in short dialogues with the robot in front of them.", "labels": [], "entities": []}, {"text": "They engaged in each of five scenarios shown in six times (three times with a 1 sec wait interval and three with 4 sec), resulting in 30 dialogues (5 \u00d7 3 \u00d7 2 = 30).", "labels": [], "entities": []}, {"text": "The order of scenarios and intervals was randomized.", "labels": [], "entities": []}, {"text": "The existence and meaning of the blinking light expression was not explained to them.", "labels": [], "entities": []}, {"text": "They were not told that the system was operated by a human operator, either.", "labels": [], "entities": []}, {"text": "After giving the instructions, the experimenter left the participants, and they practiced onetime.", "labels": [], "entities": []}, {"text": "This practice used a PromptRequestM-WhQuestion 3 type scenario with await interval of two seconds.", "labels": [], "entities": []}, {"text": "Then, thirty dialogues were performed.", "labels": [], "entities": []}, {"text": "Short breaks were inserted after ten dialogues.", "labels": [], "entities": []}, {"text": "Each dialogue proceeded as explained above.", "labels": [], "entities": []}], "tableCaptions": []}