{"title": [{"text": "Emotion Analysis Using Latent Affective Folding and Embedding", "labels": [], "entities": [{"text": "Emotion Analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9216133654117584}]}], "abstractContent": [{"text": "Though data-driven in nature, emotion analysis based on latent semantic analysis still relies on some measure of expert knowledge in order to isolate the emotional keywords or key-sets necessary to the construction of affective categories.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.7643076777458191}]}, {"text": "This makes it vulnerable to any discrepancy between the ensuing taxonomy of affective states and the underlying domain of discourse.", "labels": [], "entities": []}, {"text": "This paper proposes a more general strategy which leverages two distincts semantic levels, one that encapsulates the foundations of the domain considered, and one that specifically accounts for the overall affective fabric of the language.", "labels": [], "entities": []}, {"text": "Exposing the emergent relationship between these two levels advantageously informs the emotion classification process.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.7032652795314789}]}, {"text": "Empirical evidence suggests that this is a promising solution for automatic emotion detection in text.", "labels": [], "entities": [{"text": "automatic emotion detection in text", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.7198863506317139}]}], "introductionContent": [{"text": "The automatic detection of emotions in text is a necessary pre-processing step in many different fields touching on affective computing, such as natural language interfaces (), e-learning environments (), educational or entertainment games, opinion mining and sentiment analysis, humor recognition (), and security informatics.", "labels": [], "entities": [{"text": "automatic detection of emotions in text", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.78682541847229}, {"text": "opinion mining and sentiment analysis", "start_pos": 241, "end_pos": 278, "type": "TASK", "confidence": 0.8253316640853882}, {"text": "humor recognition", "start_pos": 280, "end_pos": 297, "type": "TASK", "confidence": 0.8580955862998962}]}, {"text": "In the latter case, for example, it can be used for monitoring levels of hateful or violent rhetoric (perhaps in multilingual settings).", "labels": [], "entities": [{"text": "monitoring levels of hateful or violent rhetoric", "start_pos": 52, "end_pos": 100, "type": "TASK", "confidence": 0.5628442806856973}]}, {"text": "More generally, emotion detection is of great interest in human-computer interaction: if a system determines that a user is upset or annoyed, for instance, it could switch to a different mode of interaction ().", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7822427451610565}]}, {"text": "And of course, it plays a critical role in the generation of expressive synthetic speech).", "labels": [], "entities": []}, {"text": "Emphasis has traditionally been placed on the set of six \"universal\" emotions: ANGER, DISGUST, FEAR, JOY, SADNESS, and SURPRISE;).", "labels": [], "entities": [{"text": "ANGER", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9945676326751709}, {"text": "DISGUST", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9870447516441345}, {"text": "FEAR", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9943329095840454}, {"text": "JOY", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9474074244499207}, {"text": "SADNESS", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.9912210702896118}]}, {"text": "Emotion analysis is typically carried out using a simplified description of emotional states in a low-dimensional space, which normally comprises dimensions such as valence (positive/negative evalution), activation (stimulation of activity), and/or control (dominant/submissive power).", "labels": [], "entities": [{"text": "Emotion analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.944522500038147}]}, {"text": "Classification proceeds based on an underlying emotional knowledge base, which strives to provide adequate distinctions between different emotions.", "labels": [], "entities": []}, {"text": "This affective information can either be built entirely upon manually selected vocabulary as in, or derived automatically from data based on expert knowledge of the most relevant features that can be extracted from the input text ().", "labels": [], "entities": []}, {"text": "In both cases, the resulting system tends to rely, for the most part, on a few thousand annotated \"emotional keywords,\" the presence of which triggers the associated emotional label(s).", "labels": [], "entities": []}, {"text": "The drawback of such confined lexical affinity is that the analysis tends to be hampered by the bias inherent in the underlying taxonomy of emotional states.", "labels": [], "entities": []}, {"text": "Because this taxonomy only supports simplified relationships between affective words and emo-1 tional categories, it often fails to meaningfully generalize beyond the relatively few core terms explicitly considered in its construction.", "labels": [], "entities": []}, {"text": "This has sparked interest in data-driven approaches based on latent semantic analysis (LSA), a paradigm originally developed for information retrieval).", "labels": [], "entities": [{"text": "latent semantic analysis (LSA)", "start_pos": 61, "end_pos": 91, "type": "TASK", "confidence": 0.7574279308319092}, {"text": "information retrieval", "start_pos": 129, "end_pos": 150, "type": "TASK", "confidence": 0.744718998670578}]}, {"text": "Upon suitable training using a large corpus of texts, LSA allows a similarity score to be computed between generic terms and affective categories ( ).", "labels": [], "entities": [{"text": "similarity score", "start_pos": 67, "end_pos": 83, "type": "METRIC", "confidence": 0.9618667364120483}]}, {"text": "This way, every word can automatically be assigned some fractional affective influence.", "labels": [], "entities": []}, {"text": "Still, the affective categories themselves are usually specified with the help of a reference lexical database like WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 116, "end_pos": 123, "type": "DATASET", "confidence": 0.9783782362937927}]}, {"text": "The purpose of this paper is to more broadly leverage the principle of latent semantics in emotion analysis.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.809173196554184}]}, {"text": "We cast the problem as a general application of latent semantic mapping (LSM), an extrapolation of LSA for modeling global relationships implicit in large volumes of data (.", "labels": [], "entities": [{"text": "latent semantic mapping (LSM)", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.7577126423517863}]}, {"text": "More specifically, we use the LSM framework to describe two distinct semantic levels: one that encapsulates the foundations of the domain considered (e.g., broadcast news, email messages, SMS conversations, etc.), and one that specifically accounts for the overall affective fabric of the language.", "labels": [], "entities": []}, {"text": "Then, we leverage these two descriptions to appropriately relate domain and affective levels, and thereby inform the emotion classification process.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.6956417411565781}]}, {"text": "This de facto bypasses the need for any explicit external knowledge.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section provides some motivation for, and gives an overview of, the proposed latent affective framework.", "labels": [], "entities": []}, {"text": "In Sections 3 and 4, we describe the two main alternatives considered, latent folding and latent embedding.", "labels": [], "entities": [{"text": "latent folding", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.7838826179504395}]}, {"text": "In Section 5, we discuss the mechanics of emotion detection based on such latent affective processing.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7872128486633301}]}, {"text": "Finally, Section 6 reports the outcome of experimental evaluations conducted on the \"Affective Text\" portion of the SemEval-2007 corpus).", "labels": [], "entities": [{"text": "Affective Text\" portion of the SemEval-2007 corpus", "start_pos": 85, "end_pos": 135, "type": "DATASET", "confidence": 0.7996369116008282}]}], "datasetContent": [{"text": "In order to evaluate the latent affective framework described above, we used the data set that was developed for the SemEval 2007 task on \"Affective Text\".", "labels": [], "entities": [{"text": "SemEval 2007 task", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.8519081274668375}]}, {"text": "This task was focused on the emotion classification of news headlines.", "labels": [], "entities": [{"text": "emotion classification of news headlines", "start_pos": 29, "end_pos": 69, "type": "TASK", "confidence": 0.8578226923942566}]}, {"text": "Headlines typically consist of a few words and are often written by creative people with the intention to \"provoke\" emotions, and consequently attract the readers' attention.", "labels": [], "entities": []}, {"text": "These characteristics make this kind of data particularly suitable for use in an automatic emotion recognition setting, as the affective/emotional features (if present) are guaranteed to appear in these short sentences.", "labels": [], "entities": [{"text": "automatic emotion recognition", "start_pos": 81, "end_pos": 110, "type": "TASK", "confidence": 0.6782095531622568}]}, {"text": "The test data accordingly consisted of 1,250 short news headlines 2 extracted from news web sites (such as Google news, CNN) and/or newspapers, and annotated along L = 6 emotions (ANGER, DISGUST, FEAR, JOY, SADNESS, and SURPRISE) by different evaluators.", "labels": [], "entities": [{"text": "ANGER", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9878777265548706}, {"text": "DISGUST", "start_pos": 187, "end_pos": 194, "type": "METRIC", "confidence": 0.9247252345085144}, {"text": "FEAR", "start_pos": 196, "end_pos": 200, "type": "METRIC", "confidence": 0.986935555934906}, {"text": "JOY", "start_pos": 202, "end_pos": 205, "type": "METRIC", "confidence": 0.8356772661209106}, {"text": "SADNESS", "start_pos": 207, "end_pos": 214, "type": "METRIC", "confidence": 0.9451419115066528}, {"text": "SURPRISE", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.9236308932304382}]}, {"text": "In all three cases, the large corpus used for LSA processing was the Wall Street Journal text collection (, comprising about 86,000 articles.", "labels": [], "entities": [{"text": "LSA processing", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.9851392805576324}, {"text": "Wall Street Journal text collection", "start_pos": 69, "end_pos": 104, "type": "DATASET", "confidence": 0.976009476184845}]}, {"text": "For the latent affective framework, we needed to select two separate training corpora.", "labels": [], "entities": []}, {"text": "For the \"domain\" corpus, we selected a collection of about N 1 = 8, 500 relatively short English sentences (with a vocabulary of roughly M 1 = 12, 000 words) originally compiled for the purpose of a building a concatenative text-to-speech voice.", "labels": [], "entities": []}, {"text": "Though not completely congruent with news headlines, we felt that the type and range of topics covered was close enough to serve as a good proxy for the domain.", "labels": [], "entities": []}, {"text": "For the \"affective\" corpus, we relied on about N 2 = 5, 000 mood-annotated blog entries from LiveJournal.com, with a filtered 3 vocabulary of about M 2 = 20, 000 words.", "labels": [], "entities": []}, {"text": "The indication of mood being explicitly specified when posting on LiveJournal, without particular coercion from the interface, moodannotated posts are likely to reflect the true mood of the blog authors (.", "labels": [], "entities": []}, {"text": "The moods were then mapped to the L = 6 emotions considered in the classification.", "labels": [], "entities": []}, {"text": "Next, we formed the domain and affective matrices W 1 and W 2 and processed them as in (2) and (5).", "labels": [], "entities": []}, {"text": "We used R 1 = 100 for the dimension of the domain space L 1 and R 2 = L = 6 for the dimension of the affective space L 2 . We then compared latent affective folding and embedding to the above systems.", "labels": [], "entities": [{"text": "latent affective folding", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.589284082253774}]}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "Consistent with the observations in, word accumulation secures the highest precision at the cost of the lowest recall, while LSA-based systems achieve high recall but significantly lower precision.", "labels": [], "entities": [{"text": "word accumulation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7653158605098724}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9987579584121704}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9986512064933777}, {"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.9982377290725708}, {"text": "precision", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.9947810769081116}]}, {"text": "Encouragingly, the Fmeasure obtained with both latent affective mapping techniques is substantially higher than with all four baseline approaches.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9985135197639465}]}, {"text": "Of the two techniques, latent embedding performs better, presumably because the embedded affective anchors are less sensitive than the folded affective anchors to the distribution of words within the affective corpus.", "labels": [], "entities": []}, {"text": "Both techniques seem to exhibit an improved ability to resolve distinctions between emotional connotations.", "labels": [], "entities": [{"text": "resolve distinctions between emotional connotations", "start_pos": 55, "end_pos": 106, "type": "TASK", "confidence": 0.9090014815330505}]}, {"text": "Empirical evidence gathered on the \"Affective Text\" portion of the SemEval-2007 corpus shows the effectiveness of the proposed strategy.", "labels": [], "entities": [{"text": "Affective Text\" portion of the SemEval-2007 corpus", "start_pos": 36, "end_pos": 86, "type": "DATASET", "confidence": 0.833838202059269}]}, {"text": "Classification performance with latent affective embedding is slightly better than with latent affective folding, presumably because of its ability to more richly describe the affective space.", "labels": [], "entities": []}, {"text": "Both techniques outperform standard LSA-based approaches, as well as affectively weighted word accumulation.", "labels": [], "entities": [{"text": "affectively weighted word accumulation", "start_pos": 69, "end_pos": 107, "type": "TASK", "confidence": 0.6025099977850914}]}, {"text": "This bodes well for the general deployability of latent affective processing across a wide range of applications.", "labels": [], "entities": []}, {"text": "Future efforts will concentrate on characterizing the influence of the parameters R 1 and R 2 on the vector spaces L 1 and L 2 , and the corresponding trade-off between modeling power and generalization properties.", "labels": [], "entities": []}, {"text": "It is also of interest to investigate 8 how incorporating higher level units (such as common lexical compounds) into the LSM procedure might further increase performance.", "labels": [], "entities": [{"text": "LSM", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9211502075195312}]}], "tableCaptions": []}