{"title": [], "abstractContent": [{"text": "As the web evolves, increasing quantities of structured information is embedded in web pages in disparate formats.", "labels": [], "entities": []}, {"text": "For example, a digital camera's description may include its price and megapixels whereas a professor's description may include her name, university , and research interests.", "labels": [], "entities": []}, {"text": "Both types of pages may include additional ambiguous information.", "labels": [], "entities": []}, {"text": "General search engines (GSEs) do not support queries over these types of data because they ignore the web document semantics.", "labels": [], "entities": []}, {"text": "Conversely, describing requisite semantics through structured queries into databases populated by information extraction (IE) techniques are expensive and not easily adaptable to new domains.", "labels": [], "entities": [{"text": "describing requisite semantics through structured queries into databases populated by information extraction (IE)", "start_pos": 12, "end_pos": 125, "type": "TASK", "confidence": 0.7247861206531525}]}, {"text": "This paper describes a methodology for rapidly developing search engines capable of answering struc-tured queries over unstructured corpora by utilizing machine learning to avoid explicit IE.", "labels": [], "entities": []}, {"text": "We empirically show that with minimum additional human effort, our system outperforms a GSE with respect to structured queries with clear object semantics.", "labels": [], "entities": []}], "introductionContent": [{"text": "General search engines (GSEs) are sufficient for fulfilling the information needs of most queries.", "labels": [], "entities": []}, {"text": "However, they are often inadequate for retrieving web pages that concisely describe real world objects as these queries require analysis of both unstructured text and structured data contained in web pages.", "labels": [], "entities": []}, {"text": "For example, digital cameras with specific brand, megapixel, zoom, and price attributes might be found on an online shopping website, or a professor with her name, university, department, and research interest attributes might be found on her homepage.", "labels": [], "entities": []}, {"text": "Correspondingly, as the web continues to evolve from a general text corpus into a heterogeneous collection of documents, targeted retrieval strategies must be developed for satisfying these more precise information needs.", "labels": [], "entities": []}, {"text": "We accomplish this by using structured queries to capture the intended semantics of a user query and learning domain specific ranking functions to represent the hidden semantics of object classes contained in web pages.", "labels": [], "entities": []}, {"text": "It is not uncommon fora user to want to pose an object query on the web.", "labels": [], "entities": []}, {"text": "For example, an online shopper might be looking for shopping pages that sell canon digital cameras with 5 megapixels costing no more than $300.", "labels": [], "entities": []}, {"text": "A graduate student might be looking for homepages of computer science professors who work in the information retrieval area.", "labels": [], "entities": [{"text": "information retrieval area", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.833252489566803}]}, {"text": "Such users expect to get a list web pages containing objects they are looking for, or object pages, which we will define more precisely in later sections.", "labels": [], "entities": []}, {"text": "GSEs rarely return satisfactory results when the user has a structured query in mind for two primary reasons.", "labels": [], "entities": [{"text": "GSEs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.7666257619857788}]}, {"text": "Firstly, GSEs only handle keyword queries whereas structured queries frequently involve data field semantics (e.g. numerical constraints) and exhibit field interdependencies.", "labels": [], "entities": []}, {"text": "Secondly, since GSEs are domain-agnostic, they will generally rank camera pages utilizing the same functions as a professor's homepage, ignoring much of the structured information specific to particular domains.", "labels": [], "entities": [{"text": "GSEs", "start_pos": 16, "end_pos": 20, "type": "TASK", "confidence": 0.8945634961128235}]}, {"text": "Conversely, vertical search engines (e.g. DBLife, cazoodle.com, Rexa.info, etc.) approach this prob-lem from the information extraction (IE) perspective.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.8303585410118103}]}, {"text": "Instead of searching an inverted index directly, they first extract data records from text).", "labels": [], "entities": []}, {"text": "IE solutions, even with large scale techniques, do not scale to the entire web and cost significantly more than GSEs.", "labels": [], "entities": [{"text": "IE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9731906056404114}]}, {"text": "Secondly, creating domainspecific models or wrappers require labeling training examples and human expertise for each individual site.", "labels": [], "entities": []}, {"text": "Thirdly, pre-extracting information lacks flexibility; decisions made during IE are irrevocable, and at query time, users may find additional value in partial or noisy records that were discarded by the IE system.", "labels": [], "entities": [{"text": "IE", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.933181881904602}]}, {"text": "These issues motivate our novel approach for designing a GSE capable of answering complex structured queries, which we refer to as Object Search.", "labels": [], "entities": []}, {"text": "At a high level, we search web pages containing structured information directly over their feature index, similarly to GSEs, adding expressivity by reformulating the structured query such that it can be executed on a traditional inverted index.", "labels": [], "entities": []}, {"text": "Thus, we avoid the expense incurred by IE approaches when supporting new object domains.", "labels": [], "entities": []}, {"text": "From a technical perspective, this work describes a principled approach to customizing GSEs to answer structured queries from any domain by proposing a compositional ranking model for ranking web pages with regards to structured queries and presenting an interactive learning approach that eases the process of training fora new domain.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present an experiment that compares Object Search with keyword search engines.", "labels": [], "entities": [{"text": "Object Search", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.7863428592681885}]}, {"text": "Since we are the first to tackle this problem of answering structured query on the web, there is no known dataset available for our experiment.", "labels": [], "entities": [{"text": "answering structured query on the web", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.8739396135012308}]}, {"text": "We collected the data ourselves using various sources from the web.", "labels": [], "entities": []}, {"text": "Then we labeled search results from different object queries using the same annotation procedure described in Section 5.", "labels": [], "entities": []}, {"text": "We collected URLs from two main sources: the open directory (DMOZ) and existing search engines (SE).", "labels": [], "entities": []}, {"text": "For DMOZ, we included URLs from relevant categories.", "labels": [], "entities": []}, {"text": "For SE, we manually entered queries with keywords related to professors' homepages, laptops, and digital cameras, and included all returned URLs.", "labels": [], "entities": [{"text": "SE", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.7915814518928528}]}, {"text": "Having collected the URLs, we crawled their content and indexed them.", "labels": [], "entities": []}, {"text": "summarizes web page data we have collected.", "labels": [], "entities": []}, {"text": "We split the data randomly into two parts, one for training and one for testing, and created a single inverted index for both of them.", "labels": [], "entities": []}, {"text": "The developer can only seethe training documents to select features and train ranking functions.", "labels": [], "entities": []}, {"text": "At testing time, we randomly generate object queries, and evaluate on the testing set.", "labels": [], "entities": []}, {"text": "Since Google's results come not from our corpus but the whole web, it might not be fair to compare against our small corpus.", "labels": [], "entities": []}, {"text": "To accommodate this, we also added Google's results into our testing corpus.", "labels": [], "entities": []}, {"text": "We believe that most 'difficult' web pages that hurt Google's performance would have been in-: Sample keyword reformulation for Google cluded in the top Google result.", "labels": [], "entities": [{"text": "Sample keyword reformulation", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.8673008481661478}]}, {"text": "Thus, they are also available to test ours.", "labels": [], "entities": []}, {"text": "In the future, we plan to implement a local IR engine to compare against ours and conduct a larger scale experiment to compare to Google.", "labels": [], "entities": []}, {"text": "We evaluated the experiment with two different domains: professor and laptop.", "labels": [], "entities": []}, {"text": "We consider homepages and online shopping pages as object pages for the professor and laptop domains respectively.", "labels": [], "entities": []}, {"text": "For each domain, we generated 5 random object queries with different field configurations.", "labels": [], "entities": []}, {"text": "Since Google does not understand structured queries, we reformulated each structured query into a simple keyword query.", "labels": [], "entities": []}, {"text": "We do so by pairing the query field with several keywords.", "labels": [], "entities": []}, {"text": "For example, a query field a brand \u2208 {lenovo} can be reformulated as \"lenovo laptop\".", "labels": [], "entities": []}, {"text": "We tried different combinations of keywords as shown in table 2.", "labels": [], "entities": []}, {"text": "To deal with numbers, we use Google's advanced search feature that supports numeric range queries 1 . For example, a price constraint a price \u2208 [100, 200] might be reformulated as \"price $100..200\".", "labels": [], "entities": []}, {"text": "Since it is too expensive to find the best keyword formulations for every query, we picked the combination that gives the best result for the first Google result page (Top 10 URLs).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of web pages (in thousands) collected  for experiment", "labels": [], "entities": []}, {"text": " Table 3: Average precision for 5 random queries. The  number of positive documents are in brackets", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9650747179985046}]}]}