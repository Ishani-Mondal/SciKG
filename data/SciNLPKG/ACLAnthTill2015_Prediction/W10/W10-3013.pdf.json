{"title": [{"text": "Hedge Detection and Scope Finding by Sequence Labeling with Normalized Feature Selection *", "labels": [], "entities": [{"text": "Hedge Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8448770344257355}, {"text": "Scope Finding", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9631953537464142}, {"text": "Sequence Labeling", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8340524137020111}]}], "abstractContent": [{"text": "This paper presents a system which adopts a standard sequence labeling technique for hedge detection and scope finding.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.8835615515708923}, {"text": "scope finding", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.9143892228603363}]}, {"text": "For the first task, hedge detection, we formulate it as a hedge labeling problem, while for the second task, we use a two-step labeling strategy, one for hedge cue labeling and the other for scope finding.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.90522900223732}, {"text": "hedge cue labeling", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.619076540072759}, {"text": "scope finding", "start_pos": 191, "end_pos": 204, "type": "TASK", "confidence": 0.8205550909042358}]}, {"text": "In particular , various kinds of syntactic features are systemically exploited and effectively integrated using a large-scale normalized feature selection method.", "labels": [], "entities": []}, {"text": "Evaluation on the CoNLL-2010 shared task shows that our system achieves stable and competitive results for all the closed tasks.", "labels": [], "entities": [{"text": "CoNLL-2010 shared task", "start_pos": 18, "end_pos": 40, "type": "DATASET", "confidence": 0.7555088798205057}]}, {"text": "Furthermore , post-deadline experiments show that the performance can be much further improved using a sufficient feature selection .", "labels": [], "entities": []}], "introductionContent": [{"text": "Hedges are linguistic devices representing speculative parts of articles.", "labels": [], "entities": []}, {"text": "Previous works such as) present research on hedge mainly as a linguistic phenomenon.", "labels": [], "entities": [{"text": "hedge", "start_pos": 44, "end_pos": 49, "type": "TASK", "confidence": 0.9801065921783447}]}, {"text": "Meanwhile, detecting hedges and their scopes automatically are increasingly important tasks in natural language processing and information extraction, especially in biomedical community.", "labels": [], "entities": [{"text": "detecting hedges and their scopes automatically", "start_pos": 11, "end_pos": 58, "type": "TASK", "confidence": 0.8168062965075175}, {"text": "natural language processing", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.6398881077766418}, {"text": "information extraction", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.8116115927696228}]}, {"text": "The shared task of CoNLL-2010 described in aims at detecting hedges (task 1) and finding their scopes (task 2) for the literature * This work is partially supported by the National Natural Science Foundation of China (Grants 60903119, 60773090, 90820018 and 90920004), the National Basic Research Program of China, and the National High-Tech Research Program of.", "labels": [], "entities": [{"text": "National Basic Research Program", "start_pos": 273, "end_pos": 304, "type": "DATASET", "confidence": 0.887920156121254}]}, {"text": "\u2020 corresponding author from BioScope corpus (  and Wikipedia.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.9304105341434479}]}, {"text": "This paper describes a system adopting sequence labeling which performs competitive in the official evaluation, as well as further test.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.5679136216640472}]}, {"text": "In addition, a large-scale feature selection procedure is applied in training and development.", "labels": [], "entities": []}, {"text": "Considering that BioScope corpus is annotated by two independent linguists according to a formal guideline, while Wikipedia weasels are tagged by netizens who are diverse in background and various in evaluation criterion, it is needed to handle them separately.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.9081812798976898}]}, {"text": "Our system selects features for Wikipedia and BioScope corpus independently and evaluate them respectively, leading to fine performances for all of them.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.8567755818367004}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents the technical details of our system of hedge detection and scope finding.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.8586088418960571}, {"text": "scope finding", "start_pos": 85, "end_pos": 98, "type": "TASK", "confidence": 0.9181923866271973}]}, {"text": "Section 3 gives information of features.", "labels": [], "entities": []}, {"text": "Section 4 shows the evaluation results, including official results and further ones after official outputs collection.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "x.lemma + x1.pos + x\u22121.pos + x.pos + x1.lemma + x\u22121.lemma -x.pos + x.hedge + x.dp + x.dprel -x1.pos -x.pos + x1.pos + x\u22121.pos + x2.pos + x\u22122.pos -   on the in-domain data and evaluated our system on the in-domain and cross-domain evaluation set.", "labels": [], "entities": []}, {"text": "All the experiments are implemented and run by Maximum Entropy Markov Models).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of hedge amount", "labels": [], "entities": []}, {"text": " Table 9: Comparing results with the best", "labels": [], "entities": []}, {"text": " Table 10: Comparing improved outputs with the  best", "labels": [], "entities": []}]}