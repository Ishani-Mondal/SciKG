{"title": [{"text": "Chinese Word Segmentation based on Mixing Multiple Preprocessor and CRF", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6593540906906128}]}], "abstractContent": [{"text": "This paper describes the Chinese Word Segmenter for our participation in CIPS-SIGHAN-2010 bake-off task of Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese Word Segmenter", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6679640611012777}, {"text": "Chinese word segmentation", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.5425975422064463}]}, {"text": "We formalize the tasks as sequence tagging problems, and implemented them using conditional random fields (CRFs) model.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7430010735988617}]}, {"text": "The system contains two modules: multiple preprocessor and basic segmenter.", "labels": [], "entities": []}, {"text": "The basic segmenter is designed as a problem of character-based tagging, and using named entity recognition and chunk recognition based on boundary to preprocess.", "labels": [], "entities": [{"text": "character-based tagging", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.5738679766654968}, {"text": "named entity recognition", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.6755322217941284}, {"text": "chunk recognition", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.7965266108512878}]}], "introductionContent": [{"text": "Word is a logical semantic and syntactic unit in natural language.", "labels": [], "entities": []}, {"text": "Chinese word segmentation is very important for Chinese language processing, which aims to recognize the implicit word boundaries in Chinese text.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5738647182782491}, {"text": "Chinese language processing", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.6686772505442301}]}, {"text": "It is the foundation of most Chinese NLP tasks.", "labels": [], "entities": [{"text": "Chinese NLP tasks", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.49573110540707904}]}, {"text": "In past decades, great success has been achieved in Chinese word segmentation).", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.664836972951889}]}, {"text": "But there still exist many problems, such as cross-domain performance of Chinese word segmentation algorithms.", "labels": [], "entities": [{"text": "Chinese word segmentation algorithms", "start_pos": 73, "end_pos": 109, "type": "TASK", "confidence": 0.6666954010725021}]}, {"text": "As the development of the internet, more and more new word has been appearing, Improving the performance of Chinese word segmentation algorithms on OOV (Out-OfVocabulary Word, is a word which occurs in the reference corpus but does not occur in the labeled training corpus) is the important research direction.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.6205310126145681}, {"text": "OOV", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.8063902258872986}]}, {"text": "Our system participated in the CIPS-SIGHAN-2010 bake-off task of Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.5572596589724222}]}, {"text": "And we have done work in dealing with two main sub-tasks: (1) Word Segmentation for Simplified Chinese Text, (2) Word Segmentation for Traditional Chinese Text.", "labels": [], "entities": [{"text": "Word Segmentation for Simplified Chinese Text", "start_pos": 62, "end_pos": 107, "type": "TASK", "confidence": 0.6932077705860138}, {"text": "Word Segmentation for Traditional Chinese Text", "start_pos": 113, "end_pos": 159, "type": "TASK", "confidence": 0.8074698646863302}]}, {"text": "Our system formalizes these tasks as consecutive sequence tagging problems, and learns the segmentation using conditional random fields approach.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7255681455135345}]}, {"text": "Our system contains two modules, a multiple preprocessor and a basic segmenter.", "labels": [], "entities": []}, {"text": "The multiple preprocessor first finds chunks based on boundary dictionary and then uses named entity recognition technology to extract the person, location, organization and special time.", "labels": [], "entities": []}, {"text": "The basic segmenter using CRF model is trained to segment the sentence to word which contains one or more characters.", "labels": [], "entities": []}, {"text": "The basic segmenter follows the study of Zhenxing Wang, Changning Huang and Jingbo, but applies more refined features and tags.", "labels": [], "entities": []}, {"text": "The reminder of the paper is organized as follows.", "labels": [], "entities": [{"text": "reminder of the paper", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.6619164049625397}]}, {"text": "In section 2, we briefly describe the task and the details of our system.", "labels": [], "entities": []}, {"text": "The experimental results are discussed in section 3.", "labels": [], "entities": []}, {"text": "In section 4 we put forward our conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the four domain  Simplified Chinese test data set", "labels": [], "entities": [{"text": "Simplified Chinese test data set", "start_pos": 42, "end_pos": 74, "type": "DATASET", "confidence": 0.8063382625579834}]}, {"text": " Table 3: Performance of four domain Traditional  Chinese test data set", "labels": [], "entities": [{"text": "Chinese test data set", "start_pos": 50, "end_pos": 71, "type": "DATASET", "confidence": 0.7947849035263062}]}]}