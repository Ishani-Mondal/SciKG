{"title": [], "abstractContent": [{"text": "Dzongkha, the national language of Bhutan, is continuous in written form and it fails to mark the word boundary.", "labels": [], "entities": []}, {"text": "Dzongkha word segmentation is one of the fundamental problems and a prerequisite that needs to be solved before more advanced Dzongkha text processing and other natural language processing tools can be developed.", "labels": [], "entities": [{"text": "Dzongkha word segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6438444256782532}]}, {"text": "This paper presents our initial attempt at segmenting Dzongkha sentences into words.", "labels": [], "entities": [{"text": "segmenting Dzongkha sentences into words", "start_pos": 43, "end_pos": 83, "type": "TASK", "confidence": 0.8680501818656922}]}, {"text": "The paper describes the implementation of Maximal Matching (Dictionary based Approach) followed by bigram techniques (Non-dictionary based Approach) in segmenting the Dzongkha scripts.", "labels": [], "entities": [{"text": "Maximal Matching", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.6602790802717209}]}, {"text": "Although the used techniques are basic and naive, it provides a baseline of the Dzongkha word segmentation task.", "labels": [], "entities": [{"text": "Dzongkha word segmentation task", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.69679244607687}]}, {"text": "Preliminary experimental results show percentage of segmentation accuracy.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 52, "end_pos": 64, "type": "TASK", "confidence": 0.9701703786849976}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.97854083776474}]}, {"text": "However, the segmentation accuracy is dependent on the type of document domain and size and quality of the lexicon and the corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.917575478553772}]}, {"text": "Some of the related issues for future directions are also discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Segmentation of a sentence into word is one of the necessary preprocessing tasks and is essential in the analysis of natural language processing.", "labels": [], "entities": [{"text": "Segmentation of a sentence into word", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8731046617031097}]}, {"text": "This is because word is both syntactically and semantically, the fundamental unit for analyzing language structure.", "labels": [], "entities": []}, {"text": "Like in any other language processing task, Dzongkha word segmentation is also viewed as one of the fundamental and foremost steps in Dzongkha related language processing tasks.", "labels": [], "entities": [{"text": "language processing task", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.7966689467430115}, {"text": "Dzongkha word segmentation", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.6051951547463735}, {"text": "Dzongkha related language processing tasks", "start_pos": 134, "end_pos": 176, "type": "TASK", "confidence": 0.6650375664234162}]}, {"text": "The most challenging features of Dzongkha script is the lack of word boundary separation between the words 1 . So, in order to do the further linguistic and natural language processing tasks, the scripts should be transformed into a chain of words.", "labels": [], "entities": []}, {"text": "Therefore, segmenting a word is an essential role in Natural Language Processing.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6437250673770905}]}, {"text": "Like Chinese, Japanese and Korean (CJK) languages, Dzongkha script being written continuously without any word delimiter causes a major problem in natural language processing tasks.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 147, "end_pos": 174, "type": "TASK", "confidence": 0.6273228327433268}]}, {"text": "But, in case of CJK, Thai, and Vietnamese languages, many solutions have been published before.", "labels": [], "entities": []}, {"text": "For Dzongkha, this is the first ever word segmentation solution to be documented.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7176639139652252}]}, {"text": "In this paper, we describe the Dzongkha word segmentation, which is performed firstly using the Dictionary based approach where the principle of maximal matching algorithm is applied to the input text.", "labels": [], "entities": [{"text": "Dzongkha word segmentation", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.5335579812526703}]}, {"text": "Here, given the collection of lexicon, the maximal matching algorithm selects the segmentation that yields the minimum number of words token from all possible segmentations of the input sentence.", "labels": [], "entities": []}, {"text": "Then, it uses non-dictionary based approach where bigram technique is applied.", "labels": [], "entities": []}, {"text": "The probabilistic model of a word sequence is studied using the Maximum Likelihood Estimation (MLE).", "labels": [], "entities": [{"text": "Maximum Likelihood Estimation (MLE)", "start_pos": 64, "end_pos": 99, "type": "METRIC", "confidence": 0.7828093071778616}]}, {"text": "The approach using the MLE has an obvious disadvantage because of the unavoidably limited size of the training corpora.", "labels": [], "entities": [{"text": "MLE", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.39568182826042175}]}, {"text": "To this problem of data sparseness, the idea of Katz back-off model with Good-Turing smoothing technique is applied.", "labels": [], "entities": []}], "datasetContent": [{"text": "Subjective evaluation has been performed by comparing the experimental results with the manually segmented tokens.", "labels": [], "entities": [{"text": "Subjective evaluation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8116998076438904}]}, {"text": "The method was evaluated using different sets of test documents from various domains consisting of 714 manually segmented words.", "labels": [], "entities": []}, {"text": "where \uf06c N is the number of correctly segmented tokens \uf06c T is the total number of manually segmented tokens/ Total number of words.", "labels": [], "entities": []}, {"text": "We have taken the extract of different test data hoping it may contain fair amount of general terms, technical terms and common nouns.", "labels": [], "entities": []}, {"text": "The manually segmented corpus containing 41,739 tokens are used for the method.", "labels": [], "entities": []}, {"text": "In the sample comparison below, the symbol ( \u0f0b ) does not make the segmentation unit's mark, but ( \u0f0d ) takes the segmentation unit's mark, despite its actual mark for comma or full_stop.", "labels": [], "entities": []}, {"text": "The whitespace in the sentence are phrase boundary or comma, and is a faithful representation of speech where we pause not between words, but either after certain phrases or at the end of sentence.", "labels": [], "entities": []}, {"text": "Consider the sample input sentence:", "labels": [], "entities": []}], "tableCaptions": []}