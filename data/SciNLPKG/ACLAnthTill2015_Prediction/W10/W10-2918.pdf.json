{"title": [{"text": "A Comparative Study of Bayesian Models for Unsupervised Sentiment Detection", "labels": [], "entities": [{"text": "Sentiment Detection", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.839820384979248}]}], "abstractContent": [{"text": "This paper presents a comparative study of three closely related Bayesian models for unsupervised document level sentiment classification, namely, the latent sentiment model (LSM), the joint sentiment-topic (JST) model, and the Reverse-JST model.", "labels": [], "entities": [{"text": "document level sentiment classification", "start_pos": 98, "end_pos": 137, "type": "TASK", "confidence": 0.7604077458381653}]}, {"text": "Extensive experiments have been conducted on two corpora, the movie review dataset and the multi-domain sentiment dataset.", "labels": [], "entities": [{"text": "movie review dataset", "start_pos": 62, "end_pos": 82, "type": "DATASET", "confidence": 0.6921343406041464}, {"text": "multi-domain sentiment dataset", "start_pos": 91, "end_pos": 121, "type": "DATASET", "confidence": 0.6852341790994009}]}, {"text": "It has been found that while all the three models achieve either better or comparable performance on these two corpora when compared to the existing unsupervised sentiment classification approaches, both JST and Reverse-JST are able to extract sentiment-oriented topics.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 162, "end_pos": 186, "type": "TASK", "confidence": 0.8194777071475983}]}, {"text": "In addition, Reverse-JST always performs worse than JST suggesting that the JST model is more appropriate for joint sentiment topic detection.", "labels": [], "entities": [{"text": "joint sentiment topic detection", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.7966641932725906}]}], "introductionContent": [{"text": "With the explosion of web 2.0, various types of social media such as blogs, discussion forums and peer-to-peer networks present a wealth of information that can be very helpful in assessing the general public's sentiments and opinions towards products and services.", "labels": [], "entities": []}, {"text": "Recent surveys have revealed that opinion-rich resources like online reviews are having greater economic impact on both consumers and companies compared to the traditional media.", "labels": [], "entities": []}, {"text": "Driven by the demand of gleaning insights of such great amounts of user-generated data, work on new methodologies for automated sentiment analysis has bloomed splendidly.", "labels": [], "entities": [{"text": "automated sentiment analysis", "start_pos": 118, "end_pos": 146, "type": "TASK", "confidence": 0.7173140446345011}]}, {"text": "Compared to the traditional topic-based text classification, sentiment classification is deemed to be more challenging as sentiment is often embodied in subtle linguistic mechanisms such as the use of sarcasm or incorporated with highly domain-specific information.", "labels": [], "entities": [{"text": "topic-based text classification", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6918648282686869}, {"text": "sentiment classification", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.9354262948036194}]}, {"text": "Although the task of identifying the overall sentiment polarity of a document has been well studied, most of the work is highly domain dependent and favoured in supervised learning (, requiring annotated corpora for every possible domain of interest, which is impractical for real applications.", "labels": [], "entities": [{"text": "identifying the overall sentiment polarity of a document", "start_pos": 21, "end_pos": 77, "type": "TASK", "confidence": 0.8498689904808998}]}, {"text": "Also, it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results when shifted to another domain, since sentiment expression can be quite different in different domains).", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.897474467754364}]}, {"text": "Moreover, aside from the diversity of genres and large-scale size of Web corpora, user-generated contents evolve rapidly overtime, which demands much more efficient algorithms for sentiment analysis than the current approaches can offer.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.9501672387123108}]}, {"text": "These observations have thus motivated the problem of using unsupervised approaches for domain-independent joint sentiment topic detection.", "labels": [], "entities": [{"text": "domain-independent joint sentiment topic detection", "start_pos": 88, "end_pos": 138, "type": "TASK", "confidence": 0.6841472864151001}]}, {"text": "Some recent research efforts have been made to adapt sentiment classifiers trained on one domain to another domain (Aue and.", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.8465503752231598}]}, {"text": "However, the adaption performance of these lines of work pretty much depends on the distribution similarity between the source and target domain, and considerable effort is still required to obtain labelled data for training.", "labels": [], "entities": [{"text": "adaption", "start_pos": 13, "end_pos": 21, "type": "TASK", "confidence": 0.9663949608802795}]}, {"text": "Intuitively, sentiment polarities are dependent on contextual information, such as topics or domains.", "labels": [], "entities": [{"text": "sentiment polarities", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.9331019818782806}]}, {"text": "In this regard, some recent work () has tried to model both sentiment and topics.", "labels": [], "entities": []}, {"text": "However, these two models either require postprocessing to calculate the positive/negative coverage in a document for polarity identification or re-quire some kind of supervised setting in which review text should contain ratings for aspects of interest ().", "labels": [], "entities": [{"text": "polarity identification", "start_pos": 118, "end_pos": 141, "type": "TASK", "confidence": 0.7614546418190002}]}, {"text": "More recently, proposed an unsupervised sentiment classification algorithm by integrating user feedbacks into a spectral clustering algorithm.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.867680549621582}]}, {"text": "Features induced for each dimension of spectral clustering can be considered as sentimentoriented topics.", "labels": [], "entities": []}, {"text": "Nevertheless, human judgement of identifying the most important dimensions during spectral clustering is required.", "labels": [], "entities": [{"text": "spectral clustering", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.6775205433368683}]}, {"text": "proposed a joint sentimenttopic (JST) model for unsupervised joint sentiment topic detection.", "labels": [], "entities": [{"text": "joint sentiment topic detection", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.7260951995849609}]}, {"text": "They assumed that topics are generated dependent on sentiment distributions and then words are generated conditioned on sentiment-topic pairs.", "labels": [], "entities": []}, {"text": "While this is a reasonable design choice, one may argue that the reverse is also true that sentiments may vary according to topics.", "labels": [], "entities": []}, {"text": "Thus in this paper, we studied the reverse dependence of the JST model called Reverse-JST, in which sentiments are generated dependent on topic distributions in the modelling process.", "labels": [], "entities": []}, {"text": "We also note that, when the topic number is set to 1, both JST and reversed-JST essentially become a simple latent Dirichlet allocation (LDA) model with only S (number of sentiment label) topics, each of which corresponds to a sentiment label.", "labels": [], "entities": []}, {"text": "We called it latent sentiment model (LSM) in this paper.", "labels": [], "entities": []}, {"text": "Extensive experiments have been conducted on the movie review (MR)) and multi-domain sentiment (MDS)) datasets to compare the performance of LSM, JST and Reverse-JST.", "labels": [], "entities": []}, {"text": "Results show that all these three models are able to give either better or comparable performance compared to the existing unsupervised sentiment classification approaches.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.8942664563655853}]}, {"text": "In addition, both JST and reverse-JST are able to extract sentiment-oriented topics.", "labels": [], "entities": [{"text": "JST", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8089050054550171}, {"text": "extract sentiment-oriented topics", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.6870962580045065}]}, {"text": "Furthermore, the fact that reverse-JST always performs worse than JST suggests that the JST model is more appropriate for joint sentiment topic detection.", "labels": [], "entities": [{"text": "joint sentiment topic detection", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.8162649124860764}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the LSM, JST and Reserver-JST models.", "labels": [], "entities": []}, {"text": "Experimental setup and results on the MR and MDS datasets are discussed in Section 4 and 5 re-", "labels": [], "entities": [{"text": "MR and MDS datasets", "start_pos": 38, "end_pos": 57, "type": "DATASET", "confidence": 0.5295799821615219}]}], "datasetContent": [{"text": "Two publicly available datasets, the MR and MDS datasets, were used in our experiments.", "labels": [], "entities": [{"text": "MR", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.5947014093399048}, {"text": "MDS datasets", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.730568453669548}]}, {"text": "The MR dataset (also known as the polarity dataset) has become a benchmark for many studies since the work of.", "labels": [], "entities": [{"text": "MR dataset", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8589305281639099}]}, {"text": "The version 2.0 used in our experiment consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB movie archive, with an average of 30 sentences in each document.", "labels": [], "entities": [{"text": "IMDB movie archive", "start_pos": 112, "end_pos": 130, "type": "DATASET", "confidence": 0.9506712555885315}]}, {"text": "We also experimented with another dataset, namely subjective MR, by removing the sentences that do not bear opinion information from the MR dataset, following the approach of.", "labels": [], "entities": [{"text": "MR dataset", "start_pos": 137, "end_pos": 147, "type": "DATASET", "confidence": 0.8066489100456238}]}, {"text": "The resulting dataset still contains 2000 documents with a total of 334,336 words and 18,013 distinct terms, about half the size of the original MR dataset without performing subjectivity detection.", "labels": [], "entities": [{"text": "MR dataset", "start_pos": 145, "end_pos": 155, "type": "DATASET", "confidence": 0.756267249584198}, {"text": "subjectivity detection", "start_pos": 175, "end_pos": 197, "type": "TASK", "confidence": 0.6842880696058273}]}, {"text": "First used by, the MDS dataset contains 4 different types of product reviews taken from Amazon.com including books, DVDs, electronics and kitchen appliances, with 1000 positive and 1000 negative examples for each domain . Preprocessing was performed on both of the datasets.", "labels": [], "entities": [{"text": "MDS dataset", "start_pos": 19, "end_pos": 30, "type": "DATASET", "confidence": 0.8049197196960449}, {"text": "Preprocessing", "start_pos": 222, "end_pos": 235, "type": "METRIC", "confidence": 0.9655920267105103}]}, {"text": "Firstly, punctuation, numbers, nonalphabet characters and stop words were removed.", "labels": [], "entities": []}, {"text": "Secondly, standard stemming was performed in order to reduce the vocabulary size and address the issue of data sparseness.", "labels": [], "entities": []}, {"text": "Summary statistics of the datasets before and after preprocessing are shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset and sentiment lexicon statistics. (Note: \u2020denotes before preprocessing and * denotes  after preprocessing.)", "labels": [], "entities": []}, {"text": " Table 2: LSM sentiment classification results.", "labels": [], "entities": [{"text": "LSM sentiment classification", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7456502517064413}]}]}