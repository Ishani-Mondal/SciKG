{"title": [{"text": "Combining Manual Rules and Supervised Learning for Hedge Cue and Scope Detection", "labels": [], "entities": [{"text": "Hedge Cue and Scope Detection", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.6374328076839447}]}], "abstractContent": [{"text": "Hedge cues were detected using a supervised Conditional Random Field (CRF) classifier exploiting features from the RASP parser.", "labels": [], "entities": []}, {"text": "The CRF's predictions were filtered using known cues and unseen instances were removed, increasing precision while retaining recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9990447163581848}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9976067543029785}]}, {"text": "Rules for scope detection, based on the grammatical relations of the sentence and the part-of-speech tag of the cue, were manually-developed.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9412811994552612}]}, {"text": "However, another supervised CRF classifier was used to refine these predictions.", "labels": [], "entities": [{"text": "CRF classifier", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.790257602930069}]}, {"text": "As a final step, scopes were constructed from the classifier output using a small set of post-processing rules.", "labels": [], "entities": []}, {"text": "Development of the system revealed a number of issues with the annotation scheme adopted by the organisers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speculative or, more generally, \"hedged\" language is away of weakening the strength of a statement.", "labels": [], "entities": []}, {"text": "It is usually signalled by a word or phrase, called a hedge cue, which weakens some clauses or propositions.", "labels": [], "entities": []}, {"text": "These weakened portions of a sentence form the scope of the hedge cues.", "labels": [], "entities": []}, {"text": "Hedging is an important tool in scientific language allowing scientists to guide research beyond the evidence without overstating what follows from their work.", "labels": [], "entities": [{"text": "Hedging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9583357572555542}]}, {"text": "show that 19.44% of all sentences in the full papers of the BioScope corpus contain hedge cues.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.8499008417129517}]}, {"text": "Detecting these cues is potentially valuable for tasks such as scientific information extraction or literature curation, as typically only definite information should be extracted and curated.", "labels": [], "entities": [{"text": "scientific information extraction", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.6720440785090128}, {"text": "literature curation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.7205309718847275}]}, {"text": "Most work so far has been done on classifying entire text sentences as hedged or not, but this risks losing valuable information in (semi-)automated systems.", "labels": [], "entities": [{"text": "classifying entire text sentences", "start_pos": 34, "end_pos": 67, "type": "TASK", "confidence": 0.8309604078531265}]}, {"text": "More recent approaches attempt to find the specific parts of a text sentence that are hedged.", "labels": [], "entities": []}, {"text": "Here we describe a system that is designed to find hedge cues and their scopes in biomedical research papers.", "labels": [], "entities": []}, {"text": "It works in three stages: 1.", "labels": [], "entities": []}, {"text": "Detecting the cues using a token-level supervised classifier.", "labels": [], "entities": []}, {"text": "2. Finding the scopes with a combination of manual rules and a second supervised tokenlevel classifier.", "labels": [], "entities": []}, {"text": "3. Applying postprocessing rules to convert the token-level annotation into predictions about scope.", "labels": [], "entities": []}, {"text": "Parts of the system are similar to that of Morante and Daelemans (2009) -both make use of machine learning to tag tokens as being in a cue or a scope.", "labels": [], "entities": []}, {"text": "The most important differences are the use of manually defined rules and the inclusion of grammatical relations from a parser as critical features.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Cue detection results.", "labels": [], "entities": [{"text": "Cue detection", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8641580939292908}]}, {"text": " Table 4: True and false positives of the ten most  common cues in the evaluation data, using ML3  system.", "labels": [], "entities": []}, {"text": " Table 5: Scope detection results using gold stan- dard cues.", "labels": [], "entities": [{"text": "Scope detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9854731857776642}]}, {"text": " Table 6: Scope detection results using predicted  cues.", "labels": [], "entities": [{"text": "Scope detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9836743474006653}]}]}