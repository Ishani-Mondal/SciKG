{"title": [{"text": "Learning to Detect Hedges and their Scope Using CRF", "labels": [], "entities": [{"text": "Learning to Detect Hedges and their Scope", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7315465680190495}]}], "abstractContent": [{"text": "Detecting speculative assertions is essential to distinguish the facts from uncertain information for biomedical text.", "labels": [], "entities": [{"text": "Detecting speculative assertions", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.9039208094278971}]}, {"text": "This paper describes a system to detect hedge cues and their scope using CRF model.", "labels": [], "entities": []}, {"text": "HCDic feature is presented to improve the system performance of detecting hedge cues on BioScope corpus.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9503863453865051}]}, {"text": "The feature can make use of cross-domain resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "George Lakoff (1972) first introduced linguistic hedges which indicate that speakers do not backup their opinions with facts.", "labels": [], "entities": []}, {"text": "Later other linguists followed the social functions of hedges closely.", "labels": [], "entities": []}, {"text": "Interestingly, Robin introduces that hedges might be one of the \"women's language features\" as they have higher frequency in women's languages than in men's.", "labels": [], "entities": []}, {"text": "In the natural language processing domain, hedges are very important, too.", "labels": [], "entities": []}, {"text": "Along with the rapid development of computational and biological technology, information extraction from huge amount of biomedical resource becomes more and more important.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.8385553359985352}]}, {"text": "While the uncertain information can be a noisy factor sometimes, affecting the performance of information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.8151504397392273}]}, {"text": "Biomedical articles are rich in speculative, while 17.70% of the sentences in the abstracts section of the BioScope corpus and 19.44% of the sentences in the full papers section contain hedge cues (.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 107, "end_pos": 122, "type": "DATASET", "confidence": 0.928322970867157}]}, {"text": "In order to distinguish facts from uncertain information, detecting speculative assertions is essential in biomedical text.", "labels": [], "entities": [{"text": "detecting speculative assertions", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.8708330988883972}]}, {"text": "Hedge detection is paid attention to in the biomedical NLP field.", "labels": [], "entities": [{"text": "Hedge detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9776051044464111}]}, {"text": "Some researchers regard the problem as a text classification problem (a sentence is speculative or not) using simple machine learning techniques.", "labels": [], "entities": [{"text": "text classification", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7504132390022278}]}, {"text": "use substring matching to annotate speculation in biomedical text.", "labels": [], "entities": []}, {"text": "create a hedging dataset and use an SVM classifier and get to a recall/precision BreakEven Point (BEP) of 0.76.", "labels": [], "entities": [{"text": "recall/precision BreakEven Point (BEP)", "start_pos": 64, "end_pos": 102, "type": "METRIC", "confidence": 0.8725766986608505}]}, {"text": "They report that the POS feature performs badly, while lemma feature works well.", "labels": [], "entities": []}, {"text": "extends the work of Medlock and Briscoe with feature selection, and further improves the result to a BEP of 0.85 by using an external dictionary.", "labels": [], "entities": [{"text": "BEP", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.999019980430603}]}, {"text": "Szarvas concludes that scientific articles contain multiword hedging cues more commonly, and the portability of hedge classifiers is limited.", "labels": [], "entities": []}, {"text": "Halil propose an algorithm to weight hedge cues, which are used to evaluate the speculative strength of sentences.", "labels": [], "entities": []}, {"text": "Roser Morante and Walter Daelemans (2009) introduce a metalearning approach to process the scope of negation, and they identify the hedge cues and their scope with a CRF classifier based on the original work.", "labels": [], "entities": []}, {"text": "They extract a hedge cues dictionary as well, but do not combine it with the CRF model.", "labels": [], "entities": []}, {"text": "In the CoNLL-2010 shared task, there are two subtasks for worldwide participants to choose: \u2022 Task 1: learning to detect sentences contain-ing uncertainty.", "labels": [], "entities": []}, {"text": "\u2022 Task 2: learning to resolve the insentence scope of hedge cues.", "labels": [], "entities": []}, {"text": "This paper describes a system using CRF model for the task, which is partly based on Roser Morante and Walter Daelemans' work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two training datasets, the BioScope and Wikipedia corpus are provided in the CoNLL-2010 shared task.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.845559298992157}, {"text": "Wikipedia corpus", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.9427883327007294}, {"text": "CoNLL-2010 shared task", "start_pos": 77, "end_pos": 99, "type": "DATASET", "confidence": 0.7904735008875529}]}, {"text": "BioScope consists of two parts, full articles and abstracts collected from biomedical papers.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6968947649002075}]}, {"text": "The latter is analyzed for having larger scale and more information of hedges.", "labels": [], "entities": []}, {"text": "In, the percentage of the speculative sentences in the abstracts section of BioScope corpus is the same as reported.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.9506503045558929}]}, {"text": "We can estimate 1.28 cue words per sentence, meaning that each sentence usually just has one hedge cue.", "labels": [], "entities": []}, {"text": "The statistics in  We extract all the hedge cues from the abstracts section of BioScope corpus, getting 143 different hedge cues and 101 cues with ignoring morphological changes.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.9364269077777863}]}, {"text": "The maximum length of the cues is 4, with 1.44 words per hedge cue.", "labels": [], "entities": []}, {"text": "This suggests that most hedge cues happen to be a single word.", "labels": [], "entities": []}, {"text": "We assume that hedge cues set is a limited one in BioScope corpus.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.9121988117694855}]}, {"text": "Most hedge cues could be identified if the known dataset of hedge cues is large enough.", "labels": [], "entities": []}, {"text": "The cue words collected from the BioScope corpus play an important role in the speculative sentences detection.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.9282074868679047}, {"text": "speculative sentences detection", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.8722789684931437}]}, {"text": "In contrast to the biomedical abstracts, the weasel cues on Wikipedia corpus make a little difference.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9540126621723175}]}, {"text": "Most weasel cues consist of more than one word, and usually appear once.", "labels": [], "entities": []}, {"text": "This leads to different results in our test.", "labels": [], "entities": []}, {"text": "A hedge cue word may appear in the nonspeculative sentences.", "labels": [], "entities": []}, {"text": "Occurrences of the four typical words in speculative and non-speculative sentences are counted.", "labels": [], "entities": [{"text": "Occurrences", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9786840081214905}]}, {"text": "As shown in, the cue words can be divided into two classes generally.", "labels": [], "entities": []}, {"text": "The hedge cue words \"feel\" and \"suggesting\", which are grouped as one class, only act as hedge cues with never appearing in the non-speculative sentences.", "labels": [], "entities": []}, {"text": "While \"may\" and \"or\" appear both in the speculative and non-speculative sentences, which are regard as the other one.", "labels": [], "entities": []}, {"text": "Moreover, we treat the words \"may\" and \"or\" in the same class differently, while \"may\" is more likely to be a hedge cue than \"or\".", "labels": [], "entities": []}, {"text": "The treatment is also unequal between \"feel\" and \"suggesting\".", "labels": [], "entities": []}, {"text": "In the training datasets, the non-S#/S# ratio can give a weight to distinguish the words in each class.", "labels": [], "entities": []}, {"text": "After all, we can divide the hedge cues into 4 groups.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics about the abstracts section of  the BioScope corpus and Wikipedia corpus.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9370806813240051}, {"text": "Wikipedia corpus", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.8860957622528076}]}, {"text": " Table 2: Statistics of cue words. (S# short for the  occurrence times in speculative sentences, non- S# for the count in non-speculative ones)", "labels": [], "entities": []}, {"text": " Table 3: Types of the HCDic words. (S# and  non-S# have the same meaning as in", "labels": [], "entities": []}, {"text": " Table 4: Statistics of the strings nearby the scope  head and tail. Item 1 shows the word follow  scope head, and item 2 shows the frequent words  next to the scope tail.", "labels": [], "entities": []}, {"text": " Table 5: Results at hedge cue-level", "labels": [], "entities": []}, {"text": " Table 6: Evaluation result of task 1", "labels": [], "entities": []}, {"text": " Table 7: Results of weasel/hedge detection in  Wikipedia and BioScope corpus.", "labels": [], "entities": [{"text": "weasel/hedge detection", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7852652668952942}, {"text": "Wikipedia and BioScope corpus", "start_pos": 48, "end_pos": 77, "type": "DATASET", "confidence": 0.7908392399549484}]}]}