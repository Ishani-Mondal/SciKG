{"title": [{"text": "Predicting Cloze Task Quality for Vocabulary Training", "labels": [], "entities": [{"text": "Predicting Cloze Task", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8014562328656515}, {"text": "Vocabulary Training", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8343345820903778}]}], "abstractContent": [{"text": "Computer generation of cloze tasks still falls short of full automation; most current systems are used by teachers as authoring aids.", "labels": [], "entities": [{"text": "Computer generation of cloze tasks", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.779427421092987}]}, {"text": "Improved methods to estimate cloze quality are needed for full automation.", "labels": [], "entities": []}, {"text": "We investigated lexical reading difficulty as a novel automatic estimator of cloze quality, to which co-occurrence frequency of words was compared as an alternate estimator.", "labels": [], "entities": []}, {"text": "Rather than relying on expert evaluation of cloze quality, we submitted open cloze tasks to workers on Amazon Mechanical Turk (AMT) and discuss ways to measure of the results of these tasks.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 103, "end_pos": 131, "type": "DATASET", "confidence": 0.9353014826774597}]}, {"text": "Results show one statistically significant correlation between the above measures and estimators, which was lexical co-occurrence and Cloze Easiness.", "labels": [], "entities": [{"text": "Cloze Easiness", "start_pos": 134, "end_pos": 148, "type": "METRIC", "confidence": 0.9104510843753815}]}, {"text": "Reading difficulty was not found to correlate significantly.", "labels": [], "entities": [{"text": "Reading difficulty", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.8515914976596832}]}, {"text": "We gave subsets of cloze sentences to an English teacher as a gold standard.", "labels": [], "entities": []}, {"text": "Sentences selected by co-occurrence and Cloze Easiness were ranked most highly, corroborating the evidence from AMT.", "labels": [], "entities": [{"text": "Cloze Easiness", "start_pos": 40, "end_pos": 54, "type": "METRIC", "confidence": 0.8677327334880829}, {"text": "AMT", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.7068076729774475}]}], "introductionContent": [], "datasetContent": [{"text": "Previous evaluation of automatically generated cloze tasks has relied on expert judgments.", "labels": [], "entities": []}, {"text": "() We present the use of crowdsourcing techniques as anew approach for this evaluation.", "labels": [], "entities": []}, {"text": "We believe the approach can be validated by statistically significant correlations with predicted cloze quality and comparison with expert judgments.", "labels": [], "entities": []}, {"text": "The set of 540 sentences were presented to workers from Amazon Mechanical Turk (AMT), an online marketplace for \"human intelligence tasks.\"", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 56, "end_pos": 84, "type": "DATASET", "confidence": 0.9041787584622701}]}, {"text": "Each worker was shown up to twenty of the stems of these sentences as open cloze tasks.", "labels": [], "entities": []}, {"text": "No worker was allowed to see more than one stem for the same key.", "labels": [], "entities": []}, {"text": "Workers were instructed to enter only those words that \"absolutely make sense in this context\", but were not encouraged to submit any particular number of answers.", "labels": [], "entities": []}, {"text": "Workers were paid US$.04 per sentence, and the task was limited to workers with approval ratings on past tasks at or above 90%.", "labels": [], "entities": []}, {"text": "For each sentence under review each worker contributes one subset of answers.", "labels": [], "entities": []}, {"text": "Cloze Easiness, as defined by is calculated as the percentage of these subsets containing the original key.", "labels": [], "entities": []}, {"text": "We define context restriction on n as the percentage of answer subsets containing nor fewer words.", "labels": [], "entities": []}, {"text": "Using the example sentence: \"Take this cloze sentence, for (example) .\" We can find the set of answer subsets A: Then, Cloze Easiness is |{A1,A2}| / |A| \u2248 .67 and Context restriction (on one or two words) is | {A2,A3}| / |A| \u2248 .67", "labels": [], "entities": []}], "tableCaptions": []}