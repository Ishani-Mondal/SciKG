{"title": [{"text": "Using Reinforcement Learning to Create Communication Channel Management Strategies for Diverse Users", "labels": [], "entities": [{"text": "Create Communication Channel Management Strategies", "start_pos": 32, "end_pos": 82, "type": "TASK", "confidence": 0.6606688916683197}]}], "abstractContent": [{"text": "Spoken dialogue systems typically do not manage the communication channel, instead using fixed values for such features as the amplitude and speaking rate.", "labels": [], "entities": [{"text": "Spoken dialogue", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7849014699459076}]}, {"text": "Yet, the quality of a dialogue can be compromised if the user has difficulty understanding the system.", "labels": [], "entities": []}, {"text": "In this proof-of-concept research, we explore using reinforcement learning (RL) to create policies that manage the communication channel to meet the needs of diverse users.", "labels": [], "entities": []}, {"text": "Towards this end, we first formalize a preliminary communication channel model, in which users provide explicit feedback regarding issues with the communication channel, and the system implicitly alters its amplitude to accommodate the user's optimal volume.", "labels": [], "entities": []}, {"text": "Second , we explore whether RL is an appropriate tool for creating communication channel management strategies, comparing two different hand-crafted policies to policies trained using both a dialogue-length and a novel annoyance cost.", "labels": [], "entities": [{"text": "RL", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9492552876472473}]}, {"text": "The learned policies performed better than hand-crafted policies, with those trained using the annoyance cost learning an equitable tradeoff between users with differing needs and also learning to balance finding a user's optimal amplitude against dialogue-length.", "labels": [], "entities": []}, {"text": "These results suggest that RL can be used to create effective communication channel management policies for diverse users.", "labels": [], "entities": [{"text": "RL", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9321092963218689}]}], "introductionContent": [{"text": "Both Spoken Dialog Systems (SDS) and Assistive Technology (AT) tend to have a narrow focus, supporting only a subset of the population.", "labels": [], "entities": []}, {"text": "SDS typically aim to support the \"average man\", ignoring wide variations in potential users' ability to hear and understand the system.", "labels": [], "entities": []}, {"text": "AT aims to support people with a recognized disability, but doesn't support those whose impairment is not severe enough to warrant the available devices or services, or those who are unaware or have not acknowledged that they need assistance.", "labels": [], "entities": []}, {"text": "However, SDS should be able to meet the needs of users whose abilities fall within, and between, the extremes of severly impaired and perfectly abled.", "labels": [], "entities": [{"text": "SDS", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.92290860414505}]}, {"text": "When aiming to support users with widely differing abilities, the cause of a user's difficulty is less important than adapting the communication channel in a manner that aids understanding.", "labels": [], "entities": []}, {"text": "For example, speech that is presented more loudly and slowly can help a hearing-impaired elderly person understand the system, and can also help a person with no hearing loss who is driving in a noisy car.", "labels": [], "entities": []}, {"text": "Although one user's difficulty is due to impairment and the other due to an adverse environment, a similar adaptation maybe appropriate to both.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9772472381591797}]}, {"text": "During human-human communication, speakers manage the communication channel; implicitly altering their manner of speech to increase the likelihood of being understood while concurrently economizing effort.", "labels": [], "entities": []}, {"text": "In addition to these implicit actions, speakers also make statements referring to breakdowns in the communication chan-nel, explicitly pointing out potential problems or corrections, (e.g. \"Could you please speak up?\")", "labels": [], "entities": []}, {"text": "(. As for human-computer dialogue, SDS are prone to misrecognition of users' spoken utterances.", "labels": [], "entities": []}, {"text": "Much research has focused on developing techniques for overcoming or avoiding system misunderstandings.", "labels": [], "entities": [{"text": "overcoming or avoiding system misunderstandings", "start_pos": 55, "end_pos": 102, "type": "TASK", "confidence": 0.664670217037201}]}, {"text": "Yet, as the quality of automatic speech recognition improves and SDS are deployed to diverse populations and in varied environments, systems will need to better attend to possible human misunderstandings.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.6774977445602417}, {"text": "SDS", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9696894884109497}]}, {"text": "Future SDS will need to manage the communication channel, in addition to managing the task, to aid in avoiding these misunderstandings.", "labels": [], "entities": []}, {"text": "Researchers have explored the use of reinforcement learning (RL) to create dialogue policies that balance and optimize measures of task success (e.g., see (;).", "labels": [], "entities": [{"text": "reinforcement learning (RL)", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.7030550956726074}]}, {"text": "Along these lines, RL is potentially well suited to creating policies for the subtask of managing the communication channel, as it can learn to adapt to the user while continuing the dialogue.", "labels": [], "entities": [{"text": "RL", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9178411960601807}]}, {"text": "In doing so, RL may choose actions that appear costly at the time, but lead to better overall dialogues.", "labels": [], "entities": [{"text": "RL", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9619786739349365}]}, {"text": "Our long term goal is to learn how to manage the communication channel along with the task, moving away from just \"what\" to say and also focusing on \"how\" to say it.", "labels": [], "entities": []}, {"text": "For this proof-of-concept, our goals are twofold: 1) to formalize a communication channel model that encompasses diverse users, initially focusing just on explicit user actions and implicit system actions, and 2) to determine whether RL is an appropriate tool for learning an effective communication channel management strategy for diverse users.", "labels": [], "entities": []}, {"text": "To explore the above issues, we use a simple communication channel model in which the system needs to determine and maintain an amplitude level that is pleasant and effective for users with differing amplitude preferences and needs.", "labels": [], "entities": []}, {"text": "As our goal includes decreasing the amount of potentially annoying utterances (i.e., those in which the system's amplitude setting is in discord with the user's optimal amplitude), we introduce a user-centric cost metric, which we have termed annoyance cost.", "labels": [], "entities": []}, {"text": "We then compare hand-crafted policies against policies trained using both annoyance and more traditional dialogue-length cost components.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of DC (left) and AC (right) interactions with a user who has an optimal amplitude of 8 and a  tolerance range of 3. The policies continue as shown, without changing the amplitude level, until all 9 queries are  answered.", "labels": [], "entities": []}]}