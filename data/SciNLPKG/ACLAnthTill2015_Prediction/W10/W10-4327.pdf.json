{"title": [{"text": "Discourse indicators for content selection in summarization", "labels": [], "entities": [{"text": "content selection", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7153721749782562}, {"text": "summarization", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9797663688659668}]}], "abstractContent": [{"text": "We present analyses aimed at eliciting which specific aspects of discourse provide the strongest indication for text importance.", "labels": [], "entities": [{"text": "text importance", "start_pos": 112, "end_pos": 127, "type": "TASK", "confidence": 0.6820435374975204}]}, {"text": "In the context of content selection for single document summarization of news, we examine the benefits of both the graph structure of text provided by discourse relations and the semantic sense of these relations.", "labels": [], "entities": [{"text": "single document summarization of news", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.7213638424873352}]}, {"text": "We find that structure information is the most robust indicator of importance.", "labels": [], "entities": []}, {"text": "Semantic sense only provides constraints on content selection but is not indicative of important content by itself.", "labels": [], "entities": []}, {"text": "However, sense features complement structure information and lead to improved performance.", "labels": [], "entities": []}, {"text": "Further, both types of discourse information prove complementary to non-discourse features.", "labels": [], "entities": []}, {"text": "While our results establish the usefulness of discourse features, we also find that lexical overlap provides a simple and cheap alternative to discourse for computing text structure with comparable performance for the task of content selection.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse relations such as cause, contrast or elaboration are considered critical for text interpretation, as they signal in what way parts of a text relate to each other to form a coherent whole.", "labels": [], "entities": [{"text": "text interpretation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7993860244750977}]}, {"text": "For this reason, the discourse structure of a text can be seen as an intermediate representation, over which an automatic summarizer can perform computations in order to identify important spans of text to include in a summary ().", "labels": [], "entities": []}, {"text": "In our work, we study the content selection performance of different types of discourse-based features.", "labels": [], "entities": [{"text": "content selection", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.6930034011602402}]}, {"text": "Discourse relations interconnect units of a text and discourse formalisms have proposed different resulting structures for the full text, i.e. tree and graph).", "labels": [], "entities": []}, {"text": "This structure is one source of information from discourse which can be used to compute the importance of text units.", "labels": [], "entities": []}, {"text": "The semantics of the discourse relations between sentences could be another indicator of content importance.", "labels": [], "entities": []}, {"text": "For example, text units connected by \"cause\" and \"contrast\" relationships might be more important content for summaries compared to those conveying \"elaboration\".", "labels": [], "entities": [{"text": "summaries", "start_pos": 110, "end_pos": 119, "type": "TASK", "confidence": 0.9782354831695557}]}, {"text": "While previous work have focused on developing content selection methods based upon individual frameworks, little is known about which aspects of discourse are actually correlated with content selection power.", "labels": [], "entities": []}, {"text": "In our work, we separate out structural and semantic features and examine their usefulness.", "labels": [], "entities": []}, {"text": "We also investigate whether simpler intermediate representations can be used in lieu of discourse.", "labels": [], "entities": []}, {"text": "More parsimonious, easy to compute representations of text have been proposed for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.9924367070198059}]}, {"text": "For example, a text can be reduced to a set of highly descriptive topical words, the presence of which is used to signal importance for content selection ().", "labels": [], "entities": [{"text": "content selection", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.715570792555809}]}, {"text": "Similarly, a graph representation of the text can be computed, in which vertices represent sentences, and the nodes are connected when the sentences are similar in terms of word overlap; properties of the graph would then determine the importance of the nodes () and guide content selection.", "labels": [], "entities": []}, {"text": "We compare the utility of discourse features for single-document text summarization from three frameworks: Rhetorical Structure Theory (, Graph Bank (Wolf and, and Penn Discourse Treebank (PDTB) ( ).", "labels": [], "entities": [{"text": "single-document text summarization", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.6686807672182719}, {"text": "Penn Discourse Treebank (PDTB)", "start_pos": 164, "end_pos": 194, "type": "DATASET", "confidence": 0.9216148753960928}]}, {"text": "We present a detailed analysis of the predictive power of different types of discourse features for content selection and compare discourse-based selection to simpler non-discourse methods.", "labels": [], "entities": [{"text": "content selection", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7161070257425308}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy (Acc) and Precision (P), Recall  (R) and F-score (F) of important sentences.", "labels": [], "entities": [{"text": "Accuracy (Acc)", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8880142122507095}, {"text": "Precision (P)", "start_pos": 29, "end_pos": 42, "type": "METRIC", "confidence": 0.9491430073976517}, {"text": "Recall  (R)", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.9597409218549728}, {"text": "F-score (F)", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9648156315088272}]}, {"text": " Table 2: ROUGE-1 recall scores", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9951099753379822}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.8155010342597961}]}, {"text": " Table 3: Tree vs graph-based discourse features", "labels": [], "entities": []}, {"text": " Table 4: Performance of lexrank summarizer", "labels": [], "entities": [{"text": "summarizer", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.4211426377296448}]}, {"text": " Table 5: Significant RST-based features", "labels": [], "entities": [{"text": "RST-based", "start_pos": 22, "end_pos": 31, "type": "TASK", "confidence": 0.7359607815742493}]}, {"text": " Table 6: Significant non-discourse features", "labels": [], "entities": []}]}