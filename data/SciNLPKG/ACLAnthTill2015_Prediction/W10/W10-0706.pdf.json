{"title": [{"text": "Shared Task: Crowdsourced Accessibility Elicitation of Wikipedia Articles", "labels": [], "entities": [{"text": "Crowdsourced Accessibility Elicitation of Wikipedia Articles", "start_pos": 13, "end_pos": 73, "type": "TASK", "confidence": 0.7318996836741766}]}], "abstractContent": [{"text": "Mechanical Turk is useful for generating complex speech resources like conversational speech transcription.", "labels": [], "entities": [{"text": "conversational speech transcription", "start_pos": 71, "end_pos": 106, "type": "TASK", "confidence": 0.7820333242416382}]}, {"text": "In this work, we explore the next step of eliciting narrations of Wikipedia articles to improve accessibility for low-literacy users.", "labels": [], "entities": []}, {"text": "This task proves a useful test-bed to implement qualitative vetting of workers based on difficult to define metrics like narrative quality.", "labels": [], "entities": []}, {"text": "Working with the Mechanical Turk API, we collected sample narrations , had other Turkers rate these samples and then granted access to full narration HITs depending on aggregate quality.", "labels": [], "entities": []}, {"text": "While narrating full articles proved too onerous a task to be viable, using other Turkers to perform vetting was very successful.", "labels": [], "entities": [{"text": "narrating full articles", "start_pos": 6, "end_pos": 29, "type": "TASK", "confidence": 0.8376580476760864}]}, {"text": "Elicitation is possible on Mechanical Turk, but it should conform to suggested best practices of simple tasks that can be completed in a streamlined workflow.", "labels": [], "entities": [{"text": "Elicitation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9788179397583008}]}], "introductionContent": [{"text": "The rise of Mechanical Turk publications in the NLP community leaves no doubt that non-experts can provide useful annotations for low cost.", "labels": [], "entities": []}, {"text": "Emerging best practices suggest designing short, simple tasks that require little amount of upfront effort to most effectively use Mechanical Turk's labor pool.", "labels": [], "entities": [{"text": "Mechanical Turk's labor pool", "start_pos": 131, "end_pos": 159, "type": "DATASET", "confidence": 0.8108606457710266}]}, {"text": "Suitable tasks are best limited to those easily accomplished in 'short bites' requiring little context switching.", "labels": [], "entities": []}, {"text": "For instance, most annotation tasks in prior work () required selection from an enumerated list, allowing for easy automated quality control and data collection.", "labels": [], "entities": [{"text": "data collection", "start_pos": 145, "end_pos": 160, "type": "TASK", "confidence": 0.7416122555732727}]}, {"text": "More recent work to collect speech transcription) or parallel text translations) demonstrated that Turkers can provide useful free-form annotation.", "labels": [], "entities": [{"text": "collect speech transcription", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.6498489379882812}, {"text": "parallel text translations", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.6952013572057089}]}, {"text": "In this paper, we extend open ended collection even further by eliciting narrations of English Wikipedia articles.", "labels": [], "entities": [{"text": "open ended collection", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.6269293030103048}]}, {"text": "To vet prospective narrators, we use qualitative qualifications by aggregating the opinions of other Turkers on narrative style, thus avoiding quantification of qualitative tasks.", "labels": [], "entities": [{"text": "vet prospective narrators", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.7579537828763326}]}, {"text": "The Spoken Wikipedia Project 1 aims to increase the accessibility of Wikipedia by recording articles for use by blind or illiterate users.", "labels": [], "entities": []}, {"text": "Since 2008, over 1600 English articles covering topics from art to technology have been narrated by volunteers.", "labels": [], "entities": []}, {"text": "The charitable nature of this work should provide additional incentive for Turkers to complete this task.", "labels": [], "entities": []}, {"text": "We use Wikipedia narrations as an initial proof-ofconcept for other more challenging elicitation tasks such as spontaneous or conversational speech.", "labels": [], "entities": []}, {"text": "While previous work used other Turkers in second-pass filtering for quality control, we flip this process and instead require that narrators be judged favorably before working on full narration tasks.", "labels": [], "entities": []}, {"text": "Relying on human opinion sidesteps the difficult task of automatically judging narrative quality.", "labels": [], "entities": []}, {"text": "This requires a multi-pass workflow to manage potential narrators and grant them access to the full narration HITs through Mechanical Turk's Qualifications.", "labels": [], "entities": []}, {"text": "In this paper, we make the following points: \u2022 Vetting based on qualitative criteria like narration quality can be effectively implemented through Turker-provided ratings.", "labels": [], "entities": []}, {"text": "\u2022 Narrating full articles is too complex and timeconsuming for timely task throughput -best practices are worth following.", "labels": [], "entities": [{"text": "Narrating full articles", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.8802123864491781}]}, {"text": "\u2022 HITs should be streamlined as much as possible.", "labels": [], "entities": [{"text": "HITs", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.587478756904602}]}, {"text": "Requiring Turkers to perform work outside of the web interface seemingly hurt task completion rate.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}