{"title": [{"text": "Hierarchical Phrase-Based MT at the Charles University for the WMT 2010 Shared Task", "labels": [], "entities": [{"text": "Hierarchical Phrase-Based MT", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5734316011269888}, {"text": "Charles University", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.9353105127811432}, {"text": "WMT 2010 Shared Task", "start_pos": 63, "end_pos": 83, "type": "DATASET", "confidence": 0.70862677693367}]}], "abstractContent": [{"text": "We describe our experiments with hierarchical phrase-based machine translation for WMT 2010 Shared Task.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.6502404510974884}, {"text": "WMT 2010 Shared Task", "start_pos": 83, "end_pos": 103, "type": "DATASET", "confidence": 0.7153518050909042}]}, {"text": "We provide a detailed description of our configuration and data so the results are replicable.", "labels": [], "entities": []}, {"text": "For English-to-Czech translation, we experiment with several datasets of various sizes and with various preprocessing sequences.", "labels": [], "entities": [{"text": "English-to-Czech translation", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.5671793520450592}]}, {"text": "For the other 7 translation directions, we just present the baseline results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Czech is a language with rich morphology (both inflectional and derivational) and relatively free word order.", "labels": [], "entities": []}, {"text": "In fact, the predicate-argument structure, often encoded by fixed word order in English, is usually captured by inflection (especially the system of 7 grammatical cases) in Czech.", "labels": [], "entities": []}, {"text": "While the free word order of Czech is a problem when translating to English (the text should be parsed first in order to determine the syntactic functions and the English word order), generating correct inflectional affixes is indeed a challenge for Englishto-Czech systems.", "labels": [], "entities": []}, {"text": "Furthermore, the multitude of possible Czech word forms (at least order of magnitude higher than in English) makes the data sparseness problem really severe, hindering both directions.", "labels": [], "entities": []}, {"text": "There are numerous ways how these issues could be addressed.", "labels": [], "entities": []}, {"text": "For instance, parsing and syntax-aware reordering of the source-language sentences can help with the word order differences (same goal could be achieved by a reordering model or asynchronous context-free grammar in a hierarchical system).", "labels": [], "entities": []}, {"text": "Factored translation, a secondary language model of morphological tags or even a morphological generator are some of the possible solutions to the poor-to-rich translation issues.", "labels": [], "entities": [{"text": "Factored translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6785369366407394}]}, {"text": "Our submission to the shared task should reveal where a pure hierarchical system stands in this jungle and what of the above mentioned ideas match the phenomena the system suffers from.", "labels": [], "entities": []}, {"text": "Although our primary focus lies on English-to-Czech translation, we also report the accuracy of the same system on moderately-sized corpora for the other three languages and seven translation directions.", "labels": [], "entities": [{"text": "English-to-Czech translation", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.6309621930122375}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9996758699417114}]}], "datasetContent": [{"text": "The set of baseline experiments with all translation directions involved running the system on lowercased News Commentary corpora.", "labels": [], "entities": [{"text": "News Commentary corpora", "start_pos": 106, "end_pos": 129, "type": "DATASET", "confidence": 0.8589117527008057}]}, {"text": "Word alignments were computed on 4-character stems (including the en-cs and cs-en directions).", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6693367511034012}]}, {"text": "A trigram language model was trained on the target side of the parallel corpus.", "labels": [], "entities": []}, {"text": "All BLEU scores were computed directly by Joshua on the News Test 2009 set.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9636614918708801}, {"text": "News Test 2009 set", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.9952990710735321}]}, {"text": "Note that they differ from what the official evaluation script would report, due to different tokenization.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of sentence pairs and tokens for  every language pair in the News Commentary cor- pus. Unlike the organizers of the shared task, we  stick with the standard ISO 639 language codes: cs  = Czech, de = German, en = English, es = Spanish,  fr = French.", "labels": [], "entities": []}, {"text": " Table 2: Number of sentences and tokens in the  Czech-English corpora.", "labels": [], "entities": []}, {"text": " Table 3: Lowercased BLEU scores of the baseline  experiments on News Test 2009 data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9861636757850647}, {"text": "News Test 2009 data", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.9925262331962585}]}, {"text": " Table 5: Feature weights are relative to the weight  of LM , the score by the language model. Then  there are the three translation features: P t 0 =  P (e|f ), P t 1 = P lex (f |e) and P t 2 = P lex (e|f ).  W P is the word penalty.", "labels": [], "entities": []}]}