{"title": [{"text": "Detecting Speculative Language Using Syntactic Dependencies and Logistic Regression", "labels": [], "entities": [{"text": "Detecting Speculative Language", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8874940474828085}]}], "abstractContent": [{"text": "In this paper we describe our approach to the CoNLL-2010 shared task on detecting speculative language in biomedical text.", "labels": [], "entities": [{"text": "detecting speculative language in biomedical text", "start_pos": 72, "end_pos": 121, "type": "TASK", "confidence": 0.6977056960264841}]}, {"text": "We treat the detection of sentences containing uncertain information (Task1) as a token classification task since the existence or absence of cues determines the sentence label.", "labels": [], "entities": []}, {"text": "We distinguish words that have speculative and non-speculative meaning by employing syntactic features as a proxy for their semantic content.", "labels": [], "entities": []}, {"text": "In order to identify the scope of each cue (Task2), we learn a classifier that predicts whether each token of a sentence belongs to the scope of a given cue.", "labels": [], "entities": []}, {"text": "The features in the classifier are based on the syntactic dependency path between the cue and the token.", "labels": [], "entities": []}, {"text": "In both tasks, we use a Bayesian logistic regression classifier incorporating a sparsity-enforcing Laplace prior.", "labels": [], "entities": []}, {"text": "Overall , the performance achieved is 85.21% F-score and 44.11% F-score in Task1 and Task2, respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.9991355538368225}, {"text": "F-score", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9984815716743469}]}], "introductionContent": [{"text": "The term speculative language, also known as hedging, refers to expressions of uncertainty over statements.", "labels": [], "entities": []}, {"text": "Recognition of such statements is important for higher-level applications.", "labels": [], "entities": [{"text": "Recognition of", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8988295793533325}]}, {"text": "For example, a multi-document summarization system can assign different weights to speculative and nonspeculative statements when aggregating information on a particular issue.", "labels": [], "entities": []}, {"text": "The CoNLL-2010 shared task () formulates speculative language detection as two subtasks.", "labels": [], "entities": [{"text": "formulates speculative language detection", "start_pos": 30, "end_pos": 71, "type": "TASK", "confidence": 0.8390338271856308}]}, {"text": "In the first subtask (Task1), systems need to determine whether a sentence contains uncertain information or not.", "labels": [], "entities": []}, {"text": "In the second subtask (Task2), systems need to identify the hedge cues and their scope in the sentence.", "labels": [], "entities": []}, {"text": "provides an example from the training data.", "labels": [], "entities": []}, {"text": "The participants are provided with data from two domains: biomedical scientific literature (both abstracts and full articles) and Wikipedia.", "labels": [], "entities": []}, {"text": "We choose to focus on the former.", "labels": [], "entities": []}, {"text": "The training data for this domain are nine full articles and 1,273 abstracts from the BioScope corpus ( and the test data are 15 full articles.", "labels": [], "entities": [{"text": "BioScope corpus", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.9359992146492004}]}, {"text": "Our approach to speculative language detection relies on syntactic parsing and machine learning.", "labels": [], "entities": [{"text": "speculative language detection", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.8473300933837891}, {"text": "syntactic parsing", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7442079186439514}]}, {"text": "We give a description of the techniques used in Sections 2 and 3.", "labels": [], "entities": []}, {"text": "We treat the detection of sentences containing uncertain information (Task1) as a token classification task in which we learn a classifier to predict whether a token is a cue or not.", "labels": [], "entities": [{"text": "detection of sentences containing uncertain information", "start_pos": 13, "end_pos": 68, "type": "TASK", "confidence": 0.7338765958944956}, {"text": "token classification task", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.8005257248878479}]}, {"text": "In order to handle words that have speculative and non-speculative meaning (e.g. \"indicating\" in the example of), we employ syntactic features as a proxy for their semantic content (Section 4).", "labels": [], "entities": []}, {"text": "For scope identification (Task2), we learn a classifier that predicts whether each token of the sentence belongs to the scope of a particular cue (Section 6).", "labels": [], "entities": [{"text": "scope identification", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8144241869449615}]}, {"text": "The features used are based on the syntactic dependency path between the cue and the token.", "labels": [], "entities": []}, {"text": "We report results and perform error analysis for both tasks, pointing out annotation issues that could be ameliorated (Sections 5 and 7).", "labels": [], "entities": []}, {"text": "Based on our experience we suggest improvements on the task definition taking into account work from the broader field (Section 8).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Performance of various feature sets on  Task1 using cross-validation on full articles.", "labels": [], "entities": []}, {"text": " Table 5: Performance of the final system in Task1.", "labels": [], "entities": []}, {"text": " Table 6: Performance on Task2 using cross- validation on BioScope full articles.", "labels": [], "entities": []}, {"text": " Table 7: Performance on cue identification and  cue/scope identification in", "labels": [], "entities": [{"text": "cue identification", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.8570965826511383}, {"text": "cue/scope identification", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.6382741332054138}]}]}