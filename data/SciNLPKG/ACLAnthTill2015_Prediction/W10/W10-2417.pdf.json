{"title": [{"text": "Simplified Feature Set for Arabic Named Entity Recognition", "labels": [], "entities": [{"text": "Arabic Named Entity Recognition", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.5422367304563522}]}], "abstractContent": [{"text": "This paper introduces simplified yet effective features that can robustly identify named entities in Arabic text without the need for morphological or syntactic analysis or gazetteers.", "labels": [], "entities": []}, {"text": "A CRF sequence labeling model is trained on features that primarily use character n-gram of leading and trailing letters in words and word n-grams.", "labels": [], "entities": [{"text": "CRF sequence labeling", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.8480041821797689}]}, {"text": "The proposed features help overcome some of the morphological and ortho-graphic complexities of Arabic.", "labels": [], "entities": []}, {"text": "In comparing to results in the literature using Arabic specific features such POS tags on the same dataset and same CRF implementation, the results in this paper are lower by 2 F-measure points for locations, but are better by 8 points for organizations and 9 points for persons.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.9954586029052734}]}], "introductionContent": [{"text": "Named entity recognition (NER) continues to bean important part of many NLP applications such as information extraction, machine translation, and question answering ( . NER is concerned with identifying sequences of words referring to named entities (NE's) such as persons, locations, and organizations.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8023158212502798}, {"text": "information extraction", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.8005041778087616}, {"text": "machine translation", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.7991782128810883}, {"text": "question answering", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.8427018523216248}, {"text": "identifying sequences of words referring to named entities (NE's) such as persons, locations, and organizations", "start_pos": 191, "end_pos": 302, "type": "TASK", "confidence": 0.7859234914183617}]}, {"text": "For example, in the word sequence \"Alan Mulally, CEO of Detroit based Ford Motor Company,\" Alan Mulally, Detroit, and Ford Motor Company would be identified as a person, a location, and an organization respectively.", "labels": [], "entities": []}, {"text": "Arabic is a Semitic language that present interesting morphological and orthographic challenges that may complicate NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.9636545181274414}]}, {"text": "Some of these challenges include: \uf0b7 Coordinating conjunctions, prepositions, possessive pronouns, and determiners are typically attached to words as prefixes or suffixes.", "labels": [], "entities": []}, {"text": "\uf0b7 Proper names are often common language words.", "labels": [], "entities": [{"text": "Proper names", "start_pos": 2, "end_pos": 14, "type": "TASK", "confidence": 0.7060783505439758}]}, {"text": "For example, the proper name \"Iman\" also means faith.", "labels": [], "entities": []}, {"text": "\uf0b7 Lack capitalization of proper nouns.", "labels": [], "entities": []}, {"text": "The paper introduces a simplified set of features that can robustly identify NER for Arabic without the need for morphological or syntactic analysis.", "labels": [], "entities": [{"text": "NER", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.8024309873580933}]}, {"text": "The proposed features include: word leading and trailing character n-gram features that help handle prefix and suffix attachment; word n-gram probability based features that attempt to capture the distribution of NE's in text; word sequence features; and word length.", "labels": [], "entities": [{"text": "prefix and suffix attachment", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.7664013206958771}]}, {"text": "The contributions of this paper are as follows: 1.", "labels": [], "entities": []}, {"text": "Identifying simplified features that work well for Arabic without gazetteers and without morphological and syntactic features, leading to improvements over previously reported results.", "labels": [], "entities": []}, {"text": "2. Using leading and trailing character n-grams in words, which help capture valuable morphological and orthographic clues that would indicate or counter-indicate the presence of NE's.", "labels": [], "entities": []}, {"text": "3. Incorporating word language modeling based features to capture word associations and relative distribution of named entities in text.", "labels": [], "entities": []}, {"text": "Conditional Random Fields (CRF) sequence labeling was used in identifying NE's, and the experiments were performed on two standard Arabic NER datasets.", "labels": [], "entities": [{"text": "Conditional Random Fields (CRF) sequence labeling", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.6600776389241219}, {"text": "identifying NE's", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.7291554609934489}, {"text": "Arabic NER datasets", "start_pos": 131, "end_pos": 150, "type": "DATASET", "confidence": 0.5852134128411611}]}, {"text": "The rest of the paper is organized as follows: Section 2 surveys prior work on Arabic NER; Section 3 introduces the proposed features and motivates their use; Section 4 describes experimental setup and evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper.", "labels": [], "entities": [{"text": "Arabic NER", "start_pos": 79, "end_pos": 89, "type": "TASK", "confidence": 0.5248317271471024}]}], "datasetContent": [{"text": "Locations (LOC) 867 Organizations (ORG) 269 Persons (PER) 524 Since both collections do not follow the same tagging conventions, training and testing were conducted separately for each collection.", "labels": [], "entities": []}, {"text": "Each collection was 80/20 split for training and testing.", "labels": [], "entities": []}, {"text": "The figures of merit for evaluation were precision, recall, and F-measure (\uf062 = 1), with evaluation being conducted at the phrase level.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9996336698532104}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9993403553962708}, {"text": "F-measure", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9991310238838196}]}, {"text": "Reporting experiments with all the different combinations of features would adversely affect the readability of the paper.", "labels": [], "entities": []}, {"text": "Thus, to ascertain the contribution of the different features, a set of 15 experiments are being reported for both datasets.", "labels": [], "entities": []}, {"text": "The experiments were conducted using raw Arabic words (3w) and stems (3s).", "labels": [], "entities": []}, {"text": "Using the short names of features (bolded after feature names in section 3), the experiments were as follows: report the best obtained results for both datasets.", "labels": [], "entities": []}, {"text": "The results include precision (P), recall (R), and Fmeasure (F) for NE's of types location (LOC), organization (ORG), and person (PER).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.955900102853775}, {"text": "recall (R)", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9510690569877625}, {"text": "Fmeasure (F)", "start_pos": 51, "end_pos": 63, "type": "METRIC", "confidence": 0.9556921571493149}]}, {"text": "The best results for P, R, and F are bolded in the tables.", "labels": [], "entities": [{"text": "F", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.9331505298614502}]}, {"text": "In comparing the base experiments 3w and 3s in which the only the surface forms and the stems were used respectively, both produced the highest precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9975214600563049}]}, {"text": "However, 3s improved recall over 3w by 7, 13, and 14 points for LOC, ORG, and PER respectively on the Benajiba dataset.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9997408986091614}, {"text": "LOC", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9919496774673462}, {"text": "ORG", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9881401062011719}, {"text": "PER", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9963430762290955}, {"text": "Benajiba dataset", "start_pos": 102, "end_pos": 118, "type": "DATASET", "confidence": 0.9870502352714539}]}, {"text": "Though using 3s led to a drop in P for ORG compared to 3w, it actually led to improvement in P for PER.", "labels": [], "entities": [{"text": "ORG", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.959112286567688}, {"text": "PER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.8054571747779846}]}, {"text": "Similar results were observed for the ACE dataset, but the differences were less pronounced with 1% to 2% improvements in recall.", "labels": [], "entities": [{"text": "ACE dataset", "start_pos": 38, "end_pos": 49, "type": "DATASET", "confidence": 0.9567924737930298}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9989892840385437}]}, {"text": "However, when including the 6bi, 6tri, and 6quad features the difference between using words or stems dropped to about 1 point in recall and nearly no difference in precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9988564252853394}, {"text": "precision", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.9978455305099487}]}, {"text": "This would indicate the effectiveness of using leading and trailing character n-grams in overcoming morphological and orthographic complexities., and 4 are macro-averages as opposed to micro-averages reported by . In comparing, the features suggested in this paper reduced F-measure for locations by 2 points, but improved Fmeasure for organizations and persons by 8 points and 9 points respectively, due to improvements in both precision and recall.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 273, "end_pos": 282, "type": "METRIC", "confidence": 0.9884003400802612}, {"text": "Fmeasure", "start_pos": 323, "end_pos": 331, "type": "METRIC", "confidence": 0.9982265830039978}, {"text": "precision", "start_pos": 429, "end_pos": 438, "type": "METRIC", "confidence": 0.9994290471076965}, {"text": "recall", "start_pos": 443, "end_pos": 449, "type": "METRIC", "confidence": 0.9978737831115723}]}], "tableCaptions": [{"text": " Table 1: NER results for the Benajiba and  ACE datasets", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.6521717309951782}, {"text": "Benajiba and  ACE datasets", "start_pos": 30, "end_pos": 56, "type": "DATASET", "confidence": 0.8206308782100677}]}, {"text": " Table 2: Best results on Benajiba dataset  (Run name: 3s_6bi_6tri_6quad_1gP)", "labels": [], "entities": [{"text": "Benajiba dataset", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.9776590168476105}]}, {"text": " Table 3: Best results on ACE dataset  (Run name: 3w_6bi_6tri_6quad_WL)", "labels": [], "entities": [{"text": "ACE dataset", "start_pos": 26, "end_pos": 37, "type": "DATASET", "confidence": 0.9402967691421509}]}]}