{"title": [{"text": "A Systematic Comparison between Inversion Transduction Grammar and Linear Transduction Grammar for Word Alignment", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.7433484792709351}]}], "abstractContent": [{"text": "We present two contributions to grammar driven translation.", "labels": [], "entities": [{"text": "grammar driven translation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.6665729284286499}]}, {"text": "First, since both Inversion Transduction Grammar and Linear Inversion Transduction Grammars have been shown to produce better alignments then the standard word alignment tool, we investigate how the trade-off between speed and end-to-end translation quality extends to the choice of grammar formalism.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 155, "end_pos": 169, "type": "TASK", "confidence": 0.7049673497676849}]}, {"text": "Second, we prove that Linear Transduction Grammars (LTGs) generate the same transduc-tions as Linear Inversion Transduction Grammars, and present a scheme for arriving at LTGs by bilingualizing Linear Grammars.", "labels": [], "entities": []}, {"text": "We also present a method for obtaining Inversion Transduction Grammars from Linear (Inversion) Transduc-tion Grammars, which can speedup grammar induction from parallel corpora dramatically.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we introduce Linear Transduction Grammars (LTGs), which are the bilingual case of Linear Grammars (LGs).", "labels": [], "entities": []}, {"text": "We also show that LTGs are equal to Linear Inversion Transduction Grammars (.", "labels": [], "entities": []}, {"text": "To be able to induce transduction grammars directly from parallel corpora an approximate search for parses is needed.", "labels": [], "entities": []}, {"text": "The trade-off between speed and end-toend translation quality is investigated and compared to Inversion Transduction Grammars () and the standard tool for word alignment,.", "labels": [], "entities": [{"text": "speed", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9614185690879822}, {"text": "Inversion Transduction Grammars", "start_pos": 94, "end_pos": 125, "type": "TASK", "confidence": 0.7159929076830546}, {"text": "word alignment", "start_pos": 155, "end_pos": 169, "type": "TASK", "confidence": 0.795597106218338}]}, {"text": "A heuristic for converting stochastic bracketing LTGs into stochastic bracketing ITGs is presented, and fitted into the speedquality trade-off.", "labels": [], "entities": []}, {"text": "In section 3 we give an overview of transduction grammars, introduce LTGs and show that they are equal to In section 4 we give a short description of the rational for the transduction grammar pruning used.", "labels": [], "entities": []}, {"text": "In section 5 we describe away of seeding a stochastic bracketing ITG with the rules and probabilities of a stochastic bracketing LTG.", "labels": [], "entities": []}, {"text": "Section 6 describes the setup, and results are given in section 7.", "labels": [], "entities": []}, {"text": "Finally, some conclusions are offered in section 8", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Size of training data.", "labels": [], "entities": [{"text": "Size of training", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.8259563048680624}]}, {"text": " Table 2: Results for the Spanish-English translation task.", "labels": [], "entities": [{"text": "Spanish-English translation task", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.7900973558425903}]}, {"text": " Table 3: Results for the French-English translation task.", "labels": [], "entities": [{"text": "French-English translation task", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.7261028190453848}]}, {"text": " Table 4: Results for the German-English translation task.", "labels": [], "entities": [{"text": "German-English translation task", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.7349227666854858}]}, {"text": " Table 5: Results for seeding an SBITG with an SBLTG (Both) compared to the pure approach. Total  time refers to 10 iterations of EM training for SBITG and SBLTG respectively, and 10 iterations of  SBLTG and one iteration of SBITG training for the combined system.", "labels": [], "entities": []}]}