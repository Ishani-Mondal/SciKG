{"title": [{"text": "Modeling Morphosyntactic Agreement in Constituency-Based Parsing of Modern Hebrew", "labels": [], "entities": [{"text": "Constituency-Based Parsing of Modern Hebrew", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.7176351904869079}]}], "abstractContent": [{"text": "We show that na\u00a8\u0131vena\u00a8\u0131ve modeling of morphosyn-tactic agreement in a Constituency-Based (CB) statistical parsing model is worse than none, whereas a linguistically adequate way of modeling inflectional morphology in CB parsing leads to improved performance.", "labels": [], "entities": [{"text": "Constituency-Based (CB) statistical parsing", "start_pos": 70, "end_pos": 113, "type": "TASK", "confidence": 0.5823169747988383}, {"text": "CB parsing", "start_pos": 217, "end_pos": 227, "type": "TASK", "confidence": 0.6832040399312973}]}, {"text": "In particular, we show that an extension of the Relational-Realizational (RR) model that incorporates agreement features is superior to CB models that treat morphosyntax as state-splits (SP), and that the RR model benefits more from inflectional features.", "labels": [], "entities": []}, {"text": "We focus on parsing Hebrew and report the best result to date, F 1 84.13 for parsing off of gold-tagged text, 5% error reduction from previous results.", "labels": [], "entities": [{"text": "parsing Hebrew", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.8860805928707123}, {"text": "F 1 84.13", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9831287066141764}, {"text": "parsing off of gold-tagged text", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.8169929504394531}, {"text": "error reduction", "start_pos": 113, "end_pos": 128, "type": "METRIC", "confidence": 0.9755678474903107}]}], "introductionContent": [{"text": "Agreement is defined by linguists as the systematic covariance of the grammatical properties of one linguistic element to reflect the semantic or formal properties of another.", "labels": [], "entities": []}, {"text": "Morphologically marked agreement features such as gender, number and person are used to realize grammatical relations between syntactic constituents, and such patterns are abundantly found in (less-or) nonconfigurational languages where the order of words is known to be (relatively) free.", "labels": [], "entities": []}, {"text": "Agreement features encompass information concerning the functional relations between constituents in the syntactic structure, but whether incorporating agreement features in a statistical parsing model leads to improved performance has so far remained an open question and saw contradictory results.", "labels": [], "entities": []}, {"text": "* The first author is currently a researcher at the department of Linguistics and Philology at Uppsala University.", "labels": [], "entities": [{"text": "Uppsala University", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.922139048576355}]}, {"text": "Taking Semitic languages as an example, it was shown that an SVM-based shallow parser) does not benefit from including agreement features for NP chunking in Hebrew.", "labels": [], "entities": [{"text": "NP chunking", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.8006733059883118}]}, {"text": "Phrase-structure based parsers for Arabic systematically discard morphological features from their label-set and never parametrize agreement explicitly (.", "labels": [], "entities": []}, {"text": "Models based on deep grammars such as CCG) and HPSG ( could in principle use inflectional morphology, but they currently rely on functional information mainly.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.8718092441558838}]}, {"text": "For formalisms that do incorporate morphology, generative models are may leak probability due to unification failures.", "labels": [], "entities": []}, {"text": "Even results from dependency parsing remain inconclusive.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8590583205223083}]}, {"text": "It was shown for dependency parsing that case, definiteness and animacy features are useful to enhance parsing (e.g.,), agreement patterns are often excluded.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8524020314216614}, {"text": "parsing", "start_pos": 103, "end_pos": 110, "type": "TASK", "confidence": 0.9651098251342773}]}, {"text": "When agreement features were included as features in dependency parser for Hebrew in for Hebrew they obtained tiny-to-no improvement.", "labels": [], "entities": []}, {"text": "A question thus emerges whether there are any benefits in explicitly incorporating morphosyntactic agreement patterns into our models.", "labels": [], "entities": []}, {"text": "This question is a manifestation of a greater issue, namely, whether it is beneficial to represent complex patterns of morphology in the statistical parsing model, or whether configurational information subsume the relevant patterns, as it is commonly assumed in constituencybased parsing.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.7001241147518158}, {"text": "constituencybased parsing", "start_pos": 263, "end_pos": 288, "type": "TASK", "confidence": 0.6954329907894135}]}, {"text": "Here we claim that agreement features are useful for statistical parsing provided that they are represented and parametrized in away that reflects their linguistic substance; to express functional information orthogonal to configuration.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.783468633890152}]}, {"text": "We do so by extending the RelationalRealizational (RR) model we presented in to explicitly encode agreement features in its native representation.", "labels": [], "entities": []}, {"text": "In the RR model, a joint distribution over grammatical relations is firstly articulated in the projection phase.", "labels": [], "entities": [{"text": "RR", "start_pos": 7, "end_pos": 9, "type": "TASK", "confidence": 0.9261919856071472}]}, {"text": "The grammatical relations maybe spelled out by positioning them with respect to one another in the configuration phase, through the use of morphology in the realization phase, or both.", "labels": [], "entities": []}, {"text": "This paper shows that, for Hebrew, this RR-AGR strategy significantly outperforms a constituency-based model that treats agreement features as internally structured non-terminal state-splits (SP-AGR).", "labels": [], "entities": []}, {"text": "As we accumulate morphological features, the performance gap between the RR and SP models becomes larger.", "labels": [], "entities": []}, {"text": "The best result we report for the RR-AGR model, F 1 84.13, is the best result reported for Hebrew to date for parsing gold PoS-tagged segments, with 5% error reduction from previous results.", "labels": [], "entities": [{"text": "F 1 84.13", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9705994129180908}, {"text": "parsing gold PoS-tagged segments", "start_pos": 110, "end_pos": 142, "type": "TASK", "confidence": 0.87632255256176}, {"text": "error", "start_pos": 152, "end_pos": 157, "type": "METRIC", "confidence": 0.9723791480064392}]}, {"text": "This result is also significantly higher than all parsing results reported so far for Arabic, a Semitic language with similar morphosyntactic phenomena.", "labels": [], "entities": []}, {"text": "The RR approach is shown to bean adequate way to model complex morphosyntactic patterns for improving constituency-based parsing of a morphologically rich, free word order language.", "labels": [], "entities": [{"text": "constituency-based parsing", "start_pos": 102, "end_pos": 128, "type": "TASK", "confidence": 0.7070393264293671}]}, {"text": "Because the RR model is also proper and generative, it may also embed as a language model to enhance more complex NLP tasks, e.g., statistical Machine Translation.", "labels": [], "entities": [{"text": "statistical Machine Translation", "start_pos": 131, "end_pos": 162, "type": "TASK", "confidence": 0.6862664520740509}]}], "datasetContent": [{"text": "We aim to examine whether the explicit incorporation of agreement features helps Hebrew parsing, and if so, which of the two modeling strategies is better for utilizing the disambiguation cues provided by morphosyntactic agreement.", "labels": [], "entities": [{"text": "Hebrew parsing", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7508511543273926}]}, {"text": "Data We use the Hebrew treebank v2.0 with the extended annotation of (, which adds inflectional properties to non-terminal categories such as NP and VP.", "labels": [], "entities": [{"text": "Hebrew treebank v2.0", "start_pos": 16, "end_pos": 36, "type": "DATASET", "confidence": 0.869732677936554}]}, {"text": "We head-annotate the corpus and systematically add the agreement features of Domains throughout the treebank.", "labels": [], "entities": []}, {"text": "We further distinguish finite from non-finite verb forms, and cliticized from non-cliticized nouns, as in ().", "labels": [], "entities": []}, {"text": "On top of the treebank labels SBJ subject, OBJ object, COM complement and CNJ conjunction we add PRD predicates and IC infinitival complements.", "labels": [], "entities": []}, {"text": "Procedure We devised a procedure to read-off treebank grammars based on (i) GPSG-like, statesplit context-free parameters (SP-AGR), and (ii) RR-AGR parameters in which context-free rules capture the projection, configuration and realization phases.", "labels": [], "entities": []}, {"text": "In each model the multiplication provides the probability of the generation.", "labels": [], "entities": []}, {"text": "We use relative frequency estimates and exhaustively parse gold pos-tagged input 8 using a general-purpose CKY parser.", "labels": [], "entities": []}, {"text": "We use the same data split as in () (training on sentences 501-6000 and parsing sentences 1-500) and we convert all trees to the flat, coarse-grained, original treebank representation for the purpose of evaluation.", "labels": [], "entities": []}, {"text": "Setup We experiment with bare constituent labels, grand-parent decorated labels (gp), and labels decorated with grand-parent and head-tag labels (gp,hd).", "labels": [], "entities": []}, {"text": "We use increasingly richer subsets of the {gender, definiteness, accusativity} set.", "labels": [], "entities": []}, {"text": "9 P configuration (\ue068S,P,O,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) P configuration (\ue068O,P,S,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": []}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9089569449424744}]}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9089569449424744}]}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "P configuration (\ue068S,P,O,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) P configuration (\ue068O,P,S,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": []}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "P configuration (\ue068S,P,O,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) P configuration (\ue068O,P,S,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": []}, {"text": "P configuration ( \ue068SBJ, SBJ:PRD, PRD, COM\ue069 | {SBJ,PRD,COM}@S FS ) P configuration ( \ue068SBJ, PRD, PRD:COM, COM\ue069 | {SBJ,PRD,COM}@S FS ) Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "FS", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.8505640625953674}]}, {"text": "P configuration (\ue068S,P,O,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) P configuration (\ue068O,P,S,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": []}, {"text": "P configuration ( \ue068SBJ, SBJ:PRD, PRD, COM\ue069 | {SBJ,PRD,COM}@S FS ) P configuration ( \ue068SBJ, PRD, PRD:COM, COM\ue069 | {SBJ,PRD,COM}@S FS ) Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "FS", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.8505640625953674}]}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "P configuration (\ue068S,P,O,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) P configuration (\ue068O,P,S,C\ue069 | {SBJ,PRD,OBJ,COM}@S MS ) Figure 1: The SP-AGR (top) and RR-AGR representations of sentences (2b-i) (left) and (2b-ii).", "labels": [], "entities": []}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.960888683795929}]}, {"text": "Figure 2: The SP-AGR (top) and RR-AGR representation of sentences (4c-i) (left) and (4c-ii).: F-score (#params) measure for all models on the Hebrew treebank dev-set for Sentences Length < 40 shows the standard F1 scores (and #param-eters) for all models.", "labels": [], "entities": [{"text": "RR-AGR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.947298526763916}, {"text": "F-score (#params) measure", "start_pos": 94, "end_pos": 119, "type": "METRIC", "confidence": 0.9205546259880066}, {"text": "F1", "start_pos": 211, "end_pos": 213, "type": "METRIC", "confidence": 0.9982056617736816}]}, {"text": "Throughout, the RR-AGR model outperforms the SP-AGR models that use the same category set and the same morphological features as state splits.", "labels": [], "entities": []}, {"text": "For RR-AGR and RR-AGR (gp) models, adding agreement features to case features improves performance.", "labels": [], "entities": []}, {"text": "The accumulative contribution is significant.", "labels": [], "entities": []}, {"text": "For SP-AGR and SP-AGR (gp) models, adding more features either remains at the same level of performance or becomes detrimental.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F-score (#params) measure for all models on  the Hebrew treebank dev-set for Sentences Length < 40", "labels": [], "entities": [{"text": "F-score (#params) measure", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8557570219039917}, {"text": "Hebrew treebank dev-set", "start_pos": 59, "end_pos": 82, "type": "DATASET", "confidence": 0.8343530495961508}]}]}