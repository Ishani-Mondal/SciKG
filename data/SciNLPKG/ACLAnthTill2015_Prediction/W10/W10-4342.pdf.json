{"title": [{"text": "Collaborating on Utterances with a Spoken Dialogue System Using an ISU-based Approach to Incremental Dialogue Management", "labels": [], "entities": [{"text": "Incremental Dialogue Management", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.7173263331254324}]}], "abstractContent": [{"text": "When dialogue systems, through the use of incremental processing, are not bounded anymore by strict, non-overlapping turn-taking, a whole range of additional interactional devices becomes available.", "labels": [], "entities": []}, {"text": "We explore the use of one such device, trial intonation.", "labels": [], "entities": []}, {"text": "We elaborate our approach to dialogue management in incremental systems, based on the Information-State-Update approach, and discuss an implementation in a micro-domain that lends itself to the use of immediate feedback, trial intonations and expansions.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7417968213558197}]}, {"text": "In an overhearer evaluation, the incremental system was judged as significantly more human-like and reactive than a non-incremental version.", "labels": [], "entities": []}], "introductionContent": [{"text": "In human-human dialogue, most utterances have only one speaker.", "labels": [], "entities": []}, {"text": "However, the shape that an utterance ultimately takes on is often determined not just by the one speaker, but also by her addressees.", "labels": [], "entities": []}, {"text": "A speaker intending to refer to something may start with a description, monitor while they goon whether the description appears to be understood sufficiently well, and if not, possibly extend it, rather than finishing the utterance in the form that was initially planned.", "labels": [], "entities": []}, {"text": "This monitoring within the utterance is sometimes even made very explicit, as in the following example from: (1) A: A man called Annegra?", "labels": [], "entities": [{"text": "Annegra", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.9134791493415833}]}, {"text": "-B: yeah, Allegra A: Allegra, uh, replied and, uh, . .", "labels": [], "entities": []}, {"text": "called a try marker, a \"questioning upward intonational contour, followed by a brief pause\".", "labels": [], "entities": []}, {"text": "As discussed by, this device is an efficient solution to the problem posed by uncertainty on the side of the speaker whether a reference is going to be understood, as it checks for understanding in situ, and lets the conversation partners collaborate on the utterance that is in production.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluating the contribution of one of the many modules in an SDS is notoriously difficult (.", "labels": [], "entities": []}, {"text": "To be able to focus on evaluation of the incremental dialogue strategies and avoid interference from ASR problems (and more technical problems; our system is still somewhat fragile), we opted for an overhearer evaluation.", "labels": [], "entities": [{"text": "ASR", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.9409444332122803}]}, {"text": "(Such a setting was also used for the test of the incremental system of (.)", "labels": [], "entities": []}, {"text": "We implemented a non-incremental version of the system that does not give non-linguistic feedback during user utterances and has only one, fixed, timeout of 800ms (comparable to typical settings in commercial dialogue systems).", "labels": [], "entities": []}, {"text": "Two of the authors then recorded 30 minutes of interactions with the two versions of the system.We then identified and discarded \"outlier\" interactions, i.e. those with technical problems, or where recognition problems were so severe that a nonunderstanding state was entered repeatedly.", "labels": [], "entities": []}, {"text": "These criteria were meant to be fair to both versions of the system, and indeed we excluded similar numbers of failed interactions from both versions (around 10 % of interactions in total).", "labels": [], "entities": []}, {"text": "We measured the length of interactions in the two sets, and found that the interactions in the incremental setting were significantly shorter (t-test, p < 0.005).", "labels": [], "entities": []}, {"text": "This was to be expected, of course, as the incremental strategies allow faster reactions (execution time can be folded into the user utterance); other outcomes would have been possible, though, if the incremental version had systematically more understanding problems.", "labels": [], "entities": []}, {"text": "We then had 8 subjects (university students, not involved in the research) watch and directly judge (questionnaire, Likert-scale replies to questions about human-likeness, helpfulness, and reactivity) 34 randomly selected interactions from either condition.", "labels": [], "entities": []}, {"text": "Human-likeness and reactivity were judged significantly higher for the incremental version (Wilcoxon rank-sum test; p < 0.05 and p < 0.005, respectively), while there was no effect for helpfulness (p = 0.06).", "labels": [], "entities": []}], "tableCaptions": []}