{"title": [], "abstractContent": [{"text": "Hierarchical Hidden Markov Model (HHMM) parsers have been proposed as psycholinguistic models due to their broad coverage within human-like working memory limits (Schuler et al., 2008) and ability to model human reading time behavior according to various complexity metrics (Wu et al., 2010).", "labels": [], "entities": []}, {"text": "But HHMMs have been evaluated previously only with very wide beams of several thousand parallel hypotheses, weakening claims to the model's efficiency and psychological relevance.", "labels": [], "entities": []}, {"text": "This paper examines the effects of varying beam width on parsing accuracy and speed in this model, showing that parsing accuracy degrades gracefully as beam width decreases dramatically (to 2% of the width used to achieve previous top results), without sacrificing gains over a baseline CKY parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.9817373752593994}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9009653329849243}, {"text": "parsing", "start_pos": 112, "end_pos": 119, "type": "TASK", "confidence": 0.9701091051101685}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.8621523380279541}]}], "introductionContent": [{"text": "Probabilistic parsers have been successful at accurately estimating syntactic structure from free text.", "labels": [], "entities": []}, {"text": "Typically, these systems work by considering entire sentences (or utterances) at once, using dynamic programming to obtain globally optimal solutions from locally optimal sub-parses.", "labels": [], "entities": []}, {"text": "However, these methods usually do not attempt to conform to human-like processing constraints, e.g. leading to center embedding and garden path effects (.", "labels": [], "entities": []}, {"text": "For systems prioritizing accurate parsing performance, there is little need to produce human-like errors.", "labels": [], "entities": []}, {"text": "But from a human modeling perspective, the success of globally optimized whole-utterance models raises the question of how humans can accurately parse linguistic input without access to this same global optimization.", "labels": [], "entities": []}, {"text": "This question creates a niche in computational research for models that are able to parse accurately while adhering as closely as possible to human-like psycholinguistic constraints.", "labels": [], "entities": []}, {"text": "Recent work on incremental parsers includes work on Hierarchical Hidden Markov Model (HHMM) parsers that operate in linear time by maintaining a bounded store of incomplete constituents (.", "labels": [], "entities": []}, {"text": "Despite this seeming limitation, corpus studies have shown that through the use of grammar transforms, this parser is able to cover nearly all sentences contained in the Penn Treebank () using a small number of unconnected memory elements.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 170, "end_pos": 183, "type": "DATASET", "confidence": 0.9952670633792877}]}, {"text": "But this bounded-memory parsing comes at a price.", "labels": [], "entities": [{"text": "bounded-memory parsing", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.6997262835502625}]}, {"text": "The HHMM parser obtains good coverage within human-like memory bounds only by pursuing an 'optionally arc-eager' parsing strategy, nondeterministically guessing which constituents can be kept open for attachment (occupying an active memory element), or closed for attachment (freeing a memory element for subsequent constituents).", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6289771795272827}]}, {"text": "Although empirically determining the number of parallel competing hypotheses used inhuman sentence processing is difficult, previous results in computational models have shown that human-like behavior can be elicited at very low levels of parallelism (), suggesting that large numbers of active hypotheses are not needed.", "labels": [], "entities": []}, {"text": "Previously, the HHMM parser has only been evaluated on large beam widths, leaving this aspect of its psycholinguistic plausibility untested.", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.6357790529727936}]}, {"text": "In this paper, the performance of an HHMM parser will be evaluated in two experiments that vary the amount of parallelism allowed during parsing, measuring the degree to which this degrades the system's accuracy.", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.5718957334756851}, {"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9949383735656738}]}, {"text": "In addition, the evaluation will compare the HHMM parser to an off-the-shelf probabilistic CKY parser to evaluate the actual run time performance at various beam widths.", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.6431008279323578}]}, {"text": "This serves two purposes, evaluating one aspect of the plausibility of this parsing framework as a psycholinguistic model, and evaluating its potential utility as a tool for operating on unsegmented text or speech.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parsing model described in Section 3 has previously been evaluated on the standard task of parsing the Wall Street Journal section of the Penn Treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9854501485824585}, {"text": "parsing the", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.902121514081955}, {"text": "Wall Street Journal section of the Penn Treebank", "start_pos": 107, "end_pos": 155, "type": "DATASET", "confidence": 0.8278380185365677}]}, {"text": "This evaluation was optimized for accuracy results, and reported a relatively wide beam width of 2000 to achieve its best results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9978175163269043}]}, {"text": "However, most psycholinguistic models of the human sentence processing mechanism suggest that if the HSPM does work in parallel, it does so with a much lower number of concurrent hypotheses ().", "labels": [], "entities": [{"text": "sentence processing mechanism", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.784879465897878}]}, {"text": "Viewing the HHMM parsing framework as a psycholinguistic model, a necessary (though not sufficient) condition for it being a valid model is that it be able to maintain relatively accurate parsing capabilities even at much lower beam widths.", "labels": [], "entities": [{"text": "HHMM parsing", "start_pos": 12, "end_pos": 24, "type": "TASK", "confidence": 0.7813969850540161}]}, {"text": "Thus, the first experiments in this paper evaluate the degradation of parsing accuracy depending on beam width of the HHMM parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.9821934700012207}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.8801890015602112}, {"text": "HHMM parser", "start_pos": 118, "end_pos": 129, "type": "DATASET", "confidence": 0.7976284325122833}]}, {"text": "Experiments were conducted again on the WSJ Penn Treebank, using sections 02-21 to train, and section 23 as the test set.", "labels": [], "entities": [{"text": "WSJ Penn Treebank", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.8549149831136068}]}, {"text": "Punctuation was included in both training and testing.", "labels": [], "entities": [{"text": "Punctuation", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9782022833824158}]}, {"text": "A set of varied beam widths were considered, from a high of 2000 to a low of 15.", "labels": [], "entities": []}, {"text": "This range was meant to roughly correspond to the range of parallelism used in other similar experiments, using 2000 as a high end due to its usage in previous parsing experiments.", "labels": [], "entities": []}, {"text": "However, it should be noted that in fact the highest value of 2000 is already an approximate search -preliminary experiments showed that exhaustive search with the HHMM would require more than 100000 elements per time step (exact values maybe much higher but could not be collected because they exhausted system memory).", "labels": [], "entities": [{"text": "HHMM", "start_pos": 164, "end_pos": 168, "type": "DATASET", "confidence": 0.9660502076148987}]}, {"text": "The HHMM parser was compared to a custom built (though standard) probabilistic CKY parser implementation trained on the CNF trees used as input to the right-corner transform, so that the CKY parser was able to compete on a fair footing.", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6091329157352448}]}, {"text": "The accuracy results of these experiments are shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996050000190735}]}, {"text": "These results show fairly graceful decline in parsing accuracy with abeam width starting at 2000 elements down to about 50 beam elements.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.977259635925293}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9785929322242737}]}, {"text": "This beam width is much less than 1% of the exhaustive search, though it is around 1% of what might be considered the highest reasonable beam width for efficient parsing.", "labels": [], "entities": []}, {"text": "The lowest beam widths attempted, 15, 20, and 25, result inaccuracy below that of the CKY parser.", "labels": [], "entities": [{"text": "beam widths", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.9100871086120605}, {"text": "CKY parser", "start_pos": 86, "end_pos": 96, "type": "DATASET", "confidence": 0.9391370117664337}]}, {"text": "The lowest beam width attempted, 15, shows the sharpest decline inaccuracy, putting the HHMM system nearly 8 points below the CKY parser in terms of accuracy.", "labels": [], "entities": [{"text": "HHMM", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.6870622038841248}, {"text": "CKY parser", "start_pos": 126, "end_pos": 136, "type": "DATASET", "confidence": 0.8210093080997467}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9983439445495605}]}, {"text": "This compares reasonably well to results by   showing that an incremental chart-parsing algorithm can parse accurately with pruning down to 1% of normal memory usage.", "labels": [], "entities": []}, {"text": "While that parsing algorithm is difficult to compare directly to this HHMM parser, the reduction in beam width in this system to 50 beam elements from an already approximated 2000 beam elements shows similar robustness to approximation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 11, "end_pos": 18, "type": "TASK", "confidence": 0.9629785418510437}]}, {"text": "Accuracy comparisons should betaken with a grain of salt due to additional annotations performed to the Treebank before training, but the HHMM parser with abeam width of 50 obtains approximately the same accuracy as the Brants and Crocker incremental CKY parser pruning to 3% of chart size.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9796643257141113}, {"text": "HHMM parser", "start_pos": 138, "end_pos": 149, "type": "TASK", "confidence": 0.6057977974414825}, {"text": "accuracy", "start_pos": 204, "end_pos": 212, "type": "METRIC", "confidence": 0.9991644620895386}]}, {"text": "At 1% pruning, Brants and Crocker achieved around 75% accuracy, which falls between the HHMM parser at beam widths of 20 and 25.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9996738433837891}, {"text": "HHMM parser", "start_pos": 88, "end_pos": 99, "type": "DATASET", "confidence": 0.8075487017631531}]}, {"text": "Results by are also difficult to compare directly due to a difference in parsing algorithm and different research priority (that paper was attempting to correlate parsing difficulty with reading difficulty).", "labels": [], "entities": [{"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9744860529899597}]}, {"text": "However, that paper showed that a dependency parser using less than ten beam elements (and as few as one) was just as capable of predicting reading difficulty as the parser using 100 beam elements.", "labels": [], "entities": []}, {"text": "A second experiment was conducted to evaluate the HHMM for its time efficiency in parsing.", "labels": [], "entities": [{"text": "HHMM", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.8494325876235962}, {"text": "parsing", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.9704380035400391}]}, {"text": "This experiment is intended to address two questions: Whether this framework is efficient enough to be considered a viable psycholinguistic model, and whether its parsing time and accuracy remain competitive with more standard cubic time parsing technologies at low beam widths.", "labels": [], "entities": [{"text": "parsing", "start_pos": 163, "end_pos": 170, "type": "TASK", "confidence": 0.9738730192184448}, {"text": "accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9981039762496948}]}, {"text": "To evaluate this aspect, the HHMM parser was run at low beam widths on sentences of varying lengths.", "labels": [], "entities": []}, {"text": "The baseline was the widely-used Stanford parser, run in 'vanilla PCFG' mode.", "labels": [], "entities": []}, {"text": "This parser was used rather than the custom-built CKY parser from the previous experiment, to avoid the possibility that its implementation was not efficient enough to provide a realistic test.", "labels": [], "entities": []}, {"text": "The HHMM parser was implemented as described in the previous section.", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8103561103343964}]}, {"text": "These experiments were run on a machine with a single 2.40 GHz Celeron CPU, with 512 MB of RAM.", "labels": [], "entities": []}, {"text": "In both implementations the parser timing includes only time spent actually parsing sentences, ignoring the overhead incurred by reading in model files or training.", "labels": [], "entities": []}, {"text": "shows a plot of parsing time versus sentence length for the HHMM parser fora beam width of 20.", "labels": [], "entities": [{"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9698618054389954}, {"text": "HHMM", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.8701425194740295}]}, {"text": "Sentences shorter than 10 words were not included for visual clarity (both parsers are extremely fast at that length).", "labels": [], "entities": []}, {"text": "At this beam width, the performance of the HHMM parser (labeled Fscore) was 74.03%, compared to 71% fora plain CKY parser.", "labels": [], "entities": []}, {"text": "As expected, the HHMM parsing time increases linearly with sentence length, while the CKY parsing time increases super-linearly.", "labels": [], "entities": [{"text": "HHMM parsing", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.6435230076313019}, {"text": "CKY parsing", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.7041053175926208}]}, {"text": "(However, due to high constants in the run time complexity of the HHMM, it was not a priori clear that the HHMM would be faster for any sentence of reasonable length.)", "labels": [], "entities": []}, {"text": "The results of this experiment show that the HHMM parser is indeed competitive with a probabilistic CKY parser, in terms of parsing efficiency, even while parsing with higher accuracy.", "labels": [], "entities": [{"text": "HHMM parser", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.6778530776500702}, {"text": "parsing", "start_pos": 124, "end_pos": 131, "type": "TASK", "confidence": 0.9658721089363098}, {"text": "parsing", "start_pos": 155, "end_pos": 162, "type": "TASK", "confidence": 0.9666154384613037}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9944721460342407}]}, {"text": "At sentences longer that 26 words (including punctuation), the HHMM parser is faster than the CKY parser.", "labels": [], "entities": []}, {"text": "This advantage is clear for segmented text such as the Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.973421111702919}]}, {"text": "However, this advantage is compounded when considering unsegmented or ambiguously segmented text such as transcribed speech or less formal written text, as the HHMM parser can also make decisions about whereto put sentence breaks, and do so in linear time.", "labels": [], "entities": []}], "tableCaptions": []}