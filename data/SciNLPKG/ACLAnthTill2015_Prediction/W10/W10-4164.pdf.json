{"title": [{"text": "Chinese Word Sense Induction with Basic Clustering Algorithms", "labels": [], "entities": [{"text": "Chinese Word Sense Induction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6155773401260376}]}], "abstractContent": [{"text": "Word Sense Induction (WSI) is an important topic in natural langage processing area.", "labels": [], "entities": [{"text": "Word Sense Induction (WSI)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7846466501553854}]}, {"text": "For the bakeoff task Chinese Word Sense Induction (CWSI), this paper proposes two systems using basic clustering algorithms, k-means and agglomerative clustering.", "labels": [], "entities": [{"text": "bakeoff task Chinese Word Sense Induction (CWSI)", "start_pos": 8, "end_pos": 56, "type": "TASK", "confidence": 0.7131914297739664}]}, {"text": "Experimental results show that k-means achieves a better performance.", "labels": [], "entities": []}, {"text": "Based only on the data provided by the task organizers, the two systems get FScores of 0.7812 and 0.7651 respectively.", "labels": [], "entities": [{"text": "FScores", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9989670515060425}]}], "introductionContent": [{"text": "Word Sense Induction (WSI) or Word Sense Discrimination is a task of automatically discovering word senses from un-annotated text.", "labels": [], "entities": [{"text": "Word Sense Induction (WSI)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.752404659986496}, {"text": "Word Sense Discrimination", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.567315677801768}, {"text": "automatically discovering word senses from un-annotated text", "start_pos": 69, "end_pos": 129, "type": "TASK", "confidence": 0.5172624247414725}]}, {"text": "It is distinct from Word Sense Disambiguation (WSD) where the senses are assumed to be known and the aim is to decide the right meaning of the target word in context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.801910604039828}]}, {"text": "WSD generally requires the use of large-scale manually annotated lexical resources, while WSI can overcome this limitation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6090785264968872}]}, {"text": "Furthermore, automatically induced word senses can improve performance on many natural language processing tasks such as information retrieval), information extraction) and machine translation (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 121, "end_pos": 142, "type": "TASK", "confidence": 0.7455582618713379}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.8227903246879578}, {"text": "machine translation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.816900372505188}]}, {"text": "WSI is typically treated as a clustering problem.", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9513804912567139}]}, {"text": "The input is instances of the ambiguous word with their accompanying contexts and the output is a grouping of these instances into classes corresponding to the induced senses.", "labels": [], "entities": []}, {"text": "In other words, contexts that are grouped together in the same class represent a specific word sense.", "labels": [], "entities": []}, {"text": "The task can be formally defined as a two stage process, feature selection and word clustering.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.76555997133255}]}, {"text": "The first stage determines which context features to consider when comparing similarity between words, while the second stage apply some process that clusters similar words using the selected features.", "labels": [], "entities": []}, {"text": "So the simplest approaches to WSI involve the use of basic word cooccurrence features and application of classical clustering algorithms, more sophisticated techniques improve performance by introducing new context features, novel clustering algorithms, or both.) makes a comprehensive survey of techniques for unsupervised word sense induction.", "labels": [], "entities": [{"text": "WSI", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9808382391929626}, {"text": "word sense induction", "start_pos": 324, "end_pos": 344, "type": "TASK", "confidence": 0.7004489600658417}]}, {"text": "Two tasks on English Word Sense Induction were held on SemEval2007 ( and) respectively, which greatly promote the research of English WSI.", "labels": [], "entities": [{"text": "English Word Sense Induction", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.5985021144151688}, {"text": "SemEval2007", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9036537408828735}, {"text": "English WSI", "start_pos": 126, "end_pos": 137, "type": "TASK", "confidence": 0.4949977397918701}]}, {"text": "However, the study on Chinese Word Sense Induction (CWSI) is inadequate, and Chinese word senses have their own characteristics.", "labels": [], "entities": [{"text": "Chinese Word Sense Induction (CWSI)", "start_pos": 22, "end_pos": 57, "type": "TASK", "confidence": 0.7066135108470917}]}, {"text": "The methods that work well in English may notwork well in Chinese.", "labels": [], "entities": []}, {"text": "So, as an exploration, this paper proposes simple approaches utilizing basic features and basic clustering algorithms, such as partitional method k-means and hierarchical agglomerative method.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly introduces the basic clustering algorithms.", "labels": [], "entities": []}, {"text": "Section 3 describes the feature set.", "labels": [], "entities": []}, {"text": "Section gives experimental details and analysis.", "labels": [], "entities": []}, {"text": "Conclusions and future work are given in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The official performance metric for the CWSI task is FScore ().", "labels": [], "entities": [{"text": "CWSI task", "start_pos": 40, "end_pos": 49, "type": "TASK", "confidence": 0.8550866842269897}, {"text": "FScore", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9971810579299927}]}, {"text": "Given a particular class Ci of size n i and a cluster Sr of size n r , suppose i r n examples in the class Ci belong to Sr . The F value of this class and cluster is defined to be: where c is the number of classes and n is the size of the clustering solution.", "labels": [], "entities": [{"text": "F", "start_pos": 129, "end_pos": 130, "type": "METRIC", "confidence": 0.9790342450141907}]}, {"text": "Another two metrics,), are also employed in this paper to measure our system performance.", "labels": [], "entities": []}, {"text": "Entropy measures how the various classes of word senses are distributed within each cluster, while Purity measures the extent to which each cluster contained word senses from primarily one class.", "labels": [], "entities": [{"text": "Purity", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9278919100761414}]}, {"text": "The entropy of cluster Sr is defined as The above three metrics are defined to evaluate the result of a single target word.", "labels": [], "entities": []}, {"text": "Macro average metrics are used to evaluate the overall performance of all the target words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Distribution of sense numbers  sense number 2 3 4 6 7 8 21  trial set  39 9 1 0 0 0 1  test set  77 10 7 4 1 1 0", "labels": [], "entities": []}, {"text": " Table 2. Distribution of relations between target  words and segmented words  relation type 1  2  3  4 Total  trial set  2314 105 68 12 2499  test set  4031 710 212 47 5000", "labels": [], "entities": [{"text": "Distribution of relations between target  words and segmented words", "start_pos": 10, "end_pos": 77, "type": "TASK", "confidence": 0.767973866727617}]}, {"text": " Table 3. Result comparison on the trial data  Entropy  Purity  k-means  0.4858  0.8288  agglomerative 0.5328  0.8020", "labels": [], "entities": []}, {"text": " Table 5. System ranking  Rank  FScore Rank  FScore  1  0.7933 6  0.7788  2  0.7895 7  0.7729  3  0.7855 8*  0.7651  4  0.7849 9  0.7598  5*  0.7812 18  0.5789", "labels": [], "entities": []}]}