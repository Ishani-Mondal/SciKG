{"title": [{"text": "Toward a Totally Unsupervised, Language-Independent Method for the Syllabification of Written Texts", "labels": [], "entities": [{"text": "Syllabification of Written Texts", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.8888643682003021}]}], "abstractContent": [{"text": "Unsupervised algorithms for the induction of linguistic knowledge should at best require as few basic assumptions as possible and at the same time in principle yield good results for any language.", "labels": [], "entities": [{"text": "induction of linguistic knowledge", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.8625787496566772}]}, {"text": "However , most of the time such algorithms are only tested on a few (closely related) languages.", "labels": [], "entities": []}, {"text": "In this paper, an approach is presented that takes into account typological knowledge in order to induce syllabic divisions in a fully automatic manner based on reasonably-sized written texts.", "labels": [], "entities": []}, {"text": "Our approach is able to account for syllable structures of languages where other approaches would fail, thereby raising the question whether computational methods can really be claimed to be language-universal when they are not tested on the variety of structures that are found in the languages of the world.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many approaches developed in the field of computational linguistics are only tested and optimized for one language (mostly English) or a small set of closely related languages, but at the same time are often claimed to be applicable to any natural language, cf..", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7243763208389282}]}, {"text": "Our aim is to stress the importance of having a more varied sample of languages that include the different types that can be found in the languages of the world in order to do justice to the range of variation in linguistic structures across languages.", "labels": [], "entities": []}, {"text": "Furthermore, we want to point to the usefulness of using typological knowledge fora language-universal approach.", "labels": [], "entities": []}, {"text": "In this paper, we present an unsupervised, language-independent syllabification method based on raw unannotated texts in a phonemic transcription.", "labels": [], "entities": []}, {"text": "The methods and procedures presented in this work rest upon insights from typological work and do not need any additional language-dependent information.", "labels": [], "entities": []}, {"text": "The main purpose of this paper is not to present an improvement on already established statistical approaches to the problem of syllabification of an individual language, but to introduce data from languages that might constitute a problem for many syllabification methods that have been optimized on languages like English and therefore make it necessary to integrate an additional component that is able to handle such cases.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, it is argued in Section 2 that orthographic texts (in any alphabetic script) can be used for the induction of phonological patterns if the spelling system is reasonably close to a phonemic transcription.", "labels": [], "entities": [{"text": "induction of phonological patterns", "start_pos": 104, "end_pos": 138, "type": "TASK", "confidence": 0.8585675358772278}]}, {"text": "The syllabification process can be divided into two steps.", "labels": [], "entities": []}, {"text": "In Section 3, we present and evaluate an algorithm for an unsupervised classification of all symbols in the input texts into vowels and consonants.", "labels": [], "entities": []}, {"text": "Based on this classification, a syllabification procedure is discussed that makes use of distributional information of clusters in order to breakup vowel and consonant sequences into syllables (Section 4).", "labels": [], "entities": []}, {"text": "Finally, we conclude with a discussion of the advantages and disadvantages of the present approach and its implications for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "To the best of our knowledge, the algorithm has never been tested on a larger cross-linguistic sample.", "labels": [], "entities": []}, {"text": "There are results fora number of languages in Sukhotin's original papers, in and in, yet almost all languages in those samples belong to the IndoEuropean family (except for Georgian, Hungarian and Finnish) or do not fulfill the criterion of a phonemic transcription (Hebrew).", "labels": [], "entities": []}, {"text": "It therefore still needs to be tested on a more cross-linguistic sample of languages.", "labels": [], "entities": []}, {"text": "In particular, it is an interesting question to see if the algorithm works even for those languages that are notorious for having many consonant clusters.", "labels": [], "entities": []}, {"text": "On the basis of his sample of five languages, Sassoon (1992) comes to the conclusion that it works very well on those languages that have only few consonant clusters but has problems when more complex clusters are involved.", "labels": [], "entities": []}, {"text": "However, he also notices that this effect disappears with larger text samples.", "labels": [], "entities": []}, {"text": "provides an evaluation of Sukhotin's algorithm on the basis of Bible texts (NT) in our sample of 39 languages.", "labels": [], "entities": []}, {"text": "The size of the corpora in Sassoon's sample range from 1641 to 3781 characters while the Bible texts contain more than 100,000 characters (e.g., English has 716,301 characters).", "labels": [], "entities": []}, {"text": "On average, Sukhotin's algorithm classifies 95.66% of the symbols correctly.", "labels": [], "entities": []}, {"text": "However, this percentage also includes those languages which do not fulfill the criterion of having a suitable phonemic writing system (e.g., Russian, English, German, French).", "labels": [], "entities": []}, {"text": "When looking only at those languages whose spelling systems are close to a phonemic transcription (or where the digraphs have been sub-stituted by single symbols), the results are even better.", "labels": [], "entities": []}, {"text": "Misclassified symbols are either very infrequent and happen to occur next to symbols of the same class or are part of one of the digraphs used in the spelling system of the language.", "labels": [], "entities": []}, {"text": "In the Maltese case, the symbol \u00ee is classified as a consonant because it only occurs twice in the corpus in the word elo\u00ee where it stands next to a symbol that is clearly a vowel.", "labels": [], "entities": []}, {"text": "For some languages, minor modifications to the original texts have been made in order to replace the most frequent digraphs.", "labels": [], "entities": []}, {"text": "In Swahili, for instance, with the official orthography the symbol c is classified as a vowel because it only occurs in the digraph ch.", "labels": [], "entities": []}, {"text": "After the digraph has been replaced by a single symbol, the classification is correct in all cases.", "labels": [], "entities": []}, {"text": "Sometimes a symbol (e.g., h in Warlpiri) is misclassified because it does not occur in the writing system of the language but is part of a digraph in foreign words (mostly proper names of people or locations in the Bible texts).", "labels": [], "entities": []}, {"text": "Another problem of the approach is with orthographies that use the same symbol for both vowels and consonants.", "labels": [], "entities": []}, {"text": "Since the classification is global, symbols like English y, which is a consonant in yoghurt and a vowel in lady, are always treated as either a vowel or a consonant for the whole language independent of the context where they occur.", "labels": [], "entities": []}, {"text": "Therefore symbols in the input text should always be able to be classified to one or the other category.", "labels": [], "entities": []}, {"text": "As the discussion of misclassified symbols shows, the main errors in the results are not due to the algorithm itself, but a problem of the spelling systems of the texts at hand.", "labels": [], "entities": []}, {"text": "Our results confirm the findings of that the algorithm is sensitive to the corpus size and the frequency of occurrence of individual symbols.", "labels": [], "entities": []}, {"text": "Larger corpora, such as Bible texts, yield much better results for these languages.", "labels": [], "entities": []}, {"text": "Even those languages with many and very complex consonant clusters (e.g., Georgian, Croatian and Czech) get an almost perfect classification.", "labels": [], "entities": []}, {"text": "It is remarkable that the overall distribution of the symbols makes up for those cases where consonants frequently occur in clusters.", "labels": [], "entities": []}, {"text": "Experiments with smaller corpus sizes also revealed that one of the first symbols that get wrongly classified is the sibilant s.", "labels": [], "entities": []}, {"text": "This might be another indicator for the exceptional status of sibilants with respect to syllabification and their occurrence in consonant sequences where they can violate the sonority principle (e.g., in the sequence str in words like string the consonant sis to the left of the consonant t although higher in sonority).", "labels": [], "entities": []}, {"text": "One of the problems of a cross-linguistic investigation is the availability of gold standards for evaluation.", "labels": [], "entities": []}, {"text": "Thus, instead of providing a comparative evaluation, we want to discuss the advantages and disadvantages of the procedure with respect to the more common sonority-based syllabification method.", "labels": [], "entities": []}, {"text": "We tested our method on a manually created gold standard of 1,000 randomly selected words in Latin.", "labels": [], "entities": []}, {"text": "The precision is 92.50% and the recall 94.96% (F-Score 0.94) for each transition from one symbol to another.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995825886726379}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9995362758636475}, {"text": "F-Score 0.94)", "start_pos": 47, "end_pos": 60, "type": "METRIC", "confidence": 0.9604247609774271}]}, {"text": "Most misplaced syllable boundaries are due to the vowel cluster io, which has been treated as a diphthong by our method.", "labels": [], "entities": []}, {"text": "The most interesting aspect of our approach is that it is able to account for those languages where intervocalic consonants are better be analyzed as belonging to the previous syllable, thereby violating OMP.", "labels": [], "entities": []}, {"text": "Approaches relying on the Onset Maximization Principle would get all of these syllable boundaries wrong.", "labels": [], "entities": [{"text": "Onset Maximization", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.6242108643054962}]}, {"text": "note that Arrernte also has only VC in word-initial position.", "labels": [], "entities": [{"text": "Arrernte", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.8818582892417908}, {"text": "VC", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9563316106796265}]}, {"text": "Consequently, an approach that is based on word-peripheral clusters can predict the lack of word-medial onsets correctly.", "labels": [], "entities": []}, {"text": "The importance of word-peripheral clusters is also supported by findings in where a bigram model improves after training with Expectation Maximization whereas a positional model does not, which might be due to the fact that a bigram model (unlike the positional model) can generalize whatever it learns about clusters no matter if they occur at word edges or word-medially.", "labels": [], "entities": [{"text": "Expectation Maximization", "start_pos": 126, "end_pos": 150, "type": "TASK", "confidence": 0.8799724876880646}]}, {"text": "Moreover, the influence of word-peripheral clusters on the syllabification of word-medial consonant sequences is not restricted to syllable types only, but sometimes also holds solely for individual consonants.", "labels": [], "entities": []}, {"text": "In Chamorro, for instance, describes the syllabification of intervocalic consonants as observing OMP.", "labels": [], "entities": []}, {"text": "However, this does not apply if the consonant is the glottal stop /'/, in which case the syllable division occurs after the consonant, leading to the syllabification /na'.i/ 'to give'.", "labels": [], "entities": []}, {"text": "The interesting observation in this respect is that the glottal stop phonologically never occurs at the beginning of a word in Chamorro whereas all other consonants (with the exception of /w/) do occur word-initially, 9 which leads to the correct syllabification results with our approach.", "labels": [], "entities": []}, {"text": "Another advantage of the present method is that clusters with sibilant consonants that do not conform to the sonority principle (see the example of str in Section 3.3) do not have to be treated differently.", "labels": [], "entities": []}, {"text": "They merely follow from the fact that these clusters are particularly frequent in wordperipheral position.", "labels": [], "entities": []}, {"text": "The biggest disadvantage is the fact that the method is sensitive to frequencies of individual clusters and thereby sometimes breaks up clusters that should be tautosyllabic (one of the few examples in our Latin corpus was teneb.rae).", "labels": [], "entities": []}], "tableCaptions": []}