{"title": [{"text": "A Lucene and Maximum Entropy Model Based Hedge Detection System", "labels": [], "entities": [{"text": "Hedge Detection", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.6692693680524826}]}], "abstractContent": [{"text": "This paper describes the approach to hedge detection we developed, in order to participate in the shared task at CoNLL-2010.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.942055732011795}, {"text": "CoNLL-2010", "start_pos": 113, "end_pos": 123, "type": "DATASET", "confidence": 0.9034568667411804}]}, {"text": "A supervised learning approach is employed in our implementation.", "labels": [], "entities": []}, {"text": "Hedge cue annotations in the training data are used as the seed to build a reliable hedge cue set.", "labels": [], "entities": []}, {"text": "Maximum Entropy (MaxEnt) model is used as the learning technique to determine uncertainty.", "labels": [], "entities": []}, {"text": "By making use of Apache Lucene, we are able to do fuzzy string match to extract hedge cues, and to incorporate part-of-speech (POS) tags in hedge cues.", "labels": [], "entities": []}, {"text": "Not only can our system determine the certainty of the sentence, but is also able to find all the contained hedges.", "labels": [], "entities": [{"text": "certainty", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9977194666862488}]}, {"text": "Our system was ranked third on the Wikipedia dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 35, "end_pos": 52, "type": "DATASET", "confidence": 0.9799010157585144}]}, {"text": "In later experiments with different parameters, we further improved our results, with a 0.612 F-score on the Wikipedia dataset, and a 0.802 F-score on the biological dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9980097413063049}, {"text": "Wikipedia dataset", "start_pos": 109, "end_pos": 126, "type": "DATASET", "confidence": 0.9918615520000458}, {"text": "F-score", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.996678352355957}, {"text": "biological dataset", "start_pos": 155, "end_pos": 173, "type": "DATASET", "confidence": 0.7065883725881577}]}], "introductionContent": [{"text": "A hedge is a mitigating device used to lessen the impact of an utterance . As a very important way to precisely express the degree of accuracy and truth assessment inhuman communication, hedging is widely used in both spoken and written languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9985905289649963}]}, {"text": "Detecting hedges in natural language text can be very useful for areas like text mining and information extraction.", "labels": [], "entities": [{"text": "text mining", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.8544569611549377}, {"text": "information extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.9059396982192993}]}, {"text": "For example, in opinion mining, hedges can be used to assess the degree of sentiment, and refine sentiment classes from {positive, negative, objective} to {positive, somehow positive, objective, somehow objective, negative, somehow negative}.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8569056689739227}]}, {"text": "Hedge detection related work has been conducted by several people.", "labels": [], "entities": [{"text": "Hedge detection related", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9797030886014303}]}, {"text": "started to do annotations on biomedicine article abstracts, and conducted the preliminary work of automatic classification for uncertainty.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.5952097028493881}]}, {"text": "devised detailed guidelines for hedge annotations, and used a probabilistic weakly supervised learning approach to classify hedges.", "labels": [], "entities": [{"text": "hedge annotations", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7477328479290009}]}, {"text": "took Wikipedia articles as training corpus, used weasel words' frequency and syntactic patterns as features to classify uncertainty.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 shows the architecture of our system.", "labels": [], "entities": []}, {"text": "Section 3 explains how we make use of Apache Lucene to do fuzzy string match and incorporate POS tag in hedge cues and our method to generate hedge cue candidates.", "labels": [], "entities": []}, {"text": "Section 4 describes the details of using MaxEnt model to classify uncertainty.", "labels": [], "entities": []}, {"text": "We present and discuss experiments and results in section 5, and conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first ran experiments to evaluate the performance of the entire system.", "labels": [], "entities": []}, {"text": "We used official dataset as training and testing, with different confidence and support thresholds.", "labels": [], "entities": [{"text": "confidence", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.97550368309021}]}, {"text": "The result on official Wikipedia dataset is presented in.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.9605503678321838}]}, {"text": "Result on the biological dataset is listed in.", "labels": [], "entities": [{"text": "biological dataset", "start_pos": 14, "end_pos": 32, "type": "DATASET", "confidence": 0.7619597017765045}]}, {"text": "In the result tables, the first 2 columns are the confidence and support threshold; \"Cues\" is the number of generated hedge cues; the last 3 columns are standard classifier evaluation measures.", "labels": [], "entities": [{"text": "Cues\"", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.938470721244812}]}, {"text": "Our submitted result used 0.35, 5 as the thresholds for confidence and support.", "labels": [], "entities": [{"text": "confidence", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.990798830986023}, {"text": "support", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.8866099715232849}]}, {"text": "We officially placed third on the Wikipedia dataset, with a 0.5741 F-score, and third from last on the biological dataset, with a 0.7692 F-score.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.977065235376358}, {"text": "F-score", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.9972196817398071}, {"text": "biological dataset", "start_pos": 103, "end_pos": 121, "type": "DATASET", "confidence": 0.6883355528116226}, {"text": "F-score", "start_pos": 137, "end_pos": 144, "type": "METRIC", "confidence": 0.9954225420951843}]}, {"text": "In later experiments, we used different parameters, which resulted in a 0.03 F-score improvement.", "labels": [], "entities": [{"text": "F-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9971746206283569}]}, {"text": "We believe the big difference of ranking on different datasets comes from the incomplete training.", "labels": [], "entities": []}, {"text": "Due to incorrect estimation of running time, we only used the smaller training file in our submitted biological result.", "labels": [], "entities": []}, {"text": "From    Since the lower support threshold could generate more hedge cues, it will generate less training instances for hedge cues with both low confidence and support, which affects the performance of the MaxEnt classifier.", "labels": [], "entities": []}, {"text": "In both datasets, it appears that 0.5 and 5 are the best thresholds for confidence and support, respectively.", "labels": [], "entities": [{"text": "confidence", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.997186005115509}, {"text": "support", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9806815981864929}]}, {"text": "Beyond the performance of the entire system, our hedge cue generator yields very promising results.", "labels": [], "entities": []}, {"text": "Using the best parameters we just noted above, our hedge cue generator generates 52 hedge cues with confidence 100% on the Wikipedia dataset, and 332 hedge cues in the biological dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 123, "end_pos": 140, "type": "DATASET", "confidence": 0.9870566427707672}]}, {"text": "Some hedge cue examples are shown in.", "labels": [], "entities": []}, {"text": "We also ran experiments to verify the performance of our MaxEnt classifier.", "labels": [], "entities": [{"text": "MaxEnt classifier", "start_pos": 57, "end_pos": 74, "type": "DATASET", "confidence": 0.8717814683914185}]}, {"text": "We used the same setting of datasets as for the system performance evaluation.", "labels": [], "entities": []}, {"text": "Given a hedge cue, we extracted all the matched sentences from the training set to train a MaxEnt classifier, and used it to classify the matched sentences by the hedge cue in testing set.", "labels": [], "entities": []}, {"text": "shows the results, the hedge cues were manually chosen with relative higher support.", "labels": [], "entities": []}, {"text": "We can see that the performance of the MaxEnt classifier correlates tightly with confidence and support.", "labels": [], "entities": [{"text": "confidence", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9486581087112427}]}, {"text": "Higher confidence means a more accurate detection fora phrase to be hedge cue, while higher support means more training instances for the classifier: the best strategy would be to find hedge cues with both high confidence and support.", "labels": [], "entities": []}, {"text": "While experimenting with the system, we found several potential improvements.", "labels": [], "entities": []}, {"text": "Take the word suggest as an example.", "labels": [], "entities": []}, {"text": "In the generated hedge cues, we found that its other forms are everywhere, like it suggested, NNS suggests a, and DT suggesting that.", "labels": [], "entities": []}, {"text": "As we put POS tags into Lucene index, we can normalize words to their base forms using a morphology parser, and put base forms into index.", "labels": [], "entities": [{"text": "Lucene index", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.8728789687156677}]}, {"text": "After that, the query with suggest will match all the forms.", "labels": [], "entities": []}, {"text": "\u2022 Use more sophisticated features to train the MaxEnt classifier.", "labels": [], "entities": []}, {"text": "Currently we only use shallow linguistics information as features, however we noticed that the role of the phrase could be very important to decide whether it indicates uncertainty.", "labels": [], "entities": []}, {"text": "We can deep parse sentences, extract the role information, and add it to the feature list of classifier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hedge Cue Examples", "labels": [], "entities": []}, {"text": " Table 3: Evaluation Result on Wikipedia Dataset", "labels": [], "entities": [{"text": "Evaluation Result", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6828901469707489}, {"text": "Wikipedia Dataset", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9713596701622009}]}, {"text": " Table 4: Evaluation Result on Biological Dataset", "labels": [], "entities": [{"text": "Evaluation Result", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7384998500347137}, {"text": "Biological Dataset", "start_pos": 31, "end_pos": 49, "type": "DATASET", "confidence": 0.7752849459648132}]}, {"text": " Table 6: MaxEnt Classifier Performance", "labels": [], "entities": []}, {"text": " Table 5: Generated Hedge Cue Examples", "labels": [], "entities": []}]}