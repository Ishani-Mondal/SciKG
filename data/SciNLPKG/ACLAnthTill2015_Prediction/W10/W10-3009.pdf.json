{"title": [{"text": "Hedge Detection Using the RelHunter Approach *", "labels": [], "entities": [{"text": "Hedge Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8235932290554047}]}], "abstractContent": [], "introductionContent": [{"text": "Hedges are linguistic devices that indicate uncertain or unreliable information within a text.", "labels": [], "entities": []}, {"text": "The detection of hedge structures is important for many applications that extract facts from textual data.) is dedicated to hedge detection.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 124, "end_pos": 139, "type": "TASK", "confidence": 0.9206973016262054}]}, {"text": "A hedge structure consists of a cue and a scope.", "labels": [], "entities": []}, {"text": "In, we present a sentence with two hedge instances.", "labels": [], "entities": []}, {"text": "The hedge cues are highlighted and their scopes are delimited by brackets.", "labels": [], "entities": [{"text": "scopes", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9654062390327454}]}, {"text": "The hedge cue comprises one or more keywords that indicate uncertainty.", "labels": [], "entities": []}, {"text": "The hedge scope is the uncertain statement which is hedged by the cue.", "labels": [], "entities": []}, {"text": "The scope always includes the corresponding cue.", "labels": [], "entities": []}, {"text": "[ They indicate that [ the demonstration is possible in this context ] and there is a correlation ] Over the last two decades, several Computational Linguistic problems have been successfully modeled as local token classification tasks.", "labels": [], "entities": [{"text": "local token classification tasks", "start_pos": 203, "end_pos": 235, "type": "TASK", "confidence": 0.7038177102804184}]}, {"text": "Nevertheless, the harder problems consist in identifying complex structures within a text.", "labels": [], "entities": []}, {"text": "These structures comprise many tokens and show non local token dependencies.", "labels": [], "entities": []}, {"text": "Phrase chunking) is a task that involves structure recognition.", "labels": [], "entities": [{"text": "Phrase chunking)", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9238691926002502}, {"text": "structure recognition", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7237818241119385}]}, {"text": "Punyakanok and Roth decompose this task into four subtasks, that are sequentially solved).", "labels": [], "entities": []}, {"text": "They use Hidden Markov Models for the first three subtasks.", "labels": [], "entities": []}, {"text": "They find out that task decomposition improves the overall token classification modeling.", "labels": [], "entities": [{"text": "task decomposition", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7076945006847382}, {"text": "token classification modeling", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.9158993562062582}]}, {"text": "Clause identification) is another task that requires structure recognition.", "labels": [], "entities": [{"text": "Clause identification)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9448217948277792}, {"text": "structure recognition", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.728199303150177}]}, {"text": "As clauses may embed other clauses, these struc-tures involve stronger dependencies than phrase chunks.", "labels": [], "entities": []}, {"text": "propose an approach that extends Punyakanok and Roth's previous work).", "labels": [], "entities": []}, {"text": "Their system comprises complex methods for training and extraction, in order to exploit the specific dependency aspects of clause structures.", "labels": [], "entities": []}, {"text": "Phrase Recognition is a general type of task that includes both phrase chunking and clause identification.", "labels": [], "entities": [{"text": "Phrase Recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8987893462181091}, {"text": "phrase chunking", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.7634152472019196}, {"text": "clause identification", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.7738798260688782}]}, {"text": "propose the FilteringRanking Perceptron (FRP) system for this general task (.", "labels": [], "entities": []}, {"text": "The FRP task modeling is strongly related to previous proposals).", "labels": [], "entities": [{"text": "FRP task modeling", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.5770077506701151}]}, {"text": "However, it simultaneously learns to solve three subtasks.", "labels": [], "entities": []}, {"text": "FRP is very effective, although computationally expensive at both training and prediction time.", "labels": [], "entities": [{"text": "FRP", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.4801950454711914}, {"text": "prediction", "start_pos": 79, "end_pos": 89, "type": "TASK", "confidence": 0.9431259036064148}]}, {"text": "Currently, FRP provides the best performing clause identification system.", "labels": [], "entities": [{"text": "FRP", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.8312923908233643}, {"text": "clause identification", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.9195165932178497}]}, {"text": "In, the hedge detection task is solved as two consecutive classification tasks.", "labels": [], "entities": [{"text": "hedge detection task", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.8817944129308065}]}, {"text": "The first one consists of classifying the tokens of a sentence as hedge cues using the IOB tagging style.", "labels": [], "entities": []}, {"text": "The second task consists of classifying tokens of a sentence as being the start of a hedge scope, the end of one, or neither.", "labels": [], "entities": []}, {"text": "The result of those two tasks is combined using a set of six rules to solve the hedge detection task.", "labels": [], "entities": [{"text": "hedge detection task", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.879192849000295}]}, {"text": "Here, we describe RelHunter, anew method for the extraction of structured information from text.", "labels": [], "entities": []}, {"text": "Additionally, we apply it to the Hedge Detection task.", "labels": [], "entities": [{"text": "Hedge Detection task", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8946999510129293}]}, {"text": "RelHunter extends the modeling strategy used both in and.", "labels": [], "entities": [{"text": "RelHunter", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9400752186775208}]}, {"text": "Other applications of this method are presented in.", "labels": [], "entities": []}, {"text": "The remainder of this text is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present an overview of the RelHunter method.", "labels": [], "entities": []}, {"text": "The modeling approach for the Hedge Detection task is presented in Sections 3 and 4.", "labels": [], "entities": [{"text": "Hedge Detection task", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.9526686271031698}]}, {"text": "The experimental findings are depicted and discussed in Section 5.", "labels": [], "entities": []}, {"text": "Finally, in Section 6, we present our final remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the corpus provided in the CoNLL-2010 Shared Task to train and evaluate our hedge detection system.", "labels": [], "entities": [{"text": "CoNLL-2010 Shared Task", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.8414428432782491}, {"text": "hedge detection", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.8400724828243256}]}, {"text": "We add the following annotation to the corpus: word stems, part-of-speech tags, phrase chunks, and clause annotations.", "labels": [], "entities": []}, {"text": "Word stems have been generated by the Porter stemmer.", "labels": [], "entities": []}, {"text": "The additional annotation has been generated by ETL based systems (dos.", "labels": [], "entities": [{"text": "ETL", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.8673377633094788}]}, {"text": "The CoNLL corpus is based on the BioScope corpus (.", "labels": [], "entities": [{"text": "CoNLL corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9289692938327789}, {"text": "BioScope corpus", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.9458372592926025}]}, {"text": "Since it contains documents of two different kinds -paper abstracts and full papers -we split it into two subcorpora.", "labels": [], "entities": []}, {"text": "The first subcorpus is called ABST and contains all the paper abstracts.", "labels": [], "entities": [{"text": "ABST", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.4837891161441803}]}, {"text": "The second is called FULL and contains all the full papers.", "labels": [], "entities": [{"text": "FULL", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9831827878952026}]}, {"text": "We have two experimental setups: Development and Evaluation.", "labels": [], "entities": []}, {"text": "In the Development Setup, we use ABST as the training corpus and FULL as the development corpus.", "labels": [], "entities": [{"text": "FULL", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9762256145477295}]}, {"text": "This is a conservative decision since the CoNLL Evaluation Corpus is comprised only of full articles.", "labels": [], "entities": [{"text": "CoNLL Evaluation Corpus", "start_pos": 42, "end_pos": 65, "type": "DATASET", "confidence": 0.9340935150782267}]}, {"text": "In the Evaluation Setup, we use the union of ABST and FULL as the training corpus and report the performance over the CoNLL Evaluation Corpus.", "labels": [], "entities": [{"text": "FULL", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9132172465324402}, {"text": "CoNLL Evaluation Corpus", "start_pos": 118, "end_pos": 141, "type": "DATASET", "confidence": 0.9194104075431824}]}, {"text": "Here, we report the evaluation setup findings.", "labels": [], "entities": []}, {"text": "In, we show the performance of the three: Evaluation performance of the three Baseline Classifiers.", "labels": [], "entities": []}, {"text": "In, we report the performance of the three entity identification ETL classifiers.", "labels": [], "entities": [{"text": "entity identification ETL classifiers", "start_pos": 43, "end_pos": 80, "type": "TASK", "confidence": 0.7831522226333618}]}, {"text": "Again, the start and end classifiers are evaluated with golden standard cue chunks.", "labels": [], "entities": []}, {"text": "The last table line shows the performance of the RelHunter method on the target task -hedge detection.", "labels": [], "entities": [{"text": "hedge detection", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.7591115534305573}]}], "tableCaptions": [{"text": " Table 1: Development performance of the three  Baseline Classifiers.", "labels": [], "entities": []}, {"text": " Table 2: Development performance of the three  entity identification ETL classifiers and the Rel- Hunter method to hedge detection.", "labels": [], "entities": [{"text": "entity identification ETL classifiers", "start_pos": 48, "end_pos": 85, "type": "TASK", "confidence": 0.8116174340248108}, {"text": "hedge detection", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.811978280544281}]}, {"text": " Table 3: Evaluation performance of the three  Baseline Classifiers.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation performance of the three  entity identification ETL classifiers and the Rel- Hunter method to hedge detection.", "labels": [], "entities": [{"text": "entity identification ETL classifiers", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.8065562546253204}, {"text": "hedge detection", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.794367790222168}]}, {"text": " Table 5: Evaluation performance of the RelHunter  system when using END and END-X.", "labels": [], "entities": []}, {"text": " Table 6: Evaluation performance of the CoNLL- 2010 systems and the RelHunter method with the  END-X end scope classifier.", "labels": [], "entities": [{"text": "CoNLL- 2010", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.8559084534645081}]}]}