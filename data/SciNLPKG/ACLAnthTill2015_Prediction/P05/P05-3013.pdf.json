{"title": [], "abstractContent": [{"text": "We demonstrate TextRank-a system for unsupervised extractive summarization that relies on the application of iterative graph-based ranking algorithms to graphs encoding the cohesive structure of a text.", "labels": [], "entities": [{"text": "unsupervised extractive summarization", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.573474278052648}]}, {"text": "An important characteristic of the system is that it does not rely on any language-specific knowledge resources or any manually constructed training data, and thus it is highly portable to new languages or domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given the overwhelming amount of information available today, on the Web and elsewhere, techniques for efficient automatic text summarization are essential to improve the access to such information.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.6862995028495789}]}, {"text": "Algorithms for extractive summarization are typically based on techniques for sentence extraction, and attempt to identify the set of sentences that are most important for the understanding of a given document.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7462384402751923}, {"text": "sentence extraction", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7189030647277832}]}, {"text": "Some of the most successful approaches to extractive summarization consist of supervised algorithms that attempt to learn what makes a good summary by training on collections of summaries built fora relatively large number of training documents, e.g. (),).", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.6315448880195618}]}, {"text": "However, the price paid for the high performance of such supervised algorithms is their inability to easily adapt to new languages or domains, as new training data are required for each new type of data.", "labels": [], "entities": []}, {"text": "TextRank (Mihalcea and Tarau, 2004),) is specifically designed to address this problem, by using an extractive summarization technique that does not require any training data or any language-specific knowledge sources.", "labels": [], "entities": []}, {"text": "TextRank can be effectively applied to the summarization of documents in different languages without any modifications of the algorithm and without any requirements for additional data.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8461776971817017}, {"text": "summarization of documents", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.9017124573389689}]}, {"text": "Moreover, results from experiments performed on standard data sets have demonstrated that the performance of TextRank is competitive with that of some of the best summarization systems available today.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 109, "end_pos": 117, "type": "DATASET", "confidence": 0.9248994588851929}]}], "datasetContent": [{"text": "English document summarization experiments are run using the summarization test collection provided in the framework of the Document Understanding Conference (DUC).", "labels": [], "entities": [{"text": "English document summarization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.4806045691172282}, {"text": "Document Understanding Conference (DUC)", "start_pos": 124, "end_pos": 163, "type": "TASK", "confidence": 0.5356312741835912}]}, {"text": "In particular, we use the data set of 567 news articles made available during the DUC 2002 evaluations, and the corresponding 100-word summaries generated for each of these documents.", "labels": [], "entities": [{"text": "DUC 2002 evaluations", "start_pos": 82, "end_pos": 102, "type": "DATASET", "confidence": 0.948432465394338}]}, {"text": "This is the single document summarization task undertaken by other systems participating in To test the language independence aspect of the algorithm, in addition to the English test collection, we also use a Brazilian Portuguese data set consisting of 100 news articles and their corresponding manually produced summaries.", "labels": [], "entities": [{"text": "Brazilian Portuguese data set", "start_pos": 209, "end_pos": 238, "type": "DATASET", "confidence": 0.7157190293073654}]}, {"text": "We use the TeM\u00e1rio test collection (, containing newspaper articles from online Brazilian newswire: 40 documents from Jornal de Brasil and 60 documents from Folha de S\u00e3o Paulo.", "labels": [], "entities": [{"text": "TeM\u00e1rio test collection", "start_pos": 11, "end_pos": 34, "type": "DATASET", "confidence": 0.908576250076294}, {"text": "Folha de S\u00e3o Paulo", "start_pos": 157, "end_pos": 175, "type": "DATASET", "confidence": 0.8895588517189026}]}, {"text": "The documents were selected to cover a variety of domains (e.g. world, politics, foreign affairs, editorials), and manual summaries were produced by an expert in Brazilian Portuguese.", "labels": [], "entities": []}, {"text": "Unlike the summaries produced for the English DUC documents -which had a length requirement of approximately 100 words, the length of the summaries in the TeM\u00e1rio data set is constrained relative to the length of the corresponding documents, i.e. a summary has to account for about 25-30% of the original document.", "labels": [], "entities": [{"text": "English DUC documents", "start_pos": 38, "end_pos": 59, "type": "DATASET", "confidence": 0.6499350170294443}, {"text": "TeM\u00e1rio data set", "start_pos": 155, "end_pos": 171, "type": "DATASET", "confidence": 0.9639483491579691}]}, {"text": "Consequently, the automatic summaries generated for the documents in this collection are not restricted to 100 words, as in the English experiments, but are required to have a length comparable to the corresponding manual summaries, to ensure a fair evaluation.", "labels": [], "entities": []}, {"text": "For evaluation, we are using the ROUGE evaluation toolkit 1 , which is a method based on Ngram statistics, found to be highly correlated with human evaluations (.", "labels": [], "entities": [{"text": "ROUGE evaluation toolkit 1", "start_pos": 33, "end_pos": 59, "type": "DATASET", "confidence": 0.6835195571184158}]}, {"text": "The evaluation is done using the Ngram(1,1) setting of ROUGE, which was found to have the highest correlation with human judgments, at a confidence level of 95%.", "labels": [], "entities": [{"text": "Ngram(1,1) setting", "start_pos": 33, "end_pos": 51, "type": "METRIC", "confidence": 0.7304320573806763}, {"text": "ROUGE", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9855060577392578}]}, {"text": "taking the first sentences in each document.", "labels": [], "entities": []}, {"text": "By ways of comparison, the best participating system in DUC 2002 was a supervised system that led to a ROUGE score of 0.5011.", "labels": [], "entities": [{"text": "DUC 2002", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9259946942329407}, {"text": "ROUGE score", "start_pos": 103, "end_pos": 114, "type": "METRIC", "confidence": 0.9834873378276825}]}, {"text": "For both data sets, TextRank applied on a directed backward graph structure exceeds the performance achieved through a simple (but powerful) baseline.", "labels": [], "entities": []}, {"text": "These results prove that graph-based ranking algorithms, previously found successful in Web link analysis and social networks, can be turned into a stateof-the-art tool for extractive summarization when applied to graphs extracted from texts.", "labels": [], "entities": [{"text": "Web link analysis", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.6026227672894796}, {"text": "extractive summarization", "start_pos": 173, "end_pos": 197, "type": "TASK", "confidence": 0.7021983563899994}]}, {"text": "Moreover, due to its unsupervised nature, the algorithm was also shown to be language independent, leading to similar results and similar improvements over baseline techniques when applied on documents in different languages.", "labels": [], "entities": []}, {"text": "More extensive experimental results with the TextRank system are reported in (,).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: English single-document summarization.", "labels": [], "entities": [{"text": "English single-document summarization", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.5106550653775533}]}, {"text": " Table 2: Portuguese single-document summarization.", "labels": [], "entities": [{"text": "Portuguese single-document summarization", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.6040372550487518}]}]}