{"title": [{"text": "High Precision Treebanking -Blazing Useful Trees Using POS Information", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present a quantitative and qualitative analysis of annotation in the Hinoki treebank of Japanese, and investigate a method of speeding annotation by using part-of-speech tags.", "labels": [], "entities": [{"text": "Hinoki treebank of Japanese", "start_pos": 86, "end_pos": 113, "type": "DATASET", "confidence": 0.952647864818573}]}, {"text": "The Hinoki treebank is a Redwoods-style treebank of Japanese dictionary definition sentences.", "labels": [], "entities": [{"text": "Hinoki treebank", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9598757326602936}, {"text": "Redwoods-style treebank of Japanese dictionary definition sentences", "start_pos": 25, "end_pos": 92, "type": "DATASET", "confidence": 0.8868209804807391}]}, {"text": "5,000 sentences are annotated by three different annotators and the agreement evaluated.", "labels": [], "entities": []}, {"text": "An average agreement of 65.4% was found using strict agreement, and 83.5% using labeled precision.", "labels": [], "entities": [{"text": "agreement", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9901589751243591}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.5322089195251465}]}, {"text": "Exploiting POS tags allowed the annotators to choose the best parse with 19.5% fewer decisions.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is important for an annotated corpus that the markup is both correct and, in cases where variant analyses could be considered correct, consistent.", "labels": [], "entities": []}, {"text": "Considerable research in the field of word sense disambiguation has concentrated on showing that the annotation of word senses can be done correctly and consistently, with the normal measure being interannotator agreement (e.g.).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.7238248785336813}]}, {"text": "Surprisingly, few such studies have been carried out for syntactic annotation, with the notable exceptions of) for the German NeGra for the Spanish Cast3LB corpus.", "labels": [], "entities": [{"text": "syntactic annotation", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7909256517887115}, {"text": "Spanish Cast3LB corpus", "start_pos": 140, "end_pos": 162, "type": "DATASET", "confidence": 0.7594273686408997}]}, {"text": "Even such valuable and widely used corpora as the Penn TreeBank have not been verified in this way.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.9933379590511322}]}, {"text": "We are constructing the Hinoki treebank as part of a larger project in cognitive and computational linguistics ultimately aimed at natural language understanding ( ).", "labels": [], "entities": [{"text": "Hinoki treebank", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.9592463970184326}, {"text": "natural language understanding", "start_pos": 131, "end_pos": 161, "type": "TASK", "confidence": 0.6475468575954437}]}, {"text": "In order to build the initial syntactic and semantic models, we are treebanking the dictionary definition sentences of the most familiar 28,000 words of Japanese and building an ontology from the results.", "labels": [], "entities": []}, {"text": "Arguably the most common method in building a treebank still is manual annotation, annotators (often linguistics students) marking up linguistic properties of words and phrases.", "labels": [], "entities": []}, {"text": "In some semi-automated treebank efforts, annotators are aided by POS taggers or phrase-level chunkers, which can propose mark-up for manual confirmation, revision, or extension.", "labels": [], "entities": []}, {"text": "As computational grammars and parsers have increased in coverage and accuracy, an alternate approach has become feasible, in which utterances are parsed and the annotator selects the best parse Carter (1997); from the full analyses derived by the grammar.", "labels": [], "entities": [{"text": "coverage", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9652208685874939}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9949468970298767}]}, {"text": "We adopted the latter approach.", "labels": [], "entities": []}, {"text": "There were four main reasons.", "labels": [], "entities": []}, {"text": "The first was that we wanted to develop a precise broad-coverage grammar in tandem with the treebank, as part of our research into natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 131, "end_pos": 161, "type": "TASK", "confidence": 0.6497794489065806}]}, {"text": "Treebanking the output of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop).", "labels": [], "entities": []}, {"text": "The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations.", "labels": [], "entities": []}, {"text": "By using a Japanese grammar (JACY:) based on a monostratal theory of grammar (HPSG: we could simultaneously annotate syntactic and semantic structure without overburdening the annota-tor.", "labels": [], "entities": []}, {"text": "The third reason was that we expected the use of the grammar to aid in enforcing consistencyat the very least all sentences annotated are guaranteed to have well-formed parses.", "labels": [], "entities": []}, {"text": "The flip side to this is that any sentences which the parser cannot parse remain unannotated, at least unless we were to fallback on full manual mark-up of their analyses.", "labels": [], "entities": []}, {"text": "The final reason was that the discriminants can be used to update the treebank when the grammar changes, so that the treebank can be improved along with the grammar.", "labels": [], "entities": []}, {"text": "This kind of dynamic, discriminant-based treebanking was pioneered in the Redwoods treebank of English (), so we refer to it as Redwoods-style treebanking.", "labels": [], "entities": [{"text": "Redwoods treebank of English", "start_pos": 74, "end_pos": 102, "type": "DATASET", "confidence": 0.9522611647844315}, {"text": "Redwoods-style treebanking", "start_pos": 128, "end_pos": 154, "type": "DATASET", "confidence": 0.9571866095066071}]}, {"text": "In the next section, we give some more details about the Hinoki Treebank and the data used to evaluate the parser ( \u00a7 2).", "labels": [], "entities": [{"text": "Hinoki Treebank", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.980196624994278}]}, {"text": "This is followed by a brief discussion of treebanking using discriminants ( \u00a7 3), and an extension to seed the treebanking using existing markup ( \u00a7 4).", "labels": [], "entities": []}, {"text": "Finally we present the results of our evaluation ( \u00a7 5), followed by some discussion and outlines for future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Exact Match Inter-annotator Agreement", "labels": [], "entities": []}, {"text": " Table 2: Inter-Annotator Agreement as Mutual Labeled Precision F-Score", "labels": [], "entities": []}, {"text": " Table 3: Number of Decisions Required", "labels": [], "entities": []}]}