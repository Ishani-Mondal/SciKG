{"title": [{"text": "Modelling the substitutability of discourse connectives", "labels": [], "entities": []}], "abstractContent": [{"text": "Processing discourse connectives is important for tasks such as discourse parsing and generation.", "labels": [], "entities": [{"text": "Processing discourse connectives", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6697978675365448}, {"text": "discourse parsing", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.6951811015605927}]}, {"text": "For these tasks, it is useful to know which connectives can signal the same coherence relations.", "labels": [], "entities": []}, {"text": "This paper presents experiments into modelling the substitutability of discourse connectives.", "labels": [], "entities": []}, {"text": "It shows that substitutability effects dis-tributional similarity.", "labels": [], "entities": []}, {"text": "A novel variance-based function for comparing probability distributions is found to assist in predicting substitutability.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse coherence relations contribute to the meaning of texts, by specifying the relationships between semantic objects such as events and propositions.", "labels": [], "entities": []}, {"text": "They also assist in the interpretation of anaphora, verb phrase ellipsis and lexical ambiguities).", "labels": [], "entities": []}, {"text": "Coherence relations can be implicit, or they can be signalled explicitly through the use of discourse connectives, e.g. because, even though.", "labels": [], "entities": []}, {"text": "For a machine to interpret a text, it is important that it recognises coherence relations, and so as explicit markers discourse connectives are of great assistance).", "labels": [], "entities": []}, {"text": "When discourse connectives are not present, the task is more difficult.", "labels": [], "entities": []}, {"text": "For such cases, unsupervised approaches have been developed for predicting relations, by using sentences containing discourse connectives as training data ().", "labels": [], "entities": [{"text": "predicting relations", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.8869776427745819}]}, {"text": "However the nature of the relationship between the coherence relations signalled by discourse connectives and their empirical distributions has to date been poorly understood.", "labels": [], "entities": []}, {"text": "In particular, one might wonder whether connectives with similar meanings also have similar distributions.", "labels": [], "entities": []}, {"text": "Concerning natural language generation, texts are easier for humans to understand if they are coherently structured.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6932932138442993}]}, {"text": "Addressing this, a body of research has considered the problems of generating appropriate discourse connectives (for example).", "labels": [], "entities": []}, {"text": "One such problem involves choosing which connective to generate, as the mapping between connectives and relations is not one-to-one, but rather many-to-many.", "labels": [], "entities": []}, {"text": "considers the task of paraphrasing a text while preserving its rhetorical relations.", "labels": [], "entities": []}, {"text": "Clauses conjoined by but, or and when are separated to form distinct orthographic sentences, and these conjunctions are replaced by the discourse adverbials however, otherwise and then, respectively.", "labels": [], "entities": []}, {"text": "The idea underlying Siddharthan's work is that one connective can be substituted for another while preserving the meaning of a text.", "labels": [], "entities": []}, {"text": "studies the substitutability of discourse connectives, and proposes that substitutability can motivate theories of discourse coherence.", "labels": [], "entities": []}, {"text": "Knott uses an empirical methodology to determine the substitutability of pairs of connectives.", "labels": [], "entities": []}, {"text": "However this methodology is manually intensive, and Knott derives relationships for only about 18% of pairs of connectives.", "labels": [], "entities": []}, {"text": "It would thus be useful if substitutability could be predicted automatically.", "labels": [], "entities": []}, {"text": "This paper proposes that substitutability can be predicted through statistical analysis of the contexts in which connectives appear.", "labels": [], "entities": []}, {"text": "Similar methods have been developed for predicting the similarity of nouns and verbs on the basis of their distributional similarity, and many distributional similarity functions have been proposed for these tasks.", "labels": [], "entities": [{"text": "predicting the similarity of nouns and verbs", "start_pos": 40, "end_pos": 84, "type": "TASK", "confidence": 0.8002374853406634}]}, {"text": "However substitutability is a more complex notion than similarity, and we propose a novel variance-based function for assisting in this task.", "labels": [], "entities": []}, {"text": "This paper constitutes a first step towards predicting substitutability of cnonectives automatically.", "labels": [], "entities": []}, {"text": "We demonstrate that the substitutability of connectives has significant effects on both distributional similarity and the new variance-based function.", "labels": [], "entities": [{"text": "distributional similarity", "start_pos": 88, "end_pos": 113, "type": "METRIC", "confidence": 0.6268835961818695}]}, {"text": "We then attempt to predict substitutability of connectives using a simplified task that factors out the prior likelihood of being substitutable.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now describe our empirical experiments which investigate the connections between a) subjects' ratings of the similarity of discourse connectives, b) the substitutability of discourse connectives, and c) KL divergence and the new function V applied to the distributions of connectives.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 206, "end_pos": 219, "type": "TASK", "confidence": 0.6215116381645203}]}, {"text": "Our motivation is to explore how distributional properties of words might be used to predict substitutability.", "labels": [], "entities": []}, {"text": "The experiments are restricted to connectives which relate clauses within a sentence.", "labels": [], "entities": []}, {"text": "These include coordinating conjunctions (e.g. but) and a range of subordinators including conjunctions (e.g. because) as well as phrases introducing adverbial clauses (e.g. now that, given that, for the reason that).", "labels": [], "entities": []}, {"text": "Adverbial discourse connectives are therefore not considered.", "labels": [], "entities": [{"text": "Adverbial discourse connectives", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.737208624680837}]}, {"text": "This experiment tests the hypotheses that 1) subjects agree on the degree of similarity between pairs of discourse connectives, and 2) similarity ratings correlate with the degree of substitutability.", "labels": [], "entities": []}, {"text": "This experiment compares subjects' ratings of similarity with lexical co-occurrence data.", "labels": [], "entities": []}, {"text": "It hypothesises that similarity ratings correlate with distributional similarity, but that neither correlates with the new variance in surprise function.", "labels": [], "entities": []}, {"text": "The previous experiments provide hope that substitutability of connectives might be predicted on the basis of their empirical distributions.", "labels": [], "entities": []}, {"text": "However one complicating factor is that EXCLUSIVE is by far the most likely relationship, holding between about 70% of pairs.", "labels": [], "entities": [{"text": "EXCLUSIVE", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.960687518119812}]}, {"text": "Preliminary experiments showed that the empirical evidence for other relationships was not strong enough to overcome this prior bias.", "labels": [], "entities": []}, {"text": "We therefore attempted two pseudodisambiguation tasks which eliminated the effects of prior likelihoods.", "labels": [], "entities": []}, {"text": "The first task involved distinguishing between the relationships whose connectives subjects rated as most similar, namely SYNONYMY and HY-PONYMY.", "labels": [], "entities": []}, {"text": "Triples of connectives p, q, q were collected such that SYNONYM(p, q) and either HY-PONYM(p, q ) or HYPONYM(q , p) (we were not attempting to predict the order of HYPONYMY).", "labels": [], "entities": []}, {"text": "The task was then to decide automatically which of q and q is the SYNONYM of p.", "labels": [], "entities": []}, {"text": "The second task was identical in nature to the first, however here the relationship between p and q was either SYNONYMY or HYPONYMY, while p and q were either CONT.", "labels": [], "entities": [{"text": "HYPONYMY", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8417514562606812}, {"text": "CONT", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.9669927358627319}]}, {"text": "These two sets of relationships are those corresponding to high and low similarity, respectively.", "labels": [], "entities": [{"text": "similarity", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9639533162117004}]}, {"text": "In combination, the two tasks are equivalent to predicting SYN-ONYMY or HYPONYMY from the set of all four relationships, by first distinguishing the high similarity relationships from the other two, and then making a finer-grained distinction between the two.", "labels": [], "entities": [{"text": "predicting SYN-ONYMY", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7542234659194946}]}], "tableCaptions": [{"text": " Table 3: Distributional analysis by substitutability", "labels": [], "entities": [{"text": "Distributional analysis", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9810048937797546}]}]}