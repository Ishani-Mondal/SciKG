{"title": [{"text": "Automatic Measurement of Syntactic Development in Child Language", "labels": [], "entities": [{"text": "Automatic Measurement of Syntactic Development", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.5335253834724426}]}], "abstractContent": [{"text": "To facilitate the use of syntactic information in the study of child language acquisition, a coding scheme for Grammatical Relations (GRs) in transcripts of parent-child dialogs has been proposed by Sagae, MacWhinney and Lavie (2004).", "labels": [], "entities": [{"text": "child language acquisition", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.6725200613339742}]}, {"text": "We discuss the use of current NLP techniques to produce the GRs in this annotation scheme.", "labels": [], "entities": []}, {"text": "By using a statistical parser (Charniak, 2000) and memory-based learning tools for classification (Daelemans et al., 2004), we obtain high precision and recall of several GRs.", "labels": [], "entities": [{"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.998777449131012}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9989884495735168}]}, {"text": "We demonstrate the usefulness of this approach by performing automatic measurements of syntactic development with the Index of Productive Syntax (Scarborough, 1990) at similar levels to what child language researchers compute manually.", "labels": [], "entities": [{"text": "Scarborough, 1990)", "start_pos": 146, "end_pos": 164, "type": "DATASET", "confidence": 0.829353928565979}]}], "introductionContent": [{"text": "Automatic syntactic analysis of natural language has benefited greatly from statistical and corpus-based approaches in the past decade.", "labels": [], "entities": [{"text": "syntactic analysis of natural language", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.8434626281261444}]}, {"text": "The availability of syntactically annotated data has fueled the development of high quality statistical parsers, which have had a large impact in several areas of human language technologies.", "labels": [], "entities": []}, {"text": "Similarly, in the study of child language, the availability of large amounts of electronically accessible empirical data in the form of child language transcripts has been shifting much of the research effort towards a corpus-based mentality.", "labels": [], "entities": []}, {"text": "However, child language researchers have only recently begun to utilize modern NLP techniques for syntactic analysis.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9158435165882111}]}, {"text": "Although it is now common for researchers to rely on automatic morphosyntactic analyses of transcripts to obtain part-of-speech and morphological analyses, their use of syntactic parsing is rare.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 169, "end_pos": 186, "type": "TASK", "confidence": 0.7128501683473587}]}, {"text": "Sagae, have proposed a syntactic annotation scheme for the CHILDES database, which contains hundreds of megabytes of transcript data and has been used in over 1,500 studies in child language acquisition and developmental language disorders.", "labels": [], "entities": [{"text": "Sagae", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8772202134132385}, {"text": "CHILDES database", "start_pos": 59, "end_pos": 75, "type": "DATASET", "confidence": 0.921802282333374}, {"text": "child language acquisition", "start_pos": 176, "end_pos": 202, "type": "TASK", "confidence": 0.634949137767156}]}, {"text": "This annotation scheme focuses on syntactic structures of particular importance in the study of child language.", "labels": [], "entities": []}, {"text": "In this paper, we describe the use of existing NLP tools to parse child language transcripts and produce automatically annotated data in the format of the scheme of Sagae et al.", "labels": [], "entities": [{"text": "parse child language transcripts", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.8272993564605713}]}, {"text": "We also validate the usefulness of the annotation scheme and our analysis system by applying them towards the practical task of measuring syntactic development in children according to the Index of Productive Syntax, or IPSyn, which requires syntactic analysis of text and has traditionally been computed manually.", "labels": [], "entities": []}, {"text": "Results obtained with current NLP technology are close to what is expected of human performance in IPSyn computations, but there is still room for improvement.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our implementation of IPSyn in two ways.", "labels": [], "entities": []}, {"text": "The first is Point Difference, which is calculated by taking the (unsigned) difference between scores obtained manually and automatically.", "labels": [], "entities": [{"text": "Point Difference", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7353169918060303}]}, {"text": "The point difference is of great practical value, since it shows exactly how close automatically produced scores are to manually produced scores.", "labels": [], "entities": []}, {"text": "The second is Point-to-Point Accuracy, which reflects the overall reliability over each individual scoring decision in the computation of IPSyn scores.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8864341378211975}]}, {"text": "It is calculated by counting how many decisions (identification of presence/absence of language structures in the transcript being scored) were made correctly, and dividing that number by the total number of decisions.", "labels": [], "entities": []}, {"text": "The pointto-point measure is commonly used for assessing the inter-rater reliability of metrics such as the IPSyn.", "labels": [], "entities": [{"text": "IPSyn", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.9481223225593567}]}, {"text": "In our case, it allows us to establish the reliability of automatically computed scores against human scoring.", "labels": [], "entities": [{"text": "reliability", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9892724752426147}]}], "tableCaptions": [{"text": " Table 1: Precision, recall and F-score (harmonic  mean) of selected Grammatical Relations.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.994938850402832}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9986911416053772}, {"text": "F-score (harmonic  mean)", "start_pos": 32, "end_pos": 56, "type": "METRIC", "confidence": 0.8038128912448883}]}, {"text": " Table 2: Summary of evaluation results. GR is our  implementation of IPSyn based on grammatical re- lations, CP is Long et al.'s (2004) implementation of  IPSyn, and HUMAN is manual scoring.", "labels": [], "entities": [{"text": "HUMAN", "start_pos": 167, "end_pos": 172, "type": "METRIC", "confidence": 0.8838353753089905}]}]}