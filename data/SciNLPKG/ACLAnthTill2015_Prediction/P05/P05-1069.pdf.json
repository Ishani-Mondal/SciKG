{"title": [{"text": "A Localized Prediction Model for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.9095127185185751}]}], "abstractContent": [{"text": "In this paper, we present a novel training method fora localized phrase-based prediction model for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 99, "end_pos": 136, "type": "TASK", "confidence": 0.8206994285186132}]}, {"text": "The model predicts blocks with orientation to handle local phrase reordering.", "labels": [], "entities": []}, {"text": "We use a maximum likelihood criterion to train a log-linear block bigram model which uses real-valued features (e.g. a language model score) as well as binary features based on the block identities themselves, e.g. block bigram features.", "labels": [], "entities": []}, {"text": "Our training algorithm can easily handle millions of features.", "labels": [], "entities": []}, {"text": "The best system obtains a \u00a2 \u00a4 \u00a3 \u00a6 \u00a5 \u00a7 % improvement over the baseline on a standard Arabic-English translation task.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The translation system is tested on an Arabic-to-English translation task.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9676098227500916}, {"text": "Arabic-to-English translation task", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.7712985475858053}]}, {"text": "The training data comes from the UN news sources.", "labels": [], "entities": [{"text": "UN news sources", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.8807832797368368}]}, {"text": "Some punctuation tokenization and some number classing are carried out on the English and the Arabic training data.", "labels": [], "entities": []}, {"text": "In this paper, we present results for two test sets: (1) the devtest set uses data provided by LDC, which consists of: here cased BLEU results are reported on MT03 Arabic-English test set ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9939384460449219}, {"text": "MT03 Arabic-English test set", "start_pos": 159, "end_pos": 187, "type": "DATASET", "confidence": 0.9356719702482224}]}, {"text": "The word casing is added as post-processing step using a statistical model (details are omitted here).", "labels": [], "entities": [{"text": "word casing", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6808917224407196}]}, {"text": "In order to speedup the parameter training we filter the original training data according to the two test sets: for each of the test sets we take all the Arabic substrings up to length \u00a2 \u0096 and filter the parallel training data to include only those training sentence pairs that contain at least one out of these phrases: the 'LDC' training data contains about thousand sentence pairs.", "labels": [], "entities": [{"text": "LDC' training data", "start_pos": 326, "end_pos": 344, "type": "DATASET", "confidence": 0.6028340756893158}]}, {"text": "Two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (.", "labels": [], "entities": []}, {"text": "These block sets also include blocks that occur only once in the training data.", "labels": [], "entities": []}, {"text": "Additionally, some heuristic filtering is used to increase phrase translation accuracy).", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7981961965560913}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.7661707997322083}]}], "tableCaptions": []}