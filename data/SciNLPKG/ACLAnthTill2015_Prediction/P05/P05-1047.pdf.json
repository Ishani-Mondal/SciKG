{"title": [{"text": "A Semantic Approach to IE Pattern Induction", "labels": [], "entities": [{"text": "IE Pattern Induction", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.9780139923095703}]}], "abstractContent": [{"text": "This paper presents a novel algorithm for the acquisition of Information Extraction patterns.", "labels": [], "entities": [{"text": "acquisition of Information Extraction patterns", "start_pos": 46, "end_pos": 92, "type": "TASK", "confidence": 0.796920096874237}]}, {"text": "The approach makes the assumption that useful patterns will have similar meanings to those already identified as relevant.", "labels": [], "entities": []}, {"text": "Patterns are compared using a variation of the standard vector space model in which information from an on-tology is used to capture semantic similarity.", "labels": [], "entities": []}, {"text": "Evaluation shows this algorithm performs well when compared with a previously reported document-centric approach .", "labels": [], "entities": []}], "introductionContent": [{"text": "Developing systems which can be easily adapted to new domains with the minimum of human intervention is a major challenge in Information Extraction (IE).", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 125, "end_pos": 152, "type": "TASK", "confidence": 0.8543636679649353}]}, {"text": "Early IE systems were based on knowledge engineering approaches but suffered from a knowledge acquisition bottleneck.", "labels": [], "entities": [{"text": "IE", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9825376868247986}]}, {"text": "For example, reported that their system required around 1,500 person-hours of expert labour to modify fora new extraction task.", "labels": [], "entities": []}, {"text": "One approach to this problem is to use machine learning to automatically learn the domain-specific information required to port a system.", "labels": [], "entities": []}, {"text": "proposed an algorithm for learning extraction patterns fora small number of examples which greatly reduced the burden on the application developer and reduced the knowledge acquisition bottleneck.", "labels": [], "entities": [{"text": "learning extraction patterns", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.7875498533248901}]}, {"text": "Weakly supervised algorithms, which bootstrap from a small number of examples, have the advantage of requiring only small amounts of annotated data, which is often difficult and time-consuming to produce.", "labels": [], "entities": []}, {"text": "However, this also means that there are fewer examples of the patterns to be learned, making the learning task more challenging.", "labels": [], "entities": []}, {"text": "Providing the learning algorithm with access to additional knowledge can compensate for the limited number of annotated examples.", "labels": [], "entities": []}, {"text": "This paper presents a novel weakly supervised algorithm for IE pattern induction which makes use of the WordNet ontology.", "labels": [], "entities": [{"text": "IE pattern induction", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.9331541260083517}, {"text": "WordNet ontology", "start_pos": 104, "end_pos": 120, "type": "DATASET", "confidence": 0.9522579312324524}]}, {"text": "Extraction patterns are potentially useful for many language processing tasks, including question answering and the identification of lexical relations (such as meronomy and hyponymy).", "labels": [], "entities": [{"text": "question answering", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.8947626650333405}, {"text": "identification of lexical relations", "start_pos": 116, "end_pos": 151, "type": "TASK", "confidence": 0.8585428446531296}]}, {"text": "In addition, IE patterns encode the different ways in which apiece of information can be expressed in text.", "labels": [], "entities": []}, {"text": "For example, \"Acme Inc.", "labels": [], "entities": [{"text": "Acme Inc.", "start_pos": 14, "end_pos": 23, "type": "DATASET", "confidence": 0.9521978298823038}]}, {"text": "fired Jones\", \"Acme Inc.", "labels": [], "entities": [{"text": "Acme Inc", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.9409565329551697}]}, {"text": "let Jones go\", and \"Jones was given notice by his employers, Acme Inc.\" are all ways of expressing the same fact.", "labels": [], "entities": [{"text": "Acme Inc.", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.9193562269210815}]}, {"text": "Consequently the generation of extraction patterns is pertinent to paraphrase identification which is central to many language processing problems.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.9326581358909607}]}, {"text": "We begin by describing the general process of pattern induction and an existing approach, based on the distribution of patterns in a corpus (Section 2).", "labels": [], "entities": [{"text": "pattern induction", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7735899686813354}]}, {"text": "We then introduce anew algorithm which makes use of WordNet to generalise extraction patterns (Section 3) and describe an implementation (Section 4).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9696076512336731}]}, {"text": "Two evaluation regimes are described; one based on the identification of relevant documents and another which aims to identify sentences in a corpus which are relevant fora particular IE task (Section 5).", "labels": [], "entities": [{"text": "IE task", "start_pos": 184, "end_pos": 191, "type": "TASK", "confidence": 0.8790634870529175}]}, {"text": "Results on each of these evaluation regimes are then presented (Sections 6 and 7).", "labels": [], "entities": []}], "datasetContent": [{"text": "Various approaches have been suggested for the evaluation of automatic IE pattern acquisition.", "labels": [], "entities": [{"text": "IE pattern acquisition", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.9256255825360616}]}, {"text": "judged the precision of patterns learned by reviewing them manually.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9993616938591003}]}, {"text": "developed an indirect method which allowed automatic evaluation.", "labels": [], "entities": []}, {"text": "In addition to learning a set of patterns, their system also notes the relevance of documents based on the current set of accepted patterns.", "labels": [], "entities": []}, {"text": "Assuming the subset of documents relevant to a particular IE scenario is known, it is possible to use these relevance judgements to determine how accurately a given set of patterns can discriminate the relevant documents from the irrelevant.", "labels": [], "entities": [{"text": "IE scenario", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9219721555709839}]}, {"text": "This evaluation is similar to the \"text-filtering\" sub-task used in the sixth Message Understanding Conference (MUC-6) in which systems were evaluated according to their ability to identify the documents relevant to the extraction task.", "labels": [], "entities": [{"text": "Message Understanding Conference (MUC-6)", "start_pos": 78, "end_pos": 118, "type": "TASK", "confidence": 0.709574763973554}]}, {"text": "The document filtering evaluation technique was used to allow comparison with previous studies.", "labels": [], "entities": [{"text": "document filtering evaluation", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.853975236415863}]}, {"text": "Identifying the document containing relevant information can be considered as a preliminary stage of an IE task.", "labels": [], "entities": [{"text": "Identifying the document containing relevant information", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8333849807580312}, {"text": "IE task", "start_pos": 104, "end_pos": 111, "type": "TASK", "confidence": 0.9348442256450653}]}, {"text": "A further step is to identify the sentences within those documents which are relevant.", "labels": [], "entities": []}, {"text": "This \"sentence filtering\" task is a more fine-grained evaluation and is likely to provide more information about how well a given set of patterns is likely to perform as part of an IE system.", "labels": [], "entities": [{"text": "sentence filtering\"", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.7917882899443308}, {"text": "IE", "start_pos": 181, "end_pos": 183, "type": "TASK", "confidence": 0.9421330690383911}]}, {"text": "Soderland (1999) developed aversion of the MUC-6 corpus in which events are marked at the sentence level.", "labels": [], "entities": [{"text": "MUC-6 corpus", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.8248335421085358}]}, {"text": "The set of patterns learned by the algorithm after each iteration can be compared against this corpus to determine how accurately they identify the relevant sentences for this extraction task.", "labels": [], "entities": []}, {"text": "The evaluation corpus used for the experiments was compiled from the training and testing corpus used in MUC-6, where the task was to extract information about the movements of executives from newswire texts.", "labels": [], "entities": [{"text": "MUC-6", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.7991340160369873}]}, {"text": "A document is relevant if it has a filled template associated with it.", "labels": [], "entities": []}, {"text": "590 documents from aversion of the MUC-6 evaluation corpus described by were used.", "labels": [], "entities": [{"text": "MUC-6 evaluation corpus", "start_pos": 35, "end_pos": 58, "type": "DATASET", "confidence": 0.8992973566055298}]}, {"text": "After the pre-processing stages described in Section 4, the MUC-6 corpus produced 15,407 pattern tokens from 11,294 different types.", "labels": [], "entities": [{"text": "MUC-6 corpus", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.9056214094161987}]}, {"text": "10,512 patterns appeared just once and these were effectively discarded since our learning algorithm only considers patterns which occur at least twice (see Section 3.3).", "labels": [], "entities": []}, {"text": "The document-centric approach benefits from a large corpus containing a mixture of relevant and irrelevant documents.", "labels": [], "entities": []}, {"text": "We provided this using a subset of the Reuters Corpus Volume I () which, like the MUC-6 corpus, consists of newswire: Seed patterns for extraction task texts.", "labels": [], "entities": [{"text": "Reuters Corpus Volume I", "start_pos": 39, "end_pos": 62, "type": "DATASET", "confidence": 0.9626903235912323}, {"text": "MUC-6 corpus", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.9788609147071838}]}, {"text": "3000 documents relevant to the management succession task (identified using document metadata) and 3000 irrelevant documents were used to produce the supplementary corpus.", "labels": [], "entities": []}, {"text": "This supplementary corpus yielded 126,942 pattern tokens and 79,473 types with 14,576 of these appearing more than once.", "labels": [], "entities": []}, {"text": "Adding the supplementary corpus to the data set used by the document-centric approach led to an improvement of around 15% on the document filtering task and over 70% for sentence filtering.", "labels": [], "entities": [{"text": "document filtering task", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.812343974908193}, {"text": "sentence filtering", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.7739734947681427}]}, {"text": "It was not used for the semantic similarity algorithm since there was no benefit.", "labels": [], "entities": [{"text": "semantic similarity algorithm", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.8342320322990417}]}, {"text": "The set of seed patterns listed in are indicative of the management succession extraction task and were used for these experiments.", "labels": [], "entities": [{"text": "management succession extraction task", "start_pos": 57, "end_pos": 94, "type": "TASK", "confidence": 0.8665080219507217}]}], "tableCaptions": [{"text": " Table 2: Comparison of the different approaches over 120 iterations", "labels": [], "entities": []}]}