{"title": [{"text": "Improving Pronoun Resolution Using Statistics-Based Semantic Compatibility Information", "labels": [], "entities": [{"text": "Improving Pronoun Resolution", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8605406483014425}]}], "abstractContent": [{"text": "In this paper we focus on how to improve pronoun resolution using the statistics-based semantic compatibility information.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8009885251522064}]}, {"text": "We investigate two unexplored issues that influence the effectiveness of such information: statistics source and learning framework.", "labels": [], "entities": []}, {"text": "Specifically, we for the first time propose to utilize the web and the twin-candidate model, in addition to the previous combination of the corpus and the single-candidate model, to compute and apply the semantic information.", "labels": [], "entities": []}, {"text": "Our study shows that the semantic compatibility obtained from the web can be effectively incorporated in the twin-candidate learning model and significantly improve the resolution of neutral pronouns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic compatibility is an important factor for pronoun resolution.", "labels": [], "entities": [{"text": "Semantic compatibility", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7585598528385162}, {"text": "pronoun resolution", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8190082013607025}]}, {"text": "Since pronouns, especially neutral pronouns, carry little semantics of their own, the compatibility between an anaphor and its antecedent candidate is commonly evaluated by examining the relationships between the candidate and the anaphor's context, based on the statistics that the corresponding predicate-argument tuples occur in a particular large corpus.", "labels": [], "entities": []}, {"text": "Consider the example given in the work of: (1) They know full well that companies held tax money aside for collection later on the basis that the government said it 1 was going to collect it 2 . For anaphor it 1 , the candidate government should have higher semantic compatibility than money because government collect is supposed to occur more frequently than money collect in a large corpus.", "labels": [], "entities": []}, {"text": "A similar pattern could also be observed for it 2 . So far, the corpus-based semantic knowledge has been successfully employed in several anaphora resolution systems.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.7521726191043854}]}, {"text": "proposed a heuristics-based approach to pronoun resolution.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7682145535945892}]}, {"text": "It determined the preference of candidates based on predicate-argument frequencies.", "labels": [], "entities": []}, {"text": "Recently, presented an unsupervised approach to coreference resolution, which mined the co-referring NP pairs with similar predicatearguments from a large corpus using a bootstrapping method.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.9741431474685669}]}, {"text": "However, the utility of the corpus-based semantics for pronoun resolution is often argued., for example, explored the usage of the corpus-based statistics in supervised learning based systems, and found that such information did not produce apparent improvement for the overall pronoun resolution.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.8147753477096558}, {"text": "pronoun resolution", "start_pos": 278, "end_pos": 296, "type": "TASK", "confidence": 0.7370052337646484}]}, {"text": "Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g.,,,).", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8583168387413025}]}, {"text": "Could the relatively noisy semantic knowledge give us further system improvement?", "labels": [], "entities": []}, {"text": "In this paper we focus on improving pronominal anaphora resolution using automatically computed semantic compatibility information.", "labels": [], "entities": [{"text": "pronominal anaphora resolution", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.6781945327917734}]}, {"text": "We propose to enhance the utility of the statistics-based knowledge from two aspects: Statistics source.", "labels": [], "entities": []}, {"text": "Corpus-based knowledge usually suffers from data sparseness problem.", "labels": [], "entities": []}, {"text": "That is, many predicate-argument tuples would be unseen even in a large corpus.", "labels": [], "entities": []}, {"text": "A possible solution is the web.", "labels": [], "entities": []}, {"text": "It is believed that the size of the web is thousands of times larger than normal large corpora, and the counts obtained from the web are highly correlated with the counts from large balanced corpora for predicate-argument bi-grams (.", "labels": [], "entities": []}, {"text": "So far the web has been utilized in nominal anaphora resolution () to determine the semantic relation between an anaphor and candidate pair.", "labels": [], "entities": [{"text": "nominal anaphora resolution", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6276349723339081}]}, {"text": "However, to our knowledge, using the web to help pronoun resolution still remains unexplored.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7448568940162659}]}, {"text": "Commonly, the predicateargument statistics is incorporated into anaphora resolution systems as a feature.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7237613350152969}]}, {"text": "What kind of learning framework is suitable for this feature?", "labels": [], "entities": []}, {"text": "Previous approaches to anaphora resolution adopt the singlecandidate model, in which the resolution is done on an anaphor and one candidate at a time ().", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.8748767971992493}]}, {"text": "However, as the purpose of the predicate-argument statistics is to evaluate the preference of the candidates in semantics, it is possible that the statistics-based semantic feature could be more effectively applied in the twincandidate () that focusses on the preference relationships among candidates.", "labels": [], "entities": []}, {"text": "In our work we explore the acquisition of the semantic compatibility information from the corpus and the web, and the incorporation of such semantic information in the single-candidate model and the twin-candidate model.", "labels": [], "entities": []}, {"text": "We systematically evaluate the combinations of different statistics sources and learning frameworks in terms of their effectiveness in helping the resolution.", "labels": [], "entities": [{"text": "resolution", "start_pos": 147, "end_pos": 157, "type": "TASK", "confidence": 0.9807189702987671}]}, {"text": "Results on the MUC data set show that for neutral pronoun resolution in which an anaphor has no specific semantic category, the web-based semantic information would be the most effective when applied in the twin-candidate model: Not only could such a system significantly improve the baseline without the semantic feature, it also outperforms the system with the combination of the corpus and the single-candidate model (by 11.5% success).", "labels": [], "entities": [{"text": "MUC data set", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.9720887939135233}, {"text": "neutral pronoun resolution", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.7740312814712524}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the acquisition of the semantic compatibility information from the corpus and the web.", "labels": [], "entities": []}, {"text": "Section 3 discusses the application of the statistics in the single-candidate and twin-candidate learning models.", "labels": [], "entities": []}, {"text": "Section 4 gives the experimental results, and finally, Section 5 gives the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our study we were only concerned about the thirdperson pronoun resolution.", "labels": [], "entities": [{"text": "thirdperson pronoun resolution", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.6922630071640015}]}, {"text": "With an attempt to examine the effectiveness of the semantic feature on different types of pronouns, the whole resolution was divided into neutral pronoun (it & they) resolution and personal pronoun (he & she) resolution.", "labels": [], "entities": [{"text": "neutral pronoun (it & they) resolution", "start_pos": 139, "end_pos": 177, "type": "TASK", "confidence": 0.7952829077839851}, {"text": "personal pronoun (he & she) resolution", "start_pos": 182, "end_pos": 220, "type": "TASK", "confidence": 0.7124755755066872}]}, {"text": "The experiments were done on the newswire domain, using MUC corpus (Wall Street Journal articles).", "labels": [], "entities": [{"text": "MUC corpus (Wall Street Journal articles)", "start_pos": 56, "end_pos": 97, "type": "DATASET", "confidence": 0.9132488742470741}]}, {"text": "The training was done on 150 documents from MUC-6 coreference data set, while the testing was on the 50 formal-test documents of and.", "labels": [], "entities": [{"text": "MUC-6 coreference data set", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.9630643725395203}]}, {"text": "Throughout the experiments, default learning parameters were applied to the C5 algorithm.", "labels": [], "entities": []}, {"text": "The performance was evaluated based on success, the ratio of the number of correctly resolved anaphors over the total number of anaphors.", "labels": [], "entities": []}, {"text": "An input raw text was preprocessed automatically by a pipeline of NLP components.", "labels": [], "entities": []}, {"text": "The noun phrase identification and the predicate-argument extraction were done based on the results of a chunk tagger, which was trained for the shared task of CoNLL-2000 and achieved 92% accuracy ().", "labels": [], "entities": [{"text": "noun phrase identification", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.7026183009147644}, {"text": "predicate-argument extraction", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.7196827530860901}, {"text": "CoNLL-2000", "start_pos": 160, "end_pos": 170, "type": "DATASET", "confidence": 0.86402827501297}, {"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9980323910713196}]}, {"text": "The recognition of NEs as well as their semantic categories was done by a HMM based NER, which was trained for the MUC NE task and obtained high F-scores of 96.9% (MUC-6) and 94.3% (MUC-7) ().", "labels": [], "entities": [{"text": "recognition of NEs", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8751330773035685}, {"text": "MUC NE task", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.6328204770882925}, {"text": "F-scores", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9978037476539612}]}, {"text": "For each anaphor, the markables occurring within the current and previous two sentences were taken as the initial candidates.", "labels": [], "entities": []}, {"text": "Those with mismatched number and gender agreements were filtered from the candidate set.", "labels": [], "entities": []}, {"text": "Also, pronouns or NEs that disagreed in person with the anaphor were removed in advance.", "labels": [], "entities": []}, {"text": "For the training set, there are totally 645 neutral pronouns and 385 personal pronouns with non-empty candidate set, while for the testing set, the number is 245 and 197.", "labels": [], "entities": []}, {"text": "Web-based feature vs. Corpus-based feature The third column of the table lists the results using the web-based compatibility feature for neutral pronouns.", "labels": [], "entities": []}, {"text": "Under both SC and TC models, incorporation of the web-based feature significantly boosts the performance of the baseline: For the best system in the SC model and the TC model, the success rate is improved significantly by around 4.9% and 5.3%, respectively.", "labels": [], "entities": []}, {"text": "A similar pattern of improvement could be seen for the corpus-based semantic feature.", "labels": [], "entities": []}, {"text": "However, the increase is not as large as using the web-based feature: Under the two learning models, the success rate of the best system with the corpus-based feature rises by up to 2.0% and 2.8% respectively, about 2.9% and 2.5% less than that of the counterpart systems with the web-based feature.", "labels": [], "entities": []}, {"text": "The larger size and the better counts of the web against the corpus, as reported in Section 4.2, should contribute to the better performance.", "labels": [], "entities": []}, {"text": "Single-candidate model vs. Twin-Candidate model The difference between the SC and the TC model is obvious from the table.", "labels": [], "entities": []}, {"text": "For the N-Pron and P-Pron resolution, the systems under TC could outperform the counterpart systems under SC by above 5% and 8% success, respectively.", "labels": [], "entities": [{"text": "TC", "start_pos": 56, "end_pos": 58, "type": "DATASET", "confidence": 0.7715995907783508}]}, {"text": "In addition, the utility of the statistics-based semantic feature is more salient under TC than under SC for N-Pron resolution: the best gains using the corpus-based and the web-based semantic features under TC are 2.9% and 5.3% respectively, higher than those under the SC model using either un-normalized semantic features (1.6% and 3.3%), or normalized semantic features (2.0% and 4.9%).", "labels": [], "entities": [{"text": "N-Pron resolution", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.7117893099784851}]}, {"text": "Although under SC, the normalized semantic feature could result in again close to under TC, its utility is not stable: with metric frequency, using the normalized feature performs even worse than using the un-normalized one.", "labels": [], "entities": []}, {"text": "These results not only affirm the claim by that the TC model is superior to the SC model for pronoun resolution, but also indicate that TC is more reliable than SC in applying the statistics-based semantic feature, for N-Pron resolution.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7329492717981339}, {"text": "N-Pron resolution", "start_pos": 219, "end_pos": 236, "type": "TASK", "confidence": 0.7247818261384964}]}, {"text": "Web+TC vs. Other combinations The above analysis has exhibited the superiority of the web over the corpus, and the TC model over the SC model.", "labels": [], "entities": []}, {"text": "The experimental results also reveal that using the the web-based semantic feature together with the TC model is able to further boost the resolution performance for neutral pronouns.", "labels": [], "entities": []}, {"text": "The system with such a Web+TC combination could achieve a high success of 79.2%, defeating all the other possible combinations.", "labels": [], "entities": []}, {"text": "Especially, it considerably outperforms (up to 11.5% success) the system with the Corpus+SC combination, which is commonly adopted in previous work (e.g.,).", "labels": [], "entities": []}, {"text": "Personal pronoun resolution vs. Neutral pronoun resolution Interestingly, the statistics-based semantic feature has no effect on the resolution of personal pronouns, as shown in the table 2.", "labels": [], "entities": [{"text": "Personal pronoun resolution", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6636719206968943}, {"text": "Neutral pronoun resolution", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.6372422774632772}]}, {"text": "We found in the learned decision trees such a feature did not occur (SC) or only occurred in bottom nodes (TC).", "labels": [], "entities": []}, {"text": "This should be because personal pronouns have strong restriction on the semantic category (i.e., human) of the candidates.", "labels": [], "entities": []}, {"text": "A non-human candidate, even with a high predicate-argument statistics, could    not be used as the antecedent (e.g. company said in the sentence \".", "labels": [], "entities": []}, {"text": "In fact, our analysis of the current data set reveals that most P-Prons refer back to a P-Pron or NE candidate whose semantic category (human) has been determined.", "labels": [], "entities": []}, {"text": "That is, simply using features NE and Pron is sufficient to guarantee a high success, and thus the relatively weak semantic feature would not betaken in the learned decision tree for resolution.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The performance of different resolution systems", "labels": [], "entities": []}]}