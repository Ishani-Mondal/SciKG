{"title": [{"text": "Boosting-based parse reranking with subtree features", "labels": [], "entities": [{"text": "Boosting-based parse reranking", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6262124081452688}]}], "abstractContent": [{"text": "This paper introduces anew application of boosting for parse reranking.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.9187142550945282}]}, {"text": "Several parsers have been proposed that utilize the all-subtrees representation (e.g., tree kernel and data oriented parsing).", "labels": [], "entities": [{"text": "data oriented parsing", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.6888741850852966}]}, {"text": "This paper argues that such an all-subtrees representation is extremely redundant and a comparable accuracy can be achieved using just a small set of subtrees.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9990664124488831}]}, {"text": "We show how the boosting algorithm can be applied to the all-subtrees representation and how it selects a small and relevant feature set efficiently.", "labels": [], "entities": []}, {"text": "Two experiments on parse rerank-ing show that our method achieves comparable or even better performance than kernel methods and also improves the testing efficiency.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work on statistical natural language parsing and tagging has explored discriminative techniques.", "labels": [], "entities": [{"text": "statistical natural language parsing", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.6895144283771515}]}, {"text": "One of the novel discriminative approaches is reranking, where discriminative machine learning algorithms are used to rerank the n-best outputs of generative or conditional parsers.", "labels": [], "entities": [{"text": "reranking", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.9624494910240173}, {"text": "generative or conditional parsers", "start_pos": 147, "end_pos": 180, "type": "TASK", "confidence": 0.6753414422273636}]}, {"text": "The discriminative reranking methods allow us to incorporate various kinds of features to distinguish the correct parse tree from all other candidates.", "labels": [], "entities": []}, {"text": "With such feature design flexibility, it is nontrivial to employ an appropriate feature set that has a good discriminative ability for parse reranking.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 135, "end_pos": 150, "type": "TASK", "confidence": 0.9511002600193024}]}, {"text": "In early studies, feature sets were given heuristically by simply preparing task-dependent feature templates).", "labels": [], "entities": []}, {"text": "These ad-hoc solutions might provide us with reasonable levels of per- * Currently, Google Japan Inc., taku@google.com formance.", "labels": [], "entities": [{"text": "Google Japan Inc.", "start_pos": 84, "end_pos": 101, "type": "DATASET", "confidence": 0.9378487666447958}]}, {"text": "However, they are highly task dependent and require careful design to create the optimal feature set for each task.", "labels": [], "entities": []}, {"text": "Kernel methods offer an elegant solution to these problems.", "labels": [], "entities": []}, {"text": "They can work on a potentially huge or even infinite number of features without a loss of generalization.", "labels": [], "entities": []}, {"text": "The best known kernel for modeling a tree is the tree kernel, which argues that a feature vector is implicitly composed of the counts of subtrees.", "labels": [], "entities": []}, {"text": "Although kernel methods are general and can cover almost all useful features, the set of subtrees that is used is extremely redundant.", "labels": [], "entities": []}, {"text": "The main question addressed in this paper concerns whether it is possible to achieve a comparable or even better accuracy using just a small and non-redundant set of subtrees.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9981048107147217}]}, {"text": "In this paper, we present anew application of boosting for parse reranking.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.9076068699359894}]}, {"text": "While tree kernel implicitly uses the all-subtrees representation, our boosting algorithm uses it explicitly.", "labels": [], "entities": []}, {"text": "Although this set-up makes the feature space large, the l 1 -norm regularization achived by boosting automatically selects a small and relevant feature set.", "labels": [], "entities": []}, {"text": "Such a small feature set is useful in practice, as it is interpretable and makes the parsing (reranking) time faster.", "labels": [], "entities": []}, {"text": "We also incorporate a variant of the branch-and-bound technique to achieve efficient feature selection in each boosting iteration.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for section 23 of the WSJ Treebank", "labels": [], "entities": [{"text": "WSJ Treebank", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.9155832231044769}]}, {"text": " Table 2: Results of shallow parsing", "labels": [], "entities": [{"text": "parsing", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.7281177043914795}]}]}