{"title": [{"text": "Machine Learning for Coreference Resolution: From Local Classification to Global Ranking", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.9825879633426666}, {"text": "Global Ranking", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.5726145058870316}]}], "abstractContent": [{"text": "In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coref-erence systems.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.9685411155223846}]}, {"text": "We propose a set of partition-based features to learn a ranking model for distinguishing good and bad partitions.", "labels": [], "entities": []}, {"text": "Our approach compares favorably to two state-of-the-art coreference systems when evaluated on three standard coreference data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent research in coreference resolution -the problem of determining which noun phrases (NPs) in a text or dialogue refer to which real-world entity -has exhibited a shift from knowledgebased approaches to data-driven approaches, yielding learning-based coreference systems that rival their hand-crafted counterparts in performance (e.g.,,, ,,).", "labels": [], "entities": [{"text": "coreference resolution -the problem of determining which noun phrases (NPs) in a text or dialogue refer to which real-world entity", "start_pos": 19, "end_pos": 149, "type": "Description", "confidence": 0.6947578243587328}]}, {"text": "The central idea behind the majority of these learningbased approaches is to recast coreference resolution as a binary classification task.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.910441666841507}]}, {"text": "Specifically, a classifier is first trained to determine whether two NPs in a document are co-referring or not.", "labels": [], "entities": []}, {"text": "A separate clustering mechanism then coordinates the possibly contradictory pairwise coreference classification decisions and constructs a partition on the given set of NPs, with one cluster for each set of coreferent NPs.", "labels": [], "entities": [{"text": "coreference classification", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.8384668827056885}]}, {"text": "Though reasonably successful, this \"standard\" approach is not as robust as one may think.", "labels": [], "entities": []}, {"text": "First, design decisions such as the choice of the learning algorithm and the clustering procedure are apparently critical to system performance, but are often made in an ad-hoc and unprincipled manner that maybe suboptimal from an empirical point of view.", "labels": [], "entities": []}, {"text": "Second, this approach makes no attempt to search through the space of possible partitions when given a set of NPs to be clustered, employing instead a greedy clustering procedure to construct a partition that maybe far from optimal.", "labels": [], "entities": []}, {"text": "Another potential weakness of this approach concerns its inability to directly optimize for clusteringlevel accuracy: the coreference classifier is trained and optimized independently of the clustering procedure to be used, and hence improvements in classification accuracy do not guarantee corresponding improvements in clustering-level accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.8535837531089783}, {"text": "accuracy", "start_pos": 265, "end_pos": 273, "type": "METRIC", "confidence": 0.8283158540725708}, {"text": "accuracy", "start_pos": 338, "end_pos": 346, "type": "METRIC", "confidence": 0.8681366443634033}]}, {"text": "Our goal in this paper is to improve the robustness of the standard approach by addressing the above weaknesses.", "labels": [], "entities": []}, {"text": "Specifically, we propose the following procedure for coreference resolution: given a set of NPs to be clustered, (1) use pre-selected learningbased coreference systems to generate candidate partitions of the NPs, and then (2) apply an automatically acquired ranking model to rank these candidate hypotheses, selecting the best one to be the final partition.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.9629664421081543}]}, {"text": "The key features of this approach are: Minimal human decision making.", "labels": [], "entities": [{"text": "Minimal human decision making", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.8945123255252838}]}, {"text": "In contrast to the standard approach, our method obviates, to a large extent, the need to make tough or potentially suboptimal design decisions.", "labels": [], "entities": []}, {"text": "1 For instance, if we We still need to determine the \u00a1 coreference systems to be employed in our framework, however.", "labels": [], "entities": []}, {"text": "Fortunately, the choice of \u00a1 is flexible, and can be as large as we want subject to the cannot decide whether learner is better to use than learner \u00a1 in a coreference system, we can simply create two copies of the system with one employing and the other \u00a1 , and then add both into our preselected set of coreference systems.", "labels": [], "entities": []}, {"text": "Generation of multiple candidate partitions.", "labels": [], "entities": []}, {"text": "Although an exhaustive search for the best partition is not computationally feasible even fora document with a moderate number of NPs, our approach explores a larger portion of the search space than the standard approach via generating multiple hypotheses, making it possible to find a potentially better partition of the NPs under consideration.", "labels": [], "entities": []}, {"text": "Optimization for clustering-level accuracy via ranking.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9276792407035828}]}, {"text": "As mentioned above, the standard approach trains and optimizes a coreference classifier without necessarily optimizing for clustering-level accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9421650767326355}]}, {"text": "In contrast, we attempt to optimize our ranking model with respect to the target coreference scoring function, essentially by training it in such away that a higher scored candidate partition (according to the scoring function) would be assigned a higher rank (see Section 3.2 for details).", "labels": [], "entities": []}, {"text": "Perhaps even more importantly, our approach provides a general framework for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.9694729745388031}]}, {"text": "Instead of committing ourselves to a particular resolution method as in previous approaches, our framework makes it possible to leverage the strengths of different methods by allowing them to participate in the generation of candidate partitions.", "labels": [], "entities": []}, {"text": "We evaluate our approach on three standard coreference data sets using two different scoring metrics.", "labels": [], "entities": []}, {"text": "In our experiments, our approach compares favorably to two state-of-the-art coreference systems adopting the standard machine learning approach, outperforming them by as much as 4-7% on the three data sets for one of the performance metrics.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation purposes, we use the ACE (Automatic Content Extraction) coreference corpus, which is composed of three data sets created from three different news sources, namely, broadcast news (BNEWS), newspaper (NPAPER), and newswire (NWIRE).", "labels": [], "entities": []}, {"text": "Statistics of these data sets are shown in.", "labels": [], "entities": []}, {"text": "In our experiments, we use the training texts to acquire coreference classifiers and evaluate the resulting systems on the test texts with respect to two commonly-used coreference scoring programs: the MUC scorer ( and the B-CUBED scorer (Bagga and Baldwin, 1998).", "labels": [], "entities": [{"text": "MUC scorer", "start_pos": 202, "end_pos": 212, "type": "DATASET", "confidence": 0.7203164398670197}]}], "tableCaptions": [{"text": " Table 2: Statistics for the ACE corpus.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.890605241060257}]}, {"text": " Table 3: Results for the three ACE data sets obtained via the MUC scoring program.", "labels": [], "entities": [{"text": "ACE data sets", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.8370998104413351}, {"text": "MUC scoring program", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.8420306841532389}]}, {"text": " Table 4: Results for the three ACE data sets obtained via the B-CUBED scoring program.", "labels": [], "entities": [{"text": "ACE data sets", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.8217849830786387}, {"text": "B-CUBED", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9350360631942749}]}]}