{"title": [{"text": "What to do when lexicalization fails: parsing German with suffix analysis and smoothing", "labels": [], "entities": [{"text": "parsing German", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.8424401581287384}, {"text": "suffix analysis", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7043922245502472}, {"text": "smoothing", "start_pos": 78, "end_pos": 87, "type": "TASK", "confidence": 0.5569011569023132}]}], "abstractContent": [{"text": "In this paper, we present an unlexical-ized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2, higher than previously reported results on the NEGRA corpus.", "labels": [], "entities": [{"text": "labelled bracket F-score", "start_pos": 119, "end_pos": 143, "type": "METRIC", "confidence": 0.5804783006509145}, {"text": "NEGRA corpus", "start_pos": 200, "end_pos": 212, "type": "DATASET", "confidence": 0.9673210978507996}]}, {"text": "In addition to the high accuracy of the model, the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9992766976356506}]}], "introductionContent": [{"text": "Recent research on German statistical parsing has shown that lexicalization adds little to parsing performance in German (.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.5695733428001404}]}, {"text": "A likely cause is the relative productivity of German morphology compared to that of English: German has a higher type/token ratio for words, making sparse data problems more severe.", "labels": [], "entities": []}, {"text": "There are at least two solutions to this problem: first, to use better models of morphology or, second, to make unlexicalized parsing more accurate.", "labels": [], "entities": []}, {"text": "We investigate both approaches in this paper.", "labels": [], "entities": []}, {"text": "In particular, we develop a parser for German which attains the highest performance known to us by making use of smoothing and a highly-tuned suffix analyzer for guessing part-of-speech (POS) tags from the input text.", "labels": [], "entities": []}, {"text": "Rather than relying on smoothing and suffix analysis alone, we also utilize treebank transformations) instead of a grammar induced directly from a treebank.", "labels": [], "entities": [{"text": "suffix analysis", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.7274003475904465}]}, {"text": "The organization of the paper is as follows: Section 2 summarizes some important aspects of our treebank corpus.", "labels": [], "entities": [{"text": "treebank corpus", "start_pos": 96, "end_pos": 111, "type": "DATASET", "confidence": 0.8368847072124481}]}, {"text": "In Section 3 we outline several techniques for improving the performance of unlexicalized parsing without using smoothing, including treebank transformations, and the use of suffix analysis.", "labels": [], "entities": [{"text": "suffix analysis", "start_pos": 174, "end_pos": 189, "type": "TASK", "confidence": 0.752630352973938}]}, {"text": "We show that suffix analysis is not helpful on the treebank grammar, but it does increase performance if used in combination with the treebank transformations we present.", "labels": [], "entities": [{"text": "suffix analysis", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.8223685622215271}]}, {"text": "Section 4 describes how smoothing can be incorporated into an unlexicalized grammar to achieve state-of-the-art results in German.", "labels": [], "entities": []}, {"text": "Rather using one smoothing algorithm, we use three different approaches, allowing us to compare the relative performance of each.", "labels": [], "entities": []}, {"text": "An error analysis is presented in Section 5, which points to several possible areas of future research.", "labels": [], "entities": []}, {"text": "We follow the error analysis with a comparison with related work in Section 6.", "labels": [], "entities": [{"text": "error", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.9685520529747009}]}, {"text": "Finally we offer concluding remarks in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Effect of rule type and suffix analysis.", "labels": [], "entities": [{"text": "rule type and suffix analysis", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.6055568397045136}]}, {"text": " Table 2: Effect of re-annotation and suffix analysis  with Markov rules.", "labels": [], "entities": [{"text": "suffix analysis", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.854677826166153}]}, {"text": " Table 3: Effect of various smoothing algorithms.", "labels": [], "entities": []}]}