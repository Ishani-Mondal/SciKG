{"title": [{"text": "Reading Level Assessment Using Support Vector Machines and Statistical Language Models", "labels": [], "entities": [{"text": "Reading Level Assessment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.624075581630071}]}], "abstractContent": [{"text": "Reading proficiency is a fundamental component of language competency.", "labels": [], "entities": [{"text": "Reading proficiency", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7075926661491394}]}, {"text": "However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers.", "labels": [], "entities": []}, {"text": "This task can be addressed with natural language processing technology to assess reading level.", "labels": [], "entities": []}, {"text": "Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models.", "labels": [], "entities": []}, {"text": "In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.", "labels": [], "entities": []}], "introductionContent": [{"text": "The U.S. educational system is faced with the challenging task of educating growing numbers of students for whom English is a second language (U.S. Dept. of).", "labels": [], "entities": [{"text": "U.S. Dept. of)", "start_pos": 143, "end_pos": 157, "type": "DATASET", "confidence": 0.8977060616016388}]}, {"text": "In the 2001-2002 school year, Washington state had 72,215 students (7.2% of all students) instate programs for Limited English Proficient (LEP) students ().", "labels": [], "entities": []}, {"text": "In the same year, one quarter of all public school students in California and one in seven students in Texas were classified as LEP (U.S. Dept. of).", "labels": [], "entities": [{"text": "LEP", "start_pos": 128, "end_pos": 131, "type": "METRIC", "confidence": 0.9570391774177551}]}, {"text": "Reading is a critical part of language and educational development, but finding appropriate reading material for LEP students is often difficult.", "labels": [], "entities": []}, {"text": "To meet the needs of their students, bilingual education instructors seek out \"high interest level\" texts at low reading levels, e.g. texts at a first or second grade reading level that support the fifth grade science curriculum.", "labels": [], "entities": []}, {"text": "Teachers need to find material at a variety of levels, since students need different texts to read independently and with help from the teacher.", "labels": [], "entities": []}, {"text": "Finding reading materials that fulfill these requirements is difficult and time-consuming, and teachers are often forced to rewrite texts themselves to suit the varied needs of their students.", "labels": [], "entities": []}, {"text": "Natural language processing (NLP) technology is an ideal resource for automating the task of selecting appropriate reading material for bilingual students.", "labels": [], "entities": [{"text": "Natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7560647378365198}]}, {"text": "Information retrieval systems successfully find topical materials and even answer complex queries in text databases and on the World Wide Web.", "labels": [], "entities": [{"text": "Information retrieval", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8031919300556183}]}, {"text": "However, an effective automated way to assess the reading level of the retrieved text is still needed.", "labels": [], "entities": []}, {"text": "In this work, we develop a method of reading level assessment that uses support vector machines (SVMs) to combine features from statistical language models (LMs), parse trees, and other traditional features used in reading level assessment.", "labels": [], "entities": [{"text": "reading level assessment", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.6926546692848206}]}, {"text": "The results presented hereon reading level assessment are part of a larger project to develop teacher-support tools for bilingual education instructors.", "labels": [], "entities": []}, {"text": "The larger project will include a text simplification system, adapting paraphrasing and summarization techniques.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8076939880847931}, {"text": "summarization", "start_pos": 88, "end_pos": 101, "type": "TASK", "confidence": 0.9747911095619202}]}, {"text": "Coupled with an information retrieval system, these tools will be used to select and simplify reading material in multiple languages for use by language learners.", "labels": [], "entities": []}, {"text": "In addition to students in bilingual education, these tools will also be useful for those with reading-related learning disabili-ties and adult literacy students.", "labels": [], "entities": []}, {"text": "In both of these situations, as in the bilingual education case, the student's reading level does not match his/her intellectual level and interests.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes related work on reading level assessment.", "labels": [], "entities": []}, {"text": "Section 3 describes the corpora used in our work.", "labels": [], "entities": []}, {"text": "In Section 4 we present our approach to the task, and Section 5 contains experimental results.", "labels": [], "entities": []}, {"text": "Section 6 provides a summary and description of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divide the Weekly Reader corpus described in Section 3 into separate training, development, and test sets.", "labels": [], "entities": [{"text": "Weekly Reader corpus", "start_pos": 14, "end_pos": 34, "type": "DATASET", "confidence": 0.9641949733098348}]}, {"text": "The number of articles in each set is shown in  measures.", "labels": [], "entities": []}, {"text": "For comparison to other methods, e.g. Flesch-Kincaid and Lexile, which are not binary classifiers, we consider the percentage of articles which are misclassified by more than one grade level.", "labels": [], "entities": [{"text": "Lexile", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.9338211417198181}]}, {"text": "Detection Error Tradeoff curves show the tradeoff between misses and false alarms for different threshold values for the classifiers.", "labels": [], "entities": [{"text": "Detection Error Tradeoff", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.8528014818827311}]}, {"text": "\"Misses\" are positive examples of a class that are misclassified as negative examples; \"false alarms\" are negative examples misclassified as positive.", "labels": [], "entities": []}, {"text": "DET curves have been used in other detection tasks in language processing, e.g..", "labels": [], "entities": []}, {"text": "We use these curves to visualize the tradeoff between the two types of errors, and select the minimum cost operating point in order to get a threshold for precision and recall calculations.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9993595480918884}, {"text": "recall", "start_pos": 169, "end_pos": 175, "type": "METRIC", "confidence": 0.9969695210456848}]}, {"text": "The minimum cost operating point depends on the relative costs of misses and false alarms; it is conceivable that one type of error might be more serious than the other.", "labels": [], "entities": []}, {"text": "After consultation with teachers (future users of our system), we concluded that there are pros and cons to each side, so for the purpose of this analysis we weighted the two types of errors equally.", "labels": [], "entities": []}, {"text": "In this work, the minimum cost operating point is selected by averaging the percentages of misses and false alarms at each point and choosing the point with the lowest average.", "labels": [], "entities": []}, {"text": "Unless otherwise noted, errors reported are associated with these actual operating points, which may not lie on the convex hull of the DET curve.", "labels": [], "entities": [{"text": "DET curve", "start_pos": 135, "end_pos": 144, "type": "DATASET", "confidence": 0.82650226354599}]}, {"text": "Precision and recall are often used to assess information retrieval systems, and our task is similar.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9845802783966064}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9985063672065735}, {"text": "information retrieval", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.6929614096879959}]}, {"text": "Precision indicates the percentage of the retrieved documents that are relevant, in this case the percentage of detected documents that match the target grade level.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.99333655834198}]}, {"text": "Recall indicates the percentage of the total number of relevant documents in the data set that are retrieved, in this case the percentage of the total number of documents from the target level that are detected.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9901919364929199}]}, {"text": "The minimum cost error rates for these classifiers, indicated by large dots in the plot, are in the range of 33-43%, with only one over 40%.", "labels": [], "entities": []}, {"text": "The curves for bigram and unigram models have similar shapes, but the trigram models outperform the lower-order models.", "labels": [], "entities": []}, {"text": "Error rates for the bigram models range from 37-45% and the unigram models have error rates in the 39-49% range, with all but one over 40%.", "labels": [], "entities": [{"text": "Error", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9916152358055115}, {"text": "error", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9786988496780396}]}, {"text": "Although our training corpus is small the feature selection described in Section 4.2 allows us to use these higher-order trigram models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of articles and words in the  Weekly Reader corpus.", "labels": [], "entities": [{"text": "Distribution of articles and words", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.8431821823120117}, {"text": "Weekly Reader corpus", "start_pos": 53, "end_pos": 73, "type": "DATASET", "confidence": 0.9030144611994425}]}, {"text": " Table 2: Distribution of articles and words in the  Britannica and CNN corpora.", "labels": [], "entities": [{"text": "Britannica and CNN corpora", "start_pos": 53, "end_pos": 79, "type": "DATASET", "confidence": 0.8958076387643814}]}, {"text": " Table 3. The development data is used as a test  set for comparing classifiers, tuning parameters, etc,  and the results presented in this section are based on  the test set.  We present results in three different formats. For  analyzing our binary classifiers, we use Detection  Error Tradeoff (DET) curves and precision/recall Grade Training Dev/Test  2  315  18  3  529  30  4  690  38  5  623  34", "labels": [], "entities": [{"text": "precision", "start_pos": 313, "end_pos": 322, "type": "METRIC", "confidence": 0.9992444515228271}, {"text": "recall Grade Training Dev", "start_pos": 323, "end_pos": 348, "type": "METRIC", "confidence": 0.8708515018224716}]}, {"text": " Table 4. The grade 3 classifier has high  recall but relatively low precision; the grade 4 classi- fier does better on precision and reasonably well on  recall. Since the minimum cost operating points do  not correspond to the equal error rate (i.e. equal per- centage of misses and false alarms) there is variation  in the precision-recall tradeoff for the different grade  level classifiers. For example, for class 3, the oper- ating point corresponds to a high probability of false  alarms and a lower probability of misses, which re- sults in low precision and high recall. For operating  points chosen on the convex hull of the DET curves,  the equal error rate ranges from 12-25% for the dif-", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9987493753433228}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9986514449119568}, {"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9992684721946716}, {"text": "recall", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.9976229071617126}, {"text": "precision-recall", "start_pos": 325, "end_pos": 341, "type": "METRIC", "confidence": 0.9850229620933533}, {"text": "precision", "start_pos": 552, "end_pos": 561, "type": "METRIC", "confidence": 0.9892916083335876}, {"text": "recall", "start_pos": 571, "end_pos": 577, "type": "METRIC", "confidence": 0.9917819499969482}, {"text": "DET curves", "start_pos": 634, "end_pos": 644, "type": "DATASET", "confidence": 0.967369794845581}]}, {"text": " Table 4: Precision and recall on test set for SVM- based classifiers.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9979878664016724}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9990530610084534}]}, {"text": " Table 5: Percentage of articles which are misclassi- fied by more than one grade level.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9720124006271362}]}]}