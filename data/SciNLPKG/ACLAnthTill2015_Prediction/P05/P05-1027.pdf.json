{"title": [{"text": "Question Answering as Question-Biased Term Extraction: A New Approach toward Multilingual QA", "labels": [], "entities": [{"text": "Question Answering as Question-Biased Term Extraction", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.7809631129105886}]}], "abstractContent": [{"text": "This paper regards Question Answering (QA) as Question-Biased Term Extraction (QBTE).", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.8682295918464661}, {"text": "Question-Biased Term Extraction (QBTE)", "start_pos": 46, "end_pos": 84, "type": "TASK", "confidence": 0.6784244080384573}]}, {"text": "This new QBTE approach liberates QA systems from the heavy burden imposed by question types (or answer types).", "labels": [], "entities": []}, {"text": "In conventional approaches, a QA system analyzes a given question and determines the question type, and then it selects answers from among answer candidates that match the question type.", "labels": [], "entities": []}, {"text": "Consequently , the output of a QA system is restricted by the design of the question types.", "labels": [], "entities": []}, {"text": "The QBTE directly extracts answers as terms biased by the question.", "labels": [], "entities": [{"text": "QBTE", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9511925578117371}]}, {"text": "To confirm the feasibility of our QBTE approach , we conducted experiments on the CRL QA Data based on 10-fold cross validation , using Maximum Entropy Models (MEMs) as an ML technique.", "labels": [], "entities": [{"text": "CRL QA Data", "start_pos": 82, "end_pos": 93, "type": "DATASET", "confidence": 0.8780202070871989}]}, {"text": "Experimental results showed that the trained system achieved 0.36 in MRR and 0.47 in Top5 accuracy.", "labels": [], "entities": [{"text": "MRR", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9507715702056885}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9111820459365845}]}], "introductionContent": [{"text": "The conventional Question Answering (QA) architecture is a cascade of the following building blocks: Question Analyzer analyzes a question sentence and identifies the question types (or answer types).", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.8689377784729004}, {"text": "Question Analyzer analyzes a question sentence", "start_pos": 101, "end_pos": 147, "type": "TASK", "confidence": 0.8113759656747183}]}], "datasetContent": [{"text": "We conducted 10-fold cross validation using the CRL QA Data.", "labels": [], "entities": [{"text": "CRL QA Data", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9463735818862915}]}, {"text": "The output is evaluated using the Top5 score and MRR.", "labels": [], "entities": [{"text": "Top5 score", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.6256372034549713}, {"text": "MRR", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9867032766342163}]}, {"text": "Top5 Score shows the rate at which at least one correct answer is included in the top 5 answers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of Questions in Question Types of CRL QA Data", "labels": [], "entities": [{"text": "CRL QA Data", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.6419749160607656}]}, {"text": " Table 2: Main Results with 10-fold Cross Validation  Correct Answer Rank  MRR Top5  1  2  3  4  5  Exact match  453 139  68 35 19 0.28  0.36  Partial match  684 222 126 80 48 0.43  0.58  Ave.  0.355 0.47  Manual evaluation 578 188  86 55 34 0.36  0.47", "labels": [], "entities": [{"text": "Cross Validation  Correct Answer Rank  MRR Top5  1", "start_pos": 36, "end_pos": 86, "type": "METRIC", "confidence": 0.6344699375331402}]}, {"text": " Table 3: Answer Extraction from Top N documents", "labels": [], "entities": [{"text": "Answer Extraction from Top N", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8758755207061768}]}]}