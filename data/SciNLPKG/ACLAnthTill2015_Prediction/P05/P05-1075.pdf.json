{"title": [{"text": "A Nonparametric Method for Extraction of Candidate Phrasal Terms", "labels": [], "entities": [{"text": "Extraction of Candidate Phrasal Terms", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.8797555327415466}]}], "abstractContent": [{"text": "This paper introduces anew method for identifying candidate phrasal terms (also known as multiword units) which applies a nonparametric, rank-based heuristic measure.", "labels": [], "entities": []}, {"text": "Evaluation of this measure, the mutual rank ratio metric, shows that it produces better results than standard statistical measures when applied to this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ordinary vocabulary of a language like English contains thousands of phrasal terms --multiword lexical units including compound nouns, technical terms, idioms, and fixed collocations.", "labels": [], "entities": []}, {"text": "The exact number of phrasal terms is difficult to determine, as new ones are coined regularly, and it is sometimes difficult to determine whether a phrase is a fixed term or a regular, compositional expression.", "labels": [], "entities": []}, {"text": "Accurate identification of phrasal terms is important in a variety of contexts, including natural language parsing, question answering systems, information retrieval systems, among others.", "labels": [], "entities": [{"text": "Accurate identification of phrasal terms", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8328456223011017}, {"text": "natural language parsing", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.6718831161657969}, {"text": "question answering", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.8676343262195587}]}, {"text": "Insofar as phrasal terms function as lexical units, their component words tend to cooccur more often, to resist substitution or paraphrase, to follow fixed syntactic patterns, and to display some degree of semantic noncompositionality).", "labels": [], "entities": []}, {"text": "However, none of these characteristics are amenable to a simple algorithmic interpretation.", "labels": [], "entities": []}, {"text": "It is true that various term extraction systems have been developed, such as Xtract (Smadja 1993), Termight, and TERMS among others (cf..", "labels": [], "entities": [{"text": "term extraction", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7109622061252594}]}, {"text": "Such systems typically rely on a combination of linguistic knowledge and statistical association measures.", "labels": [], "entities": []}, {"text": "Grammatical patterns, such as adjective-noun or noun-noun sequences are selected then ranked statistically, and the resulting ranked list is either used directly or submitted for manual filtering.", "labels": [], "entities": []}, {"text": "The linguistic filters used in typical term extraction systems have no obvious connection with the criteria that linguists would argue define a phrasal term (noncompositionality, fixed order, nonsubstitutability, etc.).", "labels": [], "entities": [{"text": "term extraction", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7629728317260742}]}, {"text": "They function, instead, to reduce the number of a priori improbable terms and thus improve precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9952061772346497}]}, {"text": "The association measure does the actual work of distinguishing between terms and plausible nonterms.", "labels": [], "entities": []}, {"text": "A variety of methods have been applied, ranging from simple frequency, modified frequency measures such as c-values and standard statistical significance tests such as the t-test, the chi-squared test, and loglikelihood, and information-based methods, e.g. pointwise mutual information.", "labels": [], "entities": []}, {"text": "Several studies of the performance of lexical association metrics suggest significant room for improvement, but also variability among tasks.", "labels": [], "entities": []}, {"text": "One series of studies) focused on the use of association metrics to identify the best candidates in particular grammatical constructions, such as adjective-noun pairs or verb plus prepositional phrase constructions, and compared the performance of simple frequency to several common measures (the log-likelihood, the t-test, the chi-squared test, the dice coefficient, relative entropy and mutual information).", "labels": [], "entities": []}, {"text": "In Krenn & Evert 2001, frequency outperformed mutual information though not the ttest, while in Evert and Krenn 2001, log-likelihood and the t-test gave the best results, and mutual information again performed worse than frequency.", "labels": [], "entities": [{"text": "frequency", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9848551154136658}]}, {"text": "However, in all these studies performance was generally low, with precision falling rapidly after the very highest ranked phrases in the list.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9995087385177612}]}, {"text": "By contrast, Schone and Jurafsky (2001) evaluate the identification of phrasal terms without grammatical filtering on a 6.7 million word extract from the TREC databases, applying both WordNet and online dictionaries as gold standards.", "labels": [], "entities": [{"text": "identification of phrasal terms", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.8623237758874893}, {"text": "TREC databases", "start_pos": 154, "end_pos": 168, "type": "DATASET", "confidence": 0.9215599298477173}, {"text": "WordNet", "start_pos": 184, "end_pos": 191, "type": "DATASET", "confidence": 0.9397369623184204}]}, {"text": "Once again, the general level of performance was low, with precision falling off rapidly as larger portions of the n-best list were included, but they report better performance with statistical and information theoretic measures (including mutual information) than with frequency.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9995218515396118}]}, {"text": "The overall pattern appears to be one where lexical association measures in general have very low precision and recall on unfiltered data, but perform far better when combined with other features which select linguistic patterns likely to function as phrasal terms.", "labels": [], "entities": [{"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9975797533988953}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9985635876655579}]}, {"text": "The relatively low precision of lexical association measures on unfiltered data no doubt has multiple explanations, but a logical candidate is the failure or inappropriacy of underlying statistical assumptions.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.997810423374176}]}, {"text": "For instance, many of the tests assume a normal distribution, despite the highly skewed nature of natural language frequency distributions, though this is not the most important consideration except at very low n (cf..", "labels": [], "entities": []}, {"text": "More importantly, statistical and information-based metrics such as the log-likelihood and mutual information measure significance or informativeness relative to the assumption that the selection of component terms is statistically independent.", "labels": [], "entities": []}, {"text": "But of course the possibilities for combinations of words are anything but random and independent.", "labels": [], "entities": []}, {"text": "Use of linguistic filters such as \"attributive adjective followed by noun\" or \"verb plus modifying prepositional phrase\" arguably has the effect of selecting a subset of the language for which the standard null hypothesis --that any word may freely be combined with any other word --may be much more accurate.", "labels": [], "entities": []}, {"text": "Additionally, many of the association measures are defined only for bigrams, and do not generalize well to phrasal terms of varying length.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to explore whether the identification of candidate phrasal terms can be improved by adopting a heuristic which seeks to take certain of these statistical issues into account.", "labels": [], "entities": [{"text": "identification of candidate phrasal terms", "start_pos": 52, "end_pos": 93, "type": "TASK", "confidence": 0.8302510738372803}]}, {"text": "The method to be presented here, the mutual rank ratio, is a nonparametric rank-based approach which appears to perform significantly better than the standard association metrics.", "labels": [], "entities": []}, {"text": "The body of the paper is organized as follows: Section 2 will introduce the statistical considerations which provide a rationale for the mutual rank ratio heuristic and outline how it is calculated.", "labels": [], "entities": []}, {"text": "Section 3 will present the data sources and evaluation methodologies applied in the rest of the paper.", "labels": [], "entities": []}, {"text": "Section 4 will evaluate the mutual rank ratio statistic and several other lexical association measures on a larger corpus than has been used in previous evaluations.", "labels": [], "entities": []}, {"text": "As will be shown below, the mutual rank ratio statistic recognizes phrasal terms more effectively than standard statistical measures.", "labels": [], "entities": []}], "datasetContent": [{"text": "Schone and Jurafsky's (2001) study examined the performance of various association metrics on a corpus of 6.7 million words with a cutoff of N=10.", "labels": [], "entities": []}, {"text": "The resulting n-gram set had a maximum recall of 2,610 phrasal terms from the WordNet gold standard, and found the best figure of merit for any of the association metrics even with linguistic filterering to be 0.265.", "labels": [], "entities": [{"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9982714653015137}, {"text": "WordNet gold standard", "start_pos": 78, "end_pos": 99, "type": "DATASET", "confidence": 0.9801883498827616}]}, {"text": "On the significantly larger Lexile corpus N must beset higher (around N=50) to make the results comparable.", "labels": [], "entities": [{"text": "Lexile corpus", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9478270411491394}]}, {"text": "The statistics were also calculated for N=50, N=10 and N=5 in order to see what the effect of including more (relatively rare) n-grams would be on the overall performance for each statistic.", "labels": [], "entities": []}, {"text": "Since many of the statistics are defined without interpolation only for bigrams, and the number of WordNet trigrams at N=50 is very small, the full set of scores were only calculated on the bigram data.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9178788065910339}]}, {"text": "For trigrams, in addition to rank ratio and frequency scores, extended pointwise mutual information and true mutual information scores were calculated using the formulas log (P xyz /P x P y P z )) and P xyz log (P xyz /P x P y P z )).", "labels": [], "entities": []}, {"text": "Also, since the standard lexical association metrics cannot be calculated across different n-gram types, results for bigrams and trigrams are presented separately for purposes of comparison.", "labels": [], "entities": []}, {"text": "The results are are shown in.", "labels": [], "entities": []}, {"text": "Two points should should be noted in particular.", "labels": [], "entities": []}, {"text": "First, the rank ratio statistic outperformed the other association measures tested across the board.", "labels": [], "entities": [{"text": "rank ratio statistic", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.9206547737121582}]}, {"text": "Its best performance, a score of 0.323 in the part of speech filtered condition with N=50, outdistanced   the best score in Schone & Jurafsky's study (0.265), and when large numbers of rare bigrams were included, at N=10 and N=5, it continued to outperform the other measures.", "labels": [], "entities": []}, {"text": "Second, the results were generally consistent with those reported in the literature, and confirmed Schone & Jurafsky's observation that the information-theoretic measures (such as mutual information and chisquared) outperform frequency-based measures (such as the T-score and raw frequency.)", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Bigram Scores for Lexical Association  Measures with N=50", "labels": [], "entities": [{"text": "Lexical Association  Measures", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7548748850822449}]}, {"text": " Table 3. Bigram Scores for Lexical Association  Measures with N=10", "labels": [], "entities": [{"text": "Lexical Association  Measures", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7567314108212789}]}, {"text": " Table 4. Bigram Scores for Lexical Association  Measures with N=5", "labels": [], "entities": [{"text": "Lexical Association  Measures", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7627153197924296}]}]}