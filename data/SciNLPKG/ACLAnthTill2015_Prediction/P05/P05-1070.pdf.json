{"title": [{"text": "Instance-based Sentence Boundary Determination by Optimization for Natural Language Generation", "labels": [], "entities": [{"text": "Instance-based Sentence Boundary Determination", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8431863188743591}]}], "abstractContent": [{"text": "This paper describes a novel instance-based sentence boundary determination method for natural language generation that optimizes a set of criteria based on examples in a corpus.", "labels": [], "entities": [{"text": "instance-based sentence boundary determination", "start_pos": 29, "end_pos": 75, "type": "TASK", "confidence": 0.655908390879631}, {"text": "natural language generation", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.6691832840442657}]}, {"text": "Compared to existing sentence boundary determination approaches , our work offers three significant contributions.", "labels": [], "entities": [{"text": "sentence boundary determination", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.7305150330066681}]}, {"text": "First, our approach provides a general domain independent framework that effectively addresses sentence boundary determination by balancing a comprehensive set of sentence complexity and quality related constraints.", "labels": [], "entities": [{"text": "sentence boundary determination", "start_pos": 95, "end_pos": 126, "type": "TASK", "confidence": 0.6793865660826365}]}, {"text": "Second, our approach can simulate the characteristics and the style of naturally occurring sentences in an application domain since our solutions are optimized based on their similarities to examples in a corpus.", "labels": [], "entities": []}, {"text": "Third, our approach can adapt easily to suit a natural language generation system's capability by balancing the strengths and weaknesses of its sub-components (e.g. its aggregation and referring expression generation capability).", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 185, "end_pos": 216, "type": "TASK", "confidence": 0.701938251654307}]}, {"text": "Our final evaluation shows that the proposed method results in significantly better sentence generation outcomes than a widely adopted approach.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.763742059469223}]}], "introductionContent": [{"text": "The problem of sentence boundary determination in natural language generation exists when more than one sentence is needed to convey multiple concepts and propositions.", "labels": [], "entities": [{"text": "sentence boundary determination in natural language generation", "start_pos": 15, "end_pos": 77, "type": "TASK", "confidence": 0.6771926922457558}]}, {"text": "In the classic natural language generation (NLG) architecture, sentence boundary decisions are made during the sentence planning stage in which the syntactic structure and wording of sentences are decided.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.847793330748876}]}, {"text": "Sentence boundary determination is a complex process that directly impacts a sentence's readability, its semantic cohesion, its syntactic and lexical realizability, and its smoothness between sentence transitions.", "labels": [], "entities": [{"text": "Sentence boundary determination", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8837113579114279}]}, {"text": "Sentences that are too complex are hard to understand, so are sentences lacking semantic cohesion and cross-sentence coherence.", "labels": [], "entities": []}, {"text": "Further more, bad sentence boundary decisions may even make sentences unrealizable.", "labels": [], "entities": []}, {"text": "To design a sentence boundary determination method that addresses these issues, we employ an instance-based approach).", "labels": [], "entities": [{"text": "sentence boundary determination", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.718189001083374}]}, {"text": "Because we optimize our solutions based on examples in a corpus, the output sentences can demonstrate properties, such as similar sentence length distribution and semantic grouping similar to those in the corpus.", "labels": [], "entities": []}, {"text": "Our approach also avoids problematic sentence boundaries by optimizing the solutions using all the instances in the corpus.", "labels": [], "entities": []}, {"text": "By taking a sentence's lexical and syntactic realizability into consideration, it can also avoid sentence realization failures caused by bad sentence boundary decisions.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.713100790977478}]}, {"text": "Moreover, since our solution can be adapted easily to suit the capability of a natural language generator, we can easily tune the algorithm to maximize the generation quality.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there is no existing comprehensive solution that is domain-independent and possesses all the above qualities.", "labels": [], "entities": []}, {"text": "In summary, our work offers three significant contributions: boundary determination framework which takes a comprehensive set of sentence complexity and quality related criteria into consideration and ensures that the proposed algorithm is sensitive to not only the complexity of the generated sentences, but also their semantic cohesion, multi-sentence coherence and syntactic and lexical realizability.", "labels": [], "entities": []}, {"text": "2. Since we employ an instance-based method, the proposed solution is sensitive to the style of the sentences in the application domain in which the corpus is collected.", "labels": [], "entities": []}, {"text": "3. Our approach can be adjusted easily to suit a sentence generation system's capability and avoid some of its known weaknesses.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7442080080509186}]}, {"text": "Currently, our work is embodied in a multimodal conversation application in the real-estate domain in which potential home buyers interact with the system using multiple modalities, such as speech and gesture, to request residential real-estate information ().", "labels": [], "entities": []}, {"text": "After interpreting the request, the system formulates a multimedia presentation, including automatically generated speech and graphics, as the response ().", "labels": [], "entities": []}, {"text": "The proposed sentence boundary determination module takes a set of propositions selected by a content planner and passes the sentence boundary decisions to SEGUE (), an instance-based sentence generator, to formulate the final sentences.", "labels": [], "entities": [{"text": "sentence boundary determination", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.6849284370740255}, {"text": "SEGUE", "start_pos": 156, "end_pos": 161, "type": "METRIC", "confidence": 0.8576772809028625}]}, {"text": "For example, our system is called upon to generate responses to a user's request: \"Tell me more about this house.\"", "labels": [], "entities": []}, {"text": "Even though not all of the main attributes of a house (more than 20) will be conveyed, it is clear that a good sentence boundary determination module can greatly ease the generation process and improve the quality of the output.", "labels": [], "entities": []}, {"text": "In the rest of the paper, we start with a discussion of related work, and then describe our instance-base approach to sentence boundary determination.", "labels": [], "entities": [{"text": "sentence boundary determination", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.7089134554068247}]}, {"text": "Finally, we present our evaluation results.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the quality of our sentence boundary decisions, we implemented a baseline system in which boundary determination of the aggregation module is based on a threshold of the maximum number of propositions allowed in a sentence (a simplified version of the second strategy in Section 2.", "labels": [], "entities": []}, {"text": "We have tested two threshold values, the average (3) and maximum (6) number of propositions among corpus instances.", "labels": [], "entities": []}, {"text": "Other sentence complexity measures, such as the number of words and depth of embedding are not easily applicable for our comparison because they require the propositions to be realized first before the boundary decisions can be made.", "labels": [], "entities": []}, {"text": "We tune the relative weight of our approach to best fit our system's capability.", "labels": [], "entities": []}, {"text": "Currently, the weights are empirically established to W d = 1, W i = 3 and SBC = 3.", "labels": [], "entities": [{"text": "SBC", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9757625460624695}]}, {"text": "Based on the output generated from both systems, we derive four evaluation metrics: 1.", "labels": [], "entities": []}, {"text": "Dangling sentences: We define dangling sentences as the short sentences with only one proposition that follow long sentences.", "labels": [], "entities": [{"text": "Dangling sentences", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8643794655799866}]}, {"text": "This measure is used to verify our claim that because we use global instead of local optimization, we can avoid generating dangling sentences by making more balanced sentence boundary decisions.", "labels": [], "entities": []}, {"text": "In contrast, the baseline approaches have dangling sentence problem when the input proposition is 1 over the multiple of the threshold values.", "labels": [], "entities": []}, {"text": "The first row of shows that when the input proposition length is set to 7, a pathological case, among the 200 input proposition sets randomly generated, the baseline approach always produce dangling sentences (100%).", "labels": [], "entities": []}, {"text": "In contrast, our approach always generates more balanced sentences (0%).", "labels": [], "entities": []}, {"text": "Since we use an instance-based approach, we can maintain the semantic cohesion better.", "labels": [], "entities": []}, {"text": "To test this, we randomly generated 200 inputs with up to 10 propositions containing semantic grouping of both the number of bedrooms and number of bathrooms.", "labels": [], "entities": []}, {"text": "The second row, Split Semantic Group, in shows that our algorithm can maintain semantic group much better than the baseline approach.", "labels": [], "entities": []}, {"text": "Only in 1% of the output sentences, our algorithm generated number of bedrooms and number of bathrooms in separate sentences.", "labels": [], "entities": []}, {"text": "In contrast, the baseline approaches did much worse (61% and 21%).", "labels": [], "entities": []}, {"text": "An realization failure occurs when the aggregation module failed to realize one sentence for all the propositions grouped by the sentence boundary determination module.", "labels": [], "entities": []}, {"text": "The third row in, Realization Failure, indicates that given 200 randomly generated input proposition sets with length from 1 to 10, how many realization happened in the output.", "labels": [], "entities": []}, {"text": "Our approach did not have any realization failure while for the baseline approaches, there are 56% and 72% outputs have one or more realization failures.", "labels": [], "entities": []}], "tableCaptions": []}