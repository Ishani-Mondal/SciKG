{"title": [{"text": "Dialogue Act Tagging for Instant Messaging Chat Sessions", "labels": [], "entities": [{"text": "Dialogue Act Tagging", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6656127671400706}, {"text": "Instant Messaging Chat Sessions", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8308092653751373}]}], "abstractContent": [{"text": "Instant Messaging chat sessions are real-time text-based conversations which can be analyzed using dialogue-act models.", "labels": [], "entities": [{"text": "Instant Messaging chat sessions", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7689437568187714}]}, {"text": "We describe a statistical approach for modelling and detecting dialogue acts in Instant Messaging dialogue.", "labels": [], "entities": [{"text": "Instant Messaging dialogue", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.8274558782577515}]}, {"text": "This involved the collection of a small set of task-based dialogues and annotating them with a revised tag set.", "labels": [], "entities": []}, {"text": "We then dealt with segmentation and synchronisation issues which do not arise in spoken dialogue.", "labels": [], "entities": []}, {"text": "The model we developed combines naive Bayes and dialogue-act n-grams to obtain better than 80% accuracy in our tagging experiment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9992375373840332}, {"text": "tagging", "start_pos": 111, "end_pos": 118, "type": "TASK", "confidence": 0.9618906378746033}]}], "introductionContent": [{"text": "Instant Messaging (IM) dialogue has received relatively little attention in discourse modelling.", "labels": [], "entities": [{"text": "Instant Messaging (IM) dialogue", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8576382100582123}]}, {"text": "The novelty and popularity of IM dialogue and the significant differences between written and spoken English warrant specific research on IM dialogue.", "labels": [], "entities": [{"text": "IM dialogue", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9193753302097321}, {"text": "IM dialogue", "start_pos": 138, "end_pos": 149, "type": "TASK", "confidence": 0.9442797005176544}]}, {"text": "We show that IM dialogue has some unique problems and attributes not found in transcribed spoken dialogue, which has been the focus of most work in discourse modelling.", "labels": [], "entities": [{"text": "IM dialogue", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9681352078914642}]}, {"text": "The present study addresses the problems presented by these differences when modelling dialogue acts in IM dialogue.", "labels": [], "entities": [{"text": "IM dialogue", "start_pos": 104, "end_pos": 115, "type": "TASK", "confidence": 0.9115493893623352}]}, {"text": "point out that the use of dialogue acts is a useful first level of analysis for describing discourse structure.", "labels": [], "entities": []}, {"text": "Dialogue acts are based on the illocutionary force of an utterance from speech act theory, and represent acts such as assertions and declarations.", "labels": [], "entities": []}, {"text": "This theory has been extended in dialogue acts to model the conversational functions that utterances can perform.", "labels": [], "entities": []}, {"text": "Dialogue acts have been used to benefit tasks such as machine translation) and the automatic detection of dialogue games ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7716215252876282}, {"text": "automatic detection of dialogue games", "start_pos": 83, "end_pos": 120, "type": "TASK", "confidence": 0.7638126492500306}]}, {"text": "This deeper level of discourse understanding may help replace or assist a support representative using IM dialogue by suggesting responses that are more sophisticated and realistic to a human dialogue participant.", "labels": [], "entities": [{"text": "IM dialogue", "start_pos": 103, "end_pos": 114, "type": "TASK", "confidence": 0.9031445384025574}]}, {"text": "The unique problems and attributes exhibited by IM dialogue prohibit existing dialogue act classification methods from being applied directly.", "labels": [], "entities": [{"text": "IM dialogue", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9401317536830902}, {"text": "dialogue act classification", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.6734386086463928}]}, {"text": "We present solutions to some of these problems along with methods to obtain high accuracy in automated dialogue act classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9987240433692932}, {"text": "automated dialogue act classification", "start_pos": 93, "end_pos": 130, "type": "TASK", "confidence": 0.6455634161829948}]}, {"text": "A statistical discourse model is trained and then used to classify dialogue acts based on the observed words in an utterance.", "labels": [], "entities": []}, {"text": "The training data are online conversations between two people: a customer and a shopping assistant, which we collected and manually annotated.", "labels": [], "entities": []}, {"text": "shows a sample of the type of dialogue and discourse structure used in this study.", "labels": [], "entities": []}, {"text": "We begin by considering the preliminary issues that arise in IM dialogue, why they are problematic when modelling dialogue acts, and present their solutions in \u00a72.", "labels": [], "entities": [{"text": "IM dialogue", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9641290307044983}]}, {"text": "With the preliminary problems solved, we investigate the dialogue act labelling task with a description of our data in \u00a73.", "labels": [], "entities": [{"text": "dialogue act labelling task", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.7816511392593384}]}, {"text": "The remainder of the paper describes our experiment involving the training of a naive Bayes model combined with a n-gram discourse model ( \u00a74).", "labels": [], "entities": []}, {"text": "The results of this model and evaluation statistics are presented in \u00a75.", "labels": [], "entities": []}, {"text": "\u00a76 contains a discussion of the approach we used including its strengths, areas of improvement, and issues for future research followed by the conclusion in \u00a77.: An example of unsynchronised messages occurring when a user prematurely assumes a turn is finished.", "labels": [], "entities": []}, {"text": "Here, message (\"Msg\") 12 is actually in response to 10, not 11 since turn 6 was sent as 2 messages: 10 and 11.", "labels": [], "entities": []}, {"text": "We use the seconds elapsed (\"Sec\") since the previous message as part of a method to resynchronise messages.", "labels": [], "entities": []}, {"text": "Utterance boundaries and their respective dialogue acts are denoted by U n .", "labels": [], "entities": [{"text": "Utterance boundaries", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7788825929164886}]}], "datasetContent": [{"text": "Evaluation of the results was conducted via 9-fold cross-validation across the 9 dialogues in our corpus using 8 dialogues for training and 1 for testing.", "labels": [], "entities": []}, {"text": "shows the results of running the experiment with various models replacing the prior probability, P (d), in Equation 3.", "labels": [], "entities": []}, {"text": "The Min, Max, and Mean columns are obtained from the cross-validation technique used for evaluation.", "labels": [], "entities": [{"text": "Mean", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.978119969367981}]}, {"text": "The baseline used for this task was to assign the most frequently observed dialogue act to each utterance, namely, STATEMENT.", "labels": [], "entities": [{"text": "STATEMENT", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.8137650489807129}]}, {"text": "Omitting P (d) from Equation 3 such that only the likelihood (Equation 2) of the naive Bayes formula is used resulted in a mean accuracy of 80.1%.", "labels": [], "entities": [{"text": "P", "start_pos": 9, "end_pos": 10, "type": "METRIC", "confidence": 0.9697371125221252}, {"text": "likelihood", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9698656797409058}, {"text": "mean", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9306600689888}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.8878203630447388}]}, {"text": "The high accuracy obtained with only the likelihood reflects the high dependency between dialogue acts and the actual words used in utterances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9992341995239258}]}, {"text": "This dependency is represented well by the bag-of-words approach.", "labels": [], "entities": []}, {"text": "Using P (d) to arrive at Equation 3 yields a slight increase inaccuracy to 80.6%.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9751374125480652}]}, {"text": "The bigram model obtains the best result with 81.6% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9990248680114746}]}, {"text": "This result is due to more accurate predictions with P (d|H).", "labels": [], "entities": []}, {"text": "The trigram model produced a slightly lower accuracy rate, partly due to alack of training data and to dialogue act adjacency pairs not being dependent on dialogue acts further removed as discussed in \u00a74.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.9890790283679962}]}, {"text": "In order to gauge the effectiveness of the bigram and trigram models in view of the small amount of training data, hit-rate statistics were collected during testing.", "labels": [], "entities": []}, {"text": "These statistics, presented in, show the percentage of conditions that existed in the various models.", "labels": [], "entities": []}, {"text": "Conditions that did not exist were not counted in the accuracy measure during evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9995469450950623}]}, {"text": "The perplexities for the various n-gram models we used are shown in.", "labels": [], "entities": []}, {"text": "The biggest improvement, indicated by a decreased perplexity, comes when moving from the unigram to bigram models as expected.", "labels": [], "entities": [{"text": "perplexity", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9793227314949036}]}, {"text": "However, the large difference between the bigram and trigram models is somewhat unexpected given the theory of adjacency pairs.", "labels": [], "entities": []}, {"text": "This maybe a result of insufficient training data as would be suggested by the lower trigram hit rate.", "labels": [], "entities": [{"text": "trigram hit rate", "start_pos": 85, "end_pos": 101, "type": "METRIC", "confidence": 0.8937896887461344}]}], "tableCaptions": [{"text": " Table 1: An example of unsynchronised messages occurring when a user prematurely assumes a turn is  finished. Here, message (\"Msg\") 12 is actually in response to 10, not 11 since turn 6 was sent as 2 messages:  10 and 11. We use the seconds elapsed (\"Sec\") since the previous message as part of a method to re- synchronise messages. Utterance boundaries and their respective dialogue acts are denoted by U n .", "labels": [], "entities": []}, {"text": " Table 3: Mean accuracy of labelling utterances with  dialogue acts using n-gram models. Shown with hit- rate results and perplexities (\"Px\")", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9659489393234253}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.8656614422798157}, {"text": "hit- rate results", "start_pos": 100, "end_pos": 117, "type": "METRIC", "confidence": 0.8744252473115921}, {"text": "Px\")", "start_pos": 137, "end_pos": 141, "type": "METRIC", "confidence": 0.8551373481750488}]}]}