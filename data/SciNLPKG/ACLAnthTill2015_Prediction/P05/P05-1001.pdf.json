{"title": [{"text": "A High-Performance Semi-Supervised Learning Method for Text Chunking", "labels": [], "entities": [{"text": "Text Chunking", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.7844298481941223}]}], "abstractContent": [{"text": "In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue.", "labels": [], "entities": []}, {"text": "Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear.", "labels": [], "entities": []}, {"text": "This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning.", "labels": [], "entities": []}, {"text": "The idea is to find \"what good classifiers are like\" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data.", "labels": [], "entities": []}, {"text": "By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem.", "labels": [], "entities": []}, {"text": "The method produces performance higher than the previous best results on CoNLL'00 syntactic chunking and CoNLL'03 named entity chunking (English and German).", "labels": [], "entities": [{"text": "CoNLL'00 syntactic chunking", "start_pos": 73, "end_pos": 100, "type": "TASK", "confidence": 0.7184603214263916}, {"text": "CoNLL'03 named entity chunking", "start_pos": 105, "end_pos": 135, "type": "TASK", "confidence": 0.6833296567201614}]}], "introductionContent": [{"text": "In supervised learning applications, one can often find a large amount of unlabeled data without difficulty, while labeled data are costly to obtain.", "labels": [], "entities": []}, {"text": "Therefore, a natural question is whether we can use unlabeled data to build a more accurate classifier, given the same amount of labeled data.", "labels": [], "entities": []}, {"text": "This problem is often referred to as semi-supervised learning.", "labels": [], "entities": []}, {"text": "Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear.", "labels": [], "entities": []}, {"text": "For example, co-training) automatically bootstraps labels, and such labels are not necessarily reliable.", "labels": [], "entities": []}, {"text": "A related idea is to use Expectation Maximization (EM) to impute labels.", "labels": [], "entities": [{"text": "Expectation Maximization (EM)", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.7155491232872009}]}, {"text": "Although useful under some circumstances, when a relatively large amount of labeled data is available, the procedure often degrades performance (e.g.).", "labels": [], "entities": []}, {"text": "A number of bootstrapping methods have been proposed for NLP tasks (e.g.,,).", "labels": [], "entities": []}, {"text": "But these typically assume a very small amount of labeled data and have not been shown to improve state-of-the-art performance when a large amount of labeled data is available.", "labels": [], "entities": []}, {"text": "Our goal has been to develop a general learning framework for reliably using unlabeled data to improve performance irrespective of the amount of labeled data available.", "labels": [], "entities": []}, {"text": "It is exactly this important and difficult problem that we tackle here.", "labels": [], "entities": []}, {"text": "This paper presents a novel semi-supervised method that employs a learning framework called structural learning (, which seeks to discover shared predictive structures (i.e. what good classifiers for the task are like) through jointly learning multiple classification problems on unlabeled data.", "labels": [], "entities": []}, {"text": "That is, we systematically create thousands of problems (called auxiliary problems) relevant to the target task using unlabeled data, and train classifiers from the automatically generated 'training data'.", "labels": [], "entities": []}, {"text": "We learn the commonality (or structure) of such many classifiers relevant to the task, and use it to improve performance on the target task.", "labels": [], "entities": []}, {"text": "One example of such auxiliary problems for chunking tasks is to 'mask' a word and predict whether it is \"people\" or not from the context, like language modeling.", "labels": [], "entities": []}, {"text": "Another example is to predict the pre-diction of some classifier trained for the target task.", "labels": [], "entities": []}, {"text": "These auxiliary classifiers can be adequately learned since we have very large amounts of 'training data' for them, which we automatically generate from a very large amount of unlabeled data.", "labels": [], "entities": []}, {"text": "The contributions of this paper are two-fold.", "labels": [], "entities": []}, {"text": "First, we present a novel robust semi-supervised method based on anew learning model and its application to chunking tasks.", "labels": [], "entities": []}, {"text": "Second, we report higher performance than the previous best results on syntactic chunking (the CoNLL'00 corpus) and named entity chunking (the CoNLL'03 English and German corpora).", "labels": [], "entities": [{"text": "syntactic chunking", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.6759302616119385}, {"text": "CoNLL'00 corpus", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.9528086483478546}, {"text": "CoNLL'03 English and German corpora", "start_pos": 143, "end_pos": 178, "type": "DATASET", "confidence": 0.8795700311660767}]}, {"text": "In particular, our results are obtained by using unlabeled data as the only additional resource while many of the top systems rely on hand-crafted resources such as large name gazetteers or even rulebased post-processing.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using auxiliary problems introduced above, we study the performance of our semi-supervised learning method on named entity chunking and syntactic chunking.", "labels": [], "entities": [{"text": "named entity chunking", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.6495705445607504}, {"text": "syntactic chunking", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.6741886734962463}]}, {"text": "This section describes the algorithmic aspects of the experimental framework.", "labels": [], "entities": []}, {"text": "The taskspecific setup is described in Sections 5 and 6.", "labels": [], "entities": []}, {"text": "We report named entity chunking performance on the CoNLL'03 shared-task 3 corpora (English and German).", "labels": [], "entities": [{"text": "named entity chunking", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6055492957433065}, {"text": "CoNLL'03 shared-task 3 corpora", "start_pos": 51, "end_pos": 81, "type": "DATASET", "confidence": 0.8294265121221542}]}, {"text": "We choose this task because the original intention of this shared task was to test the effectiveness of semi-supervised learning methods.", "labels": [], "entities": []}, {"text": "However, it turned out that none of the top performing systems used unlabeled data.", "labels": [], "entities": []}, {"text": "The likely reason is that the number of labeled data is relatively large (\ud97b\udf59200K), making it hard to benefit from unlabeled data.", "labels": [], "entities": []}, {"text": "We show that our ASO-based semi-supervised learning method (hereafter, ASO-semi) can produce results appreciably better than all of the top systems, by using unlabeled data as the only additional resource.", "labels": [], "entities": [{"text": "ASO-based semi-supervised learning", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.672013521194458}]}, {"text": "In particular, we do not use any gazetteer information, which was used in all other systems.", "labels": [], "entities": []}, {"text": "The CoNLL corpora are annotated with four types of named entities: persons, organizations, locations, and miscellaneous names (e.g., \"World Cup\").", "labels": [], "entities": [{"text": "CoNLL corpora", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.8450106680393219}, {"text": "World Cup\")", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.5950728356838226}]}, {"text": "We use the official training/development/test splits.", "labels": [], "entities": []}, {"text": "Our unlabeled data sets consist of 27 million words (English) and 35 million words (German), respectively.", "labels": [], "entities": []}, {"text": "They were chosen from the same sources -Reuters and ECI Multilingual Text Corpus -as the provided corpora but disjoint from them.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9515196681022644}, {"text": "ECI Multilingual Text Corpus", "start_pos": 52, "end_pos": 80, "type": "DATASET", "confidence": 0.8968313336372375}]}, {"text": "Next, we report syntactic chunking performance on the CoNLL'00 shared-task 5 corpus.", "labels": [], "entities": [{"text": "CoNLL'00 shared-task 5 corpus", "start_pos": 54, "end_pos": 83, "type": "DATASET", "confidence": 0.8785368204116821}]}, {"text": "The training and test data sets consist of the Wall Street Journal corpus (WSJ) sections 15-18 (212K words) and section 20, respectively.", "labels": [], "entities": [{"text": "Wall Street Journal corpus (WSJ) sections 15-18", "start_pos": 47, "end_pos": 94, "type": "DATASET", "confidence": 0.9568761653370328}]}, {"text": "They are annotated with eleven types of syntactic chunks such as noun phrases.", "labels": [], "entities": []}, {"text": "We \u00a1 uni-and bi-grams of words and POS in a 5-token window.", "labels": [], "entities": []}, {"text": "\u00a1 word-POS bi-grams in a 3-token window.", "labels": [], "entities": []}, {"text": "\u00a1 POS tri-grams on the left and right.", "labels": [], "entities": [{"text": "POS", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.9932639598846436}]}, {"text": "\u00a1 labels of the two words on the left and their bi-grams.", "labels": [], "entities": []}, {"text": "\u00a1 bi-grams of the current word and two labels on the left.", "labels": [], "entities": []}, {"text": "use the WSJ articles in 1991 (15 million words) from the TREC corpus as the unlabeled data.", "labels": [], "entities": [{"text": "WSJ articles in 1991 (15 million words) from the TREC corpus", "start_pos": 8, "end_pos": 68, "type": "DATASET", "confidence": 0.9023598157442533}]}], "tableCaptions": []}