{"title": [{"text": "Word Sense Disambiguation Using Label Propagation Based Semi-Supervised Learning", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.653609702984492}]}], "abstractContent": [{"text": "Shortage of manually sense-tagged data is an obstacle to supervised word sense dis-ambiguation methods.", "labels": [], "entities": [{"text": "word sense dis-ambiguation", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.7196512917677561}]}, {"text": "In this paper we investigate a label propagation based semi-supervised learning algorithm for WSD, which combines labeled and unlabeled data in learning process to fully realize a global consistency assumption: similar examples should have similar labels.", "labels": [], "entities": [{"text": "WSD", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.7936534285545349}]}, {"text": "Our experimental results on benchmark corpora indicate that it consistently out-performs SVM when only very few labeled examples are available, and its performance is also better than monolingual bootstrapping, and comparable to bilingual bootstrapping.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we address the problem of word sense disambiguation (WSD), which is to assign an appropriate sense to an occurrence of a word in a given context.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.8126829862594604}]}, {"text": "Many methods have been proposed to deal with this problem, including supervised learning algorithms (), semi-supervised learning algorithms, and unsupervised learning algorithms.", "labels": [], "entities": []}, {"text": "Supervised sense disambiguation has been very successful, but it requires a lot of manually sensetagged data and cannot utilize raw unannotated data that can be cheaply acquired.", "labels": [], "entities": [{"text": "Supervised sense disambiguation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6094990770022074}]}, {"text": "Fully unsupervised methods do not need the definition of senses and manually sense-tagged data, but their sense clustering results cannot be directly used in many NLP tasks since there is no sense tag for each instance in clusters.", "labels": [], "entities": []}, {"text": "Considering both the availability of a large amount of unlabelled data and direct use of word senses, semi-supervised learning methods have received great attention recently.", "labels": [], "entities": []}, {"text": "Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in learning procedure with the requirement of predefined sense inventory for target words.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9868041276931763}]}, {"text": "They roughly fall into three categories according to what is used for supervision in learning process: (1) using external resources, e.g., thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus,, (2) exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages), (3) bootstrapping sensetagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data.", "labels": [], "entities": []}, {"text": "As a commonly used semi-supervised learning method for WSD, bootstrapping algorithm works by iteratively classifying unlabeled examples and adding confidently classified examples into labeled dataset using a model learned from augmented labeled dataset in previous iteration.", "labels": [], "entities": [{"text": "WSD", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9604776501655579}]}, {"text": "It can be found that the affinity information among unlabeled examples is not fully explored in this bootstrapping process.", "labels": [], "entities": []}, {"text": "Bootstrapping is based on a local consistency assumption: examples close to labeled examples within same class will have same labels, which is also the assumption underlying many supervised learning algorithms, such as kNN.", "labels": [], "entities": []}, {"text": "Recently a promising family of semi-supervised learning algorithms are introduced, which can effectively combine unlabeled data with labeled data in learning process by exploiting cluster structure in data (;.", "labels": [], "entities": []}, {"text": "Here we investigate a label propagation based semisupervised learning algorithm (LP algorithm) () for WSD, which works by representing labeled and unlabeled examples as vertices in a connected graph, then iteratively propagating label information from any vertex to nearby vertices through weighted edges, finally inferring the labels of unlabeled examples after this propagation process converges.", "labels": [], "entities": [{"text": "WSD", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.8296032547950745}]}, {"text": "Compared with bootstrapping, LP algorithm is based on a global consistency assumption.", "labels": [], "entities": []}, {"text": "Intuitively, if there is at least one labeled example in each cluster that consists of similar examples, then unlabeled examples will have the same labels as labeled examples in the same cluster by propagating the label information of any example to nearby examples according to their proximity.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we will formulate WSD problem in the context of semisupervised learning in section 2.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9773415923118591}]}, {"text": "Then in section 3 we will describe LP algorithm and discuss the difference between a supervised learning algorithm (SVM), bootstrapping algorithm and LP algorithm.", "labels": [], "entities": []}, {"text": "Section 4 will provide experimental results of LP algorithm on widely used benchmark corpora.", "labels": [], "entities": [{"text": "LP", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9643391370773315}]}, {"text": "Finally we will conclude our work and suggest possible improvement in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For empirical comparison with SVM and bootstrapping, we evaluated LP on widely used benchmark corpora -\"interest\", \"line\" 1 and the data in English lexical sample task of SENSEVAL-3 (including all 57 English words ) 2 . We used three types of features to capture contextual information: part-of-speech of neighboring words with position information, unordered single words in topical context, and local collocations (as same as the feature set used in () except that we did not use syntactic relations).", "labels": [], "entities": [{"text": "LP", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9562628269195557}]}, {"text": "For SVM, we did not perform feature selection on SENSEVAL-3 data since feature selection deteriorates its performance ().", "labels": [], "entities": [{"text": "SENSEVAL-3 data", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.767640084028244}]}, {"text": "When running LP on the three datasets, we removed the features with occurrence frequency (counted in both training set and test set) less than 3 times.", "labels": [], "entities": []}, {"text": "We investigated two distance measures for LP: cosine similarity and Jensen-Shannon (JS) divergence.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 46, "end_pos": 63, "type": "METRIC", "confidence": 0.6649520397186279}]}, {"text": "For the three datasets, we constructed connected graphs following (): two instances u, v will be connected by an edge if u is among v's k nearest neighbors, or if v is among u's k nearest neighbors as measured by cosine or JS distance measure.", "labels": [], "entities": [{"text": "JS distance measure", "start_pos": 223, "end_pos": 242, "type": "METRIC", "confidence": 0.6648836036523184}]}, {"text": "For \"interest\" and \"line\" corpora, k is 10 (following (), while for SENSEVAL-3 data, k is 5 since the size of dataset for each word in SENSEVAL-3 is much less than that of \"interest\" and \"line\" datasets.", "labels": [], "entities": []}, {"text": "In this experiment, we evaluated LP and SVM 3 on the data of English lexical sample task in SENSEVAL-3.", "labels": [], "entities": [{"text": "LP", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9519345164299011}]}, {"text": "We used l examples from training set as labeled data, and the remaining training examples and all the test examples as unlabeled data.", "labels": [], "entities": []}, {"text": "For each labeled set size l, we performed 20 trials.", "labels": [], "entities": []}, {"text": "In each trial, we randomly sampled l labeled examples for each word from training set.", "labels": [], "entities": []}, {"text": "If any sense was absent from the sampled labeled set, we redid the sampling.", "labels": [], "entities": []}, {"text": "We conducted experiments with different values of l, including 1% \u00d7 N w,train , 10% \u00d7 N w,train , 25% \u00d7 N w,train , 50% \u00d7 N w,train , 75% \u00d7 N w,train , 100% \u00d7 N w,train (N w,train is the number of examples in training set of word w).", "labels": [], "entities": []}, {"text": "SVM and LP were evaluated using accuracy 4 (fine-grained score) on test set of SENSEVAL-3.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8198192715644836}, {"text": "LP", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.9557876586914062}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.997331976890564}, {"text": "SENSEVAL-3", "start_pos": 79, "end_pos": 89, "type": "DATASET", "confidence": 0.7185425758361816}]}, {"text": "We conducted paired t-test on the accuracy figures for each value of l.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9994984865188599}]}, {"text": "Paired t-test is not run when percentage= 100%, since there is only one paired accuracy figure.", "labels": [], "entities": [{"text": "Paired t-test", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.8823772370815277}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.945184588432312}]}, {"text": "Paired t-test is usually used to estimate the difference in means between normal populations based on a set of random paired observations.", "labels": [], "entities": [{"text": "Paired", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9260876774787903}]}, {"text": "{\u226a, \u226b}, {<, >}, and \u223c correspond to pvalue \u2264 0.01, (0.01, 0.05], and > 0.05 respectively.", "labels": [], "entities": []}, {"text": "\u226a (or \u226b) means that the performance of LP is significantly better (or significantly worse) than SVM.", "labels": [], "entities": [{"text": "\u226a", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9637752175331116}, {"text": "LP", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9088704586029053}]}, {"text": "< (or >) means that the performance of LP is better (or worse) than SVM.", "labels": [], "entities": []}, {"text": "\u223c means that the performance of LP is almost as same as SVM.", "labels": [], "entities": []}, {"text": "reports the average accuracies and paired t-test results of SVM and LP with different sizes of labled data.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9913438558578491}, {"text": "LP", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.9579214453697205}]}, {"text": "It also lists the official results of baseline method and top 3 systems in ELS task of SENSEVAL-3.", "labels": [], "entities": []}, {"text": "From, we see that with small labeled dataset (percentage of labeled data \u2264 10%), LP performs significantly better than SVM.", "labels": [], "entities": [{"text": "LP", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9755884408950806}]}, {"text": "When the percentage of labeled data increases from 50% to 75%, the performance of LP JS and SVM become almost same, while LP cosine performs significantly worse than SVM.", "labels": [], "entities": []}, {"text": "we used linear SV M light , available at http://svmlight.joachims.org/.", "labels": [], "entities": []}, {"text": "If there are multiple sense tags for an instance in training set or test set, then only the first tag is considered as correct answer.", "labels": [], "entities": []}, {"text": "Furthermore, if the answer of the instance in test set is \"U\", then this instance will be removed from test set.) and average accuracies of LP with c \u00d7 b labeled examples on \"interest\" and \"line\" corpora.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 126, "end_pos": 136, "type": "METRIC", "confidence": 0.9171068072319031}]}, {"text": "Major is a baseline method in which they always choose the most frequent sense.", "labels": [], "entities": []}, {"text": "MB-D denotes monolingual bootstrapping with decision list as base classifier, MB-B represents monolingual bootstrapping with ensemble of Naive Bayes as base classifier, and BB is bilingual bootstrapping with ensemble of Naive Bayes as base classifier.", "labels": [], "entities": [{"text": "BB", "start_pos": 173, "end_pos": 175, "type": "METRIC", "confidence": 0.9720345735549927}]}, {"text": "Ambiguous Accuracies from (  Li and Li (2004) used \"interest\" and \"line\" corpora as test data.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9630053639411926}]}, {"text": "For the word \"interest\", they used its four major senses.", "labels": [], "entities": []}, {"text": "For comparison with their results, we took reduced \"interest\" corpus (constructed by retaining four major senses) and complete \"line\" corpus as evaluation data.", "labels": [], "entities": []}, {"text": "In their algorithm, c is the number of senses of ambiguous word, and b (b = 15) is the number of examples added into classified data for each class in each iteration of bootstrapping.", "labels": [], "entities": []}, {"text": "c \u00d7 b can be considered as the size of initial labeled data in their bootstrapping algorithm.", "labels": [], "entities": []}, {"text": "We ran LP with 20 trials on reduced \"interest\" corpus and complete \"line\" corpus.", "labels": [], "entities": []}, {"text": "In each trial, we randomly sampled b labeled examples for each sense of \"interest\" or \"line\" as labeled data.", "labels": [], "entities": []}, {"text": "The rest served as both unlabeled data and test data.", "labels": [], "entities": []}, {"text": "summarizes the average accuracies of LP on the two corpora.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.995136559009552}, {"text": "LP", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9835066795349121}]}, {"text": "It also lists the accuracies of monolingual bootstrapping algorithm (MB), bilingual bootstrapping algorithm (BB) on \"interest\" and \"line\" corpora.", "labels": [], "entities": [{"text": "bilingual bootstrapping algorithm (BB", "start_pos": 74, "end_pos": 111, "type": "METRIC", "confidence": 0.5453048825263977}]}, {"text": "We can see that LP performs much better than MB-D and MB-B on both \"interest\" and \"line\" corpora, while the performance of LP is comparable to BB on these two corpora.", "labels": [], "entities": [{"text": "BB", "start_pos": 143, "end_pos": 145, "type": "METRIC", "confidence": 0.9104993343353271}]}, {"text": "\u221a and \u00d7 denote correct and wrong prediction results respectively, while \u2022 means that any prediction is acceptable.", "labels": [], "entities": []}, {"text": "LPcosine vs. LPJS Data p-value Significance SENSEVAL-3 (1%) 1.1e-003 \u226a SENSEVAL-3 (10%) 8.9e-005 forms significantly better than LP cosine , but their performance is almost comparable on \"interest\" and \"line\" corpora.", "labels": [], "entities": []}, {"text": "This observation motivates us to automatically select a distance measure that will boost the performance of LP on a given dataset.", "labels": [], "entities": [{"text": "LP", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.8967235684394836}]}, {"text": "Cross-validation on labeled data is not feasible due to the setting of semi-supervised learning (l \u226a u).", "labels": [], "entities": []}, {"text": "In ( Let Q be the M \u00d7 N matrix. Function H(Q) can measure the entropy of matrix Q, which is defined as): where \u03b1 is positive constant.", "labels": [], "entities": []}, {"text": "The possible value of \u03b1 is \u2212 ln 0.5 \u00af I , where reports the automatic prediction results of these three criteria.", "labels": [], "entities": []}, {"text": "From, we can see that using H(W ) can consistently select the optimal distance measure when the performance gap between LP cosine and LP JS is very large (denoted by \u226a or \u226b).", "labels": [], "entities": []}, {"text": "But H(D) and H(Y U ) fail to find the optimal distance measure when only very few labeled examples are available (percentage of labeled data \u2264 10%).", "labels": [], "entities": []}, {"text": "H(W ) measures the separability of matrix W . Higher value of H(W ) means that distance measure decreases the separability of examples in full dataset.", "labels": [], "entities": []}, {"text": "Then the boundary between clusters is obscured, which makes it difficult for LP to locate this boundary.", "labels": [], "entities": []}, {"text": "Therefore higher value of H(W ) results in worse performance of LP.", "labels": [], "entities": [{"text": "H(W )", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9146256595849991}, {"text": "LP", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9699961543083191}]}, {"text": "When labeled dataset is small, the distances between classes cannot be reliably estimated, which results in unreliable indication of the separability of examples in full dataset.", "labels": [], "entities": []}, {"text": "This is the reason that H(D) performs poorly on SENSEVAL-3 corpus when the percentage of labeled data is less than 25%.", "labels": [], "entities": [{"text": "SENSEVAL-3 corpus", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.7238005697727203}]}, {"text": "For H(Y U ), small labeled dataset cannot reveal intrinsic structure in data, which may bias the estimation of Y U . Then labeling confidence (H(Y U )) cannot properly indicate the performance of LP.", "labels": [], "entities": []}, {"text": "This may interpret the poor performance of H(Y U ) on SENSEVAL-3 data when percentage \u2264 25%.", "labels": [], "entities": [{"text": "SENSEVAL-3 data", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.7761821746826172}]}], "tableCaptions": [{"text": " Table 1: The upper two tables summarize accuracies (aver-", "labels": [], "entities": [{"text": "accuracies", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9886596202850342}]}]}