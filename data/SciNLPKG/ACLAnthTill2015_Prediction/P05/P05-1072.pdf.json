{"title": [{"text": "Semantic Role Labeling Using Different Syntactic Views *", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8314545353253683}]}], "abstractContent": [{"text": "Semantic role labeling is the process of annotating the predicate-argument structure in text with semantic labels.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.735582689444224}]}, {"text": "In this paper we present a state-of-the-art base-line semantic role labeling system based on Support Vector Machine classifiers.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.6403658986091614}]}, {"text": "We show improvements on this system by: i) adding new features including features extracted from dependency parses, ii) performing feature selection and calibration and iii) combining parses obtained from semantic parsers trained using different syntactic views.", "labels": [], "entities": []}, {"text": "Error analysis of the baseline system showed that approximately half of the argument identification errors resulted from parse errors in which there was no syntactic constituent that aligned with the correct argument.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.6990774720907211}]}, {"text": "In order to address this problem, we combined semantic parses from a Minipar syntactic parse and from a chunked syntactic representation with our original base-line system which was based on Charniak parses.", "labels": [], "entities": []}, {"text": "All of the reported techniques resulted in performance improvements.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Role Labeling is the process of annotating the predicate-argument structure in text with se-mantic labels).", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7415387829144796}]}, {"text": "The architecture underlying all of these systems introduces two distinct sub-problems: the identification of syntactic constituents that are semantic roles fora given predicate, and the labeling of the those constituents with the correct semantic role.", "labels": [], "entities": []}, {"text": "A detailed error analysis of our baseline system indicates that the identification problem poses a significant bottleneck to improving overall system performance.", "labels": [], "entities": []}, {"text": "The baseline system's accuracy on the task of labeling nodes known to represent semantic arguments is 90%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9997392296791077}, {"text": "labeling nodes known to represent semantic arguments", "start_pos": 46, "end_pos": 98, "type": "TASK", "confidence": 0.7547198619161334}]}, {"text": "On the other hand, the system's performance on the identification task is quite a bit lower, achieving only 80% recall with 86% precision.", "labels": [], "entities": [{"text": "identification task", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.9146686792373657}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.998977780342102}, {"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.997655987739563}]}, {"text": "There are two sources of these identification errors: i) failures by the system to identify all and only those constituents that correspond to semantic roles, when those constituents are present in the syntactic analysis, and ii) failures by the syntactic analyzer to provide the constituents that align with correct arguments.", "labels": [], "entities": []}, {"text": "The work we present here is tailored to address these two sources of error in the identification problem.", "labels": [], "entities": [{"text": "identification", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.9691721200942993}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first describe a baseline system based on the best published techniques.", "labels": [], "entities": []}, {"text": "We then report on two sets of experiments using techniques that improve performance on the problem of finding arguments when they are present in the syntactic analysis.", "labels": [], "entities": []}, {"text": "In the first set of experiments we explore new features, including features extracted from a parser that provides a different syntactic view -a Combinatory Categorial Grammar (CCG) parser).", "labels": [], "entities": []}, {"text": "In the second set of experiments, we explore approaches to identify optimal subsets of features for each argument class, and to calibrate the classifier probabilities.", "labels": [], "entities": []}, {"text": "We then report on experiments that address the problem of arguments missing from a given syntactic analysis.", "labels": [], "entities": []}, {"text": "We investigate ways to combine hypotheses generated from semantic role taggers trained using different syntactic views -one trained using the Charniak parser), another on a rule-based dependency parser -Minipar, and a third based on a flat, shallow syntactic chunk representation.", "labels": [], "entities": [{"text": "semantic role taggers", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.6801598270734152}]}, {"text": "We show that these three views complement each other to improve performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Baseline system performance on all tasks  using hand-corrected parses and automatic parses on  PropBank data.", "labels": [], "entities": [{"text": "PropBank data", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.9509662985801697}]}, {"text": " Table 5: Performance improvement on selecting fea- tures per argument and calibrating the probabilities  on 10k training data.", "labels": [], "entities": []}, {"text": " Table 7: Features used in the Baseline system using  Minipar parses.", "labels": [], "entities": []}, {"text": " Table 8: Baseline system performance on all tasks  using Minipar parses.", "labels": [], "entities": []}, {"text": " Table 9: Head-word based performance using Char- niak and Minipar parses.", "labels": [], "entities": []}, {"text": " Table 11: Semantic chunker performance on the  combined task of Id. and classification.", "labels": [], "entities": [{"text": "Semantic chunker", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7502264976501465}, {"text": "Id.", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9355089664459229}]}, {"text": " Table 13: Performance improvement on parses  changed during pair-wise Charniak and Chunk com- bination.", "labels": [], "entities": []}, {"text": " Table 14. It can be seen  that the head word based performance almost ap- proaches the constituent based performance reported  on the hand-corrected parses in", "labels": [], "entities": []}, {"text": " Table 14: Performance improvement on head word  based scoring after oracle combination. Charniak  (C), Minipar (M) and Chunker (CH).", "labels": [], "entities": []}, {"text": " Table 15: Performance improvement on head word  based scoring after combination. Charniak (C),  Minipar (M) and Chunker (CH).", "labels": [], "entities": []}]}