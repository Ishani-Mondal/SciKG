{"title": [{"text": "Modeling Local Coherence: An Entity-based Approach", "labels": [], "entities": [{"text": "Modeling Local Coherence", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.845940093199412}]}], "abstractContent": [{"text": "This paper considers the problem of automatic assessment of local coherence.", "labels": [], "entities": []}, {"text": "We present a novel entity-based representation of discourse which is inspired by Centering Theory and can be computed automatically from raw text.", "labels": [], "entities": []}, {"text": "We view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function.", "labels": [], "entities": []}, {"text": "Our experiments demonstrate that the induced model achieves significantly higher accuracy than a state-of-the-art coherence model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9991156458854675}]}], "introductionContent": [{"text": "A key requirement for any system that produces text is the coherence of its output.", "labels": [], "entities": []}, {"text": "Not surprisingly, a variety of coherence theories have been developed over the years (e.g., and their principles have found application in many symbolic text generation systems (e.g., Scott and de).", "labels": [], "entities": [{"text": "symbolic text generation", "start_pos": 144, "end_pos": 168, "type": "TASK", "confidence": 0.6402210493882498}]}, {"text": "The ability of these systems to generate high quality text, almost indistinguishable from human writing, makes the incorporation of coherence theories in robust large-scale systems particularly appealing.", "labels": [], "entities": []}, {"text": "The task is, however, challenging considering that most previous efforts have relied on handcrafted rules, valid only for limited domains, with no guarantee of scalability or portability).", "labels": [], "entities": []}, {"text": "Furthermore, coherence constraints are often embedded in complex representations (e.g., which are hard to implement in a robust application.", "labels": [], "entities": []}, {"text": "This paper focuses on local coherence, which captures text relatedness at the level of sentence-tosentence transitions, and is essential for generating globally coherent text.", "labels": [], "entities": []}, {"text": "The key premise of our work is that the distribution of entities in locally coherent texts exhibits certain regularities.", "labels": [], "entities": []}, {"text": "This assumption is not arbitrary -some of these regularities have been recognized in Centering Theory ( and other entity-based theories of discourse.", "labels": [], "entities": []}, {"text": "The algorithm introduced in the paper automatically abstracts a text into a set of entity transition sequences, a representation that reflects distributional, syntactic, and referential information about discourse entities.", "labels": [], "entities": []}, {"text": "We argue that this representation of discourse allows the system to learn the properties of locally coherent texts opportunistically from a given corpus, without recourse to manual annotation or a predefined knowledge base.", "labels": [], "entities": []}, {"text": "We view coherence assessment as a ranking problem and present an efficiently learnable model that orders alternative renderings of the same information based on their degree of local coherence.", "labels": [], "entities": [{"text": "coherence assessment", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7251125872135162}]}, {"text": "Such a mechanism is particularly appropriate for generation and summarization systems as they can produce multiple text realizations of the same underlying content, either by varying parameter values, or by relaxing constraints that control the generation process.", "labels": [], "entities": [{"text": "generation and summarization", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.6801495552062988}]}, {"text": "A system equipped with a ranking mechanism, could compare the quality of the candidate outputs, much in the same way speech recognizers employ language models at the sentence level.", "labels": [], "entities": []}, {"text": "Our evaluation results demonstrate the effectiveness of our entity-based ranking model within the general framework of coherence assessment.", "labels": [], "entities": []}, {"text": "First, we evaluate the utility of the model in a text ordering task where our algorithm has to select a maximally coherent sentence order from a set of candidate permutations.", "labels": [], "entities": [{"text": "text ordering task", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8106393019358317}]}, {"text": "Second, we compare the rankings produced by the model against human coherence judgments elicited for automatically generated summaries.", "labels": [], "entities": []}, {"text": "In both experiments, our method yields a significant improvement over a state-of-the-art coherence model based on Latent Semantic Analysis ().", "labels": [], "entities": []}, {"text": "In the following section, we provide an overview of existing work on the automatic assessment of local coherence.", "labels": [], "entities": []}, {"text": "Then, we introduce our entity-based representation, and describe our ranking model.", "labels": [], "entities": []}, {"text": "Next, we present the experimental framework and data.", "labels": [], "entities": []}, {"text": "Evaluation results conclude the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe two evaluation tasks that assess the merits of the coherence modeling framework introduced above.", "labels": [], "entities": []}, {"text": "We also give details regarding our data collection, and parameter estimation.", "labels": [], "entities": []}, {"text": "Finally, we introduce the baseline method used for comparison with our approach.", "labels": [], "entities": []}, {"text": "We further test the ability of our method to assess coherence by comparing model induced rankings against rankings elicited by human judges.", "labels": [], "entities": []}, {"text": "Admittedly, the information ordering task only partially approximates degrees of coherence violation using different sentence permutations of a source document.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.801015704870224}]}, {"text": "A stricter evaluation exercise concerns the assessment of texts with naturally occurring coherence violations as perceived by human readers.", "labels": [], "entities": []}, {"text": "A representative example of such texts are automatically generated summaries which often contain sentences taken out of context and thus display problems with respect to local coherence (e.g., dangling anaphors, thematically unrelated sentences).", "labels": [], "entities": []}, {"text": "A model that exhibits high agreement with human judges not only accurately captures the coherence properties of the summaries in question, but ultimately holds promise for the automatic evaluation of machine-generated texts.", "labels": [], "entities": []}, {"text": "Existing automatic evaluation measures such as BLEU () and ROUGE, are not designed for the coherence assessment task, since they focus on content similarity between system output and reference texts.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9976621866226196}, {"text": "ROUGE", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.9920137524604797}]}, {"text": "Model performance was assessed in the same way for information ordering and summary evaluation.", "labels": [], "entities": [{"text": "information ordering", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.8729256391525269}]}, {"text": "Given a set of pairwise rankings, we measure accuracy as the ratio of correct predictions made by the model over the size of the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9992232322692871}]}, {"text": "In this setup, random prediction results in an accuracy of 50%.", "labels": [], "entities": [{"text": "random prediction", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.5719861090183258}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9995731711387634}]}], "tableCaptions": [{"text": " Table 3: Example of a feature-vector document rep- resentation using all transitions of length two given  syntactic categories: S, O, X, and -.", "labels": [], "entities": []}, {"text": " Table 4: Ranking accuracy measured as the fraction of correct pairwise rankings in the test set.", "labels": [], "entities": [{"text": "Ranking", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9036785960197449}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8150673508644104}]}]}