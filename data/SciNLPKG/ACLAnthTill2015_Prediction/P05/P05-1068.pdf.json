{"title": [{"text": "Context-dependent SMT Model using Bilingual Verb-Noun Collocation", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8283140659332275}, {"text": "Bilingual Verb-Noun Collocation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.5495158731937408}]}], "abstractContent": [{"text": "In this paper, we propose anew context-dependent SMT model that is tightly coupled with a language model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9309949278831482}]}, {"text": "It is designed to decrease the translation ambiguities and efficiently search for an optimal hypothesis by reducing the hypothesis search space.", "labels": [], "entities": []}, {"text": "It works through reciprocal incorporation between source and target context: a source word is determined by the context of previous and corresponding target words and the next target word is predicted by the pair consisting of the previous target word and its corresponding source word.", "labels": [], "entities": []}, {"text": "In order to alleviate the data sparseness in chunk-based translation , we take a stepwise back-off translation strategy.", "labels": [], "entities": []}, {"text": "Moreover, in order to obtain more semantically plausible translation results, we use bilingual verb-noun collocations; these are automatically extracted by using chunk alignment and a monolingual dependency parser.", "labels": [], "entities": []}, {"text": "As a case study, we experimented on the language pair of Japanese and Korean.", "labels": [], "entities": []}, {"text": "As a result, we could not only reduce the search space but also improve the performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "For decades, many research efforts have contributed to the advance of statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.7855077385902405}]}, {"text": "Recently, various works have improved the quality of statistical machine translation systems by using phrase translation ().", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.6388658583164215}, {"text": "phrase translation", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.817549854516983}]}, {"text": "Most of the phrase-based translation models have adopted the noisy-channel based IBM style models \u00bd \u00b5 and language model, \u00c8 \u00d6 \u00b4\ud97b\udf59 \u00c1 \u00bd \u00b5.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6308295428752899}, {"text": "\u00c8 \u00d6 \u00b4\ud97b\udf59 \u00c1 \u00bd \u00b5", "start_pos": 122, "end_pos": 134, "type": "METRIC", "confidence": 0.8430319428443909}]}, {"text": "The translation model links the source language sentence to the target language sentence.", "labels": [], "entities": []}, {"text": "The language model describes the well-formedness of the target language sentence and might play a role in restricting hypothesis expansion during decoding.", "labels": [], "entities": [{"text": "restricting hypothesis expansion", "start_pos": 106, "end_pos": 138, "type": "TASK", "confidence": 0.659111907084783}]}, {"text": "To recover the word order difference between two languages, it also allows modeling the reordering by introducing a relative distortion probability distribution.", "labels": [], "entities": []}, {"text": "However, in spite of using such a language model and a distortion model, the translation outputs may not be fluent or in fact may produce nonsense.", "labels": [], "entities": []}, {"text": "To make things worse, the huge hypothesis search space is much too large for an exhaustive search.", "labels": [], "entities": []}, {"text": "If arbitrary reorderings are allowed, the search problem is NP-complete).", "labels": [], "entities": []}, {"text": "According to a previous analysis () of how many hypotheses are generated during an exhaustive search using the IBM models, the upper bound for the number of states is estimated by AE \u00b3 \u00be \u00c2 \ud97b\udf59\u00ce \ud97b\udf59 \ud97b\udf59 \u00be \u00c2 , where \u00c2 is the number of source words and \ud97b\udf59\u00ce \ud97b\udf59 \ud97b\udf59 is the size of the target vocabulary.", "labels": [], "entities": [{"text": "AE \u00b3 \u00be \u00c2 \ud97b\udf59\u00ce \ud97b\udf59 \ud97b\udf59 \u00be \u00c2", "start_pos": 180, "end_pos": 199, "type": "METRIC", "confidence": 0.9150615096092224}, {"text": "\ud97b\udf59", "start_pos": 244, "end_pos": 245, "type": "METRIC", "confidence": 0.9890021085739136}, {"text": "\u00ce", "start_pos": 245, "end_pos": 246, "type": "METRIC", "confidence": 0.6286581158638}]}, {"text": "Even though the number of possible translations of the last two words is much smaller than \ud97b\udf59\u00ce \ud97b\udf59 \ud97b\udf59 \u00be , we still need to make further improvement.", "labels": [], "entities": [{"text": "\ud97b\udf59\u00ce \ud97b\udf59 \ud97b\udf59 \u00be", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9370426774024964}]}, {"text": "The main concern is the ex-ponential explosion from the possible configurations of source words covered by a hypothesis.", "labels": [], "entities": []}, {"text": "In order to reduce the number of possible configurations of source words, decoding algorithms based on \ud97b\udf59 \u00a3 as well as the beam search algorithm have been proposed ().", "labels": [], "entities": []}, {"text": "() used heuristics for pruning implausible hypotheses.", "labels": [], "entities": []}, {"text": "Our approach to this problem examines the possibility of utilizing context information in a given language pair.", "labels": [], "entities": []}, {"text": "Under a given target context, the corresponding source word of a given target word is almost deterministic.", "labels": [], "entities": []}, {"text": "Conversely, if a translation pair is given, then the related target or source context is predictable.", "labels": [], "entities": []}, {"text": "This implies that if we considered bilingual context information in a given language pair during decoding, we can reduce the computational complexity of the hypothesis search; specifically, we could reduce the possible configurations of source words as well as the number of possible target translations.", "labels": [], "entities": []}, {"text": "In this study, we present a statistical machine translation model as an alternative to the classical IBM-style model.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6139036218325297}]}, {"text": "This model is tightly coupled with target language model and utilizes bilingual context information.", "labels": [], "entities": []}, {"text": "It is designed to not only reduce the hypothesis search space by decreasing the translation ambiguities but also improve translation performance.", "labels": [], "entities": []}, {"text": "It works through reciprocal incorporation between source and target context: source words are determined by the context of previous and corresponding target words, and the next target words are predicted by the current translation pair.", "labels": [], "entities": []}, {"text": "Accordingly, we do not need to consider any distortion model or language model as is the case with IBM-style models.", "labels": [], "entities": []}, {"text": "Under this framework, we propose a chunk-based translation model for more grammatical, fluent and accurate output.", "labels": [], "entities": [{"text": "chunk-based translation", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.5755580961704254}]}, {"text": "In order to alleviate the data sparseness problem in chunk-based translation, we use a stepwise back-off method in the order of a chunk, sub-parts of the chunk, and word level.", "labels": [], "entities": []}, {"text": "Moreover, we utilize verb-noun collocations in dealing with long-distance dependency which are automatically extracted by using chunk alignment and a monolingual dependency parser.", "labels": [], "entities": [{"text": "chunk alignment", "start_pos": 128, "end_pos": 143, "type": "TASK", "confidence": 0.696205273270607}]}, {"text": "As a case study, we developed a Japanese-toKorean translation model and performed some experiments on the BTEC corpus.", "labels": [], "entities": [{"text": "Japanese-toKorean translation", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.5614291578531265}, {"text": "BTEC corpus", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.9600934982299805}]}], "datasetContent": [{"text": "Translation evaluations were carried out on 510 sentences selected randomly from the test set.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9717677235603333}]}, {"text": "The metrics for the evaluations are as follows: PER(Position independent WER), which penalizes without considering positional disfluencies().", "labels": [], "entities": [{"text": "PER", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9978637099266052}, {"text": "Position independent WER)", "start_pos": 52, "end_pos": 77, "type": "METRIC", "confidence": 0.7061178609728813}]}, {"text": "mWER(multi-reference Word Error Rate), which is based on the minimum edit distance between the target sentence and the sentences in the reference set ().", "labels": [], "entities": [{"text": "mWER", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7976167798042297}, {"text": "multi-reference Word Error Rate)", "start_pos": 5, "end_pos": 37, "type": "METRIC", "confidence": 0.6134495913982392}]}, {"text": "BLEU, which is the ratio of the n-gram for the translation results found in the reference translations with a penalty for too short sentences ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9913545250892639}]}, {"text": "shows the performance evaluation of each system.", "labels": [], "entities": []}, {"text": "CBLMC outperformed CBIBM in overall evaluation criteria.", "labels": [], "entities": [{"text": "CBLMC", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9049788117408752}, {"text": "CBIBM", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.8983752727508545}]}, {"text": "WBLMC showed much better performance than WBIBM inmost of the evaluation criteria except for BLEU score.", "labels": [], "entities": [{"text": "WBLMC", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9381222128868103}, {"text": "WBIBM", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.8293447494506836}, {"text": "BLEU score", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.973598837852478}]}, {"text": "The interesting point is that the performance of WBLMC is close to that of CBIBM in PER and mWER.", "labels": [], "entities": [{"text": "WBLMC", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.501150369644165}]}, {"text": "The BLEU score of WBLMC is lower than that of CBIBM, but the NIST score of WBLMC is much better than that of CBIBM.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9813229441642761}, {"text": "WBLMC", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.6663506031036377}, {"text": "CBIBM", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.9370547533035278}, {"text": "NIST score", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.7187196314334869}, {"text": "WBLMC", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.7725910544395447}, {"text": "CBIBM", "start_pos": 109, "end_pos": 114, "type": "DATASET", "confidence": 0.9566732048988342}]}], "tableCaptions": [{"text": " Table 2: Statistics of Basic Travel Expression Corpus", "labels": [], "entities": []}, {"text": " Table 3: Evaluation Results of Translation Systems: without BiVN/with BiVN", "labels": [], "entities": [{"text": "Translation", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.9637972712516785}]}, {"text": " Table 4: Translation Speed of Each Translation Systems(sec./sentence): without BiVN/with BiVN", "labels": [], "entities": []}]}