{"title": [{"text": "Corpus-Oriented Development of Japanese HPSG Parsers", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper reports the corpus-oriented development of a wide-coverage Japanese HPSG parser.", "labels": [], "entities": []}, {"text": "We first created an HPSG treebank from the EDR corpus by using heuristic conversion rules, and then extracted lexical entries from the tree-bank.", "labels": [], "entities": [{"text": "HPSG treebank", "start_pos": 20, "end_pos": 33, "type": "DATASET", "confidence": 0.9595988988876343}, {"text": "EDR corpus", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.8064931929111481}]}, {"text": "The grammar developed using this method attained wide coverage that could hardly be obtained by conventional manual development.", "labels": [], "entities": [{"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9971461892127991}]}, {"text": "We also trained a statistical parser for the grammar on the tree-bank, and evaluated the parser in terms of the accuracy of semantic-role identification and dependency analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9994439482688904}, {"text": "semantic-role identification", "start_pos": 124, "end_pos": 152, "type": "TASK", "confidence": 0.7414820492267609}, {"text": "dependency analysis", "start_pos": 157, "end_pos": 176, "type": "TASK", "confidence": 0.7460895478725433}]}], "introductionContent": [{"text": "In this study, we report the corpus-oriented development of a Japanese HPSG parser using the EDR Japanese corpus.", "labels": [], "entities": [{"text": "EDR Japanese corpus", "start_pos": 93, "end_pos": 112, "type": "DATASET", "confidence": 0.9569475452105204}]}, {"text": "Although several researchers have attempted to utilize linguistic grammar theories, such as LFG, CCG) and HPSG, for parsing real-world texts, such attempts could hardly be successful, because manual development of wide-coverage linguistically motivated grammars involves years of labor-intensive effort.", "labels": [], "entities": [{"text": "parsing real-world texts", "start_pos": 116, "end_pos": 140, "type": "TASK", "confidence": 0.9040967424710592}]}, {"text": "Corpus-oriented grammar development is a grammar development method that has been proposed as a promising substitute for conventional manual development.", "labels": [], "entities": [{"text": "Corpus-oriented grammar development", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6731215516726176}]}, {"text": "In corpus-oriented methods, a treebank of a target grammar is constructed first, and various grammatical constraints are extracted from the treebank.", "labels": [], "entities": []}, {"text": "Previous studies reported that wide-coverage grammars can be obtained at low cost by using this method.)", "labels": [], "entities": []}, {"text": "The treebank can also be used for training statistical disambiguation models, and hence we can construct a statistical parser for the extracted grammar.", "labels": [], "entities": []}, {"text": "The corpus-oriented method enabled us to develop a Japanese HPSG parser with semantic information, whose coverage on real-world sentences is 95.3%.", "labels": [], "entities": [{"text": "coverage", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9731868505477905}]}, {"text": "This high coverage allowed us to evaluate the parser in terms of the accuracy of dependency analysis on real-world texts, the evaluation measure that is previously used for more statistically-oriented parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9992082715034485}]}], "datasetContent": [{"text": "Because the aim of our research is to construct a Japanese parser that can extract semantic information from real-world texts, we evaluated our parser in terms of its coverage and semantic-role identification accuracy.", "labels": [], "entities": [{"text": "semantic-role identification", "start_pos": 180, "end_pos": 208, "type": "TASK", "confidence": 0.7210575044155121}, {"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.8699086904525757}]}, {"text": "We also compare the accuracy of our parser with that of an existing statistical dependency analyzer, in order to investigate the necessity of further improvements to our disambiguation model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9995437264442444}]}, {"text": "The following experiments were conducted using the EDR Japanese corpus.", "labels": [], "entities": [{"text": "EDR Japanese corpus", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.9762494564056396}]}, {"text": "An HPSG grammar was extracted from 51951 6 sentences of the corpus, and the same set of sentences were used as a training set for the disambiguation model.", "labels": [], "entities": [{"text": "HPSG grammar", "start_pos": 3, "end_pos": 15, "type": "DATASET", "confidence": 0.8992530107498169}]}, {"text": "47767 sentences (91.9%) of the training set were successfully converted into an HPSG treebank, from which we extracted lexical entries.", "labels": [], "entities": [{"text": "HPSG treebank", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9673624634742737}]}, {"text": "When we construct a lexicon from the extracted lexical entries, we reserved lexical entry templates for infrequent words as default templates for unknown words of each POS, in order to achieve sufficient coverage.", "labels": [], "entities": []}, {"text": "The threshold for 'infrequent' words were determined to be 30 from the results of preliminary experiments.", "labels": [], "entities": []}, {"text": "We used 2079 EDR sentences as a test set.", "labels": [], "entities": [{"text": "2079 EDR sentences", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.7290841539700826}]}, {"text": "(Another set of 2078 sentences were used as a development set.)", "labels": [], "entities": []}, {"text": "The test set is also converted into an HPSG treebank, and the conversion was successful for 1913 sentences.", "labels": [], "entities": [{"text": "HPSG treebank", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9649741351604462}]}, {"text": "(We will call the obtained HPSG treebank the \"test treebank.\")", "labels": [], "entities": [{"text": "HPSG treebank", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.9515329003334045}]}, {"text": "As features of the log-linear model, we extracted the POS of the head, template name of the head, surface string and its ending of the head, punctuation contained in the phrase, and distance between heads of daughters, from each sign in derivation trees.", "labels": [], "entities": [{"text": "POS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9919095635414124}]}, {"text": "These features are used in combinations.", "labels": [], "entities": []}, {"text": "The coverage of the parser 7 on the test set was 95.3%.", "labels": [], "entities": [{"text": "coverage", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9942521452903748}]}, {"text": "Though it is still below the coverage achieved by SLUNG (, our grammar has richer information that enables semantic analysis, which is lacking in SLUNG.", "labels": [], "entities": [{"text": "coverage", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9512959122657776}, {"text": "semantic analysis", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.7864318192005157}]}, {"text": "We evaluated the parser in terms of its accuracy in identifying semantic roles of arguments of verbs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9988952875137329}]}, {"text": "For each phrase which is in complement-head relation with some VP, a semantic role is assigned according to the type 8 of the complement-head structure.", "labels": [], "entities": []}, {"text": "The performance of our parser on the test treebank was 63.8%/57.8% in precision/recall of semantic roles.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9992176294326782}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.8836440443992615}]}, {"text": "As most studies on syntactic parsing of Japanese have focused on bunsetsu-based dependency analysis, we also attempted an evaluation in this framework.", "labels": [], "entities": [{"text": "syntactic parsing of Japanese", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.8444056063890457}, {"text": "bunsetsu-based dependency analysis", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.5751179754734039}]}, {"text": "In order to evaluate our parser by bunsetsu dependency, we converted the phrase structures of EDR and the output of our parser into dependency structures of the right-most content word of each bunsetsu.", "labels": [], "entities": []}, {"text": "Bunsetsu boundaries of the EDR sentences were determined by using simple heuristic rules.", "labels": [], "entities": [{"text": "Bunsetsu", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9467630982398987}]}, {"text": "The dependency accuracies and the sentential accuracies of our parser and Kanayama et. al.'s analyzer are shown in: Accuracy of dependency analysis.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9906643629074097}, {"text": "dependency analysis", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.6925439685583115}]}, {"text": "Kanayama et. al., which are the best reported dependency accuracies on EDR.", "labels": [], "entities": [{"text": "EDR", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.6546942591667175}]}, {"text": "This experiment revealed that the accuracy of our parser requires further improvement, although our grammar achieved high coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9993401169776917}, {"text": "coverage", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9867349863052368}]}, {"text": "Our expectation is that incorporating grammar rules for complex structures which is ignored in the current implementation (e.g. control, relative clause, and coordination constructions) will improve the accuracy of the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9992175102233887}]}, {"text": "In addition, we should investigate whether the semantic analysis our parser provides can contribute the performance of more application-oriented tasks such as information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.8293999135494232}]}], "tableCaptions": []}