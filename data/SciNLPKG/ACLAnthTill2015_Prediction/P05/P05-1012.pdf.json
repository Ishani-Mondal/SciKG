{"title": [{"text": "Online Large-Margin Training of Dependency Parsers", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an effective training algorithm for linearly-scored dependency parsers that implements online large-margin multi-class training (Crammer and Singer, 2003; Crammer et al., 2003) on top of efficient parsing techniques for dependency trees (Eisner, 1996).", "labels": [], "entities": []}, {"text": "The trained parsers achieve a competitive dependency accuracy for both English and Czech with no language specific enhancements.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9444969296455383}]}], "introductionContent": [{"text": "Research on training parsers from annotated data has for the most part focused on models and training algorithms for phrase structure parsing.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 117, "end_pos": 141, "type": "TASK", "confidence": 0.8333147366841634}]}, {"text": "The best phrase-structure parsing models represent generatively the joint probability P (x, y) of sentence x having the structure y.", "labels": [], "entities": [{"text": "phrase-structure parsing", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.7077671885490417}]}, {"text": "Generative parsing models are very convenient because training consists of computing probability estimates from counts of parsing events in the training set.", "labels": [], "entities": []}, {"text": "However, generative models make complicated and poorly justified independence assumptions and estimations, so we might expect better performance from discriminatively trained models, as has been shown for other tasks like document classification) and shallow parsing).", "labels": [], "entities": [{"text": "document classification", "start_pos": 222, "end_pos": 245, "type": "TASK", "confidence": 0.7800151109695435}, {"text": "shallow parsing", "start_pos": 251, "end_pos": 266, "type": "TASK", "confidence": 0.5849921405315399}]}, {"text": "Ratnaparkhi's conditional maximum entropy model), trained to maximize conditional likelihood P (y|x) of the training data, performed nearly as well as generative models of the same vintage even though it scores parsing decisions in isolation and thus may suffer from the label bias problem ().", "labels": [], "entities": []}, {"text": "Discriminatively trained parsers that score entire trees fora given sentence have only recently been investigated ().", "labels": [], "entities": []}, {"text": "The most likely reason for this is that discriminative training requires repeatedly reparsing the training corpus with the current model to determine the parameter updates that will improve the training criterion.", "labels": [], "entities": []}, {"text": "The reparsing cost is already quite high for simple context-free models with O(n 3 ) parsing complexity, but it becomes prohibitive for lexicalized grammars with O(n 5 ) parsing complexity.", "labels": [], "entities": []}, {"text": "Dependency trees are an alternative syntactic representation with along history.", "labels": [], "entities": []}, {"text": "Dependency trees capture important aspects of functional relationships between words and have been shown to be useful in many applications including relation extraction (), paraphrase acquisition () and machine translation).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.8075403273105621}, {"text": "paraphrase acquisition", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.9198555648326874}, {"text": "machine translation", "start_pos": 203, "end_pos": 222, "type": "TASK", "confidence": 0.8243467807769775}]}, {"text": "Yet, they can be parsed in O(n 3 ) time.", "labels": [], "entities": []}, {"text": "Therefore, dependency parsing is a potential \"sweet spot\" that deserves investigation.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9232215583324432}]}, {"text": "We focus hereon projective dependency trees in which a word is the parent of all of its arguments, and dependencies are non-crossing with respect to word order (see.", "labels": [], "entities": []}, {"text": "However, there are cases where crossing dependencies may occur, as is the case for Czech.", "labels": [], "entities": []}, {"text": "Edges in a dependency tree maybe typed (for instance to indicate grammatical function).", "labels": [], "entities": []}, {"text": "Though we focus on the simpler non-typed case, all algorithms are easily extendible to typed structures.", "labels": [], "entities": []}, {"text": "The following work on dependency parsing is most relevant to our research.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9087643921375275}]}, {"text": "Eisner (1996) gave a generative model with a cubic parsing algorithm based on an edge factorization of trees.", "labels": [], "entities": []}, {"text": "trained support vector machines (SVM) to make parsing decisions in a shift-reduce dependency parser.", "labels": [], "entities": []}, {"text": "As in Ratnaparkhi's parser, the classifiers are trained on individual decisions rather than on the overall quality of the parse.", "labels": [], "entities": []}, {"text": "developed a history-based learning model.", "labels": [], "entities": []}, {"text": "Their parser uses a hybrid bottom-up/topdown linear-time heuristic parser and the ability to label edges with semantic types.", "labels": [], "entities": []}, {"text": "The accuracy of their parser is lower than that of.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997329115867615}]}, {"text": "We present anew approach to training dependency parsers, based on the online large-margin learning algorithms of  and . Unlike the SVM parser of and Ratnaparkhi's parser, our parsers are trained to maximize the accuracy of the overall tree.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9985468983650208}]}, {"text": "Our approach is related to those of and for phrase structure parsing.", "labels": [], "entities": [{"text": "phrase structure parsing", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.8102971712748209}]}, {"text": "presented a linear parsing model trained with an averaged perceptron algorithm.", "labels": [], "entities": []}, {"text": "However, to use parse features with sufficient history, their parsing algorithm must prune heuristically most of the possible parses.", "labels": [], "entities": []}, {"text": "formulate the parsing problem in the large-margin structured classification setting (, but are limited to parsing sentences of 15 words or less due to computation time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9836079478263855}]}, {"text": "Though these approaches represent good first steps towards discriminatively-trained parsers, they have not yet been able to display the benefits of discriminative training that have been seen in namedentity extraction and shallow parsing.", "labels": [], "entities": [{"text": "namedentity extraction", "start_pos": 195, "end_pos": 217, "type": "TASK", "confidence": 0.768803060054779}, {"text": "shallow parsing", "start_pos": 222, "end_pos": 237, "type": "TASK", "confidence": 0.6048808395862579}]}, {"text": "Besides simplicity, our method is efficient and accurate, as we demonstrate experimentally on English and Czech treebank data.", "labels": [], "entities": [{"text": "Czech treebank data", "start_pos": 106, "end_pos": 125, "type": "DATASET", "confidence": 0.8202394644419352}]}], "datasetContent": [{"text": "We tested our methods experimentally on the English Penn Treebank () and on the Czech Prague Dependency Treebank.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 44, "end_pos": 65, "type": "DATASET", "confidence": 0.875849445660909}, {"text": "Czech Prague Dependency Treebank", "start_pos": 80, "end_pos": 112, "type": "DATASET", "confidence": 0.8631890267133713}]}, {"text": "All experiments were run on a dual 64-bit AMD Opteron 2.4GHz processor.", "labels": [], "entities": []}, {"text": "To create dependency structures from the Penn Treebank, we used the extraction rules of, which are an approximation to the lexicalization rules of.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.996086448431015}]}, {"text": "We split the data into three parts: sections 02-21 for training, section 22 for development and section 23 for evaluation.", "labels": [], "entities": []}, {"text": "Currently the system has 6, 998, 447 features.", "labels": [], "entities": []}, {"text": "Each instance only uses a tiny fraction of these features making sparse vector calculations possible.", "labels": [], "entities": []}, {"text": "Our system assumes POS tags as input and uses the tagger of Ratnaparkhi (1996) to provide tags for the development and evaluation sets.", "labels": [], "entities": []}, {"text": "shows the performance of the systems that were compared.", "labels": [], "entities": []}, {"text": "Y&M2003 is the SVM-shiftreduce parsing model of, N&S2004 is the memory-based learner of and MIRA is the the system we have described.", "labels": [], "entities": [{"text": "SVM-shiftreduce parsing", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.8371247053146362}, {"text": "MIRA", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9354801774024963}]}, {"text": "We also implemented an averaged perceptron system) (another online learning algorithm) for comparison.", "labels": [], "entities": []}, {"text": "This table compares only pure dependency parsers that do: Dependency parsing results for English and Czech.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.6841454803943634}, {"text": "Dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7714358866214752}]}, {"text": "Accuracy is the number of words that correctly identified their parent in the tree.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9943536520004272}]}, {"text": "Root is the number of trees in which the root word was correctly identified.", "labels": [], "entities": [{"text": "Root", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9117777943611145}]}, {"text": "For Czech this is f-measure since a sentence may have multiple roots.", "labels": [], "entities": []}, {"text": "Complete is the number of sentences for which the entire dependency tree was correct.", "labels": [], "entities": [{"text": "Complete", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9838472008705139}]}, {"text": "We ensured that the gold standard dependencies of all systems compared were identical.", "labels": [], "entities": []}, {"text": "shows that the model described here performs as well or better than previous comparable systems, including that of.", "labels": [], "entities": []}, {"text": "Their method has the potential advantage that SVM batch training takes into account all of the constraints from all training instances in the optimization, whereas online training only considers constraints from one instance at a time.", "labels": [], "entities": [{"text": "SVM batch training", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8367858330408732}]}, {"text": "However, they are fundamentally limited by their approximate search algorithm.", "labels": [], "entities": []}, {"text": "In contrast, our system searches the entire space of dependency trees and most likely benefits greatly from this.", "labels": [], "entities": []}, {"text": "This difference is amplified when looking at the percentage of trees that correctly identify the root word.", "labels": [], "entities": []}, {"text": "The models that search the entire space will not suffer from bad approximations made early in the search and thus are more likely to identify the correct root, whereas the approximate algorithms are prone to error propagation, which culminates with attachment decisions at the top of the tree.", "labels": [], "entities": []}, {"text": "When comparing the two online learning models, it can be seen that MIRA outperforms the averaged perceptron method.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.8406122326850891}]}, {"text": "This difference is statistically significant, p < 0.005 (McNemar test on head selection accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.6495000123977661}]}, {"text": "In our Czech experiments, we used the dependency trees annotated in the Prague Treebank, and the predefined training, development and evaluation sections of this data.", "labels": [], "entities": [{"text": "Prague Treebank", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.8621965944766998}]}, {"text": "The number of sentences in this data set is nearly twice that of the English treebank, leading to a very large number of features -13, 450, 672.", "labels": [], "entities": [{"text": "English treebank", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.8728111088275909}]}, {"text": "But again, each instance uses just a handful of these features.", "labels": [], "entities": []}, {"text": "For POS tags we used the automatically generated tags in the data set.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.629687488079071}]}, {"text": "Though we made no language specific model changes, we did need to make some data specific changes.", "labels": [], "entities": []}, {"text": "In particular, we used the method of  to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features.", "labels": [], "entities": []}, {"text": "The model based on MIRA also performs well on Czech, again slightly outperforming averaged perceptron.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.5586226582527161}, {"text": "Czech", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.9832873344421387}]}, {"text": "Unfortunately, we do not know of any other parsing systems tested on the same data set.", "labels": [], "entities": []}, {"text": "The Czech parser of  was run on a different data set and most other dependency parsers are evaluated using English.", "labels": [], "entities": []}, {"text": "Learning a model from the Czech training data is somewhat problematic since it contains some crossing dependencies which cannot be parsed by the Eisner algorithm.", "labels": [], "entities": [{"text": "Czech training data", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.7375066677729288}]}, {"text": "One trick is to rearrange the words in the training set so that all trees are nested.", "labels": [], "entities": []}, {"text": "This at least allows the training algorithm to obtain reasonably low error on the training set.", "labels": [], "entities": []}, {"text": "We found that this did improve performance slightly to 83.6% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9948666095733643}]}], "tableCaptions": [{"text": " Table 2: Dependency parsing results for English and Czech. Accuracy is the number of words that correctly  identified their parent in the tree. Root is the number of trees in which the root word was correctly identified.  For Czech this is f-measure since a sentence may have multiple roots. Complete is the number of sentences  for which the entire dependency tree was correct.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8375148773193359}, {"text": "Accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9980466365814209}, {"text": "Complete", "start_pos": 293, "end_pos": 301, "type": "METRIC", "confidence": 0.9706053137779236}]}, {"text": " Table 3: Results comparing our system to those based on the Collins parser. Complexity represents the  computational complexity of each parser and Time the CPU time to parse sec. 23 of the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 190, "end_pos": 203, "type": "DATASET", "confidence": 0.9942251145839691}]}, {"text": " Table 4: Evaluation of k-best MIRA approximation.", "labels": [], "entities": [{"text": "MIRA approximation", "start_pos": 31, "end_pos": 49, "type": "METRIC", "confidence": 0.8826511204242706}]}]}