{"title": [{"text": "A Dynamic Bayesian Framework to Model Context and Memory in Edit Distance Learning: An Application to Pronunciation Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "Sitting at the intersection between statistics and machine learning, Dynamic Bayesian Networks have been applied with much success in many domains, such as speech recognition, vision, and computational biology.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 156, "end_pos": 174, "type": "TASK", "confidence": 0.75645911693573}]}, {"text": "While Natural Language Processing increasingly relies on statistical methods, we think they have yet to use Graphical Models to their full potential.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 6, "end_pos": 33, "type": "TASK", "confidence": 0.6325115462144216}]}, {"text": "In this paper, we report on experiments in learning edit distance costs using Dynamic Bayesian Networks and present results on a pronunciation classification task.", "labels": [], "entities": [{"text": "pronunciation classification task", "start_pos": 129, "end_pos": 162, "type": "TASK", "confidence": 0.9110461870829264}]}, {"text": "By exploiting the ability within the DBN framework to rapidly explore a large model space, we obtain a 40% reduction in error rate compared to a previous transducer-based method of learning edit distance.", "labels": [], "entities": [{"text": "error rate", "start_pos": 120, "end_pos": 130, "type": "METRIC", "confidence": 0.9857085347175598}]}], "introductionContent": [{"text": "Edit distance (ED) is a common measure of the similarity between two strings.", "labels": [], "entities": [{"text": "Edit distance (ED)", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.9430215716361999}]}, {"text": "It has a wide range of applications in classification, natural language processing, computational biology, and many other fields.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.6043874522050222}, {"text": "computational biology", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.7213064730167389}]}, {"text": "It has been extended in various ways; for example, to handle simple ( or (constrained) block transpositions (, and other types of block operations (; and to measure similarity between graphs ( or automata).", "labels": [], "entities": []}, {"text": "* This material was supported by NSF under Grant No. ISS-0326276.", "labels": [], "entities": [{"text": "NSF under Grant No. ISS-0326276", "start_pos": 33, "end_pos": 64, "type": "DATASET", "confidence": 0.6788690209388732}]}, {"text": "Another important development has been the use of data-driven methods for the automatic learning of edit costs, such as in () in the case of string edit distance and in) for graph edit distance.", "labels": [], "entities": [{"text": "graph edit distance", "start_pos": 174, "end_pos": 193, "type": "TASK", "confidence": 0.6407672564188639}]}, {"text": "In this paper we revisit the problem of learning string edit distance costs within the Graphical Models framework.", "labels": [], "entities": []}, {"text": "We apply our method to a pronunciation classification task and show significant improvements over the standard Levenshtein distance) and a previous transducer-based learning algorithm.", "labels": [], "entities": [{"text": "pronunciation classification task", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.9209938049316406}]}, {"text": "In section 2, we review a stochastic extension of the classic string edit distance.", "labels": [], "entities": []}, {"text": "We present our DBNbased edit distance models in section 3 and show results on a pronunciation classification task in section 4.", "labels": [], "entities": [{"text": "pronunciation classification task", "start_pos": 80, "end_pos": 113, "type": "TASK", "confidence": 0.8819854458173116}]}, {"text": "In section 5, we discuss the computational aspects of using our models.", "labels": [], "entities": []}, {"text": "We end with our conclusions and future work in section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: DBN based model results summary.", "labels": [], "entities": []}]}