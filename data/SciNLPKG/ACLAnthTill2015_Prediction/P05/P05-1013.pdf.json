{"title": [], "abstractContent": [{"text": "In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.", "labels": [], "entities": [{"text": "dependency-based syntactic parsing", "start_pos": 42, "end_pos": 76, "type": "TASK", "confidence": 0.6313740909099579}]}, {"text": "We show how a data-driven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.", "labels": [], "entities": []}, {"text": "Experiments using data from the Prague Dependency Treebank show that the combined system can handle non-projective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy.", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 32, "end_pos": 58, "type": "DATASET", "confidence": 0.9688506325085958}, {"text": "precision", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9985404014587402}, {"text": "parsing", "start_pos": 203, "end_pos": 210, "type": "TASK", "confidence": 0.9618840217590332}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.8587428331375122}]}, {"text": "This leads to the best reported performance for robust non-projective parsing of Czech.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is sometimes claimed that one of the advantages of dependency grammar over approaches based on constituency is that it allows a more adequate treatment of languages with variable word order, where discontinuous syntactic constructions are more common than in languages like English.", "labels": [], "entities": [{"text": "dependency grammar", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.8240446150302887}]}, {"text": "However, this argument is only plausible if the formal framework allows non-projective dependency structures, i.e. structures where ahead and its dependents may correspond to a discontinuous constituent.", "labels": [], "entities": []}, {"text": "From the point of view of computational implementation this can be problematic, since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.", "labels": [], "entities": [{"text": "parsing", "start_pos": 139, "end_pos": 146, "type": "TASK", "confidence": 0.9683840870857239}, {"text": "accuracy", "start_pos": 226, "end_pos": 234, "type": "METRIC", "confidence": 0.9985602498054504}]}, {"text": "Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.", "labels": [], "entities": []}, {"text": "This is true of the widely used link grammar parser for English, which uses a dependency grammar of sorts, the probabilistic dependency parser of, and more recently proposed deterministic dependency parsers).", "labels": [], "entities": []}, {"text": "It is also true of the adaptation of the Collins parser for Czech () and the finite-state dependency parser for Turkish by.", "labels": [], "entities": [{"text": "Collins", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9385098814964294}]}, {"text": "This is in contrast to dependency treebanks, e.g. Prague Dependency), Danish Dependency Treebank (, and the METU Treebank of Turkish (, which generally allow annotations with nonprojective dependency structures.", "labels": [], "entities": [{"text": "Prague Dependency)", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.9808797240257263}, {"text": "Danish Dependency Treebank", "start_pos": 70, "end_pos": 96, "type": "DATASET", "confidence": 0.9289018511772156}, {"text": "METU Treebank of Turkish", "start_pos": 108, "end_pos": 132, "type": "DATASET", "confidence": 0.9465504139661789}]}, {"text": "The fact that projective dependency parsers can never exactly reproduce the analyses found in non-projective treebanks is often neglected because of the relative scarcity of problematic constructions.", "labels": [], "entities": []}, {"text": "While the proportion of sentences containing non-projective dependencies is often 15-25%, the total proportion of non-projective arcs is normally only 1-2%.", "labels": [], "entities": []}, {"text": "As long as the main evaluation metric is dependency accuracy per word, with state-of-the-art accuracy mostly below 90%, the penalty for not handling non-projective constructions is almost negligible.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.7576909065246582}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9789041876792908}]}, {"text": "Still, from a theoretical point of view, projective parsing of non-projective structures has the drawback that it rules out perfect accuracy even as an asymptotic goal.", "labels": [], "entities": [{"text": "projective parsing of non-projective structures", "start_pos": 41, "end_pos": 88, "type": "TASK", "confidence": 0.8142642974853516}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9351625442504883}]}, {"text": "There exist a few robust broad-coverage parsers that produce non-projective dependency structures, notably and for English, for German, and Holan (2004) for Czech.", "labels": [], "entities": []}, {"text": "In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.6653046607971191}]}, {"text": "Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing.", "labels": [], "entities": []}, {"text": "In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.7484220067660013}]}, {"text": "First, the training data for the parser is projectivized by applying a minimal number of lifting operations () and encoding information about these lifts in arc labels.", "labels": [], "entities": []}, {"text": "When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts.", "labels": [], "entities": []}, {"text": "By applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise to non-projective structures.", "labels": [], "entities": []}, {"text": "We call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (.", "labels": [], "entities": [{"text": "pseudoprojective dependency parsing", "start_pos": 13, "end_pos": 48, "type": "TASK", "confidence": 0.699687659740448}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2 we introduce the graph transformation techniques used to projectivize and deprojectivize dependency graphs, and in section 3 we describe the data-driven dependency parser that is the core of our system.", "labels": [], "entities": []}, {"text": "We then evaluate the approach in two steps.", "labels": [], "entities": []}, {"text": "First, in section 4, we evaluate the graph transformation techniques in themselves, with data from the Prague Dependency Treebank and the Danish Dependency Treebank.", "labels": [], "entities": [{"text": "graph transformation", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.7586081326007843}, {"text": "Prague Dependency Treebank", "start_pos": 103, "end_pos": 129, "type": "DATASET", "confidence": 0.9702405134836832}, {"text": "Danish Dependency Treebank", "start_pos": 138, "end_pos": 164, "type": "DATASET", "confidence": 0.9601890246073405}]}, {"text": "In section 5, we then evaluate the entire parsing system by training and evaluating on data from the Prague Dependency Treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 42, "end_pos": 49, "type": "TASK", "confidence": 0.9772868156433105}, {"text": "Prague Dependency Treebank", "start_pos": 101, "end_pos": 127, "type": "DATASET", "confidence": 0.9760268727938334}]}], "datasetContent": [{"text": "The first experiment uses data from two dependency treebanks.", "labels": [], "entities": []}, {"text": "The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text, annotated on three levels, the morphological, analytical and tectogrammatical levels.", "labels": [], "entities": [{"text": "Prague Dependency Treebank (PDT)", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.9333413938681284}]}, {"text": "Our experiments all concern the analytical annotation, and the first experiment is based only on the training part.", "labels": [], "entities": []}, {"text": "The Danish Dependency Treebank (DDT) comprises about 100K words of text selected from the Danish PAROLE corpus, with annotation of primary and secondary dependencies.", "labels": [], "entities": [{"text": "Danish Dependency Treebank (DDT)", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.9076637128988901}, {"text": "Danish PAROLE corpus", "start_pos": 90, "end_pos": 110, "type": "DATASET", "confidence": 0.7877299686272939}]}, {"text": "The entire treebank is used in the experiment, but only primary dependencies are considered.", "labels": [], "entities": []}, {"text": "In all experiments, punctuation tokens are included in the data but omitted in evaluation scores.", "labels": [], "entities": []}, {"text": "In the first part of the experiment, dependency graphs from the treebanks were projectivized using the algorithm described in section 2.", "labels": [], "entities": []}, {"text": "As shown in, the proportion of sentences containing some non-projective dependency ranges from about 15% in DDT to almost 25% in PDT.", "labels": [], "entities": []}, {"text": "However, the overall percentage of non-projective arcs is less than 2% in PDT and less than 1% in DDT.", "labels": [], "entities": [{"text": "PDT", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.6619056463241577}, {"text": "DDT", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.8489450812339783}]}, {"text": "The last four show the distribution of nonprojective arcs with respect to the number of lifts required.", "labels": [], "entities": []}, {"text": "It is worth noting that, although nonprojective constructions are less frequent in DDT than in PDT, they seem to be more deeply nested, since only about 80% can be projectivized with a single lift, while almost 95% of the non-projective arcs in PDT only require a single lift.", "labels": [], "entities": []}, {"text": "In the second part of the experiment, we applied the inverse transformation based on breadth-first search under the three different encoding schemes.", "labels": [], "entities": [{"text": "breadth-first", "start_pos": 85, "end_pos": 98, "type": "METRIC", "confidence": 0.9871441721916199}]}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "As expected, the most informative encoding, Head+Path, gives the highest accuracy with over 99% of all non-projective arcs being recovered correctly in both data sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9994553923606873}]}, {"text": "However, it can be noted that the results for the least informative encoding, Path, are almost comparable, while the third encoding, Head, gives substantially worse results for both data sets.", "labels": [], "entities": [{"text": "Head", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.8052676916122437}]}, {"text": "We also see that the increase in the size of the label sets for Head and Head+Path is far below the theoretical upper bounds given in.", "labels": [], "entities": []}, {"text": "The increase is generally higher for PDT than for DDT, which indicates a greater diversity in non-projective constructions.", "labels": [], "entities": []}, {"text": "The second experiment is limited to data from PDT.", "labels": [], "entities": [{"text": "PDT", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.9233396649360657}]}, {"text": "The training part of the treebank was projectivized under different encoding schemes and used to train memory-based dependency parsers, which were run on the test part of the treebank, consisting of 7,507 Preliminary experiments using data from DDT indicated that the limited size of the treebank creates a severe sparse data problem with respect to non-projective constructions.", "labels": [], "entities": [{"text": "DDT", "start_pos": 245, "end_pos": 248, "type": "DATASET", "confidence": 0.9206815958023071}]}, {"text": "The inverse transformation was applied to the output of the parsers and the result compared to the gold standard test set.", "labels": [], "entities": [{"text": "gold standard test set", "start_pos": 99, "end_pos": 121, "type": "DATASET", "confidence": 0.7498873993754387}]}, {"text": "shows the overall parsing accuracy attained with the three different encoding schemes, compared to the baseline (no special arc labels) and to training directly on non-projective dependency graphs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9596335887908936}]}, {"text": "Evaluation metrics used are Attachment Score (AS), i.e. the proportion of tokens that are attached to the correct head, and Exact Match (EM), i.e. the proportion of sentences for which the dependency graph exactly matches the gold standard.", "labels": [], "entities": [{"text": "Attachment Score (AS)", "start_pos": 28, "end_pos": 49, "type": "METRIC", "confidence": 0.952521562576294}, {"text": "Exact Match (EM)", "start_pos": 124, "end_pos": 140, "type": "METRIC", "confidence": 0.9422502756118775}]}, {"text": "In the labeled version of these metrics (L) both heads and arc labels must be correct, while the unlabeled version (U) only considers heads.", "labels": [], "entities": []}, {"text": "The first thing to note is that projectivizing helps in itself, even if no encoding is used, as seen from the fact that the projective baseline outperforms the non-projective training condition by more than half a percentage point on attachment score, although the gain is much smaller with respect to exact match.", "labels": [], "entities": []}, {"text": "The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.", "labels": [], "entities": [{"text": "parsing", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.976763129234314}, {"text": "attachment score", "start_pos": 196, "end_pos": 212, "type": "METRIC", "confidence": 0.8242639601230621}]}, {"text": "With respect to exact match, the improvement is even more noticeable, which shows quite clearly that even if non-projective dependencies are rare on the token level, they are nevertheless important forgetting the global syntactic structure correct.", "labels": [], "entities": []}, {"text": "All improvements over the baseline are statistically significant beyond the 0.01 level (McNemar's: Precision, recall and F-measure for non-projective arcs test).", "labels": [], "entities": [{"text": "Precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9196752309799194}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9989883303642273}, {"text": "F-measure", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9971079230308533}]}, {"text": "By contrast, when we turn to a comparison of the three encoding schemes it is hard to find any significant differences, and the overall impression is that it makes little or no difference which encoding scheme is used, as long as there is some indication of which words are assigned their linear head instead of their syntactic head by the projective parser.", "labels": [], "entities": []}, {"text": "This may seem surprising, given the experiments reported in section 4, but the explanation is probably that the non-projective dependencies that can be recovered at all are of the simple kind that only requires a single lift, where the encoding of path information is often redundant.", "labels": [], "entities": []}, {"text": "It is likely that the more complex cases, where path information could make a difference, are beyond the reach of the parser inmost cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Non-projective sentences and arcs in PDT and DDT (NonP = non-projective)", "labels": [], "entities": [{"text": "DDT", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.7639594674110413}]}, {"text": " Table 5: Parsing accuracy (AS = attachment score, EM = exact match; U = unlabeled, L = labeled)", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.6942456960678101}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9486559629440308}, {"text": "AS = attachment score", "start_pos": 28, "end_pos": 49, "type": "METRIC", "confidence": 0.8136119693517685}, {"text": "EM", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.949321448802948}, {"text": "exact match", "start_pos": 56, "end_pos": 67, "type": "METRIC", "confidence": 0.9432603120803833}]}, {"text": " Table 6: Precision, recall and F-measure for non-projective arcs", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986327290534973}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9996570348739624}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9993057250976562}]}]}