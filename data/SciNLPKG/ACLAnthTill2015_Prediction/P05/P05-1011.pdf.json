{"title": [{"text": "Probabilistic disambiguation models for wide-coverage HPSG parsing", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 54, "end_pos": 66, "type": "TASK", "confidence": 0.6800263673067093}]}], "abstractContent": [{"text": "This paper reports the development of log-linear models for the disambiguation in wide-coverage HPSG parsing.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 96, "end_pos": 108, "type": "TASK", "confidence": 0.703605979681015}]}, {"text": "The estimation of log-linear models requires high computational cost, especially with wide-coverage grammars.", "labels": [], "entities": [{"text": "estimation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9668861031532288}]}, {"text": "Using techniques to reduce the estimation cost, we trained the models using 20 sections of Penn Tree-bank.", "labels": [], "entities": [{"text": "estimation", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.6061433553695679}, {"text": "Penn Tree-bank", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.9963209927082062}]}, {"text": "A series of experiments empirically evaluated the estimation techniques, and also examined the performance of the disambiguation models on the parsing of real-world sentences.", "labels": [], "entities": [{"text": "estimation", "start_pos": 50, "end_pos": 60, "type": "TASK", "confidence": 0.9652525186538696}, {"text": "parsing of real-world sentences", "start_pos": 143, "end_pos": 174, "type": "TASK", "confidence": 0.8709412068128586}]}], "introductionContent": [{"text": "Head-Driven Phrase Structure Grammar (HPSG) has been studied extensively from both linguistic and computational points of view.", "labels": [], "entities": [{"text": "Head-Driven Phrase Structure Grammar (HPSG)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7525861689022609}]}, {"text": "However, despite research on HPSG processing efficiency, the application of HPSG parsing is still limited to specific domains and short sentences).", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 76, "end_pos": 88, "type": "TASK", "confidence": 0.6295415461063385}]}, {"text": "Scaling up HPSG parsing to assess real-world texts is an emerging research field with both theoretical and practical applications.", "labels": [], "entities": [{"text": "Scaling up HPSG parsing", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.680889368057251}]}, {"text": "Recently, a wide-coverage grammar and a large treebank have become available for English HPSG (.", "labels": [], "entities": [{"text": "English HPSG", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.6874976754188538}]}, {"text": "A large treebank can be used as training and test data for statistical models.", "labels": [], "entities": []}, {"text": "Therefore, we now have the basis for the development and the evaluation of statistical disambiguation models for wide-coverage HPSG parsing.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 127, "end_pos": 139, "type": "TASK", "confidence": 0.6805081814527512}]}, {"text": "The aim of this paper is to report the development of log-linear models for the disambiguation in widecoverage HPSG parsing, and their empirical evaluation through the parsing of the Wall Street Journal of Penn Treebank II (.", "labels": [], "entities": [{"text": "widecoverage HPSG parsing", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.5818675557772318}, {"text": "parsing", "start_pos": 168, "end_pos": 175, "type": "TASK", "confidence": 0.9749525785446167}, {"text": "Wall Street Journal of Penn Treebank II", "start_pos": 183, "end_pos": 222, "type": "DATASET", "confidence": 0.9601044739995684}]}, {"text": "This is challenging because the estimation of log-linear models is computationally expensive, and we require solutions to make the model estimation tractable.", "labels": [], "entities": []}, {"text": "We apply two techniques for reducing the training cost.", "labels": [], "entities": []}, {"text": "One is the estimation on a packed representation of HPSG parse trees (Section 3).", "labels": [], "entities": [{"text": "estimation", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9313716292381287}, {"text": "HPSG parse trees", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.8921689788500468}]}, {"text": "The other is the filtering of parse candidates according to a preliminary probability distribution (Section 4).", "labels": [], "entities": []}, {"text": "To our knowledge, this work provides the first results of extensive experiments of parsing Penn Treebank with a probabilistic HPSG.", "labels": [], "entities": [{"text": "parsing", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.9539502263069153}, {"text": "Penn Treebank", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.959709107875824}, {"text": "HPSG", "start_pos": 126, "end_pos": 130, "type": "DATASET", "confidence": 0.9269636869430542}]}, {"text": "The results from the Wall Street Journal are significant because the complexity of the sentences is different from that of short sentences.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 21, "end_pos": 40, "type": "DATASET", "confidence": 0.9602081775665283}]}, {"text": "Experiments of the parsing of realworld sentences can properly evaluate the effectiveness and possibility of parsing models for HPSG.", "labels": [], "entities": [{"text": "parsing of realworld sentences", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.8873296976089478}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Feature templates for binary schema (left), unary schema (center), and root condition (right)", "labels": [], "entities": []}, {"text": " Table 3: Accuracy for development/test sets", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991945624351501}]}, {"text": " Table 4: Estimation method vs. accuracy and esti- mation time", "labels": [], "entities": [{"text": "Estimation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9595261216163635}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9995629191398621}]}, {"text": " Table 5: Filtering threshold vs. accuracy and esti- mation time", "labels": [], "entities": [{"text": "Filtering threshold", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8793312013149261}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9988263249397278}]}, {"text": " Table 6: Accuracy with different feature sets", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9973049163818359}]}]}