{"title": [], "abstractContent": [{"text": "Recently there is a need fora QA system to answer not only factoid questions but also descriptive questions.", "labels": [], "entities": []}, {"text": "Descriptive questions are questions which need answers that contain definitional information about the search term or describe some special events.", "labels": [], "entities": []}, {"text": "We have proposed anew descriptive QA model and presented the result of a system which we have built to answer descriptive questions.", "labels": [], "entities": []}, {"text": "We defined 10 Descriptive Answer Type(DAT)s as answer types for descriptive questions.", "labels": [], "entities": []}, {"text": "We discussed how our proposed model was applied to the descriptive question with some experiments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much of effort in Question Answering has focused on the 'short answers' or factoid questions, which answer questions for which the correct response is a single word or short phrase from the answer sentence.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8503492474555969}]}, {"text": "However, there are many questions which are better answer with a longer description or explanation in logs of web search engines.", "labels": [], "entities": []}, {"text": "In this paper, we introduce anew descriptive QA model and present the result of a system which we have built to answer such questions.", "labels": [], "entities": []}, {"text": "Descriptive question are questions such as \"Who is Columbus?\", \"What is tsunami?\", or \"Why is blood red?\", which need answer that contain the definitional information about the search term, explain some special phenomenon.(i.e. chemical reaction) or describe some particular events.", "labels": [], "entities": []}, {"text": "At the recent works, definitional QA, namely questions of the form \"What is X?\", is a developing research area related with a subclass of descriptive questions.", "labels": [], "entities": [{"text": "definitional QA", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.9239007234573364}]}, {"text": "Especially in TREC-12 conference, they had produced 50 definitional questions in QA track for the competition.", "labels": [], "entities": [{"text": "TREC-12 conference", "start_pos": 14, "end_pos": 32, "type": "DATASET", "confidence": 0.87404665350914}]}, {"text": "The systems in TREC-12() applied complicated technique which was integrated manually constructed definition patterns with statistical ranking component.", "labels": [], "entities": [{"text": "TREC-12", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.7427122592926025}]}, {"text": "Some experiments() tried to use external resources such as WordNet and Web Dictionary associated with a syntactic pattern.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.960687518119812}]}, {"text": "Further recent work tried to use online knowledge bases on web.", "labels": [], "entities": []}, {"text": "Domain-specific definitional QA systems in the same context of our works have been developed.", "labels": [], "entities": [{"text": "Domain-specific definitional QA", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5964200695355734}]}, {"text": "Shiffman et al(2001) applied on biographical summaries for people with datadriven method.", "labels": [], "entities": []}, {"text": "In contrast to former research, we focus on the other descriptive question, such as \"why,\" \"how,\" and \"what kind of\".", "labels": [], "entities": []}, {"text": "We also present our descriptive QA model and its experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "To extract descriptive patterns, we built 1,853 pretagged sentences within 2,000 entries.", "labels": [], "entities": []}, {"text": "About 40%(760 sentences) of all are tagged with 'Definition, while only 9 sentences were assigned to 'Principle'.", "labels": [], "entities": [{"text": "Definition", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.8083022236824036}]}, {"text": "shows the result of extracted descriptive patterns using tagged corpus.", "labels": [], "entities": []}, {"text": "408 patterns are generated for 'Definition' from 760 tagged sentences, while 938 patterns for 'Function' from 352 examples.", "labels": [], "entities": []}, {"text": "That means the sentences of describing something's function formed very diverse expressions.", "labels": [], "entities": []}, {"text": "shows the result of DIU indexing.", "labels": [], "entities": [{"text": "DIU indexing", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.8098012506961823}]}, {"text": "We extracted 300,252 DIUs from the whole encyclopedia 4 using our Descriptive Answer Indexing process.", "labels": [], "entities": [{"text": "Descriptive Answer Indexing", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.584247757991155}]}, {"text": "As expected, most DIUs(about 55%, 164,327 DIUs) are 'Definition'.", "labels": [], "entities": []}, {"text": "We assumed that the entries belonging to the 'History' category have many sentences about 'Reason' because history usually describes some events.", "labels": [], "entities": []}, {"text": "However, we obtained only 25,110 DIUs(8%) of 'Reason' because patterns of 'Reason' have lack of expressing syntactic structure of adverb clauses of cause and effect.", "labels": [], "entities": [{"text": "DIUs", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9908574223518372}]}, {"text": "'Principle' also has same problem of lack of patterns so we only 64 DIUs.", "labels": [], "entities": []}, {"text": "To evaluate our descriptive question answering method, we used 152 descriptive questions from our ETRI QA Test Set 2.0 5 , judged by 4 assessors.", "labels": [], "entities": [{"text": "descriptive question answering", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.6336782574653625}, {"text": "ETRI QA Test Set 2.0 5", "start_pos": 98, "end_pos": 120, "type": "DATASET", "confidence": 0.9331845045089722}]}, {"text": "For performance comparisons, we used Top 1 and Top 5 precision, recall and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9244173765182495}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9997410178184509}, {"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9978138208389282}]}, {"text": "Top 5 precision is a measure to consider whether there is a correct answer in top 5 ranking or not.", "labels": [], "entities": [{"text": "precision", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.9696757793426514}]}, {"text": "Top 1 measured only one best ranked answer.", "labels": [], "entities": []}, {"text": "For our experimental evaluations we constructed an operational system in the Web, named \"AnyQuestion 2.0.\"", "labels": [], "entities": []}, {"text": "To demonstrate how effectively our model works, we compared to a sentence retrieval system.", "labels": [], "entities": []}, {"text": "Our sentence retrieval system used vector space model for query retrieval and 2-poisson model for keyword weighting.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7000456899404526}, {"text": "query retrieval", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7459452450275421}, {"text": "keyword weighting", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7118047475814819}]}, {"text": "shows that the scores using our proposed method are higher than that of traditional sentence retrieval system.", "labels": [], "entities": []}, {"text": "As expected, we obtained better result(0.608) than sentence retrieval system(0.508).", "labels": [], "entities": []}, {"text": "We gain 79.3% (0.290 to 0.520) increase on Top1 than sentence retrieval and 19.6%(0.508 to 0.608) on Top5.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7443977892398834}]}, {"text": "The fact that the accuracy on Top1 has dramatically increased is remarkable, in that question answering wants exactly only one relevant answer.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995680451393127}, {"text": "Top1", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.8534587621688843}, {"text": "question answering", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7405506074428558}]}, {"text": "Whereas even the recall of sentence retrieval system(0.507) is higher than descriptive QA result(0.500) on Top5, the F-score(0.508) is lower than that(0.608).", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9987996816635132}, {"text": "descriptive QA result", "start_pos": 75, "end_pos": 96, "type": "METRIC", "confidence": 0.8150270183881124}, {"text": "Top5", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.9632618427276611}, {"text": "F-score", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.998342752456665}]}, {"text": "It comes from the fact that sentence retrieval system tends to produce more number of candidates retrieved.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7339231073856354}]}, {"text": "While sentence retrieval system retrieved 151 candidates, our descriptive QA method retrieved 98 DIUs under the same condition that the number of corrected answers of sentence retrieval is 77 and ours is 76.", "labels": [], "entities": []}, {"text": "We further realized that our system has a few week points.", "labels": [], "entities": []}, {"text": "Our system is poor for inverted retrieval which should answer to the quiz style questions, such as \"What is a large wave, often caused by an earthquake?\"", "labels": [], "entities": []}, {"text": "Moreover, our system depends on initial patterns.", "labels": [], "entities": []}, {"text": "For the details, 'Principle' has few initial patterns, so that it has few descriptive patterns.", "labels": [], "entities": []}, {"text": "This problem has influence on retrieval results, too.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Result of Descriptive QA", "labels": [], "entities": []}]}