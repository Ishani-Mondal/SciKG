{"title": [{"text": "Learning Dependencies between Case Frame Slots", "labels": [], "entities": []}], "abstractContent": [{"text": "A theoretically sound method for learning dependencies between case frame slots is proposed.", "labels": [], "entities": []}, {"text": "In particular, the problem is viewed as that of estimating a probability distribution over the case slots represented by a dependency graph (a dependency forest).", "labels": [], "entities": []}, {"text": "Experimental results indicate that the proposed method can bring about a small improvement in disambiguation, but the results are largely consistent with the assumption often made in practice that case slots are mutually independent, at least when the data size is at the level that is currently available.", "labels": [], "entities": []}], "introductionContent": [{"text": "We address the problem of automatically acquiring case frame patterns (or their near equivalents, selectional patterns and subcategorization patterns) from large corpus data.", "labels": [], "entities": []}, {"text": "In our view, the acquisition of case frame patterns involves the following three subtasks: (1) extracting case frame instances from corpus data, i2) generalizing case frame slots within the case frames, and (3) learning dependencies that exist between the (generalized) case frame slots.", "labels": [], "entities": []}, {"text": "We consider here the third of these subtasks and propose a method of learning dependencies between case frame slots.", "labels": [], "entities": []}, {"text": "The term \"dependency\" refers to the relationship that may exist between case slots and that indicates strong co-occurrence between the values of those case slots.", "labels": [], "entities": []}, {"text": "For example, consider the following sentences: (1) She flies jets.", "labels": [], "entities": []}, {"text": "(2) That airline company flies jets.", "labels": [], "entities": []}, {"text": "(3) She flies Japan Airlines.", "labels": [], "entities": [{"text": "Japan Airlines", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.9031378328800201}]}, {"text": "(4) *That airline company flies Japan Airlines.", "labels": [], "entities": [{"text": "Japan Airlines", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.962654322385788}]}, {"text": "We see that airline company can be the value of the argl (subject) slot, when the value of the arg2 (direct object) slot is airplane but not when it is airline company.", "labels": [], "entities": []}, {"text": "These sentences indicate that the possible values of case slots depend in general on those of others: dependencies between case slots exist.", "labels": [], "entities": []}, {"text": "1 The knowledge of dependencies between case slots is useful in various tasks in natural language processing, especially in analyzing sentences involving multiple prepositional phrases, such as The girl will fly a jet from Tokyo to Beijing.", "labels": [], "entities": []}, {"text": "Note in this example * c/o C&C Media Res.", "labels": [], "entities": [{"text": "C&C Media Res.", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.7960917254288992}]}, {"text": "NEC, 4-1-1 Miyazaki Miyamae-ku, Kawasaki, 216-8555 Japan.", "labels": [], "entities": [{"text": "NEC, 4-1-1 Miyazaki Miyamae-ku, Kawasaki, 216-8555 Japan", "start_pos": 0, "end_pos": 56, "type": "DATASET", "confidence": 0.9173428833484649}]}, {"text": "E-mail: {lihang, abe}@ccm.d.nec.co.jp 1 One may argue that these examples involve different word senses of fly, and in general, that if word senses were disambiguated there would be no dependency between case slots.", "labels": [], "entities": []}, {"text": "But, with that interpretation, word senses would have to be automatically disambiguated given the corpus data, and we would find ourselves left with the same problem.", "labels": [], "entities": []}, {"text": "Furthermore, word senses are in general difficult to define precisely, and we feel it is better not to rely on this notion in a natural language application, unless it is necessary.", "labels": [], "entities": []}, {"text": "(~) 1999 Association for Computational Linguistics Example case frames generated by a class-based model.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the first experiment, we used the proposed method to learn slot-based dependencies.", "labels": [], "entities": []}, {"text": "As training data, we used the entire bracketed data of the Wall Street Journal corpus (Penn Treebank).", "labels": [], "entities": [{"text": "Wall Street Journal corpus (Penn Treebank)", "start_pos": 59, "end_pos": 101, "type": "DATASET", "confidence": 0.9067090228199959}]}, {"text": "We extracted case frame data from the corpus using some heuristic rules.", "labels": [], "entities": []}, {"text": "There were 3,678 verbs for which case frame instances were extracted.", "labels": [], "entities": []}, {"text": "We considered only the 354 verbs for which more than 50 case frame instances were extracted, since dependencies are not likely to be found with smaller data sizes (see Section 3.4.)", "labels": [], "entities": []}, {"text": "Also, we only considered the 12 most frequently occurring case slots (argl, arg2, on, in, for, at, by, from, to, as, with, against) and ignored the others.", "labels": [], "entities": [{"text": "argl", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9815410375595093}]}, {"text": "We acquired slot-based case frame patterns for the 354 verbs using our method.", "labels": [], "entities": []}, {"text": "There were on the average 484/354 = 1.4 dependency links acquired for each of the 354 verbs.", "labels": [], "entities": []}, {"text": "We found that there were some verbs whose arg2 slot is dependent on a preposition (referred to as p) slot.", "labels": [], "entities": []}, {"text": "shows some of the verbs with large P(Xarg2 = 1, Xp = 1) values.", "labels": [], "entities": []}, {"text": "We also found that there were some verbs having preposition slots that depend on each other (referred to as pl and p2).", "labels": [], "entities": []}, {"text": "also shows some of the verbs with large P(Xpl = 1, Xp2 = 1) values.", "labels": [], "entities": []}, {"text": "The dependencies found by our method seem to agree with human intuition.", "labels": [], "entities": []}, {"text": "gain 10 to 100 compare profit with estimate invest share in fund convert share to cash add 1 to 3 withdraw application from office prepare case for trial file suit against company sell facility to firm lose million to 10% range from 100 to 200 climb from million to million rise from billion to billion shift from stock to bond soar from 10% to 20% fall from million to million increase from million to million climb from million in period apply to commission for permission boost from 1% to 2% Perplexity Reduction.", "labels": [], "entities": []}, {"text": "We evaluated the acquired case frame patterns (using the slotbased models) for all of the 354 verbs in terms of reduction in test data perplexity.", "labels": [], "entities": []}, {"text": "2 We conducted the evaluation through a 10-fold cross validation.", "labels": [], "entities": []}, {"text": "That is, to acquire case frame patterns fora given verb, we used nine-tenths of the case frames for that verb as training data, saving what remained for use as test data, and then calculated the test data perplexity.", "labels": [], "entities": []}, {"text": "We repeated this process 10 times and calculated the average perplexity.", "labels": [], "entities": []}, {"text": "We then compared this with the average perplexity for independent models, which were acquired based on the assumption that each case slot is independent.", "labels": [], "entities": []}, {"text": "The experimental results indicate that for some verbs the use of dependency forest models results in a reduction of perplexity as compared to that of independent models.", "labels": [], "entities": []}, {"text": "For 30 of the 354 verbs (8%), perplexity reduction exceeded 10%, while the average perplexity reduction overall was only 1%.", "labels": [], "entities": [{"text": "perplexity reduction", "start_pos": 30, "end_pos": 50, "type": "METRIC", "confidence": 0.9011334776878357}, {"text": "perplexity reduction", "start_pos": 83, "end_pos": 103, "type": "METRIC", "confidence": 0.8400419652462006}]}, {"text": "Nonetheless, it seems safe to say that, with the currently available amount of data, the dependency forest model is more suitable as a representation for the true model of case frames than the independent model, at least for 8% of the 354 verbs.", "labels": [], "entities": []}, {"text": "In order to quantitatively evaluate the acquired knowledge of case slot dependencies, we conducted a PP-attachment disambiguation experiment, in which we make a decision of the following type: Whether from Tokyo should be attached to fly or jet in the sentence he will fly a jet from Tokyo.", "labels": [], "entities": []}, {"text": "Since the second term is common to both expressions, we actually only need to compare Pfly(Xfrom = 1 [Xarg 2 = 1) and Pjet(Xfrom = 1).", "labels": [], "entities": []}, {"text": "Obviously, if we assume that case slots are independent, then we only need to compare Pfly(Xfrom = 1) and Piet(Xfrom = 1).", "labels": [], "entities": []}, {"text": "This is nearly equivalent to the disambiguafion method proposed by.", "labels": [], "entities": []}, {"text": "Their method, referred to here as the Lexical Association (LA) method, actually compares the two probabilities by means of hypothesis testing.", "labels": [], "entities": []}, {"text": "Specifically, it calculates the so-called t-score, which is a statistic about the difference between the two probabilities.", "labels": [], "entities": []}, {"text": "Here, we first employ the proposed dependency learning method to judge if slots Xarg2 and Xfrom with respect to verb fly are mutually dependent.", "labels": [], "entities": []}, {"text": "Then, if they are dependent, we make the disambiguation decision based on the t-score between Pfly(Xfrom = 1 [ Xfrom = 1) and Pjet(Xfrom = 1).", "labels": [], "entities": []}, {"text": "Otherwise, we consider the two slots independent and make a decision based on the t-score between Pfly(Xfrom = 1) and Pjet(Xfrom = 1).", "labels": [], "entities": []}, {"text": "We call this disambiguation method DepenLA, since it is a natural extension of LA.", "labels": [], "entities": [{"text": "DepenLA", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.7148870825767517}]}, {"text": "First, we randomly selected the files under one directory of the Wall Street Journal corpus, containing roughly 1/26 of the entire bracketed corpus data, and extracted (v, nl, p, n2) quadruples (e.g., (fly, jet, from, Tokyo)) as test data.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.9848700314760208}]}, {"text": "We then extracted case frames from the remaining bracketed corpus data as we did in Experiment I and used them as training data.", "labels": [], "entities": []}, {"text": "We repeated this process 10 times and obtained 10 data sets consisting of different training data and test data.", "labels": [], "entities": []}, {"text": "In each training data set, there were roughly 128, 000 case frames on the average for verbs and roughly 59, 000 case frames for nouns.", "labels": [], "entities": []}, {"text": "On the average, there were 820 quadruples in each test data set.", "labels": [], "entities": []}, {"text": "We used these 10 data sets to conduct cross-validation on the disambiguation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9149385094642639}]}, {"text": "We used the training data to acquire dependency forest models, which we then used to perform disambiguation on the test data based on DepenLA.", "labels": [], "entities": [{"text": "DepenLA", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.9053805470466614}]}, {"text": "We also tested the performance of LA for comparison.", "labels": [], "entities": [{"text": "LA", "start_pos": 34, "end_pos": 36, "type": "DATASET", "confidence": 0.8082965016365051}]}, {"text": "We set the threshold for the t-score to 1.28 for both methods.", "labels": [], "entities": []}, {"text": "In both cases, some quadruples remained whose attachment sites could not be determined.", "labels": [], "entities": []}, {"text": "In such cases, we made a default decision--namely, we forcibly attached (p, n2) to v.", "labels": [], "entities": []}, {"text": "This is because we found empirically for our data set that for what remains after applying LA or DepenLA, it is most likely that (p, n2) goes with v. summarizes the results, which are evaluated in terms of disambiguation accuracy, averaged over the ten trials.", "labels": [], "entities": [{"text": "LA", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.9666487574577332}, {"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.688758134841919}]}, {"text": "also gives the standard deviation (+) of each accuracy value, calculated based on the assumption that the 10 cross-validation trials are statistically independent.", "labels": [], "entities": [{"text": "standard deviation", "start_pos": 15, "end_pos": 33, "type": "METRIC", "confidence": 0.9618904292583466}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9991106390953064}]}, {"text": "We found that as a whole it is still difficult to judge if DepenLA significantly improves upon LA, indicating that it is almost justifiable to rely on the independence assumption in practice, at least when the data size is at the level that is currently available.", "labels": [], "entities": [{"text": "LA", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.9982187151908875}]}, {"text": "For about 11% of the verbs, however, for which the dependencies are detected and are strong enough (i.e., P(Xp = 1 I Xarg2 = 1) > 0.2 or P(Xp = 1 [ Xarg 2 = 1) < 0.002), DepenLA significantly improves upon LA.", "labels": [], "entities": [{"text": "DepenLA", "start_pos": 170, "end_pos": 177, "type": "METRIC", "confidence": 0.9709793329238892}, {"text": "LA", "start_pos": 206, "end_pos": 208, "type": "METRIC", "confidence": 0.9950838685035706}]}, {"text": "(The cutoff points were set heuristically by observing the obtained dependencies, but not after the accuracy was calculated.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9992050528526306}]}, {"text": "It is interesting to note that on the subset of data for which DepenLA is found to significantly improve upon LA, LA is already doing quite well: 93.8% as compared to 78.1%.", "labels": [], "entities": [{"text": "LA", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9406272768974304}, {"text": "LA", "start_pos": 114, "end_pos": 116, "type": "METRIC", "confidence": 0.9774108529090881}]}, {"text": "We found that in cases in which dependencies are detected (i.e., P(Xp = 1 I Xarg2 = 1~ >> P(Xp = 1) or the converse), the probability value P(Xp = 1) is already highly discriminative, that is, either very large or very small.", "labels": [], "entities": []}, {"text": "This is probably due to the fact that the verbs for which dependencies are detected are those for which the amount of training data is sufficient (relative to the inherent difficulty of disambiguation for that verb), and hence that are easy to disambiguate.", "labels": [], "entities": []}, {"text": "We also used the proposed method to acquire case frame patterns as class-based dependency forest models, using the 354 verbs in Experiment 1.", "labels": [], "entities": []}, {"text": "As before, we considered only the 12 most frequent slots.", "labels": [], "entities": []}, {"text": "We generalized the values of the case slots within these case frames using the method proposed in to obtain class-based case frame data.", "labels": [], "entities": []}, {"text": "We then used these data as input to the learning algorithm.", "labels": [], "entities": []}, {"text": "The results were rather discouraging: very few case slots were determined to be dependent in the case frame patterns.", "labels": [], "entities": []}, {"text": "To be more precise, there were on the average only 64/354 -0.2 dependency links found for each verb.", "labels": [], "entities": []}, {"text": "This is because the number of parameters in a class-based model was large as compared to the size of the data we had available.", "labels": [], "entities": []}, {"text": "These experimental results seem to justify the commonly made assumption that class-based case slots, and hence word-based case slots, are mutually independent, when the data size available is at the level of what is currently provided by the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 242, "end_pos": 255, "type": "DATASET", "confidence": 0.9954780340194702}]}, {"text": "In order to test how large a data size is required to estimate a dependency forest model, we conducted the following experiment.", "labels": [], "entities": []}, {"text": "We defined an artificial model in the form of a dependency forest model and generated data according to its distribution.", "labels": [], "entities": []}, {"text": "We then used the data obtained to estimate a model, and evaluated the estimated model by measuring the KL divergence between the estimated model and the true model.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 103, "end_pos": 116, "type": "METRIC", "confidence": 0.8365336358547211}]}, {"text": "We also checked the number of dependency links in the obtained model.", "labels": [], "entities": []}, {"text": "We repeatedly generated data and observed the learning curve, namely the relationship between the data size and the KL divergence between the estimated and true models, and the relationship between the data size and the number of dependencies in the estimated model.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 116, "end_pos": 129, "type": "METRIC", "confidence": 0.7980533242225647}]}, {"text": "We repeated this experiment on three artificial models.", "labels": [], "entities": []}, {"text": "shows the results of these experiments averaged over 10 trials.", "labels": [], "entities": []}, {"text": "The number of parameters in Model 1, Model 2, and Model 3 are 18, 30, and 44 respectivel~ and the number of links in them 1, 3, and 5.", "labels": [], "entities": []}, {"text": "Note that the KL divergence between the estimated model and the true model converges to 0, as expected.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 14, "end_pos": 27, "type": "METRIC", "confidence": 0.7976121604442596}]}, {"text": "Also note that the number of links in the estimated model converges to the correct value) in each of the three examples.", "labels": [], "entities": []}, {"text": "These simulation results verify that the dependencies between case slots can be accurately learned when there is enough data, given that the true model is representable as a dependency forest model.", "labels": [], "entities": []}, {"text": "We also see that to estimate a model reasonably accurately, the data size required is as large as 5 to 10 times the number of parameters.", "labels": [], "entities": []}, {"text": "For example, for the KL divergence to go below 0.1, we need more than 200 examples, which is roughly 5 to 10 times the number of parameters.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.5295068174600601}]}, {"text": "(Recall that there were only 354 verbs, having frequencies greater than 50 in our experiments, see Subsection 3.1.)", "labels": [], "entities": []}, {"text": "In Experiment 2, there were 12 binary-valued random variables associated with each verb, and hence its distribution is thought to be approximatable by a model with a comparable number of parameters.", "labels": [], "entities": []}, {"text": "So having 50 to 100 examples for each of these verbs approaches the minimum data size required for reasonable estimation of their dependencies.", "labels": [], "entities": []}, {"text": "In Experiment 3 there were also 12 slots, but each slot could take on roughly 10 classes as its values and thus a class-based model tended to have about 120 parameters.", "labels": [], "entities": []}, {"text": "The corpus data available to us was in noway sufficient for this case.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  PP-attachrnent disambiguation results.", "labels": [], "entities": []}]}