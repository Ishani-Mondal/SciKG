{"title": [], "abstractContent": [{"text": "This paper presents an implemented computational model for interpreting and generating indirect answers to yes-no questions in English.", "labels": [], "entities": [{"text": "interpreting and generating indirect answers to yes-no questions in English", "start_pos": 59, "end_pos": 134, "type": "TASK", "confidence": 0.7763100266456604}]}, {"text": "Interpretation and generation are treated, respectively, as recognition of and construction of a responder's discourse plan fora full answer.", "labels": [], "entities": []}, {"text": "An indirect answer is the result of the responder providing only part of the planned response, but intending for his discourse plan to be recognized by the questioner.", "labels": [], "entities": []}, {"text": "Discourse plan construction and recognition make use of shared knowledge of discourse strategies, represented in the model by discourse plan operators.", "labels": [], "entities": [{"text": "Discourse plan construction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6850124796231588}]}, {"text": "In the operators, coherence relations are used to characterize types of information that may accompany each type of answer.", "labels": [], "entities": []}, {"text": "Recognizing a mutually plausible coherence relation obtaining between the actual response and a possible direct answer plays an important role in recognizing the responder's discourse plan.", "labels": [], "entities": []}, {"text": "During generation, stimulus conditions model a speaker's motivation for selecting a satellite.", "labels": [], "entities": []}, {"text": "Also during generation, the speaker uses his own interpretation capability to determine what parts of the plan are inferable by the hearer and thus do not need to be explicitly given.", "labels": [], "entities": []}, {"text": "The model provides wider coverage than previous computational models for generating and interpreting indirect answers and extends the plan-based theory of implicature in several ways.", "labels": [], "entities": [{"text": "interpreting indirect answers", "start_pos": 88, "end_pos": 117, "type": "TASK", "confidence": 0.8216383258501688}]}], "introductionContent": [{"text": "In the following example, 1 Q asks a question in (1)i and R provides the requested information in (1)iii, although not explicitly giving (1)ii.", "labels": [], "entities": []}, {"text": "(In this paper, we use square brackets as inii to indicate information which, in our judgment, the speaker intended to convey but did not explicitly state.", "labels": [], "entities": []}, {"text": "For consistency, we refer to the questioner and responder as Q and R, respectively.", "labels": [], "entities": [{"text": "consistency", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.7603642344474792}]}, {"text": "For readability, we have standardized punctuation and capitalization and have omitted prosodic information from sources since it is not used in our model.) i. Q: Actually you'll probably get a car won't you as soon as you get there?", "labels": [], "entities": []}, {"text": "Interpreting such responses, which we refer to as indirect answers, requires the hearer to derive a conversational implicature.", "labels": [], "entities": []}, {"text": "For example, the inference that R (2) i.", "labels": [], "entities": []}, {"text": "Q: Have you gotten the letters yet?", "labels": [], "entities": [{"text": "Q", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9011684060096741}]}, {"text": "R: I've gotten the letter from X.", "labels": [], "entities": []}, {"text": "This example illustrates a casein which, provided that R had gotten some but not all of the letters in question, just yes would be untruthful and just no would be misleading (since Q might conclude from the latter that R had gotten none of them).", "labels": [], "entities": []}, {"text": "We have developed a computational model, implemented in Common LISP, for interpreting and generating indirect answers to yes-no questions in English.", "labels": [], "entities": [{"text": "Common LISP", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.8879148960113525}, {"text": "interpreting and generating indirect answers to yes-no questions in English", "start_pos": 73, "end_pos": 148, "type": "TASK", "confidence": 0.7396427035331726}]}, {"text": "By a yes-no question we mean one or more utterances used as a request by Q that R convey R's evaluation of the truth of a proposition p.", "labels": [], "entities": []}, {"text": "Consisting of one or more utterances, an indirect answer is used to convey, yet does not semantically entail, R's evaluation of the truth of p, i.e., that p is true, that p is false, that p might be true, that p might be false, or that p is partially true.", "labels": [], "entities": []}, {"text": "In contrast, a direct answer entails R's evaluation of the truth of p.", "labels": [], "entities": []}, {"text": "The model presupposes that Q and R mutually believe that Q's question has been understood by R as intended by Q, that Q's question is appropriate, and that R can provide one of the above answers.", "labels": [], "entities": []}, {"text": "Furthermore, it is assumed that Q and R are engaged in a cooperative and polite task-oriented dialogue.", "labels": [], "entities": []}, {"text": "3 The model is based upon examples of uses of direct and indirect answers found in transcripts of two-person telephone conversations between travel agents and their clients), examples given in previous studies and constructed examples reflecting our judgments.", "labels": [], "entities": []}, {"text": "To give an overview of the model, generation and interpretation are treated, respectively, as construction of and recognition of the responder's discourse plan specification fora full answer.", "labels": [], "entities": []}, {"text": "In general, a discourse plan specification (for the sake of brevity, hereafter referred to as discourse plan) explicitly relates a speaker's beliefs and discourse goals to his program of communicative actions).", "labels": [], "entities": []}, {"text": "Discourse plan construction and recognition make use of the beliefs that are presumed to be shared by the participants, as well as shared knowledge of discourse strategies, represented in the model by a set of discourse plan operators encoding generic programs of communicative actions for conveying full answers.", "labels": [], "entities": [{"text": "Discourse plan construction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6817819476127625}]}, {"text": "A full answer consists of a direct answer, which we refer to as the nucleus, and \"extra\" appropriate information, which we refer to as the satellite(s).", "labels": [], "entities": []}, {"text": "4 In the operators, coherence relations are used to characterize types of satellites that may accompany each type of answer.", "labels": [], "entities": []}, {"text": "Stimulus conditions are used to characterize the speaker's motivation for including a satellite.", "labels": [], "entities": []}, {"text": "An indirect answer is the result of the speaker (R) expressing only part of the planned response, i.e., omitting the direct answer (and possibly more), but intending for his discourse plan to be recognized by the hearer (Q).", "labels": [], "entities": []}, {"text": "Furthermore, we argue that because of the role of interpretation in generation, Q's belief that R intended for Q to recognize the answer is warranted by Q's recognition of the plan.", "labels": [], "entities": []}, {"text": "The inputs to the interpretation component of the model (a model of Q's interpretation of an indirect answer) are the semantic representation of the questioned proposition, the semantic representation of the utterances given by R during R's turn, shared pragmatic knowledge, and Q's beliefs, including those presumed by Q to be shared with R.", "labels": [], "entities": []}, {"text": "(Beliefs presumed by an agent to be shared by another agent are hereafter referred to as shared beliefs, and those that are not presumed to be shared as nonshared beliefs).", "labels": [], "entities": []}, {"text": "5 The output is a set of alternative discourse plans that might be ascribed to R by Q, ranked by plausibility.", "labels": [], "entities": []}, {"text": "R's inferred discourse plan provides the intended answer and possibly other information about R's beliefs and intentions.", "labels": [], "entities": []}, {"text": "The inputs to the generation component (a model of R's construction of a response) are the semantic representation of the questioned proposition, shared pragmatic knowledge, and R's beliefs (both shared and nonshared).", "labels": [], "entities": []}, {"text": "The output of generation is R's discourse plan fora full answer, including a specification of which parts of the plan do not need to be explicitly given by R, i.e., which parts should be inferable by Q from the rest of the answer.", "labels": [], "entities": []}, {"text": "6 This paper describes the knowledge and processes provided in our model for interpreting and generating indirect answers.", "labels": [], "entities": [{"text": "interpreting and generating indirect answers", "start_pos": 77, "end_pos": 121, "type": "TASK", "confidence": 0.8378087282180786}]}, {"text": "(The model is not intended as a cognitive model, i.e., we are not claiming that it reflects the participants' cognitive states during the time course of comprehension and generation.", "labels": [], "entities": []}, {"text": "Rather, its purpose is to compute the end products of comprehension and generation, and to contribute to a computational theory of conversational implicature.)", "labels": [], "entities": []}, {"text": "As background, Section 2 describes some relevant generalizations about questions and answers in English.", "labels": [], "entities": []}, {"text": "Section 3 describes the reversible knowledge in our model, i.e., knowledge used both in interpretation and generation of indirect answers.", "labels": [], "entities": [{"text": "interpretation and generation of indirect answers", "start_pos": 88, "end_pos": 137, "type": "TASK", "confidence": 0.7640252908070883}]}, {"text": "Sections 4 and 5 describe the interpretation and generation components, respectively.", "labels": [], "entities": []}, {"text": "Section 5 includes a description of additional pragmatic knowledge required for generation.", "labels": [], "entities": []}, {"text": "Section 6 provides an evaluation of the work.", "labels": [], "entities": []}, {"text": "Finally, the last section discusses future research and provides a summary.", "labels": [], "entities": []}, {"text": "4 This terminology was adopted from Rhetorical Structure Theory (, discussed in Section 2. 5 Our notion of shared belief is similar to the notion of one-sided mutual belief.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.7217050890127817}]}, {"text": "However, following, a shared belief is merely represented in the conversational record as if it were mutually believed, although each participant need not actually believe it.", "labels": [], "entities": []}, {"text": "6 However, our model does not address the interesting question of under what conditions a direct answer should be given explicitly even when it is inferable from other parts of the response.", "labels": [], "entities": []}, {"text": "For some related work on the function of redundant information, see.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have implemented a prototype of the model in Common LISP.", "labels": [], "entities": [{"text": "Common LISP", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.889983206987381}]}, {"text": "The implemented system can interpret and generate the types of examples discussed in Sections 4 and 5 and the specific examples tested in the experiments described below.", "labels": [], "entities": []}, {"text": "The overall coverage of the implemented system can be defined as all (direct and indirect) responses that can be composed from the 5 top-level operators and 10 satellite operators Blocks world picture used in Experiment 1.  6.1.1 Experiment.", "labels": [], "entities": []}, {"text": "The first experiment addressed whether the subjects' interpretations of indirect answers would agree with the system's interpretations.", "labels": [], "entities": []}, {"text": "The subjects were given 19 yes-no question-response exchanges.", "labels": [], "entities": []}, {"text": "Each response consisted of from 1 to 3 sentences without an explicit yes or no, e.g., as in  ii.", "labels": [], "entities": []}, {"text": "R: The yellow ball is on the floor.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9735172390937805}]}, {"text": "(For more examples, seethe appendix.)", "labels": [], "entities": []}, {"text": "Fourteen of the responses were indirect, i.e., our system would interpret them as generated from Answer-No or Answer-Yes.", "labels": [], "entities": [{"text": "Answer-No", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.8266118764877319}]}, {"text": "59 (For example,ii was interpreted as a no generated by Answer-No.) These 14 responses made use of all of the possible satellites of Answer-No and Answer-Yes in the model.", "labels": [], "entities": []}, {"text": "Several responses made use of multiple satellites.", "labels": [], "entities": []}, {"text": "For example, the response in item 19 of the questionnaire was similar to the response shown on the right-hand side of.", "labels": [], "entities": []}, {"text": "The other 5 responses we characterize as bogus, i.e., would not be interpreted as answers by our system, e.g., (38) (item 2 in the questionnaire).", "labels": [], "entities": []}, {"text": "Q: Can you pickup the ball?", "labels": [], "entities": [{"text": "Q", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8986549377441406}]}, {"text": "R: A red block is on the table.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8703395128250122}]}, {"text": "The purpose of the so-called bogus responses was to make certain that the subjects were not just interpreting every response as saying yes or no.", "labels": [], "entities": []}, {"text": "For each response, the subjects were asked to select one of the following interpretations: only 2 items were interpreted by subjects as Other (each by a different subject).", "labels": [], "entities": []}, {"text": "In 28% of the instances where the subjects interpreted a response as saying yes or no, they noted some degree of uncertainty.", "labels": [], "entities": []}, {"text": "During debriefing, the subjects who tended to express uncertainty said that while they might interpret the response as yes or no, one generally had some uncertainty when the direct answer was omitted.", "labels": [], "entities": []}, {"text": "Only one subject interpreted a bogus question as answering yes or no.", "labels": [], "entities": []}, {"text": "To test the statistical significance of the pattern of responses shown in, we took a very conservative approach.", "labels": [], "entities": []}, {"text": "We grouped Indirect Interpretation (?) with Other in for question-response instances where the system interpreted the response as an indirect answer, and we grouped Indirect Interpretation (?) with Indirect Interpretation for instances where the system did not interpret the response as an indirect answer.", "labels": [], "entities": []}, {"text": "Thus Indirect Interpretation (?) responses by the subjects were treated as disagreeing with the system's interpretation of the example.", "labels": [], "entities": []}, {"text": "We then applied Cochran's Q test to the resulting two columns of data.", "labels": [], "entities": [{"text": "Q test", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.876046895980835}]}, {"text": "The result shows that the pattern of responses is statistically significant (not the result of random chance) at better than the level p < .005.", "labels": [], "entities": []}, {"text": "To determine whether the subjects differentiated between responses that the system interpreted as indirect answers and those that it did not, we applied the Mann Whitney U statistic), which showed no score overlap at the level p < .005.", "labels": [], "entities": [{"text": "Mann Whitney U statistic", "start_pos": 157, "end_pos": 181, "type": "DATASET", "confidence": 0.63563521951437}]}, {"text": "Although the linguistic studies discussed in Section 5 show that in human-human dialogue people often include additional unrequested information in their responses to yes-no questions, we conducted a second experiment to determine how users would evaluate responses consisting of the kinds of extra unrequested information produced by our system.", "labels": [], "entities": []}, {"text": "The subjects were given 11 yes-no questions (some preceded by 1 or 2 sentences to establish some additional context), each with a set of 4 possible responses.", "labels": [], "entities": []}, {"text": "The subjects were told to suppose that all of the responses in a set were true, and were asked to select the best response in each set.", "labels": [], "entities": []}, {"text": "For each question, the response choices included: \u2022 a direct response of Yes or No (depending on the correct answer to the question), \u2022 the direct response with further emphasis (such as No, I can't), In 9 of the 11 sets, 1 of the extended responses was motivated by our stimulus conditions (e.g., (39)v), and 1 was not (e.g., (39)vi).", "labels": [], "entities": []}, {"text": "In the other 2 sets (questionnaire items 3 and 7), neither of the extended responses was motivated by any stimulus condition.", "labels": [], "entities": []}, {"text": "The purpose of these 2 so-called bogus examples was to make certain that the subjects were not inclined to always select responses with extra information.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The rows of the table present the results for each question.", "labels": [], "entities": []}, {"text": "The second column lists the stimulus condition, if any, that our system used to trigger one of the extended responses to the question.", "labels": [], "entities": []}, {"text": "Items 3 and 7 contained bogus responses, i.e., none of the responses was motivated by a stimulus condition.", "labels": [], "entities": []}, {"text": "The next three columns indicate respectively the number of subjects who selected the response motivated by the listed stimulus condition, the number who selected the direct answer alone or the direct answer with emphasis but no additional information, and the number who selected an extended response not motivated by a stimulus condition.", "labels": [], "entities": []}, {"text": "Note that none of the subjects selected a response with extra information for the two bogus questions, indicating that they were not merely inclined to select responses with extra information.", "labels": [], "entities": []}, {"text": "Items 8 and 10 warrant some discussion.", "labels": [], "entities": []}, {"text": "The original question given to the first four subjects asked whether the robot could tell the lab manager the time.", "labels": [], "entities": []}, {"text": "The response \"No. There is no clock in here.\" was motivated by the stimulus condition excuse-indicated.", "labels": [], "entities": []}, {"text": "However, two of the four subjects selected just No as the best response, and explained during debriefing that if the robot could tell time, then certainly he had an internal clock that he could use (since all computers have internal clocks) and thus the absence of a clock in the room was not relevant.", "labels": [], "entities": []}, {"text": "Since the prior beliefs of these subjects conflicted with the beliefs that were intended as the context for interpreting the robot's response, we altered the question for the remainder of the study to circumvent this problem.", "labels": [], "entities": []}, {"text": "In item 10, the extra information in the system's response was motivated by the appeasement-indicated stimulus condition.", "labels": [], "entities": []}, {"text": "In that Results of experiment on including extra information.", "labels": [], "entities": []}, {"text": "response, the robot answers No (that he has not yet done the requested task) and then attempts to appease the questioner by describing another task that he has completed.", "labels": [], "entities": []}, {"text": "1. Q: Can you make a stack of 3 blocks?", "labels": [], "entities": []}, {"text": "R: I can put the green block on the blue block.", "labels": [], "entities": []}, {"text": "2. Q: Can you pickup the ball?", "labels": [], "entities": []}, {"text": "R: A red block is on the table.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8703395128250122}]}], "tableCaptions": [{"text": " Table 5  Results of experiment on interpretation of indirect answers.", "labels": [], "entities": [{"text": "interpretation of indirect answers", "start_pos": 35, "end_pos": 69, "type": "TASK", "confidence": 0.8938817530870438}]}, {"text": " Table 6  Results of experiment on including extra information.", "labels": [], "entities": []}]}