{"title": [{"text": "Bitext Maps and Alignment via Pattern Recognition", "labels": [], "entities": [{"text": "Pattern Recognition", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.6699737161397934}]}], "abstractContent": [], "introductionContent": [{"text": "Existing translations contain more solutions to more translation problems than any other existing resource).", "labels": [], "entities": []}, {"text": "Although the above statement was made about translation problems faced by human translators, recent research ( suggests that it also applies to problems in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7943430244922638}]}, {"text": "Texts that are available in two languages (bitexts)) also play a pivotal role in various less automated applications.", "labels": [], "entities": []}, {"text": "For example, bilingual lexicographers can use bitexts to discover new cross-language lexicalization patterns; students of foreign languages can use one half of a bitext to practice their reading skills, referring to the other half for translation when they get stuck.", "labels": [], "entities": []}, {"text": "Bitexts are of little use, however, without an automatic method for matching corresponding text units in their two halves.", "labels": [], "entities": []}, {"text": "The bitext mapping problem can be formulated in terms of pattern recognition.", "labels": [], "entities": [{"text": "bitext mapping", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6046807765960693}, {"text": "pattern recognition", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7487294971942902}]}, {"text": "From this point of view, the success of a bitext mapping algorithm hinges on three tasks: signal generation, noise filtering, and search.", "labels": [], "entities": [{"text": "signal generation", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7227683812379837}, {"text": "noise filtering", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.6750940531492233}]}, {"text": "This article presents the Smooth Injective Map Recognizer (SIMR), a generic pattern recognition algorithm that is partic-t er minus ularly well suited to mapping bitext correspondence.", "labels": [], "entities": [{"text": "Smooth Injective Map Recognizer (SIMR", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.7306368698676428}, {"text": "pattern recognition", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7461340427398682}]}, {"text": "SIMR demonstrates that, given effective signal generators and noise filters, it is possible to map bitext correspondence with high accuracy in linear space and time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9876718521118164}]}, {"text": "If necessary, SIMR can be used with the Geometric Segment Alignment (GSA) algorithm, which uses segment boundary information to reduce general bitext maps to segment alignments.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.9276344776153564}, {"text": "Geometric Segment Alignment (GSA)", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.7364375243584315}]}, {"text": "Evaluations on preexisting gold standards have shown that SIMR's bitext maps and GSA's alignments are more accurate than those of comparable algorithms in the literature.", "labels": [], "entities": []}, {"text": "The article begins with a geometric interpretation of the bitext mapping problem and a discussion of previous work.", "labels": [], "entities": []}, {"text": "SIMR is detailed in Section 4 and evaluated in Section 6.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.6937831044197083}]}, {"text": "Section 7 discusses the formal relationship between bitext maps and segment alignments.", "labels": [], "entities": [{"text": "segment alignments", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8231388032436371}]}, {"text": "The GSA algorithm for converting from the former to the latter is presented in Section 7 and evaluated in Section 8.", "labels": [], "entities": [{"text": "GSA", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.4757649600505829}]}], "datasetContent": [{"text": "SIMR's parameters were optimized by simulated annealing, as described in the previous section\u2022 A separate optimization was performed on separate training bitexts for each of three language pairs.", "labels": [], "entities": []}, {"text": "SIMR was then evaluated on previously unseen test bitexts in the three language pairs\u2022 The objective function for optimization and the evaluation metric were the root mean squared distance, in characters, between each TPC and the interpolated bitext map produced by SIMR, where the distance was measured perpendicular to the main diagonal report SIMR's errors on the training and test bitexts, respectively\u2022 The TBM samples used for training and testing were derived from segment alignments.", "labels": [], "entities": []}, {"text": "All the bitexts had been manually aligned by bilingual annotators (Melamed  . The alignments were converted into sets of coordinates in the bitext space by pairing the character positions at the ends of aligned segment pairs.", "labels": [], "entities": []}, {"text": "This TBM sampling method artificially reduced the error estimates.", "labels": [], "entities": []}, {"text": "Most of the aligned segments were sentences, which ended with a period.", "labels": [], "entities": []}, {"text": "Whenever SIMR matched the periods correctly, the interpolated bitext map was pulled close to the TPC, even though it may have been much farther off in the middle of the sentence.", "labels": [], "entities": []}, {"text": "Thus, the results in should be considered only relative to each other and to other results obtained under the same experimental conditions.", "labels": [], "entities": []}, {"text": "It would be impressive indeed if any bitext mapping algorithm's actual RMS error were less than 1 character on bitexts involving languages with different word order, such as English/Korean.", "labels": [], "entities": []}, {"text": "The matching predicates for French/English and Spanish/English relied on an LCSR threshold to find cognates.", "labels": [], "entities": [{"text": "LCSR", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9015405774116516}]}, {"text": "The Korean text contained some Roman character strings, so the matching predicate for Korean/English generated candidate points of correspondence whenever one of these strings coordinated in the search rectangle with an identical string in the English half of the bitext.", "labels": [], "entities": []}, {"text": "A seed translation lexicon was also used to strengthen the Korean/English signal.", "labels": [], "entities": []}, {"text": "In addition, English, French, Spanish and Korean stop lists were used to prevent matches of closed-class words.", "labels": [], "entities": []}, {"text": "The translation lexicon and stop lists had been previously developed independently of the training and test bitexts.", "labels": [], "entities": []}, {"text": "The French/English part of the evaluation was performed on bitexts from the publicly available corpus de bi-texte anglais-franfais (BAF)).", "labels": [], "entities": []}, {"text": "SIMR's error distribution on the \"parliamentary debates\" bitext in this collection is given in.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6879472136497498}]}, {"text": "This distribution can be compared to the error distributions reported for the same test set by, who reported parts of their error distribution in words, rather than in characters: \"In 55% of the cases, there is no error in word_align's output (distance of 0), in 73% the distance from the correct alignment is at most 1, and in 84% the distance is at most 3\" (Dagan, Church, and.", "labels": [], "entities": []}, {"text": "These distances were measured horizontally from the bitext map rather than perpendicularly to the main diagonal.", "labels": [], "entities": []}, {"text": "Given the bitext slope for that bitext and a conservative estimate of 6 characters per word (including the space between words), each horizontal word of error corresponds to just over 4 characters of error perpendicular to the main diagonal.", "labels": [], "entities": []}, {"text": "Thus, Dagan, Church, and Gale's \"no error\" is the same as  Comparison of error distributions for SIMR and word_align on the parliamentary debates bitext.", "labels": [], "entities": [{"text": "parliamentary debates bitext", "start_pos": 124, "end_pos": 152, "type": "DATASET", "confidence": 0.7673343122005463}]}, {"text": "Error of at Most Error of at Most Error of at Most Algorithm 2 Characters 6 Characters 14 Characters word_align 55% 73% 84% SIMR 93% 97% 98% 2 characters of error or less, i.e., less than half a word.", "labels": [], "entities": []}, {"text": "One word of error is the same as an error of up to 6 characters and 3 words are equivalent to 4.3\u00bd = 14 characters.", "labels": [], "entities": []}, {"text": "On this basis, compares the accuracy of SIMR and word_align.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9996565580368042}]}, {"text": "5 Another interesting comparison is in terms of maximum error.", "labels": [], "entities": [{"text": "maximum error", "start_pos": 48, "end_pos": 61, "type": "METRIC", "confidence": 0.6861804723739624}]}, {"text": "Certain applications of bitext maps, such as the one described by, can tolerate many small errors but no large ones.", "labels": [], "entities": []}, {"text": "As shown in, SIMR's bitext map was never off by more than 185 characters from any of the 7,123 segment boundaries.", "labels": [], "entities": [{"text": "SIMR's bitext map", "start_pos": 13, "end_pos": 30, "type": "DATASET", "confidence": 0.6629633009433746}]}, {"text": "185 characters is about 1.5 times the length of an average sentence (Melamed 1996a).", "labels": [], "entities": []}, {"text": "The input to word_align is the output of char_align and Dagan, Church, and  have reported that word_align cannot escape from char_align's worst errors.", "labels": [], "entities": []}, {"text": "An independent implementation of char_align (Michel Simard, personal communication) erred by more than one thousand characters on the same bitext.", "labels": [], "entities": []}, {"text": "5 Error measurements at the character level are less susceptible to random variation than measurements at the word level.", "labels": [], "entities": [{"text": "Error", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9764097929000854}]}, {"text": "Character-level measurements also have the advantage of being universally applicable to all languages, including those in which words are difficult to identify automatically.", "labels": [], "entities": []}, {"text": "The Spanish/English and Korean/English bitexts were hand-aligned when SIMR was being ported to these language pairs.", "labels": [], "entities": []}, {"text": "6 The Spanish/English bitexts were drawn from the Sun Solaris AnswerBooks and hand-aligned by Philip Resnik.", "labels": [], "entities": [{"text": "Spanish/English bitexts", "start_pos": 6, "end_pos": 29, "type": "DATASET", "confidence": 0.612155593931675}, {"text": "Sun Solaris AnswerBooks", "start_pos": 50, "end_pos": 73, "type": "DATASET", "confidence": 0.9265943964322408}]}, {"text": "The Korean/ English bitexts were provided by MIT's Lincoln Laboratories and hand-aligned by Young-Suk Lee.", "labels": [], "entities": []}, {"text": "shows that SIMR's performance on Spanish/English and Korean/English bitexts is no worse than its performance on French/English bitexts.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.5373013615608215}]}, {"text": "The results in were obtained using aversion of SIMR that included all the enhancements described in Section 4.6.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.4300778806209564}]}, {"text": "It is interesting to consider the degree to which each enhancement improves performance.", "labels": [], "entities": []}, {"text": "I remapped the French/English bitexts listed in with two stripped-down versions of SIMR.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.816138744354248}]}, {"text": "One version was basic SIMR without any enhancements.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 22, "end_pos": 26, "type": "TASK", "confidence": 0.8768620491027832}]}, {"text": "The other version incorporated overlapping chains, but performed only one search pass.", "labels": [], "entities": []}, {"text": "The deterioration in performance varied widely.", "labels": [], "entities": []}, {"text": "For example, on the parliamentary debates bitext, the RMS error rose from 5.7 to 16 when only one search pass was allowed, but rose only another 2 points to 18 using non-overlapping chains.", "labels": [], "entities": [{"text": "parliamentary debates bitext", "start_pos": 20, "end_pos": 48, "type": "DATASET", "confidence": 0.734972765048345}, {"text": "RMS error", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.6716695874929428}]}, {"text": "In contrast, on the U.N. annual report bitext, the extra search passes made no difference at all but non-overlapping chains increased the RMS error from 12 to 40.", "labels": [], "entities": [{"text": "U.N. annual report bitext", "start_pos": 20, "end_pos": 45, "type": "DATASET", "confidence": 0.9228829443454742}, {"text": "RMS error", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.8856075704097748}]}, {"text": "For most of the Other bitexts, each enhancement reduced the RMS error by a few characters, compared to the basic version.", "labels": [], "entities": [{"text": "RMS error", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.6903774440288544}]}, {"text": "However, the improvement was not universal: the RMS error of the basic SIMR was 19 for the \"other technical report\" on which the enhanced SIMR scored 21.", "labels": [], "entities": [{"text": "RMS error", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.89902263879776}]}, {"text": "The expected value of the enhancements is difficult to predict, because each enhancement is aimed at solving a particular pattern recognition problem, and each problem mayor may not occur in a given bitext.", "labels": [], "entities": [{"text": "pattern recognition problem", "start_pos": 122, "end_pos": 149, "type": "TASK", "confidence": 0.7869855165481567}]}, {"text": "The relationship between geometric patterns in TPC chains and syntactic properties of bitexts is a ripe research topic.", "labels": [], "entities": []}, {"text": "GSA processed two bitext maps produced by SIMR using two different matching predicates.", "labels": [], "entities": [{"text": "GSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7910240888595581}]}, {"text": "The first matching predicate relied only on cognates that pass a certain LCSR threshold, as described in Section 4.2.", "labels": [], "entities": []}, {"text": "The second matching predicate was like the first, except that it also generated a point of correspondence whenever the input token pair appeared as an entry in a translation lexicon.", "labels": [], "entities": []}, {"text": "The translation lexicon was automatically extracted from an MRBD (.", "labels": [], "entities": [{"text": "MRBD", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.900009036064148}]}, {"text": "Bitexts involving millions of segments are becoming more and more common.", "labels": [], "entities": []}, {"text": "Before comparing bitext alignment algorithms in terms of accuracy, it is important to compare their asymptotic running times.", "labels": [], "entities": [{"text": "bitext alignment", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.5610023140907288}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9993257522583008}]}, {"text": "In order to run a quadratic-time alignment algorithm in a reasonable amount of time on a large bitext, the bitext must be presegmented into a set of smaller bitexts.", "labels": [], "entities": []}, {"text": "When a bitext contains no easily recognizable \"anchors,\" such as paragraphs or sections, this first-pass alignment must be done manually.", "labels": [], "entities": []}, {"text": "Given a reasonably good bitext map, GSA's expected running time is linear in the number of input segment boundaries.", "labels": [], "entities": [{"text": "GSA", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7978984713554382}]}, {"text": "In all the bitexts on which GSA was trained and tested, the points of correspondence in SIMR's output were sufficiently dense and accurate that GSA backed off to a quadratic-time alignment algorithm only for very small aligned blocks.", "labels": [], "entities": []}, {"text": "For example, when the seed translation lexicon was used in SIMR's matching predicate, the largest aligned block that needed to be realigned was 5x5 segments.", "labels": [], "entities": []}, {"text": "Without the seed translation lexicon, the largest realigned block was 7x7 segments.", "labels": [], "entities": []}, {"text": "Thus, GSA can obviate the need to manually prealign large bitexts.", "labels": [], "entities": [{"text": "GSA", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.5366623401641846}]}, {"text": "compares GSA's accuracy on the \"easy\" and \"hard\" French/English bitexts with the accuracy of two other alignment algorithms, as reported by.", "labels": [], "entities": [{"text": "GSA", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.6234796047210693}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.989974319934845}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.99578458070755}]}, {"text": "The error metric counts one error for each aligned block in the reference alignment that is missing from the test alignment.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9595816135406494}]}, {"text": "To account for the possibility of modularizing the overall alignment task into paragraph alignment followed by sentence alignment, have reported the accuracy of their sentence alignment algorithm when a perfect alignment at the paragraph level is given.", "labels": [], "entities": [{"text": "modularizing the overall alignment task", "start_pos": 34, "end_pos": 73, "type": "TASK", "confidence": 0.6901357233524322}, {"text": "paragraph alignment", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7319281995296478}, {"text": "sentence alignment", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.723202645778656}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9995319843292236}, {"text": "sentence alignment", "start_pos": 167, "end_pos": 185, "type": "TASK", "confidence": 0.7409732937812805}]}, {"text": "SIMR/GSA was also tested in this manner, to enable the second set of comparisons in.", "labels": [], "entities": []}, {"text": "Due to the scarcity of hand-aligned training bitexts at my disposal, GSA's backingoff heuristics are somewhat ad hoc.", "labels": [], "entities": []}, {"text": "Even so, GSA performs at least as well as, and usually better than, other alignment algorithms for which comparable results have been published. has also published a quantitative evaluation of his alignment algorithm on these reference bitexts, but his evaluation was done post hoc.", "labels": [], "entities": [{"text": "GSA", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.40058133006095886}]}, {"text": "Since the results in this article are based on a gold standard, they are not comparable to Chen's results.", "labels": [], "entities": []}, {"text": "Among other reasons, error rates based on a gold standard are sometimes inflated by errors in the gold standard and this was indeed the case for the gold standard used here (see).", "labels": [], "entities": [{"text": "error rates", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9542595148086548}, {"text": "gold standard", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.8809611201286316}]}, {"text": "It is also an open question whether GSA performs better than the algorithm proposed by.", "labels": [], "entities": [{"text": "GSA", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7222970724105835}]}, {"text": "The two algorithms have not yet been evaluated on the same test data.", "labels": [], "entities": []}, {"text": "For now, I can offer only a theoretical reason why SIMR+GSA should be more accurate than the algorithms of Chen and Wu: Bitext maps lead to alignment more directly than a translation model or a translation lexicon, because both segment alignments and bitext maps are relations between token instances, rather than between token types.", "labels": [], "entities": []}, {"text": "More important than GSA's current accuracy is GSA's potential accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9991914629936218}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9982219338417053}]}, {"text": "With a bigger development bitext, more effective backing-off heuristics can be developed.", "labels": [], "entities": []}, {"text": "Better input can also make a difference: GSA's accuracy will improve in lockstep with SIMR's accuracy.", "labels": [], "entities": [{"text": "GSA", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.7744460701942444}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9535822868347168}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9928290247917175}]}], "tableCaptions": [{"text": " Table 4  SIMR's error distribution on the French/English \"parliamentary debates\" bitext. Errors were  measured perpendicular to the main diagonal.", "labels": [], "entities": [{"text": "SIMR", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.6742824912071228}, {"text": "error distribution", "start_pos": 17, "end_pos": 35, "type": "METRIC", "confidence": 0.9520096182823181}, {"text": "French/English \"parliamentary debates\" bitext", "start_pos": 43, "end_pos": 88, "type": "DATASET", "confidence": 0.8852840214967728}, {"text": "Errors", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9964847564697266}]}, {"text": " Table 6  Comparison of bitext alignment algorithms' accuracy. One error is counted for each aligned  block in the reference alignment that is missing from the test alignment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9965343475341797}]}]}