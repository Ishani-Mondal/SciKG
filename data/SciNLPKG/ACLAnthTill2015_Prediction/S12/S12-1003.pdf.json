{"title": [{"text": "Measuring Semantic Relatedness using Multilingual Representations", "labels": [], "entities": [{"text": "Semantic Relatedness", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8021173775196075}]}], "abstractContent": [{"text": "This paper explores the hypothesis that semantic relatedness maybe more reliably inferred by using a multilingual space, as compared to the typical monolingual representation.", "labels": [], "entities": []}, {"text": "Through evaluations using several state-of-the-art semantic relatedness systems, applied on standard datasets, we show that a multilingual approach is better suited for this task, and leads to improvements of up to 47% with respect to the monolingual baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic relatedness is the task of quantifying the strength of the semantic connection between textual units, be they words, sentences, or documents.", "labels": [], "entities": [{"text": "Semantic relatedness", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8262830674648285}]}, {"text": "For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet.", "labels": [], "entities": []}, {"text": "It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval, query reformulation (, image retrieval (), plagiarism detection (, information flow (), sponsored search (), short answer grading), and textual entailment ().", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6413894593715668}, {"text": "information retrieval", "start_pos": 147, "end_pos": 168, "type": "TASK", "confidence": 0.7875427901744843}, {"text": "query reformulation", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.710428774356842}, {"text": "image retrieval", "start_pos": 193, "end_pos": 208, "type": "TASK", "confidence": 0.6963411271572113}, {"text": "plagiarism detection", "start_pos": 213, "end_pos": 233, "type": "TASK", "confidence": 0.7286270558834076}, {"text": "textual entailment", "start_pos": 306, "end_pos": 324, "type": "TASK", "confidence": 0.6874151825904846}]}, {"text": "The typical approach to semantic relatedness is to either measure the distance between the constituent words by using a knowledge base such as WordNet or Roget (e.g.,), or to calculate the similarity between the word distributions in very large corpora (e.g.,).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 143, "end_pos": 150, "type": "DATASET", "confidence": 0.9697794914245605}]}, {"text": "With almost no exception, these methods have been applied on one language at a time -English, most of the time, although measures of relatedness have also been explored on languages such as German (), Chinese (), Japanese (, and others.", "labels": [], "entities": []}, {"text": "In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates semantic relatedness scores measured on several different languages.", "labels": [], "entities": []}, {"text": "Specifically, in our method, in order to measure the relatedness of two textual units, we first determine their relatedness in multiple languages, and consequently infer a final relatedness score by averaging the scores calculated in the individual languages.", "labels": [], "entities": []}, {"text": "Our hypothesis is that a multilingual representation can enrich the relatedness space and address relevant issues such as polysemy (i.e., find that two occurrences of the same word in language L1 represent two different meanings because of different translations in language L2) and synonymy (i.e., find that two words in language L1 are related because they have the same translation in language L2).", "labels": [], "entities": []}, {"text": "We show that by measuring relatedness in a multilingual space, we are able to improve over a traditional relatedness measure that relies exclusively on a monolingual representation.", "labels": [], "entities": []}, {"text": "Through experiments using several state-of-theart measures of relatedness, applied on a multilingual space including English, Arabic, Spanish, and Romanian, we aim to answer the following research questions: (1) Does the task of semantic relatedness benefit from a multilingual representation, as compared to a monolingual one?", "labels": [], "entities": []}, {"text": "(2) Does the translation quality affect the results? and (3) Do the findings hold for different relatedness datasets?", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we overview related work on word and text relatedness, and on multilingual natural language processing.", "labels": [], "entities": [{"text": "word and text relatedness", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.5844066143035889}, {"text": "multilingual natural language processing", "start_pos": 69, "end_pos": 109, "type": "TASK", "confidence": 0.6556413024663925}]}, {"text": "We then briefly describe three corpus-based measures of relatedness, and present several word and text datasets that have been used in the past to evaluate relatedness.", "labels": [], "entities": []}, {"text": "We then present evaluations and experiments addressing each of the three research questions, and discuss our findings.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the representation strength of a multilingual semantic relatedness model we employ several standard word-to-word and text-to-text datasets.", "labels": [], "entities": []}, {"text": "For each of these datasets, we make use of their representation in the four languages of interest.", "labels": [], "entities": []}, {"text": "In this section we revisit the questions formulated in the introduction, and based on different experiment setups following the framework introduced in Section 5, we provide an answer to each one of them.", "labels": [], "entities": []}, {"text": "Does the task of semantic relatedness benefit from a multilingual representation?", "labels": [], "entities": []}, {"text": "We evaluate the three semantic relatedness models, namely LSA, ESA and SSA on our manually constructed multilingual word relatedness (M C30, W S353) and text relatedness datasets (LI30), as described in Section 4.", "labels": [], "entities": [{"text": "ESA", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.8618804812431335}, {"text": "M C30, W S353) and text relatedness datasets (LI30)", "start_pos": 134, "end_pos": 185, "type": "DATASET", "confidence": 0.8198972573647132}]}, {"text": "plots the correlation scores achieved across all the languages against the gold standard and then averaged across all the multilingual datasets.", "labels": [], "entities": [{"text": "correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9715889692306519}]}, {"text": "The figure shows a clear and steady improvement (25% -28% with respect to the monolingual baseline) achieved when more languages are incorporated into the relatedness model.", "labels": [], "entities": []}, {"text": "It is worth noting that both the Pearson and Spearman correlations exhibit the same improvement pattern, which confirms our hypothesis that adding more languages has a positive impact on the relatedness scores.", "labels": [], "entities": []}, {"text": "The fact that this trend is visible across all the systems supports the idea that a multilingual representation constitutes a better model for determining semantic relatedness.", "labels": [], "entities": []}, {"text": "Furthermore, we notice that SSA is the best performing system under these settings, with a correlation improvement of approximately 15%.", "labels": [], "entities": [{"text": "SSA", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9670568704605103}, {"text": "correlation", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.9969661831855774}]}, {"text": "To further analyze the role of the multilingual model and to explore whether some languages benefit from using this abstraction more than others, we plot the correlation scores achieved by the individual languages averaged overall the systems and the datasets in.", "labels": [], "entities": []}, {"text": "We notice a sharp rise in performance associated with the addition of more languages to the Arabic (42%) and the Romanian (47%) models, and a slower rise for Spanish (23%).", "labels": [], "entities": []}, {"text": "The performance of English is also affected, but on a smaller scale (4%) when compared to the other The results support the notion that resource poor languages can benefit from languages with richer and larger resources, such as English or Spanish.", "labels": [], "entities": []}, {"text": "Furthermore, incorporating additional languages to English also leads to small improvements, which indicates that the benefit, while disproportionate, is mutual.", "labels": [], "entities": []}, {"text": "At last, encouraged by the small performance difference between the use of manual versus automatic translations, we seek to explore how this multilingual model behaves under the different paradigms dictated byword relatedness versus text relatedness scenarios.", "labels": [], "entities": []}, {"text": "Since our previous experiments were constrained to collections for which we also had a manual translation, we perform a larger scale evaluation by including automatically translated word relatedness (RG65) and text relatedness (LEE50 and AG400) datasets into all the languages in our language set, and repeat all the word-to-word and text-to-text evaluations.", "labels": [], "entities": [{"text": "AG400) datasets", "start_pos": 238, "end_pos": 253, "type": "DATASET", "confidence": 0.7374650438626608}]}, {"text": "shows the correlation scores achieved using automatic translations on the word relatedness datasets.", "labels": [], "entities": [{"text": "correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9774938821792603}]}, {"text": "Most models on most datasets benefit from the multilingual representation (as shown by the.", "labels": [], "entities": []}, {"text": "Specifically, the SSA model has an improvement in \u00b5 of 26% for WS353 and 15% for M C30.", "labels": [], "entities": [{"text": "\u00b5", "start_pos": 50, "end_pos": 51, "type": "METRIC", "confidence": 0.9974602460861206}, {"text": "WS353", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.9050658941268921}]}, {"text": "This improvement is most evident in the case of the largest dataset W S353, where all the multilingual models exhibit a consistent and strong performance.: Automatic translation -r, \u03c1, \u00b5 correlations on the word relatedness datasets using multilingual models.", "labels": [], "entities": [{"text": "largest dataset W S353", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.7668277323246002}]}, {"text": "gual model reports some of the best scores in the literature, such as a correlations of r = 0.856 and \u03c1 = 0.87 for LI30 achieved by LSA and SSA, respectively.", "labels": [], "entities": [{"text": "LSA", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.8572311997413635}]}, {"text": "Not surprisingly, SSA is still atop contender, achieving the highest scores for AG400 and LI30.", "labels": [], "entities": [{"text": "SSA", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.759218692779541}, {"text": "AG400", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.5504174828529358}]}, {"text": "In AG400, SSA reports a \u00b5 of 0.53 which represents a 4% improvement over the English SSA model (\u00b5 = 0.51) and a 16% improvement over the best knowledge-based system J&C (\u00b5 = 0.457).", "labels": [], "entities": [{"text": "AG400", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9294148087501526}, {"text": "SSA", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8670998215675354}, {"text": "\u00b5", "start_pos": 24, "end_pos": 25, "type": "METRIC", "confidence": 0.9894891381263733}]}, {"text": "It is important to note that the evaluation in Tables 1 and 2 are restricted to data translated from English into a target language.", "labels": [], "entities": []}, {"text": "English, as a resourcerich language, has an extensive and robust monolingual model, yet it can still be enhanced with additional clues originating from other languages.", "labels": [], "entities": []}, {"text": "Accordingly, we only expected small improvements in these two experiments, unlike the cases where we start from resource-poor languages such as Romanian or Arabic (see).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatic translation -r, \u03c1, \u00b5 correlations on the word relatedness datasets using multilingual models.", "labels": [], "entities": []}, {"text": " Table 2: Automatic translation -r, \u03c1, \u00b5 correlations on the text relatedness datasets using multilingual models.", "labels": [], "entities": []}]}