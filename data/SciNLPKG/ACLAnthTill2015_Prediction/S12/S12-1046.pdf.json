{"title": [{"text": "SemEval-2012 Task 1: English Lexical Simplification", "labels": [], "entities": [{"text": "SemEval-2012 Task", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8674298822879791}, {"text": "English Lexical Simplification", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.6524002353350321}]}], "abstractContent": [{"text": "We describe the English Lexical Simplification task at SemEval-2012.", "labels": [], "entities": [{"text": "English Lexical Simplification task", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.7372329607605934}]}, {"text": "This is the first time such a shared task has been organized and its goal is to provide a framework for the evaluation of systems for lexical simplification and foster research on context-aware lexical simplification approaches.", "labels": [], "entities": []}, {"text": "The task requires that annotators and systems rank a number of alternative substitutes-all deemed adequate-for a target word in context, according to how \"simple\" these substitutes are.", "labels": [], "entities": []}, {"text": "The notion of simplicity is biased towards non-native speakers of English.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9836277961730957}]}, {"text": "Out of nine participating systems , the best scoring ones combine context-dependent and context-independent information , with the strongest individual contribution given by the frequency of the substitute regardless of its context.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical Simplification is a subtask of Text Simplification) concerned with replacing words or short phrases by simpler variants in a context aware fashion (generally synonyms), which can be understood by a wider range of readers.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8483741581439972}, {"text": "Text Simplification", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.6791491955518723}]}, {"text": "It generally envisages a certain human target audience that may find it difficult or impossible to understand complex words or phrases, e.g., children, people with poor literacy levels or cognitive disabilities, or second language learners.", "labels": [], "entities": []}, {"text": "It is similar in many respects to the task of Lexical Substitution in that it involves determining adequate substitutes in context, but in this case on the basis of a predefined criterion: simplicity.", "labels": [], "entities": [{"text": "Lexical Substitution", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.858252614736557}, {"text": "simplicity", "start_pos": 189, "end_pos": 199, "type": "METRIC", "confidence": 0.9799618721008301}]}, {"text": "A common pipeline fora Lexical Simplification system includes at least three major components: (i) complexity analysis: selection of words or phrases in a text that are considered complex for the reader and/or task at hand; (ii) substitute lookup: search for adequate replacement words or phrases deemed complex in context, e.g., taking synonyms (with the same sense) from a thesaurus or finding similar words/phrases in a corpus using distributional similarity metrics; and (iii) context-based ranking: ranking of substitutes according to how simple they are to the reader/task at hand.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.6729791909456253}]}, {"text": "As an example take the sentence: \"Hitler committed terrible atrocities during the second World War.\"", "labels": [], "entities": []}, {"text": "The system would first identify complex words, e.g. atrocities, then search for substitutes that might adequately replace it.", "labels": [], "entities": []}, {"text": "A thesaurus lookup would yield the following synonyms: abomination, cruelty, enormity and violation, but enormity should be dropped as it does not fit the context appropriately.", "labels": [], "entities": []}, {"text": "Finally, the system would determine the simplest of these substitutes, e.g., cruelty, and use it to replace the complex word, yielding the sentence: \"Hitler committed terrible cruelties during the second World War.\".", "labels": [], "entities": []}, {"text": "Different from other subtasks of Text Simplification like Syntactic Simplification, which have been relatively well studied, Lexical Simplification has received less attention.", "labels": [], "entities": [{"text": "Text Simplification", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7475633025169373}, {"text": "Syntactic Simplification", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.8379344344139099}, {"text": "Lexical Simplification", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.8682103753089905}]}, {"text": "Although a few recent attempts explicitly address dependency on context (de, most approaches are contextindependent (.", "labels": [], "entities": []}, {"text": "In addition, a general deeper understanding of the problem is yet to be gained.", "labels": [], "entities": []}, {"text": "As a first attempt to address this problem in the shape of a shared task, the English Simplification task at SemEval-2012 focuses on the third component, which we believe is the core of the Lexical Simplification problem.", "labels": [], "entities": [{"text": "English Simplification task", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.7398311396439871}, {"text": "Lexical Simplification problem", "start_pos": 190, "end_pos": 220, "type": "TASK", "confidence": 0.9064148863156637}]}, {"text": "The SemEval-2012 shared task on English Lexical Simplification has been conceived with the following main purposes: advancing the state-of-theart Lexical Simplification approaches, and providing a common framework for evaluation of Lexical Simplification systems for participants and other researchers interested in the field.", "labels": [], "entities": [{"text": "SemEval-2012 shared task on English Lexical Simplification", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.5647897635187421}]}, {"text": "Another central motive of such a shared task is to bring awareness to the general vagueness associated with the notion of lexical simplicity.", "labels": [], "entities": []}, {"text": "Our hypothesis is that in addition to the notion of a target application/reader, the notion of simplicity is highly context-dependent.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9881001710891724}]}, {"text": "In other words, given the same list of substitutes fora given target word with the same sense, we expect different orderings of these substitutes in different contexts.", "labels": [], "entities": []}, {"text": "We hope that participation in this shared task will help discover some underlying traits of lexical simplicity and furthermore shed some light on how this maybe leveraged in future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "No standard metric has yet been defined for evaluating Lexical Simplification systems.", "labels": [], "entities": [{"text": "Lexical Simplification", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.8886396586894989}]}, {"text": "Evaluating such systems is a challenging problem due to the aforementioned subjectivity of the task.", "labels": [], "entities": []}, {"text": "Since this is a ranking task, rank correlation metrics are desirable.", "labels": [], "entities": []}, {"text": "However, metrics such as Spearman's Rank Correlation are not reliable on the limited number of data points available for comparison on each ranking (note that the nature of the problem enforces a context-by-context ranking, as opposed to a global score), Other metrics for localized, pairwise rank correlation, such as Kendall's Tau, disregard ties, -which are important for our purposes -and are thus not suitable.", "labels": [], "entities": []}, {"text": "The main evaluation metric proposed for this shared task is in fact a measure of inter-annotator agreement, which is used for both contrasting two human annotators (Section 3.2) and contrasting a system output to the average of human annotations that together forms the gold-standard.", "labels": [], "entities": []}, {"text": "Out metric is based on the kappa index which in spite of many criticisms is widely used for its simplicity and adaptability for different applications.", "labels": [], "entities": [{"text": "Out", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7484824061393738}]}, {"text": "The generalized form of the kappa index is where P (A) denotes the proportion of times two annotators agree and P (E) gives the probability of agreement by chance between them.", "labels": [], "entities": []}, {"text": "In order to apply the kappa index fora ranking task, we follow the method proposed by) for measuring agreement over judgments of translation quality.", "labels": [], "entities": []}, {"text": "This method defines P (A) and P (E) in such away that it now counts agreement whenever annotators concur upon the order of pairwise ranks.", "labels": [], "entities": []}, {"text": "Thus, if one annotator ranked two given words 1 and 3, and the second annotator ranked them 3 and 7 respectively, they are still in agreement.", "labels": [], "entities": []}, {"text": "Formally, assume that two annotators A1 and A2 rank two instance a and b.", "labels": [], "entities": []}, {"text": "Then P (A) = the proportion of times A1 and A2 agree on a ranking, where an occurrence of agreement is counted whenever rank(a < b) or rank(a = b) or rank(a > b).", "labels": [], "entities": [{"text": "P (A)", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.9520052820444107}]}, {"text": "P (E) (the likelihood that annotators A1 and A2 agree by chance) is based upon the probability that both of them assign the same ranking order to a and b.", "labels": [], "entities": [{"text": "P (E)", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.951710894703865}]}, {"text": "Given that the probability of getting rank(a < b) by any annotator is P (a < b), the probability that both annotators get rank(a < b) is P (a < b) 2 (agreement is achieved when A1 assigns a < b by chance and A2 also assigns a < b).", "labels": [], "entities": [{"text": "agreement", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.9708153605461121}]}, {"text": "Similarly, the probability of chance agreement for rank(a = b) and rank(a > b) are P (a = b) 2 and P (a > b) 2 respectively.", "labels": [], "entities": []}, {"text": "Thus: However, the counts of rank(a < b) and rank(a > b) are inextricably linked, since for any particular case of a 1 < b 1 , it follows that b 1 > a 1 , and thus the two counts must be incremented equally.", "labels": [], "entities": []}, {"text": "Therefore, over the entire space of ranked pairs, the probabilities remain exactly the same.", "labels": [], "entities": []}, {"text": "In essence, after counting for P (a = b), the remaining probability mass is equally split between P (a < b) and P (a > b).", "labels": [], "entities": []}, {"text": "Therefore: Kappa is calculated for every pair of ranked items fora given context, and then averaged to get an overall kappa score: where N is the total number of contexts, and P n (A) and P n (E) are calculated based on counts extracted from the data on the particular context n.", "labels": [], "entities": []}, {"text": "The functioning of this evaluation metric is illustrated by the following example: Context: During the siege, George Robertson had appointed Shuja-ul-Mulk, who was a _____ boy only 12 years old and the youngest surviving son of Aman-ul-Mulk, as the ruler of Chitral.", "labels": [], "entities": []}, {"text": "Gold: {intelligent} {clever} {smart} {bright} System: {intelligent} {bright} {clever, smart} Out of the 6 distinct unordered pairs of lexical items, system and gold agreed 3 times.", "labels": [], "entities": []}, {"text": "Consequently, P n (A) = 3 6 . In addition, count(a = b) = 1.", "labels": [], "entities": [{"text": "count(a = b)", "start_pos": 43, "end_pos": 55, "type": "METRIC", "confidence": 0.8290613889694214}]}, {"text": "Thus, P n (a = b) = 1 12 . Which gives a P (E) = 41 96 and the final kappa score for this particular context of 0.13.", "labels": [], "entities": [{"text": "P (E)", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.8619657456874847}]}, {"text": "The statistical significance of the results from two systems A and B is measured using the method of Approximate Randomization, which has been shown to be a robust approach for several NLP tasks.", "labels": [], "entities": [{"text": "Approximate", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.9893419742584229}]}, {"text": "The randomization is run 1, 000 times and if the p-value is \u2264 0.05 the difference between systems A and B is asserted as being statistically significance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Analysis on the context-dependency of the no- tion of simplicity.", "labels": [], "entities": []}, {"text": " Table 2: Baseline kappa scores on trial and test sets", "labels": [], "entities": []}, {"text": " Table 3: Official results and ranking according to the pair- wise kappa metric. Systems are ranked together when the  difference in their kappa score is not statistically signifi- cant.", "labels": [], "entities": []}, {"text": " Table 4: Additional results according to the top-rank  (TRnk) and recall-at-n metrics.", "labels": [], "entities": [{"text": "TRnk", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.7496222257614136}, {"text": "recall-at-n", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.9938795566558838}]}]}