{"title": [{"text": "UiO 1 : Constituent-Based Discriminative Ranking for Negation Resolution", "labels": [], "entities": [{"text": "Negation Resolution", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9249011874198914}]}], "abstractContent": [{"text": "This paper describes the first of two systems submitted from the University of Oslo (UiO) to the 2012 *SEM Shared Task on resolving negation.", "labels": [], "entities": [{"text": "SEM Shared Task on resolving negation", "start_pos": 103, "end_pos": 140, "type": "TASK", "confidence": 0.6924539705117544}]}, {"text": "Our submission is an adaption of the negation system of Velldal et al.", "labels": [], "entities": []}, {"text": "(2012), which combines SVM cue classification with SVM-based ranking of syntactic constituents for scope resolution.", "labels": [], "entities": [{"text": "SVM cue classification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8456825613975525}, {"text": "scope resolution", "start_pos": 99, "end_pos": 115, "type": "TASK", "confidence": 0.850718230009079}]}, {"text": "The approach further extends our prior work in that we also identify factual negated events.", "labels": [], "entities": []}, {"text": "While submitted for the closed track, the system was the top performer in the shared task overall.", "labels": [], "entities": []}], "introductionContent": [{"text": "The First Joint Conference on Lexical and Computational Semantics (*SEM 2012) hosts a shared task on resolving negation.", "labels": [], "entities": [{"text": "Lexical and Computational Semantics (*SEM 2012)", "start_pos": 30, "end_pos": 77, "type": "TASK", "confidence": 0.724636185914278}, {"text": "resolving negation", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7405969798564911}]}, {"text": "This involves the subtasks of (i) identifying negation cues, (ii) identifying the in-sentence scope of these cues, and (iii) identifying negated (and factual) events.", "labels": [], "entities": []}, {"text": "This paper describes a system submitted by the Language Technology Group at the University of Oslo (UiO).", "labels": [], "entities": []}, {"text": "Our starting point is the negation system developed by for the domain of biomedical texts, an SVM-based system for classifying cues and ranking syntactic constituents to resolve cue scopes.", "labels": [], "entities": []}, {"text": "However, we extend and adapt this system in several important respects, such as in terms of the underlying linguistic formalisms that are used, the textual domain, handling of morphological cues and discontinuous scopes, and in that the current system also identifies negated events.", "labels": [], "entities": []}, {"text": "The data sets used for the shared task include the following, all based on negation-annotated Conan Doyle (CD) stories: a training set of 3644 sentences (hereafter referred to as CDT), a development set of 787 sentences (CDD), and a held-out evaluation set of 1089 sentences (CDE).", "labels": [], "entities": []}, {"text": "We will refer to the combination of CDT and CDD as CDTD.", "labels": [], "entities": []}, {"text": "An example of an annotated sentence is shown in (1) below, where the cue is marked in bold, the scope is underlined, and the event marked in italics.", "labels": [], "entities": []}, {"text": "(1) There was no answer.", "labels": [], "entities": [{"text": "There", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9746923446655273}]}, {"text": "We describe two different system configurations, both of which were submitted for the closed track (hence we can only make use of the data provided by the task organizers).", "labels": [], "entities": []}, {"text": "The systems only differ with respect to how they were optimized.", "labels": [], "entities": []}, {"text": "In the first configuration, (hereafter I), all components in the pipeline had their parameters tuned by 10-fold cross-validation across CDTD.", "labels": [], "entities": []}, {"text": "The second configuration (II) is tuned against CDD using CDT for training.", "labels": [], "entities": []}, {"text": "The rationale for this strategy is to guard against possible overfitting effects that could result from either optimization scheme, given the limited size of the data sets.", "labels": [], "entities": []}, {"text": "For the held-out testing all models are estimated on the entire CDTD.", "labels": [], "entities": [{"text": "CDTD", "start_pos": 64, "end_pos": 68, "type": "DATASET", "confidence": 0.9832066297531128}]}, {"text": "Unless otherwise noted, all reported scores are generated using the evaluation script provided by the organizers, which breaks down performance with respect to cues, events, scope tokens, and two variants of scope-level exact match (one requiring exact match of cues and the other only partial cue match).", "labels": [], "entities": []}, {"text": "The latter two scores are identical for our system hence are not duplicated in this paper.", "labels": [], "entities": []}, {"text": "Furthermore, as we did not optimize for the scope tokens measure this is only reported for the final evaluation.", "labels": [], "entities": []}, {"text": "Note also that the evaluation actually includes two variants of the metrics mentioned above; a set of primary measures with precision computed as P = T P/(T P + F P ) and a set of so-called B measures that instead uses P = T P/S, where S is the total number of predictions made by the system.", "labels": [], "entities": [{"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9977368116378784}]}, {"text": "The reason why S is not identical with T P + F P is that partial matches are only counted as FNs (and not FPs) in order to avoid double penalties.", "labels": [], "entities": []}, {"text": "We do not report the B measures for development testing as they were only introduced for the final evaluation and hence were not considered in our system optimization.", "labels": [], "entities": [{"text": "B", "start_pos": 21, "end_pos": 22, "type": "METRIC", "confidence": 0.9915865659713745}]}, {"text": "We note though, that the relativeranking of participating systems for the primary and B measures is identical, and that the correlation between the paired lists of scores is nearly perfect (r = 0.997).", "labels": [], "entities": []}, {"text": "The paper is structured according to the components of our system.", "labels": [], "entities": []}, {"text": "Section 2 details the process of identifying instances of negation through the disambiguation of known cue words and affixes.", "labels": [], "entities": []}, {"text": "Section 3 describes our hybrid approach to scope resolution, which utilizes both heuristic and data-driven methods to select syntactic constituents.", "labels": [], "entities": [{"text": "scope resolution", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.9118427336215973}]}, {"text": "Section 4 discusses our event detection component, which first applies a classifier to filter out non-factual events and then uses a learned ranking function to select events among in-scope tokens.", "labels": [], "entities": [{"text": "event detection", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7337437123060226}]}, {"text": "End-to-end results are presented in Section 5.", "labels": [], "entities": [{"text": "End-to-end", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9621375799179077}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Detecting negation cues using the two clas- sifiers and the majority-usage baseline.", "labels": [], "entities": [{"text": "Detecting negation cues", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.877053956190745}]}, {"text": " Table 3: Scope resolution for gold cues using the  two versions of the ranker, also listing the perfor- mance of the rule-based approach in isolation.", "labels": [], "entities": [{"text": "Scope resolution", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.6178795099258423}]}, {"text": " Table 4: Results for factuality detection (using gold  negation cues and scopes). Due to the limited train- ing data for factuality, the classifier is only opti- mized by 10-fold cross-validation on CDTD.", "labels": [], "entities": [{"text": "factuality detection", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.8388872146606445}, {"text": "CDTD", "start_pos": 200, "end_pos": 204, "type": "DATASET", "confidence": 0.9589323401451111}]}, {"text": " Table 5: Features used to describe candidates for  event detection, with indications of presence in our  two system configurations.", "labels": [], "entities": [{"text": "event detection", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.7468255460262299}]}, {"text": " Table 6: Event detection for gold scopes and gold  factuality information.", "labels": [], "entities": [{"text": "Event detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.8009543120861053}, {"text": "gold scopes", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.5857955068349838}]}, {"text": " Table 7: End-to-end results on the held-out data.", "labels": [], "entities": [{"text": "End-to-end", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9751315116882324}]}]}