{"title": [{"text": "SAGAN: A Machine Translation Approach for Cross-Lingual Textual Entailment", "labels": [], "entities": [{"text": "Machine Translation Approach", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.7756333351135254}, {"text": "Cross-Lingual Textual Entailment", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.7136152585347494}]}], "abstractContent": [{"text": "This paper describes our participation in the task denominated Cross-Lingual Textual En-tailment (CLTE) for content synchronization.", "labels": [], "entities": []}, {"text": "We represent an approach to CLTE using machine translation to tackle the problem of multilinguality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.723991721868515}]}, {"text": "Our system resides on machine learning and in the use of WordNet as semantic source knowledge.", "labels": [], "entities": []}, {"text": "Results are very promising always achieving results above mean score.", "labels": [], "entities": [{"text": "mean score", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9443527162075043}]}], "introductionContent": [{"text": "This paper describes the participation of Sagan, a TE and CLTE system, in the new task of Cross Lingual Textual Entailment for Content Synchronization.", "labels": [], "entities": [{"text": "Cross Lingual Textual Entailment", "start_pos": 90, "end_pos": 122, "type": "TASK", "confidence": 0.7574239522218704}, {"text": "Content Synchronization", "start_pos": 127, "end_pos": 150, "type": "TASK", "confidence": 0.722286731004715}]}, {"text": "The objective of the Recognizing Textual Entailment (RTE) task) is determining whether the meaning of a text fragment that we call hypothesis H can be inferred from another text fragment T.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE) task", "start_pos": 21, "end_pos": 62, "type": "TASK", "confidence": 0.8245151340961456}]}, {"text": "In this manner, we say that T entails H, if a person reading T would infer that H is most likely true.", "labels": [], "entities": []}, {"text": "Thus, this definition assumes common human understanding of language and common background knowledge.", "labels": [], "entities": []}, {"text": "In that context, Cross-Lingual Textual Entailment addresses textual entailment recognition in the challenging application scenario of content synchronization.", "labels": [], "entities": [{"text": "Cross-Lingual Textual Entailment", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.7232815027236938}, {"text": "textual entailment recognition", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.7304908136526743}]}, {"text": "Thus, CLTE constitutes a generalization of Textual Entailment task (also Monolingual Textual Entailment) , but envisioning a larger number of application areas in NLP, including question answering, information retrieval, information extraction, and document summarization, across different languages.", "labels": [], "entities": [{"text": "question answering", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.8159803748130798}, {"text": "information retrieval", "start_pos": 198, "end_pos": 219, "type": "TASK", "confidence": 0.7973440289497375}, {"text": "information extraction", "start_pos": 221, "end_pos": 243, "type": "TASK", "confidence": 0.8232790231704712}, {"text": "document summarization", "start_pos": 249, "end_pos": 271, "type": "TASK", "confidence": 0.7124669551849365}]}, {"text": "Content synchronization could be used to keep consistence among documents written in different languages.", "labels": [], "entities": []}, {"text": "For example, a CLTE system can be used in Wikipedia articles to inform lectors which information is absent or inconsistent in comparison to other page in a different language.", "labels": [], "entities": []}, {"text": "This new task has to face more additional issues than monolingual TE.", "labels": [], "entities": []}, {"text": "Among them, we emphasize the ambiguity, polysemy, and coverage of the resources.", "labels": [], "entities": []}, {"text": "Another additional problem is the necessity for semantic inference across languages, and the limited availability of multilingual knowledge resources.", "labels": [], "entities": [{"text": "semantic inference across languages", "start_pos": 48, "end_pos": 83, "type": "TASK", "confidence": 0.8462907671928406}]}, {"text": "The CLTE for content synchronization specifically consist on determining the entailment relationship between two text fragment T1 and T2 which are assumed belong a related topic.", "labels": [], "entities": [{"text": "content synchronization", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.7170465886592865}]}, {"text": "Four alternatives are possible in this relationship: -Bidirectional : It is a semantic equivalence between T1 and T2.", "labels": [], "entities": []}, {"text": "-Forward : It is an unidirectional entailment from T1 to T2.", "labels": [], "entities": [{"text": "Forward", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9976662397384644}]}, {"text": "-Backward: It is an unidirectional entailment from T2 to T1.", "labels": [], "entities": [{"text": "Backward", "start_pos": 1, "end_pos": 9, "type": "METRIC", "confidence": 0.9750488996505737}]}, {"text": "-No Entailment: It means that there is no entailment between T1 and T2.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 describes the relevant work done on cross-lingual textual entailment and related tasks, Section 3 describes the architecture of the system, then Section 4 shows experiments and results; and finally Sec-tion 5 summarize some conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset provided by the organizers consists of 500 CLTE pairs translated to four languages following the crowdsourcing-based methodology proposed in ).", "labels": [], "entities": []}, {"text": "Also, for test purpose additional 500 pairs are provided.", "labels": [], "entities": []}, {"text": "Both datasets are balanced with respect to the four entailment judgments (bidirectional, forward, backward, and no entailment).", "labels": [], "entities": []}, {"text": "We also performed experiments using traditional RTE datasets.", "labels": [], "entities": [{"text": "RTE datasets", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.7470236122608185}]}, {"text": "Because of the RTE datasets are binary classified as NO (no-entailment) and YES (entailment), then we assumed that NO class is \"no-entailment\" and YES class is \"forward\" in the CLTE task.", "labels": [], "entities": [{"text": "RTE datasets", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.8571946322917938}, {"text": "NO", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9227495193481445}, {"text": "YES", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9931180477142334}]}, {"text": "Certainly, the corpus tagged in this way will have contradictory information, since several pairs classified as forward should be classified as bidirectional, and also several pairs classified as no-entailment could be backwards, but the objective is experimenting whether we can gain accuracy in our RTE system despite of these (few) contradictory cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 285, "end_pos": 293, "type": "METRIC", "confidence": 0.9980960488319397}]}, {"text": "Additionally, in our experiments we used an algorithm to generate additional training data, in other words to expand a data set.", "labels": [], "entities": []}, {"text": "It is based on a Double Translation Process (dtp) or round-trip translation.", "labels": [], "entities": [{"text": "Double Translation Process (dtp)", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.7150054772694906}]}, {"text": "Double translation process can be defined as the process of starting with an S (String in English), translating it to a foreign language F(S), for example Spanish, and finally back into the English source language F-1(S).", "labels": [], "entities": [{"text": "Double translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6248781383037567}]}, {"text": "We applied the algorithm starting with RTE3 and RTE4 datasets.", "labels": [], "entities": [{"text": "RTE4 datasets", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.9175319373607635}]}, {"text": "Thus, the augmented corpus is denoted RTE3-4C which is tagged according to the three-way task composed of: 340 pairs Contradic-tion, 1520 pairs Yes, and 1114 pairs Unknown.", "labels": [], "entities": [{"text": "RTE3-4C", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.6446852684020996}]}, {"text": "In the case of the two-way task, it is composed by 1454 pairs No, and 1520 pairs Yes.", "labels": [], "entities": []}, {"text": "The other dataset augmented is denoted RTE4-4C, and has the following composition: 546 pairs Contradiction, 1812 pairs Entailment, and 1272 pairs Unknown.", "labels": [], "entities": [{"text": "RTE4-4C", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.7817187309265137}]}, {"text": "Therefore, in the two-way task, there are 1818 pairs No (No Entailment), and 1812 pairs Yes (Entailment) in this data set.", "labels": [], "entities": [{"text": "1812 pairs Yes (Entailment)", "start_pos": 77, "end_pos": 104, "type": "METRIC", "confidence": 0.8504486580689748}]}, {"text": "The idea behind using RTE3-4C and RTE3-4C is providing to our system an increased dataset aiming to acquire more semantic variability.", "labels": [], "entities": [{"text": "RTE3-4C", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.8966608047485352}]}, {"text": "In our system submission we report the experiments performed with the test sets provided by CLTE organizers which is composed by four datasets of 500 pairs each one.", "labels": [], "entities": [{"text": "CLTE organizers", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.9604761004447937}]}], "tableCaptions": [{"text": " Table 2. Official results for Precision, Recall and F-measure", "labels": [], "entities": [{"text": "Precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9936827421188354}, {"text": "Recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9920782446861267}, {"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9922670722007751}]}]}