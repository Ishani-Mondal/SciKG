{"title": [{"text": "Ensemble-based Semantic Lexicon Induction for Semantic Tagging", "labels": [], "entities": [{"text": "Semantic Tagging", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7788364291191101}]}], "abstractContent": [{"text": "We present an ensemble-based framework for semantic lexicon induction that incorporates three diverse approaches for semantic class identification.", "labels": [], "entities": [{"text": "semantic lexicon induction", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.8178236881891886}, {"text": "semantic class identification", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.6687493622303009}]}, {"text": "Our architecture brings together previous bootstrapping methods for pattern-based semantic lexicon induction and contextual semantic tagging, and incorporates a novel approach for inducing semantic classes from coreference chains.", "labels": [], "entities": [{"text": "pattern-based semantic lexicon induction", "start_pos": 68, "end_pos": 108, "type": "TASK", "confidence": 0.6436062380671501}, {"text": "contextual semantic tagging", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.6255417664845785}]}, {"text": "The three methods are embedded in a bootstrapping architecture where they produce independent hypotheses, consensus words are added to the lexicon, and the process repeats.", "labels": [], "entities": []}, {"text": "Our results show that the ensemble outperforms individual methods in terms of both lexicon quality and instance-based semantic tagging.", "labels": [], "entities": [{"text": "instance-based semantic tagging", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.6236387888590494}]}], "introductionContent": [{"text": "One of the most fundamental aspects of meaning is the association between words and semantic categories, which allows us to understand that a \"cow\" is an animal and a \"house\" is a structure.", "labels": [], "entities": []}, {"text": "We will use the term semantic lexicon to refer to a dictionary that associates words with semantic classes.", "labels": [], "entities": []}, {"text": "Semantic dictionaries are useful for many NLP tasks, as evidenced by the widespread use of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9641120433807373}]}, {"text": "However, off-the-shelf resources are not always sufficient for specialized domains, such as medicine, chemistry, or microelectronics.", "labels": [], "entities": []}, {"text": "Furthermore, in virtually every domain, texts contain lexical variations that are often missing from dictionaries, such as acronyms, abbreviations, spelling variants, informal shorthand terms (e.g., \"abx\" for \"antibiotics\"), and composite terms (e.g., \"maydecember\" or \"virus/worm\").", "labels": [], "entities": []}, {"text": "To address this problem, techniques have been developed to automate the construction of semantic lexicons from text corpora using bootstrapping methods (), but accuracy is still far from perfect.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9990198612213135}]}, {"text": "Our research explores the use of ensemble methods to improve the accuracy of semantic lexicon induction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9970723390579224}, {"text": "semantic lexicon induction", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.7270614306131998}]}, {"text": "Our observation is that semantic class associations can be learned using several fundamentally different types of corpus analysis.", "labels": [], "entities": []}, {"text": "Bootstrapping methods for semantic lexicon induction (e.g., () collect corpus-wide statistics for individual words based on shared contextual patterns.", "labels": [], "entities": [{"text": "semantic lexicon induction", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.7118507027626038}]}, {"text": "In contrast, classifiers for semantic tagging (e.g.,) label word instances and focus on the local context surrounding each instance.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7383665442466736}]}, {"text": "The difference between these approaches is that semantic taggers make decisions based on a single context and can assign different labels to different instances, whereas lexicon induction algorithms compile corpus statistics from multiple instances of a word and typically assign each word to a single semantic category.", "labels": [], "entities": [{"text": "semantic taggers", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.7419836819171906}]}, {"text": "We also hypothesize that coreference resolution can be exploited to infer semantic class labels.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.9652042984962463}]}, {"text": "Intuitively, if we know that two noun phrases are coreferent, then they probably belong to the same high-level semantic category (e.g., \"dog\" and \"terrier\" are both animals).", "labels": [], "entities": []}, {"text": "In this paper, we present an ensemble-based framework for semantic lexicon induction.", "labels": [], "entities": [{"text": "semantic lexicon induction", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.8529509902000427}]}, {"text": "We incorporate a pattern-based bootstrapping method for lexicon induction, a contextual semantic tagger, and anew coreference-based method for lexicon induction.", "labels": [], "entities": [{"text": "lexicon induction", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7129003703594208}, {"text": "lexicon induction", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.7317720353603363}]}, {"text": "Our results show that coalescing the decisions produced by diverse methods produces a better dictionary than any individual method alone.", "labels": [], "entities": []}, {"text": "A second contribution of this paper is an analysis of the effectiveness of dictionaries for semantic tagging.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 92, "end_pos": 108, "type": "TASK", "confidence": 0.8064389824867249}]}, {"text": "In principle, an NLP system should be able to assign different semantic labels to different senses of a word.", "labels": [], "entities": []}, {"text": "But within a specialized domain, most words have a dominant sense and we argue that using domain-specific dictionaries for tagging maybe equally, if not more, effective.", "labels": [], "entities": []}, {"text": "We analyze the tradeoffs between using an instance-based semantic tagger versus dictionary lookup on a collection of disease outbreak articles.", "labels": [], "entities": []}, {"text": "Our results show that the induced dictionaries yield better performance than an instance-based semantic tagger, achieving higher accuracy with comparable levels of recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9988906979560852}, {"text": "recall", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.997208297252655}]}], "datasetContent": [{"text": "To assess the quality of the lexicons, we estimated their accuracy by compiling external word lists from freely available sources such as Wikipedia and WordNet.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.996857762336731}, {"text": "WordNet", "start_pos": 152, "end_pos": 159, "type": "DATASET", "confidence": 0.9575847387313843}]}, {"text": "shows the sources that we used, where the bracketed items refer to WordNet hypernym categories.", "labels": [], "entities": [{"text": "WordNet hypernym categories", "start_pos": 67, "end_pos": 94, "type": "DATASET", "confidence": 0.8912986318270365}]}, {"text": "We searched each WordNet hypernym tree (also, instancerelationship) for all senses of the word.", "labels": [], "entities": [{"text": "WordNet hypernym tree", "start_pos": 17, "end_pos": 38, "type": "DATASET", "confidence": 0.8950475454330444}]}, {"text": "Additionally, we collected the manually labeled words in our test set and included them in our gold standard lists.", "labels": [], "entities": []}, {"text": "Since the induced lexicons contain individual nouns, we extracted only the head nouns of multiword phrases in the external resources.", "labels": [], "entities": []}, {"text": "This can produce incorrect entries for non-compositional phrases, but we found this issue to be relatively rare and we manually removed obviously wrong entries.", "labels": [], "entities": []}, {"text": "We adopted a conservative strategy and assumed that any lexicon entries not present in our gold standard lists are incorrect.", "labels": [], "entities": []}, {"text": "But we observed many correct entries that were missing from the external resources, so our results should be interpreted as a lower bound on the true accuracy of the induced lexicons.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.998315691947937}]}, {"text": "We generated lexicons for each method separately, and also for the ensemble and co-training models.", "labels": [], "entities": []}, {"text": "We ran Basilisk for 100 iterations (500 words).", "labels": [], "entities": [{"text": "Basilisk", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.9143998026847839}]}, {"text": "We refer to a Basilisk lexicon of size N using the notation B.", "labels": [], "entities": []}, {"text": "For example, B400 refers to a lexicon containing 400 words, which was generated from 80 bootstrapping cycles.", "labels": [], "entities": []}, {"text": "We refer to the lexicon obtained from the semantic tagger as ST Lex.", "labels": [], "entities": [{"text": "ST Lex", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.6623900681734085}]}, {"text": "shows the dictionary evaluation results.", "labels": [], "entities": []}, {"text": "We plotted Basilisk's accuracy after every 5 bootstrapping cycles (25 words).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9843223690986633}]}, {"text": "For ST Lex, we sorted the words by their confidence scores and plotted the accuracy of the top-ranked words in increments of 50.", "labels": [], "entities": [{"text": "ST Lex", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.583805724978447}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9983311295509338}]}, {"text": "The plots for Coref, Co-Training, and Ensemble B are based on the lexicons produced after each bootstrapping cycle.", "labels": [], "entities": []}, {"text": "www.wikipedia.org/ The ensemble-based framework yields consistently better accuracy than the individual methods for Animal, Body Part, Human and Temporal Reference, and similar if not better for Disease & Symptom, Fixed Location, Organization, Plant & Food.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9991793036460876}]}, {"text": "However, relying on consensus from multiple models produce smaller dictionaries.", "labels": [], "entities": []}, {"text": "Big dictionaries are not always better than small dictionaries in practice, though.", "labels": [], "entities": []}, {"text": "We believe, it matters more whether a dictionary contains the most frequent words fora domain, because they account fora disproportionate number of instances.", "labels": [], "entities": []}, {"text": "Basilisk, for example, often learns infrequent words, so its dictionaries may have high accuracy but often fail to recognize common words.", "labels": [], "entities": [{"text": "Basilisk", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8366621136665344}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9963098168373108}]}, {"text": "We investigate this issue in the next section.", "labels": [], "entities": []}, {"text": "We also evaluated the effectiveness of the induced lexicons with respect to instance-based semantic tagging.", "labels": [], "entities": [{"text": "instance-based semantic tagging", "start_pos": 76, "end_pos": 107, "type": "TASK", "confidence": 0.6372102697690328}]}, {"text": "Our goal was to determine how useful the dictionaries are in two respects: (1) do the lexicons contain words that appear frequently in the domain, and (2) is dictionary look-up sufficient for instancebased labeling?", "labels": [], "entities": []}, {"text": "Our bootstrapping processes enforce a constraint that a word can only belong to one semantic class, so if polysemy is common, then dictionary look-up will be problematic.", "labels": [], "entities": []}, {"text": "The instance-based evaluation assigns a semantic label to each instance of ahead noun.", "labels": [], "entities": []}, {"text": "When using a lexicon, all instances of the same noun are assigned the same semantic class via dictionary look-up.", "labels": [], "entities": []}, {"text": "The semantic tagger (SemTag), however, is applied directly since it was designed to label instances.", "labels": [], "entities": []}, {"text": "As a baseline, the W.Net row shows the performance of WordNet for instance tagging.", "labels": [], "entities": [{"text": "W.Net row", "start_pos": 19, "end_pos": 28, "type": "DATASET", "confidence": 0.8174526393413544}]}, {"text": "For words with multiple senses, we only used the first sense listed in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9871709942817688}]}, {"text": "The Seeds row shows the results when performing dictionary look-up using only the seed words.", "labels": [], "entities": []}, {"text": "The remaining rows show the results for Basilisk (B100 and B400), coreference-based lexicon induction (Coref), lexicon induction using the semantic tagger (ST Lex), and the original instance-based tagger (SemTag).", "labels": [], "entities": [{"text": "coreference-based lexicon induction", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.7666182716687521}]}, {"text": "The following rows show the results for co-training (after 4 iterations and 20 iterations) and for the ensemble (using Basilisk size 100 and size 400).", "labels": [], "entities": []}, {"text": "shows the micro & macro average results across all semantic categories.", "labels": [], "entities": []}, {"text": "shows that the dictionaries produced by the Ensemble w/B100 achieved better results than the individual methods and co-training with an F score of 80%.", "labels": [], "entities": [{"text": "F score", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.9888140559196472}]}, {"text": "shows that the ensemble achieved better performance than the other methods for 4 of the 9 classes, and was usually competitive on the remaining 5 classes.", "labels": [], "entities": []}, {"text": "WordNet (W.Net) consistently produced high precision, but with comparatively lower recall, indicating that WordNet does not have sufficient coverage for this domain.", "labels": [], "entities": [{"text": "WordNet (W.Net)", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9207748621702194}, {"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9991700649261475}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9994596838951111}, {"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.953965961933136}]}, {"text": "shows the performance of our ensemble when using only 2 of the 3 component methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Instance-based Semantic Tagging Results (P = Precision, R = Recall, F = F-measure)", "labels": [], "entities": [{"text": "Instance-based Semantic Tagging", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.652287612358729}, {"text": "Recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.5761973857879639}, {"text": "F-measure", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.795062780380249}]}]}