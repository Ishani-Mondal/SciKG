{"title": [{"text": "Tiantianzhu7:System Description of Semantic Textual Similarity (STS) in the SemEval-2012 (Task 6)", "labels": [], "entities": [{"text": "System Description of Semantic Textual Similarity (STS)", "start_pos": 13, "end_pos": 68, "type": "TASK", "confidence": 0.8114419049686856}]}], "abstractContent": [{"text": "This paper briefly reports our submissions to the Semantic Textual Similarity (STS) task in the SemEval 2012 (Task 6).", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 50, "end_pos": 88, "type": "TASK", "confidence": 0.8204452182565417}, {"text": "SemEval 2012 (Task 6)", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.7151672740777334}]}, {"text": "We first use knowledge-based methods to compute word semantic similarity as well as Word Sense Dis-ambiguation (WSD).", "labels": [], "entities": [{"text": "word semantic similarity", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6927386124928793}, {"text": "Word Sense Dis-ambiguation (WSD)", "start_pos": 84, "end_pos": 116, "type": "TASK", "confidence": 0.616352046529452}]}, {"text": "We also consider word order similarity from the structure of the sentence.", "labels": [], "entities": []}, {"text": "Finally we sum up several aspects of similarity with different coefficients and get the sentence similarity score.", "labels": [], "entities": [{"text": "sentence similarity score", "start_pos": 88, "end_pos": 113, "type": "METRIC", "confidence": 0.6407604217529297}]}], "introductionContent": [{"text": "The task of semantic textual similarity (STS) is to measure the degree of semantic equivalence between two sentences.", "labels": [], "entities": [{"text": "semantic textual similarity (STS)", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.7360890458027521}]}, {"text": "It plays an increasingly important role in several text-related research and applications, such as text mining, Web page retrieval, automatic question-answering, text summarization, and machine translation.", "labels": [], "entities": [{"text": "text mining", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.7902475297451019}, {"text": "Web page retrieval", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.6230916678905487}, {"text": "text summarization", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.7744117081165314}, {"text": "machine translation", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.815913587808609}]}, {"text": "The goal of the Semeval 2012 STS task (task 6) is to build a unified framework for the evaluation of semantic textual similarity modules for different systems and to characterize their impact on NLP applications.", "labels": [], "entities": [{"text": "Semeval 2012 STS task", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7238072752952576}]}, {"text": "Generally, there are two ways to measure similarity of two sentences, i.e, corpus-based methods and knowledge-based methods.", "labels": [], "entities": []}, {"text": "The corpusbased method typically computes sentence similarity based on the frequency of word occurrence or the co-occurrence between collocated words.", "labels": [], "entities": []}, {"text": "For example, in) they proposed a corpus-based sentence similarity measure as a function of string similarity, word similarity and common word order similarity (CWO).", "labels": [], "entities": [{"text": "common word order similarity (CWO)", "start_pos": 130, "end_pos": 164, "type": "METRIC", "confidence": 0.696354614836829}]}, {"text": "The knowledgebased method computes sentence similarity based on the semantic information collected from knowledge bases.", "labels": [], "entities": []}, {"text": "With the aid of a number of successful computational linguistic projects, many semantic knowledge bases are readily available, for example, WordNet, Spatial Date Transfer Standard, Gene Ontology, etc.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.9408758282661438}]}, {"text": "Among them, the most widely used one is WordNet, which is organized by meanings and developed at Princeton University.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9534143805503845}]}, {"text": "Several methods computed word similarity by using WordNet, such as the Lesk method in (, the lch method in)and the wup method in (.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7106465697288513}, {"text": "WordNet", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9483031630516052}]}, {"text": "Generally, although the knowledgebased methods heavily depend on the knowledge bases, they performed much better than the corpusbased methods inmost cases.", "labels": [], "entities": []}, {"text": "Therefore, in our STS system, we use a knowledge-based method to compute word similarity.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes our system.", "labels": [], "entities": []}, {"text": "Section 3 presents the results of our system.", "labels": [], "entities": []}], "datasetContent": [{"text": "Firstly, Stanford parser 1 is used to parse each sentence and to tag each word with apart of speech(POS).", "labels": [], "entities": [{"text": "parse each sentence", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8489302595456442}]}, {"text": "Secondly, WordNet SenseRelate AllWords 2 , a WSD tool from CPAN is used to disambiguate and to assign a sense for each word based on the assigned POS.", "labels": [], "entities": [{"text": "WordNet SenseRelate AllWords 2", "start_pos": 10, "end_pos": 40, "type": "DATASET", "confidence": 0.8915813565254211}]}, {"text": "We submitted three runs: run 1 with WSD, run 2 without WSD, run 3 removing stop words and without WSD.", "labels": [], "entities": []}, {"text": "The stoplist is available online . lists the performance of these three systems as well as the baseline and the rank 1 results on STS task in SemEval 2012.", "labels": [], "entities": [{"text": "STS task in SemEval 2012", "start_pos": 130, "end_pos": 154, "type": "DATASET", "confidence": 0.7284400820732116}]}, {"text": "We can see that run1 gets the best result, which means WSD has improved the accuracy of sentence similarity.", "labels": [], "entities": [{"text": "WSD", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.4703851044178009}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9990758895874023}]}, {"text": "Run3 gets better result than run2, which proves that stop words do disturb the computation of sentence similarity, removing them is a better choice in our system.", "labels": [], "entities": [{"text": "Run3", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8628101944923401}]}], "tableCaptions": []}