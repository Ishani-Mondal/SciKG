{"title": [{"text": "SAGAN: An approach to Semantic Textual Similarity based on Textual Entailment", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.7043517430623373}, {"text": "Textual Entailment", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.6816044598817825}]}], "abstractContent": [{"text": "In this paper we report the results obtained in the Semantic Textual Similarity (STS) task, with a system primarily developed for textual entailment.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 52, "end_pos": 90, "type": "TASK", "confidence": 0.8079186763082232}, {"text": "textual entailment", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.7504097521305084}]}, {"text": "Our results are quite promising, getting a run ranked 39 in the official results with overall Pearson, and ranking 29 with the Mean metric.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.927341103553772}, {"text": "Mean metric", "start_pos": 127, "end_pos": 138, "type": "METRIC", "confidence": 0.9749743640422821}]}], "introductionContent": [{"text": "For the last couple of years the research community has focused on a deeper analysis of natural languages, seeking to capture the meaning of the text in different contexts: in machine translation preserving the meaning of the translations is crucial to determine whether a translation is useful or not, in question-answering understanding the question leads to the desired answers (while the opposite case makes a system rather frustrating to the user) and the examples could continue.", "labels": [], "entities": [{"text": "machine translation preserving the meaning of the translations", "start_pos": 176, "end_pos": 238, "type": "TASK", "confidence": 0.8313861861824989}]}, {"text": "In this newly defined task, Semantic Textual Similarity, there is hope that efforts in different areas will be shared and united towards the goal of identifying meaning and recognizing equivalent, similar or unrelated texts.", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.7403136293093363}]}, {"text": "Our contribution to the task, is from a textual entailment point of view, as will be described below.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 describes the relevant tasks, Section 3 describes the architecture of the system, then Section 4 shows the experiments carried out and the results obtained, and Section 5 presents some conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For preliminary experiments before the STS Challenge, we used the training set provided by the organizers, denoted with \"_train\", and consisting of 750 pairs of sentences from the MSR Paraphrase Corpus (MSRpar), 750 pairs of sentences from the MSRvid Corpus (MSRvid), 459 pairs of sentences of the Europarl WMT2008 development set (SMTeur).", "labels": [], "entities": [{"text": "MSR Paraphrase Corpus (MSRpar)", "start_pos": 180, "end_pos": 210, "type": "DATASET", "confidence": 0.880149652560552}, {"text": "MSRvid Corpus (MSRvid)", "start_pos": 244, "end_pos": 266, "type": "DATASET", "confidence": 0.9150030493736268}, {"text": "Europarl WMT2008 development set (SMTeur)", "start_pos": 298, "end_pos": 339, "type": "DATASET", "confidence": 0.9411927206175668}]}, {"text": "We also used the RTE datasets from Pascal RTE Challenge () as part of our training sets.", "labels": [], "entities": [{"text": "RTE datasets from Pascal RTE Challenge", "start_pos": 17, "end_pos": 55, "type": "DATASET", "confidence": 0.893482913573583}]}, {"text": "Additionally, at the testing stage, we used the 399 pairs of news conversation (SMTnews) and 750 pairs of sentences where the first one comes from Ontonotes and the second one from a WordNet definition (On-WN).", "labels": [], "entities": [{"text": "Ontonotes", "start_pos": 147, "end_pos": 156, "type": "DATASET", "confidence": 0.916175365447998}, {"text": "WordNet definition (On-WN)", "start_pos": 183, "end_pos": 209, "type": "DATASET", "confidence": 0.8771301746368408}]}, {"text": "In STS Challenge it was required that participating systems do not use the test set of MSRParaphrase, the text of the videos in MSR-Video, and the data from the evaluation tasks at any WMT to develop or train their systems.", "labels": [], "entities": [{"text": "MSRParaphrase", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.8110229969024658}]}, {"text": "Additionally, we also assumed that the dataset to be processed was unknown in the testing phase, in order to avoid any kind of tuning of the system.", "labels": [], "entities": []}, {"text": "Ina preliminary study performed before the final submission, we experimented with three machine learning algorithms Support Vector Machine (SVM) with regression and polynomial kernel, Multilayer perceptron (MLP), and Linear Regression (LR).", "labels": [], "entities": []}, {"text": "shows the results obtained with 10-fold cross validation technique and shows the results of testing them with two datasets and 3 classifiers over MSR_train.", "labels": [], "entities": [{"text": "MSR_train", "start_pos": 146, "end_pos": 155, "type": "DATASET", "confidence": 0.9311226606369019}]}], "tableCaptions": [{"text": " Table 1. Results obtained using MSR training set  (MSRpar + MSRvid) with 10 fold-cross validation.", "labels": [], "entities": []}, {"text": " Table 2. Results obtained using MSR training set", "labels": [], "entities": [{"text": "MSR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9439834356307983}]}, {"text": " Table 3. Results obtained using RTE in the training sets  and SVM w/regression as classifier", "labels": [], "entities": []}, {"text": " Table 5. Official results of the STS challenge", "labels": [], "entities": [{"text": "STS challenge", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.5036592930555344}]}]}