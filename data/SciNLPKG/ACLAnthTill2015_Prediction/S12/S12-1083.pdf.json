{"title": [{"text": "JU_CSE_NLP: Multi-grade Classification of Semantic Similarity Between Text Pairs", "labels": [], "entities": [{"text": "JU_CSE_NLP", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8277879357337952}, {"text": "Multi-grade Classification of Semantic Similarity Between Text Pairs", "start_pos": 12, "end_pos": 80, "type": "TASK", "confidence": 0.6555502042174339}]}], "abstractContent": [{"text": "This article presents the experiments carried out at Jadavpur University as part of the participation in Semantic Textual Similarity (STS) of Task 6 @ Semantic Evaluation Exercises.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 105, "end_pos": 138, "type": "TASK", "confidence": 0.7779467105865479}]}, {"text": "Task-6 of SemEval-2012 focused on semantic relations of text pair.", "labels": [], "entities": []}, {"text": "Task-6 provides five different text pair files to compare different semantic relations and judge these relations through a similarity and confidence score.", "labels": [], "entities": [{"text": "similarity and confidence score", "start_pos": 123, "end_pos": 154, "type": "METRIC", "confidence": 0.8510661572217941}]}, {"text": "Similarity score is one kind of multi way classification in the form of grade between 0 to 5.", "labels": [], "entities": [{"text": "Similarity score", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.8728034794330597}]}, {"text": "We have submitted one run for the STS task.", "labels": [], "entities": [{"text": "STS task", "start_pos": 34, "end_pos": 42, "type": "TASK", "confidence": 0.828441709280014}]}, {"text": "Our system has two basic modules -one deals with lexical relations and another deals with dependency based syntactic relations of the text pair.", "labels": [], "entities": []}, {"text": "Similarity score given to a pair is the average of the scores of the above-mentioned modules.", "labels": [], "entities": []}, {"text": "The scores from each module are identified using rule based techniques.", "labels": [], "entities": []}, {"text": "The Pearson Correlation of our system in the task is 0.3880.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.7985177636146545}]}], "introductionContent": [{"text": "Task-6 1 of SemEval-2012 deals with semantic similarity of text pairs.", "labels": [], "entities": []}, {"text": "The task is to find the similarity between the sentences in the text pair (s1 and s2) and return a similarity score and an optional confidence score.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 99, "end_pos": 115, "type": "METRIC", "confidence": 0.9745239019393921}]}, {"text": "There are five datasets Similarity score ranges from 0 to 5 and confidence score from 0 to 100.", "labels": [], "entities": [{"text": "Similarity score", "start_pos": 24, "end_pos": 40, "type": "METRIC", "confidence": 0.9097469449043274}, {"text": "confidence score", "start_pos": 64, "end_pos": 80, "type": "METRIC", "confidence": 0.9860371351242065}]}, {"text": "An s1-s2 pair gets a similarity score of 5 if they are completely equivalent.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 21, "end_pos": 37, "type": "METRIC", "confidence": 0.9818376004695892}]}, {"text": "Similarity score 4 is allocated for mostly equivalent s1-s2 pair.", "labels": [], "entities": [{"text": "Similarity score 4", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.9576458732287089}]}, {"text": "Similarly, score 3 is allocated for roughly equivalent pair.", "labels": [], "entities": []}, {"text": "Score 2, 1 and 0 are allocated for non-equivalent details sharing, non-equivalent topic sharing and totally different pairs respectively.", "labels": [], "entities": []}, {"text": "Major challenge of this task is to find the similarity score based similarity for the text pair.", "labels": [], "entities": [{"text": "similarity score based similarity", "start_pos": 44, "end_pos": 77, "type": "METRIC", "confidence": 0.891195222735405}]}, {"text": "Generally text entailment tasks refer whether sentence pairs are entailed or not: binary classification (YES, NO) or multiclassification (Forward, Backward, bidirectional or no entailment)[4].", "labels": [], "entities": [{"text": "text entailment tasks", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7765711545944214}, {"text": "YES, NO)", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.7342600524425507}]}, {"text": "But multi grade classification of semantic similarity assigns a score to the sentence pair.", "labels": [], "entities": []}, {"text": "Our system considers lexical and dependency based syntactic measures for semantic similarity.", "labels": [], "entities": []}, {"text": "Similarity scores are the basic average of these module scores.", "labels": [], "entities": [{"text": "Similarity", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9762381911277771}]}, {"text": "A subsequent section describes the system architecture.", "labels": [], "entities": []}, {"text": "Section 2 describes JU_NLP_CSE system for STS task.", "labels": [], "entities": [{"text": "JU_NLP_CSE", "start_pos": 20, "end_pos": 30, "type": "DATASET", "confidence": 0.6719780445098877}, {"text": "STS task", "start_pos": 42, "end_pos": 50, "type": "TASK", "confidence": 0.7548271119594574}]}, {"text": "Section 3 describes evaluation and experimental results.", "labels": [], "entities": []}, {"text": "Conclusions are drawn in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have submitted one run in SemEval-2012 ALLnrm: Pearson correlation after the system outputs for each dataset are fitted to the gold standard using least squares and the corresponding rank 86.", "labels": [], "entities": [{"text": "SemEval-2012", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.5789012312889099}, {"text": "ALLnrm", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.7212911248207092}, {"text": "Pearson correlation", "start_pos": 50, "end_pos": 69, "type": "METRIC", "confidence": 0.8407051861286163}]}, {"text": "Mean: Weighted mean across the 5 datasets, where the weight depends on the number of pairs in the dataset and the corresponding rank 76.", "labels": [], "entities": []}, {"text": "The subsequent rows show the pearson correlation scores for each of the individual datasets.", "labels": [], "entities": [{"text": "pearson correlation scores", "start_pos": 29, "end_pos": 55, "type": "METRIC", "confidence": 0.7065449158350626}]}], "tableCaptions": [{"text": " Table 1: Results of Test Set", "labels": [], "entities": []}]}