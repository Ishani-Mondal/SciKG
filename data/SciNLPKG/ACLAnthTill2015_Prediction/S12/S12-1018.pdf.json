{"title": [], "abstractContent": [{"text": "Modeling user preferences is crucial in many real-life problems, ranging from individual and collective decision-making to strategic interactions between agents and game theory.", "labels": [], "entities": [{"text": "game theory", "start_pos": 165, "end_pos": 176, "type": "TASK", "confidence": 0.736511617898941}]}, {"text": "Since agents do not come with their preferences transparently given in advance, we have only two means to determine what they are if we wish to exploit them in reasoning: we can infer them from what an agent says or from his nonlinguistic actions.", "labels": [], "entities": []}, {"text": "In this paper, we analyze how to infer preferences from dialogue moves in actual conversations that involve bargaining or negotiation.", "labels": [], "entities": []}, {"text": "To this end, we propose anew annotation scheme to study how preferences are linguistically expressed in two different corpus genres.", "labels": [], "entities": []}, {"text": "This paper describes the annotation methodology and details the inter-annotator agreement study on each corpus genre.", "labels": [], "entities": []}, {"text": "Our results show that preferences can be easily annotated by humans.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modeling user preferences is crucial in many reallife problems, ranging from individual and collective decision-making () to strategic interactions between agents () and game theory.", "labels": [], "entities": [{"text": "game theory", "start_pos": 170, "end_pos": 181, "type": "TASK", "confidence": 0.728622555732727}]}, {"text": "A webbased recommender system can, for example, help a user to identify (among an optimal ranking) the product item that best fits his preferences).", "labels": [], "entities": []}, {"text": "Modeling preferences can also help to find some compromise or consensus between two or more agents having different goals during a negotiation ().", "labels": [], "entities": []}, {"text": "Working with preferences involves three subtasks: preference acquisition, which extracts preferences from users, preference modeling where a model of users' preferences is built using a preference representation language and preference reasoning which aims at computing the set of optimal outcomes.", "labels": [], "entities": [{"text": "preference acquisition", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7322145700454712}, {"text": "preference modeling", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.7272105664014816}]}, {"text": "We focus in this paper on the first task.", "labels": [], "entities": []}, {"text": "Handling preferences is not easy.", "labels": [], "entities": []}, {"text": "First, specifying an ordering over acceptable outcomes is not trivial especially when multiple aspects of an outcome matter.", "labels": [], "entities": []}, {"text": "For instance, choosing anew camera to buy may depend on several criteria (e.g. battery life, weight, etc.), hence, ordering even two outcomes (cameras) can be cognitively difficult because of the need to consider trade-offs and dependencies between the criteria.", "labels": [], "entities": []}, {"text": "Second, users often lack complete information about preferences initially.", "labels": [], "entities": []}, {"text": "They build a partial description of agents' preferences that typically changes overtime.", "labels": [], "entities": []}, {"text": "Indeed, users often learn about the domain, each others' preferences and even their own preferences during a decision-making process.", "labels": [], "entities": []}, {"text": "Since agents don't come with their preferences transparently given in advance, we have only two means to determine what they are if we wish to exploit them in reasoning: we can infer them from what an agent says or from his nonlinguistic actions.", "labels": [], "entities": []}, {"text": "In this paper, we analyze how to infer preferences from dialogue moves in actual conversations that involve bargaining or negotiation.", "labels": [], "entities": []}, {"text": "Within the Artificial Intelligence community, preference acquisition from nonlinguistic actions has been performed using a variety of specific tasks, including preference learning) and preference elicitation methods () (such as query learning), collaborative filtering () and qualitative graphical representation of preferences ().", "labels": [], "entities": [{"text": "preference acquisition from nonlinguistic actions", "start_pos": 46, "end_pos": 95, "type": "TASK", "confidence": 0.8321821331977844}]}, {"text": "However, these tasks don't occur in actual conversations about negotiation.", "labels": [], "entities": []}, {"text": "We are interested in how agents learn about preferences from actual conversational turns in real dialogue, using NLP techniques.", "labels": [], "entities": []}, {"text": "To this end, we propose anew annotation scheme to study how preferences are linguistically expressed in dialogues.", "labels": [], "entities": []}, {"text": "The annotation study is performed on two different corpus genres: the Verbmobil corpus () and a booking corpus, built by ourselves.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 70, "end_pos": 86, "type": "DATASET", "confidence": 0.9301660358905792}]}, {"text": "This paper describes the annotation methodology and details the inter-annotator agreement study on each corpus genre.", "labels": [], "entities": []}, {"text": "Our results show that preferences can be easily annotated by humans.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 presents some statistics about the annotated  data in the gold standard.", "labels": [], "entities": [{"text": "annotated  data in the gold standard", "start_pos": 44, "end_pos": 80, "type": "DATASET", "confidence": 0.6695210834344228}]}, {"text": " Table 2: Inter-annotator agreements for the two corpora.", "labels": [], "entities": []}, {"text": " Table 3: Agreements on binary operators.", "labels": [], "entities": []}]}