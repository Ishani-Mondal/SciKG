{"title": [{"text": "FBK: Exploiting Phrasal and Contextual Clues for Negation Scope Detection", "labels": [], "entities": [{"text": "FBK", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.89621901512146}, {"text": "Negation Scope Detection", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8612695535024008}]}], "abstractContent": [{"text": "Automatic detection of negation cues along with their scope and corresponding negated events is an important task that could benefit other natural language processing (NLP) tasks such as extraction of factual information from text, sentiment analysis, etc.", "labels": [], "entities": [{"text": "extraction of factual information from text", "start_pos": 187, "end_pos": 230, "type": "TASK", "confidence": 0.8282148937384287}, {"text": "sentiment analysis", "start_pos": 232, "end_pos": 250, "type": "TASK", "confidence": 0.9298985302448273}]}, {"text": "This paper presents a system for this task that exploits phrasal and contextual clues apart from various token specific features.", "labels": [], "entities": []}, {"text": "The system was developed for the participation in the Task 1 (closed track) of the *SEM 2012 Shared Task (Resolving the Scope and Focus of Negation), where it is ranked 3rd among the participating teams while attaining the highest F 1 score for negation cue detection.", "labels": [], "entities": [{"text": "SEM 2012 Shared Task", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.6394029334187508}, {"text": "F 1 score", "start_pos": 231, "end_pos": 240, "type": "METRIC", "confidence": 0.9892724355061849}, {"text": "negation cue detection", "start_pos": 245, "end_pos": 267, "type": "TASK", "confidence": 0.9115099708239237}]}], "introductionContent": [{"text": "Negation is a linguistic phenomenon that can alter the meaning of a textual segment.", "labels": [], "entities": []}, {"text": "While automatic detection of negation expressions (i.e. cues) in free text has been a subject of research interest for quite sometime (e.g., etc), automatic detection of full scope of negation is a relatively new topic.", "labels": [], "entities": [{"text": "automatic detection of negation expressions (i.e. cues) in free text", "start_pos": 6, "end_pos": 74, "type": "TASK", "confidence": 0.8433394307891527}, {"text": "automatic detection of full scope of negation", "start_pos": 147, "end_pos": 192, "type": "TASK", "confidence": 0.741256764956883}]}, {"text": "Detection of negation cues, their scope and corresponding negated events in free text could improve accuracy in other natural language processing (NLP) tasks such as extraction of factual information from text, sentiment analysis, etc.", "labels": [], "entities": [{"text": "Detection of negation cues", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7126566991209984}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9983606934547424}, {"text": "extraction of factual information from text", "start_pos": 166, "end_pos": 209, "type": "TASK", "confidence": 0.8233183920383453}, {"text": "sentiment analysis", "start_pos": 211, "end_pos": 229, "type": "TASK", "confidence": 0.9284635484218597}]}, {"text": "In this paper, we present a system that was developed for the participation in the Scope Detection task of the *SEM 2012 Shared Task 1 . The proposed system exploits phrasal and contextual clues apart from various token specific features.", "labels": [], "entities": [{"text": "Scope Detection task of the *SEM 2012 Shared Task 1", "start_pos": 83, "end_pos": 134, "type": "TASK", "confidence": 0.6053772216493433}]}, {"text": "Exploitation of phrasal clues is not new for negation scope detection.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.984541634718577}]}, {"text": "But the way we encode this information (i.e. the features for phrasal clues) is novel and differs completely from the previous work.", "labels": [], "entities": []}, {"text": "Moreover, the total number of features that we use is also comparatively lower.", "labels": [], "entities": []}, {"text": "Furthermore, to the best of our knowledge, automatic negated event/property identification has not been explored prior to the *SEM 2012 Shared Task.", "labels": [], "entities": [{"text": "negated event/property identification", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.6190095543861389}, {"text": "SEM 2012 Shared Task", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.6121241599321365}]}, {"text": "So, our proposed approach for this particular sub-task is another contribution of this paper.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organised as follows.", "labels": [], "entities": []}, {"text": "First, we describe the scope detection task as well as the accompanying datasets in Section 2.", "labels": [], "entities": [{"text": "scope detection task", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.9369979103406271}]}, {"text": "Then in Section 3, we present how we approach the task.", "labels": [], "entities": []}, {"text": "Following that, in Section 4, various empirical results and corresponding analyses are discussed.", "labels": [], "entities": []}, {"text": "Finally, we summarize our work and discuss how the system can be further improved in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our feature sets are selected after doing a number of experiments by combining various potential feature types.", "labels": [], "entities": []}, {"text": "In these experiments, the system is trained on the training data and tested on development data.", "labels": [], "entities": []}, {"text": "Due to time limitation we could not do parameter tuning for CRF model training which we assume could further improve the results.", "labels": [], "entities": [{"text": "CRF model training", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8020298282305399}]}, {"text": "shows the results 3 on the development data using the feature sets described in Section 3.", "labels": [], "entities": []}, {"text": "There are two noticeable things in these results.", "labels": [], "entities": []}, {"text": "Firstly, there is a very high F 1 score (93.29%) obtained for negation cue identification.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9941075245539347}, {"text": "negation cue identification", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.9296956062316895}]}, {"text": "And secondly, the precision obtained for scope detection (97.92%) is very high as well.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9997774958610535}, {"text": "scope detection", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.95015549659729}]}, {"text": "tification) obtained before and after the usage of our proposed 5 phrasal clue feature types (using gold annotation of negation cues).", "labels": [], "entities": []}, {"text": "As we can see, there is a significant improvement in recall (almost 10 points) due to the usage of phrasal clues which ultimately leads to a considerable increase (almost 6.5 points) of F 1 score.", "labels": [], "entities": [{"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.999721109867096}, {"text": "F 1 score", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9910681843757629}]}, {"text": "shows official results of our system in the *SEM 2012 Shared Task (closed track) of scope detection, as provided by the organisers.", "labels": [], "entities": [{"text": "SEM 2012 Shared Task", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7632167637348175}, {"text": "scope detection", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.8050683736801147}]}, {"text": "It should be noted that the test dataset is almost 1.5 times bigger than the combined training corpus (i.e. training + development data).", "labels": [], "entities": []}, {"text": "Despite this fact, the results of cue and scope detection on the test data are almost similar as those on the development data.", "labels": [], "entities": []}, {"text": "However, there is a sharp drop (almost 4 points lower F 1 score) in negated event identification, primarily due to lower precision.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9795936147371928}, {"text": "negated event identification", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.7528850038846334}, {"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9983422756195068}]}, {"text": "This resulted in a lower F 1 score (almost 4.5 points) for full negation identification.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9931033054987589}, {"text": "negation identification", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.9793321788311005}]}], "tableCaptions": [{"text": " Table 1: Various statistics of the training, development  and test datasets.", "labels": [], "entities": []}, {"text": " Table 2: Example of the data provided for *SEM 2012 Shared Task.", "labels": [], "entities": [{"text": "SEM 2012 Shared Task", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.6371183693408966}]}, {"text": " Table 6: Negated event detection results on development  data with and without the 5 phrasal clue feature types.  The results are obtained using gold annotation of nega- tion cues. Note that, TP+FN is not the same. However, since these", "labels": [], "entities": [{"text": "Negated event detection", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6571076810359955}, {"text": "TP+FN", "start_pos": 193, "end_pos": 198, "type": "METRIC", "confidence": 0.8021447459856669}]}, {"text": " Table 7: Scope and negated event detection results on  development data with and without gold annotations of  negation cues. Note that, for negated events, TP+FN is not the same.", "labels": [], "entities": [{"text": "negated event detection", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.8516905705134074}, {"text": "TP+FN", "start_pos": 157, "end_pos": 162, "type": "METRIC", "confidence": 0.7893170118331909}]}, {"text": " Table 8: Results on the development data. In the \"B\" variant of the results, Precision = TP / System, instead of  Precision = TP / (TP + FP).", "labels": [], "entities": [{"text": "Precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.98600834608078}, {"text": "TP", "start_pos": 90, "end_pos": 92, "type": "METRIC", "confidence": 0.8538060188293457}, {"text": "FP", "start_pos": 138, "end_pos": 140, "type": "METRIC", "confidence": 0.7900572419166565}]}, {"text": " Table 9: Results on the *SEM 2012 Shared Task (closed track) test data provided by the organisers. In the \"B\" variant  of the results, Precision = TP / System, instead of Precision = TP / (TP + FP).", "labels": [], "entities": [{"text": "*SEM 2012 Shared Task (closed track) test data", "start_pos": 25, "end_pos": 71, "type": "DATASET", "confidence": 0.6472562957893718}, {"text": "FP", "start_pos": 195, "end_pos": 197, "type": "METRIC", "confidence": 0.8149998188018799}]}]}