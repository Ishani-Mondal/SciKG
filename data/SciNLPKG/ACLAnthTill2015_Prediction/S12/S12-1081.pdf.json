{"title": [{"text": "DSS: Text Similarity Using Lexical Alignments of Form, Distributional Semantics and Grammatical Relations", "labels": [], "entities": [{"text": "DSS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8612188100814819}, {"text": "Text Similarity", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.6794644743204117}]}], "abstractContent": [{"text": "In this paper we present our systems for the STS task.", "labels": [], "entities": [{"text": "STS task", "start_pos": 45, "end_pos": 53, "type": "TASK", "confidence": 0.9354645609855652}]}, {"text": "Our systems are all based on a simple process of identifying the components that correspond between two sentences.", "labels": [], "entities": []}, {"text": "Currently we use words (that is word forms), lem-mas, distributional similar words and grammatical relations identified with a dependency parser.", "labels": [], "entities": []}, {"text": "All systems only use open class words.", "labels": [], "entities": []}, {"text": "Our first system (alignheuristic) tries to obtain a mapping between every open class token using all the above sources of information.", "labels": [], "entities": []}, {"text": "Our second system (wordsim) uses a different algorithm and unlike alignheuristic, it does not use the dependency information.", "labels": [], "entities": []}, {"text": "The third system (average) simply takes the average of the scores for each item from the other two systems to take advantage of the merits of both systems.", "labels": [], "entities": [{"text": "average", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9636673927307129}]}, {"text": "For this reason we only provide a brief description of that.", "labels": [], "entities": []}, {"text": "The results are promising, with Pearson's coefficients on each individual dataset ranging from .3765 to .7761 for our relatively simple heuristics based systems that do not require training on different datasets.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9339265823364258}]}, {"text": "We provide some analysis of the results and also provide results for our data using Spearman's, which as a non-parametric measure which we argue is better able to reflect the merits of the different systems (average is ranked between the others).", "labels": [], "entities": []}], "introductionContent": [{"text": "Our motivation for the systems entered in the STS task () was to model the contribu- * The first author is a visiting scholar on the Erasmus Mundus Masters Program in ' tion of each linguistic component of both sentences to the similarity of the texts by finding an alignment.", "labels": [], "entities": [{"text": "Erasmus Mundus Masters Program", "start_pos": 133, "end_pos": 163, "type": "DATASET", "confidence": 0.661554642021656}]}, {"text": "Ultimately such a system could be exploited for ranking candidate paraphrases of a chunk of text of any length.", "labels": [], "entities": []}, {"text": "We envisage a system as outlined in the future work section.", "labels": [], "entities": []}, {"text": "The systems reported are simple baselines to such a system.", "labels": [], "entities": []}, {"text": "We have two main systems (alignheuristic and wordsim) and also a system which simply uses the average score for each item from the two main systems (average).", "labels": [], "entities": []}, {"text": "In our systems we: \u2022 only deal with open class words as tokens i.e. nouns, verbs, adjectives, adverbs.", "labels": [], "entities": []}, {"text": "alignheuristic and average also use numbers \u2022 assume that tokens have a 1:1 mapping \u2022 match: -word forms -lemmas -distributionally similar lemmas -(alignheuristic and average only) argument or head in a matched grammatical relation with a word that already has a lexical mapping \u2022 score the sentence pair based on the size of the overlap.", "labels": [], "entities": []}, {"text": "Different formulations of the score are used by our methods The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In the next section we make a brief mention of related work though of course there will be more pertinent related work presented and published at SemEval 2012.", "labels": [], "entities": [{"text": "SemEval 2012", "start_pos": 146, "end_pos": 158, "type": "DATASET", "confidence": 0.7589511871337891}]}, {"text": "In section 3 we give a detailed account of the systems and in section 4 we provide the results obtained on the training data on developing our systems.", "labels": [], "entities": []}, {"text": "In section 5 we present the results on the test data, along with a little analysis using the gold standard data.", "labels": [], "entities": [{"text": "gold standard data", "start_pos": 93, "end_pos": 111, "type": "DATASET", "confidence": 0.7945680816968282}]}, {"text": "In section 6 we conclude our findings and discuss our ideas for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on training data", "labels": [], "entities": []}, {"text": " Table 2: Results for the alignheuristic algorithm on  the training data: varying wt", "labels": [], "entities": []}, {"text": " Table 3: Results for the alignheuristic algorithm on  the training data: with and without tmtch and rmtch", "labels": [], "entities": []}, {"text": " Table 4: Number of token alignments for the different  matching processes", "labels": [], "entities": []}, {"text": " Table 5: Official results: Rank (out of 89) is shown in brackets", "labels": [], "entities": [{"text": "Rank", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9956480860710144}]}, {"text": " Table 7: Spearman's \u03c1 for the 5 datasets, 'all' and the average coefficient across the datasets", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.7531960209210714}]}]}