{"title": [{"text": "Zhijun Wu: Chinese Semantic Dependency Parsing with Third-Order Features", "labels": [], "entities": [{"text": "Chinese Semantic Dependency Parsing", "start_pos": 11, "end_pos": 46, "type": "TASK", "confidence": 0.631141684949398}]}], "abstractContent": [{"text": "This paper presents our system participated on SemEval-2012 task: Chinese Semantic Dependency Parsing.", "labels": [], "entities": [{"text": "SemEval-2012 task", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.9009431898593903}, {"text": "Chinese Semantic Dependency Parsing", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.5184018984436989}]}, {"text": "Our system extends the second-order MST model by adding two third-order features.", "labels": [], "entities": [{"text": "MST", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9383912682533264}]}, {"text": "The two third-order features are grand-sibling and tri-sibling.", "labels": [], "entities": []}, {"text": "In the decoding phase, we keep the k best results for each span.", "labels": [], "entities": []}, {"text": "After using the selected third-order features, our system presently achieves LAS of 61.58% ignoring punctuation tokens which is 0.15% higher than the result of purely second-order model on the test dataset.", "labels": [], "entities": [{"text": "LAS", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.999295711517334}]}], "introductionContent": [{"text": "Recently, semantic role labeling (SRL) has been a hot research topic.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8727986117204031}]}, {"text": "CoNLL shared tasks for joint parsing for syntactic and semantic dependencies both in the year.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9053964018821716}]}, {"text": "The SRL is traditionally implemented as two subtasks, argument identification and classification.", "labels": [], "entities": [{"text": "SRL", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.940510094165802}, {"text": "argument identification", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.725643664598465}]}, {"text": "However, there are some problems for the semantic representation method used by the semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.6850012342135111}]}, {"text": "For example, the SRL only considers the predicate-argument relations and ignores the relations between a noun and its modifier, the meaning of semantic roles is related with special predicates.", "labels": [], "entities": [{"text": "SRL", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.8739091753959656}]}, {"text": "In order to overcome those problems, semantic dependency parsing (SDP) is introduced.", "labels": [], "entities": [{"text": "semantic dependency parsing (SDP)", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7959663768609365}]}, {"text": "Semantic dependencies express semantic links between predicates and arguments and represent relations between entities and events in text.", "labels": [], "entities": []}, {"text": "The SDP is a kind of dependency parsing, and its task is to build a dependency structure for an input sentence and to label the semantic relation between a word and its head.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7293480634689331}]}, {"text": "However, semantic relations are different from syntactic relations, such as position independent.", "labels": [], "entities": []}, {"text": "shows the position independent of semantic relations for the sentence XiaoMing hit XiaoBai with a book today.", "labels": [], "entities": [{"text": "XiaoMing", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9150270819664001}, {"text": "XiaoBai", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.5140116810798645}]}, {"text": "Today, XiaoMing hit XiaoBai with a book.", "labels": [], "entities": [{"text": "XiaoMing", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.9307260513305664}, {"text": "XiaoBai", "start_pos": 20, "end_pos": 27, "type": "DATASET", "confidence": 0.8936169743537903}]}, {"text": "XiaoBai was hit by XiaoMing today with a book.", "labels": [], "entities": [{"text": "XiaoBai", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9757459759712219}, {"text": "XiaoMing", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.9582423567771912}]}, {"text": "With a book, XiaoMing hit XiaoBai today.", "labels": [], "entities": [{"text": "XiaoMing", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.8956702351570129}, {"text": "XiaoBai", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.830294132232666}]}, {"text": "XiaoMing hit XiaoBai with a book today.", "labels": [], "entities": [{"text": "XiaoMing", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9768651723861694}, {"text": "XiaoBai", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.8835242986679077}]}, {"text": "Although semantic relations are different from syntactic relations, yet they are identical in the dependency tree.", "labels": [], "entities": []}, {"text": "That means the methods used in syntactic dependency parsing can also be applied in SDP.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.6691349844137827}]}, {"text": "Two main approaches to syntactic dependency paring are Maximum Spanning Tree (MST) based dependency parsing and Transition based dependency parsing).", "labels": [], "entities": [{"text": "syntactic dependency paring", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.5974196493625641}, {"text": "dependency parsing", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.718891978263855}, {"text": "Transition based dependency parsing", "start_pos": 112, "end_pos": 147, "type": "TASK", "confidence": 0.5851887688040733}]}, {"text": "The main idea of MSTParser is to take dependency parsing as a problem of searching a maximum spanning tree (MST) in a directed graph (Dependency Tree).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7829732596874237}]}, {"text": "We see MSTParser a better chance to improve the parsing speed and MSTParser provides the stateof-the-art performance for both projective and nonprojective tree banks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9743838310241699}]}, {"text": "For the reasons above, we choose MSTParser as our SemEval-2012 shared task participating system basic framework.", "labels": [], "entities": []}], "datasetContent": [{"text": "As we all know that projective dependency parsing using edge based factorization can be processed by the Einster algorithm).", "labels": [], "entities": [{"text": "projective dependency parsing", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.6343146165211996}]}, {"text": "The corpus given by SemEval-2012 is consists of 10000 sentences converting into dependency structures from Chinese Penn Treebank randomly.", "labels": [], "entities": [{"text": "Chinese Penn Treebank", "start_pos": 107, "end_pos": 128, "type": "DATASET", "confidence": 0.8394466042518616}]}, {"text": "We find that none of non-projective sentence existing by testing the 8301 sentences in training data.", "labels": [], "entities": []}, {"text": "For this reason, we set the MSTParser into projective parsing mode.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8612491488456726}]}, {"text": "We perform a number of experiments where we compare the first-order, second-order and secondorder by adding third-order features proposed in the previous sections.", "labels": [], "entities": []}, {"text": "We train the model on the full training set which contains 8301 sentences totally.", "labels": [], "entities": []}, {"text": "We use 10 training iterations and projective decoding in the experiments.", "labels": [], "entities": []}, {"text": "Experimental results show that 10 training iterations are better than others.", "labels": [], "entities": []}, {"text": "After adjusting the features of third-order, our best result reaches the labeled attachment score of 62.48% on the developing dataset which ignores punctuation.", "labels": [], "entities": [{"text": "labeled attachment score", "start_pos": 73, "end_pos": 97, "type": "METRIC", "confidence": 0.8109093308448792}]}, {"text": "We submitted our currently best result to SemEval-2012 which is 61.58% on the test dataset.", "labels": [], "entities": [{"text": "SemEval-2012", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.7251524329185486}]}, {"text": "The results in show that by adding third-order features to second-order model, we improve the dependency parsing accuracies by 1.21% comparing to first-order model and 0.15% comparing to second-order model.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.759927898645401}]}], "tableCaptions": [{"text": " Table 5: Experimental results. Second-Order+ means  second-order model by adding third-order features.  Results are tested under the developping dataset which  contains the heads and semantic relations given by  organizer.", "labels": [], "entities": []}]}