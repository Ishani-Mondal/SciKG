{"title": [{"text": "Statistical Thesaurus Construction fora Morphologically Rich Language", "labels": [], "entities": [{"text": "Statistical Thesaurus Construction", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.5922124683856964}]}], "abstractContent": [{"text": "Corpus-based thesaurus construction for Morphologically Rich Languages (MRL) is a complex task, due to the morphological variability of MRL.", "labels": [], "entities": [{"text": "Corpus-based thesaurus construction for Morphologically Rich Languages (MRL)", "start_pos": 0, "end_pos": 76, "type": "TASK", "confidence": 0.6638595253229141}]}, {"text": "In this paper we explore alternative term representations, complemented by clustering of morphological variants.", "labels": [], "entities": []}, {"text": "We introduce a generic algorithmic scheme for thesaurus construction in MRL, and demonstrate the empirical benefit of our methodology fora Hebrew thesaurus.", "labels": [], "entities": [{"text": "thesaurus construction", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.7636665105819702}, {"text": "MRL", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.6045412421226501}]}], "introductionContent": [{"text": "Corpus-based thesaurus construction has been an active research area.", "labels": [], "entities": [{"text": "Corpus-based thesaurus construction", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.636442651351293}]}, {"text": "Typically, two statistical approaches for identifying semantic relationships between words were investigated: first-order, cooccurrence-based methods which assume that words that occur frequently together are topically related) and secondorder, distributional similarity methods, which suggest that words occurring within similar contexts are semantically similar.", "labels": [], "entities": []}, {"text": "While most prior work focused on English, we are interested in applying these methods to MRL.", "labels": [], "entities": [{"text": "MRL", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9731517434120178}]}, {"text": "Such languages, Hebrew in our case, are characterized by highly productive morphology which may produce as many as thousands of word forms fora given root form.", "labels": [], "entities": []}, {"text": "Thesauri usually provide related terms for each entry term (denoted target term).", "labels": [], "entities": []}, {"text": "Since both target and related terms correspond to word lemmas, statistics collection from the corpus would be most directly applied at the lemma level as well, using a morphological analyzer and tagger.", "labels": [], "entities": []}, {"text": "However, due to the rich and challenging morphology of MRL, such tools often have limited performance.", "labels": [], "entities": [{"text": "MRL", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9708758592605591}]}, {"text": "In our research, the accuracy of a state-of-the-art modern Hebrew tagger on across genre corpus was only about 60%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9997096657752991}]}, {"text": "Considering such limited performance of morphological processing, we propose a schematic methodology for generating a co-occurrence based thesaurus in MRL.", "labels": [], "entities": [{"text": "MRL", "start_pos": 151, "end_pos": 154, "type": "TASK", "confidence": 0.7869822382926941}]}, {"text": "In particular, we propose and investigate three options for term representation, namely surface form, lemma and multiple lemmas, supplemented with clustering of term variants.", "labels": [], "entities": [{"text": "term representation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7434591948986053}]}, {"text": "While the default lemma representation is dependent on tagger performance, the two other representations avoid choosing the right lemma for each word occurrence.", "labels": [], "entities": []}, {"text": "Instead, the multiple-lemma representation assumes that the right analysis will accumulate enough statistical prominence throughout the corpus, while the surface representation solves morphological disambiguation \"in retrospect\", by clustering term variants at the end of the extraction process.", "labels": [], "entities": []}, {"text": "As the methodology provides a generic scheme for exploring the alternative representation levels, each corpus and language-specific tool set might yield a different optimal configuration.", "labels": [], "entities": []}], "datasetContent": [{"text": "The results reported in this paper were obtained from a sample of 108 randomly selected terms from a list of 5000 terms, extracted from two publicly available term lists: the University of Haifa's entry list and Hebrew Wikipedia entries 6 . In our experiments, we compared the performance of the alternative 9 configurations by four commonly used IR measures: precision (P), relative recall (R), F1, and Average Precision (AP).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 360, "end_pos": 373, "type": "METRIC", "confidence": 0.9341447651386261}, {"text": "recall (R)", "start_pos": 384, "end_pos": 394, "type": "METRIC", "confidence": 0.9205330908298492}, {"text": "F1", "start_pos": 396, "end_pos": 398, "type": "METRIC", "confidence": 0.9972503781318665}, {"text": "Average Precision (AP)", "start_pos": 404, "end_pos": 426, "type": "METRIC", "confidence": 0.9604360103607178}]}, {"text": "We assumed that our automatically-generated candidate terms will be manually filtered, thus, recall becomes more important than precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9988096952438354}, {"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9979495406150818}]}, {"text": "Since we do not have any pre-defined thesaurus, we evaluated the relativerecall.", "labels": [], "entities": []}, {"text": "Our relative-recall considered the number of suitable related terms from the output of all methods as the full set of related terms.", "labels": [], "entities": []}, {"text": "As our system yielded a ranked sequence of related terms clusters, we also considered their ranking order.", "labels": [], "entities": []}, {"text": "Therefore, we adopted the recall-oriented AP for ranking).", "labels": [], "entities": [{"text": "recall-oriented AP", "start_pos": 26, "end_pos": 44, "type": "METRIC", "confidence": 0.8682242929935455}]}], "tableCaptions": [{"text": " Table 1: Performances of the nine configuratrions", "labels": [], "entities": []}]}