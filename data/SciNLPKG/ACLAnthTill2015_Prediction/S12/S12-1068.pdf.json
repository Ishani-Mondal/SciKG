{"title": [{"text": "ANNLOR: A Na\u00a8\u0131veNa\u00a8\u0131ve Notation-system for Lexical Outputs Ranking", "labels": [], "entities": [{"text": "ANNLOR", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7594681978225708}, {"text": "\u00a8\u0131veNa\u00a8\u0131ve", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.7192256078124046}]}], "abstractContent": [{"text": "This paper presents the systems we developed while participating in the first task (English Lexical Simplification) of SemEval 2012.", "labels": [], "entities": [{"text": "English Lexical Simplification) of SemEval 2012", "start_pos": 84, "end_pos": 131, "type": "TASK", "confidence": 0.7284310970987592}]}, {"text": "Our first system relies on n-grams frequencies computed from the Simple English Wikipedia version, ranking each substitution term by decreasing frequency of use.", "labels": [], "entities": [{"text": "Simple English Wikipedia version", "start_pos": 65, "end_pos": 97, "type": "DATASET", "confidence": 0.9161657243967056}]}, {"text": "We experimented with several other systems, based on term frequencies , or taking into account the context in which each substitution term occurs.", "labels": [], "entities": []}, {"text": "On the evaluation corpus, we achieved a 0.465 score with the first system.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we present the methods we used while participating to the Lexical Simplification task at SemEval 2012).", "labels": [], "entities": [{"text": "Lexical Simplification task at SemEval 2012", "start_pos": 73, "end_pos": 116, "type": "TASK", "confidence": 0.768826444943746}]}, {"text": "We experimented with several methods: \u2022 using word frequencies or other statistical figures from the BNC corpus, Google Books NGrams, the Simple English Wikipedia, and results from the Bing search engine (with/without lemmatization); \u2022 using association measures fora word and its context based on language models (with/without inflection); \u2022 making a combination of previous methods with SVMRank.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 101, "end_pos": 111, "type": "DATASET", "confidence": 0.9706827998161316}, {"text": "Google Books NGrams", "start_pos": 113, "end_pos": 132, "type": "DATASET", "confidence": 0.8389151891072592}, {"text": "Simple English Wikipedia", "start_pos": 138, "end_pos": 162, "type": "DATASET", "confidence": 0.7120798627535502}, {"text": "SVMRank", "start_pos": 389, "end_pos": 396, "type": "DATASET", "confidence": 0.9113408327102661}]}, {"text": "Depending on the results obtained on the training corpus, we chose the methods that seemed to best fit the data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of distinct n-grams extracted from the  Simple English Wikipedia", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.852202037970225}]}, {"text": " Table 3: Results obtained with frequency-based methods,  on the trial corpus", "labels": [], "entities": []}, {"text": " Table 4: Results obtained with Microsoft Web N-gram  Service, on the trial corpus", "labels": [], "entities": []}, {"text": " Table 5: Results obtained with combination of methods  with SVMRank, on the trial corpus", "labels": [], "entities": [{"text": "SVMRank", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.844117283821106}]}]}