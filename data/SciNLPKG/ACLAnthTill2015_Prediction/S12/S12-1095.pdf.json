{"title": [{"text": "DERI&UPM: Pushing Corpus Based Relatedness to Similarity: Shared Task System Description", "labels": [], "entities": [{"text": "UPM", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.7115004658699036}, {"text": "Pushing Corpus Based Relatedness to Similarity", "start_pos": 10, "end_pos": 56, "type": "TASK", "confidence": 0.8051843444506327}]}], "abstractContent": [{"text": "In this paper, we describe our system submitted for the semantic textual similarity (STS) task at SemEval 2012.", "labels": [], "entities": [{"text": "semantic textual similarity (STS) task at SemEval 2012", "start_pos": 56, "end_pos": 110, "type": "TASK", "confidence": 0.7925762444734573}]}, {"text": "We implemented two approaches to calculate the degree of similarity between two sentences.", "labels": [], "entities": []}, {"text": "First approach combines corpus-based semantic relatedness measure over the whole sentence with the knowledge-based semantic similarity scores obtained for the words falling under the same syntactic roles in both the sentences.", "labels": [], "entities": []}, {"text": "We fed all these scores as features to machine learning models to obtain a single score giving the degree of similarity of the sentences.", "labels": [], "entities": []}, {"text": "Linear Regression and Bagging models were used for this purpose.", "labels": [], "entities": [{"text": "Regression", "start_pos": 7, "end_pos": 17, "type": "METRIC", "confidence": 0.9255136847496033}, {"text": "Bagging", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.5482074618339539}]}, {"text": "We used Explicit Semantic Analysis (ESA) as the corpus-based semantic relatedness measure.", "labels": [], "entities": [{"text": "Explicit Semantic Analysis (ESA", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.6814579367637634}]}, {"text": "For the knowledge-based semantic similarity between words, a modified WordNet based Lin measure was used.", "labels": [], "entities": [{"text": "WordNet based Lin measure", "start_pos": 70, "end_pos": 95, "type": "METRIC", "confidence": 0.7517314702272415}]}, {"text": "Second approach uses a bipartite based method over the WordNet based Lin measure, without any modification.", "labels": [], "entities": [{"text": "WordNet based Lin measure", "start_pos": 55, "end_pos": 80, "type": "DATASET", "confidence": 0.8161846995353699}]}, {"text": "This paper shows a significant improvement in calculating the semantic similarity between sentences by the fusion of the knowledge-based similarity measure and the corpus-based relatedness measure against corpus based measure taken alone.", "labels": [], "entities": []}], "introductionContent": [{"text": "Similarity between sentences is a central concept of text analysis, however previous studies about semantic similarities have mainly focused either on single word similarity or complete document similarity.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 53, "end_pos": 66, "type": "TASK", "confidence": 0.75721874833107}]}, {"text": "Sentence similarity can be defined by the degree of semantic equivalence of two given sentences, where sentences are typically 10-20 words long.", "labels": [], "entities": [{"text": "Sentence similarity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9368790686130524}]}, {"text": "The role of sentence semantic similarity measures in text-related research is increasing due to potential number of applications such as document summarization, question answering, information extraction & retrieval and machine translation.", "labels": [], "entities": [{"text": "sentence semantic similarity", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.7149712642033895}, {"text": "document summarization", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.6849780678749084}, {"text": "question answering", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.8899023532867432}, {"text": "information extraction & retrieval", "start_pos": 181, "end_pos": 215, "type": "TASK", "confidence": 0.8383791297674179}, {"text": "machine translation", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.8017327785491943}]}, {"text": "One plausible limitation of existing methods for sentence similarity is their adaptation from long text (e.g. documents) similarity methods, where word co-occurrence plays a significant role.", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7296383231878281}]}, {"text": "However, sentences are too short, thats why taking syntactic role of each word with its narrow semantic meaning into account, can be highly relevant to reflect the semantic equivalence of two sentences.", "labels": [], "entities": []}, {"text": "These narrow semantics can be reflected from any existing large lexicons and; nevertheless, these lexicons cannot provide the semantics of words which are out of lexicon (e.g. guy) or multiword expressions.", "labels": [], "entities": []}, {"text": "These semantics can be represented by a large distributed semantic space such as Wikipedia and similarity can be reflected by relatedness of these extracted semantics.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 81, "end_pos": 90, "type": "DATASET", "confidence": 0.9630060791969299}, {"text": "similarity", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9773741960525513}]}, {"text": "However, relatedness covers broader space than similarity, which forced us to tune the Wikipedia based relatedness with lexical structure (e.g. WordNet) based similarities driven by linguistic syntactic structure, in reflecting more sophisticated similarity of two given sentences.", "labels": [], "entities": []}, {"text": "In this work, we present a sentence similarity using ESA and syntactic similarities.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 explores the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our approaches in detail.", "labels": [], "entities": []}, {"text": "Section 4 explains our three different submitted runs for STS task.", "labels": [], "entities": [{"text": "STS task", "start_pos": 58, "end_pos": 66, "type": "TASK", "confidence": 0.72747403383255}]}, {"text": "Section 5 shows the results and finally we conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Overall Rank and Pearson Correlation of all runs", "labels": [], "entities": [{"text": "Overall Rank", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8487022519111633}, {"text": "Pearson", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9991151690483093}, {"text": "Correlation", "start_pos": 35, "end_pos": 46, "type": "METRIC", "confidence": 0.6979930400848389}]}, {"text": " Table 2: Pearson Correlation of all runs with all five STS test datasets", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8480809926986694}, {"text": "STS test datasets", "start_pos": 56, "end_pos": 73, "type": "DATASET", "confidence": 0.6925168732802073}]}]}