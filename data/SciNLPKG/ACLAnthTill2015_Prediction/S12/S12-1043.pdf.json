{"title": [{"text": "UMichigan: A Conditional Random Field Model for Resolving the Scope of Negation", "labels": [], "entities": [{"text": "UMichigan", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9208394289016724}, {"text": "Resolving the Scope of Negation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.8492656350135803}]}], "abstractContent": [{"text": "In this paper, we present a system for detecting negation in English text.", "labels": [], "entities": [{"text": "detecting negation in English text", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.8090323686599732}]}, {"text": "We address three tasks: negation cue detection, negation scope resolution and negated event identification.", "labels": [], "entities": [{"text": "negation cue detection", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.9371487100919088}, {"text": "negation scope resolution", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.931917150815328}, {"text": "negated event identification", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.901126484076182}]}, {"text": "We pose these tasks as sequence labeling problems.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6992121934890747}]}, {"text": "For each task, we train a Conditional Random Field (CRF) model on lexical, structural, and syntactic features extracted from labeled data.", "labels": [], "entities": []}, {"text": "The models are trained and tested using the dataset distributed with the *sem Shared Task 2012 on resolving the scope and focus of negation.", "labels": [], "entities": []}, {"text": "The system detects negation cues with 90.98% F1 measure (94.3% and 87.88% recall).", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9845775365829468}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9969937801361084}]}, {"text": "It identifies negation scope with 82.70% F1 on token-by-token level and 64.78% F1 on full scope level.", "labels": [], "entities": [{"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9981502294540405}, {"text": "F1", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9987381100654602}]}, {"text": "Negated events are detected with 51.10% F1 measure.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9869056642055511}]}], "introductionContent": [{"text": "Negation is a linguistic phenomenon present in all languages.", "labels": [], "entities": []}, {"text": "The semantic function of negation is to transform an affirmative statement into its opposite meaning.", "labels": [], "entities": []}, {"text": "The automatic detection of negation and its scope is a problem encountered in a wide range of natural language processing applications including, but not limited to, data mining, relation extraction, question answering, and sentiment analysis.", "labels": [], "entities": [{"text": "automatic detection of negation", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.7913820445537567}, {"text": "data mining", "start_pos": 166, "end_pos": 177, "type": "TASK", "confidence": 0.7917408645153046}, {"text": "relation extraction", "start_pos": 179, "end_pos": 198, "type": "TASK", "confidence": 0.8624562323093414}, {"text": "question answering", "start_pos": 200, "end_pos": 218, "type": "TASK", "confidence": 0.9160510003566742}, {"text": "sentiment analysis", "start_pos": 224, "end_pos": 242, "type": "TASK", "confidence": 0.9575930833816528}]}, {"text": "For example, failing to account for negation may result in giving wrong answers in question answering systems or in the prediction of opposite sentiment in sentiment analysis systems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7613527476787567}, {"text": "prediction of opposite sentiment in sentiment analysis", "start_pos": 120, "end_pos": 174, "type": "TASK", "confidence": 0.762753563267844}]}, {"text": "The occurrence of negation in a sentence is determined by the presence of a negation cue.", "labels": [], "entities": []}, {"text": "A negation cue is a word, a phrase, a prefix, or a postfix that triggers negation.", "labels": [], "entities": []}, {"text": "Scope of negation is the part of the meaning that is negated).", "labels": [], "entities": []}, {"text": "The negated event is the event or the entity that the negation indicates its absence or denies its occurrence.", "labels": [], "entities": []}, {"text": "For example, in the sentence below never is the negation cue.", "labels": [], "entities": []}, {"text": "The scope is enclosed in square brackets.", "labels": [], "entities": []}, {"text": "The negated event is underlined.", "labels": [], "entities": []}, {"text": "[Andrew had] never [liked smart phones], but he received one as a gift last week and started to use it.", "labels": [], "entities": []}, {"text": "Negation cues and scopes maybe discontinuous.", "labels": [], "entities": [{"text": "Negation cues and scopes", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7675147503614426}]}, {"text": "For example, the negation cue neither ...", "labels": [], "entities": []}, {"text": "In this chapter, we present a system for automatically detecting negation cues, negated events, and negation scopes in English text.", "labels": [], "entities": [{"text": "negation scopes in English text", "start_pos": 100, "end_pos": 131, "type": "TASK", "confidence": 0.8531620502471924}]}, {"text": "The system uses conditional random field (CRF) models trained on labeled sentences extracted from two classical English novels.", "labels": [], "entities": []}, {"text": "The CRF models are trained using lexical, structural, and syntactic features.", "labels": [], "entities": []}, {"text": "The experiments show promising results.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews previous work.", "labels": [], "entities": []}, {"text": "Section 3 describes the data.", "labels": [], "entities": []}, {"text": "Section 4 describes the CRFs models.", "labels": [], "entities": []}, {"text": "Section 5 presents evaluation, results, and discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the testing set described in Section 3 to evaluate the system.", "labels": [], "entities": []}, {"text": "The testing set contains 1089 sentences 235 of which contains at least one negation.", "labels": [], "entities": []}, {"text": "We use the standard precision, recall, and fmeasure metrics to evaluate the system.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9994745850563049}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.998362123966217}, {"text": "fmeasure", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9708898663520813}]}, {"text": "We perform the evaluation on different levels: 1.", "labels": [], "entities": []}, {"text": "Cues: the metrics are computed only for cue detection.", "labels": [], "entities": [{"text": "cue detection", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.8226227760314941}]}, {"text": "2. Scope (tokens): the metrics are calculated at token level.", "labels": [], "entities": []}, {"text": "If a sentence has 2 scopes, one with 5 tokens and another with 4, the total number of scope tokens is 9. 3. Scope (full): the metrics are calculated at the full scope level.", "labels": [], "entities": []}, {"text": "Both the negation cue and the whole scope should be correctly identified.", "labels": [], "entities": []}, {"text": "If a sentence contains 2 negation cues, then 2 scopes are checked.", "labels": [], "entities": []}, {"text": "We report two values here one the requires the cue match correctly and one that does not.: Results of negation cue, negated event, and negation scope detection 5.", "labels": [], "entities": [{"text": "negation scope detection", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.9015783667564392}]}, {"text": "Full negation: the metrics are computed for all the three tasks at once and requiring everything to match correctly.", "labels": [], "entities": []}, {"text": "For cue, scope and negated event to be correct, both the tokens and the words or parts of words have to be correctly identified.", "labels": [], "entities": []}, {"text": "The final periods in abbreviations are disregarded.", "labels": [], "entities": []}, {"text": "If gold has value \"Mr.\" and system \"Mr\", system is counted as correct.", "labels": [], "entities": []}, {"text": "Also, punctuation tokens are *not* taken into account for evaluation.", "labels": [], "entities": []}, {"text": "Two variants of the metrics are computed.", "labels": [], "entities": []}, {"text": "In the first variant (A), precision is calculated as tp / (tp + fp) and recall is calculated as tp / (tp + fn) where tp is the count of true positive labels, fp is the count of false positive labels, and fn is the count of false negative labels.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9995811581611633}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9992426633834839}]}, {"text": "In variant B, the precision is calculated differently, using the formula precision = tp / system.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9993282556533813}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9963020086288452}]}, {"text": "shows the results of our system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results of negation cue, negated event, and negation scope detection", "labels": [], "entities": [{"text": "negation cue", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.9365080893039703}, {"text": "negation scope detection", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.9643696149190267}]}]}