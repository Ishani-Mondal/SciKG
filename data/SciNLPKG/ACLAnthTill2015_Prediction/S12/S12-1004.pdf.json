{"title": [{"text": "Towards Building a Multilingual Semantic Network: Identifying Interlingual Links in Wikipedia", "labels": [], "entities": [{"text": "Identifying Interlingual Links", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.865893026192983}, {"text": "Wikipedia", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.4562011659145355}]}], "abstractContent": [{"text": "Wikipedia is a Web based, freely available multilingual encyclopedia, constructed in a collaborative effort by thousands of contributors.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9014895558357239}]}, {"text": "Wikipedia articles on the same topic in different languages are connected via interlin-gual (or translational) links.", "labels": [], "entities": []}, {"text": "These links serve as an excellent resource for obtaining lexical translations, or building multilingual dictionaries and semantic networks.", "labels": [], "entities": [{"text": "obtaining lexical translations", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6442556579907736}]}, {"text": "As these links are manually built, many links are missing or simply wrong.", "labels": [], "entities": []}, {"text": "This paper describes a supervised learning method for generating new links and detecting existing incorrect links.", "labels": [], "entities": []}, {"text": "Since there is no dataset available to evaluate the resulting interlingual links, we create our own gold standard by sampling translational links from four language pairs using distance heuristics.", "labels": [], "entities": []}, {"text": "We manually annotate the sampled translation links and used them to evaluate the output of our method for automatic link detection and correction.", "labels": [], "entities": [{"text": "link detection and correction", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.7262675166130066}]}], "introductionContent": [{"text": "In recent years, Wikipedia has been used as a resource of world knowledge in many natural language processing applications.", "labels": [], "entities": []}, {"text": "A diverse set of tasks such as text categorization, information extraction, information retrieval, question answering, word sense disambiguation, semantic relatedness, and named entity recognition have been shown to benefit from the semi-structured text of Wikipedia.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.795091837644577}, {"text": "information retrieval", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7975585758686066}, {"text": "question answering", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.8505001664161682}, {"text": "word sense disambiguation", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.7004257440567017}, {"text": "named entity recognition", "start_pos": 172, "end_pos": 196, "type": "TASK", "confidence": 0.6326838831106821}]}, {"text": "Most approaches that use the world knowledge encoded in Wikipedia are statistical in nature and therefore their performance depends significantly on the size of Wikipedia.", "labels": [], "entities": []}, {"text": "Currently, the English Wikipedia alone has four million articles.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 15, "end_pos": 32, "type": "DATASET", "confidence": 0.8929712176322937}]}, {"text": "However, the combined Wikipedias for all other languages greatly exceed the English Wikipedia in size, yielding a combined total of more than 10 million articles in more than 280 languages.", "labels": [], "entities": []}, {"text": "The rich hyperlink structure of these Wikipedia corpora in different languages can be very useful in identifying various relationships between concepts.", "labels": [], "entities": []}, {"text": "Wikipedia articles on the same topic in different languages are often connected through interlingual links.", "labels": [], "entities": []}, {"text": "These links are the small navigation links that show up in the \"Languages\" sidebar inmost Wikipedia articles, and they connect an article with related articles in other languages.", "labels": [], "entities": []}, {"text": "For instance, the interlingual links for the Wikipedia article about \"Football\" connect it to 20 articles in 20 different languages.", "labels": [], "entities": [{"text": "Wikipedia article about \"Football\"", "start_pos": 45, "end_pos": 79, "type": "DATASET", "confidence": 0.7476938366889954}]}, {"text": "In the ideal case, a set of articles connected directly or indirectly via such links would all describe the same entity or concept.", "labels": [], "entities": []}, {"text": "However, these links are produced either by polyglot editors or by automatic bots.", "labels": [], "entities": []}, {"text": "Editors commonly make mistakes by linking articles that have conceptual drift, or by linking to a concept at a different level of granularity.", "labels": [], "entities": []}, {"text": "For instance, if a corresponding article in one of the languages does not exist, a similar article or a more general article about the concept is sometimes linked instead.", "labels": [], "entities": []}, {"text": "Various bots also add new interlingual links or attempt to correct existing ones.", "labels": [], "entities": []}, {"text": "The downside of a bot is that an error in a translational link created by editors in Wikipedia for one language propagates to Wikipedias in other languages.", "labels": [], "entities": []}, {"text": "Thus, if a bot introduces a wrong link, one may have to search for Language Code The contributions of the research described in this paper are two-fold.", "labels": [], "entities": []}, {"text": "First, we describe the construction of a dataset of interlingual links that are automatically sampled from Wikipedia based on a set of distance heuristics.", "labels": [], "entities": []}, {"text": "This dataset is manually annotated in order to enable the evaluation of methods for translational link detection.", "labels": [], "entities": [{"text": "translational link detection", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.9362558325131735}]}, {"text": "Second, we describe an automatic model for correcting existing links and creating new links, with the aim of obtaining a more stable set of interlingual links.", "labels": [], "entities": []}, {"text": "The model's parameters are estimated on the manually labeled dataset using a supervised machine learning approach.", "labels": [], "entities": []}, {"text": "The remaining of this paper is organized as follows: Section 2 briefly describes Wikipedia and the relevant terminology.", "labels": [], "entities": []}, {"text": "Section 3 introduces our method of identifying a candidate set of translational links based on distance heuristics, while Section 4 introduces the methodology for building a manually annotated dataset.", "labels": [], "entities": []}, {"text": "Section 5 describes the machine learning experiments for detecting or correcting interlingual links.", "labels": [], "entities": [{"text": "detecting or correcting interlingual links", "start_pos": 57, "end_pos": 99, "type": "TASK", "confidence": 0.8432576060295105}]}, {"text": "Finally, we present related work in Section 6, and concluding remarks in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The translation links in Wikipedia, whether added by the Wikipedia editors (direct links), or inferred by the heuristics described in the previous section, are not guaranteed for quality.", "labels": [], "entities": []}, {"text": "In fact, previous work (de Melo and Weikum, 2010b) has shown that a large number of the links created by the Wikipedia users are incorrect, connecting articles that are not translations of each other, subsections of articles, or disambiguation pages.", "labels": [], "entities": []}, {"text": "We have therefore decided to run a manual annotation study in order to determine the quality of the interlingual links.", "labels": [], "entities": []}, {"text": "The resulting annotation can serve both as a gold standard for evaluating the quality of predicted links, and as supervision fora machine learning model that would automatically detect translation links.", "labels": [], "entities": []}, {"text": "From the large pool of links directly available in Wikipedia or inferred automatically through symmetry and transitivity, we sampled and then manually annotated 195 pairs of articles for each of four language pairs: (English, German), (English, Spanish), (Italian, French), and (Spanish, Italian).", "labels": [], "entities": []}, {"text": "The four language pairs were determined based on the native or near-native knowledge available in the group of annotators in our research group.", "labels": [], "entities": []}, {"text": "The sampling of the article pairs was done such that it covers all the potentially interesting cases obtained by combining the heuristics used to identify interlingual links.", "labels": [], "entities": []}, {"text": "The left side of shows the combination of heuristics used to select the article pairs.", "labels": [], "entities": []}, {"text": "For each such combination, and for each language pair, we randomly selected 15 articles.", "labels": [], "entities": []}, {"text": "Furthermore, we added 15 randomly selected pairs for the highest quality combination (Case 1).", "labels": [], "entities": []}, {"text": "For each language pair, the sampled links were annotated by one human judge, with the exception of the (English, Spanish) dataset, which was annotated by two judges so that we could measure the interannotator agreement.", "labels": [], "entities": []}, {"text": "The annotators were asked to check the articles in each link and annotate the link on a scale from 0 to 4, as follows: 4: Identical concepts that are perfect translations of each other.", "labels": [], "entities": []}, {"text": "3: Concepts very close in meaning, which are good translations of each other, but a better translation for one of the concepts in the pair also exists.", "labels": [], "entities": []}, {"text": "The annotators are not required to identify a better translation in Wikipedia, they only have to use their own knowledge of the language, e.g. \"building\" (English) maybe a good translation for \"tore\" (Spanish), yet a better translation is known to exist.", "labels": [], "entities": []}, {"text": "To determine the quality of the annotations, we ran an inter-annotator study for the (EnglishSpanish) language pair.", "labels": [], "entities": []}, {"text": "The two annotators had a Pearson correlation of 70%, which indicates good agreement.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 25, "end_pos": 44, "type": "METRIC", "confidence": 0.9630789756774902}]}, {"text": "We also calculated their agreement when grouping the ratings from 0 to 4 in only two categories: 0, 1, and 2 were mapped to no translation, whereas 3 and 4 were mapped to translation.", "labels": [], "entities": []}, {"text": "On this coarse scale, the annotators agreed 84% of the time, with a kappa value of 0.61, which once again indicate good agreement.", "labels": [], "entities": []}, {"text": "The annotations are summarized in the right side of.", "labels": [], "entities": []}, {"text": "For each quality rating, the table shows the number of links annotated with that rating.", "labels": [], "entities": []}, {"text": "Note that this is a summary over the annotations of five annotators, corresponding to the four language pairs, as well as an additional annotation for.", "labels": [], "entities": []}, {"text": "Not surprisingly, the links that are \"supported\" by all the heuristics considered (Case 1) are the links with the highest quality.", "labels": [], "entities": []}, {"text": "These are interlingual links that are present in Wikipedia and that can also be inferred through transitive path heuristics.", "labels": [], "entities": []}, {"text": "Interestingly, links that are only guaranteed to have a direct link (DL) and no reverse link (RL) (Case 2) have a rather low quality, with only 68% of the links being considered to represent a perfect or a good translation (score of 3 or 4).", "labels": [], "entities": [{"text": "reverse link (RL)", "start_pos": 80, "end_pos": 97, "type": "METRIC", "confidence": 0.7068121552467346}]}, {"text": "summarizes the annotations per language pair.", "labels": [], "entities": []}, {"text": "There appear to be some differences in the quality of interlingual links extracted or inferred for different languages, with (Spanish, Italian) being the pair with the highest quality of links (76% of the links are either perfect or good translations), while English to German seems to have the lowest quality (only 57% of the links are perfect or good).", "labels": [], "entities": []}, {"text": "For the (English, Spanish) pair, we used the average of the two annotators' ratings, rounded up to the nearest integer.", "labels": [], "entities": []}, {"text": "The manual annotations described above are good indicators of the quality of the interlingual links that can be extracted and inferred in Wikipedia.", "labels": [], "entities": []}, {"text": "But such manual annotations, because of the human effort involved, do not scale up, and therefore we cannot apply them on the entire interlingual Wikipedia graph to determine the links that should be preserved or the ones that should be removed.", "labels": [], "entities": [{"text": "Wikipedia graph", "start_pos": 146, "end_pos": 161, "type": "DATASET", "confidence": 0.753066748380661}]}, {"text": "Instead, we experiment with training machine learning models that would automatically determine the quality of an interlingual link.", "labels": [], "entities": []}, {"text": "As features, we use the presence or absence of director symmetric links, along with the number of inferred paths of length k = 2, 3, 4, as defined in Section 3.", "labels": [], "entities": []}, {"text": "shows the feature vectors for the same four pairs of articles that were used in.", "labels": [], "entities": []}, {"text": "The feature values are computed based on the sample network of interlingual links from.", "labels": [], "entities": []}, {"text": "Each feature vector is assigned a numerical class, corresponding to the manual annotation provided by the human judges.", "labels": [], "entities": []}, {"text": "We conduct two experiments, at a fine-grained and a coarse-grained level.", "labels": [], "entities": []}, {"text": "In both experiments, we use all the annotations for all four language pairs together (i.e., a total of 780 examples), and perform evaluations in a ten-fold cross validation scenario.", "labels": [], "entities": []}, {"text": "For the fine-grained experiments, we use all five numerical classes in a linear regression model.", "labels": [], "entities": []}, {"text": "We determine the correctness of the predictions on the test data by calculating the Pearson correlation with respect to the gold standard.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 84, "end_pos": 103, "type": "METRIC", "confidence": 0.9787412285804749}, {"text": "gold standard", "start_pos": 124, "end_pos": 137, "type": "DATASET", "confidence": 0.8796368837356567}]}, {"text": "The resulting correlation was measured at 0.461.", "labels": [], "entities": [{"text": "correlation", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.9868413209915161}]}, {"text": "For comparison, we also run an experiment where we only keep the presence or absence of the direct links as a feature (DL).", "labels": [], "entities": []}, {"text": "In this case, the correlation was measured at 0.418, which is substantially below the correlation obtained when using all the features.", "labels": [], "entities": [{"text": "correlation", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9911419153213501}]}, {"text": "This indicates that the interlingual links inferred through our heuristics are indeed useful.", "labels": [], "entities": []}, {"text": "In the coarse-grained experiments, the quality ratings 0, 1, and 2 are mapped to the no translation label, while ratings 3 and 4 are mapped to the translation label.", "labels": [], "entities": []}, {"text": "We used the Ada Boost classifier with decision stumps as the binary classification algorithm.", "labels": [], "entities": []}, {"text": "When using the entire feature vectors, the accuracy is measured at 73.97%, whereas the use of only the direct links results in an accuracy of 69.35%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9997088313102722}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9994003772735596}]}, {"text": "Similar to the fine-grained linear regression experiments, these coarse-grained experiments further validate the utility of the interlingual links inferred through the transitive path heuristics.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of articles, redirects, and users for the top nine Wikipedia editions plus Chinese. The total number  of articles also includes the disambiguation pages.", "labels": [], "entities": []}, {"text": " Table 6: Number of annotations on a scale of 0-4 for each  pair of languages", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9641122817993164}]}, {"text": " Table 5: Left side of the table: distance heuristics and number of samples based on each distance heuristic. 'y' indicates  that the corresponding path should exist, 'n' indicates that the corresponding path should not exist, '-' indicates that  we don't care whether the corresponding path exists or not. Right side of the table: manual annotations of the quality  of links, on a scale of 0 to 4, with 4 meaning perfect translations.", "labels": [], "entities": []}, {"text": " Table 7: Examples of feature vectors generated for four interlingual links, corresponding to the concept pairs listed in", "labels": [], "entities": []}]}