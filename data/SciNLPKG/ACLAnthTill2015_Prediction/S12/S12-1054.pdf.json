{"title": [{"text": "EMNLP@CPH: Is frequency all there is to simplicity?", "labels": [], "entities": [{"text": "EMNLP@CPH", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.714577297369639}]}], "abstractContent": [{"text": "Our system breaks down the problem of ranking a list of lexical substitutions according to how simple they are in a given context into a series of pairwise comparisons between candidates.", "labels": [], "entities": []}, {"text": "For this we learn a binary classifier.", "labels": [], "entities": []}, {"text": "As only very little training data is provided, we describe a procedure for generating artificial unlabeled data from Wordnet and a corpus and approach the classification task as a semi-supervised machine learning problem.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.9574666023254395}]}, {"text": "We use a co-training procedure that lets each classi-fier increase the other classifier's training set with selected instances from an unlabeled data set.", "labels": [], "entities": []}, {"text": "Our features include n-gram probabilities of candidate and context in a web corpus, dis-tributional differences of candidate in a corpus of \"easy\" sentences and a corpus of normal sentences, syntactic complexity of documents that are similar to the given context, candidate length, and letter-wise recognizability of candidate as measured by a trigram character language model.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes a system for the SemEval 2012 English Lexical Simplification shared task.", "labels": [], "entities": [{"text": "SemEval 2012 English Lexical Simplification shared task", "start_pos": 38, "end_pos": 93, "type": "TASK", "confidence": 0.9127801486424038}]}, {"text": "The task description uses a loose definition of simplicity, defining \"simple words\" as \"words that can be understood by a wide variety of people, including for example people with low literacy levels or some cognitive disability, children, and non-native speakers of English\"", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments we vary feature-split, size of unlabeled data, and number of iterations.", "labels": [], "entities": []}, {"text": "The first feature split, S\uf779\uf76e-SW, pooled all syntactic complexity features and Wikipedia-based features in one view, with the remaining feature groups in another view.", "labels": [], "entities": []}, {"text": "Our second feature split, S\uf779\uf76e-C\uf768\uf761\uf772-L\uf765\uf76e, combined the syntactic complexity features with the character trigram language model features and the basic word length features.", "labels": [], "entities": []}, {"text": "Both splits produced a pair of classifiers with similar performance-each had an F-score of around .73 and an oracle score of .87 on the trial set on the binary decision problem, and both splits performed equally on the ranking task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9989099502563477}]}, {"text": "With a large unlabeled data set available, the classifiers can avoid picking and labeling data points with a low certainty, at least initially.", "labels": [], "entities": []}, {"text": "The assumption is that this will give us a higher quality training set.", "labels": [], "entities": []}, {"text": "However, as can be seen in, none of our systems are benefitting from the additional data.", "labels": [], "entities": []}, {"text": "In fact, the systems learn more when the pool of unlabeled data is restricted to the test set.", "labels": [], "entities": []}, {"text": "Our submitted systems, O\uf772\uf7641 and O\uf772\uf7642 scored 0.405 and 0.393 on the test set, and 0.494 and 0.500 on the trial set.", "labels": [], "entities": []}, {"text": "Following submission we adjusted a parameter 7 and re-ran each split with both U and U test . We analyzed the performance by part of speech and compared them to the frequency baseline as shown in.", "labels": [], "entities": []}, {"text": "For the frequency baseline, performance is better on adverbs and adjectives alone, and somewhat worse on nouns.", "labels": [], "entities": []}, {"text": "Both our systems benefit from co-training on all word classes.", "labels": [], "entities": []}, {"text": "S\uf779\uf76e-C\uf768\uf761\uf772-L\uf765\uf76e, our best performing system, notably has a score reduction (compared to the baseline) of only 5% on adverbs, eliminates the score reduction on nouns, and effectively beats the baseline score on verbs with a 6% increase.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pearson's r correlations. The table shows  the three highest correlated features per group, all of  which are significant at the p < 0.01 level", "labels": [], "entities": [{"text": "Pearson's r correlations", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.6793151423335075}]}, {"text": " Table 2: Performance on part of speech. Unlabeled  set was U test . Subscripts tell whether the scores are  from the first or last iteration", "labels": [], "entities": [{"text": "U test", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9062091410160065}]}]}