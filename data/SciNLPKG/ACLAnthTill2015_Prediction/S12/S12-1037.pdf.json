{"title": [{"text": "UCM-I: A Rule-based Syntactic Approach for Resolving the Scope of Negation", "labels": [], "entities": [{"text": "UCM-I", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7971024513244629}, {"text": "Resolving the Scope of Negation", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.8565226078033448}]}], "abstractContent": [{"text": "This paper presents one of the two contributions from the Universidad Complutense de Madrid to the *SEM Shared Task 2012 on Resolving the Scope and Focus of Negation.", "labels": [], "entities": [{"text": "SEM Shared Task 2012", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.7670676112174988}, {"text": "Resolving the Scope", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7655856410662333}]}, {"text": "We describe a rule-based system for detecting the presence of negations and delimitating their scope.", "labels": [], "entities": []}, {"text": "It was initially intended for processing negation in opinionated texts, and has been adapted to fit the task requirements.", "labels": [], "entities": [{"text": "processing negation in opinionated texts", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.8583527326583862}]}, {"text": "It first detects negation cues using a list of explicit negation markers (such as not or nothing), and infers other implicit negations (such as affixal negations, e.g, undeniable or improper) by using semantic information from WordNet concepts and relations.", "labels": [], "entities": []}, {"text": "It next uses the information from the syntax tree of the sentence in which the negation arises to get a first approximation to the negation scope, which is later refined using a set of post-processing rules that bound or expand such scope.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detecting negation is important for many NLP tasks, as it may reverse the meaning of the text affected by it.", "labels": [], "entities": [{"text": "Detecting negation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9398806095123291}]}, {"text": "In information extraction, for instance, it is obviously important to distinguish negated information from affirmative one ().", "labels": [], "entities": [{"text": "information extraction", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.8857670426368713}]}, {"text": "It may also improve automatic indexing).", "labels": [], "entities": [{"text": "indexing", "start_pos": 30, "end_pos": 38, "type": "TASK", "confidence": 0.7793945670127869}]}, {"text": "In sentiment analysis, detecting and dealing with negation is critical, as it may change the polarity of a text.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9562868177890778}]}, {"text": "However, research on negation has mainly focused on the biomedical domain, and addressed the problem of detecting if a medical term is negated or not), or the scope of different negation signals (.", "labels": [], "entities": [{"text": "negation", "start_pos": 21, "end_pos": 29, "type": "TASK", "confidence": 0.9778388738632202}]}, {"text": "During the last years, the importance of processing negation is gaining recognition by the NLP research community, as evidenced by the success of several initiatives such as the Negation and Speculation in Natural Language Processing workshop or the CoNLL-2010 Shared Task , which aimed at identifying hedges and their scope in natural language texts.", "labels": [], "entities": [{"text": "Negation and Speculation in Natural Language Processing workshop", "start_pos": 178, "end_pos": 242, "type": "TASK", "confidence": 0.7174173258244991}]}, {"text": "In spite of this, most of the approaches proposed so far deal with negation in a superficial manner.", "labels": [], "entities": []}, {"text": "This paper describes our contribution to the *SEM Shared Task 2012 on Resolving the Scope and Focus of Negation.", "labels": [], "entities": [{"text": "SEM Shared Task 2012", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7827363163232803}, {"text": "Resolving the Scope", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8287301262219747}]}, {"text": "As its name suggests, the task aims at detecting the scope and focus of negation, as a means of encouraging research in negation processing.", "labels": [], "entities": [{"text": "detecting the scope and focus of negation", "start_pos": 39, "end_pos": 80, "type": "TASK", "confidence": 0.6265561878681183}, {"text": "negation processing", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.9678921103477478}]}, {"text": "In particular, we participate in Task 1: scope detection.", "labels": [], "entities": [{"text": "scope detection", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.9201816022396088}]}, {"text": "For each negation in the text, the negation cue must be detected, and its scope marked.", "labels": [], "entities": []}, {"text": "Moreover, the event or property that is negated must be recognized.", "labels": [], "entities": []}, {"text": "A comprehensive description of the task maybe found in.", "labels": [], "entities": []}, {"text": "For the sake of clarity, it is important to define what the organization of the task understands by negation cue, scope of negation and negated event.", "labels": [], "entities": []}, {"text": "The words that express negation are called negation cues.", "labels": [], "entities": []}, {"text": "Not and no are common examples of such cues.", "labels": [], "entities": []}, {"text": "Scope is defined as the part of the meaning that is negated, and encloses all negated concepts.", "labels": [], "entities": []}, {"text": "The negated event is the property that is negated by the cue.", "labels": [], "entities": []}, {"text": "For instance, in the sentence: did not [say anything], the scope is enclosed in square brackets, the negation cue is underlined and the negated event is shown in bold.", "labels": [], "entities": []}, {"text": "More details about the annotation of negation cues, scopes and negated events maybe found in.", "labels": [], "entities": [{"text": "negation cues", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.8938335180282593}]}, {"text": "The system presented to the shared task is an adaptation of the one published in (Carrillo de, whose aim was to detect and process negation in opinionated text in order to improve polarity and intensity classification.", "labels": [], "entities": [{"text": "Carrillo de,", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.8935464024543762}, {"text": "intensity classification", "start_pos": 193, "end_pos": 217, "type": "TASK", "confidence": 0.7413910031318665}]}, {"text": "When classifying sentiments and opinions it is important to deal with the presence of negations and their effect on the emotional meaning of the text affected by them.", "labels": [], "entities": [{"text": "classifying sentiments and opinions", "start_pos": 5, "end_pos": 40, "type": "TASK", "confidence": 0.8754244595766068}]}, {"text": "Consider the sentence (1) and (2).", "labels": [], "entities": []}, {"text": "Sentence (1) expresses a positive opinion, whereas that in sentence (2) the negation word not reverses the polarity of such opinion.", "labels": [], "entities": []}, {"text": "(1) I liked this hotel.", "labels": [], "entities": []}, {"text": "(2) I didn't like this hotel.", "labels": [], "entities": []}, {"text": "Our system has the main advantage of being simple and highly generic.", "labels": [], "entities": []}, {"text": "Even though it was originally conceived for treating negations in opinionated texts, a few simple modifications have been sufficient to successfully address negation in a very different type of texts, such as Conan Doyle stories.", "labels": [], "entities": []}, {"text": "It is rule-based and does not need to be trained.", "labels": [], "entities": []}, {"text": "It also uses semantic information in order to automatically detect the negation cues.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data collection consists of a development set, a training set, and two test sets of 787, 3644, 496 and 593 sentences, respectively from different stories by Conan Doyle (see) for details).", "labels": [], "entities": []}, {"text": "Performance is measured in terms of recall, precision and F-measure for the following subtasks: \u2022 Predicting negation cues.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9994327425956726}, {"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9995094537734985}, {"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9994754195213318}]}, {"text": "\u2022 Predicting both the scope and cue.", "labels": [], "entities": [{"text": "Predicting", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9538979530334473}, {"text": "scope", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.9867497086524963}]}, {"text": "\u2022 Predicting the scope, the cue does not need to be correct.", "labels": [], "entities": [{"text": "Predicting", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9891104102134705}, {"text": "scope", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9309930801391602}]}, {"text": "\u2022 Predicting the scope tokens, where not a full scope match is required.", "labels": [], "entities": []}, {"text": "\u2022 Full evaluation, which requires all elements to be correct.", "labels": [], "entities": []}, {"text": "The results of our system when evaluated on the development set and the two test sets (both jointly and separately), are shown in, and 6.", "labels": [], "entities": []}, {"text": "It maybe seen from these tables that our system behaves quite well in the prediction of negation cues subtask, achieving around 90% F-measure in all data sets, and the second position in the competition.", "labels": [], "entities": [{"text": "prediction of negation cues subtask", "start_pos": 74, "end_pos": 109, "type": "TASK", "confidence": 0.7673498272895813}, {"text": "F-measure", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9993864297866821}]}, {"text": "Performance in the scope prediction task, however, is around 60% F-1, and the same results are obtained if the correct prediction of cues is required (Scope (cue match)).", "labels": [], "entities": [{"text": "scope prediction task", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.8821770747502645}, {"text": "F-1", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9985727071762085}]}, {"text": "This seems to indicate that, for all correct scope predictions, our system have also predicted the negation cues correctly.", "labels": [], "entities": []}, {"text": "Obviously these results improve for the Scope tokens measure, achieving more than 77% F-1 for the Cardboard data set.", "labels": [], "entities": [{"text": "Scope tokens measure", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.6716810464859009}, {"text": "F-1", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9991101622581482}, {"text": "Cardboard data set", "start_pos": 98, "end_pos": 116, "type": "DATASET", "confidence": 0.9898573557535807}]}, {"text": "We also got the second position in the competition for these three subtasks.", "labels": [], "entities": []}, {"text": "Concerning detection of negated events, our system gets poor results, 22.85% and 19.81% F-1, respectively, in each test data set.", "labels": [], "entities": [{"text": "F-1", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9979737401008606}]}, {"text": "These results affect the performance of the full negation prediction task, where we get 32.18% and 32.96% F-1, respectively.", "labels": [], "entities": [{"text": "negation prediction task", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.9377445379892985}, {"text": "F-1", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9981256127357483}]}, {"text": "Surprisingly, the result in the test sets are slightly better than those in the development set, and this is due to a better behavior of the WordNet-based cue detection method in the formers than in the later.", "labels": [], "entities": [{"text": "WordNet-based cue detection", "start_pos": 141, "end_pos": 168, "type": "TASK", "confidence": 0.7925268212954203}]}], "tableCaptions": [{"text": " Table 4: Results for the development set.", "labels": [], "entities": []}, {"text": " Table 5: Results for the test sets (jointly).", "labels": [], "entities": []}, {"text": " Table 6: Results for the Cardboard and Circle test sets.", "labels": [], "entities": [{"text": "Cardboard and Circle test sets", "start_pos": 26, "end_pos": 56, "type": "DATASET", "confidence": 0.8774823904037475}]}]}