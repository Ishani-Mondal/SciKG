{"title": [{"text": "UWashington: Negation Resolution using Machine Learning Methods", "labels": [], "entities": [{"text": "UWashington", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8618797063827515}, {"text": "Negation Resolution", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.9804505705833435}]}], "abstractContent": [{"text": "This paper reports on a simple system for resolving the scope of negation in the closed track of the *SEM 2012 Shared Task.", "labels": [], "entities": [{"text": "negation", "start_pos": 65, "end_pos": 73, "type": "TASK", "confidence": 0.9047597646713257}, {"text": "SEM 2012 Shared Task", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.5699795037508011}]}, {"text": "Cue detection is performed using regular expression rules extracted from the training data.", "labels": [], "entities": [{"text": "Cue detection", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9221468865871429}]}, {"text": "Both scope tokens and negated event tokens are resolved using a Conditional Random Field (CRF) sequence tagger-namely the SimpleTagger library in the MALLET machine learning toolkit.", "labels": [], "entities": []}, {"text": "The full negation F 1 score obtained for the task evaluation is 48.09% (P=74.02%, R=35.61%) which ranks this system fourth among the six submitted for the closed track.", "labels": [], "entities": [{"text": "negation F 1 score", "start_pos": 9, "end_pos": 27, "type": "METRIC", "confidence": 0.8100235313177109}, {"text": "P=74.02%", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9284605979919434}, {"text": "R", "start_pos": 82, "end_pos": 83, "type": "METRIC", "confidence": 0.8064354062080383}]}], "introductionContent": [{"text": "Resolving the scope of negation is an interesting area of research for Natural Language Processing (NLP) systems because many such systems have used methods that are insensitive to polarity.", "labels": [], "entities": [{"text": "Resolving the scope of negation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8214059710502625}]}, {"text": "As a result it is fairly common to have a system that treats \"X does Y\" and \"X does not Y\" as having the same, or very nearly the same, meaning . A few application areas that have been addressing this issue recently are in sentiment analysis, bio\u00ad medical NLP, and recognition of textual entail\u00ad ment.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 223, "end_pos": 241, "type": "TASK", "confidence": 0.9793673455715179}, {"text": "bio\u00ad medical NLP", "start_pos": 243, "end_pos": 259, "type": "TASK", "confidence": 0.8029608130455017}, {"text": "recognition of textual entail\u00ad ment.", "start_pos": 265, "end_pos": 301, "type": "TASK", "confidence": 0.9016939401626587}]}, {"text": "Sentiment analysis systems are frequently used incorporate and product marketing, call cen\u00ad ter quality control, and within \"recommender\" sys\u00ad tems which are all contexts where it is important to recognize that \"X does like Y\" is contrary to \"X does not like Y\".", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8744803667068481}, {"text": "call cen\u00ad ter quality control", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.5609869360923767}]}, {"text": "Similarly in biomedical text such as research papers and abstracts, diagnostic proce\u00ad dure reports, and medical records it is important to differentiate between statements about what is the case and what is not the case.", "labels": [], "entities": []}, {"text": "The *SEM 2012 Shared Task is actually two re\u00ad lated tasks run in parallel.", "labels": [], "entities": [{"text": "SEM 2012 Shared Task", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.5640972256660461}]}, {"text": "The one this system was developed for is the identification of three features of negation: the cue, the scope, and the factual negated event (if any).", "labels": [], "entities": []}, {"text": "The other task is concerned with the focus of negation.", "labels": [], "entities": [{"text": "negation", "start_pos": 46, "end_pos": 54, "type": "TASK", "confidence": 0.9443950653076172}]}, {"text": "Detailed description of both subtasks, including definition of the relevant concepts and terminology (negation, cue, scope, event, and focus) appears in this volume.", "labels": [], "entities": []}, {"text": "Roser Morante and Eduardo Blanco describe the corpora provided to partici\u00ad pants with numbers and examples, methods used used to process the data, and briefly describes each participant and analyzes the overall results.", "labels": [], "entities": []}, {"text": "Annotation of the corpus was undertaken at the University of Antwerp and was performed on sev\u00ad eral Sherlock Holmes works of fiction written by Sir Arthur Conan Doyle.", "labels": [], "entities": [{"text": "sev\u00ad eral Sherlock Holmes works of fiction written by Sir Arthur Conan Doyle", "start_pos": 90, "end_pos": 166, "type": "TASK", "confidence": 0.4534812080008643}]}, {"text": "The corpus includes all sentences from the original text, not just those em\u00ad ploying negation.", "labels": [], "entities": []}, {"text": "Roser Morante and Walter Daelemans provide a thorough explanation of those gold annotations of negation cue, scope, and negated event (if any).", "labels": [], "entities": [{"text": "negation cue", "start_pos": 95, "end_pos": 107, "type": "TASK", "confidence": 0.8411805927753448}]}, {"text": "Their paper explains the motivations for the particular annotation decisions and describes in de\u00ad tail the guidelines, including many examples.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of full negation scores for various feature sets.", "labels": [], "entities": []}, {"text": " Table 2: System evaluation on held\u00adout data.", "labels": [], "entities": []}]}