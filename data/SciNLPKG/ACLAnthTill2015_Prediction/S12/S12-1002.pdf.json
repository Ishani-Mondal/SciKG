{"title": [{"text": "Adaptive Clustering for Coreference Resolution with Deterministic Rules and Web-Based Language Models", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.9777633845806122}]}], "abstractContent": [{"text": "We present a novel adaptive clustering model for coreference resolution in which the expert rules of a state of the art deterministic system are used as features over pairs of clusters.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.9744163751602173}]}, {"text": "A significant advantage of the new approach is that the expert rules can be easily augmented with new semantic features.", "labels": [], "entities": []}, {"text": "We demonstrate this advantage by incorporating semantic compatibility features for neutral pronouns computed from web n-gram statistics.", "labels": [], "entities": []}, {"text": "Experimental results show that the combination of the new features with the expert rules in the adaptive clustering approach results in an overall performance improvement, and over 5% improvement in F 1 measure for the target pronouns when evaluated on the ACE 2004 newswire corpus.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 199, "end_pos": 210, "type": "METRIC", "confidence": 0.9923570156097412}, {"text": "ACE 2004 newswire corpus", "start_pos": 257, "end_pos": 281, "type": "DATASET", "confidence": 0.9840755611658096}]}], "introductionContent": [{"text": "Coreference resolution is the task of clustering a sequence of textual entity mentions into a set of maximal non-overlapping clusters, such that mentions in a cluster refer to the same discourse entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9132073819637299}]}, {"text": "Coreference resolution is an important subtask in a wide array of natural language processing problems, among them information extraction, question answering, and machine translation.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9316412806510925}, {"text": "information extraction", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.8411120772361755}, {"text": "question answering", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.8928702175617218}, {"text": "machine translation", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.8053144812583923}]}, {"text": "The availability of corpora annotated with coreference relations has led to the development of a diverse set of supervised learning approaches for coreference.", "labels": [], "entities": []}, {"text": "While learning models enjoy a largely undisputed role in many NLP applications, deterministic models based on rich sets of expert rules for coreference have been shown recently to achieve performance rivaling, if not exceeding, the performance of state of the art machine learning approaches).", "labels": [], "entities": []}, {"text": "In particular, the top performing system in the CoNLL 2011 shared task) is a multi-pass system that applies tiers of deterministic coreference sieves from highest to lowest precision ().", "labels": [], "entities": [{"text": "CoNLL 2011 shared task)", "start_pos": 48, "end_pos": 71, "type": "DATASET", "confidence": 0.9124400377273559}, {"text": "precision", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9522541761398315}]}, {"text": "The PRECISECONSTRUCTS sieve, for example, creates coreference links between mentions that are found to match patterns of apposition, predicate nominatives, acronyms, demonyms, or relative pronouns.", "labels": [], "entities": []}, {"text": "This is a high precision sieve, correspondingly it is among the first sieves to be applied.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9586191773414612}]}, {"text": "The PRONOUN-MATCH sieve links an anaphoric pronoun with the first antecedent mention that agrees in number and gender with the pronoun, based on an ordering of the antecedents that uses syntactic rules to model discourse salience.", "labels": [], "entities": []}, {"text": "This is the last sieve to be applied, due to its lower overall precision, as estimated on development data.", "labels": [], "entities": [{"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9993636012077332}]}, {"text": "While very successful, this deterministic multi-pass sieve approach to coreference can nevertheless be quite unwieldy when one seeks to integrate new sources of knowledge in order to improve the resolution performance.", "labels": [], "entities": [{"text": "coreference", "start_pos": 71, "end_pos": 82, "type": "TASK", "confidence": 0.9598798751831055}]}, {"text": "Pronoun resolution, for example, was shown by to benefit from semantic compatibility information extracted from search engine statistics.", "labels": [], "entities": [{"text": "Pronoun resolution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8461889028549194}]}, {"text": "The semantic compatibility between candidate antecedents and the pronoun context induces anew ordering between the antecedents.", "labels": [], "entities": []}, {"text": "One possibility for using compatibility scores in the deterministic system is to ignore the salience-based ordering and replace it with the new compatibility-based ordering.", "labels": [], "entities": []}, {"text": "The draw-back of this simple approach is that now discourse salience, an important signal in pronoun resolution, is completely ignored.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7468303143978119}]}, {"text": "Ideally, we would want to use both discourse salience and semantic compatibility when ranking the candidate antecedents of the pronoun, something that can be achieved naturally in a discriminative learning approach that uses the two rankings as different, but overlapping, features.", "labels": [], "entities": []}, {"text": "Consequently, we propose an adaptive clustering model for coreference in which the expert rules are successfully supplemented by semantic compatibility features obtained from limited history web ngram statistics.", "labels": [], "entities": [{"text": "coreference", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.969092607498169}]}], "datasetContent": [{"text": "We compare our adaptive clustering (AC) approach with the state of the art deterministic sieves (DT) system of Lee et al.", "labels": [], "entities": []}, {"text": "(2011) on the newswire portion of the ACE-2004 dataset.", "labels": [], "entities": [{"text": "newswire portion of the ACE-2004 dataset", "start_pos": 14, "end_pos": 54, "type": "DATASET", "confidence": 0.78096604347229}]}, {"text": "The newswire section of the corpus contains 128 documents annotated with gold mentions and coreference information, where coreference is marked only between mentions that belong to one of seven semantic classes: person, organization, location, geo-political entity, facility, vehicle, and weapon.", "labels": [], "entities": []}, {"text": "This set of documents has been used before to evaluate coreference resolution sys-  tems in, with the best results so far obtained by the deterministic sieve system of Lee at al.", "labels": [], "entities": [{"text": "coreference resolution sys-  tems", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.8670170545578003}]}, {"text": "There are 11,398 annotated gold mentions, out of which 135 are possessive neutral pronouns its and 88 are neutral pronouns it in a subject-verb-object triple.", "labels": [], "entities": []}, {"text": "Given the very small number of neutral pronouns, in order to obtain reliable estimates for the model parameters we tested the adaptive clustering algorithm in a 16 fold crossvalidation scenario.", "labels": [], "entities": []}, {"text": "Thus, the set of 128 documents was split into 16 folds, where each fold contains 120 documents for training and 8 documents for testing.", "labels": [], "entities": []}, {"text": "The final results were pooled together from the 16 disjoint test sets.", "labels": [], "entities": []}, {"text": "During training, the AC's update procedure was run for 10 epochs.", "labels": [], "entities": []}, {"text": "Since the AC algorithm does not need to tune any hyper parameters, there was no need for development data.", "labels": [], "entities": []}, {"text": "shows the results obtained by the two systems on the newswire corpus under three evaluation scenarios.", "labels": [], "entities": [{"text": "newswire corpus", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.882398396730423}]}, {"text": "We use the B 3 version of the precision (P), recall (R), and F 1 measure, computed either on all mention pairs (all) or only on links that contain at least one neutral pronoun (neutral) marked as a mention in ACE.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.9546826779842377}, {"text": "recall (R)", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9551195949316025}, {"text": "F 1 measure", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.9908533096313477}, {"text": "ACE", "start_pos": 209, "end_pos": 212, "type": "DATASET", "confidence": 0.8614979386329651}]}, {"text": "Furthermore, we report results on gold mentions (Gold) as well as on mentions extracted automatically (Auto).", "labels": [], "entities": []}, {"text": "Since the number of neutral pronouns marked as gold mentions is small compared to the total number of mentions, the impact on the overall performance shown in the first two rows is small.", "labels": [], "entities": []}, {"text": "However, when looking at coreference links that contain at least one neutral pronoun, the improvement becomes substantial.", "labels": [], "entities": []}, {"text": "AC increases F 1 with 5.3% when the mentions are extracted automatically during testing, a setting that reflects a more realistic use of the system.", "labels": [], "entities": [{"text": "AC", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9028590321540833}, {"text": "F 1", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9924018681049347}]}, {"text": "We have also evaluated the AC approach in the Gold setting using only the original DT sieves as features, obtaining an F 1 of 80.3% for all mentions and 63.4% -same as DTfor neutral pronouns.", "labels": [], "entities": [{"text": "Gold setting", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8699358403682709}, {"text": "F 1", "start_pos": 119, "end_pos": 122, "type": "METRIC", "confidence": 0.9953206479549408}]}, {"text": "By matching the performance of the DT system in the first two rows of the table, the AC system proves that it can successfully learn the relative importance of the deterministic sieves, which in ( and) have been manually ordered using a separate development dataset.", "labels": [], "entities": []}, {"text": "Furthermore, in the DT system the sieves are applied on mentions in their textual order, whereas the adaptive clustering algorithm AC does not assume a predefined ordering among coreference resolution decisions.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 178, "end_pos": 200, "type": "TASK", "confidence": 0.8535080552101135}]}, {"text": "Thus, the algorithm has the capability to make the first clustering decisions in any section of the document in which the coreference decisions are potentially easier to make.", "labels": [], "entities": []}, {"text": "We have run experiments in which the AC system was augmented with a feature that computed the normalized distance between a cluster and the beginning of the document, but this did not lead to an improvement in the results, lending further credence to the hypothesis that a strictly left to right ordering of the coreference decisions is not necessary, at least with the current features.", "labels": [], "entities": []}, {"text": "The same behavior, albeit with smaller increases in performance, was observed when the DT and AC approaches were compared on the newswire section of the development dataset used in the CoNLL 2011 shared task).", "labels": [], "entities": [{"text": "CoNLL 2011 shared task", "start_pos": 185, "end_pos": 207, "type": "DATASET", "confidence": 0.7751974016427994}]}, {"text": "For these experiments, the AC system was trained on all 128 documents from the newswire portion of ACE 2004.", "labels": [], "entities": [{"text": "newswire portion of ACE 2004", "start_pos": 79, "end_pos": 107, "type": "DATASET", "confidence": 0.8740009903907776}]}, {"text": "On gold mentions, the DT and AC systems obtained a very similar performance.", "labels": [], "entities": [{"text": "DT", "start_pos": 22, "end_pos": 24, "type": "DATASET", "confidence": 0.7954704165458679}]}, {"text": "When evaluated only on links that contain at least one neutral pronoun, in a setting where the mentions were automatically detected, the AC approach improved the F 1 measure over the DT system from 58.6% to 59.1%.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 162, "end_pos": 173, "type": "METRIC", "confidence": 0.9874927202860514}]}, {"text": "One reason for the smaller increase in performance in the CoNLL experiments could be given by the different annotation schemes used in the two datasets.", "labels": [], "entities": [{"text": "CoNLL experiments", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.8956906199455261}]}, {"text": "Compared to ACE, the CoNLL dataset does not include coreference links for appositives, predicate nominals or relative pronouns.", "labels": [], "entities": [{"text": "CoNLL dataset", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.949924498796463}]}, {"text": "The different annotation schemes may have led to mismatches in the training and test data for the AC system, which was trained on ACE and tested on CoNLL.", "labels": [], "entities": [{"text": "ACE", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.9364762902259827}, {"text": "CoNLL", "start_pos": 148, "end_pos": 153, "type": "DATASET", "confidence": 0.9847714304924011}]}, {"text": "While we tried to control for these conditions during the evaluation of the AC system, it is conceivable that the differ-  ences in annotation still had some effect on the performance of the AC approach.", "labels": [], "entities": []}, {"text": "Another cause for the smaller increase in performance was that the pronominal contexts were less discriminative in the CoNLL data, especially for the neutral pronoun it.", "labels": [], "entities": [{"text": "CoNLL data", "start_pos": 119, "end_pos": 129, "type": "DATASET", "confidence": 0.9492960870265961}]}, {"text": "When evaluated only on links that contained at least one possessive neutral pronoun its, the improvement in F 1 increased at 1.9%, as shown in.", "labels": [], "entities": [{"text": "F 1", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9955137670040131}]}], "tableCaptions": [{"text": " Table 2: B 3 comparative results on ACE 2004.", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.9313598573207855}]}, {"text": " Table 3: B 3 comparative results on CoNLL 2011.", "labels": [], "entities": [{"text": "CoNLL 2011", "start_pos": 37, "end_pos": 47, "type": "DATASET", "confidence": 0.9363610744476318}]}]}