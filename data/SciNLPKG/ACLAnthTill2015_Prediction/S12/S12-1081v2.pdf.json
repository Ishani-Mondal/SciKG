{"title": [{"text": "DSS: Text Similarity Using Lexical Alignments of Form, Distributional Semantics and Grammatical Relations", "labels": [], "entities": [{"text": "DSS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8612188100814819}, {"text": "Text Similarity", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.6794644743204117}]}], "abstractContent": [{"text": "In this paper we present our systems for the STS task.", "labels": [], "entities": [{"text": "STS task", "start_pos": 45, "end_pos": 53, "type": "TASK", "confidence": 0.9354645609855652}]}, {"text": "Our systems are all based on a simple process of identifying the components that correspond between two sentences.", "labels": [], "entities": []}, {"text": "Currently we use words (that is word forms), lem-mas, distributional similar words and grammatical relations identified with a dependency parser.", "labels": [], "entities": []}, {"text": "All systems only use open class words.", "labels": [], "entities": []}, {"text": "Our first system (alignheuristic) tries to obtain a mapping between every open class token using all the above sources of information.", "labels": [], "entities": []}, {"text": "Our second system (wordsim) uses a different algorithm and unlike alignheuristic, it does not use the dependency information.", "labels": [], "entities": []}, {"text": "The third system (average) simply takes the average of the scores for each item from the other two systems to take advantage of the merits of both systems.", "labels": [], "entities": [{"text": "average", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9636673927307129}]}, {"text": "For this reason we only provide a brief description of that.", "labels": [], "entities": []}, {"text": "The results are promising, with Pearson's coefficients on each individual dataset ranging from .3765 to .7761 for our relatively simple heuris-tics based systems that do not require training on different datasets.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.959846556186676}]}, {"text": "We provide some analysis of the results and also provide results for our data using Spearman's, which as a non-parametric measure which we argue is better able to reflect the merits of the different systems (average is ranked between the others).", "labels": [], "entities": []}], "introductionContent": [{"text": "Our motivation for the systems entered in the STS task) was to model the contribution of each linguistic component of a sentence to the similarity of a candidate match and vice versa.", "labels": [], "entities": []}, {"text": "Ultimately such a system could be exploited for ranking candidate paraphrases of a chunk of text of any length.", "labels": [], "entities": []}, {"text": "We envisage a system as outlined in the future work section.", "labels": [], "entities": []}, {"text": "The systems reported are simple baselines to such a system.", "labels": [], "entities": []}, {"text": "We have two main systems (alignheuristic and wordsim) and also a system which simply uses the average score for each item from the two main systems (average).", "labels": [], "entities": []}, {"text": "In our systems we: \u2022 only deal with open class words as tokens i.e. nouns, verbs, adjectives, adverbs.", "labels": [], "entities": []}, {"text": "alignheuristic and average also use numbers \u2022 assume that tokens have a 1:1 mapping \u2022 match: -word forms -lemmas -distributionally similar lemmas -alignheuristic and average use the grammatical relation with a word that has a mapping and the same relation in reverse \u2022 score the sentence pair based on the size of the overlap.", "labels": [], "entities": []}, {"text": "Different formulations of the score are used by our methods The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In the next section we make a brief mention of related work though of course there will be more pertinent related work presented and published at SemEval 2012.", "labels": [], "entities": [{"text": "SemEval 2012", "start_pos": 146, "end_pos": 158, "type": "DATASET", "confidence": 0.7589511871337891}]}, {"text": "In section 3 we give a detailed account of the systems and in section 4 we provide the results obtained on the training data on developing our systems.", "labels": [], "entities": []}, {"text": "In section 5 we present the results on the test data, along with a little analysis using the gold standard data.", "labels": [], "entities": [{"text": "gold standard data", "start_pos": 93, "end_pos": 111, "type": "DATASET", "confidence": 0.7945680816968282}]}, {"text": "In section 6 we conclude our findings and discuss our ideas for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on training data", "labels": [], "entities": []}, {"text": " Table 2: Results for the alignheuristic algorithm  on the training data: varying wt", "labels": [], "entities": []}, {"text": " Table 3: Results for the alignheuristic algorithm  on the training data: with and without TMTCH and", "labels": [], "entities": [{"text": "TMTCH", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.8826849460601807}]}, {"text": " Table 4: Number of token alignments for different match- ing processes", "labels": [], "entities": [{"text": "match- ing", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.6401101251443228}]}, {"text": " Table 5: Official results: Rank (out of 89) is shown in brackets", "labels": [], "entities": [{"text": "Rank", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9956480860710144}]}, {"text": " Table 7: Spearman's \u03c1 for the 5 datasets, 'all' and the average coefficient across the datasets", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.7531960209210714}]}]}