{"title": [{"text": "Learning Semantics and Selectional Preference of Adjective-Noun Pairs", "labels": [], "entities": [{"text": "Selectional Preference of Adjective-Noun Pairs", "start_pos": 23, "end_pos": 69, "type": "TASK", "confidence": 0.8632975459098816}]}], "abstractContent": [{"text": "We investigate the semantic relationship between a noun and its adjectival modifiers.", "labels": [], "entities": []}, {"text": "We introduce a class of probabilistic models that enable us to to simultaneously capture both the semantic similarity of nouns and modifiers, and adjective-noun selectional preference.", "labels": [], "entities": []}, {"text": "Through a combination of novel and existing evaluations we test the degree to which adjective-noun relationships can be cat-egorised.", "labels": [], "entities": []}, {"text": "We analyse the effect of lexical context on these relationships, and the efficacy of the latent semantic representation for disam-biguating word meaning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Developing models of the meanings of words and phrases is a key challenge for computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.7611695826053619}]}, {"text": "Distributed representations are useful in capturing such meaning for individual words (.", "labels": [], "entities": []}, {"text": "However, finding a compelling account of semantic compositionality that utilises such representations has proven more difficult and is an active research topic.", "labels": [], "entities": [{"text": "semantic compositionality", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7127635478973389}]}, {"text": "It is in this area that our paper makes its contribution.", "labels": [], "entities": []}, {"text": "The dominant approaches to distributional semantics have relied on relatively simple frequency counting techniques.", "labels": [], "entities": [{"text": "distributional semantics", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.764016717672348}]}, {"text": "However, such approaches fail to generalise to the much sparser distributions encountered when modeling compositional processes and provide no account of selectional preference.", "labels": [], "entities": []}, {"text": "We propose a probabilistic model of the semantic representations for nouns and modifiers.", "labels": [], "entities": []}, {"text": "The foundation of this model is a latent variable representation of noun and adjective semantics together with their compositional probabilities.", "labels": [], "entities": []}, {"text": "We employ this formulation to give a dual view of noun-modifier semantics: the induced latent variables provide an explicit account of selectional preference while the marginal distributions of the latent variables for each word implicitly produce a distributed representation.", "labels": [], "entities": []}, {"text": "Most related work on selectional preference uses class-based probabilities to approximate (sparse) individual probabilities.", "labels": [], "entities": []}, {"text": "Relevant papers includ\u00e9includ\u00e9 O S\u00e9aghdha (2010), who evaluates several topic models adapted to learning selectional preference using co-occurence and, who represent nouns as vectors and adjectives as matrices, thus treating them as functions over noun meaning.", "labels": [], "entities": []}, {"text": "Again, inference is achieved using co-occurrence and dimensionality reduction.", "labels": [], "entities": []}], "datasetContent": [{"text": "As our model was developed on the basis of several hypotheses, we design the experiments and evaluation so that these hypotheses can be examined on their individual merit.", "labels": [], "entities": []}, {"text": "We test the first hypothesis, that nouns and adjectives can be represented by semantic classes, recoverable using co-occurence, using a sense clustering evaluation by.", "labels": [], "entities": []}, {"text": "The second hypothesis, that the distribution with respect to context and to each other is governed by these semantic classes is evaluated using pseudo-disambiguation) and bigram plausibility ( tests.", "labels": [], "entities": []}, {"text": "To test whether noun classes indeed select for adjective classes, we also evaluate an inverse model (M od i ), where the adjective class is drawn first, in turn generating both context and the noun class.", "labels": [], "entities": []}, {"text": "In addition, we evaluate copies of both models ignoring context (M od nc and M od inc ).", "labels": [], "entities": []}, {"text": "We use the British National Corpus (BNC), training on 90 percent and testing on 10 percent of the corpus.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 11, "end_pos": 40, "type": "DATASET", "confidence": 0.9661445816357931}]}, {"text": "Results are reported after 2,000 iterations including a burn-in period of 200 iterations.", "labels": [], "entities": []}, {"text": "Classes are marginalised over every 10th iteration.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Supersense evaluation results. Values are the  percentage of correctly assigned supersenses. k indicates  the number of nearest neighbours considered.", "labels": [], "entities": []}, {"text": " Table 2. As baseline we use unigram counts in our  training data, chosing the more frequent adjective.", "labels": [], "entities": []}, {"text": " Table 2: Pseudo-disambiguation: Percentage of correct  choices made. L-bound denotes the Web1T lower bound  on the (a 1 , n) bigram, size the number of decisions made.", "labels": [], "entities": [{"text": "Pseudo-disambiguation", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.9574709534645081}, {"text": "L-bound", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9476372599601746}]}, {"text": " Table 3: Results (Pearson r and Spearman \u03c1 correlations)  on the Keller and Lapata (2003) plausibility data. Bold  indicates best scores, underlining our best scores. High  values indicate high correlation with the gold standard.", "labels": [], "entities": [{"text": "Pearson r", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9533528387546539}, {"text": "Spearman \u03c1 correlations", "start_pos": 33, "end_pos": 56, "type": "METRIC", "confidence": 0.8301520943641663}]}, {"text": " Table 4: Results on the unseen plausibility dataset.", "labels": [], "entities": []}]}