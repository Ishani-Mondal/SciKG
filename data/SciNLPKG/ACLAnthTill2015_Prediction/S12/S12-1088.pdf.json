{"title": [{"text": "UNITOR: Combining Semantic Text Similarity functions through SV Regression", "labels": [], "entities": [{"text": "Combining Semantic Text Similarity", "start_pos": 8, "end_pos": 42, "type": "TASK", "confidence": 0.6416113004088402}]}], "abstractContent": [{"text": "This paper presents the UNITOR system that participated to the SemEval 2012 Task 6: Semantic Textual Similarity (STS).", "labels": [], "entities": [{"text": "SemEval 2012 Task 6", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.9137203991413116}, {"text": "Semantic Textual Similarity (STS)", "start_pos": 84, "end_pos": 117, "type": "TASK", "confidence": 0.7555181433757147}]}, {"text": "The task is here modeled as a Support Vector (SV) regression problem, where a similarity scoring function between text pairs is acquired from examples.", "labels": [], "entities": []}, {"text": "The semantic relatedness between sentences is modeled in an unsupervised fashion through different similarity functions, each capturing a specific semantic aspect of the STS, e.g. syntactic vs. lexical or topical vs. paradigmatic similarity.", "labels": [], "entities": []}, {"text": "The SV regressor effectively combines the different models, learning a scoring function that weights individual scores in a unique resulting STS.", "labels": [], "entities": []}, {"text": "It provides a highly portable method as it does not depend on any manually built resource (e.g. WordNet) nor controlled, e.g. aligned, corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two phrases or texts.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7894196311632792}]}, {"text": "An effective method to compute similarity between short texts or sentences has many applications in Natural Language Processing () and related areas such as Information Retrieval, e.g. to improve the effectiveness of a semantic search engine (), or databases, where text similarity can be used in schema matching to solve semantic heterogeneity.", "labels": [], "entities": [{"text": "compute similarity between short texts or sentences", "start_pos": 23, "end_pos": 74, "type": "TASK", "confidence": 0.7431531463350568}, {"text": "Information Retrieval", "start_pos": 157, "end_pos": 178, "type": "TASK", "confidence": 0.7775091826915741}]}, {"text": "STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs.", "labels": [], "entities": [{"text": "STS", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9731903672218323}]}, {"text": "Regression learning has been already applied to different NLP tasks.", "labels": [], "entities": [{"text": "Regression learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6558440029621124}]}, {"text": "In) it is applied to Opinion Mining, in particular to the rating-inference problem, wherein one must determine an author evaluation with respect to a multi-point scale.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8597776889801025}]}, {"text": "In) a method is proposed for developing sentence-level MT evaluation metrics using regression learning without directly relying on human reference translations.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.9183759391307831}]}, {"text": "In () it has been used to rank candidate sentences for the task of producing biographies from Wikipedia.", "labels": [], "entities": []}, {"text": "Finally, in) SV regressor has been used to rank questions within their context in the multimodal tutorial dialogue problem.", "labels": [], "entities": []}, {"text": "In this paper, the semantic relatedness between two sentences is modeled as a combination of different similarity functions, each describing the analogy between the two texts according to a specific semantic perspective: in this way, we aim at capturing syntactic and lexical equivalences between sentences and exploiting either topical relatedness or paradigmatic similarity between individual words.", "labels": [], "entities": []}, {"text": "The variety of semantic evidences that a system can employ here grows quickly, according to the genre and complexity of the targeted sentences.", "labels": [], "entities": []}, {"text": "We thus propose to combine such a body of evidence to learn a comprehensive scoring function y = f ( x) over individual measures from labeled data through SV regression: y is the gold similarity score (provided by human annotators), while x is the vector of the different individual scores, provided by the chosen similarity functions.", "labels": [], "entities": [{"text": "gold similarity score", "start_pos": 179, "end_pos": 200, "type": "METRIC", "confidence": 0.7363712588946024}]}, {"text": "The regressor objective is to learn the proper combination of different functions redundantly applied in an unsupervised fashion, without involving any in-depth description of the target domain or prior knowledge.", "labels": [], "entities": []}, {"text": "The resulting function selects and filters the most useful information and it is a highly portable method.", "labels": [], "entities": []}, {"text": "In fact, it does not depend on manually built resources (e.g. WordNet), but mainly exploits distributional analysis of unlabeled corpora.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9469891786575317}]}, {"text": "In Section 2, the employed similarity functions are described and the application of SV regression is presented.", "labels": [], "entities": []}, {"text": "Finally, Section 3 discusses results on the SemEval 2012 -Task 6.", "labels": [], "entities": [{"text": "SemEval 2012 -Task 6", "start_pos": 44, "end_pos": 64, "type": "DATASET", "confidence": 0.6994990527629852}]}], "datasetContent": [{"text": "This section describes results obtained in the SemEval 2012 Task 6: STS.", "labels": [], "entities": [{"text": "SemEval 2012 Task 6: STS", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.8164182106653849}]}, {"text": "First, the experimental setup of different similarity functions is described.", "labels": [], "entities": []}, {"text": "Then, results obtained over training datasets are reported.", "labels": [], "entities": []}, {"text": "Finally, results achieved in the competition are discussed.", "labels": [], "entities": []}, {"text": "In order to estimate the Latent Semantic Analysis (LSA) based similarity function, the distributional analysis of the English version of the Europarl Corpus) has been carried out.", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA) based similarity function", "start_pos": 25, "end_pos": 81, "type": "METRIC", "confidence": 0.6456394328011407}, {"text": "English version of the Europarl Corpus)", "start_pos": 118, "end_pos": 157, "type": "DATASET", "confidence": 0.8893754311970302}]}, {"text": "It is the same source corpus of the SMTeuroparl dataset and it allows to acquire a semantic space capturing the same topics characterizing this dataset.", "labels": [], "entities": [{"text": "SMTeuroparl dataset", "start_pos": 36, "end_pos": 55, "type": "DATASET", "confidence": 0.8287395238876343}]}, {"text": "A word-bysentence matrix models the sentence representation space.", "labels": [], "entities": []}, {"text": "The entire corpus has been split so that each vector represents a sentence: the number of different sentences is about 1.8 million and the matrix cells contain tf-idf scores between words and sentences.", "labels": [], "entities": []}, {"text": "The SVD is applied and the space dimensionality is reduced to k = 250.", "labels": [], "entities": []}, {"text": "Novel sentences are immersed in the reduced space, as described in) and the LSA-based similarity between two sentences is estimated according the cosine similarity.", "labels": [], "entities": [{"text": "LSA-based similarity", "start_pos": 76, "end_pos": 96, "type": "METRIC", "confidence": 0.9180275499820709}]}, {"text": "To estimate the Compositional Distributional Semantics (CDS) based function, a co-occurrence Word Space is first acquired through the distributional analysis of the UKWaC corpus (), i.e. a Web document collection made of about 2 billion tokens.", "labels": [], "entities": [{"text": "UKWaC corpus", "start_pos": 165, "end_pos": 177, "type": "DATASET", "confidence": 0.9944315552711487}]}, {"text": "UKWaC is larger than the Europarl corpus and we expect it makes available a more general lexical representation suited for all datasets.", "labels": [], "entities": [{"text": "UKWaC", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9709932804107666}, {"text": "Europarl corpus", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9941427409648895}]}, {"text": "An approach similar to the one described in) has been adopted for the acquisition of the word space.", "labels": [], "entities": []}, {"text": "First, all words occurring more than 200 times (i.e. the targets) are represented through vectors.", "labels": [], "entities": []}, {"text": "The original space dimensions are generated from the set of the 20,000 most frequent words (i.e. features) in the UKWaC corpus.", "labels": [], "entities": [{"text": "UKWaC corpus", "start_pos": 114, "end_pos": 126, "type": "DATASET", "confidence": 0.9954831004142761}]}, {"text": "One dimension describes the Pointwise Mutual Information score between one feature as it occurs on a left or right window of 3 tokens around a target.", "labels": [], "entities": [{"text": "Pointwise Mutual Information score", "start_pos": 28, "end_pos": 62, "type": "METRIC", "confidence": 0.5717813558876514}]}, {"text": "Left contexts of targets are treated differently from the right ones, in order to also capture asymmetric syntactic behaviors (e.g., useful for verbs): 40,000 dimensional vectors are thus derived for each target.", "labels": [], "entities": []}, {"text": "The particularly small window size allows to better capture paradigmatic relations between targets, e.g. hyponymy or synonymy.", "labels": [], "entities": []}, {"text": "Again, the SVD reduction is applied to the original matrix with a k = 250.", "labels": [], "entities": []}, {"text": "Once lexical vectors are available, a compositional similarity measure can be obtained by combining the word vectors according to a CDS operator, e.g. ( or.", "labels": [], "entities": []}, {"text": "In this work, the adopted compositional representation is the additive operator between lexical vectors, as described in and the similarity function between two sentences is the cosine similarity between their corresponding compositional vectors.", "labels": [], "entities": []}, {"text": "Moreover, two additive operators that only sum over nouns and verbs are also adopted, denoted by CDS V and CDS N , respectively.", "labels": [], "entities": []}, {"text": "The estimation of the semantically Smoothed Partial Tree Kernel (SPTK) is made available by an extended version of SVM-LightTK software 1 (Mos-1 http://disi.unitn.it/moschitti/Tree-Kernel.htm) implementing the smooth matching between tree nodes.", "labels": [], "entities": [{"text": "Smoothed Partial Tree Kernel (SPTK)", "start_pos": 35, "end_pos": 70, "type": "TASK", "confidence": 0.6554129208837237}]}, {"text": "The tree representation described in Sec.", "labels": [], "entities": []}, {"text": "2.1 allows to define 3 different kernels, i.e. SPTK LOCT , SPTK LCT and SPTK GRCT . Similarity between lexical nodes is estimated as the cosine similarity in the co-occurrence Word Space described above, as in).", "labels": [], "entities": [{"text": "SPTK GRCT", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.6231964528560638}]}, {"text": "In all corpus analysis and experiments, sentences are processed with the LTH dependency parser, described in, for Partof-speech tagging and lemmatization.", "labels": [], "entities": [{"text": "Partof-speech tagging", "start_pos": 114, "end_pos": 135, "type": "TASK", "confidence": 0.8060653507709503}]}, {"text": "Dependency parsing of datasets is required for the SPTK application.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6430764496326447}]}, {"text": "Finally, SVM-LightTK is employed for the SV regression learning to combine specific similarity functions.", "labels": [], "entities": []}, {"text": "compares the Pearson Correlation of different similarity functions described in Section 2.1, i.e. mainly the results of the unsupervised approaches, against the challenge training data.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 13, "end_pos": 32, "type": "METRIC", "confidence": 0.89054274559021}]}, {"text": "Regarding to MSRvid dataset, the topical similarity (LSA function) achieves the best result, i.e. 0.748.", "labels": [], "entities": [{"text": "MSRvid dataset", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.8903971314430237}, {"text": "topical similarity (LSA function", "start_pos": 33, "end_pos": 65, "type": "METRIC", "confidence": 0.8676472544670105}]}, {"text": "Paradigmatic lexical information as in CDS, CDS N and LO provides also good results, confirming the impact of lexical generalization.", "labels": [], "entities": []}, {"text": "However, only nouns seem to contribute significantly, as for the poor results of CDS V suggest.", "labels": [], "entities": []}, {"text": "As the dataset is characterized by short sentences with negligible syntactic differences, SPTK-based kernels are not discriminant.", "labels": [], "entities": []}, {"text": "On the contrary, the SPTK LCT achieves the best result in the MSRpar dataset, where paraphrasing phenomena are peculiar.", "labels": [], "entities": [{"text": "SPTK LCT", "start_pos": 21, "end_pos": 29, "type": "TASK", "confidence": 0.5745593756437302}, {"text": "MSRpar dataset", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.9530391991138458}]}, {"text": "Notice that the other SPTK kernels are not equivalently performant, inline with previous results on question classification and semantic role labeling (Croce et al., 2011).", "labels": [], "entities": [{"text": "question classification", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7554139196872711}, {"text": "semantic role labeling", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.6010895768801371}]}, {"text": "Lexical information provides a crucial contribution also for LO, although the contribution of topical or paradigmatic generalization seems negligible over MSRpar.", "labels": [], "entities": [{"text": "LO", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.7554789781570435}]}, {"text": "Finally, in the SMTeuroparl, longer sentences are the norm and length seems to compromise the performance of LO.", "labels": [], "entities": [{"text": "SMTeuroparl", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.8940198421478271}, {"text": "LO", "start_pos": 109, "end_pos": 111, "type": "METRIC", "confidence": 0.85935378074646}]}, {"text": "The best results seem to require the lexical and syntactic information provided by CDS and SPTK.", "labels": [], "entities": [{"text": "CDS", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.943025529384613}, {"text": "SPTK", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8877398371696472}]}, {"text": "shows Pearson Correlation results when the regressor is trained according a 10-fold cross validation schema.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 6, "end_pos": 25, "type": "METRIC", "confidence": 0.7782002389431}]}, {"text": "First, all possible feature combinations are attempted for the SV regression, so that every subset of the 10 features is evaluated.", "labels": [], "entities": []}, {"text": "Results of the best feature combination are shown in column best feat : for MSRvid, the best performance is achieved when all 10 features are considered; in MSRpar, SPTK combined with LO is sufficient; finally, in the SMTeuroparl the combination is LO, CDS and SPTK.", "labels": [], "entities": []}, {"text": "In column all feat results achieved by considering all features are reported.", "labels": [], "entities": []}, {"text": "Last column specifies the performance increase with respect to the corresponding best results in the unsupervised settings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Unsupervised results over the training dataset", "labels": [], "entities": [{"text": "training dataset", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.693726971745491}]}, {"text": " Table 2: SV regressor results over the training dataset", "labels": [], "entities": []}, {"text": " Table 3: Results over the challenge test dataset", "labels": [], "entities": [{"text": "challenge test dataset", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.6323203047116598}]}]}