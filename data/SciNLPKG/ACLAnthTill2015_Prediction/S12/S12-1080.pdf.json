{"title": [{"text": "IRIT: Textual Similarity Combining Conceptual Similarity with an N-Gram Comparison Method", "labels": [], "entities": [{"text": "IRIT", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.5857295393943787}, {"text": "Textual Similarity Combining Conceptual Similarity", "start_pos": 6, "end_pos": 56, "type": "TASK", "confidence": 0.7995076179504395}]}], "abstractContent": [{"text": "This paper describes the participation of the IRIT team to SemEval 2012 Task 6 (Seman-tic Textual Similarity).", "labels": [], "entities": [{"text": "SemEval 2012 Task 6", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.8399254828691483}, {"text": "Seman-tic Textual Similarity)", "start_pos": 80, "end_pos": 109, "type": "TASK", "confidence": 0.7509826496243477}]}, {"text": "The method used consists of a n-gram based comparison method combined with a conceptual similarity measure that uses WordNet to calculate the similarity between a pair of concepts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.9630816578865051}]}], "introductionContent": [{"text": "The system used for the participation of the IRIT team (composed by members of the research groups SIG and MELODI) to the Semantic Textual Similarity (STS) task) is based on two sub-modules: \u2022 a module that calculates the similarity between sentences using n-gram based similarity; \u2022 a module that calculates the similarity between concepts in the two sentences, using a concept similarity measure and WordNet as a resource.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 122, "end_pos": 160, "type": "TASK", "confidence": 0.7886852153709957}, {"text": "WordNet", "start_pos": 402, "end_pos": 409, "type": "DATASET", "confidence": 0.9418979287147522}]}, {"text": "In, we show the structure of the system and the connections between the main components.", "labels": [], "entities": []}, {"text": "The input phrases are passed on one hand directly to the n-gram similarity module, and on the other they are annoted with the Stanford POS Tagger (.", "labels": [], "entities": [{"text": "Stanford POS Tagger", "start_pos": 126, "end_pos": 145, "type": "DATASET", "confidence": 0.8553452094395956}]}, {"text": "All nouns and verbs are extracted from the tagged phrases and WordNet is searched for synsets corresponding to the extracted nouns and nouns associated to the verbs by the derived terms relationship.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9608367085456848}]}, {"text": "The synsets are the concepts used by the conceptual similarity module to  calculate the concept similarity.", "labels": [], "entities": []}, {"text": "Each module calculates a similarity score using its own method; the final similarity value is calculated as the geometric average between the two scores, multiplied by 5 in order to comply with the task specifications.", "labels": [], "entities": [{"text": "similarity", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9607459306716919}]}, {"text": "The n-gram based similarity relies on the idea that two sentences are semantically related if they contain along enough sub-sequence of non-empty terms.", "labels": [], "entities": []}, {"text": "Google Web 1T () has been used to calculate term idf, which is used as a measure of the importance of the terms.", "labels": [], "entities": [{"text": "Google Web 1T", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8891382217407227}]}, {"text": "The conceptual similarity is based on the idea that, given an ontology, two concepts are semantically similar if their distance from a common ancestor is small enough.", "labels": [], "entities": []}, {"text": "We used three different measures: the WuPalmer similarity measure ( and two \"Proxigenea\" measures ().", "labels": [], "entities": [{"text": "WuPalmer similarity measure", "start_pos": 38, "end_pos": 65, "type": "METRIC", "confidence": 0.7597906589508057}]}, {"text": "In the following we will explain in detail how each similarity module works.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before the official runs we carried out an evaluation to select the best similarity measures over the training set provided by the organisers.", "labels": [], "entities": [{"text": "similarity", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9872776865959167}]}, {"text": "The results of this evaluation are shown in.", "labels": [], "entities": []}, {"text": "The measure selected is the normalised Pearson correlation (.", "labels": [], "entities": [{"text": "normalised Pearson correlation", "start_pos": 28, "end_pos": 58, "type": "METRIC", "confidence": 0.7518657048543295}]}, {"text": "We evaluated also the use of the product instead of the geometric mean for the combination of the two scores.", "labels": [], "entities": []}, {"text": "We used these results to select the final configurations for our participation to the STS task: we selected to exclude Proxigenea 2 and to use the geometric mean to combine the scores of the n-gram based similarity module and the conceptual similarity module.", "labels": [], "entities": [{"text": "STS task", "start_pos": 86, "end_pos": 94, "type": "TASK", "confidence": 0.8859355747699738}]}, {"text": "Wu-Palmer similarity allowed to obtain the best results on two train sets but Proxigenea 3 was the similarity measure that obtained the best average score thanks to the good result on MSRvid.", "labels": [], "entities": [{"text": "MSRvid", "start_pos": 184, "end_pos": 190, "type": "DATASET", "confidence": 0.9736649990081787}]}, {"text": "The official results obtained by our system are shown in, with the ranking obtained for each test set.", "labels": [], "entities": []}, {"text": "We could observe that the system was well  behind the best system inmost test sets, except for SMTeur.", "labels": [], "entities": [{"text": "SMTeur", "start_pos": 95, "end_pos": 101, "type": "DATASET", "confidence": 0.5910000205039978}]}, {"text": "This was expected since our system does not use a machine learning approach and is completely unsupervised, while the best systems used supervised learning.", "labels": [], "entities": []}, {"text": "We observed also that the behaviour of the concept similarity measures was different from the behaviour on the training sets.", "labels": [], "entities": []}, {"text": "In the competition, the best results were always obtained with Proxigenea3 instead of Wu-Palmer, except for the MSRpar test set.", "labels": [], "entities": [{"text": "MSRpar test set", "start_pos": 112, "end_pos": 127, "type": "DATASET", "confidence": 0.8517983555793762}]}, {"text": "In we extrapolated the results for the composing methods and compared them with the result obtained after their combination.", "labels": [], "entities": []}, {"text": "We used the pg3 configuration for the conceptual similarity measure.", "labels": [], "entities": []}, {"text": "From these results, we can observe that MSRvid was a test set where the conceptual similarity alone would have resulted better than the combination of scores, while SMT-news was the test set where the CKPD measure obtained the best results in comparison to the result obtained by the conceptual similarity alone.", "labels": [], "entities": [{"text": "MSRvid", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.7973175048828125}]}, {"text": "It was quite surprising to observe such a good result fora method that does not take into account any information about the structure of the sentences, actually viewing them as \"bags of con-: Results obtained for each test set using only the conceptual similarity measure (pg3) and only the structural similarity measure (CKP D), compared to the result obtained by the complete system (Combined).", "labels": [], "entities": [{"text": "structural similarity measure (CKP D)", "start_pos": 291, "end_pos": 328, "type": "METRIC", "confidence": 0.8043603897094727}]}, {"text": "This is probably due to the fact that SMTnews is a corpus composed of automatically translated sentences, where structural similarity is an important clue for determining overall semantic similarity.", "labels": [], "entities": [{"text": "SMTnews", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9456250071525574}]}, {"text": "On the other hand, MSRvid sentences are very short, and CKPD is inmost cases unable to capture the semantic similarity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Term weights (idf) calculated using the fre- quency for each term in Google Web 1T unigrams set.", "labels": [], "entities": [{"text": "Term weights (idf)", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9455236077308655}, {"text": "fre- quency", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.915279229482015}, {"text": "Google Web 1T unigrams set", "start_pos": 79, "end_pos": 105, "type": "DATASET", "confidence": 0.8960958838462829}]}, {"text": " Table 2: Maximum conceptual similarity weights using  the different formulae for the concepts in the example.  c 1 : first concept, c 2 : concept for which the maximum  similarity value was calculated. wp: Wu-Palmer similar- ity; pg X : Proxigenea similarity. score is the result of (5).", "labels": [], "entities": []}, {"text": " Table 3. The mea- sure selected is the normalised Pearson correlation  (", "labels": [], "entities": [{"text": "mea- sure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.8883945544560751}, {"text": "normalised Pearson correlation", "start_pos": 40, "end_pos": 70, "type": "METRIC", "confidence": 0.7843671242396036}]}, {"text": " Table 3: Results on training corpus, comparison of dif- ferent conceptual similarity measures and combination  method. Top: geometric mean, bottom: product.", "labels": [], "entities": []}, {"text": " Table 4: Results obtained on each test set, grouped by  conceptual similarity method. r indicates the ranking  among all the participants teams.", "labels": [], "entities": []}, {"text": " Table 5: Results obtained for each test set using only the  conceptual similarity measure (pg3) and only the struc- tural similarity measure (CKP D), compared to the re- sult obtained by the complete system (Combined).", "labels": [], "entities": [{"text": "conceptual similarity measure (pg3)", "start_pos": 61, "end_pos": 96, "type": "METRIC", "confidence": 0.7361894299586614}, {"text": "struc- tural similarity measure (CKP D)", "start_pos": 110, "end_pos": 149, "type": "METRIC", "confidence": 0.8091975880993737}]}]}