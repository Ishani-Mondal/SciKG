{"title": [{"text": "MIXCD: System Description for Evaluating Chinese Word Similarity at SemEval-2012", "labels": [], "entities": [{"text": "Evaluating Chinese Word Similarity", "start_pos": 30, "end_pos": 64, "type": "TASK", "confidence": 0.6819592267274857}, {"text": "SemEval-2012", "start_pos": 68, "end_pos": 80, "type": "TASK", "confidence": 0.3065377473831177}]}], "abstractContent": [{"text": "This document describes three systems calculating semantic similarity between two Chi-nese words.", "labels": [], "entities": []}, {"text": "One is based on Machine Readable Dictionaries and the others utilize both MRDs and Corpus.", "labels": [], "entities": []}, {"text": "These systems are performed on SemEval-2012 Task 4: Evaluating Chinese Word Similarity.", "labels": [], "entities": [{"text": "SemEval-2012 Task 4", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.8043882052103678}, {"text": "Evaluating Chinese Word Similarity", "start_pos": 52, "end_pos": 86, "type": "TASK", "confidence": 0.7572341710329056}]}], "introductionContent": [{"text": "The characteristics of polysemy and synonymy that exist in words of natural language have always been a challenge in the fields of Natural Language Processing (NLP) and Information Retrieval (IR).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 169, "end_pos": 195, "type": "TASK", "confidence": 0.8699570417404174}]}, {"text": "In many cases, humans have little difficulty in determining the intended meaning of an ambiguous word, while it is extremely difficult to replicate this process computationally.", "labels": [], "entities": [{"text": "determining the intended meaning of an ambiguous word", "start_pos": 48, "end_pos": 101, "type": "TASK", "confidence": 0.7181653864681721}]}, {"text": "For many tasks in psycholinguistics and NLP, a job is often decomposed to the requirement of resolving the semantic similarity between words or concepts.", "labels": [], "entities": []}, {"text": "There are two ways to get the similarity between two words.", "labels": [], "entities": []}, {"text": "One is to utilize the machine readable dictionary (MRD).", "labels": [], "entities": []}, {"text": "The other is to use the corpus.", "labels": [], "entities": []}, {"text": "For the 4 th task in SemEval-2012 we are required to evaluate the semantic similarity of Chinese word pairs.", "labels": [], "entities": []}, {"text": "We consider 3 methods in this study.", "labels": [], "entities": []}, {"text": "One uses MRDs only and the other two use both MRD and corpus.", "labels": [], "entities": []}, {"text": "A post processing will be done on the results of these methods to treat synonyms.", "labels": [], "entities": []}, {"text": "In chapter 2 we introduce the previous works on the evaluation of Semantic Similarity.", "labels": [], "entities": [{"text": "evaluation of Semantic Similarity", "start_pos": 52, "end_pos": 85, "type": "TASK", "confidence": 0.7255069017410278}]}, {"text": "Chapter 3 shows three methods used in this task.", "labels": [], "entities": []}, {"text": "Chapter 4 reveals the results of these methods.", "labels": [], "entities": []}, {"text": "And conclusion is stated in chapter 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform our systems on trial data and then use Kendall tau Rank Correlation to evaluate the results shown in Table 1.", "labels": [], "entities": []}, {"text": "The trial data contains 50 word pairs.", "labels": [], "entities": []}, {"text": "The similarity of each pair is scored by several experts and the mean value is regarded as the standard answer to get the manual ranking.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9861457943916321}]}, {"text": "From, we can seethe tau value of MIX-CD0 is 0.1526 and MIXCD is 0.2604.", "labels": [], "entities": [{"text": "MIX-CD0", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.891947865486145}, {"text": "MIXCD", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.6536750793457031}]}, {"text": "MIXCD performed notably better than MIXCD0.", "labels": [], "entities": [{"text": "MIXCD", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9425265789031982}]}, {"text": "It shows that path's length between two words is on an important position of measuring semantic similarity.", "labels": [], "entities": []}, {"text": "This feature does improve the similarity result.", "labels": [], "entities": [{"text": "similarity", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9857624769210815}]}, {"text": "The 2-sided p value of MIXCD0 is 0.1197.", "labels": [], "entities": [{"text": "MIXCD0", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.8763706088066101}]}, {"text": "It is much larger than the value of MIXCD which is 0.0078.", "labels": [], "entities": [{"text": "MIXCD", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8113165497779846}]}, {"text": "So the ranking result of MIXCD0 is much more occasional than result of MIXCD.", "labels": [], "entities": [{"text": "MIXCD0", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.8276582956314087}, {"text": "MIXCD", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.9344137907028198}]}], "tableCaptions": [{"text": " Table 1: Kendall tau Rank Correlation of systems on trial", "labels": [], "entities": []}, {"text": " Table 2: tau value on new standard (omit max/min manual  scores)", "labels": [], "entities": []}]}