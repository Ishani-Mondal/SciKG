{"title": [{"text": "Sentence Fusion for Multidocument News Summarization", "labels": [], "entities": [{"text": "Sentence Fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9223131239414215}, {"text": "Summarization", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.6790226697921753}]}], "abstractContent": [{"text": "A system that can produce informative summaries, highlighting common information found in many online documents, will help Web users to pinpoint information that they need without extensive reading.", "labels": [], "entities": []}, {"text": "In this article, we introduce sentence fusion, a novel text-to-text generation technique for synthesizing common information across documents.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7625323534011841}, {"text": "text-to-text generation", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.7962073683738708}]}, {"text": "Sentence fusion involves bottom-up local multisequence alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9293557107448578}]}, {"text": "Sentence fusion moves the summarization field from the use of purely extractive methods to the generation of abstracts that contain sentences not found in any of the input documents and can synthesize information across sources.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9325946867465973}, {"text": "summarization", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.9890726208686829}]}], "introductionContent": [{"text": "Redundancy in large text collections, such as the Web, creates both problems and opportunities for natural language systems.", "labels": [], "entities": []}, {"text": "On the one hand, the presence of numerous sources conveying the same information causes difficulties for end users of search engines and news providers; they must read the same information over and over again.", "labels": [], "entities": []}, {"text": "On the other hand, redundancy can be exploited to identify important and accurate information for applications such as summarization and question answering).", "labels": [], "entities": [{"text": "summarization", "start_pos": 119, "end_pos": 132, "type": "TASK", "confidence": 0.9903952479362488}, {"text": "question answering", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7920215725898743}]}, {"text": "Clearly, it would be highly desirable to have a mechanism that could identify common information among multiple related documents and fuse it into a coherent text.", "labels": [], "entities": []}, {"text": "In this article, we present a method for sentence fusion that exploits redundancy to achieve this task in the context of multidocument summarization.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.7380507588386536}, {"text": "multidocument summarization", "start_pos": 121, "end_pos": 148, "type": "TASK", "confidence": 0.6968111097812653}]}, {"text": "A straightforward approach for approximating sentence fusion can be found in the use of sentence extraction for multidocument summarization.", "labels": [], "entities": [{"text": "approximating sentence fusion", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.8672571380933126}, {"text": "sentence extraction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7247726172208786}, {"text": "multidocument summarization", "start_pos": 112, "end_pos": 139, "type": "TASK", "confidence": 0.6638728976249695}]}, {"text": "Once a system finds a set of sentences that convey similar information (e.g., by clustering), one of these sentences is selected to represent the set.", "labels": [], "entities": []}, {"text": "This is a robust approach that is always guaranteed to output a grammatical sentence.", "labels": [], "entities": []}, {"text": "However, extraction is only a coarse approximation of fusion.", "labels": [], "entities": [{"text": "extraction", "start_pos": 9, "end_pos": 19, "type": "TASK", "confidence": 0.9401299953460693}]}, {"text": "An extracted sentence may include not only common information, but additional information specific to the article from which it came, leading to source bias and aggravating fluency problems in the extracted summary.", "labels": [], "entities": []}, {"text": "Attempting to solve this problem by including more sentences to restore the original context might lead to a verbose and repetitive summary.", "labels": [], "entities": []}, {"text": "Instead, we want a fine-grained approach that can identify only those pieces of sentences that are common.", "labels": [], "entities": []}, {"text": "Language generation offers an appealing approach to the problem, but the use of generation in this context raises significant research challenges.", "labels": [], "entities": [{"text": "Language generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6754052191972733}]}, {"text": "In particular, generation for sentence fusion must be able to operate in a domainindependent fashion, scalable to handle a large variety of input documents with various degrees of overlap.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7471587061882019}]}, {"text": "In the past, generation systems were developed for limited domains and required a rich semantic representation as input.", "labels": [], "entities": []}, {"text": "In contrast, for this task we require text-to-text generation, the ability to produce anew text given a set of related texts as input.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.6976148784160614}]}, {"text": "If language generation can be scaled to take fully formed text as input without semantic interpretation, selecting content and producing well-formed English sentences as output, then generation has a large potential payoff.", "labels": [], "entities": []}, {"text": "In this article, we present the concept of sentence fusion, a novel text-to-text generation technique which, given a set of similar sentences, produces anew sentence containing the information common to most sentences in the set.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.7207796722650528}]}, {"text": "The research challenges in developing such an algorithm lie in two areas: identification of the fragments conveying common information and combination of the fragments into a sentence.", "labels": [], "entities": [{"text": "identification of the fragments conveying common information", "start_pos": 74, "end_pos": 134, "type": "TASK", "confidence": 0.7276791078703744}]}, {"text": "To identify common information, we have developed a method for aligning syntactic trees of input sentences, incorporating paraphrasing information.", "labels": [], "entities": []}, {"text": "Our alignment problem poses unique challenges: We only want to match a subset of the subtrees in each sentence and are given few constraints on permissible alignments (e.g., arising from constituent ordering, start or end points).", "labels": [], "entities": []}, {"text": "Our algorithm meets these challenges through bottom-up local multisequence alignment, using words and paraphrases as anchors.", "labels": [], "entities": [{"text": "multisequence alignment", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.711556613445282}]}, {"text": "Combination of fragments is addressed through construction of a fusion lattice encompassing the resulting alignment and linearization of the lattice into a sentence using a language model.", "labels": [], "entities": []}, {"text": "Our approach to sentence fusion thus features the integration of robust statistical techniques, such as local, multisequence alignment and language modeling, with linguistic representations automatically derived from input documents.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7950628995895386}, {"text": "multisequence alignment", "start_pos": 111, "end_pos": 134, "type": "TASK", "confidence": 0.743170291185379}]}, {"text": "Sentence fusion is a significant first step toward the generation of abstracts, as opposed to extracts, for multidocument summarization.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8984913229942322}]}, {"text": "Unlike extraction methods (used by the vast majority of summarization researchers), sentence fusion allows for the true synthesis of information from a set of input documents.", "labels": [], "entities": [{"text": "summarization", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.9620777368545532}, {"text": "sentence fusion", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.7790081202983856}]}, {"text": "It has been shown that combining information from several sources is a natural strategy for multidocument summarization.", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.6796018779277802}]}, {"text": "Analysis of human-written summaries reveals that most sentences combine information drawn from multiple documents ().", "labels": [], "entities": []}, {"text": "Sentence fusion achieves this goal automatically.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.935142308473587}]}, {"text": "Our evaluation shows that our approach is promising, with sentence fusion outperforming sentence extraction for the task of content selection.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7120942622423172}, {"text": "sentence extraction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7440098524093628}, {"text": "content selection", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.6997066289186478}]}, {"text": "This article focuses on the implementation and evaluation of the sentence fusion method within the multidocument summarization system MultiGen, which daily summarizes multiple news articles on the same event as part 1 of Columbia's news browsing system Newsblaster (http:/ /newsblaster.cs.columbia.edu/).", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7184699922800064}]}, {"text": "In the next section, we provide an overview of MultiGen, focusing on components that produce input or operate over output of sentence fusion.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 125, "end_pos": 140, "type": "TASK", "confidence": 0.7182971686124802}]}, {"text": "In Section 3, we provide an overview of our fusion algorithm and detail on its main steps: identification of common information (Section 3.1), fusion lattice computation (Section 3.2), and lattice linearization (Section 3.3).", "labels": [], "entities": []}, {"text": "Evaluation results and their analysis are presented in Section 4.", "labels": [], "entities": []}, {"text": "Analysis of the system's output reveals the capabilities and the weaknesses of our textto-text generation method and identifies interesting challenges that will require new insights.", "labels": [], "entities": [{"text": "textto-text generation", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.7986602187156677}]}, {"text": "An overview of related work and a discussion of future directions conclude the article.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our previous work, we evaluated the overall summarization strategy of MultiGen in multiple experiments, including comparisons with human-written summaries in the Document Understanding Conference (DUC) 11 evaluation ( and quality assessment in the context of a particular information access task in the Newsblaster framework (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.9697182774543762}, {"text": "Newsblaster framework", "start_pos": 306, "end_pos": 327, "type": "DATASET", "confidence": 0.953584611415863}]}, {"text": "In this article, we aim to evaluate the sentence fusion algorithm in isolation from other system components; we analyze the algorithm performance in terms of content selection and the grammaticality of the produced sentences.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7252082973718643}]}, {"text": "We first present our evaluation methodology (Section 4.1), then we describe our data (Section 4.2), the results (Section 4.3), and our analysis of them (Section 4.4).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Node and edge similarity scores used by the alignment algorithm.", "labels": [], "entities": [{"text": "edge similarity scores", "start_pos": 19, "end_pos": 41, "type": "METRIC", "confidence": 0.828687846660614}]}, {"text": " Table 7  Evaluation results for a human-crafted fusion sentence (RFA2), our system output, the shortest  sentence in the theme (baseline 1), the basis sentence (baseline 2), and a simplified version of our  algorithm without paraphrasing information (baseline 3).", "labels": [], "entities": []}]}