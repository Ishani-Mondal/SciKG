{"title": [{"text": "Clustering Syntactic Positions with Similar Semantic Requirements", "labels": [], "entities": []}], "abstractContent": [{"text": "This article describes an unsupervised strategy to acquire syntactico-semantic requirements of nouns, verbs, and adjectives from partially parsed text corpora.", "labels": [], "entities": []}, {"text": "The linguistic notion of requirement underlying this strategy is based on two specific assumptions.", "labels": [], "entities": []}, {"text": "First, it is assumed that two words in a dependency are mutually required.", "labels": [], "entities": []}, {"text": "This phenomenon is called here corequirement.", "labels": [], "entities": [{"text": "here corequirement", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.522940993309021}]}, {"text": "Second, it is also claimed that the set of words occurring in similar positions defines extensionally the requirements associated with these positions.", "labels": [], "entities": []}, {"text": "The main aim of the learning strategy presented in this article is to identify clusters of similar positions by identifying the words that define their requirements extensionally.", "labels": [], "entities": []}, {"text": "This strategy allows us to learn the syntactic and semantic requirements of words in different positions.", "labels": [], "entities": []}, {"text": "This information is used to solve attachment ambiguities.", "labels": [], "entities": []}, {"text": "Results of this particular task are evaluated at the end of the article.", "labels": [], "entities": []}, {"text": "Extensive experimentation was performed on Portuguese text corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word forms, as atoms, cannot arbitrarily combine with each other.", "labels": [], "entities": []}, {"text": "They form new composites by both imposing and satisfying certain requirements.", "labels": [], "entities": []}, {"text": "A word uses a linguistic requirement (constraint or preference) in order to restrict the type of words with which it can combine in a particular position.", "labels": [], "entities": []}, {"text": "The requirement of a given word is characterized by at least two different objects: the position occupied by the words that can be combined with the given word and the condition that those words must satisfy in order to be in that position.", "labels": [], "entities": []}, {"text": "For a word wand a specific description of a location loc, the pair bloc, w\u00c0 represents a position with regard tow.", "labels": [], "entities": []}, {"text": "In addition, set represents the scope of the condition.", "labels": [], "entities": []}, {"text": "The larger the set of similar positions, the larger the condition scope, and the more general the property used to characterize the condition.", "labels": [], "entities": []}, {"text": "We distinguish syntactic and semantic requirements.", "labels": [], "entities": []}, {"text": "A syntactic requirement is characterized by both a position and a morpho-syntactic condition.", "labels": [], "entities": []}, {"text": "For instance, requirement bbof_right, ratification\u00c0, np\u00c0 consists of a position, bof_right, ratification\u00c0, which selects fora nominal phrase.", "labels": [], "entities": []}, {"text": "Note that the different syntactic requirements of a word can serve to identify the set of subcategorization frames of that word.", "labels": [], "entities": []}, {"text": "Note also that, in some cases, a particular position presupposes a particular morpho-syntactic condition.", "labels": [], "entities": []}, {"text": "In our example, position bof_right, ratification\u00c0 requires only a np.", "labels": [], "entities": []}, {"text": "So we can use this position as a shorter form of the syntactic requirement bbof_right, ratification\u00c0, np\u00c0.", "labels": [], "entities": []}, {"text": "We calla syntactic position a position that presupposes a specific morphosyntactic condition.", "labels": [], "entities": []}, {"text": "On the other hand, a semantic requirement (also known as selection restriction) is characterized by both a position and a semantic condition, which presupposes a syntactic one.", "labels": [], "entities": []}, {"text": "So bbof_right, ratification\u00c0,doc\u00c0 means that position bof_right, ratification\u00c0 selects for the head of a np denoting a legal document.", "labels": [], "entities": []}, {"text": "Condition doc presupposes then a np.", "labels": [], "entities": []}, {"text": "Identifying a particular semantic requirement entails the identification of the underlying syntactic one.", "labels": [], "entities": []}, {"text": "The final linguistic issue to be introduced is the phenomenon referred to as corequirements.", "labels": [], "entities": []}, {"text": "It is assumed that each syntactic dependency between two words (which are the heads of two phrases) is composed of two complementary requirements.", "labels": [], "entities": []}, {"text": "For instance, it seems that two different requirements underlie the expression ratification of the treaty: bof_right, ratification\u00c0 (ratification of) needs to be filled by words like treaty, while bof_left, treaty\u00c0 ( of the treaty) needs to appear with words such as ratification.", "labels": [], "entities": []}, {"text": "The main objective of this article is to describe an unsupervised method for learning syntactic and semantic requirements from large text corpora.", "labels": [], "entities": [{"text": "learning syntactic and semantic requirements from large text corpora", "start_pos": 77, "end_pos": 145, "type": "TASK", "confidence": 0.641680896282196}]}, {"text": "For instance, our method discovers that the word secretary is associated with several syntactic positions (i.e., positions with morpho-syntactic conditions), such as secretary of, of the secretary, to the secretary, and with the secretary.", "labels": [], "entities": []}, {"text": "The set of syntactic positions defined by a word can be used to characterize a set of subcategorization frames.", "labels": [], "entities": []}, {"text": "The precise characterization of these frames remains, however, beyond the scope of this article.", "labels": [], "entities": []}, {"text": "In addition, for each syntactic position, we assess the specific semantic condition a word needs to fill in order to appear in that position.", "labels": [], "entities": []}, {"text": "Another important objective of the article is to use the semantic requirements to capture contextually relevant semantic similarities between words.", "labels": [], "entities": []}, {"text": "In particular, we assume that two words filling the same semantic requirement share the same contextual word sense.", "labels": [], "entities": []}, {"text": "Consequently, learning semantic requirements also leads us to induce word senses.", "labels": [], "entities": []}, {"text": "Suppose that the word organization fills the condition imposed by secretary of.", "labels": [], "entities": []}, {"text": "In this syntactic context, the word denotes asocial institution and not a temporal processor an abstract setup.", "labels": [], "entities": []}, {"text": "To achieve our objectives, we follow a particular clustering strategy.", "labels": [], "entities": []}, {"text": "Syntactic positions (and not words) are compared according to their word distribution.", "labels": [], "entities": []}, {"text": "Similar syntactic positions are put in more clusters following some constraints that are defined later.", "labels": [], "entities": []}, {"text": "Each cluster of positions represents a semantic condition.", "labels": [], "entities": []}, {"text": "The features of each cluster are the words that can fill the common condition imposed by those positions: They are the fillers.", "labels": [], "entities": []}, {"text": "They are used to extensionally define the particular condition they can fill.", "labels": [], "entities": []}, {"text": "That is, a condition is defined by identifying those words likely to appear in positions considered similar.", "labels": [], "entities": []}, {"text": "Given that a condition is extensionally defined by the words that are able to fill it, our method describes the process of satisfying a condition as a Boolean constraint (yes/no) and not as a probabilistic preference.", "labels": [], "entities": []}, {"text": "The similar positions defining a cluster are within the scope of a particular semantic condition.", "labels": [], "entities": []}, {"text": "The association between each position of the cluster and that condition characterizes the semantic requirement of a word.", "labels": [], "entities": []}, {"text": "This learning strategy does not require hand-crafted external resources such as a WordNet-like thesaurus or a machine-readable dictionary.", "labels": [], "entities": []}, {"text": "The information captured by this strategy is useful for two different NLP disambiguation tasks: selecting contextual senses of words (word sense disambiguation) and solving structural ambiguity (attachment resolution).", "labels": [], "entities": [{"text": "NLP disambiguation", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.7400246262550354}, {"text": "attachment resolution", "start_pos": 195, "end_pos": 216, "type": "TASK", "confidence": 0.6499295681715012}]}, {"text": "This article is focused on the latter application.", "labels": [], "entities": []}, {"text": "In sum, the main contribution of our work is the large amount of linguistic information we learn for each lexical word.", "labels": [], "entities": []}, {"text": "Given a word, we acquire, at least, three types of information: (1) an unordered set of syntactic positions, which is a first approximation to define the set of subcategorization frames of the given word, (2) the semantic requirements the word imposes on its arguments, and (3) the different contextual senses of the word.", "labels": [], "entities": []}, {"text": "By contrast, related work focuses only on one or two aspects of this linguistic information.", "labels": [], "entities": []}, {"text": "Another contribution is the use of corequirements to characterize the arguments of a word.", "labels": [], "entities": [{"text": "characterize the arguments of a word", "start_pos": 53, "end_pos": 89, "type": "TASK", "confidence": 0.8048876027266184}]}, {"text": "To conclude the introduction, let's outline the organization of the article.", "labels": [], "entities": []}, {"text": "In the next section, we situate our approach with regard to related work on acquisition of linguistic requirements.", "labels": [], "entities": [{"text": "acquisition of linguistic requirements", "start_pos": 76, "end_pos": 114, "type": "TASK", "confidence": 0.882877379655838}]}, {"text": "Later, in sections 3 and 4, we describe in detail the main linguistic assumptions underlying our approach.", "labels": [], "entities": []}, {"text": "Special attention will be paid to both the relativized view on word sense (i.e., contextual sense) and corequirements.", "labels": [], "entities": []}, {"text": "Then, section 5 depicts a general overview of our strategy.", "labels": [], "entities": []}, {"text": "Two particular aspects of this strategy are analyzed next.", "labels": [], "entities": []}, {"text": "More precisely, section 6 describes both how syntactic positions are extracted and how they are clustered in larger classes (section 7).", "labels": [], "entities": []}, {"text": "Finally, in section 8, we evaluate the results by measuring their performance in a particular NLP task: syntactic-attachment resolution.", "labels": [], "entities": [{"text": "syntactic-attachment resolution", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.7307808250188828}]}], "datasetContent": [{"text": "The acquired classes are used to solve attachment ambiguities.", "labels": [], "entities": []}, {"text": "For this purpose, first, a lexicon is designed by using the linguistic information contained in the learned clusters.", "labels": [], "entities": []}, {"text": "Then a particular heuristic uses this information to propose correct attachments.", "labels": [], "entities": []}, {"text": "Some experiments are performed on two text corpora.", "labels": [], "entities": []}, {"text": "The results are evaluated in section 8.3.", "labels": [], "entities": []}, {"text": "(administration, assembly, authority, chief, commander, commission, council, director, direction, entity, state, official, cabinet, governor, government, institute, judge, member, minister, ministry, president, purveyor, secretary, secretary, mister, service, tribunal, organ) & primeiro-ministro, autoridade, entidade, estado, membro, ministro, ministe \u00a4 rio, presidente, secreta \u00a4 rio (prime minister, authority, entity, state, member, minister, ministry, president, secretary)", "labels": [], "entities": [{"text": "(administration, assembly, authority, chief, commander, commission, council, director, direction, entity, state, official, cabinet, governor, government, institute, judge, member, minister, ministry, president, purveyor, secretary, secretary, mister, service, tribunal, organ) & primeiro-ministro, autoridade, entidade, estado, membro, ministro, ministe \u00a4 rio, presidente, secreta \u00a4 rio (prime minister, authority, entity, state, member, minister, ministry, president, secretary)", "start_pos": 0, "end_pos": 479, "type": "Description", "confidence": 0.8797330353597198}]}], "tableCaptions": [{"text": " Table 11  Total scores of the three methods. For each method, we compute the average of the three  sequences and the two corpora.", "labels": [], "entities": []}]}