{"title": [{"text": "Chinese Word Segmentation and Named Entity Recognition: A Pragmatic Approach", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5642978549003601}, {"text": "Named Entity Recognition", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.7421103119850159}]}], "abstractContent": [{"text": "This article presents a pragmatic approach to Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.5905362764994303}]}, {"text": "It differs from most previous approaches mainly in three respects.", "labels": [], "entities": []}, {"text": "First, while theoretical linguists have defined Chinese words using various linguistic criteria, Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications.", "labels": [], "entities": []}, {"text": "Second, we propose a pragmatic mathematical framework in which segmenting known words and detecting unknown words of different types (i.e., morphologically derived words, factoids, named entities, and other unlisted words) can be performed simultaneously in a unified way.", "labels": [], "entities": [{"text": "segmenting known words and detecting unknown words of different types (i.e., morphologically derived words, factoids, named entities, and other unlisted words)", "start_pos": 63, "end_pos": 222, "type": "Description", "confidence": 0.7400089458183006}]}, {"text": "These tasks are usually conducted separately in other systems.", "labels": [], "entities": []}, {"text": "Finally, we do not assume the existence of a universal word segmentation standard that is application-independent.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7575493156909943}]}, {"text": "Instead, we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different natural language processing applications might require different granularities of Chinese words.", "labels": [], "entities": []}, {"text": "These pragmatic approaches have been implemented in an adaptive Chinese word segmenter, called MSRSeg, which will be described in detail.", "labels": [], "entities": [{"text": "Chinese word segmenter", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.7052081624666849}]}, {"text": "It consists of two components: (1) a generic segmenter that is based on the framework of linear mixture models and provides a unified approach to the five fundamental features of word-level Chinese language processing: lexicon word processing, morphological analysis, factoid detection, named entity recognition, and new word identification; and (2) a set of output adaptors for adapting the output of (1) to different application-specific standards.", "labels": [], "entities": [{"text": "factoid detection", "start_pos": 268, "end_pos": 285, "type": "TASK", "confidence": 0.8790752291679382}, {"text": "named entity recognition", "start_pos": 287, "end_pos": 311, "type": "TASK", "confidence": 0.6333910723527273}, {"text": "word identification", "start_pos": 321, "end_pos": 340, "type": "TASK", "confidence": 0.7311270385980606}]}, {"text": "Evaluation on five test sets with different standards shows that the adaptive system achieves state-of-the-art performance on all the test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "This article is intended to address, with a unified and pragmatic approach, two fundamental questions in Chinese natural language processing (NLP): What is a 'word' in Chinese?, and How does a computer identify Chinese words automatically?", "labels": [], "entities": [{"text": "Chinese natural language processing (NLP)", "start_pos": 105, "end_pos": 146, "type": "TASK", "confidence": 0.7576873643057687}]}, {"text": "Our approach is distinguished from most previous approaches by the following three unique components that are integrated into a single model: a taxonomy of Chinese words, a unified approach to word breaking and unknown word detection, and a customizable display of word segmentation.", "labels": [], "entities": [{"text": "word breaking and unknown word detection", "start_pos": 193, "end_pos": 233, "type": "TASK", "confidence": 0.7094926436742147}, {"text": "word segmentation", "start_pos": 265, "end_pos": 282, "type": "TASK", "confidence": 0.7013518214225769}]}, {"text": "We will describe each of these in turn.", "labels": [], "entities": []}, {"text": "Chinese word segmentation is challenging because it is often difficult to define what constitutes a word in Chinese.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5747186442216238}]}, {"text": "Theoretical linguists have tried to define Chinese words using various linguistic criteria (e.g.,.", "labels": [], "entities": []}, {"text": "While each of those criteria provides valuable insights into \"word-hood\" in Chinese, they do not consistently lead us to the same conclusions.", "labels": [], "entities": []}, {"text": "Fortunately, this may not be a serious issue in computational linguistics, where the definition of words can vary and can depend to a large degree upon how one uses and processes these words in computer applications.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.7251729667186737}]}, {"text": "In this article, we define the concept of Chinese words from the viewpoint of computational linguistics.", "labels": [], "entities": []}, {"text": "We develop a taxonomy in which Chinese words can be categorized into one of the following five types: lexicon words, morphologically derived words, factoids, named entities, and new words.", "labels": [], "entities": []}, {"text": "These five types of words have different computational properties and are processed in different ways in our system, as will be described in detail in Section 3.", "labels": [], "entities": []}, {"text": "Two of these five types, factoids and named entities, are not important to theoretical linguists but are significant in NLP.", "labels": [], "entities": []}, {"text": "Chinese word segmentation involves mainly two research issues: word boundary disambiguation and unknown word identification.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5868942340215048}, {"text": "word boundary disambiguation", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.6749486823876699}, {"text": "unknown word identification", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.6743906637032827}]}, {"text": "In most of the current systems, these are considered to be two separate tasks and are dealt with using different components in a cascaded or consecutive manner.", "labels": [], "entities": []}, {"text": "However, we believe that these two issues are not separate in nature and are better approached simultaneously.", "labels": [], "entities": []}, {"text": "In this article, we present a unified approach to the five fundamental features of word-level Chinese NLP (corresponding to the five types of words described earlier): (1) word breaking, (2) morphological analysis, (3) factoid detection, (4) named entity recognition (NER), and (5) new word identification (NWI).", "labels": [], "entities": [{"text": "word breaking", "start_pos": 172, "end_pos": 185, "type": "TASK", "confidence": 0.782754510641098}, {"text": "factoid detection", "start_pos": 219, "end_pos": 236, "type": "TASK", "confidence": 0.8770509958267212}, {"text": "named entity recognition (NER)", "start_pos": 242, "end_pos": 272, "type": "TASK", "confidence": 0.778432086110115}, {"text": "new word identification (NWI)", "start_pos": 282, "end_pos": 311, "type": "TASK", "confidence": 0.6968541840712229}]}, {"text": "This approach is based on a mathematical framework of linear mixture models in which component models are inspired by the source-channel models of Chinese sentence generation.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 147, "end_pos": 174, "type": "TASK", "confidence": 0.6782857875029246}]}, {"text": "There are basically two types of component models: a source model and a set of channel models.", "labels": [], "entities": []}, {"text": "The source model is used to estimate the generative probability of a word sequence in which each word belongs to one word type.", "labels": [], "entities": []}, {"text": "For each of the word types, a channel model is used to estimate the likelihood of a character string, given the word type.", "labels": [], "entities": []}, {"text": "We shall show that this framework is flexible enough to incorporate a wide variety of linguistic knowledge and statistical models in a unified way.", "labels": [], "entities": []}, {"text": "In computer applications, we are more concerned with segmentation units than words.", "labels": [], "entities": []}, {"text": "While words are supposed to be unambiguous and static linguistic entities, segmentation units are expected to vary from application to application.", "labels": [], "entities": []}, {"text": "In fact, different Chinese NLP-enabled applications may have different requirements that request different granularities of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.717368945479393}]}, {"text": "For example, automatic speech recognition (ASR) systems prefer longer \"words\" to achieve higher accuracy, whereas in-formation retrieval (IR) systems prefer shorter \"words\" to obtain higher recall rates.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.7810714840888977}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9967286586761475}, {"text": "in-formation retrieval (IR)", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.7228569030761719}, {"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9955946803092957}]}, {"text": "Therefore, we do not assume that an application-independent universal word segmentation standard exists.", "labels": [], "entities": [{"text": "application-independent universal word segmentation", "start_pos": 36, "end_pos": 87, "type": "TASK", "confidence": 0.5868512317538261}]}, {"text": "We argue instead for the existence of multiple segmentation standards, each fora specific application.", "labels": [], "entities": []}, {"text": "It is undesirable to develop a set of application-specific segmenters.", "labels": [], "entities": []}, {"text": "A better solution would be to develop a generic segmenter with customizable output that is able to provide alternative segmentation units according to the specification that is either predefined or implied in the application data.", "labels": [], "entities": []}, {"text": "To achieve this, we present a transformation-based learning (TBL; Brill 1995) method, to be described in Section 6.", "labels": [], "entities": []}, {"text": "We implement the pragmatic approach to Chinese word segmentation in an adaptive Chinese word segmenter called MSRSeg.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6289351185162863}]}, {"text": "It consists of two components: (1) a generic segmenter that is based on the linear mixture model framework of word breaking and unknown word detection and that can adapt to domain-specific vocabularies, and (2) a set of output adaptors for adapting the output of (1) to different application-specific standards.", "labels": [], "entities": [{"text": "word breaking and unknown word detection", "start_pos": 110, "end_pos": 150, "type": "TASK", "confidence": 0.6639960159858068}]}, {"text": "Evaluation on five test sets with different standards shows that the adaptive system achieves state-of-the-art performance on all the test sets.", "labels": [], "entities": []}, {"text": "It thus demonstrates the possibility of a single adaptive Chinese word segmenter that is capable of supporting multiple applications.", "labels": [], "entities": [{"text": "Chinese word segmenter", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.6982970833778381}]}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents previous work in this field.", "labels": [], "entities": []}, {"text": "Section 3 introduces the taxonomy of Chinese words and describes the corpora we used in our study.", "labels": [], "entities": []}, {"text": "Section 4 presents some of the theoretical background on which our unified approach is based.", "labels": [], "entities": []}, {"text": "Section 5 outlines the general architecture of the Chinese word segmenter, MSRSeg, and describes each of the components in detail, presenting a separate evaluation of each component where appropriate.", "labels": [], "entities": []}, {"text": "Section 6 presents the TBL method of standards adaptation.", "labels": [], "entities": [{"text": "TBL", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.3959819972515106}, {"text": "standards adaptation", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.6975380182266235}]}, {"text": "While in Section 5 we presume the existence of an annotated training corpus, we focus in Section 7 on the methods of creating training data in a (semi-)automatic manner, with minimal or no human annotation.", "labels": [], "entities": []}, {"text": "We thus demonstrate the possibilities of unsupervised learning of Chinese words.", "labels": [], "entities": []}, {"text": "Section 8 presents several evaluations of the system on the different corpora, each corresponding to a different segmentation standard, in comparison with other state-of-the-art systems.", "labels": [], "entities": []}, {"text": "Finally, we conclude the article in Section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "The performance of Chinese word segmenters is generally reported in terms of precision and recall.", "labels": [], "entities": [{"text": "Chinese word segmenters", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.5781330863634745}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.999603807926178}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9974997639656067}]}, {"text": "However, a comparison across systems could be very difficult for two reasons.", "labels": [], "entities": []}, {"text": "First, the \"correct\" segmentation is not clearly defined.", "labels": [], "entities": []}, {"text": "It is common that fora given sentence there are multiple plausible word segmentations.", "labels": [], "entities": []}, {"text": "As shown in, the rate of agreement between two human judges is less than 80%.", "labels": [], "entities": [{"text": "rate of agreement", "start_pos": 17, "end_pos": 34, "type": "METRIC", "confidence": 0.8247023423512777}]}, {"text": "To deal with this problem, suggest a procedure called nk-blind that uses n blind judges' standards.", "labels": [], "entities": []}, {"text": "If we set k = 1, it is sufficient fora segmentation to be considered correct if it agrees with at least one of then judges.", "labels": [], "entities": []}, {"text": "If k = n, all judges must agree.", "labels": [], "entities": []}, {"text": "Therefore, nk-blind gives a more representative performance measure by taking into account multiple judges.", "labels": [], "entities": []}, {"text": "Similarly, also uses multiple human judges.", "labels": [], "entities": []}, {"text": "In Section 8.2, we will present our method for cross-system comparison.", "labels": [], "entities": []}, {"text": "We do not use multiple human judges.", "labels": [], "entities": []}, {"text": "Instead, we only consider a set of measures that are lexicon-independent and less ambiguous among different human judges and systems.", "labels": [], "entities": []}, {"text": "The second reason that cross-system comparisons are difficult concerns the use of different test sets and ground rules by many research papers.", "labels": [], "entities": []}, {"text": "For example, some papers report precision and recall rates of 98% or 99%.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9996298551559448}, {"text": "recall rates", "start_pos": 46, "end_pos": 58, "type": "METRIC", "confidence": 0.9779261946678162}]}, {"text": "But they either count only the words that are stored in the dictionary or use unrealistically simple data with a very low OOV rate.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9759335517883301}]}, {"text": "Recently, the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff alleviated the situation to some degree.", "labels": [], "entities": [{"text": "ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff", "start_pos": 14, "end_pos": 88, "type": "TASK", "confidence": 0.6613541288035256}]}, {"text": "The Bakeoff released four data sets, each corresponding to a different standard, and consistent train-test splits.", "labels": [], "entities": [{"text": "Bakeoff", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.7808910608291626}]}, {"text": "We evaluate our segmenter using those four data sets in Sections 6.2 and 8.3.", "labels": [], "entities": []}, {"text": "As described earlier, we argue that Chinese words (or segmentation units) cannot be defined independently of the applications, and hence a more flexible system (i.e., an adaptive segmenter such as MSRSeg) should be adopted.", "labels": [], "entities": []}, {"text": "However, we are faced with the challenge of performing an objective and rigorous evaluation of such a system.", "labels": [], "entities": []}, {"text": "In general, the evaluation of NLP systems is concerned with both the criteria and the standard data sets.", "labels": [], "entities": []}, {"text": "In this article, we argue that MSRSeg is a better system in two regards.", "labels": [], "entities": []}, {"text": "First, the generic segmenter provides not only word segmentation but also word-internal structures (e.g., the tree structures of MDWs, FTs, and NEs, as will be described in Section 6) that coverall possible segmentations.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7035275399684906}]}, {"text": "Ideally, such a segmenter provides a superset of segmentation units where each different application can find the subset it needs.", "labels": [], "entities": []}, {"text": "Second, the output adaptors of MSRSeg can automatically pick different subsets (i.e., segmentation units) from the superset according to different applications.", "labels": [], "entities": []}, {"text": "Therefore, there are two criteria for evaluating an adaptive segmenter: how complete the superset is and how effective the adaptation is.", "labels": [], "entities": []}, {"text": "The real evaluation will require some application data sets (i.e., segmented texts used by different applications).", "labels": [], "entities": []}, {"text": "However, such application data are not available yet, and no other system has undergone such evaluation, so there is noway to compare our system against others in this fashion.", "labels": [], "entities": []}, {"text": "The evaluation methodology we adopted in this article is a simulation.", "labels": [], "entities": []}, {"text": "On the one hand, we developed a generic standard and a corresponding gold test set that simulates the generic superset that attempts to cover as many applications as possible.", "labels": [], "entities": []}, {"text": "We then evaluate on the data set the completeness of the generic segmenter.", "labels": [], "entities": []}, {"text": "On the other hand, we will show that we can effectively adapt the generic segmenter to the four different bakeoff data sets, each of which simulates an application subset.", "labels": [], "entities": []}, {"text": "The evaluation measures we use in this study are summarized in.", "labels": [], "entities": []}, {"text": "The performance of MSRSeg is measured through multiple precision-recall (P/R) pairs, and F-measures (defined as 2PR/(P+R)), each for one word type.", "labels": [], "entities": [{"text": "precision-recall (P/R) pairs", "start_pos": 55, "end_pos": 83, "type": "METRIC", "confidence": 0.885549145085471}, {"text": "F-measures", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9797092080116272}]}, {"text": "Riv is the recall of in-vocabulary words.", "labels": [], "entities": [{"text": "Riv", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9136760830879211}]}, {"text": "Roov is the recall of OOV words.", "labels": [], "entities": [{"text": "Roov", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7129685282707214}, {"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9301335215568542}]}, {"text": "They are used to measure the segmenter's performance in resolving ambiguities in word segmentation and detecting unknown words, respectively.", "labels": [], "entities": [{"text": "resolving ambiguities in word segmentation", "start_pos": 56, "end_pos": 98, "type": "TASK", "confidence": 0.6136848032474518}]}, {"text": "We also test the statistical significance of results, using the criterion proposed by.", "labels": [], "entities": []}, {"text": "In addition to Riv, the number of OAS (overlap ambiguity string) and CAS (combination ambiguity string) errors are used to measure the segmenter's performance of resolving ambiguities in word segmentation in more detail.", "labels": [], "entities": [{"text": "OAS", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9962164759635925}, {"text": "CAS (combination ambiguity string) errors", "start_pos": 69, "end_pos": 110, "type": "METRIC", "confidence": 0.8449733512742179}, {"text": "resolving ambiguities in word segmentation", "start_pos": 162, "end_pos": 204, "type": "TASK", "confidence": 0.5882439494132996}]}, {"text": "defines OAS and CAS as follows.", "labels": [], "entities": [{"text": "OAS", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.4520772099494934}]}, {"text": "The NWI component has been constructed as an SVM classifier.", "labels": [], "entities": []}, {"text": "This section discusses two factors that we believe have the most impact on the performance of NWI.", "labels": [], "entities": [{"text": "NWI", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.8722976446151733}]}, {"text": "First, we investigate the relative contribution of the four linguistically motivated features in NWI.", "labels": [], "entities": []}, {"text": "Second, we compare methods where we use the NWI component (i.e., an SVM classifier) as a post-processor versus as a feature function in the linear models of Equation (4).", "labels": [], "entities": []}, {"text": "The NWI results on the PK test set are shown in.", "labels": [], "entities": [{"text": "PK test set", "start_pos": 23, "end_pos": 34, "type": "DATASET", "confidence": 0.8974676728248596}]}, {"text": "We turned off the features one at a time and recorded the scores of each ablated NWI component.", "labels": [], "entities": []}, {"text": "It turns out that in cases of both NW 11 and NW 12, IWP is obviously the most effective feature show results of NWI on four Bakeoff test sets.", "labels": [], "entities": [{"text": "NW 12", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.6698301434516907}, {"text": "IWP", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9124304056167603}, {"text": "Bakeoff test sets", "start_pos": 124, "end_pos": 141, "type": "DATASET", "confidence": 0.9163039922714233}]}, {"text": "We can see that unified approaches (i.e., using the NWI component as a feature function) significantly outperform consecutive approaches (i.e., using the NWI component as a post-processor) consistently, in terms of both Roov and P/R/F of the overall word segmentation.", "labels": [], "entities": [{"text": "Roov", "start_pos": 220, "end_pos": 224, "type": "METRIC", "confidence": 0.984160840511322}, {"text": "F", "start_pos": 233, "end_pos": 234, "type": "METRIC", "confidence": 0.7053657174110413}, {"text": "word segmentation", "start_pos": 250, "end_pos": 267, "type": "TASK", "confidence": 0.7251653522253036}]}, {"text": "This demonstrates empirically the benefits of using the context model for NWI and the unified approach to Chinese word segmentation, as described in 5.5.2.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.5831399659315745}]}, {"text": "To justify the methods just described, we built a large number of context models using different initial corpora.", "labels": [], "entities": []}, {"text": "For each of the initial corpora, a context model is trained using the Viterbi iterative procedure until convergence, i.e., the improvement of the word segmentation performance of the resulting system, is less than a preset threshold.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.6839476227760315}]}, {"text": "The results are shown in, where Row 1 (FMM) presents the segmentation results of using the initial corpus segmented by a greedy word segmenterthe basic solution described earlier; in Row 2, we resolve segmentation (overlap) ambiguities on top of the corpus in Row 1; we then tag FTs in Rows 3 and 4.", "labels": [], "entities": []}, {"text": "From Rows 5 to 8, several NE annotated seed sets of different sizes are used, showing the trade-off between performance and human cost.", "labels": [], "entities": [{"text": "NE annotated seed sets", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.6976221054792404}]}, {"text": "In Rows 1 to 8, we use the raw training set containing approximately 50 million characters.", "labels": [], "entities": []}, {"text": "For comparison, we also include in Row 9 the results of MSRSeg, whose context model has been trained on a 20-million-word manually annotated corpus.", "labels": [], "entities": [{"text": "MSRSeg", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.9006264805793762}]}, {"text": "The experimental results reveal several facts.", "labels": [], "entities": []}, {"text": "r Although the greedy segmenter (FMM) can resolve around 90% of ambiguities in word segmentation, as shown in, the resulting segmenter is still much worse than MSRSeg because a large number of unknown words cannot be detected correctly even after Viterbi iterative learning.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7253615260124207}]}, {"text": "r The method of resolving OA brings marginal improvements.", "labels": [], "entities": [{"text": "resolving OA", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.7552894353866577}]}, {"text": "Since the method does not require any human annotation, Row 2 shows the best results we achieved in our experiments using unsupervised learning approaches.", "labels": [], "entities": []}, {"text": "r Factoid rules, although simple, bring substantial improvements.", "labels": [], "entities": []}, {"text": "r The Viterbi iterative training method does not turnout to bean effective way of resolving ambiguities in word segmentation or of detecting new words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.6772523820400238}, {"text": "detecting new words", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8540907700856527}]}, {"text": "In Rows 1 to 4, the word segmentation performance always saturates after 2 or 3 iterations, with little improvement.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7382128685712814}]}, {"text": "For example, FMM (Row 1) achieves an initial segmentation F-measure of 0.8771, and after two iterations, it saturates and ends up with 0.8773.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.8267588019371033}]}, {"text": "r The Viterbi iterative training is effective in boosting the precision of NER without great sacrifices for recall (e.g., the recall remains almost the same when using the seed set of Row 5 in, or becomes a little worse when using the seed sets of Rows 6 to 8).", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9993289709091187}, {"text": "NER", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9199734926223755}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9987190961837769}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.998554527759552}]}, {"text": "As shown in, we start with a series of seed sets of different sizes and achieve a reasonable accuracy of NER, which is comparable with that of MSRSeg, after two iterations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9995908141136169}, {"text": "NER", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.839716911315918}]}, {"text": "r The use of a small NE annotated seed set (e.g., in Row 5) would achieve the best trade-off between performance and human effort, because after two iterations, the accuracy of NER is very close to that of using larger seed sets, while the human effort of creating the seed set is much less.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9992656111717224}]}, {"text": "As described in Section 2.1, most segmenters, including the ones in, can be roughly grouped into two categories: ones that use a rule-based approach and ones that use a statistical approach.", "labels": [], "entities": []}, {"text": "MSRSeg is a hybrid system that takes advantage of both approaches.", "labels": [], "entities": [{"text": "MSRSeg", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9082615375518799}]}, {"text": "Though rule-based systems (e.g., S08, S10, and S11 in) can achieve reasonably good results, they cannot effectively make use of increasingly large training data and are weak in unknown word detection and adaptation.", "labels": [], "entities": [{"text": "unknown word detection", "start_pos": 177, "end_pos": 199, "type": "TASK", "confidence": 0.6346962749958038}]}, {"text": "Some statistical segmenters (e.g., S01 and S07 in) use generative models such as HMM for Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.6000330944856008}]}, {"text": "However, it is very difficult to incorporate linguistic knowledge into the (approximated or assumed) generation process of Chinese sentences, underneath which the models are developed.", "labels": [], "entities": []}, {"text": "Discriminative models (e.g., the linear models in MSRSeg, where though all components models are derived from generative models, they are combined using discriminatively trained weights) are free from this issue and provide a flexible mathematical framework to incorporate arbitrary linguistic knowledge.", "labels": [], "entities": []}, {"text": "They do not assume any underlying generation process.", "labels": [], "entities": []}, {"text": "Instead, they assume that the training and test sets are generated from the same distribution, but the form of the distribution (i.e., generative process) is unknown.", "labels": [], "entities": []}, {"text": "If we view Chinese word segmentation as a classification problem, i.e., to discriminate between \"good\" segmentations and \"bad\" ones, we may prefer discriminative models to generative models.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.6565204163392385}]}, {"text": "Intuitively, it is sufficient to find directly the desired features that can differentiate good segmentations from bad ones (as in discriminative models).", "labels": [], "entities": []}, {"text": "It is, however, not necessary to estimate the distributions based upon which Chinese sentences are generated (or segmentations) first, and then use the estimated distributions to construct the desired features (as in generative models).", "labels": [], "entities": []}, {"text": "As pointed out by: \"When solving a given problem, solve it directly and try to avoid solving a more general problem as an intermediate step.\"", "labels": [], "entities": []}, {"text": "Our models are similar to the maximum entropy models in and CRFs in in that all these models give the flexibility to incorporate arbitrary features and can be discriminatively trained.", "labels": [], "entities": []}, {"text": "Our models are novel in that many feature functions are derived from probabilistic or heuristic models inspired by source-channel models of Chinese sentence generation, as described in Section 4.3.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.6843735675017039}]}, {"text": "Therefore, these feature functions are not only potentially more reasonable but also much more informative than, for instance, the binary features used in standard maximum entropy models in NLP.", "labels": [], "entities": []}, {"text": "We also notice that many segmenters (e.g., S03 and S04 in) separate unknown word detection from word segmentation.", "labels": [], "entities": [{"text": "unknown word detection", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.696117083231608}, {"text": "word segmentation", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.7169593423604965}]}, {"text": "Though this would make the development of the segmenter easier, it seems to be a flawed solution in reality, as we discussed earlier.", "labels": [], "entities": []}, {"text": "The benefits of integrating both tasks has also been shown empirically in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Domain/style distribution in the MSR test corpus.", "labels": [], "entities": [{"text": "MSR test corpus", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.8564239144325256}]}, {"text": " Table 3  Words in the MSR gold test set.", "labels": [], "entities": [{"text": "MSR gold test set", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.9042711108922958}]}, {"text": " Table 8  FT detection results on the MSR gold test set. The 'All' column shows the results of detecting all  10 types of factoids, as described in", "labels": [], "entities": [{"text": "FT detection", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.8054314255714417}, {"text": "MSR gold test set", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.9376326352357864}]}, {"text": " Table 9  NW 11 identification results on PK test set.", "labels": [], "entities": [{"text": "PK test set", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.9184312025705973}]}, {"text": " Table 10  NW 21 identification results on PK test set.", "labels": [], "entities": [{"text": "PK test set", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.921882152557373}]}, {"text": " Table 11  NWI results on PK and CTB corpora, NWI as post-processor versus unified approach.", "labels": [], "entities": []}, {"text": " Table 12  NWI results on HK and AS corpora, NWI as post-processor versus unified approach.", "labels": [], "entities": []}, {"text": " Table 13  Comparison scores for PK open and CTB open.", "labels": [], "entities": []}, {"text": " Table 14  Comparison scores for HK open and AS open.", "labels": [], "entities": []}, {"text": " Table 15  Size of training data set and the adaptation results on AS open.", "labels": [], "entities": []}, {"text": " Table 16  Methods of resolving OAs in word segmentation, on the MSR test set.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7400173842906952}, {"text": "MSR test set", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9413059949874878}]}, {"text": " Table 17  Comparison of performance of MSRSeg: The versions that are trained using (semi-)supervised  iterative training with different initial training sets (Rows 1 to 8) versus the version that is  trained on annotated corpus of 20 million words (Row 9).", "labels": [], "entities": []}, {"text": " Table 18  Precision of person name recognition on the MSR test set, using Viterbi iterative training,  initialized by four seed sets with different sizes.", "labels": [], "entities": [{"text": "person name recognition", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.7051176826159159}, {"text": "MSR test set", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.8687162001927694}]}, {"text": " Table 19  Precision of location name recognition on the MSR test set, using Viterbi iterative training,  initialized by four seed sets with different sizes.", "labels": [], "entities": [{"text": "location name recognition", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.6965558628241221}, {"text": "MSR test set", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.8644090493520101}]}, {"text": " Table 20  Precision of organization name recognition on the MSR test set, using Viterbi iterative training,  initialized by four seed sets with different sizes.", "labels": [], "entities": [{"text": "organization name recognition", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.7667274673779806}, {"text": "MSR test set", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.8757337927818298}]}, {"text": " Table 21  MSRSeg system results for the MSR test set.", "labels": [], "entities": [{"text": "MSR test set", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.8187071879704794}]}, {"text": " Table 22  Cross-system comparison results.", "labels": [], "entities": []}, {"text": " Table 23  Comparisons against other segmenters: In Column 1, SXX indicates participating sites in the  1 st SIGHAN International Chinese Word Segmentation Bakeoff, and CRFs indicates the word  segmenter reported in (Peng et al. 2004). In Columns 2 to 5, entries contain the F-measure of each  segmenter on different open runs, with the best performance in bold. Column Site-Avg is the  average F-measure over the data sets on which a segmenter reported results of open runs, where  a bolded entry indicates the segmenter outperforms MSRSeg. Column Our-Avg is the average  F-measure of MSRSeg over the same data sets, where a bolded entry indicates that MSRSeg  outperforms the other segmenter.", "labels": [], "entities": [{"text": "SIGHAN International Chinese Word Segmentation Bakeoff", "start_pos": 109, "end_pos": 163, "type": "TASK", "confidence": 0.6777382691701254}, {"text": "CRFs", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9583942294120789}, {"text": "F-measure", "start_pos": 275, "end_pos": 284, "type": "METRIC", "confidence": 0.9682287573814392}, {"text": "F-measure", "start_pos": 395, "end_pos": 404, "type": "METRIC", "confidence": 0.9789651036262512}, {"text": "F-measure", "start_pos": 573, "end_pos": 582, "type": "METRIC", "confidence": 0.9732785224914551}]}]}