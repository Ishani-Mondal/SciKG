{"title": [{"text": "Using Wikipedia for Automatic Word Sense Disambiguation", "labels": [], "entities": [{"text": "Automatic Word Sense Disambiguation", "start_pos": 20, "end_pos": 55, "type": "TASK", "confidence": 0.7010164558887482}]}], "abstractContent": [{"text": "This paper describes a method for generating sense-tagged data using Wikipedia as a source of sense annotations.", "labels": [], "entities": []}, {"text": "Through word sense disambiguation experiments, we show that the Wikipedia-based sense annotations are reliable and can be used to construct accurate sense classifiers.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.7369260390599569}]}], "introductionContent": [{"text": "Ambiguity is inherent to human language.", "labels": [], "entities": []}, {"text": "In particular, word sense ambiguity is prevalent in all natural languages, with a large number of the words in any given language carrying more than one meaning.", "labels": [], "entities": [{"text": "word sense ambiguity", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7622090180714926}]}, {"text": "For instance, the English noun plant can mean green plant or factory; similarly the French word feuille can mean leaf or paper.", "labels": [], "entities": []}, {"text": "The correct sense of an ambiguous word can be selected based on the context where it occurs, and correspondingly the problem of word sense disambiguation is defined as the task of automatically assigning the most appropriate meaning to a polysemous word within a given context.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 128, "end_pos": 153, "type": "TASK", "confidence": 0.7387332618236542}]}, {"text": "Among the various knowledge-based) and data-driven) word sense disambiguation methods that have been proposed to date, supervised systems have been constantly observed as leading to the highest performance.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.6904730002085367}]}, {"text": "In these systems, the sense disambiguation problem is formulated as a supervised learning task, where each sense-tagged occurrence of a particular word is transformed into a feature vector which is then used in an automatic learning process.", "labels": [], "entities": [{"text": "sense disambiguation problem", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.798549234867096}]}, {"text": "Despite their high performance, these supervised systems have an important drawback: their applicability is limited to those few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.9987214207649231}]}, {"text": "To address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.", "labels": [], "entities": []}, {"text": "This includes the automatic generation of sense-tagged data using monosemous relatives (), automatically bootstrapped disambiguation patterns, parallel texts as away to point out word senses bearing different translations in a second language, and the use of volunteer contributions over the Web (.", "labels": [], "entities": []}, {"text": "In this paper, we investigate anew approach for building sense tagged corpora using Wikipedia as a source of sense annotations.", "labels": [], "entities": []}, {"text": "Starting with the hyperlinks available in Wikipedia, we show how we can generate sense annotated corpora that can be used for building accurate and robust sense classifiers.", "labels": [], "entities": []}, {"text": "Through word sense disambiguation experiments performed on the Wikipedia-based sense tagged corpus generated fora subset of the SENSE-VAL ambiguous words, we show that the Wikipedia annotations are reliable, and the quality of a sense tagging classifier built on this data set exceeds by a large margin the accuracy of an informed baseline that selects the most frequent word sense by default.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.7870163917541504}, {"text": "accuracy", "start_pos": 307, "end_pos": 315, "type": "METRIC", "confidence": 0.9990803003311157}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first pro-vide a brief overview of Wikipedia, and describe the view of Wikipedia as a sense tagged corpus.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 38, "end_pos": 47, "type": "DATASET", "confidence": 0.9208946228027344}]}, {"text": "We then show how the hyperlinks defined in this resource can be used to derive sense annotated corpora, and we show how a word sense disambiguation system can be built on this dataset.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 122, "end_pos": 147, "type": "TASK", "confidence": 0.6070713996887207}]}, {"text": "We present the results obtained in the word sense disambiguation experiments, and conclude with a discussion of the results.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.609592338403066}]}], "datasetContent": [{"text": "To evaluate the quality of the sense annotations generated using Wikipedia, we performed a word sense disambiguation experiment on a subset of the ambiguous words used during the SENSEVAL-2 and SENSEVAL-3 evaluations.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.7586049238840739}]}, {"text": "Since the Wikipedia annotations are focused on nouns (associated with the entities typically defined by Wikipedia), the sense annotations we generate and the word sense disambiguation experiments are also focused on nouns.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 158, "end_pos": 183, "type": "TASK", "confidence": 0.6348543365796407}]}, {"text": "Starting with the 49 ambiguous nouns used during the SENSEVAL-2 (29) and SENSEVAL-3 (20) evaluations, we generated sense tagged corpora following the process outlined in Section 3.1.", "labels": [], "entities": []}, {"text": "We then removed all those words that have only one Wikipedia label (e.g. detention, which occurs 58 times, but appears as a single link] in all the occurrences), or which have several labels that are all mapped to the same WordNet sense (e.g. church, which has 2,198 occurrences with several different labels such as Roman church, Christian church, Catholic church, which are all mapped to the meaning of church, Christian church as defined in WordNet).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 444, "end_pos": 451, "type": "DATASET", "confidence": 0.9541565775871277}]}, {"text": "This resulted in a set of 30 words that have their Wikipedia annotations mapped to at least two senses according to the WordNet sense inventory.", "labels": [], "entities": [{"text": "WordNet sense inventory", "start_pos": 120, "end_pos": 143, "type": "DATASET", "confidence": 0.8865464131037394}]}, {"text": "shows the disambiguation results using the word sense disambiguation system described in Section 4, using ten-fold cross-validation.", "labels": [], "entities": []}, {"text": "For each word, the table also shows the number of senses, the total number of examples, and two baselines: a simple informed baseline that selects the most frequent sense by default, and a more refined baseline that Note that this baseline assumes the availability of a sense tagged corpus in order to determine the most frequent sense of a word.", "labels": [], "entities": []}, {"text": "The baseline is therefore \"informed,\" as compared to a random, \"uninformed\" sense selection.: Word sense disambiguation results, including two baselines (MFS = most frequent sense; LeskC = Lesk-corpus) and the word sense disambiguation system.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.6493123273054758}, {"text": "word sense disambiguation", "start_pos": 210, "end_pos": 235, "type": "TASK", "confidence": 0.6232370038827261}]}, {"text": "Number of senses (#s) and number of examples (#ex) are also indicated.", "labels": [], "entities": []}, {"text": "implements the corpus-based version of the Lesk algorithm).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Word sense disambiguation results, in- cluding two baselines (MFS = most frequent sense;  LeskC = Lesk-corpus) and the word sense disam- biguation system. Number of senses (#s) and num- ber of examples (#ex) are also indicated.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6806367039680481}]}, {"text": " Table 3: Average number of senses and exam- ples, most frequent sense and Lesk-corpus baselines,  and word sense disambiguation performance on the  SENSEVAL and WIKIPEDIA datasets.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 103, "end_pos": 128, "type": "TASK", "confidence": 0.596243421236674}, {"text": "WIKIPEDIA datasets", "start_pos": 162, "end_pos": 180, "type": "DATASET", "confidence": 0.8745821714401245}]}]}