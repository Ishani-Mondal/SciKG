{"title": [{"text": "The CALO Meeting Assistant The DARPA \u2020 CALO Meeting Assistant Project Team*", "labels": [], "entities": [{"text": "DARPA \u2020 CALO Meeting Assistant Project Team", "start_pos": 31, "end_pos": 74, "type": "DATASET", "confidence": 0.9042463387761798}]}], "abstractContent": [{"text": "The CALO Meeting Assistant is an integrated , multimodal meeting assistant technology that captures speech, gestures, and multimodal data from multiparty interactions during meetings, and uses machine learning and robust discourse processing to provide a rich, browsable record of a meeting.", "labels": [], "entities": []}], "introductionContent": [{"text": "Technologies that assist in making meetings more productive have along history.", "labels": [], "entities": []}, {"text": "The latest chapter in that history involves projects that integrate recent advances in speech, natural language understanding, vision, and multimodal interaction technologies in an effort to produce tools that can perceive what happens at a meeting, extract salient events and interactions, and produce a record of the meeting that people can later consult or analyze.", "labels": [], "entities": []}, {"text": "Research projects such as the ICSI Meeting Project () have sought to produce automated and segmented transcripts from natural, multiparty speech as it occurs in meetings.", "labels": [], "entities": [{"text": "ICSI Meeting Project", "start_pos": 30, "end_pos": 50, "type": "DATASET", "confidence": 0.8995667497316996}]}, {"text": "Others, like the ISL Smart Meeting Room Task (, and the M4 and AMI projects, employ instrumented meeting rooms to collect multiple streams of behavior data and analyze the interactions of meeting participants to produce a rich and flexible record of their meeting activities, while also providing a supportive environment for collaboration.", "labels": [], "entities": [{"text": "ISL Smart Meeting Room Task", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.6338103175163269}, {"text": "AMI", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.5845558047294617}]}, {"text": "The CALO Meeting Assistant is similar to the latter in that it collects multiple streams of information about the behaviors of people in meetings, and assimilates speech, movement, and note-taking behavior to create a rich representation of the meeting that can be analyzed and reviewed at many levels.", "labels": [], "entities": []}, {"text": "However, a primary aim of the CALO Meeting Assistant is to integrate its observations with those of a larger system of agents, which can assess the meeting data it collects in the context of the ongoing projects and workflow in the work lives of each of the meeting participants.", "labels": [], "entities": []}, {"text": "Thus, our meeting assistant aims to reach beyond an intelligent room that understands only the activities of people in meetings, and attempts to understand their overarching concerns and interpret their behaviors from the perspective of what their meetings mean to them.", "labels": [], "entities": []}, {"text": "That overarching system of agents is being developed under the DARPA CALO (Cognitive Assistant that Learns and Organizes) Program, which seeks to produce machine learning technology in the form of personalized agents that support high-level knowledge workers in carrying out their professional activities.", "labels": [], "entities": [{"text": "DARPA CALO (Cognitive Assistant that Learns and Organizes)", "start_pos": 63, "end_pos": 121, "type": "TASK", "confidence": 0.5548852831125259}]}, {"text": "The CALO system handles abroad range of interrelated decision-making tasks that are traditionally resistant to automation; doing so partly by interacting with, being advised by, and learning from its users.", "labels": [], "entities": []}, {"text": "The CALO system can take initiative on completing routine tasks, and on assisting when the unexpected happens.", "labels": [], "entities": []}, {"text": "CALO is designed from the ground up as a cognitive system.", "labels": [], "entities": [{"text": "CALO", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6560729146003723}]}, {"text": "Whereas conventional, hand-coded software excels at a narrow set of capabilities in a particular domain, cognitive systems maintain explicit, declarative models of their capabilities, ongoing activities, and operating environments.", "labels": [], "entities": []}, {"text": "These models enable CALO to extend and improve its capabilities through learning and adaptation.", "labels": [], "entities": []}, {"text": "Cognitive systems are better equipped to cope with unexpected developments, learn to improve overtime, and adapt to the contexts and requirements of different situations.", "labels": [], "entities": []}, {"text": "CALO also uses natural interfaces that enable simple, effective interactions with humans and other cognitive systems.", "labels": [], "entities": []}, {"text": "The CALO Meeting Assistance Project is developing capabilities to enable CALO to participate in group discussions and meetings.", "labels": [], "entities": [{"text": "CALO Meeting Assistance", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.6842841506004333}]}, {"text": "Unlike instrumented \"intelligent room\" meeting projects, this system is designed for users in an office environment with access to the Internet, a laptop, and some small, off-the-shelf peripheral devices (such as headsets, webcams, and digital writing devices) to capture speech, gestures, and handwriting.", "labels": [], "entities": []}, {"text": "It aims to be unobtrusive by leveraging cross-training, unsupervised learning, and lightweight supervision captured from normal user interaction (e.g., users reviewing and editing notes, or adding detected action items to a todo list).", "labels": [], "entities": []}, {"text": "These data are transparently processed at a central server location and redistributed, so the meeting assistant interacts seamlessly with other CALO desktop functionalities, using a common ontology.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}