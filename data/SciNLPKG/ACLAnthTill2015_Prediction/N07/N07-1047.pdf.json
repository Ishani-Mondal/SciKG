{"title": [{"text": "Applying Many-to-Many Alignments and Hidden Markov Models to Letter-to-Phoneme Conversion", "labels": [], "entities": [{"text": "Applying Many-to-Many Alignments", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7657750050226847}]}], "abstractContent": [{"text": "Letter-to-phoneme conversion generally requires aligned training data of letters and phonemes.", "labels": [], "entities": [{"text": "Letter-to-phoneme conversion", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7449156939983368}]}, {"text": "Typically, the alignments are limited to one-to-one alignments.", "labels": [], "entities": []}, {"text": "We present a novel technique of training with many-to-many alignments.", "labels": [], "entities": []}, {"text": "A letter chunking bigram prediction manages double letters and double phonemes automatically as opposed to preprocess-ing with fixed lists.", "labels": [], "entities": [{"text": "letter chunking bigram prediction", "start_pos": 2, "end_pos": 35, "type": "TASK", "confidence": 0.8168306797742844}]}, {"text": "We also apply an HMM method in conjunction with a local classification model to predict a global phoneme sequence given a word.", "labels": [], "entities": []}, {"text": "The many-to-many alignments result in significant improvements over the traditional one-to-one approach.", "labels": [], "entities": []}, {"text": "Our system achieves state-of-the-art performance on several languages and data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Letter-to-phoneme (L2P) conversion requires a system to produce phonemes that correspond to a given written word.", "labels": [], "entities": [{"text": "Letter-to-phoneme (L2P) conversion", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6489148557186126}]}, {"text": "Phonemes are abstract representations of how words should be pronounced in natural speech, while letters or graphemes are representations of words in written language.", "labels": [], "entities": []}, {"text": "For example, the phonemes for the word phoenix are [ f in I k s ].", "labels": [], "entities": []}, {"text": "The L2P task is a crucial part of speech synthesis systems, as converting input text (graphemes) into phonemes is the first step in representing sounds.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.732353687286377}]}, {"text": "L2P conversion can also help improve performance in spelling correction).", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.9194220006465912}]}, {"text": "Unfortunately, proper nouns and unseen words prevent a table look-up approach.", "labels": [], "entities": []}, {"text": "It is infeasible to construct a lexical database that includes every word in the written language.", "labels": [], "entities": []}, {"text": "Likewise, orthographic complexity of many languages prevents us from using hand-designed conversion rules.", "labels": [], "entities": []}, {"text": "There are always exceptional rules that need to be added to cover a large vocabulary set.", "labels": [], "entities": []}, {"text": "Thus, an automatic L2P system is desirable.", "labels": [], "entities": []}, {"text": "Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including pronunciation by analogy), constraint satisfaction (Van Den Bosch and), Hidden Markov Model (, decision trees (, and neural networks.", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.7962692081928253}]}, {"text": "The training data usually consists of written words and their corresponding phonemes, which are not aligned; there is no explicit information indicating individual letter and phoneme relationships.", "labels": [], "entities": []}, {"text": "These relationships must be postulated before a prediction model can be trained.", "labels": [], "entities": []}, {"text": "Previous work has generally assumed one-to-one alignment for simplicity).", "labels": [], "entities": []}, {"text": "An expectation maximization (EM) based algorithm) is applied to train the aligners.", "labels": [], "entities": []}, {"text": "However, there are several problems with this approach.", "labels": [], "entities": []}, {"text": "Letter strings and phoneme strings are not typically the same length, so null phonemes and null letters must be introduced to make oneto-one-alignments possible, Furthermore, two letters frequently combine to produce a single phoneme (double letters), and a single letter can sometimes produce two phonemes (double phonemes).", "labels": [], "entities": []}, {"text": "To help address these problems, we propose an automatic many-to-many aligner and incorporate it into a generic classification predictor for letter-tophoneme conversion.", "labels": [], "entities": [{"text": "letter-tophoneme conversion", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.6574949622154236}]}, {"text": "Our many-to-many aligner automatically discovers double phonemes and double letters, as opposed to manually preprocessing data by merging phonemes using fixed lists.", "labels": [], "entities": []}, {"text": "To our knowledge, applying many-to-many alignments to letter-to-phoneme conversion is novel.", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.7027382999658585}]}, {"text": "Once we have our many-to-many alignments, we use that data to train a prediction model.", "labels": [], "entities": []}, {"text": "Many phoneme prediction systems are based on local prediction methods, which focus on predicting an individual phoneme given each letter in a word.", "labels": [], "entities": [{"text": "phoneme prediction", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.7283427566289902}]}, {"text": "Conversely, a method like pronunciation by analogy (PbA)) is considered a global prediction method: predicted phoneme sequences are considered as a whole.", "labels": [], "entities": [{"text": "global prediction", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.6914403140544891}]}, {"text": "Recently, Van Den Bosch and Canisius (2006) proposed trigram class prediction, which incorporates a constraint satisfaction method to produce a global prediction for letter-to-phoneme conversion.", "labels": [], "entities": [{"text": "trigram class prediction", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.6168073614438375}, {"text": "letter-to-phoneme conversion", "start_pos": 166, "end_pos": 194, "type": "TASK", "confidence": 0.6991955637931824}]}, {"text": "Both PbA and trigram class prediction show improvement over predicting individual phonemes, confirming that L2P systems can benefit from incorporating the relationship between phonemes in a sequence.", "labels": [], "entities": [{"text": "PbA", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.9158658981323242}]}, {"text": "In order to capitalize on the information found in phoneme sequences, we propose to apply an HMM method after a local phoneme prediction process.", "labels": [], "entities": []}, {"text": "Given a candidate list of two or more possible phonemes, as produced by the local predictor, the HMM will find the best phoneme sequence.", "labels": [], "entities": []}, {"text": "Using this approach, our system demonstrates an improvement on several language data sets.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "We describe the letter-phoneme alignment methods including a standard one-to-one alignment method and our many-to-many approach in Section 2.", "labels": [], "entities": [{"text": "letter-phoneme alignment", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6791738420724869}]}, {"text": "The alignment methods are used to align graphemes and phonemes before the phoneme prediction models can be trained from the training examples.", "labels": [], "entities": [{"text": "phoneme prediction", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7815824449062347}]}, {"text": "In Section 3, we present a letter chunk prediction method that automatically discovers double letters in grapheme sequences.", "labels": [], "entities": [{"text": "letter chunk prediction", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7468529641628265}]}, {"text": "It incorporates our manyto-many alignments with prediction models.", "labels": [], "entities": []}, {"text": "In Section 4, we present our application of an HMM method to the local prediction results.", "labels": [], "entities": []}, {"text": "The results of experiments on several language data sets are discussed in Section 5.", "labels": [], "entities": []}, {"text": "We conclude and propose future work in Section 6. 2 Letter-phoneme alignment 2.1 One-to-one alignment There are two main problems with one-to-one alignments: 1.", "labels": [], "entities": [{"text": "Letter-phoneme alignment", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.6746072769165039}]}, {"text": "Double letters: two letters map to one phoneme 2.", "labels": [], "entities": []}, {"text": "Double phonemes: one letter maps to two phonemes (e.g. First, consider the double letter problem.", "labels": [], "entities": []}, {"text": "In most cases when the grapheme sequence is longer than the phoneme sequence, it is because some letters are silent.", "labels": [], "entities": []}, {"text": "For example, in the word abode, pronounced [ @ b o d ], the letter e produces a null phoneme ().", "labels": [], "entities": []}, {"text": "This is well captured by one-to-one aligners.", "labels": [], "entities": []}, {"text": "However, the longer grapheme sequence can also be generated by double letters; for example, in the word king, pronounced, the letters ng together produce the phoneme.", "labels": [], "entities": []}, {"text": "In this case, one-to-one aligners using null phonemes will produce an incorrect alignment.", "labels": [], "entities": []}, {"text": "This can cause problems for the phoneme prediction model by training it to produce a null phoneme from either of the letters nor g.", "labels": [], "entities": [{"text": "phoneme prediction", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7980822622776031}]}, {"text": "In the double phoneme case, anew phoneme is introduced to represent a combination of two (or more) phonemes.", "labels": [], "entities": []}, {"text": "For example, in the word fume with phoneme sequence [ f j um ], the letter u produces both the and [ u ] phonemes.", "labels": [], "entities": []}, {"text": "There are two possible solutions for constructing a oneto-one alignment in this case.", "labels": [], "entities": []}, {"text": "The first is to create anew phoneme by merging the phonemes and.", "labels": [], "entities": []}, {"text": "This requires constructing a fixed list of new phonemes before beginning the alignment process.", "labels": [], "entities": []}, {"text": "The second solution is to add a null letter in the grapheme sequence.", "labels": [], "entities": []}, {"text": "However, the null letter not only confuses the phoneme prediction model, but also complicates the the phoneme generation phase.", "labels": [], "entities": [{"text": "phoneme prediction", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7910541296005249}, {"text": "phoneme generation", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7453095614910126}]}, {"text": "For comparison with our many-to-many approach, we implement a one-to-one aligner based on the epsilon scattering method).", "labels": [], "entities": []}, {"text": "The method applies the EM algorithm to estimate Algorithm 1: Pseudocode fora many-to-many expectation-maximization algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our approaches on CMUDict, Brulex, and German, Dutch and English Celex corpora (  For the English Celex data, we removed duplicate words as well as words shorter than four letters.", "labels": [], "entities": [{"text": "CMUDict", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.9173513054847717}, {"text": "Brulex", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.6606460809707642}, {"text": "English Celex data", "start_pos": 103, "end_pos": 121, "type": "DATASET", "confidence": 0.8086360295613607}]}, {"text": "shows the number of words and the language of each corpus.", "labels": [], "entities": []}, {"text": "For all of our experiments, our local classifier for predicting phonemes is the instance-based learning IB1 algorithm ( implemented in the TiMBL package ().", "labels": [], "entities": [{"text": "TiMBL package", "start_pos": 139, "end_pos": 152, "type": "DATASET", "confidence": 0.881775826215744}]}, {"text": "The HMM technique is applied as post processing to the instance-based learning to provide a sequence prediction.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.619106650352478}]}, {"text": "In addition to comparing one-toone and many-to-many alignments, we also compare our method to the constraint satisfaction inference method as described in Section 4.", "labels": [], "entities": []}, {"text": "The results are reported in word accuracy rate based on the 10-fold cross validation, with the mean and standard deviation values.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 33, "end_pos": 46, "type": "METRIC", "confidence": 0.9465557336807251}]}, {"text": "shows word accuracy performance across a variety of methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9515014290809631}]}, {"text": "We show results comparing the one-to-one aligner described in Section 2.1 and the one-to-one aligner provided by the PRONAL-SYL challenge.", "labels": [], "entities": [{"text": "PRONAL-SYL challenge", "start_pos": 117, "end_pos": 137, "type": "DATASET", "confidence": 0.6023967117071152}]}, {"text": "The PRONALSYS one-to-one alignments are taken directly from the PRONAL-SYL challenge, whose method is based on an EM algorithm.", "labels": [], "entities": []}, {"text": "For both alignments, we use instancebased learning as the prediction model.", "labels": [], "entities": []}, {"text": "Overall, our one-to-one alignments outperform the alignments provided by the data sets for all corpora.", "labels": [], "entities": []}, {"text": "The main difference between the PRONAL-SYS one-to-one alignment and our one-to-one alignment is that our aligner does not allow a null letter on the grapheme side.", "labels": [], "entities": []}, {"text": "Consider the word abomination [ @ b 6 m In e S @ n ]: the first six letters and phonemes are aligned the same way by both aligners (abomin-[ @ b 6 m In ]).", "labels": [], "entities": []}, {"text": "However, the two aligners produce radically different alignments for the last five letters.", "labels": [], "entities": []}, {"text": "The alignment provided by the PRONALSYS one-to-one alignments is: while our one-to-one alignment is: Clearly, the latter alignment provides more information on how the graphemes map to the phonemes.", "labels": [], "entities": []}, {"text": "also shows that impressive improvements for all evaluated corpora are achieved by using many-to-many alignments rather than one-to-one alignments (1-1 align vs. M-M align).", "labels": [], "entities": []}, {"text": "The significant improvements, ranging from 2.7% to 7.6% in word accuracy, illustrate the importance of having more precise alignments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.945020318031311}]}, {"text": "For example, we can now obtain the correct alignment for the second part of the word abomination: a ti on | | | | e S @ n Instead of adding a null phoneme in the phoneme sequence, the many-to-many aligner maps the letter chunk ti to a single phoneme.", "labels": [], "entities": []}, {"text": "The HMM approach is based on the same hypothesis as the constraint satisfaction inference (CSInf)).", "labels": [], "entities": []}, {"text": "The results in (1-1+CSInf vs. 1-1+HMM) show that the HMM approach consistently improves performance over the baseline system (1-1 align), while the CSInf degrades performance on the Brulex data set.", "labels": [], "entities": [{"text": "Brulex data set", "start_pos": 182, "end_pos": 197, "type": "DATASET", "confidence": 0.962990959485372}]}, {"text": "For the CSInf method, most errors are caused by trigram confusion in the prediction phase.", "labels": [], "entities": []}, {"text": "The results of our best system, which combines the HMM method with the many-to-many alignments (M-M+HMM), are better than the results reported in) on both the CMUDict and German Celex data sets.", "labels": [], "entities": [{"text": "CMUDict", "start_pos": 159, "end_pos": 166, "type": "DATASET", "confidence": 0.9727849960327148}, {"text": "German Celex data sets", "start_pos": 171, "end_pos": 193, "type": "DATASET", "confidence": 0.9623143225908279}]}, {"text": "This is true even though use explicit lists of letterphoneme mappings during the alignment process, while our approach is a fully automatic system that does not require any handcrafted list.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Word accuracies achieved on data sets based on the 10-fold cross validation. PRONALSYS: one- to-one alignments provided by the PRONALSYL challenge. 1-1 align: our one-to-one alignment method  described in Section 2.1. CsInf: Constraint satisfaction inference", "labels": [], "entities": []}]}