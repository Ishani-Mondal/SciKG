{"title": [{"text": "Can Semantic Roles Generalize Across Genres?", "labels": [], "entities": [{"text": "Semantic Roles Generalize Across Genres", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.7667794823646545}]}], "abstractContent": [{"text": "PropBank has been widely used as training data for Semantic Role Labeling.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9471569061279297}, {"text": "Semantic Role Labeling", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.8792907198270162}]}, {"text": "However, because this training data is taken from the WSJ, the resulting machine learning models tend to overfit on idiosyncrasies of that text's style, and do not port well to other genres.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.9687557220458984}]}, {"text": "In addition, since PropBank was designed on a verb-by-verb basis, the argument labels Arg2-Arg5 get used for very diverse argument roles with inconsistent training instances.", "labels": [], "entities": [{"text": "Arg2-Arg5", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9735074043273926}]}, {"text": "For example , the verb \"make\" uses Arg2 for the \"Material\" argument; but the verb \"multi-ply\" uses Arg2 for the \"Extent\" argument.", "labels": [], "entities": [{"text": "Arg2", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9320909380912781}, {"text": "Arg2", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9493219256401062}]}, {"text": "As a result, it can be difficult for automatic classifiers to learn to distinguish arguments Arg2-Arg5.", "labels": [], "entities": [{"text": "Arg2-Arg5", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9231985807418823}]}, {"text": "We have created a mapping between PropBank and VerbNet that provides a VerbNet thematic role label for each verb-specific PropBank label.", "labels": [], "entities": []}, {"text": "Since VerbNet uses argument labels that are more consistent across verbs, we are able to demonstrate that these new labels are easier to learn.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 6, "end_pos": 13, "type": "DATASET", "confidence": 0.8753768801689148}]}], "introductionContent": [{"text": "Correctly identifying semantic entities and successfully disambiguating the relations between them and their predicates is an important and necessary step for successful natural language processing applications, such as text summarization, question answering, and machine translation.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 220, "end_pos": 238, "type": "TASK", "confidence": 0.7375984191894531}, {"text": "question answering", "start_pos": 240, "end_pos": 258, "type": "TASK", "confidence": 0.9202218055725098}, {"text": "machine translation", "start_pos": 264, "end_pos": 283, "type": "TASK", "confidence": 0.8170802295207977}]}, {"text": "For example, in order to determine that question (1a) is answered by sentence (1b), but not by sentence (1c), we must determine the relationships between the relevant verbs (eat and feed) and their arguments.", "labels": [], "entities": []}, {"text": "What do lobsters like to eat?", "labels": [], "entities": []}, {"text": "b. Recent studies have shown that lobsters primarily feed on live fish, dig for clams, sea urchins, and feed on algae and eel-grass. c. In the early 20th century, Mainers would only eat lobsters because the fish they caught was too valuable to eat themselves.", "labels": [], "entities": []}, {"text": "An important part of this task is Semantic Role Labeling (SRL), where the goal is to locate the constituents which are arguments of a given verb, and to assign them appropriate semantic roles that describe how they relate to the verb.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.8401770989100138}]}, {"text": "Many researchers have investigated applying machine learning to corpus specifically annotated with this task in mind,).", "labels": [], "entities": []}, {"text": "For two years, the CoNLL workshop has made this problem the shared task).", "labels": [], "entities": [{"text": "CoNLL workshop", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.8221860826015472}]}, {"text": "However, there is still little consensus in the linguistic and NLP communities about what set of role labels are most appropriate.", "labels": [], "entities": []}, {"text": "The Proposition Bank (PropBank) corpus ) avoids this issue by using theory-agnostic labels (Arg0, Arg1, . .", "labels": [], "entities": [{"text": "Proposition Bank (PropBank) corpus", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.7589346170425415}, {"text": "Arg0", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9840471148490906}, {"text": "Arg1", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9644492864608765}]}, {"text": ", Arg5), and by defining those labels to have verb-specific meanings.", "labels": [], "entities": [{"text": "Arg5", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.7618687748908997}]}, {"text": "Under this scheme, PropBank can avoid making any claims about how anyone verb's arguments relate to other verbs' arguments, or about general distinctions between verb arguments and adjuncts.", "labels": [], "entities": []}, {"text": "However, there are several limitations to this approach.", "labels": [], "entities": []}, {"text": "The first is that it can be difficult to make inferences and generalizations based on role labels that are only meaningful with respect to a single verb.", "labels": [], "entities": []}, {"text": "Since each role label is verb-specific, we cannot confidently determine when two different verbs' arguments have the same role; and since no encoded meaning is associated with each tag, we cannot make generalizations across verb classes.", "labels": [], "entities": []}, {"text": "In contrast, the use of a shared set of role labels, such as thematic roles, would facilitate both inferencing and generalization.", "labels": [], "entities": []}, {"text": "The second issue with PropBank's verb-specific approach is that it can make training automatic semantic role labeling (SRL) systems more difficult.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.8128665486971537}]}, {"text": "A vast amount of data would be needed to train the verb-specific models that are theoretically mandated by PropBank's design.", "labels": [], "entities": []}, {"text": "Instead, researchers typically build a single model for the numbered arguments (Arg0, Arg1, . .", "labels": [], "entities": [{"text": "Arg0", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9436672329902649}, {"text": "Arg1", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9544447064399719}]}, {"text": "This approach works surprisingly well, mainly because an explicit effort was made to use arguments Arg0 and Arg1 consistently across different verbs; and because those two argument labels account for 85% of all arguments.", "labels": [], "entities": [{"text": "Arg0", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.976641833782196}, {"text": "Arg1", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9478569626808167}]}, {"text": "However, this approach causes the system to conflate different argument types, especially with the highly overloaded arguments Arg2-Arg5.", "labels": [], "entities": []}, {"text": "As a result, these argument labels are quite difficult to learn.", "labels": [], "entities": []}, {"text": "A final difficulty with PropBank's current approach is that it limits SRL system robustness in the face of verb senses, verbs or verb constructions that were not included in the training data, and the training data is all Wall Street Journal corpora.", "labels": [], "entities": [{"text": "SRL system", "start_pos": 70, "end_pos": 80, "type": "TASK", "confidence": 0.8722642362117767}, {"text": "Wall Street Journal corpora", "start_pos": 222, "end_pos": 249, "type": "DATASET", "confidence": 0.9515298157930374}]}, {"text": "If a PropBank-trained SRL system encounters a novel verb or verb usage, then there is noway for it to know which role labels are used for which argument types, since role labels are defined so specifically.", "labels": [], "entities": [{"text": "SRL", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.6482564210891724}]}, {"text": "This is especially problematic for Arg2-5.", "labels": [], "entities": [{"text": "Arg2-5", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.5165833234786987}]}, {"text": "Similarly, PropBank-trained SRL systems can have difficulty generalizing when a known verb is encountered in a novel construction.", "labels": [], "entities": [{"text": "SRL", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.6199927926063538}]}, {"text": "These problems can happen quite frequently if the training data comes from a different genre than the test data.", "labels": [], "entities": []}, {"text": "This issue is reflected in the relatively poor performance of most state-of-the-art SRL systems when tested on a novel genre, the Brown corpus, during CoNLL 2005.", "labels": [], "entities": [{"text": "SRL", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9650242328643799}, {"text": "Brown corpus, during CoNLL 2005", "start_pos": 130, "end_pos": 161, "type": "DATASET", "confidence": 0.7914930085341135}]}, {"text": "For example, the SRL system described in) achieves an Fscore of 81% when tested on the same genre as it is trained on (WSJ); but that score drops to 68.5% when the same system is tested on a different genre (the Brown corpus).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9993832111358643}, {"text": "Brown corpus", "start_pos": 212, "end_pos": 224, "type": "DATASET", "confidence": 0.9511736929416656}]}, {"text": "DARPA-GALE is funding an ongoing effort to PropBank additional genres, but better techniques for generalizing the semantic role labeling task are still needed.", "labels": [], "entities": [{"text": "DARPA-GALE", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9629383683204651}, {"text": "semantic role labeling task", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.6436436176300049}]}, {"text": "In this paper, we demonstrate an increase in the generality of our semantic role labeling based on a mapping that has been developed between PropBank and another lexical resource, VerbNet.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.6821330388387045}, {"text": "VerbNet", "start_pos": 180, "end_pos": 187, "type": "DATASET", "confidence": 0.9281920194625854}]}, {"text": "By taking advantage of VerbNet's more consistent set of labels, we can generate more useful role label annotations with a resulting improvement in SRL performance on novel genres.", "labels": [], "entities": [{"text": "SRL", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.9745769500732422}]}], "datasetContent": [{"text": "In order to verify the feasibility of performing semantic role labeling with VerbNet thematic roles, we re-trained our existing SRL system, which originally used PropBank role labels, with anew label set that makes use of VerbNet thematic role information.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.6106830537319183}]}, {"text": "Since PropBank arguments Arg0 and Arg1 are already quite coherent, we left them as-is in the new label set.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.7484109401702881}]}, {"text": "But since arguments Arg2-Arg5 are highly  overloaded, we replaced them by mapping them to their corresponding VerbNet thematic role.", "labels": [], "entities": []}, {"text": "We found that mapping directly to individual role labels created a significant sparse data problem, since the number of output tags was increased from 6 to 23.", "labels": [], "entities": []}, {"text": "We therefore grouped the VerbNet thematic roles into five coherent groups of similar thematic roles, shown in.", "labels": [], "entities": []}, {"text": "Our new tag set therefore included the following tags: Arg0 (agent); Arg1 (patient); Group1 (goal); Group2 (extent); Group3 (predicate/attrib); Group4 (product); and Group5 (instrument/cause).", "labels": [], "entities": [{"text": "Arg0", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9812107086181641}, {"text": "Arg1", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9767663478851318}]}, {"text": "Training our SRL system using these thematic role groups, we obtained performance similar to the original SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8476511240005493}]}, {"text": "However, it is important to note that these performance figures are not directly comparable, since the two systems are performing different tasks: The Original system labels Arg0-5,ArgA and ArgM and the Mapped system labels Arg0, Arg1, ArgA, ArgM and Group1-5.", "labels": [], "entities": [{"text": "Arg0-5,ArgA", "start_pos": 174, "end_pos": 185, "type": "METRIC", "confidence": 0.8773588538169861}, {"text": "ArgM", "start_pos": 190, "end_pos": 194, "type": "METRIC", "confidence": 0.8323747515678406}, {"text": "Arg0", "start_pos": 224, "end_pos": 228, "type": "METRIC", "confidence": 0.8048528432846069}, {"text": "Arg1", "start_pos": 230, "end_pos": 234, "type": "METRIC", "confidence": 0.7876503467559814}, {"text": "ArgA", "start_pos": 236, "end_pos": 240, "type": "METRIC", "confidence": 0.8957833647727966}, {"text": "ArgM", "start_pos": 242, "end_pos": 246, "type": "METRIC", "confidence": 0.8958359956741333}]}, {"text": "In particular, the role labels generated by the original system are verb-specific, while the role labels generated by the new system are less verb-dependent.", "labels": [], "entities": []}, {"text": "We conducted two further sets of experiments: one to test the effect of the mapping on learning Arg2; and one to test the effect on learning Arg1.", "labels": [], "entities": []}, {"text": "Since Arg2 is used in very verb-dependent ways, we expect that mapping it to VerbNet role labels will in-  crease our performance.", "labels": [], "entities": []}, {"text": "However, since a conscious effort was made to keep the meaning of Arg1 consistent across verbs, we expect that mapping it to VerbNet labels will provide less of an improvement.", "labels": [], "entities": []}, {"text": "Each experiment compares two SRL systems: one trained using the original PropBank role labels; the other trained with the argument role under consideration (Arg1 or Arg2) subdivided based on which VerbNet role label it maps to.", "labels": [], "entities": []}, {"text": "In order to prevent the training data from these subdivided labels from becoming too sparse (which would impair system performance) we grouped similar thematic roles together.", "labels": [], "entities": []}, {"text": "For Arg2, we used the same groupings as the previous experiment, shown in.", "labels": [], "entities": [{"text": "Arg2", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.8155593872070312}]}, {"text": "The argument role groupings we used for Arg1 are shown in.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.5836969017982483}]}, {"text": "The training data for both experiments is the portion of Penn Treebank II (sections 02-21) that is covered by the mapping.", "labels": [], "entities": [{"text": "Penn Treebank II", "start_pos": 57, "end_pos": 73, "type": "DATASET", "confidence": 0.9912885228792826}]}, {"text": "We evaluated each experimental system using two test sets: section 23 of the Penn Treebank II, which represents the same genre as the training data; and the PropBank-ed portion of the Brown corpus, which represents a very different genre.", "labels": [], "entities": [{"text": "Penn Treebank II", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.992625872294108}, {"text": "PropBank-ed portion of the Brown corpus", "start_pos": 157, "end_pos": 196, "type": "DATASET", "confidence": 0.7201017638047537}]}, {"text": "describes the results of SRL overall performance tested on the WSJ corpus Section 23; Table 4 demonstrates the SRL overall system performance tested on the Brown corpus.", "labels": [], "entities": [{"text": "SRL", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.557668149471283}, {"text": "WSJ corpus Section 23", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.9674214869737625}, {"text": "SRL", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.8766136765480042}, {"text": "Brown corpus", "start_pos": 156, "end_pos": 168, "type": "DATASET", "confidence": 0.9752087891101837}]}, {"text": "Systems Arg1-Original and Arg2-Original are trained using the original PropBank labels, and show the baseline performance of our SRL system.", "labels": [], "entities": [{"text": "Arg1-Original", "start_pos": 8, "end_pos": 21, "type": "METRIC", "confidence": 0.8310235142707825}, {"text": "Arg2-Original", "start_pos": 26, "end_pos": 39, "type": "METRIC", "confidence": 0.8107292056083679}, {"text": "PropBank labels", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.9519858360290527}]}, {"text": "Systems Arg1-Mapped and Arg2-Mapped are trained using PropBank labels augmented with VerbNet thematic role groups.", "labels": [], "entities": []}, {"text": "In order to allow comparison between the system using the original PropBank labels and the systems that augmented those labels with VerbNet   thematic role groups, system performance was evaluated based solely on the PropBank role label that was assigned.", "labels": [], "entities": []}, {"text": "We had hypothesized that with the use of thematic roles, we would be able to create a more consistent training data set which would result in an improvement in system performance.", "labels": [], "entities": []}, {"text": "In addition, the thematic roles would behave more consistently than the overloaded Args across verbs, which should enhance robustness.", "labels": [], "entities": [{"text": "Args", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9272724390029907}]}, {"text": "However, since in practice we are also increasing the number of argument labels an SRL system needs to tag, the system might suffer from data sparseness.", "labels": [], "entities": []}, {"text": "Our hope is that the enhancement gained from the mapping will outweigh the loss due to data sparseness.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overall SRL System performance using the  PropBank tag set (\"Original\") and the augmented  tag set (\"Mapped\")", "labels": [], "entities": [{"text": "SRL", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9732887148857117}, {"text": "PropBank tag set", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.9257657925287882}]}, {"text": " Table 2: SRL System performance evaluated on only  Arg2-5 (Original) or Group1-5 (Mapped).", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7568445205688477}, {"text": "Arg2-5", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.6844566464424133}]}, {"text": " Table 3: SRL System Performance on Arg1 Map- ping and Arg2 Mapping, tested using the WSJ cor- pus (section 23). This represents performance on the  same genre as the training corpus.", "labels": [], "entities": [{"text": "Arg2 Mapping", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.535903126001358}, {"text": "WSJ cor- pus", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.8561134934425354}]}, {"text": " Table 4: SRL System Performance on Arg1 Map- ping and Arg2 Mapping, tested using the PropBank- ed Brown corpus. This represents performance on a  different genre from the training corpus.", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7892601490020752}, {"text": "Arg2 Mapping", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.5243575572967529}, {"text": "PropBank- ed Brown corpus", "start_pos": 86, "end_pos": 111, "type": "DATASET", "confidence": 0.9345205545425415}]}]}