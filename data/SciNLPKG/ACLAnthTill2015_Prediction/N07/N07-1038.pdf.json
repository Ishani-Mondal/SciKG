{"title": [{"text": "Multiple Aspect Ranking using the Good Grief Algorithm", "labels": [], "entities": []}], "abstractContent": [{"text": "We address the problem of analyzing multiple related opinions in a text.", "labels": [], "entities": []}, {"text": "For instance , in a restaurant review such opinions may include food, ambience and service.", "labels": [], "entities": []}, {"text": "We formulate this task as a multiple aspect ranking problem, where the goal is to produce a set of numerical scores, one for each aspect.", "labels": [], "entities": []}, {"text": "We present an algorithm that jointly learns ranking models for individual aspects by modeling the dependencies between assigned ranks.", "labels": [], "entities": []}, {"text": "This algorithm guides the prediction of individual rankers by analyzing meta-relations between opinions, such as agreement and contrast.", "labels": [], "entities": []}, {"text": "We prove that our agreement-based joint model is more expressive than individual ranking models.", "labels": [], "entities": []}, {"text": "Our empirical results further confirm the strength of the model: the algorithm provides significant improvement over both individual rankers and a state-of-the-art joint ranking model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Previous work on sentiment categorization makes an implicit assumption that a single score can express the polarity of an opinion text (;.", "labels": [], "entities": [{"text": "sentiment categorization", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.9493169486522675}]}, {"text": "However, multiple opinions on related matters are often intertwined throughout a text.", "labels": [], "entities": []}, {"text": "For example, a restaurant review may express judgment on food quality as well as the service and ambience of the restaurant.", "labels": [], "entities": []}, {"text": "Rather than lumping these aspects into a single score, we would like to capture each aspect of the writer's opinion separately, thereby providing a more fine-grained view of opinions in the review.", "labels": [], "entities": []}, {"text": "To this end, we aim to predict a set of numeric ranks that reflects the user's satisfaction for each aspect.", "labels": [], "entities": []}, {"text": "In the example above, we would assign a numeric rank from 1-5 for each of: food quality, service, and ambience.", "labels": [], "entities": []}, {"text": "A straightforward approach to this task would be to rank 1 the text independently for each aspect, using standard ranking techniques such as regression or classification.", "labels": [], "entities": []}, {"text": "However, this approach fails to exploit meaningful dependencies between users' judgments across different aspects.", "labels": [], "entities": []}, {"text": "Knowledge of these dependencies can be crucial in predicting accurate ranks, as a user's opinions on one aspect can influence his or her opinions on others.", "labels": [], "entities": []}, {"text": "The algorithm presented in this paper models the dependencies between different labels via the agreement relation.", "labels": [], "entities": []}, {"text": "The agreement relation captures whether the user equally likes all aspects of the item or whether he or she expresses different degrees of satisfaction.", "labels": [], "entities": []}, {"text": "Since this relation can often be determined automatically fora given text (), we can readily use it to improve rank prediction.", "labels": [], "entities": [{"text": "rank prediction", "start_pos": 111, "end_pos": 126, "type": "TASK", "confidence": 0.6140947192907333}]}, {"text": "The Good Grief model consists of a ranking model for each aspect as well as an agreement model which predicts whether or not all rank aspects are equal.", "labels": [], "entities": []}, {"text": "The Good Grief decoding algorithm predicts a set of ranks -one for each aspect -which maximally satisfy the preferences of the individual rankers and the agreement model.", "labels": [], "entities": []}, {"text": "For example, if the agreement model predicts consensus but the individual rankers select ranks \ud97b\udf595, 5, 4\ud97b\udf59, then the decoder decides whether to trust the the third ranker, or alter its prediction and output \ud97b\udf595, 5, 5\ud97b\udf59 to be consistent with the agreement prediction.", "labels": [], "entities": []}, {"text": "To obtain a model well-suited for this decoding, we also develop a joint training method that conjoins the training of multiple aspect models.", "labels": [], "entities": []}, {"text": "We demonstrate that the agreement-based joint model is more expressive than individual ranking models.", "labels": [], "entities": []}, {"text": "That is, every training set that can be perfectly ranked by individual ranking models for each aspect can also be perfectly ranked with our joint model.", "labels": [], "entities": []}, {"text": "In addition, we give a simple example of a training set which cannot be perfectly ranked without agreement-based joint inference.", "labels": [], "entities": []}, {"text": "Our experimental results further confirm the strength of the Good Grief model.", "labels": [], "entities": []}, {"text": "Our model significantly outperforms individual ranking models as well as a stateof-the-art joint ranking model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our multi-aspect ranking algorithm on a corpus 5 of restaurant reviews available on the website http://www.we8there.com.", "labels": [], "entities": []}, {"text": "Reviews from this website have been previously used in other sentiment analysis tasks ().", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.9495932261149088}]}, {"text": "Each review is accompanied by a set of five ranks, each on a scale of 1-5, covering food, ambience, service, value, and overall experience.", "labels": [], "entities": []}, {"text": "These ranks are provided by consumers who wrote original reviews.", "labels": [], "entities": []}, {"text": "Our corpus does not contain incomplete data points since all the reviews available on this website contain both a review text and the values for all the five aspects.", "labels": [], "entities": []}, {"text": "Training and Testing Division Our corpus con-tains 4,488 reviews, averaging 115 words.", "labels": [], "entities": []}, {"text": "We randomly select 3,488 reviews for training, 500 for development and 500 for testing.", "labels": [], "entities": []}, {"text": "Parameter Tuning We used the development set to determine optimal numbers of training iterations for our model and for the baseline models.", "labels": [], "entities": []}, {"text": "Also, given an initial uncalibrated agreement model a \ud97b\udf59 , we define our agreement model to be a = \u03b1a \ud97b\udf59 for an appropriate scaling factor \u03b1.", "labels": [], "entities": []}, {"text": "We tune the value of \u03b1 on the development set.", "labels": [], "entities": []}, {"text": "Corpus Statistics Our training corpus contains 528 among 5 5 = 3025 possible rank sets.", "labels": [], "entities": [{"text": "Corpus Statistics", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.9112025201320648}]}, {"text": "The most frequent rank set \ud97b\udf595, 5, 5, 5, 5\ud97b\udf59 accounts for 30.5% of the training set.", "labels": [], "entities": []}, {"text": "However, no other rank set comprises more than 5% of the data.", "labels": [], "entities": []}, {"text": "To cover 90% of occurrences in the training set, 227 rank sets are required.", "labels": [], "entities": []}, {"text": "Therefore, treating a rank tuple as a single label is not a viable option for this task.", "labels": [], "entities": []}, {"text": "We also find that reviews with full agreement across rank aspects are quite common in our corpus, accounting for 38% of the training data.", "labels": [], "entities": []}, {"text": "Thus an agreementbased approach is natural and relevant.", "labels": [], "entities": []}, {"text": "A rank of 5 is the most common rank for all aspects and thus a prediction of all 5's gives a MAJOR-ITY baseline and a natural indication of task difficulty.", "labels": [], "entities": [{"text": "MAJOR-ITY baseline", "start_pos": 93, "end_pos": 111, "type": "METRIC", "confidence": 0.9652567505836487}]}, {"text": "Evaluation Measures We evaluate our algorithm and the baseline using ranking loss).", "labels": [], "entities": []}, {"text": "Ranking loss measures the average distance between the true rank and the predicted rank.", "labels": [], "entities": []}, {"text": "Formally, given N test instances (x 1 , y 1 ), ..., (x N , y N ) of an m-aspect ranking problem and the corresponding predictions\u02c6ypredictions\u02c6 predictions\u02c6y 1 , ..., \u02c6 y N , ranking loss is defined as \ud97b\udf59 . Lower values of this measure correspond to a better performance of the algorithm.", "labels": [], "entities": []}, {"text": "shows the performance of the Good Grief training algorithm GG TRAIN+DECODE along with various baselines, including the simple MAJORITY baseline mentioned in section 5.", "labels": [], "entities": [{"text": "GG", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.6338660717010498}, {"text": "TRAIN", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.7399489283561707}, {"text": "DECODE", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.5539476275444031}, {"text": "MAJORITY", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.7100797891616821}]}, {"text": "The first competitive baseline, PRANK, learns a separate ranker for each aspect using the PRank algorithm.", "labels": [], "entities": []}, {"text": "The second competitive baseline, SIM, shares the weight vectors across aspects using a similarity measure (  Both of these methods are described in detail in Section 2.", "labels": [], "entities": []}, {"text": "In addition, we consider two variants of our algorithm: GG DECODE employs the PRank training algorithm to independently train all component ranking models and only applies Good Grief decoding attest time.", "labels": [], "entities": [{"text": "GG DECODE", "start_pos": 56, "end_pos": 65, "type": "DATASET", "confidence": 0.6354239284992218}]}, {"text": "GG ORACLE uses Good Grief training and decoding but in both cases is given perfect knowledge of whether or not the true ranks all agree (instead of using the trained agreement model).", "labels": [], "entities": [{"text": "GG", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8419089317321777}, {"text": "ORACLE", "start_pos": 3, "end_pos": 9, "type": "METRIC", "confidence": 0.851912796497345}]}], "tableCaptions": [{"text": " Table 1: Ranking loss on the test set for variants of Good Grief and various baselines.", "labels": [], "entities": [{"text": "Ranking loss", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.970255047082901}, {"text": "Good Grief", "start_pos": 55, "end_pos": 65, "type": "TASK", "confidence": 0.7035968899726868}]}, {"text": " Table 2: Ranking loss for our model and PRANK  computed separately on cases of actual consensus  and actual disagreement.", "labels": [], "entities": [{"text": "Ranking loss", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9582350850105286}, {"text": "PRANK", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.6403583288192749}]}]}