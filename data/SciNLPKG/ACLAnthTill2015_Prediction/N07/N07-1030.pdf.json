{"title": [{"text": "Joint Determination of Anaphoricity and Coreference Resolution using Integer Programming", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.9750401973724365}]}], "abstractContent": [{"text": "Standard pairwise coreference resolution systems are subject to errors resulting from their performing anaphora identification as an implicit part of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.8822431564331055}, {"text": "coreference resolution", "start_pos": 150, "end_pos": 172, "type": "TASK", "confidence": 0.9294752180576324}]}, {"text": "In this paper, we propose an integer linear programming (ILP) formulation for coreference resolution which models anaphoricity and coreference as a joint task, such that each local model informs the other for the final assignments.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.9577372074127197}]}, {"text": "This joint ILP formulation provides f-score improvements of 3.7-5.3% over abase coreference classifier on the ACE datasets.", "labels": [], "entities": [{"text": "ACE datasets", "start_pos": 110, "end_pos": 122, "type": "DATASET", "confidence": 0.9867701828479767}]}], "introductionContent": [{"text": "The task of coreference resolution involves imposing a partition on a set of entity mentions in a document, where each partition corresponds to some entity in an underlying discourse model.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.9613524675369263}]}, {"text": "Most work treats coreference resolution as a binary classification task in which each decision is made in a pairwise fashion, independently of the others).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.9764664173126221}]}, {"text": "There are two major drawbacks with most systems that make pairwise coreference decisions.", "labels": [], "entities": []}, {"text": "The first is that identification of anaphora is done implicitly as part of the coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.9199543595314026}]}, {"text": "Two common types of errors with these systems are cases where: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.", "labels": [], "entities": []}, {"text": "To reduce such errors, and use an anaphoricity classifier -which has the sole task of saying whether or not any antecedents should be identified for each mention-as a filter for their coreference system.", "labels": [], "entities": []}, {"text": "They achieve higher performance by doing so; however, their setup uses the two classifiers in a cascade.", "labels": [], "entities": []}, {"text": "This requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration.", "labels": [], "entities": []}, {"text": "This sensitivity is unsurprising, given that the tasks are codependent.", "labels": [], "entities": [{"text": "sensitivity", "start_pos": 5, "end_pos": 16, "type": "METRIC", "confidence": 0.9751858115196228}]}, {"text": "The second problem is that most coreference systems make each decision independently of previous ones in a greedy fashion).", "labels": [], "entities": []}, {"text": "Clearly, the determination of membership of a particular mention into a partition should be conditioned on how well it matches the entity as a whole.", "labels": [], "entities": []}, {"text": "Since independence between decisions is an unwarranted assumption for the task, models that consider a more global context are likely to be more appropriate.", "labels": [], "entities": []}, {"text": "Recent work has examined such models; using using conditional random fields, and Ng (2005) using rerankers.", "labels": [], "entities": []}, {"text": "In this paper, we propose to recast the task of coreference resolution as an optimization problem, namely an integer linear programming (ILP) problem.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.9696949124336243}]}, {"text": "This framework has several properties that make it highly suitable for addressing the two aforementioned problems.", "labels": [], "entities": []}, {"text": "The first is that it can utilize existing classifiers; ILP performs global inference based on their output rather than formulating anew inference procedure for solving the basic task.", "labels": [], "entities": []}, {"text": "Second, the ILP approach supports inference over multiple classifiers, without having to fiddle with special parameterization.", "labels": [], "entities": []}, {"text": "Third, it is much more efficient than conditional random fields, especially when long-distance features are utilized).", "labels": [], "entities": []}, {"text": "Finally, it is straightforward to create categorical global constraints with ILP; this is done in a declarative manner using inequalities on the assignments to indicator variables.", "labels": [], "entities": []}, {"text": "This paper focuses on the first problem, and proposes to model anaphoricity determination and coreference resolution as a joint task, wherein the decisions made by each locally trained model are mutually constrained.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.7567122578620911}, {"text": "coreference resolution", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.9652898907661438}]}, {"text": "The presentation of the ILP model proceeds in two steps.", "labels": [], "entities": []}, {"text": "In the first, intermediary step, we simply use ILP to find a global assignment based on decisions made by the coreference classifier alone.", "labels": [], "entities": []}, {"text": "The resulting assignment is one that maximally agrees with the decisions of the classifier, that is, where all and only the links predicted to be coreferential are used for constructing the chains.", "labels": [], "entities": []}, {"text": "This is in contrast with the usual clustering algorithms, in which a unique antecedent is typically picked for each anaphor (e.g., the most probable or the most recent).", "labels": [], "entities": []}, {"text": "The second step provides the joint formulation: the coreference classifier is now combined with an anaphoricity classifier and constraints are added to ensure that the ultimate coreference and anaphoricity decisions are mutually consistent.", "labels": [], "entities": []}, {"text": "Both of these formulations achieve significant performance gains over the base classifier.", "labels": [], "entities": []}, {"text": "Specifically, the joint model achieves f -score improvements of 3.7-5.3% on three datasets.", "labels": [], "entities": [{"text": "f -score", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9784369071324667}]}, {"text": "We begin by presenting the basic coreference classifier and anaphoricity classifier and their performance, including an upperbound that shows the limitation of using them in a cascade.", "labels": [], "entities": []}, {"text": "We then give the details of our ILP formulations and evaluate their performance with respect to each other and the base classifier.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Recall (R), precision (P), and f -score (F) on the three ACE datasets for the basic coreference system  (COREF-PAIRWISE), the anaphoricity-coreference cascade system (AC-CASCADE), and the oracle which  performs perfect linkage (ORACLE-LINK). The first two systems make strictly local pairwise coreference  decisions.", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8803147971630096}, {"text": "precision (P)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.947434812784195}, {"text": "f -score (F)", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.9566217760245005}, {"text": "ACE datasets", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.9117289483547211}, {"text": "ORACLE-LINK", "start_pos": 238, "end_pos": 249, "type": "METRIC", "confidence": 0.9765565395355225}]}, {"text": " Table 2: Recall (R), precision (P), and f -score (F) on the three ACE datasets for the basic coreference system  (COREF-PAIRWISE), the coreference only ILP system (COREF-ILP), and the joint anaphoricity-coreference  ILP system (JOINT-ILP). All f -score differences are significant (p < .05).", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8233899772167206}, {"text": "precision (P)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9474679827690125}, {"text": "f -score (F)", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.9718659222126007}, {"text": "ACE datasets", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.968292772769928}]}]}