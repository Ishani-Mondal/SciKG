{"title": [{"text": "Subtree Mining for Relation Extraction from Wikipedia", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8633612990379333}]}], "abstractContent": [{"text": "In this study, we address the problem of extracting relations between entities from Wikipedia's English articles.", "labels": [], "entities": [{"text": "extracting relations between entities from Wikipedia's English articles", "start_pos": 41, "end_pos": 112, "type": "TASK", "confidence": 0.861878408326043}]}, {"text": "Our proposed method first anchors the appearance of entities in Wikipedia's articles using neither Named Entity Recognizer (NER) nor coreference resolution tool.", "labels": [], "entities": [{"text": "anchors the appearance of entities in Wikipedia", "start_pos": 26, "end_pos": 73, "type": "TASK", "confidence": 0.7118153657232013}, {"text": "coreference resolution", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.9528788924217224}]}, {"text": "It then classifies the relationships between entity pairs using SVM with features extracted from the web structure and subtrees mined from the syntactic structure of text.", "labels": [], "entities": []}, {"text": "We evaluate our method on manually annotated data from actual Wikipedia articles.", "labels": [], "entities": []}], "introductionContent": [{"text": "Wikipedia (www.wikipedia.org) has emerged as the world's largest online encyclopedia.", "labels": [], "entities": []}, {"text": "Because the encyclopedia is managed by the Wikipedia Foundation, and because numerous collaborators in the world continuously develop and edit its articles, its contents are believed to be quite reliable despite its openness.", "labels": [], "entities": [{"text": "Wikipedia Foundation", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.9307182431221008}]}, {"text": "This study is intended to deal with the problem of extracting binary relations between entity pairs from Wikipedia's English version.", "labels": [], "entities": [{"text": "extracting binary relations between entity pairs from Wikipedia's English version", "start_pos": 51, "end_pos": 132, "type": "TASK", "confidence": 0.8478470498865301}]}, {"text": "A binary relation is defined as a triple (e p , rel, e s ) in which e p and e s are entities and rel indicates a directed relationship of e p and e s . Current experiment limits entities and relations to a reasonable size in that an entity is classifiable as person, organization, location, artifact, year, month or date; and a relation can be founder, chairman, CEO, COO, president, director, vice chairman, spouse, birth date, birthplace, foundation, product and location.", "labels": [], "entities": []}, {"text": "To our knowledge, only one recent work has attempted relation extraction on Wikipedia: () presents a probabilistic model to integrate extraction and mining tasks performed on biographical text of Wikipedia.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8512870371341705}]}, {"text": "Some other works) rely on the abundance of web data to obtain easy patterns and learn such patterns based mostly on lexical information.", "labels": [], "entities": []}, {"text": "Rather than analyzing dependency path between entity pair proposed in (), our method analyzes a subtree derived from the dependency structure.", "labels": [], "entities": []}, {"text": "Such subtree contains more evidence of the entities' inter-relation than the path in some cases.", "labels": [], "entities": []}, {"text": "We propose anew feature obtained from the subtree by using a subtree-mining technique.", "labels": [], "entities": []}, {"text": "In addition, we also make use of the characteristics of Wikipedia to allocate the mentions of entities and further identify their types to help the relation extraction process.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.8488377928733826}]}], "datasetContent": [{"text": "In this experiment, 5,975 articles are selected, in which 45 articles are for testing and 5,930 articles for training.", "labels": [], "entities": []}, {"text": "We apply the framework in on the training articles to extract keywords and select relation candidates.", "labels": [], "entities": []}, {"text": "Subsequently, 3,833 positive instances (each contains at least one relation) and 805 negative instances (the ones containing no relation) from the candidates are annotated to train the Relation Extractor.", "labels": [], "entities": []}, {"text": "Among 39,467  entities collected from all principal and secondary entities, we randomly select 3,300 entities and manually annotate their types for the Entity Classifier.", "labels": [], "entities": []}, {"text": "Finally, we use 3,100 entities for training and 200 entities for testing.", "labels": [], "entities": []}, {"text": "We develop two baseline systems to evaluate our method, which use bag-of-words model.", "labels": [], "entities": []}, {"text": "The second system (B1 in) works like the Keyword Extractor on training instances in that it calculates tf-idf scores for words on the dependency path between the entities with respect to each relation.", "labels": [], "entities": [{"text": "B1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9486777186393738}]}, {"text": "During testing, it accumulates tf-idf scores of words on the path and chooses the relation label that gives the highest score for the entity pair.", "labels": [], "entities": []}, {"text": "The only difference between the two baseline systems is that the first one (B0 in) focuses on all the words between the entities in sentence text, not dependency path.", "labels": [], "entities": []}, {"text": "In our experiments, dependency graphs are obtained by Minipar parser), classifiers are trained by SVM Light (Joachims, 1999) with 2 nd -order polynomial kernel, subtrees are mined by FREQT 3 tree miner.", "labels": [], "entities": [{"text": "SVM Light (Joachims, 1999)", "start_pos": 98, "end_pos": 124, "type": "DATASET", "confidence": 0.8199194329125541}, {"text": "FREQT 3 tree miner", "start_pos": 183, "end_pos": 201, "type": "DATASET", "confidence": 0.8983899354934692}]}, {"text": "On the basis of preliminary experiments, we report the performance of our system compared with those of baseline systems in.", "labels": [], "entities": []}, {"text": "The result shows that our proposed method gives a substantial improvement over the baselines.", "labels": [], "entities": []}, {"text": "Although the recall is quite adequate, precision is low.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9997110962867737}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9997228980064392}]}, {"text": "Data analysis reveals that although the mined subtrees capture key features for relationships, they also generate many irrelevant features which degrade the performance.", "labels": [], "entities": []}, {"text": "It is necessary to carryout feature selection step for subtree feature.", "labels": [], "entities": []}, {"text": "One more reason of the poor precision is that our system suffers from the error accumulation in along pipeline of entity detection, entity classification, dependency parsing and relation classification.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9991752505302429}, {"text": "entity detection", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.7330635488033295}, {"text": "entity classification", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.7990072965621948}, {"text": "dependency parsing", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.7215887606143951}, {"text": "relation classification", "start_pos": 178, "end_pos": 201, "type": "TASK", "confidence": 0.8172579109668732}]}, {"text": "shows the effectiveness of different values of k parameter in Entity Classifier.", "labels": [], "entities": [{"text": "Entity Classifier", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.6541520655155182}]}, {"text": "The classifier works best when we trace four levels on category system.", "labels": [], "entities": []}, {"text": "An interesting fact is that Wikipedia can be used as an external", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Compare our proposed system and baselines", "labels": [], "entities": []}, {"text": " Table 4: Result of Entity Classifier with various levels (k  value) of exploited category structure", "labels": [], "entities": []}]}