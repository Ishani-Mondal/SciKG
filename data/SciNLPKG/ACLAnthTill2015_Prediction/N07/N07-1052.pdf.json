{"title": [{"text": "Approximate Factoring for A * Search", "labels": [], "entities": [{"text": "Approximate", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9850521087646484}, {"text": "A * Search", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.5626548628012339}]}], "abstractContent": [{"text": "We present a novel method for creating A * estimates for structured search problems.", "labels": [], "entities": []}, {"text": "In our approach , we project a complex model onto multiple simpler models for which exact inference is efficient.", "labels": [], "entities": []}, {"text": "We use an optimization framework to estimate parameters for these projections in away which bounds the true costs.", "labels": [], "entities": []}, {"text": "Similar to Klein and Manning (2003), we then combine completion estimates from the simpler models to guide search in the original complex model.", "labels": [], "entities": [{"text": "completion", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.9463356733322144}]}, {"text": "We apply our approach to bitext parsing and lexicalized parsing, demonstrating its effectiveness in these domains.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.5596733093261719}, {"text": "lexicalized parsing", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7032449245452881}]}], "introductionContent": [{"text": "Inference tasks in NLP often involve searching for an optimal output from a large set of structured outputs.", "labels": [], "entities": []}, {"text": "For many complex models, selecting the highest scoring output fora given observation is slow or even intractable.", "labels": [], "entities": []}, {"text": "One general technique to increase efficiency while preserving optimality is A * search; however, successfully using A * search is challenging in practice.", "labels": [], "entities": []}, {"text": "The design of admissible (or nearly admissible) heuristics which are both effective (close to actual completion costs) and also efficient to compute is a difficult, open problem inmost domains.", "labels": [], "entities": []}, {"text": "As a result, most work on search has focused on non-optimal methods, such as beam search or pruning based on approximate models, though in certain cases admissible heuristics are known).", "labels": [], "entities": [{"text": "beam search", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.861327052116394}]}, {"text": "For example, show a class of projection-based A * estimates, but their application is limited to models which have a very restrictive kind of score decomposition.", "labels": [], "entities": []}, {"text": "In this work, we broaden their projectionbased technique to give A * estimates for models which do not factor in this restricted way.", "labels": [], "entities": [{"text": "A", "start_pos": 65, "end_pos": 66, "type": "METRIC", "confidence": 0.9876036643981934}]}, {"text": "Like, we focus on search problems where there are multiple projections or \"views\" of the structure, for example lexical parsing, in which trees can be projected onto either their CFG backbone or their lexical attachments.", "labels": [], "entities": [{"text": "lexical parsing", "start_pos": 112, "end_pos": 127, "type": "TASK", "confidence": 0.7223174273967743}]}, {"text": "We use general optimization techniques) to approximately factor a model over these projections.", "labels": [], "entities": []}, {"text": "Solutions to the projected problems yield heuristics for the original model.", "labels": [], "entities": []}, {"text": "This approach is flexible, providing either admissible or nearly admissible heuristics, depending on the details of the optimization problem solved.", "labels": [], "entities": []}, {"text": "Furthermore, our approach allows a modeler explicit control over the trade-off between the tightness of a heuristic and its degree of inadmissibility (if any).", "labels": [], "entities": []}, {"text": "We describe our technique in general and then apply it to two concrete NLP search tasks: bitext parsing and lexicalized monolingual parsing.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.52848120033741}, {"text": "lexicalized monolingual parsing", "start_pos": 108, "end_pos": 139, "type": "TASK", "confidence": 0.6594091554482778}]}], "datasetContent": [{"text": "We demonstrate our technique using the synchronous grammar formalism of tree-to-tree transducers ().", "labels": [], "entities": []}, {"text": "In each weighted rule, an aligned pair of nonterminals generates two ordered lists of children.", "labels": [], "entities": []}, {"text": "The non-terminals in each list must align one-to-one to the non-terminals in the other, while the terminals are placed freely on either side.", "labels": [], "entities": []}, {"text": "Following, we learn a grammar by projecting English syntax onto a foreign language via word-level alignments, as in.", "labels": [], "entities": []}, {"text": "We parsed 1200 English-Spanish sentences using a grammar learned from 40,000 sentence pairs of the English-Spanish Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 115, "end_pos": 130, "type": "DATASET", "confidence": 0.9263836443424225}]}, {"text": "8(a) shows that A * expands substantially fewer states while searching for the optimal parse with our op-7 The bilingual corpus consists of translation pairs with fixed English parses and word alignments.", "labels": [], "entities": []}, {"text": "Rules were scored by their relative frequencies.", "labels": [], "entities": []}, {"text": "8 Rare words were replaced with their parts of speech to limit the memory consumption of the parser.", "labels": [], "entities": []}, {"text": "T r an s la timization heuristic.", "labels": [], "entities": []}, {"text": "The exhaustive curve shows edge expansions using the null heuristic.", "labels": [], "entities": []}, {"text": "The intermediate result, labeled English only, used only the English monolingual outside score as a heuristic.", "labels": [], "entities": []}, {"text": "Similar results using only Spanish demonstrate that both projections contribute to parsing efficiency.", "labels": [], "entities": [{"text": "parsing", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.9840912222862244}]}, {"text": "All three curves in represent running times for finding the optimal parse.", "labels": [], "entities": []}, {"text": "Zhang and Gildea offer a different heuristic for A * parsing of ITG grammars that provides a forward estimate of the cost of aligning the unparsed words in both sentences.", "labels": [], "entities": [{"text": "A * parsing of ITG grammars", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.7433673739433289}]}, {"text": "We cannot directly apply this technique to our grammar because tree-to-tree transducers only align non-terminals.", "labels": [], "entities": []}, {"text": "Instead, we can augment our synchronous grammar model to include a lexical alignment component, then employ both heuristics.", "labels": [], "entities": []}, {"text": "We learned the following two-stage generative model: a tree-to-tree transducer generates trees whose leaves are parts of speech.", "labels": [], "entities": []}, {"text": "Then, the words of each sentence are generated, either jointly from aligned parts of speech or independently given a null alignment.", "labels": [], "entities": []}, {"text": "The cost of a complete parse under this new model decomposes into the cost of the synchronous tree over parts of speech and the cost of generating the lexical items.", "labels": [], "entities": []}, {"text": "Given such a model, both our optimization heuristic and the lexical heuristic of can be computed independently.", "labels": [], "entities": []}, {"text": "Crucially, the sum of these heuristics is still admissible.", "labels": [], "entities": []}, {"text": "Both heuristics (lexical and optimization) alone improve parsing performance, but their sum opt+lex substantially improves upon either one.", "labels": [], "entities": []}, {"text": "We tested our approximate projection heuristic on two lexicalized parsing models.", "labels": [], "entities": []}, {"text": "The first is the factored model of, given by equation, and the second is the non-factored model described in equation.", "labels": [], "entities": []}, {"text": "Both models use the same parent-annotated head-binarized CFG backbone and a basic dependency projection which models direction, but not distance or valence.", "labels": [], "entities": [{"text": "CFG backbone", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9424276649951935}]}, {"text": "In each case, we compared A * using our approximate projection heuristics to exhaustive search.", "labels": [], "entities": []}, {"text": "We measure efficiency in terms of the number of expanded hypotheses (edges popped); see.", "labels": [], "entities": []}, {"text": "In both settings, the factored A * approach substantially outperforms exhaustive search.", "labels": [], "entities": []}, {"text": "For the fac- The CFG and dependency projections correspond to the PCFG-PA and DEP-BASIC settings in.", "labels": [], "entities": [{"text": "CFG", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.6385937929153442}, {"text": "PCFG-PA", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.948352038860321}]}, {"text": "All models are trained on section 2 through 21 of the English Penn treebank, and tested on section 23.", "labels": [], "entities": [{"text": "English Penn treebank", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.9650974273681641}]}, {"text": "tored model of, we can also compare our reconstructed bound to the known tight bound which would result from solving the pointwise admissible problem in (4) with all constraints.", "labels": [], "entities": []}, {"text": "As shows, the exact factored heuristic does outperform our approximate factored heuristic, primarily because of many looser, backedoff cost estimates for unseen dependency tuples.", "labels": [], "entities": []}, {"text": "For the non-factored model, we compared our approximate factored heuristic to one which only bounds the CFG projection as suggested by.", "labels": [], "entities": [{"text": "CFG projection", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.8378148674964905}]}, {"text": "They suggest, where we obtain factored CFG costs by minimizing over dependency projections.", "labels": [], "entities": []}, {"text": "As illustrates, this CFG only heuristic is substantially less efficient than our heuristic which bounds both projections.", "labels": [], "entities": []}, {"text": "Since our heuristic is no longer guaranteed to be admissible, we evaluated its effect on search in several ways.", "labels": [], "entities": []}, {"text": "The first is to check for search errors, where the model-optimal parse is not found.", "labels": [], "entities": []}, {"text": "In the case of the factored model, we can find the optimal parse using the exact factored heuristic and compare it to the parse found by our learned heuristic.", "labels": [], "entities": []}, {"text": "In our test set, the approximate projection heuristic failed to return the model optimal parse in less than 1% of sentences.", "labels": [], "entities": []}, {"text": "Of these search errors, none of the costs were more than 0.1% greater than the model optimal cost in negative log-likelihood.", "labels": [], "entities": []}, {"text": "For the non-factored model, the model optimal parse is known only for shorter sentences which can be parsed exhaustively.", "labels": [], "entities": []}, {"text": "For these sentences up to length 15, there were no search errors.", "labels": [], "entities": []}, {"text": "We can also check for violations of pointwise admissibility for configurations encoun-(a): Edges popped by exhaustive versus factored A * search.", "labels": [], "entities": []}, {"text": "The chart in (a) is using the factored lexicalized model from.", "labels": [], "entities": []}, {"text": "The chart in (b) is using the non-factored lexicalized model described in section 4.", "labels": [], "entities": []}, {"text": "For both the factored and nonfactored model, less than 2% of the configurations scored by the approximate projection heuristic during search violated pointwise admissibility.", "labels": [], "entities": []}, {"text": "While this is a paper about inference, we also measured the accuracy in the standard way, on sentences of length up to 40, using EVALB.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9996658563613892}, {"text": "EVALB", "start_pos": 129, "end_pos": 134, "type": "DATASET", "confidence": 0.8219171166419983}]}, {"text": "The factored model with the approximate projection heuristic achieves an F 1 of 82.2, matching the performance with the exact factored heuristic, though slower.", "labels": [], "entities": [{"text": "F 1", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9955043494701385}]}, {"text": "The non-factored model, using the approximate projection heuristic, achieves an F 1 of 83.8 on the test set, which is slightly better than the factored model.", "labels": [], "entities": [{"text": "F 1", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.995519757270813}]}, {"text": "We note that the CFG and dependency projections are as similar as possible across models, so the increase inaccuracy is likely due in part to the nonfactored model's coupling of CFG and dependency projections.", "labels": [], "entities": [{"text": "CFG", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.8330004811286926}]}], "tableCaptions": []}