{"title": [{"text": "Combination of Statistical Word Alignments Based on Multiple Preprocessing Schemes", "labels": [], "entities": [{"text": "Statistical Word Alignments", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6647869646549225}]}], "abstractContent": [{"text": "We present an approach to using multiple preprocessing schemes to improve statistical word alignments.", "labels": [], "entities": [{"text": "statistical word alignments", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.656809796889623}]}, {"text": "We show a relative reduction of alignment error rate of about 38%.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 32, "end_pos": 52, "type": "METRIC", "confidence": 0.8251029451688131}]}], "introductionContent": [], "datasetContent": [{"text": "The gold standard alignments we use here are part of the IBM Arabic-English aligned corpus (IBMAC) 4).", "labels": [], "entities": [{"text": "IBM Arabic-English aligned corpus (IBMAC) 4", "start_pos": 57, "end_pos": 100, "type": "DATASET", "confidence": 0.8667190000414848}]}, {"text": "We only use 8.8K sentences from IBMAC because the rest (smaller portion) of the corpus uses different normalizations for numerals that make the two sets incompatible.", "labels": [], "entities": [{"text": "IBMAC", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.9133417010307312}]}, {"text": "We break this data into 6.6K sentences for training and 2.2K sentences for development.", "labels": [], "entities": []}, {"text": "As for test data, we use the IBMAC's test set: NIST MTEval 2003 (663 Arabic sentences each human aligned to four English references).", "labels": [], "entities": [{"text": "IBMAC's test set", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.8316735327243805}, {"text": "NIST MTEval 2003", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.7642704049746195}]}, {"text": "To get initial Giza++ alignments, we use a larger parallel corpus together with the annotated set.", "labels": [], "entities": []}, {"text": "The Arabic-English parallel corpus has about 5 million words.", "labels": [], "entities": []}, {"text": "The Arabic text in IBMAC is preprocessed in the AR preprocessing scheme with some additional character normalizations.", "labels": [], "entities": [{"text": "IBMAC", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.9057844877243042}]}, {"text": "We match the preprocessing and normalizations on our additional data to that of IBMAC's Arabic and English preprocessing).", "labels": [], "entities": [{"text": "IBMAC", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.9168069958686829}]}, {"text": "The standard evaluation metric within word alignment is the Alignment Error Rate (AER)), which requires gold alignments that are marked as 'sure' or 'probable'.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7141127288341522}, {"text": "Alignment Error Rate (AER))", "start_pos": 60, "end_pos": 87, "type": "METRIC", "confidence": 0.9626482923825582}]}, {"text": "Since the IBMAC gold alignments we use are not marked as such, AER reduces to 1 -F-score): where A links are proposed and S links are gold.", "labels": [], "entities": [{"text": "IBMAC gold alignments", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.7508564790089926}, {"text": "AER", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9993975162506104}, {"text": "F-score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.8798635601997375}]}, {"text": "NULL links are not included in the evaluation ().", "labels": [], "entities": []}, {"text": "To determine the best subset of alignment remappings to combine, we ordered the alignments given their AER performance in the last experiment described (using combination features).", "labels": [], "entities": [{"text": "AER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9978821873664856}]}, {"text": "Starting with the best performer (D3 dir ), we continued adding alignments in the order of their performance so long the com- used only the top 50 sentences in IBMAC test data.", "labels": [], "entities": [{"text": "IBMAC test data", "start_pos": 160, "end_pos": 175, "type": "DATASET", "confidence": 0.9211713671684265}]}, {"text": "Our best AER result on their test set is 14.02% (baseline is 22.48%) which is higher than their reported result (12.2% with 20.5% baseline (unrefined GIZA++)).", "labels": [], "entities": [{"text": "AER", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9986236095428467}, {"text": "baseline", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9587731957435608}, {"text": "GIZA", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.9325100779533386}]}, {"text": "The two results are not comparable because: (a) used additional gold aligned data that was not released and (b) they use an additional 500K sentences from the LDC UN corpus for Giza training that was created by adapting to the source side of the test set -the details of such adaptation were not provided and thus it is not clear how to replicate them to compare fairly.", "labels": [], "entities": [{"text": "LDC UN corpus", "start_pos": 159, "end_pos": 172, "type": "DATASET", "confidence": 0.8769502838452657}]}, {"text": "Clearly this additional data is helpful since even their baseline is higher than ours.", "labels": [], "entities": []}, {"text": "6 Error Analysis We conducted error analysis on 50 sentences from our development set.", "labels": [], "entities": []}, {"text": "The majority of the errors involved high frequency closedclass words (54%) and complex phrases (noncompositional or divergent translations) (23%).", "labels": [], "entities": [{"text": "errors", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.956231415271759}]}, {"text": "Both kinds of errors could be partly addressed by introducing phrasal constraints which are currently lacking in our system.", "labels": [], "entities": []}, {"text": "Orthogonally, about 18% of all errors involved gold-standard inconsistencies and errors.", "labels": [], "entities": []}, {"text": "These gold errors are split equally between closed-class and complex-phrase errors.", "labels": [], "entities": []}, {"text": "Abraham Ittycheriah, personal communication.", "labels": [], "entities": [{"text": "personal communication", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7697236239910126}]}], "tableCaptions": [{"text": " Table 2: Combining the Alignment Remappings", "labels": [], "entities": [{"text": "Alignment Remappings", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.8556888103485107}]}]}