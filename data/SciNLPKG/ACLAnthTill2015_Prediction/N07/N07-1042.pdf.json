{"title": [{"text": "Multi-document Relationship Fusion via Constraints on Probabilistic Databases", "labels": [], "entities": [{"text": "Multi-document Relationship Fusion", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6469556192557017}]}], "abstractContent": [{"text": "Previous multi-document relationship extraction and fusion research has focused on single relationships.", "labels": [], "entities": [{"text": "multi-document relationship extraction", "start_pos": 9, "end_pos": 47, "type": "TASK", "confidence": 0.6781925857067108}]}, {"text": "Shifting the focus to multiple relationships allows for the use of mutual constraints to aid extraction.", "labels": [], "entities": []}, {"text": "This paper presents a fusion method which uses a probabilistic database model to pick relationships which violate few constraints.", "labels": [], "entities": []}, {"text": "This model allows improved performance on constructing corporate succession timelines from multiple documents with respect to a multi-document fusion baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Single document information extraction of named entities and relationships has received much attention since the MUC evaluations 1 in the mid-90s.", "labels": [], "entities": [{"text": "Single document information extraction of named entities and relationships", "start_pos": 0, "end_pos": 74, "type": "TASK", "confidence": 0.8120773169729445}, {"text": "MUC evaluations 1", "start_pos": 113, "end_pos": 130, "type": "DATASET", "confidence": 0.7027203241984049}]}, {"text": "Recently, there has been increased interest in the extraction of named entities and relationships from multiple documents, since the redundancy of information across documents has been shown to be a powerful resource for obtaining high quality information even when the extractors have access to little or no training data ().", "labels": [], "entities": [{"text": "extraction of named entities and relationships from multiple documents", "start_pos": 51, "end_pos": 121, "type": "TASK", "confidence": 0.811741828918457}]}, {"text": "Much of the recent work in multidocument relationship extraction has focused on the extraction of isolated relationships), but often the goal, as in 1 http://www.itl.nist.gov/iaui/894.02/related projects/muc/ single document tasks like MUC, is to extract a template or a relational database composed of related facts.", "labels": [], "entities": [{"text": "multidocument relationship extraction", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.6720122297604879}]}, {"text": "With databases containing multiple relationships, the semantics of the database impose constraints on possible database configurations.", "labels": [], "entities": []}, {"text": "This paper presents a statistical method which picks relationships which violate few constraints as measured by a probabilistic database model.", "labels": [], "entities": []}, {"text": "The constraints are hard constraints, and robust estimates are achieved by accounting for the underlying extraction/fusion uncertainty.", "labels": [], "entities": []}, {"text": "This method is applied to the problem of constructing management succession timelines which have a rich set of semantic constraints.", "labels": [], "entities": []}, {"text": "Using constraints on probabilistic databases yields F-Measure improvements of 5 to 18 points on a per-relationship basis over a state-of-the-art multi-document extraction/fusion baseline.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9675391316413879}, {"text": "multi-document extraction", "start_pos": 145, "end_pos": 170, "type": "TASK", "confidence": 0.7118690460920334}]}, {"text": "The constraints proposed in this paper are used in a context of minimally supervised information extractors and present an alternative to costly manual annotation.", "labels": [], "entities": [{"text": "information extractors", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.7572065591812134}]}], "datasetContent": [{"text": "In order to test the fusion method proposed above, human annotators manually constructed truth data of complete chief executive histories for 18 Fortune-500 companies using online resources.", "labels": [], "entities": []}, {"text": "Extraction from these documents is particularly difficult because these data have vast differences in genre and style and are considerably noisy.", "labels": [], "entities": [{"text": "Extraction", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9660362005233765}]}, {"text": "Furthermore, the task is complicated to start with.", "labels": [], "entities": []}, {"text": "A corpus was created for each company by issuing a Google query for \"CEO-of-Company OR Company-CEO\", and collecting the top ranked documents, generating up to 1000 documents per company.", "labels": [], "entities": []}, {"text": "The data was then split randomly into training, development and testing sets of 6, 4, and 8 companies.", "labels": [], "entities": []}, {"text": "Training : Anheuser-Busch, Hewlett-Packard, Lenner, McGraw-Hill, Pfizer, Raytheon Dev.", "labels": [], "entities": []}, {"text": ": Boeing, Heinz, Staples, Textron Test : General Electric, General Motors, Gannett, The Home Depot, IBM, Kroger, Sears, UPS Ground truth was created from the entire web, but since the corpus for each company is only a small web snapshot, the experimental results are not similar to extraction tasks like MUC and ACE in that the corpus is not guaranteed to contain the information necessary to build the entire database.", "labels": [], "entities": []}, {"text": "In particular, One thing to note is that since all relationships are given confidence estimates separately, this process may result ultimately in a database where constraints are violated.", "labels": [], "entities": []}, {"text": "A potential solution, which is not explored here, would be to incrementally add relationships to the database from the ranked list only if their addition doesn't make the database inconsistent.", "labels": [], "entities": []}, {"text": "8 For example, in certain companies, the title of the chief executive has changed over the years, often going from \"President\" to \"Chief Executive Officer\".", "labels": [], "entities": []}, {"text": "To make things more complicated, after the change, the role of \"President\" may still hang on as a subordinate to the CEO!", "labels": [], "entities": []}, {"text": "1) Only one start or end per person.", "labels": [], "entities": []}, {"text": "\u2200r1, r2 : \u03b7(r1, r2) = (r type  many CEOs from pre-Internet years were either infrequently mentioned or not mentioned at all in the database.", "labels": [], "entities": []}, {"text": "In the following experiments, recall is reported for facts that were retrieved by the extraction system.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9992271661758423}]}, {"text": "Given the management succession database proposed in Section 2, enumerates a set of quantified constraints.", "labels": [], "entities": []}, {"text": "Information extraction and fusion were run separately for each company to create a probabilistic database.", "labels": [], "entities": [{"text": "Information extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7739008963108063}]}, {"text": "In this section, various constraint sets are applied, either individually or jointly, and evaluated in two ways.", "labels": [], "entities": []}, {"text": "The first measures perrelationship precision/recall using the model pro- 2,5 2,3,5,: Precision/Recall curve for start(x,t) relationships.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9678272604942322}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9889776110649109}, {"text": "Precision/Recall curve", "start_pos": 85, "end_pos": 107, "type": "METRIC", "confidence": 0.8523195534944534}]}, {"text": "The joint constraint \"2,3,5,8\" is the best performing, even though constraints \"3\" and \"8\" (not pictured) alone don't perform well.", "labels": [], "entities": []}, {"text": "posed and the second looks at the precision/recall of a heterogeneous database with many relationship types.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9994359612464905}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9674726724624634}]}, {"text": "Both evaluations examine the ranked lists of relationships, where the relationships are ranked by rescoring via constraints on probabilistic databases (Equation 3) and compared to the baseline fusion score (Equation 4).", "labels": [], "entities": []}, {"text": "The evaluations use two standard metrics, interpolated precision at recall level i (P R i ), and MaxF1:, and 3 show precision/recall curves for the application of various sets of constraints.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.6956561207771301}, {"text": "recall level i (P R i )", "start_pos": 68, "end_pos": 91, "type": "METRIC", "confidence": 0.9214699566364288}, {"text": "MaxF1", "start_pos": 97, "end_pos": 102, "type": "METRIC", "confidence": 0.832504153251648}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9943057894706726}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.7815283536911011}]}, {"text": "lists the MaxF1 scores for each of the constraint variants.", "labels": [], "entities": []}, {"text": "For start and end, the majority of constraints are beneficial.", "labels": [], "entities": []}, {"text": "For precedes, only the constraint that improved performance constraints both people in the relationship to be CEOs.", "labels": [], "entities": []}, {"text": "Across all relationships, performance is hurt when using the constraint that there could only be one relationship of each type fora given CEO.", "labels": [], "entities": []}, {"text": "The reason behind this is that the confidence estimate based on this constraint favors relationships with few competitors, and those relationships are typically for people who are infrequent in the corpus (and therefore unlikely to be CEOs).", "labels": [], "entities": []}, {"text": "The best-performing constraint sets yield between 5 and 18 points of improvement on Max F1 (Table 3).", "labels": [], "entities": [{"text": "Max", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.6652660965919495}, {"text": "F1", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.3752618134021759}]}, {"text": "Surprisingly, the gains from joint con- straints are sometimes more than their additive gains.", "labels": [], "entities": []}, {"text": "\"2,3,5,6,8\" is 6 points better for the start relationship than \"2,3,5,6\", but the gains from \"8\" alone are negligible.", "labels": [], "entities": []}, {"text": "These performance gains on the individual relationship types also lead to gains when generating an entire database.", "labels": [], "entities": []}, {"text": "The highest performing constraint is the \"CEOs Only (2)\" constraint, which outperforms the joint constraints of the previous section.", "labels": [], "entities": []}, {"text": "One reason the joint constraints don't do as well here is that each constraint makes the confidence estimate smaller and smaller.", "labels": [], "entities": []}, {"text": "This doesn't have an effect when judging the relationship types individually, but when combining the relationships results, the fused relationships types (start, end) be-: Max F1 scores for three relationships Start(x,t), End(x,t) and Precedes(x,y)) in isolation and within the context of whole database DB.", "labels": [], "entities": [{"text": "F1", "start_pos": 176, "end_pos": 178, "type": "METRIC", "confidence": 0.6732320785522461}]}, {"text": "The joint constraints perform best for the explicit relationships in isolation.", "labels": [], "entities": []}, {"text": "Using constraints on implicit derived fields (Inoffice and Precedes) provides additional benefit above constraints strictly on explicit database fields (start, end, ceo).", "labels": [], "entities": []}, {"text": "come artificially lower ranked than the unfused relationship type (ceo).", "labels": [], "entities": []}, {"text": "The best performing contrained probabilistic database approach beats the baseline by 5 points.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Max F1 scores for three relationships  Start(x,t), End(x,t) and Precedes(x,y)) in isolation  and within the context of whole database DB. The  joint constraints perform best for the explicit rela- tionships in isolation. Using constraints on implicit  derived fields (Inoffice and Precedes) provides ad- ditional benefit above constraints strictly on explicit  database fields (start, end, ceo).", "labels": [], "entities": [{"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.7462514638900757}]}]}