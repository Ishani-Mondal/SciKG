{"title": [], "abstractContent": [{"text": "An open issue in data-driven dependency parsing is how to handle non-projective dependencies, which seem to be required by linguistically adequate representations, but which pose problems in parsing with respect to both accuracy and efficiency.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7280053794384003}, {"text": "accuracy", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.9977198243141174}]}, {"text": "Using data from five different languages, we evaluate an incremental deterministic parser that derives non-projective dependency structures in O(n 2) time, supported by SVM classifiers for predicting the next parser action.", "labels": [], "entities": []}, {"text": "The experiments show that unrestricted non-projective parsing gives a significant improvement inaccuracy, compared to a strictly projective baseline, with up to 35% error reduction, leading to state-of-the-art results for the given data sets.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 165, "end_pos": 180, "type": "METRIC", "confidence": 0.9453123211860657}]}, {"text": "Moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without a significant decrease inaccuracy.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven dependency parsing has been shown to give accurate and efficient parsing fora wide range of languages, such as Japanese (), English (,),), and Czech ().", "labels": [], "entities": [{"text": "Data-driven dependency parsing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5629252890745798}]}, {"text": "Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order.", "labels": [], "entities": []}, {"text": "The most popular strategy for capturing nonprojective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing), corrective modeling (), or approximate non-projective parsing ).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7203425765037537}]}, {"text": "And it is rare to find parsers that derive non-projective structures directly, the notable exception being the non-projective spanning tree parser proposed by.", "labels": [], "entities": []}, {"text": "There are essentially two arguments that have been advanced against using parsing algorithms that derive non-projective dependency structures directly.", "labels": [], "entities": []}, {"text": "The first is that the added expressivity compromises efficiency, since the parsing problem fora grammar that allows arbitrary non-projective dependency structures has been shown to be NP complete).", "labels": [], "entities": []}, {"text": "On the other hand, most data-driven approaches do not rely on grammars, and with a suitable factorization of dependency structures, it is possible to achieve parsing of unrestricted non-projective structures in O(n 2 ) time, as shown by.", "labels": [], "entities": []}, {"text": "The second argument against non-projective dependency parsing comes from the observation that, even in languages with free or flexible word order, most dependency structures are either projective or very nearly projective.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7369560599327087}]}, {"text": "This can be seen by considering data from treebanks, such as the Prague Dependency Treebank of Czech (, the TIGER Treebank of German (), or the Slovene Dependency Treebank), where the overall proportion of non-projective dependencies is only about 2% even though the proportion of sentences that contain some non-projective dependency is as high as 25%.", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.8697081804275513}, {"text": "TIGER Treebank of German", "start_pos": 108, "end_pos": 132, "type": "DATASET", "confidence": 0.8507273271679878}, {"text": "Slovene Dependency Treebank", "start_pos": 144, "end_pos": 171, "type": "DATASET", "confidence": 0.8301169673601786}]}, {"text": "This means that an approach that starts by deriving the best projective approximation of the correct dependency structure is likely to achieve high accuracy, while an approach that instead attempts to search the complete space of non-projective dependency structures runs the risk of finding structures that depart too much from the near-projective norm.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9985203146934509}]}, {"text": "Again, however, the results of suggest that the latter risk is minimized if inductive learning is used to guide the search.", "labels": [], "entities": []}, {"text": "One way of improving efficiency, and potentially also accuracy, in non-projective dependency parsing is to restrict the search to a subclass of \"mildly nonprojective\" structures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9990465044975281}, {"text": "non-projective dependency parsing", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.6647660334904989}]}, {"text": "Nivre (2006) defines degrees of non-projectivity in terms of the maximum number of intervening constituents in the projection of a syntactic head and shows that limited degrees of nonprojectivity give a much better fit with the linguistic data than strict projectivity, but also enables more efficient processing than unrestricted non-projectivity.", "labels": [], "entities": []}, {"text": "However, the results presented by are all based on oracle parsing, which means that they only provide upper bounds on the accuracy that can be achieved.", "labels": [], "entities": [{"text": "oracle parsing", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.6960656344890594}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9986716508865356}]}, {"text": "In this paper, we investigate to what extent constraints on non-projective structures can improve accuracy and efficiency in practical parsing, using treebank-induced classifiers to predict the actions of a deterministic incremental parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9970425963401794}, {"text": "parsing", "start_pos": 135, "end_pos": 142, "type": "TASK", "confidence": 0.904346227645874}]}, {"text": "The parsing algorithm used belongs to the family of algorithms described by, and the classifiers are trained using support vector machines (SVM)).", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9678434729576111}]}, {"text": "The system is evaluated using treebank data from five languages: Danish, Dutch, German, Portuguese, and Slovene.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 defines syntactic representations as labeled dependency graphs and introduces the notion of degree used to constrain the search.", "labels": [], "entities": []}, {"text": "Section 3 describes the parsing algorithm, including modifications necessary to handle degrees of non-projectivity, and section 4 describes the data-driven prediction of parser actions, using history-based models and SVM classifiers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9749286770820618}]}, {"text": "Section 5 presents the experimental setup, section 6 discusses the experimental results, and section 7 contains our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The purpose of the experiments is twofold.", "labels": [], "entities": []}, {"text": "First, we want to investigate whether allowing non-projective structures to be derived incrementally can improve parsing accuracy compared to a strictly projective baseline.", "labels": [], "entities": [{"text": "parsing", "start_pos": 113, "end_pos": 120, "type": "TASK", "confidence": 0.9738292694091797}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9322649836540222}]}, {"text": "Secondly, we want to examine whether restricting the degree of non-projectivity can improve efficiency compared to an unrestricted nonprojective baseline.", "labels": [], "entities": []}, {"text": "In order to investigate both these issues, we have trained one non-projective parser for each language, allowing arbitrary non-projective structures as found in the treebanks during training, but applying different constraints during parsing: These three versions of the non-projective parser are compared to a strictly projective parser (d = 0), which uses the same parsing algorithm but only considers projective arcs in both training and testing.", "labels": [], "entities": []}, {"text": "The experiments are based on treebank data from five languages: the Danish Dependency Treebank, the Alpino Treebank of Dutch (van der), the TIGER Treebank of German (), the Floresta Sint\u00e1ctica of Portuguese (), and the Slovene Dependency Treebank ().", "labels": [], "entities": [{"text": "Danish Dependency Treebank", "start_pos": 68, "end_pos": 94, "type": "DATASET", "confidence": 0.8508710861206055}, {"text": "TIGER Treebank of German", "start_pos": 140, "end_pos": 164, "type": "DATASET", "confidence": 0.8600570112466812}, {"text": "Slovene Dependency Treebank", "start_pos": 219, "end_pos": 246, "type": "DATASET", "confidence": 0.8842387000719706}]}, {"text": "The data sets used are the training sets from the CoNLL-X Shared Task on multilingual dependency parsing (), with 20% of the data reserved for testing using a pseudo-random split.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 73, "end_pos": 104, "type": "TASK", "confidence": 0.5339324673016866}]}, {"text": "gives an overview of the five data sets, showing the number of tokens and sentences, the presence of different kinds of linguistic annotation, and the amount of non-projectivity.", "labels": [], "entities": []}, {"text": "The features used in the history-based model for all languages include the following core set of 20 features, where i and j are the tokens about to be linked and the context stack is a stack of root nodes kin G (i+1,j\u22121) , added from right to left (i.e., with the top node being closest to i): In the specification of features, we use k and k \u22121 to refer to the two topmost tokens on the context stack, and we use h(\u03b1), l(\u03b1) and r(\u03b1) to refer to the head,", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data sets; Tok = number of tokens (*1000); Sen = number of sentences (*1000); T/S = tokens  per sentence (mean); Lem = lemmatization present; CPoS = number of coarse-grained part-of-speech tags;  PoS = number of (fine-grained) part-of-speech tags; MSF = number of morphosyntactic features (split into  atoms); Dep = number of dependency types; NPT = proportion of non-projective dependencies/tokens (%);  NPS = proportion of non-projective dependency graphs/sentences (%)", "labels": [], "entities": []}, {"text": " Table 2: Parsing accuracy; AS = attachment score; ER = error reduction w.r.t. projective baseline (%)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9808626174926758}, {"text": "AS", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.9972587823867798}, {"text": "attachment score", "start_pos": 33, "end_pos": 49, "type": "METRIC", "confidence": 0.9570763409137726}, {"text": "ER", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9977635145187378}, {"text": "error reduction", "start_pos": 56, "end_pos": 71, "type": "METRIC", "confidence": 0.964352011680603}]}, {"text": " Table 3: Parsing time; PT = parsing time (s); TR = time reduction w.r.t. non-projective baseline (%)", "labels": [], "entities": [{"text": "PT", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9983499050140381}, {"text": "parsing", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9522644281387329}, {"text": "TR", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9986182451248169}]}, {"text": " Table 4: Related work (labeled attachment score)", "labels": [], "entities": [{"text": "attachment score", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.7649787366390228}]}]}