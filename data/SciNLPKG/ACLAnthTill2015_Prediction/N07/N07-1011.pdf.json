{"title": [{"text": "First-Order Probabilistic Models for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.9806682765483856}]}], "abstractContent": [{"text": "Traditional noun phrase coreference resolution systems represent features only of pairs of noun phrases.", "labels": [], "entities": [{"text": "noun phrase coreference resolution", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.7045024707913399}]}, {"text": "In this paper, we propose a machine learning method that enables features over sets of noun phrases, resulting in a first-order proba-bilistic model for coreference.", "labels": [], "entities": []}, {"text": "We outline a set of approximations that make this approach practical, and apply our method to the ACE coreference dataset, achieving a 45% error reduction over a comparable method that only considers features of pairs of noun phrases.", "labels": [], "entities": [{"text": "ACE coreference dataset", "start_pos": 98, "end_pos": 121, "type": "DATASET", "confidence": 0.9473104079564413}, {"text": "error reduction", "start_pos": 139, "end_pos": 154, "type": "METRIC", "confidence": 0.9581958055496216}]}, {"text": "This result demonstrates an example of how a first-order logic representation can be incorporated into a probabilistic model and scaled efficiently.", "labels": [], "entities": []}], "introductionContent": [{"text": "Noun phrase coreference resolution is the problem of clustering noun phrases into anaphoric sets.", "labels": [], "entities": [{"text": "Noun phrase coreference resolution", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7788522243499756}]}, {"text": "A standard machine learning approach is to perform a set of independent binary classifications of the form \"Is mention a coreferent with mention b?\"", "labels": [], "entities": []}, {"text": "This approach of decomposing the problem into pairwise decisions presents at least two related difficulties.", "labels": [], "entities": []}, {"text": "First, it is not clear how best to convert the set of pairwise classifications into a disjoint clustering of noun phrases.", "labels": [], "entities": []}, {"text": "The problem stems from the transitivity constraints of coreference: If a and bare coreferent, and band care coreferent, then a and c must be coreferent.", "labels": [], "entities": [{"text": "coreference", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.9656274914741516}]}, {"text": "This problem has recently been addressed by a number of researchers.", "labels": [], "entities": []}, {"text": "A simple approach is to perform the transitive closure of the pairwise decisions.", "labels": [], "entities": []}, {"text": "However, as shown in recent work), better performance can be obtained by performing relational inference to directly consider the dependence among a set of predictions.", "labels": [], "entities": []}, {"text": "For example, apply a graph partitioning algorithm on a weighted, undirected graph in which vertices are noun phrases and edges are weighted by the pairwise score between noun phrases.", "labels": [], "entities": []}, {"text": "A second and less studied difficulty is that the pairwise decomposition restricts the feature set to evidence about pairs of noun phrases only.", "labels": [], "entities": []}, {"text": "This restriction can be detrimental if there exist features of sets of noun phrases that cannot be captured by a combination of pairwise features.", "labels": [], "entities": []}, {"text": "As a simple example, consider prohibiting coreferent sets that consist only of pronouns.", "labels": [], "entities": []}, {"text": "That is, we would like to require that there beat least one antecedent fora set of pronouns.", "labels": [], "entities": []}, {"text": "The pairwise decomposition does not make it possible to capture this constraint.", "labels": [], "entities": []}, {"text": "In general, we would like to construct arbitrary features over a cluster of noun phrases using the full expressivity of first-order logic.", "labels": [], "entities": []}, {"text": "Enabling this sort of flexible representation within a statistical model has been the subject of along line of research on first-order probabilistic models).", "labels": [], "entities": []}, {"text": "Conceptually, a first-order probabilistic model can be described quite compactly.", "labels": [], "entities": []}, {"text": "A configuration of the world is represented by a set of predi- Figure 1: An example noun coreference graph in which vertices are noun phrases and edge weights are proportional to the probability that the two nouns are coreferent.", "labels": [], "entities": []}, {"text": "Partitioning such a graph into disjoint clusters corresponds to performing coreference resolution on the noun phrases.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.9037432372570038}]}, {"text": "cates, each of which has an associated real-valued parameter.", "labels": [], "entities": []}, {"text": "The likelihood of each configuration of the world is proportional to a combination of these weighted predicates.", "labels": [], "entities": []}, {"text": "In practice, however, enumerating all possible configurations, or even all the predicates of one configuration, can result in intractable combinatorial growth (.", "labels": [], "entities": []}, {"text": "In this paper, we present a practical method to perform training and inference in first-order models of coreference.", "labels": [], "entities": []}, {"text": "We empirically validate our approach on the ACE coreference dataset, showing that the first-order features can lead to an 45% error reduction.", "labels": [], "entities": [{"text": "ACE coreference dataset", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.8729356924692789}, {"text": "error reduction", "start_pos": 126, "end_pos": 141, "type": "METRIC", "confidence": 0.9607291221618652}]}], "datasetContent": [{"text": "We use the B 3 algorithm to evaluate the predicted coreferent clusters.", "labels": [], "entities": []}, {"text": "B 3 is common in coreference evaluation and is similar to the precision and recall of coreferent links, except that systems are rewarded for singleton clusters.", "labels": [], "entities": [{"text": "B 3", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9170534312725067}, {"text": "coreference evaluation", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.944271594285965}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9991568326950073}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9975405931472778}]}, {"text": "For each noun phrase xi , let c i be the number of mentions in xi 's predicted cluster that are in fact coreferent with xi (including xi itself).", "labels": [], "entities": []}, {"text": "Precision for xi is defined as c i divided by the number of noun phrases in xi 's cluster.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.977009654045105}]}, {"text": "Recall for xi is defined as the c i divided by the number of mentions in the gold standard cluster for xi . F 1 is the harmonic mean of recall and precision.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9896838665008545}, {"text": "F 1", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9897028803825378}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9991436004638672}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9989802241325378}]}], "tableCaptions": [{"text": " Table 1: B 3 results for ACE noun phrase corefer- ence. FIRST-ORDER MIRA is our proposed model  that takes advantage of first-order features of the  data and is trained with error-driven and rank-based  methods. We see that both the first-order features  and the training enhancements improve performance  consistently.", "labels": [], "entities": [{"text": "ACE noun phrase corefer- ence", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.5508298128843307}, {"text": "FIRST-ORDER", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9902984499931335}, {"text": "MIRA", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.7171480655670166}]}]}