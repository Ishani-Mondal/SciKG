{"title": [{"text": "Automatic and human scoring of word definition responses", "labels": [], "entities": [{"text": "human scoring of word definition", "start_pos": 14, "end_pos": 46, "type": "TASK", "confidence": 0.6664379417896271}]}], "abstractContent": [{"text": "Assessing learning progress is a critical step in language learning applications and experiments.", "labels": [], "entities": [{"text": "Assessing learning progress", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.870046059290568}]}, {"text": "In word learning, for example , one important type of assessment is a definition production test, in which subjects are asked to produce a short definition of the word being learned.", "labels": [], "entities": [{"text": "word learning", "start_pos": 3, "end_pos": 16, "type": "TASK", "confidence": 0.88019660115242}]}, {"text": "In current practice, each free response is manually scored according to how well its meaning matches the target definition.", "labels": [], "entities": []}, {"text": "Manual scoring is not only time-consuming, but also limited in its flexibility and ability to detect partial learning effects.", "labels": [], "entities": [{"text": "Manual scoring", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6662352085113525}]}, {"text": "This study describes an effective automatic method for scoring free responses to definition production tests.", "labels": [], "entities": []}, {"text": "The algorithm compares the text of the free response to the text of a reference definition using a statistical model of text semantic similarity that uses Markov chains on a graph of individual word relations.", "labels": [], "entities": []}, {"text": "The model can take advantage of both corpus-and knowledge-based resources.", "labels": [], "entities": []}, {"text": "Evaluated on anew corpus of human-judged free responses, our method achieved significant improvements over random and cosine baselines in both rank correlation and label error.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human language technologies are playing an increasingly important role in the science and practice of language learning.", "labels": [], "entities": []}, {"text": "For example, intelligent Computer Assisted Language Learning (CALL) systems are being developed that can automatically tailor lessons and questions to the needs of individual students).", "labels": [], "entities": [{"text": "Computer Assisted Language Learning (CALL)", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.7751059106418065}]}, {"text": "One critical task that language tutors, word learning experiments, and related applications have in common is assessing the learning progress of the student or experiment subject during the course of the session.", "labels": [], "entities": []}, {"text": "When the task is learning new vocabulary, a variety of tests have been developed to measure word learning progress.", "labels": [], "entities": []}, {"text": "Some tests, such as multiplechoice selection of a correct synonym or cloze completion, are relatively passive.", "labels": [], "entities": [{"text": "multiplechoice selection of a correct synonym", "start_pos": 20, "end_pos": 65, "type": "TASK", "confidence": 0.819465234875679}]}, {"text": "In production tests, on the other hand, students are asked to write or say a short phrase or sentence that uses the word being learned, called the target word, in a specified way.", "labels": [], "entities": []}, {"text": "In one important type of production test, called a definition production test, the subject is asked to describe the meaning of the target word, as they understand it at that point in the session.", "labels": [], "entities": []}, {"text": "The use of such tests has typically required a teacher or researcher to manually score each response by judging its similarity in meaning to the reference definition of the target word.", "labels": [], "entities": []}, {"text": "The resulting scores can then be used to analyze how a person's learning of the word responded to different stimuli, such as seeing the word used in context.", "labels": [], "entities": []}, {"text": "A sample target word and its reference definition, along with examples of humanjudged responses, are given in Sections 3.3 and 4.1.", "labels": [], "entities": []}, {"text": "However, manual scoring of the definition responses has several drawbacks.", "labels": [], "entities": []}, {"text": "First, it is timeconsuming and must be done by trained experts.", "labels": [], "entities": [{"text": "timeconsuming", "start_pos": 13, "end_pos": 26, "type": "METRIC", "confidence": 0.9158614873886108}]}, {"text": "Moreover, if the researcher wanted to test anew hy-476 pothesis by examining the responses with respect to a different but related definition, the entire set of responses would have to be manually re-scored against the new target.", "labels": [], "entities": []}, {"text": "Second, manual scoring can often be limited in its ability to detect when partial learning has taken place.", "labels": [], "entities": []}, {"text": "This is due to the basic tradeoff between the sophistication of the graded scoring scale, and the ease and consistency with which human judges can use the scale.", "labels": [], "entities": [{"text": "consistency", "start_pos": 107, "end_pos": 118, "type": "METRIC", "confidence": 0.9588463306427002}]}, {"text": "For example, it maybe that the subject did not learn the complete meaning of a particular target word, but did learn that this target word had negative connotations.", "labels": [], "entities": []}, {"text": "The usual binary or ternary score would provide no or little indication of such effects.", "labels": [], "entities": []}, {"text": "Finally, because manual scoring almost always must be done off-line after the end of the session, it presents an obstacle to our goal of creating learning systems that can adapt quickly, within a single learning session.", "labels": [], "entities": [{"text": "manual scoring", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.6803314089775085}]}, {"text": "This study describes an effective automated method for assessing word learning by scoring free responses to definition production tests.", "labels": [], "entities": [{"text": "assessing word learning", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.6766976118087769}]}, {"text": "The method is flexible: it can be used to analyze a response with respect to whatever reference target(s) the teacher or researcher chooses.", "labels": [], "entities": []}, {"text": "Such a test represents a powerful new tool for language learning research.", "labels": [], "entities": []}, {"text": "It is also a compelling application of human language technologies research on semantic similarity, and we review related work for that area in Section 2.", "labels": [], "entities": [{"text": "semantic similarity", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8406797051429749}]}, {"text": "Our probabilistic model for computing text semantic similarity, described in Section 3, can use both corpus-based and knowledge-based resources.", "labels": [], "entities": [{"text": "computing text semantic similarity", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.76048294454813}]}, {"text": "In Section 4 we describe anew dataset of human definition judgments and use it to measure the effectiveness of the model against other measures of text similarity.", "labels": [], "entities": []}, {"text": "Finally, in Section 5 we discuss further directions and applications of our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first describe our corpus of gold standard human judgments.", "labels": [], "entities": []}, {"text": "We then explain the different text similarity methods and baselines we computed on the corpus responses.", "labels": [], "entities": []}, {"text": "Finally, we give an analysis and discussion of the results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Scale for human definition judgements.", "labels": [], "entities": [{"text": "human definition judgements", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.7403890788555145}]}, {"text": " Table 2: Examples of human scores of responses for  the target word abscond.", "labels": [], "entities": []}, {"text": " Table 3: Weighted kappa inter-rater reliability for  three human coders on our definition response  dataset (664 items).", "labels": [], "entities": []}, {"text": " Table 4: Ability of methods to match human ranking  of responses, as measured by Spearman rank corre- lation (corrected for ties).", "labels": [], "entities": [{"text": "Ability", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.994010865688324}, {"text": "Spearman rank corre- lation", "start_pos": 82, "end_pos": 109, "type": "METRIC", "confidence": 0.935634994506836}]}, {"text": " Table 5: Root mean squared error (RMSE) of la- bel(s) for top-ranked item, and top-three items for  all 77 words in the dataset.", "labels": [], "entities": [{"text": "Root mean squared error (RMSE) of la- bel(s)", "start_pos": 10, "end_pos": 54, "type": "METRIC", "confidence": 0.9462311395577022}]}]}