{"title": [{"text": "Exploiting acoustic and syntactic features for prosody labeling in a maximum entropy framework", "labels": [], "entities": [{"text": "prosody labeling", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.8007171154022217}]}], "abstractContent": [{"text": "In this paper we describe an automatic prosody labeling framework that exploits both language and speech information.", "labels": [], "entities": [{"text": "prosody labeling", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.7603980600833893}]}, {"text": "We model the syntactic-prosodic information with a maximum entropy model that achieves an accuracy of 85.2% and 91.5% for pitch accent and boundary tone labeling on the Boston University Radio News corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9993360638618469}, {"text": "Boston University Radio News corpus", "start_pos": 169, "end_pos": 204, "type": "DATASET", "confidence": 0.9905147552490234}]}, {"text": "We model the acoustic-prosodic stream with two different models , one a maximum entropy model and the other a traditional HMM.", "labels": [], "entities": []}, {"text": "We finally couple the syntactic-prosodic and acoustic-prosodic components to achieve significantly improved pitch accent and boundary tone classification accuracies of 86.0% and 93.1% respectively.", "labels": [], "entities": [{"text": "boundary tone classification accuracies", "start_pos": 125, "end_pos": 164, "type": "METRIC", "confidence": 0.485221229493618}]}, {"text": "Similar experimental results are also reported on Boston Directions corpus.", "labels": [], "entities": [{"text": "Boston Directions corpus", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.9868870774904887}]}], "introductionContent": [{"text": "Prosody refers to intonation, rhythm and lexical stress patterns of spoken language that convey linguistic and paralinguistic information such as emphasis, intent, attitude and emotion of a speaker.", "labels": [], "entities": []}, {"text": "Prosodic information associated with a unit of speech, say, syllable, word, phrase or clause, influence all the segments of the unit in an utterance.", "labels": [], "entities": []}, {"text": "In this sense they are also referred to as suprasegmentals (.", "labels": [], "entities": []}, {"text": "Prosody in general is highly dependent on individual speaker style, gender, dialect and other phonological factors.", "labels": [], "entities": []}, {"text": "The difficulty in reliably characterizing suprasegmental information present in speech has resulted in symbolic and parameteric prosody labeling standards like ToBI (Tones and Break Indices) and Tilt model respectively.", "labels": [], "entities": []}, {"text": "Prosody in spoken language can be characterized through acoustic features or lexical features or both.", "labels": [], "entities": []}, {"text": "Acoustic correlates of duration, intensity and pitch, like syllable nuclei duration, short time energy and fundamental frequency (f0) are some acoustic features that are perceived to confer prosodic prominence or stress in English.", "labels": [], "entities": [{"text": "duration", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9765912294387817}, {"text": "fundamental frequency (f0)", "start_pos": 107, "end_pos": 133, "type": "METRIC", "confidence": 0.9166420698165894}]}, {"text": "Lexical features like partsof-speech, syllable nuclei identity, syllable stress of neighboring words have also demonstrated high degree of discriminatory evidence in prosody detection tasks.", "labels": [], "entities": [{"text": "prosody detection tasks", "start_pos": 166, "end_pos": 189, "type": "TASK", "confidence": 0.8778650959332784}]}, {"text": "The interplay between acoustic and lexical features in characterizing prosodic events has been successfully exploited in text-to-speech synthesis, speech recognition () and speech understanding.", "labels": [], "entities": [{"text": "text-to-speech synthesis", "start_pos": 121, "end_pos": 145, "type": "TASK", "confidence": 0.7251562029123306}, {"text": "speech recognition", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.7709088325500488}, {"text": "speech understanding", "start_pos": 173, "end_pos": 193, "type": "TASK", "confidence": 0.8053519427776337}]}, {"text": "Text-to-speech synthesis relies on lexical features derived predominantly from the input text to synthesize natural sounding speech with appropriate prosody.", "labels": [], "entities": [{"text": "Text-to-speech synthesis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7306639403104782}]}, {"text": "In contrast, output of atypical automatic speech recognition (ASR) system is noisy and hence, the acoustic features are more useful in predicting prosody than the hypothesized lexical transcript which maybe erroneous.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 32, "end_pos": 66, "type": "TASK", "confidence": 0.8241528272628784}, {"text": "predicting prosody", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.8430559933185577}]}, {"text": "Speech understanding systems model both the lexical and acoustic features at the output of an ASR to improve natural language understanding.", "labels": [], "entities": [{"text": "Speech understanding", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7290992438793182}, {"text": "ASR", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.960522472858429}, {"text": "natural language understanding", "start_pos": 109, "end_pos": 139, "type": "TASK", "confidence": 0.7001211047172546}]}, {"text": "Another source of renewed interest has come from spoken language translation ().", "labels": [], "entities": [{"text": "spoken language translation", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.6681333680947622}]}, {"text": "A prerequisite for all these applications is accurate prosody detection, the topic of the present work.", "labels": [], "entities": [{"text": "prosody detection", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.8607355654239655}]}, {"text": "In this paper, we describe our framework for building an automatic prosody labeler for English.", "labels": [], "entities": [{"text": "prosody labeler", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.6809693574905396}]}, {"text": "We report results on the Boston University (BU) Radio Speech Corpus ( and Boston Directions Corpus (BDC)), two publicly available speech corpora with manual ToBI annotations intended for experiments in automatic prosody labeling.", "labels": [], "entities": [{"text": "Boston University (BU) Radio Speech Corpus", "start_pos": 25, "end_pos": 67, "type": "DATASET", "confidence": 0.9421934634447098}, {"text": "Boston Directions Corpus (BDC))", "start_pos": 74, "end_pos": 105, "type": "DATASET", "confidence": 0.9431207875410715}, {"text": "prosody labeling", "start_pos": 212, "end_pos": 228, "type": "TASK", "confidence": 0.6838911771774292}]}, {"text": "We condition prosody not only on word strings and their parts-of-speech but also on richer syntactic information encapsulated in the form of Supertags ().", "labels": [], "entities": []}, {"text": "We propose a maximum entropy modeling framework for the syntactic features.", "labels": [], "entities": []}, {"text": "We model the acoustic-prosodic stream with two different models, a maximum entropy model and a more traditional hidden markov model.", "labels": [], "entities": []}, {"text": "In an automatic prosody labeling task, one is essentially try-ing to predict the correct prosody label sequence fora given utterance and a maximum entropy model offers an elegant solution to this learning problem.", "labels": [], "entities": [{"text": "prosody labeling task", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.8021534085273743}]}, {"text": "The framework is also robust in the selection of discriminative features for the classification problem.", "labels": [], "entities": [{"text": "classification problem", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.926183819770813}]}, {"text": "So, given a word sequence W = {w 1 , \u00b7 \u00b7 \u00b7 , w n } and a set of acoustic-prosodic features A = {o 1 , \u00b7 \u00b7 \u00b7 , o T }, the best prosodic label sequence L * = {l 1 , l 2 , \u00b7 \u00b7 \u00b7 , l n } is obtained as follows, where \u03a6(W ) is the syntactic feature encoding of the word sequence W . The first term in Equation corresponds to the probability obtained through our maximum entropy syntactic model.", "labels": [], "entities": [{"text": "Equation", "start_pos": 296, "end_pos": 304, "type": "METRIC", "confidence": 0.879533052444458}]}, {"text": "The second term in Equation, computed by an HMM corresponds to the probability of the acoustic data stream which is assumed to be dependent only on the prosodic label sequence.", "labels": [], "entities": [{"text": "Equation", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9616057276725769}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we describe related work in automatic prosody labeling followed by a description of the data used in our experiments in section 3.", "labels": [], "entities": [{"text": "prosody labeling", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.6969814151525497}]}, {"text": "We present prosody prediction results from off-the-shelf synthesizers in section 4.", "labels": [], "entities": [{"text": "prosody prediction", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.8434542417526245}]}, {"text": "Section 5 details our proposed maximum entropy syntactic-prosodic model for prosody labeling.", "labels": [], "entities": [{"text": "prosody labeling", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.8064500093460083}]}, {"text": "In section 6, we describe our acoustic-prosodic model and discuss our results in section 7.", "labels": [], "entities": []}, {"text": "We finally conclude in section 8 with directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present three baseline experiments.", "labels": [], "entities": []}, {"text": "One is simply based on chance where the majority class label is predicted.", "labels": [], "entities": []}, {"text": "The second is a baseline only for pitch accents derived from the lexical stress obtained through look-up from a pronunciation lexicon labeled with stress.", "labels": [], "entities": []}, {"text": "Finally, the third and more concrete baseline is obtained through prosody detection in current speech synthesis systems.", "labels": [], "entities": [{"text": "prosody detection", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.6891292929649353}]}], "tableCaptions": [{"text": " Table 1: BU and BDC dataset used in experiments", "labels": [], "entities": [{"text": "BU", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9117830395698547}, {"text": "BDC dataset", "start_pos": 17, "end_pos": 28, "type": "DATASET", "confidence": 0.9275749921798706}]}, {"text": " Table 3: Classification results of pitch accents and boundary tones (in %) using Festival and AT&T NV R", "labels": [], "entities": [{"text": "Festival", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9807865023612976}, {"text": "AT&T NV R", "start_pos": 95, "end_pos": 104, "type": "DATASET", "confidence": 0.9602376222610474}]}, {"text": " Table 4: Classification results (%) of pitch accents and boundary tones for different syntactic representation (k = 3)", "labels": [], "entities": []}, {"text": " Table 5: Accuracy (in %) obtained by leave-one out  speaker validation using IPs as a separate class on  entire speaker set", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985916018486023}]}, {"text": " Table 6: Classification results of pitch accents and boundary tones (in %) with acoustics only and acoustics+syntax", "labels": [], "entities": []}]}