{"title": [{"text": "Coreference or Not: A Twin Model for Coreference Resolution", "labels": [], "entities": []}], "abstractContent": [{"text": "A twin-model is proposed for coreference resolution: a link component, modeling the coref-erential relationship between an anaphor and a candidate antecedent, and a creation component modeling the possibility that a phrase is not coreferential with any candidate antecedent.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.9622286558151245}]}, {"text": "The creation model depends on all candidate antecedents and is often expensive to compute; Therefore constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model.", "labels": [], "entities": []}, {"text": "The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter.", "labels": [], "entities": [{"text": "Automatic Content Extraction (ACE) task", "start_pos": 60, "end_pos": 99, "type": "TASK", "confidence": 0.7237599321774074}]}], "introductionContent": [{"text": "Coreference resolution aims to find multiple mentions of an entity (e.g., PERSON, ORGANIZATION) in a document.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9232770204544067}]}, {"text": "Ina typical machine learning-based coreference resolution system (), a statistical model is learned from training data and is used to measure how likely an anaphor 1 is coreferential to a candidate antecedent.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7654084861278534}]}, {"text": "A related, but often overlooked, problem is that the anaphor maybe noncoreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in a coreference chain.", "labels": [], "entities": []}, {"text": "In (, the problem is treated by thresholding the scores returned by the coreference model.", "labels": [], "entities": []}, {"text": "That is, if the maximum coreference score is below a threshold, then the anaphor is deemed non-referential to any candidate antecedent.", "labels": [], "entities": []}, {"text": "The threshold approach does not model noncoreferential events directly, and is by no means the optimal approach to the problem.", "labels": [], "entities": []}, {"text": "It also introduces a free parameter which has to beset by trial-and-error.", "labels": [], "entities": []}, {"text": "As an improvement, and train a separate model to classify an anaphor as either anaphoric or non-anaphoric.", "labels": [], "entities": []}, {"text": "The output of this classifier can be used either as a pre-filter () so that non-anaphoric anaphors will not be precessed in the coreference system, or as a set of features in the coreference model.", "labels": [], "entities": []}, {"text": "By rejecting any anaphor classified as non-anaphoric in coreference resolution, the filtering approach is meant to handle nonanaphoric phrases (i.e., no antecedent exists in the discourse under consideration), not the first mention in a coreference chain.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.9069112837314606}]}, {"text": "In this paper, coreference is viewed as a process of sequential operations on anaphor mentions: an anaphor can either be linked with its antecedent if the antecedent is available or present.", "labels": [], "entities": [{"text": "coreference", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9784705638885498}]}, {"text": "If the anaphor, on the other hand, is discourse new (relative to the process order), then anew entity is created.", "labels": [], "entities": []}, {"text": "Corresponding to the two types of operations, a twin-model is proposed to resolve coreferential relationships in a document.", "labels": [], "entities": []}, {"text": "The first component is a statistical model measuring how likely an anaphor is coreferential to a candidate antecedent; The second one explicitly models the non-coreferential events.", "labels": [], "entities": []}, {"text": "Both models are trained automatically and are used simultaneously in the coreference system.", "labels": [], "entities": []}, {"text": "The twin-model coreference system is tested on the 2005 ACE (Automatic Content Extraction, see) data and the best performance under both ACE-Value and entity F-measure can be obtained without tuning a free parameter.", "labels": [], "entities": [{"text": "2005 ACE", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.780479907989502}, {"text": "ACE-Value", "start_pos": 137, "end_pos": 146, "type": "DATASET", "confidence": 0.9105266332626343}, {"text": "F-measure", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.6897866725921631}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The twin-model is presented in Section 2.", "labels": [], "entities": []}, {"text": "A maximumentropy implementation and features are then presented in Section 3.", "labels": [], "entities": []}, {"text": "The experimental results on the 2005 ACE data is presented in Section 4.", "labels": [], "entities": [{"text": "2005 ACE data", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.7995028495788574}]}, {"text": "The proposed twinmodel is compared with related work in Section 5 before the paper is concluded.", "labels": [], "entities": [{"text": "Section 5", "start_pos": 56, "end_pos": 65, "type": "DATASET", "confidence": 0.8963991701602936}]}], "datasetContent": [{"text": "We report the experimental results on ACE 2005 data).", "labels": [], "entities": [{"text": "ACE 2005 data", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.9794591466585795}]}, {"text": "The dataset consists of 599 documents from a rich and diversified sources, which include newswire articles, web logs, and Usenet posts, transcription of broadcast news, broadcast conversations and telephone conversations.", "labels": [], "entities": []}, {"text": "We reserve the last 16% documents of each source as the test set and use the rest of the documents as the training set.", "labels": [], "entities": []}, {"text": "Statistics such as the number of documents, words, mentions and entities of this data split is tabulated in  The link and creation model are trained at the same time.", "labels": [], "entities": []}, {"text": "Besides the basic feature categories described in Section 3.2, we also compute composite features by taking conjunctions of the basic features.", "labels": [], "entities": []}, {"text": "Features are selected by their counts with a threshold of 8.", "labels": [], "entities": []}, {"text": "ACE-Value is the official score reported in the ACE task and will be used to report our coreference system's performance.", "labels": [], "entities": []}, {"text": "Its detailed definition can be found in the official evaluation document 3 . Since ACE-Value is a weighted metric measuring a coreference system's relative value, and it is not sensitive to certain type of errors (e.g., false-alarm entities if these entities contain correct mentions), we also report results using unweighted entity F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 333, "end_pos": 342, "type": "METRIC", "confidence": 0.9041965007781982}]}], "tableCaptions": [{"text": " Table 1: Statistics of ACE 2005 data: number of docu- ments, words, mentions and entities in the training and  test set.", "labels": [], "entities": [{"text": "ACE 2005 data", "start_pos": 24, "end_pos": 37, "type": "DATASET", "confidence": 0.945852001508077}]}]}