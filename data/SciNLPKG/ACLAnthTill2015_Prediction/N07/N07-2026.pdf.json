{"title": [{"text": "Look Who is Talking: Soundbite Speaker Name Recognition in Broadcast News Speech", "labels": [], "entities": [{"text": "Soundbite Speaker Name Recognition in Broadcast News Speech", "start_pos": 21, "end_pos": 80, "type": "TASK", "confidence": 0.523906409740448}]}], "abstractContent": [{"text": "Speaker name recognition plays an important role in many spoken language applications, such as rich transcription, information extraction , question answering, and opinion mining.", "labels": [], "entities": [{"text": "Speaker name recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7787339289983114}, {"text": "rich transcription", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7198678106069565}, {"text": "information extraction", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.8245441317558289}, {"text": "question answering", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.9056443572044373}, {"text": "opinion mining", "start_pos": 164, "end_pos": 178, "type": "TASK", "confidence": 0.8504631221294403}]}, {"text": "In this paper, we developed an SVM-based classification framework to determine the speaker names for those included speech segments in broadcast news speech, called sound-bites.", "labels": [], "entities": [{"text": "SVM-based classification", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.8764228224754333}]}, {"text": "We evaluated a variety of features with different feature selection strategies.", "labels": [], "entities": []}, {"text": "Experiments on Mandarin broadcast news speech show that using our proposed approach, the soundbite speaker name recognition (SSNR) accuracy is 68.9% on our blind test set, an absolute 10% improvement compared to a base-line system, which chooses the person name closest to the soundbite.", "labels": [], "entities": [{"text": "soundbite speaker name recognition (SSNR)", "start_pos": 89, "end_pos": 130, "type": "TASK", "confidence": 0.5618322576795306}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.5790571570396423}]}], "introductionContent": [{"text": "Broadcast news (BN) speech often contains speech or interview quotations from specific speakers other than reporters and anchors in a show.", "labels": [], "entities": [{"text": "Broadcast news (BN) speech", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7125931779543558}]}, {"text": "Identifying speaker names for these speech segmentations, called soundbites (), is useful for many speech processing applications, e.g., question answering, opinion mining fora specific person.", "labels": [], "entities": [{"text": "question answering", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.9065021872520447}, {"text": "opinion mining", "start_pos": 157, "end_pos": 171, "type": "TASK", "confidence": 0.7583714723587036}]}, {"text": "This has recently received increasing attention in programs such as the DARPA GALE program, where one query template is about a person's opinion or statement.", "labels": [], "entities": [{"text": "DARPA GALE", "start_pos": 72, "end_pos": 82, "type": "TASK", "confidence": 0.5340064913034439}]}, {"text": "Previous work in this line includes speaker role detection (e.g.,) and speaker diarization (e.g.,.", "labels": [], "entities": [{"text": "speaker role detection", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7723488410313925}, {"text": "speaker diarization", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.8153689503669739}]}, {"text": "In this paper, we formulate the problem of SSNR as a traditional classification task, and proposed an SVM-based identification framework to explore rich linguistic features.", "labels": [], "entities": [{"text": "SSNR", "start_pos": 43, "end_pos": 47, "type": "TASK", "confidence": 0.9767799973487854}, {"text": "SVM-based identification", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.8863295316696167}]}, {"text": "Experiments on Mandarin BN speech have shown that our proposed approach significantly outperforms the baseline system, which chooses the closest name as the speaker fora soundbite.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the TDT4 Mandarin broadcast news data in our experiment.", "labels": [], "entities": [{"text": "TDT4 Mandarin broadcast news data", "start_pos": 11, "end_pos": 44, "type": "DATASET", "confidence": 0.979574453830719}]}, {"text": "The data set consists of about 170 hours (336 shows) of news speech from different sources.", "labels": [], "entities": []}, {"text": "Speaker turns and soundbite segment information were annotated manually in the transcripts.", "labels": [], "entities": []}, {"text": "Our current study only uses the soundbites that have a human-labeled speaker name in the surrounding transcripts.", "labels": [], "entities": []}, {"text": "There are 1292 such soundbites in our corpus.", "labels": [], "entities": []}, {"text": "We put aside 1/10 of the data as the development set, another 1/10 as the test set, and used the rest as our training set.", "labels": [], "entities": []}, {"text": "All the transcripts were automatically tagged with named entities using the NYU tagger).", "labels": [], "entities": [{"text": "NYU tagger", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.940356582403183}]}, {"text": "For the classifier, we used the libSVM toolkit) and the RBF kernel in our experiments.", "labels": [], "entities": [{"text": "RBF kernel", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.855726569890976}]}, {"text": "A reasonable baseline for SSNR is to choose the closest person name before a soundbite as its speaker.", "labels": [], "entities": [{"text": "SSNR", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.9902092218399048}]}, {"text": "We will compare our system performance to this baseline approach.", "labels": [], "entities": []}, {"text": "We used two performance metrics in our experiments.", "labels": [], "entities": []}, {"text": "First is the instance classification accuracy (CA) for the candidate names in the framework of the binary classification task.", "labels": [], "entities": [{"text": "instance classification accuracy (CA)", "start_pos": 13, "end_pos": 50, "type": "METRIC", "confidence": 0.8036491821209589}, {"text": "binary classification task", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.8060874740282694}]}, {"text": "Second, we compute name recognition accuracy (RA) for the soundbites as follows:", "labels": [], "entities": [{"text": "name recognition accuracy (RA)", "start_pos": 19, "end_pos": 49, "type": "METRIC", "confidence": 0.7927374740441641}]}], "tableCaptions": [{"text": " Table 1. Instance classification accuracy (CA) using  different feature sets. C and G are the optimized pa- rameters in the SVM model.", "labels": [], "entities": [{"text": "Instance classification accuracy (CA)", "start_pos": 10, "end_pos": 47, "type": "METRIC", "confidence": 0.8324321210384369}]}, {"text": " Table 2. Top features ordered by F-score values.", "labels": [], "entities": [{"text": "F-score", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9946034550666809}]}, {"text": " Table 3. Results on the dev set using two metrics: in- stance classification accuracy (CA), and soundbite name  recognition accuracy (RA). The oracle RA is 79.1%.", "labels": [], "entities": [{"text": "in- stance classification accuracy (CA)", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.7067208103835583}, {"text": "soundbite name  recognition accuracy (RA)", "start_pos": 97, "end_pos": 138, "type": "METRIC", "confidence": 0.773344908441816}, {"text": "RA", "start_pos": 151, "end_pos": 153, "type": "METRIC", "confidence": 0.7972536683082581}]}]}