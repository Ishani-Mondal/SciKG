{"title": [{"text": "A Fast Method for Parallel Document Identification", "labels": [], "entities": [{"text": "Parallel Document Identification", "start_pos": 18, "end_pos": 50, "type": "TASK", "confidence": 0.9055595795313517}]}], "abstractContent": [{"text": "We present a fast method to identify homogeneous parallel documents.", "labels": [], "entities": []}, {"text": "The method is based on collecting counts of identical low-frequency words between possibly parallel documents.", "labels": [], "entities": []}, {"text": "The candidate with the most shared low-frequency words is selected as the parallel document.", "labels": [], "entities": []}, {"text": "The method achieved 99.96% accuracy when tested on the EUROPARL corpus of parliamentary proceedings, failing only in anomalous cases of truncated or otherwise distorted documents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9995720982551575}, {"text": "EUROPARL corpus of parliamentary proceedings", "start_pos": 55, "end_pos": 99, "type": "DATASET", "confidence": 0.960901391506195}]}, {"text": "While other work has shown similar performance on this type of dataset, our approach presented here is faster and does not require training.", "labels": [], "entities": []}, {"text": "Apart from proposing an efficient method for parallel document identification in a restricted domain, this paper furnishes evidence that parliamentary proceedings maybe inappropriate for testing parallel document identification systems in general.", "labels": [], "entities": [{"text": "parallel document identification", "start_pos": 45, "end_pos": 77, "type": "TASK", "confidence": 0.6618684232234955}, {"text": "parallel document identification", "start_pos": 195, "end_pos": 227, "type": "TASK", "confidence": 0.7212642232577006}]}], "introductionContent": [{"text": "Parallel documents are documents that are mutual translations.", "labels": [], "entities": []}, {"text": "There area number of reasons one might want to either identify parallel documents, or confirm that a pair of documents are in fact parallel.", "labels": [], "entities": []}, {"text": "Most prominently, one could use pairs of automatically detected parallel documents to build parallel corpora.", "labels": [], "entities": []}, {"text": "Parallel corpora have many uses in natural language processing, and their dearth has been identified as a major bottleneck).", "labels": [], "entities": []}, {"text": "They have been employed in word sense disambiguation), automatic construction of bilingual dictionaries), and inducing statistical machine translation models (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.6837356885274252}, {"text": "automatic construction of bilingual dictionaries", "start_pos": 55, "end_pos": 103, "type": "TASK", "confidence": 0.8053669512271882}, {"text": "statistical machine translation", "start_pos": 119, "end_pos": 150, "type": "TASK", "confidence": 0.6233137051264445}]}, {"text": "In addition to building parallel corpora, one can envision other uses for parallel document identification, such as cross-language information retrieval).", "labels": [], "entities": [{"text": "parallel document identification", "start_pos": 74, "end_pos": 106, "type": "TASK", "confidence": 0.7093292872111002}, {"text": "cross-language information retrieval", "start_pos": 116, "end_pos": 152, "type": "TASK", "confidence": 0.6525908211867014}]}, {"text": "Much work on identifying pairs of parallel documents focuses on the use of external features of the documents, rather than content.", "labels": [], "entities": []}, {"text": "describe PTMiner, a cross-language information retrieval system.", "labels": [], "entities": []}, {"text": "They consider a number of factors in determining if a pair of documents are parallel, including document size, date, URL, and language flag.", "labels": [], "entities": []}, {"text": "For example, if a document is available in both French and English, it is common for the French document's URL to contain .f rand the English to contain .en In addition to these measures, they consider website structure.", "labels": [], "entities": []}, {"text": "find parallel documents which they then use to automatically build a bilingual dictionary.", "labels": [], "entities": []}, {"text": "In their system, they first generate a set of candidate pairs based on manual selection, or advanced search engine use.", "labels": [], "entities": []}, {"text": "They then filter the pairs to remove non-parallel pairs.", "labels": [], "entities": []}, {"text": "First, they confirm that one of each pair is in each of the desired languages using tuned lists of stop-words, then they compare the documents based on length in tokens, and HTML markup.", "labels": [], "entities": []}, {"text": "use a similar idea of candidates and filters in their STRAND system.", "labels": [], "entities": [{"text": "STRAND system", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.6669811755418777}]}, {"text": "STRAND filters the documents based on aligning them by length in tokens and location of HTML markup in the documents.", "labels": [], "entities": [{"text": "length", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9614096879959106}]}, {"text": "Apart form the work done on external metrics, Patry and Langlais (2005) investigated a number of content-based metrics.", "labels": [], "entities": []}, {"text": "They consider several docu-ment features, including the numbers, proper names and punctuation contained within, as well as document length, and alignment scores between candidate pairs.", "labels": [], "entities": []}, {"text": "The features are then used to train an Ada-Boost classifier, which makes decisions based on edit-distance and cosine scores.", "labels": [], "entities": []}, {"text": "They experimented with several combinations of features, one of which achieved 100% correctness when tested on 487 out of 488 parallel documents that constitute the English-Spanish portion of the EUROPARL corpus.", "labels": [], "entities": [{"text": "correctness", "start_pos": 84, "end_pos": 95, "type": "METRIC", "confidence": 0.9762790203094482}, {"text": "EUROPARL corpus", "start_pos": 196, "end_pos": 211, "type": "DATASET", "confidence": 0.9608605802059174}]}, {"text": "They conclude that a bag-of-words approach is inferior to one that considers feature order.", "labels": [], "entities": []}, {"text": "In this work, we demonstrate that a much simpler approach can achieve equally good results.", "labels": [], "entities": []}, {"text": "Our method does not depend on hand-coded linguistic knowledge and requires no training data, which maybe unavailable for some language pairs.", "labels": [], "entities": []}, {"text": "In addition, thanks to its simplicity, our method is very fast.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed experiments on two different parliamentary corpora.", "labels": [], "entities": []}, {"text": "The English-French Canadian Hansards from the 36th sitting of the Canadian Parliament () was selected as the development dataset.", "labels": [], "entities": [{"text": "Hansards from the 36th sitting of the Canadian Parliament", "start_pos": 28, "end_pos": 85, "type": "DATASET", "confidence": 0.8803894254896376}]}, {"text": "In testing on the Canadian Hansards, English was used as the Language A, and French as the Language B. Our approach correctly identified all parallel documents.", "labels": [], "entities": [{"text": "Canadian Hansards", "start_pos": 18, "end_pos": 35, "type": "DATASET", "confidence": 0.8631899356842041}]}, {"text": "In order to allow fora direct comparison with the work of Patry and, we adopted the EUROPARL corpus of parliamentary proceedings) as our test dataset.", "labels": [], "entities": [{"text": "EUROPARL corpus of parliamentary proceedings", "start_pos": 84, "end_pos": 128, "type": "DATASET", "confidence": 0.9549046516418457}]}, {"text": "However, rather than focusing on a single language pair, we performed tests on all 110 language pairs involving the following 11 languages: German, English, Greek, Finnish, Swedish, Dutch, French, Danish, Italian, Spanish and Portuguese.", "labels": [], "entities": []}, {"text": "Diacritics were stripped from the documents of all languages.", "labels": [], "entities": [{"text": "Diacritics", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8077459931373596}]}, {"text": "Since Greek utilizes a different script from the rest of the documents.", "labels": [], "entities": []}, {"text": "we used a straightforward context-free mapping to convert every Greek character to its nearest roman equivalent.", "labels": [], "entities": []}, {"text": "Some of the 488 documents available in EU-ROPARL were missing in Finnish, Swedish, Greek and Danish.", "labels": [], "entities": []}, {"text": "In particular, Greek had 392 documents, Danish had 487 documents, and Swedish and Finnish had 433 each.", "labels": [], "entities": []}, {"text": "In such cases, the parallels of those missing documents were excluded from the language A for that test.", "labels": [], "entities": []}, {"text": "The EUROPARL documents range in size from 114 tokens (13 lines) to 138,557 tokens (11,101 lines).", "labels": [], "entities": [{"text": "EUROPARL documents", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9656096398830414}]}, {"text": "The mean number of tokens is 59,387 (2,826 lines).", "labels": [], "entities": [{"text": "mean number", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9239568710327148}]}, {"text": "Each orientation of each language pair was tested.", "labels": [], "entities": []}, {"text": "For example, for the language pair EnglishDutch, tests were run twice -once with English as language A and Dutch as language B, and once the other way around.", "labels": [], "entities": []}, {"text": "The results fora given language pair are not necessarily symmetric.", "labels": [], "entities": []}, {"text": "Henceforth when referring to a language pair, we list the language A as the first one.", "labels": [], "entities": []}, {"text": "For each document and each language pair, an individual test was run.", "labels": [], "entities": []}, {"text": "An individual test consisted of finding, fora given document in language A, its parallel in the language B set.", "labels": [], "entities": []}, {"text": "Since we did not take advantage of the pigeon-hole constraint, the individual tests were independent from each other.", "labels": [], "entities": []}, {"text": "No changes were made to the approach once testing on the EUROPARL corpus began, in order to avoid adapting it to work on any particular data set.", "labels": [], "entities": [{"text": "EUROPARL corpus", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9722340703010559}]}], "tableCaptions": []}