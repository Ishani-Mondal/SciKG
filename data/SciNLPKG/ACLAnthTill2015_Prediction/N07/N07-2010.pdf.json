{"title": [{"text": "Situated Models of Meaning for Sports Video Retrieval", "labels": [], "entities": [{"text": "Sports Video Retrieval", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.6103855073451996}]}], "abstractContent": [{"text": "Situated models of meaning ground words in the non-linguistic context, or situation, to which they refer.", "labels": [], "entities": []}, {"text": "Applying such models to sports video retrieval requires learning appropriate representations for complex events.", "labels": [], "entities": [{"text": "sports video retrieval", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.6860837737719218}]}, {"text": "We propose a method that uses data mining to discover temporal patterns in video, and pair these patterns with associated closed captioning text.", "labels": [], "entities": []}, {"text": "This paired corpus is used to train a situated model of meaning that significantly improves video retrieval performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent advances in digital broadcasting and recording allow fans access to an unprecedented amount of sports video.", "labels": [], "entities": []}, {"text": "The growing need to manage and search large video collections presents a challenge to traditional information retrieval (IR) technologies.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.8114313960075379}]}, {"text": "Such methods cannot be directly applied to video data, even when closed caption transcripts are available; for, unlike text documents, the occurrence of a query term in a video is often not enough to assume the video's relevance to that query.", "labels": [], "entities": []}, {"text": "For example, when searching through video of baseball games, returning all clips in which the phrase \"home run\" occurs, results primarily in video of events where a home run does not actually occur.", "labels": [], "entities": []}, {"text": "This follows from the fact that in sports, as in life, people often talk not about what is currently happening, but rather, they talk about what did, might, or will happen in the future.", "labels": [], "entities": []}, {"text": "Traditional IR techniques cannot address such problems because they model the meaning of a query term strictly by that term's relationship to other terms.", "labels": [], "entities": [{"text": "IR", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.9758338332176208}]}, {"text": "To build systems that successfully search video, IR techniques should be extended to exploit not just linguistic information but also elements of the non-linguistic context, or situation, that surrounds language use.", "labels": [], "entities": [{"text": "IR", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.9884507656097412}]}, {"text": "This paper presents a method for video event retrieval from broadcast sports that achieves this by learning a situated model of meaning from an unlabeled video corpus.", "labels": [], "entities": [{"text": "video event retrieval", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.6867784857749939}]}, {"text": "The framework for the current model is derived from previous work on computational models of verb learning.", "labels": [], "entities": []}, {"text": "In this earlier work, meaning is defined by a probabilistic mapping between words and representations of the non-linguistic events to which those words refer.", "labels": [], "entities": []}, {"text": "In applying this framework to events in video, we follow recent work on video surveillance in which complex events are represented as temporal relations between lower level sub-events).", "labels": [], "entities": []}, {"text": "While in the surveillance domain, hand crafted event representations have been used successfully, the greater variability of content in broadcast sports demands an automatic method for designing event representations.", "labels": [], "entities": []}, {"text": "The primary focus of this paper is to present a method for mining such representations from large video corpora, and to describe how these representations can be mapped to natural language.", "labels": [], "entities": []}, {"text": "We focus on a pilot dataset of broadcast baseball games.", "labels": [], "entities": []}, {"text": "Pilot video retrieval tests show that using a situated model significantly improves performances over traditional language modeling methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "Work on video IR in the news domain often focuses on indexing video data using a set of image classifiers that categorize shots into pre-determined concepts (e.g. flag, outdoors, George Bush, etc.).", "labels": [], "entities": [{"text": "video IR", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.7170494198799133}]}, {"text": "Text queries must then be translated (sometimes manually) in terms of these concepts).", "labels": [], "entities": []}, {"text": "Our work focuses on a more automated approach that is closer to traditional IR techniques.", "labels": [], "entities": [{"text": "IR", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.972770094871521}]}, {"text": "Our framework extends the language modeling approach of by incorporating a situated model of meaning.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7344720661640167}]}, {"text": "In, documents relevant to a query are ranked based on the probability that each document generated each query term.", "labels": [], "entities": []}, {"text": "We follow this approach for video events, making the assumption that the relevance of an event to a query depends both on the words associated with the event (i.e. what was said while the event occurred), as well as the situational context modeled by the video event representations: The p(word|caption) is estimated using the language modeling technique described in.", "labels": [], "entities": []}, {"text": "The p(word|video) is estimated as in equation 1 above.", "labels": [], "entities": []}, {"text": "\u03b1 is used to weight the models.", "labels": [], "entities": []}], "tableCaptions": []}