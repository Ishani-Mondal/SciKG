{"title": [{"text": "Tagging Icelandic text using a linguistic and a statistical tagger", "labels": [], "entities": [{"text": "Tagging Icelandic text", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8977716366449991}]}], "abstractContent": [{"text": "We describe our linguistic rule-based tag-ger IceTagger, and compare its tagging accuracy to the TnT tagger, a state-of-the-art statistical tagger, when tagging Ice-landic, a morphologically complex language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9871329069137573}]}, {"text": "Evaluation shows that the average tagging accuracy is 91.54% and 90.44%, obtained by IceTagger and TnT, respectively.", "labels": [], "entities": [{"text": "tagging", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.9512024521827698}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9789413213729858}, {"text": "IceTagger", "start_pos": 85, "end_pos": 94, "type": "DATASET", "confidence": 0.9390690326690674}]}, {"text": "When tag profile gaps in the lexicon , used by the TnT tagger, are filled with tags produced by our morphological analyser IceMorphy, TnT's tagging accuracy increases to 91.18%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9938271641731262}]}], "introductionContent": [{"text": "In this paper, we use a linguistic rule-based method (LRBM) and a data-driven method (DDM) for tagging text in the morphologically complex Icelandic language.", "labels": [], "entities": [{"text": "tagging text in the morphologically complex Icelandic language", "start_pos": 95, "end_pos": 157, "type": "TASK", "confidence": 0.6775255091488361}]}, {"text": "We present a novel LRBM.", "labels": [], "entities": [{"text": "LRBM", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.7433727979660034}]}, {"text": "The tagger based on this method, hereafter called IceTagger, uses about 175 local rules for initial disambiguation, and a set of heuristics, to force feature agreement where appropriate, for further disambiguation.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 50, "end_pos": 59, "type": "DATASET", "confidence": 0.9323062300682068}]}, {"text": "The average tagging accuracy of IceTagger is 91.54%, compared to 90.44% achieved by the TnT tagger, a state-of-the-art statistical tagger).", "labels": [], "entities": [{"text": "tagging", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.946962833404541}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9779648780822754}, {"text": "IceTagger", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.9338977932929993}]}, {"text": "IceTagger makes 11.5% less errors than TnT.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9534628391265869}, {"text": "errors", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9934612512588501}]}, {"text": "On the other hand, when tag profile gaps in the lexicon, used by TnT, are filled with tags produced by * The author is also affiliated with the Dept. of Computer Science, University of Sheffield, Sheffield, S1 4DP, UK.", "labels": [], "entities": []}, {"text": "IceMorphy, our morphological analyser, TnT's tagging accuracy increases to 91.18%.", "labels": [], "entities": [{"text": "IceMorphy", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9533708095550537}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.97773277759552}]}, {"text": "In that case, IceTagger makes 4.1% less errors than TnT.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 14, "end_pos": 23, "type": "DATASET", "confidence": 0.8913673162460327}, {"text": "errors", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9930243492126465}]}, {"text": "The remainder of this paper is organised as follows: In Sect.", "labels": [], "entities": [{"text": "In Sect", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.8455748558044434}]}, {"text": "2, we describe the different tagging methods in more detail.", "labels": [], "entities": [{"text": "tagging", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9623695611953735}]}, {"text": "3 briefly describes the Icelandic language and the tagset.", "labels": [], "entities": []}, {"text": "The components of IceTagger are described in Sect.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 18, "end_pos": 27, "type": "DATASET", "confidence": 0.9695489406585693}]}, {"text": "4, and evaluation results are presented in Sect.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, we used the pairs often training and test corpora of the IFD corpus, produced by.", "labels": [], "entities": [{"text": "IFD corpus", "start_pos": 73, "end_pos": 83, "type": "DATASET", "confidence": 0.8527863323688507}]}, {"text": "We used the first nine of these test corpora for evaluation, but the tenth one was set aside and used as the development corpus for IceTagger.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 132, "end_pos": 141, "type": "DATASET", "confidence": 0.9552481174468994}]}, {"text": "For each test corpus (10% of the IFD) the corresponding training corpus (90% of the IFD) was used to deduce the lexicon(s) used by TnT, IceTagger and IceMorphy.", "labels": [], "entities": [{"text": "IFD", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.7393243908882141}, {"text": "IceTagger", "start_pos": 136, "end_pos": 145, "type": "DATASET", "confidence": 0.8999601602554321}, {"text": "IceMorphy", "start_pos": 150, "end_pos": 159, "type": "DATASET", "confidence": 0.9339761734008789}]}, {"text": "When testing the two taggers, we thus made sure that the ratio of unknown words was (almost) the same.", "labels": [], "entities": []}, {"text": "The accuracy of abase tagger, which assigns each known word its most frequent tag, and the most frequent noun tag/proper noun tag to lower case/upper case unknown words, is 76.27% (see).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9998074173927307}]}, {"text": "The average tagging accuracy of IceTagger for all words is 91.54%, compared to 90.44% for TnT (see).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9692766666412354}]}, {"text": "IceTagger makes 11.5% less errors than TnT 1 . In order to improve the tagging accuracy of TnT, we used the tag profile gap filling mechanism of Ice-  Morphy in the following manner.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9411715865135193}, {"text": "errors", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9734804034233093}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9059844613075256}, {"text": "tag profile gap filling", "start_pos": 108, "end_pos": 131, "type": "TASK", "confidence": 0.570583388209343}]}, {"text": "Each record in the lexicon used by TnT consists of a word and the corresponding tags found in the training corpus.", "labels": [], "entities": []}, {"text": "Additionally, to facilitate lexical probability calculations, each tag is marked by its frequency (i.e. how often the tag appeared as a label for the given word).", "labels": [], "entities": []}, {"text": "We made IceMorphy generate a \"filled\" lexicon such that each generated missing tag was marked with the frequency 1 2 . We call the resulting tagger TnT*.", "labels": [], "entities": []}, {"text": "Indeed, when testing TnT*, we obtained an overall average tagging accuracy of 91.18%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9597392678260803}]}, {"text": "IceTagger makes 4.1% less errors than TnT*.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9545473456382751}, {"text": "errors", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9940154552459717}]}, {"text": "The development of IceTagger/IceMorphy took 7 man-months, but it has been worth the effort.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 19, "end_pos": 28, "type": "DATASET", "confidence": 0.9009592533111572}, {"text": "IceMorphy", "start_pos": 29, "end_pos": 38, "type": "DATASET", "confidence": 0.5138928294181824}]}, {"text": "First, IceTagger does make fewer errors than TnT, and its accuracy can probably be increased by improving its individual components.", "labels": [], "entities": [{"text": "IceTagger", "start_pos": 7, "end_pos": 16, "type": "DATASET", "confidence": 0.9237361550331116}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9993257522583008}]}, {"text": "Secondly, we have used IceTagger in various tagger combination methods to further increase the tagging accuracy of Icelandic text).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9081422686576843}]}], "tableCaptions": [{"text": " Table 2: Average tagging accuracy of the various  taggers.", "labels": [], "entities": [{"text": "tagging", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.8777593970298767}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9750847220420837}]}]}