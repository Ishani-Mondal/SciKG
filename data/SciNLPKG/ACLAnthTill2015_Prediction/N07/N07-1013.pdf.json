{"title": [{"text": "Improving Diversity in Ranking using Absorbing Random Walks", "labels": [], "entities": [{"text": "Improving Diversity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9825969338417053}]}], "abstractContent": [{"text": "We introduce a novel ranking algorithm called GRASSHOPPER, which ranks items with an emphasis on diversity.", "labels": [], "entities": [{"text": "GRASSHOPPER", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.9922158122062683}]}, {"text": "That is, the top items should be different from each other in order to have abroad coverage of the whole item set.", "labels": [], "entities": []}, {"text": "Many natural language processing tasks can benefit from such diversity ranking.", "labels": [], "entities": []}, {"text": "Our algorithm is based on random walks in an absorbing Markov chain.", "labels": [], "entities": []}, {"text": "We turn ranked items into absorbing states, which effectively prevents redundant items from receiving a high rank.", "labels": [], "entities": []}, {"text": "We demonstrate GRASSHOP-PER's effectiveness on extractive text sum-marization: our algorithm ranks between the 1st and 2nd systems on DUC 2004 Task 2; and on asocial network analysis task that identifies movie stars of the world.", "labels": [], "entities": [{"text": "GRASSHOP-PER", "start_pos": 15, "end_pos": 27, "type": "METRIC", "confidence": 0.9760929346084595}, {"text": "DUC 2004 Task 2", "start_pos": 134, "end_pos": 149, "type": "DATASET", "confidence": 0.9287038147449493}]}], "introductionContent": [{"text": "Many natural language processing tasks involve ranking a set of items.", "labels": [], "entities": []}, {"text": "Sometimes we want the top items to be not only good individually but also diverse collectively.", "labels": [], "entities": []}, {"text": "For example, extractive text summarization generates a summary by selecting a few good sentences from one or more articles on the same topic ().", "labels": [], "entities": [{"text": "extractive text summarization", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.7143144210179647}]}, {"text": "This can be formulated as ranking all the sentences, and taking the top ones.", "labels": [], "entities": []}, {"text": "A good sentence is one that is representative, i.e., similar to many other sentences, so that it likely conveys the central meaning of the articles.", "labels": [], "entities": []}, {"text": "On the other hand, we do not want multiple nearidentical sentences.", "labels": [], "entities": []}, {"text": "The top sentences should be diverse.", "labels": [], "entities": []}, {"text": "As another example, in information retrieval on news events, an article is often published by multiple newspapers with only minor changes.", "labels": [], "entities": [{"text": "information retrieval on news events", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.8190541684627533}]}, {"text": "It is undesirable to rank all copies of the same article highly, even though it maybe the most relevant.", "labels": [], "entities": []}, {"text": "Instead, the top results should be different and complementary.", "labels": [], "entities": []}, {"text": "In other words, one wants 'subtopic diversity' in retrieval results (.", "labels": [], "entities": []}, {"text": "The need for diversity in ranking is not unique to natural language processing.", "labels": [], "entities": []}, {"text": "In social network analysis, people are connected by their interactions, e.g., phone calls.", "labels": [], "entities": [{"text": "social network analysis", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.7198517322540283}]}, {"text": "Active groups of people have strong interactions among them, but many groups may exist with fewer interactions.", "labels": [], "entities": []}, {"text": "If we want a list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups.", "labels": [], "entities": []}, {"text": "Given the importance of diversity in ranking, there has been significant research in this area.", "labels": [], "entities": []}, {"text": "Perhaps the most well-known method is maximum marginal relevance (MMR)), as well as cross-sentence informational subsumption), mixture models (), subtopic diversity (, diversity penalty (), and others.", "labels": [], "entities": []}, {"text": "The basic idea is to penalize redundancy by lowering an item's rank if it is similar to items already ranked.", "labels": [], "entities": [{"text": "penalize redundancy", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8826342225074768}]}, {"text": "However, these methods often treat centrality ranking and diversity ranking separately, sometimes with heuristic procedures.", "labels": [], "entities": []}, {"text": "We propose GRASSHOPPER (Graph Random-walk with Absorbing StateS that HOPs among PEaks for Ranking), a novel ranking algorithm that encourages diversity.", "labels": [], "entities": [{"text": "GRASSHOPPER", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.9948263764381409}]}, {"text": "GRASSHOPPER is an alternative to MMR and variants, with a principled mathematical model and strong empirical performance.", "labels": [], "entities": [{"text": "GRASSHOPPER", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9507054090499878}, {"text": "MMR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9489156603813171}]}, {"text": "It ranks a set of items such that: 1.", "labels": [], "entities": []}, {"text": "A highly ranked item is representative of a local group in the set, i.e., it is similar to many other items (centrality); 2.", "labels": [], "entities": []}, {"text": "The top items cover as many distinct groups as possible (diversity); 3.", "labels": [], "entities": []}, {"text": "It incorporates an arbitrary pre-specified ranking as prior knowledge (prior).", "labels": [], "entities": []}, {"text": "Importantly GRASSHOPPER achieves these in a unified framework of absorbing Markov chain random walks.", "labels": [], "entities": [{"text": "GRASSHOPPER", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.8438422679901123}]}, {"text": "The key idea is the following: We define a random walk on a graph over the items.", "labels": [], "entities": []}, {"text": "Items which have been ranked so far become absorbing states.", "labels": [], "entities": []}, {"text": "These absorbing states 'drag down' the importance of similar unranked states, thus encouraging diversity.", "labels": [], "entities": []}, {"text": "Our model naturally balances centrality, diversity, and prior.", "labels": [], "entities": []}, {"text": "We discuss the algorithm in Section 2.", "labels": [], "entities": []}, {"text": "We present GRASSHOPPER's empirical results on text summarization and social network analysis in Section 3.", "labels": [], "entities": [{"text": "GRASSHOPPER", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.6763951778411865}, {"text": "text summarization", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7918880879878998}, {"text": "social network analysis", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.6685499350229899}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Text summarization results on DUC 2004 datasets. GRASSHOPPER was configured using parameters  tuned on the DUC 2003 Task 2 dataset. The rightmost column lists what our rank would have been if we  had participated in the DUC 2004 evaluation.", "labels": [], "entities": [{"text": "DUC 2004 datasets", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.934897800286611}, {"text": "GRASSHOPPER", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9923296570777893}, {"text": "DUC 2003 Task 2 dataset", "start_pos": 117, "end_pos": 140, "type": "DATASET", "confidence": 0.9391669511795044}, {"text": "DUC 2004 evaluation", "start_pos": 230, "end_pos": 249, "type": "DATASET", "confidence": 0.8471593658129374}]}]}