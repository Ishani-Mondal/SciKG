{"title": [{"text": "Building and Refining Rhetorical-Semantic Relation Models", "labels": [], "entities": [{"text": "Refining Rhetorical-Semantic Relation", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.8192124565442404}]}], "abstractContent": [{"text": "We report results of experiments which build and refine models of rhetorical-semantic relations such as Cause and Contrast.", "labels": [], "entities": []}, {"text": "We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.7542971670627594}, {"text": "syntactic parsing", "start_pos": 235, "end_pos": 252, "type": "TASK", "confidence": 0.7155913263559341}]}, {"text": "Using human-annotated and automatically-extracted test sets, we find that each of these techniques results in improved relation classification accuracy.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.8721992373466492}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9173963665962219}]}], "introductionContent": [{"text": "Relations such as Cause and Contrast, which we call rhetorical-semantic relations (RSRs), maybe signaled in text by cue phrases like because or however which join clauses or sentences and explicitly express the relation of constituents which they connect (Example 1).", "labels": [], "entities": [{"text": "rhetorical-semantic relations (RSRs)", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.7248852372169494}]}, {"text": "In other cases the relation maybe implicitly expressed (2).", "labels": [], "entities": []}, {"text": "1 Example 1 Because of the recent accounting scandals, there have been a spate of executive resignations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the impact of our syntactic heuristics on classification over the Auto and PDTB test sets using the same instance set of 400,000 training instances per relation.", "labels": [], "entities": [{"text": "PDTB test sets", "start_pos": 87, "end_pos": 101, "type": "DATASET", "confidence": 0.8846863905588785}]}, {"text": "However, each applies different filters to the instances I before computing the frequencies F (all other parameters use the same values; these are set slightly differently than the optimized values discussed earlier because of the smaller training sets).", "labels": [], "entities": []}, {"text": "In addition to an Unfiltered baseline, we evaluate Filtered models obtained with our syntactic heuristics for Cause and Contrast.", "labels": [], "entities": []}, {"text": "To provide an additional point of comparison, we also evaluate the Part-of-Speech based filtering heuristic described by Marcu and Echihabi, which retains only nouns and verbs.", "labels": [], "entities": []}, {"text": "Unlike the other filters, the POS-based filtering is applied to the NoRel instances as well as the Cause and Contrast instances.", "labels": [], "entities": [{"text": "NoRel instances", "start_pos": 68, "end_pos": 83, "type": "DATASET", "confidence": 0.9149673581123352}]}, {"text": "summarizes the results of the classifying the PDTB and Auto test sets with these different models.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.9061521291732788}, {"text": "Auto test sets", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.8583993315696716}]}, {"text": "Before we examine the results, we note that the syntactic heuristic cuts a large portion of training data out.", "labels": [], "entities": []}, {"text": "In terms of the total sum of frequencies in F cause , i.e. the word pairs extracted from all cause instances, the syntactic filtering cuts out nearly half.", "labels": [], "entities": []}, {"text": "With this in mind, we see that while the syntactic filtering achieves slightly lower mean accuracy as compared to the Unfiltered baseline on the Auto test set, the pairs it does keep appear to be used more efficiently (the differences are significant).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.8752726912498474}, {"text": "Auto test set", "start_pos": 145, "end_pos": 158, "type": "DATASET", "confidence": 0.8735341628392538}]}, {"text": "Even with this reduced training set, the syntactic heuristic improves performance in two out of three cases on the PDTB test set, including a 2.7 percent improvement for the Cause vs NoRel classifier.", "labels": [], "entities": [{"text": "PDTB test set", "start_pos": 115, "end_pos": 128, "type": "DATASET", "confidence": 0.9687366286913554}]}, {"text": "However, due to the small size of the PDTB test set, none of these differences is statistically significant.", "labels": [], "entities": [{"text": "PDTB test set", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.928226888179779}]}, {"text": "We posit that bias in the Auto set may cause this difference in performance across training sets; spans in the Auto set are not true arguments of the relation in the PDTB sense, but nonetheless occur regularly with the cue phrases used in instance mining and thus are more likely to be present in the test set.", "labels": [], "entities": [{"text": "instance mining", "start_pos": 239, "end_pos": 254, "type": "TASK", "confidence": 0.7115950435400009}]}, {"text": "Lastly, we observe that the POS-based filtering described by M&E performs uniformly poorly.", "labels": [], "entities": [{"text": "POS-based filtering", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7787216603755951}]}, {"text": "We have no explanation for this at present, given that M&E's results with this filter appear promising.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: RSR types, sample extraction patterns, number of training instances used in TextRels, and number  of training instances used by M&E. BOS and EOS are sentence beginning/end markers.", "labels": [], "entities": [{"text": "BOS", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9579429626464844}]}, {"text": " Table 2: Classifier accuracy across PDTB, Auto  and Auto-S test sets for the parameter-optimized  classifier (\"Opt\") and the same classifier trained on  segment-constrained instances (\"Seg\"). Accuracy  from M&E is reported for reference, but we note that  they use a different test set so the comparison is not  exact. Baseline in all cases is 50%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9580808281898499}, {"text": "Accuracy", "start_pos": 193, "end_pos": 201, "type": "METRIC", "confidence": 0.9881798028945923}, {"text": "Baseline", "start_pos": 320, "end_pos": 328, "type": "METRIC", "confidence": 0.9993594288825989}]}, {"text": " Table 3: Precision/Recall/F-measure of syntactic  heuristics under various data sets and settings as de- scribed in Section 7.2.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9924314022064209}, {"text": "Recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.7373849749565125}, {"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.8631507158279419}]}, {"text": " Table 4: Classifier accuracy for the Unfiltered (U),  Syntactically Filtered (Syn), and POS (P) models  described in Section 7.3, over PDTB and Auto test  sets. Baseline in all cases is 50%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9848441481590271}, {"text": "PDTB", "start_pos": 136, "end_pos": 140, "type": "DATASET", "confidence": 0.8795658946037292}, {"text": "Baseline", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9993686079978943}]}]}