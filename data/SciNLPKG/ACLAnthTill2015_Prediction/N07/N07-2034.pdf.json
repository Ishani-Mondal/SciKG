{"title": [{"text": "An integrated architecture for speech-input multi-target machine translation", "labels": [], "entities": []}], "abstractContent": [{"text": "The aim of this work is to show the ability of finite-state transducers to simultaneously translate speech into multiple languages.", "labels": [], "entities": []}, {"text": "Our proposal deals with an extension of stochastic finite-state transducers that can produce more than one output at the same time.", "labels": [], "entities": []}, {"text": "These kind of devices offer great versatility for the integration with other finite-state devices such as acoustic models in order to produce a speech translation system.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7177469879388809}]}, {"text": "This proposal has been evaluated in a practical situation, and its results have been compared with those obtained using a standard mono-target speech transducer.", "labels": [], "entities": []}], "introductionContent": [{"text": "Finite-state models constitute an important framework both in syntactic pattern recognition and in language processing.", "labels": [], "entities": [{"text": "syntactic pattern recognition", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.7047729889551798}]}, {"text": "Specifically, stochastic finitestate transducers (SFSTs) have proved to be useful for machine translation tasks within restricted domains; they usually offer high speed during the decoding step and they provide competitive results in terms of error rates ().", "labels": [], "entities": [{"text": "stochastic finitestate transducers (SFSTs", "start_pos": 14, "end_pos": 55, "type": "TASK", "confidence": 0.647318285703659}, {"text": "machine translation tasks", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.8285257617632548}]}, {"text": "Moreover, SFSTs have proved to be versatile models, which can be easily integrated with other finite-state models).", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.9419516921043396}]}, {"text": "The article ( ) explored an automatic method to learn an SFST from a bilingual set of samples for machine translation purposes, the so-called GIATI (Grammar Inference and Alignments for Transducers Inference).", "labels": [], "entities": [{"text": "SFST from a bilingual set of samples for machine translation", "start_pos": 57, "end_pos": 117, "type": "TASK", "confidence": 0.7207987546920777}, {"text": "Grammar Inference and Alignments for Transducers Inference)", "start_pos": 149, "end_pos": 208, "type": "TASK", "confidence": 0.665874570608139}]}, {"text": "It described how to learn both the structural and the probabilistic components of an SFST making use of underlying alignment models.", "labels": [], "entities": [{"text": "SFST", "start_pos": 85, "end_pos": 89, "type": "TASK", "confidence": 0.9057560563087463}]}, {"text": "A multi-target SFST is a generalization of standard SFSTs, in such away that every input string in the source language results in a tuple of output strings each being associated to a different target language.", "labels": [], "entities": [{"text": "SFST", "start_pos": 15, "end_pos": 19, "type": "TASK", "confidence": 0.8967492580413818}, {"text": "SFSTs", "start_pos": 52, "end_pos": 57, "type": "TASK", "confidence": 0.9039797782897949}]}, {"text": "An extension of GIATI that allowed to infer a multi-target SFST from a multilingual corpus was proposed in ().", "labels": [], "entities": []}, {"text": "A syntactic variant of this method (denoted as GI-AMTI) has been used in this work in order to infer the models from training samples as it is summarized in section 3.", "labels": [], "entities": [{"text": "GI-AMTI", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.8617496490478516}]}, {"text": "On the other hand, speech translation has been already carried out by integrating acoustic models into a SFST ).", "labels": [], "entities": [{"text": "speech translation", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7829762399196625}, {"text": "SFST", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.6722918152809143}]}, {"text": "Our main goal in this work is to extend and assess these methodologies to accomplish spoken language multi-target translation.", "labels": [], "entities": [{"text": "spoken language multi-target translation", "start_pos": 85, "end_pos": 125, "type": "TASK", "confidence": 0.5979827120900154}]}, {"text": "Section 2 deals with this proposal by presenting anew integrated architecture for speechinput multi-target translation.", "labels": [], "entities": [{"text": "speechinput multi-target translation", "start_pos": 82, "end_pos": 118, "type": "TASK", "confidence": 0.6675553719202677}]}, {"text": "Under this approach spoken language can be simultaneously decoded and translated into m languages using a unique network.", "labels": [], "entities": []}, {"text": "In section 4, the performance of the system has been experimentally evaluated over a trilingual task which aims to translate TV weather forecast into two languages at the same time.", "labels": [], "entities": []}, {"text": "tion system in a serial architecture with m decoupled text-to-text translators.", "labels": [], "entities": []}, {"text": "Thus, the whole process involves m + 1 searching stages, a first one for the speech signal transcription into the source language text string, and further m for the source language translation into them target languages.", "labels": [], "entities": []}, {"text": "If we replaced them translators by the multi-target SFST, the problem would be reduced to 2 searching stages.", "labels": [], "entities": [{"text": "SFST", "start_pos": 52, "end_pos": 56, "type": "TASK", "confidence": 0.46428513526916504}]}, {"text": "Nevertheless, in this paper we propose a natural way for acoustic models to be integrated in the same network.", "labels": [], "entities": []}, {"text": "As a result, the input speech-signal can be simultaneously decoded and translated into m target languages just in a single searching stage.", "labels": [], "entities": []}, {"text": "Given the acoustic representation (x) of a speech signal, the goal of multi-target speech translation is to find the most likely m target strings (t m ); that is, one string (t i ) per target language involved (i \u2208 {1, . .", "labels": [], "entities": [{"text": "multi-target speech translation", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.6880106528600057}]}, {"text": "This approach is summarized in eq., where the hidden variable scan be interpreted as the transcription of the speech signal: (1) Making use of Bayes' rule, the former expression turns into: Empirically, there is no loss of generality if we assume that the acoustic signal representation depends only on the source string: i.e., that P (x|t m , s) is independent oft m . In this sense, eq. can be rewritten as: Equation combines a standard acoustic model, P (x|s), and a multi-target translation model, P (t m , s), both of whom can be integrated on the fly during the searching routine.", "labels": [], "entities": []}, {"text": "Nevertheless, the outer maximization is computationally very expensive to search for the optimal tuple of target strings t min an effective way.", "labels": [], "entities": []}, {"text": "Thus we make use of the so called Viterbi approximation, which finds the best path.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental setup was as follows: the multitarget SFST was learned from the training set in Table 1 using the GIAMTI algorithm described in section 1; then, the speech test was translated, and the output provided by the system in each language was compared to the corresponding reference sentence.", "labels": [], "entities": [{"text": "SFST", "start_pos": 55, "end_pos": 59, "type": "TASK", "confidence": 0.8178070783615112}]}, {"text": "Additionally, two mono-target SFST were inferred from the same training set with their outputs for the aforementioned test to betaken as baseline.", "labels": [], "entities": [{"text": "SFST", "start_pos": 30, "end_pos": 34, "type": "TASK", "confidence": 0.8348316550254822}]}], "tableCaptions": [{"text": " Table 1: Main features of the METEUS corpus.", "labels": [], "entities": [{"text": "METEUS corpus", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9218353033065796}]}, {"text": " Table 2: Features of multi-target model and the two  decoupled mono-target models (one for Spanish to  Basque translation, referred to as S2B, and the sec- ond for Spanish to English, S2E).", "labels": [], "entities": []}, {"text": " Table 3: Time needed to translate the speech-test  into two languages.", "labels": [], "entities": []}, {"text": " Table 4: Speech-input translation results for Spanish  into Basque (S2B) and Spanish into English (S2E)  using a multi-target SFST or two mono-target SF- STs.", "labels": [], "entities": [{"text": "Speech-input translation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.5355596840381622}]}]}