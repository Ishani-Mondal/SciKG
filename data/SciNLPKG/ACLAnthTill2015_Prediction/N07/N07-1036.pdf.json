{"title": [{"text": "An Exploration of Eye Gaze in Spoken Language Processing for Multimodal Conversational Interfaces", "labels": [], "entities": [{"text": "Eye Gaze", "start_pos": 18, "end_pos": 26, "type": "TASK", "confidence": 0.6849643439054489}, {"text": "Spoken Language Processing", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7087908784548441}]}], "abstractContent": [{"text": "Motivated by psycholinguistic findings, we are currently investigating the role of eye gaze in spoken language understanding for multimodal conversational systems.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.6719159285227457}]}, {"text": "Our assumption is that, during human machine conversation, a user's eye gaze on the graphical display indicates salient entities on which the user's attention is focused.", "labels": [], "entities": []}, {"text": "The specific domain information about the salient entities is likely to be the content of communication and therefore can be used to constrain speech hypotheses and help language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 170, "end_pos": 192, "type": "TASK", "confidence": 0.7121314406394958}]}, {"text": "Based on this assumption, this paper describes an exploratory study that incorporates eye gaze in salience modeling for spoken language processing.", "labels": [], "entities": [{"text": "spoken language processing", "start_pos": 120, "end_pos": 146, "type": "TASK", "confidence": 0.6310373246669769}]}, {"text": "Our empirical results show that eye gaze has a potential in improving automated language processing.", "labels": [], "entities": [{"text": "automated language processing", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.6125767827033997}]}, {"text": "Eye gaze is subconscious and involuntary during human machine conversation.", "labels": [], "entities": []}, {"text": "Our work motivates more in-depth investigation on eye gaze in attention prediction and its implication in automated language processing.", "labels": [], "entities": [{"text": "attention prediction", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7028383165597916}]}], "introductionContent": [{"text": "Psycholinguistic experiments have shown that eye gaze is tightly linked to human language processing.", "labels": [], "entities": []}, {"text": "Eye gaze is one of the reliable indicators of what a person is \"thinking about\" ().", "labels": [], "entities": []}, {"text": "The direction of gaze carries information about the focus of the users attention.", "labels": [], "entities": []}, {"text": "The perceived visual context influences spoken word recognition and mediates syntactic processing ().", "labels": [], "entities": [{"text": "spoken word recognition", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.6327741841475168}]}, {"text": "In addition, directly before speaking a word, the eyes move to the mentioned object).", "labels": [], "entities": []}, {"text": "Motivated by these psycholinguistic findings, we are currently investigating the role of eye gaze in spoken language understanding during human machine conversation.", "labels": [], "entities": [{"text": "spoken language understanding during human machine conversation", "start_pos": 101, "end_pos": 164, "type": "TASK", "confidence": 0.7083975332123893}]}, {"text": "Through multimodal interfaces, a user can look at a graphic display and converse with the system at the same time.", "labels": [], "entities": []}, {"text": "Our assumption is that, during human machine conversation, a user's eye gaze on the graphical display can indicate salient entities on which the user's attention is focused.", "labels": [], "entities": []}, {"text": "The specific domain information about the salient entities is likely linked to the content of communication and therefore can be used to constrain speech hypotheses and influence language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 179, "end_pos": 201, "type": "TASK", "confidence": 0.7106810808181763}]}, {"text": "Based on this assumption, we carried out an exploration study where eye gaze information is incorporated in a salience model to tailor a language model for spoken language processing.", "labels": [], "entities": []}, {"text": "Our preliminary results show that eye gaze can be useful in improving spoken language processing and the effect of eye gaze varies among different users.", "labels": [], "entities": [{"text": "spoken language processing", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.6602156658967336}]}, {"text": "Because eye gaze is subconscious and involuntary inhuman machine conversation, our work also motivates systematic investigations on how eye gaze contributes to attention prediction and its implications in automated language processing.", "labels": [], "entities": [{"text": "attention prediction", "start_pos": 160, "end_pos": 180, "type": "TASK", "confidence": 0.7615479230880737}]}], "datasetContent": [{"text": "The evaluations were conducted on data collected from user studies (Sec. 3).", "labels": [], "entities": []}, {"text": "We evaluated the gazebased salience driven bigram models when applied for speech recognition at early and late stages.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.8392694592475891}]}, {"text": "Users' speech was first segmented, then recognized by the CMU Sphinx-4 speech recognizer using different language models.", "labels": [], "entities": [{"text": "CMU Sphinx-4 speech recognizer", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.793222963809967}]}, {"text": "Evaluation was done by a 14-fold cross validation.", "labels": [], "entities": []}, {"text": "We compare the performances of the early and late applications of two gaze-based salience driven language models: \u2022 S-Bigram1 -salience driven language model based on salience modeling 1 (Sec.", "labels": [], "entities": []}, {"text": "4.1.1) \u2022 S-Bigram2 -salience driven language model based on salience modeling 2 (Sec.", "labels": [], "entities": []}, {"text": "4.1.2) show the results of early and late application of the salience driven language models based on eye gaze.", "labels": [], "entities": []}, {"text": "We can see that all word error rates (WERs) are high.", "labels": [], "entities": [{"text": "word error rates (WERs)", "start_pos": 20, "end_pos": 43, "type": "METRIC", "confidence": 0.8416743278503418}]}, {"text": "In the experiments, users were instructed to only answer systems questions one by one.", "labels": [], "entities": []}, {"text": "There was no flow of areal conversation.", "labels": [], "entities": []}, {"text": "In this setting, users were more free to express themselves than in the situation where users believed they were conversing with a machine.", "labels": [], "entities": []}, {"text": "Thus, we observe much longer sentences that often contain disfluencies.", "labels": [], "entities": []}, {"text": "Here is one example: System: \"How big is the bed?\"", "labels": [], "entities": []}, {"text": "User: \"I would to have to offer a guess that the bed, if I look the chair that's beside it in a relative angle to the bed, it's probably six feet long, possibly, or shorter, slightly shorter.\"", "labels": [], "entities": []}, {"text": "The high WER was mainly caused by the complexity and disfluencies of users' speech.", "labels": [], "entities": [{"text": "WER", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9887813329696655}]}, {"text": "Poor speech recording quality is another reason for the bad recognition performance.", "labels": [], "entities": []}, {"text": "It was found that the trigram model performed worse than the bigram model in the experiment.", "labels": [], "entities": []}, {"text": "This is probably due to the sparseness of trigrams in the corpus.", "labels": [], "entities": []}, {"text": "The S-Bigram1 and S-Bigram2 achieved similar results in both early application) and late application.", "labels": [], "entities": []}, {"text": "In early application, the SBigram1 model performed better than the trigram model (t = 5.24, p < 0.001, one-tailed) and the bigram model (t = 3.31, p < 0.001, one-tailed).", "labels": [], "entities": []}, {"text": "The S-Bigram2 model also performed better than the trigram model (t = 5.15, p < 0.001, one-tailed) and the bigram model (t = 3.33, p < 0.001, onetailed) in early application.", "labels": [], "entities": []}, {"text": "In late application, the S-Bigram1 model performed better than the trigram model (t = 2.11, p < 0.02, one-tailed), so did the S-Bigram2 model (t = 1.99, p < 0.025, onetailed).", "labels": [], "entities": []}, {"text": "However, compared to the bigram model, the S-Bigram1 model did not change the recognition performance significantly (t = 0.38, N.S., twotailed) in late application, neither did the S-Bigram2 model (t = 0.50, N.S., two-tailed).", "labels": [], "entities": []}, {"text": "We also compare performances of the salience driven language models for individual users.", "labels": [], "entities": []}, {"text": "In early application, both the S-Bigram1 and the SBigram2 model performed better than the baselines of the bigram and trigram models for all users except user 2 and user 7.", "labels": [], "entities": []}, {"text": "T-tests have shown that these are significant improvements.", "labels": [], "entities": [{"text": "T-tests", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8209500312805176}]}, {"text": "For user 2, the S-Bigram1 model achieved the same WER as the bigram model.", "labels": [], "entities": [{"text": "WER", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9987398982048035}]}, {"text": "For user 7, neither of the salience driven language models improved recognition compared to the bigram model.", "labels": [], "entities": []}, {"text": "In late application), only for user 3 and user 4, both salience driven language models performed better than the baselines of the bigram and trigram models.", "labels": [], "entities": []}, {"text": "These improvements have also been confirmed by t-tests as significant.", "labels": [], "entities": []}, {"text": "Comparing early and late application of the salience driven language models, it is observed that early application performed better than late application for all users except user 3 and user 4.", "labels": [], "entities": []}, {"text": "T-tests have confirmed that these differences are significant.", "labels": [], "entities": [{"text": "T-tests", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8061817288398743}]}, {"text": "It is interesting to see that the effect of gaze-based salience modeling is different among users.", "labels": [], "entities": []}, {"text": "For two users (i.e., user 3 and user 4), the gaze-based salience driven language models consistently outperformed the bigram and trigram models in both early application and late application.", "labels": [], "entities": []}, {"text": "However, for some other users (e.g., user 7), this is not the case.", "labels": [], "entities": []}, {"text": "In fact, the gaze-based salience driven language models performed worse than the bigram model.", "labels": [], "entities": []}, {"text": "This observation indicates that during language production, a user's eye gaze is voluntary and unconscious.", "labels": [], "entities": []}, {"text": "This is different from deictic gesture, which is more intentionally delivered by a user.", "labels": [], "entities": []}, {"text": "Therefore, incorporating this \"unconscious\" mode of modality in salience modeling requires more in-depth research on the role of eye gaze in attention prediction during multimodal human computer interaction.", "labels": [], "entities": [{"text": "salience modeling", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.8491346538066864}, {"text": "attention prediction", "start_pos": 141, "end_pos": 161, "type": "TASK", "confidence": 0.7208419293165207}]}], "tableCaptions": [{"text": " Table 1: WER of early application of LMs", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9978603720664978}, {"text": "LMs", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.6327047944068909}]}]}