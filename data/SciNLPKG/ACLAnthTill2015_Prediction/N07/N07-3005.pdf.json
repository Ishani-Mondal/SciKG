{"title": [], "abstractContent": [{"text": "The goals of my dissertation are: 1) to propose a French terminology for the presentation of evaluation results of automatic summaries, 2) to identify and describe experimental variables in evaluations of automatic summaries, 3) to highlight the most common tendencies, inconsistencies and methodological problems in summa-rization evaluation experiments, and 4) to make recommendations for the presentation of evaluation results of automatic summaries.", "labels": [], "entities": []}, {"text": "In this paper, I focus on the second objective, i.e. identifying and describing variables in summarization evaluation experiments.", "labels": [], "entities": [{"text": "summarization evaluation", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.9215017557144165}]}], "introductionContent": [{"text": "The general subject of my dissertation is summarization evaluation.", "labels": [], "entities": [{"text": "summarization evaluation", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.9834244549274445}]}, {"text": "As stated in my thesis proposal, my work aims at four goals: 1) proposing a French terminology for the presentation of evaluation results of automatic summaries, 2) identifying and describing experimental variables in evaluations of automatic summaries, 3) highlighting the most common tendencies, inconsistencies and methodological problems in summarization evaluations, and 4) making recommendations for the presentation of evaluation results of automatic summaries.", "labels": [], "entities": [{"text": "summarization evaluations", "start_pos": 345, "end_pos": 370, "type": "TASK", "confidence": 0.9262649714946747}]}, {"text": "In this paper, I will focus on the second objective.", "labels": [], "entities": []}, {"text": "My ultimate goal is to provide the francophone scientific community with guidelines for the evaluation of automatic summaries of French texts.", "labels": [], "entities": [{"text": "evaluation of automatic summaries of French texts", "start_pos": 92, "end_pos": 141, "type": "TASK", "confidence": 0.7030380921704429}]}, {"text": "Evaluation campaigns for NLP applications already exist in France, the EVALDA project . However, no campaign has yet been launched for French automatic summaries, like Document Understanding Conferences for English texts or Text Summarization Challenge for Japanese texts.", "labels": [], "entities": [{"text": "Text Summarization Challenge for Japanese texts", "start_pos": 224, "end_pos": 271, "type": "TASK", "confidence": 0.8554961184660593}]}, {"text": "I hope that such a campaign will begin in the near future and that my thesis work may then serve as a guide for its design.", "labels": [], "entities": []}], "datasetContent": [{"text": "One of the most common evaluation methods consists of comparing automatic summaries with other summaries.", "labels": [], "entities": [{"text": "summaries", "start_pos": 74, "end_pos": 83, "type": "TASK", "confidence": 0.8542428016662598}]}, {"text": "During my analysis, I identified seven types of information about these other summaries: 1) the total number of other summaries, 2) the type of summaries, 3) the length, 4) the total number of human summarizers, 5) the number of human summarizers per source text, 6) the instructions given to the human summarizers, and 7) the human summarizers' profile.", "labels": [], "entities": [{"text": "length", "start_pos": 162, "end_pos": 168, "type": "METRIC", "confidence": 0.9545721411705017}]}, {"text": "The number of other summaries does not necessarily correspond to the number of automatic summaries evaluated, depending on many factors: the use of other summaries of different types or different lengths, the number of persons producing the other summaries, the number of other systems producing the other summaries, and soon.", "labels": [], "entities": []}, {"text": "There are two general types of summaries used for comparison with the automatic summaries being evaluated.", "labels": [], "entities": [{"text": "summaries", "start_pos": 31, "end_pos": 40, "type": "TASK", "confidence": 0.964730978012085}]}, {"text": "First, gold standard summaries (or target summaries) can be author summaries, professional summaries or summaries produced specifically for the evaluation.", "labels": [], "entities": []}, {"text": "Second, baseline summaries are generally produced by extracting random sentences from source texts or produced by another system.", "labels": [], "entities": []}, {"text": "In my corpora, gold standard summaries are often produced specifically for the evaluation.", "labels": [], "entities": []}, {"text": "In most cases, they are produced by manually extracting the most important passages, sentences or paragraphs, allowing automatic comparison between automatic summaries and gold standard summaries.", "labels": [], "entities": []}, {"text": "On the other hand, many evaluations used baseline summaries.", "labels": [], "entities": []}, {"text": "For example, used summaries produced by Word AutoSummarize, Hovy and Lin (1999) used summaries produced by automatically extracting random sentences from source texts.", "labels": [], "entities": [{"text": "Word AutoSummarize", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.8437761068344116}]}, {"text": "In, and, baseline summaries were produced by automatically extracting sentences at the beginning of the texts, and in Myaeng and Jang (1999) by extracting the first five sentences of the conclusion.", "labels": [], "entities": []}, {"text": "Logically, the length of the summaries used for the comparison should be equivalent to the length of the automatic summaries being evaluated.", "labels": [], "entities": []}, {"text": "If automatic summaries of different lengths are evaluated, there should be corresponding baselines and/or gold standard summaries for each length, unless the goal of the evaluation is to determine if the length plays a role in the quality of automatic summaries.", "labels": [], "entities": []}, {"text": "Many of the evaluations analyzed do not indicate the number of human summarizers participating in the production of gold standard summaries.", "labels": [], "entities": []}, {"text": "A few of them specify the total number of persons involved, but not the number for each source text.", "labels": [], "entities": []}, {"text": "This is an important variable because summarizing, either by extracting or abstracting, is a subjective task.", "labels": [], "entities": [{"text": "summarizing", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.985203742980957}]}, {"text": "The more people involved in the summarization of one text, the more we can consider the final summary to be reliable.", "labels": [], "entities": [{"text": "summarization", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.9703523516654968}]}, {"text": "From the pieces of information I was able to gather, the number of summarizers per source text ranges from 1 to 13 in my corpora.", "labels": [], "entities": []}, {"text": "In analyzing the evaluations of my corpora, I realized that some authors gave clear instructions to the human summarizers, for example.", "labels": [], "entities": []}, {"text": "In other cases, authors asked the summarizers to extract the most \"important\" sentences.", "labels": [], "entities": []}, {"text": "The term \"important\" includes other terms like representative, informative, relevant, and eligible.", "labels": [], "entities": []}, {"text": "It is rarely mentioned however if those words were explained to the summarizers.", "labels": [], "entities": []}, {"text": "I also noticed that some evaluations used people coming from different backgrounds, for example in, while others used more homogeneous groups, for example in Barzilay and Elhadad (1999) and.", "labels": [], "entities": []}], "tableCaptions": []}