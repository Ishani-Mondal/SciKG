{"title": [], "abstractContent": [{"text": "This report describes a logic grammar formalism,", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "This section describes briefly an experimental MLG, called HODL, which covers the same linguistic ground as the grammar (called HOD) in.", "labels": [], "entities": []}, {"text": "The syntactic component of HOD, a DCG, is essentially the same as that in.", "labels": [], "entities": []}, {"text": "One feature of these syntactic components is a systematic use of slot-filling to treat complements of verbs and nouns.", "labels": [], "entities": []}, {"text": "This method increases modularity between syntax and lexicon, and is described in detail in.", "labels": [], "entities": []}, {"text": "One purpose of HOD, which is carried over to MODL, is a good treatment of scoping of modifiers and a good specification of logical form.", "labels": [], "entities": [{"text": "MODL", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.8140517473220825}]}, {"text": "The logical form language used by >IODL as the target of semantic interpretation has been improved somewhat over that used for HOD.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7221457660198212}]}, {"text": "We describe here some of the characteristics of the new logical form language, called LFL, and give sample LFL analyses obtained by MODL, but we defer a more detailed description of LFL to a later report.", "labels": [], "entities": [{"text": "MODL", "start_pos": 132, "end_pos": 136, "type": "DATASET", "confidence": 0.8211988806724548}]}, {"text": "The main predicates of LFL are word-senses for words in the natural language being analyzed, for' example, believel(X,Y) in the sense \"X believes that Y holds\".", "labels": [], "entities": []}, {"text": "Quantifiers, like 'each', are special cases of word-senses.", "labels": [], "entities": []}, {"text": "There are also a small number of non-lexJcal predicates in LFL, some of which are associated with inflections of words, like 'past' for past tense, or syntactic constructions, like 'yesno' for yes-no questions, or have significance at discourse level, dealing for instance with topic/comment.", "labels": [], "entities": []}, {"text": "The arguments for predicates of LFL can be constants, variables, or other logical forms (expressions of LFL).", "labels": [], "entities": []}, {"text": "Expressions of LFL are either predications (in the sense just indicated) or combinations of LFL expressions using the conjunction '&' and the indexing operator ':'.", "labels": [], "entities": []}, {"text": "Specifically, if P is a logical form and E is a variable, then P:E (read \"P indexed by E\"~ is also a logical form.", "labels": [], "entities": []}, {"text": "When an indexed logical form P:E appears as part of a larger logical form Q, and the index variable E is used elsewhere in Q. then E can bethought of roughly as standing for P together with its \"context\".", "labels": [], "entities": []}, {"text": "Contexts include references to time and place which are normally left implicit in natural language.", "labels": [], "entities": []}, {"text": "When P specifies an event, as in see(john,mary), writing P:E and subsequently using E will guarantee that E refers to the same event.", "labels": [], "entities": []}, {"text": "In the logical form language used in, event variables (as arguments of verb and noun senses) were used for indexing.", "labels": [], "entities": []}, {"text": "But the indexing operator is more powerful because it can index complex logical forms.", "labels": [], "entities": []}, {"text": "For some applications, it is sufficient to ignore contexts, and in such cases we just think of P:E as verifying P and binding E to an instantiation of P.", "labels": [], "entities": []}, {"text": "In fact, for PROLOG execution of logical forms without contexts, ':' can be defined by the single clause: P:P <-F.", "labels": [], "entities": [{"text": "PROLOG execution of logical forms without contexts", "start_pos": 13, "end_pos": 63, "type": "TASK", "confidence": 0.8754938500268119}]}, {"text": "A specific purpose of the MOD system in was to point out the importance of a class of predicates called focaiizers, and to offer a method for dealing with them in semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 163, "end_pos": 186, "type": "TASK", "confidence": 0.7427878677845001}]}, {"text": "Focalizers include many determiners, adverbs, and adjectives (or their word-senses), as well ascertain non-lexical predicates like 'yesno'.", "labels": [], "entities": []}, {"text": "Focalizers take two logical form arguments called the base and the fOCUS: The Focus is often associated with sentence stress, hence the name.", "labels": [], "entities": []}, {"text": "The pair (Base, Focus) is called the SCOpe of the focalizer.", "labels": [], "entities": []}, {"text": "The adverbs 'only' and 'even' are focalizers which most clearly exhibit the connection with stress.", "labels": [], "entities": []}, {"text": "The predication only(P,Q) reads \"the only case where P holds is when Q also holds\".", "labels": [], "entities": []}, {"text": "We get different analyses depending on focus.", "labels": [], "entities": []}, {"text": "John only buys books at Smith's. only(at(smith,buy(john,X1)), book(X1)).", "labels": [], "entities": [{"text": "Smith's.", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9352824091911316}]}, {"text": "John only buys books at Smith's. only(book(Xl)&at(X2,buy(john,Xl)), X2=smith).", "labels": [], "entities": [{"text": "Smith's.", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9530296325683594}]}, {"text": "quantificational adverbs like 'always' and 'seldom', studied by David, are also focalizers.", "labels": [], "entities": []}, {"text": "Lewis made the point that these quantifiers are properly considered unseJKtJve, in the sense that they quantify overall the free variables in (what we call) their bases.", "labels": [], "entities": []}, {"text": "For example, in John always buys books at Smith's. always(book(Xl)&at(X2,buy(john,Xl)), X2=smith) \u2022 the quantification is over both X1 and X2.", "labels": [], "entities": [{"text": "John always buys books at Smith's.", "start_pos": 16, "end_pos": 50, "type": "DATASET", "confidence": 0.664174218972524}]}, {"text": "(A paraphrase is \"Always, if X1 is a book and John buys X1 at X2, then X2 is Smith's\".)", "labels": [], "entities": []}, {"text": "Quantificational determiners are also focalizers (and are unselective quantifiers); they correspond closely in meaning to the quantificational adverbs ('all' -'always', 'many' 'often', 'few' -'seldom', etc.).", "labels": [], "entities": []}, {"text": "We have the paraphrases: Leopards often attack monkeys in trees.", "labels": [], "entities": []}, {"text": "often(leopard(Xl)&tree(X2)&in(X2,attack(Xl,X3)), monkey(X3)).", "labels": [], "entities": []}, {"text": "Many leopard attacks in trees are (attacks) on monkeys.", "labels": [], "entities": []}, {"text": "many(leopard(Xl)&tree(X2)&in(X2,attack(Xi,X3)), monkey(X3)).", "labels": [], "entities": []}, {"text": "Adverbs and adjectives involving comparison or degree along some scale of evaluation (a wide class) are also focalizers.", "labels": [], "entities": []}, {"text": "The base specifies the base of comparison, and the focus singles out what is being compared to the base.", "labels": [], "entities": []}, {"text": "This shows upmost clearly in the superlative forms.", "labels": [], "entities": []}, {"text": "Consider the adverb \"fastest\": John ran fastest yesterday.", "labels": [], "entities": [{"text": "John ran fastest yesterday", "start_pos": 31, "end_pos": 57, "type": "DATASET", "confidence": 0.8549539297819138}]}, {"text": "fastest(run(john):E, yesterday(E)).", "labels": [], "entities": [{"text": "run(john):E", "start_pos": 8, "end_pos": 19, "type": "METRIC", "confidence": 0.792303999265035}, {"text": "yesterday", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.929933488368988}]}, {"text": "fastest(yesterday(run(X)), X=john).", "labels": [], "entities": []}, {"text": "In the first sentence, with focus on \"yesterday\", the meaning is that, among all the events of John's running (this is the base), John's running yesterday was fastest.", "labels": [], "entities": []}, {"text": "The logical form illustrates the indexing operator.", "labels": [], "entities": []}, {"text": "[n the second sentence, with focus on \"John\", the meaning is that among all the events of running yesterday (there is an implicit location for these events), John's running was fastest.", "labels": [], "entities": []}, {"text": "As an example of a non-lexical focalizer, we have yesno(P,q), which presupposes that a case of P holds, and asks whether P & Q holds.", "labels": [], "entities": []}, {"text": "(The pair (P, Q) is like Topic/Comment for yes-no questions.)", "labels": [], "entities": []}, {"text": "Example: Did John see M@ry yesterday?", "labels": [], "entities": []}, {"text": "yesno(yesterday(see(john,X)), X=mary).", "labels": [], "entities": []}, {"text": "It is possible to give Prolog definitions for most of the focalizers discussed above which are suitable for extensional evaluation and which amount to model-theoretic definitions of them.", "labels": [], "entities": []}, {"text": "This will be discussed in a later report on LFL.", "labels": [], "entities": [{"text": "LFL", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.8729552030563354}]}, {"text": "A point of the grammar HODL is to be able to produce LFL analyses of sentences using the modular semantic interpretation system outlined in the preceding section, and to arrive at the right (or most likely) scopes for focalizers and other modifiers.", "labels": [], "entities": []}, {"text": "The decision on scoping can depend on heuristics involving precedences, on very reliable cues from the syntactic position, and even on the specification of loci by explicit underlining in ~he input string (which is most relevant for adverbial focalizers).", "labels": [], "entities": []}, {"text": "Although written text does not often use such explici~ specification of adverbial loci, it is important that the system can get the right logical form after having some specification of the adverbial focus, because this specification might be obtained from prosody in spoken language, or might come from the use of discourse information.", "labels": [], "entities": []}, {"text": "[t also is an indication of the modularity of the system that it can use the same syntactic rules and parse path no matter where the adverbial focus happens to lie.", "labels": [], "entities": []}, {"text": "Most of the specific linguistic information for semantic interpretation is encoded in the procedures 'mod', 'reorder', and 'raise', which manipulate semantic items.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.818891853094101}]}, {"text": "In MODL there are 22 clauses for the procedure 'mod', most of which are unit clauses.", "labels": [], "entities": []}, {"text": "These involve ten different modification operators, four of which were illustrated in the preceding section.", "labels": [], "entities": []}, {"text": "The definition of 'mo<l' in MODL is taken fairly directly from the corresponding procedure 'trans' in HOD, although there are some changes involved in handling the new version of the logical form language (LFL), especially the indexing operator.", "labels": [], "entities": [{"text": "MODL", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.8366814255714417}]}, {"text": "The definitions of 'reorder' and 'raise' are essentially the same as for procedures in HOD.", "labels": [], "entities": [{"text": "raise", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.9716303944587708}]}, {"text": "An illustration of analysis in the two-pass mode in HODL is now given.", "labels": [], "entities": [{"text": "HODL", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.8460169434547424}]}, {"text": "For the sentence \"Leopards only attack monkeys in trees\", the syntactic analysis tree is as follows.", "labels": [], "entities": []}, {"text": "Here we display complete logical terminals in the leaf nodes of the tree.", "labels": [], "entities": []}, {"text": "An indicat[on of the meanings of the operators (P<Q) and @@R will be given below.", "labels": [], "entities": []}, {"text": "[n the semantic interpretation of the prepositional phrase, the 'tree' item gets promoted (by 'raise') to be a left-sister of the the 'in' item, and the list of daughter items (augmented semantic items) of the 'sent' node is the following.", "labels": [], "entities": []}, {"text": "Here we di~:play each augmented semantic item sem(nt:Feas,Op,LF) simply in the form nt Op LF.", "labels": [], "entities": []}, {"text": "The material in the first field of the 'monkey' item actually shows that it is stressed.", "labels": [], "entities": []}, {"text": "The reshaping p~ocedure 'reorder' rearran6es these items into the order: Next, these items successively modify (according to the rules for 'mod') the matrix item, sent id t, with the rightmost daughter acting as innermost oodifier.", "labels": [], "entities": []}, {"text": "The rules for 'mod' involving the operator (P<Q) associated with only(P,Q) are designed so that the logical form material to the right of 'only' goes into the focus Q of 'only' and the material to the left goes into the base P.", "labels": [], "entities": []}, {"text": "The material to the right is just monkey(Y).", "labels": [], "entities": []}, {"text": "The items on the left ('leopard', 'tree', 'in', 'attack') are allowed to combine (through 'mod') in an independent way before being put into the base of 'only'.", "labels": [], "entities": []}, {"text": "The operator ~@R associated with in(Z,R) causes R to be botmd to the logical form of the modificand --attack(X,Y).", "labels": [], "entities": []}, {"text": "The combination of items on the left of 'only' is leopard(X)&tree(Z)&in(Z,attack(X,Y)) This goes into the base, so the whole logical form is only(leopard(X)&tree(Z)&in(Z,attack(X,Y)), monkey(Y)).", "labels": [], "entities": []}, {"text": "For detailed traces of logical form construction by this method, see.", "labels": [], "entities": [{"text": "logical form construction", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.6797034541765848}]}, {"text": "An illustration of the treatment of leftembedding in HODL in a two-pass analysis of the sentence \"John sees each boy's brother's teacher\" is as follows.", "labels": [], "entities": []}, {"text": "The MODL noun phrase rules include the shift (in away that is an elaboration of the shift grammar fragment in Section 2), as well as rules for slotfilling for nouns like 'brother' and 'teacher' which have more than one argument in logical form.", "labels": [], "entities": [{"text": "MODL", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.6984387040138245}]}, {"text": "Exactly the same logical form is obtained by MODL for the sentence \"John sees the teacher of the brother of each boy\".", "labels": [], "entities": [{"text": "MODL", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.6637489199638367}]}, {"text": "Both of these analyses involve raising.", "labels": [], "entities": []}, {"text": "[n =he first, the 'poss' node resulting from the apostrophe-s is raised to become a definite article.", "labels": [], "entities": []}, {"text": "In the second, the prepositional phrases (their semantic structures) are promoted to be sisters of the \"teacher\" node, and the order of the quantlfiers ts (correctly) reversed.", "labels": [], "entities": []}, {"text": "The syntactic component of MODL was adapted as closely as possible from that of HOD (a DCG) in order to get an idea of the efficiency of HLG's.", "labels": [], "entities": []}, {"text": "The fact that the MLG rule compiler produces more structure-building arguments than are in the DCG would tend to |engthen analysis times, but it is hard to predic~ the effect of the different organization of the semantic interpreter (from a threepass system to a one-pass and a two-pass version of MODL).", "labels": [], "entities": []}, {"text": "7\"no followin E five sentences were used for timing tests.", "labels": [], "entities": [{"text": "timing", "start_pos": 45, "end_pos": 51, "type": "TASK", "confidence": 0.5988155007362366}]}, {"text": "Who did John say that the man introduced Mary to?", "labels": [], "entities": []}, {"text": "Each book Mary said was given to Bill was written by a woman.", "labels": [], "entities": []}, {"text": "Leopards only attack monkeys in trees.", "labels": [], "entities": []}, {"text": "John saw each boy's brother's teacher.", "labels": [], "entities": []}, {"text": "Does anyone wanting to seethe teacher know whether there are any hooks left in this room?", "labels": [], "entities": []}, {"text": "Using Waterloo Prolog (an interpreter) on an IBM 3081, the following average times to get the logical forms for the five sentences were obtained (not including ~ime for [/0 and initial word separation): MODL, one-pass mode -40 milliseconds.", "labels": [], "entities": [{"text": "MODL", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.9406569004058838}]}, {"text": "MODL, two-pass mode -42 milliseconds.", "labels": [], "entities": [{"text": "MODL", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6450942754745483}]}, {"text": "So there was a loss of speed, but not a significant one.", "labels": [], "entities": [{"text": "speed", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9813862442970276}]}, {"text": "MODL has also been implemented in PSC Prolog (on a 3081).", "labels": [], "entities": [{"text": "MODL", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5044423937797546}, {"text": "PSC Prolog", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.9290399551391602}]}, {"text": "Here the average one-pass analysis time for the five sentences was improved to 30 milliseconds per sentence.", "labels": [], "entities": []}, {"text": "On the other hand, the MLG grammar (in source form) ls more compact and easier to understand.", "labels": [], "entities": [{"text": "MLG grammar", "start_pos": 23, "end_pos": 34, "type": "DATASET", "confidence": 0.7969365417957306}]}, {"text": "The syntactic components for MOD and MODL were compared numerically by a Prolog program that totals up the sizes of all the grammar rules, where the size of a compound term is defined to be I plus the sum of the sizes of its arguments, and the size of any other term is I.", "labels": [], "entities": [{"text": "MODL", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.7748163938522339}]}, {"text": "The total for MODL was l&33, and for MOD was 1807, fora ratio of 79%.", "labels": [], "entities": [{"text": "MODL", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.7901757955551147}, {"text": "MOD", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.8311121463775635}]}, {"text": "So far, nothing has been said in this report about semantic constraints in HODL.", "labels": [], "entities": []}, {"text": "Currently, MODL exercises constraints by unification of semantic types.", "labels": [], "entities": []}, {"text": "Prolog terms representing type requirements on slot-fillers must be unified with types of actual fillers.", "labels": [], "entities": []}, {"text": "The types used in MODL are t%/pe trees.", "labels": [], "entities": [{"text": "MODL", "start_pos": 18, "end_pos": 22, "type": "TASK", "confidence": 0.8323324918746948}]}, {"text": "A type tr~ is either a variable {unspecified type) or a term whose principal functor is anatomic type (like 'human'), and whose arguments are subordinate type trees.", "labels": [], "entities": []}, {"text": "A type tree T1 is subordinate to a type tree T2 if either T1 is a variable or the principal functor of T1 is a subtype (ako) of the principal functor of T2.", "labels": [], "entities": []}, {"text": "Type trees area generalization of the type lists used by, which are lists of the form TI:T2:T3:..., where T1 is a supertype of T2, T2 is a supertype of TS, ..., and the tail of the list maybe a variable.", "labels": [], "entities": []}, {"text": "The point of the generalization is to allow cross-classification.", "labels": [], "entities": []}, {"text": "Multiple daughters of a type node cross-classify it.", "labels": [], "entities": []}, {"text": "The lexicon in MODL includes a preprocessor for lexical entries which allows the original lexical entries to specify type constraints in a compact, non-redundant way.", "labels": [], "entities": []}, {"text": "There is a Pro|o K representation for type-hierarchies, and the [exical preprocessor manufactures full type trees from a specification of their leaf nodes.", "labels": [], "entities": []}, {"text": "[n the one-pass mode for analysis with MLG's, logical forms get built up during parsing, so logical forms are available for examination by semantic checking procedures of the sort outlined in.", "labels": [], "entities": []}, {"text": "If such methods are arguably best, then there maybe more argument fora one-pass system (with interleaving of semantics).", "labels": [], "entities": []}, {"text": "The general question of the number of passes in a natural language understander is an interesting one.", "labels": [], "entities": []}, {"text": "The MLG formalism makes this easier to investigate, because the same syntactic component can he used with onepass or two-pass interpretation.", "labels": [], "entities": []}, {"text": "In MODL, there is a small dictionary stored directly in Prolog, but MODL is also interfaced to a large dictionary/morphology system which produces syntactic and morphological information for words based on over 70,000 lemmata.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.9640740752220154}]}, {"text": "There are plans to include enough semantic information in this dictionary to provide semantic constraints fora large MLG.", "labels": [], "entities": []}, {"text": "Alexa HcCray is working on the syntactic component for an MLG with very wide coverage.", "labels": [], "entities": []}, {"text": "I wish to thank her for useful conversations about the nature of the system.", "labels": [], "entities": []}], "tableCaptions": []}