{"title": [{"text": "Robust Text Processing in Automated Information Retrieval", "labels": [], "entities": [{"text": "Robust Text Processing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7554253339767456}, {"text": "Automated Information Retrieval", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.6082739233970642}]}], "abstractContent": [{"text": "We report on the results of a series of experiments with a prototype text retrieval system which uses relatively advanced natural language processing techniques in order to enhance the effectiveness of statistical document retrieval.", "labels": [], "entities": [{"text": "text retrieval", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7216572314500809}, {"text": "statistical document retrieval", "start_pos": 202, "end_pos": 232, "type": "TASK", "confidence": 0.6846783856550852}]}, {"text": "In this paper we show that large-scale natural language processing (hundreds of millions of words and more) is not only required fora better retrieval, but it is also doable, given appropriate resources.", "labels": [], "entities": []}, {"text": "In particular, we demonstrate that the use of syntactic compounds in the representation of database documents as well as in the user queries, coupled with an appropriate term weighting strategy, can considerably improve the effectiveness of retrospective search.", "labels": [], "entities": [{"text": "retrospective search", "start_pos": 241, "end_pos": 261, "type": "TASK", "confidence": 0.933185875415802}]}, {"text": "The experiments reported here were conducted on TIP-STER database in connection with the Text REtrieval Conference series (TREC).", "labels": [], "entities": [{"text": "TIP-STER database", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.8733421266078949}, {"text": "Text REtrieval Conference series (TREC)", "start_pos": 89, "end_pos": 128, "type": "DATASET", "confidence": 0.6913153614316668}]}], "introductionContent": [{"text": "The task of information retrieval is to extract relevant documents from a large collection of documents in response to user queries.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7456049621105194}]}, {"text": "When the documents contain primarily unrestricted text (e.g., newspaper articles, legal documents, etc.) the relevance of a document is established through 'full-text' retrieval.", "labels": [], "entities": []}, {"text": "This has been usually accomplished by identifying key terms in the documents (the process known as 'indexing') which could then be matched against terms in queries.", "labels": [], "entities": []}, {"text": "The effectiveness of any such term-based approach is directly related to the accuracy with which a set of terms represents the content of a document, as well as how well it contrasts a given document with respect to other documents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9991857409477234}]}, {"text": "In other words, we are looking fora representation R such that for any text items D1 and D2, R(D1) = R(D2) iff meaning(D1) = meaning(D2), at an appropriate level of abstraction (which may depend on the types and character of anticipated queries), ' See fora detailed description of TREC.", "labels": [], "entities": []}, {"text": "The simplest word-based representations of content are usually inadequate since single words are rarely specific enough for accurate discrimination, and their grouping is often accidental.", "labels": [], "entities": []}, {"text": "A better method is to identify groups of words that create meaningful phrases, especially if these phrases denote important concepts in the database domain.", "labels": [], "entities": []}, {"text": "For example, joint venture is an important term in the Wall Street Journal (WSJ henceforth) database, while neither joint nor venture are important by themselves.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ henceforth) database", "start_pos": 55, "end_pos": 100, "type": "DATASET", "confidence": 0.9567710310220718}]}, {"text": "In fact, in a 800+ MBytes database, both joint and venture would often be dropped from the list of terms by the system because their inverted document frequency (idj) weights were too low.", "labels": [], "entities": [{"text": "inverted document frequency (idj) weights", "start_pos": 133, "end_pos": 174, "type": "METRIC", "confidence": 0.7694911956787109}]}, {"text": "In large databases comprising hundreds of thousands of documents the use of phrasal terms is not just desirable, it becomes necessary.", "labels": [], "entities": []}, {"text": "To illustrate this point let us consider TREC Topic 104, an information request from which a database search query is to be built.", "labels": [], "entities": [{"text": "TREC Topic 104", "start_pos": 41, "end_pos": 55, "type": "DATASET", "confidence": 0.6507389644781748}]}, {"text": "The reader may note various sections of this Topic, with <desc> corresponding to the user's original request, further elaborated in <narr>, and <con> consisting of expert-assigned phrases denoting key concepts to be considered.", "labels": [], "entities": []}, {"text": "Insurance Act of 1988, or the political/legal fallout from that legislation.", "labels": [], "entities": [{"text": "Insurance Act of 1988", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.9413424879312515}]}, {"text": "<aaarr> Narrative: A relevant document will detail the content of the U.S. medicare act of 1988 which extended catastrophic illness benefits to the elderly, with particular attention to the financing scheme which led to a firestorm of protest and a Congressional retreat, or a relevant document will detail the political/legal consequences of the catastrophic health insurance imbroglio and subsequent efforts by Congress to provide similar coverages through a less-controversial mechanism.", "labels": [], "entities": []}, {"text": "<con> Concept(s): 2.", "labels": [], "entities": []}, {"text": "catastrophic-health program, catastrophic illness, catastrophic care, acute care, long-term nursing home care 3.", "labels": [], "entities": []}, {"text": "American Association of Retired Persons, AARP, senior citizen, National Committee to Preserve Social Security and Medicare </top> If the phrases are ignored altogether, 2 this query will produce an output where the relevant documents are scattered as shown in the first table below which lists the ranks and scores of relevant documents within the top 100 retrieved documents.", "labels": [], "entities": []}, {"text": "On the other hand, if we include even simple phrases, such as catastrophichealth program, acute care, home care, and senior citizen, we can considerably sharpen the outcome of the search as seen in the second A query obtained from the fields <rifle>, <desc> and <narr> will be, as maybe expected, much weaker than the one using <con> field, especially without the phrasal terms, because the narrative contains far fewer specific terms while containing some that may prove distracting, e.g., firestorm.", "labels": [], "entities": [{"text": "A", "start_pos": 209, "end_pos": 210, "type": "METRIC", "confidence": 0.9925774931907654}]}, {"text": "In fact, showed that the exclusion of the <con> field makes the queries quite ineffective, while adding the <narr> field makes them even worse as they lose precision by as much as 30%.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9983742237091064}]}, {"text": "However, adding phrasal terms can improve things considerably.", "labels": [], "entities": []}, {"text": "We return to this issue later in the paper.", "labels": [], "entities": []}, {"text": "An accurate syntactic analysis is an essential prerequisite for selection of phrasal terms.", "labels": [], "entities": []}, {"text": "Various statistical methods, e.g., based on word co-occurrences s Including extra terms in documents changes the way other terms are weighted.", "labels": [], "entities": []}, {"text": "This issue is discussed later in this paper. and mutual information, as well as partial parsing techniques, are prone to high error rates (sometimes as high as 50%), turning out many unwanted associations.", "labels": [], "entities": []}, {"text": "Therefore a good, fast parser is necessary, but it is by no means sufficienL While syntactic phrases are often better indicators of content than 'statistical phrases' where words are grouped solely on the basis of physical proximity, e.g., \"college junior\" is not the same as \"junior college\" --the creation of compound terms makes the term matching process more complex since in addition to the usual problems of synonymy and subsumption, one must deal with their structure (e.g., \"college junior\" is the same as \"junior in college\").", "labels": [], "entities": [{"text": "term matching", "start_pos": 336, "end_pos": 349, "type": "TASK", "confidence": 0.7642576694488525}]}, {"text": "For all kinds of terms that can be assigned to the representation of a document, e.g., words, syntactic phrases, fixed phrases, and proper names, various levels of \"regularization\" are needed to assure that syntactic or lexical variations of input do not obscure underlying semantic uniformity.", "labels": [], "entities": []}, {"text": "Without actually doing semantic analysis, this kind of normalization can be achieved through the following processes: 4 (1) morphological stemming: e.g., retrieving is reduced to retriev; lexicon-based word normalization: e.g., retrieval is reduced to retrieve; (3) operator-argument representation of phrases: e.g., information retrieval, retrieving of information, and retrieve relevant information are all assigned the same representation, retrieve+information; context-based term clustering into synonymy classes and subsumption hierarchies: e.g., takeover is a kind of acquisition (in business), and Fortran is a programming language.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 317, "end_pos": 338, "type": "TASK", "confidence": 0.7261825352907181}]}, {"text": "Introduction of compound terms complicates the task of discovery of various semantic relationships among them.", "labels": [], "entities": []}, {"text": "For example, the term natural language can often be considered to subsume any term denoting a specific human language, such as English.", "labels": [], "entities": []}, {"text": "Therefore, a query containing the former maybe expected to retrieve documents containing the latter.", "labels": [], "entities": []}, {"text": "The same can be said about language and English, unless language is in fact apart of the compound term programming language in which case the association languageFortran is appropriate.", "labels": [], "entities": []}, {"text": "This is a problem because (a) it is a standard practice to include both simple and compound terms in document representation, and (b) term associations have thus far been computed primarily at word level (including fixed phrases) and therefore care must betaken when such associations are used in term matching.", "labels": [], "entities": [{"text": "term matching", "start_pos": 297, "end_pos": 310, "type": "TASK", "confidence": 0.7212442755699158}]}, {"text": "This may prove particularly troublesome for systems that attempt term clustering in order to create \"meta-terms\" to be used in document representation.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Run statistics for 50 ad-hoc queries against WSJ database", "labels": [], "entities": [{"text": "WSJ database", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9584520757198334}]}]}