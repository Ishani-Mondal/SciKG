{"title": [{"text": "Combination of Symbolic and Statistical Approaches for Grammatical Knowledge Acquisition", "labels": [], "entities": [{"text": "Grammatical Knowledge Acquisition", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.7486701607704163}]}], "abstractContent": [{"text": "The framework we adopted for customiz-ing linguistic knowledge to individual application domains is an integration of symbolic and statistical approaches.", "labels": [], "entities": []}, {"text": "In order to acquire domain specific knowledge, we have previously proposed a rule-based mechanism to hypothesize missing knowledge from partial parsing results of unsuccessfully parsed sentences.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the statistical process which selects plausible knowledge from a set of hypotheses generated from the whole corpus.", "labels": [], "entities": []}, {"text": "In particular, we introduce two statistical measures of hypotheses, Local Plausibility and Global Plausibility, and describe how these measures are determined iteratively.", "labels": [], "entities": []}, {"text": "The proposed method will be incorporated into the toolkit for linguistic knowledge acquisition which we are now developing.", "labels": [], "entities": [{"text": "linguistic knowledge acquisition", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.741892397403717}]}], "introductionContent": [{"text": "Current technologies in natural language processing are not so mature as to make general purpose systems applicable to any domains; therefore rapid customization of linguistic knowledge to the sublanguage of an application domain is vital for the development of practical systems.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.6742609341939291}]}, {"text": "In the currently working systems, such customization has been carried out manually by linguists or lexicographers with time-consuming effort.", "labels": [], "entities": []}, {"text": "We have already proposed a mechanism which acquires sublanguage-specific linguistic knowledge from parsing failures and which can be used as a tool for linguistic knowledge customization (.", "labels": [], "entities": [{"text": "linguistic knowledge customization", "start_pos": 152, "end_pos": 186, "type": "TASK", "confidence": 0.6465558807055155}]}, {"text": "Our approach is characterized by a mixture of symbolic and statistical approaches to grammatical knowledge acquisition.", "labels": [], "entities": [{"text": "grammatical knowledge acquisition", "start_pos": 85, "end_pos": 118, "type": "TASK", "confidence": 0.6622812549273173}]}, {"text": "Unlike probabilistic parsing, proposed by), *also a staff member of Matsushita Electric Industrial Co.,Ltd., Shinagawa, Tokyo, JAPAN.", "labels": [], "entities": [{"text": "Matsushita Electric Industrial Co.", "start_pos": 68, "end_pos": 102, "type": "DATASET", "confidence": 0.7870306223630905}, {"text": "JAPAN", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.8590010404586792}]}], "datasetContent": [{"text": "In order to demonstrate how the HS works, we carried out a preliminary experiment with 1,000 sentences in the UNIX on-line manual (approximately one fifth of the whole manual).", "labels": [], "entities": [{"text": "HS", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.917483925819397}]}, {"text": "As the initial knowledge for the experiment, we prepared a grammar set which contains 120 rules covering English basic expressions and deliberately removed rules for participles in order to check whether the HS can discover adequate rules.", "labels": [], "entities": []}, {"text": "The input data to the statistical process is a set of 5,906 instance hypotheses generated from 282 unsuccessfully parsed sentences.", "labels": [], "entities": []}, {"text": "The statistical process removed 4,034 instance hypotheses and stopped after 63 cycles of the iterative computation of GP and LP.", "labels": [], "entities": []}, {"text": "The instance hypotheses were grouped into 2,876 generic hypotheses and the GP values of 2,331 generic hypotheses were reduced to 0 by the hypothesis deletion. is the list of \"correct\" hypotheses picked up from the whole list of generic hypotheses sorted by GP values.", "labels": [], "entities": [{"text": "GP", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9785841107368469}]}, {"text": "The hypothesis for participles, np => vp,np, is one of the 128 hypotheses whose GP values are 1.", "labels": [], "entities": []}, {"text": "This table also shows that quite a few \"correct\" lexical hypotheses are in higher positions because lexical knowledge for unknown words is indispensable to the successful parsing of the corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Distribution of \"Correct\" Hypotheses", "labels": [], "entities": [{"text": "Distribution of \"Correct\" Hypotheses", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.6723716060320536}]}]}