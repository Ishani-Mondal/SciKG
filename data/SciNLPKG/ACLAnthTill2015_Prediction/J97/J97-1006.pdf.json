{"title": [{"text": "Effects of Variable Initiative on Linguistic Behavior in Human-Computer Spoken Natural Language Dialogue", "labels": [], "entities": [{"text": "Spoken Natural Language Dialogue", "start_pos": 72, "end_pos": 104, "type": "TASK", "confidence": 0.6214677914977074}]}], "abstractContent": [{"text": "This paper presents an analysis of the dialogue structure of actual human-computer interactions.", "labels": [], "entities": []}, {"text": "The 141 dialogues analyzed were produced from experiments with a variable initiative spoken natural language dialogue system organized around the paradigm of the Missing Axiom Theory for language use.", "labels": [], "entities": []}, {"text": "Results about utterance classification into subdialogues, frequency of user-initiated subdialogue transitions, regularity of subdialogue transitions, frequency of linguistic control shifts, and frequency of user-initiated error corrections are presen ted.", "labels": [], "entities": [{"text": "utterance classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.8405889868736267}]}, {"text": "These results indicate there are differences in user behavior and dialogue structure as a function of the computer's level of initiative.", "labels": [], "entities": []}, {"text": "Furthermore, they provide evidence that a spoken natural language dialogue system must be capable of varying its level of initiative in order to facilitate effective interaction with users of varying levels of expertise and experience.", "labels": [], "entities": []}, {"text": "1. Modeling Human-Computer Dialogue It is generally acknowledged that developing a successful computational model of interactive natural language (NL) dialogue requires extensive analysis of sample dialogues.", "labels": [], "entities": [{"text": "Modeling Human-Computer Dialogue", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.7876994609832764}, {"text": "interactive natural language (NL) dialogue", "start_pos": 117, "end_pos": 159, "type": "TASK", "confidence": 0.696799269744328}]}, {"text": "Previous work has included analyses of (1) human-human dialogues in relevant task domains; (2) Wizard-of-Oz dialogues in which a human (the Wizard) simulates the role of the computer as away of testing out an initial model; and (3) human-computer dialogues based on initial implementations of computational models.", "labels": [], "entities": []}, {"text": "Each of these dialogue types has advantages as a model for system building, in terms of the relevance of the data to the final model.", "labels": [], "entities": [{"text": "system building", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7602590918540955}]}, {"text": "However, each also has particular disadvantages when researchers attempt to generalize from the findings of previous work.", "labels": [], "entities": []}, {"text": "For example, much analysis of human-human interactions has been done, such as Walker and Whittaker's (1990) analysis of mixed initiative in dialogue, or Oviatt and Cohen's (1991) comparison of interactive and non-interactive spoken modalities.", "labels": [], "entities": []}, {"text": "Analyses of human-human dialogues area good basis for an initial task model and a lexicon, but it is difficult to determine which aspects of these analyses will generalize to human-computer dialogues and which ones will not.", "labels": [], "entities": []}, {"text": "Fraser and Gilbert (1991) note that \"although it is certainly better to rely on analyses of human-human interactions than to rely on intuitions alone, the fact remains that human-human interactions are not the same as human-computer interactions and it would be surprising if they followed precisely the same rules\" (p. 81).", "labels": [], "entities": []}, {"text": "In addition, Oviatt and Cohen (1991) say that \"...", "labels": [], "entities": []}, {"text": "to model discourse accurately for interactive systems further research clearly will be needed on the extent to which human-computer speech differs from that between humans.", "labels": [], "entities": []}, {"text": "At present, there is no well developed model of human-machine communi-Computational Linguistics Volume 23, Number 1 cation ...\"", "labels": [], "entities": []}, {"text": "The dilemma of researchers is nicely summarized by Fraser and Gilbert: \"The designer is caught in a vicious circle it is necessary to know the characteristics of dialogues between people and automata in order to be able to build the system, but it is impossible to know what such dialogues would be like until such a system has been built\" (p. 81).", "labels": [], "entities": []}, {"text": "Wizard-of-Oz (WOZ) dialogues result from an experimental technique that is one way of addressing this dilemma.", "labels": [], "entities": [{"text": "Wizard-of-Oz (WOZ) dialogues", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5796951055526733}]}, {"text": "In this methodology, human subjects are told they are interacting with a computer when they are really interacting with another human (the Wizard) who simulates the performance of the computer system.", "labels": [], "entities": []}, {"text": "In some simulations (e.g., Whittaker and Stenton [1989]), the Wizard simulates the entire system while in other cases (e.g., Dahlb~ick, J6nsson, and Ahrenberg [1993]), the Wizard makes use of partially implemented systems to assist in responding.", "labels": [], "entities": []}, {"text": "Consequently, many initial models can be prototyped and tested before implementation, and researchers need not have a fully developed natural language interface.", "labels": [], "entities": []}, {"text": "As other researchers have noted (Whittaker and Stenton 1989; Dahlback, J6nsson, and Ahrenberg 1993; Fraser and Gilbert 1991), when the WOZ simulations are convincing, they obtain data that area more accurate predictor of actual human-computer interaction than human-human dialogues because speakers adapt to the perceived characteristics of their conversational partners.", "labels": [], "entities": []}, {"text": "Consequently, WOZ studies can provide an indication of the types of adaptations that humans will make in human-computer interaction.", "labels": [], "entities": [{"text": "WOZ", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8430461883544922}]}, {"text": "WOZ studies such as the ones cited above have been particularly useful in obtaining data on discourse structure and contextual references.", "labels": [], "entities": []}, {"text": "The WOZ study of Moody (1988) on the effects of restricted vocabulary on interactive spoken dialogue provided the data that influenced the development of our own system.", "labels": [], "entities": [{"text": "WOZ study of Moody (1988)", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.9004844512258258}]}, {"text": "While much knowledge can be gained from WOZ studies, they are not an adequate means of studying all elements of human-computer natural language dialogue.", "labels": [], "entities": []}, {"text": "A simulation is feasible as long as humans can use their own problem-solving skills in carrying out the simulation, but when it requires mimicking a proposed algorithm, the WOZ technique becomes impractical.", "labels": [], "entities": [{"text": "WOZ", "start_pos": 173, "end_pos": 176, "type": "METRIC", "confidence": 0.5054507255554199}]}, {"text": "For example, it is difficult to simulate and test the computer's error recovery strategies for speech recognition or natural language understanding errors, because the natural language understanding of the computer is only a simulation.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.7206683158874512}, {"text": "speech recognition or natural language understanding errors", "start_pos": 95, "end_pos": 154, "type": "TASK", "confidence": 0.6832987836429051}]}, {"text": "If we wish to test an actual computational model for natural language processing, its complexity demands the construction of a computer program to execute it.", "labels": [], "entities": []}, {"text": "Furthermore, an important feature of dialogue that is difficult to simulate via the WOZ paradigm is that of initiative.", "labels": [], "entities": [{"text": "WOZ paradigm", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.7207445204257965}]}, {"text": "Depending on the interaction environment, dialogue initiative may reside with the computer, with the user, or may change during the interaction.", "labels": [], "entities": []}, {"text": "Lacking any formal models of initiative, it would be very difficult fora Wizard to accurately simulate the response patterns a computerized conversational participant would produce in a mixed-initiative dialogue fora nontrivial domain that would be consistent from subject to subject.", "labels": [], "entities": []}, {"text": "Unfortunately, we can also have difficulties generalizing from analyses of human-computer dialogues, because parameters of the particular system with which the dialogues were collected may have significantly affected the resulting dialogues.", "labels": [], "entities": []}, {"text": "For example, if a particular system is always run with a particular speech recognizer, it maybe difficult to determine what the outcome would have been with a better speech recognizer.", "labels": [], "entities": []}, {"text": "Similarly, most human-computer dialogues are collected from systems with a particular dialogue model.", "labels": [], "entities": []}, {"text": "Since it is well known that users adapt to the system, it will be unclear how the results from a particular set of human-computer dialogues generalize to a model of interaction based on a different dialogue model.", "labels": [], "entities": []}, {"text": "This paper reports work that attempts to address both of these dilemmas through the analysis of human-computer dialogues collected in an environment in which 142 Smith and Gordon Human-Computer Dialogue aspects of the system are parameterizable.", "labels": [], "entities": []}, {"text": "We have built an integrated dialogue-processing system, the Circuit Fix-It Shop, which is parameterized fora key system behavior: initiative.", "labels": [], "entities": []}, {"text": "1 We have tested the system in 141 dialogues totaling 2,840 user utterances while varying levels of system initiative.", "labels": [], "entities": []}, {"text": "The paper discusses our model of initiative and presents quantitative results from an analysis of our corpus on the effect of the computer's level of initiative on aspects of human-computer dialogue structure such as (1) utterance classification into subdialogues, (2) frequency of user-initiated subdialogue transitions, (3) regularity of subdialogue transitions, (4) frequency of linguistic control shifts, and (5) frequency of user-initiated error corrections.", "labels": [], "entities": [{"text": "utterance classification", "start_pos": 221, "end_pos": 245, "type": "TASK", "confidence": 0.7561970055103302}]}, {"text": "The results indicate there are differences in user behavior and dialogue structure as a function of the computer's level of initiative.", "labels": [], "entities": []}, {"text": "Furthermore, they provide evidence that a spoken natural language dialogue system must be capable of varying its level of initiative in order to facilitate effective interaction with users of varying levels of expertise and experience.", "labels": [], "entities": []}, {"text": "2. A Theory of Variable Initiative Dialogue In this section we review a theory presented in Smith and Hipp (1994).", "labels": [], "entities": []}, {"text": "It is important to note that our focus is on task-oriented dialogues, that is, dialogues whose purpose is to discuss a task whose completion is being carried out at the same time as the dialogue.", "labels": [], "entities": []}, {"text": "Consequently during the discussion, we make the distinction between linguistic goals and task goals.", "labels": [], "entities": []}, {"text": "Linguistic goals relate to speaker intentions in making statements (e.g., to inform, command, or request), while task goals relate to specific actions that need to be carried out in the domain of interest in order to complete the task (e.g., performing a voltage measurement).", "labels": [], "entities": []}, {"text": "As will be seen from the discussion, we take the approach that task initiative is assigned to the participant whose current task goals have priority, and the purpose of dialogue initiative is to indicate who has the task initiative.", "labels": [], "entities": []}, {"text": "2.1 Defining Variable Initiative and Dialogue Mode Variable initiative dialogue is dialogue in which: (1) either dialogue participant can have control of the dialogue, (2) control can vary between participants during the dialogue, and (3) intermediate levels of control are allowed.", "labels": [], "entities": []}, {"text": "A variable initiative dialogue system contrasts with other NL dialogue systems such as those described in Section 3.1 in which the dialogue is either purely user-controlled or purely computer-controlled.", "labels": [], "entities": []}, {"text": "In user-controlled dialogue systems the computer acts as a passive agent responding to user queries.", "labels": [], "entities": []}, {"text": "Question-answering systems are examples of user-controlled dialogue systems.", "labels": [], "entities": []}, {"text": "2 In computer-controlled dialogue systems, the user is totally dependent on the computer for accomplishment of the task.", "labels": [], "entities": []}, {"text": "The need for variable initiative dialogue arises because at some points during task completion a user may have sufficient knowledge to take control of the dialogue and accomplish several goals without much computer assistance while at other times, a user may need detailed assistance.", "labels": [], "entities": []}, {"text": "Thus, user initiative is characterized by giving priority to the user's goals of carrying out steps uninterrupted while computer initiative is characterized by giving priority to the specific goals of the computer.", "labels": [], "entities": []}, {"text": "In general, we have observed that the level of initiative that the computer has in the dialogue is 1 Smith and Hipp (1994) presents details about the overall computational model that forms the basis of the system.", "labels": [], "entities": []}, {"text": "2 While some question-answering systems can initiate clarifications to disambiguate user queries, the user remains in control of the overall interaction.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "While WOZ simulation of directive and passive modes is feasible, the requirements for algorithmically determining the relationship between user focus and the computer goal make WOZ simulations of suggestive and declarative modes very difficult, especially given the fast response time necessary for spoken interaction.", "labels": [], "entities": []}, {"text": "Before the construction of the Circuit Fix-It Shop, Moody (1988) conducted a Wizard-of-Oz study on the effects of restricted vocabulary on interactive spoken dialogue.", "labels": [], "entities": []}, {"text": "Her data were the basis for the formulation of the experimental Circuit Fix-It Shop system.", "labels": [], "entities": []}, {"text": "Although she attempted to acquire information concerning user behavior when users were given the initiative, she was unable to provide much information because her subjects did not interact with the system enough to evolve from novices to experts.", "labels": [], "entities": []}, {"text": "Her attempts to yield the initiative to users still led to statements that guided users step-by-step through the task.", "labels": [], "entities": []}, {"text": "By direct testing of a computer system that implements our proposed model of variable initiative dialogue, we could more rigorously control the system performance and more easily run repeated tests with subjects and allow them to gain task expertise.", "labels": [], "entities": []}, {"text": "Simultaneously, we could more readily monitor the effects of the change in initiative setting while holding other system features constant.", "labels": [], "entities": []}, {"text": "In testing our theory of variable initiative dialogue, there were two main types of phenomena we wished to examine: (1) general aspects of task efficiency, such as time to completion and number of utterances spoken; and (2) the nature of the dialogue structure.", "labels": [], "entities": []}, {"text": "Results on task efficiency are reported in detail in and are briefly reviewed in Section 6.1.", "labels": [], "entities": [{"text": "Section 6.1", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.8770310282707214}]}, {"text": "The primary contribution of this paper is to present an analysis of how the dialogue structure varies according to the computer's level of initiative.", "labels": [], "entities": []}, {"text": "After reviewing some details about the overall dialogue-processing model and its implementation, in Section 3, and a review of the experimental environment, in Section 4, the remainder of the paper focuses on the results of this analysis, a review of some related analyses, and some concluding remarks about the usefulness of the analysis and the role of experimental natural language dialogue systems in modeling 'human-computer dialogue.", "labels": [], "entities": []}, {"text": "The experimental design is discussed in great detail in and.", "labels": [], "entities": []}, {"text": "Here we present an overview of the experiment sufficient for understanding the environment in which the data were collected.", "labels": [], "entities": []}, {"text": "Figure 4 provides a rough sketch of the room layout.", "labels": [], "entities": []}, {"text": "The subject was seated facing the desk containing the circuit board.", "labels": [], "entities": []}, {"text": "Communication with the speech recognizer was performed through a telephone handset.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6860743463039398}]}, {"text": "The experimenter was seated in front of the computer console.", "labels": [], "entities": []}, {"text": "Thus, the subject's back was to the experimenter.", "labels": [], "entities": []}, {"text": "The experimenter had a copy of the raw data form for the session, a copy of the word list, and a guide describing the allowed experimenter interaction with the subject.", "labels": [], "entities": []}, {"text": "Data collection mechanisms consisted of the following: . Automatic logging of the words received from the speech recognizer (subject input) and the words sent to the DECtalk (computer output).", "labels": [], "entities": [{"text": "Data collection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7148934304714203}, {"text": "DECtalk", "start_pos": 166, "end_pos": 173, "type": "DATASET", "confidence": 0.9222017526626587}]}, {"text": "An important issue in experiments such as this, as has been observed elsewhere, is the problem of giving the subject sufficient error messages to enable satisfactory progress.", "labels": [], "entities": []}, {"text": "One major source of difficulty in this experiment were misrecognitions by the Verbex speech recognizer.", "labels": [], "entities": [{"text": "Verbex speech recognizer", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.7292112509409586}]}, {"text": "These miscommunications created various problems for the dialogue interaction, ranging from repetitive dialogue to experimenter intervention to occasional failure of the dialogue.", "labels": [], "entities": []}, {"text": "Whenever a serious misrecognition caused the computer to interpret the utterance in away that contradicted what was meant, the experimenter was allowed to (1) tell the subject that a misrecognition had occurred, and (2) tell the subject the interpretation made by the computer, but could say nothing else.", "labels": [], "entities": []}, {"text": "For example, when one subject said, \"the circuit is working,\" the speech recognizer returned the words \"faster it is working.\"", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.677079364657402}]}, {"text": "This was interpreted as the phrase faster.", "labels": [], "entities": []}, {"text": "Consequently, the experimenter told the subject, \"Due to misrecognition, your words came out as faster.\"", "labels": [], "entities": []}, {"text": "It is important to note that when an utterance was misunderstood, the experimenter did not tell the subject what to do, but merely described what happened.", "labels": [], "entities": []}, {"text": "In this way, the interaction was restricted to being between the computer and the subject as much as possible, given the quality of commercial, real-time, continuous speech recognition devices at the time of the experiment.", "labels": [], "entities": []}, {"text": "Such error messages from the experimenter occurred, on average, once every 15 user-utterances throughout the experiment.", "labels": [], "entities": []}, {"text": "The other main source of difficulty in using the system was the enforcement of the single utterance, turn-taking protocol of the interaction.", "labels": [], "entities": []}, {"text": "This required the user to signal the beginning of an utterance by speaking the sentinel word verbie and end the utterance with the word over.", "labels": [], "entities": []}, {"text": "Users would sometimes forget to use the sentinel words or else would not wait for the system's response that would occasionally be delayed up to 30 seconds (normal response time was 5 to 10 seconds).", "labels": [], "entities": []}, {"text": "In cases where the interaction protocol was violated, the experimenter would issue a warning statement such as, \"Please be patient.", "labels": [], "entities": []}, {"text": "The system is taking along time to respond,\" or \"Please remember to start utterances with verbie.\"", "labels": [], "entities": []}, {"text": "These types of experimenter interactions occurred, on average, once every 33 user-utterances.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4  Subdialogues initiated by each participant.", "labels": [], "entities": []}, {"text": " Table 6  Differences in linguistic control as a function of initiative.", "labels": [], "entities": []}, {"text": " Table 7  Differences in average number of utterances between control shifts.", "labels": [], "entities": []}]}