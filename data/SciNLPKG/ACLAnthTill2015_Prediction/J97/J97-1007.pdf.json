{"title": [{"text": "An Empirical Study on the Generation of Anaphora in Chinese", "labels": [], "entities": [{"text": "Generation of Anaphora", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.8216260671615601}]}], "abstractContent": [{"text": "The goal of this work is to study how to generate various kinds of anaphora in Chinese, including zero, pronominal, and nominal anaphora, from the syntactic and semantic representation of multisentential text.", "labels": [], "entities": []}, {"text": "In this research we confi'ne ourselves to descriptive texts.", "labels": [], "entities": []}, {"text": "We examine the occurrence of anaphora in human-generated text and those generated by a hypothetical computer equipped with anaphor generation rules, assuming that the computer can generate the same texts as the human except that anaphora are generated by the rules.", "labels": [], "entities": []}, {"text": "A sequence of rules using independently motivated linguistic constraints is developed until the results obtained are close to those in the real texts.", "labels": [], "entities": []}, {"text": "The best rule obtained for the choice of anaphor type makes use of the following conditions: locality between anaphor and antecedent, syntactic constraints on zero anaphora, discourse segment structures, salience of objects and animacy of objects.", "labels": [], "entities": []}, {"text": "We further establish a rule for choosing descriptions ira nominal anaphor is decided on.", "labels": [], "entities": []}, {"text": "We have implemented the above rules in a Chinese natural language generation system that is able to generate descriptive texts.", "labels": [], "entities": []}, {"text": "We sent some generated texts to a number of native speakers of Chinese and compared human-created results and computer-generated text to investigate the quality of the generated anaphora.", "labels": [], "entities": []}, {"text": "The results of the comparison show that the rules are fairly effective in dealing with the generation of anaphora in Chinese.", "labels": [], "entities": []}], "introductionContent": [{"text": "The field of natural language generation has made a great deal of progress in the generation of multisentential text in recent years).", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.6846333543459574}]}, {"text": "Most of the well-known systems first select and organize the message contents to be generated and then map the organized results into a sequence of surface sentences.", "labels": [], "entities": []}, {"text": "When mapping into the surface form, the selection of appropriate forms for anaphora is very important to make the generated text a cohesive unit.", "labels": [], "entities": []}, {"text": "In this paper, our goal is the computer generation of anaphora in Chinese.", "labels": [], "entities": []}, {"text": "In Chinese, anaphora can be classified as zero, pronominal, and nominal forms, as exemplified in (1) by ~, ta i 'he' and nage ren i 'that person', respectively.", "labels": [], "entities": []}, {"text": "1 Zero anaphora are generally noun phrases that are understood from the context and do not need to be specified.", "labels": [], "entities": []}, {"text": "In contrast, in this paper, we use the term nonzero anaphora to denote those that are specified in discourse, namely, pronominal and nominal anaphora.", "labels": [], "entities": []}, {"text": "Zhangsan i jinghuang de wang wai pao, Zhangsan frightened NOM towards outside run 'Zhangsan was frightened and ran outside.' b. ~ zhuangdao yige renJ, (he) bump-to a person '(He) bumped into a person.' c. ta i kanqing lena ren J de zhangxiang, he see-clear ASPECT that person GEN appearance 'He saw clearly that person's appearance.' d. oi 2 renchu na renJ shi shui.", "labels": [], "entities": []}, {"text": "(he) recognize that person is who '(He) recognized who that person is.'", "labels": [], "entities": []}, {"text": "This research starts with establishing possible rules for the generation of anaphora in Chinese.", "labels": [], "entities": []}, {"text": "Previous work suggests obtaining these rules from consulting the results of linguistic study, including general principles, such as the Gricean maxims used in () and focus theory, as used in.", "labels": [], "entities": []}, {"text": "A shortcoming of previous work is that it is unclear to what extent the resulting rules are effective in dealing with the generation of anaphora.", "labels": [], "entities": []}, {"text": "In an attempt to overcome this, we adopt an empirical approach to obtaining rules based on observations of real texts.", "labels": [], "entities": []}, {"text": "The basic methodology used is to start with a set of human-generated Chinese texts and the simplest possible anaphor generation rule (a rule that only considers the locality of anaphora).", "labels": [], "entities": []}, {"text": "We then progressively add extra tests to the rule, based on independently motivated but simple linguistic principles.", "labels": [], "entities": []}, {"text": "At each stage, we conduct experiments that compare the anaphora occurring in the human-generated text with those in the texts that would be generated by a computer taking the same syntactic and semantic content as the human texts and generating Chinese anaphora according to the rule being tested (this has to be simulated by hand).", "labels": [], "entities": []}, {"text": "This process continues until a rule with promising performance on the data is obtained.", "labels": [], "entities": []}, {"text": "The objective is thus to answer the question of how complex a rule must be to account for the complexity of anaphor generation exhibited by the test data.", "labels": [], "entities": []}, {"text": "This paper presents one sequence of rules developed using the above methodology and evaluates the effectiveness of the new linguistic principles taken into account at each point.", "labels": [], "entities": []}, {"text": "At present, we have chosen only one intuitively plausible way to generate increasingly complex rules, with refinements introduced as they occurred to us (though not motivated by the data).", "labels": [], "entities": []}, {"text": "Clearly the work could and should be extended to consider all possible combinations of the principles in all possible orders.", "labels": [], "entities": []}, {"text": "Except where noted below, the preselected Chinese data serves as an independent test of the effectiveness of the different rules, which are based on principles that have been independently suggested in the literature.", "labels": [], "entities": [{"text": "Chinese data", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.7559492290019989}]}, {"text": "However, the fact that the chosen data determine the termination condition for the development means that the rules could be overfitting the chosen data.", "labels": [], "entities": []}, {"text": "Therefore a selection of the rules have been implemented in a Chinese natural language generation system and their results are further evaluated by means of an experiment using native speakers.", "labels": [], "entities": [{"text": "Chinese natural language generation", "start_pos": 62, "end_pos": 97, "type": "TASK", "confidence": 0.5888254046440125}]}, {"text": "This paper concentrates on the use of zero, pronominal, and nominal anaphora in Chinese generated text.", "labels": [], "entities": []}, {"text": "We are not concerned with lexical anaphora", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we briefly describe the implementation of the rules in our Chinese natural language generation system.", "labels": [], "entities": [{"text": "Chinese natural language generation", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.5532383993268013}]}, {"text": "We then present an evaluation of the anaphora in some texts generated by our system.", "labels": [], "entities": []}, {"text": "The linguistic principles embodied in our rules were all independently proposed, so in some respects the previous data served as both training and test data in the development of the rules.", "labels": [], "entities": []}, {"text": "Furthermore, the assumed contextual information, for example, discourse structures, maybe difficult to access in areal implementation.", "labels": [], "entities": []}, {"text": "Thus, the performance of areal anaphor generation algorithm based on the rules proposed here maybe different from the experimental results we obtained.", "labels": [], "entities": [{"text": "areal anaphor generation", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6252477367719015}]}, {"text": "In this section, we attempt a post-evaluation by asking some native speakers of Chinese to judge the quality of the anaphora generated by areal system based on the rules.", "labels": [], "entities": []}, {"text": "Evaluation is becoming an increasingly important issue for natural language generation systems, though, unfortunately, there are still no generally accepted methods.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 59, "end_pos": 86, "type": "TASK", "confidence": 0.6628070771694183}]}, {"text": "In this work, we were particularly concerned to find a method of evaluation that reflected directly on the anaphor generation of the system (unlike \"black box\" evaluation of the kind we had done before [).", "labels": [], "entities": []}, {"text": "We were also wary of asking human subjects to estimate the \"readability\" or \"coherence\" of texts (though this seemed to work well for Acker and Porter).", "labels": [], "entities": []}, {"text": "In this evaluation, we chose three Chinese natural language generation systems to compare.", "labels": [], "entities": []}, {"text": "Each system is assumed to have the same system components, as described in Section 4.1, except that the referring expression component of each system is equipped with a different anaphor generation rule.", "labels": [], "entities": []}, {"text": "Given an input to a test system, anaphora in the resulting texts will be determined by the rule used in the referring expression component of the system.", "labels": [], "entities": []}, {"text": "The rules, TRi, i = 1 .....", "labels": [], "entities": [{"text": "TRi", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.993949294090271}]}, {"text": "3, used in the test systems are shown in.", "labels": [], "entities": []}, {"text": "TR1 corresponds to our Rule 2, together with an animacy test to distinguish between pronouns and nominal anaphora.", "labels": [], "entities": [{"text": "TR1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.6352406144142151}]}, {"text": "TR2 adds the constraint on discourse structure and TR3 adds to this the salience constraint (and is the same as Rule 5).", "labels": [], "entities": [{"text": "TR2", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8395509719848633}]}, {"text": "The intention was to test a range of rules and hence get an indication of how much better (if at all) the more sophisticated rules are than the simpler ones.", "labels": [], "entities": []}, {"text": "The evaluation task can be divided into an annotation stage and a comparison stage.", "labels": [], "entities": []}, {"text": "In the annotation stage, each of 12 native speakers of Chinese is given five test sheets corresponding to five texts generated by our generation system.", "labels": [], "entities": []}, {"text": "The numbers of clauses in the texts are 5, 12, 12, 21, and 34; the numbers of anaphora in the texts are 4, 11, 11, 20, and 34.", "labels": [], "entities": []}, {"text": "Each anaphor position in a generated text was left empty and all candidate forms of the anaphor, including zero, pronominal, and full and reduced descriptions were put under the empty space.", "labels": [], "entities": []}, {"text": "The speaker was asked to annotate which form he or she preferred for each anaphor position on the test sheets.", "labels": [], "entities": []}, {"text": "After the annotations were collected, we compared the speakers' results with the generated texts to investigate the performance of the test rules.", "labels": [], "entities": []}, {"text": "In each comparison, we noted down the number of matches between the computer-generated text and the human result.", "labels": [], "entities": []}, {"text": "This approach is the same as that used in for the problem of article generation, except that in our case we had to use generated, rather than naturally immedia?a~ng violating syntactic N constraints?", "labels": [], "entities": [{"text": "article generation", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7555844783782959}]}, {"text": "ye/\\o satisfying ' ~ Z an)/n~ criterion.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Result of using the preference rule on the test data.", "labels": [], "entities": []}, {"text": " Table 4  Average match rates between the results of test systems and native speakers.", "labels": [], "entities": [{"text": "match rates", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9556975960731506}]}]}