{"title": [{"text": "Discourse Segmentation by Human and Automated Means", "labels": [], "entities": [{"text": "Discourse Segmentation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6918399333953857}]}], "abstractContent": [{"text": "The need to model the relation between discourse structure and linguistic features of utterances is almost universally acknowledged in the literature on discourse.", "labels": [], "entities": []}, {"text": "However, there is only weak consensus on what the units of discourse structure are, or the criteria for recognizing and generating them.", "labels": [], "entities": []}, {"text": "We present quantitative results of a two-part study using a corpus of spontaneous, narrative monologues.", "labels": [], "entities": []}, {"text": "The first part of our paper presents a method for empirically validating multiutterance units referred to as discourse segments.", "labels": [], "entities": []}, {"text": "We report highly significant results of segmentations performed by naive subjects, where a commonsense notion of speaker intention is the segmentation criterion.", "labels": [], "entities": []}, {"text": "In the second part of our study, data abstracted from the subjects\" segmentations serve as a target for evaluating two sets of algorithms that use utterance features to perform segmentation.", "labels": [], "entities": []}, {"text": "On the first algorithm set, we evaluate and compare the correlation of discourse segmentation with three types of linguistic cues (referential noun phrases, cue words, and pauses).", "labels": [], "entities": [{"text": "discourse segmentation", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.751379668712616}]}, {"text": "We then develop a second set using two methods: error analysis and machine learning.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7292704880237579}]}, {"text": "Testing the new algorithms on anew data set shows that when multiple sources of linguistic knowledge are used concurrently, algorithm performance improves.", "labels": [], "entities": [{"text": "anew data set", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.789858897527059}]}], "introductionContent": [{"text": "Each utterance of a discourse contributes to the communicative import of preceding utterances, or constitutes the onset of anew unit of meaning or action that subsequent utterances may add to.", "labels": [], "entities": []}, {"text": "The need to model the relation between the structure of such units (referred to here as discourse segment structure) and linguistic features of utterances I is almost universally acknowledged in the literature on discourse.", "labels": [], "entities": []}, {"text": "However, natural language systems rarely exploit the relation between discourse segment structure and linguistic devices because there is very little data about how they constrain one another.", "labels": [], "entities": []}, {"text": "We have been engaged in a two-part study addressing this gap.", "labels": [], "entities": []}, {"text": "We report on a method for empirically validating discourse segments, and on our development and evaluation of algorithms to identify these segments from linguistic features of discourse.", "labels": [], "entities": []}, {"text": "We show that human subjects can reliably perform discourse segmentation using speaker intention as a criterion.", "labels": [], "entities": [{"text": "discourse segmentation", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.743236780166626}]}, {"text": "We also show that when multiple sources of linguistic knowledge are used (referential noun phrases, cue words, and pauses), algorithm performance approaches human performance.", "labels": [], "entities": []}, {"text": "The excerpt in illustrates the two aspects of discourse that our study addresses.", "labels": [], "entities": []}, {"text": "The first pertains to an abstract structure consisting of meaningful dis- ure 1--which describe how three boys come to the aid of another boy who fell off of a bike --are more closely related to one another than to those in the intervening segment Y--which describe the paddleball toy owned by one of the three boys.", "labels": [], "entities": []}, {"text": "The second discourse feature of interest is that the usage of a wide range of lexicogrammatical devices seems to constrain or be constrained by this more abstract structure.", "labels": [], "entities": []}, {"text": "Consider the interpretation of the referent of the boxed pronoun he in segment Z.", "labels": [], "entities": []}, {"text": "The referent of the underlined noun phrase one in segment Y is the most recently mentioned male referent: without the segmentation, the reasoning required to reject it in favor of the intended referent of he is quite complex.", "labels": [], "entities": []}, {"text": "However, segment Z begins with certain features that indicate a resumption of the speaker goals associated with segment X, such as the use of the phrase well anyway, and the repeated mention of the event of picking up the pears.", "labels": [], "entities": []}, {"text": "In terms of the segmentation shown here, the referents introduced in segment X are more relevant for interpreting the pronoun in segment Z.", "labels": [], "entities": []}, {"text": "Note also that cue words (italicized) explicitly mark the boundaries of all three segments.", "labels": [], "entities": []}, {"text": "Our work is motivated by the hypothesis that natural language technologies can more sensibly interpret discourse, and can generate more comprehensible discourse, if they take advantage of this interplay between segmentation and linguistic devices.", "labels": [], "entities": []}, {"text": "In Section 2, we give a brief overview of related work.", "labels": [], "entities": []}, {"text": "In Section 3, we present our analysis of segmentation data collected from a population of naive subjects.", "labels": [], "entities": []}, {"text": "Our results demonstrate an extremely significant pattern of agreement on segment boundaries.", "labels": [], "entities": []}, {"text": "In Section 4, we use boundaries abstracted from the data produced by our subjects to quantitatively evaluate algorithms for segmenting discourse.", "labels": [], "entities": []}, {"text": "In Section 4.1, we discuss the coding and evaluation methods.", "labels": [], "entities": []}, {"text": "In Section 4,2, we test an initial set of algorithms for computing segment boundaries from a particular type of linguistic feature, either referential noun phrases, cue phrases, or pauses.", "labels": [], "entities": []}, {"text": "In Section 4.3.1, we analyze the errors of our initial algorithms in order to identify a set of enriched input features, and to determine how to combine information from the three linguistic knowledge sources.", "labels": [], "entities": []}, {"text": "In Section 4.3.2, we use machine learning to automatically construct segmentation algorithms from large feature sets.", "labels": [], "entities": []}, {"text": "Our results suggest that it is possible to approach human levels of performance, given multiple knowledge sources.", "labels": [], "entities": []}, {"text": "In Section 5, we discuss the significance of our results and briefly highlight our current directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "by quantifying their performance in segmenting a test set of 10 narratives from our corpus.", "labels": [], "entities": []}, {"text": "As discussed above, there is no training data for the algorithms in this section, which are derived from the literature.", "labels": [], "entities": []}, {"text": "These initial results provide us with a baseline for quantifying improvements resulting from distinct modifications to the algorithms.", "labels": [], "entities": []}, {"text": "In contrast, the algorithms presented in section 4.3 are developed using the 10 narratives previously used for testing as a training set of narratives.", "labels": [], "entities": []}, {"text": "The algorithms in this section are developed by tuning the previous algorithms (e.g., by considering both new and modified linguistic features) such that performance on the training set is increased.", "labels": [], "entities": []}, {"text": "The resulting algorithms are then evaluated by examining their performance on a separate test set of 5 more narratives.", "labels": [], "entities": []}, {"text": "(The remaining 5 of the 20 narratives in the corpus are reserved for future research.)", "labels": [], "entities": []}, {"text": "The 10 training narratives range in length from 51 to 162 phrases (Avg.=101.4), or from 38 to 121 clauses (Avg.=76.8).", "labels": [], "entities": [{"text": "Avg.", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9347495436668396}]}, {"text": "The 5 test narratives range in length from 47 to 113 phrases (Avg.=87.4), or from 37 to 101 clauses (Avg.=69.0).", "labels": [], "entities": [{"text": "Avg.", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9655819535255432}, {"text": "Avg.", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9462888240814209}]}, {"text": "The ratios of test to training data measured in narratives, prosodic phrases, and clauses, respectively, are 50.0%, 43.1%, and 44.9%.", "labels": [], "entities": []}, {"text": "For the machine learning algorithm we also estimate performance using cross-validation, as detailed in Section 4.3.2.", "labels": [], "entities": []}, {"text": "The evaluations in this section allow us to compare the utility of two tuning methods: error analysis, and machine learning.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.7712830603122711}]}, {"text": "To quantify algorithm performance, we use the information retrieval metrics shown in.", "labels": [], "entities": []}, {"text": "Recall is the ratio of correctly hypothesized boundaries to target boundaries.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9771085977554321}]}, {"text": "Precision is the ratio of hypothesized boundaries that are correct to the total hypothesized boundaries.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.990375816822052}]}, {"text": "(See for fallout and error.)", "labels": [], "entities": [{"text": "error", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.9583925604820251}]}, {"text": "These metrics assume that ideal behavior would be to identify all and only the target boundaries: the values for band c in would thus both equal 0, representing no errors, u The ideal values for recall, precision, fallout, and error are 1, 1, 0, and 0, while the worst values are 0, 0, 1, and 1.", "labels": [], "entities": [{"text": "recall", "start_pos": 195, "end_pos": 201, "type": "METRIC", "confidence": 0.9986234903335571}, {"text": "precision", "start_pos": 203, "end_pos": 212, "type": "METRIC", "confidence": 0.9971023201942444}, {"text": "error", "start_pos": 227, "end_pos": 232, "type": "METRIC", "confidence": 0.9695374965667725}]}, {"text": "To get an intuitive summary of overall performance, we also sum the deviation of the observed value from the ideal value for each metric: (1 -recall) + (1-precision) + fallout + error.", "labels": [], "entities": [{"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.8243823647499084}, {"text": "error", "start_pos": 178, "end_pos": 183, "type": "METRIC", "confidence": 0.8751141428947449}]}, {"text": "The summed deviation for perfect performance is thus 0.", "labels": [], "entities": []}, {"text": "Finally, to interpret our quantitative results, we use the performance of our human subjects as a target for the performance of our algorithms (Gale, Church, and Yarowsky 1992).", "labels": [], "entities": []}, {"text": "shows the average human performance for both the training and test sets of narratives, for both boundaries identified by at least three and four subjects.", "labels": [], "entities": []}, {"text": "Note that human performance is basically the same for both sets of narratives.", "labels": [], "entities": []}, {"text": "However, two factors prevent this performance from being closer to ideal (e.g., recall and precision of 1).", "labels": [], "entities": [{"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9997879862785339}, {"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9985070824623108}]}, {"text": "The first is the wide variation in the number of boundaries that subjects used, as discussed above.", "labels": [], "entities": []}, {"text": "The second is the inherently fuzzy nature of boundary location.", "labels": [], "entities": []}, {"text": "We discuss this second issue at length in.", "labels": [], "entities": []}, {"text": "In Litman and Passonneau (1995b), we also present relaxed IR metrics that penalize near misses less heavily (cases where an algorithm does not place a boundary at a statistically validated boundary location, but does place one within one phrase of the validated boundary).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Matrix representation of boundary data.", "labels": [], "entities": []}, {"text": " Table 2  Krippendorff's a comparing boundaries derived from two  sets of 4 subjects on 4 narratives.", "labels": [], "entities": []}, {"text": " Table 3  Average human performance.", "labels": [], "entities": []}, {"text": " Table 4  Evaluation for Tj >_ 4.", "labels": [], "entities": []}, {"text": " Table 6  Performance on training set.", "labels": [], "entities": []}, {"text": " Table 7  Performance on test set.", "labels": [], "entities": []}, {"text": " Table 9  Performance on test set.", "labels": [], "entities": []}]}