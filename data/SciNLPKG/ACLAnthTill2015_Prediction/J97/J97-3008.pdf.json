{"title": [{"text": "The Human Semantic Potential: Spatial Language and Constrained Connectionism", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "One of the implications of connectionist work on language is that the \"language mechanism\" is not essentially different from mechanisms that perform other cognitive tasks.", "labels": [], "entities": []}, {"text": "This leads naturally to the notion that language learning must be understood in the context of learning about the world more generally.", "labels": [], "entities": []}, {"text": "It is difficult to think of how to constrain a modeling exercise that adopts this perspective, for such a system requires an encoding not only of some interesting part of language but also of the corresponding part of \"the world.\"", "labels": [], "entities": []}, {"text": "If one were to undertake this rather daunting task, a natural place to start would be with a subdomain of language in which the important semantic contrasts can be expressed in a two-dimensional visual world and to use low-resolution computer graphics for the encoding of this world.", "labels": [], "entities": []}, {"text": "In The Human Semantic Potential, Regier takes precisely this approach, by focusing on the domain of closed-class spatial markers (e.g., prepositions such as above, below, left, right, in, and on in English).", "labels": [], "entities": []}, {"text": "Bit map \"movies\" of a trajector that moves in relation to a landmark for several movie frames, or that simply exists, are used as the input to a connectionist learning model; the outputs are labels corresponding to prepositions.", "labels": [], "entities": []}, {"text": "The scientific game plan is to construct a model that learns the semantics of spatial markers on the basis of exposure to examples in a given language; the learnable sets of markers under the model then constitute a typology of possible sets of spatial markers in languages of the world.", "labels": [], "entities": []}, {"text": "Thus the model makes cross-linguistic typological predictions.", "labels": [], "entities": []}, {"text": "Moreover, since the model generalizes from a subset of examples in each language to an assessment of the aptness of each word in all representable conditions, it makes language-internal predictions about the meanings that particular spatial markers can have.", "labels": [], "entities": []}, {"text": "Given this framework, it seems reasonable to assess the project in terms of how much we learn about these two domains of prediction from it.", "labels": [], "entities": []}, {"text": "In the former case--cross-linguistic typological prediction--the results are only mildly interesting: only a very small subset of the range of predictions that the model makes is revealed, apparently because of the assumed unanalyzability of the connectionist network at the core of the model.", "labels": [], "entities": [{"text": "cross-linguistic typological prediction", "start_pos": 20, "end_pos": 59, "type": "TASK", "confidence": 0.6207806964715322}]}, {"text": "In the case of the second task--generalization from positive examples--the results are more appealing: Regier shows how a linguistically-motivated variation on a standard connectionist learning algorithm provides an effective mechanism for generalizing in the absence of negative evidence.", "labels": [], "entities": []}, {"text": "I'll elaborate on these two assessments after providing a summary of the contents.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}