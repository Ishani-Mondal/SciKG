{"title": [{"text": "Individuality-preserving Voice Conversion for Articulation Disorders Using Dictionary Selective Non-negative Matrix Factorization", "labels": [], "entities": [{"text": "Individuality-preserving Voice Conversion", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6935843825340271}]}], "abstractContent": [{"text": "We present in this paper a voice conversion (VC) method fora person with an ar-ticulation disorder resulting from athetoid cerebral palsy.", "labels": [], "entities": [{"text": "voice conversion (VC)", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.8392122268676758}]}, {"text": "The movements of such speakers are limited by their athetoid symptoms, and their consonants are often unstable or unclear, which makes it difficult for them to communicate.", "labels": [], "entities": []}, {"text": "In this paper, exemplar-based spectral conversion using Non-negative Matrix Factor-ization (NMF) is applied to a voice with an articulation disorder.", "labels": [], "entities": [{"text": "exemplar-based spectral conversion", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.6018974582354227}, {"text": "Non-negative Matrix Factor-ization (NMF)", "start_pos": 56, "end_pos": 96, "type": "METRIC", "confidence": 0.7307838201522827}]}, {"text": "In order to preserve the speaker's individuality, we use a combined dictionary that was constructed from the source speaker's vowels and target speaker's consonants.", "labels": [], "entities": []}, {"text": "However, this exemplar-based approach needs to holdall the training exemplars (frames), and it may cause mismatching of phonemes between input signals and selected ex-emplars.", "labels": [], "entities": []}, {"text": "In this paper, in order to reduce the mismatching of phoneme alignment , we propose a phoneme-categorized sub-dictionary and a dictionary selection method using NMF.", "labels": [], "entities": [{"text": "phoneme alignment", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7427811622619629}]}, {"text": "The effectiveness of this method was confirmed by comparing its effectiveness with that of a conventional Gaussian Mixture Model (GMM)-based and conventional NMF-based method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this study, we focused on a person with an articulation disorder resulting from the athetoid type of cerebral palsy.", "labels": [], "entities": []}, {"text": "About two babies in 1,000 are born with cerebral palsy.", "labels": [], "entities": []}, {"text": "Cerebral palsy results from damage to the central nervous system, and the damage causes movement disorders.", "labels": [], "entities": []}, {"text": "Cerebral palsy is classified into the following types: 1)spastic, 2)athetoid, 3)ataxic, 4)atonic, 5)rigid, and a mixture of these types).", "labels": [], "entities": [{"text": "spastic", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9847033619880676}]}, {"text": "Athetoid symptoms develop in about 10-15% of cerebral palsy sufferers ().", "labels": [], "entities": [{"text": "Athetoid", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9608325362205505}]}, {"text": "In the case of a person with this type of articulation disorder, his/her movements are sometimes more unstable than usual.", "labels": [], "entities": []}, {"text": "That means their utterances (especially their consonants) are often unstable or unclear due to the athetoid symptoms.", "labels": [], "entities": []}, {"text": "Athetoid symptoms also restrict the movement of their arms and legs.", "labels": [], "entities": []}, {"text": "Most people suffering from athetoid cerebral palsy cannot communicate by sign language or writing, so there is great need for voice systems for them.", "labels": [], "entities": []}, {"text": "In this paper, we propose a voice conversion (VC) method for articulation disorders.", "labels": [], "entities": [{"text": "voice conversion (VC)", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.8456471562385559}]}, {"text": "Regarding speech recognition for articulation disorders, the recognition rate using a speaker-independent model which is trained by well-ordered speech, is 3.5% ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7352218776941299}]}, {"text": "This result implies that the utterance of a person with an articulation disorder is difficult to understand for people who have not communicated with them before.", "labels": [], "entities": []}, {"text": "In recent years, people with an articulation disorder may use slideshows and a previously synthesized voice when they give a lecture.", "labels": [], "entities": []}, {"text": "However, because their movement is restricted by their athetoid symptoms, to make slides or synthesize their voice in advance is hard for them.", "labels": [], "entities": []}, {"text": "People with articulation disorders desire a VC system that converts their voice into a clear voice that preserves their voice's individuality.", "labels": [], "entities": []}, {"text": "Rudzicz et al. proposed speech adjustment method for people with articulation disorders based on the observations from the database.", "labels": [], "entities": [{"text": "speech adjustment", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7017486393451691}]}, {"text": "In (), we proposed individuality-preserving VC for articulation disorders.", "labels": [], "entities": []}, {"text": "In our VC, source exemplars and target exemplars are extracted from the parallel 29 training data, having the same texts uttered by the source and target speakers.", "labels": [], "entities": []}, {"text": "The input source signal is expressed with a sparse representation of the source exemplars using.", "labels": [], "entities": []}, {"text": "By replacing a source speaker's exemplar with a target speaker's exemplar, the original speech spectrum is replaced with the target speaker's spectrum.", "labels": [], "entities": []}, {"text": "People with articulation disorders wish to communicate by their own voice if they can; therefore, we proposed a combined-dictionary, which consists of a source speaker's vowels and target speaker's well-ordered consonants.", "labels": [], "entities": []}, {"text": "In the voice of a person with an articulation disorder, their consonants are often unstable and that makes their voices unclear.", "labels": [], "entities": []}, {"text": "Their vowels are relatively stable compared to their consonants.", "labels": [], "entities": []}, {"text": "Hence, by replacing the articulation-disordered basis of consonants only, a voice with an articulation disorder is converted into a non-disordered voice that preserves the individuality of the speaker's voice.", "labels": [], "entities": []}, {"text": "In this paper, we propose advanced individuality-preserving VC using NMF.", "labels": [], "entities": []}, {"text": "In order to avoid a mixture of the source and target spectra in a converted phoneme, we applied a phoneme-categorized dictionary and a dictionary selection method to our VC using NMF.", "labels": [], "entities": []}, {"text": "In conventional NMF-based VC, the number of dictionary frames becomes large because the dictionary holds all the training exemplar frames.", "labels": [], "entities": []}, {"text": "Therefore, it may cause phoneme mismatching between input signals and selected exemplars and some frames of converted spectra might be mixed with the source and target spectra.", "labels": [], "entities": []}, {"text": "In this paper, a training exemplar is divided into a phonemecategorized sub-dictionary, and an input signal is converted by using the selected sub-dictionary.", "labels": [], "entities": []}, {"text": "The effectiveness of this method was confirmed by comparing it with a conventional NMF-based method and a conventional Gaussian Mixture Model (GMM)-based method.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: In Section 2, related works are introduced.", "labels": [], "entities": []}, {"text": "In Section 3, the basic idea of NMF-based VC is described.", "labels": [], "entities": [{"text": "NMF-based VC", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.7037026286125183}]}, {"text": "In Section 4, our proposed method is described.", "labels": [], "entities": []}, {"text": "In Section 5, the experimental data are evaluated, and the final section is devoted to our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed VC technique was evaluated by comparing it with the conventional NMF-based method () (referred to as the \"sample-based method\" in this paper) and the conventional GMM-based method () using clean speech data.", "labels": [], "entities": []}, {"text": "We recorded 432 utterances (216 words, each repeated two times) included in the ATR Japanese speechdatabase ().", "labels": [], "entities": [{"text": "ATR Japanese speechdatabase", "start_pos": 80, "end_pos": 107, "type": "DATASET", "confidence": 0.9268280069033304}]}, {"text": "The speech signals were sampled at 12 kHz and windowed with a 25-msec Hamming window every 10 msec.", "labels": [], "entities": []}, {"text": "A physically unimpaired Japanese male in the ATR Japanese speech database, was chosen as a target speaker.", "labels": [], "entities": [{"text": "ATR Japanese speech database", "start_pos": 45, "end_pos": 73, "type": "DATASET", "confidence": 0.9315443783998489}]}, {"text": "In the proposed and sample-based methods, the number of dimensions of the spectral feature is 2,565.", "labels": [], "entities": []}, {"text": "It consists of a 513-dimensional STRAIGHT spectrum () and its consecutive frames (the 2 frames coming before and the 2 frames coming after).", "labels": [], "entities": [{"text": "STRAIGHT", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.8816187977790833}]}, {"text": "The Gaussian mixture, which is used to construct a categorizing-dictionary, is 1/500 of the number of bases of each sub-dictionary.", "labels": [], "entities": []}, {"text": "The number of iterations for estimating the activity in the proposed and sample-based methods was 300.", "labels": [], "entities": []}, {"text": "In the conventional GMM-based method, MFCC+\u2206MFCC+\u2206\u2206MFCC is used as a spectral feature.", "labels": [], "entities": []}, {"text": "Its number of dimensions is 74.", "labels": [], "entities": []}, {"text": "The number of Gaussian mixtures is set to 64, which is experimentally selected.", "labels": [], "entities": []}, {"text": "In this paper, F0 information is converted using a conventional linear regression based on the mean and standard deviation (.", "labels": [], "entities": [{"text": "F0", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.7879553437232971}]}, {"text": "The other information such as aperiodic components, is synthesized without any conversion.", "labels": [], "entities": []}, {"text": "We conducted a subjective evaluation of 3 topics.", "labels": [], "entities": []}, {"text": "A total of 10 Japanese speakers took part in the test using headphones.", "labels": [], "entities": []}, {"text": "For the \"listening intelligibility\" evaluation, we performed a MOS (Mean Opinion Score) test.", "labels": [], "entities": [{"text": "MOS (Mean Opinion Score) test", "start_pos": 63, "end_pos": 92, "type": "METRIC", "confidence": 0.8719687461853027}]}, {"text": "The opinion score was set to a 5-point scale (5: excellent, 4: good, 3: fair, 2: poor, 1: bad).", "labels": [], "entities": []}, {"text": "Twenty-two words that are difficult fora person with an articulation disorder to utter were evaluated.", "labels": [], "entities": []}, {"text": "The subjects were asked about the listening intelligibility in the articulation-disordered voice, the voice converted by our proposed method, and the GMMbased converted voice.", "labels": [], "entities": [{"text": "GMMbased converted voice", "start_pos": 150, "end_pos": 174, "type": "DATASET", "confidence": 0.8979505697886149}]}, {"text": "On the \"similarity\" evaluation, the XAB test was carried out.", "labels": [], "entities": [{"text": "similarity", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.978520393371582}, {"text": "XAB", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9796285033226013}]}, {"text": "In the XAB test, each subject listened to the articulation-disordered voice.", "labels": [], "entities": []}, {"text": "Then the subject listened to the voice converted by the two methods and selected which sample sounded most similar to the articulation-disordered voice.", "labels": [], "entities": []}, {"text": "On the \"naturalness\" evaluation, a paired comparison test was carried out, where each subject listened to pairs of speech converted by the two methods and selected which sample sounded more natural.", "labels": [], "entities": []}, {"text": "show examples of converted spectrograms using our proposed method and the conventional GMM-based method, respectively.", "labels": [], "entities": []}, {"text": "In, there are fewer misconversions in the vowel part compared to.", "labels": [], "entities": []}, {"text": "Moreover, by using GMM-based conversion, the area labeled \"oi\" becomes unclear compared to NMF-based conversion.", "labels": [], "entities": []}, {"text": "shows the results of the MOS test for listening intelligibility.", "labels": [], "entities": [{"text": "MOS", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.6266065835952759}]}, {"text": "The error bars show a 95% confidence score; thus, our proposed VC method is shown to be able to improve the listening intelligibility and clarity of consonants.", "labels": [], "entities": [{"text": "clarity", "start_pos": 138, "end_pos": 145, "type": "METRIC", "confidence": 0.9726319313049316}]}, {"text": "On the other hand, GMM-based conversion can improve the clarity of consonants, but it deteriorates the listening intelligibility.", "labels": [], "entities": [{"text": "GMM-based conversion", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.6815999895334244}, {"text": "clarity", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9625430703163147}]}, {"text": "This is because GMM-based conversion has the effect of noise resulting from measurement error.", "labels": [], "entities": []}, {"text": "Our proposed VC method also has the effect of noise, but it is less than that created by GMM-based conversion.", "labels": [], "entities": []}, {"text": "shows the results of the XAB test on the similarity to the source speaker and naturalness of the converted voice.", "labels": [], "entities": [{"text": "XAB", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.5534980893135071}]}, {"text": "The error bars show a 95% confidence score.", "labels": [], "entities": [{"text": "confidence", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9745845794677734}]}, {"text": "Our proposed VC method obtained a higher score than Sample-based and GMM-based conversion on similarity.", "labels": [], "entities": []}, {"text": "shows the preference score on the naturalness.", "labels": [], "entities": []}, {"text": "The error bars show a 95% confidence score.", "labels": [], "entities": [{"text": "confidence", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9745845794677734}]}, {"text": "Our proposed VC also method obtained a higher score than Sample-based and GMM-based conversion methods in regard to naturalness.", "labels": [], "entities": []}], "tableCaptions": []}