{"title": [{"text": "A Demonstration of Dialogue Processing in SimSensei Kiosk", "labels": [], "entities": [{"text": "Dialogue Processing", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7333109974861145}]}], "abstractContent": [{"text": "This demonstration highlights the dialogue processing in SimSensei Kiosk, a virtual human dialogue system that conducts interviews related to psychological distress conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD).", "labels": [], "entities": [{"text": "dialogue processing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8209766447544098}]}, {"text": "The dialogue processing in Sim-Sensei Kiosk allows the system to conduct coherent spoken interviews of human users that are 15-25 minutes in length, and in which users feel comfortable talking and openly sharing information.", "labels": [], "entities": []}, {"text": "We present the design of the individual dialogue components, and show examples of natural conversation flow between the system and users, including expressions of empathy, follow-up responses and continuation prompts, and turn-taking.", "labels": [], "entities": []}], "introductionContent": [{"text": "This demonstration highlights the dialogue processing in SimSensei Kiosk, a virtual human dialogue system that conducts interviews related to psychological distress conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD)).", "labels": [], "entities": [{"text": "dialogue processing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8215185403823853}]}, {"text": "SimSensei Kiosk has two main functions -a virtual human called Ellie (pictured in), who converses with a user in a spoken, semi-structured interview, and a multimodal perception system which analyzes the user's behavior in real time to identify indicators of psychological distress.", "labels": [], "entities": []}, {"text": "The system has been designed and developed over two years using a series of face-toface, Wizard-of-Oz, and automated system studies involving more than 350 human participants ().", "labels": [], "entities": []}, {"text": "Agent design has been guided by two overarching goals: (1) the agent should make the user feel comfortable talking and openly sharing information, and at the same time (2) the agent should create interactional situations that support the automatic assessment of verbal and nonverbal behaviors correlated with psychological distress.", "labels": [], "entities": []}, {"text": "During an interview, the agent presents a set of questions which have been shown in user testing to support these goals.", "labels": [], "entities": []}, {"text": "Since the main interview questions and their order are mostly fixed, dialogue management concentrates on providing appropriate verbal feedback behaviors to keep the user engaged, maintain a natural and comfortable conversation flow, and elicit continuations and elaborations from the user.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7929492592811584}]}, {"text": "The agent is implemented using a modular architecture (.", "labels": [], "entities": []}, {"text": "Dialogue processing, which is the focus of this demonstration, is supported by individual modules for speech recognition, language understanding and dialogue management (see Section 2).", "labels": [], "entities": [{"text": "Dialogue processing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8460714817047119}, {"text": "speech recognition", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7740676999092102}, {"text": "language understanding", "start_pos": 122, "end_pos": 144, "type": "TASK", "confidence": 0.7602232694625854}, {"text": "dialogue management", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.8357299268245697}]}, {"text": "The agent's language and speech are executed by selecting from pre-recorded audio clips.", "labels": [], "entities": []}, {"text": "Additional agent modules include nonverbal behavior generation, which matches appropriately timed body movements to the agent's speech; character animation in a virtual 3D environment; and rendering in a game en-254 gine.", "labels": [], "entities": [{"text": "nonverbal behavior generation", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.7020816008249918}, {"text": "character animation", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.8166305720806122}]}, {"text": "The perception system analyzes audio and video in real time to identify features such as head position, gaze direction, smile intensity, and voice quality.", "labels": [], "entities": []}, {"text": "provides details on all the agent's modules.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}