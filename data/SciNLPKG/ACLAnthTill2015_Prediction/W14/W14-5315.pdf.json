{"title": [{"text": "Exploring Methods and Resources for Discriminating Similar Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "The Discriminating between Similar Languages (DSL) shared task at VarDial challenged participants to build an automatic language identification system to discriminate between 13 languages in 6 groups of highly-similar languages (or national varieties of the same language).", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.7121841973728604}, {"text": "VarDial", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.8266975283622742}]}, {"text": "In this paper, we describe the submissions made by team UniMelb-NLP, which took part in both the closed and open categories.", "labels": [], "entities": []}, {"text": "We present the text representations and modeling techniques used, including cross-lingual POS tagging as well as fine-grained tags extracted from a deep grammar of English, and discuss additional data we collected for the open submissions, utilizing custom-built web corpora based on top-level domains as well as existing corpora.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 90, "end_pos": 101, "type": "TASK", "confidence": 0.668004035949707}]}], "introductionContent": [{"text": "Language identification (LangID) is the problem of determining what natural language a document is written in.", "labels": [], "entities": [{"text": "Language identification (LangID)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8231986582279205}]}, {"text": "Studies in the area often report high accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9994083642959595}]}, {"text": "However, recent work has shown that high accuracy is only achieved under ideal conditions (, and one area that needs further work is accurate discrimination between closely-related languages).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.997880220413208}]}, {"text": "The problem has been explored for specific groups of confusable languages, such as Malay/Indonesian (), South-Eastern European languages (, as well as varieties of English (,, and Spanish ().", "labels": [], "entities": []}, {"text": "The Discriminating Similar Language (DSL) shared task ( ) was hosted at the VarDial workshop at COLING 2014, and brings together the work on these various language groups by proposing a task on a single dataset containing text from 13 languages in 6 groups, drawn from a variety of news text datasets ( . In this paper, we describe the entries made by team UniMelb NLP to the DSL shared task.", "labels": [], "entities": [{"text": "Discriminating Similar Language (DSL) shared task", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.7107884958386421}, {"text": "VarDial workshop at COLING 2014", "start_pos": 76, "end_pos": 107, "type": "DATASET", "confidence": 0.7075653672218323}, {"text": "DSL shared task", "start_pos": 376, "end_pos": 391, "type": "TASK", "confidence": 0.5726734598477682}]}, {"text": "We took part in both the closed and the open categories, submitting to the main component (Groups A-E) as well as the separate English component (Group F).", "labels": [], "entities": []}, {"text": "For our closed submissions, we focused on comparing a conventional LangID methodology based on individual words and language-indicative letter sequences (Section 2.1) to a methodology that uses a de-lexicalized representation of language (Section 2.3).", "labels": [], "entities": []}, {"text": "For Groups A-E we use cross-lingual POS-tagger adaptation (Section 2.3.1) to convert the raw text to a POS stream using a per-group tagger, and use n-grams of POS tags as our de-lexicalized representation.", "labels": [], "entities": []}, {"text": "For English, we also use a de-lexicalized representation based on lexical types extracted from a deep grammar (Section 2.3.2), which can bethought of as a very fine-grained tagset.", "labels": [], "entities": []}, {"text": "For the open submissions, we constructed new web-based corpora using a standard methodology, targeting per-language top-level domains (Section 2.4.2).", "labels": [], "entities": []}, {"text": "We also compiled additional training data from existing corpora (Section 2.4.1).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Word count of training data used for open submissions.", "labels": [], "entities": [{"text": "Word count", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8765337467193604}]}, {"text": " Table 4: Summary of the official runs submitted by UniMelbNLP. \"dev\" indicates scores from our  internal testing on the development partition of the dataset.", "labels": [], "entities": []}, {"text": " Table 5: Top 10 POS features per-group by Information Gain, along with percentage of sentences in each  language in which the feature appears. The notation used is as follows: . = punctuation, J = adjective,  P = pronoun, R = adverb, C = conjunction, D = determiner/article, N = noun, 1 = numeral, H = pronoun,  T = particle, V = verb, and X = others", "labels": [], "entities": []}]}