{"title": [{"text": "A Simple Baseline for Discriminating Similar Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes an approach to discriminating similar languages using word-and character-based features, submitted as the Queen Mary University of London entry to the Discriminating Similar Languages shared task.", "labels": [], "entities": [{"text": "Queen Mary University of London entry", "start_pos": 127, "end_pos": 164, "type": "DATASET", "confidence": 0.8126582304636637}, {"text": "Discriminating Similar Languages shared task", "start_pos": 172, "end_pos": 216, "type": "TASK", "confidence": 0.781734824180603}]}, {"text": "Our motivation was to investigate how well a simple, data-driven, linguistically naive method could perform, in order to provide a baseline by which more linguistically complex or knowledge-rich approaches can be judged.", "labels": [], "entities": []}, {"text": "Using a standard supervised classifier with word and character n-grams as features, we achieved over 90% accuracy in the test; on fixing simple file handling and feature extraction bugs, this improved to over 95%, comparable to the best submitted systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9994727969169617}]}, {"text": "Similar accuracy is achieved using only word unigram features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9990767240524292}]}], "introductionContent": [], "datasetContent": [{"text": "Development We used 10-fold cross-validation on the training set, and testing on the development set, to choose a suitable SVM cost parameter (tradeoff between error and maximum margin criterion).", "labels": [], "entities": [{"text": "error and maximum margin criterion", "start_pos": 160, "end_pos": 194, "type": "METRIC", "confidence": 0.7346661448478699}]}, {"text": "We cross-validated over the training set to check overall multi-class accuracy while varying the cost over a range from 1 to 100 -see.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9954178333282471}]}, {"text": "We then trained on the full training set, and tested accuracy on the development across each language group -see.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9994403719902039}]}, {"text": "Given reported problems with the group F dataset (en-UK/en-US), we focussed on groups A-E.", "labels": [], "entities": [{"text": "group F dataset", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.5950214664141337}]}, {"text": "A cost parameter value of 30 to 50 appeared to perform best across all groups, so these two values were used for separate runs in the shared task test.", "labels": [], "entities": []}, {"text": "Note though that performance appears relatively stable over a cost range of 10-100 (perhaps 30-100 for group E).", "labels": [], "entities": []}, {"text": "The classifier performs worst for group E (es-AR/es-ES), with only this language group failing to reach 90% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.98785001039505}]}, {"text": "Group C (cz/sk) performs best with almost perfect accuracy; this maybe due to the existence of characters which are highly discriminative on their own (e.g. \u02c6 o is used in Slovak, but not in Czech, \u02da u in Czech but not in Slovak -although a few dozen examples appear labelled as Slovak in this dataset).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.998988926410675}]}, {"text": "Test -Shared Task A blind run on the test set was then performed and submitted as part of the shared task.", "labels": [], "entities": []}, {"text": "Overall accuracy was 90.61% (macro-averaged F-score 92.51%), placing us 5 th amongst the task entrants; results per group are shown in: Accuracy on test set as submitted for the shared task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9996590614318848}, {"text": "F-score", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9123287200927734}, {"text": "Accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9923664927482605}]}, {"text": "Corrected Test However, after submission of the test run, a bug was discovered in the code which paired test sentences with predictions; predictions had been omitted for about 500 of the 11,000 test texts (i.e. 4.5% of the data) due to an unfortunate combination of unpaired double-quote characters in the test data with the use of a standard CSV-file handling library.", "labels": [], "entities": []}, {"text": "After release of the gold-standard test set labels, the classifier was therefore re-run, with resulting accuracies as shown in: True accuracy on test set after restoring omitted predictions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9827479720115662}]}, {"text": "Accuracies are very similar to those on the development set.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9891971945762634}]}, {"text": "Overall accuracy at the chosen cost parameter range of 30-50 is 94.9%, slightly worse than the 1 stand slightly better than the 2 nd -placed systems in the official test (95.71% and 94.68% respectively).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9997301697731018}]}, {"text": "Increasing the cost parameter setting could perhaps give a very slight boost to performance.", "labels": [], "entities": []}, {"text": "Again, group E performs worst, and Group C best; per-group and overall accuracies are very similar to those achieved on the development set.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9523459672927856}]}, {"text": "A second unintended feature of the feature generation code was subsequently discovered: character n-grams were being extracted spanning word boundaries (including the whitespace characters separating words).", "labels": [], "entities": []}, {"text": "These were removed, leaving only the intended character n-grams within words, and accuracies are shown in.", "labels": [], "entities": []}, {"text": "Again, overall performance increases slightly, now to over 95%, although Group A accuracy shows a slight decrease (0.1%).", "labels": [], "entities": [{"text": "Group A", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.5454085767269135}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.6024271249771118}]}, {"text": "Group E accuracy improves by over 1% and is now over 90% at the chosen cost parameter.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.8346986770629883}]}, {"text": "Cost: 1: Accuracy on test set after removing spurious character n-grams.", "labels": [], "entities": [{"text": "Cost", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9774045944213867}, {"text": "Accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9964635968208313}]}, {"text": "Effect of features To investigate the utility of our chosen feature sets and their insights into lexical and orthographic distinctions, we then compared the overall performance to that achieved when removing certain features.", "labels": [], "entities": []}, {"text": "shows the accuracies achieved without word unigram features (i.e. using only character ngrams of lengths 1-3); shows accuracies without character ngram features (i.e. using only word unigrams).: Accuracy on test set using only word unigrams.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9951321482658386}]}], "tableCaptions": [{"text": " Table 2. We then trained on the full training set, and tested accuracy on  the development across each language group -see", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9994844198226929}]}, {"text": " Table 3. Given reported problems with the group F  dataset (en-UK/en-US), we focussed on groups A-E.", "labels": [], "entities": [{"text": "group F  dataset", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.5869253675142924}]}, {"text": " Table 3: Accuracy on development set with varying SVM cost.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985490441322327}]}, {"text": " Table 5: True accuracy on test set after restoring omitted predictions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9426993131637573}]}, {"text": " Table 6. Again, overall performance increases slightly, now to over 95%, although Group  A accuracy shows a slight decrease (0.1%). Group E accuracy improves by over 1% and is now over  90% at the chosen cost parameter.", "labels": [], "entities": [{"text": "Group  A accuracy", "start_pos": 83, "end_pos": 100, "type": "METRIC", "confidence": 0.5698437690734863}, {"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.7218024730682373}]}, {"text": " Table 6: Accuracy on test set after removing spurious character n-grams.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9979133009910583}]}, {"text": " Table 7: Accuracy on test set without word unigrams.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9977467656135559}]}, {"text": " Table 8: Accuracy on test set using only word unigrams.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9969334602355957}]}]}