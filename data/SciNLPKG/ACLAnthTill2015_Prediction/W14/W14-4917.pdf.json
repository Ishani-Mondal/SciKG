{"title": [{"text": "Exploiting the human computational effort dedicated to message reply formatting for training discursive email segmenters", "labels": [], "entities": [{"text": "message reply formatting", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.7448407312234243}]}], "abstractContent": [{"text": "In the context of multi-domain and multimodal online asynchronous discussion analysis, we propose an innovative strategy for manual annotation of dialog act (DA) segments.", "labels": [], "entities": [{"text": "multimodal online asynchronous discussion analysis", "start_pos": 35, "end_pos": 85, "type": "TASK", "confidence": 0.6254344820976258}, {"text": "manual annotation of dialog act (DA) segments", "start_pos": 125, "end_pos": 170, "type": "TASK", "confidence": 0.6484840148025088}]}, {"text": "The process aims at supporting the analysis of messages in terms of DA.", "labels": [], "entities": []}, {"text": "Our objective is to train a sequence labelling system to detect the segment boundaries.", "labels": [], "entities": []}, {"text": "The originality of the proposed approach is to avoid manually annotating the training data and instead exploit the human computational efforts dedicated to message reply formatting when the writer replies to a message by inserting his response just after the quoted text appropriate to his intervention.", "labels": [], "entities": [{"text": "message reply formatting", "start_pos": 156, "end_pos": 180, "type": "TASK", "confidence": 0.6404477854569753}]}, {"text": "We describe the approach, propose anew electronic mail corpus and report the evaluation of segmentation models we built.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic processing of online conversations (forum, emails) is a highly important issue for the industrial and the scientific communities which care to improve existing question/answering systems, identify emotions or intentions in customer requests or reviews, detect messages containing requests for action or unsolved severe problems.", "labels": [], "entities": [{"text": "Automatic processing of online conversations (forum, emails)", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.8335028707981109}]}, {"text": "In most works, conversation interactions between the participants are modelled in terms of dialogue acts (DA).", "labels": [], "entities": []}, {"text": "The DAs describe the communicative function conveyed by each text utterance (e.g. question, answer, greeting,.", "labels": [], "entities": []}, {"text": "). In this paper, we address the problem of rhetorically segmenting the new content parts of messages in online asynchronous discussions.", "labels": [], "entities": [{"text": "rhetorically segmenting the new content parts of messages in online asynchronous discussions", "start_pos": 44, "end_pos": 136, "type": "TASK", "confidence": 0.8469144304593405}]}, {"text": "The process aims at supporting the analysis of messages in terms of DA.", "labels": [], "entities": []}, {"text": "We pay special attention to the processing of electronic mails.", "labels": [], "entities": [{"text": "processing of electronic mails", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.7583651691675186}]}, {"text": "The main trend in automatic DA recognition consists in using supervised learning algorithms to predict the DA conveyed by a sentence or a message ().", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9377865195274353}]}, {"text": "The hypothesized message segmentation results from the global analysis of these individual predictions over each sentence.", "labels": [], "entities": [{"text": "message segmentation", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7289073020219803}]}, {"text": "A first remark on this paradigm is that it is not realistic to use in the context of multi-domain and multimodal processing because it requires the building of training data which is a very substantial and time-consuming task.", "labels": [], "entities": []}, {"text": "A second remark is that the model does not have a fine-grained representation of the message structure or the relations between messages.", "labels": [], "entities": []}, {"text": "Considering such characteristics could drastically improve the systems to allow to focus on specific text parts or to filter out less relevant ones.", "labels": [], "entities": []}, {"text": "Indeed, apart from the closing formula, a message may for example be made of several distinct information requests, the description of an unsuccessful procedure, the quote of third-party messages.", "labels": [], "entities": []}, {"text": "So far, few works address the problem of message segmentation.", "labels": [], "entities": [{"text": "message segmentation", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7924920618534088}]}, {"text": "( propose to segment emails in prototypical zones such as the author's contribution, quotes of original messages, the signature, the opening and closing formulas.", "labels": [], "entities": []}, {"text": "In comparison, we focus on the segmentation of the author's contribution (what we call the new content part).", "labels": [], "entities": []}, {"text": "( ) identifies clusters of topically related sentences through the multiple messages of a thread, without distinguishing email and forum messages.", "labels": [], "entities": []}, {"text": "Apart from the topical aspect, our problem differs because we are only interested in the cohesion between sentences in nearby fragments and not on distant sentences.", "labels": [], "entities": []}, {"text": "Despite the drawbacks mentioned above, a supervised approach remains the most efficient and reliable method to solve classification problems in Natural Language Processing.", "labels": [], "entities": []}, {"text": "Our aim is to train a system to detect the segment boundaries, i.e. to determine, through a classification approach, if a given sentence starts, ends or continues a segment.", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe the data, the preprocessing and the evaluation protocol we use for our experiments.", "labels": [], "entities": []}, {"text": "In order to evaluate the efficiency of the segmenter, we perform a 10-fold cross-validation on the Ubuntu corpus, and compare its performance to two different baselines.", "labels": [], "entities": [{"text": "Ubuntu corpus", "start_pos": 99, "end_pos": 112, "type": "DATASET", "confidence": 0.9645708799362183}]}, {"text": "The first one, the \"regular\" baseline, is computed by segmenting the test set into regular segments of the same length as the average training set segment length, rounded up.", "labels": [], "entities": []}, {"text": "The second one is the TextTiling algorithm we described in section 3.", "labels": [], "entities": []}, {"text": "While it is used as a feature in the proposed approach in the previous section, the direct output of the TextTiling algorithm is used for the baseline.", "labels": [], "entities": []}, {"text": "The results are measured with a panel of metrics used in text segmentation and Information Retrieval (IR).", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7160118669271469}, {"text": "Information Retrieval (IR)", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.843166196346283}]}, {"text": "Precision (P ) and Recall (R) are provided for all results.", "labels": [], "entities": [{"text": "Precision (P )", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9606344848871231}, {"text": "Recall (R)", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9702068120241165}]}, {"text": "P is the percentage of boundaries identified by the classifier that are indeed true boundaries.", "labels": [], "entities": [{"text": "P", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9395203590393066}]}, {"text": "R is the percentage of true boundaries that are identified by the classifier.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9692937135696411}]}, {"text": "We also provide the harmonic mean of precision and recall: F 1 = 2 \u00b7 P \u00b7R P +R However, automatic evaluation of speech segmentation through these metrics is problematic as predicted segment boundaries seldom align precisely.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9994563460350037}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.99907386302948}, {"text": "speech segmentation", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7372782230377197}]}, {"text": "Therefore, we also provide an array of metrics relevant to the field of text segmentation : P k , WindowDiff and the Generalized Hamming Distance (GHD).", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7178478538990021}, {"text": "Generalized Hamming Distance (GHD)", "start_pos": 117, "end_pos": 151, "type": "METRIC", "confidence": 0.68564406534036}]}, {"text": "The P k metric is a probabilistically motivated error metric for the assessment of segmentation algorithms ().", "labels": [], "entities": [{"text": "assessment of segmentation algorithms", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6612602695822716}]}, {"text": "WindowDiff compares the number of segment boundaries found within a fixed-sized window to the number of boundaries found in the same window of text for the reference segmentation).", "labels": [], "entities": []}, {"text": "The GHD is an extension of the Hamming distance 12 that gives partial credit for near misses).", "labels": [], "entities": [{"text": "GHD", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8862093687057495}, {"text": "Hamming distance 12", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.6579835712909698}]}], "tableCaptions": []}