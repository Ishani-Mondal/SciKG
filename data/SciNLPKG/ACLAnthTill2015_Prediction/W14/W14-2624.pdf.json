{"title": [{"text": "The Use of Text Similarity and Sentiment Analysis to Examine Ra- tionales in the Large-Scale Online Deliberations", "labels": [], "entities": [{"text": "Text Similarity", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.6717135906219482}, {"text": "Sentiment Analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7653859555721283}]}], "abstractContent": [{"text": "To overcome the increasingly time consuming and potentially challenging identification of key points and the associated rationales in large-scale online deliberations , we propose a computational linguistics method that has the potential of facilitating this process of reading and evaluating the text.", "labels": [], "entities": []}, {"text": "Our approach is novel in how we determine the sentiment of a rationale at the sentence level and in that it includes a text similarity measure and sentence-level sentiment analysis to achieve this goal.", "labels": [], "entities": [{"text": "sentence-level sentiment analysis", "start_pos": 147, "end_pos": 180, "type": "TASK", "confidence": 0.6595113178094228}]}], "introductionContent": [{"text": "In an online deliberation situation where users join in and offer their opinions or suggestions, they are expected to provide the rationales that justify their standpoints in the deliberation.", "labels": [], "entities": []}, {"text": "In the final decision making process, one expectedly needs to read through the content and weigh different key points and related rationales.", "labels": [], "entities": []}, {"text": "Wikipedia Article for Deletion (AfD) deliberations represent one such example.", "labels": [], "entities": [{"text": "Wikipedia Article for Deletion (AfD)", "start_pos": 0, "end_pos": 36, "type": "DATASET", "confidence": 0.8806548374039787}]}, {"text": "In the Wikipedia community, any member can propose to delete an existing Wikipedia article.", "labels": [], "entities": []}, {"text": "After an article is proposed to delete, a deliberation topic about the article is opened in the AfD forum.", "labels": [], "entities": [{"text": "AfD forum", "start_pos": 96, "end_pos": 105, "type": "DATASET", "confidence": 0.935249537229538}]}, {"text": "The community members can express their opinions (e.g., to keep or to delete the article) and provide their rationales within the specified time period.", "labels": [], "entities": []}, {"text": "After that, a community member (often a Wikipedia administrator) closes the deliberation by making the final decision.", "labels": [], "entities": []}, {"text": "Researchers have analyzed the Wikipedia AfD forum and have demonstrated that it presents a successful example of largescale online deliberation by allowing many people to participate equally, encouraging people to deliberate, and producing rational and meaningful rationales (e.g.,.", "labels": [], "entities": [{"text": "Wikipedia AfD forum", "start_pos": 30, "end_pos": 49, "type": "DATASET", "confidence": 0.8500781655311584}]}, {"text": "Wikipedia policy requires that the final decision about the article should be made based on the discussed rationales instead of the count of opinion votes.", "labels": [], "entities": []}, {"text": "In practice many Wikipedia members who close the deliberations follow this policy, which implies the potential problem of representing the diverse rationales and identifying the influential ones in this context.", "labels": [], "entities": []}, {"text": "Generating the final decision of a large scale online deliberation can become a daunting task, as the amount of opinions and rationales in the deliberation content increases significantly.", "labels": [], "entities": []}, {"text": "To facilitate this decision making process in largescale online deliberations, we have developed a method that uses an existing text-to-text similarity measure and our developed sentence-level sentiment analysis algorithm to address this issue.", "labels": [], "entities": [{"text": "decision making process", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.848329504330953}, {"text": "sentence-level sentiment analysis", "start_pos": 178, "end_pos": 211, "type": "TASK", "confidence": 0.7295000453790029}]}, {"text": "Specifically, we first group participants' opinions according to the similarity measure, then we identify the positive, neutral, and negative sentiments suggested by the participants' rationales in each group, and finally we choose a representative rationale from each sentiment category in a group.", "labels": [], "entities": []}, {"text": "With our method the diverse opinions and rationales are presented to the final decision maker through a representative set of the rationales, reducing the redundant information from the deliberation content so as to make the process of reading and evaluating the deliberation content more efficient.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our sentiment polarity prediction algorithm, we randomly selected 236 sentences from the Wikipedia AfD forum and manually annotated their sentiment polarity.", "labels": [], "entities": [{"text": "sentiment polarity prediction", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.8841618895530701}, {"text": "Wikipedia AfD forum", "start_pos": 120, "end_pos": 139, "type": "DATASET", "confidence": 0.8429141640663147}]}, {"text": "83 sentences are annotated as positive, 102 as negative and 51 as neutral.", "labels": [], "entities": []}, {"text": "With our algorithm that includes the machine learning process to detect modifier negations, the accuracy is 60.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9997015595436096}]}, {"text": "In evaluation of their algorithm, 5-class (very negative, negative, neutral, positive, very positive) and 2-class (negative, positive) predictions of sentence-level sentiment analysis reached an accuracy of 45.7% and 85.4% respectively.", "labels": [], "entities": [{"text": "sentence-level sentiment analysis", "start_pos": 150, "end_pos": 183, "type": "TASK", "confidence": 0.7258207897345225}, {"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9969320297241211}]}, {"text": "We anticipate that the accuracy of their algorithm for 3-class prediction would be around 60%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9997255206108093}, {"text": "3-class prediction", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.5831513404846191}]}, {"text": "For sentence-level sentiment analysis, Moilanen and Pulman's algorithm obtained an accuracy of 65.6%.", "labels": [], "entities": [{"text": "sentence-level sentiment analysis", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.7993521690368652}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.999561607837677}]}, {"text": "Our algorithm differs from Moilanen and Pulman in two ways: (1) the nodebased computation is more general, i.e. for verbs, prepositions, and subjects it is a simple combination (multiplication or addition) of the subordinate nodes' polarities, and for local negation it is an inversion of the subordinate polarity; (2) a trained classifier serves two functions: it fulfills the role of determining the contextual information and it determines whether a modifier changes the polarity of what it modifies.", "labels": [], "entities": []}], "tableCaptions": []}