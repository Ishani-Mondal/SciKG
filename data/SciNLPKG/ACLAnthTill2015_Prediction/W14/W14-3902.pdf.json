{"title": [{"text": "Code Mixing: A Challenge for Language Identification in the Language of Social Media", "labels": [], "entities": [{"text": "Code Mixing", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8041811883449554}, {"text": "Language Identification in the Language of Social Media", "start_pos": 29, "end_pos": 84, "type": "TASK", "confidence": 0.7471245750784874}]}], "abstractContent": [{"text": "In social media communication, multilingual speakers often switch between languages , and, in such an environment, automatic language identification becomes both a necessary and challenging task.", "labels": [], "entities": [{"text": "automatic language identification", "start_pos": 115, "end_pos": 148, "type": "TASK", "confidence": 0.6706725656986237}]}, {"text": "In this paper, we describe our work in progress on the problem of automatic language identification for the language of social media.", "labels": [], "entities": [{"text": "automatic language identification", "start_pos": 66, "end_pos": 99, "type": "TASK", "confidence": 0.6573061347007751}]}, {"text": "We describe anew dataset that we are in the process of creating , which contains Facebook posts and comments that exhibit code mixing between Bengali, English and Hindi.", "labels": [], "entities": []}, {"text": "We also present some preliminary word-level language identification experiments using this dataset.", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.6160478492577871}]}, {"text": "Different techniques are employed, including a simple unsuper-vised dictionary-based approach, supervised word-level classification with and without contextual clues, and sequence labelling using Conditional Random Fields.", "labels": [], "entities": [{"text": "word-level classification", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.6891933530569077}]}, {"text": "We find that the dictionary-based approach is surpassed by supervised classification and sequence labelling, and that it is important to take contextual clues into consideration .", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic processing and understanding of Social Media Content (SMC) is currently attracting much attention from the Natural Language Processing research community.", "labels": [], "entities": [{"text": "Automatic processing and understanding of Social Media Content (SMC)", "start_pos": 0, "end_pos": 68, "type": "TASK", "confidence": 0.8682193864475597}]}, {"text": "Although English is still by far the most popular language in SMC, its dominance is receding., for example, applied an automatic language detection algorithm to over 62 million tweets to identify the top 10 most popular languages on Twitter.", "labels": [], "entities": [{"text": "SMC", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9861862659454346}, {"text": "language detection", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.7118525356054306}]}, {"text": "They found that only half of the tweets were in English.", "labels": [], "entities": []}, {"text": "Moreover, mixing multiple languages together (code mixing) is a popular trend in social media users from language-dense areas.", "labels": [], "entities": [{"text": "code mixing)", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.8151959081490835}]}, {"text": "Ina scenario where speakers switch between languages within a conversation, sentence or even word, the task of automatic language identification becomes increasingly important to facilitate further processing.", "labels": [], "entities": [{"text": "automatic language identification", "start_pos": 111, "end_pos": 144, "type": "TASK", "confidence": 0.6902133027712504}]}, {"text": "Speakers whose first language uses a nonRoman alphabet write using the Roman alphabet for convenience (phonetic typing) which increases the likelihood of code mixing with a Romanalphabet language.", "labels": [], "entities": []}, {"text": "This can be especially observed in South-East Asia and in the Indian subcontinent.", "labels": [], "entities": []}, {"text": "The following is a code mixing comment taken from a Facebook group of Indian university students: Original: Yaar tu to, GOD hain.", "labels": [], "entities": []}, {"text": "tui JU te ki korchis?", "labels": [], "entities": []}, {"text": "Translation: Buddy you are GOD.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9196224212646484}, {"text": "GOD", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9945607781410217}]}, {"text": "What are you doing in JU?", "labels": [], "entities": [{"text": "JU", "start_pos": 22, "end_pos": 24, "type": "DATASET", "confidence": 0.9132449626922607}]}, {"text": "This comment is written in three languages: English, Hindi (italics), and Bengali (boldface).", "labels": [], "entities": []}, {"text": "For Bengali and Hindi, phonetic typing has been used.", "labels": [], "entities": [{"text": "phonetic typing", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.6974975764751434}]}, {"text": "We follow in the footsteps of recent work on language identification for SMC (;, focusing specifically on the problem of word-level language identification for code mixing SMC.", "labels": [], "entities": [{"text": "language identification", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.7192621678113937}, {"text": "SMC", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9226447939872742}, {"text": "word-level language identification", "start_pos": 121, "end_pos": 155, "type": "TASK", "confidence": 0.6090419590473175}, {"text": "code mixing SMC", "start_pos": 160, "end_pos": 175, "type": "TASK", "confidence": 0.5649727781613668}]}, {"text": "Our corpus for this task is collected from Facebook and contains instances of Bengali(BN)-English(EN)-Hindi(HI) code mixing.", "labels": [], "entities": [{"text": "Bengali(BN)-English(EN)-Hindi(HI) code mixing", "start_pos": 78, "end_pos": 123, "type": "TASK", "confidence": 0.5489025584289006}]}, {"text": "The paper is organized as follows: in Section 2, we review related research in the area of code mixing and language identification; in Section 3, we describe our code mixing corpus, the data it-self and the annotation process; in Section 4, we list the tools and resources which we use in our language identification experiments, described in Section 5.", "labels": [], "entities": [{"text": "code mixing", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.7117288410663605}, {"text": "language identification", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7236419320106506}, {"text": "language identification", "start_pos": 293, "end_pos": 316, "type": "TASK", "confidence": 0.7436885833740234}]}, {"text": "Finally, in Section 6, we conclude and provide suggestions for future research on this topic.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since our training data is entirely labelled at the word-level by human annotators, we address the word-level language identification task in a fully supervised way.", "labels": [], "entities": [{"text": "word-level language identification task", "start_pos": 99, "end_pos": 138, "type": "TASK", "confidence": 0.6902511492371559}]}, {"text": "Out of the total data, 15% is set aside as a blind test set, while the rest is employed in our experiments through a 5-fold cross-validation setup.", "labels": [], "entities": []}, {"text": "There is a substantial amount of token overlap between the cross-validation data and the test set -88% of total EN tokens, 86% of total Bengali tokens and 57% of total Hindi tokens of the test set are present in the cross-validation data.", "labels": [], "entities": []}, {"text": "We address the problem of word-level in three different ways: 1.", "labels": [], "entities": []}, {"text": "A simple heuristic-based approach which uses a combination of our dictionaries to classify the language of a word 2.", "labels": [], "entities": []}, {"text": "Word-level classification using supervised machine learning with SVMs but no contextual information 3.", "labels": [], "entities": [{"text": "Word-level classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6929072886705399}]}, {"text": "Word-level classification using supervised machine learning with SVMs and sequence labelling using CRFs, both employing contextual information Named entities and instances of word-level code mixing are excluded from evaluation.", "labels": [], "entities": [{"text": "Word-level classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7531750798225403}]}, {"text": "For systems which do not take the context of a word into account, i.e. the dictionary-based approach (Section 5.1) and the SVM approach without contextual clues (Section 5.2), named entities and instances of word-level code mixing can be safely excluded from training.", "labels": [], "entities": []}, {"text": "For systems which do take context into account, the CRF system (Section 5.3.1) and the SVM system with contextual clues (Section 5.3.2), these are included in training, because to exclude them would result in unrealistic contexts.", "labels": [], "entities": []}, {"text": "This means that these systems We found 25 comments and 17 posts common between the cross-validation data and the test set.", "labels": [], "entities": []}, {"text": "The reason for this is that users of social media often express themselves in a concise way.", "labels": [], "entities": []}, {"text": "Almost all of these common data consisted of 1 to 3 token(s).", "labels": [], "entities": []}, {"text": "In most of the cases these tokens were emoticons, symbols or universal expressions such as wow and lol.", "labels": [], "entities": []}, {"text": "As the percentage of these comments is low, we keep these comments as they are.", "labels": [], "entities": []}, {"text": "can classify a word to be a named entity or an instance of word-level code mixing.", "labels": [], "entities": [{"text": "word-level code mixing", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.5629956920941671}]}, {"text": "To avoid this, we implement a post-processor which backs off in these cases to a system which hasn't seen named entities or word-level code mixing in training (see Section 5.3).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Almost 7% of total types are ambiguous  (i.e. tagged in different languages during annota- tion). Among them, a substantial amount (5.58%)  are English/Bengali.", "labels": [], "entities": []}, {"text": " Table 3: Statistics of ambiguous and monolingual  word types", "labels": [], "entities": []}, {"text": " Table 4: Average cross-validation accuracy of  dictionary-based detection", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.964056670665741}, {"text": "dictionary-based detection", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.7064347118139267}]}, {"text": " Table 7: Average cross-validation accuracy of  SVM (GDLC) context-based runs, where P-i =  previous i word(s) , N-i = next i word(s)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.941372811794281}]}, {"text": " Table 8: Test set results for Baseline (Dictionary), SVM-GDLC, SVM-P1N1 and CRF-GDC", "labels": [], "entities": [{"text": "SVM-GDLC", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.8868315815925598}, {"text": "SVM-P1N1", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8958842158317566}, {"text": "CRF-GDC", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.6611502170562744}]}]}