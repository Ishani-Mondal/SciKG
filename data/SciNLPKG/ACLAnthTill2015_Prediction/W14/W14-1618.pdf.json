{"title": [{"text": "Linguistic Regularities in Sparse and Explicit Word Representations", "labels": [], "entities": [{"text": "Linguistic Regularities in Sparse and Explicit Word Representations", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.5906993709504604}]}], "abstractContent": [{"text": "Recent work has shown that neural-embedded word representations capture many relational similarities, which can be recovered by means of vector arithmetic in the embedded space.", "labels": [], "entities": []}, {"text": "We show that Mikolov et al.'s method of first adding and subtracting word vectors, and then searching fora word similar to the result , is equivalent to searching fora word that maximizes a linear combination of three pairwise word similarities.", "labels": [], "entities": []}, {"text": "Based on this observation, we suggest an improved method of recovering relational similarities , improving the state-of-the-art results on two recent word-analogy datasets.", "labels": [], "entities": []}, {"text": "Moreover, we demonstrate that analogy recovery is not restricted to neural word embeddings, and that a similar amount of relational similarities can be recovered from traditional distributional word representations .", "labels": [], "entities": [{"text": "analogy recovery", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8566260933876038}]}], "introductionContent": [{"text": "Deep learning methods for language processing owe much of their success to neural network language models, in which words are represented as dense real-valued vectors in Rd . Such representations are referred to as distributed word representations or word embeddings, as they embed an entire vocabulary into a relatively low-dimensional linear space, whose dimensions are latent continuous features.", "labels": [], "entities": [{"text": "language processing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7154986411333084}]}, {"text": "The embedded word vectors are trained overlarge collections of text using variants of neural networks ().", "labels": [], "entities": []}, {"text": "The * Supported by the European Community's Seventh Framework Programme under grant agreement no.", "labels": [], "entities": [{"text": "European Community's Seventh Framework Programme", "start_pos": 23, "end_pos": 71, "type": "DATASET", "confidence": 0.6693292210499445}]}, {"text": "word embeddings are designed to capture what Turney (2006) calls attributional similarities between vocabulary items: words that appear in similar contexts will be close to each other in the projected space.", "labels": [], "entities": []}, {"text": "The effect is grouping of words that share semantic (\"dog cat cow\", \"eat devour\") or syntactic (\"cars hats days\", \"emptied carried danced\") properties, and are shown to be effective as features for various NLP tasks (.", "labels": [], "entities": []}, {"text": "We refer to such word representations as neural embeddings or just embeddings.", "labels": [], "entities": []}, {"text": "Recently, demonstrated that the embeddings created by a recursive neural network (RNN) encode not only attributional similarities between words, but also similarities between pairs of words.", "labels": [], "entities": []}, {"text": "Such similarities are referred to as linguistic regularities by Mikolov et al. and as relational similarities by.", "labels": [], "entities": []}, {"text": "They capture, for example, the gender relation exhibited by the pairs \"man:woman\", \"king:queen\", the language-spoken-in relation in \"france:french\", \"mexico:spanish\" and the pasttense relation in \"capture:captured\", \"go:went\".", "labels": [], "entities": []}, {"text": "Remarkably, showed that such relations are reflected in vector offsets between word pairs (apples \u2212 apple \u2248 cars \u2212 car), and that by using simple vector arithmetic one could apply the relation and solve analogy questions of the form \"a is to a * as b is to -\" in which the nature of the relation is hidden.", "labels": [], "entities": []}, {"text": "Perhaps the most famous example is that the embedded representation of the word queen can be roughly recovered from the representations of king, man and woman: The recovery of relational similarities using vector arithmetic on RNN-embedded vectors was evaluated on many relations, achieving state-of-the-art results in relational similarity identification tasks.", "labels": [], "entities": [{"text": "relational similarity identification", "start_pos": 319, "end_pos": 355, "type": "TASK", "confidence": 0.762419859568278}]}, {"text": "It was later demonstrated that relational similarities can be recovered in a similar fashion also from embeddings trained with different architectures).", "labels": [], "entities": []}, {"text": "This fascinating result raises a question: to what extent are the relational semantic properties a result of the embedding process?", "labels": [], "entities": []}, {"text": "Experiments in ( show that the RNN-based embeddings are superior to other dense representations, but how crucial is it fora representation to be dense and low-dimensional at all?", "labels": [], "entities": []}, {"text": "An alternative approach to representing words as vectors is the distributional similarity representation, or bag of contexts.", "labels": [], "entities": []}, {"text": "In this representation, each word is associated with a very highdimensional but sparse vector capturing the contexts in which the word occurs.", "labels": [], "entities": []}, {"text": "We call such vector representations explicit, as each dimension directly corresponds to a particular context.", "labels": [], "entities": []}, {"text": "These explicit vector-space representations have been extensively studied in the NLP literature (see and the references therein), and are known to exhibit a large extent of attributional similarity.", "labels": [], "entities": []}, {"text": "In this study, we show that similarly to the neural embedding space, the explicit vector space also encodes avast amount of relational similarity which can be recovered in a similar fashion, suggesting the explicit vector space representation as a competitive baseline for further work on neural embeddings.", "labels": [], "entities": []}, {"text": "Moreover, this result implies that the neural embedding process is not discovering novel patterns, but rather is doing a remarkable job at preserving the patterns inherent in the wordcontext co-occurrence matrix.", "labels": [], "entities": []}, {"text": "A key insight of this work is that the vector arithmetic method can be decomposed into a linear combination of three pairwise similarities (Section 3).", "labels": [], "entities": []}, {"text": "While mathematically equivalent, we find that thinking about the method in terms of the decomposed formulation is much less puzzling, and provides a better intuition on why we would expect the method to perform well on the analogy recovery task.", "labels": [], "entities": [{"text": "analogy recovery task", "start_pos": 223, "end_pos": 244, "type": "TASK", "confidence": 0.8736456235249838}]}, {"text": "Furthermore, the decomposed form leads us to suggest a modified optimization objective (Section 6), which outperforms the state-ofthe-art at recovering relational similarities under both representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the different word representations using the three datasets used in previous work.", "labels": [], "entities": []}, {"text": "Two of them (MSR and GOOGLE) contain analogy questions, while the third (SEMEVAL) requires ranking of candidate word pairs according to their relational similarity to a set of supplied word pairs.", "labels": [], "entities": [{"text": "GOOGLE", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.8025614023208618}, {"text": "SEMEVAL", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.8982254862785339}]}, {"text": "Open Vocabulary The open vocabulary datasets (MSR and GOOGLE) present questions of the form \"a is to a * as b is to b * \", where b * is hidden, and must be guessed from the entire vocabulary.", "labels": [], "entities": [{"text": "GOOGLE", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.819869339466095}]}, {"text": "Performance on these datasets is measured by micro-averaged accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9055945873260498}]}, {"text": "The MSR dataset 4 (Mikolov et al., 2013c) contains 8000 analogy questions.", "labels": [], "entities": [{"text": "MSR dataset 4 (Mikolov et al., 2013c)", "start_pos": 4, "end_pos": 41, "type": "DATASET", "confidence": 0.8017658233642578}]}, {"text": "The relations portrayed by these questions are morpho-syntactic, and can be categorized according to parts of speech -adjectives, nouns and verbs.", "labels": [], "entities": []}, {"text": "Adjective relations include comparative and superlative (good is to best as smart is to smartest).", "labels": [], "entities": []}, {"text": "Noun relations include single and plural, possessive and non-possessive (dog is to dog's as cat is to cat's).", "labels": [], "entities": []}, {"text": "Verb relations are tense modifications (work is to worked as accept is to accepted).", "labels": [], "entities": []}, {"text": "The GOOGLE dataset  Out-of-vocabulary words were removed from both test sets.", "labels": [], "entities": [{"text": "GOOGLE dataset  Out-of-vocabulary words", "start_pos": 4, "end_pos": 43, "type": "DATASET", "confidence": 0.8200066834688187}]}, {"text": "Closed Vocabulary The SEMEVAL dataset contains the collection of 79 semantic relations that appeared in SemEval 2012 Task 2: Measuring Relation Similarity (.", "labels": [], "entities": [{"text": "SEMEVAL dataset", "start_pos": 22, "end_pos": 37, "type": "DATASET", "confidence": 0.8128691911697388}, {"text": "SemEval 2012 Task 2", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.8801139891147614}, {"text": "Measuring Relation Similarity", "start_pos": 125, "end_pos": 154, "type": "TASK", "confidence": 0.6189938882986704}]}, {"text": "Each relation is exemplified by a few (usually 3) characteristic word-pairs.", "labels": [], "entities": []}, {"text": "Given a set of several dozen target word pairs, which supposedly have the same relation, the task is to rank the target pairs according to the degree in which this relation holds.", "labels": [], "entities": []}, {"text": "This can be cast as an analogy question in the following manner: For example, take the Recipient:Instrument relation with the prototypical word pairs king:crown and police:badge.", "labels": [], "entities": []}, {"text": "To measure the degree that a target word pair wife:ring has the same relation, we form the two analogy questions \"king is to crown as wife is to ring\" and \"police is to badge as wife is to ring\".", "labels": [], "entities": []}, {"text": "We calculate the score of each analogy, and average the results.", "labels": [], "entities": []}, {"text": "Note that as opposed to the first two test sets, this one does not require searching the entire vocabulary for the most suitable word in the corpus, but rather to rank a list of existing word pairs.", "labels": [], "entities": []}, {"text": "Following previous work, performance on SE-MEVAL was measured using accuracy, macroaveraged across all the relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9994320273399353}]}], "tableCaptions": [{"text": " Table 1: Performance of 3COSADD on different tasks with  the explicit and neural embedding representations.", "labels": [], "entities": []}, {"text": " Table 2: Performance of PAIRDIRECTION on different tasks  with the explicit and neural embedding representations.", "labels": [], "entities": [{"text": "PAIRDIRECTION", "start_pos": 25, "end_pos": 38, "type": "METRIC", "confidence": 0.8968613743782043}]}, {"text": " Table 3: Comparison of 3COSADD and 3COSMUL.", "labels": [], "entities": []}, {"text": " Table 4: Agreement between the representations on open- vocabulary tasks.", "labels": [], "entities": []}, {"text": " Table 5: Breakdown of relational similarities in each repre- sentation by relation type, using 3COSMUL.", "labels": [], "entities": []}, {"text": " Table 6: Common default-behavior errors under both repre- sentations. EMB / EXP: the number of time the word was  returned as an incorrect answer for the given relation under  the embedded or explicit representation.", "labels": [], "entities": [{"text": "EMB / EXP", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9346299171447754}]}, {"text": " Table 7: The top features of each aspect, recovered by pointwise multiplication of words that share that aspect. The result of  pointwise multiplication is an \"aspect vector\" in which the features common to both words, characterizing the relation, receive  the highest scores. The feature scores (not shown) correspond to the weight the feature contributes to the cosine similarity  between the vectors. The superscript marks the position of the feature relative to the target word.", "labels": [], "entities": []}]}