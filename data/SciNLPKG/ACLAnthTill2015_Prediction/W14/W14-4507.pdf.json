{"title": [{"text": "A Comparative Study of Conversion Aided Methods for WordNet Sentence Textual Similarity", "labels": [], "entities": [{"text": "WordNet Sentence Textual Similarity", "start_pos": 52, "end_pos": 87, "type": "TASK", "confidence": 0.6149713471531868}]}], "abstractContent": [{"text": "In this paper, we present a comparison of three methods for taxonomic-based sentence semantic relatedness, aided with word parts of speech (PoS) conversion.", "labels": [], "entities": [{"text": "taxonomic-based sentence semantic relatedness", "start_pos": 60, "end_pos": 105, "type": "TASK", "confidence": 0.7115705162286758}, {"text": "word parts of speech (PoS) conversion", "start_pos": 118, "end_pos": 155, "type": "TASK", "confidence": 0.6097908243536949}]}, {"text": "We use WordNet ontology for determining word level semantic similarity while augmenting WordNet with two other lexicographical databases; namely Categorial Variation Database (CatVar) and Morphosemantic Database in assisting the word category conversion.", "labels": [], "entities": [{"text": "determining word level semantic similarity", "start_pos": 28, "end_pos": 70, "type": "TASK", "confidence": 0.6221137166023254}, {"text": "word category conversion", "start_pos": 229, "end_pos": 253, "type": "TASK", "confidence": 0.7288074791431427}]}, {"text": "Using a human annotated benchmark data set, all the three approaches achieved a high positive correlation reaching up to (r = 0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set.", "labels": [], "entities": [{"text": "human annotated benchmark data set", "start_pos": 8, "end_pos": 42, "type": "DATASET", "confidence": 0.7775185823440551}]}], "introductionContent": [{"text": "Sentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLP tasks including text summarization, document classification, text clustering, topic detection, automatic question answering, automatic text scoring, plagiarism detection, machine translation, conversational agents among others.", "labels": [], "entities": [{"text": "Sentence textual similarity", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8449023962020874}, {"text": "text summarization", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.7311882674694061}, {"text": "document classification", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.7654828727245331}, {"text": "text clustering", "start_pos": 162, "end_pos": 177, "type": "TASK", "confidence": 0.7475644052028656}, {"text": "topic detection", "start_pos": 179, "end_pos": 194, "type": "TASK", "confidence": 0.8281274735927582}, {"text": "question answering", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.7018821239471436}, {"text": "text scoring", "start_pos": 236, "end_pos": 248, "type": "TASK", "confidence": 0.678562805056572}, {"text": "plagiarism detection", "start_pos": 250, "end_pos": 270, "type": "TASK", "confidence": 0.7916488647460938}, {"text": "machine translation", "start_pos": 272, "end_pos": 291, "type": "TASK", "confidence": 0.7674793899059296}]}, {"text": "There are two predominant approaches for sentence similarity: corpus-based and knowledgebased.", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7175398766994476}]}, {"text": "The former utilises information exclusively derived from large corpora including word frequency of occurrence, and latent semantic analysis, to infer semantic similarity.", "labels": [], "entities": []}, {"text": "On the other hand, Knowledge-based measures employ the intrinsic structure of a semantic network including its hierarchy to derive the semantic similarity.", "labels": [], "entities": []}, {"text": "One of the commonly used knowledge networks for semantic similarity is WordNet.", "labels": [], "entities": [{"text": "semantic similarity", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7821208238601685}, {"text": "WordNet", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9609179496765137}]}, {"text": "It is a hierarchical lexical database for English developed at Princeton University.", "labels": [], "entities": []}, {"text": "The state of the art WordNet sentence similarity is harvested from pairing the constituent words of the two compared sentences.", "labels": [], "entities": []}, {"text": "This is based on the intuition that similar sentences in meaning will indeed comprise semantically related words.", "labels": [], "entities": []}, {"text": "However, these pairings only handle nouns and verbs as other part-of-speech (PoS) attributes are not accounted for in WordNet taxonomy.", "labels": [], "entities": []}, {"text": "Taxonomic similarity is a conceptual relatedness derived from hyponymy/hypernymy relations of lexical ontologies.", "labels": [], "entities": []}, {"text": "In this study, we use a group of WordNet semantic relations, e.g. synonymy, hyponymy, for similarity determination and for the approximation of noun equivalents of other PoS words.", "labels": [], "entities": [{"text": "similarity determination", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.686318427324295}, {"text": "approximation of noun equivalents of other PoS words", "start_pos": 127, "end_pos": 179, "type": "TASK", "confidence": 0.7284073606133461}]}, {"text": "In implementing the conversion aided methods, we adapted a publicly available package) to measure word level similarity.", "labels": [], "entities": []}, {"text": "We computed word similarities from word senses using Wu and Palmer's measure as given in expression 1.", "labels": [], "entities": []}, {"text": "Where ( ) (lowest common subsumer) stands for the synset subsuming concepts and while depth ( ) indicates the number of nodes from concept to the root node of the hierarchy.", "labels": [], "entities": []}, {"text": "Next, the above word-to-word semantic similarity is extended to sentence-to-sentence semantic similarity, say and using like approach, where pairs of the same PoS tokens from the two sentences are evaluated.", "labels": [], "entities": [{"text": "sentence-to-sentence semantic similarity", "start_pos": 64, "end_pos": 104, "type": "TASK", "confidence": 0.6413456002871195}]}, {"text": ") stands for word level similarity measure in (1).", "labels": [], "entities": [{"text": "word level similarity measure", "start_pos": 13, "end_pos": 42, "type": "METRIC", "confidence": 0.5300788432359695}]}, {"text": "Nevertheless, for common natural language texts, it remains biased if only verbs and nouns are used to measure semantic relatedness ignoring other word categories such as adjectives, adverbs and named entities.", "labels": [], "entities": []}, {"text": "To elaborate that, consider the following pair of semantically identical sentences with different word surface forms and classes.", "labels": [], "entities": []}, {"text": "S 1 : He stated that the construction of the house is complete.", "labels": [], "entities": []}, {"text": "S 2 : He said in a statement that the house is completely constructed.", "labels": [], "entities": []}, {"text": "Initial preprocessing tasks including tokenization, normalization, and stop-words removal reduce sentences to their semantic words with S 1 yielding (state, construction, house, complete) and (statement, house, completely, construct) for S 2 . To optimize the semantic similarity of the two sentences, their scores from the word pairings need to be maximized regardless their associated part of speech.", "labels": [], "entities": []}, {"text": "For S 1 and S 2 , this is only achievable when words are paired as (statement, state), (house, house), (construction, construct) and (complete, completely).", "labels": [], "entities": []}, {"text": "However, using quantification (2) yields a Sim(S 1 ,S 2 ) score of 0.543.", "labels": [], "entities": [{"text": "Sim(S 1 ,S 2 ) score", "start_pos": 43, "end_pos": 63, "type": "METRIC", "confidence": 0.6402558750576444}]}, {"text": "This is justifiable as computing the similarity of the above first, third and fourth pairs, is out of reach using conventional WordNet measures due to each word pair falling in different PoS.", "labels": [], "entities": []}, {"text": "To handle the above limitation, the idea advocated in this paper is to turn all non-noun PoS terms into corresponding noun expressions in order to enhance the pairing tasks.", "labels": [], "entities": []}, {"text": "The rationale behind the migration to noun category instead of other PoS categories relies on the inherent well elaborated properties of noun category in the taxonomical hierarchy, e.g., number of nouns is much more important than other attributes inmost lexical databases, which increases the chance of finding noun-counterpart; WordNet 3 has a depth of 20 for nouns and 14 for verbs, which allows for much more elaborated hyponym/hypernym relations for instance.", "labels": [], "entities": []}, {"text": "It is also the case that words in the lower layers of the deeper hierarchical taxonomy have more specific concepts which consequently yield a high semantic similarity).", "labels": [], "entities": []}, {"text": "This is again supported by the argument presented in.", "labels": [], "entities": []}, {"text": "The reasons stated above and WordNet limitation of parts of speech boundary motived the current study of word PoS conversion in an attempt to improve the measurement of taxonomic-based short text semantic similarity.", "labels": [], "entities": [{"text": "word PoS conversion", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.6385942300160726}, {"text": "taxonomic-based short text semantic similarity", "start_pos": 169, "end_pos": 215, "type": "TASK", "confidence": 0.6559799790382386}]}, {"text": "In this respect, transforming all other primary word categories 1 of the previous example to nouns using CatVar aided conversion has raised the similarity from 0.543 to 0.86.", "labels": [], "entities": [{"text": "similarity", "start_pos": 144, "end_pos": 154, "type": "METRIC", "confidence": 0.9946104288101196}]}, {"text": "Since the two sentences of the previous example are intuitively highly semantically related, the noun-conversion brings the sentence similarity closer to human judgement.", "labels": [], "entities": []}, {"text": "This again highlights the importance of word PoS conversion to move freely beyond the barrier of PoS restriction.", "labels": [], "entities": [{"text": "PoS conversion", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.8201062381267548}]}, {"text": "This paper aims to investigate three distinct word conversion schemes.", "labels": [], "entities": [{"text": "word conversion", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7364501357078552}]}, {"text": "Although, all the three approaches use WordNet for measuring the term level similarity, each stands on a distinct external lexical resource in converting word's category; namely, WordNet 3.0, the Categorial Variation Database (CatVar), and the Morphosemantic Database.", "labels": [], "entities": []}, {"text": "CatVar is a lexical database containing word categorial variations for English lexemes sharing a common stem, e.g. research V , researcher N , researchable AJ ,.", "labels": [], "entities": []}, {"text": "Likewise, Morphosematic Database is a WordNet-related linguistic resource that links morphologically related nouns and verbs in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.9458456635475159}]}, {"text": "Both aforementioned databases are solely utilized to aid the PoS conversion of three primary word classes to nouns.", "labels": [], "entities": [{"text": "PoS conversion", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.9528925716876984}]}, {"text": "Contributions of this paper are two folded.", "labels": [], "entities": []}, {"text": "First, we improved traditional WordNet sentence similarity by converting poorly or non-hierarchized word categories (e.g. verbs, adverbs and adjectives) to a class with well-structured and deep taxonomy (nouns) using WordNet relations, CatVar and Morphosemantic databases.", "labels": [], "entities": [{"text": "WordNet sentence similarity", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.8024315237998962}]}, {"text": "Second, we have performed a comparison among the three PoS conversion techniques to discover the most appropriate supplementary database to WordNet.", "labels": [], "entities": [{"text": "PoS conversion", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.79844731092453}, {"text": "WordNet", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.9723543524742126}]}], "datasetContent": [{"text": "Figure 2 (a) depicts our layered implementation of the multiple conversion aided sentence semantic similarity.", "labels": [], "entities": [{"text": "multiple conversion aided sentence semantic similarity", "start_pos": 55, "end_pos": 109, "type": "TASK", "confidence": 0.6381098280350367}]}, {"text": "For every two sentences, we determine how closely the two are semantically related using scores between 1 and 0 with 1 indicating identical texts.", "labels": [], "entities": []}, {"text": "highlights a functional algorithm that summarizes the word category conversion process.", "labels": [], "entities": [{"text": "word category conversion", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6770054598649343}]}, {"text": "The convert(w) function in the same algorithm performs the parts of speech conversion from the selected database depending on the active approach (A in).", "labels": [], "entities": []}, {"text": "All text pre-processing tasks including tokenization, parts of speech tagging, and stop words removal are implemented in layer 1.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.9728732109069824}, {"text": "speech tagging", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.6871796995401382}, {"text": "stop words removal", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7130052447319031}]}, {"text": "The second layer houses the three main word category conversion approaches in discussion.", "labels": [], "entities": [{"text": "word category conversion", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.6939552625020345}]}, {"text": "In each experimental run, only one approach is used depending on the choice of internally hardcoded system logic.", "labels": [], "entities": []}, {"text": "The generated output from layer 2 is sentence text vectors having the same part of speech.", "labels": [], "entities": []}, {"text": "These vectors are then fed into the Text Semantic Similarity Module to measure the similarity score using Wu and Palmer measure for word level similarity and WordNet taxonomy as an information source according to equations (1-2).", "labels": [], "entities": [{"text": "WordNet taxonomy", "start_pos": 158, "end_pos": 174, "type": "DATASET", "confidence": 0.9294614493846893}]}, {"text": "Our evaluation for all three conversion assisted systems is centered around the human judgements.", "labels": [], "entities": []}, {"text": "Human ratings reflect the extent to which every two sentences are semantically related from the human perception.", "labels": [], "entities": []}, {"text": "A comparison of our conversion aided methods (TW, CwW, CwM, CwC) and the findings of two baseline methods (STASIS, LSA) is presented in.", "labels": [], "entities": []}, {"text": "The notations TW, CwW, CwM, CwC stand for, traditional WordNet, conversion with WordNet, conversion with Morphosemantics and conversion with CatVar respectively.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.9189406633377075}, {"text": "WordNet", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9366006851196289}]}, {"text": "We selected the baselines because of their fitness for purpose and their evaluation on the same benchmark data.", "labels": [], "entities": []}, {"text": "STASIS, thoroughly described in), is a textual similarity measure combining taxonomy and word order information to compute the semantic relatedness for two sentences.", "labels": [], "entities": [{"text": "STASIS", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.45730409026145935}]}, {"text": "While LSA (latent sematic analysis)) is a corpus-based measure developed for indexing and retrieval of text documents but later adapted for tasks including sentence similarity.", "labels": [], "entities": [{"text": "indexing and retrieval of text documents", "start_pos": 77, "end_pos": 117, "type": "TASK", "confidence": 0.7567195097605387}]}, {"text": "In LSA, texts are represented as a matrix, of high dimensional semantic vectors, which is then transformed using Singular Value Decomposition (SVD); namely, where A is a term-document matrix, S is the diagonal matrix of the Singular Value Decomposition, while T and Dare left and right singular vectors with orthogonal columns.", "labels": [], "entities": []}, {"text": "As pointed out, the results obtained in (J. O'Shea,  have been compared to our experimental results.", "labels": [], "entities": [{"text": "J. O'Shea", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.6275162994861603}]}, {"text": "Due to the space limitation, results of only 10 randomly selected sentence pairs from the benchmark data set are listed in with the second column being the human ratings.", "labels": [], "entities": [{"text": "benchmark data set", "start_pos": 90, "end_pos": 108, "type": "DATASET", "confidence": 0.812279204527537}]}], "tableCaptions": [{"text": " Table 2. Human, STASIS, LSA, TW, CwW, CwM and CwC similarity scores for 10 sentence pairs", "labels": [], "entities": [{"text": "STASIS", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.7400643825531006}, {"text": "CwC similarity scores", "start_pos": 47, "end_pos": 68, "type": "METRIC", "confidence": 0.6419196128845215}]}, {"text": " Table 3: Correlations Coefficients (r) between machine and human scores", "labels": [], "entities": [{"text": "Correlations Coefficients (r)", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.8340581655502319}]}]}