{"title": [{"text": "Extracting Multiword Translations from Aligned Comparable Documents", "labels": [], "entities": [{"text": "Extracting Multiword Translations from Aligned Comparable Documents", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.8822265352521624}]}], "abstractContent": [{"text": "Most previous attempts to identify translations of multiword expressions using comparable corpora relied on dictionaries of single words.", "labels": [], "entities": []}, {"text": "The translation of a mul-tiword was then constructed from the translations of its components.", "labels": [], "entities": []}, {"text": "In contrast , in this work we try to determine the translation of a multiword unit by analyzing its contextual behaviour in aligned comparable documents, thereby not presupposing any given dictionary.", "labels": [], "entities": []}, {"text": "Whereas with this method translation results for single words are rather good, the results for multiword units are considerably worse.", "labels": [], "entities": [{"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.9428185224533081}]}, {"text": "This is an indication that the type of multiword expressions considered here is too infrequent to provide a sufficient amount of contextual information.", "labels": [], "entities": []}, {"text": "Thus indirectly it is confirmed that it should make sense to look at the contextual behaviour of the components of a multi-word expression individually, and to combine the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of identifying word translations from comparable text has received considerable attention.", "labels": [], "entities": [{"text": "identifying word translations from comparable text", "start_pos": 12, "end_pos": 62, "type": "TASK", "confidence": 0.8534523447354635}]}, {"text": "Some early papers include and.", "labels": [], "entities": []}, {"text": "utilized a context heterogeneity measure, thereby assuming that words with productive context in one language translate to words with productive context in another language, and words with rigid context translate into words with rigid context.", "labels": [], "entities": []}, {"text": "In contrast, the underlying assumption in was that words which are translations of each other show similar co-occurrence patterns across languages.", "labels": [], "entities": []}, {"text": "This assumption is effectively an extension of distributional hypotheses to the multilingual case.", "labels": [], "entities": []}, {"text": "This work was further elaborated in some by now classical papers, such as and.", "labels": [], "entities": []}, {"text": "Based on these papers, the standard approach is to start from a dictionary of seed words, and to assume that the words occurring in the context of a source language word have similar meanings as the words occurring in the context of its target language translation.", "labels": [], "entities": []}, {"text": "There have been suggestions to eliminate the need for the seed dictionary.", "labels": [], "entities": []}, {"text": "However, most attempts, such as, and did notwork to an extent that the results would be useful for practical purposes.", "labels": [], "entities": []}, {"text": "Only recently a more promising approach has been investigated:,, and look at aligned comparable documents and deal with them in analogy to the treatment of aligned parallel sentences, i.e. effectively doing a word alignment in a very noisy environment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 209, "end_pos": 223, "type": "TASK", "confidence": 0.7066482156515121}]}, {"text": "This approach has been rather successful and it was possible to improve on previous results.", "labels": [], "entities": []}, {"text": "This is therefore the approach which we will pursue in the current paper.", "labels": [], "entities": []}, {"text": "However, in contrast to the above mentioned papers the focus of our work is on multiword expressions, and we will compare the performance of our algorithm when applied to multiword expressions and when applied to single words.", "labels": [], "entities": []}, {"text": "There has been some previous work on identifying the translations of multiword units using comparable corpora, such as,, ;.", "labels": [], "entities": [{"text": "identifying the translations of multiword units", "start_pos": 37, "end_pos": 84, "type": "TASK", "confidence": 0.803611695766449}]}, {"text": "However, none of this work utilizes aligned comparable documents, and the underlying assumption is that the translation of a multiword unit can be determined by looking at its components individually, and by merging the results.", "labels": [], "entities": []}, {"text": "In contrast, we try to explore whether the translation of a multiword unit can be determined solely by looking at its contextual behavior, i.e. whether it is possible to also apply the standard approach as successfully used for single words.", "labels": [], "entities": []}, {"text": "The underlying fundamental question is whether the meaning of a multiword unit is determined by the contextual behavior of the full unit, or by the contextual behavior of its components (or by a mix of both).", "labels": [], "entities": []}, {"text": "But multiword expressions are of complex nature, as expressed e.g. by: \"there is no unified phenomenon to describe but rather a complex of features that interact in various, often untidy, ways and represent abroad continuum between non-compositional (or idiomatic) and compositional groups of words.\"", "labels": [], "entities": []}, {"text": "The current paper is an attempt to systematically approach one aspect of this complexity.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a manual evaluation like the one described above is time consuming and subjective, we thought about how we could efficiently come up with a gold standard for multiword expressions with the aim of conducting a large scale automatic evaluation.", "labels": [], "entities": []}, {"text": "We had the idea to determine the correspondences between our English and German MWEs via translation information as extracted from a word-aligned parallel corpus.", "labels": [], "entities": []}, {"text": "Such data we had readily at hand from a previous project called COMTRANS.", "labels": [], "entities": [{"text": "COMTRANS", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8596920967102051}]}, {"text": "During this project we had constructed a large bilingual dictionary of bigrams, i.e. of pairs of adjacent words in the source language.", "labels": [], "entities": []}, {"text": "For constructing the dictionary, we word-aligned the English and German parts of the Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.9747191667556763}]}, {"text": "For this purpose, using Moses default settings, we combined two symmetric runs of Giza++, which considerably improves alignment quality.", "labels": [], "entities": [{"text": "alignment", "start_pos": 118, "end_pos": 127, "type": "TASK", "confidence": 0.9438808560371399}]}, {"text": "Then we determined and extracted for each English bigram the German word or word sequence which had been used for its translation.", "labels": [], "entities": []}, {"text": "Discontinuities of one or several word positions were allowed and were indicated by the wildcard '*'.", "labels": [], "entities": []}, {"text": "As the above method for word alignment produces many unjustified empty assignments (i.e. assignments where a source language word pair is erroneously assumed to have no equivalent in the target language sentence), so that the majority of these is incorrect, all empty assignments were removed from the dictionary.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.802249550819397}]}, {"text": "In the dictionary, for each source language word pair its absolute frequency and the absolute and relative frequencies of its translation(s) are given.", "labels": [], "entities": []}, {"text": "To filter out spurious assignments, thresholds of 2 for the absolute and 10% for the relative frequency of a translation were used.", "labels": [], "entities": []}, {"text": "The resulting dictionary is available online.", "labels": [], "entities": []}, {"text": "shows a small extract of the altogether 371,590 dictionary entries.", "labels": [], "entities": []}, {"text": "Alternatively, we could have started from a Moses phrase table, but it was easier for us to use our own data.", "labels": [], "entities": []}, {"text": "Although the quality of our bigram dictionary seems reasonably good, it contains a lot of items which are not really interesting multiword expressions (e.g. arbitrary word sequences such as credible if or the discontinuous word sequences on the target language side).", "labels": [], "entities": []}, {"text": "For this reason we filtered the dictionary using the lists of Wikipe-dia-derived multiword expressions as described in section 2.1.", "labels": [], "entities": []}, {"text": "These contained 418,627 items for English and 1,212,341 candidate items for German (the latter included unigram compounds).", "labels": [], "entities": []}, {"text": "That is, in the dictionary those items were removed where either the English side did not match any of the English MWEs, or where the German side did not match any of the German candidates.", "labels": [], "entities": []}, {"text": "This intersection resulted in a reduction of our bigram dictionary from 371,590 items to 137,701 items.", "labels": [], "entities": []}, {"text": "shows the results after filtering the items listed in.", "labels": [], "entities": []}, {"text": "Note that occasionally reasonable MWEs are eliminated if they happen not to occur in Wikipedia, or if the algorithm for extracting the MWEs does not identify them.", "labels": [], "entities": []}, {"text": "The reduced dictionary we considered as an appropriate gold standard for the automatic evaluation of our system.", "labels": [], "entities": []}, {"text": "As in section 3.2, the next step was to apply the keyword extraction algorithm to the English and the German Wikipedia documents.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7551881074905396}]}, {"text": "Hereby only terms occurring in the gold standard dictionary were taken into account.", "labels": [], "entities": [{"text": "gold standard dictionary", "start_pos": 35, "end_pos": 59, "type": "DATASET", "confidence": 0.9152555267016093}]}, {"text": "But it turned out that, when using the same log-likelihood threshold as in section 3.2, only few keyterms were assigned: on average less than one per document.", "labels": [], "entities": []}, {"text": "This had already been a problem in 3.2, but it was now considerably more severe as this time the MWE lists had been filtered, and as the filtering had been on the basis of another type of corpus (Europarl rather than Wikipedia).", "labels": [], "entities": [{"text": "MWE lists", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.8745873868465424}, {"text": "Europarl", "start_pos": 196, "end_pos": 204, "type": "DATASET", "confidence": 0.98182213306427}]}, {"text": "This is why, after some preliminary experiments with various thresholds, we finally decided to disable the log-likelihood threshold.", "labels": [], "entities": []}, {"text": "Instead, on the English side, all keyterms from the gold standard were used if they occurred at least once in the respective Wikipedia document.", "labels": [], "entities": []}, {"text": "On the German side, as here we had many unigram compounds which tend to be more stable and therefore more repetitive than MWEs, we used the keyterms if the occurred at least twice.", "labels": [], "entities": []}, {"text": "This way for most documents we obtained at least a few keyterms.", "labels": [], "entities": []}, {"text": "When running the WINTIAN algorithm on the parallel keyword lists, in some cases reasonable results were obtained.", "labels": [], "entities": []}, {"text": "For example, for the direction English to German, the system translates information society with Informationsgesellschaft, and education policy with Bildungspolitik.", "labels": [], "entities": []}, {"text": "As WINTIAN is symmetric and can likewise produce a dictionary in the opposite direction, we also generated the results for German to English.", "labels": [], "entities": [{"text": "WINTIAN", "start_pos": 3, "end_pos": 10, "type": "METRIC", "confidence": 0.483089417219162}]}, {"text": "Here, among the good examples, are Telekommunikationsmarkt, which is translated as telecommunications market, and Werbekampagne, which is translated as advertising campaign.", "labels": [], "entities": []}, {"text": "However, these are selected examples showing that the algorithm works in principle.", "labels": [], "entities": []}, {"text": "Of more interest is the quantitative evaluation which is based on thousands of test words and uses the gold standard dictionary.", "labels": [], "entities": [{"text": "gold standard dictionary", "start_pos": 103, "end_pos": 127, "type": "DATASET", "confidence": 0.7384179433186849}]}, {"text": "For English to German we obtained an accuracy of 0.77% if only the top ranked word is taken into account, i.e. if this word matches the expected translation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9995952248573303}]}, {"text": "This improves to 1.6% if it suffices that the expected translation is ranked among the top ten words.", "labels": [], "entities": []}, {"text": "The respective figures for German to English are 1.41% and 2.04%.", "labels": [], "entities": []}, {"text": "The finding that German to English performs better can be explained by the fact that other than English German is a highly inflectional language.", "labels": [], "entities": []}, {"text": "That is, when generating translations it is more likely for German that an inflectional variant not matching the gold standard translation is ranked first, thus adversely affecting performance.", "labels": [], "entities": []}, {"text": "A question more difficult to answer is why the results based on the gold standard are considerably worse than the ones reported in section 3.2 which were based on human judgment.", "labels": [], "entities": []}, {"text": "We seethe following reasons: \u2022 The evaluation in section 3.2 used only a small sample so might be not very reliable.", "labels": [], "entities": []}, {"text": "Also, other than here, it considered only source language words with frequencies above nine.", "labels": [], "entities": []}, {"text": "\u2022 Unlike the candidate expressions, the gold standard data is not lemmatized on the target language side.", "labels": [], "entities": []}, {"text": "\u2022 The hard string matching used for the goldstandard-based evaluation does not allow for inflectional variants.", "labels": [], "entities": []}, {"text": "\u2022 The gold-standard-based evaluation used terms resulting from the intersection of term lists based on Wikipedia and Europarl.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.9749772548675537}]}, {"text": "It is clear that this led to a reduction of average term frequency (if measured on the basis of Wikipedia), thus increasing the problem of data sparseness.", "labels": [], "entities": [{"text": "average term frequency", "start_pos": 44, "end_pos": 66, "type": "METRIC", "confidence": 0.7125731408596039}]}, {"text": "\u2022 As for the same reason the log-likelihood threshold had to be abandoned, on average less salient terms had to be used.", "labels": [], "entities": []}, {"text": "This is likely to additionally reduce accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9975007176399231}]}, {"text": "\u2022 For many terms the gold standard lists several possible translations.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.8943952322006226}]}, {"text": "In the current implementation of the evaluation algorithm only one of them is counted as correct.", "labels": [], "entities": []}, {"text": "However, in the human evaluation any reasonable translation was accepted.", "labels": [], "entities": [{"text": "translation", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9534240365028381}]}, {"text": "\u2022 Some reasonable MWE candidates extracted from Wikipedia are not present in the gold standard, for example credible evidence, credible source, and credible witness are not frequent enough in Europarl to be selected for alignment.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 192, "end_pos": 200, "type": "DATASET", "confidence": 0.9889194369316101}]}, {"text": "We should perhaps mention that it would be possible to come up with better looking accuracies by presenting results for selected subsets of the source language terms.", "labels": [], "entities": []}, {"text": "For example, one could concentrate on terms with particularly good cov-erage.", "labels": [], "entities": []}, {"text": "Another possibility would be to consider MWEs consisting of nouns only.", "labels": [], "entities": [{"text": "MWEs consisting of nouns", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.8350430876016617}]}, {"text": "This we actually did by limiting source and target language vocabulary (of MWEs) to compound nouns.", "labels": [], "entities": []}, {"text": "The results were as follows: English to German (top 1): 1.81% English to German (top 10): 3.75% German to English (top 1): 2.03% German to English (top 10): 3.16% As can be seen, these results look somewhat better.", "labels": [], "entities": []}, {"text": "But this is only for the reason that translating compound nouns appears to be a comparatively easier task on average.", "labels": [], "entities": [{"text": "translating compound nouns", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.9252055486043295}]}], "tableCaptions": [{"text": " Table 1. English and German keyterms for 'Airbus 320 fam- ily' (lists truncated). Score = log-likelihood score; f = occur- rence frequency of keyterm; NN = noun; VV = verb; AR =  article; AP = article+preposition; JJ = adjective; CC = con- junction; RP = preposition.", "labels": [], "entities": [{"text": "Airbus 320 fam- ily", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.9246124029159546}, {"text": "occur- rence frequency", "start_pos": 117, "end_pos": 139, "type": "METRIC", "confidence": 0.9379844814538956}, {"text": "RP", "start_pos": 251, "end_pos": 253, "type": "METRIC", "confidence": 0.9218949675559998}]}, {"text": " Table 2. Computed translations for Stra\u00dfe.", "labels": [], "entities": []}, {"text": " Table 3. Sample results for translation directions EN \u2192 DE  and DE \u2192 EN.", "labels": [], "entities": []}]}