{"title": [], "abstractContent": [{"text": "Implicit opinions are commonly seen in opinion-oriented documents, such as political editorials.", "labels": [], "entities": []}, {"text": "Previous work have utilized opinion inference rules to detect implicit opinions evoked by events that positively/negatively affect entities (good-For/badFor) to improve sentiment analysis for English text.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.929542064666748}]}, {"text": "Since people in different languages may express implicit opinions in different ways, in this work we investigate implicit opinions expressed via goodFor/badFor events in Chinese.", "labels": [], "entities": []}, {"text": "The positive results have provided evidences that such implicit opinions and inference rules are similar in Chinese and in English.", "labels": [], "entities": []}, {"text": "Moreover, we have observed cases where the inferences are blocked.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the opinion-oriented documents, many opinions are expressed implicitly rather than explicitly.", "labels": [], "entities": []}, {"text": "Consider the following example from ): EX(1.1) The reform would lower healthcare costs, which would be a tremendous positive change across the entire health-care system.", "labels": [], "entities": [{"text": "EX", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.8817209005355835}]}, {"text": "There is an explicit positive sentiment (positive) toward the event of reform lower costs.", "labels": [], "entities": []}, {"text": "In expressing this sentiment, the writer implies he is negative toward the costs, because he's happy to seethe costs being decreased.", "labels": [], "entities": []}, {"text": "The writer maybe positive toward reform since it conducts the lower event.", "labels": [], "entities": []}, {"text": "Such inferences maybe seen as opinion-oriented implicatures (i.e., defeasible inferences) . We create an annotated corpus (denoted DCW corpus) and generalizes such events, defining a badFor (bf) event to bean event that negatively affects the object and a goodFor (gf) event to bean event that positively affects the object of the event.", "labels": [], "entities": [{"text": "DCW corpus)", "start_pos": 131, "end_pos": 142, "type": "DATASET", "confidence": 0.9062607487042745}]}, {"text": "Here, lower is a bf event.", "labels": [], "entities": []}, {"text": "According to the annotation scheme, goodFor/badFor (hereafter gfbf ) events have NP agents and objects (though the agent maybe implicit), and the polarity of a gf event maybe changed to bf by a reverser (and vice versa).", "labels": [], "entities": []}, {"text": "We have developed a set of rules for inferring implicit sentiments, from explicit sentiments and gfbf events ).", "labels": [], "entities": []}, {"text": "We incorporate the rules into a graph-based model, which significantly improves classifying the sentiments toward agents and objects in the gfbf events.", "labels": [], "entities": []}, {"text": "The contribution of this work is investigating implicatures in a second language, specifically in Chinese.", "labels": [], "entities": []}, {"text": "People in different languages may express implicit opinions in different ways, so it is better to first assess similarity of implicatures in the two languages, rather than to directly utilize the English resources.", "labels": [], "entities": [{"text": "similarity", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9506152272224426}]}, {"text": "In this work we conduct an agreement study for gfbf information in Chinese.", "labels": [], "entities": []}, {"text": "The good agreement scores provide evidence for the existence of similar implicature in Chinese.", "labels": [], "entities": []}, {"text": "During the analysis of disagreement, we have observed interesting gfbf events triggered by Chinese syntax, which are rare in English but common in Chinese.", "labels": [], "entities": []}, {"text": "We should provide additional guidance for such events when developing a Chinese gfbf manual in the future.", "labels": [], "entities": [{"text": "Chinese gfbf manual", "start_pos": 72, "end_pos": 91, "type": "DATASET", "confidence": 0.7920151352882385}]}, {"text": "We run the graph-based model on the annotated Chinese corpus.", "labels": [], "entities": []}, {"text": "The good evaluation results support our hypothesis that the inference rules in English apply for Chinese.", "labels": [], "entities": []}, {"text": "Moreover, we have observed gfbf cases where the sentiment inferences are blocked, which are similar to what we have found in English ( ).", "labels": [], "entities": [{"text": "sentiment inferences", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.792582631111145}]}, {"text": "Further, we analyze gfbf words and syntax of agents/objects in Chinese.", "labels": [], "entities": []}, {"text": "Our analysis shows that it is feasible to extract components of Chinese gfbf events utilizing the existing resources.", "labels": [], "entities": []}, {"text": "In the last section we briefly talk bout the Chinese explicit sentiment analysis.", "labels": [], "entities": [{"text": "Chinese explicit sentiment analysis", "start_pos": 45, "end_pos": 80, "type": "TASK", "confidence": 0.6762437671422958}]}], "datasetContent": [{"text": "We use the same measurement for agreement for all types of spans.", "labels": [], "entities": [{"text": "agreement", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9155732989311218}]}, {"text": "(The type is either gfbf, agent, or object).", "labels": [], "entities": []}, {"text": "Suppose A is a set of annotations of a particular type and B is the set of annotations of the same type from the other annotator.", "labels": [], "entities": []}, {"text": "For any text span a \u2208 A and b \u2208 B, the span coverage c counts the percentage of overlapping Chinese characters between a and b, where |a| is the number of characters in span a, and \u2229 gives the set of characters that two spans have in common.", "labels": [], "entities": []}, {"text": "Following (, we treat each set A and B in turn as the gold-standard and calculate the average F-measure (agr(A, B)).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9960461258888245}, {"text": "agr", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9260700345039368}]}, {"text": "Now that we have the sets of annotations on which the annotators agree, we use \u03ba (Artstein and Poesio, 2008) to measure agreement for the attributes.", "labels": [], "entities": []}, {"text": "We report three \u03ba values: one for the polarities of the gfbf events, and the other two for the writer's attitudes toward the agents and objects.", "labels": [], "entities": []}, {"text": "Three annotator participate in the agreement study.", "labels": [], "entities": []}, {"text": "All of them are Chinese graduate students studying in US.", "labels": [], "entities": []}, {"text": "One of them is the co-author of this work (Anno 1), while the other two do not know details of gfbf and implicature before (Anno2, Anno3).", "labels": [], "entities": []}, {"text": "Since Anno1 is familiar with this work, we compare the other two's annotations to Anno1's.", "labels": [], "entities": [{"text": "Anno1", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.9077516198158264}]}, {"text": "In, the upper half is the agreement for span overlapping (agr(A, B)), and the lower half is the agreement for attribute (\u03ba).", "labels": [], "entities": []}, {"text": "The result have shown that the annotators have good agreement scores, though our training period is not long and our training data cover multiple topics.", "labels": [], "entities": []}, {"text": "In particular, the annotators agree quite well on recognizing the agents and objects and judging the polarity of gfbf events.", "labels": [], "entities": []}, {"text": "For recognizing gfbf events, we have found two interesting gfbf cases caused by the Chinese syntax that is different from English, elaborated in the next section.", "labels": [], "entities": []}, {"text": "Among the spans only one annotator marks, one third is due to the two cases above; one third are borderlines that could be marked; one third are incorrect.", "labels": [], "entities": []}, {"text": "For the spans two annotator mark but the third doesn't, we regard it as negligence.", "labels": [], "entities": []}, {"text": "For judging the writer's attitudes toward agents and objects, we can see from that Anno 2 and Anno 3 behave differently.", "labels": [], "entities": []}, {"text": "This is understandable because we are marking the implicit opinions of the writer.", "labels": [], "entities": []}, {"text": "Though trained, different annotators have different thresholds for judging whether an opinion is expressed here.", "labels": [], "entities": []}, {"text": "Some annotators maybe more sensitive than the others.", "labels": [], "entities": []}, {"text": "If we don't count the spans that one annotator marks it as none (i.e. neutral) but the other doesn't, the \u03ba scores increase a lot, as Row Polar shows in.", "labels": [], "entities": []}, {"text": "This indicates that the annotators mainly disagree on whether the sentiment is neutral or not, rather than the polarity of opinions.", "labels": [], "entities": []}, {"text": "To further investigate whether the disagreement is caused by Chinese, or is due to the annotators' inherent different sensitivities of opinions, we randomly select 5 documents from the DCW corpus, delete the writer's attitude toward agents and objects but keep the remaining annotations.", "labels": [], "entities": [{"text": "DCW corpus", "start_pos": 185, "end_pos": 195, "type": "DATASET", "confidence": 0.9654757082462311}]}, {"text": "The an-: \u03ba for Agreement Study Analysis.", "labels": [], "entities": [{"text": "Agreement Study Analysis", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.8321052591005961}]}, {"text": "notators are then told to mark the attitudes.", "labels": [], "entities": []}, {"text": "As Row Eng in shows, we have got consistent agreement results within the same annotators when they annotate in English and in Chinese.", "labels": [], "entities": []}, {"text": "This supports the idea that the differences between the annotators are differences on the underlying task, regardless of the language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for Agreement Study Analysis.", "labels": [], "entities": [{"text": "Agreement Study Analysis", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8293622533480326}]}, {"text": " Table 2: \u03ba for Agreement Study Analysis.", "labels": [], "entities": [{"text": "Agreement Study Analysis", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.8601996699968973}]}, {"text": " Table 3: Performance of Graph-Based Model in  Chinese.", "labels": [], "entities": []}]}