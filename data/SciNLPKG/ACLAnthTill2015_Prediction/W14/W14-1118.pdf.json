{"title": [], "abstractContent": [{"text": "The documentation of a care episode consists of clinical notes concerning patient care, concluded with a discharge summary.", "labels": [], "entities": []}, {"text": "Care episodes are stored electronically and used throughout the healthcare sector by patients, administrators and professionals from different areas, primarily for clinical purposes, but also for secondary purposes such as decision support and research.", "labels": [], "entities": [{"text": "decision support", "start_pos": 223, "end_pos": 239, "type": "TASK", "confidence": 0.9300200343132019}]}, {"text": "A common use case is, given a-possibly unfinished-care episode, to retrieve the most similar care episodes among the records.", "labels": [], "entities": []}, {"text": "This paper presents several methods for information retrieval, focusing on care episode retrieval, based on textual similarity, where similarity is measured through domain-specific modelling of the distributional semantics of words.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7698165476322174}, {"text": "care episode retrieval", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.618243396282196}]}, {"text": "Models include variants of random indexing and a semantic neural network model called word2vec.", "labels": [], "entities": []}, {"text": "A novel method is introduced that utilizes the ICD-10 codes attached to care episodes to better induce domain-specificity in the semantic model.", "labels": [], "entities": [{"text": "ICD-10 codes", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.7979960441589355}]}, {"text": "We report on an experimental evaluation of care episode retrieval that circumvents the lack of human judgements regarding episode relevance by exploiting (1) ICD-10 codes of care episodes and (2) semantic similarity between their discharge summaries.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.651438424984614}]}, {"text": "Results suggest that several of the methods proposed outperform a state-of-the art search engine (Lucene) on the retrieval task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information retrieval (IR) aims at retrieving and ranking documents relative to a textual query expressing the information need of a user.", "labels": [], "entities": [{"text": "Information retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8709078311920166}]}, {"text": "IR has become a crucial technology for many organisations that deal with vast amounts of partly structured and unstructured (free text) data stored in electronic format, including hospitals and other healthcare providers.", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9476748108863831}]}, {"text": "IR is an essential part of the clinical practice; e.g., on-line IR systems are associated with substantial improvements in clinicians decision-making concerning clinical problems).", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9664552211761475}]}, {"text": "The different stages of the clinical care of a patient are documented in clinical care notes, consisting mainly of free text.", "labels": [], "entities": []}, {"text": "A care episode consists of a sequence of individual clinical care notes, concluded by a discharge summary, as illustrated in.", "labels": [], "entities": []}, {"text": "Care episodes are stored in electronic format in electronic health record (EHR) systems.", "labels": [], "entities": []}, {"text": "These systems are used throughout the healthcare sector by patients, administrators and professionals from different areas, primarily for clinical purposes, but also for secondary purposes such as decision support and research.", "labels": [], "entities": [{"text": "decision support", "start_pos": 197, "end_pos": 213, "type": "TASK", "confidence": 0.9200868904590607}]}, {"text": "IR from EHR in general is therefore a common and important task.", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9738662242889404}]}, {"text": "This paper focuses on the particular task of retrieving those care episodes that are most similar to the sequence of clinical notes fora given patient, which we will call care episode retrieval.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 171, "end_pos": 193, "type": "TASK", "confidence": 0.6205647587776184}]}, {"text": "In conventional IR, the query typically consists of several keywords or a short phrase, while the retrievable units are typically documents.", "labels": [], "entities": [{"text": "IR", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9800721406936646}]}, {"text": "In contrast, in care episode retrieval, the query consist of the clinical notes contained in a care episode.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.5864438116550446}]}, {"text": "The discharge summary is used separately for evalu- Figure 1: Illustration of care episode retrieval.", "labels": [], "entities": [{"text": "Illustration of care episode retrieval", "start_pos": 62, "end_pos": 100, "type": "TASK", "confidence": 0.545328414440155}]}, {"text": "The two care episodes (A and B) are composed of a number of individual clinical notes and a single discharge summary.", "labels": [], "entities": []}, {"text": "Given an ongoing care episode (minus the discharge summary), the task is to retrieve other, similar care episodes.", "labels": [], "entities": []}, {"text": "ation purposes, and is assumed to be unavailable for constructing a query at retrieval time.", "labels": [], "entities": []}, {"text": "Retrievable units are thus complete care episodes without summaries.", "labels": [], "entities": []}, {"text": "We envision a number of different use cases fora care episode retrieval system.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.637201855580012}]}, {"text": "Firstly, it could facilitate clinicians in decision-making.", "labels": [], "entities": []}, {"text": "For example, given a patient that is being treated in a hospital, an involved clinician may want to find previous patients that are similar in terms of their health history, symptoms or received treatments.", "labels": [], "entities": []}, {"text": "Supplementary input from the clinician would enable the system to give heightened weight to keywords of particular interest within the care episodes, which would further be emphasized in the semantic similarity calculation during IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 230, "end_pos": 232, "type": "TASK", "confidence": 0.982744038105011}]}, {"text": "It may help considerably to see what similar patients have received in terms of medication and further treatment, what related issues such as bi-conditions or risks occurred, how other clinicians have described certain aspects, what clinical practice guidelines have been utilized, and soon.", "labels": [], "entities": []}, {"text": "This relates to the underlying principle in textual case-based reasoning ().", "labels": [], "entities": [{"text": "textual case-based reasoning", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.5768431524435679}]}, {"text": "Secondly, it could help management to get almost real time information concerning the overall situation on the unit fora specific follow-up period.", "labels": [], "entities": []}, {"text": "Such a system could for example support managerial decision-making with statistical information concerning care trends on the unit, adverse events or infections.", "labels": [], "entities": []}, {"text": "Thirdly, it could facilitate knowledge discovery and research.", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7845028042793274}]}, {"text": "For instance, it could enable researchers to map or cluster similar care episodes to find common symptoms or conditions.", "labels": [], "entities": []}, {"text": "In sum, care episode retrieval is likely to improve care quality and consistency in hospitals.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.697938084602356}, {"text": "consistency", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.9825683832168579}]}, {"text": "From the perspective of NLP, care episode retrieval -and IR from EHRs in general -is a challenging task.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.6501464943091074}, {"text": "IR", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9615005850791931}]}, {"text": "It differs from general-purpose web search in that the vocabulary, the information needs and the queries of clinicians are highly specialised.", "labels": [], "entities": []}, {"text": "Clinical notes contain highly domain-specific terminology) and generic text processing resources are therefore often suboptimal or inadequate.", "labels": [], "entities": []}, {"text": "At the same time, development of dedicated clinical NLP tools and resources is often difficult and costly.", "labels": [], "entities": []}, {"text": "For example, popular data-driven approaches to NLP are based on supervised learning, which requires substantial amounts of tailored training data, typically built through manual annotation by annotators who need both linguistic and clinical knowledge.", "labels": [], "entities": [{"text": "NLP", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.943240761756897}]}, {"text": "Additionally, variations in the language and terminology used in sub-domains within and across healthcare organisations greatly limit the scope of applicability of such training data.", "labels": [], "entities": []}, {"text": "Recent work has shown that distributional models of semantics, induced in an unsupervised manner from large corpora of clinical and/or medical text, are well suited as a resource-light approach to capturing and representing domain-specific terminology (.", "labels": [], "entities": []}, {"text": "This raises the question to what extent distributional models of semantics can alleviate the aforementioned problems of NLP in the clinical domain.", "labels": [], "entities": []}, {"text": "The work reported here investigates to what extent distributional models of semantics, built from a corpus of clinical text in an fully unsupervised manner, can be used for care episode retrieval.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.669649342695872}]}, {"text": "Models include several variants of random indexing and a semantic neural network model called word2vec, which will be described in more detail in Section 4.", "labels": [], "entities": []}, {"text": "It has been argued that clinical NLP should exploit existing knowledge resources such as knowledge bases about medications, treatments, diseases, symptoms and care plans, despite these not having been explicitly built for doing clinical NLP (.", "labels": [], "entities": []}, {"text": "Along these lines, a novel method is proposed here that utilizes the ICD-10 codes -diagnostic labels attached to care episodes by clinicians -to better induce domain-specificity in the semantic model.", "labels": [], "entities": [{"text": "ICD-10 codes", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.8212080597877502}]}, {"text": "Experimental results suggest that this method outperforms a state-of-the art search engine (Lucene) on the task of care episode retrieval.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.6135905881722769}]}, {"text": "Apart from issues related to clinical terminology, another problem in care episode retrieval is the lack of benchmark data, such as the relevance scores produced by human judges commonly used for evaluation of IR systems.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.5997462371985117}, {"text": "IR", "start_pos": 210, "end_pos": 212, "type": "TASK", "confidence": 0.9318966865539551}]}, {"text": "Although collections of care episodes maybe available, producing gold standard similarity scores required for evaluation is costly.", "labels": [], "entities": [{"text": "similarity", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.7420332431793213}]}, {"text": "Another contribution of this paper is the proposal of evaluation procedures that circumvent the lack of human judgements regarding episode similarity.", "labels": [], "entities": []}, {"text": "This is accomplished by exploiting either (1) ICD-10 codes of care episodes or (2) semantic similarity between their discharge summaries.", "labels": [], "entities": [{"text": "ICD-10 codes of care episodes", "start_pos": 46, "end_pos": 75, "type": "DATASET", "confidence": 0.7550000429153443}]}, {"text": "Despite our focus on the specific task of care episode retrieval, we hypothesize that the methods and models proposed here have the potential to increase performance of IR on clinical text in general.", "labels": [], "entities": [{"text": "care episode retrieval", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.5773044725259145}, {"text": "IR", "start_pos": 169, "end_pos": 171, "type": "TASK", "confidence": 0.9964160919189453}]}], "datasetContent": [{"text": "In these experiments we strove to have a setup that was as comparable as possible for all models and systems, both in terms of text pre-processing and in terms of the target model dimensionality when inducing the vector space models.", "labels": [], "entities": []}, {"text": "The clin-ical notes are split into sentences, tokenized, and lemmatized using a Constraint-Grammar based morphological analyzer and tagger extended with clinical vocabulary.", "labels": [], "entities": []}, {"text": "After stop words were removed 1 , the total training corpus contained 39 million words (minus the query episodes), while the evaluation subset contained 18.5 million words.", "labels": [], "entities": []}, {"text": "The vocabulary consisted of 0.6 million unique terms.", "labels": [], "entities": []}, {"text": "Twenty care episodes were randomly selected to serve as the query episodes during testing, with the requirement that each had different ICD-10 codes and consisted of a minimum of six clinical notes.", "labels": [], "entities": [{"text": "ICD-10", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.7791246771812439}]}, {"text": "The average number of words per query episode is 830.", "labels": [], "entities": []}, {"text": "RI-based and word2vec models have a predefined dimensionality of 800.", "labels": [], "entities": []}, {"text": "For RI-based models, 4 non-zeros were used in the index vectors.", "labels": [], "entities": []}, {"text": "For the RI-Word model, a narrow context window was employed (5 left + 5 right), weighting index vectors according to their distance to the target word (weight i = 2 1\u2212dist it ).", "labels": [], "entities": []}, {"text": "In addition, the index vectors were shifted once left or right depending on what side of the target word they were located, similar to direction vectors as described in) These parameters for RI were chosen based on previous work on semantic textual similarity.", "labels": [], "entities": [{"text": "RI", "start_pos": 191, "end_pos": 193, "type": "TASK", "confidence": 0.9588272571563721}]}, {"text": "Also a much larger window of 20+20 was tested, but without noteworthy improvements.", "labels": [], "entities": []}, {"text": "The word2vec model is trained with the BoW architecture and otherwise default parameters.", "labels": [], "entities": [{"text": "BoW architecture", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.9490396678447723}]}, {"text": "In addition to Apache Lucene (version 4.2.0) 2 , the word2vec tool 3 was used to train the word2vec model, and the RI-based methods utilized the JavaSDM package . Scores were calculated using the trec eval tool 5 .  In this experiment retrieved episodes with a primary ICD-10 code identical to that of the query episode were considered to be correct.", "labels": [], "entities": []}, {"text": "The number of correct episodes varies between 49 and 1654.", "labels": [], "entities": []}, {"text": "The total is 7721, and the average is 386.", "labels": [], "entities": []}, {"text": "The high total is mainly due to three query episodes with ICD-10 codes that occur very frequently in the episode collection: Mean average precision and precision at 10 for retrieval of care episodes with the same primary ICD-10 code as the query episode 1654 times).", "labels": [], "entities": [{"text": "Mean average precision", "start_pos": 125, "end_pos": 147, "type": "METRIC", "confidence": 0.8389349778493246}, {"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9984763264656067}]}, {"text": "When conducting the experiment all care episodes were retrieved for each of the 20 query episodes.", "labels": [], "entities": []}, {"text": "Performance was measured in terms of mean average precision (MAP) and precision among the top-10 results (P@10), averaged overall 20 queries, as shown in in.", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 37, "end_pos": 65, "type": "METRIC", "confidence": 0.906121701002121}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9991623163223267}, {"text": "P@10)", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.903114452958107}]}, {"text": "The best MAP score is achieved by RI-ICD, almost twice that of word2vec, which achieved the second best MAP score, whereas RI-Word performed worst of all.", "labels": [], "entities": []}, {"text": "All models score well above the random baseline, whereas RI-ICD outperforms Lucene by a large margin.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 76, "end_pos": 82, "type": "DATASET", "confidence": 0.9318525195121765}]}, {"text": "P@10 scores follow the same ranking.", "labels": [], "entities": []}, {"text": "The latter scores are more representative for most use cases where users will only inspect the top-n retrieval results.", "labels": [], "entities": []}, {"text": "In this experiment retrieved episodes with a discharge summary similar to that of the query episode were considered to be correct.", "labels": [], "entities": []}, {"text": "Using the discharge summaries of the query episodes, the top 100 care episodes with the most similar discharge summary were selected as the most similar care episodes (disregarding the query episode).", "labels": [], "entities": []}, {"text": "This was repeated for each of the methods -i.e. the five different semantic models and Luceneresulting in six different tests.", "labels": [], "entities": [{"text": "Luceneresulting", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.7885252833366394}]}, {"text": "The top 100 was used rather than a threshold on the similarity score, because otherwise six different thresholds would have to be chosen.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 52, "end_pos": 68, "type": "METRIC", "confidence": 0.9632480144500732}]}, {"text": "This procedure thus resulted in six different test collections, each consisting of 20 query episodes with their corresponding 100 most similar collection episodes.", "labels": [], "entities": []}, {"text": "Subsequently a 6-by-6 experimental design was followed where each retrieval method was tested against each test set construction method.", "labels": [], "entities": []}, {"text": "At retrieval time, for each query episode, the system retrieves and ranks 1000 care episodes.", "labels": [], "entities": []}, {"text": "It can be expected that when identical methods are used for re-trieval and test set construction, the resulting bias gives rise to relatively high scores.", "labels": [], "entities": [{"text": "test set construction", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7012162009874979}]}, {"text": "In contrast, averaging over the scores for all six construction methods is assumed to be a less biased indicator of performance.", "labels": [], "entities": []}, {"text": "shows the number of correctly retrieved episodes by the different models, with the maximum being 2000 (20 queries times 100 most similar episodes).", "labels": [], "entities": []}, {"text": "This gives an indication of the recall among a 1000 retrieved episodes per query, but without caring about precision or ranking.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9984563589096069}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9990776777267456}]}, {"text": "In general, the numbers are relatively good when the same model is used for both retrieval and construction of the test set (cf. values on the diagonal), although in a couple of cases (e.g. with word2vec) results are better with different models.", "labels": [], "entities": []}, {"text": "The RI-ICD model performs best when used for both retrieval and test construction.", "labels": [], "entities": [{"text": "test construction", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.6880810558795929}]}, {"text": "Looking at the averages, which presumably are less biased indicators, RI-ICD and word2vec seem to have comparable performance, with both of them outperforming Lucene.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 159, "end_pos": 165, "type": "DATASET", "confidence": 0.9365670084953308}]}, {"text": "Other models are less successful, although still much better than the random baseline.", "labels": [], "entities": []}, {"text": "The MAP scores in show similar results, although here RI-ICD yields the best average score.", "labels": [], "entities": [{"text": "MAP", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9178174138069153}, {"text": "RI-ICD", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9452982544898987}]}, {"text": "Both models RI-ICD and word2vec outperform Lucene.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.9668400883674622}]}, {"text": "Again the RI-ICD model performs exceptionally well when used for both retrieval and test construction.", "labels": [], "entities": []}, {"text": "Finally presents precision for top-10 retrieved care episodes.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9983956217765808}]}, {"text": "Here RI-Doc yields the best average scores, while RI-ICD and word2vec both perform slightly worse.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Mean average precision and precision at  10 for retrieval of care episodes with the same pri- mary ICD-10 code as the query episode", "labels": [], "entities": [{"text": "Mean average", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9034568667411804}, {"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.5833600759506226}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9993259906768799}]}, {"text": " Table 2: Number of correctly retrieved episodes (max 2000) for different IR models (rows) when using  different models for measuring discharge summary similarity (columns)", "labels": [], "entities": []}, {"text": " Table 4: Precision at top-10 retrieved episodes for different IR models (rows) when using different  models for measuring discharge summary similarity (columns)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9877275228500366}]}]}