{"title": [{"text": "WoNeF, an improved, expanded and evaluated automatic French translation of WordNet", "labels": [], "entities": [{"text": "WoNeF", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.928753674030304}, {"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.8169264197349548}]}], "abstractContent": [{"text": "Automatic translations of WordNet have been tried to many different target languages.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.9030935764312744}]}, {"text": "JAWS is such a translation for French nouns using bilingual dictionaries and a syntactic language model.", "labels": [], "entities": [{"text": "JAWS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9628300666809082}]}, {"text": "We improve its precision and coverage, complete it with translations of other parts of speech and enhance its evaluation method.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9992923736572266}, {"text": "coverage", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8109813928604126}]}, {"text": "The result is named WoNeF.", "labels": [], "entities": [{"text": "WoNeF", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.7600260376930237}]}, {"text": "We produce three final translations balanced between precision (up to 93%) and coverage (up to 109 447 (literal, synset) pairs).", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9991075396537781}, {"text": "coverage", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.995235025882721}]}], "introductionContent": [{"text": "Reproducing the lexicographic work of WordNet) for other languages is costly and difficult to maintain.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.9315484762191772}]}, {"text": "Even with some theoretical problems, show that translating Princeton WordNet literals while keeping its structure and its synsets leads to useful linguistic resources.", "labels": [], "entities": [{"text": "translating Princeton WordNet literals", "start_pos": 47, "end_pos": 85, "type": "TASK", "confidence": 0.6557156890630722}]}, {"text": "WordNet automatic translations use the expand approach: its structure is preserved and only literals are translated.", "labels": [], "entities": [{"text": "WordNet automatic translations", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7400584518909454}]}, {"text": "Three main techniques represent this approach in the literature.", "labels": [], "entities": []}, {"text": "The simplest one seeds WordNet using bilingual dictionaries (, which can be filtered manually by lexicographers.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.9378483295440674}]}, {"text": "A second translation method uses parallel corpora, which avoids the use of dictionaries that may cause lexical bias.", "labels": [], "entities": []}, {"text": "Back-translations between Norwegian and English were first explored), while) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation.", "labels": [], "entities": []}, {"text": "Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de or improve existing ones).", "labels": [], "entities": []}, {"text": "The French EuroWordNet) has a limited coverage and requires significant improvements to be used (.", "labels": [], "entities": [{"text": "French EuroWordNet)", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.8575449784596761}]}, {"text": "It is also neither free nor freely accessible, which prevented the community from using and improving it.", "labels": [], "entities": []}, {"text": "WOLF is a second French translation originally built using parallel corpora and since then expanded using various techniques.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9541518092155457}]}, {"text": "WOLF is distributed under a free LGPL-compatible license.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9385027885437012}]}, {"text": "Finally, JAWS (Mouton and ) is a translation of WordNet nouns developed using bilingual dictionaries and a syntactic language model.", "labels": [], "entities": [{"text": "JAWS", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.7986389398574829}]}, {"text": "Our work expands and improves the techniques used in JAWS and evaluates it based on the adjudication of two annotators work.", "labels": [], "entities": [{"text": "JAWS", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.7694854736328125}]}, {"text": "The result is called WoNeF 1 and is distributed under the LGPL-LR licence.", "labels": [], "entities": [{"text": "WoNeF 1", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.7149036228656769}, {"text": "LGPL-LR licence", "start_pos": 58, "end_pos": 73, "type": "DATASET", "confidence": 0.8748962879180908}]}, {"text": "To our knowledge, all current WordNet machine translations only exist in one version where the authors decide what metric to optimize.", "labels": [], "entities": [{"text": "WordNet machine translations", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.765841563542684}]}, {"text": "We provide such aversion, but add two resources that can serve different needs and have been obtained using different means.", "labels": [], "entities": []}, {"text": "The main WoNeF has an Fscore of 70.9%.", "labels": [], "entities": [{"text": "WoNeF", "start_pos": 9, "end_pos": 14, "type": "DATASET", "confidence": 0.742890477180481}, {"text": "Fscore", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9965073466300964}]}, {"text": "Another version has a precision of 93.3%, and the last one contains 109 447 (literal, synset) pairs.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9982106685638428}]}, {"text": "The main contributions of this paper are the improvement and completion of JAWS with all parts of speech (section 3) and its evaluation (sections 4 and 5).", "labels": [], "entities": [{"text": "completion", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9706507325172424}, {"text": "JAWS", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.6494594216346741}]}, {"text": "The evaluation is done through an adjudication itself validated by measuring the inter-annotator agreement, which validates the expand approach to translate WordNet.", "labels": [], "entities": [{"text": "translate WordNet", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.739956259727478}]}], "datasetContent": [{"text": "Using our gold standard to compare WOLF and WoNeF would unfairly penalize WOLF for all correct words not present in our dictionaries.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.8119453191757202}, {"text": "WoNeF", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.8643638491630554}]}, {"text": "Conversely, we cannot consider WOLF as a direct reference as WOLF itself is not fully validated.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.8644545078277588}]}, {"text": "The last publication giving overall WOLF figures) indicates a number of pairs around 77 000 with 86% precision 3 . We thus compare the intersections between the high-precision WoNeF (93.3% precision) and WOLF 0.1.4 and 1.0b (  The column gives the number of translations that are present in WoNeF but not in WOLF.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.6223903894424438}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9955378770828247}, {"text": "WoNeF", "start_pos": 176, "end_pos": 181, "type": "DATASET", "confidence": 0.9097352027893066}, {"text": "precision", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.9680717587471008}, {"text": "WoNeF", "start_pos": 291, "end_pos": 296, "type": "DATASET", "confidence": 0.9260187149047852}, {"text": "WOLF", "start_pos": 308, "end_pos": 312, "type": "DATASET", "confidence": 0.9477719068527222}]}, {"text": "The detailed results for WOLF 1.0b are not currently available.", "labels": [], "entities": [{"text": "WOLF 1.0b", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.8323321044445038}]}, {"text": "For nouns, verbs and adjectives, it means that we contribute 10 914 new high precision (literal, synset) pairs by merging WoNeF and WOLF 1.0, in other words 94% of the high precision WoNeF pairs which shows how much the two approaches are complementary: different literals are selected.", "labels": [], "entities": []}, {"text": "This produces a French wordnet 10% larger than WOLF with an improved accuracy.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.6838954091072083}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9982120990753174}]}, {"text": "A merging with the high F-score resource would be slightly less precise, but it would provide 81 052 new (literal, synset) pairs comparing to WOLF 1.0b, resulting in a merge containing 73 712 non-empty synsets and 188,657 (literal, synset) pairs, increasing WOLF coverage by 75% and the WoNeF one by 63%.", "labels": [], "entities": [{"text": "WOLF coverage", "start_pos": 258, "end_pos": 271, "type": "METRIC", "confidence": 0.5124416649341583}, {"text": "WoNeF", "start_pos": 287, "end_pos": 292, "type": "DATASET", "confidence": 0.8294126987457275}]}], "tableCaptions": [{"text": " Table 2: Gold standard inter-annotator agreement", "labels": [], "entities": []}, {"text": " Table 3: Top part: Precision, Recall and  F1-measure of initial selectors on all translations  (nouns, verbs and adjectives). Bottom part: scores  for various combinations of them. Coverage C is  the total number of pairs (literal, synset).", "labels": [], "entities": [{"text": "Precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9967389702796936}, {"text": "Recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9971364736557007}, {"text": "F1-measure", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9928096532821655}]}, {"text": " Table 4: Global results for all synsets and BCS  synsets only.", "labels": [], "entities": []}, {"text": " Table 5: Results by part of speech. Horizontal  parts give scores for the high-precision resource  (PR), the high-F1-measure one (F1R) and the  high coverage one (CR). JAWS containing only  nouns, it is compared with the high F-score  nominal WoNeF resource.", "labels": [], "entities": [{"text": "F1R", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.9905704259872437}, {"text": "coverage one (CR)", "start_pos": 150, "end_pos": 167, "type": "METRIC", "confidence": 0.7142951905727386}, {"text": "JAWS", "start_pos": 169, "end_pos": 173, "type": "DATASET", "confidence": 0.887839138507843}, {"text": "F-score", "start_pos": 227, "end_pos": 234, "type": "METRIC", "confidence": 0.9685025215148926}]}, {"text": " Table 6: Intersections between the high precision  WoNeF and WOLF 0.1.4 and 1.0b. \u2282 is the  percentage of WoNeF pairs included in WOLF  and \u2283 is the percentage of WOLF pairs included  in WoNeF.", "labels": [], "entities": []}]}