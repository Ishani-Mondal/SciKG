{"title": [{"text": "Using Hypothesis Selection Based Features for Confusion Network MT System Combination", "labels": [], "entities": [{"text": "Confusion Network MT", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.6588491797447205}]}], "abstractContent": [{"text": "This paper describes the development operated into MANY, an open source system combination software based on confusion networks developed at LIUM.", "labels": [], "entities": [{"text": "LIUM", "start_pos": 141, "end_pos": 145, "type": "DATASET", "confidence": 0.942211389541626}]}, {"text": "The hypotheses from Chinese-English MT systems were combined with anew version of the software.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9013614654541016}]}, {"text": "MANY has been updated in order to use word confidence score and to boost n-grams occurring in input hypotheses.", "labels": [], "entities": [{"text": "MANY", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6207047700881958}, {"text": "word confidence score", "start_pos": 38, "end_pos": 59, "type": "METRIC", "confidence": 0.8435583909352621}]}, {"text": "In this paper we propose either to use an adapted language model or adding some additional features in the decoder to boost certain n-grams probabilities.", "labels": [], "entities": []}, {"text": "Experimental results show that the updates yielded significant improvements in terms of BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9783334732055664}]}], "introductionContent": [{"text": "MANY () is an open source system combination software based on Confusion Networks (CN).", "labels": [], "entities": []}, {"text": "The combination by confusion networks generates an exponential number of hypotheses.", "labels": [], "entities": []}, {"text": "Most of these hypotheses contain ngrams do not exist in input hypotheses.", "labels": [], "entities": []}, {"text": "Some of these new n-grams are ungrammatical, despite the presence of a language model.", "labels": [], "entities": []}, {"text": "These novel ngrams are due to errors in hypothesis alignment and the confusion network structure.", "labels": [], "entities": [{"text": "hypothesis alignment", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7042725831270218}]}, {"text": "In section 3 we present two methods used to boost n-grams present in input hypotheses.", "labels": [], "entities": []}, {"text": "Currently, decisions taken by the decoder mainly depend on the language model score, which is deemed insufficient to precisely evaluate the hypotheses.", "labels": [], "entities": []}, {"text": "In consequence, it is interesting to estimate a score for better judging their quality.", "labels": [], "entities": []}, {"text": "The challenge of our work is to exploit certain parameters defined by to calculate word confidence score.", "labels": [], "entities": [{"text": "word confidence score", "start_pos": 83, "end_pos": 104, "type": "METRIC", "confidence": 0.8140518267949423}]}, {"text": "These features are detailed in section 4.", "labels": [], "entities": []}, {"text": "The approach is evaluated on the internal data of the BOLT project.", "labels": [], "entities": [{"text": "BOLT project", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.8434686660766602}]}, {"text": "Some experiments have been performed on the Chinese-English system combination task.", "labels": [], "entities": [{"text": "Chinese-English system combination task", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.6623610109090805}]}, {"text": "The experimental results are presented in section 5.", "labels": [], "entities": []}, {"text": "Before that, a quick description of MANY, including recent developments can be found in section 2. 2 System description MANY is a system combination software) based on the decoding of a lattice made of several Confusion Networks (CN).", "labels": [], "entities": []}, {"text": "This is a widespread approach in MT system combination, see e.g. (Antti-Veikko I.).", "labels": [], "entities": [{"text": "MT system combination", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.8903459509213766}]}, {"text": "MANY can be decomposed in two main modules.", "labels": [], "entities": [{"text": "MANY", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8503221869468689}]}, {"text": "The first one is the alignment module which is a modified version of TERp (Matthew G..", "labels": [], "entities": [{"text": "alignment", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9750520586967468}, {"text": "TERp", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.6911622881889343}]}, {"text": "Its role is to incrementally align the hypotheses against a backbone in order to create a confusion network.", "labels": [], "entities": []}, {"text": "1-best hypotheses from all M systems are aligned in order to build M confusion networks (one for each system considered as backbone).", "labels": [], "entities": []}, {"text": "These confusion networks are then connected together to create a lattice.", "labels": [], "entities": []}, {"text": "This module uses different costs (which corresponds to a match, an insertion, a deletion, a substitution, a shift, a synonym and a stem) to compute the best alignment and incrementally build a confusion network.", "labels": [], "entities": []}, {"text": "In the case of confusion network, the match (substitution, synonym, and stem) costs are considered when the word in the hypothesis matches (is a substitution, a synonym or a stem of) at least one word of the considered confusion sets in the CN.", "labels": [], "entities": []}, {"text": "The second module is the decoder.", "labels": [], "entities": []}, {"text": "This decoder is based on the token pass algorithm and it accepts as input the lattice previously created.", "labels": [], "entities": []}, {"text": "The probabilities computed in the decoder can be expressed as follow : where t is the hypothesis, the \u03b1 i are the weights of the feature functions hi . The following features are considered for decoding: \u2022 The language model probability: the probability given by a 4-gram language model.", "labels": [], "entities": []}, {"text": "\u2022 The word penalty: penalty depending on the size (in words) of the hypothesis.", "labels": [], "entities": [{"text": "word penalty", "start_pos": 6, "end_pos": 18, "type": "METRIC", "confidence": 0.8099312484264374}]}, {"text": "\u2022 The null-arc penalty: penalty depending on the number of null-arcs crossed in the lattice to obtain the hypothesis.", "labels": [], "entities": []}, {"text": "\u2022 System weights: each system receives a weight according to its importance.", "labels": [], "entities": []}, {"text": "Each word receives a weight corresponding to the sum of the weights of all systems which proposed it.", "labels": [], "entities": []}, {"text": "Our goal is to include the following ones: \u2022 Word confidence score: each word is given a score, which is the combination of the three scores described in section 4 (equation 7).", "labels": [], "entities": [{"text": "Word confidence score", "start_pos": 45, "end_pos": 66, "type": "METRIC", "confidence": 0.8036422332127889}]}, {"text": "\u2022 n-gram count: number of n-grams present in input hypotheses for each combined hypothesis.", "labels": [], "entities": []}, {"text": "In most cases, the new features have best weights according to MERT (e.g. the best decoding weights of these features by combining two systems are: lm-weight: 0.049703, word-penalty: 0.0605602, null-penalty: 0.319905, weight-word-score: -0.378226, weight-ngramcount: -0.11687, priors: 0.0141794#-0.0605561).", "labels": [], "entities": [{"text": "MERT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.7522007822990417}]}], "datasetContent": [{"text": "During experiments, data from the BOLT project on the Chinese to English translation task are used.", "labels": [], "entities": [{"text": "BOLT project", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.829448789358139}, {"text": "Chinese to English translation task", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.6686085104942322}]}, {"text": "The outputs (200-best lists) of eight translation systems were provided by the partners.", "labels": [], "entities": []}, {"text": "The best six systems were used for combination.", "labels": [], "entities": []}, {"text": "Syscomtune is used as development set and Dev as internal test, these corpora are described in To explore the impact of each new feature on the results, they are tested one by one (added one by one in the decoder) then both, given that, the oldest ones are used in all cases.", "labels": [], "entities": []}, {"text": "These tests are named respectively boost-ngram, CS-ngram and Boost-ngram+CS-ngram later.", "labels": [], "entities": [{"text": "Boost-ngram", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.939857006072998}]}, {"text": "The language model is used to guide the decoding in order to improve translation quality, therefore we evaluated the baseline combination system and each test (described above) with two LMs named LM-Web and LM-ad and compared their performance in terms of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 256, "end_pos": 260, "type": "METRIC", "confidence": 0.9975947737693787}]}, {"text": "By comparing their perplexities, that are respectively 295.43 and 169.923, we observe a relative reduction of about 42.5%, that results in an improvement of BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 157, "end_pos": 167, "type": "METRIC", "confidence": 0.9797420501708984}]}, {"text": "shows the results of combining the best systems (up to 6) using these models, that achieved respectively an improvement of 0.85 and 1.17 %BLEU point relatively to the best single system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.9996780157089233}]}, {"text": "In the remaining experiments we assume that MANY-LM-Web is the baseline.", "labels": [], "entities": [{"text": "MANY-LM-Web", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.7091229557991028}]}, {"text": "shows interesting differences in how approaches to boost n-gram estimates behave when the number of input systems is varied.", "labels": [], "entities": []}, {"text": "This is due to the fact that results are conditioned by the number and quality of n-grams added to the lattice when the number of systems is varied, that provides varied outputs.", "labels": [], "entities": []}, {"text": "In consequence, we observe that using the adapted LM is better than n-gram count feature to boost n-grams, indeed it guarantees n-grams quality.", "labels": [], "entities": []}, {"text": "The 200-best lists are operated to estimate the word confidence score that contributes the most to the improvement of results when several (up to 6) systems are combined, as described in, whatever the language model used, compared to the baseline.", "labels": [], "entities": [{"text": "word confidence score", "start_pos": 48, "end_pos": 69, "type": "METRIC", "confidence": 0.7611646254857382}]}, {"text": "In addition, it seems that the confidence score performs better with the adapted LM than LM-Web.", "labels": [], "entities": [{"text": "confidence", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9819190502166748}]}, {"text": "summarizes the best experiments results by combining the best six systems on the test set.", "labels": [], "entities": []}, {"text": "We observe that new features yield significant improvements in term of BLEU score whatever the language model used for decoding.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9857009649276733}]}, {"text": "But it is clear that the adapted LM performs relatively well in comparison with LM-Web, so the best gains achieved over the best single system and the baseline are respectively 1.49 and 0.71 for CS-3-gram+LM-ad.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Impact of new features and the adapted LM on the", "labels": [], "entities": []}]}