{"title": [{"text": "System Description: Dependency-based Pre-ordering for Japanese-Chinese Machine Translation", "labels": [], "entities": [{"text": "Japanese-Chinese Machine Translation", "start_pos": 54, "end_pos": 90, "type": "TASK", "confidence": 0.5793197353680929}]}], "abstractContent": [{"text": "This paper describes the Beijing Jiao-tong University Japanese-Chinese machine translation system which participated in the 1st Workshop on Asian Translation (WAT 2014).", "labels": [], "entities": [{"text": "Beijing Jiao-tong University Japanese-Chinese", "start_pos": 25, "end_pos": 70, "type": "DATASET", "confidence": 0.8760547339916229}, {"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7605931460857391}, {"text": "1st Workshop on Asian Translation (WAT 2014)", "start_pos": 124, "end_pos": 168, "type": "TASK", "confidence": 0.7435213360521529}]}, {"text": "We propose a pre-ordering approach based on dependency parsing for Japanese-Chinese statistical machine translation (SMT).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7040616273880005}, {"text": "statistical machine translation (SMT)", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.7708922723929087}]}, {"text": "Our system achieves a BLEU of 24.12 and a RIBES of 79.48 on the Japanese-Chinese translation task in the official evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9998660087585449}, {"text": "RIBES", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9997256398200989}, {"text": "Japanese-Chinese translation", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.5499772280454636}]}], "introductionContent": [{"text": "Difference in word order between source language and target language will cause troubles in word alignment and further affect the quality of statistical machine translation (SMT).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.7645460665225983}, {"text": "statistical machine translation (SMT)", "start_pos": 141, "end_pos": 178, "type": "TASK", "confidence": 0.775307352344195}]}, {"text": "Therefore, it becomes an issue in SMT, especially in the language pairs where there are great difference in word order between source language and target language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9961463212966919}]}, {"text": "Syntax-based pre-ordering has demonstrated effectiveness in previous research.", "labels": [], "entities": []}, {"text": "These kinds of approaches first parse the sentences in the side of source language.", "labels": [], "entities": []}, {"text": "Then pre-ordering rules are applied to the created parse trees, in order to obtain source language sentences which have similar word order with target language sentences.", "labels": [], "entities": []}, {"text": "Finally, the reordered source language sentences are used in the SMT system, not only in training, but also in tuning and translating.", "labels": [], "entities": [{"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9908541440963745}, {"text": "translating", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.6757199168205261}]}, {"text": "In other words, all of the sentences in the training set, the development set and the test set should be reordered while applying these kinds of approaches.", "labels": [], "entities": []}, {"text": "Since parsing is required in pre-ordering approaches, two popular parsing are often considered, i.e. constituent parsing and dependency parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.677626833319664}, {"text": "dependency parsing", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.7822027206420898}]}, {"text": "Constituent parsing has been employed in pre-ordering for the translation of EnglishFrench (), GermanyEnglish (), Chinese-English (, etc. and shown its effectiveness.", "labels": [], "entities": [{"text": "translation of EnglishFrench", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.7385262648264567}, {"text": "GermanyEnglish", "start_pos": 95, "end_pos": 109, "type": "DATASET", "confidence": 0.9715968370437622}]}, {"text": "In recent years, more and more pre-ordering research used dependency parsing for the translation of Arabic-English, English-SOV languages ( and ChineseEnglish (), because the accuracy of dependency parsing is greatly improved.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.871833324432373}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9984478950500488}, {"text": "dependency parsing", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.7052254378795624}]}, {"text": "This paper introduces a Japanese-Chinese SMT system which employs a pre-ordering approach based on dependency parsing.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9384428262710571}, {"text": "dependency parsing", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.7140540182590485}]}, {"text": "Since Japanese is a language with a fairly free word order, dependency parsing can describe the relation between two Japanese cases in a sentence better than constituent parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8071251809597015}, {"text": "constituent parsing", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.7531740963459015}]}, {"text": "Therefore, we adopt dependency parsing for pre-ordering.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7799542844295502}]}, {"text": "Experimental results show that our approach can improve the BLEU score on the test set by 0.18, compared with the baseline system (without pre-ordering).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9807239472866058}]}, {"text": "Section 2 describes some issues in JapaneseChinese translation and proposes our dependencybased pre-ordering approach.", "labels": [], "entities": [{"text": "JapaneseChinese translation", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.8079984188079834}]}, {"text": "Section 3 reports on our experiment results on a Japanese-Chinese phrase-based SMT (PBSMT) system.", "labels": [], "entities": []}, {"text": "Section 4 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Section 2 describes our dependency-based preordering approach for the translation of JapaneseChinese.", "labels": [], "entities": [{"text": "translation of JapaneseChinese", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.7788787285486857}]}, {"text": "This section reports on our experiments and evaluation results.", "labels": [], "entities": []}, {"text": "We use MOSES PBSMT system (  in our experiments and use BLEU scores () and RIBES score () for evaluation.", "labels": [], "entities": [{"text": "MOSES PBSMT", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.6031203866004944}, {"text": "BLEU scores", "start_pos": 56, "end_pos": 67, "type": "METRIC", "confidence": 0.9670340418815613}, {"text": "RIBES score", "start_pos": 75, "end_pos": 86, "type": "METRIC", "confidence": 0.9844271540641785}]}, {"text": "The data sets are from the ASPEC JapaneseChinese paper excerpt corpus.", "labels": [], "entities": [{"text": "ASPEC JapaneseChinese paper excerpt corpus", "start_pos": 27, "end_pos": 69, "type": "DATASET", "confidence": 0.7988960206508636}]}, {"text": "The training data contains 672,315 sentences, the development data contains 2,090 sentences and the test data contains 2,107 sentences.", "labels": [], "entities": []}, {"text": "We use a bilingual-based approach proposed in for Chinese word segmentation, in which n-gram feature from the raw Chinese part and word alignment from the parallel corpus are introduced to augment the conventional model based on annotation data.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6366695066293081}]}, {"text": "We employ the KNP parser 2 for Japanese dependency parsing.", "labels": [], "entities": [{"text": "Japanese dependency parsing", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.6227664252122244}]}, {"text": "The KNP parser can create dependency tree fora Japanese sentence and provide the part-of-speech (POS) for each word, both of which are used in our dependency-based preordering approach.", "labels": [], "entities": [{"text": "part-of-speech (POS)", "start_pos": 81, "end_pos": 101, "type": "METRIC", "confidence": 0.7170380502939224}]}, {"text": "After Japanese dependency trees are obtained, we conduct pre-ordering on the training set, the development set and the test set by applying the pre-ordering rules described in Section 2.2.", "labels": [], "entities": []}, {"text": "The reordered data sets are then used in training, tuning and test in the Japanese-Chinese PBSMT system.", "labels": [], "entities": [{"text": "Japanese-Chinese PBSMT system", "start_pos": 74, "end_pos": 103, "type": "DATASET", "confidence": 0.739827960729599}]}, {"text": "On the other hand, data sets without pre-: Comparisons of the pre-ordering system and the baseline system.: Human evaluation for 200 reordered sentences, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Groups of the cases and their sequence  numbers.", "labels": [], "entities": []}, {"text": " Table 2: Comparisons of the pre-ordering system and the baseline system.", "labels": [], "entities": []}, {"text": " Table 3: Human evaluation for 200 reordered sentences, respectively.", "labels": [], "entities": []}]}