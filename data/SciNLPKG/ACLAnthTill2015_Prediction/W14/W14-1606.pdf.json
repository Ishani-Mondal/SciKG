{"title": [{"text": "Inducing Neural Models of Script Knowledge", "labels": [], "entities": [{"text": "Inducing Neural Models of Script Knowledge", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8331099152565002}]}], "abstractContent": [{"text": "Induction of commonsense knowledge about prototypical sequence of events has recently received much attention (e.g., Chambers and Jurafsky (2008); Regneri et al. (2010)).", "labels": [], "entities": []}, {"text": "Instead of inducing this knowledge in the form of graphs, as in much of the previous work, in our method, distributed representations of event real-izations are computed based on distributed representations of predicates and their arguments , and then these representations are used to predict prototypical event or-derings.", "labels": [], "entities": []}, {"text": "The parameters of the composi-tional process for computing the event representations and the ranking component of the model are jointly estimated.", "labels": [], "entities": []}, {"text": "We show that this approach results in a substantial boost in performance on the event ordering task with respect to the previous approaches, both on natural and crowd-sourced texts.", "labels": [], "entities": [{"text": "event ordering task", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8115527629852295}]}], "introductionContent": [{"text": "It is generally believed that natural language understanding systems would benefit from incorporating common-sense knowledge about prototypical sequences of events and their participants.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6556470592816671}]}, {"text": "Early work focused on structured representations of this knowledge (called scripts () and manual construction of script knowledge bases.", "labels": [], "entities": []}, {"text": "However, these approaches do not scale to complex domains).", "labels": [], "entities": []}, {"text": "More recently, automatic induction of script knowledge from text have started to attract attention: these methods exploit either natural texts) or crowdsourced data (, and, consequently, do not require expensive expert annotation.", "labels": [], "entities": []}, {"text": "Given a text corpus, they extract structured representations (i.e. graphs), for example chains or more general directed acyclic graphs ().", "labels": [], "entities": []}, {"text": "These graphs are scenario-specific, nodes in them correspond to events (and associated with sets of potential event mentions) and arcs encode the temporal precedence relation.", "labels": [], "entities": []}, {"text": "These graphs can then be used to inform NLP applications (e.g., question answering) by providing information whether one event is likely to precede or succeed another.", "labels": [], "entities": [{"text": "question answering)", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.9304523865381876}]}, {"text": "Note that these graphs encode common-sense knowledge about prototypical ordering of events rather than temporal order of events as described in a given text.", "labels": [], "entities": []}, {"text": "Though representing the script knowledge as graphs is attractive from the human interpretability perspective, it may not be optimal from the application point of view.", "labels": [], "entities": []}, {"text": "More specifically, these representations (1) require a model designer to choose an appropriate granularity of event mentions (e.g., whether nodes in the graph should be associated with verbs, or also their arguments); (2) do not provide a mechanism for deciding which scenario applies in a given discourse context and (3) often do not associate confidence levels with information encoded in the graph (e.g., the precedence relation in).", "labels": [], "entities": []}, {"text": "Instead of constructing a graph and using it to provide information (e.g., prototypical event ordering) to NLP applications, in this work we advocate for constructing a statistical model which is capable to \"answer\" at least some of the questions these graphs can be used to answer, but doing this without explicitly representing the knowledge as a graph.", "labels": [], "entities": [{"text": "prototypical event ordering)", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.7796254754066467}]}, {"text": "In our method, the distributed representations (i.e. vectors of real numbers) of event realizations are computed based on distributed representations of predicates and their arguments, and then the event representations are used in a ranker to predict the prototypical ordering of events.", "labels": [], "entities": []}, {"text": "Both the parameters of the compositional process for computing the event representation and the rank-ing component of the model are estimated from texts (either relying on unambiguous discourse clues or natural ordering in text).", "labels": [], "entities": []}, {"text": "In this way we build on recent research on compositional distributional semantics (), though our approach specifically focuses on embedding predicate-argument structures rather than arbitrary phrases, and learning these representation to be especially informative for prototypical event ordering.", "labels": [], "entities": [{"text": "prototypical event ordering", "start_pos": 268, "end_pos": 295, "type": "TASK", "confidence": 0.6828019022941589}]}, {"text": "In order to get an intuition why the embedding approach maybe attractive, consider a situation where a prototypical ordering of events the bus disembarked passengers and the bus drove away needs to be predicted.", "labels": [], "entities": []}, {"text": "An approach based on frequency of predicate pairs) (henceforth CJ08), is unlikely to make aright prediction as driving usually precedes disembarking.", "labels": [], "entities": [{"text": "CJ08", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.9141630530357361}, {"text": "aright", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9796716570854187}]}, {"text": "Similarly, an approach which treats the whole predicate-argument structure as anatomic unit ( will probably fail as well, as such a sparse model is unlikely to be effectively learnable even from large amounts of unlabeled data.", "labels": [], "entities": []}, {"text": "However, our embedding method would be expected to capture relevant features of the verb frames, namely, the transitive use for the predicate disembark and the effect of the particle away, and these features will then be used by the ranking component to make the correct prediction.", "labels": [], "entities": []}, {"text": "In previous work on learning inference rules, it has been shown that enforcing transitivity constraints on the inference rules results in significantly improved performance.", "labels": [], "entities": []}, {"text": "The same is likely to be true for the event ordering task, as scripts have largely linear structure, and observing that a \u227a band b \u227a c is likely to imply a \u227a c.", "labels": [], "entities": [{"text": "event ordering task", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8037026127179464}]}, {"text": "Interestingly, in our approach we learn the model which satisfies transitivity constraints, without the need for any explicit global optimization on a graph.", "labels": [], "entities": []}, {"text": "This results in a significant boost of performance when using embeddings of just predicates (i.e. ignoring arguments) with respect to using frequencies of ordered verb pairs, as in CJ08 (76% vs. 61% on the natural data).", "labels": [], "entities": [{"text": "CJ08", "start_pos": 181, "end_pos": 185, "type": "DATASET", "confidence": 0.9228319525718689}]}, {"text": "Our model is solely focusing on the ordering task, and admittedly does not represent all the information encoded by a script graph structure.", "labels": [], "entities": []}, {"text": "For example, it cannot be directly used to predict a missing event given a set of events (the narrative cloze task f (e) arg embedding hidden layer h Ah: Computation of an event representation fora predicate with two arguments (the bus disembarked passengers), an arbitrary number of arguments is supported by our approach.", "labels": [], "entities": []}, {"text": "ertheless, we believe that the framework (a probabilistic model using event embeddings as its component) can be extended to represent other aspects of script knowledge by modifying the learning objective, but we leave this for future work.", "labels": [], "entities": []}, {"text": "In this paper, we show how our model can be used to predict if two event mentions are likely paraphrases of the same event.", "labels": [], "entities": []}, {"text": "The approach is evaluated in two set-ups.", "labels": [], "entities": []}, {"text": "First, we consider the crowdsourced dataset of and demonstrate that using our model results in the 13.5% absolute improvement in F 1 on event ordering with respect to their graph induction method (84.1% vs. 70.6%).", "labels": [], "entities": [{"text": "F 1", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.9796699583530426}]}, {"text": "Secondly, we derive an event ordering dataset from the Gigaword corpus, where we also show that the embedding method beats the frequency-based baseline (i.e. reimplementation of the scoring component of CJ08) by 22.8% inaccuracy (83.5% vs. 60.7%).", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9699917137622833}, {"text": "CJ08", "start_pos": 203, "end_pos": 207, "type": "DATASET", "confidence": 0.9568925499916077}]}], "datasetContent": [{"text": "We evaluate our approach in two different set-ups.", "labels": [], "entities": []}, {"text": "First, we induce the model from the crowdsourced data specifically collected for script induction by, secondly, we consider an arguably more challenging set-up of learning the model from news data (), in the latter case we use a learning scenario inspired by", "labels": [], "entities": [{"text": "script induction", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.8446311950683594}]}], "tableCaptions": [{"text": " Table 2: Paraphrasing results on the crowdsourced  data for Regneri et al. (2010) (MSA), Frermann  et al. (2014)", "labels": [], "entities": []}]}