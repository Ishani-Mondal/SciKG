{"title": [{"text": "Problematic Situation Analysis and Automatic Recognition for Chi- nese Online Conversational System", "labels": [], "entities": [{"text": "Problematic Situation Analysis", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8362759550412496}, {"text": "Automatic Recognition", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.656224250793457}]}], "abstractContent": [{"text": "Automatic problematic situation recognition (PSR) is important for an online conversational system to constantly improve its performance.", "labels": [], "entities": [{"text": "Automatic problematic situation recognition (PSR)", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7151893888201032}]}, {"text": "A PSR module is responsible of automatically identifying users' un-satisfactions and then sending feedbacks to conversation managers.", "labels": [], "entities": []}, {"text": "In this paper, we collect dialogues from a Chinese online chatbot, annotate the problematic situations and propose a framework to predict utterance-level problematic situations by integrating intent and sentiment factors.", "labels": [], "entities": []}, {"text": "Different from previous work, the research field is set as open-domain in which very few domain specific textual features could be used and the method is easy to be adapted to other domains.", "labels": [], "entities": []}, {"text": "Experimental results show that integrating both intent and sentiment factors gains the best performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic conversational systems are computer programs that interact with human users based on their knowledge bases.", "labels": [], "entities": []}, {"text": "Developers of conversational systems devote plenty of efforts and time in collecting and verifying knowledge so as to maximize the information needs of potential users.", "labels": [], "entities": []}, {"text": "However, problematic situations are inevitable due to several reasons (i.e. human verifiers would make mistakes or omissions, or quality of some answers couldn't be judged without certain contexts).", "labels": [], "entities": []}, {"text": "So it is necessary to equip a conversational system with an automatic PSR module to keep its performance constantly improved.", "labels": [], "entities": []}, {"text": "The program is responsible of monitoring whether the dialogue or some utterances are problematic during interactions and then providing feedbacks to the dialogue managers.", "labels": [], "entities": []}, {"text": "Problematic situations reflect that a human user is not satisfied with answers that a conversational system offers.", "labels": [], "entities": []}, {"text": "From one perspective, some of these un-satisfactions can be captured through a human user's dialogue acts.", "labels": [], "entities": []}, {"text": "For example, if a user repeats requesting the same question or frequently changes topics, it is likely that the system provides unsatisfactory answers).", "labels": [], "entities": []}, {"text": "From another perspective, some explicit manners (i.e. sentiment-related expressions or dissatisfied feelings) that reflect the change of a user's mentality would also indicate a problematic situation occurs.", "labels": [], "entities": []}, {"text": "Some previous systems use surveys to capture users' satisfactions: they let users to vote or evaluate whether the system has perfectly help them complete certain tasks) so as to collect users' satisficing scores.", "labels": [], "entities": []}, {"text": "However, fora real-world conversational application, there are very few users who are willing to provide this kind of feedbacks.", "labels": [], "entities": []}, {"text": "The dialogue materials for this research come from a Chinese online chatting robot-BIT, which is developed for chatting and entertainment.", "labels": [], "entities": []}, {"text": "It also integrates real-time data query functions about share price, weather report, post-code and telephone area code lookup.", "labels": [], "entities": []}, {"text": "In addition to queries about real-time data, the corpus is totally open-domain and the number of topics that a dialogue could be related is unlimited.", "labels": [], "entities": []}, {"text": "We annotated problematic situation labels in the utterance level (whether a question-answer pair is problematic/whether an answer is problematic) and took a deeper analysis towards different cases.", "labels": [], "entities": []}, {"text": "Finally, we introduce the PSR framework.", "labels": [], "entities": [{"text": "PSR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9344550967216492}]}, {"text": "This framework is simple but efficient: we mapped the user intent and user sentiment categories to two groups of representative features and predicted problematic situations with supervised learners.", "labels": [], "entities": []}, {"text": "Our main contributions stem from the features, domains and language: Unlike most previous researchers who considered only user intent) or took offline satisfaction scores provided by users as user sentiment, our method integrates intent and sentiment in an online manner, which automatically identifies these two factors and gives the managers realtime feedbacks.", "labels": [], "entities": []}, {"text": "The domain of the dialogue is open which is different from ().", "labels": [], "entities": []}, {"text": "Another contribution is that this is the first work that solves this issue on the Chinese language, which has very different language specific features and resources from English.", "labels": [], "entities": []}, {"text": "We experimented on the corpus through 10-fold cross validation.", "labels": [], "entities": []}, {"text": "In each individual fold, we compare our method with two baselines and with four popular classifiers.", "labels": [], "entities": []}, {"text": "Results show that integrating both user intent and user sentiment factors gains the best performance with an average F 1 of 0.62 (by SVM).", "labels": [], "entities": [{"text": "F 1", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9973675310611725}]}, {"text": "Following, we first introduce related work o PSR from different perspectives.", "labels": [], "entities": []}, {"text": "Introduction to the corpus are arranged next.", "labels": [], "entities": []}, {"text": "The feature selections and the recognition framework are proposed in Section 4.", "labels": [], "entities": []}, {"text": "Experiments, future work and conclusions constitute the rest.", "labels": [], "entities": []}], "datasetContent": [{"text": "To prove the effectiveness of our model, we compare it with two baselines on four classical classifiers through 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "The baselines include the model with general features (GF) and intent specified features (ISF), the model with GF and sentiment specified features (SSF).", "labels": [], "entities": []}, {"text": "We name our hybrid model that with hybrid features as GF+ISF+SSF.", "labels": [], "entities": []}, {"text": "We report the detailed performance gains of the GF+ISF+SSF model compared with the two baselines with intense experiments on the corpus.", "labels": [], "entities": []}, {"text": "General features (GF) only contains little useful information towards our task and has very poor performance, therefore we didn't set it as a baseline.", "labels": [], "entities": []}, {"text": "We test the model with SVM, Na\u00ef ve Bayes, Decision Tree and CRF so as to find out an efficient and stable learner for the task.", "labels": [], "entities": [{"text": "Na\u00ef ve Bayes", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.818027396996816}]}], "tableCaptions": [{"text": " Table 3. User intent specific features.", "labels": [], "entities": []}, {"text": " Table 5. Average performance by cross- validation.", "labels": [], "entities": []}, {"text": " Table 6. Detailed results in 10-fold cross validation.  -im-in\u2016 and -im-sen\u2016 stand for the improvements of the hybrid model than intent and sentiment spe- cific models. -Percent.\u2016 stands for the proportion% of problematic utterances in this fold of data.", "labels": [], "entities": []}]}