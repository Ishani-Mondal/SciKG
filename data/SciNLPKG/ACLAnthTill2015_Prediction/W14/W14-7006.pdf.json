{"title": [{"text": "Predicate-Argument Structure-based Preordering for Japanese-English Statistical Machine Translation of Scientific Papers", "labels": [], "entities": [{"text": "Predicate-Argument Structure-based Preordering", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8392205834388733}, {"text": "Statistical Machine Translation of Scientific Papers", "start_pos": 68, "end_pos": 120, "type": "TASK", "confidence": 0.7999097804228464}]}], "abstractContent": [{"text": "Translating Japanese to English is difficult because they belong to different language families.", "labels": [], "entities": [{"text": "Translating Japanese to English", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8990561962127686}]}, {"text": "Na\u00a8\u0131veNa\u00a8\u0131ve phrase-based statistical machine translation (SMT) often fails to address syntactic difference between Japanese and English.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 13, "end_pos": 63, "type": "TASK", "confidence": 0.7203743755817413}]}, {"text": "Preordering methods are one of the simple but effective approaches that can model reordering in along distance, which is crucial in translating Japanese and English.", "labels": [], "entities": []}, {"text": "Thus, we apply a predicate-argument structure-based pre-ordering method to the Japanese-English statistical machine translation task of scientific papers.", "labels": [], "entities": [{"text": "Japanese-English statistical machine translation task of scientific papers", "start_pos": 79, "end_pos": 153, "type": "TASK", "confidence": 0.7242338806390762}]}, {"text": "Our method is based on the method described in (Hoshino et al., 2013), and extends their rules to handle abbreviation and passivization frequently found in scientific papers.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed method improves performance of both (Hoshino et al., 2013)'s system and our phrase-based SMT baseline without preordering.", "labels": [], "entities": [{"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.8174010515213013}]}], "introductionContent": [{"text": "Preordering method is one of the popular techniques in statistical machine translation.", "labels": [], "entities": [{"text": "Preordering", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9017292857170105}, {"text": "statistical machine translation", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.7680833141009012}]}, {"text": "Preordering the word order of source language in advance can enhance alignments on a pair of languages with a large difference in syntax like japanese and English, and thus improve performance of machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 196, "end_pos": 215, "type": "TASK", "confidence": 0.7285681962966919}]}, {"text": "One of the advantages of preordering is that it can incorporate rich linguistic information on the source side, whilst off-the-shelf SMT toolkit can be plugged in without any modification.", "labels": [], "entities": [{"text": "SMT toolkit", "start_pos": 133, "end_pos": 144, "type": "TASK", "confidence": 0.8778572082519531}]}, {"text": "Preordering methods employ various kinds of linguistic information to achieve better alignment between source and target languages.", "labels": [], "entities": []}, {"text": "Specifically, previous work in the literature uses morphological analysis, dependency structure and predicate-argument structure () for preordering in Japanese-English statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 168, "end_pos": 199, "type": "TASK", "confidence": 0.592184454202652}]}, {"text": "However, these preordering methods are tested on limited domains: travel () and patent) corpora.", "labels": [], "entities": []}, {"text": "Translating Japanese to English in a different domain such as scientific papers is still a big challenge for preordering-based approach.", "labels": [], "entities": []}, {"text": "For example, academic writing in English traditionally relies on passive voice to give an objective impression, but one can use either passive construction or a zeropronoun in the Japanese translation of passive construction on the English side.", "labels": [], "entities": []}, {"text": "It is not clear whether existing preordering rules are applicable to scientific domain due to such stylistic difference.", "labels": [], "entities": []}, {"text": "Predicate-argument structure-based preordering is one of the promising approaches that can solve syntactic and stylistic difference between a language pair.", "labels": [], "entities": [{"text": "Predicate-argument structure-based preordering", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7427341739336649}]}, {"text": "Predicate-argument structure analysis identifies who does what to whom and generalizes grammatical relations such as active and passive construction.", "labels": [], "entities": [{"text": "Predicate-argument structure analysis", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7769686679045359}]}, {"text": "Following, we perform predicate-argument structure analysis on the Japanese side to preorder Japanese sentences to form an SVO-like word order.", "labels": [], "entities": [{"text": "predicate-argument structure analysis", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8010661800702413}]}, {"text": "We propose three modifications to the preordering rules to extend their model to better handle translation of scientific papers.", "labels": [], "entities": [{"text": "translation of scientific papers", "start_pos": 95, "end_pos": 127, "type": "TASK", "confidence": 0.8794366866350174}]}, {"text": "The main contribution of this work is as follows: \u2022 We propose an extension to () in order to deal with abbreviation and passivization frequently found in scientific papers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compared translation performance using a standard phrase-based statistical machine translation technique with three kinds of data: \u2022 original data (baseline), \u2022 preordered data by our re-implementation of, and \u2022 preordered data by our proposed methods.", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9691707491874695}, {"text": "phrase-based statistical machine translation", "start_pos": 53, "end_pos": 97, "type": "TASK", "confidence": 0.5943198353052139}]}, {"text": "We analyzed predicate-argument structure of only the last predicate for each sentence, regardless of the number of predicates in a sentence.", "labels": [], "entities": []}, {"text": "Also, following), we did not consider event nouns as predicates.", "labels": [], "entities": []}, {"text": "We used 1M Japanese-English parallel sentences extracted from scientific papers (train-1.txt) from the Asian Scientific Paper Excerpt Corpus (ASPEC) . We varied the size of the training corpus and used the best size determined by preliminary experiments.", "labels": [], "entities": [{"text": "Asian Scientific Paper Excerpt Corpus (ASPEC)", "start_pos": 103, "end_pos": 148, "type": "DATASET", "confidence": 0.7544465437531471}]}, {"text": "We identified predicate-argument structure in Japanese by SynCha 4 0.3.", "labels": [], "entities": []}, {"text": "It uses MeCab 5 0.996 with IPADic 2.7.0 for morphological analysis and CaboCha 6 0.68 for dependency parsing.", "labels": [], "entities": [{"text": "MeCab 5 0.996", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.8404708107312521}, {"text": "CaboCha 6 0.68", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.8691732486089071}, {"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8733772039413452}]}, {"text": "We used SRILM 7 1.7.0 for language model, GIZA++ 8 1.0.7 for word alignment, and Moses 9 2.1.1 for decoding.", "labels": [], "entities": [{"text": "SRILM 7 1.7.0", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.8402666250864664}, {"text": "GIZA++ 8 1.0.7", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.7783035039901733}, {"text": "word alignment", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.7974448502063751}]}, {"text": "We set distortion limits to default value 6 for all systems . Translation quality is evaluated in terms of BLEU () and RIBES (, as determined by the workshop organizers ().", "labels": [], "entities": [{"text": "Translation", "start_pos": 62, "end_pos": 73, "type": "TASK", "confidence": 0.9710574746131897}, {"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.99920254945755}, {"text": "RIBES", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.9984790682792664}]}, {"text": "We performed minimum error rate training optimized for BLEU using the development set (dev.txt) of the ASPEC corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.829473078250885}, {"text": "ASPEC corpus", "start_pos": 103, "end_pos": 115, "type": "DATASET", "confidence": 0.8435836732387543}]}, {"text": "We conducted all the experiments using the scripts distributed at KFTT Moses Baseline v1.4 11 . shows the experimental results.", "labels": [], "entities": [{"text": "KFTT Moses Baseline v1.4 11", "start_pos": 66, "end_pos": 93, "type": "DATASET", "confidence": 0.9639563918113708}]}, {"text": "In terms of BLEU, our re-implementation of) is below the baseline method while our proposed methods better than the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9983170032501221}]}, {"text": "In terms of RIBES, all preordering methods outperform the baseline, and our proposed method archieve the highest score.", "labels": [], "entities": [{"text": "RIBES", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.5040732622146606}]}, {"text": "All methods including parenthesis preordering outperform the baseline method, and when we subtract three modifications one by one from proposed method, the parenthesis rule has the largest impact on the translation quality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of the preordering methods. All the preordering models using (", "labels": [], "entities": []}]}