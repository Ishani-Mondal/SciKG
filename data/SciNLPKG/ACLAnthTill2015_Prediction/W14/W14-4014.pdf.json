{"title": [{"text": "Transformation and Decomposition for Efficiently Implementing and Improving Dependency-to-String Model In Moses", "labels": [], "entities": []}], "abstractContent": [{"text": "Dependency structure provides grammatical relations between words, which have shown to be effective in Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 103, "end_pos": 140, "type": "TASK", "confidence": 0.8480451107025146}]}, {"text": "In this paper, we present an open source module in Moses which implements a dependency-to-string model.", "labels": [], "entities": []}, {"text": "We propose a method to transform the input dependency tree into a corresponding constituent tree for reusing the tree-based decoder in Moses.", "labels": [], "entities": []}, {"text": "In our experiments , this method achieves comparable results with the standard model.", "labels": [], "entities": []}, {"text": "Furthermore , we enrich this model via the decomposition of dependency structure, including extracting rules from the sub-structures of the dependency tree during training and creating a pseudo-forest instead of the tree per se as the input during decoding.", "labels": [], "entities": []}, {"text": "Large-scale experiments on Chinese-English and German-English tasks show that the decomposition approach improves the baseline dependency-to-string model significantly.", "labels": [], "entities": []}, {"text": "Our system achieves comparable results with the state-of-the-art hierarchical phrase-based model (HPB).", "labels": [], "entities": []}, {"text": "Finally, when resorting to phrasal rules, the dependency-to-string model performs significantly better than Moses HPB.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency structure models relations between words in a sentence.", "labels": [], "entities": [{"text": "Dependency structure", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7609581053256989}]}, {"text": "Such relations indicate the syntactic function of one word to another word.", "labels": [], "entities": []}, {"text": "As dependency structure directly encodes semantic information and has the best inter-lingual phrasal cohesion properties), it is believed to be helpful to translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 155, "end_pos": 166, "type": "TASK", "confidence": 0.9811191558837891}]}, {"text": "In recent years, dependency structure has been widely used in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9961404204368591}]}, {"text": "For example, present a string-to-dependency model by using the dependency fragments of the neighbouring words on the target side, which makes it easier to integrate a dependency language model.", "labels": [], "entities": []}, {"text": "However such string-to-tree systems run slowly in cubic time).", "labels": [], "entities": []}, {"text": "Another example is the treelet approach ( ), which uses dependency structure on the source side.", "labels": [], "entities": []}, {"text": "extend the treelet approach to allow dependency fragments with gaps.", "labels": [], "entities": []}, {"text": "As the treelet is defined as an arbitrary connected sub-graph, typically both substitution and insertion operations are adopted for decoding.", "labels": [], "entities": []}, {"text": "However, as translation rules based on the treelets do not encode enough reordering information directly, another heuristic or separate reordering model is usually needed to decide the best target position of the inserted words.", "labels": [], "entities": []}, {"text": "Different from these works, Xie et al.", "labels": [], "entities": []}, {"text": "(2011) present a dependency-to-string (Dep2Str) model, which extracts head-dependent (HD) rules from word-aligned source dependency trees and target strings.", "labels": [], "entities": []}, {"text": "As this model specifies reordering information in the HD rules, during translation only the substitution operation is needed, because words are reordered simultaneously with the rule being applied. and extend the model by augmenting HD rules with the help of either constituent tree or fixed/float structure (.", "labels": [], "entities": []}, {"text": "Augmented rules are created by the combination of two or more nodes in the HD fragment, and are capable of capturing translations of non-syntactic phrases.", "labels": [], "entities": []}, {"text": "However, the decoder needs to be changed correspondingly to handle these rules.", "labels": [], "entities": []}, {"text": "Attracted by the simplicity of the Dep2Str model, in this paper we describe an easy way to integrate the model into the popular translation framework Moses (.", "labels": [], "entities": []}, {"text": "In order to share the same decoder with the conventional syntax-based model, we present an algorithm which transforms a dependency tree into a corresponding constituent tree which encodes dependency information in its non-leaf nodes and is compatible with the Dep2Str model.", "labels": [], "entities": [{"text": "Dep2Str", "start_pos": 260, "end_pos": 267, "type": "DATASET", "confidence": 0.9339159727096558}]}, {"text": "In addition, we present a method to decompose a dependency structure (HD fragment) into smaller parts which enrich translation rules and also allow us to create a pseudo-forest as the input.", "labels": [], "entities": []}, {"text": "\"Pseudo\" means the forest is not obtained by combining several trees from a parser, but rather that it is created based on the decomposition of an HD fragment.", "labels": [], "entities": []}, {"text": "Large-scale experiments on Chinese-English and German-English tasks show that the transformation and decomposition are effective for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 133, "end_pos": 144, "type": "TASK", "confidence": 0.976626455783844}]}, {"text": "In the remainder of the paper, we first describe the Dep2Str model (Section 2).", "labels": [], "entities": [{"text": "Dep2Str", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.7758820652961731}]}, {"text": "Then we describe how to transform a dependency tree into a constituent tree which is compatible with the Dep2Str model (Section 3).", "labels": [], "entities": [{"text": "Dep2Str", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9205811619758606}]}, {"text": "The idea of decomposition including extracting sub-structural rules and creating a pseudo-forest is presented in Section 4.", "labels": [], "entities": []}, {"text": "Then experiments are conducted to compare translation results of our approach with the state-of-the-art HPB model (Section 5).", "labels": [], "entities": [{"text": "translation", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.9548822641372681}]}, {"text": "We conclude in Section 6 and present avenues for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct large-scale experiments to examine our methods on the Chinese-English and German-English translation tasks.", "labels": [], "entities": [{"text": "German-English translation tasks", "start_pos": 85, "end_pos": 117, "type": "TASK", "confidence": 0.7322250405947367}]}], "tableCaptions": [{"text": " Table 1: Chinese-English corpus. For the English  dev and test sets, words counts are averaged across  4 references.", "labels": [], "entities": []}, {"text": " Table 2: German-English corpus. In the dev and  test sets, there is only one English reference for  each German sentence.", "labels": [], "entities": []}, {"text": " Table 3: BLEU score [%] of the Dep2Str model  before (XJ) and after (D2S) dependency tree be- ing transformed. Systems are trained on a selected  1.2M Chinese-English corpus.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9711655080318451}]}, {"text": " Table 4: BLEU score [%] of our method and  Moses HPB on the Chinese-English task. We use  bold font to indicate that the result of our method  is significantly better than D2S at p \u2264 0.01 level,  and * to indicate the result is significantly better  than Moses HPB at p \u2264 0.01 level.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9720999002456665}]}, {"text": " Table 5: BLEU score [%] of our method and  Moses HPB on German-English task. We use  bold font to indicate that the result of our method  is significantly better than baseline D2S at p \u2264  0.01 level, and * to indicate the result is signifi- cantly better than Moses HPB at p \u2264 0.01 level.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9714400172233582}]}]}