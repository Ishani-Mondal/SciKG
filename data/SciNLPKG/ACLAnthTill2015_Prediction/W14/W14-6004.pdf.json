{"title": [{"text": "Extracting Aspects and Polarity from Patents", "labels": [], "entities": [{"text": "Extracting Aspects and Polarity", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8996516615152359}]}], "abstractContent": [{"text": "We describe an approach to terminology extraction from patent corpora that follows from a view of patents as \"positive reviews\" of inventions.", "labels": [], "entities": [{"text": "terminology extraction from patent corpora", "start_pos": 27, "end_pos": 69, "type": "TASK", "confidence": 0.8904026865959167}]}, {"text": "As in aspect-based sentiment analysis, we focus on identifying not only the components of products but also the attributes and tasks which, in the case of patents, serve to justify an invention's utility.", "labels": [], "entities": [{"text": "aspect-based sentiment analysis", "start_pos": 6, "end_pos": 37, "type": "TASK", "confidence": 0.7249635656674703}]}, {"text": "These semantic roles (component, task, attribute) can serve as a high level ontology for categorizing domain terminology, within which the positive/negative polarity of attributes serves to identify technical goals and obstacles.", "labels": [], "entities": []}, {"text": "We show that bootstrapping using a very small set of domain-independent lexico-syntactic features maybe sufficient for constructing domain-specific classifiers capable of assigning semantic roles and polarity to terms in domains as diverse as computer science and health.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated data mining of patents has had along history of research, driven by the large volume of patents produced each year and the many tasks to which they are put to use, including prior art investigation, competitive analysis, and trend detection and forecasting.", "labels": [], "entities": [{"text": "Automated data mining of patents", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7975923180580139}, {"text": "competitive analysis", "start_pos": 209, "end_pos": 229, "type": "TASK", "confidence": 0.7115165293216705}, {"text": "trend detection and forecasting", "start_pos": 235, "end_pos": 266, "type": "TASK", "confidence": 0.7526000067591667}]}, {"text": "Much of this work has concentrated on bibliographic methods such as citation analysis, but text mining has also been widely explored as away to assist analysts to characterize patents, discover relationships, and facilitate patent searches.", "labels": [], "entities": [{"text": "citation analysis", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.9030318558216095}, {"text": "text mining", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.7262742519378662}]}, {"text": "In this paper we strive towards a middle ground, using a highlevel classification suitable for all domains, inspired in part by recent work on sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.9397218525409698}]}, {"text": "In aspect-based sentiment analysis, natural language reviews of specific target entities, such as restaurants or cameras, are analyzed to extract aspects, i.e., features of the target entities, along with the sentiment expressed toward those features.", "labels": [], "entities": [{"text": "aspect-based sentiment analysis", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7512434720993042}]}, {"text": "In the restaurant domain, for example, aspects might include the breadth of the menu, quality of the service, preparation of the food, and cost.", "labels": [], "entities": []}, {"text": "Aspects thus tend to capture the tasks that the entity is expected to perform and various dimensions and components related to those tasks.", "labels": [], "entities": []}, {"text": "Sentiment reflects the reviewer's assessment of these aspects on a scale from negative to positive.", "labels": [], "entities": []}, {"text": "A patent application is required by definition to do three things: describe an invention, argue for its novelty, and justify its utility.", "labels": [], "entities": []}, {"text": "The utility of a patent is typically defined by the accomplishment of anew task or an improvement to some existing task along one or more dimensions.", "labels": [], "entities": []}, {"text": "Thus, a patent can bethought of as a positive review of a product with respect to specific aspects of its task(s).", "labels": [], "entities": []}, {"text": "Indeed, the most commonly occurring verbs in patents include those indicative of components (\"comprise\", \"include\"), attributes (\"increase\", \"reduce\"), and tasks (\"achieve\", \"perform\").", "labels": [], "entities": []}, {"text": "Organizing keywords along these high-level distinctions, then, would allow patent analysts to explore terminological infor-mation from several different relevant perspectives.", "labels": [], "entities": []}, {"text": "Furthermore, given the interpretation of a patent as a positive review, it should be possible to identify the default polarity of measurable aspects in the context of a domain.", "labels": [], "entities": []}, {"text": "For example, if a patent makes a reference to increasing network bandwidth, then this should lend support to the notion that network bandwidth is not only a relevant attribute within the patent's domain but also a positive one.", "labels": [], "entities": []}, {"text": "Likewise, if a patent refers to reducing power consumption, then we might interpret power consumption as an aspect with negative polarity.", "labels": [], "entities": []}, {"text": "For analysts trying to assess trends within a technology domain, tracking the occurrences of terms signifying tasks and attributes, along with their polarity, could help them characterize the changing goals and obstacles for inventors overtime.", "labels": [], "entities": []}, {"text": "The US patent office receives over half a million patent applications a year.", "labels": [], "entities": []}, {"text": "1 These are classified by subject matter within several standardized hierarchical schemes, which permits dividing up the corpus of patents both by application date and subfield (e.g., computer science, health, chemistry).", "labels": [], "entities": []}, {"text": "Since our goal is to support analysts across all domains, it is highly desirable to extract domain-specific aspects through semi-supervised machine learning rather than incur the cost of domain-specific knowledge engineering.", "labels": [], "entities": []}, {"text": "To this end, we employed a bootstrapping approach in which a small number of domain independent features was used to generate a much larger number of domain dependent features for classification.", "labels": [], "entities": []}, {"text": "We then applied na\u00efve Bayes classification in a two-step classification process: first distinguishing attributes, components and tasks; and then classifying the extracted attribute terms by their polarity.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe the system architecture.", "labels": [], "entities": []}, {"text": "Section 3 shows results for two domains (computer science and health).", "labels": [], "entities": []}, {"text": "In section 4, we present an evaluation of results and discuss issues and shortcomings of the current implementation.", "labels": [], "entities": []}, {"text": "In section 5, we present related research and in section 6, our conclusions and directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the classification output, we first selected a subset of terms within each domain as candidates for evaluation based on the twin criteria of document frequency and domain specificity.", "labels": [], "entities": []}, {"text": "That is, we wished to concentrate on terms with sufficient presence in the corpus as well as terms that were likely to express concepts of particular relevance to the domain.", "labels": [], "entities": []}, {"text": "Using a frequency threshold of 10 this yielded 19,088 terms for the health corpus and 35,220 for computer science with domain specificity scores above .05 and 1.5 respectively.", "labels": [], "entities": []}, {"text": "For each domain, two judges annotated approximately 150 random term instances with ACT judgments and approximately 100 machine-labeled attributes for polarity.", "labels": [], "entities": []}, {"text": "The annotation tool displayed each term along with five random sentences from the corpus that contained the term, and asked the judge to choose the best label, given the contexts provided.", "labels": [], "entities": []}, {"text": "An \"other\" option was available if the term fit none of the target categories.", "labels": [], "entities": []}, {"text": "For the polarity task, the \"other\" label included cases where the attribute was neutral, could not be assigned a polarity, or was improperly assigned the category \"attribute\".", "labels": [], "entities": []}, {"text": "An adjudicated gold standard was compared to system labels to measure precision and recall, as shown in table 5.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9994841814041138}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9991968274116516}]}, {"text": "Although the size of the evaluation set is small, we can make some observations from this sample.", "labels": [], "entities": []}, {"text": "Precision inmost cases is strong, which is important for the intended use of this data to characterize trends along each dimension using terminology statistics overtime.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9833347797393799}]}, {"text": "The lower scores for tasks within the ACT classification may reflect the fact that the distinction between component and task is not always clear cut.", "labels": [], "entities": []}, {"text": "The term \"antivirus protection\", for example, describes a task but it is classified by the system as a component because it occurs with features like \"prev_V=distribute\" and \"prev_V=provided_with\", which outweigh the contribution of the feature \"last_word=protection\" to select for the type task.", "labels": [], "entities": [{"text": "antivirus protection\"", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.82401043176651}]}, {"text": "To capture such cases of role ambiguity, it maybe reasonable to assign some terms to multiple classes when the conditional probabilities for the two most probable classes are very close (as they are in this case).", "labels": [], "entities": []}, {"text": "It may also be possible to integrate other forms of evidence, such as syntactic coordination patterns (Zierning, 2013) to refine system decisions.", "labels": [], "entities": []}, {"text": "One shortcoming of the current polarity classifier is that it does not attempt to identify attributes for which the polarity is neutral or dependent upon further context within the domain.", "labels": [], "entities": []}, {"text": "For example, the attribute \"body weight gain\" is labeled as a negative.", "labels": [], "entities": []}, {"text": "However, in the context of premature birth or cancer recovery, it maybe actually be a positive attribute.", "labels": [], "entities": []}, {"text": "Testing whether an attribute co-occurs with conflicting features (e.g., prev_V=increase and prev_V=decrease) could help spot such cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4. Examples of (pos)itive and (neg)ative polarity terms in health and computer science domains", "labels": [], "entities": []}]}