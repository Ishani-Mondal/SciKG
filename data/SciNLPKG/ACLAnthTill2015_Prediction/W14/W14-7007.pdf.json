{"title": [{"text": "A machine translation system combining rule-based machine translation and statistical post-editing", "labels": [], "entities": [{"text": "machine translation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7746968269348145}, {"text": "rule-based machine translation", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.6716809471448263}]}], "abstractContent": [{"text": "System architecture, experimental settings and evaluation results of the EIWA in the WAT2014 Japanese to English (ja-en) and Chinese to Japanese (zh-ja) tasks are described.", "labels": [], "entities": [{"text": "EIWA", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.8844808340072632}, {"text": "WAT2014 Japanese to English", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.548276774585247}]}, {"text": "Our system is combining rule-based machine translation (RBMT) and statistical post-editing (SPE).", "labels": [], "entities": [{"text": "rule-based machine translation (RBMT)", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.7574581752220789}]}, {"text": "Evaluation results for ja-en task show 19.86 BLEU score, 0.7067 RIBES score, and 22.50 human evaluation score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9837550222873688}, {"text": "RIBES score", "start_pos": 64, "end_pos": 75, "type": "METRIC", "confidence": 0.9821856319904327}]}, {"text": "Evaluation results for zh-ja task show 33.57 BLEU score, 0.8114 RIBES score, and 15.00 human evaluation score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9867106378078461}, {"text": "RIBES score", "start_pos": 64, "end_pos": 75, "type": "METRIC", "confidence": 0.9818451106548309}]}], "introductionContent": [{"text": "One of the architectures of combining rule-based technique and statistical technique in the machine translation field is combining a rule-based machine translation (RBMT) and a statistical postediting (SPE).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.7674039900302887}, {"text": "rule-based machine translation (RBMT)", "start_pos": 133, "end_pos": 170, "type": "TASK", "confidence": 0.7127515276273092}]}, {"text": "The RBMT part translates source documents to target documents using rule-based machine translation.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.6744542717933655}, {"text": "rule-based machine translation", "start_pos": 68, "end_pos": 98, "type": "TASK", "confidence": 0.6618931194146475}]}, {"text": "The SPE part automatically post-edits the output of the RBMT part to be more accurate target documents.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.6778435111045837}]}, {"text": "2 System architecture and experimental setting for the ja-en task Our basic system architecture for ja-en task is shown in that is the same in the previous works.", "labels": [], "entities": []}, {"text": "We use commercial based translation software for the RBMT part and the phrase based Moses () for the SPE part.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.7145395278930664}]}, {"text": "The distortion limit in the tuning process and decoding process for the SPE part is set to 1, because both the source and target languages on the SPE part are the same.", "labels": [], "entities": [{"text": "SPE part", "start_pos": 72, "end_pos": 80, "type": "TASK", "confidence": 0.7223779559135437}]}, {"text": "a first step, we select training sentences which include a low frequency word in the development sentences (or the test sentences).", "labels": [], "entities": []}, {"text": "The low frequency word means the count of such word in the training sentences are less than a threshold (we set 300).", "labels": [], "entities": []}, {"text": "The word \"\uff33\uff21\uff32\uff33\", which occurs 13 times in the development set, occurs 189 times in the training set.", "labels": [], "entities": []}, {"text": "So, it is a low frequency word in the development data.", "labels": [], "entities": []}, {"text": "On the other hand, the word \"\u5316\u5b66\", which occurs 29 times in the development set, occurs 40,964 times in the training set.", "labels": [], "entities": []}, {"text": "So, it is not a low frequency word in the development data.", "labels": [], "entities": []}, {"text": "At a second step, we add training sentences which include a word in the development sentences that is not in the set made by the first step.", "labels": [], "entities": []}, {"text": "However, we do not add any sentences by the second step.", "labels": [], "entities": []}, {"text": "For example, the word \"\u6a19\u984c\" occurs 19 times in the development set and is not included in the set made by the first step but it occurs no times in the whole training set.", "labels": [], "entities": []}, {"text": "We make a TM from this adapted training data.", "labels": [], "entities": [{"text": "TM", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9484505653381348}]}, {"text": "We refer to this TM as TM1.", "labels": [], "entities": [{"text": "TM1", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.7477458715438843}]}, {"text": "The training sentence pairs for the TM1 for the test data are selected by the similar method.", "labels": [], "entities": []}, {"text": "Adding to the training sentences of TM1, we add additional training sentences from the RBMT outputs of the development data (or the test data).", "labels": [], "entities": []}, {"text": "This means SPE part makes easier not to rewrite RBMT outputs.", "labels": [], "entities": [{"text": "SPE", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.706606924533844}]}, {"text": "We refer to this TM as TM2.", "labels": [], "entities": [{"text": "TM2", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.7857532501220703}]}, {"text": "The training data for the TM2 of the development set includes 134,634 sentence pairs and the training data for the TM2 of the test set includes 129,737 sentence pairs.", "labels": [], "entities": []}], "datasetContent": [{"text": "Automatic evaluation results for the whole test sentences (zh-ja: 2107, ja-en: 1812) and human evaluation results for the selected test sentences (400) by the organizer are shown in with our system rank and the number of all evaluated systems up to September 14th.", "labels": [], "entities": []}, {"text": "In (a), EIWA's translation of the Chinese expression \"\u77f3\u6cb9\u6cc4\u6f0f\" is \"\u706f\u6cb9\u6f0f\u6d29\" compared with the baseline translation \"\u77f3\u6cb9\u6d41\u51fa\".", "labels": [], "entities": []}, {"text": "This case has lexical mistranslation in EIWA.", "labels": [], "entities": [{"text": "EIWA", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.9551039338111877}]}, {"text": "In (b), Chinese subordinate clause including \"\u7740\u773c\" is incorrectly parsed by EIWA's RBMT part.", "labels": [], "entities": [{"text": "EIWA's RBMT part", "start_pos": 75, "end_pos": 91, "type": "DATASET", "confidence": 0.9328659623861313}]}, {"text": "This case has syntactic mistranslation in EIWA.", "labels": [], "entities": [{"text": "EIWA", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9434914588928223}]}, {"text": "For human evaluated 400 sentences of zh-ja task, we conduct automatic evaluations with RIBES ( and IMPACT.", "labels": [], "entities": [{"text": "RIBES", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.9493844509124756}, {"text": "IMPACT", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9669467210769653}]}, {"text": "shows examples having big difference between HUM and DIFF_RIBES.", "labels": [], "entities": [{"text": "RIBES", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.4267342984676361}]}, {"text": "At (a), lexical error \"\u6697\u53f7\u967d\uff12\uff13\u53f7\" may affect HUM score to be negative, while DIFF_RIBES is positive because sentence structures of EIWA and reference is more similar than the sentence structures of baseline and reference.", "labels": [], "entities": [{"text": "HUM score", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9611848592758179}, {"text": "DIFF_RIBES", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.8898612856864929}]}, {"text": "(b), the main part of the sentence, \"\uff25\uff4d\uff4d\uff41\uff0f\uff31\uff4f\uff33\u3092\u63d0\u6848\u3057\u305f\" in the reference, is correctly translated in EIWA.", "labels": [], "entities": [{"text": "EIWA", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.9665805101394653}]}, {"text": "So, HUM maybe 1.", "labels": [], "entities": [{"text": "HUM", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9714260697364807}]}, {"text": "It is not clear that DIFF_RIBES is negative.", "labels": [], "entities": [{"text": "DIFF_RIBES", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.75895756483078}]}, {"text": "At (c), baseline translation is perfectly equal to the reference translation.", "labels": [], "entities": []}, {"text": "So, RIBES score of baseline is 1 then DIFF_RIBES is negative.", "labels": [], "entities": [{"text": "RIBES score", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9561299383640289}, {"text": "DIFF_RIBES", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.8679895599683126}]}, {"text": "However, two annotators evaluated EIWA's win and one annotator evaluated baseline's win.", "labels": [], "entities": [{"text": "EIWA", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.8048753142356873}]}, {"text": "The reason maybe that EIWA's translation is more literal than baseline translation.", "labels": [], "entities": [{"text": "EIWA's translation", "start_pos": 22, "end_pos": 40, "type": "DATASET", "confidence": 0.8285120129585266}]}, {"text": "Another reason maybe that the references were not shown to annotators when they made evaluation.", "labels": [], "entities": []}, {"text": "Multiple references by additional translation or scrambling of reference () may make DIFF_RIBES be smaller.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Examples of EIWA's loss cases", "labels": [], "entities": [{"text": "EIWA's loss", "start_pos": 22, "end_pos": 33, "type": "DATASET", "confidence": 0.9341687162717184}]}]}