{"title": [{"text": "COV Model and its Application in Chinese Part-of-Speech Tagging", "labels": [], "entities": [{"text": "Chinese Part-of-Speech Tagging", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.5120673676331838}]}], "abstractContent": [{"text": "This article presents anew sequence labeling model named Context OVerlapping (COV) model, which expands observation from single word to n-gram unit and there is an overlapping part between the neighboring units.", "labels": [], "entities": []}, {"text": "Due to the co-occurrence constraint and transition constraint, COV model reduces the search space and improves tagging accuracy.", "labels": [], "entities": [{"text": "tagging", "start_pos": 111, "end_pos": 118, "type": "TASK", "confidence": 0.9584066867828369}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.8723081350326538}]}, {"text": "The 2-gram COV is applied to Chinese PoS tagging and the precision rate of the open testis as high as 96.83%, which is higher than the second order HMM, which is 95.73%.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.6636185944080353}, {"text": "precision rate", "start_pos": 57, "end_pos": 71, "type": "METRIC", "confidence": 0.980622261762619}]}, {"text": "The result is also comparable to the discriminative models but COV takes much less training time than them.", "labels": [], "entities": []}, {"text": "With symbol decoding COV prunes many nodes before statistics decoding and the search space of COV is about10-20% less than that of HMM.", "labels": [], "entities": []}], "introductionContent": [{"text": "Part of Speech (PoS) can provide much useful information for most natural language processing tasks such as word sense disambiguation, chunk detection, sentence parsing, speech synthesis, machine translation and soon.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.6747297445933024}, {"text": "chunk detection", "start_pos": 135, "end_pos": 150, "type": "TASK", "confidence": 0.8946385383605957}, {"text": "sentence parsing", "start_pos": 152, "end_pos": 168, "type": "TASK", "confidence": 0.7252206057310104}, {"text": "speech synthesis", "start_pos": 170, "end_pos": 186, "type": "TASK", "confidence": 0.7556846141815186}, {"text": "machine translation", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.8152352273464203}]}, {"text": "Therefore lots of efforts have been made to build effective and robust models for automatic PoS tagging.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.883292555809021}]}, {"text": "According to, a practical PoS tagger should be \"robust, efficient, accurate, tunable and reusable\".", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.8968601226806641}]}, {"text": "With regard to efficiency the basic requirement fora PoS tagger is that training and test time should not be too long.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 53, "end_pos": 63, "type": "TASK", "confidence": 0.8170138895511627}]}, {"text": "And fora robust tagger the tagging accuracy should be as high as possible and can well deal with the sparseness data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9842959642410278}]}, {"text": "Most of the approaches to PoS tagging can be divided into two main classes, rule-based and statistics-based approach.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.9453677833080292}]}, {"text": "In rule-based approaches, words are assigned tags based on a set of rules and a lexicon.", "labels": [], "entities": []}, {"text": "These rules can either be manually crafted, or learned, as in the transformation-based error-driven approach of.", "labels": [], "entities": []}, {"text": "In the statistics-based approaches HMM is the representative of generative models and is widely used in PoS tagging) . Maximum Entropy model and Conditional Random Fields (CRFs) model are the representatives of discriminative models and are also applied in PoS tagging.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 104, "end_pos": 115, "type": "TASK", "confidence": 0.7477822601795197}, {"text": "PoS tagging", "start_pos": 257, "end_pos": 268, "type": "TASK", "confidence": 0.828637570142746}]}, {"text": "Thanks to the flexibility of features selection these discriminative models achieve higher precision rates than the generative models in PoS tagging.", "labels": [], "entities": [{"text": "precision rates", "start_pos": 91, "end_pos": 106, "type": "METRIC", "confidence": 0.9826475977897644}, {"text": "PoS tagging", "start_pos": 137, "end_pos": 148, "type": "TASK", "confidence": 0.7947618663311005}]}, {"text": "But the training of discriminative models is time-consuming and requires high-quality computer processing power, which affects their applications in the real tasks.", "labels": [], "entities": []}, {"text": "Concerning all the characteristics of generative and discriminative models, we proposed anew model on the basis of HMM.", "labels": [], "entities": []}, {"text": "The new model expand the observation from one single word to n-gram unit and between the neighboring units there is an n-1 gram part, which is shared by the neighboring units.", "labels": [], "entities": []}, {"text": "So the new model is called Context OVerlapping (COV) model.", "labels": [], "entities": []}, {"text": "COV is a general sequence labeling model and has been applied to Chinese and English PoS tagging tasks.", "labels": [], "entities": [{"text": "COV", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7558777928352356}, {"text": "sequence labeling", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.6046874225139618}, {"text": "PoS tagging tasks", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.8027759591738383}]}, {"text": "In these tasks COV achieves better performance than HMM and its performance is comparable to the discriminative models.", "labels": [], "entities": []}, {"text": "Meanwhile its training time is much less than the discriminative models, which makes the model more efficient and robust in the real tasks.", "labels": [], "entities": []}, {"text": "The structure of the article is that: the first part will briefly introduce PoS tagging, in the second part we will introduce COV model.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.6991340816020966}]}, {"text": "The third part will compare COV with HMM.", "labels": [], "entities": [{"text": "HMM", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.7698651552200317}]}, {"text": "The fourth part will address how to estimate parameters and handle sparseness data.", "labels": [], "entities": []}, {"text": "The fifth part is about the algorithm of symbol decoding.", "labels": [], "entities": [{"text": "symbol decoding", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.781478613615036}]}, {"text": "The sixth part is about evaluation criteria and the seventh part presents the experiments and results.", "labels": [], "entities": []}, {"text": "The final part is some discussions and future work to do.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the following criteria to evaluate the performances of COV.", "labels": [], "entities": [{"text": "COV", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.6173117756843567}]}, {"text": "(1) PA : Overall precision rate (2) PM : Precision rate of the multi-class words, (3)P O : Precision rate of OOV (Out Of Vocabulary), not including the personal names, location names and organization names, etc.", "labels": [], "entities": [{"text": "PA", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9990956783294678}, {"text": "precision rate", "start_pos": 17, "end_pos": 31, "type": "METRIC", "confidence": 0.9764725565910339}, {"text": "PM", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9982839226722717}, {"text": "Precision rate", "start_pos": 41, "end_pos": 55, "type": "METRIC", "confidence": 0.983153909444809}, {"text": "P O", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.6865836083889008}, {"text": "Precision rate", "start_pos": 91, "end_pos": 105, "type": "METRIC", "confidence": 0.9580274820327759}, {"text": "OOV", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.5932535529136658}]}, {"text": "(4) PE : Error reduction rate, comparing with the baseline model.", "labels": [], "entities": [{"text": "PE", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9983391761779785}, {"text": "Error reduction rate", "start_pos": 9, "end_pos": 29, "type": "METRIC", "confidence": 0.9304077625274658}]}, {"text": "All the above criteria have been introduced in and Cutting (1992) etc and will not be repeated here.", "labels": [], "entities": [{"text": "and Cutting (1992)", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.6500501871109009}]}, {"text": "(5) PS : State certainty rate In order to measure the statistics decoding complexity, we define State certainty rate PS . Count(Total_State_Nodes) denotes the total number of possible states for all the observations in statistics decoding.", "labels": [], "entities": [{"text": "PS", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9828903079032898}, {"text": "State certainty rate", "start_pos": 9, "end_pos": 29, "type": "METRIC", "confidence": 0.657881478468577}, {"text": "State certainty rate PS", "start_pos": 96, "end_pos": 119, "type": "METRIC", "confidence": 0.7423394471406937}, {"text": "Count(Total_State_Nodes)", "start_pos": 122, "end_pos": 146, "type": "METRIC", "confidence": 0.7302027903497219}]}, {"text": "Due to the symbol decoding many states have been pruned in COV and the search space for statistics decoding is reduced accordingly.", "labels": [], "entities": [{"text": "COV", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.770350992679596}]}, {"text": "The level of search space reduction can be indicated by the criteria of P s .", "labels": [], "entities": [{"text": "search space reduction", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.6425769825776418}]}], "tableCaptions": [{"text": " Table 4: Results of the close test.  Corpus of group 2 in table 3 is used as the  training corpus.", "labels": [], "entities": []}, {"text": " Table 5: P A of HMM, 2-gram and 3-gram COV  in open test.  The corpus of Group 1 and 2 are used as  training corpus.  The above results show that 2-gram and  3-gram COV all outperform second order  HMM. And 3-gram COV outperforms 2-gram  COV, which indicates that with the expansion  of observation the precision rate of COV will  not decline but increase.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 304, "end_pos": 318, "type": "METRIC", "confidence": 0.992095023393631}]}, {"text": " Table 6: P M of HMM and COV in open test.  The result shows that COV has a better  performance in tagging multi-class words than", "labels": [], "entities": [{"text": "M", "start_pos": 12, "end_pos": 13, "type": "METRIC", "confidence": 0.5841318964958191}, {"text": "tagging multi-class words", "start_pos": 99, "end_pos": 124, "type": "TASK", "confidence": 0.8756224910418192}]}, {"text": " Table 9: Ps of 2nd order HMM and 2-gram  COV  The above result shows that the search space in  statistics decoding of COV is smaller than  HMM.  We also count the tokens which can be tagged  with symbol decoding.", "labels": [], "entities": []}, {"text": " Table 11 Results of English PoS tagging  Experiments  The above results show that COV also  outperforms HMM in English PoS tagging.", "labels": [], "entities": [{"text": "English PoS tagging", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.5675902167956034}, {"text": "English PoS tagging", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.4789327581723531}]}]}