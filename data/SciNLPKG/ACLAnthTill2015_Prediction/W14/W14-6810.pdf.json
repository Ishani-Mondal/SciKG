{"title": [{"text": "Bilingual Product Name Dictionary Construction Using a Two Stage Method", "labels": [], "entities": [{"text": "Bilingual Product Name Dictionary Construction", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7384556531906128}]}], "abstractContent": [{"text": "This paper proposes a novel two-stage method for bilingual product name dictionary construction from comparable corpora.", "labels": [], "entities": [{"text": "bilingual product name dictionary construction", "start_pos": 49, "end_pos": 95, "type": "TASK", "confidence": 0.6542519986629486}]}, {"text": "In previous work, some researchers study the problem of expanding a set of given seed entities into a more complete set by discovering other entities that also belong to the same concept, it just solves the problem about expansion of entity set in a monolingual language, but the expansion of bilingual entity is really blank problem from comparable corpora.", "labels": [], "entities": []}, {"text": "A typical example is to use/Honda-X\"as seed entity , and derive other entities(e.g.,/Ford-4A\") in the same concept set of product name.", "labels": [], "entities": []}, {"text": "We address this problem by utilizing a two-stage approach based on entity set expansion and bilingual entity alignment from comparable corpora.", "labels": [], "entities": [{"text": "entity set expansion", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.6261234978834788}]}, {"text": "Evaluations using English and Chinese reviewer corpus verify that our method outperforms conventional methods.", "labels": [], "entities": [{"text": "English and Chinese reviewer corpus", "start_pos": 18, "end_pos": 53, "type": "DATASET", "confidence": 0.644327312707901}]}], "introductionContent": [{"text": "Bilingual lexicons are important resources for bilingual tasks such as machine translation (MT) and cross-language information retrieval (CLIR).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.8405193090438843}, {"text": "cross-language information retrieval (CLIR)", "start_pos": 100, "end_pos": 143, "type": "TASK", "confidence": 0.7652731190125147}]}, {"text": "Therefore, the automatic building of bilingual product name lexicons from corpus is one of the important issues, however it has not attracted many researchers.", "labels": [], "entities": [{"text": "automatic building of bilingual product name lexicons", "start_pos": 15, "end_pos": 68, "type": "TASK", "confidence": 0.7733808543000903}]}, {"text": "As a solution, a number of previous works have been proposed for extracting bilingual product name lexicons from comparable corpora, in which documents are not direct translations but share the same topic or domain.", "labels": [], "entities": [{"text": "extracting bilingual product name lexicons", "start_pos": 65, "end_pos": 107, "type": "TASK", "confidence": 0.7669990181922912}]}, {"text": "The use of comparable corpora is motivated by the fact that large parallel corpora are only available fora few language pairs and limited domains.", "labels": [], "entities": []}, {"text": "Bilingual product name lexicon is similar to traditional bilingual lexicon extraction, what they are all common on is extract bilingual entity translation pair from comparable corpora, but there is some difference between them.", "labels": [], "entities": [{"text": "Bilingual product name lexicon", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6315993294119835}, {"text": "bilingual lexicon extraction", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.750271717707316}]}, {"text": "Our problem is: first given an seed set for semantic classes, finding the conceptually entities by extending semantic classes.", "labels": [], "entities": []}, {"text": "Then, the bilingual entity translation pairs are extracted from comparable corpora.", "labels": [], "entities": []}, {"text": "Traditional bilingual lexicon extraction approaches can only find entity translation pairs from comparable corpora, but not expand semantic set.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.7193352977434794}]}, {"text": "Set expansion systems provide us a useful solution to the above problem because they create a more perfect set of name entities by expanding the small number of seed words given for the target domain.", "labels": [], "entities": [{"text": "Set expansion", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.708580806851387}]}, {"text": "Google Sets is a well-known example of a web-based set expansion system.", "labels": [], "entities": []}, {"text": "Another prominent work is the SEAL system (, which adoptes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages.", "labels": [], "entities": [{"text": "SEAL", "start_pos": 30, "end_pos": 34, "type": "TASK", "confidence": 0.9791191220283508}]}, {"text": "Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph.", "labels": [], "entities": []}, {"text": "The third method is set expansion by iterative similarity aggregation (, in which a set of given seed entities is expanded into a more complete set.", "labels": [], "entities": [{"text": "set expansion", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.7146898806095123}]}, {"text": "All these methods are entity expansion from monolingual data sources.", "labels": [], "entities": [{"text": "entity expansion", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.722774088382721}]}, {"text": "Another meaningful work is the bilingual lexicon extraction).", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.6489175856113434}]}, {"text": "Most of the previous methods are based on the assumption that a word and its translation tend to appear in similar contexts across languages.", "labels": [], "entities": []}, {"text": "Based on this assumption, many methods calculate word similarity using context and then extract word translation pairs with a high context similarity.", "labels": [], "entities": []}, {"text": "while their researches aim to generate a general bilingual lexicons, our work is bilingual entity extraction of the same semantic category, these entities are refer to product name.", "labels": [], "entities": [{"text": "bilingual entity extraction", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6712580919265747}]}, {"text": "Considerable progresses have been made in developing high-quality set expansion systems in the monolingual setting.", "labels": [], "entities": []}, {"text": "while bilingual product name dictionary construction and extraction still do not attract much research attention.", "labels": [], "entities": [{"text": "bilingual product name dictionary construction", "start_pos": 6, "end_pos": 52, "type": "TASK", "confidence": 0.6898697495460511}]}, {"text": "For bilingual product name dictionary construction, there are two major fundamental problems.", "labels": [], "entities": [{"text": "bilingual product name dictionary construction", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.6785104513168335}]}, {"text": "The first is generating an extensive list of the same semantic entity, while some seed entities of the same concept are given as input.", "labels": [], "entities": []}, {"text": "The second problem is to find bilingual entity translation from comparable corpora.", "labels": [], "entities": [{"text": "bilingual entity translation", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.6231382886568705}]}, {"text": "Facing the above problems, we present a novel approach to construct bilingual product name dictionary in this paper.", "labels": [], "entities": []}, {"text": "In order to express the simplification, we will replace word \"product name\" with \"entity\" each other.", "labels": [], "entities": []}, {"text": "Following the common practice, our system proceeds in two stages, which first expands the entity set for the semantic category by giving some bilingual set pairs and then finds bilingual product name translation pair from comparable corpora.", "labels": [], "entities": []}, {"text": "Semantic category set expansion is carried out through the bootstrapping algorithm.", "labels": [], "entities": [{"text": "Semantic category set expansion", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5893699675798416}]}, {"text": "In this stage ,our goal is to discover relevant entities by giving some entity seed set.", "labels": [], "entities": []}, {"text": "In the second stage, we use this assumption that a word and its translation tend to appear in similar context across languages.", "labels": [], "entities": []}, {"text": "Our method calculates entity similarity using context and then extract entity translation pairs with a high context similarity.", "labels": [], "entities": []}, {"text": "We call this method as context-similarity-based methods.", "labels": [], "entities": []}, {"text": "The context similarity is usually computed using machine translation model by mapping contexts expressed in two different languages into the same language space.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.6836415082216263}]}, {"text": "In the mapping process, information not represented by the seed lexicon is discarded.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are as follows: 1) we propose a bilingual product name extraction method that can get the set of semantic category by bootstrapping.", "labels": [], "entities": [{"text": "bilingual product name extraction", "start_pos": 69, "end_pos": 102, "type": "TASK", "confidence": 0.7027254998683929}]}, {"text": "At the same time, we can find bilingual product name translation pairs based on context similarity from comparable corpora.", "labels": [], "entities": []}, {"text": "2) we propose an the algorithm that cannot only build set of semantic category by giving some bilingual seed set but also find entity translation pairs from comparable corpora.", "labels": [], "entities": []}, {"text": "3) we construct a dictionary of the bilingual product name from comparable corpora, which do not need fully parallel data that is seldom.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our approach, we conduct experiments on two real data sets, which are from collection of brand reviews including digital cameras and car domains.", "labels": [], "entities": []}, {"text": "For the target language of English, the product dataset contains 9542 reviews which are collected from www.buzzilions.com and www.carreview.com.", "labels": [], "entities": []}, {"text": "For the source language of Chinese, the product dataset contains 8432 reviews which are collected from www.Amazon.cn and www.xche.com.cn.", "labels": [], "entities": []}, {"text": "For our experiment,we use a Oxford English-Chinese bilingual dictionary to match similarity semantic reviewer sentence, any two of them are used as comparable corpus,the copora are non-parallel, but loosely compara in term of its content.", "labels": [], "entities": [{"text": "Oxford English-Chinese bilingual dictionary", "start_pos": 28, "end_pos": 71, "type": "DATASET", "confidence": 0.828991487622261}]}, {"text": "Though the scale of Chinese corpora is large, most of the reviews are short texts and there area lot noise in the content.", "labels": [], "entities": []}, {"text": "For Chinese, we use the ICTLAS 3.0 ( toolkit to conduct word segmentation over sentences.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7434425354003906}]}, {"text": "To evaluate the effectiveness of our algorithms, we select two semantic entity sets in camera domain and car domain as seeds, where set expansion experiments are conducted . We select these two categories because (1) they are from different domains; and  In experiments, each English review is segmented into sentences according to punctuation.", "labels": [], "entities": []}, {"text": "Then sentences are tokenized and the part-of-speech of each word is assigned.", "labels": [], "entities": []}, {"text": "Stanford NLP tool is used to perform POS-tagging.", "labels": [], "entities": [{"text": "Stanford NLP tool", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.9558314482371012}]}, {"text": "Next, function words were removed since function words with little semantic information spuriously co-occurred with many words.", "labels": [], "entities": []}, {"text": "shows the size of each corpora.", "labels": [], "entities": []}, {"text": "We measure the performance on product name translation pair extraction as Top N accuracy (Acc N ), which is the number of test words whose top N translation candidates contain a correct translation equivalent over the total number of test words.", "labels": [], "entities": [{"text": "product name translation pair extraction", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.7230532467365265}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.6883922815322876}, {"text": "Acc N )", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9622912208239237}]}, {"text": "We randomly select 50 Chinese words as our test data.", "labels": [], "entities": []}, {"text": "We manually evaluate whether translation candidates contained a correct translation equivalent.", "labels": [], "entities": []}, {"text": "We do not use recall because we do not know whether the translation equivalents of a test word appear or not in the corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9975690245628357}]}, {"text": "lists the top 20 ranked results produced by two stage algorithm for the two domains that we experiment with.", "labels": [], "entities": []}, {"text": "In each domain, those terms in boldface are the input seeds.", "labels": [], "entities": []}, {"text": "The underlined terms are the results that do not belong to the ground truth set and thus counted as incorrect results.", "labels": [], "entities": []}, {"text": "While the remaining terms are correct results expanded from the input seeds.", "labels": [], "entities": []}, {"text": "Rapp's method computed associations with context words using the log-likelihood ratio.", "labels": [], "entities": []}, {"text": "The city-block metric is used to compute similarity between context vector.", "labels": [], "entities": []}, {"text": "Andrade define context as a set of words with a positive association in a window, Pointwise Mutual Information estimated by a Bayesian method is used to calculate.", "labels": [], "entities": []}, {"text": "The similarity between contexts is estimated based on the number of overlapping words.", "labels": [], "entities": []}, {"text": "Tamura's method utilize indirect relations with the bilingual seeds together with direct relations, in which each word   is represented by a distribution of translated seeds.", "labels": [], "entities": []}, {"text": "Then they extracts translation pairs from comparable corpora by using graph-based label propagation.", "labels": [], "entities": []}, {"text": "The parameter setting in these three baselines are the same as the original papers.", "labels": [], "entities": []}, {"text": "The overall performance results are shown in and 4.", "labels": [], "entities": []}, {"text": "From these results, we can make the following observations.", "labels": [], "entities": []}, {"text": "1) Ours achieves performance improvement over other methods.", "labels": [], "entities": []}, {"text": "This indicates that our method is effective for bilingual product name extraction.", "labels": [], "entities": [{"text": "bilingual product name extraction", "start_pos": 48, "end_pos": 81, "type": "TASK", "confidence": 0.7679701298475266}]}, {"text": "2) Our two stage method outperform Rapp's method, Andrade's method and Tamura's method.", "labels": [], "entities": []}, {"text": "The reason is that two stage-based method extract bilingual entity name in a flexible way, we first consider entity set expansion, then find bilingual entity pair by using machine translation methods from comparable corpora, which is not only find the same semantic entity, but also can find entity translation pair, so we can extract bilingual product name on specific domain.", "labels": [], "entities": []}, {"text": "but Rapp's method, Andrade's method and Tamura's method only build a general bilingual lexicon.", "labels": [], "entities": []}, {"text": "3) Our method construct context association by utilizing machine translation model between bilingual entity name.", "labels": [], "entities": []}, {"text": "Machine translation model have the characteristic of accurate and interpretation, which favor our problems.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6623842567205429}, {"text": "accurate", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9973850846290588}]}, {"text": "Our test data, on the other hand, includes many low-frequency words.", "labels": [], "entities": []}, {"text": "It is generally true that translation of highfrequency words is much easier than that of low frequency words.", "labels": [], "entities": [{"text": "translation of highfrequency words", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.8598131835460663}]}, {"text": "The accuracies of the baselines in and 4 are worse than the previous reports: 14% Acc 1 and 46% Acc, and 72% Acc 1 (Rapp, 1999).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9981979727745056}, {"text": "Acc 1", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9822140336036682}, {"text": "Acc", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9943291544914246}, {"text": "Acc 1", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.989248126745224}]}, {"text": "4) Our methods expand entity name of the same semantic concept by using the bootstrapping algorithm, which is weak-supervised learning algorithm.", "labels": [], "entities": []}, {"text": "The algorihtm need not labeled dateset to train model, meanwhile which is easier to implement it, it exceeds Tamura's method,which only considers distribution of translated seeds, then each word is represented by seeds distribution.", "labels": [], "entities": []}, {"text": "The seed distributions are propagated over a graph representing relations among words, but constructing a graph is consuming lot of forces, its effect is very low.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on English corpus about Cam- era and Car domain. # denotes the size of the re- views/sentences", "labels": [], "entities": [{"text": "English corpus", "start_pos": 24, "end_pos": 38, "type": "DATASET", "confidence": 0.8588580191135406}, {"text": "Cam- era", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.8674610455830892}, {"text": "Car domain", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.8462518155574799}]}, {"text": " Table 3: Performance statistics on Camera domain  by using Top N accuracy (Acc N ).N is 1,10,20 re- spectively.", "labels": [], "entities": [{"text": "Top N accuracy (Acc N ).N", "start_pos": 60, "end_pos": 85, "type": "METRIC", "confidence": 0.707335826009512}]}, {"text": " Table 4: Performance statistics on Car domain by  using Top N accuracy (Acc N ).N is 1,10,20 respec- tively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.6161293387413025}, {"text": "Acc N ).N", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9279922544956207}]}, {"text": " Table 5: Performance statistics on Car domain  by using Top N accuracy (Acc N ).The number of  seeds choose 4,6 and 8 respectively.", "labels": [], "entities": [{"text": "Top N accuracy", "start_pos": 57, "end_pos": 71, "type": "METRIC", "confidence": 0.52602552374204}, {"text": "Acc N ).", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9376074274381002}]}, {"text": " Table 6: Performance statistics on Camera domain  by using Top N accuracy (Acc N ).The number of  seeds choose 4,6 and 8 respectively.", "labels": [], "entities": [{"text": "Camera domain", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.9322495460510254}, {"text": "Top N accuracy", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.5398269295692444}, {"text": "Acc N ).", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9166296720504761}]}]}