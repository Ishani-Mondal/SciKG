{"title": [{"text": "Foreign Words and the Automatic Processing of Arabic Social Media Text Written in Roman Script", "labels": [], "entities": [{"text": "Automatic Processing of Arabic Social Media Text Written in Roman Script", "start_pos": 22, "end_pos": 94, "type": "TASK", "confidence": 0.7095667205073617}]}], "abstractContent": [{"text": "Arabic on social media has all the properties of any language on social media that make it tough for natural language processing, plus some specific problems.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.790957490603129}]}, {"text": "These include diglossia, the use of an alternative alphabet (Roman), and code switching with foreign languages.", "labels": [], "entities": [{"text": "code switching", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.8034620881080627}]}, {"text": "In this paper, we present a system which can process Arabic written in Roman alphabet (\"Arabizi\").", "labels": [], "entities": []}, {"text": "It identifies whether each word is a foreign word or one of another four categories (Arabic, name, punctuation , sound), and transliterates Arabic words and names into the Arabic alphabet.", "labels": [], "entities": []}, {"text": "We obtain an overall system performance of 83.8% on an unseen test set.", "labels": [], "entities": []}], "introductionContent": [{"text": "These facts pose a wellknown problem for natural language processing of social media texts, which has become an area of interest as applications such as sentiment analysis, information extraction, and machine translation turn to this genre.", "labels": [], "entities": [{"text": "natural language processing of social media texts", "start_pos": 41, "end_pos": 90, "type": "TASK", "confidence": 0.8079359020505633}, {"text": "sentiment analysis", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.963261753320694}, {"text": "information extraction", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.8524706065654755}, {"text": "machine translation", "start_pos": 201, "end_pos": 220, "type": "TASK", "confidence": 0.778573215007782}]}, {"text": "This situation is exacerbated in the case of Arabic social media.", "labels": [], "entities": []}, {"text": "There are three principal reasons.", "labels": [], "entities": []}, {"text": "First, the Arabic language is a collection of varieties: Modern Standard Arabic (MSA), which is used informal settings, and different forms of Dialectal Arabic (DA), which are commonly used informally.", "labels": [], "entities": []}, {"text": "This situation is referred to as \"diglossia\".", "labels": [], "entities": []}, {"text": "MSA has a standard orthography, while the dialects do not.", "labels": [], "entities": [{"text": "MSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9591023325920105}]}, {"text": "What is used in Arabic social media is typically DA.", "labels": [], "entities": []}, {"text": "This means that there is no standard orthography to begin with, resulting in an even broader variation in orthographic forms found.", "labels": [], "entities": []}, {"text": "Diglossia is seen in other linguistic communities as well, including German-speaking Switzerland, in the Czech Republic, or to a somewhat lesser extent among French speakers.", "labels": [], "entities": [{"text": "Diglossia", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.7480880618095398}]}, {"text": "Second, while both MSA and DA are commonly written in the Arabic script, DA is sometimes written in the Roman script.", "labels": [], "entities": []}, {"text": "Arabic written in Roman is often called \"Arabizi\".", "labels": [], "entities": []}, {"text": "It is common in other linguistic communities as well to write informal communication in the Roman alphabet rather than in the native writing system, for example, among South Asians.", "labels": [], "entities": []}, {"text": "And third, educated speakers of Arabic are often bilingual or near-bilingual speakers of another language as well (such as English or French), and will code switch between DA and the foreign language in the same utterance (and sometimes MSA as well).", "labels": [], "entities": []}, {"text": "As is well known, code switching is common in many linguistic communities, for example among South Asians.", "labels": [], "entities": [{"text": "code switching", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.9101042151451111}]}, {"text": "In this paper, we investigate the issue of processing Arabizi input with code switching.", "labels": [], "entities": []}, {"text": "There are two tasks: identification of tokens that are not DA or MSA (and should not be transliterated into Arabic script for downstream processing), and then the transliteration into Arabic script of the parts identified as DA or MSA.", "labels": [], "entities": []}, {"text": "In this paper, we 1 use as a black box an existing component that we developed to transliterate from Arabizi to Arabic script (Al- ).", "labels": [], "entities": []}, {"text": "This paper concentrates on the task of identifying which tokens should be transliterated.", "labels": [], "entities": []}, {"text": "A recent release of annotated data by the Linguistic Data Consortium) has enabled novel research on this topic.", "labels": [], "entities": [{"text": "Linguistic Data Consortium", "start_pos": 42, "end_pos": 68, "type": "DATASET", "confidence": 0.7381143867969513}]}, {"text": "The corpus provides each token with a tag, as well as a transliteration if appropriate.", "labels": [], "entities": []}, {"text": "The tags identify foreign words, as well as Arabic words, names, punctuation, and sounds.", "labels": [], "entities": []}, {"text": "Only Arabic words and names are transliterated.", "labels": [], "entities": []}, {"text": "(Note that code switching is not distinguished from borrowing.)", "labels": [], "entities": [{"text": "code switching", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.8480039238929749}]}, {"text": "Emoticons, which maybe isolated or part of an input token, are also identified, and converted into a conventional symbol (#).", "labels": [], "entities": []}, {"text": "This paper presents taggers for the tags, and an end-to-end system which takes Arabizi input and produces a complex output which consists of a tag for each input token and a transliteration of Arabic words and names into the Arabic script.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first system that handles the complete task as defined by the LDC data.", "labels": [], "entities": [{"text": "LDC data", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.8639876246452332}]}, {"text": "This paper focuses on the task of identifying foreign words (as well as the other tags), on creating a single system, and on evaluating the system as a whole.", "labels": [], "entities": []}, {"text": "This paper makes three main contributions.", "labels": [], "entities": []}, {"text": "First, we clearly define the computational problem of dealing with social media Arabizi, and propose anew formulation of the evaluation metric for the LDC corpus.", "labels": [], "entities": [{"text": "LDC corpus", "start_pos": 151, "end_pos": 161, "type": "DATASET", "confidence": 0.8886864185333252}]}, {"text": "Second, we present novel modules for the detection of foreign words as well as of emoticons, sounds, punctuation marks, and names in Arabizi.", "labels": [], "entities": []}, {"text": "Third, we compose a single system from the various components, and evaluate the complete system.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We start by presenting related work (Section 2), and then we present relevant linguistic facts and explain how the data is annotated (Section 3).", "labels": [], "entities": []}, {"text": "After summarizing our system architecture (Section 4) and experimental setup (Section 5), we present our systems for tagging in Sections 6, 7 and 8.", "labels": [], "entities": []}, {"text": "The evaluation results are presented in Section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "We define a foreignness index formula that gives each word a score given its unigram probabilities against Arabic and English language models (LMs).", "labels": [], "entities": []}, {"text": "\u03b5(w) is the foreignness score of the Arabizi word w.", "labels": [], "entities": [{"text": "\u03b5(w)", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8765773773193359}]}, {"text": "PE (w) is the unigram probability of win the English LM, and PA (w t ) is the unigram probability in the Arabic LM of the transliteration into Arabic (w t ) proposed by our system for the Arabizi word w. \u03b1 is a tuning parameter varying from zero to one.", "labels": [], "entities": [{"text": "PE", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9791256189346313}, {"text": "English LM", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.8575214445590973}, {"text": "PA (w t )", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9283834457397461}]}, {"text": "From equation 1 we define the minimum and maximum \u03b5 values as follows: Where PE min and P Emax are the minimum and maximum uni-gram probabilities in the English LM.", "labels": [], "entities": [{"text": "PE min", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9669996798038483}]}, {"text": "And PA min and P Amax are the minimum and maximum uni-gram probabilities in the Arabic LM.", "labels": [], "entities": [{"text": "PA min", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9641959369182587}, {"text": "Amax", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.6766422390937805}, {"text": "Arabic LM", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.8891716301441193}]}, {"text": "The foreignness index F oreignness(w) is the normalized foreignness score derived using equations 1 and 2 as follow: If the foreignness index of a word is higher than a certain threshold \u03b2, we consider the word Foreign.", "labels": [], "entities": [{"text": "foreignness index F oreignness(w)", "start_pos": 4, "end_pos": 37, "type": "METRIC", "confidence": 0.7583910695144108}]}, {"text": "We define three baseline experiments as follows: \u2022 FW-index-manual: Use brute force search to find the best \u03b1 and \u03b2 that maximize the foreign words tagging on Dev.", "labels": [], "entities": [{"text": "FW-index-manual", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.9446122050285339}]}, {"text": "\u2022 FW-index-SVM: Use the best \u03b1 from above and train an SVM model using the foreignness index as sole feature.", "labels": [], "entities": [{"text": "FW-index-SVM", "start_pos": 2, "end_pos": 14, "type": "METRIC", "confidence": 0.7285829782485962}]}, {"text": "Then use this model to classify each word in Dev.", "labels": [], "entities": []}, {"text": "\u2022 LM-lookup: The word is said to be Foreign if it exists in the English LM and does not exist in the Arabic LM.", "labels": [], "entities": []}, {"text": "We conducted a suite of experiments by training different machine learning techniques using WEKA () on the following groups of features.", "labels": [], "entities": [{"text": "WEKA", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.599686861038208}]}, {"text": "We performed a two-stage feature exploration, where we did an exhaustive search overall features in each group in the first phase, and then exhaustively searched overall retained feature groups.", "labels": [], "entities": []}, {"text": "In addition, we also performed an exhaustive search overall features in the first three groups.", "labels": [], "entities": []}, {"text": "\u2022 Word n-gram features: Run the input Arabizi word through an English LM and the corresponding Arabic transliteration through an Arabic LM to get the set of features that are defined in \"Group1\" in.", "labels": [], "entities": []}, {"text": "Then find the best combination of features that maximizes the F-score on Dev.", "labels": [], "entities": [{"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9973324537277222}]}, {"text": "\u2022 FW-char-n-gram features: Run the input Arabizi word through a character-level ngram LM of the Arabizi words that are tagged as foreign in the training data.", "labels": [], "entities": [{"text": "FW-char-n-gram", "start_pos": 2, "end_pos": 16, "type": "METRIC", "confidence": 0.9418447613716125}]}, {"text": "We get the set of features that are defined in \"Group2\" in Table 4.", "labels": [], "entities": []}, {"text": "Then find the best feature combination from this group that maximizes the F-score on Dev.", "labels": [], "entities": [{"text": "F-score", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.995784342288971}]}, {"text": "\u2022 AR-char-n-gram features: Run the input Arabizi word through a character-level ngram LM of the Arabizi words that are tagged Group Description Group1 Uni and bi-grams probabilities from English and Arabic LMs Group2 1,2,3,4, and 5 characters level n-grams of foreign words Group3 1,2,3,4, and 5 characters level n-grams of Arabic words Use the Arabizi word itself as a feature Group4 Was the input Arabizi word tagged as foreign in the gold training data?", "labels": [], "entities": [{"text": "AR-char-n-gram", "start_pos": 2, "end_pos": 16, "type": "METRIC", "confidence": 0.947470486164093}]}, {"text": "Was the input Arabizi word tagged as Arabic in the gold training data?", "labels": [], "entities": [{"text": "gold training data", "start_pos": 51, "end_pos": 69, "type": "DATASET", "confidence": 0.6631564895311991}]}, {"text": "Does the input word has speech effects?", "labels": [], "entities": []}, {"text": "Group5 Word length Is the Arabizi word capitalized?: List of the different features that are used in the foreign word tagging as non-foreign in the training data.", "labels": [], "entities": [{"text": "foreign word tagging", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.6945740977923075}]}, {"text": "We get the set of features that are defined in \"Group3\" in.", "labels": [], "entities": []}, {"text": "Then find the best feature that maximizes the F-score on Dev.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9975971579551697}]}, {"text": "\u2022 Word identity: Use the input Arabizi word to get all features that are defined in \"Group4\" in.", "labels": [], "entities": []}, {"text": "Then find the best combination of features that maximizes the F-score on Dev.", "labels": [], "entities": [{"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9973324537277222}]}, {"text": "\u2022 Word properties: Use the input Arabizi word to get all features that are defined in \"Group5\" in.", "labels": [], "entities": []}, {"text": "Then find the best combination of features that maximizes the Fscore on Dev.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9456407427787781}]}, {"text": "\u2022 Best-of-all-groups: Use the best selected set of features from each of the above experiments.", "labels": [], "entities": []}, {"text": "Then find the best combination of these features that maximizes the F-score on Dev.", "labels": [], "entities": [{"text": "F-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9979758858680725}]}, {"text": "\u2022 All-features: Use all features from all groups.", "labels": [], "entities": []}, {"text": "\u2022 Probabilistic-features-only: Find the best combination of features from \"Group1\", \"Group2\", and \"Group3\" in that maximizes the F-score on Dev.", "labels": [], "entities": [{"text": "F-score", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.992119312286377}]}, {"text": "shows the results on Dev using Train-S. It can be seen that the decision tree classifier is doing better than the SVM except in the \"Word properties\" and \"All-features\" experiments.", "labels": [], "entities": []}, {"text": "The best performing setup is \"Probabilistic-featuresonly\" with decision trees which has 87.3% Fscore.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9991682767868042}]}, {"text": "The best selected features are EN-Unigram, AR-char-2-grams, FW-char-1-grams, FW-char-2-grams, FW-char-5-grams.", "labels": [], "entities": [{"text": "EN-Unigram", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.5274738669395447}, {"text": "AR-char-2-grams", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.9464030265808105}, {"text": "FW-char-1-grams", "start_pos": 60, "end_pos": 75, "type": "METRIC", "confidence": 0.8936706185340881}, {"text": "FW-char-2-grams", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.5638784170150757}, {"text": "FW-char-5-grams", "start_pos": 94, "end_pos": 109, "type": "DATASET", "confidence": 0.8554878234863281}]}, {"text": "In this subsection we report on evaluating the overall system accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9986977577209473}]}, {"text": "This includes the correct tagging and Arabizi to Arabic transliteration.", "labels": [], "entities": []}, {"text": "However, since there is no manually annotated gold transliteration for foreign words, punctuation, or sounds into Arabic, we cannot compare the system transliteration of foreign words to the gold transliteration.", "labels": [], "entities": []}, {"text": "Thus, we define the following metric to judge the overall system accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9985456466674805}]}, {"text": "Overall System Accuracy Metric A word is said to be correctly transliterated according to the following rules: 1.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9309484362602234}]}, {"text": "If the gold tag is anything other than Arabic and Name, the produced tag must match the gold tag.", "labels": [], "entities": []}, {"text": "2. If the gold tag is either Arabic or Name, the produced tag and the produced transliteration must both match the gold.: Error Analysis of tag classification errors As a baseline, we use the most frequent tag, which is Arabic in our case, along with the transliteration of the word using our black box system.", "labels": [], "entities": [{"text": "Error", "start_pos": 122, "end_pos": 127, "type": "METRIC", "confidence": 0.9721753001213074}]}, {"text": "Then we apply the above evaluation metric on both Dev and Test.", "labels": [], "entities": []}, {"text": "The results are shown in table 8.", "labels": [], "entities": []}, {"text": "The baseline accuracies on Dev and Test are 65.7% and 76.8% respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9560747146606445}, {"text": "Test", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.6180017590522766}]}, {"text": "By considering the actual output of our system, the accuracy on the Dev and Test data increases to 82.5% and 83.8% respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9998072981834412}, {"text": "Dev and Test data", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.5875747203826904}]}], "tableCaptions": [{"text": " Table 3: Name tagging results on Dev with Train-S", "labels": [], "entities": [{"text": "Name tagging", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.8333078026771545}, {"text": "Train-S", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.7114831209182739}]}, {"text": " Table 5: Foreign words tagging results on Dev in terms of F-score (%).", "labels": [], "entities": [{"text": "Foreign words tagging", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6046236356099447}, {"text": "F-score", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9988389611244202}]}, {"text": " Table 6: Tagging results on Dev using Train-L", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9889427423477173}, {"text": "Train-L", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.6936580538749695}]}, {"text": " Table 8: Baseline vs. System Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.8624038100242615}]}, {"text": " Table 9: Error Analysis of tag classification errors", "labels": [], "entities": [{"text": "Error Analysis of tag classification", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.7776404619216919}]}]}