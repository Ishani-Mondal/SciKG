{"title": [], "abstractContent": [{"text": "Disaster response agencies incorporate social media as a source of fast-breaking information to understand the needs of people affected by the many crises that occur around the world.", "labels": [], "entities": [{"text": "Disaster response", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7977123558521271}]}, {"text": "These agencies look for tweets from within the region affected by the crisis to get the latest updates on the status of the affected region.", "labels": [], "entities": []}, {"text": "However only 1% of all tweets are \"geotagged\" with explicit location information.", "labels": [], "entities": []}, {"text": "In this work we seek to identify non-geotagged tweets that originate from within the crisis region.", "labels": [], "entities": []}, {"text": "Towards this, we address three questions: (1) is there a difference between the language of tweets originating within a crisis region, (2) what linguistic patterns differentiate within-region and outside-region tweets, and (3) can we automatically identify those originating within the crisis region in real-time?", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to Twitter's massive popularity, it has become a tool used by first responders-those who provide first-hand aid in times of crisis-to understand crisis situations and identify the people in the most dire need of assistance).", "labels": [], "entities": []}, {"text": "To do this, first responders can survey \"geotagged\" tweets: those where the user has supplied a geographic location.", "labels": [], "entities": []}, {"text": "The advantage of geotagged tweets is that first responders know whether a person is tweeting from within the affected region or is tweeting from afar.", "labels": [], "entities": []}, {"text": "Tweets from within this region are more likely to contain emerging topics () and tactical, actionable, information that contribute to situational awareness.", "labels": [], "entities": []}, {"text": "A major limitation of surveying geotagged tweets is that only 1% of all tweets are geotagged . This leaves the first responders unable to tap into the vast majority of the tweets they collect.", "labels": [], "entities": []}, {"text": "This limitation leads to the question driving this work: can we discover whether a tweet originates from within a crisis region using only the language used of the tweet?", "labels": [], "entities": []}, {"text": "We focus on the language of a tweet as the defining factor of location for three major reasons: (1) the language of Twitter users is dependent on their location (, (2) the text is readily available in every tweet, and (3) the text allows for real-time analysis.", "labels": [], "entities": []}, {"text": "Due to the short time window presented by most crises, first responders need to be able to locate users quickly.", "labels": [], "entities": []}, {"text": "Towards this goal, we examine tweets from two recent crises: the Boston Marathon bombing and Hurricane Sandy.", "labels": [], "entities": [{"text": "Boston Marathon bombing", "start_pos": 65, "end_pos": 88, "type": "DATASET", "confidence": 0.8906411528587341}]}, {"text": "We show that linguistic differences exist between tweets authored inside and outside the affected regions.", "labels": [], "entities": []}, {"text": "By analyzing the text of individual tweets we can predict whether the tweet originates from within the crisis region, in real-time.", "labels": [], "entities": []}, {"text": "To better understand the characteristics of crisis-time language on Twitter, we conclude with a discussion of the linguistic features that our models find most discriminative.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Twitter data used in our experiments comes from two crises: the Boston Marathon bombing and Hurricane Sandy.", "labels": [], "entities": [{"text": "Boston Marathon bombing", "start_pos": 68, "end_pos": 91, "type": "DATASET", "confidence": 0.8846336603164673}]}, {"text": "Both events provoked a significant Twitter response from within and beyond Hurricane Sandy was a \"superstorm\" that ravaged the Eastern United States in October, 2012.", "labels": [], "entities": []}, {"text": "Utilizing Twitter's Filter API, we collected tweets based on several keywords pertaining to the storm.", "labels": [], "entities": []}, {"text": "Filtering by keywords, this dataset contains both geotagged and non-geotagged data beginning from the day the storm made landfall to several days after (2012-11-02).", "labels": [], "entities": []}, {"text": "Here, we assess the effectiveness of our linguistic features at the task of identifying tweets originating from within the crisis region.", "labels": [], "entities": []}, {"text": "To do this we use a Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifier configured with an individual set of feature classes.", "labels": [], "entities": []}, {"text": "Each of our features are represented as raw frequency counts of the number of times they occur within the tweet.", "labels": [], "entities": []}, {"text": "The output is a prediction of whether the tweet is inside region (IR) or outside region (OR).", "labels": [], "entities": [{"text": "IR) or outside region (OR)", "start_pos": 66, "end_pos": 92, "type": "METRIC", "confidence": 0.7414666041731834}]}, {"text": "We identify the features that can differentiate the two classes of users, and we show that this process can indeed be automated.", "labels": [], "entities": []}, {"text": "We ensure a 50/50 split of IR and OR instances by sampling the OR dataset.", "labels": [], "entities": []}, {"text": "Using the classifier described above, we perform 3 \u00d7 5-fold cross validation on the data.", "labels": [], "entities": []}, {"text": "Because of the 50/50 split, a \"select-all\" baseline that labels all tweets as IR will have an accuracy of 50%, a precision of 50%, and a recall of 100%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9992181062698364}, {"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9992673993110657}, {"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9996846914291382}]}, {"text": "All precision and recall values are from the perspective of the IR class.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995259046554565}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.997806966304779}]}], "tableCaptions": [{"text": " Table 1: Properties of the Twitter crisis datasets.", "labels": [], "entities": [{"text": "Twitter crisis datasets", "start_pos": 28, "end_pos": 51, "type": "DATASET", "confidence": 0.8982783555984497}]}, {"text": " Table 2: Top Feature Combinations: Unigrams  (Uni), Bigrams (Bi) and Crisis-Sensitive (CS)  combinations have the best results.", "labels": [], "entities": []}]}