{"title": [{"text": "Likelihood of external causation in the structure of events", "labels": [], "entities": []}], "abstractContent": [{"text": "This article addresses the causal structure of events described by verbs: whether an event happens spontaneously or it is caused by an external causer.", "labels": [], "entities": []}, {"text": "We automatically estimate the likelihood of external causation of events based on the distribution of causative and anticausative uses of verbs in the causative alternation.", "labels": [], "entities": []}, {"text": "We train a Bayesian model and test it on a monolin-gual and on a bilingual input.", "labels": [], "entities": []}, {"text": "The performance is evaluated against an independent scale of likelihood of external causation based on typological data.", "labels": [], "entities": []}, {"text": "The accuracy of a two-way classification is 85% in both monolingual and bilingual setting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996577501296997}]}, {"text": "On the task of a three-way classification, the score is 61% in the monolingual setting and 69% in the bilingual setting.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ubiquitously present inhuman thinking, causality is encoded in language in various ways.", "labels": [], "entities": []}, {"text": "Computational approaches to causality are mostly concerned with automatic extraction of causal schemata from spontaneously produced texts based on linguistic encoding.", "labels": [], "entities": [{"text": "automatic extraction of causal schemata from spontaneously produced texts", "start_pos": 64, "end_pos": 137, "type": "TASK", "confidence": 0.8190808693567911}]}, {"text": "A key to success in this endeavour is understanding how human language encodes causality.", "labels": [], "entities": []}, {"text": "Linguistic expressions of causality, such as causative conjunctions, verbs, morphemes, and constructions, are highly ambiguous, encoding not only the real-world causality, but also the structure of discourse, as well as speakers' attitudes.", "labels": [], "entities": []}, {"text": "Causality judgements are hard to elicit in an annotation project.", "labels": [], "entities": []}, {"text": "This results in a low inter-annotator agreement and makes the evaluation of automatic systems difficult.", "labels": [], "entities": []}, {"text": "Our study addresses the relationship between world-knowledge about causality and the grammar of language, focusing on the causal structure of events expressed by verbs.", "labels": [], "entities": []}, {"text": "In current analyses, the meaning of verbs is decomposed into multiple predicates which can be in a temporal and causal relation.", "labels": [], "entities": []}, {"text": "Causative: Adam broke the laptop. b. Anticausative: The laptop broke.", "labels": [], "entities": []}, {"text": "We propose a computational approach to the causative alternation, illustrated in (1), in which an event (breaking the laptop in (1)) can be dissociated from its immediate causer).", "labels": [], "entities": []}, {"text": "The causative alternation has been attested in almost all languages, but it is realised with considerable cross-linguistic variation in the sets of alternating verbs and in the grammatical encoding (;.", "labels": [], "entities": []}, {"text": "Since the causative alternation involves most verbs, identifying the properties of verbs which allow them to alternate is important for developing representations of the meaning of verbs in general.", "labels": [], "entities": []}, {"text": "Analysing the structural components of the meaning of verbs proves important for tasks such as word sense disambiguation (), semantic role labelling, cross-linguistic transfer of semantic annotation).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.6895962953567505}, {"text": "semantic role labelling", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.6846876343091329}, {"text": "cross-linguistic transfer of semantic annotation", "start_pos": 150, "end_pos": 198, "type": "TASK", "confidence": 0.8363470196723938}]}, {"text": "The knowledge about the likelihood of external causation might be helpful in the task of detecting implicit arguments of verbs and, especially deverbal nouns (.", "labels": [], "entities": [{"text": "detecting implicit arguments of verbs", "start_pos": 89, "end_pos": 126, "type": "TASK", "confidence": 0.8340172052383423}]}, {"text": "Knowing, for example, that a verb expresses an externally caused event increases the probability of an implicit causer if an explicit causer is not detected in a particular instance of the verb.", "labels": [], "entities": []}, {"text": "Our study should 40 contribute to the development of formal and extensive representations of grammatically relevant semantic properties of verbs, such as Verb Net) and PropBank ().", "labels": [], "entities": [{"text": "Verb Net)", "start_pos": 154, "end_pos": 163, "type": "DATASET", "confidence": 0.8945331374804179}]}], "datasetContent": [{"text": "The accuracy of the predictions of the model is evaluated in experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994526505470276}]}, {"text": "We evaluate the performance of the models against the scale of spontaneous occurrence proposed by, shown in (9).", "labels": [], "entities": []}, {"text": "We expect the verbs classified as internally caused by our models to correspond to the verbs with a low morphological anticausative/causative ratio (those on the left side of the scale).", "labels": [], "entities": []}, {"text": "The opposite is expected for externally caused verbs.", "labels": [], "entities": []}, {"text": "Cause-unspecified verbs are expected to be in the middle of Haspelmath's scale.", "labels": [], "entities": [{"text": "Haspelmath's scale", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.8903529047966003}]}, {"text": "(9) boil, dry, wake up, sink, learn-teach, melt, stop, turn, dissolve, burn, fill, finish, begin, spread, roll, develop, rise-raise, improve, rock, connect, change, gather, open, break, close, split To evaluate the output of our models against the scale, we discretise the scale so that the agreement is maximised for each version of the model.", "labels": [], "entities": [{"text": "boil, dry, wake up, sink, learn-teach, melt, stop, turn, dissolve, burn, fill, finish, begin, spread, roll, develop, rise-raise, improve, rock, connect, change, gather, open, break, close, split", "start_pos": 4, "end_pos": 198, "type": "Description", "confidence": 0.8308840508644397}, {"text": "agreement", "start_pos": 291, "end_pos": 300, "type": "METRIC", "confidence": 0.9549793004989624}]}, {"text": "For example, the threshold which divides the verbs into anticausative and causative in the two-way classification is set after the verb turn.", "labels": [], "entities": []}, {"text": "By evaluating the performance of our models against a typology-based measure, we avoid eliciting human judgements, which is a known problem in computational approaches to causality.", "labels": [], "entities": []}, {"text": "The downside of this approach is that such evaluation is currently possible fora relatively small number of verbs.", "labels": [], "entities": []}, {"text": "shows all the confusion matrices of the classifications performed automatically in comparison with the classifications based on the typology rankings.", "labels": [], "entities": []}, {"text": "In the two-way classification, the two versions of the model, with monolingual and with bilingual input, result in identical classifications.", "labels": [], "entities": []}, {"text": "The agreement of the models with the typological ranking can be considered very good (85%).", "labels": [], "entities": []}, {"text": "The optimal threshold divides the verbs into two asymmetric classes: eight verbs in the internally caused class and eighteen in the externally caused class.", "labels": [], "entities": []}, {"text": "The agreement is better for the internally caused class.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Per class and overall agreement between the corpus-based and the typology-based classification  of verbs; acaus = internally caused, caus = externally caused, unspec. = cause-unspecified.", "labels": [], "entities": []}]}