{"title": [{"text": "Coloring Objects: Adjective-Noun Visual Semantic Compositionality", "labels": [], "entities": [{"text": "Adjective-Noun Visual Semantic Compositionality", "start_pos": 18, "end_pos": 65, "type": "TASK", "confidence": 0.5913484245538712}]}], "abstractContent": [{"text": "This paper reports preliminary experiments aiming at verifying the conjecture that semantic com-positionality is a general process irrespective of the underlying modality.", "labels": [], "entities": []}, {"text": "In particular, we model compositionality of an attribute with an object in the visual modality as done in the case of an adjective with a noun in the linguistic modality.", "labels": [], "entities": []}, {"text": "Our experiments show that the concept topologies in the two modalities share similarities, results that strengthen our conjecture.", "labels": [], "entities": []}, {"text": "1 Language and Vision Recently, fields like computational linguistics and computer vision have converged to a common way of capturing and representing the linguistic and visual information of atomic concepts, through vector space models.", "labels": [], "entities": []}, {"text": "At the same time, advances in computational semantics have lead to effective and linguistically inspired approaches of extending such methods from single concepts to arbitrary linguistic units (e.g. phrases), through means of vector-based semantic composition (Mitchell and Lapata, 2010).", "labels": [], "entities": []}, {"text": "Compositionality is not to be considered only an important component from a linguistic perspective, but also from a cognitive perspective and there has been efforts to validate it as a general cognitive process.", "labels": [], "entities": []}, {"text": "However, in computer vision so far compositionality has received limited attention.", "labels": [], "entities": []}, {"text": "Thus, in this work, we study the phenomenon of visual compositionality and we complement limited previous literature that has focused on event compositionality (St\u00f6ttinger et al., 2012) or general image structure (Socher et al., 2011), by studying models of attribute-object semantic composition.", "labels": [], "entities": [{"text": "event compositionality", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.7453810274600983}, {"text": "attribute-object semantic composition", "start_pos": 258, "end_pos": 295, "type": "TASK", "confidence": 0.6721723179022471}]}, {"text": "Ina nutshell, our work consists of learning vector representations of attribute-object (e.g., \"red car\", \"cute dog\" etc.) and objects (e.g., \"car\", \"dog\", \"truck\", \"cat\" etc.) and by using those compute the representation of new objects having similar attributes (\"red truck\", \"cute cat\" etc.).", "labels": [], "entities": []}, {"text": "This question has both theoretical and applied impact.", "labels": [], "entities": []}, {"text": "The possibility of developing a visual compositional model of attribute-object, on the one hand, could shed light on the acquisition of such ability in humans; how we learn attribute representation and compose them with different objects is still an open question within the cognitive science community (Mintz and Gleitman, 2002).", "labels": [], "entities": []}, {"text": "On the other hand, computer vision systems could become generative and be able to recognize unseen attribute-object combinations, a component especially useful for object recognition and image retrieval.", "labels": [], "entities": [{"text": "object recognition", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.7749001979827881}, {"text": "image retrieval", "start_pos": 187, "end_pos": 202, "type": "TASK", "confidence": 0.7387339174747467}]}], "introductionContent": [], "datasetContent": [{"text": "The visual representations of attribute-objects and objects are created with the PHOW-color features ( and SIFT color-agnostic features) respectively.", "labels": [], "entities": [{"text": "PHOW-color", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.8709959983825684}]}, {"text": "The linguistic representations for the adjective-noun W phrase and noun W noun are built with the word2vec toolkit 1 using a corpus of 3 billion tokens.", "labels": [], "entities": []}, {"text": "Both visual and linguistic representations consist of 300 dimensions.", "labels": [], "entities": []}, {"text": "In this work, we focus on attributes related to 10 colors () fora total number of 9699 images depicting 202 unique objects/nouns and 886 unique phrases (attributeobject/adjective-noun).", "labels": [], "entities": []}, {"text": "Our experiments are conducted with aggregated attribute-object representations obtained by summing the visual vectors extracted from images representing the same attribute-object, The same pipeline is followed for the objects to obtain aggregated object vectors.", "labels": [], "entities": []}, {"text": "This work aims at comparing the behavior of the semantically-driven compositionality process across the two modalities.", "labels": [], "entities": []}, {"text": "For this reason, we report results on the intersection of V phrase and W phrase , a process that results in 266 attribute-object/adjective-noun items.", "labels": [], "entities": []}, {"text": "Furthermore, although the training data for the two modalities are different, the size of the training data is identical, i.e., the f V attr is trained using the remaining 620 attribute-object items, whereas for the f W adj , we randomly sample 620 adjective-noun items from the language space.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Spearman correlations between the similarities in the V comp  phrase and other semantic spaces.", "labels": [], "entities": []}]}