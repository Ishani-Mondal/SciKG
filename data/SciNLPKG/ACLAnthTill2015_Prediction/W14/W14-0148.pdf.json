{"title": [{"text": "Towards Building Lexical Ontology via Cross-Language Matching", "labels": [], "entities": [{"text": "Cross-Language Matching", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7879458963871002}]}], "abstractContent": [{"text": "In this paper, we introduce a methodology for mapping linguistic ontologies lexicalized across different languages.", "labels": [], "entities": []}, {"text": "We present a classification-based semantics for mappings of lexicalized concepts across different languages.", "labels": [], "entities": []}, {"text": "We propose an experiment for validating the proposed cross-language mapping semantics, and discuss its role in creating a gold standard that can be used in assessing cross-language matching systems.", "labels": [], "entities": [{"text": "cross-language mapping semantics", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.834727923075358}, {"text": "cross-language matching", "start_pos": 166, "end_pos": 189, "type": "TASK", "confidence": 0.7338922023773193}]}], "introductionContent": [], "datasetContent": [{"text": "We present an experimental setting whereby the proposed cross-language mapping semantics can be evaluated and a gold standard to assess the quality and to compare alternative crosslanguage mapping methods can be generated.", "labels": [], "entities": []}, {"text": "In order to validate the equivalent relation we need to perform the following CL-WSD classification tasks: given a parallel corpus ( or two corpuses) which lexicalized in English and Arabic.", "labels": [], "entities": [{"text": "CL-WSD classification", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.674987405538559}]}, {"text": "We disambiguate each occurrence of w en,i in English sentences with a word sense \ud97b\udf59 \ud97b\udf59 and \ud97b\udf59 \ud97b\udf59 in English and Arabic respectively.", "labels": [], "entities": []}, {"text": "In this way, we obtain two sets of distinct concepts \ud97b\udf59 \u0305 and \ud97b\udf59 \ud97b\udf59 that have been used to disambiguate the English word wen respectively in senses form English and Arabic.", "labels": [], "entities": []}, {"text": "For each \ud97b\udf59 \ud97b\udf59 \u2208 \u2208 \u0305 we count how many times \ud97b\udf59 \ud97b\udf59 has been co-disambiguated with every \ud97b\udf59 \ud97b\udf59 \u2208 \u2208 \ud97b\udf59 . The co-disambiguation count for the two concepts \ud97b\udf59 and \ud97b\udf59 represent the degree (confidence level) at which we can consider \ud97b\udf59 as a subclass of \ud97b\udf59.", "labels": [], "entities": []}, {"text": "In the same way, we disambiguate each occurrence of w ar,i in Arabic sentences with a word sense \ud97b\udf59 \ud97b\udf59 and \ud97b\udf59 \ud97b\udf59 in English and Arabic respectively.", "labels": [], "entities": []}, {"text": "The distinct set of concepts \ud97b\udf59 \u0305 and \ud97b\udf59 \ud97b\udf59 have been used to disambiguate the Arabic word war respectively in senses from English and Arabic.", "labels": [], "entities": []}, {"text": "For each \ud97b\udf59 \ud97b\udf59 \u2208 \u2208 \ud97b\udf59 we count the number that \ud97b\udf59 \ud97b\udf59 has been co-disambiguated with every \ud97b\udf59 \ud97b\udf59 \u2208 \u2208 \u0305 . The proportion of the co-disambiguation for the two concepts \ud97b\udf59 and \ud97b\udf59 represent the confidence level at which we can consider \ud97b\udf59 as a subclass of \ud97b\udf59.", "labels": [], "entities": []}, {"text": "Then we use the F-measure to interpret the confidence level of the equivalent relation that aligns the two concepts \ud97b\udf59 and \ud97b\udf59.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9877827763557434}]}, {"text": "However, it might be difficult and costly to make such experiment at large scale.", "labels": [], "entities": []}, {"text": "One way is to use available sense annotated corpuses.", "labels": [], "entities": []}, {"text": "Nevertheless, such an Arabic corpus is not available.", "labels": [], "entities": []}, {"text": "Therefore, we propose to mine the subclass relations starting form a sense annotated English corpus, we CL-WSD the English words with the equivalent Arabic senses, and then we check if these relations can be converted to equivalence relations by exploiting the structure (relations) of the WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 290, "end_pos": 297, "type": "DATASET", "confidence": 0.9686535000801086}]}, {"text": "The proposed experiment corresponds to a classification task; asking bilingual speakers to perform a CL-WSD classification task.", "labels": [], "entities": [{"text": "CL-WSD classification task", "start_pos": 101, "end_pos": 127, "type": "TASK", "confidence": 0.7280719876289368}]}, {"text": "We collect sentences from \"Princeton Annotated Gloss Corpus\", a corpus of manually annotated WordNet synset definitions (glosses).", "labels": [], "entities": [{"text": "Princeton Annotated Gloss Corpus\"", "start_pos": 27, "end_pos": 60, "type": "DATASET", "confidence": 0.9435258746147156}]}, {"text": "The selected sentences are annotated with at least one sense that belongs to \"Core WordNet\".", "labels": [], "entities": []}, {"text": "The reason for selecting Core WordNet concepts is that they represent the most frequent and salient concepts and thus can shared among many or most languages.", "labels": [], "entities": []}, {"text": "Accordingly, we hypothesize that mapping the core WordNet concepts to the equivalent Arabic concepts will form the core for the Arabic Ontology.", "labels": [], "entities": []}, {"text": "Then we can extend it to include more cultural and language-specific concepts.", "labels": [], "entities": []}, {"text": "For each English word sense, a number of bilingual speakers (lexicographers) are asked to provide the equivalent Arabic word sense.", "labels": [], "entities": []}, {"text": "For each word sense, the lexicographers substitute the English word with one of the Arabic synsets, which have been developed at Sina Institute and classified under the top levels.", "labels": [], "entities": []}, {"text": "Using available bilingual dictionaries the lexicographers select the best translation.", "labels": [], "entities": []}, {"text": "In, in the sentence \"the act of starting to construct a house\", the English word \"house\" was CL-WSD with the English sense house 1 n and the Arabic sense (\u202b,\u0645\u0646\u0632\u0644\u202c Mnzel) . For the same sentence we substitute the sense house 1 n with its direct hypernym (subclass) sense home 1 n from the WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 288, "end_pos": 295, "type": "DATASET", "confidence": 0.9791648387908936}]}, {"text": "We CL-WSD the sense home 1 n with the Arabic sense (\u202b,\u0628\u064a\u062a\u202c Baet).", "labels": [], "entities": []}, {"text": "Ideally, we should be able to deduce the subclass relation between (\u202b)\u0645\u0646\u0632\u0644\u202c and (\u202b.)\u0628\u064a\u062a\u202c: Example of CL-WSD task and a possible inference.", "labels": [], "entities": []}, {"text": "However, as mentioned before, not every concept is lexicalized in both (all) languages.", "labels": [], "entities": []}, {"text": "The mappings thus obtained will form an initial semantic network.", "labels": [], "entities": []}, {"text": "However, conflicts and overlaps might exist.", "labels": [], "entities": []}, {"text": "The top levels concepts can control and eliminate part of this problem.", "labels": [], "entities": []}, {"text": "For example, the associated concepts should be classified under the same top concept.", "labels": [], "entities": []}, {"text": "This direction of work also taking into account the relations confidence level will be pursued in the future.", "labels": [], "entities": []}, {"text": "We plan to experiment with the proposed mapping approach on a large scale by considering all 5,000 Core WordNet concepts and to simulate the majority of speakers by incorporation larger number of bilingual speakers (lexicographers).", "labels": [], "entities": []}, {"text": "We suggest adopting a crowdsourcing method (e.g., Amazon Mechanical Turkey () to collect feedback from larger number of lexicographers.", "labels": [], "entities": [{"text": "Amazon Mechanical Turkey", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.9511515100797018}]}, {"text": "A significance result of a fullscale version of the proposed experiment is to generate a gold standard for cross-language mappings.", "labels": [], "entities": []}, {"text": "That can be used to assess the various automatic cross-language matching systems as well to validate the proposed semantic mapping.", "labels": [], "entities": [{"text": "cross-language matching", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7015230506658554}]}, {"text": "Thereby selecting or extending such mapping methods that can be used to discover mappings at large-scale and solve the problem of creating large-scale linguistic ontologies in a (semi)-automatic way.", "labels": [], "entities": []}, {"text": "Moreover, we can validate the language-dependence hypothesis of the salient (core) concepts.", "labels": [], "entities": []}, {"text": "In addition, we plan to investigate the explicit semantic analysis approach in the cross-language mapping settings (Sorg and Cimiano 2012) to enhance the word sense selection (conceptual translation) task.", "labels": [], "entities": [{"text": "explicit semantic analysis", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.697374572356542}, {"text": "word sense selection (conceptual translation)", "start_pos": 154, "end_pos": 199, "type": "TASK", "confidence": 0.7915127617972237}]}], "tableCaptions": []}