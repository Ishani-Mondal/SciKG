{"title": [{"text": "Knowledge Acquisition Strategies for Goal-Oriented Dialog Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "Many goal-oriented dialog agents are expected to identify slot-value pairs in a spoken query, then perform lookup in a knowledge base to complete the task.", "labels": [], "entities": []}, {"text": "When the agent encounters unknown slot-values, it may ask the user to repeat or re-formulate the query.", "labels": [], "entities": []}, {"text": "But a robust agent can proactively seek new knowledge from a user, to help reduce subsequent task failures.", "labels": [], "entities": []}, {"text": "In this paper, we propose knowledge acquisition strategies fora dialog agent and show their effectiveness.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.8612366914749146}]}, {"text": "The acquired knowledge can be shown to subsequently contribute to task completion.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many spoken dialog agents are designed to perform specific tasks in a specified domain e.g., information about public events in a city.", "labels": [], "entities": []}, {"text": "To carryout its task, an agent parses an input utterance, fills in slot-value pairs, then completes the task.", "labels": [], "entities": []}, {"text": "Sometimes, information on these slot-value pairs may not be available in its knowledge base.", "labels": [], "entities": []}, {"text": "In such cases, typically the agent categorizes utterances as non-understanding errors.", "labels": [], "entities": []}, {"text": "Ideally the incident is recorded and the missing knowledge is incorporated into the system with a developer's assistance -a slow offline process.", "labels": [], "entities": []}, {"text": "There are other sources of knowledge: automatically crawling the web, as done by NELL, and community knowledge bases such as Freebase.", "labels": [], "entities": []}, {"text": "These approaches provide globally popular slotvalues and high-level semantic contexts.", "labels": [], "entities": []}, {"text": "Despite their size, these knowledge bases may not contain information about the entities in a specific target domain.", "labels": [], "entities": []}, {"text": "However, users in the agent's domain can potentially provide specific information on slot/values that are unavailable on the web, e.g., regarding a recent interest/hobby of the user's friend.", "labels": [], "entities": []}, {"text": "have elicited natural language dialogs from humans to build NLU models for the agent and Bigham et al. have elicited answers to visual questions by integrating users into the system.", "labels": [], "entities": []}, {"text": "One observation from this work is that both users and non-users can impart useful knowledge to system.", "labels": [], "entities": []}, {"text": "In this paper we propose spoken language strategies that allow an agent to elicit new slot-value pairs from its own user population to extend its knowledge base.", "labels": [], "entities": []}, {"text": "Open-domain knowledge maybe elicited through text-based questionnaires from non-users of the system, but in a situated interaction scenario spoken strategies maybe more effective.", "labels": [], "entities": []}, {"text": "We address the following research questions: 1.", "labels": [], "entities": []}, {"text": "Can an agent elicit reliable knowledge about its domain from users?", "labels": [], "entities": []}, {"text": "Particularly knowledge it cannot locate elsewhere (e.g., on-line knowledge bases).", "labels": [], "entities": []}, {"text": "Is the collective knowledge of the users sufficient to allow the agent to augment its knowledge through interactive means?", "labels": [], "entities": []}, {"text": "2. What strategies elicit useful knowledge from users?", "labels": [], "entities": []}, {"text": "Based on previous work in commonsense knowledge acquisition, we devise spoken language strategies that allow the system to solicit information by presenting concrete situations and by asking user-centric questions.", "labels": [], "entities": [{"text": "commonsense knowledge acquisition", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.8652599652608236}]}, {"text": "We address these questions in the context of the EVENTSPEAK dialog system, an agent that provides information about seminars and talks in an academic environment.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss knowledge acquisition strategies.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.8777684569358826}]}, {"text": "In Section 3, we describe a user study on these strategies.", "labels": [], "entities": []}, {"text": "Then, we present an evaluation on system acquired knowledge and finally we make concluding remarks.", "labels": [], "entities": []}, {"text": "They are described below: QUERYDRIVEN.", "labels": [], "entities": [{"text": "QUERYDRIVEN", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.5575476884841919}]}, {"text": "The system prompts a user with an open-ended question akin to \"how-may-Ihelp-you\" to learn what \"values\" of a slot are of interest to the user.", "labels": [], "entities": []}, {"text": "This strategy does not ground user about system's knowledge limitations.", "labels": [], "entities": []}, {"text": "However, it allows the system to acquire information (slot-value pairs) from user's input.", "labels": [], "entities": []}, {"text": "The system can choose to respond to the input or ignore the input depending on its knowledge about the slotvalue pairs in the input.", "labels": [], "entities": []}, {"text": "shows strategies of this kind i.e., QUERYEVENT and QUERYPERSON.", "labels": [], "entities": [{"text": "QUERYEVENT", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.7928059697151184}, {"text": "QUERYPERSON", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.778412938117981}]}, {"text": "The system asks a user about their own interests and people who may share those interests.", "labels": [], "entities": []}, {"text": "This is an open-ended request as well, but the system expects the response to be confined to the user's knowledge about specific entities in the environment.", "labels": [], "entities": []}, {"text": "BUZZWORDS and FAMOUSPEOPLE expects the user to provide values for the slots.", "labels": [], "entities": [{"text": "BUZZWORDS", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8529148697853088}, {"text": "FAMOUSPEOPLE", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.8361055850982666}]}, {"text": "The system provides a description of an event and asks questions to ground user's responses in relation to that event.", "labels": [], "entities": []}, {"text": "E.g., given the title and abstract of a technical talk, the system asks the user questions about the talk.", "labels": [], "entities": []}, {"text": "TWEET strategy is expected to elicit a concise description of the event, which eventually may help the agent to both summarize events for other users and identify keywords for an event.", "labels": [], "entities": [{"text": "summarize events", "start_pos": 117, "end_pos": 133, "type": "TASK", "confidence": 0.8877116143703461}]}, {"text": "KEYWORDS strategy expects the user to explicitly supply keywords for an event.", "labels": [], "entities": []}, {"text": "PEOPLE strategy expects the user to provide names of likely event participants.", "labels": [], "entities": []}, {"text": "We hypothesized that these strategies may allow the agent to learn new slot-value pairs that may help towards better task performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "To answer Can an agent elicit reliable knowledge about its domain from users?", "labels": [], "entities": []}, {"text": "we analyzed the relevance of acquired knowledge.", "labels": [], "entities": []}, {"text": "We have two disjoint list of entities, (a) researchers and (b) research interests; in addition we have speaker names from the talk descriptions.", "labels": [], "entities": []}, {"text": "Our goal is to implicitly infer a list of interests for each researcher without soliciting the user for the interests of every researcher exhaustively.", "labels": [], "entities": []}, {"text": "To each researcher in the list, we attribute list of interests that were mentioned in the same context as researcher was mentioned.", "labels": [], "entities": []}, {"text": "We tag list of names acquired from the FAMOUSPEOPLE strategy with list of keywords acquired from the BUZZWORDS strategyboth lists acquired from same user.", "labels": [], "entities": [{"text": "BUZZWORDS", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.8559659123420715}]}, {"text": "We repeat this process for each name mentioned in relation to a talk in the SHOW&ASK strategy.", "labels": [], "entities": [{"text": "SHOW&ASK strategy", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.515815295279026}]}, {"text": "We tag keywords mentioned in the KEYWORDS strategy to researchers mentioned in the PEOPLE strategy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Mean Precision for 200 researchers, broken down by the \"source\" strategy used to acquire their name  Note: Only 85 of 200 researchers had Google Scholar pages, GScholar Accuracy is computed for only those 85.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9960450530052185}, {"text": "Precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.7875488996505737}, {"text": "GScholar", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9089535474777222}, {"text": "Accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.6094810962677002}]}]}