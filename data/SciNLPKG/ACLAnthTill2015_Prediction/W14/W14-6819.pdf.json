{"title": [{"text": "An Introduction to BLCU Personal Attributes Extraction System", "labels": [], "entities": [{"text": "BLCU Personal Attributes Extraction", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.7718035876750946}]}], "abstractContent": [{"text": "We describe our methods for share task of personal attributes extraction.", "labels": [], "entities": [{"text": "personal attributes extraction", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6565466523170471}]}, {"text": "We divide all 25 attributes into several categories and propose 4 kinds of pipelines to carryout value extraction.", "labels": [], "entities": [{"text": "value extraction", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.7329614013433456}]}, {"text": "There are two stages in the process.", "labels": [], "entities": []}, {"text": "The first stage uses CRF model or regular expression based extractor to produce initial answers.", "labels": [], "entities": []}, {"text": "In the second stage, we propose two methods to filter out mistake answers: protagonist dependency relationship based filter and attribute keywords based filter.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe the BLCU-PAE system for CIPS-SIGHAN 2014 bakeoffs.", "labels": [], "entities": [{"text": "BLCU-PAE", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9648861289024353}, {"text": "CIPS-SIGHAN 2014 bakeoffs", "start_pos": 51, "end_pos": 76, "type": "DATASET", "confidence": 0.784354567527771}]}, {"text": "The Personal Attributes Extraction (PAE) in Chinese Text Task is designed to extract person specific attributes, like date of birth and death, family relationships, education, title etc. from unstructured Chinese texts.", "labels": [], "entities": [{"text": "Personal Attributes Extraction (PAE) in Chinese Text Task", "start_pos": 4, "end_pos": 61, "type": "TASK", "confidence": 0.7440486282110215}]}, {"text": "The corresponding techniques play an important role in information extraction, event tracking, entity disambiguation and other related research areas.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.8614671528339386}, {"text": "event tracking", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.8504395484924316}, {"text": "entity disambiguation", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.8033314943313599}]}, {"text": "In the task, the incomplete attributes of a target person are defined as Slots, i.e. the extracted attribute value need to be filled into these slots.", "labels": [], "entities": [{"text": "Slots", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.9825108647346497}]}, {"text": "There are 3 kinds of slots, name slots, value slots and string slots, in which only entity name, number/time and string can be filled in.", "labels": [], "entities": []}, {"text": "Single-value slots have only one correct answer while listvalue slots have a set of answers.", "labels": [], "entities": []}, {"text": "There are totally 25 attributes need to be extracted, as shown in.", "labels": [], "entities": []}, {"text": "Slot filling task has been one of shared tasks in the TAC KBP workshop science 2009.", "labels": [], "entities": [{"text": "Slot filling task", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9102330406506857}, {"text": "TAC KBP workshop science 2009", "start_pos": 54, "end_pos": 83, "type": "DATASET", "confidence": 0.9249776840209961}]}, {"text": "In this area, earlier systems generally use one main pipeline that contains 3 stages: document retrieval, answer extraction, and answer combination.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7135666012763977}, {"text": "answer extraction", "start_pos": 106, "end_pos": 123, "type": "TASK", "confidence": 0.8083096444606781}]}, {"text": "Supervised learning normally leads to a reasonably good performance.", "labels": [], "entities": []}, {"text": "Both bootstrapping and rule based pattern matching with trigger words are used in.", "labels": [], "entities": [{"text": "rule based pattern matching", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.5919302105903625}]}, {"text": "Active learning techniques are also used in the task.", "labels": [], "entities": []}, {"text": "UNED system introduces a graph structure to solve the problem.", "labels": [], "entities": [{"text": "UNED", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9254960417747498}]}, {"text": "CMUML uses distant supervision and CRF-based structured prediction for producing the final answers.", "labels": [], "entities": [{"text": "CMUML", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9339265823364258}, {"text": "CRF-based structured prediction", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.5388745466868082}]}, {"text": "Up to now, slot filling remains a very challenging task; most of the shortfall reflects inadequacies in the answer extraction stage.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.9342440664768219}, {"text": "answer extraction", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.9210707247257233}]}], "datasetContent": [{"text": "The PAE task takes the same evaluation metrics adopted in the slot filling of TAC KBP.", "labels": [], "entities": [{"text": "PAE", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.6428565979003906}, {"text": "slot filling", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.7042385339736938}, {"text": "TAC KBP", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.8301437795162201}]}, {"text": "For single attributes, system score is computed by (1), where we set NumCorrect to 1.0 when it is zero.", "labels": [], "entities": []}, {"text": "For list attributes, system score is computed by (2), in which ListSlotValue is defined by (3), ) ( Where F \u03b2 = 2 (to weight precision over recall), IP = instance precision and IR = instance recall . Also we set ListSlotValue to 0.0, when both IP and IR are zero.", "labels": [], "entities": [{"text": "precision", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.7950738668441772}, {"text": "recall", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.8878588080406189}, {"text": "instance precision", "start_pos": 154, "end_pos": 172, "type": "METRIC", "confidence": 0.5387196093797684}]}, {"text": "System performance is finally evaluated by (4), that is the average of single attributes evaluation score and list attributes evaluation score.", "labels": [], "entities": []}, {"text": "In the evaluation, both the lenient evaluation and strict evaluation are performed.", "labels": [], "entities": []}, {"text": "In the strict evaluation, all instance attributes are compared to the answers while in the lenient evaluation, the offset string_begin and string_end are ignored.", "labels": [], "entities": []}, {"text": "In evaluation, there are totally 90 test persons and 233 test documents.", "labels": [], "entities": []}, {"text": "shows the evaluation results of our system and the best performance system.", "labels": [], "entities": []}, {"text": "In general, there is still a big gap between our system and the best one.", "labels": [], "entities": []}, {"text": "In our system, performances of lenient and strict results are similar.", "labels": [], "entities": []}, {"text": "Single score is obviously better than list score, shows that multi-value attributes is more difficult to extract.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The statistic of annotations", "labels": [], "entities": []}]}