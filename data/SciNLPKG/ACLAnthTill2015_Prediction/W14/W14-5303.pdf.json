{"title": [{"text": "Pos-tagging different varieties of Occitan with single-dialect resources", "labels": [], "entities": []}], "abstractContent": [{"text": "In this study, we tackle the question of pos-tagging written Occitan, a lesser-resourced language with multiple dialects each containing several varieties.", "labels": [], "entities": []}, {"text": "For pos-tagging, we use a supervised machine learning approach, requiring annotated training and evaluation corpora and optionally a lexicon, all of which were prepared as part of the study.", "labels": [], "entities": []}, {"text": "Although we evaluate two dialects of Occitan, Lengadocian and Gascon, the training material and lexicon concern only Lengadocian.", "labels": [], "entities": []}, {"text": "We concluded that reasonable results (> 89% accuracy) are possible with a very limited training corpus (2500 tokens), as long as it is compensated by intensive use of the lexicon.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9959217309951782}]}, {"text": "Results are much lower across dialects, and pointers are provided for improvement.", "labels": [], "entities": []}, {"text": "Finally, we compare the relative contribution of more training material vs. a larger lexicon, and conclude that within our configuration, spending effort on lexicon construction yields higher returns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Pos-tagging is one of the first steps in many Natural Language Processing chains, and generally requires annotated corpora and lexicons to function properly.", "labels": [], "entities": []}, {"text": "Substantial efforts are needed to create such resources, few of which exist in the required format for less-resourced languages like Occitan.", "labels": [], "entities": []}, {"text": "Creating them is more challenging since less-resourced languages present spelling and dialectal variations and are not necessarily standardized.", "labels": [], "entities": []}, {"text": "In this paper, we apply a tool that was initially developed for rich-resourced languages (French and English), the pos-tagger Talismane, to different varieties and dialects of literary Occitan.", "labels": [], "entities": []}, {"text": "We evaluate whether adapting this tool with only little annotated data is worthwhile.", "labels": [], "entities": []}, {"text": "Various efforts have been made recently to adapt pos-taggers to lesser-resourced languages.", "labels": [], "entities": []}, {"text": "use a semi-supervised approach based on aligned bitext between a resource-rich and resource-poor language, and achieve substantial gains.", "labels": [], "entities": []}, {"text": "In our case, without an aligned bitext resource, we were unable to attempt this approach.", "labels": [], "entities": []}, {"text": "perform an experiment giving annotators limited time (4 hours) to annotate either training corpora or lexicons (which they call token and type annotation) for 2 low-resourced languages.", "labels": [], "entities": []}, {"text": "They conclude that lexicons provide higher initial gains.", "labels": [], "entities": []}, {"text": "However, whereas their lexicons are constructed by automatically selecting the most frequent words from large unannotated corpora, our study can make use of existing wide-coverage lexical resources.", "labels": [], "entities": []}, {"text": "use an approach where lexical cognates are identified between a resource-rich and resource-poor language, and their pos-tags are then used to help tagging the resource-poor language.", "labels": [], "entities": []}, {"text": "Their approach is interesting for languages, unlike Occitan, with no lexical resources available.", "labels": [], "entities": []}, {"text": "However, even cross-language approaches require a small manually-annotated corpus for accurate evaluation.", "labels": [], "entities": []}, {"text": "It seems simpler to begin by using this corpus for both training and evaluation before attempting more complex approaches.", "labels": [], "entities": []}, {"text": "A finer evaluation would then be required to determine whether data quality (a small purpose-built corpus) or quantity (a large cross-language corpus) are more important for the present task.", "labels": [], "entities": []}, {"text": "A pos-tagger for Occitan was also developped as an intermediate step for machine translation in Apertium, where the most likely translation is used to select the correct pos-tags.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.776242733001709}, {"text": "Apertium", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.9244376420974731}]}, {"text": "However, since they only evaluate the resulting translation quality, and since Apertium is not available as a standalone pos-tagger, we were unable to perform comparisons.", "labels": [], "entities": []}, {"text": "Our article is organized as follows: in Section 2, we give an overview of the Occitan language and its dialects.", "labels": [], "entities": []}, {"text": "In Section 3, we present the software used, Talismane, as well as the feature and rule sets applied.", "labels": [], "entities": []}, {"text": "In Section 4, we discuss the various resources that were constructed for this study, including corpora and lexica.", "labels": [], "entities": []}, {"text": "In Section 5 we give the experimental setup, and discuss the results in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, three different corpora were compiled: the first one, the Rouergue corpus, was extracted from: Los crocants de Roergue by FerranDe\u00ec eris, another author from the Rouergue region; the second one, the Lot corpus, was extracted from Dels caminsbartass\u00ec ers by Marceu Esquieu, written in another shows a statistical comparison of the different corpora.", "labels": [], "entities": []}, {"text": "As we can see, the percent of tokens unseen in the training corpus (excluding punctuation) ranges from 46% for the same dialectal variant (Rouergue) to 56% fora different dialect (Gascon).", "labels": [], "entities": []}, {"text": "The difference is even more striking in terms of the Lengadocian lexicon: 17% unknown forms in the Rouergue corpus vs. 40% unknown forms in the Gascon corpus.", "labels": [], "entities": [{"text": "Lengadocian lexicon", "start_pos": 53, "end_pos": 72, "type": "DATASET", "confidence": 0.791395366191864}, {"text": "Rouergue corpus", "start_pos": 99, "end_pos": 114, "type": "DATASET", "confidence": 0.9543177783489227}, {"text": "Gascon corpus", "start_pos": 144, "end_pos": 157, "type": "DATASET", "confidence": 0.9502592980861664}]}, {"text": "Closed class coverage is particularly good for the two Lengadocian variants, with only 1.5% and 1% unknown forms, as opposed to 20% in the Gascon corpus.", "labels": [], "entities": [{"text": "Gascon corpus", "start_pos": 139, "end_pos": 152, "type": "DATASET", "confidence": 0.9501911997795105}]}, {"text": "The resources we built were designed with several questions in mind: \u2022 Which is the best strategy for each evaluation corpus?", "labels": [], "entities": []}, {"text": "\u2022 Is it always useful to apply closed-class rules?", "labels": [], "entities": []}, {"text": "\u2022 To what extent can a model built from a training corpus fora single dialectal variety be applied to other varieties and dialects?", "labels": [], "entities": []}, {"text": "\u2022 To what extent can a lexicon for one dialect be applied to another dialect?", "labels": [], "entities": []}, {"text": "\u2022 What methods can be used to improve analysis fora dialect different from the training/lexicon dialect?: Training and evaluation corpora A second range of experiments was designed to answer the following question: Given limited resources, is it better to annotate a larger training corpus, or compile a larger lexicon?", "labels": [], "entities": []}, {"text": "To this end, we divided the training corpus into two halves, train1 and train2.", "labels": [], "entities": []}, {"text": "We also created several sub-lexica: closed classes only (closed), closed classes + half of the open class entries (half1) closed classes + the other half of the open class entries (half2), the full lexicon (full) and an empty lexicon (empty).", "labels": [], "entities": []}, {"text": "Finally, we tested with and without closed class rules.", "labels": [], "entities": []}, {"text": "This gave us a total of 3 training corpus options \u00d7 5 lexicon options \u00d7 2 rule options = 30 evaluations per evaluation corpus.", "labels": [], "entities": []}, {"text": "We measured in each evaluation the total accuracy, the precision, recall and f-score for each pos-tag, and for all open pos-tags and all closed pos-tags combined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9992926120758057}, {"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9997915625572205}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9991201758384705}, {"text": "f-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9914597272872925}]}, {"text": "These were also measured separately for the set of tokens known and unknown in the lexicon.", "labels": [], "entities": []}, {"text": "shows results for the different lexicons and with/without closed-class rules (+rules on the.", "labels": [], "entities": []}, {"text": "Not surprisingly, the best configuration for all evaluation corpora was the full training corpus, the full lexicon, and closed-class rules applied.", "labels": [], "entities": []}, {"text": "This gives an accuracy of 87.02% for the Rouergue corpus, 89.08% for the Lot corpus, and 66.17% for the Gascon corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996519088745117}, {"text": "Rouergue corpus", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9734091460704803}, {"text": "Lot corpus", "start_pos": 73, "end_pos": 83, "type": "DATASET", "confidence": 0.9596242308616638}, {"text": "Gascon corpus", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.9631707072257996}]}, {"text": "We can see that even a small training corpus provides reasonable results: almost 90% with only 2500 annotated tokens.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Training and evaluation corpora", "labels": [], "entities": []}]}