{"title": [{"text": "Automatic CEFR level prediction for Estonian learner text", "labels": [], "entities": [{"text": "CEFR level prediction", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7392903963724772}]}], "abstractContent": [{"text": "This paper reports on approaches for automatically predicting a learner's language proficiency in Estonian according to the European CEFR scale.", "labels": [], "entities": [{"text": "predicting a learner's language proficiency in Estonian", "start_pos": 51, "end_pos": 106, "type": "TASK", "confidence": 0.7203688248991966}, {"text": "European CEFR scale", "start_pos": 124, "end_pos": 143, "type": "DATASET", "confidence": 0.9218952258427938}]}, {"text": "We used the morphological and POS tag information extracted from the texts written by learners.", "labels": [], "entities": []}, {"text": "We compared classification and regression modeling for this task.", "labels": [], "entities": []}, {"text": "Our models achieve a classification accuracy of 79% and a correlation of 0.85 when modeled as regression.", "labels": [], "entities": [{"text": "classification", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8620993494987488}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9369407892227173}, {"text": "correlation", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9936922788619995}]}, {"text": "After a comparison between them, we concluded that classification is more effective than regression in terms of exact error and the direction of error.", "labels": [], "entities": [{"text": "classification", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.960198163986206}, {"text": "exact error", "start_pos": 112, "end_pos": 123, "type": "METRIC", "confidence": 0.9762806296348572}]}, {"text": "Apart from this, we investigated the most predictive features for both multi-class and binary classification between groups and also explored the nature of the correlations between highly predictive features.", "labels": [], "entities": []}, {"text": "Our results show considerable improvement in classification accuracy over previously reported results and take us a step closer towards the automated assessment of Estonian learner text.", "labels": [], "entities": [{"text": "classification", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.9008480906486511}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9420676231384277}]}], "introductionContent": [{"text": "People learn a foreign language for many reasons like: living in anew country, having a general interest in the language etc., In many of these scenarios, language learners also undertake exams to get certified for their proficiency in a foreign language.", "labels": [], "entities": []}, {"text": "Language proficiency is typically measured using some standardized scale like the CEFR) in European nations.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.9639614820480347}]}, {"text": "Evaluating free text responses like essays is one of the standard ways of assessing the language proficiency of a learner.", "labels": [], "entities": []}, {"text": "Traditionally, these student essays were evaluated by experienced human graders trained for doing the task.", "labels": [], "entities": []}, {"text": "With the ever increasing number of people taking language tests and with the advent of computational tools that can process language, automatic approaches that reduce human grading effort became a standard way to assess language proficiency.", "labels": [], "entities": [{"text": "assess language proficiency", "start_pos": 213, "end_pos": 240, "type": "TASK", "confidence": 0.5946113367875417}]}, {"text": "Automated essay grading is already being used along with human grading in several assessment exams like Graduate Record Examination (GRE) and Graduate Management Admission Test.", "labels": [], "entities": []}, {"text": "It can also be useful in a placement test that one may take at a language teaching institute before starting to learn a language at a certain level or serve as a guiding tool for language learners in self-assessment.", "labels": [], "entities": []}, {"text": "Apart from this, automated approaches can also enable us to identify distinctive features at a proficiency level, thereby providing us with insights about the process of language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 170, "end_pos": 190, "type": "TASK", "confidence": 0.709030345082283}]}, {"text": "While automated assessment is an active area of research for English, approaches for the automatic proficiency classification of learner essays according to the European CEFR scale were recently proposed for German, and Estonian (.", "labels": [], "entities": [{"text": "automated assessment", "start_pos": 6, "end_pos": 26, "type": "TASK", "confidence": 0.6352798789739609}, {"text": "automatic proficiency classification of learner essays", "start_pos": 89, "end_pos": 143, "type": "TASK", "confidence": 0.7567074398199717}, {"text": "European CEFR scale", "start_pos": 161, "end_pos": 180, "type": "DATASET", "confidence": 0.8235718210538229}]}, {"text": "In this paper, we focus on the proficiency classification of Estonian learner essays.", "labels": [], "entities": [{"text": "proficiency classification of Estonian learner essays", "start_pos": 31, "end_pos": 84, "type": "TASK", "confidence": 0.7751533488432566}]}, {"text": "We started with the feature set described in and added more features to the list.", "labels": [], "entities": []}, {"text": "We also used a more fine-grained subset of the same base corpus, consisting of four CEFR proficiency levels.", "labels": [], "entities": []}, {"text": "We show that our approach improves the overall classification accuracy for this task reaching up to 79% fora four-level classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.980678141117096}]}, {"text": "We compare this approach with modeling the problem as regression and show that classification performs better in terms of accuracy and the direction of error.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9992634654045105}]}, {"text": "Apart from these, to gain a better understanding of the modeling process, we also studied the issues of feature selection, most predictive features for classification between categories and for overall classification, and correlations between features.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.6866618692874908}]}, {"text": "In sum, we investigate proficiency classification both from a prediction as well as an interpretational perspective.", "labels": [], "entities": [{"text": "proficiency classification", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.907065212726593}]}, {"text": "Rest of this paper is organized as follows: we start with an overview of contemporary research in proficiency classification of free text responses in Section 2 and describe the corpus and features we used in Section 3.", "labels": [], "entities": [{"text": "proficiency classification of free text responses", "start_pos": 98, "end_pos": 147, "type": "TASK", "confidence": 0.897347112496694}]}, {"text": "Section 4 describes our experimental setup and explains the classification and regression experiments we performed along with our results.", "labels": [], "entities": []}, {"text": "Section 5 briefly discusses feature selection and correlational analysis with all the features.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.8063226938247681}, {"text": "correlational analysis", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7077579349279404}]}, {"text": "Section 6 concludes the paper with pointers to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our corpus is a collection of texts spanning multiple proficiency levels.", "labels": [], "entities": []}, {"text": "The proficiency levels can be assumed to be discrete or continuous, and with varying degree of difference between succeeding levels (i.e., difference between A2 and B1 maybe less than that of B1 and B2).", "labels": [], "entities": [{"text": "A2", "start_pos": 158, "end_pos": 160, "type": "METRIC", "confidence": 0.9858172535896301}]}, {"text": "This allows us to conceptualize the problem of proficiency classification as belonging to nominal or interval or ordinal scales.", "labels": [], "entities": [{"text": "proficiency classification", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.9241305291652679}]}, {"text": "Accordingly, we investigated this dataset by considering the problem as classification and regression.", "labels": [], "entities": []}, {"text": "We did not explore ordinal representation yet.", "labels": [], "entities": []}, {"text": "We used WEKA () for training the machine learning models and for feature selection.", "labels": [], "entities": [{"text": "WEKA", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.6681873798370361}, {"text": "feature selection", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7556641399860382}]}, {"text": "We used multiple evaluation measures based on the choice of learning approaches.", "labels": [], "entities": []}, {"text": "We evaluated classification performance in terms of its prediction accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9614929556846619}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.7950513362884521}]}, {"text": "Additionally, we report the confusion matrices and F-scores per class to compare the performance with balanced and unbalanced datasets.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9806078672409058}]}, {"text": "For linear regression, we report Pearson correlation and Root Mean Square Error (RMSE) as evaluation measures.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 33, "end_pos": 52, "type": "METRIC", "confidence": 0.8977283537387848}, {"text": "Root Mean Square Error (RMSE)", "start_pos": 57, "end_pos": 86, "type": "METRIC", "confidence": 0.8931966083390372}]}, {"text": "All the evaluation was performed in a 10-fold Cross Validation setting.", "labels": [], "entities": []}, {"text": "We are not aware of any direct measure of comparison between classification and regression approaches using the same data.", "labels": [], "entities": []}, {"text": "Hence, we used three measures after rounding off the regression prediction to the nearest integer value: 1.", "labels": [], "entities": []}, {"text": "Percentage of exact matches (This is the same as accuracy for classification.)", "labels": [], "entities": [{"text": "exact", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.7434311509132385}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9997289776802063}, {"text": "classification", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.9605377912521362}]}, {"text": "2. Percentage of instances where the prediction is within one-level of the actual value (This is closely related to the prediction error and adjacent accuracy in regression models.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.7787216305732727}]}, {"text": "3. Percentage of errors where the prediction is higher than the actual level.", "labels": [], "entities": [{"text": "Percentage of errors", "start_pos": 3, "end_pos": 23, "type": "METRIC", "confidence": 0.9145059585571289}]}, {"text": "This measure was considered with the assumption that in a placement testing scenario, assigning a learner actually belonging to A2 assay, B2 is more undesirable compared to assigning a B2 learner to A2 level.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The Estonian Interlanguage Corpus", "labels": [], "entities": [{"text": "Estonian Interlanguage", "start_pos": 14, "end_pos": 36, "type": "DATASET", "confidence": 0.8799407780170441}]}, {"text": " Table 3: Confusion matrices for Unbalanced and Balanced training datasets", "labels": [], "entities": []}, {"text": " Table 4: F-scores per category, for Balanced and Unbalanced training datasets", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9927736520767212}, {"text": "Balanced and Unbalanced training datasets", "start_pos": 37, "end_pos": 78, "type": "DATASET", "confidence": 0.5179346203804016}]}, {"text": " Table 5: Binary Classification Accuracy", "labels": [], "entities": [{"text": "Binary Classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9594590961933136}, {"text": "Accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8948059678077698}]}, {"text": " Table 7: Classification Accuracy with Feature Selection", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.961402952671051}, {"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9280195236206055}]}, {"text": " Table 9: The Most Correlated Features  Several features in the most predictive features have a high degree of correlation between each  other, as shown in the table. It would perhaps be sufficient to use only one of them to achieve  the same amount of predictability. Further analysis is needed to choose a refined feature set  that can be as predictive in terms of modeling but also more interpretable in linguistic terms.", "labels": [], "entities": []}]}