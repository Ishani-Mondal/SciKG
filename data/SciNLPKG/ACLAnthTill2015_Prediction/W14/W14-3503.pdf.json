{"title": [{"text": "Towards Automatic Scoring of Cloze Items by Selecting Low-Ambiguity Contexts", "labels": [], "entities": [{"text": "Automatic Scoring of Cloze Items", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.7147560775279999}]}], "abstractContent": [{"text": "In second language learning, cloze tests (also known as fill-in-the-blank tests) are frequently used for assessing the learning progress of students.", "labels": [], "entities": []}, {"text": "While preparation effort for these tests is low, scoring needs to be done manually, as there usually is a huge number of correct solutions.", "labels": [], "entities": [{"text": "preparation", "start_pos": 6, "end_pos": 17, "type": "METRIC", "confidence": 0.9683849811553955}]}, {"text": "In this paper, we examine whether the ambiguity of cloze items can be lowered to a point where automatic scoring becomes possible.", "labels": [], "entities": []}, {"text": "We utilize the local context of a word to collect evidence of low-ambiguity.", "labels": [], "entities": []}, {"text": "We do that by seeking for collocated word sequences, but also taking structural information on sentence level into account.", "labels": [], "entities": []}, {"text": "We evaluate the effectiveness of our method in a user study on cloze items ranked by our method.", "labels": [], "entities": []}, {"text": "For the top-ranked items (lowest ambiguity) the subjects provide the target word significantly more often than for the bottom-ranked items (59.9% vs. 36.5%).", "labels": [], "entities": []}, {"text": "While this shows the potential of our method, we did not succeed in fully eliminating ambiguity.", "labels": [], "entities": []}, {"text": "Thus, further research is necessary before fully automatic scoring becomes possible.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cloze items are frequently used to test language proficiency.", "labels": [], "entities": []}, {"text": "A cloze item consists of a sentence with usually one word being blanked.", "labels": [], "entities": []}, {"text": "The learner's task is to find the correct word for the blank: (1) He sold his ____ yesterday below price.", "labels": [], "entities": []}, {"text": "As we can see from example (1), blanks can be quite ambiguous, i.e. a very high number of correct solutions exists.", "labels": [], "entities": []}, {"text": "In this example, a wide range of nouns are acceptable solutions including books, house, or bike, but also daughter or kidney cannot be ruled out in this (quite limited) context.", "labels": [], "entities": []}, {"text": "Such ambiguity is not only a problem for language learners, but even native speakers frequently fail when facing such a task.", "labels": [], "entities": []}, {"text": "If cloze items should be automatically generated and scored, ambiguous items pose a serious problem, as we only know for sure one correct answer namely the one that was used in the original sentence.", "labels": [], "entities": []}, {"text": "Students might get frustrated if they provide a valid solution that is not recognized by the system.", "labels": [], "entities": []}, {"text": "The same problem affects an alternative solution to the problem: providing a list of alternative answer options -called distractors ().", "labels": [], "entities": []}, {"text": "Determining whether a distractor is actually another valid solution is equivalent to the problem described above.", "labels": [], "entities": []}, {"text": "Thus, finding good distractors is still an unsolved problem that attracts a lot of research ().", "labels": [], "entities": []}, {"text": "Furthermore, providing distractors for cloze items also considerably changes the nature of the task, as distractors are recognition stimuli, i.e. the student recognizes the correct answer rather than having to actively produce it.", "labels": [], "entities": []}, {"text": "Now consider example sentence (2): (2) I went to the ____ today and now I have sand in my shoes.", "labels": [], "entities": []}, {"text": "Most people would come up with beach or maybe desert, while other solutions are highly unlikely, which means that the blank is less ambiguous than example (1).", "labels": [], "entities": []}, {"text": "This leads to our research question, whether it is possible to find contexts that are specific enough to only allow one correct solution.", "labels": [], "entities": []}, {"text": "Such a setup would dramatically simplify automatic scoring.", "labels": [], "entities": [{"text": "automatic scoring", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.6347482800483704}]}, {"text": "We limit the scope of this work to determine low-ambiguity contexts for single-word nouns and leave other parts of speech for future work.", "labels": [], "entities": []}, {"text": "In the next section, we describe how such contexts can be detected.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our methods, we have to determine how often human subjects are able to complete the cloze items with the target word.", "labels": [], "entities": []}, {"text": "If subjects consistently only give the correct answer, our method would work perfectly.", "labels": [], "entities": []}, {"text": "However, as this might be too optimistic, we will measure how often the correct word (the originally deleted word) is provided and how many different alternatives human subjects provide.", "labels": [], "entities": []}, {"text": "In order to create the evaluation dataset, we randomly select sentences from the UkWaC corpus () which contains general-purpose text obtained from uk-domain websites.", "labels": [], "entities": [{"text": "UkWaC corpus", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.9776222705841064}]}, {"text": "The sentences are filtered by their reading-difficulty using the Flesch-Kincaid test: we remove all sentences requiring more than 10 years of school-education.", "labels": [], "entities": []}, {"text": "We then only keep sentences that contain a noun from a randomly chosen subset of common nouns.", "labels": [], "entities": []}, {"text": "We then apply our method to the remaining sentences obtaining weight scores from 0 to 52, where a higher number means more evidence (less ambiguity).", "labels": [], "entities": []}, {"text": "From this ranking, we select the 25 top-ranked sentences and the 25 bottom-ranked sentences.", "labels": [], "entities": []}, {"text": "The bottom-ranked sentences have a score-range of 11 to 16, thus, none of the strong detectors contributed to their score.", "labels": [], "entities": []}, {"text": "We compiled a cloze test from both collections (replacing the common noun with a blank) and asked volunteer participants to solve the items.", "labels": [], "entities": []}, {"text": "Overall, 30 native speakers of English completed the study, which was conducted online.", "labels": [], "entities": []}, {"text": "Before the actual study, participants were shown a detailed manual describing the study.", "labels": [], "entities": []}, {"text": "Participants were asked not to cheat and not to use any search engines or ask other people for second opinions.", "labels": [], "entities": []}, {"text": "If they could not come up with an answer, participants were instructed to move to the next sentence.", "labels": [], "entities": []}, {"text": "The fifty sentences were offered over 4 web pages; each page briefly repeated the manual.", "labels": [], "entities": []}, {"text": "shows the result of the study in terms of how often participants provided the target word.", "labels": [], "entities": []}, {"text": "For the top-ranked items, participants provided the target word on average in 59.9% of the cases, while the average was only 36.5% in the bottom-ranked group.", "labels": [], "entities": []}, {"text": "This clearly shows that our method is effective in reducing the ambiguity of cloze items.", "labels": [], "entities": []}, {"text": "However, we did not succeed in fully eliminating ambiguity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: List of detectors with their reliability and assigned weigth", "labels": [], "entities": [{"text": "reliability", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.9901676177978516}]}]}