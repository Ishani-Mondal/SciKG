{"title": [{"text": "Word Clustering Based on Un-LP Algorithm", "labels": [], "entities": []}], "abstractContent": [{"text": "Word clustering which generalizes specific features cluster words in the same syntactic or semantic categories into a group.", "labels": [], "entities": [{"text": "Word clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7009643763303757}]}, {"text": "It is an effective approach to reduce feature dimensionality and feature sparseness which are clearly useful for many NLP applications.", "labels": [], "entities": []}, {"text": "This paper proposes an unsu-pervised label propagation algorithm (Un-LP) for word clustering which uses multi-exemplars to represent a cluster.", "labels": [], "entities": [{"text": "unsu-pervised label propagation", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.6558429400126139}, {"text": "word clustering", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.752238929271698}]}, {"text": "Experiments on a synthetic 2D dataset show the strong ability of self-correcting of the proposed algorithm.", "labels": [], "entities": []}, {"text": "Besides, the experimental results on 20NG demonstrate that our algorithm outperforms the conventional cluster algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word clustering is the task of the division of words into a certain number of clusters (groups or categories).", "labels": [], "entities": [{"text": "Word clustering is the task of the division of words into a certain number of clusters (groups or categories)", "start_pos": 0, "end_pos": 109, "type": "Description", "confidence": 0.7384529837540218}]}, {"text": "Each cluster is required to consist of words that are similar to one another in syntactic or semantic construct and dissimilar to words in distinctive groups.", "labels": [], "entities": []}, {"text": "Word clustering generalizes specific features by considering the common characteristics and ignoring the specific characteristics among the individual features.", "labels": [], "entities": [{"text": "Word clustering generalizes specific features", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8425434768199921}]}, {"text": "It is an effective approach to reduce feature dimensionality and feature sparseness (.", "labels": [], "entities": []}, {"text": "Recently, word clustering offers great potential for various useful NLP applications.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.8417108356952667}]}, {"text": "Several studies have addressed dependency parsing (.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8827551603317261}]}, {"text": "propose a word clustering approach to improve the performance of sentence retrieval in Question Answering (QA) systems.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7468068599700928}, {"text": "sentence retrieval in Question Answering (QA)", "start_pos": 65, "end_pos": 110, "type": "TASK", "confidence": 0.7615606151521206}]}, {"text": "present an approach to integrate word clustering information into the process of unsupervised feature selection.", "labels": [], "entities": [{"text": "word clustering information", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8023186524709066}]}, {"text": "use large-scale word clustering fora semi-supervised relation extraction system.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7278102785348892}, {"text": "relation extraction", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7231581211090088}]}, {"text": "It also contributes to word sense disambiguation, named entity recognition (, part-of-speech tagging and machine translation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.7699350118637085}, {"text": "named entity recognition", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.615999440352122}, {"text": "part-of-speech tagging", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7266498059034348}, {"text": "machine translation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7783624231815338}]}, {"text": "This paper presents an unsupervised algorithm for word clustering based on a probabilistic transition matrix.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.7815232872962952}]}, {"text": "Given a text document dataset, a list of words is generated by removing stop words and very unfrequent words.", "labels": [], "entities": []}, {"text": "Each word is required to be represented by the documents in the dataset, which results in a co-occurrence matrix.", "labels": [], "entities": []}, {"text": "By calculating the similarity of words, a word similarity graph with transition (propagation) probabilities as weight edges is created.", "labels": [], "entities": []}, {"text": "Then, anew kind word clustering algorithm, based on label propagation, is applied.", "labels": [], "entities": [{"text": "kind word clustering", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.6525768438975016}, {"text": "label propagation", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7095421850681305}]}, {"text": "The remaining parts of this paper are organized as follows: Section 2 formulates word clustering problem in the context of unsupervised learning.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.7842427492141724}]}, {"text": "Then we describe the word clustering algorithm in Section 3 and present our experiments in Section 4.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7678893208503723}]}, {"text": "Finally we conclude our work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate properties of our proposed algorithm we investigate both a synthetic dataset and a realworld dataset.", "labels": [], "entities": []}, {"text": "For areal world example we test Un-LP on a subset of 20 Newsgroups (20NG) dataset which is preprocessed by removing common stop-words and stemming.", "labels": [], "entities": [{"text": "20 Newsgroups (20NG) dataset", "start_pos": 53, "end_pos": 81, "type": "DATASET", "confidence": 0.7370741665363312}]}, {"text": "We use the classes atheism, hardware, hockey and space for test and randomly select 300 samples from each class as the test dataset in this section.", "labels": [], "entities": []}, {"text": "However, 20NG is not suited for word clustering evaluation.", "labels": [], "entities": [{"text": "word clustering evaluation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.839969257513682}]}, {"text": "So, firstly, we reconstruct it by pair-wise testing which is a specification-based testing criterion.", "labels": [], "entities": []}, {"text": "Then we can obtain six (C 2 4 = 6) pairwise subsets represented by {D 1 , \u00b7 \u00b7 \u00b7 , D 6 }.", "labels": [], "entities": []}, {"text": "In order to facilitate the evaluation, we use those words that only occur in one class for clustering.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Distributions of the incorrect words partitioned by the literal meaning.", "labels": [], "entities": []}]}