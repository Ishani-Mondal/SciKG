{"title": [{"text": "KyotoEBMT System Description for the 1st Workshop on Asian Translation", "labels": [], "entities": [{"text": "KyotoEBMT System Description", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.8878841201464335}, {"text": "1st Workshop on Asian Translation", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.4918505370616913}]}], "abstractContent": [{"text": "This paper introduces the Ky-otoEBMT Example-Based Machine Translation framework.", "labels": [], "entities": [{"text": "Ky-otoEBMT Example-Based Machine Translation", "start_pos": 26, "end_pos": 70, "type": "TASK", "confidence": 0.5465001240372658}]}, {"text": "Our system uses a tree-to-tree approach, employing syntactic dependency analysis for both source and target languages in an attempt to preserve non-local structure.", "labels": [], "entities": []}, {"text": "The effectiveness of our system is maximized with online example matching and a flexible decoder.", "labels": [], "entities": [{"text": "online example matching", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.605321059624354}]}, {"text": "Evaluation demonstrates BLEU scores competitive with state-of-the-art SMT baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9984593391418457}, {"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9857776761054993}]}, {"text": "The system implementation is available as open-source.", "labels": [], "entities": []}], "introductionContent": [{"text": "Corpus-based approaches have become a major focus of Machine Translation research.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9041556119918823}]}, {"text": "We present here a fully-fledged ExampleBased Machine Translation (EBMT) platform making use of both source-language and target-language dependency structure.", "labels": [], "entities": [{"text": "ExampleBased Machine Translation (EBMT)", "start_pos": 32, "end_pos": 71, "type": "TASK", "confidence": 0.7686761319637299}]}, {"text": "This paradigm has been explored comparatively less, as studies on Syntactic-based SMT/EBMT tend to focus on constituent trees rather than dependency trees, and on tree-to-string rather than tree-to-tree approaches.", "labels": [], "entities": [{"text": "Syntactic-based SMT/EBMT", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.730089396238327}]}, {"text": "Furthermore, we employ separate dependency parsers for each language rather than projecting the dependencies from one language to another, as in).", "labels": [], "entities": []}, {"text": "The dependency structure information is used end-to-end: for improving the quality of the alignment of the translation examples, for constraining the translation rule extraction and for guiding the decoding.", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 150, "end_pos": 177, "type": "TASK", "confidence": 0.7454946835835775}]}, {"text": "We believe that dependency structure, which considers more than just local context, is important in order to generate fluent and accurate translations of complex sentences across distant language pairs.", "labels": [], "entities": [{"text": "dependency structure", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.7616722285747528}]}, {"text": "Our experiments focus on technical domain translation for Japanese-Chinese and Japanese-English, however our implementation is applicable to any domain and language pair for which there exist translation examples and dependency parsers.", "labels": [], "entities": [{"text": "technical domain translation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6786072055498759}]}, {"text": "A further unique characteristic of our system is that, again contrary to the majority of similar systems, it does not rely on precomputation of translation rules.", "labels": [], "entities": []}, {"text": "Instead it matches each input sentence to the full database of translation examples before extracting translation rules online.", "labels": [], "entities": []}, {"text": "This has the merit of maximizing the information available when creating and combining translation rules, while retaining the ability to produce excellent translations for input sentences similar to an existing translation example.", "labels": [], "entities": []}, {"text": "The system is mostly developed in C++ and incorporates a web-based translation interface for ease of use.", "labels": [], "entities": []}, {"text": "The web interface (see) also displays information useful for error analysis such as the list of translation examples used.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.6538797169923782}]}, {"text": "Experiments are facilitated through the inclusion of a curses-based graphical interface for performing tuning and evaluation.", "labels": [], "entities": []}, {"text": "The decoder supports multiple threads.", "labels": [], "entities": []}, {"text": "The system has been made available as open-source.", "labels": [], "entities": []}, {"text": "The code can be downloaded from http://nlp.ist.i.kyotou.ac.jp/kyotoebmt/.", "labels": [], "entities": []}, {"text": "shows the basic structure of the Kyoto EBMT translation pipeline.", "labels": [], "entities": [{"text": "Kyoto EBMT translation pipeline", "start_pos": 33, "end_pos": 64, "type": "DATASET", "confidence": 0.7811331748962402}]}], "datasetContent": [{"text": "The following dependency parsers were used.", "labels": [], "entities": []}, {"text": "The scores in parentheses are the approximate parsing accuracies (micro-average), which were evaluated by hand on a random subset of sentences from the test data.", "labels": [], "entities": []}, {"text": "The parsers were trained on domains different to those used in the experiments.", "labels": [], "entities": []}, {"text": "\u2022 English: NLParser 4 (92%) \u2022 Japanese: KNP (96%) ( \u2022 Chinese: SKP (88%) (Shen et al., 2012) K-best dependency parsing was done with k set to 20.", "labels": [], "entities": [{"text": "K-best dependency parsing", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.6819237371285757}]}], "tableCaptions": []}