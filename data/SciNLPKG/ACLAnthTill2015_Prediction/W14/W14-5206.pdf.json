{"title": [{"text": "A Conceptual Framework of Online Natural Language Processing Pipeline Application", "labels": [], "entities": [{"text": "Online Natural Language Processing Pipeline", "start_pos": 26, "end_pos": 69, "type": "TASK", "confidence": 0.6832045555114746}]}], "abstractContent": [{"text": "This paper describes a conceptual framework that enables online NLP pipelined applications to solve various interoperability issues and data exchange problems between tools and platforms; e.g., tokenizers and part-of-speech taggers from GATE, UIMA, or other platforms.", "labels": [], "entities": []}, {"text": "We propose a restful wrapping solution, which allows for universal resource identification for data management , a unified interface for data exchange, and a lightweight serialization for data visualization.", "labels": [], "entities": [{"text": "universal resource identification", "start_pos": 57, "end_pos": 90, "type": "TASK", "confidence": 0.7313071091969808}]}, {"text": "In addition, we propose a semantic mapping-based pipeline composition, which allows experts to interactively exchange data between heterogeneous components.", "labels": [], "entities": []}], "introductionContent": [{"text": "The recent work on open infrastructures for human language technology (HLT) research and development has stressed the important role that interoperability should play in developing Natural Language Processing (NLP) pipelines.", "labels": [], "entities": []}, {"text": "For example, GATE), UIMA, and NLTK () all allow integrating components from different categories based on common XML, or object-based (e.g., Java or Python) data presentation.", "labels": [], "entities": [{"text": "GATE", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.5965734720230103}]}, {"text": "The major categories of components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer, Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution, etc.", "labels": [], "entities": [{"text": "Sentence Splitter", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7400345206260681}]}, {"text": "Pipelined NLP applications can be built by composing several components; for example, a text analysis application such as \"relationship analysis from medical records\" can be composed by Sentence Splitter, Tokenizer, POS Tagger, NER, and Coreference Resolution components.", "labels": [], "entities": [{"text": "relationship analysis from medical records", "start_pos": 123, "end_pos": 165, "type": "TASK", "confidence": 0.8240554094314575}, {"text": "Sentence Splitter", "start_pos": 186, "end_pos": 203, "type": "TASK", "confidence": 0.699775829911232}, {"text": "Coreference Resolution", "start_pos": 237, "end_pos": 259, "type": "TASK", "confidence": 0.7837287485599518}]}, {"text": "In addition to interoperability, the very availability of a component can also play an important role in building online application based on distributed components, especially in tasks such as online testing and judging new NLP techniques by comparing to existing components.", "labels": [], "entities": []}, {"text": "For example, the Language Grid) addresses issues relating to accessing components from different locations or providers based on Service-Oriented Architecture (SOAs) models.", "labels": [], "entities": []}, {"text": "In this paper, we explore structural, conceptual interoperability, and availability issues, and provide a conceptual framework for building online pipelined NLP applications.", "labels": [], "entities": []}, {"text": "The conventional view of structural interoperability is that a common set of data formats and communication protocols should be specified by considering data management, data exchange, and data visualization issues.", "labels": [], "entities": []}, {"text": "Data management determines how to access, store and locate sources of data.", "labels": [], "entities": [{"text": "Data management", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7032848447561264}]}, {"text": "For example, GATE provides pluggable document readers or writers and XML (with meta-data configuration) serialization of reusable objected-based data.", "labels": [], "entities": [{"text": "GATE", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.6064446568489075}]}, {"text": "UIMA provides document or database readers and writers and XMI serialization of common object-based data structures.", "labels": [], "entities": [{"text": "UIMA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8762460350990295}, {"text": "XMI serialization", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7369990348815918}]}, {"text": "The Language Grid provides Java object serialization of data collections.", "labels": [], "entities": [{"text": "Java object serialization of data collections", "start_pos": 27, "end_pos": 72, "type": "TASK", "confidence": 0.7308406631151835}]}, {"text": "Data exchange strategies describe how components communicate their data.", "labels": [], "entities": []}, {"text": "For example, GATE provides CREOLE (Collection of REusable Objects for Language Engineering) data collections for data exchange.", "labels": [], "entities": [{"text": "GATE", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7843418121337891}]}, {"text": "UIMA provides CAS (Common Analysis Structure), and NLTK provides API modules for each component type.", "labels": [], "entities": [{"text": "UIMA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9705750942230225}, {"text": "NLTK", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.9015754461288452}]}, {"text": "Similarly, the Language Grid provides LSI (Language Service Interface) fora concrete ontology fora given language infrastructure.", "labels": [], "entities": []}, {"text": "Data visualization facilitates manual reading, editing and adjudication.", "labels": [], "entities": []}, {"text": "For example, GATE and UIMA provide XML-based viewers for selection, searching, matching and comparison functionality.", "labels": [], "entities": [{"text": "GATE", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7728085517883301}]}, {"text": "The conventional view of conceptual interoperability is that expert knowledge should be used in bridging heterogeneous components.", "labels": [], "entities": []}, {"text": "For example, GATE provides integration plugins for UIMA, OpenNLP, and Stanford NLP, where experts have already engineered the specific knowledge on conversion strategies among these components.", "labels": [], "entities": [{"text": "GATE", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7193364500999451}, {"text": "OpenNLP", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9318974614143372}, {"text": "Stanford NLP", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.8446323275566101}]}, {"text": "This leaves open the question of how one would ensure the interoperable pipelining of new or never-before-seen heterogeneous components, for which experts have not encoded bridge protocols.", "labels": [], "entities": []}, {"text": "In order to achieve an open infrastructure of online pipelined applications, we will argue two points regarding the conceptual design, considering both interoperability and availability: \u2022 Universal resource identification, a SQL-like data management, and a light-weight data serialization should be added with structural interoperability in online infrastructure of distributed components.", "labels": [], "entities": [{"text": "Universal resource identification", "start_pos": 189, "end_pos": 222, "type": "TASK", "confidence": 0.6614668567975363}, {"text": "SQL-like data management", "start_pos": 226, "end_pos": 250, "type": "TASK", "confidence": 0.6361216306686401}]}, {"text": "\u2022 By verifying and modifying inconsistent ontology mappings, experts can interactively learn conceptual interoperability for online heterogeneous components pipelines.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}