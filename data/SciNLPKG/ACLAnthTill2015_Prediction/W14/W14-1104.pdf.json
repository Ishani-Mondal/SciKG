{"title": [{"text": "Domain Adaptation with Active Learning for Coreference Resolution", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7367404699325562}, {"text": "Coreference Resolution", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.9230656623840332}]}], "abstractContent": [{"text": "In the literature, most prior work on coreference resolution centered on the newswire domain.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.9897973835468292}]}, {"text": "Although a coreference resolution system trained on the newswire domain performs well on newswire texts, there is a huge performance drop when it is applied to the biomedical domain.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8894652724266052}]}, {"text": "In this paper, we present an approach integrating domain adaptation with active learning to adapt coreference resolution from the newswire domain to the biomedical domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7168656140565872}, {"text": "coreference resolution", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.9196255803108215}]}, {"text": "We explore the effect of domain adaptation, active learning, and target domain instance weighting for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.9552414119243622}]}, {"text": "Experimental results show that domain adaptation with active learning and target domain instance weighting achieves performance on MEDLINE abstracts similar to a system trained on coref-erence annotation of only target domain training instances, but with a greatly reduced number of target domain training instances that we need to annotate.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8125349283218384}, {"text": "MEDLINE abstracts", "start_pos": 131, "end_pos": 148, "type": "DATASET", "confidence": 0.8259007334709167}]}], "introductionContent": [{"text": "Coreference resolution is the task of determining whether two or more noun phrases (NPs) in a text refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9214489161968231}]}, {"text": "Successful coreference resolution benefits many natural language processing (NLP) tasks, such as information extraction and question answering.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.9604332447052002}, {"text": "information extraction", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.8301014006137848}, {"text": "question answering", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.8887111246585846}]}, {"text": "In the literature, most prior work on coreference resolution recasts the problem as a two-class classification problem.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.9849563241004944}]}, {"text": "Machine learning-based classifiers are applied to determine whether a candidate anaphor and a potential antecedent are coreferential (.", "labels": [], "entities": []}, {"text": "In recent years, with the advances in biological and life science research, there is a rapidly increasing number of biomedical texts, including research papers, patent documents, etc.", "labels": [], "entities": []}, {"text": "This results in an increasing demand for applying natural language processing and information retrieval techniques to efficiently exploit information contained in these large amounts of texts.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.7098641842603683}]}, {"text": "However, coreference resolution, one of the core tasks in NLP, has only a relatively small body of prior research in the biomedical domain.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.9844631254673004}]}, {"text": "A large body of prior research on coreference resolution focuses on texts in the newswire domain.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.9887351095676422}]}, {"text": "Standardized data sets, such as MUC (DARPA Message Understanding Conference,) and ACE (NIST Automatic Content Extraction Entity Detection and Tracking task,) data sets are widely used in the study of coreference resolution.", "labels": [], "entities": [{"text": "MUC (DARPA Message Understanding Conference", "start_pos": 32, "end_pos": 75, "type": "DATASET", "confidence": 0.7576627731323242}, {"text": "NIST Automatic Content Extraction Entity Detection and Tracking task", "start_pos": 87, "end_pos": 155, "type": "TASK", "confidence": 0.7344031863742404}, {"text": "coreference resolution", "start_pos": 200, "end_pos": 222, "type": "TASK", "confidence": 0.9875992238521576}]}, {"text": "Traditionally, in order to apply supervised machine learning approaches to an NLP task in a specific domain, one needs to collect a text corpus in the domain and annotate it to serve as training data.", "labels": [], "entities": []}, {"text": "Compared to other NLP tasks, e.g., part-ofspeech (POS) tagging or named entity (NE) tagging, the annotation for coreference resolution is much more challenging and time-consuming.", "labels": [], "entities": [{"text": "part-ofspeech (POS) tagging or named entity (NE) tagging", "start_pos": 35, "end_pos": 91, "type": "TASK", "confidence": 0.6455983196695646}, {"text": "coreference resolution", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.9619893133640289}]}, {"text": "The reason is that in tasks like POS tagging, an annotator only needs to focus on each markable (a word, in the case of POS tagging) and a small window of its neighboring words.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.7554466426372528}, {"text": "POS tagging)", "start_pos": 120, "end_pos": 132, "type": "TASK", "confidence": 0.6921633978684744}]}, {"text": "In contrast, to annotate a coreferential relation, an annotator needs to first recognize whether a certain text span is a markable, and then scan through the text preceding the markable (a potential anaphor) to look for the antecedent.", "labels": [], "entities": []}, {"text": "It also requires the annotator to understand the text in order to annotate coreferential relations, which are semantic in nature.", "labels": [], "entities": []}, {"text": "If a markable is non-anaphoric, the annotator has to scan to the beginning of the text to realize that.", "labels": [], "entities": []}, {"text": "reported that it took an average of 20 hours to annotate coreferential relations in a single document with an average length of 6,155 words, while an annotator could annotate 3,000 words per hour in POS tag annotation).", "labels": [], "entities": []}, {"text": "The simplest approach to avoid the timeconsuming data annotation in anew domain is to train a coreference resolution system on a resource-rich domain and apply it to a different target domain without any additional data annotation.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.9017518758773804}]}, {"text": "Although coreference resolution systems work well on test texts in the same domain as the training texts, there is a huge performance drop when they are tested on a different domain.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.939155787229538}]}, {"text": "This motivates the usage of domain adaptation techniques for coreference resolution: adapting a coreference resolution system from one source domain in which we have a large collection of annotated data, to a second target domain in which we need good performance.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9478109776973724}, {"text": "coreference resolution", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.8465735018253326}]}, {"text": "It is almost inevitable that we annotate some data in the target domain to achieve good coreference resolution performance.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.9208621084690094}]}, {"text": "The question is how to minimize the amount of annotation needed.", "labels": [], "entities": []}, {"text": "In the literature, active learning has been exploited to reduce the amount of annotation needed (.", "labels": [], "entities": []}, {"text": "In contrast to annotating the entire data set, active learning selects only a subset of the data to annotate in an iterative process.", "labels": [], "entities": []}, {"text": "How to apply active learning and integrate it with domain adaptation remains an open problem for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.9687736928462982}]}, {"text": "In this paper, we explore domain adaptation for coreference resolution from the resource-rich newswire domain to the biomedical domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7212314456701279}, {"text": "coreference resolution", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.9758978486061096}]}, {"text": "Our approach comprises domain adaptation, active learning, and target domain instance weighting to leverage the existing annotated corpora from the newswire domain, so as to reduce the cost of developing a coreference resolution system in the biomedical domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7381687462329865}, {"text": "coreference resolution", "start_pos": 206, "end_pos": 228, "type": "TASK", "confidence": 0.8961195647716522}]}, {"text": "Our approach achieves comparable coreference resolution performance on MEDLINE abstracts, but with a large reduction in the number of training instances that we need to annotate.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.880212813615799}]}, {"text": "To the best of our knowledge, our work is the first to combine domain adaptation and active learning for coreference resolution.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7130110412836075}, {"text": "coreference resolution", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.9517423808574677}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first review the related work in Section 2.", "labels": [], "entities": []}, {"text": "Then we describe the coreference resolution system in Section 3, and the domain adaptation and active learning techniques in Section 4.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.9303876459598541}]}, {"text": "Experimental results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Finally, we analyze the results in Section 6 and conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of the NPAPER and GENIA  data sets", "labels": [], "entities": [{"text": "NPAPER", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.9248420596122742}, {"text": "GENIA  data sets", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.9341484506924947}]}, {"text": " Table 2: MUC F-measures on the GENIA test set", "labels": [], "entities": [{"text": "MUC", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.42497581243515015}, {"text": "F-measures", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.7622835636138916}, {"text": "GENIA test set", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9745311538378397}]}, {"text": " Table 3: MUC F-measures of different active learning settings on the GENIA test set. All systems use", "labels": [], "entities": [{"text": "MUC F-measures", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.5506361126899719}, {"text": "GENIA test set", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.983911375204722}]}]}