{"title": [{"text": "Chinese Spelling Error Detection and Correction Based on Language Model, Pronunciation, and Shape", "labels": [], "entities": [{"text": "Chinese Spelling Error Detection", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6142406836152077}]}], "abstractContent": [{"text": "Spelling check is an important preprocessing task when dealing with user generated texts such as tweets and product comments.", "labels": [], "entities": [{"text": "Spelling check", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7583549916744232}]}, {"text": "Compared with some western languages such as English, Chinese spelling check is more complex because there is no word delimiter in Chinese written texts and misspelled characters can only be determined in word level.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7218361099561056}]}, {"text": "Our system works as follows.", "labels": [], "entities": []}, {"text": "First, we use character-level n-gram language models to detect potential misspelled characters with low probabilities below some predefined threshold.", "labels": [], "entities": []}, {"text": "Second, for each potential incorrect character, we generate a candidate set based on pronunciation and shape similarities.", "labels": [], "entities": [{"text": "pronunciation", "start_pos": 85, "end_pos": 98, "type": "METRIC", "confidence": 0.9594499468803406}]}, {"text": "Third, we filter some candidate corrections if the candidate cannot form a legal word with its neighbors according to a word dictionary.", "labels": [], "entities": []}, {"text": "Finally, we find the best candidate with highest language model probability.", "labels": [], "entities": []}, {"text": "If the probability is higher than a predefined threshold, then we replace the original character; or we consider the original character as correct and take no action.", "labels": [], "entities": []}, {"text": "Our preliminary experiments shows that our simple method can achieve relatively high precision but low recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9987315535545349}, {"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.9991206526756287}]}], "introductionContent": [{"text": "Spelling check is a traditional and important preprocessing task for natural language processing, since spelling errors happen in written texts, such as short messages, emails, and soon.", "labels": [], "entities": [{"text": "Spelling check", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9012742936611176}, {"text": "natural language processing", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.6766882141431173}]}, {"text": "Lots of research has been devoted to English spelling error detection and correction.", "labels": [], "entities": [{"text": "English spelling error detection", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.716804064810276}]}, {"text": "In English spelling error detection and correction, the errors can be classified into \"nonword\" error and \"real-word\" error.", "labels": [], "entities": [{"text": "English spelling error detection and correction", "start_pos": 3, "end_pos": 50, "type": "TASK", "confidence": 0.6453243990739187}]}, {"text": "Unlike English, Chinese words are not separated by space and all characters in Chinese are \"real-word\".", "labels": [], "entities": []}, {"text": "Therefore, automatic word segmentation need to be applied in order to produce words ().", "labels": [], "entities": [{"text": "automatic word segmentation", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6429523428281149}]}, {"text": "There are many Chinese input methods ().", "labels": [], "entities": []}, {"text": "Different input methods lead to different types of spelling errors.", "labels": [], "entities": []}, {"text": "For example, input methods based on pinyin which usually lead to spelling errors of characters sharing similar pronunciations; while input methods based on radical methods usually lead to errors related to character shapes.", "labels": [], "entities": []}, {"text": "proposed a learning model based on Chinese phonemic alphabet to detect Chinese spelling errors.", "labels": [], "entities": []}, {"text": "presented a method based on Ngram ranked inverted index list to deal with this problem.", "labels": [], "entities": [{"text": "Ngram ranked inverted index list", "start_pos": 28, "end_pos": 60, "type": "DATASET", "confidence": 0.8694350481033325}]}], "datasetContent": [{"text": "In this paper, we use 300 sentences from the final test of SIGHAN Bake-off 2013 as our training data and 1000 sentences provided by the SIGHAN organizer are our test data.", "labels": [], "entities": [{"text": "SIGHAN Bake-off 2013", "start_pos": 59, "end_pos": 79, "type": "DATASET", "confidence": 0.8204962412516276}, {"text": "SIGHAN organizer", "start_pos": 136, "end_pos": 152, "type": "DATASET", "confidence": 0.840103954076767}]}, {"text": "In: Results of our error detection and correction subtask characters are marked as error characters by our system.", "labels": [], "entities": [{"text": "error detection and correction subtask characters", "start_pos": 19, "end_pos": 68, "type": "TASK", "confidence": 0.7463539987802505}]}, {"text": "The average length of sentences in our training data is about 70 characters.", "labels": [], "entities": []}, {"text": "When the threshold has been set to be -1, more than half of the characters in a sentence have been marked as errors on average.", "labels": [], "entities": []}, {"text": "Though the recall is very high in this case, too many correct characters have been recognized as errors.", "labels": [], "entities": [{"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9984602928161621}]}, {"text": "So we prefer to give up the high recall rather than reserve too many irrelevant characters.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9981096982955933}]}, {"text": "As we mentioned in Section 2.2, the average number of spelling errors in a sentence is quite low.", "labels": [], "entities": [{"text": "number of spelling errors", "start_pos": 44, "end_pos": 69, "type": "METRIC", "confidence": 0.6239642724394798}]}, {"text": "Threshold = -2 only leads to a slight reduce in recall but the average number of characters have been cut down by half.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9963016510009766}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9994978904724121}]}, {"text": "As shown in, we firstly prepare two resources: a forward-backward 5-gram language model and a word dictionary.", "labels": [], "entities": []}, {"text": "As described in previous sections, such two resources will be applied into both spelling check detection and correction.", "labels": [], "entities": [{"text": "spelling check detection", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.8754794200261434}]}, {"text": "Then, we start to detect the error characters in a sentence.", "labels": [], "entities": []}, {"text": "For each character in a sentence, if its score which calculated by the forward-backward 5-gram language model is less than the threshold value, it will be sent to next phase.", "labels": [], "entities": []}, {"text": "And the threshold is set at -2 as we discussed before.", "labels": [], "entities": []}, {"text": "Next, we will test the character for constructing a word.", "labels": [], "entities": []}, {"text": "We set the size of the window at 4 which means the target character can be combined with its neighbors at a distance of 4 characters.", "labels": [], "entities": []}, {"text": "For example, describes the details.", "labels": [], "entities": []}, {"text": "After the target character is combined with its neighbors, we will lookup the word dictionary.", "labels": [], "entities": []}, {"text": "While none of combinations can be found in the word dictionary, we make the assumption that the target character maybe an error.", "labels": [], "entities": []}, {"text": "In this example, none of these 7 words can be found in word dictionary.", "labels": [], "entities": []}, {"text": "So, the character \" \u7adf \" in this sentence would be marked as an error and sent to next phase.", "labels": [], "entities": []}, {"text": "In spelling check correction phase, we first generate candidates by similar pronunciation or shape.", "labels": [], "entities": [{"text": "spelling check correction", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.8477105299631754}]}, {"text": "Then the candidates are filtered by constructing a word.", "labels": [], "entities": []}, {"text": "This time, we reserve the candidates which can construct a word with its neighbors.", "labels": [], "entities": []}, {"text": "At last, the rest candidates will be ranked by language model.", "labels": [], "entities": []}, {"text": "The best candidate with its score higher than threshold will replace the original character in the sentence.", "labels": [], "entities": []}, {"text": "Here, the threshold is the same with the value in detection level.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on error detection", "labels": [], "entities": [{"text": "error detection", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7600043416023254}]}, {"text": " Table 2: Results of our error detection and correction subtask", "labels": [], "entities": [{"text": "error detection and correction subtask", "start_pos": 25, "end_pos": 63, "type": "TASK", "confidence": 0.7566962301731109}]}]}