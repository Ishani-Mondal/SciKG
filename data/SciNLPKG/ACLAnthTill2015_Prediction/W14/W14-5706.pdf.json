{"title": [{"text": "A Comparative Study of Different Classification Methods for the Identification of Brazilian Portuguese Multiword Expressions", "labels": [], "entities": [{"text": "Identification of Brazilian Portuguese Multiword Expressions", "start_pos": 64, "end_pos": 124, "type": "TASK", "confidence": 0.8984145323435465}]}], "abstractContent": [{"text": "This paper presents a comparative study of different methods for the identification of multiword expressions, applied to a Brazilian Portuguese corpus.", "labels": [], "entities": []}, {"text": "First, we selected the candidates based on the frequency of bigrams.", "labels": [], "entities": []}, {"text": "Second, we used the linguistic information based on the grammatical classes of the words forming the bigrams, together with the frequency information in order to compare the performance of different classification algorithms.", "labels": [], "entities": []}, {"text": "The focus of this study is related to different classification techniques such as support-vector machines (SVM), multi-layer perceptron, na\u00efve Bayesian nets, decision trees and random forest.", "labels": [], "entities": []}, {"text": "Third, we evaluated three different multi-layer perceptron training functions in the task of classifying different patterns of multiword expressions.", "labels": [], "entities": []}, {"text": "Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "The identification of multiword expressions (MWEs) and their appropriate handling is necessary in constructing professional tools for language manipulation.", "labels": [], "entities": [{"text": "identification of multiword expressions (MWEs)", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.7879456537110465}, {"text": "language manipulation", "start_pos": 134, "end_pos": 155, "type": "TASK", "confidence": 0.710718959569931}]}, {"text": "MWEs are considered as a very challenging problem for various natural language processing (NLP) applications, such as machine translation.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.9081013202667236}, {"text": "machine translation", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.8155944645404816}]}, {"text": "There are several definitions of MWE in the scientific literature.", "labels": [], "entities": []}, {"text": "defines MWE as an arbitrary and recurrent word combination; while Choueka (1988) defines them as a syntactic and semantic unit whose exact meaning or connotation cannot be derived directly and unambiguously from the meaning or connotation of its components.", "labels": [], "entities": []}, {"text": "Moreover, defines MWE as an idiosyncratic interpretation that exceeds the limit of the word (or spaces).", "labels": [], "entities": []}, {"text": "We adopt in this paper a definition similar to the one given by: a MWE is an expression formed by two or more words, whose meaning can vary from totally dependent to completely independent of the meaning of its constituent words.", "labels": [], "entities": []}, {"text": "Examples of MWEs: \"take care\", \"Bill Gates\", \"coffee break\" and \"by the way\".", "labels": [], "entities": [{"text": "MWEs", "start_pos": 12, "end_pos": 16, "type": "TASK", "confidence": 0.8675111532211304}]}, {"text": "This study treats only two-word MWEs.", "labels": [], "entities": []}, {"text": "We are not considering some common Portuguese MWEs, such as \"tempo de espera\" (waiting time, lit.: time of waiting), \"dar um tempo\" (to have a break, lit.: to give a time) or \"come\u00e7ar tudo de novo\" (restart, lit. start everything of new).", "labels": [], "entities": []}, {"text": "However, our experience and some related work show that we are already covering the majority of MWEs.", "labels": [], "entities": []}, {"text": "For their data, for example, found that 81.88% of the recognized MWEs were bigrams.", "labels": [], "entities": []}, {"text": "Moreover, our focus is in MWE formed by nouns, adjectives, verbs and adverbs.", "labels": [], "entities": [{"text": "MWE formed", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.8851611912250519}]}, {"text": "As a consequence, two-word MWEs formed by prepositions were not considered, such as \"de novo\" (again, lit. of new), \"\u00e0 toa\" (for nothing), \"apesar de\" (despite of) or \"desde ontem\" (since yesterday).", "labels": [], "entities": []}, {"text": "In resume, we evaluated the performance of different classification algorithms and tools for the recognition of twoword MWEs formed by nouns, adjectives, verbs and adverbs.", "labels": [], "entities": [{"text": "recognition of twoword MWEs formed by nouns, adjectives, verbs and adverbs", "start_pos": 97, "end_pos": 171, "type": "TASK", "confidence": 0.8207216904713557}]}, {"text": "We intend, in the future, to extend this study to MWEs formed by words belonging to any grammatical class and having any number of words.", "labels": [], "entities": [{"text": "MWEs formed by words belonging to any grammatical class", "start_pos": 50, "end_pos": 105, "type": "TASK", "confidence": 0.767259935537974}]}, {"text": "The correct identification of MWEs is important for different NLP applications, such as machine translation, information retrieval and the semantic web, to which the principle of syntactic or semantic unit is important (.", "labels": [], "entities": [{"text": "identification of MWEs", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.717109203338623}, {"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.8020790219306946}, {"text": "information retrieval", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7758635580539703}]}, {"text": "Methods for identifying MWEs rely on statistical measures, especially association measures, such as mutual information), log-likelihood or Dice's coefficient.", "labels": [], "entities": [{"text": "identifying MWEs", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7872903347015381}]}, {"text": "The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit.", "labels": [], "entities": []}, {"text": "There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each word, the sense of the composite expression or the syntactic regularities.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied nine different classification algorithms to our data set.", "labels": [], "entities": []}, {"text": "The parameters used with each algorithm are listed below.", "labels": [], "entities": []}, {"text": "Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25.", "labels": [], "entities": [{"text": "confidence factor", "start_pos": 51, "end_pos": 68, "type": "METRIC", "confidence": 0.9780702292919159}]}, {"text": "Random Forest): number of trees = 10; max depth = 0; seed = 1.", "labels": [], "entities": [{"text": "Random Forest)", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.8939777612686157}, {"text": "max depth", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9590332806110382}]}, {"text": "Ada Boost (: classifier = decision stamp; weight threshold = 100; iterations = 10; seed = 1.", "labels": [], "entities": [{"text": "Boost", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.861062228679657}]}, {"text": "Bagging Multilayer perceptron: learning rate = 0.3; momentum = 0.2; training time = 500; validation threshold = 500; seed = 0; Bayesian net: search algorithm = k2; estimator = simple estimator (alpha = 0.5).", "labels": [], "entities": []}, {"text": "As we can see in, the values of precision are very similar for all the algorithms, varying between 0.830 (random forest) and 0.857 (bagging), with the exception of SVM, which gave a precision of 0.738.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9992364645004272}, {"text": "precision", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.9880272150039673}]}, {"text": "The recall values were between 0.831 and 0.857 (0.655 for SVM).", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9997479319572449}]}, {"text": "We obtained good precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9995094537734985}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9996629953384399}]}, {"text": "However, we must consider that the values of recall are based only on the MWEs present in our reference list, and not in the entire corpus, since we could not count all the MWEs present in the corpus.: True-positive rate, false-positive rate, precision and recall for nine classification algorithms.", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9989084005355835}, {"text": "precision", "start_pos": 243, "end_pos": 252, "type": "METRIC", "confidence": 0.9996832609176636}, {"text": "recall", "start_pos": 257, "end_pos": 263, "type": "METRIC", "confidence": 0.999265730381012}]}, {"text": "Using the same excerpts of our corpus, we proceeded to the evaluation of two different tools for extracting MWEs from text: MWEtoolkit 1 (Ramisch, 2012) and Text-NSP 2 (Banerjee and Pedersen, 2003).", "labels": [], "entities": [{"text": "extracting MWEs from text", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.79374860227108}]}], "tableCaptions": [{"text": " Table 1: True-positive rate, false-positive rate, precision and recall for nine classification algorithms.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9997653365135193}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9996408224105835}]}, {"text": " Table 3: MWEtoolkit: number of MWEs among the first n-best candidates, ranked by five association  measures.", "labels": [], "entities": []}, {"text": " Table 4: MWEtoolkit: precision, recall and F-measure for the log-likelihood measure.", "labels": [], "entities": [{"text": "MWEtoolkit", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.7382602095603943}, {"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9996826648712158}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9994376301765442}, {"text": "F-measure", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9990129470825195}]}, {"text": " Table 5: Text-NSP: number of MWEs among the first n-best candidates, ranked by four association  measures.", "labels": [], "entities": []}, {"text": " Table 6: Text-NSP: precision, recall and F-measure for the log-likelihood measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9996752738952637}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9993823766708374}, {"text": "F-measure", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9988701939582825}]}, {"text": " Table 7: MWEtoolkit and Text-NSP precision for the first n best candidates, using Student's t-test  association measure.", "labels": [], "entities": [{"text": "MWEtoolkit", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.6660777926445007}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.8277530074119568}, {"text": "Student's t-test  association measure", "start_pos": 83, "end_pos": 120, "type": "METRIC", "confidence": 0.713613224029541}]}]}