{"title": [{"text": "Estimating Grammar Correctness fora Priori Estimation of Machine Translation Post-Editing Effort", "labels": [], "entities": [{"text": "Machine Translation Post-Editing Effort", "start_pos": 57, "end_pos": 96, "type": "TASK", "confidence": 0.7304946333169937}]}], "abstractContent": [{"text": "We present a supervised learning pilot application for estimating Machine Translation (MT) output reusability, in view of supporting a human post-editor of MT content.", "labels": [], "entities": [{"text": "estimating Machine Translation (MT) output reusability", "start_pos": 55, "end_pos": 109, "type": "TASK", "confidence": 0.8737701177597046}, {"text": "MT content", "start_pos": 156, "end_pos": 166, "type": "TASK", "confidence": 0.8362284302711487}]}, {"text": "We train our model on typed dependencies (labeled grammar relationships) extracted from human reference and raw MT data, to then predict grammar relationship correctness values that we aggregate to provide a binary segment-level evaluation.", "labels": [], "entities": []}, {"text": "In view of scaling up to larger data, we provide implemented Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and Stochastic Gradient Descent with Support Vector Machine loss function approaches and their evaluation, and verify the correlation of predicted values with human judgement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Currently the Machine Translation (MT) research community attempts to seamlessly integrate both humans and MT-instances in the workflow of textual translation.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.8400817394256592}, {"text": "textual translation", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.7088533788919449}]}, {"text": "Efforts towards this integration focus, for instance, on automating a posteriori processes such as post-editing (, or other format coherence maintenance (e.g. date, spelling).", "labels": [], "entities": []}, {"text": "Our contribution addresses cases when a post-editor has to start a segment from scratch, because the MT raw output turns out to be a hindrance rather than an aid, and the corresponding evaluation time between editing and manually retranslating a sequence is wasted a posteriori.", "labels": [], "entities": []}, {"text": "This paper proposes a supervised learning approach to discriminate typed grammar relation instances that compose a human-written sentence from any other form, in order to identify segments that can potentially lead to time loss on the basis of its incorrect grammar or word adjacency and delete them before postediting.", "labels": [], "entities": []}, {"text": "The remainder presents the project's assumptions and the nature of the adopted learning features (Section 2), the high-level algorithmic approach and the theory behind the adopted prediction models (Section 3).", "labels": [], "entities": []}, {"text": "We then provide our implementation outline and the evaluation approaches (Section 4).", "labels": [], "entities": []}, {"text": "In conclusion we present current limitations (Section 5), related and future work (Section 6), and the conclusions (Section 7).", "labels": [], "entities": []}], "datasetContent": [{"text": "As a proof-of-concept and means of evaluation, we constructed a Java prototype that implements the pipeline in, by making use of the Moses process () for machine translation, the Stanford Parser (De Marneffe and Manning, 2008) for typed dependency extraction, the API of the general-purpose machine learning analysis platform Weka () for training and prediction, and ad-hoc implementations of the remaining specified modules.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.7796386778354645}, {"text": "typed dependency extraction", "start_pos": 231, "end_pos": 258, "type": "TASK", "confidence": 0.7192750970522562}]}, {"text": "Typed dependency extraction is possible by feeding a pre-trained language-specific Probabilistic Context-Free Grammar (PCFG) into the parser, which is a model that defines probabilistic grammar production rules for such language.", "labels": [], "entities": [{"text": "Typed dependency extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7631117304166158}]}, {"text": "Such a model is trained beforehand on a large, syntactically annotated text corpus (i.e. a treebank)).", "labels": [], "entities": []}, {"text": "We used our prototype on a subset of the Europarl test data (, extracting 536404 instances from 11270 human reference lines, and from 11270 machine-translated lines that share the same source.", "labels": [], "entities": [{"text": "Europarl test data", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.9921165307362875}]}, {"text": "Our Naive Bayes algorithm (using word frequencies, no pruning) required 1.08 seconds to formulate a hypothesis model, versus the 28613.64 seconds required for the construction of a Stochastic Gradient Descent model (hinge loss function for SVM, step length 0.01, 500 steps, no pruning).", "labels": [], "entities": []}, {"text": "A 10-fold cross validation on the training set provided a correct instance classification of 67.0168% for NB model, versus the 66.0118% of the SGD model.", "labels": [], "entities": [{"text": "correct instance classification", "start_pos": 58, "end_pos": 89, "type": "METRIC", "confidence": 0.8045178651809692}]}], "tableCaptions": [{"text": " Table 1: Precision and recall values of the 10-fold  cross validation for both NB and SGD methods", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9966861605644226}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9989387392997742}]}, {"text": " Table 2: Evaluation data obtained with the clus- ter model generated from the human judgement  dataset, with the number of clusters defined as 4.", "labels": [], "entities": []}]}