{"title": [{"text": "Active Learning with Constrained Topic Model", "labels": [], "entities": []}], "abstractContent": [{"text": "Latent Dirichlet Allocation (LDA) is a topic modeling tool that automatically discovers topics from a large collection of documents.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.686275119582812}, {"text": "topic modeling", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.6991759985685349}]}, {"text": "It is one of the most popular text analysis tools currently in use.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.8697381317615509}]}, {"text": "In practice however, the topics discovered by LDA do not always make sense to end users.", "labels": [], "entities": []}, {"text": "In this extended abstract, we propose an active learning framework that interactively and iteratively acquires user feedback to improve the quality of learned topics.", "labels": [], "entities": []}, {"text": "We conduct experiments to demonstrate its effectiveness with simulated user input on a benchmark dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical topic models such as Latent Dirichlet Allocation (LDA) () provide powerful tools for uncovering hidden thematic patterns in text and are useful for representing and summarizing the contents of large document collections.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.6244905392328898}, {"text": "summarizing the contents of large document collections", "start_pos": 177, "end_pos": 231, "type": "TASK", "confidence": 0.8275970731462751}]}, {"text": "However, when using topic models in practice, users often face one critical problem: topics discovered by the model do not always make sense.", "labels": [], "entities": []}, {"text": "A topic may contain thematically unrelated words.", "labels": [], "entities": []}, {"text": "Moreover, two thematic related words may appear in different topics.", "labels": [], "entities": []}, {"text": "This is mainly because the objective function optimized by LDA may not reflect human judgments of topic quality).", "labels": [], "entities": []}, {"text": "Potentially, we can solve these problems by incorporating additional user guidance or domain knowledge in topic modeling.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.7510120868682861}]}, {"text": "With standard LDA however, it is impossible for users to interact with the model and provide feedback.", "labels": [], "entities": []}, {"text": "() proposed an interactive topic modeling framework that allows users to add word must-links.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7547797560691833}]}, {"text": "However, it has several limitations.", "labels": [], "entities": []}, {"text": "Since the vocabulary size of a large document collection can be very large, users may need to annotate a large number of word constraints for this method to be effective.", "labels": [], "entities": []}, {"text": "Thus, this process can be very tedious.", "labels": [], "entities": []}, {"text": "More importantly, it cannot handle polysemes.", "labels": [], "entities": []}, {"text": "For example, the word \"pound\" can refer to either a currency or a unit of mass.", "labels": [], "entities": []}, {"text": "If a user adds a must-link between \"pound\" and another financial term, then he/she cannot add a must-link between \"pound\" and any measurement terms.", "labels": [], "entities": []}, {"text": "Since word must-links are added without context, there is noway to disambiguate them.", "labels": [], "entities": []}, {"text": "As a result, word constraints frequently are not as effective as document constraints.", "labels": [], "entities": []}, {"text": "Active learning) provides a useful framework which allows users to iteratively give feedback to the model to improve its quality.", "labels": [], "entities": []}, {"text": "In general, with the same amount of human labeling, active learning often results in a better model than that learned by an off-line method.", "labels": [], "entities": []}, {"text": "In this extended abstract, we propose an active learning framework for LDA.", "labels": [], "entities": []}, {"text": "It is based on anew constrained topic modeling framework which is capable of handling pairwise document constraints.", "labels": [], "entities": []}, {"text": "We present several design choices and the pros and cons of each choice.", "labels": [], "entities": []}, {"text": "We also conduct simulated experiments to demonstrate the effectiveness of the approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our active learning framework.", "labels": [], "entities": []}, {"text": "Topic models are often evaluated using perplexity on held-out test data.", "labels": [], "entities": []}, {"text": "However, recent work has shown that human judgment sometimes is contrary to the perplexity measure.", "labels": [], "entities": []}, {"text": "Following), we employ Topic Coherence, a metric which was shown to be highly consistent with human judgment, to measure a topic model's quality.", "labels": [], "entities": []}, {"text": "It relies upon word co-occurrence statistics within documents, and does not depend on external resources or human labeling.", "labels": [], "entities": []}, {"text": "We followed () to create a Mix3 sub-dataset from the 20 Newsgroups data 2 , which consists of two newsgroups with similar topics (rec.sport.hockey, rec.sport.baseball) and one with a distinctive topic (sci.space).", "labels": [], "entities": [{"text": "20 Newsgroups data 2", "start_pos": 53, "end_pos": 73, "type": "DATASET", "confidence": 0.7924561724066734}]}, {"text": "We use this dataset to evaluate the effectiveness of the proposed framework.", "labels": [], "entities": []}, {"text": "We first burn-in LDA for 500 iterations.", "labels": [], "entities": []}, {"text": "Then for each additional iteration, the active learner generates one query which consists of one target document and one or more anchor documents.", "labels": [], "entities": []}, {"text": "We simulate user feedback using the documents' ground truth labels.", "labels": [], "entities": []}, {"text": "If a target document has the same label as one of the anchor documents, we add a must-link between them.", "labels": [], "entities": []}, {"text": "We also add cannot-links between the target document and the rest of the anchor documents.", "labels": [], "entities": []}, {"text": "All these constraints are added into a constraint pool.", "labels": [], "entities": []}, {"text": "We also augment the constraint pool with derived constraints.", "labels": [], "entities": []}, {"text": "a must link between (a, c).", "labels": [], "entities": []}, {"text": "We simulate the process for 100 iterations to acquire constraints.", "labels": [], "entities": []}, {"text": "After that, we keep cLDA running for 400 more iterations with the acquired constraints until it converges.", "labels": [], "entities": []}, {"text": "shows the topic coherence scores for different target document selection strategies.", "labels": [], "entities": []}, {"text": "This result indicates 1).", "labels": [], "entities": []}, {"text": "MaxEntropy has the best topic coherence score.", "labels": [], "entities": [{"text": "MaxEntropy", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9397483468055725}]}, {"text": "All active learning strategies outperform standard LDA, and the results are statistically significant at p = 0.05.", "labels": [], "entities": []}, {"text": "With standard LDA, 500 more iterations without any constraints does not improve the topic coherence.", "labels": [], "entities": []}, {"text": "However, by active learning with cLDA for 500 iterations, the topic coherences are significantly improved.", "labels": [], "entities": []}, {"text": "Using MaxEntropy target document selection method, we demonstrate the improvement of the most probable topic keywords before and after active learning.", "labels": [], "entities": [{"text": "MaxEntropy target document selection", "start_pos": 6, "end_pos": 42, "type": "TASK", "confidence": 0.6501061916351318}]}, {"text": "shows that before active learning, topic 1's most probable words are incoherent and thus it is difficult to determine the meaning of the topic . After active learning, in contrast, topic 1's most probable words become more consistent with a \"baseball\" topic.", "labels": [], "entities": []}, {"text": "This example suggests that the active learning framework that interactively and iteratively acquires pairwise document constraints is effective in improving the topic model's quality.", "labels": [], "entities": []}], "tableCaptions": []}