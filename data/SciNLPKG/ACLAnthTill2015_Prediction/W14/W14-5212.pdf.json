{"title": [{"text": "EUMSSI: a Platform for Multimodal Analysis and Recommendation using UIMA", "labels": [], "entities": [{"text": "EUMSSI", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9493768215179443}, {"text": "Multimodal Analysis and Recommendation", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.8376301527023315}, {"text": "UIMA", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.7372020483016968}]}], "abstractContent": [{"text": "The EUMSSI project (Event Understanding through Multimodal Social Stream Interpretation) aims at developing technologies for aggregating data presented as unstructured information in sources of very different nature.", "labels": [], "entities": [{"text": "Event Understanding through Multimodal Social Stream Interpretation)", "start_pos": 20, "end_pos": 88, "type": "TASK", "confidence": 0.6508909910917282}]}, {"text": "The multimodal analytics will help organize, classify and cluster cross-media streams, by enriching its associated metadata in an interactive manner, so that the data resulting from analysing one media helps reinforce the aggregation of information from other media, in a cross-modal semantic representation framework.", "labels": [], "entities": []}, {"text": "Once all the available descriptive information has been collected, an interpretation component will dynamically reason over the semantic representation in order to derive implicit knowledge.", "labels": [], "entities": []}, {"text": "Finally the enriched information will be fed to a hybrid recommendation system, which will beat the basis of two well-motivated use-cases.", "labels": [], "entities": []}, {"text": "In this paper we give a brief overview of EUMSSI's main goals and how we are approaching its implementation using UIMA to integrate and combine various layers of annotations coming from different sources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Nowadays, a multimedia journalist has access to avast amount of data from a plurality of types of sources to document a story.", "labels": [], "entities": []}, {"text": "In order to put information into context and tell his story from all significant angles, he needs to go through an enormous amount of records with information of very diverse degrees of granularity.", "labels": [], "entities": []}, {"text": "At the same time, he needs to reduce the noise of irrelevant content.", "labels": [], "entities": []}, {"text": "This is extremely time-consuming, especially when a topic or event is interconnected with multiple entities from different domains.", "labels": [], "entities": []}, {"text": "At a different level, many TV viewers are getting used to navigating with their tablets or iPads while watching the TV, the tablet effectively functioning as a second screen, often providing background information on the program or interaction in social networks about what is being watched.", "labels": [], "entities": []}, {"text": "Both the journalist and the TV viewer would greatly benefit from a system capable of automatically analysing and interpreting unstructured multimedia data stream and its social background, and, with this understanding, be able of contextualising the data, and contributing with new, related information.", "labels": [], "entities": []}, {"text": "The FP7-ICT-2013-10 STREP project EUMSSI, which started in December 2013, is developing methodologies and techniques for identifying and aggregating data presented as unstructured information in sources of very different nature (video, image, audio, speech, text and social context), including both online (e.g., YouTube) and traditional media (e.g. audiovisual repositories), and for dealing with information of very different degrees of granularity.", "labels": [], "entities": [{"text": "FP7-ICT-2013-10 STREP project EUMSSI", "start_pos": 4, "end_pos": 40, "type": "DATASET", "confidence": 0.7832753956317902}, {"text": "identifying and aggregating data presented as unstructured information in sources of very different nature (video, image, audio, speech, text and social context)", "start_pos": 121, "end_pos": 282, "type": "Description", "confidence": 0.6946423905236381}]}, {"text": "This will be accomplished thanks to the integration in a UIMA-based 1 multimodal platform of stateof-the-art information extraction and analysis techniques from the different fields involved (image, audio, text and social media analysis).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.718553751707077}]}, {"text": "The multimodal interpretation platform, in an optimized process chain, will analyze avast amount of multimedia content, aggregate all the resulting information and semantically enrich it with additional metadata layers.", "labels": [], "entities": [{"text": "multimodal interpretation", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6868028789758682}]}, {"text": "The resulting system will be potentially useful for any application in need of cross-media data analysis and interpretation, such as intelligent content management, recommendation, real time event tracking, content filtering, etc.", "labels": [], "entities": [{"text": "cross-media data analysis and interpretation", "start_pos": 79, "end_pos": 123, "type": "TASK", "confidence": 0.7151161551475524}, {"text": "intelligent content management", "start_pos": 133, "end_pos": 163, "type": "TASK", "confidence": 0.7231990297635397}, {"text": "real time event tracking", "start_pos": 181, "end_pos": 205, "type": "TASK", "confidence": 0.6114420890808105}, {"text": "content filtering", "start_pos": 207, "end_pos": 224, "type": "TASK", "confidence": 0.7527692914009094}]}, {"text": "In particular, the EUMSSI project will use the semantically enriched information to make personalized content-based recommendation.", "labels": [], "entities": [{"text": "EUMSSI", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.906489372253418}]}], "datasetContent": [], "tableCaptions": []}