{"title": [{"text": "Extrinsic Evaluation of Dialog State Tracking and Predictive Metrics for Dialog Policy Optimization", "labels": [], "entities": [{"text": "Dialog State Tracking", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.6783237258593241}, {"text": "Dialog Policy Optimization", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.7543907562891642}]}], "abstractContent": [{"text": "During the recent Dialog State Tracking Challenge (DSTC), a fundamental question was raised: \"Would better performance in dialog state tracking translate to better performance of the optimized policy by reinforcement learning?\"", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge (DSTC)", "start_pos": 18, "end_pos": 56, "type": "TASK", "confidence": 0.7931329395089831}, {"text": "dialog state tracking", "start_pos": 122, "end_pos": 143, "type": "TASK", "confidence": 0.6918610135714213}]}, {"text": "Also, during the challenge system evaluation, another non-trivial question arose: \"Which evaluation metric and schedule would best predict improvement in overall dialog performance?\"", "labels": [], "entities": []}, {"text": "This paper aims to answer these questions by applying an off-policy reinforcement learning method to the output of each challenge system.", "labels": [], "entities": []}, {"text": "The results give a positive answer to the first question.", "labels": [], "entities": []}, {"text": "Thus the effort to separately improve the performance of dialog state tracking as carried out in the DSTC maybe justified.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.845039447148641}, {"text": "DSTC", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8795949220657349}]}, {"text": "The answer to the second question also draws several insightful conclusions on the characteristics of different evaluation metrics and schedules.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical approaches to spoken dialog management have proven very effective in gracefully dealing with noisy input due to Automatic Speech Recognition (ASR) and Spoken Language Understanding (SLU) error).", "labels": [], "entities": [{"text": "spoken dialog management", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.7331277132034302}]}, {"text": "Most recent advances in statistical dialog modeling have been based on the Partially Observable Markov Decision Processes (POMDP) framework which provides a principled way for sequential action planning under uncertainty (.", "labels": [], "entities": [{"text": "statistical dialog modeling", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.7309070626894633}, {"text": "sequential action planning", "start_pos": 176, "end_pos": 202, "type": "TASK", "confidence": 0.7395138343175253}]}, {"text": "In this approach, the task of dialog management is generally decomposed into two subtasks, i.e., dialog state tracking and dialog policy learning.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.9160604774951935}, {"text": "dialog state tracking", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7765811085700989}, {"text": "dialog policy learning", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.7688393195470175}]}, {"text": "The aim of dialog state tracking is to accurately estimate the true dialog state from noisy observations by incorporating patterns between turns and external knowledge as a dialog unfolds).", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.8554531733194987}]}, {"text": "The dialog policy learning process then strives to select an optimal system action given the estimated dialog state.", "labels": [], "entities": [{"text": "dialog policy learning", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8378143906593323}]}, {"text": "Many dialog state tracking algorithms have been developed.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.7951668699582418}]}, {"text": "Few studies, however, have reported the strengths and weaknesses of each method.", "labels": [], "entities": []}, {"text": "Thus the Dialog State Tracking Challenge (DSTC) was organized to advance state-of-the-art technologies for dialog state tracking by allowing for reliable comparisons between different approaches using the same datasets ( ).", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge (DSTC)", "start_pos": 9, "end_pos": 47, "type": "TASK", "confidence": 0.816409000328609}, {"text": "dialog state tracking", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.840077797571818}]}, {"text": "Thanks to the DSTC, we now have a better understanding of effective models, features and training methods we can use to create a dialog state tracker that is not only of superior performance but also very robust to realistic mismatches between development and deployment environments (.", "labels": [], "entities": [{"text": "DSTC", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.919174313545227}]}, {"text": "Despite the fruitful results, it was largely limited to intrinsic evaluation, thus leaving an important question unanswered: \"Would the improved performance in dialog state tracking carryover to dialog policy optimization?\"", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 160, "end_pos": 181, "type": "TASK", "confidence": 0.762181301911672}, {"text": "dialog policy optimization", "start_pos": 195, "end_pos": 221, "type": "TASK", "confidence": 0.8130931456883749}]}, {"text": "Furthermore, there was no consensus on what and when to measure, resulting in a large set of metrics being evaluated with three different schedules.", "labels": [], "entities": []}, {"text": "With this variety of metrics, it is not clear what the evaluation result means.", "labels": [], "entities": []}, {"text": "Thus it is important to answer the question: \"Which metric best serves as a predictor to the improvement in dialog policy optimization\" since this is the ultimate goal, in terms of end-to-end dialog performance.", "labels": [], "entities": [{"text": "dialog policy optimization", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.8611185352007548}]}, {"text": "The aim of this paper is to answer these two questions via corpus-based experiments.", "labels": [], "entities": []}, {"text": "Similar to the rationale behind the DSTC, the corpus-based design allows us to compare different trackers on the same data.", "labels": [], "entities": []}, {"text": "We applied a sample efficient off-policy reinforcement learning (RL) method to the outputs of each tracker so that we may examine the relationship between the performance of dialog state tracking and that of the optimized policy as well as which metric shows the highest correlation with the performance of the optimized policy.", "labels": [], "entities": [{"text": "off-policy reinforcement learning (RL)", "start_pos": 30, "end_pos": 68, "type": "TASK", "confidence": 0.6689706494410833}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes the DSTC and the metrics adopted in the challenge.", "labels": [], "entities": []}, {"text": "Section 3 elaborates on the extrinsic evaluation method based on offpolicy RL.", "labels": [], "entities": [{"text": "offpolicy RL", "start_pos": 65, "end_pos": 77, "type": "TASK", "confidence": 0.43608973920345306}]}, {"text": "Section 4 presents the extrinsic evaluation results and discusses its implication on metrics for dialog state tracking evaluation.", "labels": [], "entities": [{"text": "dialog state tracking evaluation", "start_pos": 97, "end_pos": 129, "type": "TASK", "confidence": 0.8526802510023117}]}, {"text": "Finally, Section 5 concludes with a brief summary and suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section briefly describes the task for the DSTC and evaluation metrics.", "labels": [], "entities": [{"text": "DSTC", "start_pos": 48, "end_pos": 52, "type": "TASK", "confidence": 0.6981778144836426}]}, {"text": "For more details, please refer to the DSTC manual 1 . 1 http://research.microsoft.com/apps/pubs/?id=169024  To evaluate tracker output, the correctness of each hypothesis is labeled at each turn.", "labels": [], "entities": [{"text": "DSTC manual 1 . 1", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.9232303619384765}]}, {"text": "Then hypothesis scores and labels over the entire dialogs are collected to compute 11 metrics: \uf0b7 Accuracy measures the ratio of states under evaluation where the top hypothesis is correct.", "labels": [], "entities": [{"text": "\uf0b7", "start_pos": 95, "end_pos": 96, "type": "METRIC", "confidence": 0.998931348323822}, {"text": "Accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9192308187484741}]}, {"text": "\uf0b7 ROC.V1 computes the following quantity: where is the total number of top hypotheses over the entire data and ( ) denotes the number of correctly accepted top hypotheses with the threshold being set to . Similarly FA denotes false-accepts and FR false-rejects.", "labels": [], "entities": [{"text": "\uf0b7", "start_pos": 0, "end_pos": 1, "type": "DATASET", "confidence": 0.6112858653068542}, {"text": "ROC.V1", "start_pos": 2, "end_pos": 8, "type": "DATASET", "confidence": 0.4722018241882324}, {"text": "FA", "start_pos": 215, "end_pos": 217, "type": "METRIC", "confidence": 0.9972489476203918}, {"text": "FR", "start_pos": 244, "end_pos": 246, "type": "METRIC", "confidence": 0.9946278929710388}]}, {"text": "From these quantities, several metrics are derived.", "labels": [], "entities": []}, {"text": "ROC.V1.EER computes FA.V1(s) where FA.V1(s) = FR.V1(s).", "labels": [], "entities": [{"text": "FA.V1", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.9785242080688477}, {"text": "FA.V1", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.9839029312133789}, {"text": "FR.V1", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9956275224685669}]}, {"text": "The metrics ROC.V1.CA05, ROC.V1.CA10, and ROC.V1.CA20 compute CA.V1(s) when FA.V1(s) = 0.05, 0.10, and 0.20 respectively.", "labels": [], "entities": [{"text": "ROC.V1.CA05", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.8812057375907898}, {"text": "FA.V1", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.9729031324386597}]}, {"text": "These metrics measure the quality of score via plotting accuracy with respect to false-accepts so that they may reflect not only accuracy but also discrimination.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9614015221595764}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9964079260826111}]}, {"text": "\uf0b7 ROC.V2 computes the conventional ROC quantity: ROC.V2.CA05, ROC.V2.CA10, and ROC.V2.CA20 do the same as the V1 versions.", "labels": [], "entities": []}, {"text": "These metrics measure the discrimination of the score for the top hypothesis independently of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.998259961605072}]}, {"text": "Note that Accuracy and ROC curves do not take into consideration non-top hypotheses while the following measures do.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991368651390076}, {"text": "ROC", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9824902415275574}]}, {"text": "\uf0b7 L2 calculates the Euclidean distance between the vector consisting of the scores of all hypotheses and a zero vector with 1 in the position of the correct one.", "labels": [], "entities": []}, {"text": "This measures the quality of tracker's output score as probability.", "labels": [], "entities": []}, {"text": "\uf0b7 AvgP indicates the averaged score of the correct hypothesis.", "labels": [], "entities": [{"text": "\uf0b7", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9956026077270508}, {"text": "AvgP", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9845998883247375}]}, {"text": "Note that this measures the quality of the score of the correct hypothesis, ignoring the scores assigned to incorrect hypotheses.", "labels": [], "entities": []}, {"text": "\uf0b7 MRR denotes the mean reciprocal rank of the correct hypothesis.", "labels": [], "entities": [{"text": "\uf0b7", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8500659465789795}, {"text": "MRR", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.7467613816261292}, {"text": "mean reciprocal rank", "start_pos": 18, "end_pos": 38, "type": "METRIC", "confidence": 0.6948712468147278}]}, {"text": "This measures the quality of rank instead of score.", "labels": [], "entities": [{"text": "quality of rank", "start_pos": 18, "end_pos": 33, "type": "METRIC", "confidence": 0.8654911716779073}]}, {"text": "As far as evaluation schedule is concerned, there are three schedules for determining which turns to include in each evaluation.", "labels": [], "entities": []}, {"text": "\uf0b7 Schedule 1: Include all turns.", "labels": [], "entities": [{"text": "Include", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.7162153720855713}]}, {"text": "This schedule allows us to account for changes in concepts that are not in focus.", "labels": [], "entities": []}, {"text": "But this makes acrossconcept comparison invalid since different concepts appear at different times in a dialog.", "labels": [], "entities": [{"text": "acrossconcept comparison", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.845374345779419}]}, {"text": "\uf0b7 Schedule 2: Include a turn fora given concept only if that concept either appears on the SLU N-Best list in that turn, or if the system's action references that concept in that turn.", "labels": [], "entities": []}, {"text": "Unlike schedule 1, this schedule makes comparisons across concepts valid but cannot account for changes in concepts which are not in focus.", "labels": [], "entities": []}, {"text": "\uf0b7 Schedule 3: Include only the turn before the system starts over from the beginning, and the last turn of the dialog.", "labels": [], "entities": [{"text": "Include", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9477413892745972}]}, {"text": "This schedule does not consider what happens during a dialog.", "labels": [], "entities": []}, {"text": "In this section, we present a corpus-based method for extrinsic evaluation of dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7543326814969381}]}, {"text": "Thanks to the corpus-based design where outputs of various trackers with different characteristics are involved, it is possible to examine how the differences between trackers affect the performance of learned policies.", "labels": [], "entities": []}, {"text": "The performance of a learned policy is measured by the expected return at the initial state of a dialog which is one of the common performance measures for episodic tasks.", "labels": [], "entities": []}, {"text": "In order to seethe relationship between the performance of dialog state tracking and that of the optimized policy, we applied the off-policy RL method presented in Section 3 to the outputs of each tracker for all four DSTC test datasets 2 . The summary statistics of the datasets are presented in.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7711986899375916}, {"text": "RL", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.8092890381813049}, {"text": "DSTC test datasets", "start_pos": 218, "end_pos": 236, "type": "DATASET", "confidence": 0.9453909794489542}]}, {"text": "In addition, to quantify the impact of dialog state tracking on an end-to-end dialog, the performance of policies optimized by RL was compared with Behavior policies and another set of learned policies using supervised learning (SL).", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.6725742419560751}]}, {"text": "Note that Behavior policies were developed by experts in spoken dialog research.", "labels": [], "entities": []}, {"text": "The use of a learned policy using supervised We took the entry from each team that achieved the highest ranks of that team in the largest number of evaluation metrics: entry2 for team3 and team6, entry3 for team8, entry4 for team9, and entry1 for the rest of the teams.", "labels": [], "entities": []}, {"text": "We were not, however, able to process the tracker output of team2 due to its large size.", "labels": [], "entities": []}, {"text": "This does not negatively impact the general results of this paper.: The DSTC test datasets (DS1-4) were evenly divided into two groups of datasets for off-policy RL training and test.", "labels": [], "entities": [{"text": "DSTC test datasets (DS1-4)", "start_pos": 72, "end_pos": 98, "type": "DATASET", "confidence": 0.9373959004878998}, {"text": "RL training", "start_pos": 162, "end_pos": 173, "type": "TASK", "confidence": 0.8625951409339905}]}, {"text": "To simplify the analysis, the dialogs that include startover and canthelp were excluded.", "labels": [], "entities": []}, {"text": "learning () is also one of the common methods of spoken dialog system development.", "labels": [], "entities": [{"text": "spoken dialog system development", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.71595498919487}]}, {"text": "We exploited the SVM method with the same kernel functions as defined in Section 3.2 except that the action element is not included.", "labels": [], "entities": []}, {"text": "The posterior probability of the SVM model was also used for handling the insufficient exploration problem (in Section 3.1).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The DSTC test datasets (DS1-4)  were evenly divided into two groups of  datasets for off-policy RL training and test. To  simplify the analysis, the dialogs that include  startover and canthelp were excluded.", "labels": [], "entities": [{"text": "DSTC test datasets (DS1-4)", "start_pos": 14, "end_pos": 40, "type": "DATASET", "confidence": 0.9022822678089142}, {"text": "RL training", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.8751237988471985}]}]}