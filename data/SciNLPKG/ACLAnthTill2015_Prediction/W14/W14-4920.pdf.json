{"title": [{"text": "Interactive Annotation for Event Modality in Modern Standard and Egyptian Arabic Tweets", "labels": [], "entities": [{"text": "Event Modality", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7726804316043854}, {"text": "Modern Standard and Egyptian Arabic Tweets", "start_pos": 45, "end_pos": 87, "type": "DATASET", "confidence": 0.695182591676712}]}], "abstractContent": [{"text": "We present an interactive procedure to annotate a large-scale corpus of Modern Standard and Egyptian Arabic tweets for event modality that comprises obligation, permission, commitment, ability, and volition.", "labels": [], "entities": []}, {"text": "The procedure splits up the annotation process into a series of simplified questions, dispenses with the requirement of expert linguistic knowledge, and captures nested modality triggers and their attributes semi-automatically.", "labels": [], "entities": []}], "introductionContent": [{"text": "Event modality, according to, describes events that are not actualized but are merely potential.", "labels": [], "entities": []}, {"text": "It comprises obligation, permission, commitment, ability, and volition.", "labels": [], "entities": []}, {"text": "Both obligation and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises.", "labels": [], "entities": []}, {"text": "Ability is the (in)capacity to do something.", "labels": [], "entities": [{"text": "Ability", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9731602072715759}]}, {"text": "Volition is broadly defined as intensions, desires, wishes, and preferences.", "labels": [], "entities": [{"text": "Volition", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9599199295043945}]}, {"text": "Event modality is used for several NLP tasks, including sales and marketing analysis (, sentiment analysis (), the automatic detection of request emails, and the classification of animacy and writers' emotions (.", "labels": [], "entities": [{"text": "sales and marketing analysis", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.6512397825717926}, {"text": "sentiment analysis", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.9151198863983154}, {"text": "automatic detection of request emails", "start_pos": 115, "end_pos": 152, "type": "TASK", "confidence": 0.7321089208126068}, {"text": "classification of animacy and writers' emotions", "start_pos": 162, "end_pos": 209, "type": "TASK", "confidence": 0.8048406938711802}]}, {"text": "To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (), Japanese (), Portuguese (), and Chinese (.", "labels": [], "entities": []}, {"text": "One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines.", "labels": [], "entities": []}, {"text": "Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically takes place in in-lab settings at small scales.", "labels": [], "entities": []}, {"text": "In this paper, we present an interactive annotation procedure to annotate event modality and its attributes of sense, polarity, intensification, tense, holders, and scopes in Modern Standard and Egyptian Arabic tweets.", "labels": [], "entities": [{"text": "Modern Standard and Egyptian Arabic tweets", "start_pos": 175, "end_pos": 217, "type": "DATASET", "confidence": 0.8258753518263499}]}, {"text": "The procedure depicts the following ideas: first, it defines each annotation task as a series of questions displayed 1 /hidden based on prior answers; second, it avoids lengthy theoretically-sophisticated definitions and uses the questions instead as simplified self-explanatory annotation prompts; and third, based on the elicited answers it automatically determines nested triggers and their attributes.", "labels": [], "entities": []}, {"text": "The fact that our procedure does not require special linguistic background and consists of easy-to-administer questions makes it eligible for large-scale crowdsourcing annotation.", "labels": [], "entities": []}, {"text": "Our corpus comprises 9949 unique tweets, annotated for 12134 tokens that map to 315 unique types of event modality triggers and their attributes of sense, polarity, intensification, tense, holders, and scopes.", "labels": [], "entities": []}, {"text": "The reason to work on the genre of tweets is that our corpus is part of a larger project to incorporate linguistic features, such as modality, with network-based features to automatically identify the key players of political discourse on Twitter for countries with fast-changing politics such as Egypt.", "labels": [], "entities": []}, {"text": "The fact that our corpus is harvested from the Arabic Egyptian Twitter entails that the corpus is diglossic for Modern Standard Arabic (MSA), the formal Arabic variety, and Egyptian Arabic (EA), the native Arabic dialect of Egypt.", "labels": [], "entities": []}, {"text": "We evaluate the annotation results with Krippendorff's alpha.", "labels": [], "entities": []}, {"text": "Results show high inter-annotator reliability rates, indicating that our annotation scheme and procedure are effective.", "labels": [], "entities": [{"text": "reliability", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.8794189095497131}]}, {"text": "The contribution of this paper, therefore, is twofold: first, we create a novel annotated resource for Arabic NLP that is larger than existing corpora even for languages other than Arabic; and second, we present an efficient and easy-to-administer annotation procedure with interactive crowdsourcing potentials.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 outlines the annotation scheme, guidelines and the interactive procedure; Section 3 gives examples for the final output representations; Section 4 describes corpus harvesting and sampling; Section 5 provides the annotation results and disagreement analysis; and Section 6 compares and contrasts our work with related work.", "labels": [], "entities": [{"text": "corpus harvesting", "start_pos": 215, "end_pos": 232, "type": "TASK", "confidence": 0.7157622426748276}]}], "datasetContent": [{"text": "Our annotation tasks are of two types: (1) Tasks 1-4 are label-based where there is a pre-defined set of labels from which annotators choose; and (2) Tasks 5-6 are segmentation-based where the output of the annotation is a text segment.", "labels": [], "entities": []}, {"text": "For the segmentation-based tasks, we use an all-ornothing method to measure inter-annotator reliability: for segments to be considered as agreement, they must share both the beginning and end boundaries.", "labels": [], "entities": []}, {"text": "We use Krippendorff's alpha \u03b1 (Krippendorff 2011) as our inter-annotator reliability measure, following the most recent work on modality annotation for other languages including English () and Chinese (.", "labels": [], "entities": []}, {"text": "For more details on Krippendorff's alpha and a, we refer the reader to.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Krippendorff's alpha rates for inter-annotator reliability", "labels": [], "entities": []}, {"text": " Table 2: Token statistics for each annotation task per event modality sense where MD is modal, NMD is  non-modal, AFF is affirmative, NEG is negative, AMP is amplified, MTG is mitigated, ASIS is as is, PRS is  present, and PST is past", "labels": [], "entities": [{"text": "AFF", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.9882458448410034}, {"text": "ASIS", "start_pos": 188, "end_pos": 192, "type": "METRIC", "confidence": 0.7579951882362366}]}]}