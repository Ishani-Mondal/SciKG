{"title": [], "abstractContent": [{"text": "This paper presents a method for decomposing long, complex consumer health questions.", "labels": [], "entities": [{"text": "decomposing long, complex consumer health questions", "start_pos": 33, "end_pos": 84, "type": "TASK", "confidence": 0.8387937375477382}]}, {"text": "Our approach largely decomposes questions using their syntactic structure , recognizing independent questions embedded in clauses, as well as coordinations and exemplifying phrases.", "labels": [], "entities": []}, {"text": "Additionally , we identify elements specific to disease-related consumer health questions, such as the focus disease and background information.", "labels": [], "entities": []}, {"text": "To achieve this, our approach combines rank-and-filter machine learning methods with rule-based methods.", "labels": [], "entities": []}, {"text": "Our results demonstrate significant improvements over the heuristic methods typically employed for question decomposition that rely only on the syntactic parse tree.", "labels": [], "entities": [{"text": "question decomposition", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.8382091224193573}]}], "introductionContent": [{"text": "Natural language questions provide an intuitive method for consumers (non-experts) to query for health-related content.", "labels": [], "entities": []}, {"text": "The most intuitive way for consumers to formulate written questions is the same way they write to other humans: multisentence, complex questions that contain background information and often more than one specific question.", "labels": [], "entities": []}, {"text": "Consider the following: \u2022 Will Fabry disease affect a transplanted kidney?", "labels": [], "entities": []}, {"text": "Previous to the transplant the disease was being managed with an enzyme supplement.", "labels": [], "entities": []}, {"text": "Will this need to be continued?", "labels": [], "entities": []}, {"text": "What cautions or additional treatments are required to manage the disease with a transplanted kidney?", "labels": [], "entities": []}, {"text": "This complex question contains three question sentences and one background sentence.", "labels": [], "entities": []}, {"text": "The focus (Fabry disease) is stated in the first question but is necessary fora full understanding of the other questions as well.", "labels": [], "entities": [{"text": "Fabry disease)", "start_pos": 11, "end_pos": 25, "type": "METRIC", "confidence": 0.8249138196309408}]}, {"text": "The background sentence is necessary to understand the second question: the anaphor this must be resolved to an enzyme treatment, and the predicate continue's implicit argument that must be re-constructed from the discourse (i.e., continue after a kidney transplant).", "labels": [], "entities": []}, {"text": "The final question sentence uses a coordination to ask two separate questions (cautions and additional treatments).", "labels": [], "entities": []}, {"text": "A decomposition of this complex question would then result in four questions: 1.", "labels": [], "entities": []}, {"text": "Will Fabry disease affect a transplanted kidney?", "labels": [], "entities": []}, {"text": "2. Will enzyme treatment for Fabry disease need to be continued after a kidney transplant?", "labels": [], "entities": [{"text": "Fabry disease", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.5315594375133514}]}, {"text": "3. What cautions are required to manage Fabry disease with a transplanted kidney?", "labels": [], "entities": [{"text": "Fabry disease", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.6651504039764404}]}, {"text": "4. What additional treatments are required to manage Fabry disease with a transplanted kidney?", "labels": [], "entities": [{"text": "Fabry disease", "start_pos": 53, "end_pos": 66, "type": "TASK", "confidence": 0.6939932405948639}]}, {"text": "Each question above could be independently answered by a question answering (QA) system.", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.818540620803833}]}, {"text": "While previous work has discussed methods for resolving co-reference and implicit arguments in consumer health questions (), it does not address question decomposition.", "labels": [], "entities": [{"text": "question decomposition", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.7122050225734711}]}, {"text": "In this work, we propose methods for automatically recognizing six annotation types useful for decomposing consumer health questions.", "labels": [], "entities": []}, {"text": "These annotations distinguish between sentences that contain questions and background information.", "labels": [], "entities": []}, {"text": "They also identify when a question sentence can be split in multiple independent questions, and 29 when they contain optional or coordinated information embedded within a question.", "labels": [], "entities": []}, {"text": "For each of these decomposition annotations, we propose a combination of machine learning (ML) and rule based methods.", "labels": [], "entities": []}, {"text": "The ML methods largely take the form of a 3-step rank-and-filter approach, where candidates are generated, ranked by an ML classifier, then the top-ranked candidate is passed through a separate ML filtering classifier.", "labels": [], "entities": [{"text": "ML", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9545499682426453}]}, {"text": "We evaluate each of these methods on a set of 1,467 consumer health questions related to genetic and rare diseases.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: FOCUS recognition results. E = exact  match; R = relaxed match.", "labels": [], "entities": [{"text": "FOCUS recognition", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6672463417053223}, {"text": "exact  match", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.9603724777698517}, {"text": "R", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.9423666000366211}, {"text": "relaxed match", "start_pos": 59, "end_pos": 72, "type": "METRIC", "confidence": 0.9649892151355743}]}, {"text": " Table 2: QUESTION recognition results.", "labels": [], "entities": [{"text": "QUESTION recognition", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7371487617492676}]}, {"text": " Table 3: COORDINATION recognition results.  E = exact match; R = relaxed match.", "labels": [], "entities": [{"text": "COORDINATION recognition", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7381281554698944}, {"text": "E", "start_pos": 45, "end_pos": 46, "type": "METRIC", "confidence": 0.9681326746940613}, {"text": "exact match", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.9671091139316559}, {"text": "R", "start_pos": 62, "end_pos": 63, "type": "METRIC", "confidence": 0.9592612385749817}, {"text": "relaxed match", "start_pos": 66, "end_pos": 79, "type": "METRIC", "confidence": 0.9344156980514526}]}, {"text": " Table 4: EXEMPLIFICATION recognition results.  E = exact match; R = relaxed match.", "labels": [], "entities": [{"text": "EXEMPLIFICATION recognition", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6967519521713257}, {"text": "exact match", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.9714507758617401}, {"text": "R", "start_pos": 65, "end_pos": 66, "type": "METRIC", "confidence": 0.9585292339324951}, {"text": "relaxed match", "start_pos": 69, "end_pos": 82, "type": "METRIC", "confidence": 0.9481074512004852}]}]}