{"title": [{"text": "Adverse Drug Event prediction combining shallow analysis and machine learning", "labels": [], "entities": [{"text": "Adverse Drug Event prediction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8909755051136017}]}], "abstractContent": [{"text": "The aim of this work is to infer a model able to extract cause-effect relations between drugs and diseases.", "labels": [], "entities": []}, {"text": "A two-level system is proposed.", "labels": [], "entities": []}, {"text": "The first level carries out a shallow analysis of Electronic Health Records (EHRs) in order to identify medical concepts such as drug brand-names, substances, diseases, etc.", "labels": [], "entities": []}, {"text": "Next, all the combination pairs formed by a concept from the group of drugs (drug and substances) and the group of diseases (diseases and symptoms) are characterised through a set of 57 features.", "labels": [], "entities": []}, {"text": "A supervised classifier inferred on those features is in charge of deciding whether that pair represents a cause-effect type of event.", "labels": [], "entities": []}, {"text": "One of the challenges of this work is the fact that the system explores the entire document.", "labels": [], "entities": []}, {"text": "The contributions of this paper stand on the use of real EHRs to discover adverse drug reaction events even in different sentences.", "labels": [], "entities": []}, {"text": "Besides, the work fo-cuses on Spanish language.", "labels": [], "entities": []}], "introductionContent": [{"text": "This work deals with semantic data mining within the clinical domain.", "labels": [], "entities": [{"text": "semantic data mining", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.6908863683541616}]}, {"text": "The aim is to automatically highlight the Adverse Drug Reactions (ADRs) in EHRs in order to alleviate the work-load to several services within a hospital (pharmacy service, documentation service,.", "labels": [], "entities": []}, {"text": ") that have to read these reports.", "labels": [], "entities": []}, {"text": "Event detection was thoroughly tackled in the Natural Language Processing for Clinical Data 2010 Challenge.", "labels": [], "entities": [{"text": "Event detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.903106153011322}, {"text": "Natural Language Processing for Clinical Data 2010 Challenge", "start_pos": 46, "end_pos": 106, "type": "TASK", "confidence": 0.7306386642158031}]}, {"text": "Since then, cause-effect event extraction has emerged as afield of interest in the Biomedical domain).", "labels": [], "entities": [{"text": "cause-effect event extraction", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.6741896569728851}]}, {"text": "The motivation is, above all, practical.", "labels": [], "entities": []}, {"text": "Electronic Health Records (EHRs) are studied by several services in the hospital, not only by the doctor in charge of the patient but also by the pharmacy and documentation services, amongst others.", "labels": [], "entities": []}, {"text": "There are some attempts in the literature that aim to make the reading of the reports in English easier and less time-consuming by means of an automatic annotation toolkit (.", "labels": [], "entities": []}, {"text": "This work is a first approach on automatic learning of relations between drugs causing diseases in Spanish EHRs.", "labels": [], "entities": []}, {"text": "This work presents a system that entails two stages in cascade: 1) the first one carries out the annotation of drugs or substances (from now onwards both of them shall be referred to as DRUG) and diseases or symptoms (referred to as DIS-EASE); 2) the second one determines whether a given (DRUG, DISEASE) pair of concepts represents a cause-effect reaction.", "labels": [], "entities": []}, {"text": "Note that we are interested in highlighting events involving pairs where the drug caused an adverse reaction or a disease.", "labels": [], "entities": []}, {"text": "By contrast, often, (DRUG, DISEASE) pairs would entail a drug prescribed to combat a disease, but these correspond to a different kind of events (indeed, diametrically opposed).", "labels": [], "entities": [{"text": "DRUG", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.8732695579528809}]}, {"text": "Besides, (DRUG, DISEASE) pairs might represent other sort of events or they might even be unrelated at all.", "labels": [], "entities": [{"text": "DRUG", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9083995223045349}, {"text": "DISEASE", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.8171067237854004}]}, {"text": "Finally, the system should present the ADRs marked in a friendly front-end.", "labels": [], "entities": []}, {"text": "To this end, the aim is to represent the text in the framework provided by Brat ().", "labels": [], "entities": []}, {"text": "shows an example, represented in Brat, of some cause-effect events manually tagged by experts.", "labels": [], "entities": [{"text": "Brat", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.6909588575363159}]}, {"text": "There are related works in this field aiming at a variety of biomedical event extraction, such as binary protein-protein interaction, biomolecular event extraction, and drug-drug interaction extraction).", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.6334937214851379}, {"text": "biomolecular event extraction", "start_pos": 134, "end_pos": 163, "type": "TASK", "confidence": 0.6366750597953796}, {"text": "drug-drug interaction extraction", "start_pos": 169, "end_pos": 201, "type": "TASK", "confidence": 0.6988322337468466}]}, {"text": "We are focusing on a variety of interaction extraction: drugs causing diseases.", "labels": [], "entities": [{"text": "interaction extraction", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8070658147335052}]}, {"text": "There are previous works in the literature that try to warn whether a document contains or not this type of events.", "labels": [], "entities": []}, {"text": "There are more recent works that cope with event extraction within the same sentence, that is, intra-sentence events.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.7314615845680237}]}, {"text": "By contrast, in this work we have realised that around 26% of the events occur between concepts that are in different sentences.", "labels": [], "entities": []}, {"text": "Moreover, some of them are at very long distance.", "labels": [], "entities": []}, {"text": "Hence, our method aims at providing all the (DRUG, DISEASE) concepts within the document that represent a cause-effect relation.", "labels": [], "entities": []}, {"text": "We cope with real discharge EHRs written by around 400 different doctors.", "labels": [], "entities": []}, {"text": "These records are not written in a template, that is, the EHRs do not follow a pre-determined structure, and this, by itself entails a challenge.", "labels": [], "entities": []}, {"text": "The EHRs we are dealing with are written in a free structure using natural language, non-standard abbreviations etc.", "labels": [], "entities": [{"text": "EHRs", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9137430191040039}]}, {"text": "Moreover, we tackle Spanish language, for which little work has been carried out.", "labels": [], "entities": []}, {"text": "In addition, we do not only aim at single concept-words but also at concepts based on multi-word terms.", "labels": [], "entities": []}], "datasetContent": [{"text": "We count on data consisting of discharge summaries from Galdakao-Usansolo Hospital.", "labels": [], "entities": [{"text": "Galdakao-Usansolo Hospital", "start_pos": 56, "end_pos": 82, "type": "DATASET", "confidence": 0.9188803136348724}]}, {"text": "The records are semi-structured in the sense that there are two main fields: the first one for personal data of the patient (age, dates relating to admittance) that were not provided by the hospital for privacy issues; and the second one, our target, a single field that contains the antecedents, treatment, clinical analysis, etc.", "labels": [], "entities": []}, {"text": "This second field is an unstructured section (some hospitals rely upon templates that divide this field into several subfields, providing it with further structure).", "labels": [], "entities": []}, {"text": "The discharge notes describe a chronological development of the patient's condition, the undergone treatments, and also the clinical tests that were carried out.", "labels": [], "entities": []}, {"text": "Given the entire set of manually annotated documents, 34% were randomly selected without replacement to produce the evaluation set.", "labels": [], "entities": []}, {"text": "The resulting partition is presented in: Quantitative description of the data.", "labels": [], "entities": [{"text": "Quantitative", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.7362149357795715}]}, {"text": "All together, there are 194 EHRs manually tagged with more than 8,000 concepts (entailing diseases, symptoms, drugs, substances and procedures).", "labels": [], "entities": []}, {"text": "From these EHRs all the (DRUG,DISEASE) pairs are taken into account as event candidates, and these are referred to as relations in.", "labels": [], "entities": []}, {"text": "The system was assessed using per-class averaged precision, recall and f1-measure as presented in.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9631937146186829}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9995879530906677}, {"text": "f1-measure", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9597466588020325}]}, {"text": "Precision Recall F1-measure 0.932 0.849 0.883: Experimental results.", "labels": [], "entities": [{"text": "Precision Recall F1-measure 0.932 0.849 0.883", "start_pos": 0, "end_pos": 45, "type": "METRIC", "confidence": 0.8570849001407623}]}, {"text": "Semantic knowledge and contextual features have proven very relevant to detect cause-effect relations.", "labels": [], "entities": []}, {"text": "Particularly, those used to detect the concepts and also negation or speculation of the context in which the concept appear.", "labels": [], "entities": []}, {"text": "A manual inspection was carried out on both the false positives and false negative predictions and the following conclusions were drawn: \u2022 The majority of false positives were caused by i) pairs of concepts at a very long distance; ii) pairs where one of the elements is related to past-events undergone while the other element is in the current treatment prescribed (e.g. the disease is in the antecedents and the drug in the current diagnostics).", "labels": [], "entities": []}, {"text": "\u2022 The vast majority of false negatives were due to concepts in the same sentence where the context-words are irrelevant (e.g. filler words, determiners, etc.).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Quantitative description of the data.", "labels": [], "entities": [{"text": "Quantitative description", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8044503927230835}]}]}