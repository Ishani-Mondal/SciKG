{"title": [{"text": "A Cascaded Approach for Social Media Text Normalization of Turkish", "labels": [], "entities": [{"text": "Social Media Text Normalization", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.6208045929670334}]}], "abstractContent": [{"text": "Text normalization is an indispensable stage for natural language processing of social media data with available NLP tools.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7597422897815704}, {"text": "natural language processing of social media", "start_pos": 49, "end_pos": 92, "type": "TASK", "confidence": 0.7574678659439087}]}, {"text": "We divide the normalization problem into 7 categories, namely; letter case transformation, replacement rules & lexicon lookup, proper noun detection, deasci-ification, vowel restoration, accent nor-malization and spelling correction.", "labels": [], "entities": [{"text": "letter case transformation", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.662555992603302}, {"text": "noun detection", "start_pos": 134, "end_pos": 148, "type": "TASK", "confidence": 0.6962347477674484}, {"text": "vowel restoration", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.6803111582994461}, {"text": "spelling correction", "start_pos": 213, "end_pos": 232, "type": "TASK", "confidence": 0.7636795043945312}]}, {"text": "We propose a cascaded approach where each ill formed word passes from these 7 modules and is investigated for possible transformations.", "labels": [], "entities": []}, {"text": "This paper presents the first results for the normalization of Turkish and tries to shed light on the different challenges in this area.", "labels": [], "entities": [{"text": "normalization of Turkish", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.9153633912404379}]}, {"text": "We report a 40 percentage points improvement over a lexicon lookup baseline and nearly 50 percentage points over available spelling correctors.", "labels": [], "entities": [{"text": "spelling correctors", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.6835830509662628}]}], "introductionContent": [{"text": "With the increasing number of people using micro blogging sites like Facebook and Twitter, social media became an indefinite source for machine learning area especially for natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 173, "end_pos": 200, "type": "TASK", "confidence": 0.6649055182933807}]}, {"text": "This service is highly attractive for information extraction, text mining and opinion mining purposes as the large volumes of data available online daily.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7997729480266571}, {"text": "text mining", "start_pos": 62, "end_pos": 73, "type": "TASK", "confidence": 0.8709290027618408}, {"text": "opinion mining", "start_pos": 78, "end_pos": 92, "type": "TASK", "confidence": 0.8498338758945465}]}, {"text": "The language used in this platform differs severely from formally written text in that, people do not feel forced to write grammatically correct sentences, generally write like they talk or try to impress their thoughts within a limited number of characters (such as in Twitter 140 characters).", "labels": [], "entities": []}, {"text": "This results with a totally different language than the conventional languages.", "labels": [], "entities": []}, {"text": "The research on text normalization of social media gained speed towards the end of the last decade and as always, almost all of these elementary studies are conducted on the English language.", "labels": [], "entities": [{"text": "text normalization of social media", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.8448552370071412}]}, {"text": "We know from earlier research results that morphologically rich languages such as Turkish differ severely from English and the methods tailored for English do not fit for these languages.", "labels": [], "entities": []}, {"text": "It is the case for text normalization as well.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8171707093715668}]}, {"text": "Highly inflectional or agglutinative languages share the same characteristic that a unique lemma in these languages may have hundreds of possible surface forms.", "labels": [], "entities": []}, {"text": "This increases the data sparsity in statistical models.", "labels": [], "entities": []}, {"text": "For example, it's pointed out in Hakkani- that, it is due to Turkish language's inflectional and derivational morphology that the number of distinct word forms is very large compared to English distinct word size.", "labels": [], "entities": []}, {"text": "This large vocabulary size is the reason why the dictionary 1 lookup or similarity based approaches are not suitable for this kind of languages.", "labels": [], "entities": []}, {"text": "And in addition to this, it is not an easy task to collect manually annotated data which could coverall these surface forms and their related mistakes for statistical approaches.", "labels": [], "entities": []}, {"text": "Corpus Size Turkish English 1M words 106,547 33,398 10M words 417,775 97,734: Vocabulary sizes for two Turkish and English corpora In this paper, we propose a cascaded approach for the social text normalization (specifically for Tweets) of Turkish language.", "labels": [], "entities": [{"text": "social text normalization", "start_pos": 185, "end_pos": 210, "type": "TASK", "confidence": 0.6712667544682821}]}, {"text": "The approach is a combination of rule based and machine learning components for different layers of normalization, namely; letter case transformation, replacement rules & lexicon lookup, proper noun detection, deasciification, vowel restoration, accent normalization and spelling correction.", "labels": [], "entities": [{"text": "letter case transformation", "start_pos": 123, "end_pos": 149, "type": "TASK", "confidence": 0.6763372421264648}, {"text": "proper noun detection", "start_pos": 187, "end_pos": 208, "type": "TASK", "confidence": 0.6198528607686361}, {"text": "vowel restoration", "start_pos": 227, "end_pos": 244, "type": "TASK", "confidence": 0.7356813699007034}, {"text": "accent normalization", "start_pos": 246, "end_pos": 266, "type": "TASK", "confidence": 0.6873885095119476}, {"text": "spelling correction", "start_pos": 271, "end_pos": 290, "type": "TASK", "confidence": 0.8673556447029114}]}, {"text": "Following the work of Han and Baldwin (2011), we divided the work into two stages: ill formed word detection and candidate word generation.", "labels": [], "entities": [{"text": "word detection", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.7191185355186462}, {"text": "candidate word generation", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.5954694847265879}]}, {"text": "Our contribution is: 1.", "labels": [], "entities": []}, {"text": "anew normalization model which could be applied to other morphologically rich languages as well with appropriate NLP tools 2.", "labels": [], "entities": []}, {"text": "the first results and test data sets for the text normalization of Turkish.", "labels": [], "entities": [{"text": "text normalization of Turkish", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.8525672256946564}]}, {"text": "The paper is structured as follows: Section 2 and 3 give brief information about related work and morphologically rich languages, Section 4 presents our normalization approach and Section 5 the experimental setup, Section 6 gives our experimental results and discussions and Section 7 the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we provide information about our used data sets, our evaluation strategy and the used models in the experiments.", "labels": [], "entities": []}, {"text": "We evaluated our work both for ill formed word detection and candidate generation separately.", "labels": [], "entities": [{"text": "word detection", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7618103623390198}, {"text": "candidate generation", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.76383838057518}]}, {"text": "For ill formed word detection, we provide precision (P), recall (R), f-measure (F) and accuracy (Acc.) scores.", "labels": [], "entities": [{"text": "ill formed word detection", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6201456785202026}, {"text": "precision (P)", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.9476108700037003}, {"text": "recall (R)", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9572979956865311}, {"text": "f-measure (F)", "start_pos": 69, "end_pos": 82, "type": "METRIC", "confidence": 0.924654558300972}, {"text": "accuracy (Acc.) scores", "start_pos": 87, "end_pos": 109, "type": "METRIC", "confidence": 0.8787500977516174}]}, {"text": "For candidate generation, we provide only the accuracy scores (the number of correctly normalized tokens over the total number of detected ill formed words).", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7863172292709351}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9992033839225769}]}], "tableCaptions": [{"text": " Table 6: Description of the Data Sets", "labels": [], "entities": []}, {"text": " Table 7: Ill Formed Word Detection Evaluation  Results on Validation Set", "labels": [], "entities": [{"text": "Ill Formed Word Detection Evaluation", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.6136489510536194}]}, {"text": " Table 8: Ill Formed Word Detection Evaluation  Results on Test Set", "labels": [], "entities": [{"text": "Ill Formed Word Detection Evaluation", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.6160297393798828}]}, {"text": " Table 9: Candidate Generation Results on Data  Sets", "labels": [], "entities": [{"text": "Candidate Generation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8166010975837708}]}]}