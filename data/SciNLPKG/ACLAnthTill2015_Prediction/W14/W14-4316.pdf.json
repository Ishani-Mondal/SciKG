{"title": [{"text": "Combining Task and Dialogue Streams in Unsupervised Dialogue Act Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Unsupervised machine learning approaches hold great promise for recognizing dialogue acts, but the performance of these models tends to be much lower than the accuracies reached by supervised models.", "labels": [], "entities": []}, {"text": "However, some dialogues, such as task-oriented dialogues with parallel task streams, hold rich information that has not yet been leveraged within unsu-pervised dialogue act models.", "labels": [], "entities": []}, {"text": "This paper investigates incorporating task features into an unsupervised dialogue act model trained on a corpus of human tutoring in introductory computer science.", "labels": [], "entities": []}, {"text": "Experimental results show that incorporating task features and dialogue history features significantly improve unsupervised dialogue act classification, particularly within a hierarchical framework that gives prominence to dialogue history.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 124, "end_pos": 151, "type": "TASK", "confidence": 0.6217367847760519}]}, {"text": "This work constitutes a step toward building high-performing unsupervised dialogue act models that will be used in the next generation of task-oriented dialogue systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogue acts represent the underlying intent of utterances, and constitute a crucial level of representation for dialogue systems).", "labels": [], "entities": []}, {"text": "The task of automatic dialogue act classification has been extensively studied for decades within several domains including train fares and timetables), virtual personal assistants, conversational telephone speech (), Wikipedia talk pages) and as in the case of this paper, tutorial dialogue).", "labels": [], "entities": [{"text": "automatic dialogue act classification", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.6070414185523987}]}, {"text": "Most of the prior work on dialogue act classification has depended on manually applying dialogue act tags and then leveraging supervised machine learning).", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.8260995348294576}]}, {"text": "This process involves engineering a dialogue act taxonomy (or using an existing one, though domain-specific phenomena can be difficult to capture within multi-purpose dialogue act taxonomies) and manually annotating each utterance in the corpus.", "labels": [], "entities": []}, {"text": "Then, the tagged utterances are provided to a supervised machine learner.", "labels": [], "entities": []}, {"text": "This supervised approach can achieve strong performance, in excess of 75% accuracy on manual tags, approaching the agreement level that is sometimes observed between human annotators (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9979771971702576}]}, {"text": "However, the supervised approach has several major drawbacks, including the fact that handcrafting dialogue act tagsets and applying them manually tend to be bottlenecks within the research and design process.", "labels": [], "entities": []}, {"text": "To overcome these drawbacks, the field has recently seen growing momentum surrounding unsupervised approaches, which do not require any manual labels during model training.", "labels": [], "entities": []}, {"text": "A variety of unsupervised machine learning techniques have been investigated for dialogue act classification, and each line of investigation has explored which features best support this goal.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.881878654162089}]}, {"text": "However, to date the best performing unsupervised models achieve in the range of 40% () to 60% (Joty et al., 2011) training set accuracy on manual tags, substantially lower than the mid-70% accuracy) often achieved on testing sets with supervised models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9526573419570923}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9467337131500244}]}, {"text": "In order to close this performance gap between unsupervised and supervised techniques, we suggest that it is crucial to enrich the features available to unsupervised models.", "labels": [], "entities": []}, {"text": "In particular, when a dialogue is task-oriented and includes a rich source of information within a parallel task stream, these features may substantially boost the ability of an unsupervised model to distinguish dialogue acts.", "labels": [], "entities": []}, {"text": "For example, in situated dialogue, features representing the state of the physical world maybe highly influential for dialogue act modeling (.", "labels": [], "entities": [{"text": "dialogue act modeling", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.6411670843760172}]}, {"text": "Human tutorial dialogue, which is the domain being considered in the current work, often exhibits this structure: the task artifact is external to the dialogue utterances themselves (in the case of our work, this artifact is a computer program that the student is constructing).", "labels": [], "entities": []}, {"text": "Task features have already been shown beneficial for supervised dialogue act classification in our domain ().", "labels": [], "entities": [{"text": "supervised dialogue act classification", "start_pos": 53, "end_pos": 91, "type": "TASK", "confidence": 0.6405837312340736}]}, {"text": "We hypothesize that including these task features within an unsupervised model will significantly improve its performance.", "labels": [], "entities": []}, {"text": "In addition, we hypothesize that including dialogue history as a prominent feature within an unsupervised model will provide significant improvement.", "labels": [], "entities": []}, {"text": "This paper represents the first investigation into combining task and dialogue features within an unsupervised dialogue act classification model.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.7346839507420858}]}, {"text": "First, we discuss representation of these task features and dialogue structure features, and compare these representations within both flat and hierarchical clustering approaches.", "labels": [], "entities": []}, {"text": "Second, we report on experiments that demonstrate that the inclusion of task features significantly improves dialogue act classification, and that a hierarchical cluster structure which explicitly captures dialogue history performs best.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 109, "end_pos": 136, "type": "TASK", "confidence": 0.8146529793739319}]}, {"text": "Finally, we breakdown the model's performance by dialogue act and investigate which features are most beneficial for distinguishing particular acts.", "labels": [], "entities": []}, {"text": "These contributions constitute a step toward building high-performing unsupervised dialogue act models that can be used in the next generation of task-oriented dialogue systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of this work is to investigate the impact of including task and dialogue context features on unsupervised dialogue act models.", "labels": [], "entities": []}, {"text": "We hypothesize that incorporating task features will significantly improve the performance of an unsupervised model, and we also hypothesize that properly incorporating dialogue context features, which are at a different granularity than the lexical features extracted from utterances, will substantially improve model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 319, "end_pos": 327, "type": "METRIC", "confidence": 0.9826679825782776}]}, {"text": "We conducted experiments with seven different feature combinations: L, lexical features only, T , task features only, D, dialogue context features only, and then the combinations of these fea- We hypothesized that the addition of task features would significantly improve the models' accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 284, "end_pos": 292, "type": "METRIC", "confidence": 0.9956092238426208}]}, {"text": "As shown in, adding task features to dialogue context features significantly outperforms dialogue context features alone (T + D > D).", "labels": [], "entities": []}, {"text": "Similarly, adding task features to lexical features provides significant improvement (T + L > L).", "labels": [], "entities": []}, {"text": "However, adding task features to the dialogue context plus lexical features model does not provide benefit, and in fact slightly (not significantly) degrades performance (T + D + L > D + L).", "labels": [], "entities": []}, {"text": "As reflected by the Kappa scores, the test set performance attained by these models is hardly better than would be expected by chance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Student dialogue act tags and their fre- quencies.", "labels": [], "entities": []}, {"text": " Table 5: Test set accuracies and Kappa for the flat  clustering model (L: Lexical features, D: Dialogue  context features, T: Task features) *indicates sta- tistically significant compared to the similar model  without task features (p < 0.05).", "labels": [], "entities": []}, {"text": " Table 6: The number of student utterances after  branching on the previous tutor dialogue act.", "labels": [], "entities": []}, {"text": " Table 8: Accuracies for individual dialogue acts.  Acts with fewer than 10 utterances after branching  are omitted from the table.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.992333173751831}]}]}