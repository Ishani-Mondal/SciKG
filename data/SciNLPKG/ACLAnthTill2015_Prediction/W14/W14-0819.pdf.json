{"title": [{"text": "Identifying collocations using cross-lingual association measures", "labels": [], "entities": [{"text": "Identifying collocations", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9222894608974457}]}], "abstractContent": [{"text": "We introduce a simple and effective cross-lingual approach to identifying colloca-tions.", "labels": [], "entities": []}, {"text": "This approach is based on the observation that true collocations, which cannot be translated word for word, will exhibit very different association scores before and after literal translation.", "labels": [], "entities": []}, {"text": "Our experiments in Japanese demonstrate that our cross-lingual association measure can successfully exploit the combination of bilingual dictionary and large monolingual corpora , outperforming monolingual association measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Collocations are part of the wide range of linguistic phenomena such as idioms (kick the bucket), compounds (single-mind) and fixed phrases (by and large) defined as Multiword Expressions (MWEs).", "labels": [], "entities": []}, {"text": "MWEs, and collocations, in particular, are very pervasive not only in English, but in other languages as well.", "labels": [], "entities": []}, {"text": "Although handling MWEs properly is crucial in many natural language processing (NLP) tasks, manually annotating them is a very costly and time consuming task.", "labels": [], "entities": []}, {"text": "The main goal of this work-in-progress is, therefore, to evaluate the effectiveness of a simple cross-lingual approach that allows us to automatically identify collocations in a corpus and subsequently distinguish them according to one of their intrinsic properties: the meaning of the expression cannot be predicted from the meaning of the parts, i.e. they are characterized by limited compositionality (.", "labels": [], "entities": []}, {"text": "Given an expression, we predict whether the expression(s) resulted from the word byword translation is also commonly used in another language.", "labels": [], "entities": []}, {"text": "If not, that might be evidence that the original expression is a collocation (or an idiom).", "labels": [], "entities": []}, {"text": "This can be captured by the ratio of association scores, assigned by association measures, in the target vs. source language.", "labels": [], "entities": []}, {"text": "The results indicate that our method improves the precision comparing with standard methods of MWE identification through monolingual association measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9995015859603882}, {"text": "MWE identification", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.9792067110538483}]}], "datasetContent": [{"text": "In our evaluation, we average the precision considering all true collocations and idioms as threshold points, obtaining the mean average precision (MAP).", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9993109703063965}, {"text": "mean average precision (MAP)", "start_pos": 124, "end_pos": 152, "type": "METRIC", "confidence": 0.853058805068334}]}, {"text": "Differently from the traditional approach used to evaluate an association measure, using MAP we do not need to set a hard threshold.", "labels": [], "entities": []}, {"text": "presents the MAP values for our proposed method and for the two baselines.", "labels": [], "entities": [{"text": "MAP", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9346380233764648}]}, {"text": "Our cross-lingual method performs best in terms of MAP values against the two baselines.", "labels": [], "entities": [{"text": "MAP", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.7982625961303711}]}, {"text": "We found out that it performs statistically better only compared to the Monolingual Association Measure baseline . The Monolingual Association Measure baseline performed worst, since free combinations were assigned high scores as well, and the system was notable to perform a clear separation into collocations and non-collocations.", "labels": [], "entities": []}, {"text": "The Phrase-Based SMT system obtained a higher MAP value than Monolingual Association measure, but the score maybe optimistic since we are testing in-domain.", "labels": [], "entities": [{"text": "Phrase-Based SMT", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.5087546855211258}, {"text": "MAP", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9849355220794678}]}, {"text": "One concern is that there are only a very few bilingual/parallel corpora for the Japanese/English language pair, in case we want to test with a different domain and larger test set.", "labels": [], "entities": []}, {"text": "The fact that our proposed method outperforms SMT implies that using such readily-available monolingual data (English Wikipedia) is a better way to exploit crosslingual information.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9871172308921814}, {"text": "English Wikipedia)", "start_pos": 110, "end_pos": 128, "type": "DATASET", "confidence": 0.906413753827413}]}, {"text": "Some cases where the system could not perform well include those where a collocation can also have a literal translation.", "labels": [], "entities": []}, {"text": "For instance, in Japanese, there is the collocation kokoro-wo-hiraku \"to open your heart\", where the literal translation of the noun kokoro \"heart\" and the verb hiraku \"open\" correspond to the translation of the expression as well.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on the Hiragana Times corpus  and Wikipedia corpus, showing the number of sen- tences, number of words and number of noun- verb and verb-noun expressions in English and  Japanese.", "labels": [], "entities": [{"text": "Hiragana Times corpus", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.9242612918217977}, {"text": "Wikipedia corpus", "start_pos": 55, "end_pos": 71, "type": "DATASET", "confidence": 0.8696222305297852}]}, {"text": " Table 2: Mean average precision of proposed  method and baselines.", "labels": [], "entities": [{"text": "Mean average", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.956434965133667}, {"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.5398944616317749}]}]}