{"title": [{"text": "Augmenting String-to-Tree and Tree-to-String Translation with Non-Syntactic Phrases", "labels": [], "entities": [{"text": "Augmenting String-to-Tree and Tree-to-String Translation", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.7460346996784211}]}], "abstractContent": [{"text": "We present an effective technique to easily augment GHKM-style syntax-based machine translation systems (Galley et al., 2006) with phrase pairs that do not comply with any syntactic well-formedness constraints.", "labels": [], "entities": [{"text": "GHKM-style syntax-based machine translation", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.6135300770401955}]}, {"text": "Non-syntactic phrase pairs are distinguished from syntactic ones in order to avoid harming effects.", "labels": [], "entities": []}, {"text": "We apply our technique in state-of-the-art string-to-tree and tree-to-string setups.", "labels": [], "entities": []}, {"text": "For tree-to-string translation, we furthermore investigate novel approaches for translating with source-syntax GHKM rules in association with input tree constraints and input tree features.", "labels": [], "entities": [{"text": "tree-to-string translation", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.7531861364841461}]}], "introductionContent": [{"text": "Syntax-based statistical machine translation systems utilize linguistic information that is obtained by parsing the training data.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.6355441610018412}]}, {"text": "In tree-to-string translation, source-side syntactic tree annotation is employed, while string-to-tree translation exploits target-side syntax.", "labels": [], "entities": []}, {"text": "The syntactic parse tree annotation constrains phrase extraction to syntactically well-formed phrase pairs: spans of syntactic phrases must match constituents in the parse tree.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7732642292976379}]}, {"text": "Standard phrase-based and hierarchical phrasebased statistical machine translation systems, in contrast, allow all phrase pairs that are consistent with the word alignment (.", "labels": [], "entities": [{"text": "phrasebased statistical machine translation", "start_pos": 39, "end_pos": 82, "type": "TASK", "confidence": 0.6017596423625946}]}, {"text": "A restriction of the phrase inventory to syntactically well-formed phrase pairs entails that possibly valuable information from the training data remains disregarded.", "labels": [], "entities": []}, {"text": "While we would expect phrase pairs that are not linguistically motivated to be less reliable, discarding them altogether might bean overly harsh decision.", "labels": [], "entities": []}, {"text": "The quality of an inventory of syntactic phrases depends heavily on the tree annotation scheme and the quality of the syntactic parses of the training data.", "labels": [], "entities": []}, {"text": "Phrase pairs that do not span constituents in the tree annotation obtained from syntactic parses can provide reasonable alternative segmentations or alternative translation options which prove to be valuable to the decoder.", "labels": [], "entities": []}, {"text": "In this work, we augment the phrase inventories of string-to-tree and tree-to-string translation systems with phrase pairs that are not induced in the syntax-based extraction.", "labels": [], "entities": []}, {"text": "We extract continuous phrases that are consistent with the word alignment, without enforcing any constraints with respect to syntactic tree annotation.", "labels": [], "entities": []}, {"text": "Non-syntactic phrases are added as rules to the baseline syntactic grammar with a fill-up technique.", "labels": [], "entities": []}, {"text": "New rules are only added if their right-hand side does not exist yet.", "labels": [], "entities": []}, {"text": "We extend the glue grammar with a special glue rule to allow for application of non-syntactic phrases during decoding.", "labels": [], "entities": []}, {"text": "A feature in the loglinear model combination serves to distinguish non-syntactic phrases from syntactic ones.", "labels": [], "entities": []}, {"text": "During decoding, the decoder can draw on both syntactic and non-syntactic phrase table entries and produce derivations which resort to both types of phrases.", "labels": [], "entities": []}, {"text": "Such derivations yield hypotheses that make use of the alternative segmentations and translation options provided through non-syntactic phrases.", "labels": [], "entities": []}, {"text": "The search space is more diverse, and in some cases all hypotheses from purely syntax-based derivations score worse than a translation that applies one or more non-syntactic phrases.", "labels": [], "entities": []}, {"text": "We empirically demonstrate that this technique can lead to substantial gains in translation quality.", "labels": [], "entities": []}, {"text": "Our syntactic translation models conform to the GHKM syntax approach as proposed by) with composed rules as in () and.", "labels": [], "entities": []}, {"text": "State-of-theart GHKM string-to-tree systems have recently shown very competitive performance in public evaluation campaigns.", "labels": [], "entities": []}, {"text": "We apply the GHKM approach not only in a string-to-tree setting as in previous work, but employ it to build tree-to-string systems as well.", "labels": [], "entities": []}, {"text": "We conduct tree-to-string translation with text input and additionally adopt translation with tree input and input tree constraints as suggested for hierarchical translation by.", "labels": [], "entities": []}, {"text": "We also implement translation with tree input and feature-driven soft tree matching.", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9709787964820862}, {"text": "feature-driven soft tree matching", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.671860858798027}]}, {"text": "The effect of augmenting the systems with nonsyntactic phrases is evaluated for all variants.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the effect of augmenting GHKM syntax-based translation systems-both string-totree and tree-to-string-with non-syntactic phrase pairs on the English\u2192German language pair using the standard newstest sets of the Workshop on Statistical Machine Translation (WMT) for testing.", "labels": [], "entities": [{"text": "GHKM syntax-based translation", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.6144070227940878}, {"text": "Statistical Machine Translation (WMT)", "start_pos": 233, "end_pos": 270, "type": "TASK", "confidence": 0.7847970426082611}]}, {"text": "The experiments are conducted with the opensource Moses implementations of GHKM rule extraction ( and decoding with CYK+ parsing and cube pruning ().", "labels": [], "entities": [{"text": "GHKM rule extraction", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.821110208829244}]}, {"text": "We work with an English-German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning and symmetrizing the two trained alignments.", "labels": [], "entities": []}, {"text": "For string-to-tree translation, we parse the German target side with BitPar ().", "labels": [], "entities": [{"text": "string-to-tree translation", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.5326594114303589}]}, {"text": "For tree-to-string translation, we parse the English source side of the parallel data with the English Berkeley Parser ().", "labels": [], "entities": [{"text": "tree-to-string translation", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6865783333778381}]}, {"text": "When extracting syntactic phrases, we impose several restrictions for composed rules, in particular a maximum number of twenty tree nodes per rule, a maximum depth of five, and a maximum size of five.", "labels": [], "entities": []}, {"text": "We discard rules with non-terminals on their right-hand side if they are singletons in the training data.", "labels": [], "entities": []}, {"text": "Only the 100 best translation options per distinct source side with respect to the weighted phrase-level model scores are loaded by the decoder.", "labels": [], "entities": []}, {"text": "The decoder is configured with a maximum chart span of 25 and a rule limit of 100.", "labels": [], "entities": [{"text": "rule limit", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9678940773010254}]}, {"text": "A standard set of models is used in the baselines, comprising phrase translation probabilities and lexical translation probabilities in both direc- tions, word and phrase penalty, an n-gram language model, a rule rareness penalty, and the monolingual PCFG probability of the tree fragment from which the rule was extracted ().", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.694345235824585}]}, {"text": "Phrase translation probabilities are smoothed via Good-Turing smoothing.", "labels": [], "entities": [{"text": "Phrase translation probabilities", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8533291419347128}]}, {"text": "The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing).", "labels": [], "entities": []}, {"text": "The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data.", "labels": [], "entities": [{"text": "German News Crawl corpora", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.9371353983879089}]}, {"text": "We use the SRILM toolkit) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding.", "labels": [], "entities": [{"text": "language model scoring", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.6556076804796854}]}, {"text": "Model weights are optimized to maximize BLEU () with batch MIRA (Cherry and Foster, 2012) on 1000-best lists.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9986730813980103}, {"text": "MIRA", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9608423113822937}]}, {"text": "We selected 2000 sentences from the newstest2008-2012 sets as a development set.", "labels": [], "entities": [{"text": "newstest2008-2012 sets", "start_pos": 36, "end_pos": 58, "type": "DATASET", "confidence": 0.9376620054244995}]}, {"text": "The selected sentences obtained high sentence-level BLEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9830076694488525}]}, {"text": "newstest2013 and newstest2014 are used as unseen test sets.", "labels": [], "entities": [{"text": "newstest2013", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9656273126602173}, {"text": "newstest2014", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.9231305122375488}]}, {"text": "Translation quality is measured in truecase with BLEU and TER).", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9335106611251831}, {"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9993591904640198}, {"text": "TER", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9957026839256287}]}, {"text": "We apply a phrase length limit of five when extracting non-syntactic phrases for the fill-up of syntactic phrase tables.", "labels": [], "entities": []}, {"text": "comprises the results of our empirical evaluation of the translation quality achieved by the different systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: English\u2192German experimental results (truecase). BLEU scores are given in percentage.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.998309850692749}]}]}