{"title": [{"text": "Preference Grammars and Soft Syntactic Constraints for GHKM Syntax-based Statistical Machine Translation", "labels": [], "entities": [{"text": "Syntax-based Statistical Machine Translation", "start_pos": 60, "end_pos": 104, "type": "TASK", "confidence": 0.5802361741662025}]}], "abstractContent": [{"text": "In this work, we investigate the effectiveness of two techniques fora feature-based integration of syntactic information into GHKM string-to-tree statistical machine translation (Galley et al., 2004): (1.)", "labels": [], "entities": [{"text": "GHKM string-to-tree statistical machine translation", "start_pos": 126, "end_pos": 177, "type": "TASK", "confidence": 0.7553428411483765}]}, {"text": "Preference grammars on the target language side promote syntactic well-formedness during decoding while also allowing for derivations that are not linguistically motivated (as in hierarchical translation).", "labels": [], "entities": []}, {"text": "Soft syntactic constraints augment the system with additional source-side syntax features while not modifying the set of string-to-tree translation rules or the baseline feature scores.", "labels": [], "entities": []}, {"text": "We conduct experiments with a state-of-the-art setup on an English\u2192German translation task.", "labels": [], "entities": [{"text": "English\u2192German translation task", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.69408198595047}]}, {"text": "Our results suggest that preference grammars for GHKM translation are inferior to the plain target-syntactified model, whereas the enhancement with soft source syntactic constraints provides consistent gains.", "labels": [], "entities": [{"text": "GHKM translation", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7402451634407043}]}, {"text": "By employing soft source syntactic constraints with sparse features, we are able to achieve improvements of up to 0.7 points BLEU and 1.0 points TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9991693496704102}, {"text": "TER", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.9951367974281311}]}], "introductionContent": [{"text": "Previous research in both formally syntax-based (i.e., hierarchical) and linguistically syntax-based statistical machine translation has demonstrated that significant quality gains can be achieved via integration of syntactic information as features in a non-obtrusive manner, rather than as hard constraints.", "labels": [], "entities": [{"text": "linguistically syntax-based statistical machine translation", "start_pos": 73, "end_pos": 132, "type": "TASK", "confidence": 0.6508212447166443}]}, {"text": "We implemented two feature-based extensions fora GHKM-style string-to-tree translation system (): \u2022 Preference grammars to soften the hard target-side syntactic constraints that are imposed by the target non-terminal labels.", "labels": [], "entities": [{"text": "GHKM-style string-to-tree translation", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.7759333252906799}]}, {"text": "\u2022 Soft source-side syntactic constraints that enhance the string-to-tree translation model with input tree features based on source syntax labels.", "labels": [], "entities": [{"text": "string-to-tree translation", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.7220010459423065}]}, {"text": "The empirical results on an English\u2192German translation task are twofold.", "labels": [], "entities": [{"text": "English\u2192German translation task", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6879366397857666}]}, {"text": "Target-side preference grammars do not show an improvement over the string-to-tree baseline with syntactified translation rules.", "labels": [], "entities": []}, {"text": "Source-side syntactic constraints, on the other hand, yield consistent moderate gains if applied as supplementary features in the string-totree setup.", "labels": [], "entities": []}], "datasetContent": [{"text": "We empirically evaluate the effectiveness of preference grammars and soft source syntactic constraints for GHKM translation on the English\u2192German language pair using the standard newstest sets of the Workshop on Statistical Machine Translation (WMT) for testing.", "labels": [], "entities": [{"text": "GHKM translation", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.6541878432035446}, {"text": "Statistical Machine Translation (WMT)", "start_pos": 212, "end_pos": 249, "type": "TASK", "confidence": 0.7948765357335409}]}, {"text": "The experiments are conducted with the open-source Moses implementations of GHKM rule extraction ( and decoding with CYK+ parsing and cube pruning ().", "labels": [], "entities": [{"text": "GHKM rule extraction", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.794308066368103}, {"text": "CYK+ parsing", "start_pos": 117, "end_pos": 129, "type": "TASK", "confidence": 0.6575232346852621}]}, {"text": "We work with an English-German parallel training corpus of around 4.5 M sentence pairs (after corpus cleaning).", "labels": [], "entities": []}, {"text": "The parallel data originates from three different sources which have been eligible for the constrained track of the ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task: Europarl (, News Commentary, and the Common Crawl corpus as provided on the WMT website.", "labels": [], "entities": [{"text": "ACL 2014 Ninth Workshop on Statistical Machine Translation shared translation task", "start_pos": 116, "end_pos": 198, "type": "TASK", "confidence": 0.663897611878135}, {"text": "Europarl", "start_pos": 200, "end_pos": 208, "type": "DATASET", "confidence": 0.8739343881607056}, {"text": "Common Crawl corpus", "start_pos": 237, "end_pos": 256, "type": "DATASET", "confidence": 0.812929650147756}, {"text": "WMT website", "start_pos": 276, "end_pos": 287, "type": "DATASET", "confidence": 0.967317134141922}]}, {"text": "Word alignments are created by aligning the data in both directions with MGIZA++ ( and symmetrizing the two trained alignments).", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.634852945804596}]}, {"text": "The German target side training data is parsed with BitPar).", "labels": [], "entities": [{"text": "German target side training data", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.6959646940231323}]}, {"text": "We remove grammatical case and function information from the annotation obtained with BitPar and apply right binarization of the German parse trees prior to rule extraction ().", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 157, "end_pos": 172, "type": "TASK", "confidence": 0.6749729216098785}]}, {"text": "For the soft source syntactic constraints, we parse the English source side of the parallel data with the English Berkeley Parser () and produce composite SAMT-style labels as discussed in Section 6.", "labels": [], "entities": []}, {"text": "When extracting syntactic rules, we impose several restrictions for composed rules, in particular a maximum number of 100 tree nodes per rule, a maximum depth of seven, and a maximum size of seven.", "labels": [], "entities": []}, {"text": "We discard rules with non-terminals on their right-hand side if they are singletons in the training data.", "labels": [], "entities": []}, {"text": "For efficiency reasons, we also enforce a limit on the number of label vectors that are stored as additional properties.", "labels": [], "entities": []}, {"text": "Label vectors are only stored if they occur at least as often as the 50th most frequent label vector of the given rule.", "labels": [], "entities": []}, {"text": "This limit is applied separately for both source-side label vectors (which are used by the soft syntactic contraints) and target-side label vectors (which are used by the preference grammar).", "labels": [], "entities": []}, {"text": "Only the 200 best translation options per distinct rule source side with respect to the weighted rule-level model scores are loaded by the decoder.", "labels": [], "entities": []}, {"text": "Search is carried outwith a maximum chart span of 25, a rule limit of 500, a stack limit of 200, and a k-best limit of 1000 for cube pruning.", "labels": [], "entities": []}, {"text": "A standard set of models is used in the baseline, comprising rule translation probabilities and lexical translation probabilities in both directions, word penalty and rule penalty, an n-gram language: English\u2192German experimental results (truecase).", "labels": [], "entities": []}, {"text": "BLEU scores are given in percentage.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.967445433139801}]}, {"text": "A selection of 2000 sentences from the newstest2008-2012 sets is used as development set.", "labels": [], "entities": [{"text": "newstest2008-2012 sets", "start_pos": 39, "end_pos": 61, "type": "DATASET", "confidence": 0.9451011717319489}]}, {"text": "model, a rule rareness penalty, and the monolingual PCFG probability of the tree fragment from which the rule was extracted ().", "labels": [], "entities": []}, {"text": "Rule translation probabilities are smoothed via Good-Turing smoothing.", "labels": [], "entities": [{"text": "Rule translation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7470056712627411}]}, {"text": "The language model (LM) is a large interpolated 5-gram LM with modified Kneser-Ney smoothing).", "labels": [], "entities": []}, {"text": "The target side of the parallel corpus and the monolingual German News Crawl corpora are employed as training data.", "labels": [], "entities": [{"text": "German News Crawl corpora", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.9371353983879089}]}, {"text": "We use the SRILM toolkit) to train the LM and rely on KenLM (Heafield, 2011) for language model scoring during decoding.", "labels": [], "entities": [{"text": "language model scoring", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.6556076606114706}]}, {"text": "Model weights are optimized to maximize BLEU () with batch MIRA (Cherry and Foster, 2012) on 1000-best lists.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9986730813980103}, {"text": "MIRA", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9608420133590698}]}, {"text": "We selected 2000 sentences from the newstest2008-2012 sets as a development set.", "labels": [], "entities": [{"text": "newstest2008-2012 sets", "start_pos": 36, "end_pos": 58, "type": "DATASET", "confidence": 0.9376620054244995}]}, {"text": "The selected sentences obtained high sentence-level BLEU scores when being translated with a baseline phrasebased system, and do each contain less than 30 words for more rapid tuning.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9830076694488525}]}, {"text": "newstest2013 and newstest2014 are used as unseen test sets.", "labels": [], "entities": [{"text": "newstest2013", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9656273126602173}, {"text": "newstest2014", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.9231305122375488}]}, {"text": "Translation quality is measured in truecase with BLEU and TER).", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9335106611251831}, {"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9993591904640198}, {"text": "TER", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9957026839256287}]}], "tableCaptions": [{"text": " Table 2: English\u2192German experimental results (truecase). BLEU scores are given in percentage.  A selection of 2000 sentences from the newstest2008-2012 sets is used as development set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9987126588821411}, {"text": "newstest2008-2012 sets", "start_pos": 135, "end_pos": 157, "type": "DATASET", "confidence": 0.9298104345798492}]}, {"text": " Table 3: English\u2192German experimental results (truecase). BLEU scores are given in percentage.  newstest2012 is used as development set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9987137317657471}, {"text": "newstest2012", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.884926974773407}]}]}