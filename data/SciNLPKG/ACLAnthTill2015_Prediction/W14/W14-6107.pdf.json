{"title": [{"text": "The effect of disfluencies and learner errors on the parsing of spoken learner language", "labels": [], "entities": [{"text": "parsing of spoken learner language", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.8458338499069213}]}], "abstractContent": [{"text": "NLP tools are typically trained on written data from native speakers.", "labels": [], "entities": []}, {"text": "However, research into language acquisition and tools for language teaching & proficiency assessment would benefit from accurate processing of spoken data from second language learners.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7251482456922531}, {"text": "proficiency assessment", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6797557175159454}]}, {"text": "In this paper we discuss manual annotation schemes for various features of spoken language; we also evaluate the automatic tagging of one particular feature (filled pauses)-finding a success rate of 81%; and we evaluate the effect of using our manual annotations to 'clean up' the transcriptions for sentence parsing, resulting in a 25% improvement in parse success rate by completely cleaning the texts of disfluencies and errors.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 300, "end_pos": 316, "type": "TASK", "confidence": 0.7061609178781509}]}, {"text": "We discuss the need to adapt existing NLP technology to non-canonical domains such as spoken learner language, while emphasising the worth of continued integration of manual and automatic annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language processing (NLP) tools are typically trained on written data from native speakers.", "labels": [], "entities": [{"text": "Natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7629360357920328}]}, {"text": "However, research into language acquisition and tools for language proficiency assessment & language teaching -such as learner dialogue and feedback systems -would benefit from accurate processing of spoken data from second language learners.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7419397830963135}, {"text": "language proficiency assessment", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.7945815126101176}]}, {"text": "Being able to convert the text from unparseable to parseable form will enable us to (a) posit a target hypothesis that the learner intended to produce, and (b) provide feedback on this target based on the information removed or repaired in achieving that parseable form.", "labels": [], "entities": []}, {"text": "To proceed towards this goal, we need to adapt current NLP tools to the non-canonical domain of spoken learner language in a persistent fashion rather than use ad hoc post-processing steps to 'correct' the non-canonical data.", "labels": [], "entities": []}, {"text": "Outcomes of this approach have been reported in the literature (e.g. in the biomedical domain; for spoken language).", "labels": [], "entities": []}, {"text": "These fully adaptive approaches require large amounts of annotated data to be successful and, as we intend to work along these lines in future, the discussion in this paper is pointed in that direction.", "labels": [], "entities": []}, {"text": "The work presented here will act as a foundation for more permanent adaptations to existing tools.", "labels": [], "entities": []}, {"text": "We annotate transcriptions of speech for linguistic features that are known to interfere with standard NLP to assess whether large-scale annotation of these features will be useful for training purposes.", "labels": [], "entities": []}, {"text": "Obvious instances of this include disfluencies (e.g. filled pauses, false starts, repetition), formal errors of morphology and syntax, as well as 'errors' of word and phrase selection . Since manual annotation is costly in terms of time and often money, one might question whether so many feature types are strictly necessary or even helpful for the task in hand.", "labels": [], "entities": [{"text": "word and phrase selection", "start_pos": 158, "end_pos": 183, "type": "TASK", "confidence": 0.6057590767741203}]}, {"text": "Indeed, filled pauses such as 'oh' and 'um' are already accounted for in the part-of-speech (POS) tagset we use (CLAWS2); and one might also argue that lexico-semantic errors might be dismissed a priori on the assumption that both the original and proposed forms are of the same POS (and thus won't affect a parser that performs tagging before the parse).", "labels": [], "entities": []}, {"text": "We investigate the contribution of these features to parsing success.", "labels": [], "entities": [{"text": "parsing success", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.90047487616539}]}, {"text": "From a theoretical perspective we are interested in these features with regard to second language acquisition and therefore need to analyse them closely.", "labels": [], "entities": [{"text": "second language acquisition", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.6281495988368988}]}, {"text": "In this paper we describe our initial efforts to address the challenge of parsing learner speech with tools trained on native speaker writing.", "labels": [], "entities": [{"text": "parsing learner speech", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.8502516349156698}]}, {"text": "We also present empirical results that demonstrate the utility of annotated spoken transcription with respect to both tagging and parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 130, "end_pos": 137, "type": "TASK", "confidence": 0.8235222101211548}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Error counts in our corpus", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.989968478679657}]}, {"text": " Table 2: POS tagging of filled pauses", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6909359991550446}]}, {"text": " Table 3: Mean parse likelihoods, deltas to baseline and parse success rates in all transcription modes", "labels": [], "entities": [{"text": "Mean parse likelihoods", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.7588092883427938}]}]}