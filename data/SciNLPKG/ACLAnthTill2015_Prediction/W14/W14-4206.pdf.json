{"title": [{"text": "Adapting Predicate Frames for Urdu PropBanking", "labels": [], "entities": [{"text": "Adapting Predicate Frames", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9174471696217855}, {"text": "PropBanking", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.5550047159194946}]}], "abstractContent": [{"text": "Hindi and Urdu are two standardized reg", "labels": [], "entities": []}], "introductionContent": [{"text": "Hindi and Urdu, spoken primarily in northern India and Pakistan, are socially and even officially considered two different language varieties.", "labels": [], "entities": []}, {"text": "However, such a division between the two is not established linguistically.", "labels": [], "entities": []}, {"text": "They are two standardized registers of what has been called the Hindustani language, which belongs to the Indo-Aryan language family.", "labels": [], "entities": []}, {"text": "explains that, while they are different languages officially, they are not even different dialects or sub-dialects in a linguistic sense; rather, they are different literary styles based on the same linguistically defined sub-dialect.", "labels": [], "entities": []}, {"text": "He further explains that at the colloquial level, Hindi and Urdu are nearly identical, both in terms of core vocabulary and grammar.", "labels": [], "entities": []}, {"text": "However, at formal and literary levels, vocabulary differences begin to loom much larger (Hindi drawing its higher lexicon from Sanskrit and Urdu from Persian and Arabic) to the point where the two styles/languages become mutually unintelligible.", "labels": [], "entities": []}, {"text": "In written form, not only the vocabulary but the way Urdu and Hindi are written makes one believe that they are two separate languages.", "labels": [], "entities": []}, {"text": "They are written in separate orthographies, Hindi being written in Devanagari, and Urdu in a modified Persio-Arabic script.", "labels": [], "entities": []}, {"text": "Given such (apparent) divergences between the two varieties, two parallel treebanks are being built under The Hindi-Urdu treebanking.", "labels": [], "entities": [{"text": "The Hindi-Urdu treebanking", "start_pos": 106, "end_pos": 132, "type": "DATASET", "confidence": 0.6829890807469686}]}, {"text": "Both the treebanks follow a multi-layered and multi-representational framework which features Dependency, PropBank and Phrase Structure annotations.", "labels": [], "entities": []}, {"text": "Among the two treebanks the Hindi treebank is ahead of the Urdu treebank across all layers.", "labels": [], "entities": [{"text": "Hindi treebank", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9103985726833344}, {"text": "Urdu treebank", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.8230101466178894}]}, {"text": "In the case of PropBanking, the Hindi treebank has made considerable progress while Urdu PropBanking has just started.", "labels": [], "entities": [{"text": "Hindi treebank", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9203652441501617}]}, {"text": "The creation of predicate frames is the first step in PropBanking, which is followed by the actual annotation of verb instances in corpora.", "labels": [], "entities": []}, {"text": "In this paper, we look at the possibility of porting related frames from Arabic and Hindi PropBanks for Urdu PropBanking.", "labels": [], "entities": []}, {"text": "Given that Urdu shares its vocabulary with Arabic, Hindi and Persian, we look at verbal and nominal predicates that Urdu shares with these languages and try to port and adapt their frames from the respective PropBanks instead of creating them afresh.", "labels": [], "entities": []}, {"text": "This implies that identification of the source of Urdu predicates becomes a necessary step in this process.", "labels": [], "entities": [{"text": "identification of the source of Urdu predicates", "start_pos": 18, "end_pos": 65, "type": "TASK", "confidence": 0.6918932625225612}]}, {"text": "Thus, in order to port the relevant frames, we need to first identify the source of Urdu predicates and then extract their frames from the related PropBanks.", "labels": [], "entities": [{"text": "PropBanks", "start_pos": 147, "end_pos": 156, "type": "DATASET", "confidence": 0.9525418877601624}]}, {"text": "To state briefly, we present the following as contributions of this paper: \u2022 Automatic identification of origin or source of Urdu vocabulary.", "labels": [], "entities": []}, {"text": "\u2022 Porting and adapting nominal and verbal predicate frames from the PropBanks of related languages.", "labels": [], "entities": []}, {"text": "The rest of the paper is organised as follows: In the next Section we discuss the Hindi-Urdu treebanking project with the focus on PropBanking.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss our efforts to automatically identify the source of Urdu vocabulary and in Section 4, we discuss the process of adapting and porting Arabic and Hindi frames for Urdu PropBanking.", "labels": [], "entities": []}, {"text": "Finally we conclude with some future directions in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out a number of experiments in order to explore the effect of data size and the order of n-gram models on the classification performance.", "labels": [], "entities": [{"text": "classification", "start_pos": 121, "end_pos": 135, "type": "TASK", "confidence": 0.9616381525993347}]}, {"text": "By varying the size of training data, we wanted to identify the lower bound on the training size with respect to the classification performance.", "labels": [], "entities": []}, {"text": "We varied the training size per training iteration by 1% for n-grams in the order 1-5 for both the classification problems.", "labels": [], "entities": []}, {"text": "For each n-gram order 100 experiments were carried out, i.e overall 800 experiments for binary and tri-class classification.", "labels": [], "entities": []}, {"text": "The impact of training size on the classification performance is shown in and for binary and tri-class classification respectively.", "labels": [], "entities": []}, {"text": "As expected, at every iteration the additional data points introduced into the training data increased the performance of the model.", "labels": [], "entities": []}, {"text": "With a mere 3% of the training data, we could reach a reasonable accuracy of 0.85 in terms of F-score for binary classification and for tri-class classification we reached the same accuracy with 6% of the data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9995336532592773}, {"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.998420238494873}, {"text": "binary classification", "start_pos": 106, "end_pos": 127, "type": "TASK", "confidence": 0.6520761549472809}, {"text": "tri-class classification", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.6502985507249832}, {"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9978852868080139}]}, {"text": "Similarly, we tried different order n-gram models to quantify the effect of character context on the classification performance.", "labels": [], "entities": []}, {"text": "As with the increase in data size, increasing the n-gram order profoundly improved the results.", "labels": [], "entities": []}, {"text": "In both the classification tasks, unigram based models converge faster than the higher order n-gram based models.", "labels": [], "entities": []}, {"text": "The obvious reason for it is the small, finite set of characters that a language operates with.", "labels": [], "entities": []}, {"text": "A small set of words (unique in our case) is probably enough to capture at least a single instance of each character.", "labels": [], "entities": []}, {"text": "As no new n-gram is introduced with subsequent additions of new tokens in the training data, the accuracy stabilizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9995916485786438}]}, {"text": "However, the accuracy with higher order n-grams kept on increasing with an increase in the data size, though it was marginal after 5-grams.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.999554455280304}]}, {"text": "The abrupt increase after 8,000 training instances is probably due to the addition of an unknown bigram sequence(s) to the training data.", "labels": [], "entities": []}, {"text": "In particular, the Recall of PersioArabic increased by 2.2%.", "labels": [], "entities": [{"text": "the", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9935318231582642}, {"text": "Recall of PersioArabic", "start_pos": 19, "end_pos": 41, "type": "METRIC", "confidence": 0.7340961297353109}]}], "tableCaptions": [{"text": " Table 3: Statistics of Etymological Data", "labels": [], "entities": []}, {"text": " Table 4: Results of 10-fold Cross Validation on  Binary Classification", "labels": [], "entities": [{"text": "Binary Classification", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.8599445223808289}]}, {"text": " Table 5: Results of 10-fold Cross Validation on  Tri-Class Classification", "labels": [], "entities": [{"text": "Cross Validation", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.6103001087903976}]}, {"text": " Table 6: Confusion Matrix of Binary Classifica- tion", "labels": [], "entities": []}, {"text": " Table 7: Confusion Matrix of Tri-class Classifica- tion", "labels": [], "entities": []}, {"text": " Table 8: Urdu Treebank Predicate Statistics", "labels": [], "entities": [{"text": "Urdu Treebank", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.9697515964508057}, {"text": "Predicate", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.42505499720573425}]}]}