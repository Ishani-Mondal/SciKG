{"title": [{"text": "Handling OOV Words in Dialectal Arabic to English Machine Translation", "labels": [], "entities": [{"text": "Handling OOV Words in Dialectal Arabic to English Machine Translation", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.5798849552869797}]}], "abstractContent": [{"text": "Dialects and standard forms of a language typically share a set of cognates that could bear the same meaning in both varieties or only be shared homographs but serve as faux amis.", "labels": [], "entities": []}, {"text": "Moreover, there are words that are used exclusively in the dialect or the standard variety.", "labels": [], "entities": []}, {"text": "Both phenomena, faux amis and exclusive vocabulary, are considered out of vocabulary (OOV) phenomena.", "labels": [], "entities": []}, {"text": "In this paper, we present this problem of OOV in the context of machine translation.", "labels": [], "entities": [{"text": "OOV", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8499132394790649}, {"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7848784029483795}]}, {"text": "We present anew approach for dialect to English Statistical Machine Translation (SMT) enhancement based on normalizing dialectal language into standard form to provide equivalents to address both aspects of the OOV problem posited by di-alectal language use.", "labels": [], "entities": [{"text": "English Statistical Machine Translation (SMT) enhancement", "start_pos": 40, "end_pos": 97, "type": "TASK", "confidence": 0.7407301366329193}]}, {"text": "We specifically focus on Arabic to English SMT.", "labels": [], "entities": [{"text": "Arabic to English SMT", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.5526489317417145}]}, {"text": "We use two publicly available dialect identification tools: AIDA and MADAMIRA, to identify and replace dialectal Arabic OOV words with their modern standard Arabic (MSA) equivalents.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7501703798770905}, {"text": "AIDA", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.7134788632392883}, {"text": "MADAMIRA", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9283000230789185}]}, {"text": "The results of evaluation on two blind test sets show that using AIDA to identify and replace MSA equivalents enhances translation results by 0.4% absolute BLEU (1.6% relative BLEU) and using MADAMIRA achieves 0.3% absolute BLEU (1.2% relative BLEU) enhancement over the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9433589577674866}, {"text": "BLEU", "start_pos": 176, "end_pos": 180, "type": "METRIC", "confidence": 0.8597160577774048}, {"text": "BLEU", "start_pos": 224, "end_pos": 228, "type": "METRIC", "confidence": 0.9133986830711365}, {"text": "BLEU) enhancement", "start_pos": 244, "end_pos": 261, "type": "METRIC", "confidence": 0.9068845709164938}]}, {"text": "We show our replacement scheme reaches a noticeable enhancement in SMT performance for faux amis words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.992228090763092}]}], "introductionContent": [{"text": "In this day of hyper connectivity, spoken vernaculars are ubiquitously evermore present in textual social media and informal communication channels.", "labels": [], "entities": []}, {"text": "Written (very close to the spoken) informal language as represented by dialect poses a significant challenge to current natural language processing (NLP) technology in general due to the lack of standards for writing in these vernaculars.", "labels": [], "entities": []}, {"text": "The problem is exacerbated when the vernacular constitutes a dialect of the language that is quite distinct and divergent from a language standard and people code switch within utterance between the standard and the dialect.", "labels": [], "entities": []}, {"text": "This is the case for Arabic.", "labels": [], "entities": []}, {"text": "Modern Standard Arabic (MSA), as the name indicates, is the official standard for the Arabic language usually used informal settings, while its vernaculars vary from it significantly forming dialects known as dialectal Arabic (DA), commonly used in informal settings such as the web and social media.", "labels": [], "entities": []}, {"text": "Contemporary Arabic is a collection of these varieties.", "labels": [], "entities": []}, {"text": "Unlike MSA, DA has no standard orthography.", "labels": [], "entities": []}, {"text": "Most of the studies in Arabic NLP have been conducted on MSA.", "labels": [], "entities": [{"text": "Arabic NLP", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.5177108645439148}]}, {"text": "NLP research on DA, the unstandardized spoken variety of Arabic, is still at its infancy.", "labels": [], "entities": []}, {"text": "This constitutes a problem for Arabic processing in general due to the ubiquity of DA usage in written social media.", "labels": [], "entities": [{"text": "Arabic processing", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.6688633263111115}]}, {"text": "Moreover, linguistic code switching between MSA and DA always happens either in the course of a single sentence or across different sentences.", "labels": [], "entities": [{"text": "linguistic code switching", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6040914158026377}]}, {"text": "However this intrasentential code switching is quite pervasive ( ).", "labels": [], "entities": [{"text": "code switching", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.6995221376419067}]}, {"text": "For instance 98.13% of sentences crawled from Egyptian DA (EGY) discussion forums for the COLABA project () contains intrasentential code switching.", "labels": [], "entities": [{"text": "Egyptian DA (EGY) discussion forums for the COLABA project", "start_pos": 46, "end_pos": 104, "type": "DATASET", "confidence": 0.8270810300653632}]}, {"text": "MSA has a wealth of NLP tools and resources compared to a stark deficiency in such resources for DA.", "labels": [], "entities": []}, {"text": "The mix of MSA and DA in utterances constitutes a significant problem of Out of Vocabulary (OOV) words in the input to NLP applications.", "labels": [], "entities": [{"text": "DA", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9243444800376892}]}, {"text": "The OOV problem is two fold: completely unseen words in training data, and homograph OOVs where the word appears in the training data but with a different sense.", "labels": [], "entities": []}, {"text": "Given these issues, DA NLP and especially DA statistical machine translation (SMT) can be seen as highly challenging tasks and this illustrates the need for conducting more research on DA.", "labels": [], "entities": [{"text": "DA NLP", "start_pos": 20, "end_pos": 26, "type": "TASK", "confidence": 0.8791922032833099}, {"text": "DA statistical machine translation (SMT)", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.7194014532225472}]}, {"text": "MSA has a wealth of resources such as parallel corpora and tools like morphological analyzers, disambiguation systems, etc.", "labels": [], "entities": []}, {"text": "On the other hand, DA still lacks such tools and resources.", "labels": [], "entities": [{"text": "DA", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.8102298974990845}]}, {"text": "As an example, parallel DA to English (EN) corpora are still very few and there are almost no MSA-DA parallel corpora.", "labels": [], "entities": []}, {"text": "Similar to MSA, DA has the problem of writing with optional diacritics.", "labels": [], "entities": []}, {"text": "It also lacks orthographic standards.", "labels": [], "entities": []}, {"text": "Hence, translating from DA to EN is challenging as there are impediments posed by the nature of the language coupled with the lack of resources and tools to process DA (.", "labels": [], "entities": [{"text": "translating from DA to EN", "start_pos": 7, "end_pos": 32, "type": "TASK", "confidence": 0.8191445112228394}]}, {"text": "MSA and DA are significantly different on all levels of linguistic representation: phonologically, morphologically, lexically, syntactically, semantically and pragmatically.", "labels": [], "entities": []}, {"text": "The morphological differences between MSA and DA are most noticeably expressed by using some clitics and affixes that do not exist in MSA.", "labels": [], "entities": []}, {"text": "For instance, the DA (Egyptian and Levantine) future marker clitic H 1 is expressed as the clitic sin MSA.", "labels": [], "entities": []}, {"text": "On a lexical level, MSA and DA share a considerable number of faux amis where the lexical tokens are homographs but have different meanings.", "labels": [], "entities": []}, {"text": "For instance the word yEny in MSA means 'to mean', but in DA, it is a pragmatic marker meaning 'to some extent'.", "labels": [], "entities": []}, {"text": "We refer to this phenomenon as sense OOV (SOOV).", "labels": [], "entities": [{"text": "OOV", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.5505849123001099}]}, {"text": "This phenomenon is in addition to the complete OOV (COOV) that exist in DA but don't exist in MSA.", "labels": [], "entities": [{"text": "OOV", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9780442118644714}]}, {"text": "These issues constitute a significant problem for processing DA using MSA trained tools.", "labels": [], "entities": [{"text": "processing DA", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.6743087023496628}]}, {"text": "This problem is very pronounced in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7460064888000488}]}, {"text": "In this paper, we present anew approach to build a DA-to-EN MT system by normalizing DA words into MSA.", "labels": [], "entities": [{"text": "DA-to-EN MT", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.664067268371582}]}, {"text": "We focus our investigation on the Egyptian variety of DA (EGY).", "labels": [], "entities": [{"text": "Egyptian variety of DA (EGY)", "start_pos": 34, "end_pos": 62, "type": "DATASET", "confidence": 0.5667489043303898}]}, {"text": "We leverage MSA resources with robust DA identification tools to improve SMT performance for DA-to-EN SMT.", "labels": [], "entities": [{"text": "DA identification", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.920067310333252}, {"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.996249258518219}, {"text": "DA-to-EN SMT", "start_pos": 93, "end_pos": 105, "type": "TASK", "confidence": 0.624536782503128}]}, {"text": "We focus our efforts on replacing identified DA words by MSA counterparts.", "labels": [], "entities": [{"text": "replacing identified DA words", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.7133909165859222}]}, {"text": "We investigate the replacement specifically in the decoding phase of the SMT pipeline.", "labels": [], "entities": [{"text": "SMT pipeline", "start_pos": 73, "end_pos": 85, "type": "TASK", "confidence": 0.8424347043037415}]}, {"text": "We explore two state of the art DA identification tools for the purposes of our study.", "labels": [], "entities": [{"text": "DA identification", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.9546487629413605}]}, {"text": "We demonstrate the effects of our replacement scheme on each OOV type and show that normalizing DA words into their equivalent MSA considerably enhances SMT performance in translating SOOVs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 153, "end_pos": 156, "type": "TASK", "confidence": 0.9958310723304749}]}, {"text": "The remainder of this paper is organized as follows: Section 2 overviews related work; Section 3 details our approach; Section 4 presents the results obtained on standard data sets; in Section 5, we discuss the results and perform error analysis; finally we conclude with some further observations in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run the SMT pipeline using the feature weights that performed best during the tuning session on our dev set.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.987534761428833}]}, {"text": "Then the SMT pipeline with these tuned weights is run on two blind test sets.", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9899172186851501}]}, {"text": "To account for statistical significance tests we used bootstrapping methods as detailed in. shows BLEU scores of different DA identification and replacement schemes exploited in different setups on the test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9992207288742065}, {"text": "DA identification and replacement", "start_pos": 123, "end_pos": 156, "type": "TASK", "confidence": 0.8049981743097305}]}, {"text": "As we can see in, both AIDA and MADAMIRA replacement schemes outperform the baseline scores using MSA+DA trained models and lem+POS-to-lex;lex-to-lex setup.", "labels": [], "entities": [{"text": "MADAMIRA", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7770915627479553}]}, {"text": "AIDA reaches 0.4% absolute BLEU (1.6% relative BLEU) improvement and MADAMIRA achieves 0.3% absolute BLEU (1.2% relative BLEU) enhancement over the corresponding baselines.", "labels": [], "entities": [{"text": "AIDA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8226913213729858}, {"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9135807156562805}, {"text": "BLEU) improvement", "start_pos": 47, "end_pos": 64, "type": "METRIC", "confidence": 0.9320016304651896}, {"text": "MADAMIRA", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.8592959046363831}, {"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9454680681228638}, {"text": "BLEU) enhancement", "start_pos": 121, "end_pos": 138, "type": "METRIC", "confidence": 0.9259715874989828}]}, {"text": "This is while the same enhancement in BLEU scores cannot be captured when we exploit the model", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9984104633331299}]}], "tableCaptions": [{"text": " Table 1: Baseline BLUE scores for each setup on two test sets: BOLT-arz-test and MT09-test. Results  are reported for each training input language variety separately.", "labels": [], "entities": [{"text": "BLUE", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9613990783691406}, {"text": "BOLT-arz-test", "start_pos": 64, "end_pos": 77, "type": "METRIC", "confidence": 0.9958831071853638}, {"text": "MT09-test", "start_pos": 82, "end_pos": 91, "type": "DATASET", "confidence": 0.9064661264419556}]}, {"text": " Table 2: BLEU scores of AIDA and MADAMIRA replacement for the different setups on  BOLT-arz-test and MT09-test. Results are reported for each training language variety separately.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992232322692871}, {"text": "AIDA", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.6672695875167847}, {"text": "MADAMIRA", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8058652281761169}, {"text": "BOLT-arz-test", "start_pos": 84, "end_pos": 97, "type": "METRIC", "confidence": 0.9708789587020874}, {"text": "MT09-test", "start_pos": 102, "end_pos": 111, "type": "DATASET", "confidence": 0.9137347936630249}]}, {"text": " Table 3: Number of sentences, types, tokens and  COOV percentages in each test set", "labels": [], "entities": [{"text": "COOV percentages", "start_pos": 50, "end_pos": 66, "type": "METRIC", "confidence": 0.9791409075260162}]}, {"text": " Table 5: Columns from left to right: number of DA COOV, SOOV and percentages of enhanced  sentences for BOLT-arz set.", "labels": [], "entities": [{"text": "DA COOV", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.7579573392868042}, {"text": "SOOV", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9861469864845276}, {"text": "BOLT-arz", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.8894687294960022}]}]}