{"title": [{"text": "Language variety identification in Spanish tweets", "labels": [], "entities": [{"text": "Language variety identification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7428629299004873}]}], "abstractContent": [{"text": "We study the problem of language variant identification, approximated by the problem of labeling tweets from Spanish speaking countries by the country from which they were posted.", "labels": [], "entities": [{"text": "language variant identification", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.7351384659608206}]}, {"text": "While this task is closely related to \"pure\" language identification , it comes with additional complications.", "labels": [], "entities": [{"text": "pure\" language identification", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.6339575126767159}]}, {"text": "We build a balanced collection of tweets and apply techniques from language modeling.", "labels": [], "entities": []}, {"text": "A simplified version of the task is also solved by human test subjects, who are outperformed by the automatic classification.", "labels": [], "entities": []}, {"text": "Our best automatic system achieves an overall F-score of 67.7% on 5-class classification.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9992836117744446}]}], "introductionContent": [{"text": "Spanish (or castellano), a descendant of Latin, is currently the language with the second largest number of native speakers after Mandarin Chinese, namely around 414 million people ().", "labels": [], "entities": []}, {"text": "Spanish has a large number of regional varieties across Spain and the Americas.", "labels": [], "entities": []}, {"text": "They diverge in spoken language and vocabulary and also, albeit to a lesser extent, in syntax.", "labels": [], "entities": []}, {"text": "Between different American varieties of Spanish, there are important differences; however, the largest differences can be found between American and European (\"Peninsular\") Spanish.", "labels": [], "entities": []}, {"text": "Language identification, the task of automatically identifying the natural language used in a given text segment, is a relatively well understood problem (see Section 2).", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7458010613918304}, {"text": "automatically identifying the natural language used in a given text segment", "start_pos": 37, "end_pos": 112, "type": "TASK", "confidence": 0.4857801307331432}]}, {"text": "To our knowledge, however, there is little previous work on the identification of the varieties of a single language, such as the regional varieties of Spanish.", "labels": [], "entities": []}, {"text": "This task is especially challenging because the differences between variants are subtle, making it difficult to discern between them.", "labels": [], "entities": []}, {"text": "This is evidenced by the fact that humans that are native speakers of the varieties are often unable to solve the problem, particularly when given short, noisy text segments (which are the focus of this work) where the amount of available information is limited.", "labels": [], "entities": []}, {"text": "In this paper, we approximate the problem of language variety identification by the problem of classifying status messages from the microblogging service Twitter (\"tweets\") from Spanish speaking countries by the country from which they were sent.", "labels": [], "entities": [{"text": "language variety identification", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.7351284623146057}]}, {"text": "With the tweet, the location of the device from which the tweet was sent can be recorded (depending on the Twitter users' permission) and can then be retrieved from the metadata of the tweet.", "labels": [], "entities": []}, {"text": "The tweet location information does not always correlate with the actual language variety used in the tweet: it is conceivable, e.g., that migrants do not use the prevalent language variety of the country in which they live, but rather their native variety.", "labels": [], "entities": []}, {"text": "Nevertheless, Twitter can give a realistic picture of actual language use in a certain region, which, additionally, is closer to spoken than to standard written language.", "labels": [], "entities": []}, {"text": "Eventually and more importantly, Twitter data is available from almost all Spanish speaking countries.", "labels": [], "entities": []}, {"text": "We build a balanced collection of tweets sent by Twitter users from five countries, namely Argentina, Chile, Colombia, Mexico, and Spain.", "labels": [], "entities": []}, {"text": "Applying different methods, we perform an automatic classification between all countries.", "labels": [], "entities": []}, {"text": "In order to obtain a more detailed view of the difficulty of our task, we also investigate human performance.", "labels": [], "entities": []}, {"text": "For this purpose, we build a smaller sample of tweets from Argentina, Chile and Spain and have them classified by both our system and three native human evaluators.", "labels": [], "entities": []}, {"text": "The results show that automatic classification outperforms human annotators.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.6931865513324738}]}, {"text": "The best variant of our system, using a meta-classifier with voting, reaches an overall F-score of 67.72 on the fiveclass problem.", "labels": [], "entities": [{"text": "F-score", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9996625185012817}]}, {"text": "On the two-class problem, human classification is outperformed by a large margin.", "labels": [], "entities": [{"text": "human classification", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.688250407576561}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In the following section, we present related work.", "labels": [], "entities": []}, {"text": "Section 3 presents our data collection.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present our classification methodology and the experiments.", "labels": [], "entities": []}, {"text": "Section 7 discusses the results, and Section 8 concludes the article.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results (F 1 ): n-gram frequency profiles  (classes/profile sizes)", "labels": [], "entities": []}, {"text": " Table 2: Results: n-gram frequency profile with  500 n-grams", "labels": [], "entities": []}, {"text": " Table 3: Confusion matrix (n-gram freq. profiles,  500 n-grams)", "labels": [], "entities": []}, {"text": " Table 4: Results: 6-grams without pruning", "labels": [], "entities": []}, {"text": " Table 5: Confusion matrix (6-grams, no pruning)", "labels": [], "entities": []}, {"text": " Table 6: Results (F 1 ): Syllable 4-gram lm", "labels": [], "entities": []}, {"text": " Table 7: Results (F 1 ): LZW without ties", "labels": [], "entities": []}, {"text": " Table 9: Results: Human vs. automatic classifica- tion", "labels": [], "entities": []}, {"text": " Table 10: Results: Human vs. automatic classifi- cation (filtered)", "labels": [], "entities": []}, {"text": " Table 12: Results: Filtered by langid.py", "labels": [], "entities": []}]}