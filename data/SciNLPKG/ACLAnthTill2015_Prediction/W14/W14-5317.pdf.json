{"title": [{"text": "Experiments in Sentence Language Identification with Groups of Similar Languages", "labels": [], "entities": [{"text": "Sentence Language Identification", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.8758211334546407}]}], "abstractContent": [{"text": "Language identification is a simple problem that becomes much more difficult when its usual assumptions are broken.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6842173486948013}]}, {"text": "In this paper we consider the task of classifying short segments of text in closely-related languages for the Discriminating Similar Languages shared task, which is broken into six subtasks, (A) Bosnian, Croatian, and Serbian, (B) Indonesian and Malay, (C) Czech and Slovak, (D) Brazilian and European Portuguese, (E) Argentinian and Peninsular Spanish, and (F) American and British English.", "labels": [], "entities": [{"text": "classifying short segments of text", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.8474471569061279}, {"text": "Discriminating Similar Languages shared task", "start_pos": 110, "end_pos": 154, "type": "TASK", "confidence": 0.751006293296814}]}, {"text": "We consider a number of different methods to boost classification performance, such as feature selection and data filtering, but we ultimately find that a simple na\u00a8\u0131vena\u00a8\u0131ve Bayes classifier using character and word n-gram features is a strong baseline that is difficult to improve on, achieving an average accuracy of 0.8746 across the six tasks.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7116009742021561}, {"text": "data filtering", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.7449320554733276}, {"text": "accuracy", "start_pos": 308, "end_pos": 316, "type": "METRIC", "confidence": 0.9990525841712952}]}], "introductionContent": [{"text": "Language identification constitutes the first stage of many NLP pipelines.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6922275722026825}]}, {"text": "Before applying tools trained on specific languages, one must determine the language of the text.", "labels": [], "entities": []}, {"text": "It is also is often considered to be a solved task because of the high accuracy of language identification methods in the canonical formulation of the problem with long monolingual documents and a set of mostly dissimilar languages to choose from.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9987484216690063}, {"text": "language identification", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.7183676362037659}]}, {"text": "We consider a different setting with much shorter text in the form of single sentences drawn from very similar languages or dialects.", "labels": [], "entities": []}, {"text": "This paper describes experiments related to and our submissions to the Discriminating Similar Languages (DSL) shared task.", "labels": [], "entities": [{"text": "Discriminating Similar Languages (DSL) shared task", "start_pos": 71, "end_pos": 121, "type": "TASK", "confidence": 0.6650490909814835}]}, {"text": "This shared task has six subtasks, each a classification task in which a sentence must be labeled as belonging to a small set of related languages: \u2022  The first three tasks involve classes that could be rightly called separate languages or dialects.", "labels": [], "entities": []}, {"text": "The classes of each of the final three tasks have high mutual intelligibility and are so similar that some linguists may not even classify them as separate dialects.", "labels": [], "entities": []}, {"text": "We will use the term \"language variant\" to refer to such classes.", "labels": [], "entities": []}, {"text": "In this paper we experiment with several types of methods aimed at improving the classification accuracy of these tasks: machine learning methods, data pre-processing, feature selection, and additional training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.876358687877655}, {"text": "feature selection", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.714374378323555}]}, {"text": "We find that a simple na\u00a8\u0131vena\u00a8\u0131ve Bayes classifier using character and word n-gram features is a strong baseline that is difficult to improve on.", "labels": [], "entities": []}, {"text": "Because this paper covers so many different types of methods, its format eschews the standard \"Results\" section, instead providing comparisons of methods as they are presented.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sources and amounts of training data collected for the open track for each task.", "labels": [], "entities": []}, {"text": " Table 2: Accuracies compared for different sets of features compared. The classifier used here is na\u00a8\u0131vena\u00a8\u0131ve  Bayes.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9970431923866272}]}, {"text": " Table 3: Comparison of different machine learning methods using word unigram features on the six  tasks.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of manual and automatic feature selection methods. IG and parallel feature selec- tion both use the 10,000 features with the highest IG scores.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of data filtering methods using word unigram features on the six tasks.", "labels": [], "entities": []}]}