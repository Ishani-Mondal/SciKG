{"title": [{"text": "How Well Can a Corpus-Derived Co-Occurrence Network Simulate Human Associative Behavior?", "labels": [], "entities": [{"text": "Corpus-Derived Co-Occurrence Network Simulate Human Associative Behavior", "start_pos": 15, "end_pos": 87, "type": "TASK", "confidence": 0.7113034469740731}]}], "abstractContent": [{"text": "Free word associations are the words people spontaneously come up within response to a stimulus word.", "labels": [], "entities": []}, {"text": "Such information has been collected from test persons and stored in databases.", "labels": [], "entities": []}, {"text": "A well known example is the Edinburgh Associative Thesaurus (EAT).", "labels": [], "entities": [{"text": "Edinburgh Associative Thesaurus (EAT)", "start_pos": 28, "end_pos": 65, "type": "DATASET", "confidence": 0.9400783777236938}]}, {"text": "We will show in this paper that this kind of knowledge can be acquired automatically from corpora, enabling the computer to produce similar associative responses as people do.", "labels": [], "entities": []}, {"text": "While in the past test sets typically consisted of approximately 100 words, we will use here a large part of the EAT which, in total , comprises 8400 words.", "labels": [], "entities": []}, {"text": "Apart from extending the test set, we consider different properties of words: saliency, frequency and part-of-speech.", "labels": [], "entities": []}, {"text": "For each feature categorize our test set, and we compare the simulation results to those based on the EAT.", "labels": [], "entities": [{"text": "EAT", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.8409829139709473}]}, {"text": "It turns out that there are surprising similarities which supports our claim that a corpus-derived co-occurrence network can simulate human asso-ciative behavior, i.e. an important part of language acquisition and verbal behavior.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 189, "end_pos": 209, "type": "TASK", "confidence": 0.6976228207349777}]}], "introductionContent": [{"text": "Word associations in general and free word association in particular (Galton, 1879) have been used by psychologists of various schools 1 to understand the human mind (memory, cognition, language) and the hidden mechanisms driving peoples' thoughts, utterances, and actions.", "labels": [], "entities": []}, {"text": "In the case of free word associations, a person typically hears or reads a word, and is asked to produce the first other word coming to mind.", "labels": [], "entities": []}, {"text": "have used this method for compar-isons, introducing to this end 100 emotionally neutral test words.", "labels": [], "entities": []}, {"text": "Having conducted the first large scale study of word associations (1000 test persons) they reached the conclusion that there was a great uniformity concerning people's associations, that is, speakers of a language share stable, comparable associative networks.", "labels": [], "entities": []}, {"text": "In this paper, we are mainly interested in the automatic acquisition of associations by computer.", "labels": [], "entities": [{"text": "automatic acquisition of associations", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.674736276268959}]}, {"text": "More precisely, we want to check whether a corpus-based method allows us to build automatically an associative network akin to the one in peoples' mind, that is, a network able to mimic human behavior.", "labels": [], "entities": []}, {"text": "This means, given a stimulus word the system is supposed to produce the same responses as people do.", "labels": [], "entities": []}, {"text": "We know since the old Greeks that thoughts and their expressions (words) are linked via associations.", "labels": [], "entities": []}, {"text": "Yet, what we still do not know is the nature of these links.", "labels": [], "entities": []}, {"text": "Also, links vary in terms of strength.", "labels": [], "entities": []}, {"text": "Associationist learning theory explains how these strengths (or weights) are acquired.", "labels": [], "entities": []}, {"text": "The strength between two perceived events increases by a constant fraction of a maximally possible increment at each co-occurrence, and decreases in the opposite case.", "labels": [], "entities": []}, {"text": "have shown that this mechanism can be replicated by looking at word co-occurrence frequencies in large text collections.", "labels": [], "entities": []}, {"text": "But there had been earlier corpus-linguistic work: For example, compared several association measures in order to find search terms to be used for queries in information retrieval.", "labels": [], "entities": []}, {"text": "suggested to use mutual information, an information theoretic measure, for computing association strength.", "labels": [], "entities": []}, {"text": "Prior to this, a lot of work had been done without reliance of corpora.", "labels": [], "entities": []}, {"text": "For example, used associative semantic networks to show the distance between words.", "labels": [], "entities": []}, {"text": "Others tried to show the universal status of a large subset of associations.", "labels": [], "entities": []}, {"text": "While all these findings are important, we will not consider them further here.", "labels": [], "entities": []}, {"text": "Rather we will focus on the claim that acorpus-derived co-occurrence network is able to mimic human associative behavior.", "labels": [], "entities": []}, {"text": "Such a network consists of nodes, which in our case correspond to words (or lemmas), and of weights connecting the nodes.", "labels": [], "entities": []}, {"text": "The strengths of these weights are computed on the basis of word co-occurrence data, and by optionally applying an association measure.", "labels": [], "entities": []}, {"text": "But there are many association measures.", "labels": [], "entities": [{"text": "association", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.9452033638954163}]}, {"text": "Given their number and diversity some researchers felt that there was a need to define some criteria and methods in order to allow for quantitative comparisons via task-based evaluations.", "labels": [], "entities": []}, {"text": "(2011) investigated the potential of asymmetric association measures, i.e. \"associations whose associational strength is significantly greater in one direction (e.g., from Pyrrhic to victory) than in the other (e.g., from victory to Pyrrhic)\".", "labels": [], "entities": []}, {"text": "tried to determine whether word associations should be computed via window-based co-occurrence counts or rather via a windowless approach measuring the distances between words.", "labels": [], "entities": []}, {"text": "Our work is related to previous studies comparing human word associations with those derived from corpus statistics (e.g.).", "labels": [], "entities": []}, {"text": "The main differences are that we categorize our stimulus words and present results for each class, and that we have a stronger focus on the graph aspect of our network.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Extracts from the EAT for the stimulus words bath  and cold.", "labels": [], "entities": [{"text": "EAT", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.7295215129852295}]}]}