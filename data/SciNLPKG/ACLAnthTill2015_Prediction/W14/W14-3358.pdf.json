{"title": [{"text": "Dynamic Topic Adaptation for SMT using Distributional Profiles", "labels": [], "entities": [{"text": "Dynamic Topic Adaptation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6826582252979279}, {"text": "SMT", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9935740828514099}]}], "abstractContent": [{"text": "Despite its potential to improve lexical selection, most state-of-the-art machine translation systems take only minimal con-textual information into account.", "labels": [], "entities": [{"text": "lexical selection", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.665894478559494}, {"text": "machine translation", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7447809875011444}]}, {"text": "We capture context with a topic model over dis-tributional profiles built from the context words of each translation unit.", "labels": [], "entities": []}, {"text": "Topic distributions are inferred for each translation unit and used to adapt the translation model dynamically to a given test context by measuring their similarity.", "labels": [], "entities": []}, {"text": "We show that combining information from both local and global test contexts helps to improve lexical selection and outperforms a baseline system by up to 1.15 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.997831404209137}]}, {"text": "We test our topic-adapted model on a diverse data set containing documents from three different domains and achieve competitive performance in comparison with two supervised domain-adapted systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of lexical selection plays an important role in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.7692991296450297}]}, {"text": "It strongly depends on context and is particularly difficult when the domain of a test document is unknown, for example when translating web documents from diverse sources.", "labels": [], "entities": []}, {"text": "Selecting translations of words or phrases that preserve the sense of the source words is closely related to the field of word sense disambiguation (WSD), which has been studied extensively in the past.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.8028313716252645}]}, {"text": "Most approaches to WSD model context at the sentence level and do not take the wider context of a word into account.", "labels": [], "entities": [{"text": "WSD", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9831441640853882}]}, {"text": "Some of the ideas from the field of WSD have been adapted for machine translation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9756719470024109}, {"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7767587006092072}]}, {"text": "For example, Carpuat and Wu (2007a) extend word sense disambiguation to phrase sense disambiguation and show improved performance due to the better fit with multiple possible segmentations in a phrasebased system.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.7384876608848572}, {"text": "phrase sense disambiguation", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.7423856457074484}]}, {"text": "Carpuat (2009) test the \"one sense per discourse\" hypothesis () for MT and find that enforcing it as a constraint at the document level could potentially improve translation quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.9924983382225037}]}, {"text": "Our goal is to make correct lexical choices in a given context without explicitly enforcing translation consistency.", "labels": [], "entities": []}, {"text": "More recent work in SMT uses latent representations of the document context to dynamically adapt the translation model with either monolingual topic models or bilingual topic models), thereby allowing the translation system to disambiguate source phrases using document context.", "labels": [], "entities": [{"text": "SMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9943642616271973}]}, {"text": "also apply a topic model to each test sentence and find that sentence context is sufficient for picking good translations, but they do not attempt to combine sentence and document level information.", "labels": [], "entities": []}, {"text": "Sentence-level topic adaptation for SMT has also been employed by.", "labels": [], "entities": [{"text": "Sentence-level topic adaptation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.782200038433075}, {"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9890962243080139}]}, {"text": "Other approaches to topic adaptation for SMT include and, both of which use adapted lexical weights.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7386378943920135}, {"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9822961688041687}]}, {"text": "In this paper, we present a topic model that learns latent distributional representations of the context of a phrase pair which can be applied to both local and global contexts attest time.", "labels": [], "entities": []}, {"text": "We introduce similarity features that compare latent representations of phrase pair types to test contexts to disambiguate senses for improved lexical selection.", "labels": [], "entities": []}, {"text": "We also propose different strategies for combining local and global topical context and show that using clues from both levels of contexts is beneficial for translation model adaptation.", "labels": [], "entities": [{"text": "translation model adaptation", "start_pos": 157, "end_pos": 185, "type": "TASK", "confidence": 0.930362860361735}]}, {"text": "We evaluate our model on a dynamic adaptation task where the domain of a test document is unknown and hence the problem of lexical selection is harder.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were carried out on a mixed French-English data set containing the TED corpus (), parts of the News Commentary corpus (NC) and parts of the Commoncrawl corpus (CC) from the WMT13 shared task () as described in.", "labels": [], "entities": [{"text": "French-English data set", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.8015207449595133}, {"text": "TED corpus", "start_pos": 83, "end_pos": 93, "type": "DATASET", "confidence": 0.9252116978168488}, {"text": "News Commentary corpus (NC)", "start_pos": 111, "end_pos": 138, "type": "DATASET", "confidence": 0.8669125239054362}, {"text": "Commoncrawl corpus (CC)", "start_pos": 156, "end_pos": 179, "type": "DATASET", "confidence": 0.9467111110687256}, {"text": "WMT13 shared task", "start_pos": 189, "end_pos": 206, "type": "DATASET", "confidence": 0.8178457021713257}]}, {"text": "To ensure that the baseline model does not have an implicit preference for any particular domain, we selected subsets of the NC and CC corpora such that the training data contains 2.7M English words per domain.", "labels": [], "entities": []}, {"text": "We were guided by two constraints in chosing our data set in order to simulate an environment where very diverse documents have to be translated, which is atypical scenario for web translation engines: 1) the data has document boundaries and the content of each document is assumed to be topically related, 2) there is some degree of topical variation within each data set.", "labels": [], "entities": []}, {"text": "This setup allows us to evaluate our dynamic topic adaptation approach because the test documents are from different domains and also differ within each domain, which makes lexical selection a much harder problem.", "labels": [], "entities": [{"text": "dynamic topic adaptation", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.6524209976196289}]}, {"text": "The topic adaptation approach does not make use of the domain labels in training or test, because it infers topic mixtures in an unsupervised way.", "labels": [], "entities": [{"text": "topic adaptation", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.8928846716880798}]}, {"text": "However, we compare the performance of our dynamic approach to domain adaptation methods by providing them the domain labels for each document in training and test.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7142008692026138}]}, {"text": "In order to abstract away from adaptation effects that concern tuning of length penalties and language models, we use a mixed tuning set containing data from all three domains and train one language model on the concatenation of the target sides of the training data.", "labels": [], "entities": []}, {"text": "Word alignments are trained on the concatenation of all training data and fixed for all models.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6927887946367264}]}, {"text": "In order to verify that the topic model is learning useful topic representations for phrase pairs, we inspect the inferred topic distributions for three phrase pairs where the translation of the same source word differs depending on the topical context: noyau \u2192 kernel, noyau \u2192 nucleus and noyau \u2192 core.", "labels": [], "entities": []}, {"text": "shows the topic distributions fora PPT model with 20 topics (with topic 0 removed) and highlights the most prominent topics with labels describing their content (politics, IT, science, economy) . The most peaked topic distribution was learned for the phrase pair noyau \u2192 kernel which would be expected to occur mostly in an IT context and the topic with the largest probability mass is in fact related to IT.", "labels": [], "entities": []}, {"text": "The most prominent topic for the phrase pair noyau \u2192 nucleus is the science topic, though it seems to be occurring in with the political topic as well.", "labels": [], "entities": []}, {"text": "The phrase pair noyau \u2192 core was assigned the most ambiguous topic distribution with peaks at the politics, economy and IT topics.", "labels": [], "entities": []}, {"text": "Note also that its topic distribution overlaps with those of the other translations, for example, like the phrase pair noyau \u2192 kernel, it can occur in IT contexts.", "labels": [], "entities": []}, {"text": "This shows that the model captures the fact that even within a given topic there can still be ambiguity about the correct translation (both target phrases kernel and core are plausible translations in an IT context).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 shows the aver- age length of a document for each domain. While  a CC document contains 29.1 sentences on aver- age, documents from NC and TED are on average  more than twice as long. The length of a document  could have an influence on how reliable global  topic information is but also on how important it  is to have information from both local and global  test contexts.", "labels": [], "entities": [{"text": "NC", "start_pos": 141, "end_pos": 143, "type": "DATASET", "confidence": 0.9145008325576782}]}, {"text": " Table 2: Average number of sentences per docu- ment in the test set (per domain).", "labels": [], "entities": []}, {"text": " Table 4: BLEU scores of baseline system +  phrSim-global feature for different numbers of  topics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988179802894592}]}, {"text": " Table 5: Properties of test documents per domain.", "labels": [], "entities": []}, {"text": " Table 6: BLEU scores of baseline and combina- tions of phrase pair similarity features with local  and global context (significance compared to base- line+global). All models were trained with 50 top- ics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991362690925598}]}, {"text": " Table 9: BLEU scores of translation model using similarity features derived from PPT model (50 topics)  in comparison with two (supervised) domain-adapted systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9980425834655762}, {"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.964857816696167}]}, {"text": " Table 10: BLEU scores of baseline, baseline + document similarity feature and additional phrase pair  similarity features (significance compared to baseline+docSim). All models were trained with 50 topics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9991539716720581}]}]}