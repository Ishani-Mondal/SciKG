{"title": [{"text": "Diachronic proximity vs. data sparsity in cross-lingual parser projection. A case study on Germanic", "labels": [], "entities": [{"text": "cross-lingual parser projection", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7419523596763611}, {"text": "Germanic", "start_pos": 91, "end_pos": 99, "type": "DATASET", "confidence": 0.7336234450340271}]}], "abstractContent": [{"text": "For the study of historical language varieties, the sparsity of training data imposes immense problems on syntactic annotation and the development of NLP tools that automatize the process.", "labels": [], "entities": []}, {"text": "In this paper, we explore strategies to compensate the lack of training data by including data from related varieties in a series of annotation projection experiments from English to four old Germanic languages: On dependency syntax projected from English to one or multiple language(s), we train a fragment-aware parser trained and apply it to the target language.", "labels": [], "entities": []}, {"text": "For parser training, we consider small datasets from the target language as a baseline, and compare it with models trained on larger datasets from multiple varieties with different degrees of relatedness, thereby balancing sparsity and diachronic proximity.", "labels": [], "entities": []}, {"text": "Our experiments show (a) that including related language data to training data in the target language can improve parsing performance, (b) that a parser trained on data from two related languages (and none from the target language) can reach a performance that is statistically not significantly worse than that of a parser trained on the projections to the target language, and (c) that both conclusions holds only among the three most closely related languages under consideration, but not necessarily the fourth.", "labels": [], "entities": [{"text": "parsing", "start_pos": 114, "end_pos": 121, "type": "TASK", "confidence": 0.9793485403060913}]}, {"text": "The experiments motivate the compilation of a larger parallel corpus of historical Germanic varieties as a basis for subsequent studies.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We study the projection of dependency syntax, as it is considered particularly suitable for free word-order languages like IS, OE and DE.", "labels": [], "entities": [{"text": "projection of dependency syntax", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.7688194811344147}]}, {"text": "The existing constituent annotations were thus converted with standard tools for PTB conversion.", "labels": [], "entities": [{"text": "PTB conversion", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7764260768890381}]}, {"text": "For annotating EN, we created dependency versions of WSJ and Brown sections of the PTB with the LTH Converter (.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.8628582954406738}, {"text": "PTB", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.8925600647926331}]}, {"text": "We trained Malt 1.7.2, optimized its features with MaltOptimizer (, and parsed the EN bible using the resulting feature model.", "labels": [], "entities": [{"text": "EN bible", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8939878940582275}]}, {"text": "The ME, OE, DE and IS datasets were word aligned with EN using GIZA++.", "labels": [], "entities": [{"text": "ME", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9425092935562134}, {"text": "OE", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.8697798848152161}, {"text": "DE", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.9420178532600403}, {"text": "IS datasets", "start_pos": 19, "end_pos": 30, "type": "DATASET", "confidence": 0.8522440493106842}]}, {"text": "1 : n alignments were resolved to the most probable 1 : 1 mapping.", "labels": [], "entities": []}, {"text": "During annotation projection, we assume that the aligned words represent the respective heads for the remaining n \u2212 1 words.", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 7, "end_pos": 28, "type": "TASK", "confidence": 0.8173653483390808}]}, {"text": "These dependent words are assigned the dependency relation FRAG to the word that got the highest score in the translation table.", "labels": [], "entities": [{"text": "FRAG", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9528053402900696}]}, {"text": "This solution solves, among others, the problem of separable verb prefixes in DE, for example, DE ruffen with prefix an would be aligned to English word call: As P (\"call\"|\"an\") < P (\"call\"|\"ruffen\"), the syntactic information of \"call\" will be projected to \"ruffen\" and \"an\" will be its dependent labeled with \"FRAG\".", "labels": [], "entities": [{"text": "FRAG", "start_pos": 312, "end_pos": 316, "type": "METRIC", "confidence": 0.9971565008163452}]}, {"text": "The projected dependency trees were checked on well-formedness, sentences with cycles were dismissed from the data set.", "labels": [], "entities": []}, {"text": "We formed training sets containing 437 sentences for ME, OE, DE, IS.", "labels": [], "entities": [{"text": "ME", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9794415235519409}, {"text": "OE", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9594535827636719}, {"text": "DE", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9620010852813721}, {"text": "IS", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.7734488248825073}]}, {"text": "Monolingual data sets were combined into bi-, tri-or quadrilingual training data sets with a simple concatenation, thereby creating less sparse, but more heterogeneous training data sets.", "labels": [], "entities": []}, {"text": "For every language, test data was taken from J, 174 sentences per language.", "labels": [], "entities": []}, {"text": "We used the projected dependencies to train fMalt (), a fragment-aware dependency parser, in order to maximize the gain of information from incomplete projections.", "labels": [], "entities": []}, {"text": "In our setting, fMalt used two features, POS and hyperlemmas.", "labels": [], "entities": [{"text": "fMalt", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.9448405504226685}]}, {"text": "POS The tagsets of the historical corpora originate in PTB, but show incompatible adaptations to the native morphosyntax.", "labels": [], "entities": [{"text": "POS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8259410858154297}, {"text": "PTB", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.949356198310852}]}, {"text": "Tagset extensions on grammatical casein OE, IS and DE were removed and language-specific extensions for auxiliaries and modal verbs were leveled, in favor of a common, but underspecified tagset for all four languages.", "labels": [], "entities": [{"text": "DE", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9784496426582336}]}, {"text": "As these generalized tags preserve information not found in EN, they were fed into the parser.", "labels": [], "entities": []}, {"text": "(hyper-)lemma Lexicalization is utterly important for the dependency parsing), but to generalize over specifics of historical language varieties, hyperlemmatization needs to be performed.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7689486742019653}]}, {"text": "Similar to, we use projected English words as hyperlemmas and feed them into the parser.", "labels": [], "entities": []}, {"text": "Hyperlemmatization against a closely related languages is acceptable as we can expect that the syntactic properties of words are likely to be similar.", "labels": [], "entities": []}, {"text": "The projected annotations were then evaluated against dependency annotations created analoguously to the EN annotations from manual PTB-style constituency syntax.", "labels": [], "entities": []}, {"text": "As LTH works exclusively on PTB data, the historical corpora were converted with its antecessor Penn2Malt 4 using user-defined head-rules ().", "labels": [], "entities": [{"text": "PTB data", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.9458405375480652}, {"text": "Penn2Malt", "start_pos": 96, "end_pos": 105, "type": "DATASET", "confidence": 0.9110033512115479}]}, {"text": "We evaluate the unlabeled attachment score (, UAS), i.e., the proportion of tokens in a sentence (without punctuation) that are assigned the correct head, on test sets of 174 sentences in each language.", "labels": [], "entities": [{"text": "unlabeled attachment score", "start_pos": 16, "end_pos": 42, "type": "METRIC", "confidence": 0.6627159118652344}, {"text": "UAS)", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9756312072277069}]}, {"text": "As a baseline for the evaluation we take the performance of the parser trained solely on the target language data.", "labels": [], "entities": []}, {"text": "1 (second col.), the UAS scores mirror both the diachronic relatedness (ME>DE>IS), as well as the relative loss of morphology (ME>DE>IS/OE), indicating that diachronic relatedness may not be the only factor licensing the applicability of the annotation projection scenario (H3).", "labels": [], "entities": [{"text": "UAS", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.5207170248031616}, {"text": "OE)", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.8966062366962433}]}, {"text": "It is also important, though, to keep in mind that the OE and IS translations of the Bible had considerable influence of Latin syntax, whereas DE and ME translations aimed fora language easy to understand.", "labels": [], "entities": [{"text": "OE", "start_pos": 55, "end_pos": 57, "type": "DATASET", "confidence": 0.8282220363616943}]}, {"text": "gives the best and worst results for the unlabeled attachment score for the parser trained on target and related language(s) (H1).", "labels": [], "entities": []}, {"text": "With the exception of DE, we observed no significant differences in UAS scores relative to the baseline.", "labels": [], "entities": [{"text": "DE", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9980916380882263}, {"text": "UAS", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.7948225736618042}]}, {"text": "DE may benefit from ME because of its more flexible syntax (thus closer to ME [and OE] than to Modern English), and from IS because of Luther's direct influence on the IS bible.", "labels": [], "entities": []}, {"text": "That ME did not mutually benefit from German maybe due to the good quality of ME annotation projections (resulting from its proximity to EN).", "labels": [], "entities": [{"text": "ME", "start_pos": 5, "end_pos": 7, "type": "DATASET", "confidence": 0.7724633812904358}, {"text": "EN", "start_pos": 137, "end_pos": 139, "type": "DATASET", "confidence": 0.9652117490768433}]}, {"text": "Parsers trained on trilingual and quadrilingual sets exhibited no improvement over the bilingual sets.", "labels": [], "entities": []}, {"text": "Taken together, we found no positive effect of using additional training data from language stages diachronically separated for more than 500 years (e.g., OE/ME), but also, we did not find a negative effect among the West Germanic languages.", "labels": [], "entities": [{"text": "OE", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.773050844669342}]}, {"text": "If additional training material is carefully chosen among particularly closely related varieties, however, the DE effect can be replicated, and then, including related language data to training data in the target language can improve parsing performance.", "labels": [], "entities": [{"text": "DE", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.9578587412834167}, {"text": "parsing", "start_pos": 234, "end_pos": 241, "type": "TASK", "confidence": 0.9607576131820679}]}, {"text": "While in our setting, training data from related languages may (but does not have to) improve a parser training if training data for the target language is available, it may very well be employed fruitfully if no training data for the target language is available (H2): shows that, unsurprisingly, parsers trained only on one related language had the lowest performance in the experiment, so using multiple train languages seems to compensate language-specific idiosyncrasies.", "labels": [], "entities": []}, {"text": "The best-performing parsing models trained on two or more related languages achieved a performance not significantly worse (if not better) than models being trained on target language data.", "labels": [], "entities": []}, {"text": "This effect extends to all languages except for IS and indicates that a careful choice of additional training data from related varieties may facilitate annotation projection.", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 153, "end_pos": 174, "type": "TASK", "confidence": 0.7053471058607101}]}, {"text": "Equally important (and valid across all languages) is that none of the models trained on one language outperformed any of the model trained on two languages.", "labels": [], "entities": []}, {"text": "Using training data from two related languages doesn't seem to hurt performance in our setting.", "labels": [], "entities": []}, {"text": "Adding a third language did not yield systematic improvements, the scores for trilingual models are in the range of the bilingual models.", "labels": [], "entities": []}, {"text": "Again, DE is exceptionally good, benefitting from being a direct source of the IS translation as well as structurally comparable to ME.", "labels": [], "entities": [{"text": "DE", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.986289918422699}, {"text": "IS translation", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.8443650603294373}]}, {"text": "In both settings, the worst-performing language is IS, with a significant drop in annotation projection quality with Western Germanic material added, indicating that diachronic distance between Northern and Western Germanic languages limits the applicability of (H2), thereby supporting (H3).", "labels": [], "entities": []}, {"text": "Taken together, our results indicate 1.", "labels": [], "entities": []}, {"text": "a significant positive effect for the Western Germanic languages (ME, OE, DE) for (H2), and 2.", "labels": [], "entities": [{"text": "DE", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.8757330179214478}]}, {"text": "a significant negative effect for Western and Northern Germanic languages (IS) for (H2) As a tentative hypothesis, one may speculate that languages separated for 1000 years (OE-IS) or more are too remote from each other to provide helpful background information, but that languages separated within the last 750 years (ME-DE) or less are still sufficiently close.", "labels": [], "entities": []}, {"text": "This novel assumption may provide a guideline for future efforts to project annotations among related languages, and is thus of immense practical relevance for developing future NLP tools for historical and less-resourced language varieties.", "labels": [], "entities": []}, {"text": "Ultimately, one may formulate rules of best practice like the following: \u2022 If no syntactic annotations fora target language are available, annotation projection among closely related languages maybe a solution.", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 139, "end_pos": 160, "type": "TASK", "confidence": 0.6911682784557343}]}, {"text": "Even with limited amounts of parallel data, diachronic distances of more than 500 years can be successfully bridged (EN/ME, baseline).", "labels": [], "entities": [{"text": "ME", "start_pos": 120, "end_pos": 122, "type": "METRIC", "confidence": 0.5629258155822754}]}, {"text": "\u2022 If no syntactic annotations fora target language are available, a parser trained on hyperlemmatized corpora in two languages may yield a performance comparable to a parser trained on small amounts of target data.", "labels": [], "entities": []}, {"text": "A parser trained on hyperlemmatized monolingual data maybe significantly worse (H2).", "labels": [], "entities": []}, {"text": "\u2022 The sparsity of parallel text to conduct annotation projection and train a (hyperlemmatized) parser can only be compensated by adding parallel data from one related language if these are closely diachronically related (with a separation being less than, say, 500 years ago) and at a similar developmental stage (DE/ME, H1).", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.7828902900218964}]}, {"text": "Adding data from multiple, equally remote languages does not necessarily improve the results further.", "labels": [], "entities": []}, {"text": "At the current state, such recommendations would be premature, they require deeper investigation, but with the confirmation of (H2) and (H3), we can now motivate larger-scale efforts to compile a massive parallel corpus of historical Germanic language varieties as a basis for subsequent studies.", "labels": [], "entities": []}, {"text": "Initial steps towards this goal are described in the following section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of best-and worst-performing parsing models (UAS diff. vs. baseline with \u03c7 2 :  *  p < .05,  *  *  p < .01,  *  *  *  p < .005)", "labels": [], "entities": []}, {"text": " Table 2: Verse-aligned texts in the Germanic parallel Bible corpus (parentheses indicate marginal frag- ments with less than 50,000 tokens)", "labels": [], "entities": [{"text": "Germanic parallel Bible corpus", "start_pos": 37, "end_pos": 67, "type": "DATASET", "confidence": 0.7571966126561165}]}]}