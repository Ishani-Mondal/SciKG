{"title": [{"text": "Maximum Entropy for Chinese Comma Classification with Rich Lin- guistic Features", "labels": [], "entities": [{"text": "Chinese Comma Classification", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.5908398230870565}]}], "abstractContent": [{"text": "Discourse relation is an important content of discourse semantic analysis, and the study of punctuation is of importance for discourse relation.", "labels": [], "entities": [{"text": "discourse semantic analysis", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.7997810244560242}, {"text": "discourse relation", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.8102690577507019}]}, {"text": "In this paper, we propose a method of Chinese comma classification based on maximum entropy (ME).", "labels": [], "entities": [{"text": "Chinese comma classification", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.616183857123057}, {"text": "maximum entropy (ME)", "start_pos": 76, "end_pos": 96, "type": "METRIC", "confidence": 0.8104180097579956}]}, {"text": "This method classifies the sentence relation based on comma with ME by extracting rich linguistic features before and after the commas in sentences.", "labels": [], "entities": []}, {"text": "Experimental results show that this method of sentence relation based on comma is feasible.", "labels": [], "entities": [{"text": "sentence relation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7441155016422272}]}], "introductionContent": [{"text": "Discourse consists of word, phrase, sentence and sentence group, also known as text or utterance.", "labels": [], "entities": []}, {"text": "Discourse relation studies the intrinsic structure of natural language text and understands the semantic relation between the text units, which plays a vital role in language understanding and natural language generation, is a challenge and difficult research hotspot in recent years(.", "labels": [], "entities": [{"text": "Discourse relation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7722350060939789}, {"text": "language understanding", "start_pos": 166, "end_pos": 188, "type": "TASK", "confidence": 0.7267932742834091}, {"text": "natural language generation", "start_pos": 193, "end_pos": 220, "type": "TASK", "confidence": 0.6630205313364664}]}, {"text": "Discourse relation is a fundamental work in the research of discourse analysis.", "labels": [], "entities": [{"text": "Discourse relation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7943184673786163}, {"text": "discourse analysis", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7423544973134995}]}, {"text": "Discourse relation means the logical semantic relation, between two text unit (section, clause, sentence, sentence group, paragraphs, etc.) in one discourse, such as coordinative relation, progressive relation, adversative relation), etc.", "labels": [], "entities": []}, {"text": "Defining a hierarchical semantic relationship type system to extend sentence semantic analysis results in that discourse level of semantic information become one of the important ways to solve the discourse semantic analysis, which is benefit to many NLP tasks such as automatic summarization, automatic question answering and machine translation (Zhang.", "labels": [], "entities": [{"text": "sentence semantic analysis", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.7964299122492472}, {"text": "discourse semantic analysis", "start_pos": 197, "end_pos": 224, "type": "TASK", "confidence": 0.7758846084276835}, {"text": "summarization", "start_pos": 279, "end_pos": 292, "type": "TASK", "confidence": 0.7815529108047485}, {"text": "question answering", "start_pos": 304, "end_pos": 322, "type": "TASK", "confidence": 0.7646934688091278}, {"text": "machine translation", "start_pos": 327, "end_pos": 346, "type": "TASK", "confidence": 0.7615309655666351}]}, {"text": "The commas separates a sentence into two parts, each part is called an argument of the sentence.", "labels": [], "entities": []}, {"text": "Discourse relation can be generally classified into explicit relation and implicit relation.", "labels": [], "entities": []}, {"text": "Explicit relation recognition is to identify the logical relationship between two arguments in the presence of conjunctions) while implicit relation recognition is to identify the logical relationship without the presence of conjunctions.", "labels": [], "entities": [{"text": "relation recognition", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7769893407821655}, {"text": "implicit relation recognition", "start_pos": 131, "end_pos": 160, "type": "TASK", "confidence": 0.6677130957444509}]}, {"text": "Example 1 exemplifies the explicit relation of coordination with the conjunction word \"\u5e76(and)\", and example 2 exemplifies the implicit relation of coordination in the absence of \"\u5e76 (and)\", in which conjunction does not appear.", "labels": [], "entities": []}, {"text": "For the implicit relation recognition, the absence of conjunction entails methods that can deduce the semantic type from other features in the context before and/or after commas.", "labels": [], "entities": [{"text": "relation recognition", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7331671863794327}]}, {"text": "In previous researches, explicit relation recognition often has a higher precision only based on conjunction, while implicit relation recognition is much more difficult than explicit relation recognition.", "labels": [], "entities": [{"text": "explicit relation recognition", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.602557897567749}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9984210729598999}, {"text": "implicit relation recognition", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.5976481835047404}, {"text": "explicit relation recognition", "start_pos": 174, "end_pos": 203, "type": "TASK", "confidence": 0.6774310866991679}]}, {"text": "Some additional information is gradually introduced in addition to lexical features (Zhang Mu-yu et al., 2013). eg. 1\uff1a\u8df3\u6c34\u9009\u624b\u5df2\u5168\u90e8\u62b5\u8fbe\u7f57\u9a6c\uff0c\u5e76\u5f00\u59cb\u8d5b\u524d\u8bad \u7ec3\u3002", "labels": [], "entities": []}, {"text": "\"All divers have arrived in Rome, and start training before the game.\" eg. 2\uff1a\u4e2d\u56fd\u7684\u7a33\u5b9a\u548c\u53d1\u5c55\u6709\u5229\u4e8e\u4e16\u754c\u7684\u548c\u5e73\u4e0e\u53d1 \u5c55\uff0c\u4e2d\u56fd\u7684\u7e41\u8363\u4e0e\u7a33\u5b9a\u662f\u6fb3\u95e8\u7e41\u8363\u4e0e\u7a33\u5b9a\u7684\u6839\u672c \u4fdd\u8bc1\u3002", "labels": [], "entities": []}, {"text": "\"China's stability and development are conducive to world's peace and development, China's prosperity and stability are the fundamental guarantee of Macro's prosperity and stability.\"", "labels": [], "entities": []}, {"text": "Most researches about discourse relation recognition are mainly for English.", "labels": [], "entities": [{"text": "discourse relation recognition", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7965790232022604}]}, {"text": "Although there are some Chinese-oriented research (Jin Mei-xun et al.,; Xu Sheng-qin and Li Pei-feng, 2013; Yang yaqin and Xue Nianwen, 2012), they are mainly concentrated on the analysis and corpus annotation, rarely involving discourse relation recognition; and existing research mostly directly used the English discourse relation system, ignoring the linguistic characteristics of Chinese language itself.", "labels": [], "entities": [{"text": "discourse relation recognition", "start_pos": 228, "end_pos": 258, "type": "TASK", "confidence": 0.6571909487247467}]}, {"text": "We carried out the classification experiment on both the explicit relation recognition and the implicit relation recognition respectively consisted of the 9 categories mentioned above.", "labels": [], "entities": [{"text": "relation recognition", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.725035548210144}, {"text": "relation recognition", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.6804185211658478}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe the related work about comma classification research.", "labels": [], "entities": [{"text": "comma classification research", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.8979814052581787}]}, {"text": "Section 3 introduces the features we used and other features selecting method used in related work.", "labels": [], "entities": []}, {"text": "Section 4 reviews ME method and describe the comma classification method based on ME model.", "labels": [], "entities": [{"text": "comma classification", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7620399296283722}]}, {"text": "In section 5, we present the process of our experiment and evaluate the experimental result.", "labels": [], "entities": []}, {"text": "In section 6, we analyze the causes that lead to the main classification error in different aspects.", "labels": [], "entities": []}, {"text": "Finally, a conclusion and future work are put forward.", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpus used in our experiment is rebuilt from part of CTB 5.0.", "labels": [], "entities": [{"text": "Corpus", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.831941545009613}, {"text": "CTB 5.0", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.9738079011440277}]}, {"text": "We annotated it with the information of class.", "labels": [], "entities": []}, {"text": "The corpus is divided into explicit relation and implicit relation according to whether the sentences contain conjunction.", "labels": [], "entities": []}, {"text": "The distribution of the sample set for each class is shown in table 2 . The eigenvector expressed with features in for each sentence in is obtained.", "labels": [], "entities": []}, {"text": "All the eigenvectors obtained constitute our data set.", "labels": [], "entities": []}, {"text": "The data set is divided into training data set and testing data set with the proportion of 80% : 20%, 10-times 10-fold cross-validation policy is employed.", "labels": [], "entities": [{"text": "training data set", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.7733607590198517}]}, {"text": "All of above prepared, one of the mallet toolkit classifier--maximum entropy (MaxEnt) classifier is adopted to train and test the final model.", "labels": [], "entities": [{"text": "maximum entropy (MaxEnt)", "start_pos": 61, "end_pos": 85, "type": "METRIC", "confidence": 0.782817542552948}]}, {"text": "The experimental results, i.e., classification precisions for all sentence relation class, are shown in table 3.", "labels": [], "entities": [{"text": "precisions", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.7444243431091309}]}, {"text": "We conducted several experiments on different training set size and testing set size.", "labels": [], "entities": []}, {"text": "Results show that the unbalance of training set size has a significant effect on the experimental results.", "labels": [], "entities": []}, {"text": "So we use the same training set size avoid this instability.", "labels": [], "entities": []}, {"text": "As can be seen in table 3, results for four relations (Location, Progressiveness, Reliance and Purpose) are absent.", "labels": [], "entities": []}, {"text": "The reason for the absence is that the corresponding precision is unreliable due to the sparseness of related samples in training data showed in.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.999214768409729}]}, {"text": "In addition, the precision for implicit relations is significantly lower than that for the explicit relations.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9996646642684937}]}, {"text": "shows the details of explicit relation classification, which includes the percentage of the samples that are correctly classified and falsely classified into other classes.", "labels": [], "entities": [{"text": "explicit relation classification", "start_pos": 21, "end_pos": 53, "type": "TASK", "confidence": 0.6449020206928253}]}, {"text": "Each item in is the average calculated from 10 times repeated experiment. is corresponding result for implicit relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 111, "end_pos": 134, "type": "TASK", "confidence": 0.6969778686761856}]}], "tableCaptions": []}