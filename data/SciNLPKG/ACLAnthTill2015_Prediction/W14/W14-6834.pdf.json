{"title": [{"text": "NCTU and NTUT's Entry to CLP-2014 Chinese Spelling Check Eval- uation", "labels": [], "entities": [{"text": "NCTU", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9415439963340759}, {"text": "NTUT", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.8281277418136597}, {"text": "Entry", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.8485144376754761}, {"text": "Chinese Spelling Check Eval- uation", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.7699779570102692}]}], "abstractContent": [{"text": "This paper describes our Chinese spelling check system submitted to SIGHAN Bake-off 2014 evaluation.", "labels": [], "entities": [{"text": "SIGHAN Bake-off 2014 evaluation", "start_pos": 68, "end_pos": 99, "type": "DATASET", "confidence": 0.8344246000051498}]}, {"text": "The system's main components are still the conditional random field (CRF)-based word segmentation/part-of-speech (POS) tagger and tri-gram language model (LM) used last year.", "labels": [], "entities": [{"text": "word segmentation/part-of-speech (POS) tagger", "start_pos": 80, "end_pos": 125, "type": "TASK", "confidence": 0.8184003569185734}]}, {"text": "But we tried to refine the misspelling rules, decision-making threshold and improve LM rescoring speed to reduce false alarm rate and improve rescoring speed.", "labels": [], "entities": [{"text": "LM rescoring speed", "start_pos": 84, "end_pos": 102, "type": "METRIC", "confidence": 0.6467605829238892}]}, {"text": "Bake-off 2014 evaluation results show that one of our system (Run2) did achieve reasonable performance with about 0.485/0.468 accuracies and 0.226/0.180 F1 scores in the de-tection/correction metrics.", "labels": [], "entities": [{"text": "F1", "start_pos": 153, "end_pos": 155, "type": "METRIC", "confidence": 0.997972309589386}]}], "introductionContent": [{"text": "Chinese spelling check could be treated as an abnormal word sequence detection problem.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5799945791562399}, {"text": "word sequence detection", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.6506941119829813}]}, {"text": "Therefore, word segmentation, part-of-speech (POS) parser and language models (LM) are usually adopted to correct the sentence.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7490040361881256}]}, {"text": "Therefore, a Chinese spelling checker (Wang 2013) had been built by integrating our conditional random field (CRF)-based parser and a 100K tri-gram LM.", "labels": [], "entities": [{"text": "spelling checker", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7150033414363861}]}, {"text": "Although, these two components are originally designed for automatic speech recognizer (ASR), the system did get some success on Bake-off 2013 evaluation . These results have confirmed the generalization and sophistication of our parser and LM.", "labels": [], "entities": [{"text": "speech recognizer (ASR)", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.8419068992137909}, {"text": "Bake-off 2013 evaluation", "start_pos": 129, "end_pos": 153, "type": "DATASET", "confidence": 0.948357085386912}]}, {"text": "However, there are still many issues in our system.", "labels": [], "entities": []}, {"text": "Especially, our system often produces a large amount of false alarms and requires very long processing time on Bake-off 2013 evaluation.", "labels": [], "entities": [{"text": "Bake-off 2013 evaluation", "start_pos": 111, "end_pos": 135, "type": "DATASET", "confidence": 0.9373342990875244}]}, {"text": "Therefore, the focus of this report is on how to reduce the false alarm rate, reduce search space and increase computing speed.", "labels": [], "entities": [{"text": "false alarm rate", "start_pos": 60, "end_pos": 76, "type": "METRIC", "confidence": 0.7519292831420898}]}], "datasetContent": [{"text": "Four configurations of our system (Run1~4) were tested.", "labels": [], "entities": []}, {"text": "Run1 applied only the rule-based frontend.", "labels": [], "entities": [{"text": "Run1", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9152425527572632}]}, {"text": "Run2~4 explored different search space and LM score threshold.", "labels": [], "entities": [{"text": "LM score threshold", "start_pos": 43, "end_pos": 61, "type": "METRIC", "confidence": 0.810909112294515}]}, {"text": "The settings of the different runs are shown in.", "labels": [], "entities": []}, {"text": "Among them, the search range of Run1~2 is very restricted and Run3~4 are much larger than others.", "labels": [], "entities": [{"text": "Run1", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.905228853225708}]}], "tableCaptions": [{"text": " Table 2: Evaluation results of the proposed system on  Bake-off 2014 Chinese spelling check task. The table  shows the false positive (F/P) rate, accuracy (Acc.),  precision (Pre.), recall (Rec.), and F1 score for both the  detection and correction levels.", "labels": [], "entities": [{"text": "Bake-off 2014 Chinese spelling check task", "start_pos": 56, "end_pos": 97, "type": "DATASET", "confidence": 0.9011215766270956}, {"text": "false positive (F/P) rate", "start_pos": 120, "end_pos": 145, "type": "METRIC", "confidence": 0.9252706319093704}, {"text": "accuracy (Acc.)", "start_pos": 147, "end_pos": 162, "type": "METRIC", "confidence": 0.8512613475322723}, {"text": "precision (Pre.)", "start_pos": 165, "end_pos": 181, "type": "METRIC", "confidence": 0.8308670222759247}, {"text": "recall (Rec.)", "start_pos": 183, "end_pos": 196, "type": "METRIC", "confidence": 0.9538262337446213}, {"text": "F1 score", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.9856972694396973}, {"text": "correction", "start_pos": 239, "end_pos": 249, "type": "METRIC", "confidence": 0.9420302510261536}]}]}