{"title": [{"text": "Personal Attributes Extraction in Chinese Text Bakeoff in CLP 2014\uff1a Overview", "labels": [], "entities": [{"text": "Personal Attributes Extraction in Chinese Text Bakeoff", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.817011011498315}]}], "abstractContent": [{"text": "This paper presents the overview of Personal Attributes Extraction in Chinese Text Bakeoff in CLP 2014.", "labels": [], "entities": [{"text": "Personal Attributes Extraction in Chinese Text Bakeoff", "start_pos": 36, "end_pos": 90, "type": "TASK", "confidence": 0.7853730746677944}, {"text": "CLP 2014", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.7698988318443298}]}, {"text": "Personal attribute extraction plays an important role in information extraction, event tracking, entity disambiguation and other related research areas.", "labels": [], "entities": [{"text": "Personal attribute extraction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6613731880982717}, {"text": "information extraction", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8503799140453339}, {"text": "event tracking", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.789010226726532}, {"text": "entity disambiguation", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7692850232124329}]}, {"text": "This task is designed to evaluate the techniques for extracting person specific attributes from unstructured Chinese texts, which is similar to slot filling, but focuses on person attributes.", "labels": [], "entities": [{"text": "extracting person specific attributes from unstructured Chinese texts", "start_pos": 53, "end_pos": 122, "type": "TASK", "confidence": 0.8549029603600502}, {"text": "slot filling", "start_pos": 144, "end_pos": 156, "type": "TASK", "confidence": 0.8109642863273621}]}, {"text": "This task brings some challenges issues because Chinese language contains some common words and lacks of capital clues as in English.", "labels": [], "entities": []}, {"text": "The task organizer manually constructs the query names and corresponding documents.", "labels": [], "entities": []}, {"text": "The value/presence of the texts corresponding 25 pre-defined attributes are annotated to construct the training and testing dataset.", "labels": [], "entities": []}, {"text": "The bakeoff results achieved by the participators show the good progress in this field.", "labels": [], "entities": []}], "introductionContent": [{"text": "Personal Attributes Extraction in Chinese Text Task is designed to evaluate the techniques for extracting person specific attributes, such as birth date, spouse, children, education, and title etc. from unstructured Chinese texts.", "labels": [], "entities": [{"text": "Personal Attributes Extraction in Chinese Text", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7979288548231125}]}, {"text": "These techniques play an important role in information extraction, event tracking, entity disambiguation and other related research areas.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.861388623714447}, {"text": "event tracking", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.8536503911018372}, {"text": "entity disambiguation", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.801667720079422}]}, {"text": "Slot filling task has been proposed as one of shared tasks in the TAC KBP workshop since 2009.", "labels": [], "entities": [{"text": "Slot filling task", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.928681472937266}, {"text": "TAC KBP workshop", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.8668793042500814}]}, {"text": "Generally speaking, the mainstream techniques for slot filling and person attributes extraction maybe camped into two major approaches, namely: Rule-based approach and statistics-based ones.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.9416698515415192}, {"text": "person attributes extraction", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.6520535051822662}]}, {"text": "Rule-based approach normally defines the extraction rules manually or learns the rules automatically.", "labels": [], "entities": []}, {"text": "The rules play the key role in this approach.", "labels": [], "entities": []}, {"text": "As long as finding the constraint information which matches the rules in the text, the system may extract the target extraction information.", "labels": [], "entities": []}, {"text": "As for the statistics-based approach, it has good portability to this extraction problem.", "labels": [], "entities": []}, {"text": "Several statistics machine learning models such as Hidden Markov Model (HMM) and Condition Random Fields (CRFs) are employed.", "labels": [], "entities": []}, {"text": "The shortcoming for this approach is that it requires large amount of training data which is always unavailable.", "labels": [], "entities": []}, {"text": "Currently, there are limited existing works on personal attributes extraction in Chinese text.", "labels": [], "entities": [{"text": "personal attributes extraction", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6848690112431844}]}, {"text": "Comparing to the works on English, the characteristics of Chinese language including the Chinese word segmentation, the confusion of named entity with common words, lack of capital clues bring more difficulties for person attributes extraction in Chinese.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.688798745473226}, {"text": "person attributes extraction", "start_pos": 215, "end_pos": 243, "type": "TASK", "confidence": 0.6725379427274069}]}, {"text": "The task of person attributes extraction in Chinese text in CLP 2014 bakeoff is designed on the basis of the slot filling task in the TAC KBP workshop.", "labels": [], "entities": [{"text": "person attributes extraction", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6456360717614492}, {"text": "CLP 2014 bakeoff", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.890251100063324}, {"text": "slot filling", "start_pos": 109, "end_pos": 121, "type": "TASK", "confidence": 0.8213039636611938}, {"text": "TAC KBP workshop", "start_pos": 134, "end_pos": 150, "type": "DATASET", "confidence": 0.8953869740168253}]}, {"text": "The task organizer provides a collection of documents corresponding to a target person and a knowledge base which contains partial list of attributes for the person.", "labels": [], "entities": []}, {"text": "Participants are required to extract additional attributes from the collections of documents.", "labels": [], "entities": []}, {"text": "The task is similar to the slot filling, but it focuses on person attributes extraction.", "labels": [], "entities": [{"text": "slot filling", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.8497227132320404}, {"text": "person attributes extraction", "start_pos": 59, "end_pos": 87, "type": "TASK", "confidence": 0.6285931567351023}]}, {"text": "Furthermore, the collection of documents is not limited to the news corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "The person names are manually selected from the web, in which 10 person names are used in training dataset and 90 person names, including 48 names for Chinese person and 42 names for foreign person are used in testing dataset.", "labels": [], "entities": []}, {"text": "The corresponding knowledge base is constructed from Wikipedia person entity while the source documents in each folder are constructed based on search engine output with manually selection.", "labels": [], "entities": []}, {"text": "The personal attributes are categorized as being Person (PER) slots based on the type of entities about which they seek to extract information.", "labels": [], "entities": []}, {"text": "The attributes are also categorized by the content and quantity of their fillers.", "labels": [], "entities": []}, {"text": "In the evaluation, both the lenient evaluation and strict evaluation are performed.", "labels": [], "entities": []}, {"text": "In the strict evaluation, all instance attributes are compared to the answers while in the lenient evaluation, the offset string_begin and string_end are ignored.", "labels": [], "entities": []}, {"text": "The detail evaluation metrics are shown as follows.", "labels": [], "entities": []}, {"text": "Score \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 = When numCorrect is zero, the numCorrect is set to 1.0;  When IP is the instance precision and IR is the instance recall, in the evaluation we set the weight F \ud97b\udf59 = 2, and when both IP and IR are zero, we set the ListSlotValue to zero;", "labels": [], "entities": [{"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.7479203939437866}]}], "tableCaptions": []}