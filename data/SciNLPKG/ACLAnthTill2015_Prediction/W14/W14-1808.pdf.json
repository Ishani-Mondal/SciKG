{"title": [{"text": "Towards Domain-Independent Assessment of Elementary Students' Science Competency using Soft Cardinality", "labels": [], "entities": [{"text": "Soft Cardinality", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.6688148528337479}]}], "abstractContent": [{"text": "Automated assessment of student learning has become the subject of increasing attention.", "labels": [], "entities": []}, {"text": "Students' textual responses to short answer questions offer a rich source of data for assessment.", "labels": [], "entities": []}, {"text": "However, automatically analyzing textual constructed responses poses significant computational challenges, exacerbated by the disfluencies that occur prominently in elementary students' writing.", "labels": [], "entities": []}, {"text": "With robust text analytics, there is the potential to analyze a student's text responses and accurately predict his or her future success.", "labels": [], "entities": []}, {"text": "In this paper, we propose applying soft cardinality, a technique that has shown success grading less disfluent student answers, on a corpus of fourth-grade responses to constructed response questions.", "labels": [], "entities": []}, {"text": "Based on decomposition of words into their constituent character sub-strings, soft cardinality's evaluations of responses written by fourth graders correlates with summative analyses of their content knowledge.", "labels": [], "entities": []}], "introductionContent": [{"text": "As a tool for automated assessment, short answer questions reveal cognitive processes and states in students that are difficult to uncover in multiplechoice equivalents.", "labels": [], "entities": []}, {"text": "Even when it seems that items could be designed to address the same cognitive construct, success in devising multiple-choice and short answer items that behave with psychometric equivalence has proven to be limited.", "labels": [], "entities": []}, {"text": "Because standards-based STEM education in the United States explicitly promotes the development of writing skills for which constructed response items are ideally suited, the prospect of designing text analytics techniques for automatically assessing students' textual responses has become even more appealing).", "labels": [], "entities": []}, {"text": "An important family of short answer questions is the constructed response question.", "labels": [], "entities": []}, {"text": "A constructed response question is designed to elicit a response of no more than a few sentences and features a relatively clear distinction between incorrect, partially correct, and correct answers.", "labels": [], "entities": []}, {"text": "Ideally, a system designed for constructed response analysis (CRA) would be machinelearned from examples that include both graded student answers and expert-constructed \"reference\" answers.", "labels": [], "entities": [{"text": "constructed response analysis (CRA)", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.8065628806749979}]}, {"text": "The challenges of creating an accurate machine-learning-based CRA system stem from the variety of ways in which a student can express a given concept.", "labels": [], "entities": []}, {"text": "In addition to lexical and syntactic variety, students often compose ill-formed text replete with ungrammatical phrasings and misspellings, which significantly complicate analysis.", "labels": [], "entities": []}, {"text": "The task of automated grading also becomes increasingly difficult as the material graded comes from questions and domains more and more distant from that of human graded responses on which the system is trained, leading to interest in domain-independent CRA systems designed to deal with this challenge (.", "labels": [], "entities": []}, {"text": "In this paper we explore the applications of soft cardinality, an approach to constructed response analysis that has shown prior success in domain-independent CRA.", "labels": [], "entities": [{"text": "constructed response analysis", "start_pos": 78, "end_pos": 107, "type": "TASK", "confidence": 0.6329171160856882}]}, {"text": "We investigate whether soft cardinality is robust to the disfluency common among elementary students and whether its analyses of a student's work as she progresses through a problem-solving session can be used to roughly predict the content knowledge she will have at the end.", "labels": [], "entities": []}, {"text": "Because like other bag of words techniques, soft cardinality is independent of word order, it is robust to grammatical disfluencies.", "labels": [], "entities": []}, {"text": "What distinguishes soft cardinality, however, is its characteroverlap technique, which allows it to evaluate word similarity across misspellings.", "labels": [], "entities": []}, {"text": "We evaluate soft cardinality on a dataset of textual responses to short-text science questions collected in a study conducted at elementary schools in two states.", "labels": [], "entities": []}, {"text": "Responders were in fourth grade and generally aged between nine and ten.", "labels": [], "entities": []}, {"text": "We train our system on student responses to circuits questions and test it on two domains in the physical sciences-circuits and magnetism.", "labels": [], "entities": []}, {"text": "The results indicate that, soft cardinality shows promise as a first step for predicting a student's future success with similar content even grading unseen domains in the presence of high disfluency.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides related work as a context for our research.", "labels": [], "entities": []}, {"text": "Section 3 introduces the corpus, collected on tablet-based digital science notebook software from elementary students.", "labels": [], "entities": []}, {"text": "Section 4 describes soft cardinality and an evaluation thereof.", "labels": [], "entities": []}, {"text": "Section 6 discusses the findings and explores how soft cardinality may serve as the basis for future approaches to real-time formative assessment.", "labels": [], "entities": []}], "datasetContent": [{"text": "Soft cardinality) uses decompositions of words into character sequences, known as q-grams, to gauge similarity between two words.", "labels": [], "entities": []}, {"text": "We use it hereto bridge the gap between misspellings of the same word.", "labels": [], "entities": []}, {"text": "Considering \"dcells\" in an example answer, \"mor dcells,\" and \"D-cells\" in the reference answer, we can find overlaps in \"ce,\" \"el,\" \"ll,\" \"ls,\" \"ell,\" \"lls,\" and soon up to and including \"cells.\"", "labels": [], "entities": []}, {"text": "This technique functions equally well for real-word spelling errors such as if the student had forgotten the \"d\" and typed only \"cells.\"", "labels": [], "entities": []}, {"text": "Such overlaps signify a close match for both of these words.", "labels": [], "entities": []}, {"text": "We evaluated the soft cardinality implementation of a generic short answer grading framework that we developed, WRITEEVAL, based on an answer grading system described in an earlier work).", "labels": [], "entities": [{"text": "WRITEEVAL", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9591889381408691}]}, {"text": "We used 100-fold cross-validation on the \"Energy and Circuits\" module.", "labels": [], "entities": []}, {"text": "We compare WRITEEVAL using soft cardinality to the majority class baseline and to WRITEEVAL using Precedent Feature Collection (PFC), a latent semantic analysis technique that performs competitively with the second highest-scoring system in Semeval Task 7 on unseen answers on the SciEntsBank corpus (.", "labels": [], "entities": [{"text": "SciEntsBank corpus", "start_pos": 281, "end_pos": 299, "type": "DATASET", "confidence": 0.8091195225715637}]}, {"text": "Using a Kruskal-Wallis test over one hundred folds, both systems significantly outperform the baseline (p<.001), which achieved an accuracy score of .61.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9995728135108948}]}, {"text": "We could not evaluate the scores directly on the Magnetism dataset as we did not have any human-graded gold standard for comparison.", "labels": [], "entities": [{"text": "Magnetism dataset", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.8489654958248138}]}, {"text": "To evaluate soft cardinality's robustness to disfluency, we created a duplicate of the Energy and Circuits dataset and manually spell-corrected it. and show our results.", "labels": [], "entities": [{"text": "Energy and Circuits dataset", "start_pos": 87, "end_pos": 114, "type": "DATASET", "confidence": 0.6887105852365494}]}, {"text": "Using the Kruskal-Wallis Test, on the uncorrected data PFC's accuracy suffered with marginal significance (p = .054) while macro-averaged precision and recall both suffered significantly (p < .01).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9966733455657959}, {"text": "precision", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9553385376930237}, {"text": "recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9992039799690247}]}, {"text": "Soft cardinality suffered much less, with a marginally significant decrease in performance (p=.075) only in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9907903671264648}]}, {"text": "The decreases inaccuracy and precision had p=.88 and p=.25 respectively.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.99339359998703}, {"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9997853636741638}]}, {"text": "To determine the usefulness of automatic grading of science content in predicting the overall trajectory of a student's performance, we computed a running average of the grades given by soft cardinality (converted to '1', '2', and '3' for incorrect, partially correct, correct) on students' answers as they progressed through the Energy and Circuits module and the Magnetism module.", "labels": [], "entities": []}, {"text": "Because we would intend to be able to use this technique in a classroom on entirely new questions and student answers, we use running average instead of a regression, which would require prior data on the questions to determine the weights.", "labels": [], "entities": [{"text": "running average", "start_pos": 126, "end_pos": 141, "type": "METRIC", "confidence": 0.9354417026042938}]}, {"text": "Students completed a multiple-choice test before and after their interaction with the CYBER-PAD.", "labels": [], "entities": [{"text": "CYBER-PAD", "start_pos": 86, "end_pos": 95, "type": "DATASET", "confidence": 0.9799721837043762}]}, {"text": "The Energy and Circuits module and the Magnetism module each had different teststhere were ten questions on the Energy and Circuits test and twenty on the Magnetism test.", "labels": [], "entities": [{"text": "Magnetism test", "start_pos": 155, "end_pos": 169, "type": "DATASET", "confidence": 0.7073455154895782}]}, {"text": "We calculated the correlation of our running average of formative assessments against the student's score on the final test.", "labels": [], "entities": [{"text": "running average", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.9626071453094482}]}, {"text": "A critical assumption underlying the running average is that students answered each question in order.", "labels": [], "entities": [{"text": "running average", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.9527338743209839}]}, {"text": "Although WRITEEVAL does not prevent students from answering questions out of order, it is organized to strongly encourage linear progression.", "labels": [], "entities": [{"text": "WRITEEVAL", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.8396378755569458}]}, {"text": "We excluded empty responses from the running average because we did not want an artificial boost from simply noting what questions students did and did not answer.", "labels": [], "entities": []}, {"text": "Data from students who did not take the pre or post-test was excluded, and students missing responses to more than twenty out of twenty-nine questions in Magnetism or fifteen out of twenty questions in Energy and Circuits were excluded from consideration.", "labels": [], "entities": []}, {"text": "After cleaning, our results include 85 students in Energy and Circuits and 61 in Magnetism..", "labels": [], "entities": []}, {"text": "Accuracy and Macro-Averaged Precision and Recall for Soft-Cardinality and PFC on spell-corrected and uncorrected versions of the LEONARDO Energy and Circuits module.", "labels": [], "entities": [{"text": "Precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.846522867679596}, {"text": "Recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.997866690158844}]}, {"text": "*marginally significant decrease from spellchecked **significant decrease from spell-checked depicts the correlation between the running average of automatic scoring by WRITEEVAL soft cardinality, PFC, and human scores with post-test score on the responses in the Energy and Circuits module.", "labels": [], "entities": [{"text": "running average", "start_pos": 129, "end_pos": 144, "type": "METRIC", "confidence": 0.9623124301433563}, {"text": "WRITEEVAL soft cardinality", "start_pos": 169, "end_pos": 195, "type": "METRIC", "confidence": 0.7805498043696085}]}, {"text": "When spellcorrected, the correlation, as shown in, surprisingly becomes worse.", "labels": [], "entities": [{"text": "correlation", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9797539114952087}]}, {"text": "We discuss a possible reason for this in the discussion section.", "labels": [], "entities": []}, {"text": "shows correlation of the running average of Magnetism's automatic scores with posttest.", "labels": [], "entities": [{"text": "running average", "start_pos": 25, "end_pos": 40, "type": "METRIC", "confidence": 0.9777892827987671}, {"text": "Magnetism", "start_pos": 44, "end_pos": 53, "type": "TASK", "confidence": 0.8168501257896423}, {"text": "posttest", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9502736330032349}]}, {"text": "For soft cardinality, significant correlation starts five questions in and stays for the rest of the 29.", "labels": [], "entities": [{"text": "correlation", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.9624090194702148}]}, {"text": "As it relies heavily on relevant training data, PFC is less stable and does not achieve nearly as high a correlation.", "labels": [], "entities": [{"text": "PFC", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8212091326713562}]}], "tableCaptions": [{"text": " Table 1. Accuracy and Macro-Averaged Preci- sion and Recall for Soft-Cardinality and PFC on  spell-corrected and uncorrected versions of the  LEONARDO Energy and Circuits module.  *marginally significant decrease from spell- checked  **significant decrease from spell-checked", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998981773853302}, {"text": "Preci- sion", "start_pos": 38, "end_pos": 49, "type": "METRIC", "confidence": 0.9360293745994568}, {"text": "Recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9706893563270569}, {"text": "PFC", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9607071876525879}]}]}