{"title": [{"text": "Word Segmenter for Chinese Micro-blogging Text Segmentation \uf0be Report for CIPS-SIGHAN'2014 Bakeoff", "labels": [], "entities": [{"text": "Word Segmenter", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6100290864706039}, {"text": "Chinese Micro-blogging Text Segmentation", "start_pos": 19, "end_pos": 59, "type": "TASK", "confidence": 0.5362799912691116}, {"text": "CIPS-SIGHAN'2014", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.667756199836731}, {"text": "Bakeoff", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.7704964876174927}]}], "abstractContent": [{"text": "This paper presents our system for the CIPS-SIGHAN-2014 bakeoff task of Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.5307373801867167}]}, {"text": "This system adopts a character-based joint approach, which combines a character based generative model and a character-based discriminative model.", "labels": [], "entities": []}, {"text": "To further improve the performance in cross-domain, an external dictionary is employed.", "labels": [], "entities": []}, {"text": "In addition, pre-processing and post-processing rules are utilized to further improve the performance.", "labels": [], "entities": []}, {"text": "The final performance on the test corpus shows that our system achieves comparable results with other state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Because Chinese text is written without natural delimiters, word segmentation is a prerequisite and fundamental task in Chinese natural language processing.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7229772061109543}, {"text": "Chinese natural language processing", "start_pos": 120, "end_pos": 155, "type": "TASK", "confidence": 0.6253083422780037}]}, {"text": "And many approaches have been proposed for this task.", "labels": [], "entities": []}, {"text": "Among these methods, the character-based tagging approach has become the prevailing technique for Chinese word segmentation (CWS) due to its good performance.", "labels": [], "entities": [{"text": "character-based tagging", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.6120710223913193}, {"text": "Chinese word segmentation (CWS)", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.7644873609145483}]}, {"text": "In recent years, within the framework of character-based, much efforts () have been made to further improve word segmentation's performance.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7531042397022247}]}, {"text": "The character-based joint model () achieves a good balance between in-vocabulary (IV) words recognition and out-of-vocabulary (OOV) words identification.", "labels": [], "entities": [{"text": "words recognition", "start_pos": 86, "end_pos": 103, "type": "TASK", "confidence": 0.7252090573310852}, {"text": "out-of-vocabulary (OOV) words identification", "start_pos": 108, "end_pos": 152, "type": "TASK", "confidence": 0.6931393692890803}]}, {"text": "So, in this evaluation task, following their work we adopt the character-based joint model as our basic system, which combines a character-based discriminative model and a character-based generative model.", "labels": [], "entities": []}, {"text": "The generative module holds a robust performance on IV words, while the discriminative module can handle the extra features easily and enhance the OOV words segmentation.", "labels": [], "entities": [{"text": "OOV words segmentation", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.6442905962467194}]}, {"text": "Because the 2014 SIGHAN bakeoff task of Chinese Word Segmentation is an opened evaluation task and no training set is provided, the OOV problem will be more serious.", "labels": [], "entities": [{"text": "SIGHAN bakeoff task of Chinese Word Segmentation", "start_pos": 17, "end_pos": 65, "type": "TASK", "confidence": 0.5575774397168841}, {"text": "OOV", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.631372332572937}]}, {"text": "Although the discriminative module can handle some cases of OOV, the performance is less preferable if no technique is utilized.", "labels": [], "entities": [{"text": "OOV", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.5657008290290833}]}, {"text": "Soto further improve the performance of the basic system and minimize the OOV, we employ an external dictionary containing a large set of unknown words from different domains.", "labels": [], "entities": [{"text": "OOV", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9979977011680603}]}, {"text": "Another notable problem is the Microblog text segmentation because Microblog has become anew Internet literary which is different from the genres of common text.", "labels": [], "entities": [{"text": "Microblog text segmentation", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.8039764165878296}, {"text": "Microblog", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.9652025103569031}]}, {"text": "To make our system more robust on Microblog text, we propose several simple but novel pre-processing and post-processing approaches in our system.", "labels": [], "entities": [{"text": "Microblog text", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9594897925853729}]}, {"text": "The final results show that our system performs well on test set and achieves comparable segmentation results with other participants.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first evaluate our approach on the five test datasets using different strategies.", "labels": [], "entities": []}, {"text": "The results are shown in and the evaluation criterion is F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.994976282119751}]}, {"text": "The strategies we used are: \uf06c Joint: represents the result of our model without dictionary.", "labels": [], "entities": []}, {"text": "\uf06c +Dic: represents the result of our model using the external dictionary.", "labels": [], "entities": []}, {"text": "\uf06c +Rule: represents the result of our model using the external dictionary and the preprocessing and post-processing rules.", "labels": [], "entities": []}, {"text": "As shows, our joint model performs well on all the five datasets even though the domain of the training data which is mainly composed of news data is different from the test sets.", "labels": [], "entities": []}, {"text": "This shows that our character-based joint model is very robust and can achieve a good balance between in-vocabulary (IV) words recognition and OOV words identification After the external dictionary added, the performance increased a lot, which shows the external dictionary is very useful and can help alleviate the OOV problem efficiently.", "labels": [], "entities": [{"text": "words recognition", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.7363277673721313}, {"text": "OOV words identification", "start_pos": 143, "end_pos": 167, "type": "TASK", "confidence": 0.6694332361221313}]}, {"text": "Finally, we adopt the pre-processing and post-processing rules in our system, the performance can be further improved on all testing set except Testing-C. Since the final test data will be multi-domain, we add all the five datasets to the training data and retrain the segmentation model.", "labels": [], "entities": []}, {"text": "Then we apply the retrained model to the final test data (containing 1,665 sentences) and the performance is shown in. shows that our system can achieve an F-score of 0.9578.", "labels": [], "entities": [{"text": "F-score", "start_pos": 156, "end_pos": 163, "type": "METRIC", "confidence": 0.9993250370025635}]}], "tableCaptions": [{"text": " Table 2: Evaluation results with different strategies", "labels": [], "entities": []}, {"text": " Table 3: Final Result of the Test Set", "labels": [], "entities": [{"text": "Test Set", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.7836936116218567}]}]}