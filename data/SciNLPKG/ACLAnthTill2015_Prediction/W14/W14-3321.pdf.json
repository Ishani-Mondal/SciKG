{"title": [{"text": "Machine Translation and Monolingual Postediting: The AFRL WMT-14 System", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7570017278194427}, {"text": "AFRL WMT-14", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.8019180297851562}]}], "abstractContent": [{"text": "This paper describes the AFRL statistical MT system and the improvements that were developed during the WMT14 evaluation campaign.", "labels": [], "entities": [{"text": "AFRL statistical MT", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.5356095135211945}, {"text": "WMT14 evaluation", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.5974719226360321}]}, {"text": "As part of these efforts we experimented with a number of extensions to the standard phrase-based model that improve performance on Russian to English and Hindi to English translation tasks.", "labels": [], "entities": [{"text": "Hindi to English translation tasks", "start_pos": 155, "end_pos": 189, "type": "TASK", "confidence": 0.7241507649421692}]}, {"text": "In addition, we describe our efforts to make use of monolingual English speakers to correct the output of machine translation, and present the results of monolingual postediting of the entire 3003 sentences of the WMT14 Russian-English test set.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7096821367740631}, {"text": "WMT14 Russian-English test set", "start_pos": 214, "end_pos": 244, "type": "DATASET", "confidence": 0.901820182800293}]}], "introductionContent": [{"text": "As part of the 2014 Workshop on Machine Translation (WMT14) shared translation task, the human language technology team at the Air Force Research Laboratory participated in two language pairs: Russian-English and Hindi-English.", "labels": [], "entities": [{"text": "2014 Workshop on Machine Translation (WMT14) shared translation task", "start_pos": 15, "end_pos": 83, "type": "TASK", "confidence": 0.7538781247355721}, {"text": "Air Force Research Laboratory", "start_pos": 127, "end_pos": 156, "type": "DATASET", "confidence": 0.8204062879085541}]}, {"text": "Our machine translation system represents enhancements to our system from IWSLT 2013 (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7370064556598663}, {"text": "IWSLT 2013", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9216006696224213}]}, {"text": "In this paper, we focus on enhancements to our procedures with regard to data processing and the handling of unknown words.", "labels": [], "entities": [{"text": "data processing", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.7563813328742981}, {"text": "handling of unknown words", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.8760586977005005}]}, {"text": "In addition, we describe our efforts to make use of monolingual English speakers to correct the output of machine translation, and present the results of monolingual postediting of the entire 3003 sentences of the WMT14 RussianEnglish test set.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7084275335073471}, {"text": "WMT14 RussianEnglish test set", "start_pos": 214, "end_pos": 243, "type": "DATASET", "confidence": 0.9074732661247253}]}, {"text": "Using a binary adequacy classification, we evaluate the entire postedited \u2020 This work is sponsored by the Air Force Research Laboratory under Air Force contract FA-8650-09-D-6939-029.", "labels": [], "entities": [{"text": "Air Force Research Laboratory", "start_pos": 106, "end_pos": 135, "type": "DATASET", "confidence": 0.8393405824899673}, {"text": "FA-8650-09-D-6939-029", "start_pos": 161, "end_pos": 182, "type": "DATASET", "confidence": 0.39641138911247253}]}, {"text": "test set for correctness against the reference translations.", "labels": [], "entities": []}, {"text": "Using bilingual judges, we further evaluate a substantial subset of the postedited test set using a more fine-grained adequacy metric; using this metric, we show that monolingual posteditors can successfully produce postedited translations that convey all or most of the meaning of the original source sentence in up to 87.8% of sentences.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Translation results, as measured by  BLEU (Papineni et al., 2002).", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.954587459564209}, {"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9973834156990051}]}, {"text": " Table 3: Number of documents within the  Russian-English test set processed by each  monolingual human posteditor. Number of  machine translated sentences processed by  each posteditor is also listed, along with the  total number of words in the corresponding  Russian source sentences.", "labels": [], "entities": [{"text": "Russian-English test set processed", "start_pos": 42, "end_pos": 76, "type": "DATASET", "confidence": 0.7699704021215439}]}, {"text": " Table 4: For each monolingual posteditor, the  number and percentage of sentences judged to  be correct (\u2713) versus incorrect (\u2717) according  to a monolingual human judge.", "labels": [], "entities": []}, {"text": " Table 5: Evaluation guidelines for bilingual  human judges, adapted from Albrecht et al.  (2009).", "labels": [], "entities": []}, {"text": " Table 7: Number of sentences in each evalu- ation category (see", "labels": [], "entities": []}]}