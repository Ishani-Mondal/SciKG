{"title": [{"text": "Reducing Sparsity Improves the Recognition of Implicit Discourse Relations", "labels": [], "entities": [{"text": "Sparsity Improves", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.6915372759103775}, {"text": "Recognition of Implicit Discourse", "start_pos": 31, "end_pos": 64, "type": "TASK", "confidence": 0.8359013348817825}]}], "abstractContent": [{"text": "The earliest work on automatic detection of implicit discourse relations relied on lexical features.", "labels": [], "entities": [{"text": "automatic detection of implicit discourse relations", "start_pos": 21, "end_pos": 72, "type": "TASK", "confidence": 0.8096406211455663}]}, {"text": "More recently, researchers have demonstrated that syntactic features are superior to lexical features for the task.", "labels": [], "entities": []}, {"text": "In this paper we reexamine the two classes of state of the art representations: syntactic production rules and word pair features.", "labels": [], "entities": []}, {"text": "In particular, we focus on the need to reduce sparsity in instance representation , demonstrating that different representation choices even for the same class of features may exacerbate sparsity issues and reduce performance.", "labels": [], "entities": []}, {"text": "We present results that clearly reveal that lexicalization of the syntactic features is necessary for good performance.", "labels": [], "entities": []}, {"text": "We introduce a novel, less sparse, syntactic representation which leads to improvement in discourse relation recognition.", "labels": [], "entities": [{"text": "discourse relation recognition", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.6634098986784617}]}, {"text": "Finally, we demonstrate that classifiers trained on different representations , especially lexical ones, behave rather differently and thus could likely be combined in future systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Implicit discourse relations hold between adjacent sentences in the same paragraph, and are not signaled by any of the common explicit discourse connectives such as because, however, meanwhile, etc.", "labels": [], "entities": []}, {"text": "Consider the two examples below, drawn from the Penn Discourse Treebank (PDTB) (, of a causal and a contrast relation, respectively.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB)", "start_pos": 48, "end_pos": 78, "type": "DATASET", "confidence": 0.9504426519076029}]}, {"text": "The italic and bold fonts mark the arguments of the relation, i.e the portions of the text connected by the discourse relation.", "labels": [], "entities": []}, {"text": "Ex1: Mrs Yeargin is lying.", "labels": [], "entities": [{"text": "Mrs", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.9520511031150818}, {"text": "Yeargin", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.5390051007270813}]}, {"text": "[Implicit = BECAUSE] They found students in an advanced class a year earlier who said she gave them similar help.", "labels": [], "entities": [{"text": "BECAUSE", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.8363080620765686}]}, {"text": "Ex2: Back downtown, the execs squeezed in a few meetings at the hotel before boarding the buses again.", "labels": [], "entities": []}, {"text": "[Implicit = BUT] This time, it was for dinner and dancing -a block away.", "labels": [], "entities": [{"text": "Implicit", "start_pos": 1, "end_pos": 9, "type": "METRIC", "confidence": 0.9823741912841797}, {"text": "BUT", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.8290789723396301}]}, {"text": "The task is undisputedly hard, partly because it is hard to come up with intuitive feature representations for the problem.", "labels": [], "entities": []}, {"text": "Lexical and syntactic features form the basis of the most successful studies on supervised prediction of implicit discourse relations in the PDTB.", "labels": [], "entities": []}, {"text": "Lexical features were the focus of the earliest work in discourse recognition, when cross product of words (word pairs) in the two spans connected via a discourse relation was studied.", "labels": [], "entities": [{"text": "discourse recognition", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.7313313484191895}]}, {"text": "Later, grammatical productions were found to be more effective.", "labels": [], "entities": []}, {"text": "Features of other classes such as verbs, inquirer tags, positions were also studied, but they only marginally improve upon syntactic features.", "labels": [], "entities": []}, {"text": "In this study, we compare the most commonly used lexical and syntactic features.", "labels": [], "entities": []}, {"text": "We show that representations that minimize sparsity issues are superior to their sparse counterparts, i.e. the better representations are those for which informative features occur in larger portions of the data.", "labels": [], "entities": []}, {"text": "Not surprisingly, lexical features are more sparse (occurring in fewer instances in the dataset) than syntactic features; the superiority of syntactic representations may thus be partially explained by this property.", "labels": [], "entities": []}, {"text": "More surprising findings come from a closer examination of instance representation approaches in prior work.", "labels": [], "entities": []}, {"text": "We first discuss how choices in prior work have in fact exacerbated the sparsity problem of lexical features.", "labels": [], "entities": []}, {"text": "Then, we introduce anew syntactically informed feature class, which is less sparse than prior lexical and syntactic features, and improves significantly the classification of implicit discourse relations.", "labels": [], "entities": []}, {"text": "Given these findings, we address the question if any lexical information at all should be preserved in discourse parsers.", "labels": [], "entities": []}, {"text": "We find that purely syntactic representations show lower recognition for most relations, indicating that lexical features, albeit sparse, are necessary for the task.", "labels": [], "entities": []}, {"text": "Lexical features also account fora high percentage of the most predictive features.", "labels": [], "entities": []}, {"text": "We further quantify the agreement of predictions produced from classifiers using different instance representations.", "labels": [], "entities": []}, {"text": "We find that our novel syntactic representation is better for implicit discourse relation prediction than prior syntactic feature because it has higher overall accuracy and makes correct predictions for instances for which the alternative representations are also correct.", "labels": [], "entities": [{"text": "discourse relation prediction", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.6222968697547913}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.997819185256958}]}, {"text": "Different representation of lexical features however appear complementary to each other, with markedly higher fraction of instances recognized correctly by only one of the models.", "labels": [], "entities": []}, {"text": "Our work advances the state of the art in implicit discourse recognition by clarifying the extent to which sparsity issues influence predictions, by introducing a strong syntactic representation and by documenting the need for furthermore complex integration of lexical information.", "labels": [], "entities": [{"text": "implicit discourse recognition", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6194084485371908}]}], "datasetContent": [{"text": "In our experiments we use only lexical and syntactic features.", "labels": [], "entities": []}, {"text": "This choice is motivated by the fact that lexical features have been used most widely for the task and that recent work has demonstrated that syntactic features are the single best type of representation.", "labels": [], "entities": []}, {"text": "Adding additional features only minimally improves performance (.", "labels": [], "entities": []}, {"text": "By zeroing in only on these classes of features we are able to discuss more clearly the impact that different instance representation have on sparsity and classifier performance.", "labels": [], "entities": []}, {"text": "We use gold-standard parses from the original Penn Treebank for syntax features.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9933283925056458}]}, {"text": "To ensure that our conclusions are based on analysis of the most common relations, we train binary SVM classifiers 2 for the seven relations described above.", "labels": [], "entities": []}, {"text": "We adopt the standard practice in 1 All other sub-classes of implicit relations are too small for general practical applications.", "labels": [], "entities": []}, {"text": "For example the Alternative class and Concession class have only 185 and 228 occurrences, respectively, in the 16,224 implicit relation annotations of the PDTB.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 155, "end_pos": 159, "type": "DATASET", "confidence": 0.9684804677963257}]}, {"text": "We use SVMLight (Joachims, 1999) with linear kernel.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F-scores and average accuracies of paired  and binary representations of words.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9753241539001465}]}, {"text": " Table 2: Number of features and rate of occur- rence for binary lexical representation, production  rules and sticks.", "labels": [], "entities": [{"text": "rate of occur- rence", "start_pos": 33, "end_pos": 53, "type": "METRIC", "confidence": 0.7584758996963501}]}, {"text": " Table 3: F-scores and average accuracies of pro- duction rules and production sticks.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9944385290145874}, {"text": "accuracies", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.7533290386199951}]}, {"text": " Table 4: F-scores and average accuracies of pro- duction rules and sticks, with (rows 1-2) and with- out (rows 3-4) lexical items.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9910566806793213}]}, {"text": " Table 5: Number of features and rate of occur- rence for production rules and sticks, with (rows  1-2) and without (rows 3-4) lexical items.", "labels": [], "entities": [{"text": "rate of occur- rence", "start_pos": 33, "end_pos": 53, "type": "METRIC", "confidence": 0.8214542508125305}]}, {"text": " Table 6: Non-lexical features selected using fea- ture selection. %-nonlex records the percentage of  non-lexical features among all features selected;  %-allfeats records the percentage of selected non- lexical features among all non-lexical features.", "labels": [], "entities": []}, {"text": " Table 8: F-score (accuracy) of each relation for  each feature representation. The representations  in each relation are sorted in descending order.  The column \"sig-best\" marks the significance test  result against the best representation, the col- umn \"sig-worst\" marks the significance test re- sult against the worst representation. \"Y\" denotes  p \u2264 0.05, \"T\" denotes p \u2264 0.1.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9985334873199463}, {"text": "accuracy)", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9675560593605042}]}, {"text": " Table 9: Q statistic and disagreement of different  classes of representations", "labels": [], "entities": [{"text": "disagreement", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9134746193885803}]}]}