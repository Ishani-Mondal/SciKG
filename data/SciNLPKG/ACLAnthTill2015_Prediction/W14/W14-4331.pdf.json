{"title": [{"text": "Detecting Inappropriate Clarification Requests in Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Detecting Inappropriate Clarification Requests", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8756325840950012}]}], "abstractContent": [{"text": "Spoken Dialogue Systems ask for clarification when they think they have misunderstood users.", "labels": [], "entities": []}, {"text": "Such requests may differ depending on the information the system believes it needs to clarify.", "labels": [], "entities": []}, {"text": "However, when the error type or location is misiden-tified, clarification requests appear confusing or inappropriate.", "labels": [], "entities": []}, {"text": "We describe a clas-sifier that identifies inappropriate requests, trained on features extracted from user responses in laboratory studies.", "labels": [], "entities": []}, {"text": "This classi-fier achieves 88.5% accuracy and .885 F-measure in detecting such requests.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9211101531982422}, {"text": "F-measure", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9976447224617004}]}], "introductionContent": [{"text": "When Spoken Dialogue Systems (SDS) believe they have not understood a user, they generate requests for clarification.", "labels": [], "entities": []}, {"text": "For example, in the following exchange, the System believes it has misunderstood the word Washington in the user's utterance and asks a clarification question, prompting the user to repeat the misrecognized word.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the Weka machine learning library) to train classifiers to predict whether a clarification request was appropriate or inappropriate.", "labels": [], "entities": [{"text": "Weka machine learning library", "start_pos": 12, "end_pos": 41, "type": "DATASET", "confidence": 0.9047641307115555}]}, {"text": "Our features were extracted from transcripts of user utterances, and included lexical, syntactic, numeric, and features from the output of Linguistic Inquiry and Word Count (LIWC) as described in.", "labels": [], "entities": []}, {"text": "We included unigram and bigram features, excluding unigrams that appeared fewer than 3 times in the dataset (11% of the unigrams), and bigrams that appeared fewer than 2 times (25%), with thresholds set empirically.", "labels": [], "entities": []}, {"text": "LIWC features were extracted using the LIWC 2007 software, which includes lexical categories, such as articles and negations, and psychological constructs, such as affect and cognition.", "labels": [], "entities": [{"text": "LIWC 2007 software", "start_pos": 39, "end_pos": 57, "type": "DATASET", "confidence": 0.9346153338750204}]}, {"text": "In one version of the corpus, we replaced sequences of user spellings with the tag \"SPELL\" and disfluencies with the symbol \"DISF\".", "labels": [], "entities": [{"text": "SPELL", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.9699572324752808}]}, {"text": "We used the Stanford POS tagger ( to tag both the original corpus as well as the modified version.", "labels": [], "entities": [{"text": "Stanford POS tagger", "start_pos": 12, "end_pos": 31, "type": "DATASET", "confidence": 0.8620623548825582}]}, {"text": "In the latter, we replaced the \"SPELL\" and  \"DISF\" tags with the symbols themselves.", "labels": [], "entities": [{"text": "SPELL", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.8048953413963318}]}, {"text": "We also mapped nine of the most frequent unigrams to their own POS classes, such as \"no\", \"not\", and \"neither\" to \"NO\" and \"word\" to \"WORD\".", "labels": [], "entities": []}, {"text": "We then used counts of POS bigrams as a syntactic feature.", "labels": [], "entities": []}, {"text": "Additionally, as we observed that responses to inappropriate requests contained a higher proportion of function words, we added this as a numeric feature.", "labels": [], "entities": []}, {"text": "We also observed that average length of responses to inappropriate requests was greater than responses to appropriate ones, and we hypothesized this was in part due to inappropriate requests to spell long phrases.", "labels": [], "entities": [{"text": "length", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.8165387511253357}]}, {"text": "Therefore, we also used the length of the total spelling sequences, or the count of letters spelled out, as a numeric feature.", "labels": [], "entities": [{"text": "length", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9605450630187988}]}, {"text": "We also added type of clarification request as a feature since some requests are less likely to be inappropriate than others.", "labels": [], "entities": []}, {"text": "For example, we consider confirmation questions (\"Did you say . .", "labels": [], "entities": [{"text": "confirmation", "start_pos": 25, "end_pos": 37, "type": "TASK", "confidence": 0.9488636255264282}]}, {"text": "?\") to always be appropriate.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Classifying Inappropriate Requests: All  Features vs. Baseline vs. Leave-One-Out Classi- fiers, where * indicates statistically significant dif- ference from All Features (p < 0.01)", "labels": [], "entities": [{"text": "Classifying Inappropriate Requests", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.7713654239972433}, {"text": "statistically significant dif- ference", "start_pos": 124, "end_pos": 162, "type": "METRIC", "confidence": 0.6505451202392578}]}]}