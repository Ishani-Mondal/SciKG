{"title": [{"text": "Generating Subjective Responses to Opinionated Articles in Social Media: An Agenda-Driven Architecture and a Turing-Like Test", "labels": [], "entities": [{"text": "Generating Subjective Responses to Opinionated Articles in Social Media", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.8178189131948683}]}], "abstractContent": [{"text": "Natural language traffic in social media (blogs, microblogs, talkbacks) enjoys vast monitoring and analysis efforts.", "labels": [], "entities": []}, {"text": "However , the question whether computer systems can generate such content in order to effectively interact with humans has been only sparsely attended to.", "labels": [], "entities": []}, {"text": "This paper presents an architecture for generating subjective responses to opinionated articles based on users' agenda, docu-ments' topics, sentiments and a knowledge graph.", "labels": [], "entities": []}, {"text": "We present an empirical evaluation method for quantifying the human-likeness and relevance of the generated responses.", "labels": [], "entities": []}, {"text": "We show that responses generated using world knowledge in the input are regarded as more human-like than those that rely on topic, sentiment and agenda only, whereas the use of world knowledge does not affect perceived relevance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Digital media, user-generated content and social networks enable effective human interaction; so much so that much of our day-to-day interaction is conducted online (.", "labels": [], "entities": []}, {"text": "Interaction in social media fundamentally changes the way businesses and consumers behave), can be instrumental to the success of individuals and businesses, and even affects the stability of political regimes.", "labels": [], "entities": []}, {"text": "These facts force organizations (businesses, governments, and non-profit organizations) to be constantly involved in the monitoring of, and the interaction with, human agents in digital environments (.", "labels": [], "entities": []}, {"text": "Automatic analysis of user-generated online content benefits from extensive research and commercial opportunities.", "labels": [], "entities": []}, {"text": "In natural language processing, there is ample research on the analysis of subjectivity and sentiment of content in social media.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6645256280899048}]}, {"text": "The development of tools for sentiment analysis (, mood aggregation (, opinion mining, and many more, now enjoys wide interest and exposure, as is also evident by the many workshops and dedicated tracks at ACL venues.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9849612712860107}, {"text": "opinion mining", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.7521083354949951}]}, {"text": "Methods are also developed for the analysis of political texts) and for text-driven forecasting based on these data (.", "labels": [], "entities": [{"text": "text-driven forecasting", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.5575884431600571}]}, {"text": "A related strand of research uses computational methods to find out what kind of published utterances are influential, and how they affect linguistic communities (Danescu-Niculescu-).", "labels": [], "entities": []}, {"text": "Such work complements, and contributes to, studies from sociology and sociolinguistics that aim to delineate the process of generating meaningful responses (e.g.,).", "labels": [], "entities": []}, {"text": "In contrast to these analysis efforts, the topic of generating responses to content in social media is only sparsely explored.", "labels": [], "entities": []}, {"text": "Commercially, there is movement towards online response automation.", "labels": [], "entities": [{"text": "online response automation", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.683307558298111}]}, {"text": "Research on user interfaces is trying to move away from scriptbased interaction towards the development of chat bots that attempt natural human-like interaction ().", "labels": [], "entities": []}, {"text": "However, these chat bots are typically designed to provide an automated one-size-fits-all type of interaction.", "labels": [], "entities": []}, {"text": "A study by addresses the generation of responses to natural language tweets in a data-driven setup.", "labels": [], "entities": []}, {"text": "It applies a machine-translation approach to response generation, where moods and sentiments already ex-pressed in the past are replicated or reused.", "labels": [], "entities": [{"text": "response generation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.9491169154644012}]}, {"text": "A recent study by modifies Ritter's approach to produce responses that elicit an emotion from the addressee.", "labels": [], "entities": []}, {"text": "Yet, these responses do not target particular topics and are not driven by a user agenda.", "labels": [], "entities": []}, {"text": "The present paper addresses the problem of generating novel, subjective, responses to online opinionated articles.", "labels": [], "entities": []}, {"text": "We formally define the document-to-response mapping problem and suggest an end-to-end system to solve it.", "labels": [], "entities": [{"text": "document-to-response mapping problem", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.7827185094356537}]}, {"text": "Our system integrates a range of NLP and NLG technologies (including topic models, sentiment analysis, and the integration of a knowledge graph) to design a flexible generation mechanism that allows us to vary the information in the input to the generation procedure.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.9042439758777618}]}, {"text": "We then use a Turing-inspired test to study the different factors that contribute to the perceived human-likeness and relevance of the generated responses, and show how the perception of responses depends on external knowledge and the expressed sentiment.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents our proposal: Section 2.1 describes our approach, Section 2.2 formalizes the proposal, and Section 2.3 presents our end-to-end architecture.", "labels": [], "entities": []}, {"text": "This is followed by our evaluation method and empirical results in Section 3.", "labels": [], "entities": []}, {"text": "We discuss related and future work in Section 4, and in Section 5 we conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "We set out to evaluate how computer-generated responses compare to human responses in their perceived human-likeness and relevance.", "labels": [], "entities": []}, {"text": "More in particular, we compare different system variants in order to investigate what makes responses seem more human-like or relevant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Responses generated by the system with or without a knowledge-base (KB), with different  sentiment levels.", "labels": [], "entities": []}, {"text": " Table 4: Computer-likeness rating regression re- sults, comparing human to computer responses.", "labels": [], "entities": []}, {"text": " Table 5: Computer-likeness rating regression re- sults, comparing systems with and without KB.", "labels": [], "entities": []}, {"text": " Table 6: Mean and 95% confidence interval of  relevance rating per response category. 'Source'  indicates whether the response is from the pre- sented text snippet or a random other snippet.  \u00b1KB indicates whether g base or g kb was used.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9659368395805359}]}, {"text": " Table 7: Relevance ratings regression results,  comparing human to computer responses.", "labels": [], "entities": [{"text": "Relevance", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8510387539863586}]}, {"text": " Table 8: Relevance ratings regression results,  comparing systems with and without KB.", "labels": [], "entities": [{"text": "Relevance ratings regression", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7638652722040812}]}]}