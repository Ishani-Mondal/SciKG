{"title": [{"text": "Fast and Robust Arabic Error Correction System", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we describe the implementation of an Arabic error correction system developed for the EMNLP2014 shared task on automatic error correction for Arabic text.", "labels": [], "entities": [{"text": "Arabic error correction", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.5469811062018076}, {"text": "EMNLP2014 shared task", "start_pos": 100, "end_pos": 121, "type": "DATASET", "confidence": 0.7918675144513448}, {"text": "automatic error correction for Arabic text", "start_pos": 125, "end_pos": 167, "type": "TASK", "confidence": 0.6981020470460256}]}, {"text": "We proposed a novel algorithm, where we find some correction rules and calculate their probability based on the training data, they we rank the correction rules, then we apply them on the text to maximize the overall F-score for the provided data.", "labels": [], "entities": [{"text": "F-score", "start_pos": 217, "end_pos": 224, "type": "METRIC", "confidence": 0.9971227049827576}]}, {"text": "The system achieves and F-score of 0.6573 on the test data .", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9998146891593933}]}], "introductionContent": [{"text": "Traditional techniques in text correction is the generation of a large set of candidates for an incorrect word using different approaches like enumerating all possible candidates in edit distance of one.", "labels": [], "entities": [{"text": "text correction", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8401090800762177}]}, {"text": "Then, all the candidates are ranked such that the best candidates are ranked on the top of the list.", "labels": [], "entities": []}, {"text": "Finally, the best candidate is chosen to replace incorrect word.", "labels": [], "entities": []}, {"text": "The traditional techniques are slow, since the generation of a large set of candidates is time consuming task.", "labels": [], "entities": []}, {"text": "Also, it doesn't take into consideration the overall score of the system.", "labels": [], "entities": []}, {"text": "While, in this paper we apply a novel technique in automatic error correction, where we take into consideration the correction rules, not the variants.", "labels": [], "entities": [{"text": "automatic error correction", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.6335846285025278}]}, {"text": "In the propose technique, we order corrections to be applied on text to maximize the F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9970833659172058}]}, {"text": "This shared task was on automatic Arabic text correction.", "labels": [], "entities": [{"text": "automatic Arabic text correction", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.5344753190875053}]}, {"text": "For this task, the Qatar Arabic Language Bank (QALB) corpus ) was provided.", "labels": [], "entities": [{"text": "Qatar Arabic Language Bank (QALB) corpus", "start_pos": 19, "end_pos": 59, "type": "DATASET", "confidence": 0.9171206951141357}]}, {"text": "The QALB corpus contains a preprocessed input text with some features extracted and the corrected output.", "labels": [], "entities": [{"text": "QALB corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9363566935062408}]}, {"text": "The main issue in the shared task, that the tools used for the extraction of the provided features wasn't provided.", "labels": [], "entities": []}, {"text": "So, we had a choice, to create an algorithm that can deal with missing features, or to generate our own set of features.", "labels": [], "entities": []}, {"text": "Finally, we have chosen to generate our own set of features.", "labels": [], "entities": []}, {"text": "The proposed framework could be described as a probabilistic rule-based framework.", "labels": [], "entities": []}, {"text": "During the training of this framework, we extracted some rules and assign a probability to each rule as shown later in section 3.", "labels": [], "entities": []}, {"text": "The extracted rules are then sorted based on their probabilities.", "labels": [], "entities": []}, {"text": "And during the test, we apply the rules from the highest probability to the lowest probability one by one, on the entire test data till a stopping criteria is satisfied.", "labels": [], "entities": []}, {"text": "During the algorithm we have some kind of heuristic to estimate the F-score after each rule is apply.", "labels": [], "entities": [{"text": "F-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9968230724334717}]}, {"text": "The stopping criteria for the algorithm is that the estimated F-score start to decrease.", "labels": [], "entities": [{"text": "stopping", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9527180194854736}, {"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.997226893901825}]}, {"text": "This paper is organized as follow, in section 2, an overview of the related work in the field of error correction is discussed.", "labels": [], "entities": [{"text": "error correction", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.820390522480011}]}, {"text": "In section 3, the proposed system and its main components are explained.", "labels": [], "entities": []}, {"text": "The evaluation process is presented in section 4.", "labels": [], "entities": []}, {"text": "Finally, concluding remarks and future work are presented in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the evaluation of the system, we used the M2 scorer by.", "labels": [], "entities": []}, {"text": "When we evaluated the system with the development dataset, we have reached an F-score of 0.6817; and when the system is evaluated the test dataset, we have reached and F-score of 0.6573.", "labels": [], "entities": [{"text": "F-score", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9994762539863586}, {"text": "F-score", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9995774626731873}]}, {"text": "The proposed algorithm is very fast compared to traditional error correction algorithm.", "labels": [], "entities": [{"text": "error correction", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.6668229848146439}]}, {"text": "In traditional error correction algorithm, you generate all possible variants of an incorrect word, then you rank the solutions and choose the best solution.", "labels": [], "entities": [{"text": "error correction", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7127795368432999}]}, {"text": "But, in the proposed algorithm, you rank the rules during the training time, and you apply one rule at the time until you find an appropriate solution of an incorrect word.", "labels": [], "entities": []}, {"text": "For example, let's consider single character replace spelling error, if the incorrect word length is five characters, so you need to make ((28-1)*5) iterations to generate all possible variants of a word, while in the proposed algorithm you generate one variant at the time, and you might stop after that.", "labels": [], "entities": []}], "tableCaptions": []}