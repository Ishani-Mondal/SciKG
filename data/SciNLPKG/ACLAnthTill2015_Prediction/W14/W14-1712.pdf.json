{"title": [{"text": "NTHU at the CoNLL-2014 Shared Task", "labels": [], "entities": [{"text": "NTHU at the CoNLL-2014 Shared Task", "start_pos": 0, "end_pos": 34, "type": "DATASET", "confidence": 0.7453838934501013}]}], "abstractContent": [{"text": "In this paper, we describe a system for correcting grammatical errors in texts written by non-native learners.", "labels": [], "entities": [{"text": "correcting grammatical errors in texts written by non-native learners", "start_pos": 40, "end_pos": 109, "type": "TASK", "confidence": 0.8814672297901578}]}, {"text": "In our approach, a given sentence with syntactic features are sent to a number of modules, each focuses on a specific error type.", "labels": [], "entities": []}, {"text": "A main program integrates corrections from these modules and outputs the corrected sentence.", "labels": [], "entities": []}, {"text": "We evaluated our system on the official test data of the CoNLL-2014 shared task and obtained 0.30 in F-measure.", "labels": [], "entities": [{"text": "official test data of the CoNLL-2014 shared task", "start_pos": 31, "end_pos": 79, "type": "DATASET", "confidence": 0.7255524769425392}, {"text": "F-measure", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9977883100509644}]}], "introductionContent": [{"text": "Millions of non-native learners are using English as their second language (ESL) or foreign language (EFL).", "labels": [], "entities": []}, {"text": "These learners often make different kinds of grammatical errors and are not aware of it.", "labels": [], "entities": []}, {"text": "With a grammatical error corrector applies rules or statistical learning methods, learners can use the system to improve the quality of writing, and become more aware of the common errors.", "labels": [], "entities": [{"text": "grammatical error corrector", "start_pos": 7, "end_pos": 34, "type": "TASK", "confidence": 0.696231484413147}]}, {"text": "It may also help learners improve their writing skills.", "labels": [], "entities": []}, {"text": "The CoNLL-2014 shared task is aimed at promoting research on correcting grammatical errors.", "labels": [], "entities": [{"text": "correcting grammatical errors", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.8230887850125631}]}, {"text": "Types of errors handled in the shared task are extended from the five types in the previous shared task to include all common errors present in an essay.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the following errors made by ESL writers: \u2022 Spelling and comma \u2022 Article and determiner", "labels": [], "entities": [{"text": "Article and determiner", "start_pos": 92, "end_pos": 114, "type": "METRIC", "confidence": 0.7929718097050985}]}], "datasetContent": [{"text": "Two types of trigram language models, ngram model and recurrent neural network (RNN) model, are used in correcting spelling, noun number, word form, and determiner errors.", "labels": [], "entities": [{"text": "correcting spelling", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.9210256636142731}]}, {"text": "We trained the ngram language model on English Gigaword and BNC corpus, using the SRILM tool).", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.8590169548988342}, {"text": "SRILM", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.7667617797851562}]}, {"text": "We train the RNN model with RNNLM toolkit).", "labels": [], "entities": [{"text": "RNN model", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.8910442292690277}, {"text": "RNNLM toolkit", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.8637762367725372}]}, {"text": "Complexity of training the RNN language model is much higher, so we train it on a smaller corpus, the British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 102, "end_pos": 131, "type": "DATASET", "confidence": 0.9730472266674042}]}, {"text": "We used the Stanford Parser ( to obtain dependency relations in the preposition module, and to obtain POS tags for the word form module.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.8307517766952515}]}, {"text": "The subjectverb-agreement module also uses dependency relations contained in test data.", "labels": [], "entities": []}, {"text": "Dependency relations in Google Books Syntactic N-grams were also used to develop our dendepency-based model in the preposition module.", "labels": [], "entities": []}, {"text": "To assess the effectiveness of the proposed method, we used the official training, development, and test data of the CoNLL-2014 shared task.", "labels": [], "entities": [{"text": "CoNLL-2014 shared task", "start_pos": 117, "end_pos": 139, "type": "DATASET", "confidence": 0.8264079888661703}]}, {"text": "On the test data, our system obtained the precision, recall and F 0.5 score of 0.351, 0.189, and 0.299.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9998743534088135}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9996125102043152}, {"text": "F 0.5 score", "start_pos": 64, "end_pos": 75, "type": "METRIC", "confidence": 0.9837490121523539}]}, {"text": "The following table shows the performance breakdown by module.", "labels": [], "entities": []}, {"text": "In the spelling and hyphen module, candidates from Aspell include words that only differ from the original word in one character, s.", "labels": [], "entities": [{"text": "Aspell", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.8936633467674255}]}, {"text": "Language models are then used to choose the candidate with highest probability as our correction.", "labels": [], "entities": []}, {"text": "The module therefore gives some corrections about noun numbers or subject-verb-agreement.", "labels": [], "entities": []}, {"text": "As a result, some corrections made by this module overlap with corrections made by the noun numbers module and the subject-verb-agreement module, which makes the recall of correcting spelling and hyphen errors, 4.11%, overestimated.", "labels": [], "entities": [{"text": "recall", "start_pos": 162, "end_pos": 168, "type": "METRIC", "confidence": 0.9994664788246155}]}], "tableCaptions": []}