{"title": [{"text": "Pre-reordering Model of Chinese Special Sentences for Patent Machine Translation", "labels": [], "entities": [{"text": "Patent Machine Translation", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.5699363350868225}]}], "abstractContent": [{"text": "Chinese prepositions play an important role in sentence reordering, especially in patent texts.", "labels": [], "entities": [{"text": "sentence reordering", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7171338498592377}]}, {"text": "In this paper, a rule-based model is proposed to deal with the long distance reordering of sentences with special prepositions.", "labels": [], "entities": []}, {"text": "We firstly identify the prepositions and their syntax levels.", "labels": [], "entities": []}, {"text": "After that, sentences are parsed and transformed to be much closer to English word order with reordering rules.", "labels": [], "entities": []}, {"text": "After integrating our method into a patent MT system, the reordering and translation results of source language are effectively improved.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9591174125671387}]}], "introductionContent": [{"text": "As typical technical documents, Patents have proven to be suitable for automatic translation for its strict format and united writing pattern (Jin and Liu, 2011), and patent machine translation (MT) is one of the major application fields of MT.", "labels": [], "entities": [{"text": "automatic translation", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.6804039478302002}, {"text": "patent machine translation (MT)", "start_pos": 167, "end_pos": 198, "type": "TASK", "confidence": 0.7607468068599701}, {"text": "MT", "start_pos": 241, "end_pos": 243, "type": "TASK", "confidence": 0.9873773455619812}]}, {"text": "However, sentences in patent are known for their complicated structures with multiple verbs and prepositions.", "labels": [], "entities": []}, {"text": "Some Chinese prepositions are used to change the original S-V-O order of sentences, such as \u628a(BA), which make it more difficult for reordering in Chinese-English machine translation.", "labels": [], "entities": [{"text": "\u628a(BA)", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.7805282473564148}, {"text": "Chinese-English machine translation", "start_pos": 146, "end_pos": 181, "type": "TASK", "confidence": 0.6934810280799866}]}, {"text": "In ancient Chinese, these prepositions are mostly verbs or other notional words, and in modern Chinese they became grammatical markers after diachronic grammaticalization. and discussed the reordering function of these prepositions, and defined them as Logic-0 (L0) words.", "labels": [], "entities": []}, {"text": "A linguistic study by shows that more than 20% Chinese sentences are reordered by the prepositions, including \u628a(BA), \u5c06(JIANG), \u5411(XIANG), \u4e0e(YU), \u5bf9(DUI), \u7ed9(GEI), \u88ab(BEI), \u7531 (YOU) and \u4e3a(WEI).", "labels": [], "entities": [{"text": "BA", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9276737570762634}, {"text": "BEI", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.9234493374824524}]}, {"text": "After analyzing sentences of 500 Chinese patent documents, we find that L0 words appear more frequently in patent texts.", "labels": [], "entities": []}, {"text": "Sentences with 1 L0 word occupy 30.75%, sentences with 2 L0 word occupy 9.05%, and sentences with \u22653 L0 words occupy 2.10%.", "labels": [], "entities": []}, {"text": "Therefore, Chinese special sentences with L0 words are concerned in this paper, and we will present a pre-reordering model of these special sentences for patent translation. and show an example illustrating some of the differences in word order between Chinese and English.", "labels": [], "entities": [{"text": "patent translation.", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.721388190984726}]}, {"text": "And where a natural translation in English would be An adhesive activated by ultraviolet secures the sensor housing to the middle bracket.", "labels": [], "entities": []}, {"text": "As exemplified by this sentence, differences of word order between Chinese and English are determined by BA and YOU, and they are in two different levels in the syntax tree.", "labels": [], "entities": [{"text": "BA", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9980046153068542}, {"text": "YOU", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.9785130023956299}]}, {"text": "In order to produce a good English translation, we firstly identify L0 words in two levels, and parse the sentence into chunks with core predicate and L0 words.", "labels": [], "entities": []}, {"text": "Based on the sentence parsing, chunks are reordered according to related rules, transforming Chinese special sentence into a word order that is closer to that of English.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7607551217079163}]}, {"text": "After integrating into a patent MT system running in SIPO (State Intellectual Property Office of People's Republic of China) 1 , our model performs better than the baseline system and Google Translate in an open test, and it greatly improves the performance of patent translation.", "labels": [], "entities": [{"text": "SIPO (State Intellectual Property Office of People's Republic of China) 1", "start_pos": 53, "end_pos": 126, "type": "DATASET", "confidence": 0.7142888328858784}, {"text": "patent translation", "start_pos": 261, "end_pos": 279, "type": "TASK", "confidence": 0.7225220650434494}]}, {"text": "After a discussion of related work in section 2 and an introduction to semantic features in section 3, we will discuss the reordering model in section 4.", "labels": [], "entities": []}, {"text": "Section 5 presents the processing steps, and section 6 gives the experiment and evaluation.", "labels": [], "entities": []}, {"text": "Finally we draw some conclusions in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiment takes 500 authentic patent texts provided by SIPO (State Intellectual Property Office of China) as the training set.", "labels": [], "entities": []}, {"text": "The evaluation will use the development data for the NTCIR-9 Patent Machine Translation Pilot Task 2 , containing 2,000 bilingual Chinese-English sentence pairs.", "labels": [], "entities": [{"text": "NTCIR-9 Patent Machine Translation Pilot Task", "start_pos": 53, "end_pos": 98, "type": "TASK", "confidence": 0.789235939582189}]}, {"text": "After integrating into a rule-based patent machine translation system(Zhu et al, 2012), we will take a closed test on the training set, and an open test on the evaluation set.", "labels": [], "entities": [{"text": "rule-based patent machine translation", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6715565919876099}]}, {"text": "To evaluate the effects of the reordering rules, precision and recall are calculated by manual evaluation for both two tests.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9997112154960632}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9996480941772461}]}, {"text": "In the open test, NIST () and BLEU score () are also employed to evaluate the translation performance.", "labels": [], "entities": [{"text": "NIST", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.5878239274024963}, {"text": "BLEU score", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9856148660182953}]}, {"text": "shows the result of the closed test.", "labels": [], "entities": []}, {"text": "In the open test, comparison is made as shown in table 4.", "labels": [], "entities": []}, {"text": "RB-MT is the baseline system.", "labels": [], "entities": []}, {"text": "RB-MT+PRM is the system integrated with our reordering model.", "labels": [], "entities": []}, {"text": "GOOGLE is an online statistical MT system, the reordering result of which is inferred from its translation result.", "labels": [], "entities": [{"text": "GOOGLE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9073232412338257}, {"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.945918619632721}]}, {"text": "shows the comparison in reordering of the three systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Experiment Result on the Training Set", "labels": [], "entities": []}, {"text": " Table 4. Compared Result of the Open Test", "labels": [], "entities": [{"text": "Compared Result", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8525668978691101}, {"text": "Open Test", "start_pos": 33, "end_pos": 42, "type": "DATASET", "confidence": 0.713258370757103}]}, {"text": " Table 5. NIST and BLEU-4 Scores", "labels": [], "entities": [{"text": "NIST", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.7726205587387085}, {"text": "BLEU-4 Scores", "start_pos": 19, "end_pos": 32, "type": "METRIC", "confidence": 0.9686388671398163}]}]}