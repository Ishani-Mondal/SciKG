{"title": [{"text": "Target-Centric Features for Translation Quality Estimation", "labels": [], "entities": [{"text": "Translation Quality Estimation", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.8931581974029541}]}], "abstractContent": [{"text": "We describe the DCU-MIXED and DCU-SVR submissions to the WMT-14 Quality Estimation task 1.1, predicting sentence-level perceived post-editing effort.", "labels": [], "entities": [{"text": "WMT-14 Quality Estimation task 1.1", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.6109457373619079}]}, {"text": "Feature design focuses on target-side features as we hypothesise that the source side has little effect on the quality of human translations , which are included in task 1.1 of this year's WMT Quality Estimation shared task.", "labels": [], "entities": [{"text": "WMT Quality Estimation shared task", "start_pos": 189, "end_pos": 223, "type": "TASK", "confidence": 0.8147526621818543}]}, {"text": "We experiment with features of the QuEst framework, features of our past work, and three novel feature sets.", "labels": [], "entities": [{"text": "QuEst framework", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.8585518300533295}]}, {"text": "Despite these efforts, our two systems perform poorly in the competition.", "labels": [], "entities": []}, {"text": "Follow up experiments indicate that the poor performance is due to improperly optimised parameters .", "labels": [], "entities": []}], "introductionContent": [{"text": "Translation quality estimation tries to predict the quality of a translation given the source and target text but no reference translations.", "labels": [], "entities": [{"text": "Translation quality estimation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7568038702011108}]}, {"text": "Different from previous years, the WMT 2014 Quality Estimation shared task is MT system-independent, i. e. no glass-box features are available and translations in the training and test sets are produced by different MT systems and also by human translators.", "labels": [], "entities": [{"text": "WMT 2014 Quality Estimation shared task", "start_pos": 35, "end_pos": 74, "type": "TASK", "confidence": 0.6616380115350088}, {"text": "MT system-independent", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.8538801670074463}]}, {"text": "This paper describes the CNGL@DCU team submission to task 1.1 of the WMT 2014 Quality Estimation shared task.", "labels": [], "entities": [{"text": "CNGL@DCU team submission", "start_pos": 25, "end_pos": 49, "type": "DATASET", "confidence": 0.6624494016170501}, {"text": "WMT 2014 Quality Estimation shared task", "start_pos": 69, "end_pos": 108, "type": "TASK", "confidence": 0.6063618262608846}]}, {"text": "The task is to predict the perceived post-editing effort given a source sentence and its raw translation.", "labels": [], "entities": []}, {"text": "Due to the inclusion of human translation in the task, we focus our efforts on target-side features as we expect that the quality of a translation produced by a human translator is much less affected by features of the source than by extrinsic factors such as time pressure and familiarity with the domain.", "labels": [], "entities": []}, {"text": "To build our quality estimation system, we use and extend the QuEst framework for translation quality estimation.", "labels": [], "entities": [{"text": "translation quality estimation", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.8562586307525635}]}, {"text": "QuEst provides modules for feature extraction and machine learning.", "labels": [], "entities": [{"text": "QuEst", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9194012880325317}, {"text": "feature extraction", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7356081008911133}]}, {"text": "We modify both the feature extraction framework and the machine learning components to add functionality to QuEst.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7122474908828735}]}, {"text": "The novel features we add to our systems are (a) a language model on a combination of stop words and POS tags, (b) inverse glass-box features for translating the translation, and (c) random indexing) for measuring the semantic similarity of source and target side across languages.", "labels": [], "entities": [{"text": "translating the translation", "start_pos": 146, "end_pos": 173, "type": "TASK", "confidence": 0.8316328128178915}]}, {"text": "Furthermore, we integrated (d) sourceside pseudo-reference features and (e) error grammar features), which were used first in MT quality estimation by.", "labels": [], "entities": [{"text": "MT quality estimation", "start_pos": 126, "end_pos": 147, "type": "TASK", "confidence": 0.8930099010467529}]}, {"text": "The remaining sections are organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives details on the features we use.", "labels": [], "entities": []}, {"text": "Section 3 describes how we setup our experiments.", "labels": [], "entities": []}, {"text": "Results are presented in Section 4 and conclusions are drawn in Section 5 together with pointers to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes how we setup our experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cross-validation results for English to  German. LR > 0.5 indicates that we require the  LR decision function to be > 0.5. SVR-r rounds  the output to the nearest natural number.", "labels": [], "entities": [{"text": "LR", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9723772406578064}]}]}