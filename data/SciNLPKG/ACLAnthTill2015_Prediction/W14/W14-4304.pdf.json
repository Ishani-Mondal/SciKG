{"title": [{"text": "Situated Language Understanding at 25 Miles per Hour", "labels": [], "entities": [{"text": "Situated Language Understanding", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6599885622660319}]}], "abstractContent": [{"text": "In this paper, we address issues in situated language understanding in a rapidly changing environment-a moving car.", "labels": [], "entities": [{"text": "situated language understanding", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.742637018362681}]}, {"text": "Specifically, we propose methods for understanding user queries about specific target buildings in their surroundings.", "labels": [], "entities": []}, {"text": "Unlike previous studies on physically situated interactions such as interaction with mobile robots, the task is very sensitive to timing because the spatial relation between the car and the target is changing while the user is speaking.", "labels": [], "entities": []}, {"text": "We collected situated utterances from drivers using our research system, Townsurfer, which is embedded in areal vehicle.", "labels": [], "entities": [{"text": "Townsurfer", "start_pos": 73, "end_pos": 83, "type": "DATASET", "confidence": 0.9168856739997864}]}, {"text": "Based on this data, we analyze the timing of user queries, spatial relationships between the car and targets , head pose of the user, and linguistic cues.", "labels": [], "entities": []}, {"text": "Optimized on the data, our algorithms improved the target identification rate by 24.1% absolute.", "labels": [], "entities": [{"text": "target identification", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.6738394051790237}]}], "introductionContent": [{"text": "Recent advances in sensing technologies have enabled researchers to explore applications that require a clear awareness of the systems' dynamic context and physical surroundings.", "labels": [], "entities": []}, {"text": "Such applications include multi-participant conversation systems () and human-robot interaction).", "labels": [], "entities": []}, {"text": "The general problem of understanding and interacting with human users in such environments is referred to as situated interaction.", "labels": [], "entities": []}, {"text": "We address yet another environment, where situated interactions takes place -a moving car.", "labels": [], "entities": []}, {"text": "In the previous work, we collected over 60 hours of in-car human-human interactions, where drivers interact with an expert co-pilot sitting next to them in the vehicle ().", "labels": [], "entities": []}, {"text": "One of the * Currently with insights from the analysis on this corpus is that drivers frequently use referring expressions about their surroundings.", "labels": [], "entities": []}, {"text": "(e.g. What is that big building on the right?)", "labels": [], "entities": []}, {"text": "Based on this insight, we have developed Townsurfer (), a situated in-car intelligent assistant.", "labels": [], "entities": [{"text": "Townsurfer", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.8720031976699829}]}, {"text": "Using geo-location information, the system can answer user queries/questions that contain object references about points-of-interest (POIs) in their surroundings.", "labels": [], "entities": []}, {"text": "We use driver (user) face orientation to understand their queries and provide the requested information about the POI they are looking at.", "labels": [], "entities": []}, {"text": "We have previously demonstrated and evaluated the system in a simulated environment.", "labels": [], "entities": []}, {"text": "In this paper, we evaluate its utility in real driving situations.", "labels": [], "entities": []}, {"text": "Compared to conventional situated dialog tasks, query understanding in our task is expected to be more time sensitive, due to the rapidly changing environment while driving.", "labels": [], "entities": [{"text": "query understanding", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8096423447132111}]}, {"text": "Typically, a car will move 10 meters in one second while driving at 25 mi/h.", "labels": [], "entities": []}, {"text": "So timing can be a crucial factor.", "labels": [], "entities": [{"text": "timing", "start_pos": 3, "end_pos": 9, "type": "METRIC", "confidence": 0.7112817764282227}]}, {"text": "In addition, it is not well understood what kind of linguistic cues are naturally provided by drivers, and their contributions to situated language understanding in such an environment.", "labels": [], "entities": [{"text": "situated language understanding", "start_pos": 130, "end_pos": 161, "type": "TASK", "confidence": 0.7006928523381551}]}, {"text": "To the best of our knowledge, this is the first study that tackles the issue of situated language understanding in rapidly moving vehicles.", "labels": [], "entities": [{"text": "situated language understanding", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.6611884534358978}]}, {"text": "In this paper, we first present an overview of the Townsurfer in-car spoken dialog system (Section 2).", "labels": [], "entities": [{"text": "Townsurfer in-car spoken dialog system", "start_pos": 51, "end_pos": 89, "type": "DATASET", "confidence": 0.8480945229530334}]}, {"text": "Based on our data collection using the system, we analyze user behavior while using the system focusing on language understanding (Section 3).", "labels": [], "entities": [{"text": "language understanding", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.709507167339325}]}, {"text": "Specifically, we answer the following research questions about the task and the system through data collection and analysis: 1.", "labels": [], "entities": []}, {"text": "Is timing an important factor of situated language understanding?", "labels": [], "entities": [{"text": "situated language understanding", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6580022176106771}]}, {"text": "2. Does head pose play an important role in language understanding?", "labels": [], "entities": [{"text": "language understanding", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7501749396324158}]}, {"text": "Or is spatial distance information enough?", "labels": [], "entities": []}, {"text": "(POI located on the left) S3: This is Roger's Deli, a low-priced restaurant that serves American food.", "labels": [], "entities": [{"text": "POI", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.983752965927124}]}, {"text": "3. What is the role of linguistic cues in this task?", "labels": [], "entities": []}, {"text": "What kinds of linguistic cues do drivers naturally provide?", "labels": [], "entities": []}, {"text": "Based on the hypothesis obtained from the analysis for these questions, we propose methods to improve situated language understanding, and analyze their contributions based on the collected data (Sections 5 and 6).", "labels": [], "entities": [{"text": "situated language understanding", "start_pos": 102, "end_pos": 133, "type": "TASK", "confidence": 0.6275819838047028}]}, {"text": "We then clarify our research contributions through discussion (Section 7) and comparison with related studies (Section 8).", "labels": [], "entities": []}], "datasetContent": [{"text": "We use manual transcriptions and natural language understanding results of the user queries to focus our evaluations on the issues listed in Section 1.", "labels": [], "entities": []}, {"text": "We evaluate the situated language understanding (POI identification) performance based on cross validation.", "labels": [], "entities": [{"text": "situated language understanding (POI identification)", "start_pos": 16, "end_pos": 68, "type": "TASK", "confidence": 0.7748187695230756}]}, {"text": "We use the data from 13 users to train GMM parameters and to define a set of possible linguistic values, and the data from the remaining user for evaluation.", "labels": [], "entities": []}, {"text": "We train the model parameters of the GMM using the EM algorithm.", "labels": [], "entities": [{"text": "GMM", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.9317132830619812}]}, {"text": "Knowledge about the sites (downtown or residential area) is not used in the training . We do not set a threshold for the presentation.", "labels": [], "entities": []}, {"text": "We judge the system successfully understands a user query when the posterior of the target (userintended) POI is the highest.", "labels": [], "entities": []}, {"text": "The chance rate, given by the average of the inverse number of candidate POIs in the POI look-up is 10.0%.", "labels": [], "entities": [{"text": "chance rate", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9889363348484039}]}], "tableCaptions": [{"text": " Table 2: Comparison of average and standard deviation of distance (in meter) of POI form the car", "labels": [], "entities": [{"text": "standard deviation of distance", "start_pos": 36, "end_pos": 66, "type": "METRIC", "confidence": 0.9081651717424393}, {"text": "POI", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.8534156084060669}]}, {"text": " Table 3: User-provided linguistic cues", "labels": [], "entities": []}, {"text": " Table 4: Comparison of POI identification rate", "labels": [], "entities": [{"text": "POI identification", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8093607723712921}]}, {"text": " Table 5: Relation between the parameters used for  the POI identification and success rates (%)", "labels": [], "entities": [{"text": "Relation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.650873064994812}, {"text": "POI identification", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8763386905193329}]}]}