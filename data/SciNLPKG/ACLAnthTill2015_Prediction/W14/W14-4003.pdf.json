{"title": [{"text": "Better Semantic Frame Based MT Evaluation via Inversion Transduction Grammars", "labels": [], "entities": [{"text": "MT Evaluation", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8803655505180359}]}], "abstractContent": [{"text": "We introduce an inversion transduc-tion grammar based restructuring of the MEANT automatic semantic frame based MT evaluation metric, which, by leveraging ITG language biases, is able to further improve upon MEANT's already-high correlation with human adequacy judgments.", "labels": [], "entities": [{"text": "MEANT automatic semantic frame based MT evaluation", "start_pos": 75, "end_pos": 125, "type": "TASK", "confidence": 0.4640742114612034}]}, {"text": "The new metric, called IMEANT, uses bracketing ITGs to biparse the reference and machine translations , but subject to obeying the semantic frames in both.", "labels": [], "entities": [{"text": "IMEANT", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.5422941446304321}]}, {"text": "Resulting improvements support the presumption that ITGs, which constrain the allowable permutations between compositional segments across the reference and MT output, score the phrasal similarity of the semantic role fillers more accurately than the simple word alignment heuristics (bag-of-word alignment or maximum alignment) used in previous version of MEANT.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 357, "end_pos": 362, "type": "DATASET", "confidence": 0.6988518238067627}]}, {"text": "The approach successfully integrates (1) the previously demonstrated extremely high coverage of cross-lingual semantic frame alternations by ITGs, with (2) the high accuracy of evaluating MT via weighted f-scores on the degree of semantic frame preservation.", "labels": [], "entities": [{"text": "cross-lingual semantic frame alternations", "start_pos": 96, "end_pos": 137, "type": "TASK", "confidence": 0.6040517389774323}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9989802241325378}, {"text": "MT", "start_pos": 188, "end_pos": 190, "type": "TASK", "confidence": 0.9828295111656189}, {"text": "semantic frame preservation", "start_pos": 230, "end_pos": 257, "type": "TASK", "confidence": 0.6443090339501699}]}], "introductionContent": [{"text": "There has been to date relatively little use of inversion transduction grammars to improve the accuracy of MT evaluation metrics, despite long empirical evidence the vast majority of translation patterns between human languages can be accommodated within ITG constraints (and the observation that most current state-of-the-art SMT systems employ ITG decoders).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9965234398841858}, {"text": "MT evaluation", "start_pos": 107, "end_pos": 120, "type": "TASK", "confidence": 0.9408831000328064}, {"text": "SMT", "start_pos": 327, "end_pos": 330, "type": "TASK", "confidence": 0.9748486876487732}]}, {"text": "We show that ITGs can be used to redesign the MEANT semantic frame based MT evaluation metric ) to produce improvements inaccuracy and reliability.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.7809790968894958}]}, {"text": "This work is driven by the motivation that especially when considering semantic MT metrics, ITGs would beseem to be a natural basis for several reasons.", "labels": [], "entities": []}, {"text": "To begin with, it is quite natural to think of sentences as having been generated from an abstract concept using a rewriting system: a stochastic grammar predicts how frequently any particular realization of the abstract concept will be generated.", "labels": [], "entities": []}, {"text": "The bilingual analogy is a transduction grammar generating a pair of possible realizations of the same underlying concept.", "labels": [], "entities": []}, {"text": "Stochastic transduction grammars predict how frequently a particular pair of realizations will be generated, and thus represent a good way to evaluate how well a pair of sentences correspond to each other.", "labels": [], "entities": []}, {"text": "The particular class of transduction grammars known as ITGs tackle the problem that the (bi)parsing complexity for general syntaxdirected transductions) is exponential.", "labels": [], "entities": []}, {"text": "By constraining a syntax-directed transduction grammar to allow only monotonic straight and inverted reorderings, or equivalently permitting only binary or ternary rank rules, it is possible to isolate the low end of that hierarchy into a single equivalence class of inversion transductions.", "labels": [], "entities": []}, {"text": "ITGs are guaranteed to have a two-normal form similar to context-free grammars, and can be biparsed in polynomial time and space (O ( n 6 ) time and O ( n 4 ) space).", "labels": [], "entities": []}, {"text": "It is also possible to do approximate biparsing in O ( n 3 ) time ).", "labels": [], "entities": []}, {"text": "These polynomial complexities makes it feasible to estimate the parameters of an ITG using standard machine learning techniques such as expectation maximization . At the same time, inversion transductions have also been directly shown to be more than sufficient to account for the reordering that occur within semantic frame alternations.", "labels": [], "entities": []}, {"text": "This makes ITGs an appealing alternative for eval-uating the possible links between both semantic role fillers in different languages as well as the predicates, and how these parts fit together to form entire semantic frames.", "labels": [], "entities": []}, {"text": "We believe that ITGs are not only capable of generating the desired structural correspondences between the semantic structures of two languages, but also provide meaningful constraints to prevent alignments from wandering off in the wrong direction.", "labels": [], "entities": []}, {"text": "In this paper we show that IMEANT, anew metric drawing from the strengths of both MEANT and inversion transduction grammars, is able to exploit bracketing ITGs (also known as BITGs or BTGs) which are ITGs containing only a single non-differentiated non terminal category, so as to produce even higher correlation with human adequacy judgments than any automatic MEANT variants, or other common automatic metrics.", "labels": [], "entities": [{"text": "IMEANT", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.6680314540863037}, {"text": "BITGs", "start_pos": 175, "end_pos": 180, "type": "METRIC", "confidence": 0.9859015941619873}]}, {"text": "We argue that the constraints provided by BITGs over the semantic frames and arguments of the reference and MT output sentences are essential for accurate evaluation of the phrasal similarity of the semantic role fillers.", "labels": [], "entities": [{"text": "BITGs", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.7784589529037476}, {"text": "MT output sentences", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7958027124404907}]}, {"text": "In common with the various MEANT semantic MT evaluation metrics (, our proposed IMEANT metric measures the degree to which the basic semantic event structure is preserved by translation-the \"who did what to whom, for whom, when, where, how and why\")-emphasizing that a good translation is one that can successfully be understood by a human.", "labels": [], "entities": [{"text": "MEANT semantic MT evaluation", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.6929860711097717}]}, {"text": "In the other versions of MEANT, similarity between the MT output and the reference translations is computed as a modified weighted fscore over the semantic predicates and role fillers.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.5175842046737671}]}, {"text": "Across a variety of language pairs and genres, it has been shown that MEANT correlates better with human adequacy judgment than both n-gram based MT evaluation metrics such as BLEU), NIST, and ME-TEOR (, as well as editdistance based metrics such as CDER (), WER (), and TER) when evaluating MT output (.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.94562166929245}, {"text": "BLEU", "start_pos": 176, "end_pos": 180, "type": "METRIC", "confidence": 0.9972729086875916}, {"text": "NIST", "start_pos": 183, "end_pos": 187, "type": "DATASET", "confidence": 0.8756117820739746}, {"text": "TER", "start_pos": 271, "end_pos": 274, "type": "METRIC", "confidence": 0.9907275438308716}, {"text": "MT output", "start_pos": 292, "end_pos": 301, "type": "TASK", "confidence": 0.8867041170597076}]}, {"text": "Furthermore, tuning the parameters of MT systems with MEANT instead of BLEU or TER robustly improves translation adequacy across different genres and different languages (English and Chinese).", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.9666035771369934}, {"text": "MEANT", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.9915047287940979}, {"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9982383251190186}, {"text": "TER", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9909976720809937}]}, {"text": "This has motivated our choice of MEANT as the basis on which to experiment with deploying ITGs into semantic MT evaluation.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9249258041381836}, {"text": "MT evaluation", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.8803529441356659}]}], "datasetContent": [{"text": "Relatively little investigation into the potential benefits of ITGs is found in previous MT evaluation work.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.9105381071567535}]}, {"text": "One exception is invWER, proposed by and.", "labels": [], "entities": []}, {"text": "The invWER metric interprets weighted BITGs as a generalization of the Levenshtein edit distance, in which entire segments (blocks) can be inverted, as long as this is done strictly compositionally so as not to violate legal ITG biparse tree structures.", "labels": [], "entities": [{"text": "BITGs", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.8065006136894226}]}, {"text": "The input and output languages are considered to be those of the reference and machine translations, and thus are over the same vocabulary (say,English).", "labels": [], "entities": []}, {"text": "At the sentence level, correlation of invWER with human adequacy judgments was found to be among the best.", "labels": [], "entities": []}, {"text": "Our current approach differs in several key respects from invWER.", "labels": [], "entities": []}, {"text": "First,invWER operates purely at the surface level of exact token match, IMEANT mediates between segments of reference translation and MT output using lexical BITG probabilities.", "labels": [], "entities": []}, {"text": "Secondly, there is no explicit semantic modeling in invWER.", "labels": [], "entities": []}, {"text": "Providing they meet the BITG constraints, the biparse trees in invWER are completely unconstrained.", "labels": [], "entities": [{"text": "BITG", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9605834484100342}]}, {"text": "In contrast, IMEANT employs the same explicit, strong semantic frame modeling as MEANT, on both the reference and machine translations.", "labels": [], "entities": []}, {"text": "In IMEANT, the semantic frames always take precedence over pure BITG biases.", "labels": [], "entities": [{"text": "BITG", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.8508208990097046}]}, {"text": "Compared to invWER, this strongly constrains the space of biparses that IMEANT permits to be considered.", "labels": [], "entities": [{"text": "IMEANT", "start_pos": 72, "end_pos": 78, "type": "DATASET", "confidence": 0.496186763048172}]}, {"text": "Like invWER, other common surface-form oriented metrics like BLEU), NIST), METEOR (Banerjee and), CDER (), WER (), and TER) do not correctly reflect the meaning similarities of the input sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.997984766960144}, {"text": "METEOR", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9956047534942627}, {"text": "WER", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.958872377872467}, {"text": "TER", "start_pos": 119, "end_pos": 122, "type": "METRIC", "confidence": 0.9944915771484375}]}, {"text": "There are in fact several large scale meta-evaluations) reporting cases where BLEU strongly disagrees with human judgments of translation adequacy.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9764164090156555}]}, {"text": "Such observations have generated a recent surge of work on developing MT evaluation metrics that would outperform BLEU in correlation with human adequacy judgment (HAJ).", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.9130502045154572}, {"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9982789754867554}, {"text": "human adequacy judgment (HAJ)", "start_pos": 139, "end_pos": 168, "type": "TASK", "confidence": 0.4890376478433609}]}, {"text": "Like MEANT, the TINE automatic recall-oriented evaluation metric) aims to preserve basic event structure.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.800925076007843}, {"text": "TINE automatic recall-oriented evaluation metric", "start_pos": 16, "end_pos": 64, "type": "METRIC", "confidence": 0.651540994644165}]}, {"text": "However, its correlation with human adequacy judgment is comparable to that of BLEU and not as high as that of METEOR.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9982494711875916}, {"text": "METEOR", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.6582030653953552}]}, {"text": "improved correlation with human fluency judgments by using LFG to extend the approach of evaluating syntactic dependency structure similarity proposed by, but did not achieve higher correlation with human adequacy judgments than metrics like ME-TEOR.", "labels": [], "entities": []}, {"text": "Another automatic metric, ULC (, incorporates several semantic similarity features and shows improved correlation with human judgement of translation quality but no work has been done towards tuning an SMT system using a pure form of ULC perhaps due to its expensive run time.", "labels": [], "entities": [{"text": "SMT", "start_pos": 202, "end_pos": 205, "type": "TASK", "confidence": 0.9883549213409424}]}, {"text": "Likewise, SPEDE () predicts the edit sequence needed to match the machine translation to the reference translation via an integrated probabilistic FSM and probabilistic PDA model.", "labels": [], "entities": [{"text": "SPEDE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.6211269497871399}]}, {"text": "The semantic textual similarity metric Sagan) is based on a complex textual entailment pipeline.", "labels": [], "entities": []}, {"text": "These aggregated metrics require sophisticated feature extraction steps, contain many parameters that need to be tuned, and employ expensive linguistic resources such as WordNet or paraphrase tables.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 170, "end_pos": 177, "type": "DATASET", "confidence": 0.9387354850769043}]}, {"text": "The expensive training, tuning and/or running time renders these metrics difficult to use in the SMT training cycle.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 97, "end_pos": 109, "type": "TASK", "confidence": 0.9045325517654419}]}, {"text": "In this section we discuss experiments indicating that IMEANT further improves upon MEANT's The reduction in hierarchy helps raise the efficiency of inspection and supervisory work . [MT2] The level of reduction is conducive to raising the inspection and supervision work efficiency .  We perform the meta-evaluation upon two different partitions of the DARPA GALE P2.5 ChineseEnglish translation test set.", "labels": [], "entities": [{"text": "IMEANT", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.6053778529167175}, {"text": "MEANT", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.6677796840667725}, {"text": "MT2", "start_pos": 184, "end_pos": 187, "type": "DATASET", "confidence": 0.8393888473510742}, {"text": "DARPA GALE P2.5 ChineseEnglish translation test set", "start_pos": 354, "end_pos": 405, "type": "DATASET", "confidence": 0.8457018733024597}]}, {"text": "The corpus includes the Chinese input sentences, each accompanied by one English reference translation and three participating state-of-the-art MT systems' output.", "labels": [], "entities": []}, {"text": "For the sake of consistent comparison, the first evaluation partition, GALE-A, is the same as the one used in, and the second evaluation partition, GALE-B, is the same as the one used in Lo and Wu (2011b).", "labels": [], "entities": [{"text": "GALE-A", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.4435040056705475}]}, {"text": "For both reference and machine translations, the ASSERT () semantic role labeler was used to automatically predict semantic parses.: Sentence-level correlation with human adequacy judgements on different partitions of GALE P2.5 data.", "labels": [], "entities": [{"text": "ASSERT", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9299622178077698}, {"text": "predict semantic parses.", "start_pos": 107, "end_pos": 131, "type": "TASK", "confidence": 0.7357132236162821}, {"text": "GALE P2.5 data", "start_pos": 218, "end_pos": 232, "type": "DATASET", "confidence": 0.8357538978258768}]}, {"text": "IMEANT always yields top correlations, and is more consistent than either MEANT or its recent cross-lingual XMEANT quality estimation variant.", "labels": [], "entities": [{"text": "IMEANT", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.5605068802833557}, {"text": "MEANT", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.7908145189285278}]}, {"text": "For reference, the human HMEANT upper bound is 0.53 for GALE-A and 0.37 for GALE-B-thus, the fully automated IMEANT approximation is not far from closing the gap.", "labels": [], "entities": [{"text": "HMEANT upper", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.9384223818778992}, {"text": "GALE-A", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.5789365172386169}, {"text": "GALE-B-thus", "start_pos": 76, "end_pos": 87, "type": "DATASET", "confidence": 0.71495521068573}, {"text": "IMEANT", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.7581244111061096}]}], "tableCaptions": [{"text": " Table 1: Sentence-level correlation with human  adequacy judgements on different partitions of  GALE P2.5 data. IMEANT always yields top  correlations, and is more consistent than either  MEANT or its recent cross-lingual XMEANT  quality estimation variant. For reference, the hu- man HMEANT upper bound is 0.53 for GALE-A  and 0.37 for GALE-B-thus, the fully automated  IMEANT approximation is not far from closing the  gap.", "labels": [], "entities": [{"text": "GALE P2.5 data", "start_pos": 97, "end_pos": 111, "type": "DATASET", "confidence": 0.6323385139306387}, {"text": "MEANT", "start_pos": 189, "end_pos": 194, "type": "METRIC", "confidence": 0.7089108824729919}]}]}