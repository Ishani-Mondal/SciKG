{"title": [{"text": "Learning a Lexicon for Broad-Coverage Semantic Parsing", "labels": [], "entities": [{"text": "Broad-Coverage Semantic Parsing", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.5767609079678854}]}], "abstractContent": [{"text": "While there has been significant recent work on learning semantic parsers for specific task/ domains, the results don't transfer from one domain to another domains.", "labels": [], "entities": []}, {"text": "We describe a project to learn a broad-coverage semantic lexicon for domain independent semantic parsing.", "labels": [], "entities": [{"text": "domain independent semantic parsing", "start_pos": 69, "end_pos": 104, "type": "TASK", "confidence": 0.640167661011219}]}, {"text": "The technique involves several bootstrapping steps starting from a semantic parser based on a modest-sized hand-built semantic lexicon.", "labels": [], "entities": []}, {"text": "We demonstrate that the approach shows promise in building a semantic lexicon on the scale of WordNet, with more coverage and detail that currently available in widely-used resources such as VerbNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.9351011514663696}, {"text": "coverage", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9574521780014038}, {"text": "detail", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9065145254135132}, {"text": "VerbNet", "start_pos": 191, "end_pos": 198, "type": "DATASET", "confidence": 0.9479607343673706}]}, {"text": "We view having such a lexicon as a necessary prerequisite for any attempt at attaining broad-coverage semantic parsing in any domain.", "labels": [], "entities": [{"text": "broad-coverage semantic parsing", "start_pos": 87, "end_pos": 118, "type": "TASK", "confidence": 0.6865523060162863}]}, {"text": "The approach we described applies to all word classes, but in this paper we focus hereon verbs, which are the most critical phenomena facing semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 141, "end_pos": 157, "type": "TASK", "confidence": 0.7251690030097961}]}], "introductionContent": [], "datasetContent": [{"text": "This is a work in progress, so we do not yet have a comprehensive evaluation.", "labels": [], "entities": []}, {"text": "We do have preliminary evaluations of specific aspects of the lexical entries we are producing, however.", "labels": [], "entities": []}, {"text": "For the most part, our evaluations have been performed using set of human judges (some fellow colleagues and some recruited using Amazon Turk).", "labels": [], "entities": [{"text": "Amazon Turk", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9116369783878326}]}, {"text": "Because of the complexity of such judging tasks, we generally use at least seven judges, and sometimes up to eleven.", "labels": [], "entities": []}, {"text": "We then eliminate cases where there is not substantial human agreement, typically at least 75%.", "labels": [], "entities": []}, {"text": "We have found that this eliminates less that 20% of the potential test cases.", "labels": [], "entities": []}, {"text": "The remaining cases provide a gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.8484826683998108}]}], "tableCaptions": []}