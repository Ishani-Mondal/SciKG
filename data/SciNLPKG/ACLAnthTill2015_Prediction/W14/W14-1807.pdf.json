{"title": [{"text": "Surprisal as a Predictor of Essay Quality", "labels": [], "entities": [{"text": "Surprisal", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.8159626722335815}, {"text": "Predictor of Essay", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.6425884366035461}]}], "abstractContent": [{"text": "Modern automated essay scoring systems rely on identifying linguistically-relevant features to estimate essay quality.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.7568670511245728}]}, {"text": "This paper attempts to bridgework in psy-cholinguistics and natural language processing by proposing sentence processing complexity as a feature for automated essay scoring, in the context of English as a Foreign Language (EFL).", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.711924691994985}, {"text": "essay scoring", "start_pos": 159, "end_pos": 172, "type": "TASK", "confidence": 0.6829569935798645}]}, {"text": "To quantify processing complexity we used a psy-cholinguistic model called surprisal theory.", "labels": [], "entities": []}, {"text": "First, we investigated whether es-says' average surprisal values decrease with EFL training.", "labels": [], "entities": []}, {"text": "Preliminary results seem to support this idea.", "labels": [], "entities": []}, {"text": "Second, we investigated whether surprisal can be effective as a predictor of essay quality.", "labels": [], "entities": []}, {"text": "The results indicate an inverse correlation between surprisal and essay scores.", "labels": [], "entities": []}, {"text": "Overall, the results are promising and warrant further investigation on the usability of sur-prisal for essay scoring.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 104, "end_pos": 117, "type": "TASK", "confidence": 0.875995934009552}]}], "introductionContent": [{"text": "Standardized testing continues to bean integral part of modern-day education, and an important area of research in educational technologies is the development of tools and methodologies to facilitate automated evaluation of standardized tests.", "labels": [], "entities": []}, {"text": "Unlike multiple-choice questions, automated evaluation of essays presents a particular challenge.", "labels": [], "entities": []}, {"text": "The specific issue is the identification of a suitable evaluation rubric that can encompass the broad range of responses that maybe received.", "labels": [], "entities": []}, {"text": "Unsurprisingly then, much emphasis has been placed on the development of Automated Essay Scoring (henceforth, AES) systems.", "labels": [], "entities": [{"text": "Automated Essay Scoring", "start_pos": 73, "end_pos": 96, "type": "TASK", "confidence": 0.5979144672552744}]}, {"text": "Notable AES systems include Project Essay Grade), ETS's e-rater R \u20dd (), Intelligent Essay Assessor TM (), BETSY), and Vantage Learning's IntelliMetric TM.", "labels": [], "entities": [{"text": "ETS's e-rater R \u20dd", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.7356624007225037}, {"text": "Intelligent Essay Assessor TM", "start_pos": 72, "end_pos": 101, "type": "TASK", "confidence": 0.5608063042163849}, {"text": "BETSY", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9956061244010925}]}, {"text": "The common thread inmost modern AES systems is the identification of various observable linguistic features, and the development of computational models that combine those features for essay evaluation.", "labels": [], "entities": [{"text": "essay evaluation", "start_pos": 185, "end_pos": 201, "type": "TASK", "confidence": 0.7106145620346069}]}, {"text": "One aspect of an essay's quality that almost all AES systems do not yet fully capture is sentence processing complexity.", "labels": [], "entities": []}, {"text": "The ability to clearly and concisely convey information without requiring undue effort on the part of the reader is one hallmark of good writing.", "labels": [], "entities": []}, {"text": "Decades of behavioral research on language comprehension has suggested that some sentence structures are harder to comprehend than others.", "labels": [], "entities": []}, {"text": "For example, passive sentences, such as the girl was pushed by the boy, are known to be harder to process than semantically equivalent active sentences, such as the boy pushed the girl.", "labels": [], "entities": []}, {"text": "Thus, it is likely that the overall processing complexity of the sentence structures used in an essay could influence its perceived quality.", "labels": [], "entities": []}, {"text": "One reason why sentence processing complexity has not yet been fully utilized is the lack of a suitable way of quantifying it.", "labels": [], "entities": [{"text": "sentence processing complexity", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.8308471242586771}]}, {"text": "This paper proposes the use of a psycholinguistic model of sentence comprehension called surprisal theory to quantify sentence processing complexity.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the surprisal theory, and discusses its applicability in modeling sentence processing complexity.", "labels": [], "entities": [{"text": "sentence processing complexity", "start_pos": 86, "end_pos": 116, "type": "TASK", "confidence": 0.7481578489144644}]}, {"text": "Section 3 details our investigation on whether essays' average surprisal values decrease following English as a Foreign Language training.", "labels": [], "entities": []}, {"text": "Section 4 presents a study where we investigated whether surprisal can be effective as a predictor of essay quality.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the second experiment, we directly examined whether surprisal values are related to essay quality by using a dataset of pre-scored essays.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Surprisal values of two example relative-clause sentences. The values were computed using a  top-down parser by Roark et al. (2009) trained on the Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Surprisal", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9209905862808228}, {"text": "Wall Street Journal corpus", "start_pos": 157, "end_pos": 183, "type": "DATASET", "confidence": 0.9721771627664566}]}, {"text": " Table 2: Means and standard deviations of total surprisal, syntactic surprisal, and lexical surprisal for  Analysis and Argumentation essays", "labels": [], "entities": [{"text": "Means", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9898988604545593}]}, {"text": " Table 3: Means and standard deviations of total surprisal, syntactic surprisal, and lexical surprisal for the  three different essay score levels", "labels": [], "entities": [{"text": "Means", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9884145259857178}]}, {"text": " Table 4: Pearson's R coefficients between the three surprisal values and the essay scores", "labels": [], "entities": [{"text": "R", "start_pos": 20, "end_pos": 21, "type": "METRIC", "confidence": 0.8647892475128174}]}]}