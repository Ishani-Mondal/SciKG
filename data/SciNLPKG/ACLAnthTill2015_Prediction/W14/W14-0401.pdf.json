{"title": [], "abstractContent": [{"text": "The conventional tools of the \"web as cor-pus\" framework rely heavily on URLs obtained from search engines.", "labels": [], "entities": []}, {"text": "Recently, the corresponding querying process became much slower or impossible to perform on a low budget.", "labels": [], "entities": [{"text": "querying process", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.8886726796627045}]}, {"text": "I try to find acceptable substitutes , i.e. viable link sources for web corpus construction.", "labels": [], "entities": [{"text": "web corpus construction", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.6457016666730245}]}, {"text": "To this end, I perform a study of possible alternatives, including social networks as well as the Open Directory Project and Wikipedia.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 125, "end_pos": 134, "type": "DATASET", "confidence": 0.8550821542739868}]}, {"text": "Four different languages (Dutch, French, Indonesian and Swedish) taken as examples show that complementary approaches are needed.", "labels": [], "entities": []}, {"text": "My scouting approach using open-source software leads to a URL directory enriched with metadata which maybe used to start a web crawl.", "labels": [], "entities": []}, {"text": "This is more than a drop-in replacement for existing tools since said metadata enables researchers to filter and select URLs that fit particular needs, as they are classified according to their language, their length and a few other indicators such as host-and markup-based data.", "labels": [], "entities": []}], "introductionContent": [{"text": "1.1 The \"web as corpus\" paradigm and its URL seeds problem The state of the art tools of the \"web as corpus\" framework rely heavily on URLs obtained from search engines.", "labels": [], "entities": []}, {"text": "The BootCaT method () consists in repeated search engine queries using several word seeds that are randomly combined, first coming from an initial list and later from unigram extraction over the corpus itself.", "labels": [], "entities": []}, {"text": "As a result, so-called \"seed URLs\" are gathered which are used as a starting point for web crawlers.", "labels": [], "entities": []}, {"text": "This approach is not limited to English: it has been successfully used by and for major world languages.", "labels": [], "entities": []}, {"text": "Until recently, the BootCaT method could be used in free web corpus building approaches.", "labels": [], "entities": []}, {"text": "To my best knowledge it is now pass\u00e9 because of increasing limitations on the search engines' APIs, which make the querying process on a low budget much slower or impossible.", "labels": [], "entities": []}, {"text": "Other technical difficulties include diverse and partly unknown search biases due in part to search engine optimization tricks as well as undocumented PageRank adjustments.", "labels": [], "entities": []}, {"text": "All in all, the APIs maybe too expensive and/or too unstable to support large-scale corpus building projects.", "labels": [], "entities": []}, {"text": "API changes are combined with an evolving web document structure and a slow but inescapable shift from \"web as corpus\" to \"web for corpus\" due to the increasing number of web pages and the necessity of using sampling methods at some stage.", "labels": [], "entities": []}, {"text": "This is what I call the postBootCaT world in web corpus construction.", "labels": [], "entities": [{"text": "web corpus construction", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.668350507815679}]}, {"text": "Moreover, the question whether the method used so far, i.e. randomizing keywords, provides a good overview of a language is still open.", "labels": [], "entities": []}, {"text": "It now seems reasonable to look for alternatives, so that research material does not depend on a single data source, as this kind of black box effect combined with paid queries really impedes reproducibility of research.", "labels": [], "entities": []}, {"text": "Using diverse sources of URL seeds could at least ensure that there is not a single bias, but several.", "labels": [], "entities": []}, {"text": "Additionally, the lack of interest and project financing when dealing with certain less-resourced languages makes it necessary to use light-weight 1 approaches where costs are lowered as much as possible.", "labels": [], "entities": []}, {"text": "In this perspective, a preliminary light scouting approach and a fullfledged focused crawler like those used by the Spiderling ( or the COW) projects are complementary.", "labels": [], "entities": []}, {"text": "A \"web for corpus\" crawling method using a seed set enriched with metadata as described in this article may yield better results, e.g. ensure a more diverse and less skewed sample distribution in a population of web documents, and/or reach faster a given quantitative goal.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: URLs extracted from search engines queries", "labels": [], "entities": [{"text": "URLs extracted from search engines queries", "start_pos": 10, "end_pos": 52, "type": "TASK", "confidence": 0.8121482729911804}]}, {"text": " Table 2: URLs extracted from a blend of social networks crawls (FriendFeed, identi.ca, and Reddit) with  no language target. 738,476 URLs analyzed, 73,271 URLs retained in the global process.", "labels": [], "entities": []}, {"text": " Table 3: URLs extracted from DMOZ and Wikipedia", "labels": [], "entities": [{"text": "DMOZ", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9346768856048584}]}]}