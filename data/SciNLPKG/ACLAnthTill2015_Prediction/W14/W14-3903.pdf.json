{"title": [{"text": "Detecting Code-Switching in a Multilingual Alpine Heritage Corpus", "labels": [], "entities": [{"text": "Detecting Code-Switching", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8514542579650879}]}], "abstractContent": [{"text": "This paper describes experiments in detecting and annotating code-switching in a large multilingual diachronic corpus of Swiss Alpine texts.", "labels": [], "entities": [{"text": "multilingual diachronic corpus of Swiss Alpine texts", "start_pos": 87, "end_pos": 139, "type": "DATASET", "confidence": 0.5995155615465981}]}, {"text": "The texts are in En-glish, French, German, Italian, Romansh and Swiss German.", "labels": [], "entities": []}, {"text": "Because of the multilingual authors (mountaineers, scientists) and the assumed multilingual readers, the texts contain numerous code-switching elements.", "labels": [], "entities": []}, {"text": "When building and annotating the corpus, we faced issues of language identification on the sentence and sub-sentential level.", "labels": [], "entities": [{"text": "language identification", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.7157769352197647}]}, {"text": "We present our strategy for language identification and for the annotation of foreign language fragments within sentences.", "labels": [], "entities": [{"text": "language identification", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7255381643772125}, {"text": "annotation of foreign language fragments within sentences", "start_pos": 64, "end_pos": 121, "type": "TASK", "confidence": 0.7618022561073303}]}, {"text": "We report 78% precision on detecting a subset of code-switches with correct language labels and 92% un-labeled precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9996418952941895}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.8956866264343262}]}], "introductionContent": [{"text": "In the Text+Berg project we have digitized the yearbooks of the Swiss Alpine Club (SAC) from its first edition in 1864 until today.", "labels": [], "entities": [{"text": "yearbooks of the Swiss Alpine Club (SAC)", "start_pos": 47, "end_pos": 87, "type": "DATASET", "confidence": 0.7312717801994748}]}, {"text": "They contain articles about mountain expeditions, the flora and fauna of the Alpes and other mountain regions, glacier and climate observations, geology and history papers, book reviews, accident and security reports, as well as the protocols of the annual club gatherings.", "labels": [], "entities": [{"text": "Alpes", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.9721305966377258}]}, {"text": "The texts are in the four official languages of Switzerland French, German, Italian and Romansh 1 plus a few in English and Swiss German dialects.", "labels": [], "entities": []}, {"text": "Because of the multilinguality of the authors and readers, many articles are mixed-language texts with inter-sentential and intra-sentential code-switching.", "labels": [], "entities": []}, {"text": "This poses a challenge for automatically processing the texts.", "labels": [], "entities": []}, {"text": "When we apply Part-of-Speech (PoS) tagging, named entity recognition or parsing, our systems need to know the language that they are dealing with.", "labels": [], "entities": [{"text": "Part-of-Speech (PoS) tagging", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.6142601668834686}, {"text": "named entity recognition or parsing", "start_pos": 44, "end_pos": 79, "type": "TASK", "confidence": 0.6518733084201813}]}, {"text": "Therefore we had used a language identifier from the start of the project to mark the language of each sentence.", "labels": [], "entities": []}, {"text": "We report on our experiences with sentence-based language identification in section 3.", "labels": [], "entities": [{"text": "sentence-based language identification", "start_pos": 34, "end_pos": 72, "type": "TASK", "confidence": 0.6355925798416138}]}, {"text": "shows an example of a French text with an English appendix title plus an English quote from this book.", "labels": [], "entities": []}, {"text": "Lately we discovered that our corpus also contains many intra-sentential code-switches.", "labels": [], "entities": []}, {"text": "For example, we find sentences like ...", "labels": [], "entities": []}, {"text": "und ich finde es very nice and delightful einen Vortrag halten zu d\u00fcrfen.", "labels": [], "entities": []}, {"text": "(Die Alpen, 1925) (EN : ... and I find it very nice and delightful to be allowed to give a talk.) where the German sentence contains an English phrase in quotation marks.", "labels": [], "entities": [{"text": "EN", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.8104787468910217}]}, {"text": "Obviously, a German PoS tagger will produce nonsense tags for the English phrase as the words will be unknown to it.", "labels": [], "entities": []}, {"text": "PoS taggers are good at tagging single unknown words based on the surrounding context, but most taggers fail miserably when a sequence of two or more words is unknown.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.69801265001297}, {"text": "tagging single unknown words", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.8639625161886215}]}, {"text": "The upper half of figure 2 shows the PoS tagger output for the above example.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 37, "end_pos": 47, "type": "TASK", "confidence": 0.6103221476078033}]}, {"text": "The words very, nice, delightful are senselessly tagged as proper names (NE), only and is tagged as foreign word (FM).", "labels": [], "entities": [{"text": "NE", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.8403670787811279}, {"text": "foreign word (FM)", "start_pos": 100, "end_pos": 117, "type": "METRIC", "confidence": 0.602928775548935}]}, {"text": "Our goal is to detect all intra-sentential codeswitches and to annotate them as exemplified in the lower half of figure 2.", "labels": [], "entities": []}, {"text": "They shall be framed with the TEI-conformant tag <foreign> which also shall specify the language of the foreign language segment.", "labels": [], "entities": [{"text": "TEI-conformant", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.9316551685333252}]}, {"text": "All tokens in the segment shall be tagged as foreign words (e.g. FM in the German STTS tag set, ET in the French Le Monde tag set (), and each lemma shall get the special symbol @fn@ to set it apart from lemmas of the surrounding sentence.", "labels": [], "entities": [{"text": "STTS tag set", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.6748170157273611}, {"text": "French Le Monde tag set", "start_pos": 106, "end_pos": 129, "type": "DATASET", "confidence": 0.7074148714542389}]}, {"text": "In this paper we report on our experiments towards this goal and suggest an algorithm for detecting code-switching.", "labels": [], "entities": []}, {"text": "We adopt a wide definition of code-switching.", "labels": [], "entities": []}, {"text": "We are interested in detecting all instances where a text is in a dominant language and contains words, phrases and sentences in another language.", "labels": [], "entities": []}, {"text": "Though our definition is broad, it is clearly more restricted than others, as e.g. the definition by which includes special purpose codes like bank account numbers or shoe sizes.", "labels": [], "entities": []}, {"text": "In this paper we will give an overview of the language mix in the yearbooks of the Swiss Alpine Club over the 150 years, and we will illustrate how we identified inter-sentential and intrasentential code-switching.", "labels": [], "entities": [{"text": "Swiss Alpine Club", "start_pos": 83, "end_pos": 100, "type": "DATASET", "confidence": 0.9324232141176859}]}, {"text": "We will give a quantitative overview of the number of code-switching candidates that we automatically located.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to assess the performance of Langid for the detection of code-switching we performed an exploratory experiment with the SAC yearbook 1925.", "labels": [], "entities": [{"text": "SAC yearbook 1925", "start_pos": 129, "end_pos": 146, "type": "DATASET", "confidence": 0.8490745226542155}]}, {"text": "We extracted all word sequences between pairs of quotation marks whereat least one token had been assigned the \"unknown\" lemma by our PoS tagger.", "labels": [], "entities": []}, {"text": "The \"unknown\" lemma indicates that this word sequence may come from a different language.", "labels": [], "entities": []}, {"text": "The word sequence had to beat least 4 characters long, thus skipping single letters and abbreviations.", "labels": [], "entities": []}, {"text": "In this way we obtained 333 word sequences that are potential candidates for intrasentential code-switching.", "labels": [], "entities": []}, {"text": "We then ran these word sequences through the Langid language identification system with the restriction that we expect the word sequences only to be either English, French, German, Italian or Latin (Romansh and Swiss German are not included in Langid).", "labels": [], "entities": [{"text": "Langid language identification", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.6448248624801636}]}, {"text": "For a given string Langid delivers the most likely language together with a confidence score.", "labels": [], "entities": [{"text": "confidence", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9743421077728271}]}, {"text": "We then compared the language predicted by the Langid system with the (automatically) computed language of the complete sentence.", "labels": [], "entities": []}, {"text": "In 189 out of the 333 sentences the Langid output predicted a code-switch.", "labels": [], "entities": []}, {"text": "We then manually graded all Langid judgements and found that 225 language judgements (67.5%) were correct.", "labels": [], "entities": []}, {"text": "But only 89 of the 189 predicted code-switches came with the correct language.", "labels": [], "entities": []}, {"text": "40 of the 100 incorrect judgements were actually code-switches but with a different language.", "labels": [], "entities": []}, {"text": "The remaining ones should have been classified with the same language as the surrounding sentence and are thus no examples of code-switching.", "labels": [], "entities": []}, {"text": "A closer inspection of the results revealed that the book contained not only code-switches in the expected 5 languages, but also into Romansh (6), Spanish (4) and Swiss-German.", "labels": [], "entities": []}, {"text": "Obviously all of these were incorrectly classified.", "labels": [], "entities": []}, {"text": "Most (8) of the Swiss-German word sequences were classified as German which could count as half correct, but the others were misclassified as English (among them a variant of the popular Swiss German farewell phrase uf Wiederluege spelled as uf's Wiederluege).", "labels": [], "entities": []}, {"text": "The Langid system has a tendency to classify word sequences as English.", "labels": [], "entities": []}, {"text": "Many of the short, incorrectly classified word sequences were judged as English.", "labels": [], "entities": []}, {"text": "It turns out that Langid judges even the empty string as English with a score of 9.06.", "labels": [], "entities": []}, {"text": "Therefore all judgements with this score are dubious.", "labels": [], "entities": []}, {"text": "We found that 56 short word sequences were classified as English with this score, out of which 35 were erroneously judged as English.", "labels": [], "entities": []}, {"text": "Only strings with a length of 15 and more characters that are classified as English should be trusted.", "labels": [], "entities": []}, {"text": "All others need to be discarded.", "labels": [], "entities": []}, {"text": "In general, if precision is the most important aspect, then Langid should only be used for strings SAC yearbooks candidates predicted code-sw correct wrong lang no with 20 or more characters.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9991074204444885}, {"text": "SAC yearbooks", "start_pos": 99, "end_pos": 112, "type": "DATASET", "confidence": 0.7247217893600464}]}, {"text": "In our test set only 4 strings that were longer than 20 characters were incorrectly classified within the selected language set.", "labels": [], "entities": []}, {"text": "Among the errors was the famous Latin phrase conditio sine qua non (length : 21 characters including blanks) which Langid incorrectly classified as Italian.", "labels": [], "entities": []}, {"text": "Another reason for the considerable number of misclassifications can be repeated occurrences of a word sequence.", "labels": [], "entities": []}, {"text": "Our error count is a token-based count and thus prone to misclassified recurring phrases.", "labels": [], "entities": []}, {"text": "In our experiment, Langid misclassified the French book name Echo des Alpes as Italian.", "labels": [], "entities": [{"text": "French book name Echo des Alpes", "start_pos": 44, "end_pos": 75, "type": "DATASET", "confidence": 0.8211264510949453}]}, {"text": "Unfortunately this name occurs 18 times in our test set and thus accounts for 18 errors.", "labels": [], "entities": []}, {"text": "We suspect that an -o at the end of a word is a strong indicator for Italian.", "labels": [], "entities": []}, {"text": "Ina short string like Echo des Alpes (14 characters), this can make the difference.", "labels": [], "entities": [{"text": "Echo des Alpes", "start_pos": 22, "end_pos": 36, "type": "DATASET", "confidence": 0.8271588484446207}]}, {"text": "Another interesting observation is that hyphens speak for German.", "labels": [], "entities": []}, {"text": "Our test set contains the hyphenated French string vesse-de-neige which Langid misclassifies as German with a clear margin over French.", "labels": [], "entities": []}, {"text": "When the same string is analyzed without hyphens, then Langid correctly computes a preference for French over German.", "labels": [], "entities": []}, {"text": "A similar observation comes from the Swiss German phrase uf's Wiederluege being classified as English when spelled with the apostrophe (which is less frequent in German than in English).", "labels": [], "entities": []}, {"text": "Without the apostrophe Langid would count the string as German.", "labels": [], "entities": []}, {"text": "With short strings like this, special symbols have a visible impact on the language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.702038049697876}]}, {"text": "We also observed that Langid is sensitive to all-caps capitalization.", "labels": [], "entities": []}, {"text": "For example, AUS DEM LEBEN DER GEBIRGSMUNDARTEN (EN : The Lives of Mountain Dialects) is misclassified as English (with the default score) while Aus dem Leben der Gebirgsmundarten is correctly classified as German.", "labels": [], "entities": [{"text": "AUS DEM LEBEN DER GEBIRGSMUNDARTEN", "start_pos": 13, "end_pos": 47, "type": "METRIC", "confidence": 0.8485924363136291}]}, {"text": "Overall, we found that code-switching within the same article rarely targets different languages.", "labels": [], "entities": []}, {"text": "For example, if the article is in German and contains code-switches into English, then it hardly ever contains code-switches into other languages.", "labels": [], "entities": []}, {"text": "In analogy to the one-sense-per-discourse hypothesis we might call this the one-code-switchlanguage-per-discourse hypothesis.", "labels": [], "entities": []}], "tableCaptions": []}