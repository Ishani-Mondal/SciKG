{"title": [{"text": "Experiments to Improve Named Entity Recognition on Turkish Tweets", "labels": [], "entities": [{"text": "Improve Named Entity Recognition", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.731378048658371}]}], "abstractContent": [{"text": "Social media texts are significant information sources for several application areas including trend analysis, event monitoring , and opinion mining.", "labels": [], "entities": [{"text": "trend analysis", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.7230829298496246}, {"text": "event monitoring", "start_pos": 111, "end_pos": 127, "type": "TASK", "confidence": 0.7281898707151413}, {"text": "opinion mining", "start_pos": 134, "end_pos": 148, "type": "TASK", "confidence": 0.7651587128639221}]}, {"text": "Unfortunately, existing solutions for tasks such as named entity recognition that perform well on formal texts usually perform poorly when applied to social media texts.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.6127361754576365}]}, {"text": "In this paper , we report on experiments that have the purpose of improving named entity recognition on Turkish tweets, using two different annotated data sets.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.6966857314109802}]}, {"text": "In these experiments , starting with a baseline named entity recognition system, we adapt its recognition rules and resources to better fit Twitter language by relaxing its capitalization constraint and by diacritics-based expansion of its lexical resources, and we employ a simplistic normalization scheme on tweets to observe the effects of these on the overall named entity recognition performance on Turkish tweets.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 364, "end_pos": 388, "type": "TASK", "confidence": 0.7261714935302734}]}, {"text": "The evaluation results of the system with these different settings are provided with discussions of these results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Analysis of social media texts, particularly microblog texts like tweets, has attracted recent attention due to significance of the contained information for diverse application areas like trend analysis, event monitoring, and opinion mining.", "labels": [], "entities": [{"text": "trend analysis", "start_pos": 189, "end_pos": 203, "type": "TASK", "confidence": 0.7149175703525543}, {"text": "event monitoring", "start_pos": 205, "end_pos": 221, "type": "TASK", "confidence": 0.7602759897708893}, {"text": "opinion mining", "start_pos": 227, "end_pos": 241, "type": "TASK", "confidence": 0.7983936369419098}]}, {"text": "Tools for well-studied problems like named entity recognition (NER) are usually employed as components within these social media analysis applications.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.784811794757843}]}, {"text": "For instance, in), named entities extracted from tweets are used to determine trending topics for user modeling within the context of personalized recommender systems and in (), named entities in tweets are used to complement the events extracted by an open domain event extraction system for Twitter.", "labels": [], "entities": []}, {"text": "However, existing NER solutions for well-formed text types like news articles are reported to suffer from considerable performance degradations when they are ported to social media texts, mainly due to the peculiarities of this latter text type.", "labels": [], "entities": []}, {"text": "In this paper, we report on our NER experiments on Turkish tweets in order to determine facilitating and impeding factors during the development of a NER system for Turkish tweets which can be used in social media analysis applications.", "labels": [], "entities": []}, {"text": "We carryout these experiments on two tweet data sets annotated with named entities.", "labels": [], "entities": []}, {"text": "After the initial evaluation results of a rule-based NER system) on these data sets, we gradually present the performance results achieved by the extended versions of the system together with discussions of these results.", "labels": [], "entities": []}, {"text": "For these experiments, we first perform two system adaptations, i.e., relaxing the capitalization constraint of the system and diacritics-based expansion of the system's lexical resources.", "labels": [], "entities": []}, {"text": "Next, we incorporate a simplistic tweet normalization scheme into the NER procedure.", "labels": [], "entities": [{"text": "tweet normalization", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7500366568565369}, {"text": "NER", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.7673636078834534}]}, {"text": "After the evaluation of these extensions, we provide discussions on the plausible features of a NER system tailored to Turkish tweets.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In Section 2, we review the literature on NER on tweets and NER on Turkish texts.", "labels": [], "entities": [{"text": "NER", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.8635597229003906}, {"text": "NER on Turkish texts", "start_pos": 107, "end_pos": 127, "type": "TASK", "confidence": 0.4893847033381462}]}, {"text": "In Section 3, we present our NER experiments on Turkish tweets.", "labels": [], "entities": [{"text": "NER", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.8770977854728699}]}, {"text": "Directions of future work are outlined in Section 4 and finally Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The NER experiments are performed using the rule-based NER system which makes use of a set of lexical resources, i.e., lists of person/location/organization names (henceforth referred to as PLOs), and patterns for the extraction of named entities (NEs) of type PLOs and time/date/money/percent expressions).", "labels": [], "entities": []}, {"text": "The system is proposed for news articles which is a considerably well-formed text type usually with proper capitalization of the initial letters of PLOs and separation of these PLOs from their suffixes with apostrophes . Yet, as even such well-formed texts maybe lacking these important indicators of PLOs, the system can be configured to make use of the capitalization clue or not, and it includes a simplistic morphological analyzer to check the suffixes at the end of PLO candidates and thereby validate these candidates).", "labels": [], "entities": []}, {"text": "This NER system achieves a balanced FMeasure of 78.7% (without giving any credit to partial extractions) on a news article data set of about 20K tokens obtained from the METU Turkish corpus () where the annotated form of this data set includes a total of 1,613 NEs.", "labels": [], "entities": [{"text": "FMeasure", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9969430565834045}, {"text": "news article data set", "start_pos": 110, "end_pos": 131, "type": "DATASET", "confidence": 0.7067210227251053}, {"text": "METU Turkish corpus", "start_pos": 170, "end_pos": 189, "type": "DATASET", "confidence": 0.9556658069292704}]}, {"text": "Within the course of the current study, we have evaluated this system on two tweet data sets in Turkish where statistical information about these data sets are provided in.", "labels": [], "entities": []}, {"text": "The first one, which is referred to as T weet Set\u22121 in, is presented in) and comprises 2,320 tweets with about 20K tokens.", "labels": [], "entities": []}, {"text": "The second data set (T weet Set\u22122) includes about 5K tweets with about 50K tokens and is described in (C \u00b8 elikkaya et al., 2013).", "labels": [], "entities": []}, {"text": "We have first evaluated the system's performance on the data sets without any extensions to the existing NER system.", "labels": [], "entities": []}, {"text": "presents these evaluation results using the commonly employed metrics of precision, recall, and balanced F-Measure, without giving any credit to partially extracted NEs.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.999502420425415}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9991055130958557}, {"text": "F-Measure", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9498128890991211}]}, {"text": "displays those results with the same metrics this time giving credit to partial extractions with the constraint that the NE type within the system output and the answer key must be the same, where these metrics have been employed in studies like ().", "labels": [], "entities": []}, {"text": "The evaluation results in and are inline with the common finding reported in the literature that the NER systems for comparatively well-formed text types face considerable performance decreases when they are evaluated on tweets.", "labels": [], "entities": []}, {"text": "This observation is usually attributed to the peculiarities of tweet texts such as common grammatical/spelling errors and deliberate contractions.", "labels": [], "entities": []}, {"text": "With strict metrics, the system is reported to achieve an F-Measure rate of 78.7%.", "labels": [], "entities": [{"text": "F-Measure rate", "start_pos": 58, "end_pos": 72, "type": "METRIC", "confidence": 0.9927948713302612}]}, {"text": "When it is ported to tweets, the best overall FMeasure rates achieved are 53.23% and 44.25% on T weet Set\u22121 and T weet Set\u22122, respectively, while the corresponding best F-Measure rates for only PLOs are 47.76% and 36.63%, respectively, all with strict metrics.", "labels": [], "entities": [{"text": "FMeasure", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.8440091013908386}, {"text": "F-Measure", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9752858281135559}]}, {"text": "The difference between the results for PLOs and the overall results also confirms that the system recognizes temporal and numerical expressions (within its scope) with decent performance, compared to the recognition of PLOs.", "labels": [], "entities": []}, {"text": "The F-Measure rates obtained when partial extractions are also given credit are about 5% higher than those obtained without giving any credit to partially extracted NEs.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9986467957496643}]}, {"text": "This increase is important due to pragmatic reasons as these partially extracted NEs can help conveniently filter tweet streams and retrieve relevant subsets of tweets in several application settings.", "labels": [], "entities": []}, {"text": "Tweet texts possess the following peculiarities usually as opposed to other formal text types: \u2022 Grammatical/spelling errors are common, like incorrectly writing proper names all in lowercase letters.", "labels": [], "entities": []}, {"text": "A Turkish example illustrating a spelling error is the use of geliyoooo instead of geliyor (meaning is coming).", "labels": [], "entities": []}, {"text": "\u2022 Contracted word forms are commonly used instead of full forms, like referring to the football club called F enerbah\u00e7e as F ener only, where the latter contracted form is also homonymous to a common name in Turkish (meaning lantern).", "labels": [], "entities": []}, {"text": "\u2022 For the particular case of Turkish tweets, non-accentuated characters (c, g, i, o, s, and u) are often utilized instead of the corresponding Turkish characters with diacritics (c \u00b8, \u02d8 g, \u0131, \u00a8 o, s \u00b8, and\u00fcand\u00a8and\u00fc).", "labels": [], "entities": []}, {"text": "An example of this phenomenon is writing cunku instead of the correct form, c \u00b8 \u00a8 unk\u00fcunk\u00a8unk\u00fc (meaning because).", "labels": [], "entities": []}, {"text": "Considering the above features, in order to improve the initial NER performance on Turkish tweets, we have tested two adaptations of the rulebased NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8944980502128601}]}, {"text": "The details of these adaptations and the corresponding evaluation results are presented in the following subsections.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: NE Statistics on the Data Sets.", "labels": [], "entities": [{"text": "NE Statistics on the Data Sets", "start_pos": 10, "end_pos": 40, "type": "DATASET", "confidence": 0.7882064282894135}]}, {"text": " Table 2: Initial NER Evaluation Results (Strict Metrics).", "labels": [], "entities": [{"text": "NER Evaluation", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7942230403423309}]}, {"text": " Table 3: Initial NER Evaluation Results (Partial Metrics).", "labels": [], "entities": [{"text": "NER Evaluation", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.800803154706955}]}, {"text": " Table 4: NER Evaluation Results After Diacritics-Based Expansion of Resources (Strict Metrics).", "labels": [], "entities": [{"text": "NER Evaluation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8763852119445801}]}, {"text": " Table 5: NER Evaluation Results After Diacritics-Based Expansion of Resources (Partial Metrics).", "labels": [], "entities": [{"text": "NER Evaluation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8759702146053314}]}, {"text": " Table 6: Evaluation Results of the NER Pipeline with Normalization, on T weet Set\u22121.", "labels": [], "entities": [{"text": "NER Pipeline", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.6489345133304596}]}]}