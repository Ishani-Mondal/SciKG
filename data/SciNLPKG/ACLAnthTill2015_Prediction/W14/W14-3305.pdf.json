{"title": [{"text": "CimS -The CIS and IMS joint submission to WMT 2014 translating from English into German", "labels": [], "entities": [{"text": "WMT", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.561936616897583}]}], "abstractContent": [{"text": "We present the CimS submissions to the 2014 Shared Task for the language pair EN\u2192DE.", "labels": [], "entities": []}, {"text": "We address the major problems that arise when translating into German: complex nominal and verbal morphology , productive compounding and flexible word ordering.", "labels": [], "entities": []}, {"text": "Our morphology-aware translation systems handle word formation issues on different levels of morpho-syntactic modeling.", "labels": [], "entities": [{"text": "word formation", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7652896046638489}]}], "introductionContent": [{"text": "In our shared task submissions, we focus on the English to German translation direction: we address different levels of productivity of the German language, i.e., nominal and verbal inflection and productive word formation, which lead to data sparsity and thus confuse classical SMT systems.", "labels": [], "entities": [{"text": "word formation", "start_pos": 208, "end_pos": 222, "type": "TASK", "confidence": 0.7438947260379791}, {"text": "SMT", "start_pos": 279, "end_pos": 282, "type": "TASK", "confidence": 0.9906326532363892}]}, {"text": "Our basic goal is to make the two languages as morphosyntactically similar as possible.", "labels": [], "entities": []}, {"text": "We use a parser and a morphological analyser to remove linguistic features from German that are not present in English and reorder the English input to make it more similar to the German sentence structure.", "labels": [], "entities": []}, {"text": "Prior to training, all words are lemmatised and compounds are split into single words.", "labels": [], "entities": []}, {"text": "This is not only beneficial for word alignment, but it also allows us to generalise over inflectional variants of the same lexemes and over single words which could occur in one place as a standalone word and in another place as part of a compound.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.8027758896350861}]}, {"text": "Translation happens in two steps: first, we translate from English into split, lemmatised German and then, we perform compound merging and generation of inflection as a postprocessing step.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9493066668510437}]}, {"text": "This way, we are able to create German compounds and inflectional variants that have not been seen in the parallel training data.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the performance of well-established source-side reordering, nominal re-inflection and compound processing systems on an up-to-date shared task.", "labels": [], "entities": []}, {"text": "In addition, we present experimental results on a verbal inflection component and a syntax-based variant including source-side reordering.", "labels": [], "entities": []}], "datasetContent": [{"text": "In all our systems, we only used data distributed for the shared task.", "labels": [], "entities": []}, {"text": "All available German data was morphologically analysed with SMOR.", "labels": [], "entities": [{"text": "German data", "start_pos": 14, "end_pos": 25, "type": "DATASET", "confidence": 0.8853473663330078}, {"text": "SMOR", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.5470892190933228}]}, {"text": "For lemmatisation of the German training data, we disambiguated SMOR using POS tags we obtained through parsing the German section of the parallel training data with BitPar (Schmid, Language Model We trained 5-gram language models based on all available German monolingual training data from the shared task (roughly 1.5 billion words) using the SRILM toolkit) with Kneser-Ney smoothing.", "labels": [], "entities": []}, {"text": "We then used KenLM (Heafield, 2011) for faster processing.", "labels": [], "entities": [{"text": "KenLM (Heafield, 2011)", "start_pos": 13, "end_pos": 35, "type": "DATASET", "confidence": 0.7212618539730707}]}, {"text": "For each of our experiments, we trained a separate language model on the whole data set, corresponding to the different underspecified representations of German used in our experiments, e.g. lemmatised for CimS-RI, lemmatised with split compounds for CimS-CoRI, etc.", "labels": [], "entities": []}, {"text": "Phrase-based Translation model We performed word alignment using the multithreaded GIZA++ toolkit).", "labels": [], "entities": [{"text": "Phrase-based Translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7613472938537598}, {"text": "word alignment", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.8023858666419983}]}, {"text": "For translation model training and decoding, we used the Moses toolkit ( ) to build phrase-based statistical machine translation systems, following the instructions for the baseline system for the shared task, using only default settings.", "labels": [], "entities": [{"text": "translation model training", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.9430378278096517}, {"text": "statistical machine translation", "start_pos": 97, "end_pos": 128, "type": "TASK", "confidence": 0.60161492228508}]}, {"text": "Syntax-based Translation model As a variant to the phrase-based systems, we applied the inflection prediction system to a string-to-tree system with GHKM extraction (,).", "labels": [], "entities": [{"text": "Syntax-based Translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6422959864139557}]}, {"text": "We used the same data-sets as for the phrase-based systems, and applied BitPar) to obtain targetside trees.", "labels": [], "entities": []}, {"text": "For this system, we used source-side reordering according to relying on parses obtained with EGRET 3 . Tuning For tuning of feature weights, we used batch-mira with '-safe-hope' (Cherry and Foster, 2012) until convergence (or maximal 25 runs).", "labels": [], "entities": []}, {"text": "We used the 3,000 sentences of newstest2012 for tuning.", "labels": [], "entities": [{"text": "newstest2012", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9132954478263855}]}, {"text": "Each experiment was tuned separately, optimising Bleu scores () against a lemmatised version of the tuning reference.", "labels": [], "entities": [{"text": "Bleu scores", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.9715365171432495}]}, {"text": "In the compound processing systems we integrated the CRF-based prediction and merging procedure into each tuning iteration and scored each output against the same unsplit and lemmatised reference as the other systems.", "labels": [], "entities": [{"text": "CRF-based prediction and merging", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.7705065235495567}]}, {"text": "Testing After decoding, the underspecified representation has to be retransformed into fluent German text, i.e., compounds need to be re-combined and all words have to be reinflected.", "labels": [], "entities": []}, {"text": "The whole procedure can be divided into the following steps: 1a) translation into lemmatised German representation (RI, RIVe) 1b) translation into split and lemmatised German (CoRi, CoRIVe) 2) compound merging (CoRI, CoRIVe): 3) nominal inflection prediction and generation of full forms using SMOR (all) 4) verbal re-inflection (RIVe, CoRIVe) 5) merging of portmanteaus (all): Bleu scores for all CimS-submissions of the 2014 shared task.", "labels": [], "entities": [{"text": "nominal inflection prediction", "start_pos": 229, "end_pos": 258, "type": "TASK", "confidence": 0.6316443085670471}, {"text": "Bleu", "start_pos": 378, "end_pos": 382, "type": "METRIC", "confidence": 0.9957188963890076}]}, {"text": "ci = case-insensitive, cs = casesensitive; P = primary submission.", "labels": [], "entities": []}, {"text": "After these post-processing steps, the text was automatically recapitalised and detokenised, using the tools provided by the shared task, which we trained on the whole German dataset.", "labels": [], "entities": [{"text": "German dataset", "start_pos": 168, "end_pos": 182, "type": "DATASET", "confidence": 0.9173516929149628}]}, {"text": "We calculated Bleu () scores using the NIST script version 13a.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9758073687553406}, {"text": "NIST script version 13a", "start_pos": 39, "end_pos": 62, "type": "DATASET", "confidence": 0.9734507352113724}]}, {"text": "We manually screened the filtered 2014 test set and identified 3,456 German compound tokens, whereof 862 did not occur in the parallel training data and thereof, 244 did not even occur in the monolingual training data.", "labels": [], "entities": [{"text": "2014 test set", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.7585708598295847}]}, {"text": "For each of our systems, we calculated the number of compound reference matches they produced.", "labels": [], "entities": []}, {"text": "The results are given in  The compound processing systems (with Co in the name) generate many more correct compounds than comparable systems without compound handling.", "labels": [], "entities": []}, {"text": "Compared to the raw baseline, CoRI/CoRIVe did not only produce 237/243 more reference matches, but also 109/122 compounds that matched the reference but did not occur in the parallel training data.", "labels": [], "entities": []}, {"text": "A lookup of those 109/122 compounds in the monolingual training data (consisting of roughly 1.5 billion words) revealed, that 8/6 of them did not oc-cur there either 5 . These were thus not accessible to a list-based compound merging approach either.", "labels": [], "entities": [{"text": "list-based compound merging", "start_pos": 206, "end_pos": 233, "type": "TASK", "confidence": 0.6636472145716349}]}, {"text": "This result also shows that despite the fact that CoRIVe does not yield a competitive translation quality performance yet, the compound processing component seems to benefit from the verbal inflection and it is definitely worth more investigation in the future.", "labels": [], "entities": []}, {"text": "Moreover, it can be seen from that the re-inflection systems (*RI*) produce more reference matches than the raw baseline.", "labels": [], "entities": [{"text": "RI", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9191629886627197}]}, {"text": "Interestingly, they even produce some reference matches that have not been seen in the parallel training data due to inflectional variation, and in the case of the syntax-based system due to a naive list-based compound merging: even though it has not been trained on a split representation of German text, it might occasionally occur that two German nouns occur next to each other in the MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 388, "end_pos": 390, "type": "TASK", "confidence": 0.8504266142845154}]}, {"text": "If so, these two words are merged into a compound, using a list-based approach, similar to Popovi\u00b4c.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Bleu scores for all CimS-submissions of the 2014 shared task. ci = case-insensitive, cs = case- sensitive; P = primary submission.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9952685236930847}]}, {"text": " Table 3: Numbers of compounds produced by  the systems that matched the reference (ref ) and  did not occur in the parallel training data (new).", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of the reordering system  trained on Europarl v7.", "labels": [], "entities": [{"text": "Europarl v7", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.9573730230331421}]}]}