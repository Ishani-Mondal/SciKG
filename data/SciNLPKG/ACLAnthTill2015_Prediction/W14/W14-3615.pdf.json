{"title": [{"text": "Arabic Spelling Correction using Supervised Learning", "labels": [], "entities": [{"text": "Arabic Spelling Correction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6587347189585367}]}], "abstractContent": [{"text": "In this work, we address the problem of spelling correction in the Arabic language utilizing the new corpus provided by QALB (Qatar Arabic Language Bank) project which is an annotated corpus of sentences with errors and their corrections.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7966817617416382}, {"text": "QALB (Qatar Arabic Language Bank) project", "start_pos": 120, "end_pos": 161, "type": "DATASET", "confidence": 0.8004793040454388}]}, {"text": "The corpus contains edit, add before, split, merge, add after, move and other error types.", "labels": [], "entities": []}, {"text": "We are concerned with the first four error types as they contribute more than 90% of the spelling errors in the corpus.", "labels": [], "entities": []}, {"text": "The proposed system has many models to address each error type on its own and then integrating all the models to provide an efficient and robust system that achieves an overall recall of 0.59, precision of 0.58 and F1 score of 0.58 including all the error types on the development set.", "labels": [], "entities": [{"text": "recall", "start_pos": 177, "end_pos": 183, "type": "METRIC", "confidence": 0.9992590546607971}, {"text": "precision", "start_pos": 193, "end_pos": 202, "type": "METRIC", "confidence": 0.999457061290741}, {"text": "F1 score", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.9907298684120178}]}, {"text": "Our system participated in the QALB 2014 shared task \"Automatic Arabic Error Correction\" and achieved an F1 score of 0.6, earning the sixth place out of nine participants.", "labels": [], "entities": [{"text": "QALB 2014 shared task \"Automatic Arabic Error Correction", "start_pos": 31, "end_pos": 87, "type": "TASK", "confidence": 0.5813892367813323}, {"text": "F1 score", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9867993295192719}]}], "introductionContent": [{"text": "The Arabic language is a highly inflected natural language that has an enormous number of possible words.", "labels": [], "entities": []}, {"text": "And although it is the native language of over 300 million people, it suffers from the lack of useful resources as opposed to other languages, specially English and until now there are no systems that cover the wide range of possible spelling errors.", "labels": [], "entities": []}, {"text": "Fortunately the QALB corpus ( ) will help enrich the resources for Arabic language generally and the spelling correction specifically by providing an annotated corpus with corrected sentences from user comments, native student essays, nonnative data and machine translation data.", "labels": [], "entities": [{"text": "QALB corpus", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.8538954257965088}, {"text": "spelling correction", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.8598247468471527}, {"text": "machine translation", "start_pos": 254, "end_pos": 273, "type": "TASK", "confidence": 0.6710887104272842}]}, {"text": "In this work, we are trying to use this corpus to build an error correction system that can cover a range of spelling errors.", "labels": [], "entities": []}, {"text": "This paper is a system description paper that is submitted in the EMNLP 2014 conference shared task \"Automatic Arabic Error Correction\" ) in the Arabic NLP workshop.", "labels": [], "entities": [{"text": "EMNLP 2014 conference shared task \"Automatic Arabic Error Correction", "start_pos": 66, "end_pos": 134, "type": "TASK", "confidence": 0.6649947255849838}, {"text": "Arabic NLP workshop", "start_pos": 145, "end_pos": 164, "type": "DATASET", "confidence": 0.7789614200592041}]}, {"text": "The challenges that faced us while working on this system was the shortage of contribution in the area of spelling correction in the Arabic language.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.9046876430511475}]}, {"text": "But hopefully the papers and the work in this shared task specifically and in the workshop generally will enrich this area and flourish it.", "labels": [], "entities": []}, {"text": "Our system targets four types of spelling errors, edit errors, add before errors, merge errors and split errors.", "labels": [], "entities": [{"text": "merge errors", "start_pos": 82, "end_pos": 94, "type": "METRIC", "confidence": 0.9303618967533112}]}, {"text": "For each error type, A model is built to correct erroneous words detected by the error detection technique.", "labels": [], "entities": []}, {"text": "Edit errors and add before errors are corrected using classifiers with contextual features, while the merge and split errors are corrected by inserting or omitting a space between words and choosing the best candidate based on the language model score of each candidate.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2, we give a brief background on related work in spelling correction.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.9322893023490906}]}, {"text": "In section 3, we introduce our system for spelling correction with the description of the efficient models used in the system.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.956550657749176}]}, {"text": "In section 4, we list some experimental results on the development set.", "labels": [], "entities": []}, {"text": "In section 5, we give some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to know the contribution of each error type models to the overall system performance, we adopted an incremental approach of the models.", "labels": [], "entities": []}, {"text": "We implemented the system using python and NLTK 8) toolkit.", "labels": [], "entities": []}, {"text": "The models are trained on the QALB corpus training set and the results are obtained by applying the trained models on the development set.", "labels": [], "entities": [{"text": "QALB corpus training set", "start_pos": 30, "end_pos": 54, "type": "DATASET", "confidence": 0.9647193253040314}]}, {"text": "Our goal was to achieve high recall but without losing too much precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9976348876953125}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9983231425285339}]}, {"text": "The models were evaluated using M2 scorer.", "labels": [], "entities": [{"text": "M2 scorer", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.6523354947566986}]}, {"text": "First, we start with only the preprocessed undiacriticized word, then we added our edit error classifier.", "labels": [], "entities": []}, {"text": "Adding the add before classifier was a great addition to the system as the system was able to increase the number of corrected errors significantly, notably the add before classifier proposed too many incorrect suggestions that decreased the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 242, "end_pos": 251, "type": "METRIC", "confidence": 0.9983534812927246}]}, {"text": "Then we added the merging correction technique.", "labels": [], "entities": [{"text": "merging correction", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.751130223274231}]}, {"text": "Finally we added the split error correction technique.", "labels": [], "entities": [{"text": "split error correction", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.6695281068483988}]}, {"text": "The system corrects 9860 errors versus 16659 golden error corrections and pro-posed 17057 correction resulting in the final system recall of 0.5919, precision of 0.5781 and F1 score of 0.5849.", "labels": [], "entities": [{"text": "corrects 9860 errors", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.8494330644607544}, {"text": "golden error corrections", "start_pos": 45, "end_pos": 69, "type": "METRIC", "confidence": 0.8343395789464315}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.952549397945404}, {"text": "precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9996600151062012}, {"text": "F1 score", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9902687072753906}]}, {"text": "We tried other combinations of the models by removing one or more of the components to get the best results possible.", "labels": [], "entities": []}, {"text": "Noting that all the systems results are using the undiacriticized word.", "labels": [], "entities": []}, {"text": "Details are shown in Table 4: The results of some combinations of the models and applying them on the development set.", "labels": [], "entities": []}, {"text": "The models are abbreviated as Edit E, Merge M, Split S, and Add before A.", "labels": [], "entities": [{"text": "Edit E", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.921130359172821}, {"text": "Merge", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.8806767463684082}, {"text": "A", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.4904945194721222}]}], "tableCaptions": [{"text": " Table 3: The incremental results after adding each  error type model and applying them on the devel- opment set.", "labels": [], "entities": []}]}