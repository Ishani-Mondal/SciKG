{"title": [{"text": "Exploration of functional semantics of prepositions from corpora of descriptions of visual scenes", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a method of extracting functional semantic knowledge from corpora of descriptions of visual scenes.", "labels": [], "entities": [{"text": "extracting functional semantic knowledge from corpora of descriptions of visual scenes", "start_pos": 23, "end_pos": 109, "type": "TASK", "confidence": 0.830732833255421}]}, {"text": "Such knowledge is required for interpretation and generation of spatial descriptions in tasks such as visual search.", "labels": [], "entities": [{"text": "interpretation and generation of spatial descriptions", "start_pos": 31, "end_pos": 84, "type": "TASK", "confidence": 0.746001680692037}]}, {"text": "We identify semantic classes of target and landmark objects related by each preposition by abstracting over WordNet taxonomy.", "labels": [], "entities": [{"text": "WordNet taxonomy", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9503760635852814}]}, {"text": "The inclusion of such knowledge in visual search should equip robots with a better, more human-like spatial cognition.", "labels": [], "entities": []}], "introductionContent": [{"text": "Visual search is an area of growing research importance in mobile robotics; see) among others.", "labels": [], "entities": [{"text": "Visual search", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7765736877918243}]}, {"text": "Visual search involves directing the visual sensors of a robot with the goal of locating a specific object.", "labels": [], "entities": [{"text": "Visual search", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7927568852901459}]}, {"text": "Several recent approaches have integrated non-visual (often linguistically motivated information) into the visual search process.", "labels": [], "entities": []}, {"text": "The intuition behind this is that if the robot knows that object X is often located near/on/.", "labels": [], "entities": []}, {"text": "object Y then in situations where Y is visually salient it maybe easier for the system to search by first locating Y and then use relational information to direct the search for X.", "labels": [], "entities": []}, {"text": "A key component of these approaches to visual search is the definition of spatial semantics of the relational information.", "labels": [], "entities": []}, {"text": "Appropriately modelling these semantics is crucial because fundamentally it is these models that define the scope of the visual search in relation to Y.", "labels": [], "entities": []}, {"text": "In language spatial relations between objects are often expressed using locative expressions such as \"the apple above a bowl\", \"the computer is on the shelf\" and \"the plane is over the house\".", "labels": [], "entities": []}, {"text": "In these expressions a target object is located relative to a landmark object using a preposition to describe the spatial relation.", "labels": [], "entities": []}, {"text": "Crucially, there are differences between prepositions with respect to how their spatial relations are defined.", "labels": [], "entities": []}, {"text": "The semantics of some prepositions can be modelled in terms of geometric primitives whereas the semantics of other prepositions are sensitive to the functional relations between the target and the landmark ().", "labels": [], "entities": []}, {"text": "Consider the example \"Alex is at her desk\".", "labels": [], "entities": []}, {"text": "This description refers to a situation where Alexis not only geometrically proximate to her desk but also where she is sitting down and working.", "labels": [], "entities": []}, {"text": "The extra constraints are coming from the functional relations that normally exist between an individual and a desk.", "labels": [], "entities": []}, {"text": "Returning to visual search, being able to identify whether a given preposition is primarily geometric of functional is important because this classification informs the design of the spatial semantics for the preposition and hence the appropriate definition of the search relative to the landmark object.", "labels": [], "entities": []}, {"text": "In this paper we present some ongoing experiments which attempt to develop techniques that can classify prepositions as geometric or functional.", "labels": [], "entities": []}, {"text": "sensitive to the object function component than \"above\".", "labels": [], "entities": []}, {"text": "Descriptions of \"the umbrella is over a man\" were considered acceptable even in cases where the umbrella was held horizontally but was providing protection from the rain.", "labels": [], "entities": []}, {"text": "Modelling of functional knowledge in the computational models of meaning of spatial prepositions is not straightforward.", "labels": [], "entities": []}, {"text": "Humans (and even expert linguists) do not seem to have clear intuitions what the functional component of each preposition sense maybe and hence they must be confirmed experimentally ().", "labels": [], "entities": []}, {"text": "This may take significant time for various combinations of prepositions and target and landmark objects.", "labels": [], "entities": []}, {"text": "One needs to develop a complex ontology of object properties and then associate spatial prepositions with rules that pick out certain properties of objects fora particular preposition sense (for examples of such rules see ().", "labels": [], "entities": []}, {"text": "In this paper we describe a method of extraction of these meaning components from a corpus of descriptions of visual scenes automatically.", "labels": [], "entities": []}, {"text": "Unlike in the psycho-linguistic experiments described above we examine general corpora that obtain a wide and unrestricted set of images that humans described freely.", "labels": [], "entities": []}, {"text": "The purpose of the experiment is to investigate whether functional knowledge can be extracted from contextual language use.", "labels": [], "entities": []}, {"text": "For example, can we make generalisations about the semantics of the arguments that a particular prepositional sense takes automatically.", "labels": [], "entities": []}, {"text": "Furthermore, we are also interested if the distinctions between geometric and functional sensitivity of prepositions reported experimentally could be determined this way.", "labels": [], "entities": []}, {"text": "This information would allow us to weight the contributions of the geometric and functional knowledge when generating and interpreting spatial descriptions of scenes.", "labels": [], "entities": [{"text": "interpreting spatial descriptions of scenes", "start_pos": 122, "end_pos": 165, "type": "TASK", "confidence": 0.8351646304130554}]}, {"text": "We hypothesise, that if a preposition is sensitive to functional meaning then there will be functional relations between target and landmark objects that it is used with and consequently the preposition will will be much more restrictive or specific in the semantic type of targets and landmarks that it requires.", "labels": [], "entities": []}, {"text": "Other prepositions maybe more sensitive to the satisfaction of the geometric constraint and hence we expect that they will co-occur with objects of more general semantic types.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of this work is to analyse the semantics of linguistic expressions that are used to describe the relative location of objects in visual contexts.", "labels": [], "entities": []}, {"text": "We base our analysis on two corpora of image descriptions: specifically, the IAPR TC-12 Benchmark corpus () 1 which contains 20,000 images and multi-sentence descriptions and the 8K ImageFlickr dataset (Rashtchian et al., 2010) 2 which contains 8108 images.", "labels": [], "entities": [{"text": "IAPR TC-12 Benchmark corpus", "start_pos": 77, "end_pos": 104, "type": "DATASET", "confidence": 0.93705615401268}, {"text": "8K ImageFlickr dataset (Rashtchian et al., 2010)", "start_pos": 179, "end_pos": 227, "type": "DATASET", "confidence": 0.821695277094841}]}, {"text": "In both corpora the situations and events represented by images are described by several sentences which contain spatial descriptions with prepositions: in the first case all sentences are by a single annotator and in the second case each sentence is by a different annotator.", "labels": [], "entities": []}, {"text": "The descriptions are geometrically constrained by the visual context.", "labels": [], "entities": []}, {"text": "On the other hand, the describers' choice of the target and the landmarks objects and the preposition in these descriptions will tell us about their functional semantics.", "labels": [], "entities": []}, {"text": "The main pre-processing step was to extract parts of spatial expressions used in the image descriptions.", "labels": [], "entities": []}, {"text": "Once extracted each spatial expression was stored in a type with the following structure: preposition, target, landmark.", "labels": [], "entities": []}, {"text": "To do this extraction we first parsed both corpora of linguistic descriptions for dependencies) using Stanford CoreNLP tools . Then we wrote several extraction rules that matched dependency parses and extracted all three parts of spatial expressions that we are looking for.", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 102, "end_pos": 118, "type": "DATASET", "confidence": 0.8081704080104828}]}, {"text": "All words were lemmatized and converted to lowercase, compound prepositions such as \"on the left side of\" were rewritten as single words and names, etc. were converted to their named entity categories such as \"person\".", "labels": [], "entities": []}, {"text": "The extracted patterns from both corpora were combined into a single dataset from which we can determine their frequency counts.", "labels": [], "entities": []}], "tableCaptions": []}