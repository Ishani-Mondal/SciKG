{"title": [{"text": "LDAvis: A method for visualizing and interpreting topics", "labels": [], "entities": []}], "abstractContent": [{"text": "We present LDAvis, a web-based interactive visualization of topics estimated using Latent Dirichlet Allocation that is built using a combination of Rand D3.", "labels": [], "entities": []}, {"text": "Our visu-alization provides a global view of the topics (and how they differ from each other), while at the same time allowing fora deep inspection of the terms most highly associated with each individual topic.", "labels": [], "entities": []}, {"text": "First, we propose a novel method for choosing which terms to present to a user to aid in the task of topic interpretation, in which we define the relevance of a term to a topic.", "labels": [], "entities": [{"text": "topic interpretation", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.748295396566391}]}, {"text": "Second, we present results from a user study that suggest that ranking terms purely by their probability under a topic is suboptimal for topic interpretation.", "labels": [], "entities": [{"text": "topic interpretation", "start_pos": 137, "end_pos": 157, "type": "TASK", "confidence": 0.7504303157329559}]}, {"text": "Last, we describe LDAvis, our visualization system that allows users to flexibly explore topic-term relationships using relevance to better understand a fitted LDA model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently much attention has been paid to visualizing the output of topic models fit using Latent Dirichlet Allocation (LDA) ().", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 90, "end_pos": 123, "type": "METRIC", "confidence": 0.9155405958493551}]}, {"text": "Such visualizations are challenging to create because of the high dimensionality of the fitted model -LDA is typically applied to many thousands of documents, which are modeled as mixtures of dozens (or hundreds) of topics, which themselves are modeled as distributions over thousands of terms ().", "labels": [], "entities": []}, {"text": "The most promising basic technique for creating LDA visualizations that are both compact and thorough is interactivity.", "labels": [], "entities": []}, {"text": "We introduce an interactive visualization system that we call LDAvis that attempts to answer a few basic questions about a fitted topic model: (1) What is the meaning of each topic?, (2) How prevalent is each topic?, and (3) How do the topics relate to each other?", "labels": [], "entities": []}, {"text": "Different visual components answer each of these questions, some of which are original, and some of which are borrowed from existing tools.", "labels": [], "entities": []}, {"text": "Our visualization (illustrated in) has two basic pieces.", "labels": [], "entities": []}, {"text": "First, the left panel of our visualization presents a global view of the topic model, and answers questions 2 and 3.", "labels": [], "entities": []}, {"text": "In this view, we plot the topics as circles in the two-dimensional plane whose centers are determined by computing the distance between topics, and then by using multidimensional scaling to project the intertopic distances onto two dimensions, as is done in ().", "labels": [], "entities": []}, {"text": "We encode each topic's overall prevalence using the areas of the circles, where we sort the topics in decreasing order of prevalence.", "labels": [], "entities": []}, {"text": "Second, the right panel of our visualization depicts a horizontal barchart whose bars represent the individual terms that are the most useful for interpreting the currently selected topic on the left, and allows users to answer question 1, \"What is the meaning of each topic?\".", "labels": [], "entities": []}, {"text": "A pair of overlaid bars represent both the corpus-wide frequency of a given term as well as the topic-specific frequency of the term, as in ().", "labels": [], "entities": []}, {"text": "The left and right panels of our visualization are linked such that selecting a topic (on the left) reveals the most useful terms (on the right) for interpreting the selected topic.", "labels": [], "entities": []}, {"text": "In addition, selecting a term (on the right) reveals the conditional distribution over topics (on the left) for the selected term.", "labels": [], "entities": []}, {"text": "This kind of linked selection allows users to examine a large number of topic-term relationships in a compact manner.", "labels": [], "entities": []}, {"text": "A key innovation of our system is how we determine the most useful terms for interpreting a given topic, and how we allow users to interactively ad- just this determination.", "labels": [], "entities": [{"text": "interpreting a given topic", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.879458487033844}]}, {"text": "A topic in LDA is a multinomial distribution over the (typically thousands of) terms in the vocabulary of the corpus.", "labels": [], "entities": []}, {"text": "To interpret a topic, one typically examines a ranked list of the most probable terms in that topic, using anywhere from three to thirty terms in the list.", "labels": [], "entities": []}, {"text": "The problem with interpreting topics this way is that common terms in the corpus often appear near the top of such lists for multiple topics, making it hard to differentiate the meanings of these topics.", "labels": [], "entities": [{"text": "interpreting topics", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9042646884918213}]}, {"text": "propose ranking terms fora given topic in terms of both the frequency of the term under that topic as well as the term's exclusivity to the topic, which accounts for the degree to which it appears in that particular topic to the exclusion of others.", "labels": [], "entities": []}, {"text": "We propose a similar measure that we call the relevance of a term to a topic that allows users to flexibly rank terms in order of usefulness for interpreting topics.", "labels": [], "entities": []}, {"text": "We discuss our definition of relevance, and its graphical interpretation, in detail in Section 3.1.", "labels": [], "entities": [{"text": "definition of relevance", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.7508875131607056}]}, {"text": "We also present the results of a user study conducted to determine the optimal tuning parameter in the definition of relevance to aid the task of topic interpretation in Section 3.2, and we describe how we incorporate relevance into our interactive visualization in Section 4.", "labels": [], "entities": [{"text": "topic interpretation", "start_pos": 146, "end_pos": 166, "type": "TASK", "confidence": 0.7566565573215485}]}], "datasetContent": [], "tableCaptions": []}