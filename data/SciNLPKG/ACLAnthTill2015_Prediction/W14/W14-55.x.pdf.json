{"title": [{"text": "The Fifth Workshop on South and Southeast Asian Natural Language processing WSSANLP-2014 WSSANLP Organizers WSSANLP Invited Speaker Program Committee", "labels": [], "entities": [{"text": "Southeast Asian Natural Language processing WSSANLP-2014 WSSANLP Organizers WSSANLP Invited Speaker Program", "start_pos": 32, "end_pos": 139, "type": "TASK", "confidence": 0.5360020945469538}]}], "abstractContent": [{"text": "Influenza is an acute respiratory illness that occurs every year.", "labels": [], "entities": [{"text": "Influenza is an acute respiratory illness", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8158103426297506}]}, {"text": "Detection of Influenza in its earliest stage would reduce the spread of the illness.", "labels": [], "entities": [{"text": "Detection of Influenza", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8707220951716105}]}, {"text": "Sina microblog is a popular microblogging service, provides perfect sources for flu detection due to its real-time nature and large number of users.", "labels": [], "entities": [{"text": "Sina microblog", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9321697354316711}, {"text": "flu detection", "start_pos": 80, "end_pos": 93, "type": "TASK", "confidence": 0.8398959338665009}]}, {"text": "In this paper we investigate the real-time flu detection problem and describe a Flu model with emotion factors and sematic information (em-flu model).", "labels": [], "entities": [{"text": "real-time flu detection", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.6819751163323721}]}, {"text": "Experimental results show the robustness and effectiveness of our method and we are hopeful that it would help health organizations in identifying flu outbreak and take timely actions to control.", "labels": [], "entities": [{"text": "identifying flu outbreak", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.9039957920710245}]}], "introductionContent": [{"text": "Nowadays, it is admitted that word segmentation is a crucial part of Statistical Machine Translation (SMT) especially in the languages where there are no explicit word boundaries such as Chinese, Japanese or Thai.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7425100803375244}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.8723443845907847}]}, {"text": "The writing system of these languages allow each word can be written continuously with no space appearing between words.", "labels": [], "entities": []}, {"text": "Consequently, word ambiguities will arise if word boundary has been misplace which finally lead to an incorrect translation.", "labels": [], "entities": []}, {"text": "Thus, the effective word segmentator is required to disambiguate each word separator before processing another task in SMT.", "labels": [], "entities": [{"text": "word segmentator", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7324888855218887}, {"text": "SMT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9775851368904114}]}, {"text": "Several word segmentators which focusing on word, character or both and have been implemented to accomplish this goal.", "labels": [], "entities": [{"text": "word segmentators", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7065500766038895}]}, {"text": "In order to retrieve a useful information to segment or cluster the word, most of word segmentators are trained on a manually segmented monolingual corpus by using various approaches such as dictionary-based, Hidden Markov Model (HMM), support vector machine (SVM) or conditional random field (CRF).", "labels": [], "entities": [{"text": "word segmentators", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7631722390651703}]}, {"text": "Although, a number of segementators are able to yield very promising results, certain of them might be unsuitable for SMT task due to the influence of segmentation scheme.", "labels": [], "entities": [{"text": "SMT task", "start_pos": 118, "end_pos": 126, "type": "TASK", "confidence": 0.9118514955043793}]}, {"text": "Therefore, instead of solely rely on monolingual corpus, various researches make use of either manually segmented or unsegment 1 ed bilingual corpus as a guideline information to perform a word segmentation task and improve the performance of SMT system.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 189, "end_pos": 211, "type": "TASK", "confidence": 0.792305717865626}, {"text": "SMT", "start_pos": 243, "end_pos": 246, "type": "TASK", "confidence": 0.9936566948890686}]}, {"text": "In this paper, we propose a novel segmentation approach for Phrase-Based Statistical Machine Translation (PB-SMT) to languages where word boundaries are not obviously marked by using both monolingual and bilingual information on English-Thai language pair and demonstrate that (1) unsegmented corpus is able to provide the nearly identical result to manually segmented corpus in PB-SMT task when the good heuristics character clustering algorithm is applied on it, (2) the performance of PB-SMT task has significantly increased when bilingual information are used on top of monolingual segmented result.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation (PB-SMT)", "start_pos": 60, "end_pos": 113, "type": "TASK", "confidence": 0.7228970144476209}]}, {"text": "Our technique, instead of focusing on word separation, mainly concentrate on character clustering.", "labels": [], "entities": [{"text": "word separation", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7735625803470612}, {"text": "character clustering", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.7383732199668884}]}, {"text": "First, we cluster each character from the unsegmented monolingual corpus by employing heuristic algorithm and language insight.", "labels": [], "entities": []}, {"text": "Secondly, we enhance the segmented result by incorporating the bilingual information which are character cluster (CC) alignment, CC co-occurrence frequency and alignment confidence into that result.", "labels": [], "entities": [{"text": "CC co-occurrence frequency", "start_pos": 129, "end_pos": 155, "type": "METRIC", "confidence": 0.7322134574254354}]}, {"text": "These two tasks can be performed repeatedly.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides some information related to our work.", "labels": [], "entities": []}, {"text": "Section 3 describes the methodology of our approach.", "labels": [], "entities": []}, {"text": "Section 4 present the experiments setting.", "labels": [], "entities": []}, {"text": "Section 5 present the experimental results and empirical analysis.", "labels": [], "entities": []}, {"text": "Section 6 and 7 gives a conclusion and future work respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the next step, a clustering algorithm was applied to the data.", "labels": [], "entities": []}, {"text": "This was done using the clustering tool described in.", "labels": [], "entities": []}, {"text": "At the moment, the tool features two clustering algorithms: the k-means algorithm as well as the Greedy Variance Minimization (GVM) algorithm.", "labels": [], "entities": []}, {"text": "We made use of an automatic method using Hindi WordNet to choose the best partition value.", "labels": [], "entities": [{"text": "Hindi WordNet", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.8897882103919983}]}, {"text": "We followed the technique described in Van de Cruys (2006), which uses WordNet relations to arrive at the most semantically coherent clusters.", "labels": [], "entities": []}, {"text": "We define semantic coherence as the similarity between items in a cluster, based on an overlap between their WordNet relations.", "labels": [], "entities": []}, {"text": "Specifically, for each k = 2\u221210, we iterated through the automatically generated clusters and performed the following steps: 1.", "labels": [], "entities": []}, {"text": "Using WordNet, we extracted synonyms, hypernyms and hyponyms for every word in a cluster.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 6, "end_pos": 13, "type": "DATASET", "confidence": 0.971908688545227}]}, {"text": "http://www.bbc.co.uk/hindi 5 http://dumps.wikimedia.org/hiwiki 6 even goes so far as to call the topicalization of nouns in N-V CPs ungrammatical.", "labels": [], "entities": []}, {"text": "The implementation of UML is done in Java.", "labels": [], "entities": []}, {"text": "After applying our method, the paradigms obtained were compared to the paradigms obtained using p-similar method with minimum stem-size five.", "labels": [], "entities": []}, {"text": "The precision was computed as ratio of number of words correctly segmented to total number of words segmented.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9993305206298828}]}, {"text": "Recall is computed as ratio of number of words correctly segmented to number of words in given input which could be segmented.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9826823472976685}]}, {"text": "The results have been tabulated in below.: Results for English, Hindi and Konkani Language  This section briefly introduces the selection of SMT models that are used to build the baseline English-Urdu SMT system and also explains the processing of parallel data before passing it to the MT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 141, "end_pos": 144, "type": "TASK", "confidence": 0.9900346398353577}, {"text": "SMT", "start_pos": 201, "end_pos": 204, "type": "TASK", "confidence": 0.8648456931114197}, {"text": "MT", "start_pos": 287, "end_pos": 289, "type": "TASK", "confidence": 0.9222214221954346}]}, {"text": "In Hindi, We don't have any data available annotated with clause boundary, Soto generate clause annotated corpora we have used () technique where they have showed how implicit clause information present in dependency trees can be used to extract clauses in sentences.", "labels": [], "entities": []}, {"text": "By this technique we have automatically generated 16000 sentences of Hindi treebank ) marked with clause boudaries.", "labels": [], "entities": []}, {"text": "Out of which, 14500 sentences were taken as training set, 500 for development set and remaining 1000 sentences for testing set.", "labels": [], "entities": []}, {"text": "As these sentences were generated automatically there are chances of noises inform of wrongly marked clause boundaries, so for proper evaluation of the system, we have manually corrected the wrongly marked clauses in development and testing sets.", "labels": [], "entities": []}, {"text": "To manually analyze the output of best performing models sample of 175 sentences is randomly selected from the large test set translated using both PBMT with lexical reordering and hierarchical models trained on \"ALL\" data sets.", "labels": [], "entities": [{"text": "ALL\" data sets", "start_pos": 213, "end_pos": 227, "type": "DATASET", "confidence": 0.6593336388468742}]}, {"text": "QuickJudge 11 is used to rank the outputs.", "labels": [], "entities": [{"text": "QuickJudge 11", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.7801716327667236}]}, {"text": "The annotator is shown the source, reference and output from both machine translation systems, the identity of the MT systems is not known.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.6928088217973709}]}, {"text": "There are four permitted outcomes of the ranking: both systems marked as equally good; both systems are equally bad or the output of one of the systems is better than the other one.", "labels": [], "entities": []}, {"text": "Here is the summary of annotation by a single annotator: \u2022 Out of 175 sentences, 41 sentences received equally bad translations from both systems.", "labels": [], "entities": []}, {"text": "\u2022 17 items are marked as equally good.", "labels": [], "entities": []}, {"text": "\u2022 In 79 cases, the hierarchical MT is ranked better than the phrase-based MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.8345947861671448}]}, {"text": "\u2022 In the remaining 38 cases, the phrase-based MT is ranked better than the hierarchical MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.7388973236083984}]}, {"text": "The results from the manual ranking show that the hierarchical systems wins twice more often than PBMT.", "labels": [], "entities": []}, {"text": "The two systems tie in about one third of input sentences, of which about 70 % are cases where the translations are bad.", "labels": [], "entities": []}, {"text": "As mentioned earlier identification of clause boundary for finite and non-finite clauses are independent, we have evaluated them separately.", "labels": [], "entities": []}, {"text": "Finite clause mainly have 5 types; Main clause, Complement Clause, Adverbial Clause, Relative Clause and Coordinate clause and evaluation has been done on them.", "labels": [], "entities": []}, {"text": "Our experimental setup is as follows: We take some English text as source, and translate it to a target language (German and Hindi in these experiments) by passing it through the translation pipeline described in section 3.", "labels": [], "entities": []}, {"text": "To show the usefulness of the lexicons described in section 2 and for comparison, we translate the same source twice: with and without word sense disambiguation.", "labels": [], "entities": []}, {"text": "For the first attempt, we used exactly the same translation pipeline as shown in, except that to overcome the deficiencies of our existing parse-tree disambiguator, for some of the examples, we used trees directly from the PennTreebank, which are supposed to be correct.", "labels": [], "entities": [{"text": "PennTreebank", "start_pos": 223, "end_pos": 235, "type": "DATASET", "confidence": 0.9839820265769958}]}, {"text": "However, this should not damage the claims made in this paper which is about developing wide coverage interlingual translation lexicons and then using them for WSD in an interlingual translation pipeline.", "labels": [], "entities": [{"text": "WSD", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.9081106781959534}, {"text": "interlingual translation pipeline", "start_pos": 170, "end_pos": 203, "type": "TASK", "confidence": 0.7630111376444498}]}, {"text": "For the second attempt, we plugged out the word sense disambiguation form the translation pipeline and used our old GF style lexicons (one target word per source word irrespective of its sense) in the linearization phase.", "labels": [], "entities": []}, {"text": "Finally, we compared both candidate translations to see if we have gained anything.", "labels": [], "entities": []}, {"text": "We did both manual and automatic evaluations to confirm our findings.", "labels": [], "entities": []}, {"text": "For a set of 25 sentences for English-German pair we got marginal BLEU score improvements (from 0.3904 to 0.399 with 'old' and 'new' dictionaries).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9792862236499786}]}, {"text": "Manual inspection, however, was much more encouraging, and explained the reasons for very low improvements in the BLEU scores in some cases.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 114, "end_pos": 125, "type": "METRIC", "confidence": 0.9784168899059296}]}, {"text": "The reason was that even if the word sense disambiguation, and hence, our new lexicon gives a better lexical choice, it will still be considered 'wrong\" by the evaluation tool if the gold-standard has a different choice.", "labels": [], "entities": []}, {"text": "It was also observed that there were cases where the 'old' lexicon produced a much better translation than the 'new' one.", "labels": [], "entities": []}, {"text": "The reasons for this are obvious.", "labels": [], "entities": []}, {"text": "The word sense disambiguator has its own limitations and is known to make mistakes.", "labels": [], "entities": []}, {"text": "Also, as explained in Section 5, the lexicon cannot be guaranteed to always give the right translation.", "labels": [], "entities": []}, {"text": "Next, we give a number of example sentence with comments 5 to show that how the new lexicons improved the quality of translations, and also give some examples where it worked the other way around.", "labels": [], "entities": []}, {"text": "The main goal of our task is to help raise an alarm at those moments when there is a high probability that the flu breaks out.", "labels": [], "entities": []}, {"text": "In real time situations, for each time, available data only comes from the previous days, and there is no known information about what will happen in the following days or week.", "labels": [], "entities": []}, {"text": "By adding the data day by day, we calculate the posterior probability for transiting to epidemic states based on previous observed data.", "labels": [], "entities": []}, {"text": "The sum over parameter Z i,t-1 and Z j,t makes it infeasible to calculate.", "labels": [], "entities": []}, {"text": "We use Gibbs Sampling by first sampling Z i,t-1 and Z j,t first and then attain the value of Z i,t given Zi,t-1,Zi,t-1,\u2026: shows the global distribution of DE, SE and RE in the year of 2013.", "labels": [], "entities": [{"text": "RE", "start_pos": 166, "end_pos": 168, "type": "METRIC", "confidence": 0.7405459880828857}]}, {"text": "The left hand side figure corresponds to number of flu-related microblog records overtime.", "labels": [], "entities": []}, {"text": "Purple symbols denote the phase of RE, red symbols denote the phase of SE and white symbols denote the phase of DE.", "labels": [], "entities": [{"text": "RE", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9196370244026184}, {"text": "SE", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9934296011924744}, {"text": "DE", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9787429571151733}]}, {"text": "shows the result of searching key words like influenza on Baidu Index platform.", "labels": [], "entities": [{"text": "Baidu Index platform", "start_pos": 58, "end_pos": 78, "type": "DATASET", "confidence": 0.9850467046101888}]}, {"text": "Compared to seems our influenza curve matches well.", "labels": [], "entities": [{"text": "influenza curve", "start_pos": 22, "end_pos": 37, "type": "METRIC", "confidence": 0.9114426374435425}]}, {"text": "The interesting thing we observe from is that if the percentage of RE > 0.5, there is strong possibility to convince the flu alarm is coming.", "labels": [], "entities": [{"text": "RE", "start_pos": 67, "end_pos": 69, "type": "METRIC", "confidence": 0.9862086772918701}]}, {"text": "Two-Phase: A simple version of our approach but using a simple two-phase in Markove network.", "labels": [], "entities": []}, {"text": "We only report partial experimental results for one province.", "labels": [], "entities": []}, {"text": "As we can see from, our model can best fit the actual microblog data and semms stable.", "labels": [], "entities": [{"text": "microblog data", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.8801383972167969}]}, {"text": "The other two measures also represent the actual truth but not stable enough.", "labels": [], "entities": []}, {"text": "As shown in, a large number of English adjectives (tagged JJ tag) are not tagged as named entities while their translations are tagged as locations.", "labels": [], "entities": []}, {"text": "Most of them are coming from country names, such as French, English, and Vietnamese, and they refer to people or languages.", "labels": [], "entities": []}, {"text": "In the English text \"Cuban missile crisis\", the word Cuban is not tagged as a location because Cuban is an adjective (\"Cuban/JJ missile/NN crisis/NN\"), while, in its Vietnamese translation, \"Khhng khoong t\u00ean lla [Cu Ba] LOC \", \"Cu Ba\" is tagged as a location.", "labels": [], "entities": [{"text": "Cuban missile crisis\"", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.5860727205872536}]}, {"text": "Moreover, there are several English named entities that are split into two entities in the Vietnamese sentences.", "labels": [], "entities": []}, {"text": "We evaluate our system in term of translation quality based on phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.6983464956283569}]}, {"text": "Source sentences are sequence of English words while target sentences are sequences of Thai character clusters and each cluster size depends on which approach used in the experiment.", "labels": [], "entities": []}, {"text": "Translation model and language model are train based on the standard phrase-based SMT.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9489359259605408}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.7540683746337891}]}, {"text": "Alignments of source (English word) and target (Thai Character Cluster) are extracted using GIZA++ and the phrase extraction algorithm is applied using Moses SMT package.", "labels": [], "entities": [{"text": "Thai Character Cluster)", "start_pos": 48, "end_pos": 71, "type": "DATASET", "confidence": 0.9226265549659729}, {"text": "phrase extraction", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.7765204608440399}, {"text": "Moses SMT package", "start_pos": 152, "end_pos": 169, "type": "DATASET", "confidence": 0.7559000054995219}]}, {"text": "We apply SRILM to train the 3-gram language model of target side.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.693979799747467}]}, {"text": "We use the default parameter settings for decoding.", "labels": [], "entities": []}, {"text": "In testing process, we use another two test sets difference to the training data.", "labels": [], "entities": []}, {"text": "Then we compared the translation result with the reference in term of BLEU score instead of F-score because of two main reasons.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9823054075241089}, {"text": "F-score", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9910428524017334}]}, {"text": "First, it is cumbersome to construct a reliable gold standard since their annotation schemes are different.", "labels": [], "entities": []}, {"text": "Second, there is no strong correlation with SMT translation quality in terms of BLEU score.", "labels": [], "entities": [{"text": "SMT translation", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.9363735914230347}, {"text": "BLEU score", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9780709445476532}]}, {"text": "Therefore, we re-segment the reference data (manually segmented) and the translation result data based on TCC.", "labels": [], "entities": [{"text": "TCC", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.8769674897193909}]}, {"text": "Some may concern about using TCC will lead to overestimation (higher than actual) due to the BLEU score is design based on word and not based on character.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.975717157125473}]}, {"text": "However, we used this BLEU score only for comparing translation quality among our experiments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9993114471435547}, {"text": "translation", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.9502044320106506}]}, {"text": "Comparing to other SMT system still require running BLEU score based on the same segmentation guideline.", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9850119352340698}, {"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9724872708320618}]}], "tableCaptions": [{"text": " Table 1: Semantic coherence values for k = 5 \u2212 9 for clustering algorithms GVM and k-means", "labels": [], "entities": [{"text": "GVM", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8679373860359192}]}, {"text": " Table 1: Results for English, Hindi and Konkani Language", "labels": [], "entities": []}, {"text": " Table 1: Statistics of English-Urdu parallel corpora.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of official English-Urdu test sets.", "labels": [], "entities": []}, {"text": " Table 3: Results of Phrase-based, Phrase-based with Lexical Reordering and Hierarchical MT  systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 89, "end_pos": 91, "type": "TASK", "confidence": 0.795830249786377}]}, {"text": " Table 4: Results of Phrase-based and Hierarchical systems on official test sets.", "labels": [], "entities": []}, {"text": " Table 2: Results on development set.", "labels": [], "entities": []}, {"text": " Table 3: Results on testing set.", "labels": [], "entities": []}, {"text": " Table 1  gives some statistics about the coverage of these lexicons.", "labels": [], "entities": []}, {"text": " Table 2. We observe that A+B is  much better than A or B. So in our following experiments, microblog are selected according to a classifier  based on feather A+B.", "labels": [], "entities": [{"text": "A+B", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.8877053260803223}]}, {"text": " Table 2: Result of different combinations of features for filtering", "labels": [], "entities": [{"text": "filtering", "start_pos": 59, "end_pos": 68, "type": "TASK", "confidence": 0.8285232186317444}]}, {"text": " Table 1: Characteristics of EVBNews part", "labels": [], "entities": [{"text": "EVBNews", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9545391201972961}]}, {"text": " Table 2: Number of files and sentences for each topic  Topic  File Sentence", "labels": [], "entities": [{"text": "Topic  File Sentence", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.5835425655047098}]}, {"text": " Table 3: Number of entities at the first stage  Tag  Name  Tagged English Entity Mapped Vietnamese Entity Unmapped Entity", "labels": [], "entities": [{"text": "Tag  Name  Tagged English Entity Mapped Vietnamese Entity Unmapped Entity", "start_pos": 49, "end_pos": 122, "type": "TASK", "confidence": 0.618228417634964}]}, {"text": " Table 4: Number of entities in the EVNECorpus  Tag  Name  English Entity Vietnamese Entity Unmatched Entity", "labels": [], "entities": [{"text": "EVNECorpus  Tag  Name  English Entity Vietnamese Entity Unmatched Entity", "start_pos": 36, "end_pos": 108, "type": "DATASET", "confidence": 0.7929660744137235}]}, {"text": " Table 5: Common Unmatched Named Entities  Description/Examples  POS Count", "labels": [], "entities": []}, {"text": " Table 1. Information of bilingual corpus", "labels": [], "entities": []}, {"text": " Table 2. Number of character clusters when different character clustering approaches are applied on the bilingual corpus", "labels": [], "entities": []}, {"text": " Table 3. BLEU score of each character clustering method  and the percentage of the improvement when we applied CCR to the data", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9729983508586884}, {"text": "character clustering", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.6899704784154892}]}, {"text": " Table 1: Clause distribution table.", "labels": [], "entities": [{"text": "Clause distribution", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.795887678861618}]}, {"text": " Table 2: Results of Clause Classification", "labels": [], "entities": [{"text": "Clause", "start_pos": 21, "end_pos": 27, "type": "TASK", "confidence": 0.9458439946174622}]}]}