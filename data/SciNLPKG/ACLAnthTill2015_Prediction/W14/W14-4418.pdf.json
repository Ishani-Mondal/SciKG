{"title": [{"text": "FlowGraph2Text: Automatic Sentence Skeleton Compilation for Procedural Text Generation \u2020 1", "labels": [], "entities": [{"text": "Procedural Text Generation", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.7643410762151083}]}], "abstractContent": [{"text": "In this paper we describe a method for generating a procedural text given its flow graph representation.", "labels": [], "entities": []}, {"text": "Our main idea is to automatically collect sentence skeletons from real texts by replacing the important word sequences with their type labels to form a skeleton pool.", "labels": [], "entities": []}, {"text": "The experimental results showed that our method is feasible and has a potential to generate natural sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Along with computers penetrating in our daily life, the needs for the natural language generation (NLG) technology are increasing more and more.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 70, "end_pos": 103, "type": "TASK", "confidence": 0.8140006065368652}]}, {"text": "If computers understand both the meaning of a procedural text and the progression status, they can suggest us what to do next.", "labels": [], "entities": []}, {"text": "In such situation they can show sentences describing the next instruction on a display or speak it.", "labels": [], "entities": []}, {"text": "On this background we propose a method for generating instruction texts from a flow graph representation fora series of procedures.", "labels": [], "entities": []}, {"text": "Among various genres of procedural texts, we choose cooking recipes, because they are one of the most familiar procedural texts for the public.", "labels": [], "entities": []}, {"text": "In addition, a computerized help system proposed by called smart kitchen is becoming more and more realistic.", "labels": [], "entities": []}, {"text": "Thus we try to generate cooking procedural texts from a formal representation fora series of preparation instructions of a dish.", "labels": [], "entities": []}, {"text": "As the formal representation, we adopt the flow graph representation (, in which the vertices and the arcs correspond to important objects \u2021 His current affiliation is Cybozu Inc., or actions in cooking and relationships among them, respectively.", "labels": [], "entities": []}, {"text": "We use the flow graphs as the input and the text parts as the references for evaluation.", "labels": [], "entities": []}, {"text": "Our generation method first automatically compiles a set of templates, which we call the skeleton pool, from a huge number of real procedural sentences.", "labels": [], "entities": []}, {"text": "Then it decomposes the input flow graph into a sequence of subtrees that are suitable fora sentence.", "labels": [], "entities": []}, {"text": "Finally it converts subtrees into natural language sentences.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments generating texts from flow graphs.", "labels": [], "entities": []}, {"text": "In this section, we report the coverage and the sentence quality.", "labels": [], "entities": [{"text": "coverage", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9759268760681152}]}, {"text": "The recipe flow graph corpus () contains 200 recipes.", "labels": [], "entities": [{"text": "recipe flow graph corpus", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.6357036083936691}]}, {"text": "We randomly selected 40 flow graphs as the test data from which we generate texts.", "labels": [], "entities": []}, {"text": "The other 160 recipes were used to train the NE recognizer PWNER () with 200 more recipes that we annotated with NE tags.", "labels": [], "entities": [{"text": "NE recognizer PWNER", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.6021229525407156}]}, {"text": "To compile the skeleton pool we crawled 100,000 recipes containing 713,524 sentences (see).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus specifications.  Usage  #Recipes #Sent.  #NEs  #Words  #Char.  Test  40  245  1,352  4,005  7,509  NER training  360  2,813  12,101  51,847  97,911  Skeleton pool  100,000 713,524  *  3,919,964  *  11,988,344 22,826,496  The numbers with asterisc are estimated values on the NLP result.", "labels": [], "entities": [{"text": "NLP result", "start_pos": 292, "end_pos": 302, "type": "DATASET", "confidence": 0.7782195210456848}]}, {"text": " Table 2: Statistical results of various skeleton pool sizes.  No. of sentences used for  2,769 11,077 44,308 177,235 708,940  skeleton pool compilation (1/256) (1/64) (1/16)  (1/4)  (1/1)  No. of uncovered subtrees  52  27  17  9  4  Average no. of skeletons  37.4  124.3  450.2  1598.1  5483.3  BLEU  11.19  11.25  12.86  13.12  13.76", "labels": [], "entities": [{"text": "BLEU", "start_pos": 297, "end_pos": 301, "type": "METRIC", "confidence": 0.9746843576431274}]}]}