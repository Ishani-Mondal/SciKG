{"title": [{"text": "Looking for Hyponyms in Vector Space", "labels": [], "entities": []}], "abstractContent": [{"text": "The task of detecting and generating hy-ponyms is at the core of semantic understanding of language, and has numerous practical applications.", "labels": [], "entities": []}, {"text": "We investigate how neural network embeddings perform on this task, compared to dependency-based vector space models, and evaluate a range of similarity measures on hyponym generation.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.7333315014839172}]}, {"text": "A new asymmetric similarity measure and a combination approach are described , both of which significantly improve precision.", "labels": [], "entities": [{"text": "asymmetric similarity measure", "start_pos": 6, "end_pos": 35, "type": "METRIC", "confidence": 0.6555862923463186}, {"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.998375415802002}]}, {"text": "We release three new datasets of lexical vector representations trained on the BNC and our evaluation dataset for hyponym generation.", "labels": [], "entities": [{"text": "BNC", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.958377480506897}, {"text": "hyponym generation", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7389833927154541}]}], "introductionContent": [{"text": "Hyponymy is a relation between two word senses, indicating that the meaning of one word is also contained in the other.", "labels": [], "entities": []}, {"text": "It can bethought of as a type-of relation; for example car, ship and train are all hyponyms of vehicle.", "labels": [], "entities": []}, {"text": "We denote a hyponymy relation between words a and b as (a \u2192 b), showing that a is a hyponym of b, and b is a hypernym of a.", "labels": [], "entities": []}, {"text": "Hyponymy relations are closely related to the concept of entailment, and this notation is consistent with indicating the direction of inference -if a is true, b must be true as well.", "labels": [], "entities": []}, {"text": "Automatic detection and generation of hyponyms has many practical applications in nearly all natural language processing tasks.", "labels": [], "entities": [{"text": "Automatic detection and generation of hyponyms", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8118151923020681}, {"text": "natural language processing tasks", "start_pos": 93, "end_pos": 126, "type": "TASK", "confidence": 0.731131836771965}]}, {"text": "Information retrieval, information extraction and question answering can be improved by performing appropriate query expansions.", "labels": [], "entities": [{"text": "Information retrieval", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8284393548965454}, {"text": "information extraction", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8535881042480469}, {"text": "question answering", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8903293907642365}]}, {"text": "For example, a user searching for arthritis treatment is most likely also interested in results containing the hyponyms of treatment, such as arthritis therapy, arthritis medication, and arthritis rehabilitation.", "labels": [], "entities": [{"text": "arthritis rehabilitation", "start_pos": 187, "end_pos": 211, "type": "TASK", "confidence": 0.7056678682565689}]}, {"text": "Summarisation systems can increase coherence and reduce repetition by correctly handling hyponymous words in the input text.", "labels": [], "entities": [{"text": "Summarisation", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9483475089073181}, {"text": "repetition", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9807080626487732}]}, {"text": "Entailment and inference systems can improve sentence-level entailment resolution by detecting the presence and direction of wordlevel hyponymy relations.", "labels": [], "entities": [{"text": "sentence-level entailment resolution", "start_pos": 45, "end_pos": 81, "type": "TASK", "confidence": 0.7234743336836497}]}, {"text": "Distributionally similar words have been used for smoothing language models and word co-occurrence probabilities, and hyponyms can be more suitable for this application.", "labels": [], "entities": []}, {"text": "We distinguish between three different tasks related to hyponyms.", "labels": [], "entities": []}, {"text": "Given a directional word pair, the goal of hyponym detection is to determine whether one word is a hyponym of the other).", "labels": [], "entities": [{"text": "hyponym detection", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7892278134822845}]}, {"text": "In contrast, hyponym acquisition is the task of extracting all possible hyponym relations from a given text).", "labels": [], "entities": [{"text": "hyponym acquisition", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8500030934810638}]}, {"text": "Such systems often make use of heuristic rules and patterns for extracting relations from surface text, and populate a database with hyponymous word pairs.", "labels": [], "entities": []}, {"text": "Finally, the task of hyponym generation is to return a list of all possible hyponyms, given only a single word as input.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8815607726573944}]}, {"text": "This is most relevant to practical applications, as many systems require a set of appropriate substitutes fora specific term.", "labels": [], "entities": []}, {"text": "Automated ontology creation () is a related field that also makes use of distributional similarity measures.", "labels": [], "entities": [{"text": "Automated ontology creation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7874075969060262}]}, {"text": "However, it is mostly focused on building prototype-based ontologies through clustering), and is not directly applicable to hyponym generation.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.7577392756938934}]}, {"text": "While most work has been done on hyponym detection (and the related task of lexical substitution), barely any evaluation has been done for hyponym generation.", "labels": [], "entities": [{"text": "hyponym detection", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8085812330245972}, {"text": "lexical substitution", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7597192823886871}, {"text": "hyponym generation", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7548812031745911}]}, {"text": "We have found that systems for hyponym detection often perform poorly on hyponym generation, as the latter requires returning results from a much less restricted candidate set, and therefore a task-specific evaluation is required.", "labels": [], "entities": [{"text": "hyponym detection", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8844040334224701}, {"text": "hyponym generation", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.8100312650203705}]}, {"text": "In this paper we focus on hyponym generation and approach it by scoring a very large candidate set of potential hyponyms.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9018096029758453}]}, {"text": "Distributional similarity methods are especially interesting for this task, as they can be easily applied to different domains, genres and languages without requiring annotated training data or manual pattern construction.", "labels": [], "entities": []}, {"text": "We perform a systematic comparison of different vector space models and similarity measures, in order to better understand the properties of a successful method for hyponym generation.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.7146066427230835}]}, {"text": "The main contributions of this paper are: 1.", "labels": [], "entities": []}, {"text": "Systematic evaluation of different vector space models and similarity measures on the task of hyponym generation.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7281380742788315}]}, {"text": "2. Proposal of new properties for modelling the directional hyponymy relation.", "labels": [], "entities": []}, {"text": "3. Release of three lexical vector datasets, trained using neural network, window-based, and dependency-based features.", "labels": [], "entities": []}], "datasetContent": [{"text": "As WordNet contains numerous manually annotated hyponymy relations, we can use it to construct suitable datasets for evaluating hyponym generation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.9332733154296875}, {"text": "hyponym generation", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.733364149928093}]}, {"text": "While WordNet terms are annotated with only the closest hyponyms, we are considering all indirect/inherited hyponyms to be relevant -for example, given relations (genomics \u2192 genetics) and (genetics \u2192 biology), then genomics is also regarded as a hyponym of biology.", "labels": [], "entities": []}, {"text": "WordNet relations are defined between synsets, but we refrain from the task of word sense disambiguation and count word a as a valid hyponym for word b if it is valid for any sense of b.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.6540372172991434}]}, {"text": "Synonymy can bethought of as asymmetric isa relation, and most real-world applications would require synonyms to also be returned, together with hyponyms.", "labels": [], "entities": []}, {"text": "Therefore, in our dataset we consider synonyms as hyponyms in both directions.", "labels": [], "entities": []}, {"text": "We also performed experiments without synonyms and found that this had limited effect on the results -while the accuracy of all similarity measures slightly decreased (due to fewer numbers of correct answers), the relative ranking remained the same.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.999177873134613}]}, {"text": "As shown in the next section, the number of synonyms is typically small compared to the number of all inherited hyponyms.", "labels": [], "entities": []}, {"text": "To construct the dataset, we first found all single-word nouns in WordNet that are contained at least 10 times in the British National Corpus (BNC).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9673137664794922}, {"text": "British National Corpus (BNC)", "start_pos": 118, "end_pos": 147, "type": "DATASET", "confidence": 0.9715486665566763}]}, {"text": "Next, we retained only words that have at least 10 hyponyms, such that they occur 10 or more times in the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.9536353945732117}]}, {"text": "This selection process aims to discard WordNet hypernyms that are very rare in practical use, and would not have enough examples for learning informative vector representations.", "labels": [], "entities": []}, {"text": "The final dataset contains the remaining terms, together with all of their hyponyms, including the rare/unseen hyponyms.", "labels": [], "entities": []}, {"text": "As expected, some general terms, such as group or location, have a large number of inherited hyponyms.", "labels": [], "entities": []}, {"text": "On average, each hypernym in the dataset has 233 hyponyms, but the distribution is roughly exponential, and the median is only 36.", "labels": [], "entities": []}, {"text": "In order to better facilitate future experiments with supervised methods, such as described by, we randomly separated the data into training (1230 hypernyms), validation (922), and test (922) sets, and we make these datasets publically available online.", "labels": [], "entities": []}, {"text": "We evaluate how well different vector space models and similarity measures perform on the task of hyponym generation.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7191389054059982}]}, {"text": "Given a single word as input, the system needs to return a ranked list of words with correct hyponyms at the top.", "labels": [], "entities": []}, {"text": "As the list of candidates for scoring we use all words in the BNC that occur at least 10 times (a total of 86,496 words).", "labels": [], "entities": [{"text": "BNC", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.9066219925880432}]}, {"text": "All the experiments are performed using tokenised and lemmatised words.", "labels": [], "entities": []}, {"text": "As the main evaluation measure, we report: Experiments using different vector space models for hyponym generation on the test set.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7165304571390152}]}, {"text": "We report results using regular cosine similarity and the vector offset method described in Section 2.", "labels": [], "entities": []}, {"text": "Mean Average Precision (MAP), which averages precision values at various recall points in the returned list.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 0, "end_pos": 28, "type": "METRIC", "confidence": 0.9657242099444071}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9983966946601868}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9951081871986389}]}, {"text": "It combines both precision and recall, as well as the quality of the ranking, into a single measure, and is therefore well-suited for comparing different methods.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9994003772735596}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9989281296730042}]}, {"text": "The reported MAP values are very low -this is due to many rare WordNet hyponyms not occurring in the candidate set, for which all systems are automatically penalised.", "labels": [], "entities": [{"text": "MAP", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9261611104011536}, {"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9228901267051697}]}, {"text": "However, this allows us to evaluate recall, making the results comparable between different systems and background datasets.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.998331606388092}]}, {"text": "We also report precision at top-1 and top-5 returned hyponyms.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9992363452911377}]}, {"text": "As a baseline we report the results of a traditional hyponym acquisition system.", "labels": [], "entities": []}, {"text": "For this, we implemented the pattern-based matching process described by, and also used by.", "labels": [], "entities": []}, {"text": "These patterns look for explicit examples of hyponym relations mentioned in the text, for example: where X will be extracted as the hypernym, and Y 1 to Y n as hyponyms.", "labels": [], "entities": []}, {"text": "We ran the patterns over the BNC and extracted 21,704 hyponym pairs, which were then ranked according to the number of times they were found.", "labels": [], "entities": [{"text": "BNC", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.9715625643730164}]}, {"text": "contains experiments with different vector space models.", "labels": [], "entities": []}, {"text": "We report here results using cosine, as it is an established measure and a competitive baseline.", "labels": [], "entities": []}, {"text": "For our task, the HLBL vectors perform better than CW vectors, even though they were trained on the same data.", "labels": [], "entities": []}, {"text": "Both of them are outperformed by word2vec-100 vectors, which have the same dimensionality but are trained on much more text.", "labels": [], "entities": []}, {"text": "Increasing the dimensionality with word2vec-500 gives a further improvement.", "labels": [], "entities": []}, {"text": "Interestingly, the simple window-based vectors perform just as well as the ones trained with neural networks.", "labels": [], "entities": []}, {"text": "However, the advantage of word2vec-500 is that the representations are more compact and require only about half the space.", "labels": [], "entities": []}, {"text": "Finally, the dependency-based vectors outperform all other vector types, giving 2.73% MAP and 25.41% precision at the top-ranked result.", "labels": [], "entities": [{"text": "MAP", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9949799180030823}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9995514750480652}]}, {"text": "While the other models are built by using neighbouring words as context, this model looks at dependency relations, thereby taking both semantic and syntactic roles into account.", "labels": [], "entities": []}, {"text": "The results indicate that word2vec and window-based models are more suitable when the general topic of words needs to be captured, whereas dependency-based vectors are preferred when the task requires both topical and functional similarity between words.", "labels": [], "entities": []}, {"text": "Our experiments also included the evaluation of other similarity measures on different vector space models, and we we found these results to be representative.", "labels": [], "entities": []}, {"text": "Contrary to previous work, the vector offset method, described in Section 2, did not provide substantial improvements on the hyponym generation task.", "labels": [], "entities": [{"text": "vector offset", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.7527397572994232}, {"text": "hyponym generation task", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.7930647730827332}]}, {"text": "For the neural network-based vectors this approach generally decreased performance, compared to using direct cosine similarity.", "labels": [], "entities": []}, {"text": "There are some marginal improvements for window and dependency-based models.", "labels": [], "entities": []}, {"text": "Unfortunately, the original work did not include baseline performance using cosine similarity, without applying vector modifications.", "labels": [], "entities": []}, {"text": "It is possible that this method does not generalise to all word relations equally well.", "labels": [], "entities": []}, {"text": "As part of future work, it is worth exploring if a hypernym-specific strategy of selecting training examples could improve the performance.: Evaluation of different vector similarity measures on the validation and test set of hyponym generation.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 226, "end_pos": 244, "type": "TASK", "confidence": 0.7136616110801697}]}, {"text": "We report Mean Average Precision (MAP), precision at rank 1 (P@1), and precision at rank 5 (P@5).", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.9509830276171366}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9996115565299988}, {"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9995669722557068}]}, {"text": "contains experiments with different similarity measures, using the dependency-based model, and contains sample output from the best system.", "labels": [], "entities": []}, {"text": "The results show that the patternbased baseline does rather poorly on this task.", "labels": [], "entities": []}, {"text": "MAP is low due to the system having very limited recall, but higher precision at top ranks would have been expected.", "labels": [], "entities": [{"text": "MAP", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9211726188659668}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.999518871307373}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9993059635162354}]}, {"text": "Analysis showed that this system was unable to find any hyponyms for more than half (513/922) of the hypernyms in the validation set, leading to such poor recall that it also affects Precision@1.", "labels": [], "entities": [{"text": "recall", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9984898567199707}]}, {"text": "While the pattern-based system did extract a relatively large number of hyponyms from the corpus (21,704 pairs), these are largely concentrated on a small number of hypernyms (e.g., area, company, material, country) that are more likely to be mentioned in matching contexts.", "labels": [], "entities": []}, {"text": "Cosine, DiceGen2 and Lin -all symmetric similarity measures -perform relatively well on this task, whereas established directional measures perform unexpectedly poorly.", "labels": [], "entities": []}, {"text": "This can perhaps be explained by considering the distribution of hyponyms.", "labels": [], "entities": []}, {"text": "Given a word, the most likely candidates fora high cosine similarity are synonyms, antonyms, hypernyms and hyponyms of that word -these are words that are likely to be used in similar topics, contexts, and syntactic roles.", "labels": [], "entities": []}, {"text": "By definition, there are an equal number of hyponym and hypernym relations in WordNet, but this ratio changes rapidly as we remove lower-frequency words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9531561136245728}]}, {"text": "shows the number of relations extracted from WordNet, as we restrict the minimum frequency of the main word.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.9642069339752197}]}, {"text": "It can be seen that the number of hyponyms increases much faster compared to the other three relations.", "labels": [], "entities": []}, {"text": "This also applies to real-world data -when averaging over word instances found in the BNC, hyponyms cover 85% of these relations.", "labels": [], "entities": [{"text": "BNC", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.8746355175971985}]}, {"text": "Therefore, the high performance of cosine can be explained by distributionally similar words having a relatively high likelihood of being hyponyms.", "labels": [], "entities": []}, {"text": "One possible reason for the poor performance of directional measures is that most of them quantify how well the features of the narrower term are included in the broader term.", "labels": [], "entities": []}, {"text": "In contrast, we found that for hyponym generation it is more important to measure how well the features of the broader term are included in the narrower term.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.78109410405159}]}, {"text": "This scientist researcher, biologist, psychologist, economist, observer, physicist, sociologist sport football, golf, club, tennis, athletics, rugby, cricket, game, recreation, entertainment treatment therapy, medication, patient, procedure, surgery, remedy, regimen, medicine: Examples of top results using the combined system.", "labels": [], "entities": []}, {"text": "WordNet hyponyms are marked in bold. is supported by WeedsRec outperforming WeedsPrec, although the opposite was intended by their design.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9310505390167236}]}, {"text": "Another explanation for the low performance is that these directional measures are often developed in an artificial context.", "labels": [], "entities": []}, {"text": "For example, evaluated lexical entailment detection on a dataset where the symmetric Lin similarity measure was used to select word pairs for manual annotation.", "labels": [], "entities": [{"text": "lexical entailment detection", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6862402458985647}]}, {"text": "This creates a different task, as correct terms that do not have a high symmetric similarity will be excluded from evaluation.", "labels": [], "entities": []}, {"text": "The BalAPInc measure performed best in that setting, but does not do as well for hyponym generation, where candidates are filtered only based on minimum frequency.", "labels": [], "entities": [{"text": "BalAPInc", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.946270227432251}, {"text": "hyponym generation", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7139410376548767}]}, {"text": "The weighted cosine measure, proposed in Section 5, outperformed all other similarity measures on both hyponym generation datasets.", "labels": [], "entities": []}, {"text": "The improvement over cosine is relatively small; however, it is consistent and the improvement in MAP is statistically significant on both datasets (p < 0.05), using the Approximate Randomisation Test) with 10 6 iterations.", "labels": [], "entities": [{"text": "MAP", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.8968923091888428}, {"text": "Approximate Randomisation Test", "start_pos": 170, "end_pos": 200, "type": "METRIC", "confidence": 0.8610537846883138}]}, {"text": "This further supports the properties of a directional similarity measure described in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we created anew system by combining together two separate approaches: the weighted cosine measure using the dependency-based vector space, and the normal cosine similarity using word2vec-500 vectors.", "labels": [], "entities": []}, {"text": "We found that the former is good at modelling the grammatical roles and directional containment, whereas the latter can provide useful information about the topic and semantics of the word.", "labels": [], "entities": []}, {"text": "Turney (2012) also demonstrated the importance of both topical (domain) and functional vector space models when working with semantic relations.", "labels": [], "entities": []}, {"text": "We combined these approaches by calculating both scores for each word pair and taking their geometric average, or 0 if it could not be calculated.", "labels": [], "entities": []}, {"text": "This final system gives considerable improvements across all evaluation metrics, and is significantly (p < 0.05) better compared to cosine or weighted cosine methods individually.", "labels": [], "entities": []}, {"text": "contains some example output from this system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experiments using different vector space models for hyponym generation on the test set. We  report results using regular cosine similarity and the vector offset method described in Section 2.", "labels": [], "entities": [{"text": "hyponym generation", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7422414720058441}]}, {"text": " Table 3: Evaluation of different vector similarity measures on the validation and test set of hyponym  generation. We report Mean Average Precision (MAP), precision at rank 1 (P@1), and precision at rank  5 (P@5).", "labels": [], "entities": [{"text": "hyponym  generation", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7499726116657257}, {"text": "Mean Average Precision (MAP)", "start_pos": 126, "end_pos": 154, "type": "METRIC", "confidence": 0.9665044049421946}, {"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.999071478843689}, {"text": "precision", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.9994227886199951}]}]}