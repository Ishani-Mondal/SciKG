{"title": [{"text": "Automatic Annotation of Parameters from Nanodevice Development Research Papers", "labels": [], "entities": []}], "abstractContent": [{"text": "In utilizing nanodevice development research papers to assist in experimental planning and design , it is useful to identify and annotate characteristic categories of information contained in those papers such as source material, evaluation parameter, etc.", "labels": [], "entities": []}, {"text": "In order to support this annotation process, we have been working to construct a nanodevice development corpus and a complementary automatic annotation scheme.", "labels": [], "entities": []}, {"text": "Due to the variations of terms, however, recall of the automatic annotation in some information categories was not adequate.", "labels": [], "entities": [{"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9976637363433838}]}, {"text": "In this paper, we propose to use a basic physical quantities list to extract parameter information.", "labels": [], "entities": []}, {"text": "We confirmed the efficiency of this method to improve the annotation of parameters.", "labels": [], "entities": []}, {"text": "Recall for parameters increases between 4% and 7% depending on the type of parameter and analysis metric.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9946423768997192}]}], "introductionContent": [{"text": "\"Nanoinformatics\" is an emerging interdisciplinary research field in developing a computational framework to support nanoscale research ().", "labels": [], "entities": []}, {"text": "Nanoinformatics is the science and practice of determining which information is relevant to the nanoscale science and engineering community, and then developing and implementing effective mechanisms for collecting, validating, storing, sharing, analyzing, modeling, and applying this information (De la).", "labels": [], "entities": []}, {"text": "In order to support nanodevice development process, we have been working on a project that aims at analyzing the experiment results related to nanodevice development to provide insights for nanodevice novice researchers to help them planning their experiments more effectively (.", "labels": [], "entities": []}, {"text": "In this project, we have proposed a framework to annotate useful information from research papers related to nanodevice development (e.g., source material, evaluation parameter, and so on), and use them for analyzing experiment results ().", "labels": [], "entities": []}, {"text": "In order to speedup the annotation process, we have built an automatic annotation framework using machine-learning techniques to annotate research papers ().", "labels": [], "entities": []}, {"text": "However, due to the variations of terms, this framework may miss to annotate terms that are not in the training data set.", "labels": [], "entities": [{"text": "training data set", "start_pos": 103, "end_pos": 120, "type": "DATASET", "confidence": 0.7986964384714762}]}, {"text": "Therefore, we have used chemical named entity recognition system to add generalized feature to extract \"source material\" terms.", "labels": [], "entities": [{"text": "chemical named entity recognition", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.6541639938950539}]}, {"text": "This generalized information is useful to extract \"source material\" terms and recall of this category increased.", "labels": [], "entities": [{"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9993932247161865}]}, {"text": "However, there are several other categories whose recall is inadequate.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9995073080062866}]}, {"text": "In this paper, we propose to use a physical quantities list for adding generalized feature for extracting parameter terms in two categories (\"evaluation parameter\" and \"experiment parameter\").", "labels": [], "entities": []}, {"text": "In those two categories, since \"experiment parameter\" represents a control parameter for the experimental equipment and \"evaluation parameter\" represents ones measured by measuring devices, most of the terms are associated with physical quantities and they contains (a) term(s) that represent(s) its characteristics.", "labels": [], "entities": []}, {"text": "We use 2 methods for the identification: first one we try to identify parameters (experiment and evaluation) using the new automatic annotated framework.", "labels": [], "entities": []}, {"text": "The other one, we identify the parameters (in general) using the automatic annotation framework, and then classify the parameters into experiment and evaluation using SVM (Support Vector Machine)).", "labels": [], "entities": []}, {"text": "Several attempts have been made to use dictionary to enhance machine-learning performance.", "labels": [], "entities": []}, {"text": "For example, is using a dictionary to assist in identifying certain categories of chemical entities in biomedical text.", "labels": [], "entities": []}, {"text": "Our method is using the physical quantities list to enhance the identification of parameter information.", "labels": [], "entities": []}, {"text": "This paper has five sections.", "labels": [], "entities": []}, {"text": "The first one is introduction.", "labels": [], "entities": [{"text": "introduction", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.9490854740142822}]}, {"text": "Second one introduces the nanodevice development papers corpus we have developed () and the automatic annotation framework we have built () in brief.", "labels": [], "entities": []}, {"text": "Section 3 discusses parameter identification methods.", "labels": [], "entities": [{"text": "parameter identification", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.7477408349514008}]}, {"text": "In section 4, we demonstrate the experiment and discuss the results, and section 5 is a conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Automatic annotation framework performance", "labels": [], "entities": []}, {"text": " Table 2: Performance comparison between base line system and suggested one", "labels": [], "entities": []}]}