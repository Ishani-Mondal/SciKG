{"title": [{"text": "Chinese Spelling Check System Based on Tri-gram Model", "labels": [], "entities": [{"text": "Chinese Spelling Check", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5426674286524454}]}], "abstractContent": [{"text": "This paper describes our system in the Chinese spelling check (CSC) task of CLP-SIGHAN Bake-Off 2014.", "labels": [], "entities": [{"text": "Chinese spelling check (CSC) task", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.7131374137742179}, {"text": "CLP-SIGHAN Bake-Off 2014", "start_pos": 76, "end_pos": 100, "type": "DATASET", "confidence": 0.5897964934508005}]}, {"text": "CSC is still an open problem today.", "labels": [], "entities": [{"text": "CSC", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7528794407844543}]}, {"text": "To the best of our knowledge, n-gram language modeling (LM) is widely used in CSC because of its simplicity and fair predictive power.", "labels": [], "entities": [{"text": "n-gram language modeling (LM)", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.7510273158550262}]}, {"text": "Our work in this paper continues this general line of research by using a tri-gram LM to detect and correct possible spelling errors.", "labels": [], "entities": []}, {"text": "In addition, we use dynamic programming to improve the efficiency of the algorithm, and additive smoothing to solve the data sparseness problem in training set.", "labels": [], "entities": []}, {"text": "Empirical evaluation results demonstrate the utility of our CSC system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spelling check is a common task in every written language, which is an automatic mechanism to detect and correct human errors ( ).", "labels": [], "entities": [{"text": "Spelling check", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8152138888835907}]}, {"text": "The problem of devising algorithms and techniques for automatically correcting words in text began as early as the 1960s on computer techniques for automatic spelling correction and automatic text recognition, and it has continued up to the present.", "labels": [], "entities": [{"text": "automatic spelling correction", "start_pos": 148, "end_pos": 177, "type": "TASK", "confidence": 0.6451027095317841}, {"text": "text recognition", "start_pos": 192, "end_pos": 208, "type": "TASK", "confidence": 0.6918894946575165}]}, {"text": "A spelling checker should have both capabilities consisting of error detection and error correction.", "labels": [], "entities": [{"text": "spelling checker", "start_pos": 2, "end_pos": 18, "type": "TASK", "confidence": 0.9299125373363495}, {"text": "error detection", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.8195274174213409}]}, {"text": "Spelling error detection is to indicate the various types of spelling errors in the text.", "labels": [], "entities": [{"text": "Spelling error detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9099662105242411}]}, {"text": "Spelling error correction is further to suggest the correct characters of detected errors.", "labels": [], "entities": [{"text": "Spelling error correction", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.5535635054111481}]}, {"text": "Chinese as a foreign language (CFL) have attracted more and more attention, and this trend is continuing.", "labels": [], "entities": [{"text": "Chinese as a foreign language (CFL)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.64674212038517}]}, {"text": "For this purpose, at the SIGHAN Bake-offs, Chinese spelling check (CSC) task are organized to provide an evaluation platform for developing and implementing automatic Chinese spelling checkers.", "labels": [], "entities": [{"text": "SIGHAN Bake-offs", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.6402102112770081}, {"text": "Chinese spelling check (CSC)", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.5189702113469442}]}, {"text": "However, spelling check in Chinese is very different from that in English or other alphabetic languages.", "labels": [], "entities": [{"text": "spelling check", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.5594386607408524}]}, {"text": "There are no word delimiters between words and the length of each word is very short.", "labels": [], "entities": []}, {"text": "A Chinese \"word\" usually comprises two or more characters.", "labels": [], "entities": []}, {"text": "The difficulty of Chinese processing is that many Chinese characters have similar shapes or similar (or same) pronunciations.", "labels": [], "entities": []}, {"text": "Some characters are even similar in both shape and pronunciation ().", "labels": [], "entities": []}, {"text": "There are many research effort developed for CSC recently, including rule-based model, n-gram model (, graph theory (, statistical learning method, etc.", "labels": [], "entities": []}, {"text": "Some of them are hybrid model.", "labels": [], "entities": []}, {"text": "Language modeling (LM) is widely used in CSC, and the most widely-used and wellpracticed language model, by far, is the n-gram LM), because of its simplicity and fair predictive power.", "labels": [], "entities": [{"text": "Language modeling (LM)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8274580478668213}]}, {"text": "Our work in this paper continues this general line of research by using a tri-gram LM to detect and correct possible spelling errors.", "labels": [], "entities": []}, {"text": "In addition, in order to solve the high complexity in the computation process of the tri-gram based CSC, dynamic programming is used to improve the efficiency of the algorithm.", "labels": [], "entities": []}, {"text": "Moreover, additive smoothing to solve the data sparseness problem in training set.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly present the proposed CSC system, confusion sets and the choice of ngram order.", "labels": [], "entities": []}, {"text": "Section 3 details our Chinese trigram model.", "labels": [], "entities": []}, {"text": "Evaluation results are presented in Section 4.", "labels": [], "entities": []}, {"text": "Finally, the last section summarizes this paper and describes our future work.", "labels": [], "entities": []}, {"text": "shows the flowchart of our CSC system.", "labels": [], "entities": []}, {"text": "The system is mainly composed by three components: confusion sets, corpus and language model.", "labels": [], "entities": []}, {"text": "It performs CSC in the following steps:", "labels": [], "entities": [{"text": "CSC", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9451639652252197}]}], "datasetContent": [{"text": "The CSC task of CLP-SIGHAN Bake-Off 2014 attracted 19 research teams.", "labels": [], "entities": [{"text": "CSC task of CLP-SIGHAN Bake-Off 2014", "start_pos": 4, "end_pos": 40, "type": "DATASET", "confidence": 0.685168186823527}]}, {"text": "Among 19 registered research teams, 13 participants submitted their testing results.", "labels": [], "entities": []}, {"text": "For formal testing, each participant can submit at most three runs that use different models or parameter settings.", "labels": [], "entities": []}, {"text": "Finally, there are 34 runs submitted in total.", "labels": [], "entities": []}, {"text": "shows the evaluation results of the final test.", "labels": [], "entities": []}, {"text": "Run1, run2 and run3 are the three runs  chosen three runs with different estimated recall levels as submissions.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9973626732826233}]}, {"text": "The \"Best\" indicates the high score of each metric achieved in CSC task.", "labels": [], "entities": []}, {"text": "The \"Average\" represents the average of the 34 runs.", "labels": [], "entities": [{"text": "Average\"", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9510892629623413}]}, {"text": "As we can see from, we achieve a result close to the average level.", "labels": [], "entities": []}, {"text": "The major weakness of our system is its low recall rate, which might be the result of not applying a separate error detection module.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.9882248640060425}]}, {"text": "It is our first attempt on Chinese spelling check.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.7570267717043558}]}, {"text": "The potential of the n-gram method is far from fully exploited.", "labels": [], "entities": []}, {"text": "Some typical errors of our current system will be presented in the next subsection, and the corresponding improvements are summarized in the last section.", "labels": [], "entities": []}, {"text": "shows some typical error examples of our system (\"O\" original, \"M\" modified): The first case is an overkill error that belongs to long distance error correction problem.", "labels": [], "entities": [{"text": "long distance error correction", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.5761096999049187}]}, {"text": "Our system didn't recognize the dependencies of \"\u6234\" and \"\u5e3d\u5b50\", and \"\u6211\u5e36\u8457\" get a highest score in tri-gram model.", "labels": [], "entities": []}, {"text": "So our system select \"\u5e36\" to replace \"\u6234\", and leads to error at the same time.", "labels": [], "entities": [{"text": "error", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.9874750971794128}]}], "tableCaptions": [{"text": " Table 1. Evaluation results of final test.", "labels": [], "entities": []}]}