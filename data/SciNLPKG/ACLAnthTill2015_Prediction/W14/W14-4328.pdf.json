{"title": [{"text": "Interaction Quality Estimation in Spoken Dialogue Systems Using Hybrid-HMMs", "labels": [], "entities": [{"text": "Interaction Quality Estimation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8134159048398336}]}], "abstractContent": [{"text": "Research trends on SDS evaluation are recently focusing on objective assessment methods.", "labels": [], "entities": [{"text": "SDS evaluation", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9780726432800293}]}, {"text": "Most existing methods, which derive quality for each system-user-exchange, do not consider temporal dependencies on the quality of previous exchanges.", "labels": [], "entities": []}, {"text": "In this work, we investigate an approach for determining Interaction Quality for human-machine dialogue based on methods modeling the sequential characteristics using HMM mod-eling.", "labels": [], "entities": []}, {"text": "Our approach significantly outper-forms conventional approaches by up to 4.5% relative improvement based on Un-weighted Average Recall metrics.", "labels": [], "entities": [{"text": "Un-weighted Average Recall metrics", "start_pos": 108, "end_pos": 142, "type": "METRIC", "confidence": 0.8588861376047134}]}], "introductionContent": [{"text": "Spoken Dialogue Systems (SDSs) play a key role in achieving natural human-machine interaction.", "labels": [], "entities": []}, {"text": "One reason is that speech is one major channel of natural human communication.", "labels": [], "entities": []}, {"text": "Assessing the quality of such SDSs has been discussed frequently in recent years.", "labels": [], "entities": [{"text": "SDSs", "start_pos": 30, "end_pos": 34, "type": "TASK", "confidence": 0.9582434892654419}]}, {"text": "The basic principles which all approaches underlie have been analyzed by creating a taxonomy for quality of human-machine interaction, i.e., Quality of Service (QoS) and Quality of Experience (QoE).", "labels": [], "entities": []}, {"text": "Quality of Service describes objective criteria like total number of turns.", "labels": [], "entities": []}, {"text": "The recent shift of interest in dialogue assessment methods towards subjective criteria is described as Quality of Experience, putting the user in the spotlight of dialogue assessment.", "labels": [], "entities": [{"text": "dialogue assessment", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8130544126033783}, {"text": "dialogue assessment", "start_pos": 164, "end_pos": 183, "type": "TASK", "confidence": 0.8054728806018829}]}, {"text": "For QoE, identified several aspects contributing to a good user experience, e.g., usability or acceptability.", "labels": [], "entities": []}, {"text": "These aspects can be combined under the term user satisfaction, describing the degree by which the user is satisfied with the system's performance.", "labels": [], "entities": []}, {"text": "By assessing QoE, the hope of the research community is to better measure the human-like quality of an SDS.", "labels": [], "entities": []}, {"text": "While this information maybe used during the design process, enabling automatically derived user satisfaction within the dialogue management allows for adaption of the ongoing dialogue (.", "labels": [], "entities": []}, {"text": "First work on deriving subjective metrics automatically has been performed by resulting in the PARADISE framework, which is the current quasi-standard in this field.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9158160090446472}]}, {"text": "Briefly explained, a linear dependency is assumed between dialogue parameters and user satisfaction to estimate qualitative performance on the dialogue level.", "labels": [], "entities": []}, {"text": "Measuring the performance of complete dialogues does not allow for adapting to the user during the dialogue ().", "labels": [], "entities": []}, {"text": "Hence, performance measures which provide a measurement for each system-user-exchange 1 are of interest.", "labels": [], "entities": []}, {"text": "Approaches based on Hidden Markov Models (HMMs) are widely used for sequence modeling.", "labels": [], "entities": [{"text": "sequence modeling", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.8601919114589691}]}, {"text": "Therefore,  used these models for predicting the dialogue quality on the exchange level.", "labels": [], "entities": []}, {"text": "Similar to this, we presented work on estimating Interaction Quality using HMMs and Conditioned HMMs (.", "labels": [], "entities": []}, {"text": "In this contribution, we investigate an approach for recognizing the dialogue quality using a hybrid Markovian model.", "labels": [], "entities": []}, {"text": "Here, hybrid means combining statistical approaches such as Support Vector Machines with Hidden Markov Models by modeling the observation probability of the HMMs using classification.", "labels": [], "entities": []}, {"text": "While this is the first time hybrid approaches are used for estimating Interaction Quality, they are well-known and have been used before for other classification tasks (e.g. ().", "labels": [], "entities": [{"text": "estimating Interaction Quality", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.7540215055147806}]}, {"text": "This paper is outlined as follows: Related work on subjective quality measurement on the ex-change level is presented in Section 2.", "labels": [], "entities": []}, {"text": "All experiments in this work are based on the Interaction Quality metric of the LEGO corpus described in Section 3.", "labels": [], "entities": [{"text": "LEGO corpus", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.8842031955718994}]}, {"text": "We motivate for introducing time dependency and present our own approach on recognizing Interaction Quality using a Markovian model presented in Section 4 and briefly present the classification algorithms used for the experiments in Section 5.", "labels": [], "entities": [{"text": "Interaction Quality", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7885837852954865}]}, {"text": "Experiments are presented in Section 6 and their results discussion in Section 7.", "labels": [], "entities": [{"text": "Section", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.8982904553413391}]}], "datasetContent": [{"text": "All experiments are conducted using 6-fold crossvalidation . This includes the baseline approach (also producing the observation probabilities of the Hybrid-HMM approach) and the evaluation of the Hybrid-HMM.", "labels": [], "entities": []}, {"text": "For the latter, two phases of cross-validation were applied.", "labels": [], "entities": []}, {"text": "Interaction Quality estimation is done by using three commonly used evaluation metrics: Unweighted Average Recall (UAR),.", "labels": [], "entities": [{"text": "Interaction Quality estimation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.883246103922526}, {"text": "Unweighted Average Recall (UAR)", "start_pos": 88, "end_pos": 119, "type": "METRIC", "confidence": 0.9693781832853953}]}, {"text": "These are also selected as the same metrics have been used in as well.", "labels": [], "entities": []}, {"text": "Recall in general is defined as the rate of correctly classified samples belonging to one class.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.901323676109314}]}, {"text": "The recall in UAR for multi-class classification problems with N classes recall i is computed for each class i and then averaged overall class-wise recalls: Cohen's Kappa measures the relative agreement between two corresponding sets of ratings.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9988106489181519}]}, {"text": "In our case, we compute the number of label agreements corrected by the chance level of agreement divided by the maximum proportion of times the labelers could agree.", "labels": [], "entities": []}, {"text": "However, Cohen's weighted Kappa is applied as ordinal scores are compared.", "labels": [], "entities": []}, {"text": "A weighting factor w is introduced reducing the discount of disagreements the smaller the difference is between two ratings: Here, r 1 and r 2 denote the rating pair and r max and r min the maximum and minimum ratings possible.", "labels": [], "entities": [{"text": "discount", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9620341658592224}]}, {"text": "Correlation between two variables describes the degree by which one variable can be expressed by the other.", "labels": [], "entities": []}, {"text": "Spearman's Rho is a non-parametric method assuming a monotonic function between the two variables (Spearman, 1904).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for IQ recognition of the statis- tical classifiers: UAR, \u03ba and \u03c1 for linear SVM,  Bayes classification and Rule Induction. \u03c3 2 repre- sents the variances of the confidence scores.", "labels": [], "entities": [{"text": "IQ recognition", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.9793828427791595}, {"text": "UAR", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9956513047218323}]}, {"text": " Table 2: Results for the Hybrid-HMM approach:  UAR, \u03ba and \u03c1 for the action-independent (AI) and  action-dependent (AD) versions.", "labels": [], "entities": [{"text": "UAR", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9985707998275757}]}, {"text": " Table 3: Results of Hybrid-HMM with hand- crafted transition matrix of the action-independent  version.", "labels": [], "entities": []}, {"text": " Table 4: Handcrafted transition matrix based on  empirical data.", "labels": [], "entities": []}]}