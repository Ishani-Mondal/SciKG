{"title": [{"text": "WN-Toolkit: Automatic generation of WordNets following the expand model", "labels": [], "entities": [{"text": "WN-Toolkit", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.7699880599975586}]}], "abstractContent": [{"text": "This paper presents a set of methodolo-gies and algorithms to create WordNets following the expand model.", "labels": [], "entities": []}, {"text": "We explore dictionary and BabelNet based strategies, as well as methodologies based on the use of parallel corpora.", "labels": [], "entities": []}, {"text": "Evaluation results for six languages are presented: Catalan, Spanish, French, German, Italian and Por-tuguese.", "labels": [], "entities": [{"text": "Por-tuguese", "start_pos": 98, "end_pos": 109, "type": "DATASET", "confidence": 0.8415315747261047}]}, {"text": "Along with the methodologies and evaluation we present an implementation of all the algorithms grouped in a set of programs or toolkit.", "labels": [], "entities": []}, {"text": "These programs have been successfully used in the Know2 Project for the creation of Catalan and Spanish WordNet 3.0.", "labels": [], "entities": []}, {"text": "The toolkit is published under the GNU-GPL license and can be freely downloaded from http: //lpg.uoc.edu/wn-toolkit.", "labels": [], "entities": []}], "introductionContent": [{"text": "The WN-Toolkit implements a simple word alignment algorithm useful for the creation of WordNets from parallel corpora.", "labels": [], "entities": [{"text": "WN-Toolkit", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8460268974304199}, {"text": "word alignment", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7613421678543091}]}, {"text": "The program, called synset-word-alignement.py, calculates the most frequent translation found in the corpus for each synset.", "labels": [], "entities": []}, {"text": "We must bear in mind that the parallel corpus must be tagged with PWN synsets in the English part.", "labels": [], "entities": []}, {"text": "The target corpus must be lemmatized and tagged with very simple tags (n for nouns; v for verbs; a for adjectives; r for adverbs and any other letter for other pos).", "labels": [], "entities": []}, {"text": "The synset-word-alignment program uses two parameters to tune its behaviour: \u2022 The i parameter forces the first translation equivalent to have a frequency at least i times greater than the frequency of the second candidate.", "labels": [], "entities": []}, {"text": "If this condition is not achieved, the translation candidate is rejected and the program fails to give a target variant for the given synset.", "labels": [], "entities": []}, {"text": "\u2022 The f parameter is the greater value for the ratio between the frequency of the translation candidate in the target part of the parallel corpus and the frequency of the synset in the source part of the parallel corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments we have used two strategies for the creation of the parallel corpus with sense tags in the English part.", "labels": [], "entities": []}, {"text": "\u2022 Machine translation of sense-tagged corpora.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.6513746082782745}]}, {"text": "We have used two corpora: Semcor and Princeton WordNet Gloss Corpus.", "labels": [], "entities": [{"text": "Princeton WordNet Gloss Corpus", "start_pos": 37, "end_pos": 67, "type": "DATASET", "confidence": 0.8994150161743164}]}, {"text": "We have used Google Translate to machine translate these corpora to Catalan, Spanish, French, German, Italian and Portuguese.", "labels": [], "entities": []}, {"text": "\u2022 Automatic sense tagging of parallel corpora, using two WSD techniques: (i) WSD using multilingual information and (ii) Freeling + UKB.", "labels": [], "entities": [{"text": "Automatic sense tagging of parallel corpora", "start_pos": 2, "end_pos": 45, "type": "TASK", "confidence": 0.7472926725943884}, {"text": "UKB", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.5166586637496948}]}, {"text": "We have used a 118K sentences fragment of the DGT-TM multilingual corpus (available in English, Spanish, French, German, Italian and Portuguese, but not in Catalan).", "labels": [], "entities": [{"text": "DGT-TM multilingual corpus", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.8713014523188273}]}, {"text": "We have chosen this number of sentences to have a corpus of a similar size to the Princeton WordNet Gloss Corpus For our experiments we have set the parameter i to 2.5 and the parameter f to 5.", "labels": [], "entities": [{"text": "Princeton WordNet Gloss Corpus", "start_pos": 82, "end_pos": 112, "type": "DATASET", "confidence": 0.9050468504428864}]}, {"text": "In and 12 we can seethe results for the use of machine translation of Semcor an PWGC.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.6752419471740723}, {"text": "PWGC", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.5048258900642395}]}, {"text": "As we can see, the precision figures are very similar for both corpora, but the number of extracted variants is greater for the PWGC, due to the larger size of the corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9994713664054871}, {"text": "PWGC", "start_pos": 128, "end_pos": 132, "type": "DATASET", "confidence": 0.9422128796577454}]}, {"text": "We have manually evaluated 20% of the results for Catalan.", "labels": [], "entities": []}, {"text": "In the case of Semcor we have calculated a corrected value of 94.74%, whereas for PWGC corpus we have obtained a corrected value of 96.18%.", "labels": [], "entities": [{"text": "Semcor", "start_pos": 15, "end_pos": 21, "type": "DATASET", "confidence": 0.9383187294006348}, {"text": "corrected value", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.9789900779724121}, {"text": "PWGC corpus", "start_pos": 82, "end_pos": 93, "type": "DATASET", "confidence": 0.9765081405639648}, {"text": "corrected value", "start_pos": 113, "end_pos": 128, "type": "METRIC", "confidence": 0.9736161231994629}]}, {"text": "In and 14 we can seethe results for the use of automatic sense tagging for the DGT-TM corpus using a multilingual strategy and Freeling+UKB.", "labels": [], "entities": [{"text": "DGT-TM corpus", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9586279094219208}, {"text": "Freeling+UKB", "start_pos": 127, "end_pos": 139, "type": "DATASET", "confidence": 0.8310235341389974}]}, {"text": "Here the precision figures are also similar for both strategies, but the number of extracted variants is greater for the Freeling+UKB strategy.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.999656081199646}, {"text": "Freeling+UKB", "start_pos": 121, "end_pos": 133, "type": "DATASET", "confidence": 0.852277139822642}]}, {"text": "The reason is that using Freeling and UKB we can disambiguate all the ambiguous words, while using the multilingual strategy we are notable to disambiguate all of them and in some cases some degree of ambiguity remains.", "labels": [], "entities": [{"text": "Freeling", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.9484879970550537}, {"text": "UKB", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.8734931349754333}]}, {"text": "For the extraction process we have only considered the fully disambiguated words.", "labels": [], "entities": []}, {"text": "If we analyse the results, we see that the extraction task has a much higher precision than the Word Sense Disambiguation strategies used to process the corpora.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9978837370872498}, {"text": "Word Sense Disambiguation", "start_pos": 96, "end_pos": 121, "type": "TASK", "confidence": 0.7069560686747233}]}, {"text": "This may seem a little odd but we must bear in mind that we have used very restrictive values for the parameters i and f of the extraction program.", "labels": [], "entities": []}, {"text": "These parameters allow us to extract only the best candidates, ensuring a good precision value for the extraction process, but a very poor recall value.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9978345036506653}, {"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9987961053848267}]}, {"text": "It should be noted than for Spanish with the machine translation strategy we are getting 2,076 candidatesfor the Semcor Corpus and 4,959 for the Princeton Gloss Corpus, and we are now getting 313 candidates for the multilingual WSD strategy and 1,155 for the UKB WSD.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7077750116586685}, {"text": "Semcor Corpus", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.9391636550426483}, {"text": "Princeton Gloss Corpus", "start_pos": 145, "end_pos": 167, "type": "DATASET", "confidence": 0.9718754490216573}, {"text": "UKB WSD", "start_pos": 259, "end_pos": 266, "type": "DATASET", "confidence": 0.9675483703613281}]}, {"text": "If we force the extraction process to get 2,076 candidates, we obtain a precision value of 43.77% for the multilingual WSD strategy and 58.12% for UKB.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9996122717857361}, {"text": "WSD", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.7018104195594788}, {"text": "UKB", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.969723641872406}]}], "tableCaptions": [{"text": " Table 1: Size of the WordNets", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9835403561592102}, {"text": "WordNets", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.7549179196357727}]}, {"text": " Table 2: Degree of polysemy in PWN 3.0", "labels": [], "entities": [{"text": "Degree", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9953627586364746}, {"text": "PWN 3.0", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.8740505278110504}]}, {"text": " Table 3: Number of monosemic variants with the  first letter in uppercase or lowercase", "labels": [], "entities": []}, {"text": " Table 4: Precision figures of the Freeling's implementation of UKB algorithm for four English Corpora", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9854024648666382}, {"text": "UKB algorithm", "start_pos": 64, "end_pos": 77, "type": "DATASET", "confidence": 0.8460292220115662}]}, {"text": " Table 5: Size of the dictionaries", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9593022465705872}]}, {"text": " Table 6: Evaluation of the dictionary based strat- egy using Wiktionary", "labels": [], "entities": [{"text": "Wiktionary", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.6111559867858887}]}, {"text": " Table 7: Evaluation of the dictionary based strat- egy using Wikipedia", "labels": [], "entities": []}, {"text": " Table 8: Evaluation of the Babelnet-based strategy", "labels": [], "entities": []}, {"text": " Table 9: Evaluation of the Babelnet-based strategy  with Wikipedia dictionary", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 58, "end_pos": 67, "type": "DATASET", "confidence": 0.9529380798339844}]}, {"text": " Table 10: Evaluation of the Babelnet-based strat- egy using Babelnet 2.0", "labels": [], "entities": []}, {"text": " Table 11: Evaluation of the parallel corpus based  strategy: machine translation of Semcor corpus", "labels": [], "entities": [{"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7366234958171844}, {"text": "Semcor corpus", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.8122189044952393}]}, {"text": " Table 12: Evaluation of the parallel corpus based  strategy: machine translation of PWGC corpus", "labels": [], "entities": [{"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7259745597839355}, {"text": "PWGC corpus", "start_pos": 85, "end_pos": 96, "type": "DATASET", "confidence": 0.7758808732032776}]}, {"text": " Table 13: Multilingual WSD of 118K sentences  fragment of the DGT-TM corpus", "labels": [], "entities": [{"text": "DGT-TM corpus", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.9390046000480652}]}, {"text": " Table 14: Freeling + UKB of 118K sentences frag- ment of the DGT-TM corpus", "labels": [], "entities": [{"text": "Freeling", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.7660139203071594}, {"text": "UKB", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.5537428855895996}, {"text": "DGT-TM", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9702553153038025}]}, {"text": " Table  15. Here we have mixed the results for extended  dictionary, Babelnet, translated PWGC and trans- lated Semcor. The overall precision is 71.06% but,  if we take into account the variants extracted using  2 or more methodologies, this precision rises up to  91.35%, although the number of extracted variants  is drastically reduced.", "labels": [], "entities": [{"text": "PWGC", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.8529450297355652}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9982513785362244}, {"text": "precision", "start_pos": 242, "end_pos": 251, "type": "METRIC", "confidence": 0.9872127175331116}]}, {"text": " Table 15: Evaluation of the repetition of the results  for different strategies for Catalan", "labels": [], "entities": [{"text": "repetition", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9527238011360168}]}, {"text": " Table 16: Comparison of automatic and corrected  precision figures", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.8612906336784363}]}]}