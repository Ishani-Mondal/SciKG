{"title": [{"text": "CMUQ@QALB-2014: An SMT-based System for Automatic Arabic Error Correction", "labels": [], "entities": [{"text": "CMUQ@QALB-2014", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.8259828488032023}, {"text": "SMT-based", "start_pos": 19, "end_pos": 28, "type": "TASK", "confidence": 0.977042019367218}, {"text": "Automatic Arabic Error Correction", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.6465517431497574}]}], "abstractContent": [{"text": "In this paper, we describe the CMUQ system we submitted to The ANLP-QALB 2014 Shared Task on Automatic Text Correction for Arabic.", "labels": [], "entities": [{"text": "ANLP-QALB 2014 Shared Task on Automatic Text Correction for Arabic", "start_pos": 63, "end_pos": 129, "type": "TASK", "confidence": 0.7577180445194245}]}, {"text": "Our system combines rule-based linguistic techniques with statistical language modeling techniques and machine translation-based methods.", "labels": [], "entities": [{"text": "statistical language modeling", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.7205959558486938}]}, {"text": "Our system outperforms the baseline and reaches an F-score of 65.42% on the test set of QALB corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9993975162506104}, {"text": "QALB corpus", "start_pos": 88, "end_pos": 99, "type": "DATASET", "confidence": 0.8579385578632355}]}, {"text": "This ranks us 3rd in the competition.", "labels": [], "entities": []}], "introductionContent": [{"text": "The business of text creation and editing represents a large market where NLP technologies might be applied naturally).", "labels": [], "entities": [{"text": "text creation and editing", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.8786793500185013}]}, {"text": "Today's users of word processors get surprisingly little help in checking spelling, and a small number of them use more sophisticated tools such as grammar checkers, to provide help in ensuring that a text remains grammatically accurate after modification.", "labels": [], "entities": []}, {"text": "For instance, in the Arabic version of Microsoft Word, the spelling checker for Arabic, does not give reasonable and natural proposals for many realword errors and even for simple probable errors.", "labels": [], "entities": []}, {"text": "With the increased usage of computers in the processing of natural languages comes the need for correcting errors introduced at different stages.", "labels": [], "entities": []}, {"text": "Natural language errors are not only made by human operators at the input stage but also by NLP systems that produce natural language output.", "labels": [], "entities": []}, {"text": "Machine translation (MT), or optical character recognition (OCR), often produce incorrect output riddled with odd lexical choices, grammar errors, or incorrectly recognized characters.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8855586409568786}, {"text": "optical character recognition (OCR)", "start_pos": 29, "end_pos": 64, "type": "TASK", "confidence": 0.8092224697271982}]}, {"text": "Correcting human/machine-produced errors, or post-editing, can be manual or automated.", "labels": [], "entities": []}, {"text": "For morphologically and syntactically complex languages, such as Modern Standard Arabic (MSA), correcting texts automatically requires complex human and machine processing which makes generation of correct candidates a challenging task.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 65, "end_pos": 93, "type": "DATASET", "confidence": 0.788499097029368}, {"text": "correcting texts", "start_pos": 95, "end_pos": 111, "type": "TASK", "confidence": 0.9060038924217224}]}, {"text": "For instance, the Automatic Arabic Text Correction Shared Task is an interesting testbed to develop and evaluate spelling correction systems for Arabic trained either on naturally occurring errors in texts written by humans (e.g., non-native speakers), or machines (e.g., MT output).", "labels": [], "entities": [{"text": "Automatic Arabic Text Correction Shared Task", "start_pos": 18, "end_pos": 62, "type": "TASK", "confidence": 0.6535009344418844}, {"text": "spelling correction", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.7881779372692108}]}, {"text": "In such tasks, participants are asked to implement a system that takes as input Modern Standard Arabic texts with various spelling errors and automatically correct them.", "labels": [], "entities": []}, {"text": "In this paper, we describe the CMUQ system we developed to participate in the The First Shared Task on Automatic Text Correction for Arabic ).", "labels": [], "entities": []}, {"text": "Our system combines rule-based linguistic techniques with statistical language modeling techniques and machine translationbased methods.", "labels": [], "entities": [{"text": "statistical language modeling", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.719193677107493}]}, {"text": "Our system outperforms the baseline, achieves a better correction quality and reaches an Fscore of 62.96% on the development set of QALB corpus ( ) and 65.42% on the test set.", "labels": [], "entities": [{"text": "correction quality", "start_pos": 55, "end_pos": 73, "type": "METRIC", "confidence": 0.9523183405399323}, {"text": "Fscore", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9997575879096985}, {"text": "QALB corpus", "start_pos": 132, "end_pos": 143, "type": "DATASET", "confidence": 0.8157735764980316}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we review the main previous efforts for automatic spelling correction, in Section 2.", "labels": [], "entities": [{"text": "automatic spelling correction", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.6515780886014303}]}, {"text": "In Section 3, we describe our system, which consists of several modules.", "labels": [], "entities": []}, {"text": "We continue with our experiments on the shared task 2014 dev set (Section 4).", "labels": [], "entities": [{"text": "shared task 2014 dev set", "start_pos": 40, "end_pos": 64, "type": "DATASET", "confidence": 0.668212765455246}]}, {"text": "Then, we give an analysis of our system output in Section 5.", "labels": [], "entities": []}, {"text": "Finally, we conclude and hint towards future improvement of the system, in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train and evaluate our system with the training and development datasets provided for the shared task and the m2Scorer).", "labels": [], "entities": []}, {"text": "These datasets are extracted from the QALB corpus of human-edited Arabic text produced by native speakers, non-native speakers and machines ).", "labels": [], "entities": [{"text": "QALB corpus of human-edited Arabic text", "start_pos": 38, "end_pos": 77, "type": "DATASET", "confidence": 0.9189009666442871}]}, {"text": "We conducted a small scale statistical study on the 950K tokens training set used to build our system.", "labels": [], "entities": [{"text": "950K tokens training set", "start_pos": 52, "end_pos": 76, "type": "DATASET", "confidence": 0.6899349018931389}]}, {"text": "We realized that 306K tokens are affected by a correction action which could be a word edit, insertion, deletion, split or merge.", "labels": [], "entities": []}, {"text": "169K tokens were edited to correct the spelling errors and 99K tokens were inserted (mostly punctuation marks).", "labels": [], "entities": []}, {"text": "Furthermore, there is a total of 6,7K non necessary tokens deleted and 10.6K attached tokens split and 18.2 tokens merged.", "labels": [], "entities": []}, {"text": "Finally, there are only 427 tokens moved in the sentence and 1563 multiple correction action.", "labels": [], "entities": []}, {"text": "We experiment with different configurations and reach the sweet spot of performance when combining the different modules.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: System results on the dev set (upper part) and on the test set (lower part).", "labels": [], "entities": []}]}