{"title": [{"text": "An Open Corpus of Everyday Documents for Simplification Tasks", "labels": [], "entities": [{"text": "Simplification Tasks", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.8841677904129028}]}], "abstractContent": [], "introductionContent": [{"text": "People constantly interact with texts in everyday life.", "labels": [], "entities": []}, {"text": "While many people read for enjoyment, some texts must be readout of necessity.", "labels": [], "entities": []}, {"text": "For example, to file taxes, open a bank account, apply fora driver's license or rent a house, one must read instructions and the contents of forms, applications, and other documents.", "labels": [], "entities": []}, {"text": "For people with limited reading ability -whether because they are not native speakers of the language, have an incomplete education, have a disability, or for some other reason -the reading level of these everyday documents can limit accessibility and affect their well-being.", "labels": [], "entities": []}, {"text": "The need to present people with texts that are at a reading level which is suitable for them has motivated research into measuring readability of any given text in order to assess whether automatic simplification has rendered a more difficult text into a more readable one.", "labels": [], "entities": []}, {"text": "Readability can be measured using tools which assess the reading level of a text.", "labels": [], "entities": []}, {"text": "We define simplification as the process of changing a text to lower its reading level without removing necessary information or producing an ungrammatical result.", "labels": [], "entities": []}, {"text": "This is similar to the definition of (cf. (), except that we avoid defining a specific, limited, set of simplification operations.", "labels": [], "entities": []}, {"text": "The Related Work section details research into measures of readability and work on automatic simplification systems.", "labels": [], "entities": []}, {"text": "We have begun to construct a large, accessible corpus of everyday documents.", "labels": [], "entities": []}, {"text": "This corpus will eventually contain thousands of these documents, each having statistics characterising its contents, and multiple readability measures.", "labels": [], "entities": []}, {"text": "Multiple different simplifications will be collected for the original documents and their content statistics and readability measures will be included in the corpus.", "labels": [], "entities": []}, {"text": "This type of large and accessible corpus is of vital importance in driving development of automated text simplification.", "labels": [], "entities": [{"text": "automated text simplification", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.6144420802593231}]}, {"text": "It will provide training material for the systems as well as a common basis of evaluating results from different systems.", "labels": [], "entities": []}, {"text": "Thus far, we have collected a basic corpus of everyday documents from a wide variety of sources.", "labels": [], "entities": []}, {"text": "We plan to extend this basic corpus to create the much larger and more structured corpus that we describe here.", "labels": [], "entities": []}, {"text": "We have also carried out a preliminary study to evaluate the feasibility of using crowdsourcing as one source of simplifications in the extended corpus.", "labels": [], "entities": []}, {"text": "We have used Amazon Mechanical Turk (AMT) and collected 10 simplifications each for 200 sentences from the basic cor-pus to determine feasibility, a good experimental design, quality control of the simplifications, and time and cost effectiveness.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 13, "end_pos": 41, "type": "DATASET", "confidence": 0.9039604564507803}]}, {"text": "In the next section we discuss related work relevant to creating and evaluating a large corpus of everyday documents and their simplifications.", "labels": [], "entities": []}, {"text": "In Section 3 we further demonstrate the need fora corpus of everyday documents.", "labels": [], "entities": []}, {"text": "Section 4 presents a description of our existing basic corpus.", "labels": [], "entities": []}, {"text": "Section 5 describes the details of the extended corpus and presents our evaluation of the feasibility of using crowdsourcing to generate human simplifications for the corpus.", "labels": [], "entities": []}, {"text": "Section 6 shows how the extended corpus will be made accessible.", "labels": [], "entities": []}, {"text": "Section 7 concludes and outlines the future work that we will undertake to develop the extended corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "Measures of readability are important because they help us assess the reading level of any document, provide a target for simplification systems, and help evaluate and compare the performance of different simplification systems.", "labels": [], "entities": []}, {"text": "Several measures of readability have been proposed; DuBay (2004) counted 200 such measures developed by the 1980s and the number has grown, with more advanced automated measures introduced since then.", "labels": [], "entities": []}, {"text": "Early measures of readability such as the Flesch-Kincaid grade level formula () use counts of surface features of the text such as number of words and number of sentences.", "labels": [], "entities": []}, {"text": "While these older measures are less sophisticated than more modern reading level classifiers, they are still widely used and reported and recent work has shown that they can be a good first approximation of more complex measures.", "labels": [], "entities": []}, {"text": "More recent approaches use more complicated features and machine learning techniques to learn classifiers that can predict readability.", "labels": [], "entities": []}, {"text": "For example, combine a naive Bayes classifier that uses a vocabulary-based language model with a k-Nearest Neighbors classifier using grammatical features and interpolate the two to predict reading grade level. and examine a large number of possible textual features at various levels and compare SVM and Linear Regression classifiers to predict grade level.", "labels": [], "entities": []}, {"text": "reported significantly higher accuracy on a similar task using Multi-level Perceptron classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9994925260543823}, {"text": "Multi-level Perceptron classification", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.4688531657059987}]}, {"text": "The above two methods of measuring readability can be computed directly using the text of a document itself.", "labels": [], "entities": []}, {"text": "To evaluate the performance of a simplification system which aims to make texts easier to read and understand, it is also useful to measure improvement in individuals' reading and comprehension of the texts.", "labels": [], "entities": []}, {"text": "recently studied sentence recall to test comprehension; and Temnikova and Maneva (2013) evaluated simplifications using the readers' ability to answer multiple choice questions about the text.", "labels": [], "entities": [{"text": "sentence recall", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.6405439078807831}]}], "tableCaptions": [{"text": " Table 1. The documents are split so that each sen- tence is on a separate line to enable easy align- ments between the original and simplified versions  of the documents.", "labels": [], "entities": []}, {"text": " Table 1: Example basic corpus entry for Alabama  Driver Manual", "labels": [], "entities": [{"text": "Alabama  Driver Manual", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.949519157409668}]}, {"text": " Table 2: Corpus statistics by lexical reading level", "labels": [], "entities": []}, {"text": " Table 3: Corpus statistics for the basic corpus documents", "labels": [], "entities": []}, {"text": " Table 5: Training statistics for workers who com- pleted training", "labels": [], "entities": []}, {"text": " Table 6: Training statistics for workers who did not  complete training", "labels": [], "entities": []}, {"text": " Table 7: Self-assessed worker confidences in their  simplifications", "labels": [], "entities": [{"text": "simplifications", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.8259958028793335}]}, {"text": " Table 8: Number of outlier simplifications with  similarity ratio above the threshold for at most one  other simplification", "labels": [], "entities": [{"text": "similarity ratio", "start_pos": 50, "end_pos": 66, "type": "METRIC", "confidence": 0.985081672668457}]}, {"text": " Table 9: Manual evaluation of 1000 AMT simplifications. Numbers of simplifications with each feature.", "labels": [], "entities": [{"text": "AMT simplifications", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8869326412677765}]}]}