{"title": [{"text": "Addressing Class Imbalance for Improved Recognition of Implicit Discourse Relations", "labels": [], "entities": [{"text": "Addressing Class Imbalance", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8561016718546549}, {"text": "Improved Recognition of Implicit Discourse", "start_pos": 31, "end_pos": 73, "type": "TASK", "confidence": 0.863991129398346}]}], "abstractContent": [{"text": "In this paper we address the problem of skewed class distribution in implicit discourse relation recognition.", "labels": [], "entities": [{"text": "implicit discourse relation recognition", "start_pos": 69, "end_pos": 108, "type": "TASK", "confidence": 0.5935186743736267}]}, {"text": "We examine the performance of classifiers for both binary classification predicting if a particular relation holds or not and for multi-class prediction.", "labels": [], "entities": [{"text": "binary classification predicting", "start_pos": 51, "end_pos": 83, "type": "TASK", "confidence": 0.771820068359375}, {"text": "multi-class prediction", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.7377130091190338}]}, {"text": "We review prior work to point out that the problem has been addressed differently for the binary and multi-class problems.", "labels": [], "entities": []}, {"text": "We demonstrate that adopting a unified approach can significantly improve the performance of multi-class prediction.", "labels": [], "entities": [{"text": "multi-class prediction", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.7605081796646118}]}, {"text": "We also propose an approach that makes better use of the full annotations in the training set when downsampling is used.", "labels": [], "entities": []}, {"text": "We report significant absolute improvements in performance in multi-class prediction, as well as significant improvement of binary classifiers for detecting the presence of implicit Temporal, Comparison and Contingency relations.", "labels": [], "entities": [{"text": "multi-class prediction", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.8332439959049225}]}], "introductionContent": [{"text": "Discourse relations holding between adjacent sentences in text play an essential role in establishing local coherence and contribute to the semantic interpretation of the text.", "labels": [], "entities": []}, {"text": "For example, the causal relationship is helpful for textual entailment or question answering while restatement and exemplification are important for automatic summarization.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7404224574565887}, {"text": "question answering", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7812815010547638}, {"text": "summarization", "start_pos": 159, "end_pos": 172, "type": "TASK", "confidence": 0.9098047614097595}]}, {"text": "Predicting the type of implicit relations, which are not signaled by any of the common explicit discourse connectives such as because, however, has proven to be a most challenging task in discourse analysis.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.7183687090873718}]}, {"text": "The Penn Discourse Treebank (PDTB) () provided valuable annotations of implicit relations.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB)", "start_pos": 4, "end_pos": 34, "type": "DATASET", "confidence": 0.9663767019907633}]}, {"text": "Most research to date has focused on developing and refining lexical and linguistically rich features for the task.", "labels": [], "entities": []}, {"text": "Mostly ignored remains the problem of addressing the highly skewed distribution of implicit discourse relations.", "labels": [], "entities": []}, {"text": "Only about 35% of pairs of adjacent sentences in the PDTB are connected by three of the four top level discourse relation: 5% participate in Temporal relation, 10% in Comparison (contrast) and 20% in Contingency (causal) relations.", "labels": [], "entities": []}, {"text": "The remaining pairs are connected by the catch-all Expansion relation (40%) or by some other linguistic devices (24%).", "labels": [], "entities": [{"text": "catch-all Expansion relation", "start_pos": 41, "end_pos": 69, "type": "METRIC", "confidence": 0.8299626509348551}]}, {"text": "Finer grained relations of interest to particular applications account for increasingly smaller percentage of the PDTB data.", "labels": [], "entities": [{"text": "PDTB data", "start_pos": 114, "end_pos": 123, "type": "DATASET", "confidence": 0.9022059440612793}]}, {"text": "Class imbalance is particularly problematic for training a binary classifier to distinguish one relation from the rest.", "labels": [], "entities": []}, {"text": "As we will show later, it also impacts the performance of multi-class prediction in which each pair of sentences is labeled with one of the five possible relations.", "labels": [], "entities": [{"text": "multi-class prediction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.7084975838661194}]}, {"text": "All prior work has resorted to downsampling the training data for binary classifiers to distinguish a particular relation and use the full training set for multi-class prediction.", "labels": [], "entities": [{"text": "multi-class prediction", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.753597766160965}]}, {"text": "In this paper we compare several methods for addressing the skewed class distribution during training: downsampling, upsampling and computing feature weights and performing feature selection on the unaltered full training data.", "labels": [], "entities": []}, {"text": "A major motivation for our work is to establish if any of the alternatives to downsampling would prove beneficial, because in downsampling most of the expensively annotated data is not used in the model.", "labels": [], "entities": []}, {"text": "In addition, we seek to align the treatment of data imbalance for the binary and multi-class tasks.", "labels": [], "entities": []}, {"text": "We show that downsampling in general leads to the best prediction accuracy but that the alternative models provide complementary information and significant improvement can be obtained by combining both types of models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.94630366563797}]}, {"text": "We also report significant improvement of multi-class prediction accuracy, achieved by using the alternative binary classifiers to perform the task.", "labels": [], "entities": [{"text": "multi-class prediction", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7070601284503937}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9439718723297119}]}], "datasetContent": [{"text": "In our experiments, we used all non-explicit instances in the PDTB sections 2-19 for training and those in sections 20-24 for testing.", "labels": [], "entities": [{"text": "PDTB sections 2-19", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.931406577428182}]}, {"text": "Like most studies, we kept sections 0-1 as development set.", "labels": [], "entities": []}, {"text": "In order to ensure we have a large enough test set to properly perform tests for statistical significance over F scores and balanced accuracies, we did not follow previous work () that used only section 23 or sections 23-24 for testing.", "labels": [], "entities": []}, {"text": "Also, the traditional rule of thumb is to split the available data into training The rest of the data are EntRel/NoRel.", "labels": [], "entities": [{"text": "NoRel", "start_pos": 113, "end_pos": 118, "type": "DATASET", "confidence": 0.6999356746673584}]}], "tableCaptions": [{"text": " Table 1: Distribution of implicit relations in the  PDTB.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.8876427412033081}]}, {"text": " Table 5: Balanced accuracy for multiway  SVM and one-against-all for 5-way classification.", "labels": [], "entities": [{"text": "Balanced", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9939484596252441}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9566459059715271}, {"text": "SVM", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.7077042460441589}, {"text": "5-way classification", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.5898030698299408}]}, {"text": " Table 6: F score (precision/recall) of classifiers with feature augmentation. Asterisk(*) means F score or  BAC is significantly greater than plain downsampling at p < 0.05.", "labels": [], "entities": [{"text": "F score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9869410693645477}, {"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9002858400344849}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.7769966125488281}, {"text": "Asterisk", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9922119379043579}, {"text": "F score", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9908095896244049}, {"text": "BAC", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.9264169335365295}]}, {"text": " Table 7: Q statistics and agreements (in percent- ages) of each downsampling system vs. weighted  cost. \"D\" denotes the respective downsample sys- tem in the left most column; \"C\" denotes the  weighted cost system. A \"+\" means that a system  makes a correct prediction; a \"-\" means a system  makes an incorrect prediction.", "labels": [], "entities": []}]}