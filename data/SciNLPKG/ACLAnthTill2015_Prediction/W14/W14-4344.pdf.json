{"title": [{"text": "Markovian Discriminative Modeling for Dialog State Tracking", "labels": [], "entities": [{"text": "Dialog State Tracking", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8517518639564514}]}], "abstractContent": [{"text": "Discriminative dialog state tracking has become a hot topic in dialog research community recently.", "labels": [], "entities": [{"text": "Discriminative dialog state tracking", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.785670131444931}]}, {"text": "Compared to genera-tive approach, it has the advantage of being able to handle arbitrary dependent features , which is very appealing.", "labels": [], "entities": []}, {"text": "In this paper, we present our approach to the DSTC2 challenge.", "labels": [], "entities": [{"text": "DSTC2 challenge", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.8155779242515564}]}, {"text": "We propose to use dis-criminative Markovian models as a natural enhancement to the stationary discrim-inative models.", "labels": [], "entities": []}, {"text": "The Markovian structure allows the incorporation of 'transitional' features, which can lead to more efficiency and flexibility in tracking user goal changes.", "labels": [], "entities": []}, {"text": "Results on the DSTC2 dataset show considerable improvements over the baseline, and the effects of the Markovian dependency is tested empirically.", "labels": [], "entities": [{"text": "DSTC2 dataset", "start_pos": 15, "end_pos": 28, "type": "DATASET", "confidence": 0.9892348349094391}]}], "introductionContent": [{"text": "Spoken dialog systems (SDS) have become much more popular these days, but still far from wide adoption.", "labels": [], "entities": [{"text": "Spoken dialog systems (SDS)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7091766993204752}]}, {"text": "One of the most outstanding problems that affect user experience in an SDS is due to automatic speech recognition (ASR) and spoken language understanding (SLU) errors.", "labels": [], "entities": [{"text": "SDS", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9619603753089905}, {"text": "automatic speech recognition (ASR)", "start_pos": 85, "end_pos": 119, "type": "TASK", "confidence": 0.7313710451126099}, {"text": "spoken language understanding (SLU)", "start_pos": 124, "end_pos": 159, "type": "TASK", "confidence": 0.7536150018374125}]}, {"text": "While the advancement of ASR technology has a positive effect on SDS, it is possible to improve the SDS user experience by designing a module which explicitly handles ASR and SLU errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9614150524139404}, {"text": "SDS", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9843904376029968}]}, {"text": "With accurately estimated dialog state, the dialog manager could select more effective and flexible dialog actions, resulting in shorter dialogs and higher dialog success rate.", "labels": [], "entities": []}, {"text": "Dialog state tracking is the task of identifying the correct dialog state (user action, user goal, etc.) from ASR and SLU outputs in the presence of errors.", "labels": [], "entities": [{"text": "Dialog state tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8537352681159973}]}, {"text": "Commercial dialog systems these days usually use simple dialog state tracking strategies that only consider the most probable SLU output.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.6539929111798605}]}, {"text": "Previous research shows that several errors in dialog state tracking can be rectified by considering the full N-best results from the ASR and SLU components.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.8333969314893087}]}, {"text": "Thus it is very important to develop robust and practical dialog state tracking models.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7563365896542867}]}, {"text": "In statistical dialog state tracking, models can be roughly divided into two major classes, i.e. generative and discriminative.", "labels": [], "entities": [{"text": "statistical dialog state tracking", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.6436373069882393}]}, {"text": "Generative (Bayesian) dialog tracking models are prevalent in early studies due to its close relationship with the POMDP dialog management model ( ).", "labels": [], "entities": [{"text": "dialog tracking", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.7698473930358887}, {"text": "POMDP dialog management", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.6314171552658081}]}, {"text": "Generative models generally use Dynamic Bayesian Networks to model the observation probability P (O t |S t ) and transition probability P (S t |S t\u22121 ), where O t and St are observations and dialog state at turn t.", "labels": [], "entities": []}, {"text": "Ina discriminative model, the conditional probability P (S t |O t 1 ) is modeled directly, where O t 1 is all the observations from turn 1 tot.", "labels": [], "entities": []}, {"text": "One problem with the generative models is that the independent assumptions are always not realistic.", "labels": [], "entities": [{"text": "generative", "start_pos": 21, "end_pos": 31, "type": "TASK", "confidence": 0.965328574180603}]}, {"text": "For example, N-best hypotheses are often assumed independent of each other, which is flawed in realistic scenarios.", "labels": [], "entities": []}, {"text": "Furthermore, it is intrinsically difficult for generative models to handle overlapping features, which prevents model designers from incorporating arbitrarily large feature set.", "labels": [], "entities": []}, {"text": "Discriminative model does not suffer from the above problems as there is no need to make any assumptions about the probabilistic dependencies of the features.", "labels": [], "entities": []}, {"text": "it is potentially able to handle much larger feature sets and to make more accurate predictions ().", "labels": [], "entities": []}, {"text": "Discriminative models also tend to be more data-driven, unlike generative models in which many sub-models parameters are heuristically tuned.", "labels": [], "entities": []}], "datasetContent": [{"text": "Featured metrics on the test set are shown in table 2.", "labels": [], "entities": []}, {"text": "By most metrics our models are superior to the simple baseline.", "labels": [], "entities": []}, {"text": "Especially in tracking user goals which is the most important state to track in DSTC2, the discriminative trackers show considerable performance gain.", "labels": [], "entities": []}, {"text": "Judging from the performance of Entry1 to Entry3, we can conclude that the more complex 2-layer neural networks have better performance.", "labels": [], "entities": []}, {"text": "Markovian neural networks can fit to the training instances with much more flexibility than the simple MEMM model.", "labels": [], "entities": []}, {"text": "We have also trained a standard multi-layer neural network (MLP) model by disabling all the transitional features.", "labels": [], "entities": []}, {"text": "By comparing the model 'Entry 3' and 'MLP', which share the same network structure, we explicitly test the effect of the Markovian structure.", "labels": [], "entities": []}, {"text": "On the state 'goal' and 'requested', the Markovian model shows better tracking accu-racies, which means that the Markovian structure has a positive effect on fitting the target.", "labels": [], "entities": []}, {"text": "But in tracking the state 'method', the MLP model has the best performance among all the models compared.", "labels": [], "entities": []}, {"text": "Thus although the log-likelihood increases considerably on the training set by adding the transitional features, the overfiting to the training set is more serious in tracking 'method'.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Evaluation results on the DSTC2 test set.  ACC stands for accuracy, L2 measures the Eu- clidean distance between the predicted distribution  and the ground truth vector with only the correct  hypothesis set to 1. CA05 is the correct accep- tance rate when false acceptance rate is 5%. De- tails of the metrics can be found in (", "labels": [], "entities": [{"text": "DSTC2 test set", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.9584258000055949}, {"text": "ACC", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9605393409729004}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9995238780975342}, {"text": "accep- tance rate", "start_pos": 243, "end_pos": 260, "type": "METRIC", "confidence": 0.9562095105648041}, {"text": "De- tails", "start_pos": 295, "end_pos": 304, "type": "METRIC", "confidence": 0.8121041059494019}]}]}