{"title": [{"text": "The Effect of Sensor Errors in Situated Human-Computer Dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "Errors in perception area problem for computer systems that use sensors to perceive the environment.", "labels": [], "entities": []}, {"text": "If a computer system is engaged in dialogue with a human user, these problems in perception lead to problems in the dialogue.", "labels": [], "entities": []}, {"text": "We present two experiments, one in which participants interact through dialogue with a robot with perfect perception to fulfil a simple task, and a second one in which the robot is affected by sensor errors and compare the resulting dialogues to determine whether the sensor problems have an impact on dialogue success.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computer systems that can engage in natural language dialogue with human users are known as dialogue systems.", "labels": [], "entities": []}, {"text": "A special class of dialogue systems are situated dialogue systems, which are dialogue systems that operate in a spatial context.", "labels": [], "entities": []}, {"text": "Situated dialogue systems are an active research topic (e.g.).", "labels": [], "entities": []}, {"text": "Recently opportunities for more practical applications of situated dialogue systems have arisen due to advances in the robustness of speech recognition and the increasing proliferation of mobile computer systems such as mobile phones or augmented reality glasses.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.7582926154136658}]}, {"text": "When a dialogue system operates in a situated context, it needs the ability to perceive the environment.", "labels": [], "entities": []}, {"text": "Perception, such as computer vision, always has the potential of producing errors, such as failing to notice an objector misrecognizing an object.", "labels": [], "entities": []}, {"text": "We are interested in the effect of perception-based errors on human-computer dialogue.", "labels": [], "entities": []}, {"text": "If the human user and the system have shared view, false perception by the system will lead to a divergence between the user's understanding of the environment and the system's understanding.", "labels": [], "entities": []}, {"text": "Such misunderstandings are frequent in human-human dialogue and human speakers use different strategies to establish a shared understanding or common ground.", "labels": [], "entities": []}, {"text": "We investigated this problem in an earlier work based on a corpus of human dialogue () and are currently moving toward the same problem in human-computer dialogue.", "labels": [], "entities": []}, {"text": "The problem of misunderstandings in human-computer dialogue has previously mostly been addressed under the aspect of problems arising from problems in speech recognition or language understanding (e.g. ().", "labels": [], "entities": [{"text": "speech recognition or language understanding", "start_pos": 151, "end_pos": 195, "type": "TASK", "confidence": 0.6498078048229218}]}, {"text": "The problem of producing referring expressions when it is not certain that the other participant shares the same perception and understanding of the scene has been addressed by).", "labels": [], "entities": []}, {"text": "More recently () performed a similar experiment in the context of human-human interaction.", "labels": [], "entities": []}, {"text": "Their work was chiefly concerned with the generation of referring expressions.", "labels": [], "entities": [{"text": "generation of referring expressions", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.8426380902528763}]}, {"text": "We report on a work in progress in which we investigate the effect of sensor problems on humancomputer dialogue using a dialogue system fora simulated robot.", "labels": [], "entities": []}, {"text": "We describe two experiments we performed so far.", "labels": [], "entities": []}, {"text": "Both experiments are based on a shared experimental platform.", "labels": [], "entities": []}, {"text": "In the first experiment participants interact with a simulated robot using a text based dialogue interface to complete a series of tasks.", "labels": [], "entities": []}, {"text": "In the second experiment the participants again interact with the robot, except this time errors are introduced into the robots perception.", "labels": [], "entities": []}, {"text": "The goal of the second experiment is to investigate what effect  the presence of sensor errors has on the dialogue and the task performance and compare it to the results from the first experiment.", "labels": [], "entities": []}, {"text": "It should be emphasized that the goal of the experiments is not to evaluate the performance of the dialogue system, but to investigate the effect of perception errors on the dialogues.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were performed using an experiment system that was developed for this experiment.", "labels": [], "entities": []}, {"text": "It consists of a simulated world and a dialogue system.", "labels": [], "entities": []}, {"text": "The world contains a number of objects such as boxes and balls.", "labels": [], "entities": []}, {"text": "These object can be manipulated by an abstract simulated robot arm.", "labels": [], "entities": []}, {"text": "The dialogue system is a frame based dialogue system that uses the Stanford Parser () for parsing.", "labels": [], "entities": [{"text": "Stanford Parser ()", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.8947915633519491}]}, {"text": "The simulation environment was implement using Microsoft Robotics Studio.", "labels": [], "entities": []}, {"text": "The system is capable of understanding and performing a range of simple to complicated spatial action instructions such as \"Put the ball behind the red box\" or \"Pick up the red ball between the green box and the yellow box\".", "labels": [], "entities": []}, {"text": "The participants interact with the system through the user interface shown in.", "labels": [], "entities": []}, {"text": "It consists of two elements.", "labels": [], "entities": []}, {"text": "The simulation window shows a rendering of the simulation world that is updated in real time.", "labels": [], "entities": []}, {"text": "The interaction window provides access to a text based chat interface that the participants use to interact with the simulated robot.", "labels": [], "entities": []}, {"text": "When the participant sends a request to the system, the system analyses the input and attempts to perform it in the simulation world.", "labels": [], "entities": []}, {"text": "If it cannot perform the request, it replies through the user interface and explains its problem.", "labels": [], "entities": []}, {"text": "The robot's perception is provided by a simulated vision system.", "labels": [], "entities": []}, {"text": "In general its perception is correct, but sensor errors can be introduced.", "labels": [], "entities": []}, {"text": "For example, it can be specified that the robot perceives entire objects or some of their properties incorrectly.", "labels": [], "entities": []}, {"text": "Each run of the experiment consisted of a sequence of test scenes.", "labels": [], "entities": []}, {"text": "Each scene consisted of a start scene and a target scene.", "labels": [], "entities": []}, {"text": "The start scene determined how the objects in the simulation world were arranged at the beginning of the test scene.", "labels": [], "entities": []}, {"text": "The target scene was presented to the participants as an image in the interaction window.", "labels": [], "entities": []}, {"text": "The participants' task was to interact with the robot to recreate the target scene in the simulation world.", "labels": [], "entities": []}, {"text": "After a participant had successfully recreated the target scene, the system automatically advanced to the next scene.", "labels": [], "entities": []}, {"text": "The participants were also offered the option to abandon a scene and goon to the next one if they thought they would not be able to complete the current scene.", "labels": [], "entities": []}, {"text": "All utterances by the participant and the system are transcribed and annotated with their semantic interpretation.", "labels": [], "entities": []}, {"text": "The system also logs metrics that are used in the evaluation of dialogue systems to describe the cost of a dialogue, such as the task completion rate, the number of utterances, the completion time and the number of errors ().", "labels": [], "entities": []}, {"text": "In the following we describe two experiments we performed with this setup so far.", "labels": [], "entities": []}, {"text": "In the first experiment participants completed a series of tasks.", "labels": [], "entities": []}, {"text": "In the second experiment, participants also completed a series of tasks.", "labels": [], "entities": []}, {"text": "In this iteration however, errors were introduced into the system's perception.", "labels": [], "entities": []}, {"text": "The first experiment uses the basic version of the experiment system.", "labels": [], "entities": []}, {"text": "The purpose of the experiment was to establish how difficult the basic experiment task would be and to create a set of performance measurements that could be used to compare this version of the system to later ones.", "labels": [], "entities": []}, {"text": "The main purpose of the second experiment was to investigate how the introduction of sensor errors would influence the interactions and the outcome.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of the cost metrics for Phase 1. Few scenes were abandoned. The percentage of  unresolved references forms a baseline for the resolution performance of the system.  Scene name  Average  number of  actions per  scene", "labels": [], "entities": []}, {"text": " Table 2: Summary of the cost metrics for Phase 2. Scenes that contained no errors are highlighted in  green. Compared to Table 1, scenes that contained errors were more often abandoned, and resolution  problems were more frequent.", "labels": [], "entities": [{"text": "resolution", "start_pos": 191, "end_pos": 201, "type": "METRIC", "confidence": 0.7726799845695496}]}]}