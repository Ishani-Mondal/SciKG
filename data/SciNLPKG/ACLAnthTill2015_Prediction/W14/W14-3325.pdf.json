{"title": [{"text": "DCU-Lingo24 Participation in WMT 2014 Hindi-English Translation task", "labels": [], "entities": [{"text": "WMT 2014 Hindi-English Translation", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.8198066502809525}]}], "abstractContent": [{"text": "This paper describes the DCU-Lingo24 submission to WMT 2014 for the Hindi-English translation task.", "labels": [], "entities": [{"text": "DCU-Lingo24 submission to WMT 2014", "start_pos": 25, "end_pos": 59, "type": "DATASET", "confidence": 0.9128845930099487}, {"text": "Hindi-English translation task", "start_pos": 68, "end_pos": 98, "type": "TASK", "confidence": 0.7944207986195883}]}, {"text": "We exploit miscellaneous methods in our system, including: Context-Informed PB-SMT, OOV Word Conversion (OWC), Multi-Alignment Combination (MAC), Operation Sequence Model (OSM), Stemming Align and Normal Phrase Extraction (SANPE), and Language Model Interpolation (LMI).", "labels": [], "entities": [{"text": "Stemming Align and Normal Phrase Extraction", "start_pos": 178, "end_pos": 221, "type": "TASK", "confidence": 0.6353304733832678}]}, {"text": "We also describe various pre-processing steps we tried for Hindi in this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the DCU-Lingo24 submission to WMT 2014 for the Hindi-English translation task.", "labels": [], "entities": [{"text": "DCU-Lingo24 submission to WMT 2014", "start_pos": 25, "end_pos": 59, "type": "DATASET", "confidence": 0.9128844141960144}, {"text": "Hindi-English translation task", "start_pos": 68, "end_pos": 98, "type": "TASK", "confidence": 0.7944207986195883}]}, {"text": "All our experiments on WMT 2014 are built upon the Moses phrase-based model (PB-SMT) ( and tuned with MERT.", "labels": [], "entities": [{"text": "WMT 2014", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9104627370834351}, {"text": "MERT", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9367522597312927}]}, {"text": "Starting from this baseline system, we exploit various methods including ContextInformed PB-SMT (CIPBSMT), zero-shot learning () using neural networkbased language modelling () for OOV word conversion, various lexical reordering models;, various Multiple Alignment Combination (MAC) (, Operation Sequence Model (OSM)) and Language Model Interpolation(LMI).", "labels": [], "entities": [{"text": "OOV word conversion", "start_pos": 181, "end_pos": 200, "type": "TASK", "confidence": 0.6643059750398}]}, {"text": "In the next section, the preprocessing steps are explained.", "labels": [], "entities": []}, {"text": "In Section 3 a detailed explanation of the technique we exploit is provided.", "labels": [], "entities": []}, {"text": "Then in Section 4, we provide our experimental results and resultant discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We employed a source language (Hindi) normalisation technique, namely suffix separation, but unfortunately this did not bring about any improvement for the Hindi-to-English translation task.", "labels": [], "entities": [{"text": "source language (Hindi) normalisation", "start_pos": 14, "end_pos": 51, "type": "TASK", "confidence": 0.6919110318024954}, {"text": "suffix separation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7138492465019226}, {"text": "Hindi-to-English translation", "start_pos": 156, "end_pos": 184, "type": "TASK", "confidence": 0.6840869635343552}]}, {"text": "The improvement gained by individually employing OSM, three lexical reordering models, Multi-alignment Combination, Stem-align and normal Phrase Extraction and Language Model Interpolation can be seen in.", "labels": [], "entities": [{"text": "Phrase Extraction", "start_pos": 138, "end_pos": 155, "type": "TASK", "confidence": 0.6542334109544754}]}, {"text": "Our best system is achieved by combining OSM, Three LMR, MAC, SANPE and LMI, which results in a 1.6 BLEU point improvement over the Baseline.", "labels": [], "entities": [{"text": "SANPE", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.9523729085922241}, {"text": "LMI", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.9116393327713013}, {"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9993171691894531}]}], "tableCaptions": [{"text": " Table 1: BLEU scores of the English-to-Hindi MT  Systems on the WMT test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991313815116882}, {"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.8689262270927429}, {"text": "WMT test set", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9654015501340231}]}, {"text": " Table 2: BLEU scores of the Hindi-to-English MT  Systems on the WMT test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991625547409058}, {"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.7646098732948303}, {"text": "WMT test set", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9662982026735941}]}]}