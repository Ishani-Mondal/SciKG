{"title": [{"text": "Weblio Pre-reordering Statistical Machine Translation System", "labels": [], "entities": [{"text": "Pre-reordering Statistical Machine Translation", "start_pos": 7, "end_pos": 53, "type": "TASK", "confidence": 0.6720060855150223}]}], "abstractContent": [{"text": "This paper describes details of the We-blio Pre-reordering Statistical Machine Translation (SMT) System, participated in the English-Japanese translation task of 1st Workshop on Asian Translation (WAT2014).", "labels": [], "entities": [{"text": "Pre-reordering Statistical Machine Translation (SMT)", "start_pos": 44, "end_pos": 96, "type": "TASK", "confidence": 0.7362017376082284}, {"text": "English-Japanese translation task of 1st Workshop on Asian Translation (WAT2014)", "start_pos": 125, "end_pos": 205, "type": "TASK", "confidence": 0.7425874347488085}]}, {"text": "In this system, we applied the pre-reordering method described in (Zhu et al., 2014), and extended the model to obtain N-best pre-reordering results.", "labels": [], "entities": []}, {"text": "We also utilized N-best parse trees simultaneously to explore the potential improvement for pre-reordering system with forest input.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe the details of Weblio Pre-reordering Statistical Machine Translation (SMT) System, experiments and some issues we faced.", "labels": [], "entities": [{"text": "Pre-reordering Statistical Machine Translation (SMT)", "start_pos": 49, "end_pos": 101, "type": "TASK", "confidence": 0.7710578058447156}]}, {"text": "For this SMT system, we applied the pre-reordering method proposed in ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9943952560424805}]}, {"text": "In particular, this method automatically learns pre-reordering model from word alignments and parse trees.", "labels": [], "entities": []}, {"text": "Statistical language model is integrated in the pre-reordering model in order to reorder each node layer in parse trees.", "labels": [], "entities": []}, {"text": "In the 1st Workshop on Asian Translation (WAT2014) (, we mainly applied this method in English-Japanese translation subtask.", "labels": [], "entities": [{"text": "Asian Translation (WAT2014)", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.7709796130657196}]}, {"text": "The parse tree we used is head-restructured CFG parse tree for English, which is also proposed in ().", "labels": [], "entities": [{"text": "CFG parse tree", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.7617697517077128}]}, {"text": "After the pre-reordering phase, we trained a conventional Phrase-based model to do the final translation.", "labels": [], "entities": []}, {"text": "To make some improvements, we enabled the pre-reordering system to output N -best reordering results.", "labels": [], "entities": []}, {"text": "Also, we feed the whole translation pipeline with N -best parse trees generated by Egret parser.", "labels": [], "entities": []}, {"text": "As a result, multiple translation hypotheses can be collected for one input sentence.", "labels": [], "entities": []}, {"text": "Finally, we select the best hypothesis according to a balanced score.", "labels": [], "entities": []}, {"text": "In our experiments, the system utilizes N -best pre-reordering results shows the ability to obtain more accurate translation result.", "labels": [], "entities": []}, {"text": "After incorporating N -best parse trees, improvements on the automatic evaluation scores are also observed.", "labels": [], "entities": []}, {"text": "In section 2 and 3, we briefly describe the method used for tree parsing and pre-reordering.", "labels": [], "entities": [{"text": "tree parsing", "start_pos": 60, "end_pos": 72, "type": "TASK", "confidence": 0.6286885738372803}]}, {"text": "In the remaining sections, we give some details of the experiments of our system.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our baseline system, we use 1 -best parse trees for training and test.", "labels": [], "entities": []}, {"text": "Stanford tokenizer and Berkeley parser () are selected in the pre-processing phase in order to produce CFG parse trees.", "labels": [], "entities": []}, {"text": "Then we obtain dependency parse trees by applying Stanford rules () to CFG parse trees.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7799161076545715}]}, {"text": "HRCFG trees are built upon these two kinds of parse trees.", "labels": [], "entities": []}, {"text": "For the Japanese text, we use Kytea) to tokenize it.", "labels": [], "entities": []}, {"text": "Due to the limitation of computational resource, we are only able to train our reordering model on 1.5M bilingual text (with relatively high scores in ASPEC parallel corpus) for English-to-Japanese translation task.", "labels": [], "entities": [{"text": "ASPEC parallel corpus", "start_pos": 151, "end_pos": 172, "type": "DATASET", "confidence": 0.639663944641749}, {"text": "English-to-Japanese translation", "start_pos": 178, "end_pos": 209, "type": "TASK", "confidence": 0.5958782434463501}]}, {"text": "We used this trained reordering model to reorder all training data in the source side.", "labels": [], "entities": []}, {"text": "We use conventional Phrase-based model implemented in Moses toolkit to finish remaining SMT pipeline.", "labels": [], "entities": [{"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9775855541229248}]}, {"text": "Distortion limit is set to 6 in all our experiments.", "labels": [], "entities": [{"text": "Distortion limit", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.97738116979599}]}, {"text": "For system translates forest inputs, we use Egret parser to generate N -best packed forests.", "labels": [], "entities": []}, {"text": "We unpack each forest and parse each individual tree to HRCFG tree.", "labels": [], "entities": [{"text": "HRCFG tree", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.8536508977413177}]}, {"text": "For all candidate of parse trees, we reorder them and merge same reordering results.", "labels": [], "entities": []}, {"text": "Then for all reordering results we obtained, we translate them and record translation scores given by Moses.", "labels": [], "entities": []}, {"text": "Finally, a best translation result is selected out by the sum of translation score and reordering score.", "labels": [], "entities": [{"text": "reordering", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9522007703781128}]}, {"text": "We carried out several experiments combining the use of N -best parse trees and N -best reordering results.", "labels": [], "entities": []}, {"text": "A list of automatic evaluation scores for different system settings are listed in.", "labels": [], "entities": []}, {"text": "In this section, we evaluate the performance of pre-reordering.", "labels": [], "entities": []}, {"text": "Follows the method described in, we estimate Kendall's \u03c4 from word alignments.", "labels": [], "entities": [{"text": "Kendall's \u03c4", "start_pos": 45, "end_pos": 56, "type": "METRIC", "confidence": 0.6797733108202616}]}, {"text": "A comparison of Kendall's \u03c4 distribution upon first 1.5M sentences of ASPEC corpus is shown in., the algorithm for estimating Kendall's \u03c4 does not take the words with multiple alignments into account.", "labels": [], "entities": [{"text": "ASPEC corpus", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.8985103964805603}]}, {"text": "Hence, the graph of Kendall's \u03c4 only gives a rough idea of the performance of pre-reordering.", "labels": [], "entities": []}, {"text": "In particular, the algorithm skipped 20.30% aligned words for corpus in natural order and 14.06% aligned words for pre-reordered corpus.", "labels": [], "entities": []}, {"text": "However, the distribution of Kendall's \u03c4 in gives a intuitive picture of the improvements of word order.", "labels": [], "entities": []}, {"text": "Sentences which are fully identical in word order increased from 1.8% to 15% after pre-reordering (labeled with \"=1.0\" in).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experiment results for different system  settings", "labels": [], "entities": []}, {"text": " Table 3. Where \"BASELINE\" refers  to Phrase-based SMT system", "labels": [], "entities": [{"text": "BASELINE", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9894756078720093}, {"text": "Phrase-based SMT", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7282833158969879}]}, {"text": " Table 3: Official evaluation scores in WAT2014  (kytea used for post-processing)  # System BLEU(%) RIBES HUMAN", "labels": [], "entities": [{"text": "WAT2014", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.7326045632362366}, {"text": "BLEU", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9722042679786682}, {"text": "RIBES HUMAN", "start_pos": 100, "end_pos": 111, "type": "METRIC", "confidence": 0.7424034178256989}]}]}