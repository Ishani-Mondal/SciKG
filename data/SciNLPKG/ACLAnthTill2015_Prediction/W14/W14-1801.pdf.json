{"title": [], "abstractContent": [{"text": "We describe a system for automatically scoring a vocabulary item type that asks test-takers to use two specific words in writing a sentence based on a picture.", "labels": [], "entities": []}, {"text": "The system consists of a rule-based component and a machine learned statistical model which uses a variety of construct-relevant features.", "labels": [], "entities": []}, {"text": "Specifically, in constructing the statistical model, we investigate if grammar , usage, and mechanics features developed for scoring essays can be applied to short answers, as in our task.", "labels": [], "entities": []}, {"text": "We also explore new features reflecting the quality of the collocations in the response, as well as features measuring the consistency of the response to the picture.", "labels": [], "entities": []}, {"text": "System accuracy in scoring is 15 percentage points greater than the majority class baseline and 10 percentage points less than human performance .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9992052912712097}]}], "introductionContent": [{"text": "It is often said that the best way to see if a person knows the meaning of a word is to have that person use the word in a sentence.", "labels": [], "entities": []}, {"text": "Despite this widespread view, most vocabulary testing continues to rely on multiple choice items (e.g. ().", "labels": [], "entities": []}, {"text": "In fact, few assessments use constructed sentence responses to measure vocabulary knowledge, in part because of the considerable time and cost required to score such responses manually.", "labels": [], "entities": []}, {"text": "While much progress has been made in automatically scoring writing quality in essays (;, the essay scoring engines do not measure proficiency in the use of specific words, except perhaps for some frequently confused homophones (e.g., its/it's, there/their/they're, affect/effect).", "labels": [], "entities": []}, {"text": "In this paper we present a system for automated scoring of targeted vocabulary knowledge based on short constructed responses in a picture description task.", "labels": [], "entities": [{"text": "picture description task", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.7192039092381796}]}, {"text": "Specifically, we develop a system for scoring a vocabulary item type that is in operational use in English proficiency tests for nonnative speakers.", "labels": [], "entities": []}, {"text": "Each task prompt in this item type consists of two target key words, for which the vocabulary proficiency is tested, and a picture that provides the context for the sentence construction.", "labels": [], "entities": []}, {"text": "The task is to generate a single sentence, incorporating both key words, consistent with the picture.", "labels": [], "entities": []}, {"text": "Presumably, a test-taker with competent knowledge of the key words will be able to use them in a well-formed grammatical sentence in the context of the picture.", "labels": [], "entities": []}, {"text": "Picture description tasks have been employed in a number of areas of study ranging from second language acquisition to Alzheimer's disease).", "labels": [], "entities": [{"text": "Picture description tasks", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8110300302505493}, {"text": "second language acquisition", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.7111811836560568}]}, {"text": "Pictures and picture-based story narration have also been used to study referring expressions ( and to analyze child narratives in order to predict language impairment (.", "labels": [], "entities": []}, {"text": "employ a series of pictures and elicit (oral) story narration to test English language proficiency.", "labels": [], "entities": []}, {"text": "In our task, the picture is used as a constraining factor to limit the type and content of sentences that can be generated using the given key words.", "labels": [], "entities": []}, {"text": "In the course of developing our system, we examined existing features that have been developed for essay scoring, such as detectors of errors in grammar, usage and mechanics, as well as collocation features, to see if they can be re-used for scoring short responses.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 99, "end_pos": 112, "type": "TASK", "confidence": 0.7919095456600189}]}, {"text": "We also developed new features for assessing the quality of sentence construction using Pointwise Mutual Information (PMI).", "labels": [], "entities": [{"text": "sentence construction", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.720805823802948}]}, {"text": "As our task requires responses to describe the prompt pictures, we manually constructed detailed textual descriptions of the pictures, and de-1 veloped features that measure the overlap between the content of the responses and the textual description.", "labels": [], "entities": []}, {"text": "Our automated scoring system is partly based on deterministic scoring criteria and partly statistical.", "labels": [], "entities": []}, {"text": "Overall, it achieves an accuracy of 76%, which is a 15 percentage point improvement over a simple majority class baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9997736811637878}]}, {"text": "The organization of this paper is as follows: Section 2 describes the picture description task and the scoring guide that is used to manually score the picture description responses operationally.", "labels": [], "entities": [{"text": "picture description task", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.7586123247941335}]}, {"text": "It also considers which aspects of scoring maybe handled best by deterministic procedures and which are more amenable to statistical modeling.", "labels": [], "entities": []}, {"text": "Section 3 details the construction of a reference corpus of text describing each picture, and Section 4 presents the features used in scoring.", "labels": [], "entities": []}, {"text": "Section 5 describes our system architecture and presents our experiments and results.", "labels": [], "entities": []}, {"text": "Detailed analysis is presented in Section 6, followed by related work in Section 7 and a summary with directions for future research in Section 8.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Feature sets and the counts of features in  each set", "labels": [], "entities": []}, {"text": " Table 2: Overall system and human accuracy  (in percentage) and agreement (using Quadratic  Weighted Kappa)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9882354736328125}, {"text": "agreement", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9983065128326416}, {"text": "Quadratic  Weighted Kappa", "start_pos": 82, "end_pos": 107, "type": "METRIC", "confidence": 0.8784006237983704}]}, {"text": " Table 3: Overall system performance at each score  point using all features", "labels": [], "entities": []}, {"text": " Table 4: System performance for individual fea- tures", "labels": [], "entities": []}, {"text": " Table 5: System performance for feature combi- nations (i) typically used in essay scoring, (ii) that  measure awkwardness, (iii) newly proposed here,  (iv) newly proposed plus rubric-specific criteria", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.7762465476989746}]}]}