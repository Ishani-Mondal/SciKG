{"title": [], "abstractContent": [{"text": "Segmentation of spoken discourse into distinct conversational activities has been applied to broadcast news, meetings, monologs, and two-party dialogs.", "labels": [], "entities": []}, {"text": "This paper considers the aspectual properties of discourse segments, meaning how they transpire in time.", "labels": [], "entities": []}, {"text": "Classifiers were constructed to distinguish between segment boundaries and non-boundaries, where the sizes of utterance spans to represent data instances were varied, and the locations of segment boundaries relative to these instances.", "labels": [], "entities": []}, {"text": "Classifier performance was better for representations that included the end of one discourse segment combined with the beginning of the next.", "labels": [], "entities": []}, {"text": "In addition, classification accuracy was better for segments in which speakers accomplish goals with distinctive start and end points.", "labels": [], "entities": [{"text": "classification", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.952022135257721}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9636480212211609}]}], "introductionContent": [{"text": "People engage in dialogue to address a wide range of goals.", "labels": [], "entities": []}, {"text": "It has long been observed that discourse can be structured into units that correspond to distinct goals and activities.", "labels": [], "entities": []}, {"text": "This is conceptually distinct from structuring discourse into the topical units addressed in.", "labels": [], "entities": []}, {"text": "The ability to recognize where distinct activities occur in spoken discourse could support offline applications to spoken corpora such as search (), summarization (), and question answering.", "labels": [], "entities": [{"text": "summarization", "start_pos": 149, "end_pos": 162, "type": "TASK", "confidence": 0.9840807318687439}, {"text": "question answering", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.8896230757236481}]}, {"text": "Further, a deeper understanding of the relation of conversational activities to observable features of utterance sequences could inform the design of interactive systems for online applications such as information gathering, service requests, tutoring, and companionship.", "labels": [], "entities": [{"text": "information gathering", "start_pos": 202, "end_pos": 223, "type": "TASK", "confidence": 0.7227351069450378}]}, {"text": "Automatic identification of such units, however, has been difficult to achieve.", "labels": [], "entities": [{"text": "Automatic identification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6280674636363983}]}, {"text": "This paper considers the aspectual properties of speakers' conversational activities, meaning how they transpire in time.", "labels": [], "entities": []}, {"text": "We hypothesize that recognition of a transition to anew conversational activity depends on recognizing not only the start of anew activity but also the end of the preceding one, on the grounds that the relative contrast between endings and beginnings might matter as much or more than absolute characteristics consistent across all beginnings or all endings.", "labels": [], "entities": []}, {"text": "We further hypothesize that transitions to certain kinds of conversational activity maybe easier to detect than others.", "labels": [], "entities": []}, {"text": "Following Austin's view that speech constitutes action of different kinds, we assume that different kinds of communicative action have different ways of transpiring in time, just as other actions do.", "labels": [], "entities": []}, {"text": "Conversational activities that address objective goals, for example, can have very well-demarcated beginnings and endings, as when two people choose a restaurant to go to for dinner.", "labels": [], "entities": []}, {"text": "Conversational participants can, however, address goals that need not have a specific resolution, such as shared complaints about the lack of good Chinese restaurants.", "labels": [], "entities": []}, {"text": "This distinction between different kinds of actions that speakers perform through their communicative behavior is analogous to the distinction in linguistic semantics pertaining to verbal aspect, between states, processes and transition events (or accomplishments and achievements).", "labels": [], "entities": []}, {"text": "States (e.g., being at a standstill) have no perceptible change from moment to moment; processes (e.g., walking) have detectable differences instate from moment to moment with no clearly demarcated change of state during the process; transition events (e.g., starting to walk; walking to the end of the block) involve a transition from one state or process to another.", "labels": [], "entities": []}, {"text": "To investigate the aspectual properties of discourse segments, we constructed classifiers to de-tect discourse segment boundaries based on features of utterances.", "labels": [], "entities": []}, {"text": "We considered the aspectual properties of discourse segments in two ways.", "labels": [], "entities": []}, {"text": "First, to investigate the relative contribution of features from segment endings versus beginnings, we experimented with different sizes of utterance sequences, and different locations of segment boundaries relative to these sequences.", "labels": [], "entities": []}, {"text": "Second, we considered different categories of segments, based on the speculation that segment transitions that are easier to recognize would be associated with conversational activities that have a well-demarcated event structure, in constrast to activities that involve goals to maintain or sustain aspects of interaction.", "labels": [], "entities": []}, {"text": "The following section describes related work in this area, as well as the difficulties in achieving good performance.", "labels": [], "entities": []}, {"text": "Most work on identification of discourse segments (or other forms of discourse structure in spoken interaction) depends on a prior phase of annotation (e.g., ().", "labels": [], "entities": [{"text": "identification of discourse segments", "start_pos": 13, "end_pos": 49, "type": "TASK", "confidence": 0.865690678358078}]}, {"text": "We studied a corpus of eighty-two transcribed and annotated telephone dialogues between library patrons and librarians that had been annotated with units analogous to speech acts, and subsequently annotated with discourse segments comprised of these units.", "labels": [], "entities": []}, {"text": "The annotation yielded eight distinct kinds of discourse segment, where a segment results from a linear segmentation of a discourse into strictly sequential units.", "labels": [], "entities": []}, {"text": "(While the segmentation is sequential, the units can have hierarchical relations.)", "labels": [], "entities": []}, {"text": "We found that classifiers to detect segment boundaries performed best with boundaries represented by features of sequences of utterances that spanned the end of one segment and the beginning of the next.", "labels": [], "entities": []}, {"text": "Error analysis indicated that performance was better for boundaries that initiate conversational activities with clear beginnings and endings.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments to automatically identify the locations of the annotated discourse units apply machine learning to instances consisting of utterance sequences that represent the two classes, presence versus absence of a boundary.", "labels": [], "entities": []}, {"text": "We hyothesize that the enormous challenges for identifying discourse structure in human-machine dialogue can be better addressed through complementary reliance on semantics and interaction structure (behavioral cues), and each can reinforce the other.", "labels": [], "entities": []}, {"text": "The main focus of the experiments reported here is on data representation to address the questions, what features of the context support the ability to segment a dialogue into conversational activity units, and how much context is necessary?", "labels": [], "entities": []}, {"text": "A disadvantage of the dataset is its relatively small size, especially given the extreme skew with the positive class consisting of only 10% of the instances.", "labels": [], "entities": []}, {"text": "On the other hand, the small size made detailed annotation feasible, and the corpus is well-suited to our research question in that it represents naturally occurring, spontaneous humanhuman telephone discourse.", "labels": [], "entities": []}, {"text": "the manner in which the dialogs evolve overtime is entirely natural.", "labels": [], "entities": []}, {"text": "Our major question of interest is how much of the time-course of the discourse is required fora machine learner to identify the start of anew discourse unit.", "labels": [], "entities": []}, {"text": "To examine this question, we vary two dimensions of the representation of the instances for learning.", "labels": [], "entities": []}, {"text": "The first is the number of utterances around the location of the start of anew discourse unit.", "labels": [], "entities": []}, {"text": "The second is the set of features to represent each instance, which as we will see below, affects to some degree how many utterances to include before and after the start of anew discourse unit.", "labels": [], "entities": []}, {"text": "Four machine learning methods were tested using the Weka toolkit (): Naive Bayes, J48 Decision Trees, Logistic Regression and Multilayer Perceptron.", "labels": [], "entities": [{"text": "Weka toolkit", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.9532200992107391}, {"text": "J48 Decision Trees", "start_pos": 82, "end_pos": 100, "type": "DATASET", "confidence": 0.7881858150164286}]}, {"text": "Of these, J48 had the best and most consistent performance, which we speculate is due to a combination of the small size of the dataset, and non-linearity of the data.", "labels": [], "entities": []}, {"text": "Because J48 is doing feature selection while building the tree, it can identify different threshholds for the same features, depending on the location in the tree.", "labels": [], "entities": []}, {"text": "All results reported here are for J48.", "labels": [], "entities": [{"text": "J48", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.9367666840553284}]}, {"text": "The experimental conditions varied the feature set, the selection of training data versus testing data, and the fourteen kinds of instance spans and labels.", "labels": [], "entities": []}, {"text": "Three feature sets consisted of the discourse features from Table 1 (discourse), bag-of-words (bow), and the combination of the two (combo).", "labels": [], "entities": []}, {"text": "In all experiments, the data was randomly split into 75% for training, and 25% for testing, using two methods to select instances.", "labels": [], "entities": []}, {"text": "In randomization by dialog, all utterances from a single dialog were kept together and 75% of the dialogs were selected for training.", "labels": [], "entities": []}, {"text": "In randomization by utterance, 75% of all utterances were randomly selected for training, without regard to which dialog they came from.", "labels": [], "entities": []}, {"text": "This was done to test the hypothesis that the bow representation would be more sensitive to changes of vocabulary across dialogs.", "labels": [], "entities": []}, {"text": "The three feature sets, fourteen data representations and two randomization methods yield 84 experimental conditions.", "labels": [], "entities": []}, {"text": "While N-fold cross-validation is a popular method to estimate a classifier's prediction error, it is not a perfect substitute for isolating the training data from the test data).", "labels": [], "entities": []}, {"text": "The crossvalidation estimate of prediction error is relatively unbiased, but it can be highly variable)(.", "labels": [], "entities": []}, {"text": "To avoid the inherent risk of overfitting, one recommendation is to use cross-validation to compare models, and to reserve a test set to verify that a selected classifier has superior generalization (.", "labels": [], "entities": []}, {"text": "To assess whether performance measures of different models are genuinely different requires error bounds on the result, which is not done with cross-validation.", "labels": [], "entities": []}, {"text": "We perform train-test splits of the data to minimize overfitting, and bootstrap confidence intervals for each classifier's accuracy (and other metrics) in order to measure the variance, and thereby assess whether the performance error bounds of two conditions are distinct.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9829722046852112}]}], "tableCaptions": [{"text": " Table 2: Classification performance (with standard deviations in parentheses) of the best 40% of 84  J48 models trained on 75% of the data and tested on the remaining 25%, with bootstrapped confidence  intervals from 50 trials each.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.7547309994697571}, {"text": "bootstrapped confidence  intervals", "start_pos": 178, "end_pos": 212, "type": "METRIC", "confidence": 0.9404647946357727}]}]}