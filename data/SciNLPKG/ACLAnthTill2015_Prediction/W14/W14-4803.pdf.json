{"title": [{"text": "Identification of Bilingual Terms from Monolingual Documents for Statistical Machine Translation", "labels": [], "entities": [{"text": "Identification of Bilingual Terms from Monolingual Documents", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.8815435596874782}, {"text": "Statistical Machine Translation", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7981841166814169}]}], "abstractContent": [{"text": "The automatic translation of domain-specific documents is often a hard task for generic Statistical Machine Translation (SMT) systems, which are notable to correctly translate the large number of terms encountered in the text.", "labels": [], "entities": [{"text": "automatic translation of domain-specific documents", "start_pos": 4, "end_pos": 54, "type": "TASK", "confidence": 0.7307221293449402}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.784823939204216}]}, {"text": "In this paper, we address the problems of automatic identification of bilingual terminology using Wikipedia as a lexical resource, and its integration into an SMT system.", "labels": [], "entities": [{"text": "automatic identification of bilingual terminology", "start_pos": 42, "end_pos": 91, "type": "TASK", "confidence": 0.7566421151161193}, {"text": "SMT", "start_pos": 159, "end_pos": 162, "type": "TASK", "confidence": 0.9831021428108215}]}, {"text": "The correct translation equivalent of the disambiguated term identified in the monolingual text is obtained by taking advantage of the multilingual versions of Wikipedia.", "labels": [], "entities": []}, {"text": "This approach is compared to the bilingual terminology provided by the Terminology as a Service (TaaS) platform.", "labels": [], "entities": []}, {"text": "The small amount of high quality domain-specific terms is passed to the SMT system using the XML markup and the Fill-Up model methods, which produced a relative translation improvement up to 13% BLEU score points", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.976269543170929}, {"text": "BLEU score", "start_pos": 195, "end_pos": 205, "type": "METRIC", "confidence": 0.9780823588371277}]}], "introductionContent": [{"text": "Translation tasks often need to deal with domain-specific terms in technical documents, which require specific lexical knowledge of the domain.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9564099907875061}]}, {"text": "Nowadays, SMT systems are suitable to translate very frequent expressions but fail in translating domain-specific terms.", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9905942678451538}]}, {"text": "This mostly depends on alack of domainspecific parallel data from which the SMT systems can learn.", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9843034744262695}]}, {"text": "Translation tools such as Google Translate or open source phrase-based SMT systems, trained on generic data, are the most common solutions and they are often used to translate manuals or very specific texts, resulting in unsatisfactory translations.", "labels": [], "entities": []}, {"text": "This problem is particular relevant for professional translators that work with documents coming from different domains and are supported by generic SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 149, "end_pos": 152, "type": "TASK", "confidence": 0.973844051361084}]}, {"text": "A valuable solution to help them in handling domain-specific terms is represented by online terminology resources, e.g. IATE -Inter-Active Terminology for Europe, 1 which are continuously updated and can be easily queried.", "labels": [], "entities": [{"text": "IATE -Inter-Active Terminology for Europe, 1", "start_pos": 120, "end_pos": 164, "type": "DATASET", "confidence": 0.6034997366368771}]}, {"text": "However, the manual use of these services can be very time demanding.", "labels": [], "entities": []}, {"text": "For this reason, the identification and embedding of domain-specific terms in an SMT system is a crucial step towards increasing translator productivity and translation quality in highly specific domains.", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9721086025238037}]}, {"text": "In this paper, we propose an approach to automatically detect monolingual domain-specific terms from a source language document and identify their equivalents using Wikipedia cross-lingual links.", "labels": [], "entities": []}, {"text": "For this purpose we extend The Wiki Machine API, 2 a tool for linking terms in text to Wikipedia pages, adding two more components able to first identify domain-specific terms, and to find their translations in a target language.", "labels": [], "entities": []}, {"text": "The identified bilingual terms are then compared with those obtained by.", "labels": [], "entities": []}, {"text": "The embedding of the domain-specific terms into an SMT system is performed by use of the XML markup approach, which uses the terms as preferred translation candidates at run time, and the Fill-Up model), which emphasizes phrase pairs extracted from the bilingual terms.", "labels": [], "entities": [{"text": "SMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9850581288337708}]}, {"text": "Our results show that the performance of our technique and TaaS are comparable in the identification of monolingual and bilingual domain-specific terms.", "labels": [], "entities": []}, {"text": "From the machine translation point of view, our experiments highlight the benefit of integrating bilingual terms into the SMT system, and the relative improvement in BLEU score of the Fill-Up model over the baseline and the XML markup approach.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.757141500711441}, {"text": "SMT", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9899396300315857}, {"text": "BLEU score", "start_pos": 166, "end_pos": 176, "type": "METRIC", "confidence": 0.9810819327831268}]}], "datasetContent": [{"text": "In our experiments, we used different English-Italian and Italian-English test sets from two domains: (i) a small subset of the GNOME project data 3 (4,3K tokens) and KDE4 Data 4 (9,5K) for the IT domain and (ii) a subset of the EMEA corpus (11K) for the medical domain.", "labels": [], "entities": [{"text": "GNOME project data 3", "start_pos": 128, "end_pos": 148, "type": "DATASET", "confidence": 0.9248311072587967}, {"text": "KDE4 Data 4", "start_pos": 167, "end_pos": 178, "type": "DATASET", "confidence": 0.8658585747083029}, {"text": "EMEA corpus", "start_pos": 229, "end_pos": 240, "type": "DATASET", "confidence": 0.944457471370697}]}, {"text": "In order to assess the quality of the monolingual and bilingual terms, we create a terminological gold standard.", "labels": [], "entities": []}, {"text": "Two annotators with a linguistic background and English and Italian proficiency were asked to mark all domain-specific terms in a set of 66 English and Italian documents of the GNOME corpus, and a set of 100 paragraphs (4,3K tokens) from the KDE4 corpus.", "labels": [], "entities": [{"text": "GNOME corpus", "start_pos": 177, "end_pos": 189, "type": "DATASET", "confidence": 0.939033031463623}, {"text": "KDE4 corpus", "start_pos": 242, "end_pos": 253, "type": "DATASET", "confidence": 0.9316769540309906}]}, {"text": "Domain-specificity was defined as all (multi-)words that are typically used in the IT domain and that may have different Italian translations in other domains.", "labels": [], "entities": []}, {"text": "The average Cohen's Kappa of GNOME and KDE anno computed at token level was 0.66 for English and 0.53 for Italian.", "labels": [], "entities": [{"text": "Cohen's Kappa", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.75237508614858}]}, {"text": "Following, this corresponds to a substantial and moderate agreement between the annotators.", "labels": [], "entities": []}, {"text": "Finally the gold standard dataset was generated by the intersection of the annotations of the two annotators.", "labels": [], "entities": [{"text": "gold standard dataset", "start_pos": 12, "end_pos": 33, "type": "DATASET", "confidence": 0.8993586301803589}]}, {"text": "In detail, for the GNOME dataset the annotators marked 93 single-word and 134 multi-word expressions (MWEs), resulting 227 terms in overall.", "labels": [], "entities": [{"text": "GNOME dataset", "start_pos": 19, "end_pos": 32, "type": "DATASET", "confidence": 0.9416999816894531}]}, {"text": "For the KDE anno dataset, 321 monolingual terms for the GNOME dataset were annotated, whereby 192 of them were multi-word expressions.", "labels": [], "entities": [{"text": "KDE anno dataset", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.6841773589452108}, {"text": "GNOME dataset", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.9223616123199463}]}, {"text": "This results in 190 unique bilingual terms for the GNOME corpus and 355 for the KDE anno dataset.", "labels": [], "entities": [{"text": "GNOME corpus", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.9344185888767242}, {"text": "KDE anno dataset", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.7755492925643921}]}, {"text": "We compare the monolingual and bilingual terms identified by our approach to the terms obtained by the online service TaaS, 6 which is a cloud-based platform for terminology services based on the state-of-the-art terminology extraction and bilingual terminology alignment methods.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 213, "end_pos": 235, "type": "TASK", "confidence": 0.7134498506784439}, {"text": "bilingual terminology alignment", "start_pos": 240, "end_pos": 271, "type": "TASK", "confidence": 0.6271787186463674}]}, {"text": "TaaS provides several options in term identification, of which we selected TWSC, Tilde wrapper system for CollTerm, (.", "labels": [], "entities": [{"text": "TaaS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9199318885803223}, {"text": "term identification", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7362355887889862}, {"text": "TWSC", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.8131411671638489}, {"text": "Tilde wrapper", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.7833257913589478}]}, {"text": "TWSC is based on linguistic analysis, i.e. part of speech tagging and morphosyntactic patterns, enriched with statistical features.", "labels": [], "entities": [{"text": "TWSC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6747674942016602}, {"text": "speech tagging", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7363473773002625}]}, {"text": "TaaS allows for lookup in several manually and automatically built monolingual and bilingual terminological resources and for our experiment we use EuroTermBank (ETB), Taus Data and Web Data.", "labels": [], "entities": [{"text": "TaaS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7802361845970154}, {"text": "EuroTermBank (ETB)", "start_pos": 148, "end_pos": 166, "type": "DATASET", "confidence": 0.9081621468067169}, {"text": "Taus Data", "start_pos": 168, "end_pos": 177, "type": "DATASET", "confidence": 0.6638413220643997}]}, {"text": "Accessing several resources, TaaS may provide several translations fora unique source term, but not an indicator of their translation quality.", "labels": [], "entities": []}, {"text": "To avoid assigning the same probability to all the translations of the same source term, we prioritise a translation by the resource it was provided.", "labels": [], "entities": []}, {"text": "In our case, we favour first the translation provided by ETB.", "labels": [], "entities": [{"text": "translation", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.9571185111999512}, {"text": "ETB", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.9915068745613098}]}, {"text": "If no translation is available, we use the translation provided by Taus Data or eventually from Web Data.", "labels": [], "entities": [{"text": "Taus Data", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.8756295442581177}, {"text": "Web Data", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.879847526550293}]}, {"text": "Before starting the term extraction approach, TaaS requires manual specification of the source and target languages, the domain, and the source document.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7109118402004242}]}, {"text": "Since we focused on the IT and medical domains we set the options to 'Information and communication technology' and 'Medicine and pharmacy', respectively.", "labels": [], "entities": []}, {"text": "For each translation task, we use the statistical translation toolkit Moses ( , where the word alignments were built with the GIZA++ toolkit (.", "labels": [], "entities": [{"text": "translation task", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.8948490917682648}, {"text": "statistical translation toolkit Moses", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.6765814572572708}, {"text": "word alignments", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.727396160364151}]}, {"text": "The IRSTLM toolkit) was used to build the 5-gram language model.", "labels": [], "entities": [{"text": "IRSTLM toolkit", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8099222779273987}]}, {"text": "For a broader domain coverage, we merged parts of the following parallel resources: JRC-Acquis (), Europarl () and OpenSubtitles2013, this results in a generic training corpus of \u223c37M tokens and a development set of \u223c10K tokens.", "labels": [], "entities": [{"text": "JRC-Acquis", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.9249714612960815}, {"text": "Europarl", "start_pos": 99, "end_pos": 107, "type": "DATASET", "confidence": 0.9657601118087769}]}, {"text": "In our experiments, an instance of Moses trained on the generic parallel dataset was used in three different scenarios: (i) as baseline SMT system without embedded terminology; (ii) in the XML markup approach for translating remaining parts that were not covered by the embedded terminology; (iii) in the Fill-Up method as background translation model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.9775980710983276}]}, {"text": "In this Section, we report the performance of the different term identification tools and term embedding methods for the two domains: IT and the medical domain.", "labels": [], "entities": [{"text": "term identification", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7250109165906906}]}, {"text": "For evaluating the extracted monolingual and bilingual terms, we calculate precision, recall and f-measure using the manually labelled KDE anno and GNOME datasets.", "labels": [], "entities": [{"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9996650218963623}, {"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9993698000907898}, {"text": "f-measure", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9923793077468872}, {"text": "KDE anno and GNOME datasets", "start_pos": 135, "end_pos": 162, "type": "DATASET", "confidence": 0.7768828749656678}]}, {"text": "In addition, we perform a manual inspection of a subset of the bilingual identified terms.", "labels": [], "entities": []}, {"text": "The BLEU metric () was used to automatically evaluate the quality of the translations.", "labels": [], "entities": [{"text": "BLEU metric", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9766485393047333}]}, {"text": "The metric calculates the overlap of n-grams between the SMT system output and a reference translation, provided by a professional translator.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9843140840530396}]}], "tableCaptions": [{"text": " Table 1: Evaluation of monolingual term identification for the KDE anno and GNOME dataset.", "labels": [], "entities": [{"text": "monolingual term identification", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.6828406651814779}, {"text": "KDE anno and GNOME dataset", "start_pos": 64, "end_pos": 90, "type": "DATASET", "confidence": 0.6608903169631958}]}, {"text": " Table 2: Automatic evaluation of bilingual terms ex- tracted from GNOME and KDE anno.", "labels": [], "entities": []}, {"text": " Table 3: Manual evaluation of bilingual terms  based on four error categories (1-4).", "labels": [], "entities": []}, {"text": " Table 4: Automatic BLEU Evaluation on GNOME, KDE and EMEA datasets with different term em- bedding strategies (bold results = best performance ; * statistically significant compared to baseline).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9666216969490051}, {"text": "EMEA datasets", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.8166709840297699}]}]}