{"title": [{"text": "Concept-oriented labelling of patent images based on Random Forests and proximity-driven generation of synthetic data", "labels": [], "entities": []}], "abstractContent": [{"text": "Patent images are very important for patent examiners to understand the contents of an invention.", "labels": [], "entities": []}, {"text": "Therefore there is a need for automatic labelling of patent images in order to support patent search tasks.", "labels": [], "entities": []}, {"text": "Towards this goal, recent research works propose classification-based approaches for patent image annotation.", "labels": [], "entities": [{"text": "patent image annotation", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.797009805838267}]}, {"text": "However, one of the main drawbacks of these methods is that they rely upon large annotated patent image datasets, which require substantial manual effort to be obtained.", "labels": [], "entities": []}, {"text": "In this context, the proposed work performs extraction of concepts from patent images building upon a supervised machine learning framework, which is trained with limited annotated data and automatically generated synthetic data.", "labels": [], "entities": [{"text": "extraction of concepts from patent images", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.7954464852809906}]}, {"text": "The classification is realised with Random Forests (RF) and a combination of visual and textual features.", "labels": [], "entities": []}, {"text": "First, we make use of RF's implicit ability to detect outliers to rid our data of unnecessary noise.", "labels": [], "entities": []}, {"text": "Then, we generate new synthetic data cases by means of Synthetic Minority Over-sampling Technique (SMOTE).", "labels": [], "entities": []}, {"text": "We evaluate the different retrieval parts of the framework by using a dataset from the footwear domain.", "labels": [], "entities": []}, {"text": "The results of the experiments indicate the benefits of using the proposed methodology.", "labels": [], "entities": []}], "introductionContent": [{"text": "The vast number of patent documents submitted to patent offices worldwide calls for the need of advanced patent search technologies, which could deal effectively with the complexity and the unique characteristics of patents.", "labels": [], "entities": []}, {"text": "The majority of existing patent retrieval techniques and search engines rely upon text, given the fact that the ideas and the innovations to be patented are described in text format in the claims and the disclosure parts of the patent.", "labels": [], "entities": []}, {"text": "However, we should not overlook the fact that most of the patents include a drawings section, which contains figures, drawings and diagrams as a means to further describe and understand the patented inventions.", "labels": [], "entities": []}, {"text": "In the recent years, the Intellectual Property and Information Retrieval communities, motivated by the interest in patent image search, have directed their efforts towards the development of systems that have the ability to search in patents by considering both textual and visual information.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.7197298109531403}, {"text": "patent image search", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.594541609287262}]}, {"text": "Following the latest trends and challenges in image retrieval, the most recent studies in patent image search deal with concept extraction and classification using visual features (e.g.).", "labels": [], "entities": [{"text": "image retrieval", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7507860362529755}, {"text": "patent image search", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.5919850667317709}, {"text": "concept extraction", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7392832785844803}]}, {"text": "The concept extraction techniques involve the identification of images with common characteristics that fall into a specific semantic category or depict a specific concept.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7420587092638016}]}, {"text": "The motivation behind the interest in patent concept-based search is revealed by the following scenario presented in: a patent searcher searches fora dancing shoe that incorporates a rotating heel with ball bearings; at first, the patent searcher recognises the main concepts of the invention (e.g. dancing shoe) and based on them keywords and relevant classification areas are defined.", "labels": [], "entities": []}, {"text": "In many cases the important information is described with figures.", "labels": [], "entities": []}, {"text": "Therefore, it would be important if the patent searcher could directly retrieve patents, which include figures depicting these concepts.", "labels": [], "entities": []}, {"text": "The main obstacle of this ap-proach is the need fora significant number of annotated images required during the training phase for developing models for each concept/category, something that is arduous and time-consuming (due to the specific nature of these images, it is not easy to retrieve training instances from the web).", "labels": [], "entities": []}, {"text": "To deal with the aforementioned restriction, we present an approach for concept extraction from patent images with the ability to supplement a small manually annotated dataset by means of automatic synthetic data cases generation.", "labels": [], "entities": [{"text": "concept extraction from patent images", "start_pos": 72, "end_pos": 109, "type": "TASK", "confidence": 0.8491272807121277}]}, {"text": "The proposed methodology is based on a supervised machine learning framework using Random Forests (RF) trained with textual and visual features.", "labels": [], "entities": []}, {"text": "RF's advantage of handling multiclass classification tasks directly eliminates the need to develop a classification model for each concept separately.", "labels": [], "entities": [{"text": "multiclass classification tasks", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.7592095732688904}]}, {"text": "Moreover, its outlier detection technique carries out a suitable preprocessing of the data.", "labels": [], "entities": []}, {"text": "The main contribution and the research objective of this paper is the examination of concept extraction based on multimodal classification, coupled with RF construction driven by synthetic data and outlier elimination.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7541590631008148}, {"text": "multimodal classification", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.7083369195461273}, {"text": "RF construction", "start_pos": 153, "end_pos": 168, "type": "TASK", "confidence": 0.9708501994609833}]}, {"text": "While the research works up to date apply Synthetic Minority Over-sampling Technique (SMOTE) for the purpose of overcoming imbalanced-related problems, the proposed approach extends the application of SMOTE to the generation of synthetic cases in an already balanced dataset.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there isn't any relevant literature concerning the application of SMOTE to multiclass datasets that are balanced but contain a relatively small amount of training instances per class (which is the casein this study).", "labels": [], "entities": [{"text": "SMOTE", "start_pos": 96, "end_pos": 101, "type": "TASK", "confidence": 0.9804977178573608}]}, {"text": "The rest of the paper is organised as follows: In Section 2 we provide the theoretical background of our study.", "labels": [], "entities": []}, {"text": "In Section 3, the related work is presented.", "labels": [], "entities": []}, {"text": "The feature extraction process and the architecture of the proposed framework are analysed in Sections 4 and 5, respectively.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7330620288848877}]}, {"text": "Section 6 describes the conducted experiments, as well as the results.", "labels": [], "entities": []}, {"text": "Finally, concluding remarks are provided in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset 1 was manually extracted from around 300 patents.", "labels": [], "entities": []}, {"text": "It contains around 1000 patent images depicting parts of footwear.", "labels": [], "entities": []}, {"text": "The feature vectors that were generated (Section 4) for this dataset consist of 100 visual and 250 textual features.", "labels": [], "entities": []}, {"text": "With the help of professional patent searchers we selected the following 8 concepts for this domain: cleat, ski boot, high heel, lacing closure, heel with spring, tongue, toe caps and roller skates ().", "labels": [], "entities": []}, {"text": "The procedure of associating the patent images with the figure text descriptions was carried out manually.", "labels": [], "entities": []}, {"text": "This was done in order to acquire quality data and consequently, draw safer conclusions on the concept extraction method.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7741065621376038}]}, {"text": "The images were manually annotated with the support and advice of professional patent searchers.", "labels": [], "entities": []}, {"text": "For our experiments, the dataset was randomly split into training and test sets.", "labels": [], "entities": []}, {"text": "We kept 2/3 of the images for training purposes, whereas the rest (1/3) were used as test set, in order to estimate the classification scheme's performance.", "labels": [], "entities": []}, {"text": "We note here that because of the fact that RF provides an internal estimate of its performance on cases that do not participate in its training procedure (the OOB error estimate), no cross-validation was required.", "labels": [], "entities": [{"text": "OOB error estimate", "start_pos": 159, "end_pos": 177, "type": "METRIC", "confidence": 0.9236988226572672}]}, {"text": "Moreover, since SMOTE is applied during the training phase, it is important to mention that the test set contains only real (not synthetic) data.", "labels": [], "entities": [{"text": "SMOTE", "start_pos": 16, "end_pos": 21, "type": "TASK", "confidence": 0.9075859189033508}]}, {"text": "Regarding the parameters of the methods involved in the experiments, we selected and applied the following setting: The number of trees used for the construction of each RF was set based on the OOB error estimate.", "labels": [], "entities": [{"text": "OOB error estimate", "start_pos": 194, "end_pos": 212, "type": "METRIC", "confidence": 0.9645561178525289}]}, {"text": "After conducting several experiments and gradually increasing the number of trees, we noticed that the OOB error estimate was stabilised after using 1000 trees and no longer improved.", "labels": [], "entities": [{"text": "OOB error estimate", "start_pos": 103, "end_pos": 121, "type": "METRIC", "confidence": 0.9637287259101868}]}, {"text": "Hence, the number of trees was set to 1000.", "labels": [], "entities": []}, {"text": "Moreover, for each node split during the growing of each tree, the number of the subset of variables used to determine the best split was set to \u221a , where k is the total number of features of the dataset (according to).", "labels": [], "entities": []}, {"text": "Concerning the RF outlier detection and elimination procedure, states that a case can be considered an outlier if its outlier measure value is higher than 10.", "labels": [], "entities": [{"text": "RF outlier detection and elimination", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.8140291094779968}]}, {"text": "We note that after choosing this configuration, approximately 2% of the textual modality's cases were detected as outliers and discarded, keeping the rest of the cases for further processing, while for the visual modality no outliers were detected.", "labels": [], "entities": []}, {"text": "Finally, the SMOTE oversampling rate for each concept in both modalities datasets was set to 500%, i.e. for each case 5 new synthetic cases were generated, based on this case's nearest neighbours.", "labels": [], "entities": [{"text": "SMOTE oversampling rate", "start_pos": 13, "end_pos": 36, "type": "METRIC", "confidence": 0.6909374892711639}]}], "tableCaptions": [{"text": " Table 1. Precision, recall and F-score test set results (without outlier deletion and without SMOTE)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9983354210853577}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9978442192077637}, {"text": "F-score test set", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.9538785219192505}, {"text": "SMOTE", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9672203063964844}]}, {"text": " Table 2. Precision, recall and F-score test set results (with outlier deletion and SMOTE)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.997844934463501}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.997869610786438}, {"text": "F-score test set", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.94610462586085}, {"text": "SMOTE", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.988292396068573}]}]}