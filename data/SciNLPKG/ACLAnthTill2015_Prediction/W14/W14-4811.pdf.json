{"title": [{"text": "Evaluating Term Extraction Methods for Interpreters", "labels": [], "entities": [{"text": "Evaluating Term Extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7293887337048849}, {"text": "Interpreters", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.6408376097679138}]}], "abstractContent": [{"text": "The study investigates term extraction methods using comparable corpora for interpreters.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.742264986038208}]}, {"text": "Simultaneous interpreting requires efficient use of highly specialised domain-specific terminology in the working languages of an interpreter with limited time to prepare for new topics.", "labels": [], "entities": [{"text": "interpreting", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.9608909487724304}]}, {"text": "We evaluate several terminology extraction methods for Chinese and English using settings which replicate real-life scenarios, concerning the task difficulty, the range of terms and the amount of materials available, etc.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7154040187597275}]}, {"text": "We also investigate interpreters' perception on the usefulness of automatic termlists.", "labels": [], "entities": []}, {"text": "The results show the accuracy of the terminology extraction pipelines is not perfect, as their precision ranges from 27% on short texts to 83% on longer corpora for English, 24% to 31% on Chinese.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9994699358940125}, {"text": "terminology extraction pipelines", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.85209854443868}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9990019202232361}]}, {"text": "Nevertheless, the use of even small corpora for specialised topics greatly facilitates interpreters in their preparation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The study investigates term extraction methods using comparable corpora for interpreters.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.742264986038208}]}, {"text": "Simultaneous interpreting requires efficient use of highly specialised domain-specific terminology in the working languages of the interpreter.", "labels": [], "entities": [{"text": "interpreting", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.9677143692970276}]}, {"text": "By necessity, interpreters often work in a wide range of domains and have limited time to prepare for new topics.", "labels": [], "entities": []}, {"text": "To ensure the best possible simultaneous interpreting of specialised conferences where a great number of domain-specific terms are used, interpreters need preparation, usually under considerable time pressure.", "labels": [], "entities": [{"text": "interpreting of specialised conferences", "start_pos": 41, "end_pos": 80, "type": "TASK", "confidence": 0.8406512141227722}]}, {"text": "They need to familiarise themselves with concepts, technical terms, and proper names in the interpreters' working languages.", "labels": [], "entities": []}, {"text": "However, there is little research into the use of modern terminology extraction tools and pipelines for the task of simultaneous interpretation.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7857562303543091}, {"text": "simultaneous interpretation", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.656586617231369}]}, {"text": "At the start of computer-assisted termbank development, overviewed the needs and workflow of practicing interpreters with respect to terminology and offered some guidelines for developing term management tools specifically for the interpreters.", "labels": [], "entities": [{"text": "termbank development", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.6898614168167114}]}, {"text": "That study did review the functionalities of some termbanks and term management systems, yet there was no mention of corpus collection (a fairly new idea at the time) or automatic term extraction.", "labels": [], "entities": [{"text": "corpus collection", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7434521317481995}, {"text": "term extraction", "start_pos": 180, "end_pos": 195, "type": "TASK", "confidence": 0.7353706955909729}]}, {"text": "A few previous studies mentioned the application of corpora as potential electronic tools for the interpreters. and discussed the functions of specific online crawling tools and explored ways to extract specialised terminology from disposable web corpora for interpreters.", "labels": [], "entities": []}, {"text": "Our work is most closely connected to Fantinuoli's work on evaluation of termlists obtained from Webderived corpora.", "labels": [], "entities": []}, {"text": "However, that study relied on a single method of corpus collection and term extraction, and did not include an investigation into integration of corpus research into practice of interpreter training.", "labels": [], "entities": [{"text": "corpus collection", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7199124544858932}, {"text": "term extraction", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.7168291360139847}]}, {"text": "R\u00fctten (2003) suggested a conceptual software model for interpreters' terminology management, in which termlists are expected to be extracted (semi-)automatically and then to be revised by their users, the interpreters, who can concentrate on those terms which are relevant and important to remember.", "labels": [], "entities": [{"text": "terminology management", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.7640942931175232}]}, {"text": "However the study neither tested the functions of the term extraction tools nor further discussed interpreters' perception on the usefulness of the automatically lists in their preparation for interpreting tasks.: Corpora used in this study (the size is in words for En, in characters for Zh) Based on R\u00fctten model, this paper will further test the functions of several term extraction tools for English and Chinese, and will discuss the interpreters' perception on the usefulness of the automaticallygenerated lists in their preparation for interpreting tasks.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 370, "end_pos": 385, "type": "TASK", "confidence": 0.779156357049942}]}], "datasetContent": [{"text": "specialised terms that were manually extracted by the terminologist (and are contained in the reference term list);  2.", "labels": [], "entities": []}, {"text": "highly specialised terms that were not detected by the terminologist; 3.", "labels": [], "entities": []}, {"text": "non-specialised terms that are commonly used in the field of his study (medicine); 4.", "labels": [], "entities": []}, {"text": "general terms that are not specific to the medical field; 5.", "labels": [], "entities": []}, {"text": "ill-formed, incomplete expressions and fragments.", "labels": [], "entities": []}, {"text": "Our annotation system extends Fantinuoli's study because the purpose of annotation in this project is to give the interpreters possibility to extract relevant terms from all the candidate terms regardless of their levels of specialisation.", "labels": [], "entities": []}, {"text": "Our premise is that interpreters may need relevant terms, both highly specialised and less specialised, in order to prepare themselves fora conference.", "labels": [], "entities": []}, {"text": "The annotators are the end users of the list, i.e. the trainee interpreters who participated in this research.", "labels": [], "entities": []}, {"text": "Since the interpreters are tasked with translating speeches in the domain, they need themselves to decide what is likely to be relevant instead of relying on the terminologists who describe the overall structure of the domain.", "labels": [], "entities": []}, {"text": "It only took several minutes to generate a termlist after uploading the designated corpus onto TTC TermSuite, Syllabs Tools and TeaBoat.", "labels": [], "entities": [{"text": "TTC TermSuite", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.9449909031391144}, {"text": "TeaBoat", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.9675672650337219}]}, {"text": "Each of them automatically generated corresponding monolingual termlists sorted by their term specificity scores.", "labels": [], "entities": []}, {"text": "For all the tools we set the threshold of obtaining 500 terms (if possible), as a practical limit for all evaluation experiments.", "labels": [], "entities": []}, {"text": "The trainee interpreters were asked to annotate the list by using the above annotation system.", "labels": [], "entities": []}, {"text": "Each of them reported that it took them about 60 minutes to annotate both lists (in EN & ZH) on each of the topics (FR & SM).", "labels": [], "entities": [{"text": "FR & SM)", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.5941671058535576}]}, {"text": "All the annotators were briefed about what counts as terms and the annotation system before they started their evaluation of term lists.", "labels": [], "entities": []}, {"text": "We aim for consistency, yet inter-annotator disagreement does exist and there is a certain degree of subjectivity in annotation.", "labels": [], "entities": []}, {"text": "To measure the level of agreement we used Krippendorff's \u03b1 over the other measures, such as Fleiss' \u03ba, because Krippendorff's \u03b1 offers an extension of such measures as Fleiss' \u03ba and Scott's \u03c0 by introducing a distance metric for the pairwise disagreements, thus making it possible to work with interval-scale ratings, e.g., considering disagreement between Rand P as less severe than between Rand I (.", "labels": [], "entities": []}, {"text": "The values of Krippendorff's \u03b1 (see) are relatively low.", "labels": [], "entities": []}, {"text": "The most common cases of disagreement are between Rand P (the boundary between them often depends on the amount of knowledge on the side of the annotator), but also quite surprisingly between Rand IL, when some annotators interpret ill-formed sequences as a contribution to useful terms.", "labels": [], "entities": []}, {"text": "With the disagreement taken into consideration, our evaluation on the number of relevant terms was judged by the agreement between at least two annotators among four to six annotators for the topic of FR.", "labels": [], "entities": [{"text": "FR", "start_pos": 201, "end_pos": 203, "type": "TASK", "confidence": 0.5582232475280762}]}, {"text": "This established the gold standard lists reported in.", "labels": [], "entities": [{"text": "gold standard lists", "start_pos": 21, "end_pos": 40, "type": "DATASET", "confidence": 0.7391241788864136}]}, {"text": "The annotation results from   relevant terms from FR2.", "labels": [], "entities": [{"text": "FR2", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.9475528597831726}]}, {"text": "In addition, Syllabs' and TeaBoat's English lists contain more specialised terms in the domain of FR, such as defence-in-depth, once-through fuel cycle, suppression chamber of the containment, etc.", "labels": [], "entities": [{"text": "Syllabs'", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.8859015703201294}, {"text": "TeaBoat's English lists", "start_pos": 26, "end_pos": 49, "type": "DATASET", "confidence": 0.8443327695131302}, {"text": "FR", "start_pos": 98, "end_pos": 100, "type": "TASK", "confidence": 0.753584086894989}, {"text": "suppression chamber of the containment", "start_pos": 153, "end_pos": 191, "type": "TASK", "confidence": 0.7377761602401733}]}, {"text": "These specialised terms with relatively low frequency are not included in the TTC's list.", "labels": [], "entities": [{"text": "TTC's list", "start_pos": 78, "end_pos": 88, "type": "DATASET", "confidence": 0.8990105589230856}]}, {"text": "The terms included in TTC's list are more general terms, such as steam, energy, liquid, heat, leak, etc., which are likely to be already known by the trainee interpreters.", "labels": [], "entities": [{"text": "TTC's list", "start_pos": 22, "end_pos": 32, "type": "DATASET", "confidence": 0.9105741381645203}]}, {"text": "The English termlists from all the tools contain a number of repetitions in the form of term variants, following Daille's definition as \"an utterance which is semantically and conceptually related to an original term\").", "labels": [], "entities": []}, {"text": "The annotation results from for Chinese show, both Syllabs' and Teaboat's lists offer obviously less relevant terms from FR1 compared with the English lists.", "labels": [], "entities": [{"text": "Syllabs'", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.8836849927902222}, {"text": "Teaboat's lists", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.8645554780960083}, {"text": "FR1", "start_pos": 121, "end_pos": 124, "type": "DATASET", "confidence": 0.9158439636230469}]}, {"text": "When we further investigate the distribution of the term classes in annotations in, Syllabs' Chinese list on FR1 contains a large number of ill-formed constructions, including incomplete terms, eg. \u6c34\u5806 'water reactor', \u91cc\u5c9b\u6838\u7535 \u7ad9 'Mile Island nuclear plant' and longer chunks, eg. \u6700\u5927\u7a0b\u5ea6\u4e0a\u4fdd\u8bc1\u4e86\u94a0, \u53ef\u7528\u538b\u6c34\u5806\u540e\u5904\u7406\u5f97 \u5230\u7684\u949a\u4f5c\u4e3a\u6838\u71c3\u6599.", "labels": [], "entities": [{"text": "Syllabs' Chinese list", "start_pos": 84, "end_pos": 105, "type": "DATASET", "confidence": 0.694095253944397}, {"text": "FR1", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.5336666107177734}, {"text": "Mile Island nuclear plant", "start_pos": 226, "end_pos": 251, "type": "DATASET", "confidence": 0.9265439212322235}]}, {"text": "Teaboat's list contains a number of general words, eg. \u5f00\u53d1 'development', \u751f\u4ea7 'production' or \u5de5\u7a0b 'project'.", "labels": [], "entities": [{"text": "Teaboat's list", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9686891436576843}]}, {"text": "Both categories (G and IL) are frequent in the TTC's Chinese list.", "labels": [], "entities": [{"text": "G", "start_pos": 17, "end_pos": 18, "type": "METRIC", "confidence": 0.9838566780090332}, {"text": "TTC's Chinese list", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.9090988785028458}]}, {"text": "On the basis of these results, we selected a single tool (Syllabs) with comparatively better performance in both languages to generate termlists on SM1 (En & Zh) and asked 12 annotators to select the relevant terms and learn the terms during their interpreting preparation.", "labels": [], "entities": [{"text": "interpreting preparation", "start_pos": 248, "end_pos": 272, "type": "TASK", "confidence": 0.8750512599945068}]}, {"text": "Among the 500 candidate terms for English, 441 terms were agreed as relevant by at least two annotators, 266 terms were agreed by five annotators.", "labels": [], "entities": []}, {"text": "Precision rates are 88.2% and 53.2% respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9921104311943054}]}, {"text": "On the other hand, only 130 terms were agreed as relevant by two annotators from the 500 Chinese candidate terms.", "labels": [], "entities": []}, {"text": "The precision rate for the Chinese list is 26%.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9864389598369598}, {"text": "Chinese list", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.9538513123989105}]}, {"text": "The results basically replicate the previous findings on FR1.", "labels": [], "entities": [{"text": "FR1", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.5661337971687317}]}, {"text": "The other pattern we observe from the current data is that the larger the corpus is, the more relevant terms the tools can generate.", "labels": [], "entities": []}, {"text": "If the corpus is of very limited size (eg. FR0-en has only 774 words), the TTC TermSuite fails to generate any list fora 'corpus' of only 774 words, while the Syllabs and Teaboat tools produce shorter lists of 104 or 56 terms respectively.", "labels": [], "entities": [{"text": "FR0-en", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.8436397910118103}, {"text": "TTC TermSuite", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.9018032252788544}, {"text": "Teaboat", "start_pos": 171, "end_pos": 178, "type": "DATASET", "confidence": 0.870394766330719}]}, {"text": "The situation is similar to other studies which used small (single-document) corpora, e.g.,).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpora used in this study (the size is in words for En, in characters for Zh)", "labels": [], "entities": []}, {"text": " Table 3: Krippendorff's \u03b1 for different term lists", "labels": [], "entities": []}, {"text": " Table 5: Distribution of term annotation classes", "labels": [], "entities": []}]}