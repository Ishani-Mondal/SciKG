{"title": [{"text": "Combining strategies for tagging and parsing Arabic", "labels": [], "entities": [{"text": "tagging", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9672704935073853}, {"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.6959408521652222}]}], "abstractContent": [{"text": "We describe a simple method for combining taggers which produces substantially better performance than any of the contributing tools.", "labels": [], "entities": []}, {"text": "The method is very simple, but it leads to considerable improvements in performance: given three taggers for Arabic whose individual accuracies range from 0.956 to 0.967, the combined tagger scores 0.995-a seven-fold reduction in the error rate when compared to the best of the contributing tools.", "labels": [], "entities": [{"text": "error rate", "start_pos": 234, "end_pos": 244, "type": "METRIC", "confidence": 0.9723499715328217}]}, {"text": "Given the effectiveness of this approach to combining taggers, we have investigated its applicability to parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 105, "end_pos": 112, "type": "TASK", "confidence": 0.9833655953407288}]}, {"text": "For parsing, it seems better to take pairs of similar parsers and back off to a third if they disagree.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9867956638336182}]}], "introductionContent": [{"text": "If you have several systems that perform the same task, it seems reasonable to suppose that you can obtain better performance by using some judicious combination of them than can be obtained by any of them in isolation.", "labels": [], "entities": []}, {"text": "A large number of combining strategies have been proposed, with majority voting being particularly popular ().", "labels": [], "entities": []}, {"text": "We have investigated a range of such strategies for combining taggers and parsers for Arabic: the best strategy we have found for tagging involves asking each of the contributing taggers how confident it is, and accepting the answer given by the most confident one.", "labels": [], "entities": []}, {"text": "We hypothesise that the reason for the effectiveness of this strategy for tagging arises from the fact that the contributing taggers work in essentially different ways (different training data, different underlying algorithms), and hence if they make systematic mistakes these will tend to be different.", "labels": [], "entities": [{"text": "tagging", "start_pos": 74, "end_pos": 81, "type": "TASK", "confidence": 0.9742580056190491}]}, {"text": "This means, in turn, that the places where they don't make mistakes will be different.", "labels": [], "entities": []}, {"text": "This strategy is less effective for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9881340861320496}]}, {"text": "We have tried combining two members of the MALTParser family) with MSTParser ().", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.863141655921936}]}, {"text": "The best strategy here seems to be to accept the output of the two versions of MALTParser when they agree, but to switch to MSTParser if the MALTParser versions disagree.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 124, "end_pos": 133, "type": "DATASET", "confidence": 0.917809009552002}]}, {"text": "It maybe that this is because the MALTParser versions are very similar, so that when they disagree this suggests that there is something anomalous about the input text, and that neither of them can be trusted at this point.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Tagger accuracies in isolation, with and  without TBR", "labels": [], "entities": [{"text": "TBR", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.803093671798706}]}, {"text": " Table 4: Modified majority voting vs proposed strategy", "labels": [], "entities": [{"text": "Modified majority voting", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8785512844721476}]}, {"text": " Table 5: Labelled accuracy (LA) for various combinations of MSTParser, MALTParser 1 and  MALTParser 2 five fold cross-validation with 4000 training sentences and 1000 testing", "labels": [], "entities": [{"text": "Labelled accuracy (LA)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8960707068443299}]}]}