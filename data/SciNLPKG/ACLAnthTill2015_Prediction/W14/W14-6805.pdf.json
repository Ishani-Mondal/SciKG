{"title": [{"text": "Improving Bilingual Lexicon Extraction Performance from Comparable Corpora via Optimizing Translation Candidate Lists", "labels": [], "entities": [{"text": "Improving Bilingual Lexicon Extraction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8860637843608856}]}], "abstractContent": [{"text": "In this paper, we propose a novel method to optimize translation candidate lists derived from window-based approach for the task of bilingual lexicon extraction.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 132, "end_pos": 160, "type": "TASK", "confidence": 0.6577757696310679}]}, {"text": "The optimizing process consists of two cross-comparisons between 1 th translation candidate of each target word, and between set of all the 1 th candidates and that of each word's 2 th to N th ones.", "labels": [], "entities": []}, {"text": "Experiment results demonstrate that the proposed method leads to a significant improvement on accuracy over window-based approach in bilingual lexicon extraction from both English-Chinese and Chinese-English comparable corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9991533756256104}, {"text": "bilingual lexicon extraction", "start_pos": 133, "end_pos": 161, "type": "TASK", "confidence": 0.6937284270922343}]}], "introductionContent": [{"text": "Bilingual lexicon is a basic resource in the field of Natural Language Processing such as machine translation and cross-language information retrieval (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7986738681793213}, {"text": "cross-language information retrieval", "start_pos": 114, "end_pos": 150, "type": "TASK", "confidence": 0.71289990345637}]}, {"text": "Parallel corpora) are typically applied to automatically extracting bilingual lexicon with high precision, but they are difficult to obtain in several domains.", "labels": [], "entities": [{"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9827544093132019}]}, {"text": "Due to the high cost of acquiring parallel corpora, comparable corpora, which consist of sets of documents in different languages dealing with a given topic or domain and are much easier to collect from the increasingly rich web data (), become an alternative resource to the task.", "labels": [], "entities": []}, {"text": "Based on comparable corpora, researchers begin to use a variety of approaches to exploit them for bilingual lexicon extraction in recent years ().", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 98, "end_pos": 126, "type": "TASK", "confidence": 0.661957840124766}]}, {"text": "These approaches mainly share a standard strategy based on the assumption that a word and its translation appear in similar context.", "labels": [], "entities": []}, {"text": "These previous work shows that equivalent extraction from comparable corpora is unstable on all but the most frequent words.", "labels": [], "entities": [{"text": "equivalent extraction from comparable corpora", "start_pos": 31, "end_pos": 76, "type": "TASK", "confidence": 0.8689060091972352}]}, {"text": "An explanation for the phenomenon is that translation candidate lists of target words, coming from matrix of context similarities, are always disturbed by lots of noises introduced by many-to-many mapping between the contexts of words in different languages and only more frequent ones keep comparatively robust).", "labels": [], "entities": [{"text": "translation candidate lists of target words", "start_pos": 42, "end_pos": 85, "type": "TASK", "confidence": 0.8539508779843649}]}, {"text": "Regardless of the polysemy, in the candidate list of a certain target word, there maybe only one correct candidate and the rest ones can be regarded as noises.", "labels": [], "entities": []}, {"text": "Moreover, the correct candidate of one target word may become the noise in the candidate list of another target one.", "labels": [], "entities": []}, {"text": "Therefore, to retain the correct candidate in one list and remove it (viewed as noise) from others' list when it appears, comparison between candidates in each list need to be done.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel method to remove these noises via optimizing translation candidate lists.", "labels": [], "entities": []}, {"text": "The optimizing process is on the basis of cross-comparison which means comparison object lies on different candidate lists.", "labels": [], "entities": []}, {"text": "Firstly, we adopt window-based approach to acquire translation candidate lists).", "labels": [], "entities": []}, {"text": "Then, we use the proposed two cross-comparisons of similarity.", "labels": [], "entities": []}, {"text": "The first one called identical ranking cross-comparison is the comparison between 1 th translation candidate of each target word.", "labels": [], "entities": []}, {"text": "The second named distinct ranking cross-comparison is the comparison between set of all the 1 th candidates and that of each word's 2 th to N th ones.", "labels": [], "entities": []}, {"text": "Finally, we conduct the experiments to find target words with different frequencies from both Chinese-English and English-Chinese.", "labels": [], "entities": []}, {"text": "The organization of the paper is as follows: Related work is presented in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 is devoted to the introduction of window-based approach.", "labels": [], "entities": []}, {"text": "In Section 4, we present the proposed optimizing process.", "labels": [], "entities": []}, {"text": "In Section 5 we describe the experimental setup and report the results of bilingual lexicon extraction.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.7210561235745748}]}, {"text": "Section 6 summarizes the paper with a final conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on a Chinese-English corpora derived from the data used in bilingual Wikipedia with 3254 comparable document pairs.", "labels": [], "entities": []}, {"text": "The general bilingual dictionary is constructed from an online dictionary which contains 42,373 distinct entries.", "labels": [], "entities": []}, {"text": "In addition, we perform the following linguistic preprocessing stepson the comparable corpora: tokenization, lemmatization and removing stop words.", "labels": [], "entities": []}, {"text": "After these steps the corpora contain ca.", "labels": [], "entities": []}, {"text": "925,000 Chinese words, and ca.", "labels": [], "entities": []}, {"text": "The windows size \u03b2 in building the context vectors is defined as 5, and different sizes are assessed and the above setting turns out to have the best performance in window-based method.", "labels": [], "entities": []}, {"text": "Two experiments are performed on target words with random frequency distribution and certain frequency in order to evaluate the proposed method.", "labels": [], "entities": []}, {"text": "During each experiment we also absorb in the extraction performance from both English-Chinese and Chinese-English.", "labels": [], "entities": []}, {"text": "The baseline in our experiments is the window-based approach without any optimizing, and we successively use two cross-comparisons in the proposed method and focus on performance respectively.", "labels": [], "entities": []}, {"text": "We adopt the accuracy as evaluation metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9996552467346191}]}, {"text": "Accuracy, which means precision among the top n ranking, is a common metric in bilingual lexicon extraction.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9944843649864197}, {"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9988608360290527}, {"text": "bilingual lexicon extraction", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.6661788821220398}]}, {"text": "In this paper, translation candidates in lists from 1 th to 20 th ranking are kept for automatic and manual evaluation of accuracy, and score of accuracy is calculated in the following equation: Where n means top n evaluation (n ranging from 1 to 20), M means the number of target words and n top count means the number of correct translation in top n ranking.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.998684823513031}, {"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9989711046218872}]}], "tableCaptions": [{"text": " Table 1: Ranked lists from window-based approach", "labels": [], "entities": []}, {"text": " Table 2: Lists after identical ranking cross-comparison", "labels": [], "entities": []}, {"text": " Table 3: Final optimized lists", "labels": [], "entities": []}]}