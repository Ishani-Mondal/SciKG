{"title": [{"text": "Integrated Tools for Query-driven Development of Light-weight Ontologies and Information Extraction Components", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper reports on a user-friendly terminology and information extraction development environment that integrates into existing infrastructure for natural language processing and aims to close a gap in the UIMA community.", "labels": [], "entities": [{"text": "information extraction development", "start_pos": 54, "end_pos": 88, "type": "TASK", "confidence": 0.7771639327208201}]}, {"text": "The tool supports domain experts in data-driven and manual terminology refinement and refactoring.", "labels": [], "entities": [{"text": "terminology refinement", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7001240998506546}]}, {"text": "It can propose new concepts and simple relations and includes an information extraction algorithm that considers the context of terms for disambigua-tion.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7952989041805267}]}, {"text": "With its tight integration of easy-to-use and technical tools for component development and resource management, the system is especially designed to shorten times necessary for domain adaptation of such text processing components.", "labels": [], "entities": []}, {"text": "Search support provided by the tool fosters this aspect and is helpful for building natural language processing modules in general.", "labels": [], "entities": []}, {"text": "Specialized queries are included to speedup several tasks, for example, the detection of new terms and concepts, or simple quality estimation without gold standard documents.", "labels": [], "entities": [{"text": "detection of new terms and concepts", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.85658926765124}]}, {"text": "The development environment is modular and extensible by using Eclipse and the Apache UIMA framework.", "labels": [], "entities": []}, {"text": "This paper describes the system's architecture and features with a focus on search support.", "labels": [], "entities": []}, {"text": "Notably, this paper proposes a generic middleware component for queries in a UIMA based workbench.", "labels": [], "entities": []}], "introductionContent": [{"text": "According to general understanding, a specification of relevant concepts, relations, and their types is required to build Information Extraction (IE) components.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 122, "end_pos": 149, "type": "TASK", "confidence": 0.7149463534355164}]}, {"text": "Named Entity Recognition (NER) systems in the newspaper domain, for example, try to detect concepts like persons, organizations, or locations.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7621919910113016}]}, {"text": "Regarding clinical text, it has been shown that lookup-based approaches) can achieve high precision and recall if a terminology exists that maps terms to their meanings.", "labels": [], "entities": [{"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9979016780853271}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.998798131942749}]}, {"text": "However, this approach is not directly applicable if such resources are not available fora certain language or subdomain, or if the domain and its terminology are changing.", "labels": [], "entities": []}, {"text": "Unsupervised methods can help to find and to group the relevant terms of a domain, for example, into concept hierarchies ( ).", "labels": [], "entities": []}, {"text": "Nevertheless, automatically derived terminologies are not perfect, and there are many applications that require high precision knowledge resources and representations, for instance, to buildup a clinical data warehouse.", "labels": [], "entities": []}, {"text": "In this case, automatically generated ontologies have to be refined by domain experts like clinicians, which imposes special requirements on the usability of the tools.", "labels": [], "entities": []}, {"text": "There have been several efforts to support ontology extraction and refinement), predominantly with text processing based on the GATE) infrastructure.", "labels": [], "entities": [{"text": "ontology extraction", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8622629046440125}]}, {"text": "In the Apache UIMA () community 1 , several tools exist that ease system development and management.", "labels": [], "entities": []}, {"text": "Much work has, for instance, been spent on pipeline management, rule development (, or evaluation.", "labels": [], "entities": [{"text": "pipeline management", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.921014815568924}, {"text": "rule development", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.9394737482070923}]}, {"text": "Terminology and ontology development support, however, have not gained as much attention in the context of this framework by now.", "labels": [], "entities": []}, {"text": "This is surprising since the integration of tools for terminology development and especially terminology generation and information extraction into existing infrastructure for text processing is promising.", "labels": [], "entities": [{"text": "terminology development", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.946410596370697}, {"text": "terminology generation", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.8938648402690887}, {"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7155400812625885}]}, {"text": "Actually, the approach taken in this paper regards terminology creation and information extraction as two related tasks.", "labels": [], "entities": [{"text": "terminology creation", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.933066338300705}, {"text": "information extraction", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.8330193758010864}]}, {"text": "The proposed system aims to assist users in the development of components that extract information with lexical resources gathered during the specification of the concepts of the domain.", "labels": [], "entities": []}, {"text": "This paper introduces Edtgar: a user-friendly integrated terminology development environment.", "labels": [], "entities": []}, {"text": "It provides many features that help domain experts to construct and refine light-weight ontologies driven by flexible corpus queries.", "labels": [], "entities": []}, {"text": "In this work, \"light-weight ontology\" means that we focus on simple relations, as well as restricted inference.", "labels": [], "entities": []}, {"text": "We call the knowledge representation \"terminology\" since the tool aims to manage lexical information for information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.7886066436767578}]}, {"text": "The major components of the system area terminology editor, a plug-in concept for terminology extraction and an information extraction API, as well as support for corpus queries.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.8969274461269379}, {"text": "information extraction", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.7196751236915588}]}, {"text": "Special views show extraction statistics, provide semi-automatic annotation of gold standard documents, as well as evaluation and deployment support.", "labels": [], "entities": []}, {"text": "The tool comprises an implementation for terminology induction and an information extraction algorithm that considers contexts.", "labels": [], "entities": [{"text": "terminology induction", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.9435057640075684}, {"text": "information extraction", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.797687441110611}]}, {"text": "In order to keep the system modular and extensible, it integrates into Eclipse 2 and uses the Apache UIMA framework.", "labels": [], "entities": []}, {"text": "Apache UIMA provides a well-established framework for text processing, hence, a variety of natural language processing components can easily be integrated, for example, by accessing component repositories like DKPro Core . At the technical level, the default processing components of the proposed system use a combination of Apache UIMA Ruta 4 scripts and custom analysis engines implemented in Java.", "labels": [], "entities": [{"text": "text processing", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7121354937553406}]}, {"text": "As a consequence, the tight integration of the terminology development tools into Apache UIMA's Eclipse Tools and Apache UIMA Ruta's rule engine and workbench allows technical engineers to use several existing features.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows: Section 2 gives a brief overview of ontology development systems and tools.", "labels": [], "entities": []}, {"text": "Section 3 and 4 introduce the tool and its support for corpus queries.", "labels": [], "entities": []}, {"text": "Results of a case study are given in Section 5.", "labels": [], "entities": [{"text": "Section", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.7109555602073669}]}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Similar to quality assurance or quality assessment in factories, users can specify assertions for text processing tasks where system behavior is expected to conform to these assertions (.", "labels": [], "entities": []}, {"text": "Such expectations allow to compute quality estimates even without annotated documents.", "labels": [], "entities": []}, {"text": "To this end, we provide special annotation types for these cases that can be categorized to distinguish different tasks or types of misclassifications.", "labels": [], "entities": []}, {"text": "By now, knowledge-driven evaluation is realized by the contributed search commands (see Section 4).", "labels": [], "entities": []}, {"text": "They allow to find, count, and group constraint violations which helps to estimate the quality of the text processing component and to understand the errors it makes.", "labels": [], "entities": []}, {"text": "For example, the user can expect that all nouns should either be assigned to a concept annotation or listed in a blacklist.", "labels": [], "entities": []}, {"text": "Elaboration of this aspect of the tool is planned for future releases.", "labels": [], "entities": []}], "tableCaptions": []}