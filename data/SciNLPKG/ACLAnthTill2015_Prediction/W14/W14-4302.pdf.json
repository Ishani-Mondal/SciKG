{"title": [{"text": "Crowdsourcing Street-level Geographic Information Using a Spoken Dialogue System", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a technique for crowd-sourcing street-level geographic information using spoken natural language.", "labels": [], "entities": []}, {"text": "In particular, we are interested in obtaining first-person-view information about what can be seen from different positions in the city.", "labels": [], "entities": []}, {"text": "This information can then for example be used for pedestrian routing services.", "labels": [], "entities": [{"text": "pedestrian routing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8761976957321167}]}, {"text": "The approach has been tested in the lab using a fully implemented spoken dialogue system, and has shown promising results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Crowdsourcing is increasingly being used in speech processing for tasks such as speech data acquisition, transcription/labeling, and assessment of speech technology, e.g. spoken dialogue systems).", "labels": [], "entities": [{"text": "speech processing", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7316190600395203}, {"text": "speech data acquisition", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.6504190762837728}, {"text": "transcription/labeling", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8253770470619202}]}, {"text": "However, we are not aware of any attempts where a dialogue system is the vehicle for crowdsourcing rather than the object of study, that is, where a spoken dialogue system is used to collect information from a large body of users.", "labels": [], "entities": []}, {"text": "A task where such crowdsourcing dialogue systems would be useful is to populate geographic databases.", "labels": [], "entities": []}, {"text": "While there are now open databases with geographic information, such as OpenStreetMap, these are typically intended for map drawing, and therefore lack detailed streetlevel information about city landmarks, such as colors and height of buildings, ornamentations, facade materials, balconies, conspicuous signs, etc.", "labels": [], "entities": [{"text": "map drawing", "start_pos": 120, "end_pos": 131, "type": "TASK", "confidence": 0.7597327530384064}]}, {"text": "Such information could for example be very useful for pedestrian navigation).", "labels": [], "entities": [{"text": "pedestrian navigation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.8280066549777985}]}, {"text": "With the current growing usage of smartphones, we might envisage a community of users using their phones to contribute information to geographic databases, annotating cities to a great level of detail, using multi-modal method including speech.", "labels": [], "entities": []}, {"text": "The key reason for using speech for map annotation is convenience; it is easy to talk into a mobile phone while walking down the street, so a user with a little experience will not be slowed down by the activity of interacting with a database.", "labels": [], "entities": [{"text": "map annotation", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.7729814052581787}]}, {"text": "This way, useful information could be obtained that is really hard to add offline, sitting in front of one's PC using a map interface, things like: Can you see X from this point?", "labels": [], "entities": []}, {"text": "Is there a big sign over the entrance of the restaurant?", "labels": [], "entities": []}, {"text": "What color is the building on your right?", "labels": [], "entities": []}, {"text": "Another advantage of using a spoken dialogue system is that the users could be asked to freely describe objects they consider important in their current view.", "labels": [], "entities": []}, {"text": "In this way, the system could learn new objects not anticipated by the system designers, and their associated properties.", "labels": [], "entities": []}, {"text": "In this paper we present a proof-of-concept study of how a spoken dialogue system could be used to enrich geographic databases by crowdsourcing.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first attempt at using spoken dialogue systems for crowdsourcing in this way.", "labels": [], "entities": []}, {"text": "In Section 2, we elaborate on the need of spoken dialogue systems for crowdsourcing geographic information.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the dialogue system implementation.", "labels": [], "entities": []}, {"text": "Section 4 presents our in-lab crowdsourcing experiment.", "labels": [], "entities": []}, {"text": "We present an analysis of crowd-sourced data in Section 5, and discuss directions for future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Nine visual scenes (wide-angle pictures in firstperson perspective and taken in Stockholm city, cf.) were used for the task of crowdsourcing.", "labels": [], "entities": []}, {"text": "Fifteen human participants (4 females and 11 males) participated in the crowdsourcing exercise.", "labels": [], "entities": []}, {"text": "All participants either studied or worked at the School of Computer Science and Communication, KTH, Stockholm.", "labels": [], "entities": []}, {"text": "Participants were placed in front of a computer display and were told that the system will engage them in a spoken conversation to seek or clarify details about landmarks and other objects in visual scenes.", "labels": [], "entities": []}, {"text": "They were told that the details would be used for pedestrian routing and therefore they are free to choose and specify details (in openended questions) that they thought would be useful when giving route instructions to another person.", "labels": [], "entities": [{"text": "pedestrian routing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.906724601984024}]}, {"text": "Each participant did the nine visual scenes in the same order, with a 1 minute pause between each of them.", "labels": [], "entities": []}, {"text": "The first visual scene was used as atrial in order to familiarize participants with the interaction scenario.", "labels": [], "entities": []}, {"text": "For this reason, the trial interaction was specifically designed to engage the participants in both wh-and yes-no type questions.", "labels": [], "entities": []}, {"text": "We also wanted to investigate whether the use of wh-or yes-no questions alone has any impact on the interactions.", "labels": [], "entities": []}, {"text": "For the remaining eight interactions, the dialogue system therefore alternatively used wh-and yes-no questions throughout the whole dialogue.", "labels": [], "entities": []}, {"text": "The order of query types was switched for each successive participant.", "labels": [], "entities": []}, {"text": "Thus visual scenes presented with whqueries to a participant pi were presented to participant p i+1 with only yes-no queries, and viceversa.", "labels": [], "entities": []}, {"text": "After each interaction participants were asked (1) whether the system appeared to be familiar with the visual scene; and (2) whether the interactions went smoothly.", "labels": [], "entities": []}, {"text": "An example of a conversation with wh-type queries is presented in.", "labels": [], "entities": []}, {"text": "The second column indicates the various types of utterances (dialogue acts) used by the system during this interaction.", "labels": [], "entities": []}, {"text": "Note that during the slot-filling mode, the system has the initiative, whereas in the open-ended queries (cf. rows 15-22 in) the system gives the initiative to the participant and only produces feedback responses.", "labels": [], "entities": []}, {"text": "Table 2 presents a conversation with yes-no queries following the conversation in.", "labels": [], "entities": []}, {"text": "Ina conversation with only yes-no queries, a wh-query maybe presented if a slot has been observed with no-value (cf. rows 9-10 in) or when the participant disputes the system's current best estimate (cf. rows 6-9 in).", "labels": [], "entities": []}, {"text": "As described above, the participants filled in a questionnaire after each interaction.", "labels": [], "entities": []}, {"text": "They were asked to rate the system's familiarity with the visual scene based on the questions asked.", "labels": [], "entities": []}, {"text": "A Mann-Whitney U test suggests that participants' perception of the system's familiarity with the visual scene was significantly higher for interactions with yes-no queries than interactions with wh-queries (U=1769.5, p= 0.007).", "labels": [], "entities": [{"text": "U=1769.5", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.8906219800313314}]}, {"text": "This result has implications for the design choice for systems that provide as well as ask for information from users.", "labels": [], "entities": []}, {"text": "For example, a pedestrian routing system can already be used to offer routing instructions as well as crowdsourcing information.", "labels": [], "entities": [{"text": "pedestrian routing", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7813889980316162}]}, {"text": "The system is more likely to give an impression of familiarity with the surrounding, to the user, by asking yes-no type questions than whquestions.", "labels": [], "entities": []}, {"text": "This may influence a user's confidence or trust in using the routing system.", "labels": [], "entities": []}, {"text": "Since yes-no questions expect a \"yes\" or \"no\" in response, we therefore hypothesized that interactions with yes-no questions would be perceived smoother in comparison to interactions with wh-questions.", "labels": [], "entities": []}, {"text": "However, a Mann-Whitney U test suggests that the participants perceived no significant difference between the two interaction types (U=1529.0, p= 0.248).", "labels": [], "entities": [{"text": "U", "start_pos": 133, "end_pos": 134, "type": "METRIC", "confidence": 0.9880016446113586}]}, {"text": "Feedback comments from participants suggest that abrupt ending of open-ended interactions by the system (due to the simplistic model of detecting whether the user has anything more to say) gave users an impression that the system is not allowing them to speak.", "labels": [], "entities": []}], "tableCaptions": []}