{"title": [{"text": "Grounding Language with Points and Paths in Continuous Spaces", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a model for generating path-valued interpretations of natural language text.", "labels": [], "entities": []}, {"text": "Our model encodes a map from natural language descriptions to paths, mediated by segmentation variables which break the language into a discrete set of events, and alignment variables which reorder those events.", "labels": [], "entities": []}, {"text": "Within an event, lexical weights capture the contribution of each word to the aligned path segment.", "labels": [], "entities": []}, {"text": "We demonstrate the applicability of our model on three diverse tasks: anew color description task, anew financial news task and an established direction-following task.", "labels": [], "entities": []}, {"text": "On all three, the model outperforms strong baselines, and on a hard variant of the direction-following task it achieves results close to the state-of-the-art system described in Vogel and Jurafsky (2010).", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper introduces a probabilistic model for predicting grounded, real-valued trajectories from natural language text.", "labels": [], "entities": [{"text": "predicting grounded, real-valued trajectories from natural language text", "start_pos": 48, "end_pos": 120, "type": "TASK", "confidence": 0.8367409573660957}]}, {"text": "A long tradition of research in compositional semantics has focused on discrete representations of meaning.", "labels": [], "entities": [{"text": "compositional semantics", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.7827999889850616}]}, {"text": "The original focus of such work was on logical translation: mapping statements of natural language to a formal language like first-order logic) or database queries.", "labels": [], "entities": [{"text": "logical translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7563702166080475}]}, {"text": "Subsequent work has integrated this logical translation with interpretation against a symbolic database (.", "labels": [], "entities": []}, {"text": "There has been a recent increase in interest in perceptual grounding, where lexical semantics anchor in perceptual variables (points, distances, etc.) derived from images or video.", "labels": [], "entities": []}, {"text": "describe a procedure for constructing word representations using text-and image-based dis- U.S. stocks rebound after bruising two-day swoon: Example stock data.", "labels": [], "entities": []}, {"text": "The chart displays index value over a two-day period (divided by the dotted line), while the accompanying headline describes the observed behavior.", "labels": [], "entities": [{"text": "index value", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.9780349731445312}]}, {"text": "describe a model for identifying scenes given descriptions, and,, and describe models for identifying individual components of scenes described by text.", "labels": [], "entities": []}, {"text": "These all have the form of matching problems between text and observed groundings-what has been missing so far is the ability to generate grounded interpretations from scratch, given only text.", "labels": [], "entities": []}, {"text": "Our work continues in the tradition of this perceptual grounding work, but makes two contributions.", "labels": [], "entities": []}, {"text": "First, our approach is able to predict simple world states (and their evolution): fora general class of continuous domains, we produce a representation of p(world | text) that admits easy sampling and maximization.", "labels": [], "entities": []}, {"text": "This makes it possible to produce grounded interpretations of text without reference to a pre-existing scene.", "labels": [], "entities": []}, {"text": "Simultaneously, we extend the range of temporal phenomena that can be modeled-unlike the aforementioned spatial semantics work, we consider language that de-scribes time-evolving trajectories, and unlike, we allow these trajectories to have event substructure, and model temporal ordering.", "labels": [], "entities": []}, {"text": "Our class of models generalizes to a variety of different domains: anew color-picking task, anew financial news task, and a more challenging variant of the direction-following task established by.", "labels": [], "entities": []}, {"text": "As an example of the kinds of phenomena we want to model, consider, which shows the value of the Dow Jones Industrial Average over June 3rd and 4th 2008, along with a financial news headline from June 4th.", "labels": [], "entities": [{"text": "Dow Jones Industrial Average over June 3rd and 4th 2008", "start_pos": 97, "end_pos": 152, "type": "DATASET", "confidence": 0.9165048956871032}]}, {"text": "There are several effects of interest here.", "labels": [], "entities": []}, {"text": "One phenomenon we want to capture is that the lexical semantics of individual words must be combined: swoon roughly describes a drop while bruising indicates that the drop was severe.", "labels": [], "entities": []}, {"text": "We isolate this lexical combination in Section 4, where we consider a limited model of color descriptions (.", "labels": [], "entities": []}, {"text": "A second phenomenon is that the description is composed of two separate events, a swoon and a rebound; moreover, those events do not occur in their textual order, as revealed by after.", "labels": [], "entities": []}, {"text": "In Section 5, we extend the model to include segmentation and ordering variables and apply it to this stock data.", "labels": [], "entities": []}, {"text": "The situation where language describes a path through some continuous space-literal or metaphorical-is more general than stock headlines.", "labels": [], "entities": []}, {"text": "Our claim is that a variety of problems in language share these same characteristics.", "labels": [], "entities": []}, {"text": "To demonstrate generality of the model, we also apply it in Section 6 to a challenging variant of the direction-following task described by), where we achieve results close to a state-of-the-art system that makes stronger assumptions about the task.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Map Task Corpus consists of 128 dialogues describing paths on 16 maps, accompanied by transcriptions of spoken instructions, presegmented using prosodic cues.", "labels": [], "entities": []}, {"text": "See Vogel and Jurafsky (2010) fora more detailed description of the corpus in a language learning setting.", "labels": [], "entities": []}, {"text": "For comparability, we'll use the same evaluation as Vogel and Jurafsky, which rewards the system for moving between pairs of landmarks that also appear in the reference path, and penalizes it for additional superfluous movement.", "labels": [], "entities": []}, {"text": "Note that we are solving a significantly harder problem: the version addressed by Vogel and Jurafsky is a discrete search problem, and the system has hard-coded knowledge that all paths pass along one of the four sides of each landmark.", "labels": [], "entities": []}, {"text": "Our system, by contrast, can navigate to any point in R 2 , and must learn that most paths stay close to a named landmark.", "labels": [], "entities": []}, {"text": "At test time, the system is given anew sequence of text instructions, and must output the corresponding path.", "labels": [], "entities": []}, {"text": "It is scored on the fraction of correct transitions in its output path (precision), and the fraction of transitions in the gold path recovered (recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9986829161643982}, {"text": "recall", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.9976723790168762}]}, {"text": "Vogel and Jurafsky compare their system to a policy-gradient algorithm for using language to follow natural language instructions described by, and we present both systems for comparison.", "labels": [], "entities": []}, {"text": "Our system substantially outperforms the policy gradient baseline of Branavan et al., and performs close (particularly with respect to transition recall) to the system of Vogel and Jurafsky, with fewer assumptions.", "labels": [], "entities": [{"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.8027598261833191}]}], "tableCaptions": [{"text": " Table 2: Results for the color selection task.  Sel(ection accuracy) is frequency with which the  system was able to correctly identify the color de- scribed when paired with a random alternative.", "labels": [], "entities": [{"text": "color selection task", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.7793899774551392}, {"text": "Sel(ection accuracy)", "start_pos": 49, "end_pos": 69, "type": "METRIC", "confidence": 0.8350826740264893}]}, {"text": " Table 3: Results for the stocks task. Sel(ection  accuracy) measures the frequency with which the  system correctly identifies the stock described in  the headline when paired with a random alterna- tive. Pred(iction error) is the mean sum of squared  errors between the real and predicted paths. Full  model selection accuracy is a statistically signif- icant improvement (p < 0.05) over the baseline  using a paired sign test.", "labels": [], "entities": [{"text": "Sel(ection  accuracy", "start_pos": 39, "end_pos": 59, "type": "METRIC", "confidence": 0.8885623067617416}, {"text": "Pred(iction error)", "start_pos": 206, "end_pos": 224, "type": "METRIC", "confidence": 0.9326950192451477}, {"text": "accuracy", "start_pos": 320, "end_pos": 328, "type": "METRIC", "confidence": 0.9640451669692993}]}, {"text": " Table 4: Learned parameter settings for overall  daily change, which the path featurization decom- poses into a sign and a magnitude.", "labels": [], "entities": []}, {"text": " Table 5: Results for the navigation task. Higher is  better for all of precision, recall and F 1 .", "labels": [], "entities": [{"text": "navigation task", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.9160169064998627}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9997792840003967}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9996936321258545}, {"text": "F 1", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9893212616443634}]}]}