{"title": [{"text": "Optimizing Features in Active Machine Learning for Complex Qualitative Content Analysis", "labels": [], "entities": [{"text": "Complex Qualitative Content Analysis", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.6332758441567421}]}], "abstractContent": [{"text": "We propose a semi-automatic approach for content analysis that leverages machine learning (ML) being initially trained on a small set of hand-coded data to perform a first pass in coding, and then have human annotators correct machine annotations in order to produce more examples to retrain the existing model incrementally for better performance.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7809681296348572}]}, {"text": "In this \"active learning\" approach, it is equally important to optimize the creation of the initial ML model given less training data so that the model is able to capture most if not all positive examples, and filter out as many negative examples as possible for human annotators to correct.", "labels": [], "entities": []}, {"text": "This paper reports our attempt to optimize the initial ML model through feature exploration in a complex content analysis project that uses a multidimensional coding scheme, and contains codes with sparse positive examples.", "labels": [], "entities": [{"text": "ML", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9681264162063599}]}, {"text": "While different codes respond optimally to different combinations of features , we show that it is possible to create an optimal initial ML model using only a single combination of features for codes with at least 100 positive examples in the gold standard corpus.", "labels": [], "entities": [{"text": "gold standard corpus", "start_pos": 243, "end_pos": 263, "type": "DATASET", "confidence": 0.7163208822409312}]}], "introductionContent": [{"text": "Content analysis, a technique for finding evidence of concepts of theoretical interest through text, is an increasingly popular technique social scientists use in their research investigations.", "labels": [], "entities": [{"text": "Content analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7434957176446915}]}, {"text": "In the process commonly known as \"coding\", social scientists often have to painstakingly comb through large quantities of natural language corpora to annotate text segments (e.g., phrase, sentence, and paragraphs) with codes exhibiting the concepts of interest.", "labels": [], "entities": []}, {"text": "Analyzing textual data is very labor-intensive, time-consuming, and is often limited to the capabilities of individual researchers (W..", "labels": [], "entities": [{"text": "Analyzing textual", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8717508316040039}]}, {"text": "The coding process becomes even more demanding as the complexity of the project increases especially in the case of attempting to apply a multidimensional coding scheme with a significant number of codes).", "labels": [], "entities": [{"text": "coding", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.9529786705970764}]}, {"text": "With the proliferation and availability of digital texts, it is challenging, if not impossible, for human coders to manually analyze torrents of text to help advance social scientists' understanding of the practices of different populations of interest through textual data.", "labels": [], "entities": []}, {"text": "Therefore, computational methods offer significant benefits to help augment human capabilities to explore massive amounts of text in more complex ways for theory generation and theory testing.", "labels": [], "entities": [{"text": "theory generation", "start_pos": 155, "end_pos": 172, "type": "TASK", "confidence": 0.7261394411325455}]}, {"text": "Content analysis can be framed as a text classification problem, where each text segment is labeled based on a predetermined set of categories or codes.", "labels": [], "entities": [{"text": "Content analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8361533880233765}, {"text": "text classification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7335590571165085}]}, {"text": "Full automation of content analysis is still far from being perfect.", "labels": [], "entities": [{"text": "automation", "start_pos": 5, "end_pos": 15, "type": "METRIC", "confidence": 0.967858076095581}, {"text": "content analysis", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.7631402909755707}]}, {"text": "The accuracy of current automatic approaches on the best performing codes in social science research ranges from 60-90% (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996562004089355}]}, {"text": "While the potential of automatic content analysis is promising, computational methods should not be viewed as a replacement for the role of the primary researcher in the careful interpretation of text.", "labels": [], "entities": [{"text": "automatic content analysis", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.6359267135461172}]}, {"text": "Rather, the computers' pattern recognition capabilities can be leveraged to seek out the most likely examples for each code of interest, thus reducing the amount of texts researchers have to read and process.", "labels": [], "entities": [{"text": "pattern recognition", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7914728820323944}]}, {"text": "We propose a semi-automatic method that promotes a close human-computer partnership for content analysis.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7584654986858368}]}, {"text": "Machine learning (ML) is used to perform the first pass of coding on the unlabeled texts.", "labels": [], "entities": []}, {"text": "Human annotators then have to correct only what the ML model identifies as positive examples of each code.", "labels": [], "entities": []}, {"text": "The initial ML model needs to learn only from a small set of hand-coded examples (i.e., gold standard data), and will evolve and improve as machine annotations that are verified by human annotators are used to incrementally retrain the model.", "labels": [], "entities": [{"text": "ML", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.938787579536438}]}, {"text": "In contrast to conventional machine learning, this \"active learning\" approach will significantly reduce the amount of training data needed upfront from the human annotators.", "labels": [], "entities": []}, {"text": "However, it is still equally important to optimize the creation of the initial ML model given less training data so that the model is able to capture most if not all positive examples, and filter out as many negative examples as possible for human annotators to correct.", "labels": [], "entities": []}, {"text": "To effectively implement the active learning approach for coding qualitative data, we have to first understand the nature and complexity of content analysis projects in social science research.", "labels": [], "entities": []}, {"text": "Our pilot case study, an investigation of leadership behaviors exhibited in emails from a FLOSS development project, reveals that it is common for researchers to use a multidimensional coding scheme consisting of a significant number of codes in their research inquiry.", "labels": [], "entities": [{"text": "FLOSS development project", "start_pos": 90, "end_pos": 115, "type": "DATASET", "confidence": 0.7968710064888}]}, {"text": "Previous work has shown that not all dimensions in a multidimensional coding scheme could be applied fully automatically with acceptable level of accuracy () but little is known if it is possible at all to train an optimal model for all codes using the same combination of features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.998056173324585}]}, {"text": "Also, the distribution of codes is oftentimes uneven with some rarely occurring codes having only few positive examples in the gold standard corpus.", "labels": [], "entities": [{"text": "gold standard corpus", "start_pos": 127, "end_pos": 147, "type": "DATASET", "confidence": 0.7230315407117208}]}, {"text": "This paper presents our attempt in optimizing the initial ML model through feature exploration using gold standard data created from a multidimensional coding scheme, including codes that suffer from sparseness of positive examples.", "labels": [], "entities": [{"text": "ML", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9700119495391846}]}, {"text": "Specifically, our study is guided by two research questions: a) How can features for an initial machine learning model be optimized for all codes in a text classification problem based on multidimensional coding schemes?", "labels": [], "entities": [{"text": "text classification problem", "start_pos": 151, "end_pos": 178, "type": "TASK", "confidence": 0.7950785557428995}]}, {"text": "Is it possible to train a one-size-fits-all model for all codes using a single combination of features?", "labels": [], "entities": []}, {"text": "b) Are certain features better suited for codes with sparse positive examples?", "labels": [], "entities": []}], "datasetContent": [{"text": "To optimize the initial machine learning model, we systematically ran multiple experiments using a gold standard corpus of emails from a free/libre/open-source software (FLOSS) development project coded for leadership behaviors).", "labels": [], "entities": []}, {"text": "The coding scheme contained six dimensions: 1) social/relationship, 2) task process, 3) task substance, 4) dual process and substance, 5) change behaviors, and 6) networking.", "labels": [], "entities": []}, {"text": "The number of codes for each dimension ranged from 1 to 14.", "labels": [], "entities": []}, {"text": "There were a total of 35 codes in the coding scheme.", "labels": [], "entities": []}, {"text": "Each sentence could be assigned more than one code.", "labels": [], "entities": []}, {"text": "Framing the problem as a multi-label classification task, we trained a binary classification model for each code using support vector machine (SVM) with ten-fold cross-validation.", "labels": [], "entities": [{"text": "multi-label classification task", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8116600513458252}]}, {"text": "This gold standard corpus consisted of 3,728 hand-coded sentences from 408 email messages.", "labels": [], "entities": []}, {"text": "For the active learning setup, we tune the initial ML model for high recall since having the annotators pick out positive examples that have been incorrectly classified by the model is preferable to missing machine-annotated positive examples to be presented to human annotators for verification.", "labels": [], "entities": [{"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9989607334136963}]}, {"text": "Therefore, the initial ML model with low precision is acceptable..", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9972565770149231}]}, {"text": "Comparison of mean recall and mean precision between SINGLE and MULTIPLE models.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9079689383506775}, {"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.5656458139419556}, {"text": "MULTIPLE", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.618591845035553}]}], "tableCaptions": [{"text": " Table 2. Comparison of mean recall and mean precision between SINGLE and MULTIPLE models.", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.878801167011261}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.5234783291816711}]}]}