{"title": [{"text": "Automated Scoring of Speaking Items in an Assessment for Teachers of English as a Foreign Language", "labels": [], "entities": [{"text": "Automated Scoring of Speaking Items", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.76897132396698}]}], "abstractContent": [{"text": "This paper describes an end-to-end prototype system for automated scoring of spoken responses in a novel assessment for teachers of English as a Foreign Language who are not native speakers of English.", "labels": [], "entities": []}, {"text": "The 21 speaking items contained in the assessment elicit both restricted and moderately restricted responses, and their aim is to assess the essential speaking skills that English teachers need in order to be effective communicators in their classrooms.", "labels": [], "entities": []}, {"text": "Our system consists of a state-of-the-art automatic speech recognizer; multiple feature generation modules addressing diverse aspects of speaking proficiency, such as fluency, pronunciation, prosody, grammatical accuracy, and content accuracy; a filter that identifies and flags problematic responses; and linear regression models that predict response scores based on subsets of the features.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7377221286296844}, {"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.7442873120307922}, {"text": "accuracy", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.7924751043319702}]}, {"text": "The automated speech scoring system was trained and evaluated on a data set involving about 1,400 test takers, and achieved a speaker-level correlation (when scores for all 21 responses of a speaker are aggregated) with human expert scores of 0.73.", "labels": [], "entities": []}], "introductionContent": [{"text": "As English has become increasingly important as a language of international business, trade, science, and communication, efforts to promote teaching English as a Foreign Language (EFL) have seen substantially more emphasis in many non-Englishspeaking countries worldwide in recent years.", "labels": [], "entities": [{"text": "teaching English as a Foreign Language (EFL)", "start_pos": 140, "end_pos": 184, "type": "TASK", "confidence": 0.6360499428378211}]}, {"text": "In addition, the prevailing trend in English pedagogy has been to promote the use of spoken English in the classroom, as opposed to the respective native languages of the EFL learners.", "labels": [], "entities": [{"text": "EFL learners", "start_pos": 171, "end_pos": 183, "type": "DATASET", "confidence": 0.8445154130458832}]}, {"text": "However, due to the high demand for EFL teachers in many countries, the training of these teachers has not always caught up with these high expectations, so there is a need for both governmental and private institutions involved in the employment and training of EFL teachers to assess their competence in the English language, as well as in English pedagogy.", "labels": [], "entities": []}, {"text": "Against this background, we developed a language assessment for EFL teachers who are not native speakers of English that addresses the four basic English language skills of Reading, Listening, Writing and Speaking.", "labels": [], "entities": []}, {"text": "This paper focuses only on the speaking portion of the English assessment, and, in particular, on the system that we developed to automatically compute scores for test takers' spoken responses.", "labels": [], "entities": []}, {"text": "Several significant challenges needed to be addressed during the course of building this automated speech scoring system, including, but not limited to: \u2022 The 21 Speaking items belong to 8 different task types with different characteristics; therefore, we had to select features and build scoring models for each task type separately.", "labels": [], "entities": []}, {"text": "\u2022 The test takers speak a variety of native languages, and thus have very different nonnative accents in their spoken English.", "labels": [], "entities": []}, {"text": "Furthermore, the test takers also exhibit a wide range of speaking proficiency levels, which contributes to the diversity of their spoken responses.", "labels": [], "entities": []}, {"text": "Our speech recognizer therefore had to be trained and adapted to a large database of non-native speech.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7156486809253693}]}, {"text": "\u2022 Since content accuracy is very important for the types of tasks contained in the test, even small error rates by the automatic speech recognition (ASR) system can lead to a noticeable impact on feature performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9552463889122009}, {"text": "automatic speech recognition (ASR)", "start_pos": 119, "end_pos": 153, "type": "TASK", "confidence": 0.7797201573848724}]}, {"text": "This fact motivated the development of a set of features that are robust to speech recognition errors.", "labels": [], "entities": [{"text": "speech recognition errors", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.8054083983103434}]}, {"text": "\u2022 A significant amount of responses (more than 7%) exhibit issues that make them hard or impossible to score automatically, e.g., high noise levels, background speech, etc.", "labels": [], "entities": []}, {"text": "We therefore implemented a filter to identify these non-scorable responses automatically.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 discusses related work; in Section 3, we present the data used for system training and evaluation; Section 4 describes the system architecture of the automated speech scoring system.", "labels": [], "entities": [{"text": "automated speech scoring system", "start_pos": 195, "end_pos": 226, "type": "TASK", "confidence": 0.6622736304998398}]}, {"text": "We detail the methods we used to build our system in Section 5, followed by an overview of the results in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 discusses our findings; finally, Section 8 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Amount of data contained in each partition (speakers, responses, hours of speech) and distribu- tion of human scores (percentages of scores per partition in brackets).", "labels": [], "entities": [{"text": "Amount", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9897261261940002}, {"text": "distribu- tion of human scores", "start_pos": 96, "end_pos": 126, "type": "METRIC", "confidence": 0.9239727954069773}]}, {"text": " Table 5: Speaker-level performance (Pearson r  correlations) computed over the sum of all 21  scores from each speaker, N=272", "labels": [], "entities": [{"text": "Pearson r  correlations)", "start_pos": 37, "end_pos": 61, "type": "METRIC", "confidence": 0.9497494697570801}]}, {"text": " Table 6: Range of Pearson r correlations for dif- ferent features with human scores (H1) by sub- construct for restricted and semi-restricted item  types.", "labels": [], "entities": [{"text": "Range", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9573155045509338}, {"text": "Pearson r correlations", "start_pos": 19, "end_pos": 41, "type": "METRIC", "confidence": 0.9417412082354227}]}]}