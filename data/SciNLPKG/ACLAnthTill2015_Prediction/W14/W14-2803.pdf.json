{"title": [{"text": "Comparing Models of Phonotactics for Word Segmentation", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7175852656364441}]}], "abstractContent": [{"text": "Developmental research indicates that infants use low-level statistical regularities, or pho-notactics, to segment words from continuous speech.", "labels": [], "entities": []}, {"text": "In this paper, we present a segmenta-tion framework that enables the direct comparison of different phonotactic models for segmentation.", "labels": [], "entities": []}, {"text": "We compare a model using phoneme transitional probabilities, which have been widely used in computational models, to syllable-based bigram models, which have played a prominent role in the developmental literature.", "labels": [], "entities": []}, {"text": "We also introduce a novel estimation method, and compare it to other strategies for estimating the parameters of the phonotactic models from unsegmented data.", "labels": [], "entities": []}, {"text": "The results show that syllable-based models outperform the phoneme models, specifically in the context of improved unsu-pervised parameter estimation.", "labels": [], "entities": []}, {"text": "The syllable-based transitional probability model achieves a word token f-score of nearly 80%, the highest reported performance fora phonotactic segmentation model with no lexicon.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the first language learning tasks infants must solve is the segmentation of fluent speech into words.", "labels": [], "entities": [{"text": "segmentation of fluent speech into words", "start_pos": 67, "end_pos": 107, "type": "TASK", "confidence": 0.8514629304409027}]}, {"text": "Extensive experimental work has demonstrated that infants are able to use phonotactic restrictions) and other low-level statistical regularities () to extract words from fluent speech before the age of one.", "labels": [], "entities": []}, {"text": "This work has shown that infants utilize these low-level statistical regularities to segment speech during the second half of the first year of life before they have developed extensive vocabularies that could provide top-down lexical information to guide segmentation.", "labels": [], "entities": []}, {"text": "Developmental research indicates that on average infants know fewer than 100 word types during this period.", "labels": [], "entities": []}, {"text": "One statistical cue that has received a great deal of support in experimental work on infant speech segmentation is transitional probability calculated over syllables.", "labels": [], "entities": [{"text": "infant speech segmentation", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.6491563816865286}]}, {"text": "In foundational work, found that infants are able to segment words from continuous speech using statistical regularities between syllables.", "labels": [], "entities": []}, {"text": "Numerous subsequent studies have confirmed that infants can track transitional probabilities and use them to segment speech (.", "labels": [], "entities": []}, {"text": "Despite the extensive experimental literature demonstrating infants' sensitivity to transitional probability in an artificial language learning setting, the utility of these statistical cues in a natural language learning context is disputed.", "labels": [], "entities": []}, {"text": "shows that a segmentation strategy relying on transitional probabilities over syllables achieves very poor results on English childdirected speech, even when the input is perfectly syllabified.", "labels": [], "entities": []}, {"text": "Yang implements the local minimum segmentation strategy proposed by wherein word boundaries are posited at syllable transitions whenever the transitional probabilities at these positions are lower than at the neighboring transitions.", "labels": [], "entities": []}, {"text": "He reports that this strategy discovers a mere 23% of target words and posits incorrect words nearly 60% of the time.", "labels": [], "entities": []}, {"text": "argues that statistical cues calculated over syllables can provide sufficient information for infants to begin building an initial lexicon.", "labels": [], "entities": []}, {"text": "However, the learning strategy explored by Swingley is highly conservative, reliably detecting only a small proportion of target words in the input.", "labels": [], "entities": []}, {"text": "Overall, these results raise questions about whether syllable-based statistics can be reliably used to identify word boundaries in natural language data.", "labels": [], "entities": []}, {"text": "While the experimental work emphasizes syllable-level transitional probability, recent computational modeling work and corpus analyses have primarily focused on the utility of phoneme-level statistics.", "labels": [], "entities": [{"text": "syllable-level transitional probability", "start_pos": 39, "end_pos": 78, "type": "TASK", "confidence": 0.6429290374120077}]}, {"text": "A number of phonotactically-based segmentation models, focusing on the discovery of word boundaries based on phoneme-level statistics, have achieved more promising results).", "labels": [], "entities": []}, {"text": "For example, showed that a local minimum strategy relying on phoneme bigrams correctly extracts about 50% of word tokens in English child-directed speech.", "labels": [], "entities": []}, {"text": "Corpus analyses of child-directed speech have also highlighted the information content of phoneme-level statistics.", "labels": [], "entities": []}, {"text": "Related work has shown that phonotactic information can improve the performance of state-ofthe-art segmentation models whose primary objective is to discover the lexicon that underlies the regularities in the continuous speech signal.", "labels": [], "entities": []}, {"text": "Again, this work has largely emphasized phoneme-level statistical cues, and those models that do rely on syllable structure, do not directly encode sequential statistics between adjacent syllables of the sort investigated in the infant literature.", "labels": [], "entities": []}, {"text": "Finally, some models assume computations are performed over syllables and that all word boundaries in the input are aligned with syllable boundaries, but provide no mechanism by which such language-specific syllabification principles could be learned.", "labels": [], "entities": []}, {"text": "Overall, the existing evidence clearly shows that there are phonotactic cues to word boundaries in spontaneous, child-directed speech.", "labels": [], "entities": []}, {"text": "However, there are remaining questions regarding the exact nature of these cues, their reliability, and how they relate to the statistical cues explored in the infant word segmentation literature.", "labels": [], "entities": [{"text": "reliability", "start_pos": 87, "end_pos": 98, "type": "METRIC", "confidence": 0.9853654503822327}, {"text": "infant word segmentation", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.6694229443868002}]}, {"text": "In this paper, we investigate the computational mechanisms underlying infants' early speech segmentation abilities relying on low-level statistical regularities, or phonotactics.", "labels": [], "entities": [{"text": "early speech segmentation abilities", "start_pos": 79, "end_pos": 114, "type": "TASK", "confidence": 0.7461808323860168}]}, {"text": "We present a computational framework that permits the direct comparison of segmentation predictions for alternative models of phonotactics.", "labels": [], "entities": []}, {"text": "In particular, we compare a standard phonotactic model relying on phoneme-level bigrams to two syllable-based phonotactic models relying on transitional probabilities.", "labels": [], "entities": []}, {"text": "Unlike previous models relying on syllabified data, we do not assume that word boundaries align with syllable boundaries in the input.", "labels": [], "entities": []}, {"text": "Rather, we present a simple syllabification method that can be used to model phonotactic probability for arbitrary strings using statistics estimated from unsyllabified, unsegmented utterances.", "labels": [], "entities": []}, {"text": "We also compare the local minimum segmentation strategy) to alternatives designed to deal with the challenges of unsupervised estimation of transitional probabilities from unsegmented input.", "labels": [], "entities": []}, {"text": "Our focus on the early phonotactic segmentation stage differentiates our approach from many computational models emphasizing the discovery of the lexicon and higher-level language structure.", "labels": [], "entities": []}, {"text": "It complements that of recent work investigating the use of phoneme-level statistical regularities for segmentation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 103, "end_pos": 115, "type": "TASK", "confidence": 0.9616214036941528}]}, {"text": "Our work differs from these latter approaches, however, in comparing several phonotactic models, including ones relying on the syllable-based transitional probability statistics investigated in infant research.", "labels": [], "entities": []}, {"text": "Our work also contributes to existing segmentation work that assumes a syllabified input by showing how many aspects of syllable structure can be inferred.", "labels": [], "entities": []}, {"text": "Our results reveal an interaction between estimation strategy and the choice of phonotactic model.", "labels": [], "entities": [{"text": "estimation", "start_pos": 42, "end_pos": 52, "type": "TASK", "confidence": 0.9746317863464355}]}, {"text": "The local minimum segmentation strategy works poorly in general for all models considered, but the lowest performance is achieved by the syllable-based models.", "labels": [], "entities": []}, {"text": "However, when the same cues are used in the context of a simple, generative probability model with improved unsupervised parameter estimation, the syllablebased models substantially outperform the phoneme-based models.", "labels": [], "entities": []}, {"text": "Indeed, the syllable-based transitional probability phonotactic model achieves a word token segmentation f-score of nearly 80%, which is the highest reported performance among purely phonotactically-based segmentation models).", "labels": [], "entities": [{"text": "word token segmentation f-score", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.5850220993161201}]}, {"text": "Indeed, this performance compares favorably with state-of-theart segmentation models that involve learning of higher level regularities, such as the lexicon and collocations, and demonstrates that good segmentation performance can be achieved by exploiting simple syllable-level phonotactic cues.", "labels": [], "entities": []}], "datasetContent": [{"text": "Precision, recall, and f-scores of both word tokens and boundaries were used to evaluate performance.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9865537285804749}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9923793077468872}]}, {"text": "For the models with iterative reestimation, the reported performance scores are taken from the iteration after convergence.", "labels": [], "entities": []}, {"text": "This typically happened after 5-10 iterations.", "labels": [], "entities": []}, {"text": "summarizes the word boundary and word token f-scores for all models, while presents the precision and recall scores for the best-performing adjusted count models and the local minimum models.", "labels": [], "entities": [{"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9994981288909912}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9900418519973755}]}], "tableCaptions": [{"text": " Table 1: Word token (WF) and boundary (BF) f-scores for all models. The columns in the first section  of the table represent different settings of the p # parameter, with highest performance for each adjusted  count model shown in bold. p # values were selected to show a representative range of performance. P  = phoneme model; OR = onset-rhyme model; S = syllable model; IR = iterative re-estimation; LM =  local minimum strategy. The best performing local minimum model is shaded.", "labels": [], "entities": [{"text": "IR", "start_pos": 374, "end_pos": 376, "type": "METRIC", "confidence": 0.9631487131118774}]}, {"text": " Table 2: Word precision (WP), word recall (WR), boundary precision (BP), and boundary recall (BR)  scores for selected models. For the adjusted count estimation models, the results for the best perform- ing parameter value are shown (P-IR: 0.6; OR-IR: 0.75; S-IR: 0.99).", "labels": [], "entities": [{"text": "Word precision (WP)", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7385744512081146}, {"text": "word recall (WR)", "start_pos": 31, "end_pos": 47, "type": "METRIC", "confidence": 0.7838024377822876}, {"text": "boundary precision (BP)", "start_pos": 49, "end_pos": 72, "type": "METRIC", "confidence": 0.9425742626190186}, {"text": "boundary recall (BR)  scores", "start_pos": 78, "end_pos": 106, "type": "METRIC", "confidence": 0.9028263886769613}]}]}