{"title": [{"text": "Emotive or Non-emotive: That is The Question", "labels": [], "entities": []}], "abstractContent": [{"text": "In this research we focus on discriminating between emotive (emotionally loaded) and non-emotive sentences.", "labels": [], "entities": []}, {"text": "We define the problem from a linguistic point of view assuming that emotive sentences standout both lexically and grammatically.", "labels": [], "entities": []}, {"text": "We verify this assumption experimentally by comparing two sets of such sentences in Japanese.", "labels": [], "entities": []}, {"text": "The comparison is based on words, longer n-grams as well as more sophisticated patterns.", "labels": [], "entities": []}, {"text": "In the classification we use a novel unsupervised learning algorithm based on the idea of language com-binatorics.", "labels": [], "entities": []}, {"text": "The method reached results comparable to the state of the art, while the fact that it is fully automatic makes it more efficient and language independent.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently the field of sentiment analysis has attracted great interest.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9649172127246857}]}, {"text": "It has become popular to try different methods to distinguish between sentences loaded with positive and negative sentiments.", "labels": [], "entities": []}, {"text": "However, a few research focused on a task more generic, namely, discriminating whether a sentence is even loaded with emotional content or not.", "labels": [], "entities": []}, {"text": "The difficulty of the task is indicated by three facts.", "labels": [], "entities": []}, {"text": "Firstly, the task has not been widely undertaken.", "labels": [], "entities": []}, {"text": "Secondly, in research which addresses the challenge, the definition of the task is usually based on subjective ad hoc assumptions.", "labels": [], "entities": []}, {"text": "Thirdly, in research which do tackle the problem in a systematic way, the results are usually unsatisfactory, and satisfactory results can be obtained only with large workload.", "labels": [], "entities": []}, {"text": "We decided to tackle the problem in a standardized and systematic way.", "labels": [], "entities": []}, {"text": "We defined emotionally loaded sentences as those which in linguistics are described as fulfilling the emotive function of language.", "labels": [], "entities": []}, {"text": "We assumed that there are repetitive patterns which appear uniquely in emotive sentences.", "labels": [], "entities": []}, {"text": "We performed experiments using a novel unsupervised clustering algorithm based on the idea of language combinatorics.", "labels": [], "entities": []}, {"text": "By using this method we were also able to minimize human effort and achieve F-score comparable to the state of the art with much higher Recall rate.", "labels": [], "entities": [{"text": "F-score", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9994919300079346}, {"text": "Recall rate", "start_pos": 136, "end_pos": 147, "type": "METRIC", "confidence": 0.9834621548652649}]}, {"text": "The outline of the paper is as follows.", "labels": [], "entities": []}, {"text": "We present the background for this research in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 describes the language combinatorics approach which we used to compare emotive and non-emotive sentences.", "labels": [], "entities": []}, {"text": "In section 4 we describe our dataset and experiment settings.", "labels": [], "entities": []}, {"text": "The results of the experiment are presented in Section 5.", "labels": [], "entities": []}, {"text": "Finally the paper is concluded in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments we used a dataset developed by for the needs of evaluating their affect analysis system ML-Ask for Japanese language.", "labels": [], "entities": [{"text": "ML-Ask", "start_pos": 107, "end_pos": 113, "type": "DATASET", "confidence": 0.9219637513160706}]}, {"text": "The dataset contains 50 emotive and 41 non-emotive sentences.", "labels": [], "entities": []}, {"text": "It was created as follows.", "labels": [], "entities": []}, {"text": "Thirty people of different age and social groups participated in an anonymous survey.", "labels": [], "entities": []}, {"text": "Each participant was to imagine or remember a conversation with any person they know and write three sentences from that conversation: one free, one emotive, and one non-emotive.", "labels": [], "entities": []}, {"text": "Additionally, the participants were asked to make the emotive and nonemotive sentences as close in content as possible, so the only difference was whether a sentence was loaded with emotion or not.", "labels": [], "entities": []}, {"text": "The participants also annotated on their own free utterances whether or not they were emotive.", "labels": [], "entities": []}, {"text": "Some examples from the dataset are represented in.", "labels": [], "entities": []}, {"text": "In our research the above dataset was further preprocessed to make the sentences separable into elements.", "labels": [], "entities": []}, {"text": "We did this in three ways to check how the preprocessing influences the results.", "labels": [], "entities": []}, {"text": "We used MeCab 2 , a morphological analyzer for Japanese to preprocess the sentences from the dataset in the three following ways: \u2022 Tokenization: All words, punctuation marks, etc. are separated by spaces..", "labels": [], "entities": []}, {"text": "In theory, the more generalized a sentence is, the less unique patterns it will produce, but the produced patterns will be more frequent.", "labels": [], "entities": []}, {"text": "This can be explained by comparing tokenized sentence with its POS representation.", "labels": [], "entities": []}, {"text": "For example, in the sentence from we can see that a simple phrase kimochi ii (\"feeling good\") can be: Three kinds of preprocessing of a sentence in Japanese; N = noun, TOP = topic marker, ADV = adverbial particle, ADJ = adjective, COP = copula, EXCL = exclamation mark.", "labels": [], "entities": [{"text": "TOP", "start_pos": 168, "end_pos": 171, "type": "METRIC", "confidence": 0.9516571164131165}, {"text": "EXCL", "start_pos": 245, "end_pos": 249, "type": "METRIC", "confidence": 0.9918943047523499}]}, {"text": "represented by a POS pattern N ADJ.", "labels": [], "entities": [{"text": "POS pattern N ADJ", "start_pos": 17, "end_pos": 34, "type": "METRIC", "confidence": 0.49099332839250565}]}, {"text": "We can easily assume that there will be more N ADJ patterns than kimochi ii, because many word combinations can be represented as N ADJ.", "labels": [], "entities": []}, {"text": "Therefore POS patterns will come in less variety but with higher occurrence frequency.", "labels": [], "entities": [{"text": "POS", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9317511916160583}, {"text": "occurrence frequency", "start_pos": 65, "end_pos": 85, "type": "METRIC", "confidence": 0.92226642370224}]}, {"text": "By comparing the result of classification using different preprocessing methods we can find out whether it is better to represent sentences as more generalized or as more specific.", "labels": [], "entities": []}, {"text": "The experiment was performed three times, once for each kind of preprocessing.", "labels": [], "entities": []}, {"text": "Each time 10-fold cross validation was performed and the results were calculated using Precision (P), Recall (R) and balanced F-score (F) for each threshold.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 87, "end_pos": 100, "type": "METRIC", "confidence": 0.9604800939559937}, {"text": "Recall (R)", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.966084361076355}, {"text": "F-score (F)", "start_pos": 126, "end_pos": 137, "type": "METRIC", "confidence": 0.9697559922933578}]}, {"text": "We verified which version of the algorithm achieves the top score within the threshold span.", "labels": [], "entities": []}, {"text": "However, an algorithm could achieve the best score for one certain threshold, while for others it could perform poorly.", "labels": [], "entities": []}, {"text": "Therefore we also looked at which version achieves high scores for the longest threshold span.", "labels": [], "entities": []}, {"text": "This shows which algorithm is more balanced.", "labels": [], "entities": []}, {"text": "Finally, we checked the statistical significance of the results.", "labels": [], "entities": []}, {"text": "We used paired t-test because the classification results could represent only one of two classes (emotive or non-emotive).", "labels": [], "entities": []}, {"text": "We also compared the performance to the state of the art, namely the affect analysis system ML-Ask developed by.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Best results for each version of the  method compared with the ML-Ask system.", "labels": [], "entities": []}]}