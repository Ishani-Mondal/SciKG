{"title": [{"text": "Using Comparable Corpora to Adapt MT Models to New Domains", "labels": [], "entities": [{"text": "MT Models to New Domains", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.8222610116004944}]}], "abstractContent": [{"text": "In previous work we showed that when using an SMT model trained on old-domain data to translate text in a new-domain, most errors are due to unseen source words, unseen target translations, and inaccurate translation model scores (Irvine et al., 2013a).", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9884327054023743}]}, {"text": "In this work, we target errors due to inaccurate translation model scores using new-domain comparable corpora , which we mine from Wikipedia.", "labels": [], "entities": []}, {"text": "We assume that we have access to a large old-domain parallel training corpus but only enough new-domain parallel data to tune model parameters and do evaluation.", "labels": [], "entities": []}, {"text": "We use the new-domain comparable corpora to estimate additional feature scores over the phrase pairs in our baseline models.", "labels": [], "entities": []}, {"text": "Augmenting models with the new features improves the quality of machine translations in the medical and science domains by up to 1.3 BLEU points over very strong baselines trained on the 150 million word Canadian Hansard dataset.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.9990459084510803}, {"text": "Canadian Hansard dataset", "start_pos": 204, "end_pos": 228, "type": "DATASET", "confidence": 0.8453832864761353}]}], "introductionContent": [{"text": "Domain adaptation for machine translation is known to be a challenging research problem that has substantial real-world application.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7933790385723114}, {"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7883537709712982}]}, {"text": "In this setting, we have access to training data in some olddomain of text but very little or no training data in the domain of the text that we wish to translate.", "labels": [], "entities": []}, {"text": "For example, we may have a large corpus of parallel newswire training data but no training data in the medical domain, resulting in low quality translations attest time due to the mismatch.", "labels": [], "entities": []}, {"text": "In, we introduced a taxonomy for classifying machine translation errors related to lexical choice.", "labels": [], "entities": [{"text": "classifying machine translation errors", "start_pos": 33, "end_pos": 71, "type": "TASK", "confidence": 0.8291435688734055}]}, {"text": "Our 'S4' taxonomy includes seen, sense, score, and search errors.", "labels": [], "entities": []}, {"text": "Seen errors result when a source language word or phrase in the test set was not observed at all during training.", "labels": [], "entities": []}, {"text": "Sense errors occur when the source language word or phrase was observed during training but not with the correct target language translation.", "labels": [], "entities": []}, {"text": "If the source language word or phrase was observed with its correct translation during training, but an incorrect alternative outweighs the correct translation, then a score error has occurred.", "labels": [], "entities": []}, {"text": "Search errors are due to pruning in beam search decoding.", "labels": [], "entities": []}, {"text": "We measured the impact of each error type in a domain adaptation setting and concluded that seen and sense errors are the most frequent but that there is also room for improving errors due to inaccurate translation model scores (.", "labels": [], "entities": []}, {"text": "In this work, we target score errors, using comparable corpora to reduce their frequency in a domain adaptation setting.", "labels": [], "entities": []}, {"text": "We assume the setting where we have an olddomain parallel training corpus but no new domain training corpus.", "labels": [], "entities": []}, {"text": "We do, however, have access to a mixed-domain comparable corpus.", "labels": [], "entities": []}, {"text": "We identify new-domain text within our comparable corpus and use that data to estimate new translation features on the translation models extracted from old-domain training data.", "labels": [], "entities": []}, {"text": "Specifically, we focus on the French-English language pair because carefully curated datasets exist in several domains for tuning and evaluation.", "labels": [], "entities": []}, {"text": "Following our prior work, we use the Canadian Hansard parliamentary proceedings as our old-domain and adapt models to both the medical and the science domains ().", "labels": [], "entities": [{"text": "Canadian Hansard parliamentary proceedings", "start_pos": 37, "end_pos": 79, "type": "DATASET", "confidence": 0.9306944757699966}]}, {"text": "At over 8 million sentence pairs, the Canadian Hansard dataset is one of the largest publicly available parallel corpora and provides a very strong baseline.", "labels": [], "entities": [{"text": "Canadian Hansard dataset", "start_pos": 38, "end_pos": 62, "type": "DATASET", "confidence": 0.8443203767140707}]}, {"text": "We give details about each dataset in Section 4.1.", "labels": [], "entities": []}, {"text": "We use comparable corpora to estimate several signals of translation equivalence.", "labels": [], "entities": []}, {"text": "In particular, we estimate the contextual, topic, and orthographic similarity of each phrase pair in our baseline old-domain translation model.", "labels": [], "entities": []}, {"text": "In Section 3, we describe each feature in detail.", "labels": [], "entities": []}, {"text": "Using just 5 thousand comparable new-domain document pairs, which we mine from Wikipedia, and five new phrase table features, we observe performance gains of up to 1.3 BLEU points on the science and medical translation tasks over very strong baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9991868138313293}, {"text": "science and medical translation tasks", "start_pos": 187, "end_pos": 224, "type": "TASK", "confidence": 0.7114980518817902}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Comparison between the performance of baseline old-domain translation models and domain-adapted models in", "labels": [], "entities": []}]}