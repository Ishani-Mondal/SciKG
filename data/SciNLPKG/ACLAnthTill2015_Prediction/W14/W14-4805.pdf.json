{"title": [{"text": "NPMI driven recognition of nested terms", "labels": [], "entities": []}], "abstractContent": [{"text": "In the paper, we propose anew method of identifying terms nested within candidates for the terms extracted from domain texts.", "labels": [], "entities": []}, {"text": "The list of all terms is then ranked by the process of automatic term recognition.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.6951218247413635}]}, {"text": "Our method of identifying nested terms is based on two aspects: grammatical correctness and normalised pointwise mutual information (NPMI) counted for all bigrams on the basis of a corpus.", "labels": [], "entities": [{"text": "normalised pointwise mutual information (NPMI)", "start_pos": 92, "end_pos": 138, "type": "METRIC", "confidence": 0.738385042973927}]}, {"text": "NPMI is typically used for recognition of strong word connections but in our solution we use it to recognise the weakest points within phrases to suggest the best place for division of a phrase into two parts.", "labels": [], "entities": [{"text": "NPMI", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7826804518699646}, {"text": "recognition of strong word connections", "start_pos": 27, "end_pos": 65, "type": "TASK", "confidence": 0.7630541682243347}]}, {"text": "By creating only two nested phrases in each step we introduce a binary hierarchical term structure.", "labels": [], "entities": []}, {"text": "In the paper, we test the impact of the proposed nested terms recognition method applied together with the C-value ranking method to the automatic term recognition task.", "labels": [], "entities": [{"text": "terms recognition", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7208388447761536}, {"text": "term recognition task", "start_pos": 147, "end_pos": 168, "type": "TASK", "confidence": 0.7722533841927847}]}], "introductionContent": [{"text": "The Automatic Term Recognition (ATR) task consists in identifying linguistic expressions that refer to domain concepts.", "labels": [], "entities": [{"text": "Automatic Term Recognition (ATR)", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.8217216730117798}]}, {"text": "This is usually realised in two steps.", "labels": [], "entities": []}, {"text": "In the first one, candidates for terms are identified in a corpus of domain texts.", "labels": [], "entities": []}, {"text": "This step usually consists in identifying grammatically correct phrases by means of linguistically motivated grammars describing noun phrases in a given language.", "labels": [], "entities": []}, {"text": "However, sometimes no linguistic knowledge is utilised and candidates for terms are just frequent n-grams as in).", "labels": [], "entities": []}, {"text": "The second processing step consists in ranking the extracted candidates and selecting those which are most important fora considered domain.", "labels": [], "entities": []}, {"text": "This task is usually based on statistics.", "labels": [], "entities": []}, {"text": "The ranking procedure can be based on different measures which are characterised as either \"termhood-based\" or \"unithood-based\".", "labels": [], "entities": []}, {"text": "defined the termhood-based methods measure as \"the degree that a linguistic unit is related to domain-specific concepts\", i.e. the likelihood that a phrase is a valid domain term.", "labels": [], "entities": []}, {"text": "The unithood-based methods measure the collocation strength of word sequences, usually with the help of log-likelihood, pointwise mutual information or T-score measures, described in (), while ATR applications based on them are described in e.g.,,.", "labels": [], "entities": []}, {"text": "A comparison of these approaches is given in ().", "labels": [], "entities": []}, {"text": "Some hybrid solutions to the ATR problem have also been proposed ( or ().", "labels": [], "entities": [{"text": "ATR problem", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.925644189119339}]}, {"text": "In the paper (, the comparison between these two groups of methods led the authors to the conclusion that the termhood-based methods outperform the unithood-based ones.", "labels": [], "entities": []}, {"text": "This paper is devoted to the problem of selecting candidates for terms from an annotated domain corpus.", "labels": [], "entities": []}, {"text": "Our approach is based on the C-value method, ().", "labels": [], "entities": []}, {"text": "An important feature of this method that attracted our attention was the focus on nested terms.", "labels": [], "entities": []}, {"text": "described nested terms as terms that appear within other longer terms, and mayor may not appear by themselves in the corpus.", "labels": [], "entities": []}, {"text": "They show that recognition of nested terms is very important in terms extraction, but they also give examples when a nested phrase constructed according to the grammar rules is not a term.", "labels": [], "entities": [{"text": "terms extraction", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7287232130765915}]}, {"text": "One of these examples is the phrase real time clock which has two nested phrases: real time and time clock, but the second one is not a good term.", "labels": [], "entities": []}, {"text": "The authors define the C-value measure that is used to rank candidate terms extracted from a domain corpus, together with their nested terms.", "labels": [], "entities": []}, {"text": "It is counted on the basis of the frequency of the term as a whole phrase in the corpus, its frequency as a nested phrase in other terms, the number of different phrases in which that nested phrase occurred, and its length.", "labels": [], "entities": []}, {"text": "The authors expect that phrases that aren't considered as terms should be placed at the end of the list ordered according to this coefficient value.", "labels": [], "entities": []}, {"text": "We applied the C-value method to extract terminology from a corpus of hospital discharge documents in Polish.", "labels": [], "entities": []}, {"text": "Experiments, where different methods of counting the C-value were tested, are described in).", "labels": [], "entities": []}, {"text": "Unfortunately, a few grammatically correct but semantically odd phrases were always placed in the top part of the ranking list of terms.", "labels": [], "entities": []}, {"text": "Examples of such phrases, placed among the 200 top positions, are: USG jamy 'USG of cavity' being a nested phrase of the very frequent phrase USG jamy brzusznej 'USG of abdominal cavity', infekcja g\u00f3rnych dr\u00f3g 'infection of upper tract' or powi\u02db ekszony w\u02db eze\u0142 'enlarged node'.", "labels": [], "entities": []}, {"text": "We propose a method that prevents the creation and promotion of such nested phrases to be considered as terms.", "labels": [], "entities": []}, {"text": "The main idea is to use a unithood-based method e.g., Normalised Pointwise Mutual Information (NPMI) for driving recognition of nested phrases.", "labels": [], "entities": [{"text": "recognition of nested phrases", "start_pos": 113, "end_pos": 142, "type": "TASK", "confidence": 0.8694900721311569}]}, {"text": "Our solution is based on the division of each considered phrase into only two parts.", "labels": [], "entities": []}, {"text": "The places where a phrase is divided must create nested phrases that are consistent with grammar rules.", "labels": [], "entities": []}, {"text": "Usually, there are several possible places for division of a phrase.", "labels": [], "entities": [{"text": "division of a phrase", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.8693306595087051}]}, {"text": "From all of them, we choose the weakest point according to NPMI counted for bigrams on the basis of the whole corpus.", "labels": [], "entities": [{"text": "NPMI", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.7595967054367065}]}, {"text": "So, as a bigram constitutes a strong collocation, it prevents the phrase from being dividing in this place, and does not usually lead to the creation of semantically odd nested phrases, of which examples are given above.", "labels": [], "entities": []}, {"text": "The analysed corpus of Polish medical texts is described in Section 2.", "labels": [], "entities": [{"text": "analysed corpus of Polish medical texts", "start_pos": 4, "end_pos": 43, "type": "DATASET", "confidence": 0.7628181676069895}]}, {"text": "In the following two sections we present the method in detail.", "labels": [], "entities": []}, {"text": "Then, in Section 5, we describe the comparison of the resulting lists of terms ranked according to the C-value measure, for two methods of recognition of nested phrases , i.e.: for all possible phrases fulfilling grammatical rules, and for the method proposed in the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied the C-value method to two sets of term candidates.", "labels": [], "entities": []}, {"text": "The first set contains all possible phrases fulfilling the grammatical rules, while the second one is obtained by the method described in the previous sections.", "labels": [], "entities": []}, {"text": "It is worth noting that we consider contexts of nested phrases only when they are recognised in phrases by the method.", "labels": [], "entities": []}, {"text": "As both methods recognised different numbers of phrases, 4 gives the comparison of their numbers.", "labels": [], "entities": []}, {"text": "In this table, s-phrases refers to the baseline solution in which all grammatically correct nested phrases are taken into account, npmi-phrases refers to the solution obtained while recognising nested phrases using only NPMI value and s&nmpi-pharses is a name used for the final solution in which both grammar rules and NPMI values are utilised.", "labels": [], "entities": []}, {"text": "Initially, 32809 phrases were extracted.", "labels": [], "entities": []}, {"text": "The number of candidate phrases was significantly lower after applying NPMI selection (by 15%), but some of them were not grammatically correct.", "labels": [], "entities": []}, {"text": "When applying both selection criteria we obtained about 80% of the phrases (only grammatically correct) from the s-phrases set.", "labels": [], "entities": []}, {"text": "The reduction concerned phrases irrespective of their occurrences within texts.", "labels": [], "entities": []}, {"text": "As to the distribution of the C-value, it maybe seen that we finally obtained much fewer phrases with a 0 C-value.", "labels": [], "entities": []}, {"text": "In the paper, an evaluation of different aspects of the original Cvalue method applied to the same domain corpus is given.", "labels": [], "entities": []}, {"text": "In this paper, we want to verify the tendencies of changes introduced by the proposed method.", "labels": [], "entities": []}, {"text": "To focus on this task, we analysed all phrases that were included in the top 2000 positions ranked by the first method and whose position was moved below the 3000 in the final list, see.", "labels": [], "entities": []}, {"text": "This comparison shows that our solution removed 6.6% (132) of phrases from the top of the list of terms, and 73.5% (97) among them were semantically odd phrases.", "labels": [], "entities": []}, {"text": "We compared the baseline with the version in which, the minimum of NPMI value was always used to indicate phrase division (s&nmpi 1 ) and with the final version, in which the division into two noun phrases was preferred (i.e. if the NPMI at the division position was not significantly higher than the minimum inside phrase).", "labels": [], "entities": [{"text": "phrase division", "start_pos": 106, "end_pos": 121, "type": "TASK", "confidence": 0.6997161358594894}]}, {"text": "In the first case, we observed the elimination of only 39 phrases from the top 2000.", "labels": [], "entities": []}, {"text": "From these sequences, 9 were incorrectly removed from the candidates list.", "labels": [], "entities": []}, {"text": "Using both NPMI value and grammaticality test resulted in 137 changes inside the top 2000.", "labels": [], "entities": []}, {"text": "This time, from 28 removed elements only 2 could be considered correct.", "labels": [], "entities": []}, {"text": "In the final solution, all 27 phrases eliminated form the first 2000 were correctly eliminated, while from the remaining 105 phrases, whose positions were significantly lowered, 70 were not terms.", "labels": [], "entities": []}, {"text": "For some phrases it is difficult to judge whether they are domain related phrases or are rather related to other topics.", "labels": [], "entities": []}, {"text": "These cases were labelled as \"questionable\" in the table.", "labels": [], "entities": []}, {"text": "As the proposed method does not change the way of counting whole phrases recognised in the corpus, we cannot expect that every incorrect phrase will be eliminated.", "labels": [], "entities": []}, {"text": "For example, the phrase infekcja g\u00f3rnych dr\u00f3g 'infection (of the) upper tract' cannot disappear from our list of term candidates, as it occurred three times as a whole phrase due to a spelling error in the word oddechowy 'respiratory'.", "labels": [], "entities": []}, {"text": "We only expect that its position is similar to the position of this phrase ranked according to the frequency of the whole phrase.", "labels": [], "entities": []}, {"text": "We obtained this required effect.", "labels": [], "entities": []}, {"text": "The semantically odd phrase, considered above, changed its position from 144 to 4374.", "labels": [], "entities": []}, {"text": "The presented results show that integrating NPMI with syntactic rules resulted both in better selection and ranking of candidates.", "labels": [], "entities": []}, {"text": "The final decision to prefer division into two noun phrases had rather small but positive effects.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The number of recognised phrases", "labels": [], "entities": []}, {"text": " Table 5: The number of correct changes for the first 2000 positions", "labels": [], "entities": [{"text": "number of correct", "start_pos": 14, "end_pos": 31, "type": "METRIC", "confidence": 0.7764500975608826}]}]}