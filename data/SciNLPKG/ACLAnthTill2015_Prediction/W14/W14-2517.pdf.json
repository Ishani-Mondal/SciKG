{"title": [{"text": "Temporal Analysis of Language through Neural Language Models", "labels": [], "entities": [{"text": "Temporal Analysis of Language", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9135521948337555}]}], "abstractContent": [{"text": "We provide a method for automatically detecting change in language across time through a chronologically trained neural language model.", "labels": [], "entities": []}, {"text": "We train the model on the Google Books Ngram corpus to obtain word vector representations specific to each year, and identify words that have changed significantly from 1900 to 2009.", "labels": [], "entities": [{"text": "Google Books Ngram corpus", "start_pos": 26, "end_pos": 51, "type": "DATASET", "confidence": 0.8255915194749832}]}, {"text": "The model identifies words such as cell and gay as having changed during that time period.", "labels": [], "entities": []}, {"text": "The model simultaneously identifies the specific years during which such words underwent change.", "labels": [], "entities": []}], "introductionContent": [{"text": "Existing words adopt additional senses (gay), new words are created (internet), and some words 'die out' (many irregular verbs, such as burnt, are being replaced by their regularized counterparts ().", "labels": [], "entities": []}, {"text": "Traditionally, scarcity of digitized historical corpora has prevented applications of contemporary machine learning algorithms-which typically require large amounts of data-in such temporal analyses.", "labels": [], "entities": []}, {"text": "Publication of the Google Books Ngram corpus in 2009, however, has contributed to an increased interest in culturomics, wherein researchers analyze changes inhuman culture through digitized texts).", "labels": [], "entities": [{"text": "Google Books Ngram corpus", "start_pos": 19, "end_pos": 44, "type": "DATASET", "confidence": 0.8720821440219879}]}, {"text": "Developing computational methods for detecting and quantifying change in language is of interest to theoretical linguists as well as NLP researchers working with diachronic corpora.", "labels": [], "entities": [{"text": "detecting and quantifying change in language", "start_pos": 37, "end_pos": 81, "type": "TASK", "confidence": 0.8243287205696106}]}, {"text": "Methods employed in previous work have been varied, from analyses of word frequencies to more involved techniques;).", "labels": [], "entities": []}, {"text": "In our framework, we train a Neural Language Model (NLM) on yearly corpora to obtain word vectors for each year from 1900 to 2009.", "labels": [], "entities": []}, {"text": "We chronologically train the model by initializing word vectors for subsequent years with the word vectors obtained from previous years.", "labels": [], "entities": []}, {"text": "We compare the cosine similarity of the word vectors for same words in different years to identify words that have moved significantly in the vector space during that time period.", "labels": [], "entities": []}, {"text": "Our model identifies words such as cell and gay as having changed between 1900-2009.", "labels": [], "entities": []}, {"text": "The model additionally identifies words whose change is more subtle.", "labels": [], "entities": []}, {"text": "We also analyze the yearly movement of words across the vector space to identify the specific periods during which they changed.", "labels": [], "entities": []}, {"text": "The trained word vectors are publicly available.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Top 10 most/least changed words from 1900-2009,  based on cosine similarity of words in 2009 against their 1900  counterparts. Infrequent words (words that occurred less than  500 times) are omitted.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 68, "end_pos": 85, "type": "METRIC", "confidence": 0.8224024176597595}]}]}