{"title": [{"text": "Combining Domain Adaptation Approaches for Medical Text Transla- tion", "labels": [], "entities": [{"text": "Combining Domain Adaptation Approaches", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7002748772501945}, {"text": "Medical Text Transla- tion", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.5315244615077972}]}], "abstractContent": [{"text": "This paper explores a number of simple and effective techniques to adapt statistical machine translation (SMT) systems in the medical domain.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 73, "end_pos": 110, "type": "TASK", "confidence": 0.7841875354448954}]}, {"text": "Comparative experiments are conducted on large corpora for six language pairs.", "labels": [], "entities": []}, {"text": "We not only compare each adapted system with the baseline, but also combine them to further improve the domain-specific systems.", "labels": [], "entities": []}, {"text": "Finally, we attend the WMT2014 medical summary sentence translation constrained task and our systems achieve the best BLEU scores for Czech-English, English-German, French-English language pairs and the second best BLEU scores for reminding pairs.", "labels": [], "entities": [{"text": "WMT2014 medical summary sentence translation constrained task", "start_pos": 23, "end_pos": 84, "type": "TASK", "confidence": 0.7588238290378025}, {"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.998877227306366}, {"text": "BLEU", "start_pos": 215, "end_pos": 219, "type": "METRIC", "confidence": 0.9987710118293762}]}], "introductionContent": [{"text": "This paper presents the experiments conducted by the NLP 2 CT Laboratory at the University of Macau for WMT2014 medical sentence translation task on six language pairs: Czech-English (cs-en), French-English (fr-en), German-English (de-en) and the reverse direction pairs, i.e., en-cs, en-fr and en-de.", "labels": [], "entities": [{"text": "WMT2014 medical sentence translation task", "start_pos": 104, "end_pos": 145, "type": "TASK", "confidence": 0.8490681052207947}]}, {"text": "By comparing the medical text with common text, we discovered some interesting phenomena in medical genre.", "labels": [], "entities": []}, {"text": "We apply domain-specific techniques in data pre-processing, language model adaptation, translation model adaptation, numeric and hyphenated words translation.", "labels": [], "entities": [{"text": "language model adaptation", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6793926060199738}, {"text": "translation model adaptation", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.8931405941645304}, {"text": "numeric and hyphenated words translation", "start_pos": 117, "end_pos": 157, "type": "TASK", "confidence": 0.6366480588912964}]}, {"text": "Compared to the baseline systems (detailed in, the results of each method show reasonable gains.", "labels": [], "entities": []}, {"text": "We combine individual approach to further improve the performance of our systems.", "labels": [], "entities": []}, {"text": "To validate the robustness and language-independency of individual and combined systems, we conduct experiments on the official training data (detailed in Section 3) in all six language pairs.", "labels": [], "entities": []}, {"text": "We anticipate the numeric comparison (BLEU scores) on these individual and combined domain adaptation approaches that could be valuable for others on building a real-life domain-specific system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.8326489925384521}]}, {"text": "The reminder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we detail the configurations of our experiments as well as the baseline systems.", "labels": [], "entities": []}, {"text": "Section 3 presents the specific preprocessing for medical data.", "labels": [], "entities": []}, {"text": "In Section 4 and 5, we describe the language model (LM) and translation model (TM) adaptation, respectively.", "labels": [], "entities": [{"text": "translation model (TM) adaptation", "start_pos": 60, "end_pos": 93, "type": "TASK", "confidence": 0.7117070704698563}]}, {"text": "Besides, the techniques for numeric and hyphenated words translation are reported in Section 6 and 7.", "labels": [], "entities": [{"text": "numeric and hyphenated words translation", "start_pos": 28, "end_pos": 68, "type": "TASK", "confidence": 0.6312578916549683}]}, {"text": "Finally, the performance of design systems and the official results are reported in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "All available training data from both WMT2014 standard translation task 1 (general-domain data) and medical translation task 2 (in-domain data) are used in this study.", "labels": [], "entities": [{"text": "WMT2014 standard translation task", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.750287190079689}, {"text": "medical translation task", "start_pos": 100, "end_pos": 124, "type": "TASK", "confidence": 0.7685985565185547}]}, {"text": "The official medical summary development sets (dev) are used for tuning and evaluating all the comparative systems.", "labels": [], "entities": []}, {"text": "The official medical summary test sets (test) are only used in our final submitted systems.", "labels": [], "entities": []}, {"text": "The experiments were carried outwith the Moses 1.0 3 ( . The translation and the re-ordering model utilizes the \"growdiag-final\" symmetrized word-to-word alignments created with MGIZA++ 4 and the training scripts from Moses.", "labels": [], "entities": [{"text": "translation", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9679514765739441}]}, {"text": "A 5-gram LM was trained using the SRILM toolkit), exploiting improved modified Kneser-Ney smoothing, and quantizing both probabilities and back-off weights.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9049683809280396}]}, {"text": "For the log-linear model training, we take the minimum-error-rate training (MERT) method as described in).", "labels": [], "entities": [{"text": "minimum-error-rate training (MERT)", "start_pos": 47, "end_pos": 81, "type": "METRIC", "confidence": 0.8498101234436035}]}], "tableCaptions": [{"text": " Table 1: BLEU scores of two baseline systems  trained on original and processed corpora for  different language pairs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9980181455612183}]}, {"text": " Table 2: Statistics summary of corpora after pre-processing.  only use the in-domain training data, but also the  selected pseudo in-domain data 8 from general- domain corpus to enhance the LMs", "labels": [], "entities": []}]}