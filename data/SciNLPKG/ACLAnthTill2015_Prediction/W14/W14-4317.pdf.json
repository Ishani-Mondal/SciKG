{"title": [{"text": "Dialogue Act Modeling for Non-Visual Web Access", "labels": [], "entities": [{"text": "Dialogue Act Modeling", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6452048122882843}, {"text": "Non-Visual Web Access", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.6819859147071838}]}], "abstractContent": [{"text": "Speech-enabled dialogue systems have the potential to enhance the ease with which blind individuals can interact with the Web beyond what is possible with screen readers the currently available assistive technology which narrates the textual content on the screen and provides shortcuts to navigate the content.", "labels": [], "entities": []}, {"text": "In this paper, we present a dialogue act model towards developing a speech enabled browsing system.", "labels": [], "entities": []}, {"text": "The model is based on the corpus data that was collected in a wizard-of-oz study with 24 blind individuals who were assigned a gamut of browsing tasks.", "labels": [], "entities": []}, {"text": "The development of the model included extensive experiments with assorted feature sets and classifiers; the outcomes of the experiments and the analysis of the results are presented.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Web is the \"go-to\" computing infrastructure for participating in our fast-paced digital society.", "labels": [], "entities": []}, {"text": "It has the potential to provide an even greater benefit to blind people who once required human assistance with many of their activities.", "labels": [], "entities": []}, {"text": "According to the American Federation for the Blind, there are 21.5 million Americans who have vision loss, of whom 1.5 million are computer users.", "labels": [], "entities": []}, {"text": "Blind users employ screen readers as the assistive technology to interact with digital content (e.g.., JAWS) and VoiceOver).", "labels": [], "entities": [{"text": "JAWS", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.8097970485687256}]}, {"text": "Screen readers serially narrate the content of the screen using textto-speech engines and enable users to navigate in the content using keyboard shortcuts and touchscreen gestures.", "labels": [], "entities": []}, {"text": "Navigating content-rich web pages and conducting online transactions spanning multiple pages requires using shortcuts and this can get quite cumbersome and tedious.", "labels": [], "entities": []}, {"text": "Specifically, in online shopping a user typically browses through product categories, searches for products, adds products to cart, logs into his/her account, and finally makes a payment.", "labels": [], "entities": []}, {"text": "All these steps require screen-reader users listen through a lot of content, fill forms, and find links and buttons that have to be selected to get through these steps.", "labels": [], "entities": []}, {"text": "If users do not want to go through all content on the page, they have to remember and use a number of different shortcuts.", "labels": [], "entities": [{"text": "remember", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9856797456741333}]}, {"text": "Beginner users often use the \"Down\" key to go through the page line byline, listening to all content on the way (.", "labels": [], "entities": []}, {"text": "Now suppose that blind users were to tell the web browser what they wanted to accomplish and let the browsing application automatically determine what has to be clicked, fill out forms, help find products, answer questions, breeze through checkout, and wherever possible, relieve the user from doing all the mundane and tedious low-level operations such as clicking, typing, etc.", "labels": [], "entities": []}, {"text": "The ability to carryout a dialogue with the web browser at a higher level has the potential to overcome the limitations of shortcut-based screen reading and thus offers a richer and more productive user experience for blind people.", "labels": [], "entities": []}, {"text": "The first step toward building a dialogue-based system is the understanding of what users could say and dialogue act modeling.", "labels": [], "entities": [{"text": "dialogue act modeling", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.6290387809276581}]}, {"text": "Although dialogue act modeling is a well-researched topic (with details provided in related work -Section 2), it has remained unexplored in the context of web accessibility for blind people.", "labels": [], "entities": [{"text": "dialogue act modeling", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.8239457209904989}]}, {"text": "The commercial speech-based applications have been around fora while and new ones continue to emerge at a rapid pace; however, these are mainly stand-alone (e.g.., Apple's Siri) domain specific systems that are not connected to web browsers, which precludes dialogue-based interaction with the Web.", "labels": [], "entities": []}, {"text": "Current spoken input modules integrated with web browsers are limited to certain specific functionalities such as search (e.g.., Google's voice search) or are used as a measure of last resort (e.g.., Siri searching for terms online).", "labels": [], "entities": []}, {"text": "In this paper, we made a principal step towards building a dialogue-based assistive web browsing system for blind people; specifically, we built a dialogue act model for non-visual access to the Web.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Corpus details. \u03c4 u -number of utterances,  \u03c4 d -number of dialogs.", "labels": [], "entities": []}, {"text": " Table 3: Inter-rater agreement measured in terms  of Cohen's \u03ba for all tasks in the corpus.", "labels": [], "entities": []}]}