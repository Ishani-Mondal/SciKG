{"title": [{"text": "Verbal Valency Frame Detection and Selection in Czech and English", "labels": [], "entities": [{"text": "Verbal Valency Frame Detection", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7441683709621429}]}], "abstractContent": [{"text": "We present a supervised learning method for verbal valency frame detection and selection , i.e., a specific kind of word sense disambiguation for verbs based on subcat-egorization information, which amounts to detecting mentions of events in text.", "labels": [], "entities": [{"text": "verbal valency frame detection", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6347019448876381}, {"text": "word sense disambiguation", "start_pos": 116, "end_pos": 141, "type": "TASK", "confidence": 0.6719521284103394}, {"text": "detecting mentions of events in text", "start_pos": 210, "end_pos": 246, "type": "TASK", "confidence": 0.7754393815994263}]}, {"text": "We use the rich dependency annotation present in the Prague Dependency Tree-banks for Czech and English, taking advantage of several analysis tools (taggers, parsers) developed on these datasets previously.", "labels": [], "entities": [{"text": "Prague Dependency Tree-banks", "start_pos": 53, "end_pos": 81, "type": "DATASET", "confidence": 0.9777863621711731}]}, {"text": "The frame selection is based on manually created lexicons accompanying these treebanks, namely on PDT-Vallex for Czech and EngVallex for English.", "labels": [], "entities": []}, {"text": "The results show that verbal predicate detection is easier for Czech, but in the subsequent frame selection task, better results have been achieved for English.", "labels": [], "entities": [{"text": "verbal predicate detection", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.7542818784713745}]}], "introductionContent": [{"text": "Valency frames area detailed semantic and syntactic description of individual predicate senses.", "labels": [], "entities": []}, {"text": "1 As such, they represent different event types.", "labels": [], "entities": []}, {"text": "We present a system for automatic detection and selection of verbal valency frames in Czech and English, which corresponds to detecting and disambiguating mentions of events in text.", "labels": [], "entities": [{"text": "detecting and disambiguating mentions of events in text", "start_pos": 126, "end_pos": 181, "type": "TASK", "confidence": 0.8054505959153175}]}, {"text": "This is an important step toward event instance identification, which should help greatly in linking the mentions of a single event.", "labels": [], "entities": [{"text": "event instance identification", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.6786718666553497}]}, {"text": "We took advantage of the fact that the Prague family of dependency treebanks contains comparable valency frame annotation for Czech and English (cf. Section 2).", "labels": [], "entities": [{"text": "Prague family of dependency treebanks", "start_pos": 39, "end_pos": 76, "type": "DATASET", "confidence": 0.9265516877174378}]}, {"text": "Thus the feature templates used in frame selection are the same and the features initially considered differ only in their instantiation (cf. Section 3).", "labels": [], "entities": [{"text": "frame selection", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7610606551170349}]}, {"text": "While somewhat similar to the) in the predicate detection part, our task differs from the semantic role labeling task in that the whole frame has to be detected, not only individual arguments, and is therefore more difficult not only in terms of scoring, but also in the selection part: several verbal frames might share the same syntactic features, making them virtually indistinguishable unless semantics is taken into account, combined with a detailed grammatical and morphological context.", "labels": [], "entities": [{"text": "predicate detection", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.828520804643631}, {"text": "semantic role labeling", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.7250703970591227}]}], "datasetContent": [{"text": "We evaluated the system described in Section 3 on PDT 2.5 for Czech and on the English part of PCEDT 2.0 for English.", "labels": [], "entities": [{"text": "PCEDT 2.0", "start_pos": 95, "end_pos": 104, "type": "DATASET", "confidence": 0.8742074966430664}]}, {"text": "From PCEDT 2.0, whose division follows the PTB-WSJ, we used Sections 02-21 as training data, Section 24 as development data, and Section 23 as evaluation data.", "labels": [], "entities": [{"text": "PCEDT 2.0", "start_pos": 5, "end_pos": 14, "type": "DATASET", "confidence": 0.8983313739299774}, {"text": "PTB-WSJ", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9838972687721252}]}, {"text": "Since the system is intended to be used in a fully automatic annotation scenario, we use automatically parsed sentences with projected goldstandard valency frames to train the classifiers.", "labels": [], "entities": []}, {"text": "The results of our system in the best setting for both languages are given in.", "labels": [], "entities": []}, {"text": "The unlabeled figures measure the ability of the system to detect that a valency frame should be filled fora given node.", "labels": [], "entities": []}, {"text": "The labeled figures show the overall system performance, including selecting the correct frame.", "labels": [], "entities": []}, {"text": "The frame selection accuracy value shows only the percentage of frames selected correctly, disregarding misplaced frames.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9478479623794556}]}, {"text": "The accuracy for ambiguous verbs further disregards frames of lemmas where only one frame is possible.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992327690124512}]}, {"text": "Here we include a comparison of our trained classifier with a baseline that always selects the most frequent frame seen in the training data.", "labels": [], "entities": []}, {"text": "Our results using the classifier for both languages have been confirmed by pairwise bootstrap resampling to be significantly better than the baseline at 99% level.", "labels": [], "entities": []}, {"text": "We can see that the system is more successful in Czech in determining whether a valency frame should be filled fora given node.", "labels": [], "entities": []}, {"text": "This is most probably given by the fact that the most Czech verbs are easily recognizable by their morphological endings, whereas English verbs are more prone to be misrepresented as nouns or adjectives.", "labels": [], "entities": []}, {"text": "The English system is better at selecting the correct valency frame.", "labels": [], "entities": []}, {"text": "This is probably caused by a more fine-grained word sense resolution in the Czech valency lexicon, where more figurative uses and idioms are included.", "labels": [], "entities": [{"text": "word sense resolution", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.6678696473439535}]}, {"text": "For example, over 16% Redundancy-Maximum Relevance (mRMR) (), ReliefF, mutual information (MI), symmetric uncertainty (, and an average of the ranks given by mRMR and MI.", "labels": [], "entities": [{"text": "Redundancy-Maximum Relevance (mRMR)", "start_pos": 22, "end_pos": 57, "type": "METRIC", "confidence": 0.8721302032470704}, {"text": "ReliefF", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.98087477684021}, {"text": "mutual information (MI)", "start_pos": 71, "end_pos": 94, "type": "METRIC", "confidence": 0.6220453262329102}]}, {"text": "The best setting for Czech uses L1-regularization and 10% best features according to Anova, with other parameters tuned on the development set for each lemma.", "labels": [], "entities": []}, {"text": "The best setting for English uses L2-regularization with best feature subsets tuned on the development set and fixed parameters C = 0.1, E = 0.01. 9 All other parts of the system, up to the identification of the frame to be filled in, are identical with the baseline. of errors in the Czech evaluation data were caused just by idioms or light verb constructions not being recognized by our system.", "labels": [], "entities": [{"text": "Czech evaluation data", "start_pos": 285, "end_pos": 306, "type": "DATASET", "confidence": 0.7967140475908915}]}, {"text": "In Czech, additional 15% of errors occurred for verbs where two or more valency frames share the same number of arguments and their labels, but these verb senses are considered different (because they have different meaning), compared to only 9% in English.", "labels": [], "entities": []}], "tableCaptions": []}