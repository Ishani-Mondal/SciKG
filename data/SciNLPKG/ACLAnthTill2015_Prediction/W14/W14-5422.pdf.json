{"title": [{"text": "Towards automatic annotation of communicative gesturing", "labels": [], "entities": []}], "abstractContent": [{"text": "We report ongoing work on automatic annotation of head and hand gestures in videos of conversational interaction.", "labels": [], "entities": []}, {"text": "The Anvil annotation tool was extended by two plugins for automatic face and hand tracking.", "labels": [], "entities": [{"text": "hand tracking", "start_pos": 77, "end_pos": 90, "type": "TASK", "confidence": 0.6414922922849655}]}, {"text": "The results of automatic annotation are compared with the human annotations on the same data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hand and head movements are important inhuman communication as they not only accompany speech to emphasize the message, but also coordinate and control the interaction.", "labels": [], "entities": []}, {"text": "However, video analysis of human behaviour is a slow and resource-consuming procedure even by trained annotators using tools such as Anvil.", "labels": [], "entities": []}, {"text": "There is an urgent need for more advanced tools to speedup the process by performing higher-level annotation functions automatically.", "labels": [], "entities": []}, {"text": "We use two Anvil plugins, a face tracker (Jongejan 2012) and a hand tracker, that automatically create annotations for head and hand movements.", "labels": [], "entities": []}, {"text": "Objects are recognized based on visual features such as colour and texture, and Haar-liked digital image features, using OpenCV framework.", "labels": [], "entities": []}, {"text": "Motion trajectories are estimated by calculating the mean velocity and acceleration during the time span of a set of frames (we experimented with 7 frames as more than 10 makes the algorithm insensitive for quick, short movements).", "labels": [], "entities": []}, {"text": "Movement annotations with respect to velocity and acceleration are marked on the appropriate Anvil track, to indicate the movement and its start and stop.", "labels": [], "entities": [{"text": "Anvil track", "start_pos": 93, "end_pos": 104, "type": "DATASET", "confidence": 0.9240284860134125}]}, {"text": "The interface has controls for minimum saturation threshold and for how many frames to skip).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Annotation features for head and hand movements.", "labels": [], "entities": []}, {"text": " Table 2. Manual and automatic head movement annotations for 4 videos.  Precision: Velocity 73%, Acceleration 66%", "labels": [], "entities": [{"text": "Precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9987194538116455}, {"text": "Velocity", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9969493746757507}, {"text": "Acceleration", "start_pos": 97, "end_pos": 109, "type": "METRIC", "confidence": 0.9995889067649841}]}]}