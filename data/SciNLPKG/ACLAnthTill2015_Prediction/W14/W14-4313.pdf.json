{"title": [{"text": "Back to the Blocks World: Learning New Actions through Situated Human-Robot Dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes an approach fora robotic arm to learn new actions through dialogue in a simplified blocks world.", "labels": [], "entities": []}, {"text": "In particular, we have developed a three-tier action knowledge representation that on one hand, supports the connection between symbolic representations of language and continuous sensorimotor representations of the robot; and on the other hand, supports the application of existing planning algorithms to address novel situations.", "labels": [], "entities": []}, {"text": "Our empirical studies have shown that, based on this representation the robot was able to learn and execute basic actions in the blocks world.", "labels": [], "entities": []}, {"text": "When a human is engaged in a dialogue to teach the robot new actions, step-by-step instructions lead to better learning performance compared to one-shot instructions.", "labels": [], "entities": []}], "introductionContent": [{"text": "When anew generation of robots start to work side-by-side with their human partners in joint tasks, they will often encounter new objects or are required to perform new actions.", "labels": [], "entities": []}, {"text": "It is important for the robots to automatically learn new knowledge about the environment and the tasks from their human partners.", "labels": [], "entities": []}, {"text": "To address this issue, this paper describes our recent work on action learning through dialogue.", "labels": [], "entities": []}, {"text": "As a first step, we limit our investigation to a simple blocks world motivated by Terry Winograd's early work.", "labels": [], "entities": []}, {"text": "By using an industrial robotic arm (SCHUNK) in this small world, we are interested in addressing the following questions.", "labels": [], "entities": []}, {"text": "First, human language has a discrete and symbolic representation, but the robot arm has a continuous representation for its movements.", "labels": [], "entities": []}, {"text": "Where should the connections between the symbolic representation and the continuous representation take place so that human language can be used to direct the robot's movements?", "labels": [], "entities": []}, {"text": "Second, when the robot learns new tasks from its human partner, how to represent the acquired knowledge effectively so that it can be applied in novel situations?", "labels": [], "entities": []}, {"text": "Third, during human-robot dialogue, when the robot fails to perform the expected actions due to the lack of knowledge, how should the human teach the robot new actions? through step-by-step instructions or one-shot instructions?", "labels": [], "entities": []}, {"text": "With these questions in mind, we have developed a three-tier action knowledge representation for the robotic arm.", "labels": [], "entities": []}, {"text": "The lower level connects to the physical arm and defines the trajectories of executing three atomic actions supported by the arm (i.e., open gripper, close gripper, move).", "labels": [], "entities": []}, {"text": "The middle level defines primitive operators such as Open Grip, Close Grip and MoveTo in the fashion of the traditional AI planner and directly links to the lower level.", "labels": [], "entities": []}, {"text": "The upper-level captures the high-level actions acquired by learning from the human.", "labels": [], "entities": []}, {"text": "These highlevel actions are represented as the desired goal states of the environment as a result of these actions.", "labels": [], "entities": []}, {"text": "This three-tier representation allows the robot to automatically come up with a sequence of lower-level actions by applying existing planning algorithms.", "labels": [], "entities": []}, {"text": "Based on this representation, we implemented a dialogue system for action learning and further conducted an empirical study with human subjects.", "labels": [], "entities": [{"text": "action learning", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.7596165835857391}]}, {"text": "In particular, we compared the dialogue based on the step-by-step instructions (i.e., one step at a time and wait for the robot's response at each step before going to the next step) with the one-shot instructions (i.e., give the instruction with all steps at once).", "labels": [], "entities": []}, {"text": "Our empirical results have shown that the three-tier knowledge representation can capture the learned new action and apply it to novel situations.", "labels": [], "entities": []}, {"text": "Although the step-by-step instructions resulted in a lengthier teaching process compared to the one-shot instructions, they led to better learning performance for the robot.", "labels": [], "entities": []}], "datasetContent": [{"text": "Similar to the setup shown in, in the study, we have multiple blocks with different colors and sizes placed on a flat surface, with a SCHUNK arm positioned on one side of the surface and the human subject seated on the opposite side.", "labels": [], "entities": []}, {"text": "The video stream of the environment is sent to the vision system).", "labels": [], "entities": []}, {"text": "With the pre-trained object model of each block, the vision system could capture blocks' 3D positions from each frame.", "labels": [], "entities": []}, {"text": "Five human subjects participated in our experiments 2 . During the study, each subject was informed about the basic actions the robot can perform (i.e., open gripper, close gripper, and move to) and was instructed to teach the robot several new actions through dialogue.", "labels": [], "entities": []}, {"text": "Each subject would go through the following two phases:", "labels": [], "entities": []}], "tableCaptions": []}