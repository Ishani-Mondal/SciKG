{"title": [{"text": "Lexical Access Preference and Constraint Strategies for Improving Multiword Expression Association within Semantic MT Evaluation", "labels": [], "entities": [{"text": "Lexical Access Preference", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7524537245432535}, {"text": "Improving Multiword Expression", "start_pos": 56, "end_pos": 86, "type": "TASK", "confidence": 0.6894528865814209}, {"text": "Semantic MT", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.6256789267063141}]}], "abstractContent": [{"text": "We examine lexical access preferences and constraints in computing multiword expression associations from the standpoint of a high-impact extrinsic task-based performance measure, namely semantic machine translation evaluation.", "labels": [], "entities": [{"text": "semantic machine translation evaluation", "start_pos": 187, "end_pos": 226, "type": "TASK", "confidence": 0.7318173050880432}]}, {"text": "In automated MT evaluation metrics, machine translations are compared against human reference translations, which are almost never worded exactly the same way except in the most trivial of cases.", "labels": [], "entities": [{"text": "MT evaluation metrics", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.944473385810852}]}, {"text": "Because of this, one of the most important factors in correctly predicting semantic translation adequacy is the accuracy of recognizing alternative lexical realizations of the same multiword expressions in semantic role fillers.", "labels": [], "entities": [{"text": "predicting semantic translation adequacy", "start_pos": 64, "end_pos": 104, "type": "TASK", "confidence": 0.7759670615196228}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9982833862304688}, {"text": "semantic role fillers", "start_pos": 206, "end_pos": 227, "type": "TASK", "confidence": 0.6358177661895752}]}, {"text": "Our results comparing bag-of-words, maximum alignment, and inversion transduction grammars indicate that cognitively motivated ITGs provide superior lexical access characteristics for multiword expression associations, leading to state-of-the-art improvements in correlation with human adequacy judgments.", "labels": [], "entities": []}], "introductionContent": [{"text": "We investigate lexical access strategies in the context of computing multiword expression associations within automatic semantic MT evaluation metrics-a high-impact real-world extrinsic task-based performance measure.", "labels": [], "entities": []}, {"text": "The inadequacy of lexical coverage of multiword expressions is one of the serious issues in machine translation and automatic MT evaluation; there are simply too many forms to enumerate explicitly within the lexicon.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8232761919498444}, {"text": "MT evaluation", "start_pos": 126, "end_pos": 139, "type": "TASK", "confidence": 0.9672811329364777}]}, {"text": "Automatic MT evaluation has driven machine translation research fora decade and a half, but until recently little has been done to use lexical semantics as the main foundation for MT metrics.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.9748237729072571}, {"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7954860925674438}, {"text": "MT metrics", "start_pos": 180, "end_pos": 190, "type": "TASK", "confidence": 0.9322639107704163}]}, {"text": "Common surface-form oriented metrics like BLEU), NIST), METEOR (Banerjee and), CDER (), WER (), and TER) do not explicitly reflect semantic similarity between the reference and machine translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9969736337661743}, {"text": "NIST", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.8100335001945496}, {"text": "METEOR", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9839030504226685}, {"text": "WER", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9519278407096863}, {"text": "TER", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9947815537452698}]}, {"text": "Several large scale meta-evaluations) have in fact reported that BLEU significantly disagrees with human judgments of translation adequacy.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9959625601768494}]}, {"text": "Recently, the MEANT semantic frame based MT evaluation metrics (, have instead directly couched MT evaluation in the more cognitive terms of semantic frames, by measuring the degree to which the basic event structure is preserved by translationthe \"who did what to whom, for whom, when, where, how and why\")-emphasizing that a good translation is one that can successfully be understood by a human.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.69963139295578}, {"text": "MT evaluation", "start_pos": 96, "end_pos": 109, "type": "TASK", "confidence": 0.9714197218418121}]}, {"text": "Across a variety of language pairs and genres, MEANT was shown to correlate better with human adequacy judgment than both ngram based MT evaluation metrics such as BLEU (), NIST, and METEOR (, as well as edit-distance based metrics such as CDER (), WER (), and TER) when evaluating MT output: Examples of automatic shallow semantic parses.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.8199935555458069}, {"text": "BLEU", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.9965355396270752}, {"text": "NIST", "start_pos": 173, "end_pos": 177, "type": "DATASET", "confidence": 0.8704705238342285}, {"text": "TER", "start_pos": 261, "end_pos": 264, "type": "METRIC", "confidence": 0.9835364818572998}, {"text": "MT output", "start_pos": 282, "end_pos": 291, "type": "TASK", "confidence": 0.9267182648181915}, {"text": "automatic shallow semantic parses", "start_pos": 305, "end_pos": 338, "type": "TASK", "confidence": 0.6980151981115341}]}, {"text": "Both the reference and machine translations are parsed using automatic English SRL.", "labels": [], "entities": []}, {"text": "There are no semantic frames for MT3 since automatic SRL decided to drop the predicate.", "labels": [], "entities": [{"text": "MT3", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.8154032826423645}, {"text": "SRL", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.6476433873176575}]}, {"text": "adequacy) across different languages (English and Chinese) and different genres (formal newswire text, informal web forum text and informal public speech).", "labels": [], "entities": []}, {"text": "Because of this, we have chosen to run our lexical association experiments in the context of the necessity of recognizing matching semantic role fillers, approximately 85% of which are multiword expressions in our data, the overwhelming majority of which would not be enumerated within conventional lexicons.", "labels": [], "entities": [{"text": "recognizing matching semantic role fillers", "start_pos": 110, "end_pos": 152, "type": "TASK", "confidence": 0.5922162771224976}]}, {"text": "We compare four common lexical access approaches to aggregation, preferences, and constraints: bagof-words, two different types of maximal alignment, and inversion transduction grammar based methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we discuss experiments comparing the four alternative lexical access preference and constraint strategies.", "labels": [], "entities": []}, {"text": "We compared using the DARPA GALE P2.5 Chinese-English translation test set, as used in Lo and Wu (2011a).", "labels": [], "entities": [{"text": "DARPA GALE P2.5 Chinese-English translation test set", "start_pos": 22, "end_pos": 74, "type": "DATASET", "confidence": 0.7635197469166347}]}, {"text": "The corpus includes the Chinese input sentences, each accompanied by an English reference translation and three participating state-of-the-art MT systems' output.", "labels": [], "entities": []}, {"text": "We computed sentence-level correlations following the benchmark assessment procedure used by WMT and NIST MetricsMaTr, which use Kendall's \u03c4 correlation coefficient, to evaluate the correlation of evaluation metrics against human judgment on ranking the translation adequacy of the three systems' output.", "labels": [], "entities": [{"text": "WMT", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.9428603649139404}]}, {"text": "A higher value for Kendall's \u03c4 indicates more similarity to the human adequacy rankings by the evaluation metrics.", "labels": [], "entities": [{"text": "Kendall's \u03c4", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.5648615260918936}]}, {"text": "The range of possible values of Kendall's \u03c4 correlation coefficient is, where 1 means the: Sentence-level correlation with human adequacy judgements on different partitions of GALE P2.5 data.", "labels": [], "entities": [{"text": "Kendall's \u03c4 correlation coefficient", "start_pos": 32, "end_pos": 67, "type": "METRIC", "confidence": 0.6152974843978882}, {"text": "GALE P2.5 data", "start_pos": 176, "end_pos": 190, "type": "DATASET", "confidence": 0.85920516649882}]}, {"text": "For reference, the human HMEANT upper bound is 0.53-so the fully automatic ITG based MEANT approximation is not far from closing the gap.", "labels": [], "entities": [{"text": "HMEANT upper", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.9388906359672546}, {"text": "MEANT", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.9153151512145996}]}, {"text": "For both reference and machine translations, the ASSERT () semantic role labeler was used to automatically predict semantic parses.", "labels": [], "entities": [{"text": "ASSERT", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.734113335609436}, {"text": "predict semantic parses", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.6373731791973114}]}], "tableCaptions": [{"text": " Table 1: Sentence-level correlation with human adequacy judgements on different partitions of GALE  P2.5 data. For reference, the human HMEANT upper bound is 0.53-so the fully automatic ITG based  MEANT approximation is not far from closing the gap.", "labels": [], "entities": [{"text": "GALE  P2.5 data", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.8327133258183798}, {"text": "HMEANT upper", "start_pos": 137, "end_pos": 149, "type": "METRIC", "confidence": 0.9328246116638184}, {"text": "MEANT", "start_pos": 198, "end_pos": 203, "type": "METRIC", "confidence": 0.943416953086853}]}]}