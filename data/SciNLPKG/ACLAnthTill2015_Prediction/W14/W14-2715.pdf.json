{"title": [{"text": "Collective Stance Classification of Posts in Online Debate Forums", "labels": [], "entities": [{"text": "Collective Stance Classification of Posts in Online Debate Forums", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.828633553451962}]}], "abstractContent": [{"text": "Online debate sites area large source of informal and opinion-sharing dialogue on current socio-political issues.", "labels": [], "entities": []}, {"text": "Inferring users' stance (PRO or CON) towards discussion topics in domains such as politics or news is an important problem, and is of utility to researchers, government organizations , and companies.", "labels": [], "entities": [{"text": "Inferring users' stance (PRO or CON) towards discussion topics in domains such as politics or news", "start_pos": 0, "end_pos": 98, "type": "TASK", "confidence": 0.7713947196801504}]}, {"text": "Predicting users' stance supports identification of social and political groups, building of better recommender systems, and personaliza-tion of users' information preferences to their ideological beliefs.", "labels": [], "entities": [{"text": "identification of social and political groups", "start_pos": 34, "end_pos": 79, "type": "TASK", "confidence": 0.8733801047007242}]}, {"text": "In this paper, we develop a novel collective classification approach to stance classification, which makes use of both structural and linguistic features, and which collectively labels the posts' stance across a network of the users' posts.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.9060890972614288}]}, {"text": "We identify both linguistic features of the posts and features that capture the underlying relationships between posts and users.", "labels": [], "entities": []}, {"text": "We use probabilistic soft logic (PSL) (Bach et al., 2013) to model post stance by leveraging both these local linguistic features as well as the observed network structure of the posts to reason over the dataset.", "labels": [], "entities": []}, {"text": "We evaluate our approach on 4FORUMS (Walker et al., 2012b), a collection of discussions from an online debate site on issues ranging from gun control to gay marriage.", "labels": [], "entities": [{"text": "4FORUMS (Walker et al., 2012b)", "start_pos": 28, "end_pos": 58, "type": "DATASET", "confidence": 0.8349629044532776}, {"text": "gun control to gay marriage", "start_pos": 138, "end_pos": 165, "type": "TASK", "confidence": 0.6266597509384155}]}, {"text": "We show that our collective classification model is able to easily incorporate rich, relational information and outperforms a local model which uses only linguistic information.", "labels": [], "entities": [{"text": "collective classification", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.6563689112663269}]}], "introductionContent": [{"text": "Modeling user stance (PRO, in discussion topics in online social media debate is of interest to researchers, corporations and governmental organizations alike.", "labels": [], "entities": []}, {"text": "Predicting a user's stance towards a given issue can support the identification of social or political groups (, help develop better recommendation systems, or tailor users' information preferences to their ideologies and beliefs.", "labels": [], "entities": [{"text": "identification of social or political groups", "start_pos": 65, "end_pos": 109, "type": "TASK", "confidence": 0.8312025765577952}]}, {"text": "Stance classification problems consist of a collection of debate-style discussions by authors on different controversial, political topics.", "labels": [], "entities": [{"text": "Stance classification problems", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9512418905893961}]}, {"text": "While these maybe spoken as in the Congressional Debates corpus (, we focus on forum posts on social media debate sites.", "labels": [], "entities": [{"text": "Congressional Debates corpus", "start_pos": 35, "end_pos": 63, "type": "DATASET", "confidence": 0.6743359963099161}]}, {"text": "Users on debate sites share their opinions freely, using informal and social language, providing a rich and much more challenging domain for stance prediction.", "labels": [], "entities": [{"text": "stance prediction", "start_pos": 141, "end_pos": 158, "type": "TASK", "confidence": 0.9862846434116364}]}, {"text": "Social media debate sites contain online discussions with posts from various authors, where each post is either a response to another post or the root of the discussion).", "labels": [], "entities": []}, {"text": "Posts are linked to one another by either rebuttal or agreement links and are labelled for stance, either PRO or CON, depending on the framing of the issue under discussion.", "labels": [], "entities": []}, {"text": "Each post reflects the stance and sentiment of its author.", "labels": [], "entities": []}, {"text": "Authors may participate in multiple discussions in the same topic, and may discuss multiple topics.", "labels": [], "entities": []}, {"text": "For example consider the sample posts from the online discussion forum 4forums.com shown in.", "labels": [], "entities": []}, {"text": "Here, we see discussion topics, together with sample quotes and responses, where the response is a direct reply to the quote text.", "labels": [], "entities": []}, {"text": "The annotations for stance were gathered using Amazon's Mechanical Turk service with an interface that allowed annotators to see complete discussions.", "labels": [], "entities": [{"text": "stance", "start_pos": 20, "end_pos": 26, "type": "TASK", "confidence": 0.9702502489089966}]}, {"text": "Quotes provide additional context that were used by human annotators in a separate task for annotating agreement and disagreement.", "labels": [], "entities": []}, {"text": "Responses can be labeled as either PRO or CON toward the topic.", "labels": [], "entities": [{"text": "PRO", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.870849609375}]}, {"text": "For the example shown in, Quote Q, Response R Stance Topic Q: I thought I'd start anew thread for those newcomers who don't want to be shocked by sick minded nazi XXXX.", "labels": [], "entities": [{"text": "Response R Stance Topic Q", "start_pos": 35, "end_pos": 60, "type": "METRIC", "confidence": 0.793123972415924}]}, {"text": "When are fetuses really alive, and how many fetuses are actually aborted (murdered) before that time?", "labels": [], "entities": []}, {"text": "R: The heart starts beating 3 weeks after conception, and you can't live without a beating heart, but me personally, I think that as soon as the miracle starts, (egg and sperm combine) that is when life begins.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8719624876976013}]}, {"text": "I know it's more of a spiritual thing for me instead of a fact.", "labels": [], "entities": []}, {"text": ":) CON Abortion Q2: Most americans support a Federal Marriage Amendment.", "labels": [], "entities": [{"text": "CON Abortion Q2", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.711317221323649}]}, {"text": "Defining Marriage as a union between a man and a woman.", "labels": [], "entities": []}, {"text": "This is the text of the Amend: Marriage in the United States shall consist only of the union of a man and a woman.", "labels": [], "entities": [{"text": "Amend", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.8109782934188843}]}, {"text": "Neither this constitution or the constitution of any state, nor state or federal law, shall be construed to require that marital status or the legal incidents thereof be conferred upon unmarried couples or groups.", "labels": [], "entities": []}, {"text": "R2: Debator, why does it bother you so much that some people are gay?", "labels": [], "entities": []}, {"text": "People like certain things when they have sex.", "labels": [], "entities": []}, {"text": "Example: A man likes a women with small boobs.", "labels": [], "entities": []}, {"text": "Or, a man likes a women with nice legs.", "labels": [], "entities": []}, {"text": "People like the way certain things feel (I'm not giving te example for that one;) ).", "labels": [], "entities": []}, {"text": "So why does it bother people that someone's sexual prefference is just a little kinkier than thiers?", "labels": [], "entities": []}], "datasetContent": [{"text": "We first describe the dataset we use for evaluation and then describe our evaluation method and results.", "labels": [], "entities": []}, {"text": "We evaluate our proposed approach on discussions from https://www.4forums.com, an online debate site on social and political issues.", "labels": [], "entities": []}, {"text": "The dataset is publicly available as part of the Internet Argument Corpus, an annotated collection of 109,533 forum posts ().", "labels": [], "entities": [{"text": "Internet Argument Corpus", "start_pos": 49, "end_pos": 73, "type": "DATASET", "confidence": 0.8384208877881368}]}, {"text": "On 4FORUMS, a user initiates a discussion by posting anew question or comment under a topic, or participate in an ongoing discussion by replying to any of the posts in the thread.", "labels": [], "entities": []}, {"text": "The discussions were given to English speaking Mechanical Turk annotators fora number of annotation tasks to get labels for the stances of discussion participants towards the topic, and scores for each post in a discussion indicating whether it is in agreement or disagreement with the preceding post.", "labels": [], "entities": []}, {"text": "The scores for agreement and disagreement were on a 11 point scale implemented using a slider, and annotators were given quote/response pairs to determine if the response text agreed or disagreed with the quote text.", "labels": [], "entities": []}, {"text": "We use the mean score across the 5-7 annotators used in the task.", "labels": [], "entities": []}, {"text": "A more negative value indicates higher inter-annotator confidence of disagreement, and a more positive value indicates higher confidence of agreement.", "labels": [], "entities": []}, {"text": "The gold-standard annotation used for the stance label of each post is given by the majority annotation among 3-8 Mechanical Turk annotators performed as a separate task, using entire discussions to determine the stance of the authors in the discussion towards the topic.", "labels": [], "entities": []}, {"text": "We use the stance of each post's author to determine the post's stance.", "labels": [], "entities": []}, {"text": "For our experiments, we use all posts with annotations for stance, and about 90% of these posts also have annotations for agree-ment/disagreement.", "labels": [], "entities": [{"text": "stance", "start_pos": 59, "end_pos": 65, "type": "TASK", "confidence": 0.9475423693656921}]}, {"text": "The discussions span many topics, and gives a summary of the topics we consider in our experiments and the distribution of posts across these topics.", "labels": [], "entities": []}, {"text": "Each post in a discussion comes as a quote-response pair, where the quote is the text that the post is in response to, and the response is the post text.", "labels": [], "entities": []}, {"text": "We refer to () fora full description of the corpus and the annotation process.", "labels": [], "entities": []}, {"text": "In order to evaluate our methods, we split the dataset into training and testing sets by randomly selecting half the authors from each topic and their posts for the training set and using the remaining authors and their posts for the test set.", "labels": [], "entities": []}, {"text": "This way, we ensure that no two authors appear in both training and test sets for the same topic, since stance is topic-dependent.", "labels": [], "entities": []}, {"text": "We create 10 randomly sampled train/test splits for evaluation.", "labels": [], "entities": []}, {"text": "Each split contains about 18,000 posts.", "labels": [], "entities": []}, {"text": "For each train/test split, we train a linear SVM for each topic, with the L2-regularized-L1-loss SVM implemented in the LibLINEAR package.", "labels": [], "entities": []}, {"text": "We use only the linguistic features from the posts, for each topic in the training set.", "labels": [], "entities": []}, {"text": "We refer to the baseline model which only uses the the output of the SVM as the LOCAL model.", "labels": [], "entities": [{"text": "LOCAL", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.926525890827179}]}, {"text": "We output the predictions from LOCAL model and get stance labels for posts in both the training and test sets.", "labels": [], "entities": []}, {"text": "We use the predictions as prior information for the true stance label in our PSL model, with the hasLabel predicate.", "labels": [], "entities": []}, {"text": "We use the gold standard stance annotation (PRO, CON) for each post as ground truth for weight learning and inference.", "labels": [], "entities": [{"text": "stance annotation (PRO, CON)", "start_pos": 25, "end_pos": 53, "type": "METRIC", "confidence": 0.6167636045387813}, {"text": "weight learning", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.8433210849761963}]}, {"text": "A truth value of 1 for isPostPro and isAuthPro denotes a PRO stance and a truth value of 0 denotes a CON stance.", "labels": [], "entities": []}, {"text": "We learn the weights of our PSL model (initially set to 1) for each of our training sets and perform inference on each of the test sets.", "labels": [], "entities": []}, {"text": "shows averages for F1 score for the positive class (PRO), area under the precision-recall curve (AUC-PR) for the negative class (CON) and area under the ROC curve (AUROC) over the 10 train/test splits.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9812752306461334}, {"text": "precision-recall curve (AUC-PR)", "start_pos": 73, "end_pos": 104, "type": "METRIC", "confidence": 0.9446800112724304}, {"text": "ROC curve (AUROC)", "start_pos": 153, "end_pos": 170, "type": "METRIC", "confidence": 0.9390266299247741}]}, {"text": "For the PSL model, the measures are computed for joint inference overall topics in the test sets.", "labels": [], "entities": [{"text": "PSL", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9487688541412354}]}, {"text": "For the per-topic linear SVMs (LOCAL model), we compute the measures individually for the predictions of each topic in the test sets and take a weighted average over the topics.", "labels": [], "entities": []}, {"text": "Our PSL model outperforms the LOCAL model, with statistically significant improvements in the F1 score and AUC-PR for the negative class.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9926132559776306}, {"text": "AUC-PR", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9955911636352539}]}, {"text": "Moreover, our model completes weight learning and inference on the order of seconds, boasting an advantage in computational efficiency, while also maintaining model interpretability.", "labels": [], "entities": [{"text": "weight learning", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.8276804089546204}]}, {"text": "shows the weights learned by the PSL model for the rules in one of the train/test splits of the experiment.", "labels": [], "entities": []}, {"text": "The first two rules relating post stance and author stance are weighted more heavily, in part because the writesPost predicate has a grounding for each author-post pair and contributes to lots of groundings of the rule.", "labels": [], "entities": []}, {"text": "The rules that capture the alternating disagreement stance also have significant weight, while the rules denoting agreement both between posts and between authors are weighted least heavily since there are far fewer instances of agreement than disagreement.", "labels": [], "entities": []}, {"text": "This matches our intuition of political debates.", "labels": [], "entities": []}, {"text": "We also explored variations of the PSL model by removing the first two rules relating post stance and author stance and found that the weight learning algorithm drove the weights of the other rules close to 0, worsening the performance.", "labels": [], "entities": []}, {"text": "We also removed rules 3-10 that capture agreement/disagreement from the model, and found that the model performs poorly when disregarding the links between nodes entirely.", "labels": [], "entities": []}, {"text": "The PSL model learns to weight the first and second rule very highly, and does worse than when considering the prior alone.", "labels": [], "entities": []}, {"text": "Thus, the combination of the rules gives the model its advantage, allowing the PSL model to make use of a richer structure that has multiple types of relations and more information.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Overview of topics in 4FORUMSdataset.", "labels": [], "entities": [{"text": "4FORUMSdataset", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.880716860294342}]}]}