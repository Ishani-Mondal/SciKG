{"title": [{"text": "A Novel Two-stage Framework for Extracting Opinionated Sentences from News Articles", "labels": [], "entities": [{"text": "Extracting Opinionated Sentences from News Articles", "start_pos": 32, "end_pos": 83, "type": "TASK", "confidence": 0.9028981427351633}]}], "abstractContent": [{"text": "This paper presents a novel two-stage framework to extract opinionated sentences from a given news article.", "labels": [], "entities": [{"text": "extract opinionated sentences from a given news article", "start_pos": 51, "end_pos": 106, "type": "TASK", "confidence": 0.6308112926781178}]}, {"text": "In the first stage, Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifier by utilizing the local features assigns a score to each sentence-the score signifies the probability of the sentence to be opinionated.", "labels": [], "entities": []}, {"text": "In the second stage, we use this prior within the HITS (Hyperlink-Induced Topic Search) schema to exploit the global structure of the article and relation between the sentences.", "labels": [], "entities": []}, {"text": "In the HITS schema, the opinionated sentences are treated as Hubs and the facts around these opinions are treated as the Authorities.", "labels": [], "entities": [{"text": "HITS schema", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.8908030986785889}]}, {"text": "The algorithm is implemented and evaluated against a set of manually marked data.", "labels": [], "entities": []}, {"text": "We show that using HITS significantly improves the precision over the baseline Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9995428323745728}]}, {"text": "We also argue that the proposed method actually discovers the underlying structure of the article, thus extracting various opinions, grouped with supporting facts as well as other supporting opinions from the article.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the advertising based revenues becoming the main source of revenue, finding novel ways to increase focussed user engagement has become an important research topic.", "labels": [], "entities": []}, {"text": "A typical problem faced by web publishing houses like Yahoo!, is understanding the nature of the comments posted by readers of 10 5 articles posted at any moment on its website.", "labels": [], "entities": [{"text": "understanding the nature of the comments posted by readers of 10 5 articles posted at any moment", "start_pos": 65, "end_pos": 161, "type": "TASK", "confidence": 0.6453922163037693}]}, {"text": "A lot of users engage in discussions in the comments section of the articles.", "labels": [], "entities": []}, {"text": "Each user has a different perspective and thus comments in that genre -this many a times, results in a situation where the discussions in the comment section wander faraway from the articles topic.", "labels": [], "entities": []}, {"text": "In order to assist users to discuss relevant points in the comments section, a possible methodology can be to generate questions from the article's content that seek user's opinions about various opinions conveyed in the article (.", "labels": [], "entities": []}, {"text": "It would also direct the users into thinking about a spectrum of various points that the article covers and encourage users to share their unique, personal, daily-life experience in events relevant to the article.", "labels": [], "entities": []}, {"text": "This would thus provide a broader viewpoint for readers as well as perspective questions can be created thus catering to users with rich user generated content, this in turn can increase user engagement on the article pages.", "labels": [], "entities": []}, {"text": "Generating such questions manually for huge volume of articles is very difficult.", "labels": [], "entities": []}, {"text": "However, if one could identify the main opinionated sentences within the article, it will be much easier for an editor to generate certain questions around these.", "labels": [], "entities": []}, {"text": "Otherwise, the sentences themselves may also serve as the points for discussion by the users.", "labels": [], "entities": []}, {"text": "Hence, in this paper we discuss a two-stage algorithm which picks opinionated sentences from the articles.", "labels": [], "entities": []}, {"text": "The algorithm assumes an underlying structure for an article, that is, each opinionated sentence is supported by a few factual statements that justify the opinion.", "labels": [], "entities": []}, {"text": "We use the HITS schema to exploit this underlying structure and pick opinionated sentences from the article.", "labels": [], "entities": [{"text": "HITS schema", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.8868513405323029}]}, {"text": "The main contribtutions of this papers are as follows.", "labels": [], "entities": []}, {"text": "First, we present a novel two-stage framework for extracting opinionated sentences from a news article.", "labels": [], "entities": [{"text": "extracting opinionated sentences from a news article", "start_pos": 50, "end_pos": 102, "type": "TASK", "confidence": 0.8243900282042367}]}, {"text": "Secondly, we propose anew evaluation metric that takes into account the fact that since the amount of polarity (and thus, the number of opinionated sentences) within documents can vary a lot and thus, we should stress on the ratio of opinionated sentences in the top sentences, relative to the ratio of opinionated sentences in the article.", "labels": [], "entities": []}, {"text": "Finally, discussions on how the proposed algorithm captures the underlying structure of the opinions and surrounding facts in a news article reveal that the algorithm does much more than just extracting opinionated sentences.", "labels": [], "entities": []}, {"text": "This paper has been organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses related work in this field.", "labels": [], "entities": []}, {"text": "In section 3, we discuss our two-stage model in further details.", "labels": [], "entities": []}, {"text": "Section 4 discusses the experimental framework and the results.", "labels": [], "entities": []}, {"text": "Further discussions on the underlying assumption behind using HITS along with error analysis are carried out in Section 5.", "labels": [], "entities": [{"text": "HITS", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.6989445090293884}, {"text": "Section 5", "start_pos": 112, "end_pos": 121, "type": "DATASET", "confidence": 0.9246100187301636}]}, {"text": "Conclusions and future work are detailed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiment was conducted with 90 news articles in politics domain from Yahoo!", "labels": [], "entities": []}, {"text": "The sentences in the articles were marked as opinionated or factual by a group of annotators.", "labels": [], "entities": []}, {"text": "In the training set, 1393 out of 3142 sentences were found to be opinianated.", "labels": [], "entities": []}, {"text": "In the test set, 347 out of 830 sentences were marked as opinionated.", "labels": [], "entities": []}, {"text": "Out of these 90 articles, 70 articles were used for training the Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifier as well as for tuning various parameters.", "labels": [], "entities": []}, {"text": "The rest 20 articles were used for testing.", "labels": [], "entities": []}, {"text": "The evaluation was done in an Information Retrieval setting.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.6815105974674225}]}, {"text": "That is, the system returns the sentences in a decreasing order of their score (or probability in the case of Na\u00a8\u0131veNa\u00a8\u0131ve Bayes) as being opinionated.", "labels": [], "entities": []}, {"text": "We then utilize the human judgements (provided by the annotators) to compute precision at various points.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9988596439361572}]}, {"text": "Let op(.) be a binary function fora given rank such that op(r) = 1 if the sentence returned as rank r is opinionated as per the human judgements.", "labels": [], "entities": []}, {"text": "AP @k precision is calculated as follows: While the precision at various points indicates how reliable the results returned by the system are, it does not take into account the fact that some of the documents are opinion-rich and some are not.", "labels": [], "entities": [{"text": "AP @k precision", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.5638775303959846}, {"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9975342750549316}]}, {"text": "For the opinion-rich documents, a high P @k value might be similar to picking sentences randomly, whereas for the documents with a very few opinions, even a lower P @k value might be useful.", "labels": [], "entities": [{"text": "P @k value", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9536985009908676}]}, {"text": "We, therefore, devise another evaluation metric M @k that indicates the ratio of opinionated sentences at any point, normalized with respect to the ratio of opinionated sentences in the article.", "labels": [], "entities": []}, {"text": "Correspondingly, an M @k value is calculated as where Ratio op denotes the fraction of opinionated sentences in the whole article.", "labels": [], "entities": [{"text": "Ratio op", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9622206687927246}]}, {"text": "Thus Ratio op = Number of opinionated sentences Number of sentences The parameters that we needed to fix for the HITS algorithm were the weight function W ij and the threshold at which we stop the iteration.", "labels": [], "entities": [{"text": "Ratio op", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9550367891788483}]}, {"text": "We varied from 0.0001 to 0.1 multiplying it by 10 in each step.", "labels": [], "entities": []}, {"text": "The results were not sensitive to the value of and we used = 0.01.", "labels": [], "entities": []}, {"text": "For fixing the weight function, we tried out various combinations using the criteria outlined in Section 3.2.", "labels": [], "entities": []}, {"text": "Various weight functions and the corresponding P @5 and M @5 scores are shown in.", "labels": [], "entities": [{"text": "P @5 and M @5 scores", "start_pos": 47, "end_pos": 67, "type": "METRIC", "confidence": 0.8198264315724373}]}, {"text": "Firstly, we varied kin Sim ij k and found that the square of the similarity function gives better results.", "labels": [], "entities": []}, {"text": "Then, keeping it constant, we varied l in H i land found the best results for l = 3.", "labels": [], "entities": []}, {"text": "Then, keeping both of these constants, we varied \u03b1 in (\u03b1 + 1 d ).", "labels": [], "entities": []}, {"text": "We found the best results for \u03b1 = 1.0.", "labels": [], "entities": []}, {"text": "With this \u03b1, we tried to vary l again but it only reduced the final score.", "labels": [], "entities": []}, {"text": "Therefore, we fixed the weight function to be Note that H i (0) in Equation 6 corresponds to the probablity assigned by the classifier that the sentence Si is opinionated.", "labels": [], "entities": []}, {"text": "We use the classifier results as the baseline for the comparisons.", "labels": [], "entities": []}, {"text": "The second-stage HITS algorithm is then applied and we compare the performance with respect to the classifier.", "labels": [], "entities": []}, {"text": "shows the comparison results for various precision scores for the classifier and the HITS algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9944420456886292}]}, {"text": "In practical situation, an editor requires quick identification of 3-5 opinionated sentences from the article, which she can then use to formulate questions.", "labels": [], "entities": []}, {"text": "We thus report P @k and M @k values fork = 3 and k = 5.", "labels": [], "entities": []}, {"text": "From the results shown in, it is clear that applying the second-stage HITS over the Na\u00a8\u0131veNa\u00a8\u0131ve Bayes Classifier improves the performance by a large degree, both in term of P @k and M @k.", "labels": [], "entities": []}, {"text": "For instance, the first-stage NB Classifier gives a P @5 of 0.52 and P @3 of 0.53.", "labels": [], "entities": []}, {"text": "Using the classifier outputs during the second-stage HITS algorithm improves the  preformance by 21.2% to 0.63 in the case of P @5.", "labels": [], "entities": []}, {"text": "For P @3, the improvements were much more significant and a 35.8% improvement was obtained over the NB classifier.", "labels": [], "entities": []}, {"text": "M @5 and M @3 scores also improve by 17.7% and 30.8% respectively.", "labels": [], "entities": [{"text": "M @5", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7757849295934042}]}, {"text": "Strikingly, while the classifier gave nearly the same scores for P @k and M @k fork = 3 and k = 5, HITS gave much better results fork = 3 thank = 5.", "labels": [], "entities": [{"text": "HITS", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8036983609199524}]}, {"text": "Specially, the P @3 and M @3 scores obtained by HITS were very encouraging, indicating that the proposed approach helps in pushing the opinionated sentences to the top.", "labels": [], "entities": [{"text": "P @3", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9505855441093445}, {"text": "M @3 scores", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.9300539046525955}, {"text": "HITS", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.8669750690460205}]}, {"text": "This clearly shows the advantage of using the global structure of the document in contrast with the features extracted from the sentence itself, ignoring the context.", "labels": [], "entities": []}, {"text": "show the P @5, M @5, P @3 and M @3 scores for individual documents as numbered from 1 to 20 on the X-axis.", "labels": [], "entities": [{"text": "M @3 scores", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.8181018978357315}]}, {"text": "The articles are sorted as per the ratio of P @5 (and M @5) obtained using the HITS and NB classifier.", "labels": [], "entities": [{"text": "HITS", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.7707808017730713}, {"text": "NB classifier", "start_pos": 88, "end_pos": 101, "type": "DATASET", "confidence": 0.8032792210578918}]}, {"text": "Y-axis shows the corresponding scores.", "labels": [], "entities": [{"text": "Y-axis", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8749839067459106}]}, {"text": "Two different lines are used to represent the results as returned by the classifier and the HITS algorithm.", "labels": [], "entities": []}, {"text": "A dashed line denotes the scores obtained by HITS while a continuous line denotes the scores obtained by the NB classifier.", "labels": [], "entities": [{"text": "HITS", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.7234834432601929}]}, {"text": "A detailed analysis of these figures can help us draw the following conclusions: \u2022 For 40% of the articles (numbered 13 to 20) HITS improves over the baseline NB classifier.", "labels": [], "entities": [{"text": "HITS", "start_pos": 127, "end_pos": 131, "type": "METRIC", "confidence": 0.6509316563606262}]}, {"text": "For 40% of the articles (numbered 5 to 12) the results provided by HITS were the same as that of the baseline.", "labels": [], "entities": [{"text": "HITS", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.8580927848815918}]}, {"text": "For 20% of the articles (numbered 1 to 4) HITS gives a performance lower than that of the baseline.", "labels": [], "entities": [{"text": "HITS", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9140729904174805}]}, {"text": "Thus, for 80% of the documents, the second-stage performs at least as good as the first stage.", "labels": [], "entities": []}, {"text": "This indicates that the second-stage HITS is quite robust.", "labels": [], "entities": [{"text": "HITS", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.7302986979484558}]}, {"text": "\u2022 M @5 results are much more robust for the HITS, with 75% of the documents having an M @5 score > 1.", "labels": [], "entities": [{"text": "HITS", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.8025032877922058}, {"text": "M @5 score", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.8394392281770706}]}, {"text": "An M @k score > 1 indicates that the ratio of opinionated sentences in top k sentences, picked up by the algorithm, is higher than the overall ratio in the article.", "labels": [], "entities": [{"text": "M @k score", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.9017651826143265}]}, {"text": "\u2022 For 45% of the articles, (numbered 6, 9 \u2212 11 and 15 \u2212 20), HITS was able to achieve a P @3 = 1.0.", "labels": [], "entities": [{"text": "HITS", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.769162654876709}, {"text": "P", "start_pos": 88, "end_pos": 89, "type": "METRIC", "confidence": 0.9912562370300293}]}, {"text": "Thus, for these 9 articles, the top 3 sentences picked up by the algorithm were all marked as opinionated.", "labels": [], "entities": []}, {"text": "The graphs also indicate a high correlation between the results obtained by the NB classifier and HITS.", "labels": [], "entities": [{"text": "HITS", "start_pos": 98, "end_pos": 102, "type": "DATASET", "confidence": 0.7374980449676514}]}, {"text": "We used Pearson's correlation to find the correlation strength.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 8, "end_pos": 29, "type": "METRIC", "confidence": 0.7699520985285441}]}, {"text": "For the P @5 values, the correlation was found to be 0.6021 and for the M @5 values, the correlation was obtained as 0.5954.", "labels": [], "entities": [{"text": "correlation", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9899133443832397}, {"text": "correlation", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.9754250049591064}]}, {"text": "In the next section, we will first attempt to further analyze the basic assumption behind using HITS, by looking at some actual Hub-Authority structures, captured by the algorithm.", "labels": [], "entities": []}, {"text": "We will also take some cases of failure and perform error analysis.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Average P @5 and M @5 scores: Performance  comparison between various functions for W ij", "labels": [], "entities": [{"text": "Average P @5", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8937364667654037}]}, {"text": " Table 3: Average P @5, M @5, P @3 and M @3 scores:  Performance comparison between the NB classifier and  HITS", "labels": [], "entities": [{"text": "NB", "start_pos": 88, "end_pos": 90, "type": "DATASET", "confidence": 0.8797546029090881}, {"text": "HITS", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.6742560267448425}]}]}