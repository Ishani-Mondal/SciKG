{"title": [], "abstractContent": [{"text": "This paper presents an annotation scheme fora new semantic annotation task with relevance for analysis and computation at both the clause level and the discourse level.", "labels": [], "entities": []}, {"text": "More specifically, we label the finite clauses of texts with the type of situation entity (e.g., eventualities, statements about kinds, or statements of belief) they introduce to the discourse, following and extending work by Smith (2003).", "labels": [], "entities": []}, {"text": "We take a feature-driven approach to annotation, with the result that each clause is also annotated with fundamental aspectual class, whether the main NP referent is specific or generic, and whether the situation evoked is episodic or habitual.", "labels": [], "entities": []}, {"text": "This annotation is performed (so far) on three sections of the MASC corpus, with each clause labeled by at least two annotators.", "labels": [], "entities": [{"text": "MASC corpus", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.9093906283378601}]}, {"text": "In this paper we present the annotation scheme, statistics of the corpus in its current version, and analyses of both inter-annotator agreement and intra-annotator consistency.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic expressions form patterns in discourse.", "labels": [], "entities": []}, {"text": "Passages of text can be analyzed in terms of the individuals, concepts, times and situations that they introduce to the discourse.", "labels": [], "entities": []}, {"text": "In this paper we introduce anew semantic annotation task which focuses on the latter and in particular their aspectual nature.", "labels": [], "entities": []}, {"text": "Situations are expressed at the clause level; situation entity (SE) annotation is the task of associating individual clauses of text with the type of SE introduced to the discourse by the clause.", "labels": [], "entities": [{"text": "situation entity (SE) annotation", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.6775979350010554}]}, {"text": "Following, we distinguish the following SE types (see Sec.", "labels": [], "entities": []}, {"text": "3.1): EVENTS, STATES, GENERALIZING SEN-TENCES, GENERIC SENTENCES, FACTS, PROPOSITIONS, QUESTIONS and IMPERATIVES.", "labels": [], "entities": [{"text": "EVENTS", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.990806519985199}, {"text": "STATES", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9397178888320923}, {"text": "SEN-TENCES", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.6132809519767761}, {"text": "FACTS", "start_pos": 66, "end_pos": 71, "type": "METRIC", "confidence": 0.7399877905845642}, {"text": "IMPERATIVES", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.9808921217918396}]}, {"text": "Although these categories are clearly distinct from one another on theoretical grounds, in practice it can be difficult to cleanly draw boundaries between them.", "labels": [], "entities": []}, {"text": "We improve annotation consistency by defining the SE types in terms of features whose values are easier for annotators to identify, and which provide guidance for distinguishing the more complex SE types.", "labels": [], "entities": []}, {"text": "As with most complex annotation tasks, multiple interpretations are often possible, and we cannot expect agreement on all instances.", "labels": [], "entities": []}, {"text": "The feature-driven approach (see Sec. 3.2) is a valuable source of information for investigating annotator disagreements, as the features indicate precisely how annotators differ in their interpretation of the situation.", "labels": [], "entities": []}, {"text": "Analysis of intra-annotator consistency shows that personal preferences of annotators play a role, and we conclude that disagreements often highlight cases where multiple interpretations are possible.", "labels": [], "entities": []}, {"text": "We further argue that such cases should be handled carefully in supervised learning approaches targeting methods to automatically classify situation entity types.", "labels": [], "entities": []}, {"text": "As the first phase of the SE annotation project, we are in the process of annotating the written portion of MASC (, the manually-annotated subcorpus of the Open American National Corpus.", "labels": [], "entities": [{"text": "MASC", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.714593768119812}, {"text": "Open American National Corpus", "start_pos": 156, "end_pos": 185, "type": "DATASET", "confidence": 0.7161596640944481}]}, {"text": "MASC provides texts from 20 different genres and has already been annotated with various linguistic and semantic phenomena.", "labels": [], "entities": [{"text": "MASC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.736873984336853}]}, {"text": "1 MASC offers several benefits: it includes text from a wide variety of genres, it facilitates study of interactions between various levels of analysis, and the data is freely available with straightforward mechanisms for distribution.", "labels": [], "entities": [{"text": "1 MASC", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.6358731687068939}]}, {"text": "In this paper we report results for three of the MASC genres: news, letters, and jokes.", "labels": [], "entities": [{"text": "MASC genres", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.800153374671936}]}, {"text": "Once a larger portion of MASC has been labeled with SEs and their associated features, we will add our annotations to those currently available for MASC.", "labels": [], "entities": []}, {"text": "We mark the SE types of clauses with the aim of providing a large corpus of annotated text for the following purposes: (1) To assess the applicability of SE type classification as described by: to what extent can situations be classified easily, which borderline cases occur, and how do humans perform on this task?", "labels": [], "entities": [{"text": "SE type classification", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.8134520252545675}]}, {"text": "(see Sec. 4) (2) Training, development and evaluation of automatic systems classifying situation entities, as well as sub-tasks which have (partially) been studied by the NLP community, but for which no large annotated corpora are available (for example, automatically predicting the fundamental aspectual class of verbs in context or the genericity of clauses and noun phrases).", "labels": [], "entities": [{"text": "predicting the fundamental aspectual class of verbs in context", "start_pos": 269, "end_pos": 331, "type": "TASK", "confidence": 0.7425202793545194}]}, {"text": "(3) To provide a foundation for analysis of the theory of Discourse Modes, which we explain next (Sec. 2).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Cohen's \u03ba, for pairs of annotators on the MASC news section.", "labels": [], "entities": [{"text": "MASC news section", "start_pos": 52, "end_pos": 69, "type": "DATASET", "confidence": 0.9655816555023193}]}, {"text": " Table 3: Cohen's \u03ba, for two annotators on three different sections of MASC.", "labels": [], "entities": [{"text": "MASC", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.8375558853149414}]}, {"text": " Table 4: Consistency study: Cohen's \u03ba, for two annotators, comparing against each other and against  themselves (re-annotated data). A1 = annotator A in first pass, B2 = annotator B in second pass etc.", "labels": [], "entities": []}]}