{"title": [{"text": "Bilingual Termbank Creation via Log-Likelihood Comparison and Phrase-Based Statistical Machine Translation", "labels": [], "entities": [{"text": "Bilingual Termbank Creation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6769131422042847}, {"text": "Statistical Machine Translation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.5962108472983042}]}], "abstractContent": [{"text": "Bilingual termbanks are important for many natural language processing (NLP) applications, especially in translation workflows in industrial settings.", "labels": [], "entities": []}, {"text": "In this paper, we apply a log-likelihood comparison method to extract monolingual terminology from the source and target sides of a parallel corpus.", "labels": [], "entities": []}, {"text": "Then, using a Phrase-Based Statistical Machine Translation model, we create a bilingual terminology with the extracted monolingual term lists.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation", "start_pos": 14, "end_pos": 58, "type": "TASK", "confidence": 0.5926087647676468}]}, {"text": "We manually evaluate our novel terminology extraction model on English-to-Spanish and English-to-Hindi data sets, and observe excellent performance for all domains.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.8905969560146332}, {"text": "English-to-Hindi data sets", "start_pos": 86, "end_pos": 112, "type": "DATASET", "confidence": 0.8061115145683289}]}, {"text": "Furthermore, we report the performance of our monolin-gual terminology extraction model comparing with a number of the state-of-the-art terminology extraction models on the English-to-Hindi datasets.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7341461777687073}, {"text": "terminology extraction", "start_pos": 136, "end_pos": 158, "type": "TASK", "confidence": 0.7394848167896271}]}], "introductionContent": [{"text": "Terminology plays an important role in various NLP tasks including Machine Translation (MT) and Information Retrieval.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.8430905044078827}, {"text": "Information Retrieval", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.8441719710826874}]}, {"text": "It is also exploited inhuman translation workflows, where it plays a key role in ensuring translation consistency and reducing ambiguity across large translation projects involving multiple files and translators over along period of time.", "labels": [], "entities": []}, {"text": "The creation of monolingual and bilingual terminological resources using human experts are, however, expensive and time-consuming tasks.", "labels": [], "entities": []}, {"text": "In contrast, automatic terminology extraction is much faster and less expensive, but cannot be guaranteed to be error-free.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8633264303207397}]}, {"text": "Accordingly, in real NLP applications, a manual inspection is required to amend or discard anomalous items from an automatically extracted terminology list.", "labels": [], "entities": []}, {"text": "The automatic terminology extraction task starts with selecting candidate terms from the input domain corpus, usually in two different ways: (i) linguistic processors are used to identify noun phrases that are regarded as candidate terms), and (ii) non-linguistic n-gram word sequences are regarded as candidate terms.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.8579280376434326}]}, {"text": "Various statistical measures have been used to rank candidate terms, such as C-Value (, NC-Value (), log-likelihood comparison), and TF-IDF (.", "labels": [], "entities": [{"text": "TF-IDF", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.7641409635543823}]}, {"text": "In this paper, we present our bilingual terminology extraction model, which is composed of two consecutive and independent processes: 1.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7542016208171844}]}, {"text": "A log-likelihood comparison method is employed to rank candidate terms (n-gram word sequences) independently from the source and target sides of a parallel corpus, 2.", "labels": [], "entities": []}, {"text": "The extracted source terms are aligned to one or more extracted target terms using a Phrase-Based Statistical Machine Translation (PB-SMT) model ().", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation (PB-SMT)", "start_pos": 85, "end_pos": 138, "type": "TASK", "confidence": 0.663536765745708}]}, {"text": "We then evaluate our novel bilingual terminology extraction model on various domain corpora considering English-to-Spanish and low-resourced and less-explored English-to-Hindi language-pairs and see excellent performance for all data sets.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7470436990261078}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our two-stage terminology extraction model.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8393370509147644}]}, {"text": "Section 4 presents the results and analyses of our experiments, while Section 5 concludes, and provides avenues for further work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Of course, it is one thing to rapidly create translation assets such as bilingual termbanks, and another entirely to ensure the quality of such resources.", "labels": [], "entities": []}, {"text": "Accordingly, we evaluated the performance of our bilingual terminology extraction model on each English-to-Spanish and English-to-Hindi domain corpus reported in, with the evaluation goals being twofold: (i) measuring the accuracy of the monolingual terminology extraction process, and (ii) measuring the accuracy of our novel bilingual terminology creation model.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.6768178790807724}, {"text": "accuracy", "start_pos": 222, "end_pos": 230, "type": "METRIC", "confidence": 0.9946660995483398}, {"text": "terminology extraction", "start_pos": 250, "end_pos": 272, "type": "TASK", "confidence": 0.6823918372392654}, {"text": "accuracy", "start_pos": 305, "end_pos": 313, "type": "METRIC", "confidence": 0.998671293258667}]}, {"text": "As mentioned in Section 3.2, a source term maybe aligned with up to four target terms.", "labels": [], "entities": []}, {"text": "For evaluation purposes, we considered the top-100 source terms based on the LL values (cf. (1)) and their target counterparts (i.e. one to four target terms).", "labels": [], "entities": []}, {"text": "The quality of the extracted terms was judged by native Spanish and Hindi speakers, both with excellent English skills, and the evaluation results are reported in.", "labels": [], "entities": []}, {"text": "Note that we were notable to measure recall of the term extraction model on the domain corpora due to the unavailability of a reference terminology set.", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9979944229125977}, {"text": "term extraction", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.6906656920909882}]}, {"text": "The evaluator counted the number of valid terms in the source term list for the domain in question, and the percentage of valid terms with respect to the total number of terms (i.e. 100) is reported in the second column in.", "labels": [], "entities": []}, {"text": "We refer to this as VST (Valid Source Terms).", "labels": [], "entities": []}, {"text": "For each valid source term there are one to four target terms that are ranked according to the weights in.", "labels": [], "entities": []}, {"text": "In theory, therefore, the top-ranked target term is the most suitable target translation of the aligned source term.", "labels": [], "entities": []}, {"text": "The evaluator counted the number of instances where the top-ranked target term was a suitable target translation of the source term; the percentage with respect to the number of valid source terms is shown in the third column in, and denoted as VTT (Valid Target Terms).", "labels": [], "entities": [{"text": "VTT", "start_pos": 245, "end_pos": 248, "type": "METRIC", "confidence": 0.8988743424415588}]}, {"text": "The evaluator also reported the number of cases where any of the four target terms was a suitable translation of the source term; the percentage with respect to the number of valid source terms is given in the fourth column in.", "labels": [], "entities": []}, {"text": "Furthermore, the evaluator counted the number of instances where any of the four target terms with minor editing can be regarded as suitable target translation; the percentage with respect to the number of valid source terms is reported in the last column of.", "labels": [], "entities": []}, {"text": "In, we show three English-Spanish term-pairs extracted by our automatic term extractor where the target terms (Spanish) are slightly incorrect.", "labels": [], "entities": []}, {"text": "In all these examples the edit distance between the correct term and the one proposed by our automatic extraction method is quite low, meaning that just a few keystrokes can transform the candidate term into the correct one.", "labels": [], "entities": []}, {"text": "In these cases editing the candidate term is much cheaper (in terms of time) than creating the translations from scratch.", "labels": [], "entities": []}, {"text": "In, we see that the accuracy of the monolingual term extraction model varies from 72% to 94% for both English-to-Spanish and English-to-Hindi.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9995911717414856}, {"text": "monolingual term extraction", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.5863594512144724}]}, {"text": "For English-to-Spanish, the accuracy of our bilingual terminology creation model ranges from 86.1% to 93.6%, 91.7% to 97.8% and 93.1% to 97.8% when the 1-best, 4-best and 4-best with slightly edited target terms are considered, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9997062087059021}, {"text": "terminology creation", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.6793737560510635}]}, {"text": "For Englishto-Hindi, the accuracy of our bilingual terminology creation model ranges from 62.1% to 95.4%, 83.5% to 98.8% and 94.9% to 98.8% when the 1-best, 4-best and 4-best with slightly edited target terms are considered, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9997072815895081}, {"text": "terminology creation", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.6725879311561584}]}, {"text": "We are greatly encouraged by these results, as they demonstrate that our novel bilingual termbank creation method is robust in the face of the somewhat noisy monolingual term-extraction results; as a consequence, if better methods for suggesting monolingual term candidates are proposed, we expect the performance of our bilingual term-creation model to improve accordingly.", "labels": [], "entities": [{"text": "termbank creation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.6385086625814438}]}, {"text": "We calculated the distributions of unigram, bigram and trigram in the valid source terms (cf.) and reported in.", "labels": [], "entities": []}, {"text": "We also calculated the percentages of their distributions in the valid source terms averaged overall 10 data sets.", "labels": [], "entities": []}, {"text": "As can be seen from, the percentage of the average distribution of the trigram terms is quite low (i.e. 2.5%).", "labels": [], "entities": []}, {"text": "This result justifies our decision for extraction of up to 3-gram terms.).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Manual evaluation results obtained on the top-100 term pairs. VST: Valid Source Terms, VTT1:  Valid Target Terms (1-best), VTT4: Valid Target Terms (4-best), VTTME4: Valid Target Terms with  Minor Editing (4-best).", "labels": [], "entities": [{"text": "VST", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.5811342597007751}, {"text": "VTT1", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.6537187099456787}, {"text": "VTT4", "start_pos": 133, "end_pos": 137, "type": "DATASET", "confidence": 0.6915233135223389}, {"text": "VTTME4", "start_pos": 168, "end_pos": 174, "type": "DATASET", "confidence": 0.6506994962692261}]}, {"text": " Table 5: Distributions of unigram, bigram and trigram in the valid source term pairs (cf. second column  in", "labels": [], "entities": []}, {"text": " Table 6: Monolingual evaluation results. LLC: Log-Likelihood Comparison, STF: Simple Term Fre- quency, ACTF: Average Corpus Term Frequency, JK: Justeson Katz", "labels": [], "entities": [{"text": "ACTF", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9797998070716858}]}]}