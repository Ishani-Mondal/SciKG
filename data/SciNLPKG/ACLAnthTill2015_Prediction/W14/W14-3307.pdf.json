{"title": [{"text": "The KIT-LIMSI Translation System for WMT 2014 *", "labels": [], "entities": [{"text": "KIT-LIMSI Translation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6636151373386383}, {"text": "WMT 2014", "start_pos": 37, "end_pos": 45, "type": "TASK", "confidence": 0.6590469479560852}]}], "abstractContent": [{"text": "This paper describes the joined submission of LIMSI and KIT to the Shared Translation Task for the German-to-English direction.", "labels": [], "entities": [{"text": "Shared Translation Task", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.8602612217267355}]}, {"text": "The system consists of a phrase-based translation system using a pre-reordering approach.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6761502623558044}]}, {"text": "The base-line system already includes several models like conventional language models on different word factors and a discriminative word lexicon.", "labels": [], "entities": []}, {"text": "This system is used to generate a k-best list.", "labels": [], "entities": []}, {"text": "Ina second step, the list is reranked using SOUL language and translation models (Le et al., 2011).", "labels": [], "entities": []}, {"text": "Originally, SOUL translation models were applied to n-gram-based translation systems that use tuples as translation units instead of phrase pairs.", "labels": [], "entities": [{"text": "SOUL translation", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.9549372792243958}]}, {"text": "In this article, we describe their integration into the KIT phrase-based system.", "labels": [], "entities": []}, {"text": "Experimental results show that their use can yield significant improvements in terms of BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9812732934951782}]}], "introductionContent": [{"text": "This paper describes the KIT-LIMSI system for the Shared Task of the ACL 2014 Ninth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "Shared Task of the ACL 2014 Ninth Workshop on Statistical Machine Translation", "start_pos": 50, "end_pos": 127, "type": "TASK", "confidence": 0.6352555155754089}]}, {"text": "The system participates in the German-to-English translation task.", "labels": [], "entities": [{"text": "German-to-English translation task", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.7554448246955872}]}, {"text": "It consists of two main components.", "labels": [], "entities": []}, {"text": "First, a k-best list is generated using a phrasebased machine translation system.", "labels": [], "entities": [{"text": "phrasebased machine translation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.6158798237641653}]}, {"text": "This system will be described in Section 2.", "labels": [], "entities": []}, {"text": "Afterwards, the kbest list is reranked using SOUL (Structured OUtput Layer) models.", "labels": [], "entities": []}, {"text": "Thereby, a neural network language model (), as well as several translation models () are used.", "labels": [], "entities": []}, {"text": "A detailed description of these models can be found in Section 3.", "labels": [], "entities": []}, {"text": "While the translation system uses phrase pairs, the SOUL translation model uses tuples as described in the n-gram approach).", "labels": [], "entities": [{"text": "SOUL translation", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.8650758266448975}]}, {"text": "We describe the integration of the SOUL models into the translation system in Section 3.2.", "labels": [], "entities": []}, {"text": "Section 4 summarizes the experimental results and compares two different tuning algorithms: Minimum Error Rate Training and k-best Batch Margin Infused Relaxed Algorithm).", "labels": [], "entities": [{"text": "Minimum Error Rate Training", "start_pos": 92, "end_pos": 119, "type": "METRIC", "confidence": 0.9271225333213806}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results using KBMIRA", "labels": [], "entities": [{"text": "KBMIRA", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.6664648056030273}]}, {"text": " Table 2: Results using MERT. Results in bold correpond to the submitted system.", "labels": [], "entities": [{"text": "MERT", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.4507763981819153}]}]}