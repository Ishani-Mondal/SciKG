{"title": [{"text": "Word-Based Dialog State Tracking with Recurrent Neural Networks", "labels": [], "entities": [{"text": "Word-Based Dialog State Tracking", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6252075135707855}]}], "abstractContent": [{"text": "Recently discriminative methods for tracking the state of a spoken dialog have been shown to outperform traditional generative models.", "labels": [], "entities": []}, {"text": "This paper presents anew word-based tracking method which maps directly from the speech recognition results to the dialog state without using an explicit semantic decoder.", "labels": [], "entities": [{"text": "word-based tracking", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7369124889373779}]}, {"text": "The method is based on a recurrent neural network structure which is capable of generalising to unseen dialog state hypotheses, and which requires very little feature engineering.", "labels": [], "entities": []}, {"text": "The method is evaluated on the second Dialog State Tracking Challenge (DSTC2) corpus and the results demonstrate consistently high performance across all of the metrics.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge (DSTC2) corpus", "start_pos": 38, "end_pos": 84, "type": "DATASET", "confidence": 0.7605947628617287}]}], "introductionContent": [{"text": "While communicating with a user, statistical spoken dialog systems must maintain a distribution over possible dialog states in a process called dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.6632605294386545}]}, {"text": "This distribution, also called the belief state, directly determines the system's decisions.", "labels": [], "entities": []}, {"text": "In MDP-based systems, only the most likely dialog state is considered and in this case the primary metric is dialog state accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9727600812911987}]}, {"text": "In POMDP-based systems, the full distribution is considered and then the shape of the distribution as measured by an L2 norm is equally important ().", "labels": [], "entities": []}, {"text": "In both cases, good quality state tracking is essential to maintaining good overall system performance.", "labels": [], "entities": []}, {"text": "Typically, state tracking has assumed the output of a Spoken Language Understanding (SLU) component in the form of a semantic decoder, which maps the hypotheses from Automatic Speech Recognition (ASR) to a list of semantic hypotheses.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.81954026222229}, {"text": "Automatic Speech Recognition (ASR)", "start_pos": 166, "end_pos": 200, "type": "TASK", "confidence": 0.7849561870098114}]}, {"text": "This paper considers mapping directly from ASR hypotheses to an updated belief state at each turn in the dialog, omitting the intermediate SLU processing step.", "labels": [], "entities": [{"text": "ASR hypotheses", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8953491747379303}]}, {"text": "This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage.", "labels": [], "entities": [{"text": "word-based state tracking", "start_pos": 5, "end_pos": 30, "type": "TASK", "confidence": 0.625543882449468}]}, {"text": "Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.7309994995594025}]}, {"text": "Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (;.", "labels": [], "entities": [{"text": "discriminative state tracking", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.7046776413917542}]}, {"text": "One notable exception is, which used conditional random fields to model the sequence temporally.", "labels": [], "entities": []}, {"text": "Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (.", "labels": [], "entities": [{"text": "discriminative state tracking", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.6629883944988251}]}, {"text": "It is unclear whether differences in performance are due to feature engineering or the underlying models.", "labels": [], "entities": []}, {"text": "This paper proposes a method of using simple ngram type features which avoid the need for feature engineering.", "labels": [], "entities": []}, {"text": "Instead of using inputs with a select few very informative features, the approach is to use high-dimensional inputs with all the information to potentially reconstruct any such handcrafted feature.", "labels": [], "entities": []}, {"text": "The impact of significantly increasing the dimensionality of the inputs is managed by careful initialisation of model parameters.", "labels": [], "entities": []}, {"text": "Accuracy on unseen or infrequent slot values is an important concern, particularly for discriminative classifiers which are prone to overfitting training data.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9314218759536743}]}, {"text": "This is addressed by structuring the recurrent neural network to include a component which is independent of the actual slot value in question.", "labels": [], "entities": []}, {"text": "It thus learns general behaviours for specifying slots enabling it to successfully decode 292 ASR output which includes previously unseen slot values.", "labels": [], "entities": []}, {"text": "In summary, this paper presents a word-based approach to dialog state tracking using recurrent neural networks.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.8498185873031616}]}, {"text": "The model is capable of generalising to unseen dialog state hypotheses, and requires very little feature engineering.", "labels": [], "entities": []}, {"text": "The approach is evaluated in the second Dialog State Tracking Challenge (DSTC2) ( where it is shown to be extremely competitive, particularly in terms of the quality of its confidence scores.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge (DSTC2)", "start_pos": 40, "end_pos": 79, "type": "TASK", "confidence": 0.732228296143668}]}, {"text": "Following a brief outline of DSTC2 in section 2, the definition of the model is given in section 3.", "labels": [], "entities": [{"text": "DSTC2", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9348433017730713}]}, {"text": "Section 4 then gives details on the initialisation methods used for training.", "labels": [], "entities": []}, {"text": "Finally results on the DSTC2 evaluation are given in 5.", "labels": [], "entities": [{"text": "DSTC2 evaluation", "start_pos": 23, "end_pos": 39, "type": "DATASET", "confidence": 0.8859383165836334}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance on the dev set when varying initialisation techniques for word-based tracking. Acc  denotes the accuracy of the most likely belief at each turn, and L2 denotes the squared l2 norm between  the estimated belief distribution and correct (delta) distribution. For each row, 5 trackers are trained  and then combined using score averaging. The final row shows the results for the focus-based baseline  tracker (", "labels": [], "entities": [{"text": "word-based tracking", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7243216931819916}, {"text": "Acc", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9934074878692627}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9991174340248108}, {"text": "correct (delta) distribution", "start_pos": 249, "end_pos": 277, "type": "METRIC", "confidence": 0.9318959712982178}]}, {"text": " Table 2: Featured metrics on the test set for the 4 RNN trackers entered to the challenge.", "labels": [], "entities": []}]}