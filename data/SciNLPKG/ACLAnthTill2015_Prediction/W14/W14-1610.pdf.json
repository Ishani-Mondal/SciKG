{"title": [{"text": "Focused Entailment Graphs for Open IE Propositions", "labels": [], "entities": []}], "abstractContent": [{"text": "Open IE methods extract structured propositions from text.", "labels": [], "entities": []}, {"text": "However, these propositions are neither consolidated nor generalized , and querying them may lead to insufficient or redundant information.", "labels": [], "entities": []}, {"text": "This work suggests an approach to organize open IE propositions using entail-ment graphs.", "labels": [], "entities": []}, {"text": "The entailment relation unifies equivalent propositions and induces a specific-to-general structure.", "labels": [], "entities": []}, {"text": "We create a large dataset of gold-standard proposition entailment graphs, and provide a novel algorithm for automatically constructing them.", "labels": [], "entities": []}, {"text": "Our analysis shows that predicate entailment is extremely context-sensitive, and that current lexical-semantic resources do not capture many of the lexical inferences induced by proposition entailment.", "labels": [], "entities": [{"text": "predicate entailment", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.8672085702419281}]}], "introductionContent": [{"text": "Open information extraction (open IE) extracts natural language propositions from text without pre-defined schemas as in supervised relation extraction ().", "labels": [], "entities": [{"text": "Open information extraction (open IE) extracts natural language propositions from text", "start_pos": 0, "end_pos": 86, "type": "TASK", "confidence": 0.8225413721341354}, {"text": "supervised relation extraction", "start_pos": 121, "end_pos": 151, "type": "TASK", "confidence": 0.695889413356781}]}, {"text": "These propositions represent predicate-argument structures as tuples of natural language strings.", "labels": [], "entities": []}, {"text": "Open IE enables knowledge search by aggregating billions of propositions from the web . It may also be perceived as capturing an unsupervised knowledge representation schema, complementing supervised knowledge bases such as Freebase (, as suggested by.", "labels": [], "entities": [{"text": "knowledge search", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7059720605611801}]}, {"text": "However, language variability obstructs open IE from becoming a viable knowledge representation framework.", "labels": [], "entities": []}, {"text": "As it does not consolidate natural language expressions, querying a database of open IE propositions may lead to either insufficient or redundant information.", "labels": [], "entities": []}, {"text": "As an illustrative example, See demo: openie.cs.washington.edu querying the demo (footnote 1) for the generally equivalent relieves headache or treats headache returns two different lists of entities; out of the top few results, the only answers these queries seem to agree on are caffeine and sex.", "labels": [], "entities": []}, {"text": "This is a major drawback relative to supervised knowledge representations, which map natural language expressions to structured formal representations, such as treatments in Freebase.", "labels": [], "entities": []}, {"text": "In this work, we investigate an approach for organizing and consolidating open IE propositions using the novel notion of proposition entailment graphs (see) -graphs in which each node represents a proposition and each directed edge reflects an entailment relation, in the spirit of textual entailment ( . Entailment provides an effective structure for aggregating natural-language based information; it merges semantically equivalent propositions into cliques, and induces specification-generalization edges between them.", "labels": [], "entities": []}, {"text": "For example, (aspirin, eliminate, headache) entails, and is more specific than, (headache, respond to, painkiller).", "labels": [], "entities": []}, {"text": "We thus propose the task of constructing an entailment graph over a set of open IE propositions (Section 3), which is closely related to Berant et al's work (2012) who introduced predicate entailment graphs.", "labels": [], "entities": []}, {"text": "In contrast, our work explores propositions, which are essentially predicates instantiated with arguments, and thus semantically richer.", "labels": [], "entities": []}, {"text": "We provide a dataset of 30 such graphs, which represent 1.5 million pairwise entailment decisions between propositions (Section 4).", "labels": [], "entities": []}, {"text": "To approach this task, we extend the state-ofthe-art method for building entailment graphs) from predicates to complete propositions.", "labels": [], "entities": []}, {"text": "Both Snow et al (2006) and Berant et al used WordNet as distant supervision when training a local pairwise model of lexical entailment.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.9583531618118286}]}, {"text": "However, analyzing our data revealed that the lexical inferences captured in WordNet are quite dif-", "labels": [], "entities": [{"text": "WordNet", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9670118093490601}]}], "datasetContent": [{"text": "To construct our dataset of open IE extractions, we found Google's syntactic ngrams) as a useful source of high-quality propositions.", "labels": [], "entities": [{"text": "IE extractions", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.9073066115379333}]}, {"text": "Based on a corpus of 3.5 million English books, it aggregates every syntactic ngram -subtree of a dependency parse -with at most 4 dependency arcs.", "labels": [], "entities": []}, {"text": "The resource contains only tree fragments that appeared at least 10 times in the corpus, filtering out many low-quality syntactic ngrams.", "labels": [], "entities": []}, {"text": "We extracted the syntactic ngrams that reflect propositions, i.e. subject-verb-object fragments where object modifies the verb with either dobj or pobj.", "labels": [], "entities": []}, {"text": "Prepositions in pobj were concatenated to the verb (e.g. use with).", "labels": [], "entities": []}, {"text": "In addition, both subject and object must each be a noun phrase containing two tokens at most, which are either nouns or adjectives.", "labels": [], "entities": []}, {"text": "Each token in the extracted fragments was then lemmatized using WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9883091449737549}]}, {"text": "After lemmatization, we grouped all identical propositions and aggregated their counts.", "labels": [], "entities": []}, {"text": "Approximately 68 million propositions were collected.", "labels": [], "entities": []}, {"text": "We chose 30 topics from the healthcare domain (such as influenza, hiv, and penicillin).", "labels": [], "entities": []}, {"text": "For each topic, we collected the set of propositions containing it, and manually filtered noisy extractions.", "labels": [], "entities": []}, {"text": "This yielded 30 high-quality sets of 5,714 propositions in total, where each set becomes the set of nodes in a separate focused entailment graph.", "labels": [], "entities": []}, {"text": "The graphs range from 55 propositions (scurvy) to 562 (headache), with an average of over 190 propositions per graph.", "labels": [], "entities": [{"text": "headache", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9497190117835999}]}, {"text": "Summing the number of proposition pairs within each graph amounts to a total of 1.5 million potential entailment edges, which makes it by far the largest annotated textual entailment dataset to date.", "labels": [], "entities": []}, {"text": "We used a semi-automatic annotation process, which dramatically narrows down the number of manual decisions, and hence, the required annotation time.", "labels": [], "entities": []}, {"text": "In short, the annotators are given a series of small clustering tasks before annotating entailment between those clusters.", "labels": [], "entities": []}, {"text": "The annotation process was carried out by two native English speakers, with the aid of encyclopedic knowledge for unfamiliar medical terms.", "labels": [], "entities": []}, {"text": "The agreement on a subset of five randomly sampled graphs was \u03ba = 0.77.", "labels": [], "entities": []}, {"text": "Annotating a single graph took about an hour and a half on average.", "labels": [], "entities": []}, {"text": "Positive entailment judgements constituted only 8.4% of potential edges, and were found to be 100% transitive.", "labels": [], "entities": []}, {"text": "We observe that in nearly all of those cases, a natural alignment between entailing components occurs: predicates align with each other, the topic is shared, and the remaining non- The annotated dataset is publicly available on the first author's website.", "labels": [], "entities": []}, {"text": "topic argument aligns with its counterpart.", "labels": [], "entities": []}, {"text": "Consider the topic arthritis and the entailing proposition pair (arthritis, cause, pain)\u2192(symptom, associate with, arthritis); cause\u2192associate with, while pain\u2192symptom.", "labels": [], "entities": []}, {"text": "Rarely, some misalignments do occur; for instance (vaccine, protects, body)\u2192(vaccine, provides, protection).", "labels": [], "entities": []}, {"text": "However, it is almost always the case that propositions entail if and only if their aligned lexical components entail as well.", "labels": [], "entities": []}, {"text": "We evaluate the models in Sections 5 & 6 on the 30 annotated entailment graphs presented in Section 4.", "labels": [], "entities": []}, {"text": "During testing, each graph was evaluated separately.", "labels": [], "entities": []}, {"text": "The results presented in this section are all micro-averages, though macro-averages were also computed and found to reflect the same trends.", "labels": [], "entities": []}, {"text": "Models trained with distant supervision were evaluated on all graphs.", "labels": [], "entities": []}, {"text": "For directly super-vised methods, we used 2 \u00d7 6-fold cross validation (25 training graphs per fold).", "labels": [], "entities": []}, {"text": "In this scenario, each graph induced a set of labeled examplesits edges being positive examples, and the missing potential edges being negative ones -and the union of these sets was used as the training set of that cross-validation fold.", "labels": [], "entities": []}, {"text": "compares the performance of CEC with that of the baseline methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on gold-standard (micro averaged).", "labels": [], "entities": []}, {"text": " Table 2: The modifications made by enforcing transitivity  w.r.t. the gold standard. 55% of the edges added by enforcing  transitivity are incorrect, but it removed even more incorrect  edges, improving the overall performance.", "labels": [], "entities": []}, {"text": " Table 3: The portion of positive predicate entailments cov- ered by each WordNet relation. WordNet relations are di- vided according to their common interpretations with respect  to lexical entailment.", "labels": [], "entities": []}]}