{"title": [{"text": "Temporal Scoping of Relational Facts based on Wikipedia Data", "labels": [], "entities": [{"text": "Temporal Scoping of Relational Facts", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.9035990476608277}, {"text": "Wikipedia", "start_pos": 46, "end_pos": 55, "type": "DATASET", "confidence": 0.979040265083313}]}], "abstractContent": [{"text": "Most previous work in information extraction from text has focused on named-entity recognition, entity linking, and relation extraction.", "labels": [], "entities": [{"text": "information extraction from text", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8280829936265945}, {"text": "named-entity recognition", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.7274055182933807}, {"text": "entity linking", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.7510384321212769}, {"text": "relation extraction", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.8335700929164886}]}, {"text": "Less attention has been paid given to extracting the temporal scope for relations between named entities; for example, the relation president-Of(John F. Kennedy, USA) is true only in the time-frame (January 20, 1961-November 22, 1963).", "labels": [], "entities": []}, {"text": "In this paper we present a system for temporal scoping of relational facts, which is trained on distant supervision based on the largest semi-structured resource available: Wikipedia.", "labels": [], "entities": [{"text": "temporal scoping of relational facts", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.7909005284309387}, {"text": "Wikipedia", "start_pos": 173, "end_pos": 182, "type": "DATASET", "confidence": 0.9558795690536499}]}, {"text": "The system employs language models consisting of patterns automatically bootstrapped from Wikipedia sentences that contain the main entity of a page and slot-fillers extracted from the corresponding infoboxes.", "labels": [], "entities": []}, {"text": "This proposed system achieves state-of-the-art results on 6 out of 7 relations on the benchmark Text Analysis Conference 2013 dataset for temporal slot filling (TSF), and out-performs the next best system in the TAC 2013 evaluation by more than 10 points.", "labels": [], "entities": [{"text": "Text Analysis Conference 2013 dataset", "start_pos": 96, "end_pos": 133, "type": "DATASET", "confidence": 0.8076009333133698}, {"text": "temporal slot filling (TSF)", "start_pos": 138, "end_pos": 165, "type": "TASK", "confidence": 0.7454506307840347}, {"text": "TAC 2013 evaluation", "start_pos": 212, "end_pos": 231, "type": "DATASET", "confidence": 0.8175909519195557}]}], "introductionContent": [{"text": "Previous work on relation extraction) by systems such as NELL (, KnowItAll () and have targeted the extraction of entity tuples, such as president-Of(George W. Bush, USA), in order to build large knowledge bases of facts.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7984455525875092}]}, {"text": "These systems assume that relational facts are time-invariant.", "labels": [], "entities": []}, {"text": "However, this assumption is not always true, for example * This research was carried out during an internship at Microsoft Research.", "labels": [], "entities": []}, {"text": "president-Of(George W. Bush, USA) holds within the time-frame only.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the relatively less explored problem of attaching temporal scope to relation between entities.", "labels": [], "entities": []}, {"text": "The Text Analysis Conference (TAC) introduced temporal slot filling (TSF) as one of the knowledge base population (KBP) tasks in 2013.", "labels": [], "entities": [{"text": "Text Analysis Conference (TAC)", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.8357488214969635}, {"text": "temporal slot filling (TSF)", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.7100472152233124}]}, {"text": "The input to a TAC-TSF system is a binary relation e.g. per:spouse(Brad Pitt, Jennifer Aniston) and a document assumed to contain supporting evidence for the relation.", "labels": [], "entities": []}, {"text": "The required output is a 4-tuple timestamp [T1, T2, T3, T4], where T1 and T2 are normalized dates that provide a range for the start date of the relation, and T3 and T4 provide the range for the end of the relationship.", "labels": [], "entities": []}, {"text": "Systems must also output the offsets of the text mentions that support the temporal information extracted.", "labels": [], "entities": []}, {"text": "For example, from a text such as \"Pitt married Jennifer Aniston on July 29, 2000.] the couple divorced five years later in 2005.\", a system must extract the normalized timestamp, together with the entity and date offsets that support the timestamp.", "labels": [], "entities": []}, {"text": "In this paper, we describe TSRF, a system for temporal scoping of relational facts.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.5777764320373535}, {"text": "temporal scoping of relational facts", "start_pos": 46, "end_pos": 82, "type": "TASK", "confidence": 0.7529757976531982}]}, {"text": "For every relation type, TSRF uses distant supervision from Wikipedia infobox tuples to learn a language model consisting of patterns of entity types, categories, and word n-grams.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.5507317185401917}]}, {"text": "Then it uses this trained relation-specific language model to extract the top k sentences that support the given relation between the query entity and the slot filler.", "labels": [], "entities": []}, {"text": "Ina second stage, TSRF performs timestamp classification by employing models which learn \"Start\", \"End\" and \"In\" predictors of entities in a relationship; it computes the best 4-tuple timestamp [T1, T2, T3, T4] based on the confidence values associated to the top sentences extracted.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 18, "end_pos": 22, "type": "TASK", "confidence": 0.8276673555374146}, {"text": "timestamp classification", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.8072128295898438}, {"text": "End", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9012001752853394}]}, {"text": "Following the TAC-TSF task for 2013, TSRF is trained and evaluated for seven relation types, as shown in per:spouse per:title per:employee or member of org:top employees/members per:cities of residence per:statesorprovinces of residence per:countries of residence: Types of relations in the TAC-TSF.", "labels": [], "entities": [{"text": "TAC-TSF", "start_pos": 291, "end_pos": 298, "type": "DATASET", "confidence": 0.8983252644538879}]}, {"text": "The remainder of the paper is organized as follows: The next section describes related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces the TAC-TSF input and output formats.", "labels": [], "entities": []}, {"text": "Section 4 discusses the main challenges, and Section 5 details our method for temporal scoping of relations.", "labels": [], "entities": []}, {"text": "Section 6 describes our experiments and results, and it is followed by concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, we train our system on the infobox tuples and sentences extracted from the Wikipedia dump of May 2013.", "labels": [], "entities": [{"text": "Wikipedia dump of May 2013", "start_pos": 91, "end_pos": 117, "type": "DATASET", "confidence": 0.9167309761047363}]}, {"text": "We set aside a portion of the dump as our development data.", "labels": [], "entities": []}, {"text": "We chose to use the top-relevant n-grams based on the performance on the development data as features.", "labels": [], "entities": []}, {"text": "We employ then the TAC evaluation data, which is publicly available through LDC.", "labels": [], "entities": [{"text": "TAC evaluation data", "start_pos": 19, "end_pos": 38, "type": "DATASET", "confidence": 0.7316004435221354}, {"text": "LDC", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.9463398456573486}]}, {"text": "We utilize the evaluation metric developed for TAC.", "labels": [], "entities": [{"text": "TAC", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.7514557242393494}]}, {"text": "In order fora temporal constraint (T1-T4) to be valid, the document must justify both the query relation (which is similar to the regular English slot filling task) and the temporal constraint.", "labels": [], "entities": [{"text": "slot filling task", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.7791508833567301}]}, {"text": "Since the time information provided in text maybe approximate, the TAC metric measures the similarity of each constraint in the key and system response.", "labels": [], "entities": [{"text": "TAC metric", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9631932079792023}, {"text": "similarity", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.974143385887146}]}, {"text": "Formally, if the date in the gold standard is k i , while the date hypothesized by the system is r i , and d i = |k i \u2212 r i | is their difference measured in years, then the score for the set of temporal constraints on a slot is computed as: TAC sets the constant c to one year, so that predictions that differ from the gold standard by one year get 50% credit.", "labels": [], "entities": [{"text": "TAC", "start_pos": 242, "end_pos": 245, "type": "METRIC", "confidence": 0.8015449643135071}]}, {"text": "The absence of a constraint in T1 or T3 is treated as a value of \u2212\u221e and the absence of a constraint in T2 or T4 is treated as +\u221e, which lead to zero-value terms in the scoring sum.", "labels": [], "entities": []}, {"text": "Therefore, the overall achievable score has a range between 0 and 1.", "labels": [], "entities": [{"text": "achievable score", "start_pos": 23, "end_pos": 39, "type": "METRIC", "confidence": 0.976780354976654}]}, {"text": "We compare TSRF against four other TSF systems: (i) RPI-Blender (Artiles et al., 2011), (ii) CMU-NELL (), (iii) UNED () and (iv) Abby-Compreno ().", "labels": [], "entities": [{"text": "UNED", "start_pos": 112, "end_pos": 116, "type": "DATASET", "confidence": 0.809859037399292}]}, {"text": "Most of these systems employ distant supervision strategies too.", "labels": [], "entities": []}, {"text": "RPI-Blender and UNED obtained the top scores in the 2011 TAC TSF pilot evaluation, and thus, could be considered as the state-of-the-art at the time.", "labels": [], "entities": [{"text": "RPI-Blender", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9434223771095276}, {"text": "UNED", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.8518783450126648}, {"text": "TAC TSF pilot evaluation", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.7768323719501495}]}, {"text": "We also compare our system with a reasonable baseline similar to . This baseline makes the simple assumption that the corresponding relation is valid at the document date.", "labels": [], "entities": []}, {"text": "That means that it creates a \"within\" tuple as follows: < \u2212\u221e, doc date, doc date, +\u221e >.", "labels": [], "entities": []}, {"text": "Hence, this baseline system fora particular relation always predicts T2 = T3 = the date of the document.", "labels": [], "entities": []}, {"text": "lists the results obtained by our system on the TAC test set of 201 queries, overall and for each individual slot, in conjunction with the results of the other systems evaluated and the output generated by the LDC human experts.", "labels": [], "entities": [{"text": "TAC test set", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.9316447973251343}]}, {"text": "Only two out of the five systems evaluated, TSRF and RPIBlender, are able to beat the \"within\" baseline.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.7155521512031555}, {"text": "RPIBlender", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.7197700142860413}]}, {"text": "TSRF achieves approximately 48% of human performance (LDC) and outperforms all other sys-  tems in overall score, as well as for all individual relations with the exception of per:title, for which RPI-Blender obtains a better score.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.609393835067749}, {"text": "human performance (LDC)", "start_pos": 35, "end_pos": 58, "type": "METRIC", "confidence": 0.6880109071731567}]}, {"text": "In fact, TSRF outperforms the next best systems by 10 and 19 points.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.47485461831092834}]}, {"text": "These two systems obtained the top score in TAC 2011, and outperformed other systems such as).", "labels": [], "entities": [{"text": "TAC 2011", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.7947160303592682}]}, {"text": "TSRF also outperforms CMU-NELL which employs a very large KB of relational facts already extracted from the Web and makes use of the Google N-gram corpus (http://books.google.com/ngrams).", "labels": [], "entities": [{"text": "TSRF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5376625061035156}, {"text": "Google N-gram corpus", "start_pos": 133, "end_pos": 153, "type": "DATASET", "confidence": 0.6425308883190155}]}, {"text": "We believe that this large performance difference is due in part to the fact that TSRF uses a language model to cleanup the noise introduced by distant supervision before the actual temporal classification step.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.5427887439727783}, {"text": "temporal classification", "start_pos": 182, "end_pos": 205, "type": "TASK", "confidence": 0.7071959376335144}]}, {"text": "Also, the learning algorithm employed, GBDT, is highly effective in using the extracted n-grams as features to decide whether the extracted (entity, filler, time) tuples belong to the relation under consideration or not.", "labels": [], "entities": [{"text": "GBDT", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.6547954678535461}]}, {"text": "Finally, shows another reason that gives TSRF an edge in obtaining the best score.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.46467888355255127}]}, {"text": "The employed EL component) is a state-of-the-art system for extracting and linking entities, and resolving coreference chains.", "labels": [], "entities": []}, {"text": "By using this system, we have been able to extract slot-filler mentions with a precision of 96.8% at 66.4% recall, which is substantially higher than the extraction results of all other systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.99883633852005}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9971920847892761}]}, {"text": "Encouragingly, the performance of this component also comes close to that of the LDC annotators, which obtained a precision of 97.3% at 72.5% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9990109205245972}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9901913404464722}]}, {"text": "It is also important to note that our system exhibits a balanced performance on the relations on which it was tested.", "labels": [], "entities": []}, {"text": "As shown in column StDev in, this system achieves the lowest standard deviation in the performance across the relations tested.", "labels": [], "entities": [{"text": "standard deviation", "start_pos": 61, "end_pos": 79, "type": "METRIC", "confidence": 0.9313816428184509}]}, {"text": "It is interesting to note also that TSRF achieves the best performance on the employee of (S4) and city of residence (S2) relations even though the system development was done on the spouse relation (S1) as an encouraging sign that our distant supervision algorithm can be transferred successfully across relations for domain-specific temporal scoping.", "labels": [], "entities": [{"text": "TSRF", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.45870766043663025}]}], "tableCaptions": [{"text": " Table 3: Results for the TAC-TSF 2013 test set, overall and for individual slots. The slots notation is: S1:  org:top members employees, S2: per:city of residence, S3: per:country of residence, S4: per:employee  or member of, S5: per:spouse, S6: per:statesorprovince of residence, S7: per:title. The score for the  output created by the LDC experts is also shown.", "labels": [], "entities": [{"text": "TAC-TSF 2013 test set", "start_pos": 26, "end_pos": 47, "type": "DATASET", "confidence": 0.8717131018638611}]}, {"text": " Table 4: Extraction accuracy for slot-filler men- tions. TSRF clearly outperforms all systems and  comes close to human performance (LDC).", "labels": [], "entities": [{"text": "Extraction", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9501872062683105}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.923780620098114}, {"text": "TSRF", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.792547881603241}, {"text": "human performance (LDC)", "start_pos": 115, "end_pos": 138, "type": "METRIC", "confidence": 0.6693708658218384}]}]}