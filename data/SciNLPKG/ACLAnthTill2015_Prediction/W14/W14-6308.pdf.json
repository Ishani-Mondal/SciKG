{"title": [{"text": "21 \u00e8me Traitement Automatique des Langues Naturelles", "labels": [], "entities": []}], "abstractContent": [{"text": "Task 4 of DEFT2014 was considered to bean instance of a classification problem with opened number of classes.", "labels": [], "entities": [{"text": "DEFT2014", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.7947344183921814}]}, {"text": "We aimed to solve it by means of geometric mesurements within reflective vector spaces-every class is attributed a point C in the vector space, N document-denoting nearest neighbors of C are subsequently considered to belong to class denoted by C. Novelty of our method consists in way how we optimize the very construction of the semantic space: during the training, evolutionary algorithm looks for such combination of features which yields the vector space most \u00ab fit \u00bb for the classification.", "labels": [], "entities": []}, {"text": "Slightly modified precision evaluation script and training corpus gold standard, both furnished by DEFT organiers, yielded a fitness function.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9623121619224548}, {"text": "DEFT organiers", "start_pos": 99, "end_pos": 113, "type": "DATASET", "confidence": 0.9189175069332123}]}, {"text": "Only word unigrams and bigrams extracted only from titles, author names, keywords and abstracts were taken into account as features triggering the reflective vector space construction processses.", "labels": [], "entities": []}, {"text": "It is discutable whether evolutionary optimization of reflective vector spaces can be of certain interest since it had performed the partitioning of DEFT2014 testing corpus articles into 7 and 9 classes with micro-precision of 25%, respectively 31.8%.", "labels": [], "entities": [{"text": "DEFT2014 testing corpus articles", "start_pos": 149, "end_pos": 181, "type": "DATASET", "confidence": 0.903633177280426}]}], "introductionContent": [{"text": "We understood the Task 4 of 2014 edition of the datamining competition Defi en Fouille Textuelle (DEFT) as an instance of multiclass classification problem.", "labels": [], "entities": [{"text": "datamining competition Defi en Fouille Textuelle (DEFT)", "start_pos": 48, "end_pos": 103, "type": "TASK", "confidence": 0.4833138518863254}, {"text": "multiclass classification", "start_pos": 122, "end_pos": 147, "type": "TASK", "confidence": 0.7144460529088974}]}, {"text": "More concretely, the challenge was to create an artificial system which would be able attribute a specific member of the set of all class labels to scientific articles of the testing corpus.", "labels": [], "entities": []}, {"text": "The training corpus of 208 scientific articles presented in diverse sessions of diverse editions of an annual TALN/RECITAL conference was furnished to facilitate the training of the model.", "labels": [], "entities": [{"text": "TALN/RECITAL conference", "start_pos": 110, "end_pos": 133, "type": "TASK", "confidence": 0.4129391759634018}]}, {"text": "The tricky aspect of the challenge was, that one could be potentially asked, in the testing phase, to attribute to an object, which was not present during training phase, a label which was also not present in the turing phase.", "labels": [], "entities": []}, {"text": "For this reason, we had considered Task 4 to bean instance of an open-class variant of classification problem, i.e. a multiclass classification problem when one does not know in advance neither the number nor even the nature of categories which are to be constructed.", "labels": [], "entities": []}, {"text": "We had decided to try to solve the problem of open-classification problem by a following approach, based principially on mutually intertwined notions of \u00ab object \u00bb and \u00ab feature \u00bb : 1.", "labels": [], "entities": []}, {"text": "During the (train|learn)ing phase, use the training corpus to create a D-dimensional semantic vector space, i.e. attribute the vectors of length D to all members of the set of entities (word fragments, words, documents, phrases, patterns) E which includes all observables within the training corpus", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}