{"title": [{"text": "A multimodal corpus for the evaluation of computational models for (grounded) language acquisition", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7566549181938171}]}], "abstractContent": [{"text": "This paper describes the design and acquisition of a German multimodal corpus for the development and evaluation of computational models for (grounded) language acquisition and algorithms enabling corresponding capabilities in robots.", "labels": [], "entities": []}, {"text": "The corpus contains parallel data from multiple speakers/actors, including speech, visual data from different perspectives and body posture data.", "labels": [], "entities": []}, {"text": "The corpus is designed to support the development and evaluation of models learning rather complex grounded linguistic structures, e.g. syntactic patterns, from sub-symbolic input.", "labels": [], "entities": []}, {"text": "It provides moreover a valuable resource for evaluating algorithms addressing several other learning processes, e.g. concept formation or acquisition of manipulation skills.", "labels": [], "entities": [{"text": "concept formation", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7546438276767731}, {"text": "acquisition of manipulation skills", "start_pos": 138, "end_pos": 172, "type": "TASK", "confidence": 0.6251498013734818}]}, {"text": "The corpus will be made available to the public.", "labels": [], "entities": []}], "introductionContent": [{"text": "Children acquire linguistic structures through exposure to (spoken) language in a rich context and environment.", "labels": [], "entities": []}, {"text": "The semantics of language maybe learned by establishing connections between linguistic structures and corresponding structures in the environment, i.e. in different domains such as the visual one.", "labels": [], "entities": []}, {"text": "In order to gain insights concerning the mechanisms at play during language acquisition (LA), which enable children to solve these learning tasks, models are needed which ideally cover several learning tasks.", "labels": [], "entities": [{"text": "language acquisition (LA)", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.7929523825645447}]}, {"text": "For instance, they may cover the acquisition of both words and grammatical rules as well as the acquisition of their grounded meanings.", "labels": [], "entities": []}, {"text": "Complementarily, data resources are needed which enable the design and evaluation of these models by providing suitable parallel data.", "labels": [], "entities": []}, {"text": "Aiming to provide a basis for the development and evaluation of LA models addressing the acquisition of rather complex and grounded linguistic structures, i.e. syntactic patterns, from subsymbolic input, we designed a German multimodal input corpus.", "labels": [], "entities": [{"text": "German multimodal input corpus", "start_pos": 218, "end_pos": 248, "type": "DATASET", "confidence": 0.6918829903006554}]}, {"text": "The corpus consists of data of multiple speakers/actors who performed actions in front of a robot and described these actions while executing them.", "labels": [], "entities": []}, {"text": "Subjects were recorded, i.e. parallel data of speech, stereo vision (including the view-perspective of the \"infant\"/robot) and body postures were gathered.", "labels": [], "entities": []}, {"text": "The resulting data hence allow grounding of linguistic structures in both vision and body postures.", "labels": [], "entities": []}, {"text": "Among others, learning processes that maybe evaluated using the corpus include: acquisition of several linguistic structures, acquisition of visual structures, concept formation, acquisition of generalized patterns which abstract over different speakers and actors, establishment of correspondences between structures from different domains, acquisition of manipulation skills, and development of appropriate models for the representations of actions.", "labels": [], "entities": [{"text": "concept formation", "start_pos": 160, "end_pos": 177, "type": "TASK", "confidence": 0.7186323404312134}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Next, we will provide background information concerning computational models of LA.", "labels": [], "entities": []}, {"text": "In Section 3, we will then describe the corpus design and acquisition, including the desired properties of the collected data, corresponding experimental settings and technical implementation.", "labels": [], "entities": []}, {"text": "We will then present the resulting data set and subsequently conclude..", "labels": [], "entities": []}], "datasetContent": [{"text": "Human subjects performed pre-defined actions and simultaneously described their performances in front of the robot iCub (Metta et al., 2008); depicts a human subject interacting with iCub.", "labels": [], "entities": []}, {"text": "While interacting with iCub, human subjects' be-: A human subject interacting with iCub.", "labels": [], "entities": []}, {"text": "In particular, the following data were recorded simultaneously: \u2022 Speech/Audio (via a headset microphone) \u2022 Vision/Video, static perspective (via two cameras, allowing for stereo vision) \u2022 iCub-Vision/Video, iCub's (attentive) perspective (via iCub's two internal cameras, again allowing for stereo vision) \u2022 Body postures (via a Kinect).", "labels": [], "entities": []}, {"text": "An experimental sketch showing the experimental setting including the positions of the human subject and iCub, as well as camera and Kinect positions, is illustrated in.", "labels": [], "entities": []}, {"text": "As can be seen, the human subject was placed directly opposite to iCub.", "labels": [], "entities": [{"text": "iCub", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.964754045009613}]}, {"text": "The two external cameras and the Kincet were placed slightly sloped opposite to the subject.", "labels": [], "entities": [{"text": "Kincet", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.7594103217124939}]}, {"text": "Subjects were instructed about which actions should be performed via a computer screen which was operated by an experimentator.", "labels": [], "entities": []}, {"text": "In order to encourage subjects to perform the tutoring task rather naturally, i.e. just like they were interacting with a human (child), iCub provided feedback).", "labels": [], "entities": []}, {"text": "In particular, a gazing behavior was implemented to make the robot appear attentively following the tutoring.", "labels": [], "entities": []}], "tableCaptions": []}