{"title": [{"text": "Retrieving Word Associations with a Simple Neighborhood Algorithm in a Graph-Based Resource", "labels": [], "entities": [{"text": "Retrieving Word Associations", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8879683613777161}]}], "abstractContent": [{"text": "The paper explains the procedure to obtain word associations starting from a graph that has not been specifically built for that purpose.", "labels": [], "entities": []}, {"text": "Our goal is being able to simulate human word associations by using the simplest possible methods, including the basic tools of a co-occurrence network from a non-annotated corpus, and a very simple search algorithm based on neighborhood.", "labels": [], "entities": [{"text": "simulate human word associations", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.6439610123634338}]}, {"text": "The method has been tested in the Cogalex shared task, revealing the difficulty of achieving word associations without semantic annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Building annotated computational resources for natural language is a difficult and time-consuming task that not always produces the desired results.", "labels": [], "entities": []}, {"text": "A good alternative to semantic annotation by hand could be using statistics and graph-based operations in corpora.", "labels": [], "entities": []}, {"text": "In order to implement a system capable to work with such methods we have designed co-occurrence networks from large existing corpora, like Wikipedia or the British National Corpus.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 156, "end_pos": 179, "type": "DATASET", "confidence": 0.9242180585861206}]}, {"text": "The underlying idea is that systems based on mathematics and statistics can achieve comparable results to the ones obtained with more sophisticated methods relying on semantic processing.", "labels": [], "entities": []}, {"text": "Non-annotated networks have been suggested and implemented, for example, by Ferrer-i-Cancho and Sol\u00e9.", "labels": [], "entities": []}, {"text": "The authors suggested non-semantically annotated graphs, building exclusively syntagmatic networks.", "labels": [], "entities": []}, {"text": "By this method, they reduced the syntagmatic-paradigmatic relations.", "labels": [], "entities": []}, {"text": "The authors used the BNC corpus to build two graphs G1 and G2.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.9666027724742889}]}, {"text": "First, a so-called co-occurrence graph G1 in which words are linked if they co-occur in at least one sentence within a span of maximal three tokens.", "labels": [], "entities": []}, {"text": "Then a collocation graph G2 is extracted in which only those links of G1 are retained whose end vertices co-occur more frequent than expected by chance.", "labels": [], "entities": []}, {"text": "A non-annotated graph built from a large corpus) is a good representation to allow for the discovery of a large number of word relationships.", "labels": [], "entities": []}, {"text": "It can be used fora number of tasks, one of them being computing word associations.", "labels": [], "entities": [{"text": "computing word associations", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.8165635069211324}]}, {"text": "To test the consistence of the results obtained by our method, they will be compared with the Edinburgh Association Thesaurus, a collection of 8000 words whose association norms were produced by presenting each of the stimulus words to about 100 subjects each, and by collecting their responses.", "labels": [], "entities": [{"text": "Edinburgh Association Thesaurus", "start_pos": 94, "end_pos": 125, "type": "DATASET", "confidence": 0.9651036461194357}]}, {"text": "The subjects were 17 to 22 year old British students.", "labels": [], "entities": []}, {"text": "To perform the tests, we take a sample (EAT: http://www.eat.rl.ac.uk/) consisting in 100 words.", "labels": [], "entities": [{"text": "EAT", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.8344321250915527}]}, {"text": "For building a network to deal with the specific task of producing word associations we have used the British National Corpus (BNC) as a source.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 102, "end_pos": 131, "type": "DATASET", "confidence": 0.9764803449312845}]}, {"text": "The way the network has been constructed has also some interest and impact in the final results.", "labels": [], "entities": []}, {"text": "Firstly, for the sake of simplicity, we removed all words other than Nouns and Adjectives.", "labels": [], "entities": []}, {"text": "Nouns have been normalized to singular form.", "labels": [], "entities": []}, {"text": "After this pre-processing, a graph has been built where the nouns and adjectives in the corpus are the nodes, and where the edges between these nodes are zero at the beginning, and are incremented by 1 whenever the two respective words co-occur in the corpus as direct neighbors (i.e. more distant neighborhood was not taken into account).", "labels": [], "entities": []}, {"text": "That is, after processing the corpus the weight of each edge represents the number of times the respective words (nodes) cooccur.", "labels": [], "entities": []}, {"text": "To build the graph our system runs through a pipeline of four modules: \u2022 document cleaning (deletion of stop-words), extracting only 'Nouns' and 'Adjectives'; \u2022 lemmatisation of word forms to avoid duplicates (horse, horses); \u2022 computation of the (un-directed) graph's edges.", "labels": [], "entities": [{"text": "document cleaning", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7005883455276489}]}, {"text": "Links are created between direct neighbours; \u2022 computation of the edges' weights.", "labels": [], "entities": []}, {"text": "The weight of an edge is equal to the number of its occurrences.", "labels": [], "entities": []}, {"text": "We only use absolute values.", "labels": [], "entities": []}, {"text": "\u2022 computation of the node's weights.", "labels": [], "entities": []}, {"text": "As in the edges, the weight of anode is the number of it occurrences.", "labels": [], "entities": []}, {"text": "The graph has been implemented with Python.", "labels": [], "entities": []}, {"text": "The resultant network has 427668 nodes (different words).", "labels": [], "entities": []}, {"text": "Of them, 1894 are happax (occur only once), only the 0,5%.", "labels": [], "entities": [{"text": "happax", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9860418438911438}]}, {"text": "From them, 9836987 with weight one; and 3817827 have a weight higher than one, on a percentage relation 72/28.", "labels": [], "entities": []}, {"text": "The average degree of the nodes of the network is 31, 92.", "labels": [], "entities": [{"text": "degree", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9205358028411865}]}], "datasetContent": [], "tableCaptions": []}