{"title": [{"text": "Free on-line speech recogniser based on Kaldi ASR toolkit producing word posterior lattices", "labels": [], "entities": [{"text": "Kaldi ASR toolkit", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.6292949914932251}]}], "abstractContent": [{"text": "This paper presents an extension of the Kaldi automatic speech recognition toolkit to support on-line recognition.", "labels": [], "entities": [{"text": "Kaldi automatic speech recognition", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.5394830852746964}, {"text": "on-line recognition", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7748399078845978}]}, {"text": "The resulting recogniser supports acoustic models trained using state-of-the-art acoustic modelling techniques.", "labels": [], "entities": []}, {"text": "As the recogniser produces word posterior lattices , it is particularly useful in statistical dialogue systems, which try to exploit uncertainty in the recogniser's output.", "labels": [], "entities": []}, {"text": "Our experiments show that the on-line recogniser performs significantly better in terms of latency when compared to a cloud-based recogniser.", "labels": [], "entities": []}], "introductionContent": [{"text": "There are many choices of speech recognisers, but we find no alternative with both a permissive license and on-line recognition suitable fora spoken dialogue system.", "labels": [], "entities": [{"text": "speech recognisers", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7014144212007523}]}, {"text": "The Google speech recognition service 1 provides state-of-the-art quality for many tasks) and maybe used for free; however, the licensing conditions are not clear, adaptation of acoustic and language models to a task at hand is not possible and the service is not officially supported.", "labels": [], "entities": [{"text": "Google speech recognition", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5715439716974894}]}, {"text": "Another option is Nuance cloud based recognition 2 ; however, again adjustments to the system are not possible.", "labels": [], "entities": [{"text": "Nuance cloud based recognition", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.5796055719256401}]}, {"text": "Moreover, it is a paid service.", "labels": [], "entities": []}, {"text": "When considering local ASR systems, we found no viable alternatives either.", "labels": [], "entities": [{"text": "ASR", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.979003369808197}]}, {"text": "The HTK toolkit does not provide on-line large vocabulary decoders suitable for real-time decoding.", "labels": [], "entities": [{"text": "HTK toolkit", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8978357017040253}]}, {"text": "OpenJulius can be used with custom-built acoustic and The API is available at https://www.google.", "labels": [], "entities": []}, {"text": "com/speech-api/v1/recognize, and its use described in a blog post at http://mikepultz.com/2013/07/ google-speech-api-full-duplex-php-version/.", "labels": [], "entities": []}, {"text": "2 http://www.nuancemobiledeveloper.com/ language models and for on-line decoding).", "labels": [], "entities": []}, {"text": "However, OpenJulius suffers from software instability when producing lattices and confusion networks; therefore, it is not suitable for practical use.", "labels": [], "entities": []}, {"text": "The RWTH decoder is not a free software and a license must be purchased for commercial applications.", "labels": [], "entities": [{"text": "RWTH decoder", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8786020576953888}]}, {"text": "As a result, we implemented a lightweight modification of the LatticeFasterDecoder from the Kaldi toolkit and created an on-line recogniser with an interface that is suitable for statistical dialogue systems.", "labels": [], "entities": [{"text": "statistical dialogue", "start_pos": 179, "end_pos": 199, "type": "TASK", "confidence": 0.834979921579361}]}, {"text": "The Kaldi toolkit as well as the online recogniser is distributed under the Apache 2.0 license 3 . Our on-line recogniser may use acoustic models trained using the state-of-the-art techniques, such as Linear Discriminant Analysis (LDA), Maximum Likelihood Linear Transform (MLLT), Boosted Maximum Mutual Information (BMMI), Minimum Phone Error (MPE).", "labels": [], "entities": [{"text": "Boosted Maximum Mutual Information (BMMI)", "start_pos": 281, "end_pos": 322, "type": "METRIC", "confidence": 0.6894839150565011}, {"text": "Minimum Phone Error (MPE)", "start_pos": 324, "end_pos": 349, "type": "METRIC", "confidence": 0.8092829038699468}]}, {"text": "It produces word posterior lattices which can be easily converted into high quality n-best lists.", "labels": [], "entities": []}, {"text": "The recogniser's speed and latency can be effectively controlled off-line by optimising a language model and during decoding by beam thresholds.", "labels": [], "entities": []}, {"text": "In the next section, the Kaldi recognition toolkit is briefly described.", "labels": [], "entities": [{"text": "Kaldi recognition", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7563134431838989}]}, {"text": "Section 3 describes the implementation of the OnlineLatgenRecogniser.", "labels": [], "entities": []}, {"text": "Section 4 evaluates the accuracy and speed of the recogniser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9996671676635742}, {"text": "speed", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9934808015823364}, {"text": "recogniser", "start_pos": 50, "end_pos": 60, "type": "TASK", "confidence": 0.968017578125}]}, {"text": "Finally, Section 5 concludes this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We focus on evaluating the speed of the OnlineLatgenRecogniser and its relationship with the accuracy of the decoder, namely: \u2022 Real Time Factor (RTF) of decoding -the ratio of the recognition time to the duration of the audio input, \u2022 Latency -the delay between utterance end and the availability of the recognition results, \u2022 Word Error Rate (WER).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9986374974250793}, {"text": "Real Time Factor (RTF)", "start_pos": 128, "end_pos": 150, "type": "METRIC", "confidence": 0.9141477545102438}, {"text": "Latency", "start_pos": 236, "end_pos": 243, "type": "METRIC", "confidence": 0.9896728992462158}, {"text": "Word Error Rate (WER)", "start_pos": 328, "end_pos": 349, "type": "METRIC", "confidence": 0.900774339834849}]}, {"text": "Accuracy and speed of the OnlineLatgenRecogniser are controlled by the max-active-states, beam, and lattice-beam parameters).", "labels": [], "entities": []}, {"text": "Max-active-states limits the maximum number of active tokens during decoding.", "labels": [], "entities": []}, {"text": "Beam is used during graph search to prune ASR hypotheses at the state level.", "labels": [], "entities": [{"text": "Beam", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8958988189697266}, {"text": "ASR hypotheses", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.9207310378551483}]}, {"text": "Lattice-beam is used when producing word level lattices after the decoding is finished.", "labels": [], "entities": []}, {"text": "It is crucial to tune these parameters optimally to obtain good results.", "labels": [], "entities": []}, {"text": "In general, one aims fora setting RTF smaller than 1.0.", "labels": [], "entities": []}, {"text": "However, in practice, it is useful if the RTF is even smaller because other processes running on the machine can influence the amount of available computational resources.", "labels": [], "entities": []}, {"text": "Therefore, we target the RTF of 0.6 in our setup.", "labels": [], "entities": [{"text": "RTF", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9979767203330994}]}, {"text": "We used grid search on the development set to identify optimal parameters.", "labels": [], "entities": []}, {"text": "shows the impact of the beam on the WER and RTF measures.", "labels": [], "entities": [{"text": "WER", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.6339471936225891}, {"text": "RTF", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.7645713090896606}]}, {"text": "In this case, we set max-active-states to 2000 in order to limit the worst case RTF to 0.6.", "labels": [], "entities": []}, {"text": "Observing (a), we set beam to 13 as this setting balances the WER, 95th RTF percentile, and the average RTF.", "labels": [], "entities": [{"text": "beam", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.988994300365448}, {"text": "WER", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9982361793518066}, {"text": "95th RTF percentile", "start_pos": 67, "end_pos": 86, "type": "METRIC", "confidence": 0.735302209854126}, {"text": "RTF", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.90887451171875}]}, {"text": "shows the impact of the lattice-beam on WER and latency when beam is fixed to 13.", "labels": [], "entities": [{"text": "WER", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.7896909117698669}, {"text": "latency", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.9967513084411621}]}, {"text": "We set latticebeam to 5 based onto obtain the 95th latency percentile of 200 ms, which is considered natural in a dialogue.", "labels": [], "entities": []}, {"text": "Lattice-beam does not affect WER, but larger lattice-beam improves the oracle WER of generated lattices).", "labels": [], "entities": [{"text": "WER", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9685714840888977}]}, {"text": "shows the percentile graph of the RTF and latency measures over the development set.", "labels": [], "entities": [{"text": "RTF", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.5275267362594604}, {"text": "latency", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.9669264554977417}]}, {"text": "For example, the 95th percentile is the value of a measure such that 95% of the data has the measure below that value.", "labels": [], "entities": []}, {"text": "One can see from Figure 2 that 95% of development utterances is decoded with RTF under 0.6 and latency under 200 ms.", "labels": [], "entities": [{"text": "RTF", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.8310609459877014}]}, {"text": "The extreme values are typically caused by decoding long noisy utterances where uncertainty in decoding slows down the recogniser.", "labels": [], "entities": []}, {"text": "Using this setting, OnlineLatgenRecogniser decodes the utterances with a WER of about 21%.", "labels": [], "entities": [{"text": "WER", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9990799427032471}]}, {"text": "Please note that OnlineLatgenRecogniser only extends the batch Kaldi decoder for incremental speech processing interface.", "labels": [], "entities": [{"text": "OnlineLatgenRecogniser", "start_pos": 17, "end_pos": 39, "type": "DATASET", "confidence": 0.8959171772003174}]}, {"text": "It uses the same code as the batch Kaldi decoder to compute speech parametrisation, frame likelihoods, and state-level lattices.", "labels": [], "entities": []}, {"text": "Therefore, the accuracy of OnlineLatgenRecogniser is equal to that of the batch Kaldi decoder given the same parameters.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9996637105941772}]}, {"text": "The percentile graphs show RTF and Latency scores for development data for max-activesates=2000, beam=13, lattice-beam=5.", "labels": [], "entities": [{"text": "RTF", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9891721606254578}, {"text": "Latency", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9953402280807495}]}, {"text": "Note that 95 % of utterances were decoded with the latency lower that 200ms.", "labels": [], "entities": []}, {"text": "In addition, we have also experimented with Google ASR service on the same domain.", "labels": [], "entities": []}, {"text": "The Google ASR service decodes 95% of test utterances with latency under 1900 ms and WER is about 48%.", "labels": [], "entities": [{"text": "Google ASR service decodes", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.7855956479907036}, {"text": "WER", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9980823993682861}]}, {"text": "The high latency is presumably caused by the batch processing of audio data and network latency, and the high WER is likely caused by a mismatch between Google's acoustic and language models and the test data.", "labels": [], "entities": [{"text": "WER", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.9970434308052063}]}], "tableCaptions": []}