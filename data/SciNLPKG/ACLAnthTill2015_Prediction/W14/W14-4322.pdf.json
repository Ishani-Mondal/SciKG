{"title": [{"text": "In-depth Exploitation of Noun and Verb Semantics to Identify Causation in Verb-Noun Pairs", "labels": [], "entities": []}], "abstractContent": [{"text": "Recognition of causality is important to achieve natural language discourse understanding.", "labels": [], "entities": [{"text": "natural language discourse understanding", "start_pos": 49, "end_pos": 89, "type": "TASK", "confidence": 0.6639633998274803}]}, {"text": "Previous approaches rely on shallow linguistic features.", "labels": [], "entities": []}, {"text": "In this work, we propose to identify causality in verb-noun pairs by exploiting deeper semantics of nouns and verbs.", "labels": [], "entities": []}, {"text": "Particularly, we acquire and employ three novel types of knowledge: (1) semantic classes of nouns with a high and low tendency to encode causality along with information regarding metonymies, (2) data-driven semantic classes of verbal events with the least tendency to encode causality, and (3) tendencies of verb frames to encode causal-ity.", "labels": [], "entities": []}, {"text": "Using these knowledge sources, we achieve around 15% improvement in F-score over a supervised classifier trained using linguistic features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9991099238395691}]}], "introductionContent": [{"text": "The identification of cause-effect relations is critical to achieve natural language discourse understanding.", "labels": [], "entities": [{"text": "natural language discourse understanding", "start_pos": 68, "end_pos": 108, "type": "TASK", "confidence": 0.6679981127381325}]}, {"text": "Causal relations are encoded in text using various linguistic constructions e.g., between two verbs, a verb and a noun, two discourse segments, etc.", "labels": [], "entities": []}, {"text": "In this research, we focus on identifying causality encoded between a verb and a noun (or noun phrase).", "labels": [], "entities": []}, {"text": "For example, consider the following example: 1.", "labels": [], "entities": []}, {"text": "At least 1,833 people died in the hurricane.", "labels": [], "entities": []}, {"text": "In example (1), the verb-noun phrase pair \"died\"-\"the hurricane\" encodes causality where event \"died\" is the effect of \"hurricane\" event.", "labels": [], "entities": []}, {"text": "Previously several approaches have been proposed to identify causality between two verbs and discourse segments.", "labels": [], "entities": []}, {"text": "However, the problem of identifying causality in verb-noun pairs has not received a considerable attention.", "labels": [], "entities": [{"text": "identifying causality in verb-noun pairs", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.8464389085769654}]}, {"text": "For example, have studied this task but they worked only with a list of predefined nouns representing events.", "labels": [], "entities": []}, {"text": "In this work, we focus on the linguistic construction of verb-noun (or noun phrase) pairs where noun can be of any semantic type.", "labels": [], "entities": []}, {"text": "Traditional approaches for identifying causality mainly employ linguistic features (e.g., lexical items, part-of-speech tags of words, etc.) in the framework of supervised learning and do not involve deeper semantics of language.", "labels": [], "entities": []}, {"text": "Analysis of such approaches by have revealed that the linguistic features are not always sufficient to achieve a good performance on the task of identifying semantic relations including causality.", "labels": [], "entities": []}, {"text": "In this work, we propose a model that deeply processes and acquires the specific semantic information about the participants of a verb-noun phrase (v-np) pair (i.e., noun and verb semantics) to identify causality with a better performance over the baseline model depending merely on shallow linguistic features.", "labels": [], "entities": []}, {"text": "The work in this paper builds on our recent work reported in.", "labels": [], "entities": []}, {"text": "In that previous model, we identified the semantic classes of nouns and verbs with a high and low tendency to encode causation.", "labels": [], "entities": []}, {"text": "For example, a named entity such as LOCATION may have the least tendency to encode causation.", "labels": [], "entities": []}, {"text": "We leveraged such information about nouns to filter false positives.", "labels": [], "entities": []}, {"text": "Similarly, we utilized the TimeBank's () classification of verbal events (i.e., Occurrence, Perception, Aspectual, State, I State, I Action and Reporting) and their definitions to claim that the reporting events (e.g., say, tell, etc.) just describe and narrate other events instead of encoding causality with them.", "labels": [], "entities": []}, {"text": "We proposed an Integer Linear Programming (ILP) model) to combine noun and verb semantics with the decisions of a supervised classifier which only relies on linguistic features.", "labels": [], "entities": []}, {"text": "In this paper, we extend our previous model by acquiring and exploiting the following three novel types of knowledge: 1.", "labels": [], "entities": []}, {"text": "We learn the information about tendencies of various verb frames to encode causation.", "labels": [], "entities": []}, {"text": "For example, our model identifies if the subject of verb \"destroy\" (\"occur\") has a high (low) tendency to encode causation.", "labels": [], "entities": []}, {"text": "Such information helps gain performance by exploiting causal semantics of each verb frame separately.", "labels": [], "entities": []}, {"text": "We also learn and incorporate information about the verb frames in general e.g., how likely it is for the subject of any verb to encode causation with its verb.", "labels": [], "entities": []}, {"text": "2. In, we utilized the TimeBank's definition of reporting events to argue that such events have the least tendency to encode causation.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9627071022987366}]}, {"text": "Instead of relying on human judgment we now introduce a data intensive approach to identify the TimeBank's classes of events with the least tendency to encode causation.", "labels": [], "entities": []}, {"text": "3. Although, information about the nouns with the least tendency to encode causation helps to filter false positives it can lead to false negatives when metonymic readings are associated with such nouns.", "labels": [], "entities": []}, {"text": "Therefore, we introduce a metonymy resolver on top of our current model to avoid false negatives.", "labels": [], "entities": [{"text": "metonymy resolver", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.8800574839115143}]}, {"text": "We provide details of our previously proposed model in section 3.", "labels": [], "entities": []}, {"text": "We introduce new model and discuss its performance in sections 4 and 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes the current research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present experiments and discussion on the performance achieved for the current task.", "labels": [], "entities": []}, {"text": "In order to evaluate our model, we generated a test set of instances of v-np pairs.", "labels": [], "entities": []}, {"text": "For this purpose, we collected three wiki articles on the topics of Hurricane Katrina, Iraq War and Egyptian Revolution of 2011.", "labels": [], "entities": []}, {"text": "We apply a part-of-speech tagger and a dependency parser on all sentences of these three articles ().", "labels": [], "entities": []}, {"text": "We extracted all v-np pairs from each sentence of these articles.", "labels": [], "entities": []}, {"text": "For each of the these three articles, we selected first 500 instances of vnp pairs.", "labels": [], "entities": []}, {"text": "Two annotators were asked to provide the labels C and \u00acC to the instances of v-np pairs using the annotation guidelines from.", "labels": [], "entities": []}, {"text": "We have achieved a 0.64 kappa score for the human inter-annotator agreement on a total of 1,500 v-np instances.", "labels": [], "entities": []}, {"text": "This results in a total of 1,365 instances of v-np pairs with 11.86% C pairs.", "labels": [], "entities": []}, {"text": "In this section, we present performance of the following models (see): 1.", "labels": [], "entities": []}, {"text": "Baseline: NB and MaxEnt supervised classifiers using only the shallow linguistic features (see section 3.1).", "labels": [], "entities": [{"text": "NB", "start_pos": 10, "end_pos": 12, "type": "DATASET", "confidence": 0.9146705269813538}]}, {"text": "2. Basic noun and verb semantics: ILP with the addition of semantic classes of nouns without metonymy (denoted by +N ! M ) and the addition of semantic classes of verbs where \u00acC ev ={(R)eporting events} (denoted by +N ! M +V {R} ).", "labels": [], "entities": []}, {"text": "These models represent the work proposed in Riaz and Girju (2014) (section 3).", "labels": [], "entities": []}, {"text": "The row 1 (2) of this table presents results over NB (MaxEnt) baseline supervised classifier, respectively.", "labels": [], "entities": []}, {"text": "shows that MaxEnt gives a very high accuracy and F-score as compared with NB.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 11, "end_pos": 17, "type": "DATASET", "confidence": 0.761429488658905}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.999605119228363}, {"text": "F-score", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9995552897453308}, {"text": "NB", "start_pos": 74, "end_pos": 76, "type": "DATASET", "confidence": 0.8690810203552246}]}, {"text": "Model +N ! M +V {R} with basic noun and verb semantics introduced in section 3.2 results in more than 10% improvement in F-score over NB and MaxEnt classifiers relying only on shallow linguistic features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.9975625276565552}]}, {"text": "Model +N M +VF+V {A,R,IS} with enriched verb and noun semantics brings more than 4% improvement in F-score over +N ! M +V {R} with MaxEnt as baseline.", "labels": [], "entities": [{"text": "F-score", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9966757297515869}]}, {"text": "We perform statistical significance test using bootstrap sampling method given in Berg- (see for the details).", "labels": [], "entities": []}, {"text": "+N M +VF+V {A,R,IS} brings significant improvement in F-score over +N ! M +V {R} with pvalue 0.0.", "labels": [], "entities": [{"text": "F-score", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.9983844757080078}]}, {"text": "Though +N ! M gives significantly better F-score over baseline, it drops recall by more than 16%.", "labels": [], "entities": [{"text": "N ! M", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.67647385597229}, {"text": "F-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.999672532081604}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9997387528419495}]}, {"text": "Metonymy resolution helps perform quite better by recovering more than 8% recall with +N M 1 GR + M 2 over +N ! M . +N M 1 GR + M 2 also results in 3.9% improvement in F-score over +N ! M with MaxEnt as baseline model (significant improvement with p-value 0.0).", "labels": [], "entities": [{"text": "Metonymy resolution", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.5277449488639832}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9985779523849487}, {"text": "F-score", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9977262616157532}]}, {"text": "Metonymies resolved via verb frames with all and core grammatical relations (i.e., set GR) recover more than 2% recall and slightly improve F-score.", "labels": [], "entities": [{"text": "GR", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.6647282242774963}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9994762539863586}, {"text": "F-score", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.998542070388794}]}, {"text": "Model with the addition of information of verb frames (i.e.,+N M +VF) brings 0.49% improvement in F-score over +N M 1 GR + M 2 using MaxEnt as baseline model (significant improvement with p-value 0.027).", "labels": [], "entities": [{"text": "F-score", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.9979540109634399}]}, {"text": "Model with the addition of data-driven verb semantics (i.e., +N M +V {A,R,IS} ) results in 0.98% improvement in F-score over +N M 1 GR + M 2 using MaxEnt as baseline model (significant improvement with p-value 0.0021).", "labels": [], "entities": [{"text": "F-score", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9974091649055481}]}, {"text": "Overall the model +N M +VF+V{A, R, IS} yields more than 16% (20%) F-score (accuracy) over the baseline models build via NB and MaxEnt.", "labels": [], "entities": [{"text": "F-score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9992212057113647}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9684802889823914}, {"text": "NB", "start_pos": 120, "end_pos": 122, "type": "DATASET", "confidence": 0.9270219802856445}]}], "tableCaptions": [{"text": " Table 1: A knowledge base of verb frames. This  knowledge base is populated using the instances  of C and \u00acC labels given in this table.", "labels": [], "entities": []}, {"text": " Table 2: A knowledge base of verb frames. This  knowledge base is populated using the instances  of C np and \u00acC np labels given in this table.", "labels": [], "entities": []}, {"text": " Table 3: Performance of (B)aseline, +N ! M , +N ! M +V {R} , +N M 1 , +N M 1 GR , +N M 1 GR + M 2 , +N M +VF,  +N M +V {A,R,IS} and +N M +VF+V {A,R,IS}", "labels": [], "entities": []}]}