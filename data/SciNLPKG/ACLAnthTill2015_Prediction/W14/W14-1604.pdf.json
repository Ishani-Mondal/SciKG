{"title": [{"text": "Automatic Transliteration of Romanized Dialectal Arabic", "labels": [], "entities": [{"text": "Automatic Transliteration of Romanized Dialectal Arabic", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6772231012582779}]}], "abstractContent": [{"text": "In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called Arabizi) into Arabic script following the CODA convention for DA orthography.", "labels": [], "entities": []}, {"text": "The presented system uses a finite state transducer trained at the character level to generate all possible transliterations for the input Arabizi words.", "labels": [], "entities": []}, {"text": "We then filter the generated list using a DA morphological analyzer.", "labels": [], "entities": []}, {"text": "After that we pick the best choice for each input word using a language model.", "labels": [], "entities": []}, {"text": "We achieve an accuracy of 69.4% on an unseen test set compared to 63.1% using a system which represents a previously proposed approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996623992919922}]}], "introductionContent": [{"text": "The Arabic language is a collection of varieties: Modern Standard Arabic (MSA), which is used informal settings and has a standard orthography, and different forms of Dialectal Arabic (DA), which are commonly used informally and with increasing presence on the web, but which do not have standard orthographies.", "labels": [], "entities": []}, {"text": "While both MSA and DA are commonly written in the Arabic script, DA (and less so MSA) is sometimes written in the Latin script.", "labels": [], "entities": []}, {"text": "This happens when using an Arabic keyboard is dispreferred or impossible, for example when communicating from a mobile phone that has no Arabic script support.", "labels": [], "entities": []}, {"text": "Arabic written in the Latin script is often referred to as \"Arabizi\".", "labels": [], "entities": []}, {"text": "Arabizi is not a letter-based transliteration from the Arabic script as is, for example, the Buckwalter transliteration).", "labels": [], "entities": [{"text": "Buckwalter transliteration", "start_pos": 93, "end_pos": 119, "type": "DATASET", "confidence": 0.9312821626663208}]}, {"text": "Instead, roughly speaking, writers use sound-to-letter rules inspired by those of English 1 as well as informally established conventions to render the sounds of the DA sentence.", "labels": [], "entities": []}, {"text": "Because the sound-to-letter rules of English are very different from those of Arabic, we obtain complex mappings between the two writing systems.", "labels": [], "entities": []}, {"text": "This issue is compounded by the underlying problem that DA itself does not have any standard orthography in the Arabic script.", "labels": [], "entities": []}, {"text": "Table 1 shows different plausible ways of writing an Egyptian Arabic (EGY) sentence in Arabizi and in Arabic script.", "labels": [], "entities": [{"text": "writing an Egyptian Arabic (EGY) sentence", "start_pos": 42, "end_pos": 83, "type": "TASK", "confidence": 0.6358006671071053}]}, {"text": "Arabizi poses a problem for natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.813216100136439}]}, {"text": "While some tools have recently become available for processing EGY input, e.g.,), they expect Arabic script input (or a Buckwalter transliteration).", "labels": [], "entities": []}, {"text": "We therefore need a tool that converts from Arabizi to Arabic script.", "labels": [], "entities": []}, {"text": "However, the lack of standard orthography in EGY compounds the problem: what should we convert Arabizi into?", "labels": [], "entities": [{"text": "EGY", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.9078763723373413}]}, {"text": "Our answer to this question is to use CODA, a conventional orthography created for the purpose of supporting NLP tools ().", "labels": [], "entities": []}, {"text": "The goal of CODA is to reduce the data sparseness that comes from the same word form appearing in many spontaneous orthographies in data (be it annotated or unannotated).", "labels": [], "entities": []}, {"text": "CODA has been defined for EGY as well as Tunisian Arabic (, and it has been used as part of different approaches for modeling DA morphology), tagging) and spelling correction).", "labels": [], "entities": [{"text": "CODA", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.49559709429740906}, {"text": "EGY", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.8424965739250183}, {"text": "DA morphology", "start_pos": 126, "end_pos": 139, "type": "TASK", "confidence": 0.8181740343570709}, {"text": "spelling correction", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.8946782946586609}]}, {"text": "This paper makes two main contributions.", "labels": [], "entities": []}, {"text": "First, we clearly define the computational problem of transforming Arabizi to CODA.", "labels": [], "entities": [{"text": "CODA", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.5549978017807007}]}, {"text": "This improves over previous work by unambiguously fixing the guages that natively uses the Latin script, such as English or French.", "labels": [], "entities": []}, {"text": "In this paper, we concentrate on Egyptian Arabic, which uses English as its main source of sound-to-letter rules.", "labels": [], "entities": []}, {"text": "target representation for the transformation.", "labels": [], "entities": []}, {"text": "Second, we perform experiments using different components in a transformation pipeline, and show that a combination of character-based transduction, filtering using a morphological analyzer, and using a language model outperforms other architectures, including the state-of-the-art system described in. presented a conversion tool, but did not discuss conversion into a conventionalized orthography, and did not investigate different architectures.", "labels": [], "entities": []}, {"text": "We show in this paper that our proposed architecture, which includes an EGY morphological analyzer, improves over Darwish's architecture.", "labels": [], "entities": [{"text": "EGY morphological analyzer", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.5700256725152334}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We start out by presenting relevant linguistic facts (Section 2) and then we discuss related work.", "labels": [], "entities": []}, {"text": "We present our approach in Section 4 and our experiments and results in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted a suite of experiments to evaluate the performance of our approach and identify optimal settings on the Dev set.", "labels": [], "entities": [{"text": "Dev set", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.907441258430481}]}, {"text": "The optimal result and the baseline are then applied to the blind Test set.", "labels": [], "entities": [{"text": "baseline", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9463109970092773}, {"text": "blind Test set", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.7094001273314158}]}, {"text": "During development, the following settings were explored: \u2022 INV-Selection: The training data of the finite state transducer is used to generate the list of possibilities for each input Arabizi word.", "labels": [], "entities": [{"text": "INV-Selection", "start_pos": 60, "end_pos": 73, "type": "METRIC", "confidence": 0.9873030185699463}]}, {"text": "If the input word cannot be found in the FST training data, the word is kept in Arabizi.", "labels": [], "entities": [{"text": "FST training data", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.757439931233724}]}, {"text": "\u2022 FST-ONLY: Pick the top choice from the list generated by the finite state transducer.", "labels": [], "entities": [{"text": "FST-ONLY", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.95140141248703}]}, {"text": "\u2022 FST-CALIMA: Pick the top choice from the list after the CALIMA filtering.", "labels": [], "entities": [{"text": "FST-CALIMA", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.875621497631073}]}, {"text": "\u2022 FST-CALIMA-Tokenized-LM-5: Run the full pipeline of 3ARRIB with a 5-gram tokenized LM.", "labels": [], "entities": [{"text": "FST-CALIMA-Tokenized-LM-5", "start_pos": 2, "end_pos": 27, "type": "METRIC", "confidence": 0.683405876159668}]}, {"text": "8 \u2022 FST-CALIMA-Tokenized-LM-5-MLE: The same as FST-CALIMA-Tokenized-LM-5, but for an Arabizi word that appears in training, force its most frequently seen mapping directly instead of running the transliteration pipeline for that word.", "labels": [], "entities": [{"text": "FST-CALIMA-Tokenized-LM-5-MLE", "start_pos": 4, "end_pos": 33, "type": "METRIC", "confidence": 0.5092622637748718}, {"text": "FST-CALIMA-Tokenized-LM-5", "start_pos": 47, "end_pos": 72, "type": "DATASET", "confidence": 0.631084144115448}]}, {"text": "\u2022 FST-CALIMA-Untokenized-LM-5: Run the full pipeline of 3ARRIB with a 5-gram untokenized LM.", "labels": [], "entities": [{"text": "FST-CALIMA-Untokenized-LM-5", "start_pos": 2, "end_pos": 29, "type": "METRIC", "confidence": 0.7615535259246826}]}, {"text": "\u2022 FST-Untokenized-LM-5: Run the full pipeline of 3ARRIB minus the CALIMA filtering with a 5-gram untokenized LM.", "labels": [], "entities": [{"text": "FST-Untokenized-LM-5", "start_pos": 2, "end_pos": 22, "type": "DATASET", "confidence": 0.5001282691955566}, {"text": "3ARRIB", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9012713432312012}, {"text": "CALIMA", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9721965789794922}]}, {"text": "This setup is analogous to the transliteration approach proposed by).", "labels": [], "entities": []}, {"text": "Thus we use it as our baseline.", "labels": [], "entities": []}, {"text": "Each of the above experiments is evaluated with exact match, and with Alif/Ya normalization.", "labels": [], "entities": [{"text": "exact match", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.8637447655200958}]}, {"text": "summarizes the results on the Dev set.", "labels": [], "entities": [{"text": "Dev set", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.858212947845459}]}, {"text": "Our best performing setup is FST-CALIMATokenized-LM-5 which has 77.5% accuracy and 79.1% accuracy with normalization.", "labels": [], "entities": [{"text": "FST-CALIMATokenized-LM-5", "start_pos": 29, "end_pos": 53, "type": "METRIC", "confidence": 0.6677280068397522}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9992650151252747}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9993501305580139}]}, {"text": "The baseline system, FST-Untokenized-LM-5, gives 74.1% accuracy and 74.9 % accuracy with normalization.", "labels": [], "entities": [{"text": "FST-Untokenized-LM-5", "start_pos": 21, "end_pos": 41, "type": "DATASET", "confidence": 0.6204473376274109}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9994480013847351}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9993354678153992}]}, {"text": "This highlights the value of morphological filtering as well as sparsity-reducing tokenization.", "labels": [], "entities": []}, {"text": "shows how we do (best system and best baseline) on a blind Test set.", "labels": [], "entities": []}, {"text": "Although the accuracy drops overall, the gap between the best system and the baseline increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9996668100357056}]}], "tableCaptions": [{"text": " Table 2: Results on the Dev set in terms of accuracy (%).", "labels": [], "entities": [{"text": "Dev set", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.8582542240619659}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9996398687362671}]}]}