{"title": [{"text": "Optimizing Generative Dialog State Tracker via Cascading Gradient Descent", "labels": [], "entities": [{"text": "Optimizing Generative Dialog State Tracker", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7680699765682221}]}], "abstractContent": [{"text": "For robust spoken dialog management, various dialog state tracking methods have been proposed.", "labels": [], "entities": [{"text": "spoken dialog management", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.698509931564331}, {"text": "dialog state tracking", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.7363801598548889}]}, {"text": "Although discriminative models are gaining popularity due to their superior performance, generative models based on the Partially Observable Markov Decision Process model still remain attractive since they provide an integrated framework for dialog state tracking and dialog policy optimization.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 242, "end_pos": 263, "type": "TASK", "confidence": 0.7533879280090332}, {"text": "dialog policy optimization", "start_pos": 268, "end_pos": 294, "type": "TASK", "confidence": 0.8173155387242635}]}, {"text": "Although a straightforward way to fit a generative model is to independently train the component probability models, we present a gradient descent algorithm that simultaneously train all the component models.", "labels": [], "entities": []}, {"text": "We show that the resulting tracker performs competitively with other top-performing trackers that participated in DSTC2.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialog systems, afield rapidly growing with the spread of smart mobile devices, has to deal with challenges to become a primary user interface for natural interaction using conversations.", "labels": [], "entities": []}, {"text": "One of the challenges is to maintain the state of the dialog in the conversational process, which is called dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.689647893110911}]}, {"text": "The dialog state encapsulates the information needed to successfully finish the dialog, such as users' goal or requests, and thus it is an essential entity in spoken dialog systems.", "labels": [], "entities": []}, {"text": "However, the error incurred by Automatic Speech Recognition (ASR) and Spoken Language Understanding (SLU) makes the true user utterance not directly observable, and this makes it difficult to figure out the true dialog state.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.7724929749965668}]}, {"text": "Various methods have been used to construct dialog state trackers.", "labels": [], "entities": [{"text": "dialog state trackers", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7204148769378662}]}, {"text": "The traditional methods used inmost commercial systems use hand-crafted rules that typically rely on the most likely result from SLU.", "labels": [], "entities": []}, {"text": "However, these rule-based systems are prone to frequent errors as the most likely result is not always correct.", "labels": [], "entities": []}, {"text": "Hence, these systems often drive the users to respond using simple keywords and to explicitly confirm everything they say, which is far from a natural conversational interaction.", "labels": [], "entities": []}, {"text": "An accurate tracking of the dialog state is crucial for natural and efficient dialogs.", "labels": [], "entities": []}, {"text": "On the other hand, modern methods take a statistical approach to calculate the posterior distribution over the dialog states using multiple results from SLU in order to overcome the error in the most likely SLU result.", "labels": [], "entities": []}, {"text": "Statistical dialog state trackers can be categorized into two approaches depending on how the posterior calculation is modeled.", "labels": [], "entities": [{"text": "dialog state trackers", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.6433965961138407}]}, {"text": "The generative approach uses the generative model that describes how the SLU results are generated from the hidden dialog state and uses the Bayes' rule to calculate the posterior.", "labels": [], "entities": [{"text": "generative", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9633857011795044}]}, {"text": "It has been a popular approach for statistical dialog state tracking, since it naturally fits into the Partially Observable Markov Decision Process (POMDP)), an integrated model for dialog state tracking and dialog strategy optimization.", "labels": [], "entities": [{"text": "statistical dialog state tracking", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7074297294020653}, {"text": "dialog state tracking", "start_pos": 182, "end_pos": 203, "type": "TASK", "confidence": 0.6849806706110636}, {"text": "dialog strategy optimization", "start_pos": 208, "end_pos": 236, "type": "TASK", "confidence": 0.7135758996009827}]}, {"text": "In the POMDP point of view, the dialog state tracking is essentially belief monitoring, which is the task of calculating posterior distribution over the hidden state given the history of observations.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.687117338180542}, {"text": "belief monitoring", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7286668419837952}]}, {"text": "Examples of the dialog state trackers that take the generative approach include ( On the other hand, the discriminative approach directly models the posterior distribution.", "labels": [], "entities": [{"text": "dialog state trackers", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.6432571907838186}, {"text": "generative", "start_pos": 52, "end_pos": 62, "type": "TASK", "confidence": 0.9600148797035217}]}, {"text": "Since it avoids modeling of unnecessary aspects of the task, it typically achieves a better tracking accuracy compared to the generative approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9492634534835815}]}, {"text": "Examples of discriminative dialog state trackers include.", "labels": [], "entities": []}, {"text": "However, their feature functions often refer to past observations, and it remains yet to be seen whether the discriminative approach can be successfully incorporated into POMDP or reinforcement learning (RL) for dialog strategy optimization.", "labels": [], "entities": [{"text": "dialog strategy optimization", "start_pos": 212, "end_pos": 240, "type": "TASK", "confidence": 0.7766242027282715}]}, {"text": "This paper is concerned with the generative approach to dialog state tracking.", "labels": [], "entities": [{"text": "generative", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.9823725819587708}, {"text": "dialog state tracking", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.8542952140172323}]}, {"text": "In our earlier work, the optimization of the tracker was carried out independently for each component model (observation model, user action model, and belief refinement model) that comprised our tracker.", "labels": [], "entities": []}, {"text": "This was not exactly a proper way to train the tracker for overall performance optimization.", "labels": [], "entities": [{"text": "overall performance optimization", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.6961866021156311}]}, {"text": "In this paper, we present an optimization method, which we call \"cascading gradient descent\", that trains component models simultaneously.", "labels": [], "entities": []}, {"text": "We show that this approach yields a dialog state tracker that performs on par with the best ones that participated in the second Dialog State Tracking Challenge (DSTC2).", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7113042672475179}, {"text": "Dialog State Tracking Challenge (DSTC2)", "start_pos": 129, "end_pos": 168, "type": "TASK", "confidence": 0.7629341695989881}]}, {"text": "The rest of the paper is organized as follows: We briefly review the background of our work in section 2, and present our method in section 3.", "labels": [], "entities": []}, {"text": "We then explain the DSTC2 dialog domain and the experimental settings in section 4, and discuss the results in section 5.", "labels": [], "entities": [{"text": "DSTC2 dialog domain", "start_pos": 20, "end_pos": 39, "type": "DATASET", "confidence": 0.8644960125287374}]}, {"text": "Finally, we conclude the paper with the summary and the suggestion for future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The restaurant information domain used in DSTC2 is arranged into three datasets: train, dev, test.", "labels": [], "entities": [{"text": "DSTC2", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.5924163460731506}]}, {"text": "The first two datasets are labeled with the true user goals and user actions to optimize the dialog state tracker before submission.", "labels": [], "entities": []}, {"text": "The half of the dialogs are created with artificially degraded speech recognizers, intended to better distinguish the performances of trackers.", "labels": [], "entities": []}, {"text": "Details of each dataset are as below: \u2022 dstc2 train: Composed of 1612 dialogs of 11405 turns, produced from two different dialog managers with a hand-crafted dialog policy.", "labels": [], "entities": []}, {"text": "\u2022 dstc2 dev: Composed of 506 dialogs of 3836 turns, produced from the dialog managers used in dstc2 train set.", "labels": [], "entities": []}, {"text": "Most of dialog state trackers show lower performance on this dataset than others.", "labels": [], "entities": [{"text": "dialog state trackers", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.7334276040395101}]}, {"text": "\u2022 dstc2 test: Composed of 1117 dialogs of 9689 turns, produced from the dialog policy trained by reinforcement learning, which is not used for the train and dev datasets.", "labels": [], "entities": []}, {"text": "We used both train and dev sets as the training data, as if they were one big dataset.", "labels": [], "entities": []}, {"text": "Although the true labels for the test dataset were made public after the challenge, we did not use these labels in anyway for optimizing our tracker.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Test set scores of joint goal slot of our proposed algorithm and other trackers are presented. The  joint goal slot is a slot that is treated as correct when every goal slot is correct.", "labels": [], "entities": []}]}