{"title": [{"text": "English-to-Hindi system description for WMT 2014: Deep Source-Context Features for Moses", "labels": [], "entities": [{"text": "WMT 2014", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.7038367092609406}]}], "abstractContent": [{"text": "This paper describes the IPN-UPV participation on the English-to-Hindi translation task from WMT 2014 International Evaluation Campaign.", "labels": [], "entities": [{"text": "English-to-Hindi translation task", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.7139623562494913}, {"text": "WMT 2014 International Evaluation Campaign", "start_pos": 93, "end_pos": 135, "type": "DATASET", "confidence": 0.8064040422439576}]}, {"text": "The system presented is based on Moses and enhanced with deep learning by means of a source-context feature function.", "labels": [], "entities": []}, {"text": "This feature depends on the input sentence to translate, which makes it more challenging to adapt it into the Moses framework.", "labels": [], "entities": []}, {"text": "This work reports the experimental details of the system putting special emphasis on: how the feature function is integrated in Moses and how the deep learning representations are trained and used.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the joint participation of the Instituto Polit\u00e9cnico Nacional (IPN) and the Universitat Polit\u00e8cnica de Valencia (UPV) in cooperation with Institute for Infocomm Research (I2R) on the 9th Workshop on Statistical Machine Translation).", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 220, "end_pos": 251, "type": "TASK", "confidence": 0.7863472501436869}]}, {"text": "In particular, our participation was in the English-to-Hindi translation task.", "labels": [], "entities": [{"text": "English-to-Hindi translation task", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.7647217114766439}]}, {"text": "Our baseline system is an standard phrasebased SMT system built with Moses (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9460346102714539}]}, {"text": "Starting from this system we propose to introduce a source-context feature function inspired by previous works (R. ). The main novelty of this work is that the source-context feature is computed in anew deep representation.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the motivation of this semantic feature and the description of how the source context feature function is added to Moses.", "labels": [], "entities": []}, {"text": "Section 3 explains how both the latent semantic indexing and deep representation of sentences are used to better compute similarities among source contexts.", "labels": [], "entities": [{"text": "latent semantic indexing", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6571392118930817}]}, {"text": "Section 4 details the WMT experimental framework and results, which proves the relevance of the technique proposed.", "labels": [], "entities": [{"text": "WMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.8893537521362305}]}, {"text": "Finally, section 5 reports the main conclusions of this system description paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the experiments carried out in the context of WMT 2014.", "labels": [], "entities": [{"text": "WMT 2014", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.6055234372615814}]}, {"text": "For English-Hindi the parallel training data was collected by Charles University and consisted of 3.6M English words and 3.97M Hindi words.", "labels": [], "entities": [{"text": "Charles University", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.9506449699401855}]}, {"text": "There was a monolingual corpus for Hindi comming from different sources which consisted of 790.8M Hindi words.", "labels": [], "entities": []}, {"text": "In addition, there was a development corpus of news data translated specifically for the task which consisted of 10.3m English words and 10.1m Hindi words.", "labels": [], "entities": []}, {"text": "For internal experimentation we built a test set extracted from the training set.", "labels": [], "entities": []}, {"text": "We selected randomly 429 sentences from the training corpus which appeared only once, removed them from training and used them as internal test set.", "labels": [], "entities": []}, {"text": "Monolingual Hindi corpus was used to build a larger language model.", "labels": [], "entities": []}, {"text": "The language model was computed doing an interpolation of the language model trained on the Hindi part of the bilingual corpus (3.97M words) and the language model trained on the monolingual Hindi corpus (790.8M words).", "labels": [], "entities": []}, {"text": "Interpolation was optimised in the development set provided by the organizers.", "labels": [], "entities": [{"text": "Interpolation", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.8685129880905151}]}, {"text": "Both language models interpolated were 5-grams using Kneser-Ney smoothing.", "labels": [], "entities": []}, {"text": "The preprocessing of the corpus was done with the standard tools from Moses.", "labels": [], "entities": []}, {"text": "English was lowercased and tokenized.", "labels": [], "entities": []}, {"text": "Hindi was tokenized with the simple tokenizer provided by the organizers.", "labels": [], "entities": []}, {"text": "We cleaned the corpus using standard parameters (i.e. we keep sentences between 1 and 80 words of length).", "labels": [], "entities": []}, {"text": "For training, we used the default Moses options, which include: the grow-diag-final and word alignment symmetrization, the lexicalized reordering, relative frequencies (conditional and posterior probabilities) with phrase discounting, lexical weights and phrase bonus for the translation model (with phrases up to length 10), a language model (see details below) and a word bonus model.", "labels": [], "entities": []}, {"text": "Optimisation was done using the MERT algorithm available in Moses.", "labels": [], "entities": [{"text": "MERT", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9041581153869629}]}, {"text": "Optimisation is slow because of the way integration of the feature function is done that it requires one phrase table for each input sentence.", "labels": [], "entities": []}, {"text": "During translation, we dropped unknown words and used the option of minimum bayes risk decoding.", "labels": [], "entities": [{"text": "translation", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.9803017973899841}]}, {"text": "Postprocessing consisted in de-tokenizing Hindi using the standard detokenizer of Moses (the English version).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU scores for En2Hi translation task..   \u2020 depicts statistical significance (p-value<0.05).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992567896842957}, {"text": "En2Hi translation task.", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7366881668567657}, {"text": "statistical significance", "start_pos": 63, "end_pos": 87, "type": "METRIC", "confidence": 0.8061342835426331}]}, {"text": " Table 3: Probability values (conditional, cp, and  posterior, pp, as standard features in a phrase- based system) for the word cry and two Hindi  translations.", "labels": [], "entities": []}]}