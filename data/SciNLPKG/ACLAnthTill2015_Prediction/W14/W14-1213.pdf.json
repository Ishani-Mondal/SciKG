{"title": [], "abstractContent": [{"text": "Document classification using automated linguistic analysis and machine learning (ML) has been shown to be a viable road forward for readability assessment.", "labels": [], "entities": [{"text": "Document classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9454646408557892}, {"text": "readability assessment", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.7724100053310394}]}, {"text": "The best models can be trained to decide if a text is easy to read or not with very high accuracy, e.g. a model using 117 parameters from shallow, lexical, morphological and syntactic analyses achieves 98,9% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9950953722000122}, {"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.997547447681427}]}, {"text": "In this paper we compare models created by parameter optimization over subsets of that total model to find out to which extent different high-performing models tend to consist of the same parameters and if it is possible to find models that only use features not requiring parsing.", "labels": [], "entities": []}, {"text": "We used a genetic algorithm to systematically optimize parameter sets of fixed sizes using accuracy of a Support Vector Machine classi-fier as fitness function.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9991918206214905}]}, {"text": "Our results show that it is possible to find models almost as good as the currently best models while omitting parsing based features.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of readability assessment is the problem of mapping from a text to some unit representing the text's degree of readability.", "labels": [], "entities": [{"text": "readability assessment", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.7424122989177704}]}, {"text": "Measures of readability are mostly used to inform a reader how difficult a text is to read, either to give them a hint that they may try to find an easier to read text on the same topic or simply to inform them that a text may take sometime to comprehend.", "labels": [], "entities": []}, {"text": "Readability measures are mainly used to inform persons with reading disabilities on the complexity of a text, but can also be used to, for instance, assist teachers with assessing the reading ability of a student.", "labels": [], "entities": []}, {"text": "By measuring the reading abilities of a person, it might also be possible to automatically find texts that fits that persons reading ability.", "labels": [], "entities": []}, {"text": "Since the early 2000s the speed and accuracy of text analysis tools such as lemmatizers, partof-speech taggers and syntax parsers have made new text features available for readability assessment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9981291890144348}, {"text": "partof-speech taggers", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.7608305513858795}]}, {"text": "By using machine learning a number of researchers have devised innovative ways of assessing readability.", "labels": [], "entities": []}, {"text": "For instance, phrase grammar parsing has been used to find the average number of sub-clauses, verb phrases, noun phrases and average tree depth ().", "labels": [], "entities": [{"text": "phrase grammar parsing", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.8737478852272034}]}, {"text": "The use of language models to assess the degree of readability was also introduced in the early 2000s) and later combined with classification algorithms such as support vector machines to further increase accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9963294863700867}]}, {"text": "In this paper we investigate if it is possible to find a set of parameters for easy-to-read classification, on par with the best models used today, without using parsing based features.", "labels": [], "entities": []}, {"text": "Finding such a set would facilitate portability and provide faster assessment of readability.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the single feature models.  The accuracy represents the average percentage of  texts classified correctly, with the standard devia- tion within parentheses. Precision and Recall are  also provided for both easy-to-read (L\u00e4SBarT) and  non-easy-to-read (Other) sets. Italicized features  consist of more than one parameter.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9992789626121521}, {"text": "Precision", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.9981813430786133}, {"text": "Recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.998777449131012}]}, {"text": " Table 3. Using  all features provides the best model with 98.9%  accuracy which could be considered the target ac- curacy of our parameter optimization.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9989860653877258}, {"text": "ac- curacy", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9366538921991984}]}, {"text": " Table 2: Performance of the POS-tag ratio param- eters ordered by performance. The various mod- els are tags used in the SUC corpus (Ejerhed et  al., 2006), normally part of speech tags, e.g. VB is  verb, with some extensions, but the tags comprise  other features as well e.g. MAD comprises sen- tence terminating delimiters, PAD pair-wise de- limiters such as parentheses and MID other delim- iters such as comma and semicolon. Measures as  described in Table 1.", "labels": [], "entities": [{"text": "SUC corpus", "start_pos": 122, "end_pos": 132, "type": "DATASET", "confidence": 0.7456022500991821}]}, {"text": " Table 3: Performance of the full feature sets. Mea- sures as described in Table 1.", "labels": [], "entities": [{"text": "Mea- sures", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9481669465700785}]}, {"text": " Table 4: Performance of the Dependency type ra- tio attributes ordered by performance. Measures  as described in", "labels": [], "entities": []}, {"text": " Table 1 Continued in table 5.", "labels": [], "entities": []}, {"text": " Table 5: Performance of the Dependency type ra- tio attributes ordered by performance. Measures  as described in Table 1. Continued from table 4.", "labels": [], "entities": [{"text": "Measures", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.8718801140785217}]}, {"text": " Table 6: Features in the best performing sets found  for each size by the genetic search through the  POS-ratio space.", "labels": [], "entities": []}, {"text": " Table 7: Sizes of model space based on number of  attributes in the target model.", "labels": [], "entities": []}, {"text": " Table 8: Performance of the feature sets selected  from the set of POS-tag ratio features ordered by  number of parameters. Measures as described in  Table 1.", "labels": [], "entities": [{"text": "Measures", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.7414425611495972}]}, {"text": " Table 9: Features in the best performing sets found  for each size by the genetic search through the  non-syntactic space.", "labels": [], "entities": []}]}