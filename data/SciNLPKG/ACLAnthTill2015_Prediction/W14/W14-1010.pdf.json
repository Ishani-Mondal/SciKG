{"title": [{"text": "Improving the precision of automatically constructed human-oriented translation dictionaries", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9627979397773743}, {"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9946430921554565}]}], "abstractContent": [{"text": "In this paper we address the problem of automatic acquisition of a human-oriented translation dictionary from a large-scale parallel corpus.", "labels": [], "entities": [{"text": "automatic acquisition of a human-oriented translation dictionary", "start_pos": 40, "end_pos": 104, "type": "TASK", "confidence": 0.7268352636269161}]}, {"text": "The initial translation equivalents can be extracted with the help of the techniques and tools developed for the phrase-table construction in statistical machine translation.", "labels": [], "entities": [{"text": "phrase-table construction", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.7557155191898346}, {"text": "statistical machine translation", "start_pos": 142, "end_pos": 173, "type": "TASK", "confidence": 0.6565506954987844}]}, {"text": "The acquired translation equivalents usually provide good lexicon coverage, but they also contain a large amount of noise.", "labels": [], "entities": []}, {"text": "We propose a supervised learning algorithm for the detection of noisy translations, which takes into account the context and syntax features, averaged over the sentences in which a given phrase pair occurred.", "labels": [], "entities": [{"text": "detection of noisy translations", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.784170538187027}]}, {"text": "Across nine Euro-pean language pairs the number of serious translation errors is reduced by 43.2%, compared to a baseline which uses only phrase-level statistics.", "labels": [], "entities": []}], "introductionContent": [{"text": "The automatic acquisition of translation equivalents from parallel texts has been extensively studied since the 1990s.", "labels": [], "entities": [{"text": "automatic acquisition of translation equivalents from parallel texts", "start_pos": 4, "end_pos": 72, "type": "TASK", "confidence": 0.7960866615176201}]}, {"text": "At the beginning, the acquired bilingual lexicons had much poorer quality as compared to the human-built translation dictionaries.", "labels": [], "entities": []}, {"text": "The limited size of available parallel corpora often resulted in small coverage and the imperfections of alignment methods introduced a considerable amount of noisy translations.", "labels": [], "entities": []}, {"text": "However, the automatimacally acquired lexicons served as internal resources for statistical machine translation (SMT) (, information retrieval (IR) (, or computer-assisted lexicography.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.8154729803403219}, {"text": "information retrieval (IR)", "start_pos": 121, "end_pos": 147, "type": "TASK", "confidence": 0.8412352681159974}]}, {"text": "The current progress in search of web-based parallel documents makes it possible to automatically construct largescale bilingual lexicons.", "labels": [], "entities": []}, {"text": "These lexicons can already compare in coverage to the traditional translation dictionaries.", "labels": [], "entities": [{"text": "coverage", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9740309715270996}]}, {"text": "Hence anew interesting possibility arises -to produce automatically acquired human-oriented translation dictionaries, that have a practical application.", "labels": [], "entities": []}, {"text": "A machine translation system can output an automatically generated dictionary entry in response to the short queries.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7136069238185883}]}, {"text": "The percentage of short queries can be quite large, and the system benefits from showing several possible translations instead of a single result of machine translation ().", "labels": [], "entities": []}, {"text": "The initial translation equivalents fora bilingual lexicon can be extracted with the help of the techniques and tools developed for the phrasetable construction in SMT.", "labels": [], "entities": [{"text": "phrasetable construction", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.8107952177524567}, {"text": "SMT", "start_pos": 164, "end_pos": 167, "type": "TASK", "confidence": 0.8478001952171326}]}, {"text": "The widely used word alignment and phrase extraction algorithms are described in and.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7867420315742493}, {"text": "phrase extraction", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8100995123386383}]}, {"text": "Though an SMT phrase-table actually consists of translation equivalents, it may differ substantially from a traditional dictionary.", "labels": [], "entities": [{"text": "SMT phrase-table", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.8729845881462097}]}, {"text": "Human-oriented dictionary SMT phrase- Precision is important.", "labels": [], "entities": [{"text": "SMT phrase", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.8133465051651001}, {"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.6454668045043945}]}, {"text": "Having lots of lowprobability noise is acceptable, since it is generally overridden by better translations.: Differences between a human-oriented dictionary and an SMT phrase-table.", "labels": [], "entities": [{"text": "SMT phrase-table", "start_pos": 164, "end_pos": 180, "type": "TASK", "confidence": 0.8597931563854218}]}, {"text": "While the problems of lemmatization and selection of linguistically motivated phrases can be addressed by applying appropriate morphological and syntactic tools, the problem of noise reduction is essential for the dictionary quality.", "labels": [], "entities": []}, {"text": "The current progress in the automatic acquisition of similar Web documents in different languages allows to collect large-scale corpora.", "labels": [], "entities": []}, {"text": "But the automatically found documents can be non-parallel, or contain spam, machine translation, language recognition mistakes, badly parsed HTML-markup.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.6927337795495987}]}, {"text": "The noisy parallel sentences can be the source of lots of noisy translations -unrelated, misspelled, or belonging to a different language.", "labels": [], "entities": []}, {"text": "For example, non-parallel sentences The apartment is at a height of 36 floors!", "labels": [], "entities": []}, {"text": "(English) La plage est\u00e0est`est\u00e0 1 minute en voiture.", "labels": [], "entities": []}, {"text": "(French: The beach is 1 minute by car.) may produce a wrong translation \"apartmentplage\".", "labels": [], "entities": []}, {"text": "Or, automatically translated sentences The figures in the foreground and background playoff each other well.", "labels": [], "entities": []}, {"text": "(English) Les chiffres du premier planet jouer hors de l'autre bien.", "labels": [], "entities": []}, {"text": "(French: The digits of the foreground and play out of the other well.) may produce a wrong phrase translation \"figures in the foreground -chiffres du premier plan\".", "labels": [], "entities": []}, {"text": "An intuitive approach would be to apply noise filtering to the corpus, not to the lexicon.", "labels": [], "entities": []}, {"text": "One could discard those sentences that deviate too much from the expected behavior.", "labels": [], "entities": []}, {"text": "For example, sentences that have many unknown words and few symmetrically aligned words are unlikely to be really parallel.", "labels": [], "entities": []}, {"text": "However, natural language demonstrates a great variability.", "labels": [], "entities": []}, {"text": "A single sentence pair can deviate strongly from the expected behavior, and still contain some good translations.", "labels": [], "entities": []}, {"text": "On the other hand, many noisy translations can still penetrate the lexicon, and further noise detection is necessary.", "labels": [], "entities": []}, {"text": "Ina bilingual lexicon we want not just to lower the probabilities of noisy translations, but to remove them completely.", "labels": [], "entities": []}, {"text": "This can be regarded as a binary classification task -the phrase pairs are to be classified into good and noisy ones.", "labels": [], "entities": []}, {"text": "Different types of information can be combined in a feature vector.", "labels": [], "entities": []}, {"text": "We take advantage of the phrase-level features, such as co-occurrence counts or translation probabilities, and also propose a number of sentence-level context features.", "labels": [], "entities": []}, {"text": "To calculate the sentence-level features fora given phrase-pair, we average the characteristics of all the sentences where it occurs.", "labels": [], "entities": []}, {"text": "We test the proposed algorithm experimentally, by constructing the bilingual lexicons for nine language pairs.", "labels": [], "entities": []}, {"text": "The manually annotated samples of phrase pairs serve as the data for training supervised classifiers.", "labels": [], "entities": []}, {"text": "The experiment shows that the use of the sentence-level features increases the classification accuracy, compared to a baseline which uses only phrase frequencies and translation probabilities.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9802150726318359}]}, {"text": "We compare the accuracy of different classifiers and evaluate the importance of different features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9988434314727783}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we outline the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our approach to the noise reduction in a bilingual lexicon and discusses the proposed features.", "labels": [], "entities": [{"text": "noise reduction", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7279957830905914}]}, {"text": "We describe our experiments on training classifiers in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on nine language pairs: German-English, German-Russian, FrenchEnglish, French-Russian, Italian-English, ItalianRussian, Spanish-English, Spanish-Russian and English-Russian.", "labels": [], "entities": []}, {"text": "The parallel corpora consisted of the sentence-aligned documents automatically collected from multilingual web-sites.", "labels": [], "entities": []}, {"text": "We implemented the procedure of bilingual lexicon construction and the algorithm calculating the sentence-level features (Section 3).", "labels": [], "entities": [{"text": "bilingual lexicon construction", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.7046650250752767}]}, {"text": "The annotated phrase pair samples, one for each language pair, provided positive and negative examples for training a supervised classifier.", "labels": [], "entities": []}, {"text": "We compared the accuracy of several classifiers trained on different feature sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9993274211883545}]}, {"text": "The importance of different features was evaluated .  For the experiment we selected random 1 translation equivalents from the nine translation lexicons, to which no further noise reduction had been applied.", "labels": [], "entities": []}, {"text": "The resulting translation equivalents were assessed by human experts.", "labels": [], "entities": []}, {"text": "The annotation task was to determine how well a phrase pair fits fora human-oriented translation dictionary.", "labels": [], "entities": []}, {"text": "The annotators classified each translation according to the following gradation: Class 0 -difficult to assess.", "labels": [], "entities": []}, {"text": "1 Random was used proportionally to the square root of joint frequency, in order to balance rare and frequent phrase pairs in the sample.", "labels": [], "entities": [{"text": "Random", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.9755337834358215}]}, {"text": "Class 1 -totally wrong or noisy (e.g. misspelled); Class 2 -incorrect or incomplete translation; Class 3 -not a mistake, but unnecessary translation; Class 4 -good, but not vital; Class 5 -vital translation (must be present in human-built dictionary); The pairs annotated as 0 usually represented the translations of unfamiliar words, abbreviations and the like.", "labels": [], "entities": []}, {"text": "Such phrases were excluded from training and testing.", "labels": [], "entities": []}, {"text": "We didn't use \"acceptable, but unnecessary\" translation pairs either, because they do not influence the quality of the lexicon.", "labels": [], "entities": []}, {"text": "We treated as negative the phrase pairs that were annotated as 1 or 2.", "labels": [], "entities": []}, {"text": "Analogously, the positive examples had to belong to 4 or 5 class.", "labels": [], "entities": []}, {"text": "The annotation statistics is given in: Statistics of the annotated data: the number of annotated phrase pairs, the percentage of negative and positive examples.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The number of phrase pairs on different  stages of French-English and French-Russian dic- tionary creation. Phrase pairs in the initial phrase  table are restricted to at most 1 source word and at  most 3 target words.", "labels": [], "entities": [{"text": "French-Russian dic- tionary creation", "start_pos": 80, "end_pos": 116, "type": "TASK", "confidence": 0.5219038784503937}]}, {"text": " Table 4: Statistics of the annotated data: the num- ber of annotated phrase pairs, the percentage of  negative and positive examples.", "labels": [], "entities": []}, {"text": " Table 5: Percentage of prediction errors of dif- ferent classifiers, averaged over the nine language  pairs.", "labels": [], "entities": []}, {"text": " Table 6: Classification quality of the classifier  trained on all features, compared to the baseline  trained only on phrase-level features. The relative  change of the baseline values is given in brackets.", "labels": [], "entities": []}, {"text": " Table 7: Classification accuracy w.r.t different size  of training set averaged over eight language pairs.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9279769062995911}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9535090923309326}]}, {"text": " Table 8: Feature importance measured by  the mean decrease of classification accu- racy", "labels": [], "entities": [{"text": "Feature importance", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9857889115810394}, {"text": "classification accu- racy", "start_pos": 63, "end_pos": 88, "type": "METRIC", "confidence": 0.7992366403341293}]}, {"text": " Table 9: English translations of the French word  \"connexion\". C(e, f ) is the co-occurrence count,  p(f |e), p(e|f ) are the translation probabilities of  lemmatized pairs. The last column shows the clas- sification result.", "labels": [], "entities": []}]}