{"title": [{"text": "Self-disclosure topic model for Twitter conversations", "labels": [], "entities": []}], "abstractContent": [{"text": "Self-disclosure, the act of revealing oneself to others, is an important social behavior that contributes positively to intimacy and social support from others.", "labels": [], "entities": []}, {"text": "It is a natural behavior, and social scientists have carried out numerous quantitative analyses of it through manual tagging and survey questionnaires.", "labels": [], "entities": []}, {"text": "Recently, the flood of data from online social networks (OSN) offers a practical way to observe and analyze self-disclosure behavior at an unprecedented scale.", "labels": [], "entities": []}, {"text": "The challenge with such analysis is that OSN data come with no annotations, and it would be impossible to manually annotate the data fora quantitative analysis of self-disclosure.", "labels": [], "entities": []}, {"text": "As a solution, we propose a semi-supervised machine learning approach, using a variant of latent Dirichlet allocation for automatically classifying self-disclosure in a massive dataset of Twitter conversations.", "labels": [], "entities": []}, {"text": "For measuring the accuracy of our model, we manually annotate a small subset of our dataset, and we show that our model shows significantly higher accuracy and F-measure than various other methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9989340901374817}, {"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9989632368087769}, {"text": "F-measure", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9987370371818542}]}, {"text": "With the results our model, we uncover a positive and significant relationship between self-disclosure and online conversation frequency overtime.", "labels": [], "entities": []}], "introductionContent": [{"text": "Self-disclosure is an important and pervasive social behavior.", "labels": [], "entities": []}, {"text": "People disclose personal information about themselves to improve and maintain relationships.", "labels": [], "entities": []}, {"text": "For example, when two people meet for the first time, they disclose their names and interests.", "labels": [], "entities": []}, {"text": "One positive outcome of self-disclosure is social support from others, shown also in online social networks (OSN) such as Twitter ( ).", "labels": [], "entities": []}, {"text": "Receiving social support would then lead the user to be more active on OSN (.", "labels": [], "entities": [{"text": "OSN", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.9179713726043701}]}, {"text": "In this paper, we seek to understand this important social behavior using a large-scale Twitter conversation data, automatically classifying the level of self-disclosure using machine learning and correlating the patterns with subsequent OSN usage.", "labels": [], "entities": []}, {"text": "Twitter conversation data, explained in more detail in section 4.1, enable a significantly larger scale study of naturally-occurring self-disclosure behavior, compared to traditional social science studies.", "labels": [], "entities": []}, {"text": "One challenge of such large scale study, though, remains in the lack of labeled groundtruth data of self-disclosure level.", "labels": [], "entities": []}, {"text": "That is, naturally-occurring Twitter conversations do not come tagged with the level of self-disclosure in each conversation.", "labels": [], "entities": []}, {"text": "To overcome that challenge, we propose a semi-supervised machine learning approach using probabilistic topic modeling.", "labels": [], "entities": []}, {"text": "Our self-disclosure topic model (SDTM) assumes that self-disclosure behavior can be modeled using a combination of simple linguistic features (e.g., pronouns) with automatically discovered semantic themes (i.e., topics).", "labels": [], "entities": []}, {"text": "For instance, an utterance \"I am finally through with this disastrous relationship\" uses a first-person pronoun and contains a topic about personal relationships.", "labels": [], "entities": []}, {"text": "In comparison with various other models, SDTM shows the highest accuracy, and the resulting self-disclosure patterns of the users are correlated significantly with their future OSN usage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9993771910667419}]}, {"text": "Our contributions to the research community include the following: \u2022 We present a topic model that explicitly includes the level of self-disclosure in a conversation using linguistic features and the latent semantic topics (Sec. 3).", "labels": [], "entities": []}, {"text": "\u2022 We collect a large dataset of Twitter conversations over three years and annotate a small subset with self-disclosure level (Sec. 4).", "labels": [], "entities": []}, {"text": "\u2022 We compare the classification accuracy of SDTM with other models and show that it performs the best (Sec. 5).", "labels": [], "entities": [{"text": "classification", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.9064825773239136}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7573262453079224}]}, {"text": "\u2022 We correlate the self-disclosure patterns of users and their subsequent OSN usage to show that there is a positive and significant relationship (Sec. 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "We first run SDTM with all of our Twitter conversation data with 150; 120; 120 topics for SDTM K G , K M and K H respectively.", "labels": [], "entities": []}, {"text": "The hyper-parameters are the same as in section 5.", "labels": [], "entities": []}, {"text": "To handle a large dataset, we employ a distributed algorithm).", "labels": [], "entities": []}, {"text": "shows some of the topics that were prominent in each SD level by KL-divergence.", "labels": [], "entities": []}, {"text": "As expected, G level includes general topics such as food, celebrity, soccer and IT devices, M level includes personal communication and birthday, and finally, H level includes sickness and profanity.", "labels": [], "entities": []}, {"text": "For comparing conversation frequencies overtime, we divided the conversations into two sets for each dyad.", "labels": [], "entities": []}, {"text": "For the initial period, we include conversations from the dyad's first conversation to 60 days later.", "labels": [], "entities": []}, {"text": "And for the subsequent period, we include conversations during the subsequent 30 days.", "labels": [], "entities": []}, {"text": "We compute proportions of conversation for each SD level for each dyad in the initial and subsequent periods.", "labels": [], "entities": []}, {"text": "Also, we define anew measurement, SD level score fora dyad in the period, which is a weighted sum of each conversation with SD levels mapped to 1, 2, and 3, for the levels G, M, and H, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: SD level classification accuracies and F- measures using annotated data. Acc is accuracy,  and G F 1 is F-measure for classifying the G level.  Avg F 1 is the average value of G F 1 , M F 1 and H  F 1 . SDTM outperforms all other methods com- pared. The difference between SDTM and FirstP  is statistically significant (p-value < 0.05 for ac- curacy, < 0.0001 for Avg F 1 ).", "labels": [], "entities": [{"text": "SD level classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8019376993179321}, {"text": "F- measures", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.9372578263282776}, {"text": "Acc", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9979841709136963}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9985546469688416}, {"text": "F-measure", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9670421481132507}, {"text": "Avg F 1", "start_pos": 154, "end_pos": 161, "type": "METRIC", "confidence": 0.9704098304112753}, {"text": "FirstP", "start_pos": 292, "end_pos": 298, "type": "DATASET", "confidence": 0.8910751342773438}]}, {"text": " Table 5: High ranked topics in each level by comparing KL-divergence with other level's topics", "labels": [], "entities": []}]}