{"title": [{"text": "21 \u00e8me Traitement Automatique des Langues Naturelles", "labels": [], "entities": []}], "abstractContent": [{"text": "Nous d\u00e9crivons une \u00e9tude visant \u00e0 rep\u00e9rer automatiquement des relations lexico-s\u00e9mantiques \u00e0 partir de corpus sp\u00e9cialis\u00e9s au moyen d'une m\u00e9thode d'analyse distributionnelle.", "labels": [], "entities": []}, {"text": "Les r\u00e9sultats obtenus montrent qu'un mod\u00e8le non structur\u00e9, bas\u00e9 sur la cooccurrence des mots dans le corpus, permet d'obtenir, pour un terme donn\u00e9, des termes reli\u00e9s sur le plan paradigmatique (quasi-synonymes, antonymes, hyponymes).", "labels": [], "entities": []}, {"text": "Nous discuterons la m\u00e9thodologie d'\u00e9valuation et de s\u00e9lection des param\u00e8tres, qui exploite des donn\u00e9es extraites d'un dictionnaire sp\u00e9cialis\u00e9.", "labels": [], "entities": []}, {"text": "Nous analyserons l'influence de param\u00e8tres tels que la forme et la taille de la fen\u00eatre de contexte, la pond\u00e9ration des statistiques et l'utilisation d'une technique de r\u00e9duction de dimension.", "labels": [], "entities": [{"text": "pond\u00e9ration des statistiques", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.8450591564178467}]}, {"text": "Nous comparerons \u00e9galement les relations identifi\u00e9es dans deux corpus, un portant sur le domaine de l'environnement et l'autre, sur le traitement automatique de la langue.", "labels": [], "entities": []}, {"text": "We describe an experiment wherein a word space model is used to automatically extract lexico-semantic relations from specialized corpora.", "labels": [], "entities": []}, {"text": "Results show that an unstructured model, which exploits basic word cooccurrence information, can effectively identify paradigmatically related terms (near synonyms, antonyms, hyponyms) given a target term.", "labels": [], "entities": []}, {"text": "We discuss the parameter selection and evaluation methodologies, which rely on data extracted from a specialized dictionary.", "labels": [], "entities": [{"text": "parameter selection", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.6834715455770493}]}, {"text": "We analyze the impact of parameters such as the shape and size of the context window, the weighting scheme and the use of dimensionality reduction.", "labels": [], "entities": []}, {"text": "We also compare the relations identified in two specialized corpora, one dealing with the environment and the other pertaining to natural language processing.", "labels": [], "entities": []}, {"text": "Mots-cl\u00e9s : S\u00e9mantique distributionnelle, s\u00e9mantique computationnelle, relations lexico-s\u00e9mantiques, corpus sp\u00e9-cialis\u00e9, terminologie.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dans le cadre d'un projet portant sur l'identification de th\u00e9matiques en corpus sp\u00e9cialis\u00e9, nous cherchons \u00e0 extraire des relations lexico-s\u00e9mantiques \u00e0 partir de donn\u00e9es textuelles.", "labels": [], "entities": []}, {"text": "Notre objectif est d'obtenir, \u00e0 partir d'un terme donn\u00e9, des termes dont le sens est reli\u00e9 \u00e0 celui de la requ\u00eate ; dans cet article, nous nous int\u00e9resserons particuli\u00e8rement \u00e0 une classe de relations paradigmatiques classiques, \u00e0 savoir la (quasi-)synonymie, l'antonymie et l'hyponymie.", "labels": [], "entities": []}, {"text": "Il n'est pas important, du moins \u00e0 cette \u00e9tape du projet, que les relations extraites soient \u00e9tiquet\u00e9es, seulement qu'elles concernent des termes du domaine cibl\u00e9 pour le projet et qu'elles appartiennent \u00e0 cette classe particuli\u00e8re de relations.", "labels": [], "entities": []}, {"text": "Les techniques de la s\u00e9mantique distributionnelle apparaissent comme un moyen efficace de r\u00e9aliser cette t\u00e2che.", "labels": [], "entities": [{"text": "s\u00e9mantique distributionnelle", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6610606610774994}]}, {"text": "Celles-ci sont bas\u00e9es sur l'hypoth\u00e8se distributionnelle, d'abord formul\u00e9e par, selon laquelle les mots apparaissant dans des contextes similaires ont tendance \u00e0 pr\u00e9senter des affinit\u00e9s s\u00e9mantiques.", "labels": [], "entities": []}, {"text": "Ces techniques ont d'abord \u00e9t\u00e9 d\u00e9ploy\u00e9es sur des corpus sp\u00e9cialis\u00e9s, \"puisque c'est pr\u00e9cis\u00e9ment pour traiter des donn\u00e9es de ce type qu'a \u00e9t\u00e9 formul\u00e9e l'hypoth\u00e8se distributionnelle\".", "labels": [], "entities": []}, {"text": "La tendance actuelle consiste plut\u00f4t \u00e0 utiliser des corpus les plus gros possibles, provenant souvent de sources h\u00e9t\u00e9rog\u00e8nes, dont le nombre de mots d\u00e9passe souvent le milliard.", "labels": [], "entities": []}, {"text": "() soulignent cette tendance, et optent d\u00e9lib\u00e9r\u00e9ment pour un corpus de taille plus modeste ; de m\u00eame, utilise un corpus relativement petit parce que la taille des corpus qu'il est possible de construire d\u00e9pend de la langue et du domaine cibl\u00e9s.", "labels": [], "entities": []}, {"text": "Les corpus utilis\u00e9s dans ces travaux contiennent tout de m\u00eame des centaines de millions de 239 GABRIEL BERNIER-COLBORNE mots.", "labels": [], "entities": [{"text": "GABRIEL", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.8048258423805237}, {"text": "BERNIER-COLBORNE", "start_pos": 103, "end_pos": 119, "type": "METRIC", "confidence": 0.7160146832466125}]}, {"text": "Ainsi, il est difficile de d\u00e9terminer dans quelle mesure les techniques de la s\u00e9mantique distributionnelle permettront d'identifier des relations lexico-s\u00e9mantiques dans un corpus sp\u00e9cialis\u00e9 contenant quelques millions de mots seulement.", "labels": [], "entities": []}, {"text": "En lien avec la question de la taille et de la nature des corpus se pose celle du type de mod\u00e8le utilis\u00e9, ou plus pr\u00e9cis\u00e9ment la nature des contextes utilis\u00e9s pour construire le mod\u00e8le.", "labels": [], "entities": []}, {"text": "\u00c0 notre connaissance, les travaux d\u00e9crivant l'application de m\u00e9thodes distributionnelles \u00e0 des corpus sp\u00e9cialis\u00e9s) ont surtout exploit\u00e9 des mod\u00e8les structur\u00e9s, \u00e0 savoir des mod\u00e8les qui exloitent des contextes denature syntaxique plut\u00f4t que la simple cooccurrence.", "labels": [], "entities": []}, {"text": "Nous avons plut\u00f4t opt\u00e9 pour un mod\u00e8le non structur\u00e9, tout comme, qui justifie ce choix par le fait que les analyseurs syntaxiques robustes ne sont pas disponibles pour toutes les langues.", "labels": [], "entities": []}, {"text": "Par ailleurs, l'auteur observe que les r\u00e9sultats qu'il obtient sont comparables \u00e0 ceux obtenus au moyen d'un mod\u00e8le structur\u00e9 sur la m\u00eame t\u00e2che (WordNet-Based Synonymy Test).", "labels": [], "entities": []}, {"text": "Puisque l'auteur utilise un corpus de plusieurs centaines de millions de mots, nous ne pouvons pas conclure d'embl\u00e9e qu'un mod\u00e8le non structur\u00e9 produira de bons r\u00e9sultats sur un petit corpus sp\u00e9cialis\u00e9.", "labels": [], "entities": []}, {"text": "Voil\u00e0 une des questions auxquelles nous tenterons de r\u00e9pondre dans cet article, \u00e0 savoir si un mod\u00e8le non structur\u00e9 permet d'identifier des relations lexico-s\u00e9mantiques dans un corpus sp\u00e9cialis\u00e9 de petite taille.", "labels": [], "entities": []}, {"text": "\u00c0 cette fin, nous avons construit des mod\u00e8les sur un corpus du domaine de l'environnement et compar\u00e9 les voisinages identifi\u00e9s \u00e0 des donn\u00e9es extraites d'un dictionnaire sp\u00e9cialis\u00e9 du m\u00eame domaine.", "labels": [], "entities": []}, {"text": "Comme le soulignent, ce type d'\u00e9valuation ne permet pas d'\u00e9valuer la qualit\u00e9 de tous les liens de voisinage distributionnel, qui peuvent correspondre \u00e0 des relations quine sont pas d\u00e9crites dans la ressource lexicale.", "labels": [], "entities": []}, {"text": "Dans cette optique, nous avons r\u00e9alis\u00e9 une \u00e9valuation manuelle portant sur les voisins consid\u00e9r\u00e9s comme incorrects lors de l'\u00e9valuation automatique, ce qui permet non seulement une mesure plus exacte de la pr\u00e9cision des r\u00e9sultats, mais aussi une estimation de la capacit\u00e9 du mod\u00e8le \u00e0 am\u00e9liorer la couverture de la ressource lexicale, aspect occult\u00e9 par l'\u00e9valuation automatique.", "labels": [], "entities": []}, {"text": "La 2e t\u00e2che de cette \u00e9dition de SemDis nous fournit l'occasion d'examiner les r\u00e9sultats obtenus sur ce corpus, puis de les comparer \u00e0 ceux que l'on obtient sur un corpus comparable quant \u00e0 sa taille et sa nature sp\u00e9cialis\u00e9e, mais portant sur un domaine diff\u00e9rent, \u00e0 savoir le traitement automatique de la langue.", "labels": [], "entities": []}, {"text": "L'approche que nous avons adopt\u00e9e consiste \u00e0 d\u00e9terminer les param\u00e8tres optimaux du mod\u00e8le en explorant syst\u00e9matiquement l'espace des param\u00e8tres et en \u00e9valuant les mod\u00e8les r\u00e9sultants sur les donn\u00e9es de r\u00e9f\u00e9rence.", "labels": [], "entities": []}, {"text": "Par la suite, nous construisons un nouveau mod\u00e8le sur le corpus TALN en utilisant les m\u00eames param\u00e8tres, et comparons les r\u00e9sultats obtenus sur les deux corpus.", "labels": [], "entities": [{"text": "TALN", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.59063321352005}]}, {"text": "Une partie de cet article sera donc consacr\u00e9e \u00e0 la s\u00e9lection des param\u00e8tres du mod\u00e8le, sujet qui a fait l'objet de nombreux travaux sur la s\u00e9mantique distributionnelle.", "labels": [], "entities": [{"text": "s\u00e9mantique distributionnelle", "start_pos": 139, "end_pos": 167, "type": "TASK", "confidence": 0.7701153755187988}]}, {"text": "Par exemple,) a examin\u00e9 l'influence du type d'information contextuelle exploit\u00e9 par le mod\u00e8le (segments textuels dans le cas de la LSA, cooccurrents dans le cas de HAL), et l'influence de la distance ou mesure de similarit\u00e9 entre vecteurs a \u00e9t\u00e9 examin\u00e9e par (.", "labels": [], "entities": []}, {"text": "En ce qui concerne HAL, la m\u00e9thode que nous employons dans ce travail,) ont \u00e9valu\u00e9 l'influence de plusieurs des param\u00e8tres de ce mod\u00e8le, y compris certains des param\u00e8tres sur lesquels nous nous pencherons dans cet article : taille, forme et type de fen\u00eatre de contexte ; pond\u00e9ration des statistiques ; choix d'une technique de s\u00e9lection d'attributs ou de r\u00e9duction de dimension.", "labels": [], "entities": []}, {"text": "Ils se sont d'ailleurs int\u00e9ress\u00e9s \u00e0 la question de la taille du corpus, et ont montr\u00e9 que la s\u00e9lection de certains param\u00e8tres tels que la pond\u00e9ration et la mesure de similarit\u00e9 entre vecteurs peut exercer une influence particuli\u00e8rement importante lorsque le corpus est de petite taille (en l'occurrence 4,6 millions de mots).", "labels": [], "entities": []}, {"text": "Plus r\u00e9cemment,) ont r\u00e9alis\u00e9 une \u00e9valuation syst\u00e9matique de la plupart des param\u00e8tres de ce mod\u00e8le sur plusieurs jeux de donn\u00e9es en utilisant des corpus de diff\u00e9rentes tailles ; une des conclusions int\u00e9ressantes de ce travail est que l'utilisation de contextes denature syntaxique n'est pas forc\u00e9ment b\u00e9n\u00e9fique, l'utilisation d'une fen\u00eatre de cooccurrence \u00e9troite sur un gros corpus produisant de meilleurs r\u00e9sultats que les contextes syntaxiques sur la plupart des jeux de donn\u00e9es utilis\u00e9s pour l'\u00e9valuation.", "labels": [], "entities": []}, {"text": "Soulignons finalement l'\u00e9tude de (), qui compare quelques pond\u00e9rations et mesures de similarit\u00e9, et qui souligne l'influence importante du seuil de fr\u00e9quence minimale utilis\u00e9 pour choisir les mots-cibles du mod\u00e8le.", "labels": [], "entities": []}, {"text": "Dans la section suivante, nous d\u00e9crirons les ressources que nous avons utilis\u00e9es.", "labels": [], "entities": []}, {"text": "La section 3 portera sur la construction et les param\u00e8tres du mod\u00e8le.", "labels": [], "entities": [{"text": "param\u00e8tres du mod\u00e8le", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.8158077001571655}]}, {"text": "Dans la section 4, nous d\u00e9crirons la proc\u00e9dure de s\u00e9lection des param\u00e8tres, qui repose sur une \u00e9valuation automatique.", "labels": [], "entities": []}, {"text": "Les r\u00e9sultats obtenus seront analys\u00e9s \u00e0 la section 5 ; entre autres, nous y pr\u00e9senterons les r\u00e9sultats obtenus sur le corpus TALN et les comparerons \u00e0 ceux obtenus sur le corpus du domaine de l'environnement.", "labels": [], "entities": []}, {"text": "[ 240 ANALYSE DISTRIBUTIONNELLE DE CORPUS SP\u00c9CIALIS\u00c9S 2 Ressources utilis\u00e9es", "labels": [], "entities": [{"text": "ANALYSE DISTRIBUTIONNELLE DE CORPUS SP\u00c9CIALIS\u00c9S 2 Ressources utilis\u00e9es", "start_pos": 6, "end_pos": 76, "type": "METRIC", "confidence": 0.8155079558491707}]}], "datasetContent": [], "tableCaptions": []}