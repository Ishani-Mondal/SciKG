{"title": [{"text": "Abu-MaTran at WMT 2014 Translation Task: Two-step Data Selection and RBMT-Style Synthetic Rules", "labels": [], "entities": [{"text": "WMT 2014 Translation", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.6361323595046997}, {"text": "RBMT-Style Synthetic", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.6690895110368729}]}], "abstractContent": [{"text": "This paper presents the machine translation systems submitted by the Abu-MaTran project to the WMT 2014 translation task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7508551776409149}, {"text": "WMT 2014 translation task", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.8337306529283524}]}, {"text": "The language pair concerned is English-French with a focus on French as the target language.", "labels": [], "entities": []}, {"text": "The French to En-glish translation direction is also considered , based on the word alignment computed in the other direction.", "labels": [], "entities": [{"text": "French to En-glish translation direction", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.5633742928504943}]}, {"text": "Large language and translation models are built using all the datasets provided by the shared task organisers, as well as the monolin-gual data from LDC.", "labels": [], "entities": [{"text": "LDC", "start_pos": 149, "end_pos": 152, "type": "DATASET", "confidence": 0.8068788647651672}]}, {"text": "To build the translation models, we apply a two-step data selection method based on bilingual cross-entropy difference and vocabulary saturation , considering each parallel corpus individually.", "labels": [], "entities": []}, {"text": "Synthetic translation rules are extracted from the development sets and used to train another translation model.", "labels": [], "entities": []}, {"text": "We then interpolate the translation models , minimising the perplexity on the development sets, to obtain our final SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.9944601058959961}]}, {"text": "Our submission for the English to French translation task was ranked second amongst nine teams and a total of twenty submissions.", "labels": [], "entities": [{"text": "English to French translation task", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.6916119635105134}]}], "introductionContent": [{"text": "This paper presents the systems submitted by the Abu-MaTran project (runs named DCU-Prompsit-UA) to the WMT 2014 translation task for the English-French language pair.", "labels": [], "entities": [{"text": "WMT 2014 translation task", "start_pos": 104, "end_pos": 129, "type": "TASK", "confidence": 0.7821299284696579}]}, {"text": "Phrase-based statistical machine translation (SMT) systems were submitted, considering the two translation directions, with the focus on the English to French direction.", "labels": [], "entities": [{"text": "Phrase-based statistical machine translation (SMT)", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7193079463073185}]}, {"text": "Language models (LMs) and translation models (TMs) are trained using all the data provided by the shared task organisers, as well as the Gigaword monolingual corpora distributed by LDC.", "labels": [], "entities": []}, {"text": "To train the LMs, monolingual corpora and the target side of the parallel corpora are first used individually to train models.", "labels": [], "entities": []}, {"text": "Then the individual models are interpolated according to perplexity minimisation on the development sets.", "labels": [], "entities": []}, {"text": "To train the TMs, first a baseline is built using the News Commentary parallel corpus.", "labels": [], "entities": [{"text": "TMs", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9397387504577637}, {"text": "News Commentary parallel corpus", "start_pos": 54, "end_pos": 85, "type": "DATASET", "confidence": 0.9019220024347305}]}, {"text": "Second, each remaining parallel corpus is processed individually using bilingual cross-entropy difference) in order to separate pseudo in-domain and out-of-domain sentence pairs, and filtering the pseudo out-ofdomain instances with the vocabulary saturation approach (.", "labels": [], "entities": []}, {"text": "Third, synthetic translation rules are automatically extracted from the development set and used to train another translation model following a novel approach ().", "labels": [], "entities": []}, {"text": "Finally, we interpolate the four translation models (baseline, in-domain, filtered out-of-domain and rules) by minimising the perplexity obtained on the development sets and investigate the best tuning and decoding parameters.", "labels": [], "entities": []}, {"text": "The reminder of this paper is organised as follows: the datasets and tools used in our experiments are described in Section 2.", "labels": [], "entities": []}, {"text": "Then, details about the LMs and TMs are given in Section 3 and Section 4 respectively.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the performance of the final SMT system according to different tuning and decoding parameters in Section 5 before presenting conclusions in Section 6.", "labels": [], "entities": [{"text": "SMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9932066202163696}]}], "datasetContent": [{"text": "We use all the monolingual and parallel datasets in English and French provided by the shared task organisers, as well as the LDC Gigaword for the same languages 1 . For each language, a true-case model is trained using all the data, using the traintruecaser.perl script included in the MOSES toolkit (.", "labels": [], "entities": [{"text": "MOSES toolkit", "start_pos": 287, "end_pos": 300, "type": "DATASET", "confidence": 0.9003067016601562}]}, {"text": "Punctuation marks of all the monolingual and parallel corpora are then normalised using the script normalize-punctuation.perl provided by the organisers, before being tokenised and true-cased using the scripts distributed with the MOSES toolkit.", "labels": [], "entities": [{"text": "MOSES toolkit", "start_pos": 231, "end_pos": 244, "type": "DATASET", "confidence": 0.9175190925598145}]}, {"text": "The same pre-processing steps are applied to the development and test sets.", "labels": [], "entities": []}, {"text": "As development sets, we used all the test sets from previous years of.", "labels": [], "entities": []}, {"text": "Finally, the training parallel corpora are cleaned using the script clean-corpus-n.perl, keeping the sentences longer than 1 word, shorter than 80 words, and with a length ratio between sentence pairs lower than 4.", "labels": [], "entities": []}, {"text": "The statistics about the corpora used in our experiments after pre-processing are presented in.", "labels": [], "entities": []}, {"text": "For training LMs we use KENLM ( ) and the SRILM tool-kit).", "labels": [], "entities": [{"text": "KENLM", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9635696411132812}, {"text": "SRILM tool-kit", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.8001643717288971}]}, {"text": "For training TMs, we use MOSES () version 2.1 with MGIZA++.", "labels": [], "entities": [{"text": "TMs", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8230335116386414}, {"text": "MOSES", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.5247898697853088}, {"text": "MGIZA++", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.8555719256401062}]}, {"text": "These tools are used with default parameters for our experiments except when explicitly said.", "labels": [], "entities": []}, {"text": "The decoder used to generate translations is MOSES using features weights optimised with MERT.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.7012515664100647}]}, {"text": "As our approach relies on training individual TMs, one for each parallel corpus, our final TM is obtained by linearly interpolating the individual ones.", "labels": [], "entities": []}, {"text": "The interpolation of TMs is performed using the script tmcombine.py, minimising the cross-entropy between the TM and the concatenated development sets from 2008 to 2012 (noted newstest2008-2012), as described in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics, in millions of n-grams, of the  interpolated LMs.", "labels": [], "entities": []}, {"text": " Table 3: Number of sentence pairs and BLEU  scores reported by MERT on English-French new- stest2013 for the pseudo in-domain corpora ob- tained by filtering the out-of-domain corpora with  bilingual cross-entropy difference. The interpola- tion of pseudo in-domain models is evaluated in  the last row.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9995825886726379}, {"text": "MERT", "start_pos": 64, "end_pos": 68, "type": "DATASET", "confidence": 0.8151499629020691}]}, {"text": " Table 4: Number of sentence pairs and BLEU  scores reported by MERT on English-French  newstest2013 for the pseudo out-of-domain cor- pora obtained by filtering the out-of-domain cor- pora with bilingual cross-entropy difference, keep- ing sentence pairs below an entropy score of 10  and applying vocabulary saturation. The interpo- lation of pseudo out-of-domain models is evalu- ated in the last row.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9997079968452454}, {"text": "MERT on English-French  newstest2013", "start_pos": 64, "end_pos": 100, "type": "DATASET", "confidence": 0.7073006182909012}]}, {"text": " Table 5. A slight im- provement over the baseline is observed, which  motivates the use of synthetic rules in our final MT  system. This small improvement may be related  to the small coverage of the Apertium dictionar- ies: the English-French bilingual dictionary has a  low number of entries compared to more mature  language pairs in Apertium which have around 20  times more bilingual entries.", "labels": [], "entities": [{"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.8782467246055603}, {"text": "Apertium dictionar- ies", "start_pos": 201, "end_pos": 224, "type": "DATASET", "confidence": 0.9512763619422913}, {"text": "Apertium", "start_pos": 338, "end_pos": 346, "type": "DATASET", "confidence": 0.984423816204071}]}, {"text": " Table 5: BLEU scores reported by MERT on  English-French newstest2013 for the baseline  SMT system standalone and with automatically  extracted translation rules.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994670748710632}, {"text": "MERT on  English-French newstest2013", "start_pos": 34, "end_pos": 70, "type": "DATASET", "confidence": 0.7093850672245026}, {"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9721392393112183}]}, {"text": " Table 6: BLEU scores reported by MERT on  English-French newstest2013 development set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993207454681396}, {"text": "MERT on  English-French newstest2013 development set", "start_pos": 34, "end_pos": 86, "type": "DATASET", "confidence": 0.7397580146789551}]}, {"text": " Table 7: Case sensitive results obtained with  our final English-French SMT system on new- stest2013 when experimenting with different de- coding parameters. The best parameters are kept  to translate the WMT14 test set (newstest2014)  and official results are reported in the last two  rows.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.955542266368866}, {"text": "WMT14 test set", "start_pos": 206, "end_pos": 220, "type": "DATASET", "confidence": 0.9592057863871256}]}]}