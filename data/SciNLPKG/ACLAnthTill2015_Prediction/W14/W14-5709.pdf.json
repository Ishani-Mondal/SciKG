{"title": [{"text": "Distinguishing Degrees of Compositionality in Compound Splitting for Statistical Machine Translation", "labels": [], "entities": [{"text": "Compound Splitting", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.6981050372123718}, {"text": "Statistical Machine Translation", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.805484414100647}]}], "abstractContent": [{"text": "The paper presents an approach to morphological compound splitting that takes the degree of compositionality into account.", "labels": [], "entities": [{"text": "morphological compound splitting", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.6387927830219269}]}, {"text": "We apply our approach to German noun compounds and particle verbs within a German-English SMT system, and study the effect of only splitting compositional compounds as opposed to an aggressive splitting.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.8814214468002319}]}, {"text": "A qualitative study explores the translational behaviour of non-compositional compounds.", "labels": [], "entities": []}], "introductionContent": [{"text": "In German, as in many other languages, two (or more) simplex words can be combined to form a compound.", "labels": [], "entities": []}, {"text": "This is a productive process, leading to a potentially infinite number of sound German compounds.", "labels": [], "entities": []}, {"text": "As a consequence, many NLP applications suffer from coverage issues for compounds which do not appear or appear only infrequently in language resources.", "labels": [], "entities": []}, {"text": "However, while many compounds are not covered, their component words are often found in lexical resources or training data.", "labels": [], "entities": []}, {"text": "Compound processing allows access to these component words and thus can overcome these sparsity issues.", "labels": [], "entities": []}, {"text": "We use Statistical Machine Translation (SMT) as an example application for compound processing.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.8365927636623383}, {"text": "compound processing", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8291276097297668}]}, {"text": "Our SMT system translates from German to English, where compounds are usually split in the German source language prior to training and decoding.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9850844740867615}]}, {"text": "The benefits are obvious: vocabulary size is reduced and the languages are adjusted in terms of granularity, as exemplified by the compound Holzzaun.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section gives an overview on the technical details of the SMT system and our data sets.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9943437576293945}]}, {"text": "Compound splitting is applied to all source-language data, i.e. the parallel data used to train the model, as well as the input for parameter tuning and testing.", "labels": [], "entities": [{"text": "Compound splitting", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7684613168239594}, {"text": "parameter tuning", "start_pos": 132, "end_pos": 148, "type": "TASK", "confidence": 0.7382460832595825}]}, {"text": "Translation Model Moses is a state-of-the-art toolkit for phrase-based SMT systems (.", "labels": [], "entities": [{"text": "Translation Model Moses", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7958987752596537}, {"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.831853449344635}]}, {"text": "We use it with default settings to train a translation model and we do so separately for each of the different compound splittings.", "labels": [], "entities": []}, {"text": "Word alignment is performed using GIZA++.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7081215977668762}]}, {"text": "Feature weights are tuned using Batch-Mira (Cherry and Foster, 2012) with '-safe-hope' until convergence.", "labels": [], "entities": [{"text": "Batch-Mira (Cherry and Foster, 2012)", "start_pos": 32, "end_pos": 68, "type": "DATASET", "confidence": 0.8932889699935913}]}, {"text": "Training Data Our parallel training data contains the Europarl corpus (version 4, cf.) and also newspaper texts, overall ca.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9954995512962341}]}, {"text": "1.5 million sentences 3 (roughly 44 million words).", "labels": [], "entities": []}, {"text": "In addition, we use an English corpus of roughly 227 million words (including the English part of the parallel data) to build a target-side 5-gram language model with SRILM) in combination with KENLM.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 167, "end_pos": 172, "type": "METRIC", "confidence": 0.5607430934906006}, {"text": "KENLM", "start_pos": 194, "end_pos": 199, "type": "DATASET", "confidence": 0.8265389800071716}]}, {"text": "For parameter tuning, we use 1,025 sentences of news data.", "labels": [], "entities": []}, {"text": "Standard Test set 1,026 sentences of news data (test set from the 2009 WMT Shared Task): this set is to measure the translation quality on a standard SMT test and make it comparable to other work.", "labels": [], "entities": [{"text": "Standard Test set 1,026 sentences of news data (test set from the 2009 WMT Shared Task", "start_pos": 0, "end_pos": 86, "type": "DATASET", "confidence": 0.8588622913641089}, {"text": "SMT", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.969420850276947}]}, {"text": "Noun/Verb Test set As our main focus lies on sentences containing compounds, we created a second test set which is rich in compounds.", "labels": [], "entities": []}, {"text": "From the combined 2008-2013 Shared Task test sets, we extracted all sentences containing at least one noun compound for which we have compound-constituent similarity scores.", "labels": [], "entities": [{"text": "Shared Task test sets", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.7695082128047943}]}, {"text": "Moreover, we excluded sentences containing nouns that are not in the parallel training data: such compounds can only be translated when split which allows to translate their components.", "labels": [], "entities": []}, {"text": "The final test set consists of 2,574 sentences.", "labels": [], "entities": []}, {"text": "Similarly, we also created a set rich in particle verbs (855 sentences).", "labels": [], "entities": []}, {"text": "Opaque Test set As the two first test sets mainly contain compositional compounds, we use a third test set consisting of sentences with only non-compositional compounds.", "labels": [], "entities": []}, {"text": "The underlying compounds were chosen based on a list containing noun compounds and human ratings for compositionality (von der).", "labels": [], "entities": []}, {"text": "As before, the compounds must have occurred in the parallel data.", "labels": [], "entities": []}, {"text": "The result is a list of 14 compounds, of which 11 have a low modifier-compound similarity and 3 have a low head-compound similarity.", "labels": [], "entities": []}, {"text": "We then extracted sentences containing these compounds (5 per compound = 70 in total) from German newspaper data . In contrast to the other sets, we use this test set in a qualitative study, to approximate the translation quality by counting the number of correctly translated compounds.", "labels": [], "entities": [{"text": "German newspaper data", "start_pos": 91, "end_pos": 112, "type": "DATASET", "confidence": 0.7190567155679067}]}], "tableCaptions": [{"text": " Table 1: BLEU scores for all compound- constituent variations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999197781085968}]}, {"text": " Table 2: Examples for different compound-constitutent score ranges: HIGH: highly compositional,  MEDIUM: cases of doubt, LOW: highly non-compositional, according to their scores.", "labels": [], "entities": [{"text": "HIGH", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9935599565505981}, {"text": "MEDIUM", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.993915855884552}, {"text": "LOW", "start_pos": 122, "end_pos": 125, "type": "METRIC", "confidence": 0.9946980476379395}]}, {"text": " Table 3: correct vs. wrong -Translation of non-compositional compounds (opaque test set) without  being split (unsplit) vs. being split prior to translation. '*' highlights untranslated compounds.", "labels": [], "entities": []}]}