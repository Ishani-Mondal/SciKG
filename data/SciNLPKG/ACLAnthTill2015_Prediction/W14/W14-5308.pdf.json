{"title": [{"text": "Employing Phonetic Speech Recognition for Language and Dialect Specific Search", "labels": [], "entities": [{"text": "Employing Phonetic Speech Recognition", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6390871852636337}, {"text": "Language and Dialect Specific Search", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.7128484964370727}]}], "abstractContent": [{"text": "We discuss the notion of language and dialect-specific search in the context of audio indexing.", "labels": [], "entities": [{"text": "audio indexing", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.7052258253097534}]}, {"text": "A system is described where users can find dialect or language-specific pronunciations of Afghan placenames in Dari and Pashto.", "labels": [], "entities": []}, {"text": "We explore the efficacy of a phonetic speech recognition system employed in this task.", "labels": [], "entities": [{"text": "phonetic speech recognition", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6531476974487305}]}], "introductionContent": [{"text": "The Audio Gazetteer hotspotting tool was developed by and employs the Nexidia phonetic speech recognition engine () in several languages, including Dari (the Afghan variety of Persian) and Pashto, the two main languages of Afghanistan.", "labels": [], "entities": [{"text": "Nexidia phonetic speech recognition", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.6886209696531296}]}, {"text": "These languages are both members of the Iranian language family and share a number of phonetic characteristics.", "labels": [], "entities": []}, {"text": "This tool enables a user to load audio clips and to search them for words contained within them using one of three methods: the Dari or Pashto alphabets, a Romanization scheme, or phonetics in SAMPA.", "labels": [], "entities": []}, {"text": "Such a search will yield each starting timepoint in an audio file where the system has identified the term being searched, along with a number between 0 and 100 indicating the level of confidence the system has in its determination.", "labels": [], "entities": []}, {"text": "While terms of any kind can be searched, the system provides additional mapping capabilities for placenames.", "labels": [], "entities": []}, {"text": "Audio hotspotting, also known as keyword spotting or audio indexing, is a form of information retrieval employing speech recognition that is used for quickly identifying passages of interest within audio files.", "labels": [], "entities": [{"text": "keyword spotting or audio indexing", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.6974839448928833}, {"text": "information retrieval", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.7369638681411743}, {"text": "speech recognition", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7449207007884979}, {"text": "quickly identifying passages of interest within audio files", "start_pos": 150, "end_pos": 209, "type": "TASK", "confidence": 0.6573975011706352}]}, {"text": "It can be used to identify calls of interest in call centers, or to explore reports of natural disasters or political crises in the media.", "labels": [], "entities": []}, {"text": "There are two main approaches to audio hotspotting; one involves speech-to-text (STT), also known as large vocabulary continuous speech recognition (LVCSR), and the other employs phonetic speech recognition.", "labels": [], "entities": [{"text": "large vocabulary continuous speech recognition (LVCSR)", "start_pos": 101, "end_pos": 155, "type": "TASK", "confidence": 0.7109522446990013}, {"text": "phonetic speech recognition", "start_pos": 179, "end_pos": 206, "type": "TASK", "confidence": 0.6702073017756144}]}, {"text": "STT ingests speech and outputs orthographic text.", "labels": [], "entities": []}, {"text": "To do this, it requires language-specific acoustic and language models mediated by a pronunciation model or dictionary that maps words to phonetic forms.", "labels": [], "entities": []}, {"text": "The output text transcript can then be mined for terms of interest.", "labels": [], "entities": []}, {"text": "Raytheon's BBN Broadcast Monitoring System is an example of such a system.", "labels": [], "entities": [{"text": "BBN Broadcast Monitoring System", "start_pos": 11, "end_pos": 42, "type": "DATASET", "confidence": 0.8716456592082977}]}, {"text": "One liability of this approach is the need to establish the vocabulary, upon which the language and pronunciation models depend, upfront.", "labels": [], "entities": []}, {"text": "That means that one cannot easily search for terms that have not been programmed into the system beforehand.", "labels": [], "entities": []}, {"text": "This is an especially challenging impediment when confronting natural disasters and political crises in regions with towns and personalities whose names are \"out of vocabulary\" (OOV).", "labels": [], "entities": []}, {"text": "Phonetic speech recognition uses language-specific acoustic models directly; allowing users to query phonetic strings, possibly with the aid of a pronunciation model allowing orthographic search.", "labels": [], "entities": [{"text": "Phonetic speech recognition", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8319366971651713}]}, {"text": "The ability to query phonetic strings removes the OOV problem; any string that can be composed of the phonemes of a particular language can be searched.", "labels": [], "entities": [{"text": "OOV", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.6790177822113037}]}, {"text": "While this technology is useful for keyword spotting, it cannot be used to generate a meaningful orthographic transcript of speech, due to its lack of a language model.", "labels": [], "entities": [{"text": "keyword spotting", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7888700067996979}]}, {"text": "Our purpose is to explore the feasibility of using phonetic speech recognition technology to explore subtle dialect and language differences, with the ultimate aim of enabling language or dialect specific search.", "labels": [], "entities": [{"text": "phonetic speech recognition", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6918976704279581}]}, {"text": "In such a scenario, a user is not simply interested in finding a particular term of interest, he is also interested in the sociolinguistic characteristics of the speaker of that term of interest.", "labels": [], "entities": []}, {"text": "Various researchers have performed promising experiments using STT to explore phonetic variation.", "labels": [], "entities": [{"text": "STT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9628077745437622}]}, {"text": "These experiments utilize STT in forced alignment mode; that is, given a pre-existing orthographic transcript, they ask the recognizer to focus on deciding which pronunciation among a finite set supplied by the researcher maps best onto particular audio exemplars.", "labels": [], "entities": [{"text": "STT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9463182687759399}]}, {"text": "used this technique to examine several realizations of syllable-final /s/ 1 in Spanish including, and deletion, while explored variable deletion of /n/, /r/ and /t/ in Dutch, as well as schwa-insertion and deletion.", "labels": [], "entities": []}, {"text": "Both demonstrated promising agreement between the STT-based approaches and human coding.", "labels": [], "entities": [{"text": "STT-based", "start_pos": 50, "end_pos": 59, "type": "TASK", "confidence": 0.9580621123313904}]}, {"text": "In contrast, the phonetic speech recognizer employed here requires neither an orthographic transcript, nor a predetermined set of phonetic variants from which to choose.", "labels": [], "entities": [{"text": "phonetic speech recognizer", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.6415999432404836}]}, {"text": "For that reason, we felt it offered a flexible platform from which to explore phonetic variation, and thus enabled employing knowledge of that variation to perform dialect and language-specific search for Dari and Pashto.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 6: Dialect-specific results on compensatory lengthening in Dari", "labels": [], "entities": [{"text": "Dari", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.7347915172576904}]}, {"text": " Table 7: Dialect-agnostic results on Qalah-ye Now", "labels": [], "entities": []}, {"text": " Table 8: Dialect-specific results on /\u0282/ vs. /x/ in Pashto", "labels": [], "entities": []}, {"text": " Table 9: Dialect-agnostic results on /\u0282/ vs. /x/ in Pashto", "labels": [], "entities": []}, {"text": " Table 11 compares performance  on language-agnostic search performed for Kabul in each language.", "labels": [], "entities": []}]}