{"title": [{"text": "Reducing VSM data sparseness by generalizing contexts: application to health text mining", "labels": [], "entities": [{"text": "VSM data sparseness", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.8834583163261414}, {"text": "health text mining", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.6487909257411957}]}], "abstractContent": [{"text": "Vector Space Models are limited with low frequency words due to few available contexts and data sparseness.", "labels": [], "entities": []}, {"text": "To tackle this problem, we generalize contexts by integrating semantic relations acquired with linguistic approaches.", "labels": [], "entities": []}, {"text": "We use three methods that acquire hypernymy relations on a EHR corpus.", "labels": [], "entities": [{"text": "EHR corpus", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.950103759765625}]}, {"text": "Context Generalization obtains the best results when performed with hypernyms, the quality of the relations being more important than the quantity.", "labels": [], "entities": [{"text": "Context Generalization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8730309903621674}]}], "introductionContent": [{"text": "Distributional Analysis (DA)) computes a similarity between target words from the contexts shared by those two words.", "labels": [], "entities": [{"text": "Distributional Analysis (DA))", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8142280161380768}]}, {"text": "This hypothesis is applied with geometric methods, such as the Vector Space Model (VSM).", "labels": [], "entities": []}, {"text": "The advantage of the VSM is that the similarity of word meaning can be easily quantified by measuring their distance in the vector space, or the cosine of the angle between them (.", "labels": [], "entities": []}, {"text": "On the other hand, a major inconvenience is data sparseness within the matrix that represents the vector space.", "labels": [], "entities": []}, {"text": "The data sparseness problem is the consequence of the word distribution in a corpus (: in any corpus, most of the words have a very low frequency and appear only a few times.", "labels": [], "entities": []}, {"text": "Thus, those words have a limited set of contexts and similarity is difficult to catch.", "labels": [], "entities": []}, {"text": "Thus, methods based on DA perform better when more information is available and are efficient with large corpora of general language.", "labels": [], "entities": []}, {"text": "But with specialized texts, as EHR texts that are usually of smaller size, reducing data sparseness is a major issue and methods need to be adapted.", "labels": [], "entities": []}, {"text": "Semantic grouping of contexts should decrease their diversity, and thus increase the frequency of the remaining generalized contexts.", "labels": [], "entities": []}, {"text": "We assume that generalizing contexts may influence the distributional context frequencies.", "labels": [], "entities": []}, {"text": "Information for generalization can be issued from existing resources or can be computed by linguistic approaches.", "labels": [], "entities": [{"text": "generalization", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.9778173565864563}]}, {"text": "In this paper, we propose to use semantic relations acquired by relation acquisition methods to group words in contexts.", "labels": [], "entities": [{"text": "relation acquisition", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7128917425870895}]}, {"text": "We define a method that switches words in DA contexts for their hierarchical parent or morphosyntactic variant that have been computed on the corpus with linguistic approaches before applying the VSM method.", "labels": [], "entities": []}, {"text": "In the following, we first present the related work, then our method and we finally describe the different experiments we led.", "labels": [], "entities": []}, {"text": "The results obtained on the EHR corpus are then evaluated in terms of precision and MAP, and analyzed.", "labels": [], "entities": [{"text": "EHR corpus", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.9775488972663879}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9996740818023682}, {"text": "MAP", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9987627267837524}]}], "datasetContent": [{"text": "In this section, we present the material we use for the experiments and evaluation, and the distributional parameter values of the VSM automatically determined from the data.", "labels": [], "entities": [{"text": "VSM", "start_pos": 131, "end_pos": 134, "type": "DATASET", "confidence": 0.4682588279247284}]}, {"text": "We then describe the generalization sets we experiment and the evaluation measures we used for evaluation.", "labels": [], "entities": []}, {"text": "In order to evaluate the quality of the acquired relations, we compare our relations to the 53,203 UMLS relations between terms occurring in our EHR corpus.", "labels": [], "entities": [{"text": "EHR corpus", "start_pos": 145, "end_pos": 155, "type": "DATASET", "confidence": 0.950861930847168}]}, {"text": "We perform the evaluation with the Mean Average Precision (MAP)) and the macro-precision computed for each target word: semantic neighbors found in the resource by the total semantic neighbors acquired by our method.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP))", "start_pos": 35, "end_pos": 64, "type": "METRIC", "confidence": 0.9738105138142904}]}, {"text": "We consider three sets of neighbors: precision after examining 1 (P@1), 5 (P@5) and 10 (P@10) neighbors.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9996185302734375}]}], "tableCaptions": []}