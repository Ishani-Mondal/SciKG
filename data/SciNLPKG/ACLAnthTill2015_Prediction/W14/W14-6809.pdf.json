{"title": [{"text": "Segment-based Fine-grained Emotion Detection for Chinese Text", "labels": [], "entities": [{"text": "Segment-based Fine-grained Emotion Detection", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7670552730560303}]}], "abstractContent": [{"text": "Emotion detection has been extensively studied in recent years.", "labels": [], "entities": [{"text": "Emotion detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9547606706619263}]}, {"text": "Current base-line methods often use token-based features which cannot properly capture more complex linguistic phenomena and emotional composition in fine grained emotion detection.", "labels": [], "entities": [{"text": "fine grained emotion detection", "start_pos": 150, "end_pos": 180, "type": "TASK", "confidence": 0.7951162755489349}]}, {"text": "A novel supervised learning approach-segment-based fine-grained emotion detection model for Chinese text has been proposed in this paper.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7372825443744659}]}, {"text": "Different from most existing methods, the proposed model applies the hierarchical structure of sentence (e.g., dependency relationship) and exploits segment-based features.", "labels": [], "entities": []}, {"text": "Furthermore, the emotional composition in short text is addressed by using the log linear model.", "labels": [], "entities": []}, {"text": "We perform emotion detection on our dataset: news contents, fairly tales, and blog dataset, and compare our proposed method to representative existing approaches.", "labels": [], "entities": [{"text": "emotion detection", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7207145243883133}]}, {"text": "The experimental results demonstrate the effectiveness of the proposed segment-based model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Emotion detection aims to identify fine-grained emotion categories (e.g., happy, angry, disgust, fear, sadness and surprise) of a given text, and it is a challenging and difficult problem with applications throughout natural language processing.", "labels": [], "entities": [{"text": "Emotion detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9491884112358093}]}, {"text": "Currently, the most widely used probability models for emotion classification are supervised based machine learning algorithms, such as Naive Bayes (NB) and Support Vector Machine (SVM) etc,.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.8081886768341064}]}, {"text": "Researchers have trained the classifier depends on corpus-based features, mainly unigrams, combined with lexical features).", "labels": [], "entities": []}, {"text": "Nevertheless, these methods used in the emotion classification system concentrate on token based features and do not include any linguistic or contextual information, which often yields poor performance.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7834114730358124}]}, {"text": "Therefore, recent studies have investigated the approach using contextual information around emotional words to identify fine grained emotion classes.", "labels": [], "entities": []}, {"text": "( observe that the emotion word, POS, intensifier and direct dependency features play an important role in extracting emotional expressions as well as tagging sentences with emotions and intensities.) propose an approach which takes the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes.", "labels": [], "entities": [{"text": "POS", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9383298754692078}]}, {"text": "However, these works still use token-based features, which cannot address the problem of the emotional composition, especially those that are the expression-level representations.", "labels": [], "entities": []}, {"text": "There has been previous work using composition rules and statistical methods to handle sentiment composition.", "labels": [], "entities": [{"text": "sentiment composition", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.8652858138084412}]}, {"text": "propose a theoretical composition model, and evaluate a lexical dependency parsing post-process implementation, which treat both negation and intensifier via three models: sentiment propagation, polarity conflict resolution and polarity reversal.", "labels": [], "entities": [{"text": "lexical dependency parsing", "start_pos": 56, "end_pos": 82, "type": "TASK", "confidence": 0.7616806030273438}, {"text": "sentiment propagation", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.8282236754894257}, {"text": "polarity conflict resolution", "start_pos": 195, "end_pos": 223, "type": "TASK", "confidence": 0.6123103102048238}, {"text": "polarity reversal", "start_pos": 228, "end_pos": 245, "type": "TASK", "confidence": 0.7250429093837738}]}, {"text": "incorporate structural inference motivated by compositional semantics into the learning procedure for subsentential sentiment analysis.) present matrix-vector representations with a recursive neural network.", "labels": [], "entities": [{"text": "subsentential sentiment analysis.", "start_pos": 102, "end_pos": 135, "type": "TASK", "confidence": 0.7438253362973531}]}, {"text": "The model is built on a parse tree where the nodes are associated to a vector.", "labels": [], "entities": []}, {"text": "The matrix captures how each constituent modifies its neighbor.) propose a computational model that accounts for the effects of negation and modality on opinion expressions.", "labels": [], "entities": []}, {"text": "However, it is not as clear how to use a compositional treatment to classify fine grained emotion classes.", "labels": [], "entities": [{"text": "classify fine grained emotion classes", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.821821415424347}]}, {"text": "Sentiment composition combines individual positive and negative words or phrases, and the final polarity of a sentence is positive or negative.", "labels": [], "entities": [{"text": "Sentiment composition", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9374077618122101}]}, {"text": "Nevertheless, it is more challenging and difficult to make categorization into distinct emotion classes for the higher level of classification in emotion recognition task.", "labels": [], "entities": [{"text": "emotion recognition task", "start_pos": 146, "end_pos": 170, "type": "TASK", "confidence": 0.8001188437143961}]}, {"text": "In order to facilitate our discussion, consider the following examples: 1.\u4e0d\u8fc7\u5728\u6559\u5802\u91cc,\u7ad9\u5728\u8bb2\u53f0\u4e0a\u7684\u7267\u5e08\u5374\u662f\u5927\u53eb \u5927\u56b7,\u975e\u5e38\u751f\u6c14.", "labels": [], "entities": []}, {"text": "(But inside the church the pastor stood in the pulpit, and spoke very loudly and angrily.)", "labels": [], "entities": []}, {"text": "2.\u8ff7 \u4fe1 \u4f7f \u5979 \u7684 \u8840 \u4e00 \u4f1a \u513f \u53d8 \u51b7,\u4e00 \u4f1a \u513f \u53d8 \u70ed.(Superstition made her alternately shudder with cold or burn with the heat of fever.)", "labels": [], "entities": []}, {"text": "3 (All at once the wax doll which rode on the carnival rod seemed to grow larger and taller, and it turned round and said to the paper flowers, \"How can you put such things in a child's head?", "labels": [], "entities": []}, {"text": "they are all foolish fancies;\" and then the doll was exactly like the lawyer with the broad brimmed hat, and looked as yellow and as cross as he did; but the paper dolls struck him on his thin legs, and he shrunk up again and became quite a little wax doll.)", "labels": [], "entities": []}, {"text": "In the first example, we can use the key words \"\u5927 \u53eb\",\"\u5927 \u56b7\"(spoke very loudly), and \"\u751f \u6c14\"(anger), to easily identify the emotion classes of the sentence.", "labels": [], "entities": []}, {"text": "However, in the second example, we cannot use the words \"\u8840\"(blood), \"\u53d8 \u51b7\"(make cold), \"\u53d8\u70ed\"(make burn) or the phrase \"\u8840\u53d8\u51b7\" and \"\u8840\u53d8\u70ed\" to easily detect the final emotion category of the sentence.", "labels": [], "entities": []}, {"text": "\"\u8840\" and \"\u53d8 \u51b7\" carry \"fear\" category, and the words \"\u8840\" and \"\u53d8\u70ed\" can be classified as \"joy\", but the final emotion label of the sentence is \"fear\".", "labels": [], "entities": []}, {"text": "In the last example, there are four types of emotion classes for sub-sentential segments, for example, \"\u8721\u4eba\u53d8 \u5f97\u53c8\u9ad8\u53c8\u5927\"( the wax doll seemed to grow larger and taller), \"\u602a\u60f3\u5934\"(such things), \"\u6ca1\u6709\u9053\u7406\u7684\u5e7b\u60f3!\"(foolish fancies), \"\u751f \u6c14\"(anger), and \"\u4e00\u4e2a\u6e3a\u5c0f\u7684\u8721\u4eba\"( a little wax doll), but the overall emotion of the short text is \"anger\".", "labels": [], "entities": []}, {"text": "These examples demonstrate that a sentence or short text exists several expression-level emotion labels, and the words or constituents interact with each other to yield the overall emotion label, which cannot be easily resolved by tokenbased methods.", "labels": [], "entities": []}, {"text": "To solve this problem, we present segment-based supervised learning approach to investigate how to recognize the overall emotion tag of a sentence or short text.", "labels": [], "entities": [{"text": "recognize the overall emotion tag of a sentence or short text", "start_pos": 99, "end_pos": 160, "type": "TASK", "confidence": 0.7864115861329165}]}, {"text": "Closer to our current purposes is the work of ().", "labels": [], "entities": []}, {"text": "It employs a conditional random field (CRF) for sentiment classification of Japanese and English subjective sentences using dependency tree-based method.", "labels": [], "entities": [{"text": "sentiment classification of Japanese and English subjective sentences", "start_pos": 48, "end_pos": 117, "type": "TASK", "confidence": 0.9103661105036736}]}, {"text": "In their method, the sentiment polarity of each dependency subtree, which is not observable in training data, is represented by a hidden variable.", "labels": [], "entities": []}, {"text": "The polarity of the whole sentence is calculated in consideration of interactions between the hidden variables.", "labels": [], "entities": []}, {"text": "However, this research doesn't work on the fine grained emotion recognition and it is unable to deal with multiple consecutive tokens (e.g., a phrase).", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.76552814245224}]}, {"text": "In this paper, we employ semi-Markov conditional random fields (semi-CRFs) for segmentbased emotion detection.", "labels": [], "entities": [{"text": "segmentbased emotion detection", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.7364175120989481}]}, {"text": "Semi-CRFs () are more powerful than CRFs in that they can assign labels to segments instead of tokens; hence, features can be defined at the segment level.", "labels": [], "entities": []}, {"text": "To our knowledge, segment-based fine-grained emotion recognition for Chinese text has not been attempted.", "labels": [], "entities": [{"text": "segment-based fine-grained emotion recognition", "start_pos": 18, "end_pos": 64, "type": "TASK", "confidence": 0.6249057874083519}]}, {"text": "Our learning framework can be determined in a three-step process: (1) segment the input sentence or short text into some dependency subtrees and then (2) employ the semiCRFs with various context informed features to assess the emotion classes of the constituents of the segment, and (3) exploit a composition learning model to combine the segment level emotion labels.", "labels": [], "entities": []}, {"text": "We evaluate the proposed model on our construction dataset, which consists of news content, fairy tales and blog dataset, and the experimental results show that segment-based learning algorithm works well in our experimental data.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this subsection, we report experimental results on our dataset which contains news dataset, Alm's translation dataset and blogs dataset.", "labels": [], "entities": [{"text": "news dataset", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.8728732466697693}, {"text": "Alm's translation dataset", "start_pos": 95, "end_pos": 120, "type": "DATASET", "confidence": 0.8819643706083298}, {"text": "blogs dataset", "start_pos": 125, "end_pos": 138, "type": "DATASET", "confidence": 0.8121322989463806}]}, {"text": "The entries of our dataset are short text or sentence.", "labels": [], "entities": []}, {"text": "The news dataset consists of 1135 entries and its average length is 27.09.", "labels": [], "entities": [{"text": "news dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8705108463764191}, {"text": "length", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.853078305721283}]}, {"text": "The Alm's translation dataset consist of 1223 entries and its average length 34.76.", "labels": [], "entities": [{"text": "Alm's translation dataset", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.9372371286153793}]}, {"text": "The blog dataset contains 1000 entries and its average length is 30.73.", "labels": [], "entities": [{"text": "length", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.8745000958442688}]}, {"text": "The tasks on the Alm's translation dataset maybe difficult because the syntactic structures of the sentences are less restricted and highly variable., respectively shows the accuracy result of our segment-based method compared to two token-based approach using SVM and MaxEnt, and a segment-based method using CRF models (similar to the work of (), which employ five kinds of feature sets (BOW, contentBOW, part-ofspeech, emotion words and dependency relations) and their combination features, setting 10-fold cross validation as a testing option.", "labels": [], "entities": [{"text": "Alm's translation dataset", "start_pos": 17, "end_pos": 42, "type": "DATASET", "confidence": 0.8526599109172821}, {"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9994580149650574}]}, {"text": "As shown in-4, we can obtain below conclusions: (1) We can see that our approach based on the   segment-based semi-CRF model has the highest accuracy rate for each dataset using the combination features of contentBOW + Emotion + POS + Dependency.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 141, "end_pos": 154, "type": "METRIC", "confidence": 0.9862208962440491}]}, {"text": "Segment-based approach performed better than token-based approach for the news dataset, but without expected results for the Alm's translation and blogs dataset.", "labels": [], "entities": [{"text": "Alm's translation and blogs dataset", "start_pos": 125, "end_pos": 160, "type": "DATASET", "confidence": 0.9249910215536753}]}, {"text": "This result, on the one hand, demonstrates that Semi-CRF is more powerful than CRF, and on the other hand, our emotion tag distribution model gives effective results.", "labels": [], "entities": []}, {"text": "For token-based method, SVM gives a better result than MaxEnt for all three of our Chinese corpora.", "labels": [], "entities": []}, {"text": "(2) The accuracy rate of SVM has slightly less than our model, but the results of MaxEnt and CR-F is unbalanced.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 8, "end_pos": 21, "type": "METRIC", "confidence": 0.9881965816020966}, {"text": "SVM", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8076103925704956}, {"text": "MaxEnt", "start_pos": 82, "end_pos": 88, "type": "DATASET", "confidence": 0.7497276067733765}]}, {"text": "As we notice from table 2 to table 4, CRF gives better results on the news dataset than on the Alm's translation dataset, but the results of MaxEnt on all dataset is worst.", "labels": [], "entities": [{"text": "CRF", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.6388481259346008}, {"text": "news dataset", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.9170451760292053}, {"text": "Alm's translation dataset", "start_pos": 95, "end_pos": 120, "type": "DATASET", "confidence": 0.9451943635940552}]}, {"text": "The reasons for this result maybe due to the bias problem of MaxEnt.", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.9517186284065247}]}, {"text": "(3) We can observe that using the combination features of contentBOW + Emotion + POS + Dependency has the highest accuracy rate for each dataset and each classifier.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 114, "end_pos": 127, "type": "METRIC", "confidence": 0.9890549182891846}]}, {"text": "There are two types of features achieve significantly improvements: emotion words and the dependency relations, for example, on news dataset, SVM with contentBOW has the accuracy rate of 48.59% and adding emotion words has the accuracy rate of 51.46%, showing the improvements of 2.87%.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 170, "end_pos": 183, "type": "METRIC", "confidence": 0.9879527986049652}, {"text": "accuracy rate", "start_pos": 227, "end_pos": 240, "type": "METRIC", "confidence": 0.9833221435546875}]}, {"text": "This is not surprising result since emotion words has key influence to detection of the emotion category of a sentence.", "labels": [], "entities": []}, {"text": "However, the words or constituents interact with each other to yield the overall emotion label, there exists expression level emotion.", "labels": [], "entities": []}, {"text": "Dependency relationship features can solve this problem and improve the performance of the system,like in the example above,adding Dependency relationship features has the accuracy rate of 54.45%, showing the improvements of 5.86%.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 172, "end_pos": 185, "type": "METRIC", "confidence": 0.9912993907928467}]}, {"text": "When the baseline system use the content-BOW features, the POS, Emotion and Dependency representation improve the accuracy rates of the SVM, CRF and our classifier for each dataset, but the use of POS representation for the MaxEnt classifier decreased the accuracy rate compared to the Emotion and Dependency representations.", "labels": [], "entities": [{"text": "POS", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.949355959892273}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9986053109169006}, {"text": "accuracy", "start_pos": 256, "end_pos": 264, "type": "METRIC", "confidence": 0.9987990856170654}]}, {"text": "One reason lead to this problem might be the quality of the data we use in this experiment.", "labels": [], "entities": []}, {"text": "(4) Overall performances on the news dataset are better than on the Alm's translation dataset and blogs dataset.", "labels": [], "entities": [{"text": "news dataset", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.7666478157043457}, {"text": "Alm's translation dataset and blogs dataset", "start_pos": 68, "end_pos": 111, "type": "DATASET", "confidence": 0.8520313331059047}]}, {"text": "The reason perhaps is that the syntactic structures of the sentences from Alm's translation dataset are less restricted and highly variable, and the sentences from blogs dataset are noisy, and there exist some linguistic or spelling error.", "labels": [], "entities": [{"text": "Alm's translation dataset", "start_pos": 74, "end_pos": 99, "type": "DATASET", "confidence": 0.8779871612787247}]}], "tableCaptions": [{"text": " Table 2: Experimental results on news dataset %", "labels": [], "entities": [{"text": "news dataset", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.8368551135063171}]}, {"text": " Table 3: Experimental results on Alm's translation dataset %", "labels": [], "entities": [{"text": "Alm's translation dataset", "start_pos": 34, "end_pos": 59, "type": "DATASET", "confidence": 0.7064379304647446}]}, {"text": " Table 4: Experimental results on blog dataset %", "labels": [], "entities": [{"text": "blog dataset", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.8726350963115692}]}]}