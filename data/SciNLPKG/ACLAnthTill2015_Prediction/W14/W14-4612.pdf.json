{"title": [{"text": "Subsegmental language detection in Celtic language text", "labels": [], "entities": [{"text": "Subsegmental language detection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8863261342048645}]}], "abstractContent": [{"text": "This paper describes an experiment to perform language identification on a sub-sentence basis.", "labels": [], "entities": [{"text": "language identification", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.7557286322116852}]}, {"text": "The typical case of language identification is to detect the language of documents or sentences.", "labels": [], "entities": [{"text": "language identification", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7295738011598587}, {"text": "detect the language of documents or sentences", "start_pos": 50, "end_pos": 95, "type": "TASK", "confidence": 0.7013973849160331}]}, {"text": "However, it maybe the case that a single sentence or segment contains more than one language.", "labels": [], "entities": []}, {"text": "This is especially the casein texts where code switching occurs.", "labels": [], "entities": [{"text": "code switching", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.8355635404586792}]}], "introductionContent": [{"text": "Determining the language of apiece of text is one of the first steps that must betaken before proceeding with further computational processing.", "labels": [], "entities": [{"text": "Determining the language of apiece of text", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.844295356954847}]}, {"text": "This task has received a substantial amount of attention in recent years.", "labels": [], "entities": []}, {"text": "However, previous research has on the whole assumed that a given text will be in a single language.", "labels": [], "entities": []}, {"text": "When dealing with text from formal domains, this maybe the case -although there are exceptions -such as quotations embedded in the text in another language.", "labels": [], "entities": []}, {"text": "But when dealing with informal text, particularly in languages where the speech community is predominantly bi-or multi-lingual, this assumption may not hold.", "labels": [], "entities": []}, {"text": "The work presented in this paper was motivated by the problems in normalising non-standard input for the Celtic languages as a precursor to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7962173819541931}]}, {"text": "When applying a normalisation strategy to apiece of text, it is necessary to first know the language of the piece of text you are applying it to.", "labels": [], "entities": []}, {"text": "The remainder of the paper is laid out as follows.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the problem in more detail and look at relevant prior work before proposing a novel method of sub-sentential language detection.", "labels": [], "entities": [{"text": "sub-sentential language detection", "start_pos": 119, "end_pos": 152, "type": "TASK", "confidence": 0.6283066868782043}]}, {"text": "Section 4 describes the evaluation methodology.", "labels": [], "entities": []}, {"text": "Then in Section 5 we present the results of our method and compare it against several other possible methods.", "labels": [], "entities": []}, {"text": "Finally, Section 6 presents future work and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the Evaluation procedure, we follow the footsteps of the CoNLL-2000 shared task on languageindependent named entity recognition: dividing text into syntactically related non-overlapping groups of words.", "labels": [], "entities": [{"text": "languageindependent named entity recognition", "start_pos": 87, "end_pos": 131, "type": "TASK", "confidence": 0.5374530106782913}]}, {"text": "This chunking mechanism) is very similar to ours, in terms of words which only belong to one category (here, language), and also evaluation based on the segment structure present in the data.", "labels": [], "entities": []}, {"text": "The chunks here are such that they belong to only one language.", "labels": [], "entities": []}, {"text": "The evaluation statistics shown in mention two values for each of the experiment conducted on the three bilingual language datasets.", "labels": [], "entities": []}, {"text": "The first, is the percentage of correctly detected phrases, which is the overall precision and the second is the number of phrases in the data that were found by the chunker, which is the overall recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9988420605659485}, {"text": "recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.9967418313026428}]}, {"text": "Apart from the techniques discussed in Section 3, some baselines are also used to give a comparative view of how well all the mechanisms perform.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Document statistics of the annotated data used.", "labels": [], "entities": []}, {"text": " Table 2: Precision, p and recall, r for the systems by language.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9951972365379333}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9993776679039001}]}, {"text": " Table 3: Accuracy of the systems over the three language pairs. The accuracy measures how often a token was assigned to the  right language, independent of span.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.989477813243866}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.999496579170227}]}]}