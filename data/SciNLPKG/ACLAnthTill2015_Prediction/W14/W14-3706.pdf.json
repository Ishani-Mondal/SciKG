{"title": [{"text": "Semi-supervised Graph-based Genre Classification for Web Pages", "labels": [], "entities": [{"text": "Graph-based Genre Classification", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.6215545733769735}]}], "abstractContent": [{"text": "Until now, it is still unclear which set of features produces the best result in automatic genre classification on the web.", "labels": [], "entities": [{"text": "automatic genre classification", "start_pos": 81, "end_pos": 111, "type": "TASK", "confidence": 0.5930265684922537}]}, {"text": "Therefore, in the first set of experiments, we compared a wide range of content-based features which are extracted from the data appearing within the web pages.", "labels": [], "entities": []}, {"text": "The results show that lexical features such as word unigrams and character n-grams have more discriminative power in genre classification compared to features such as part-of-speech n-grams and text statistics.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.6984629780054092}]}, {"text": "Ina second set of experiments, with the aim of learning from the neighbouring web pages, we investigated the performance of a semi-supervised graph-based model, which is a novel technique in genre classification.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 191, "end_pos": 211, "type": "TASK", "confidence": 0.7944314479827881}]}, {"text": "The results show that our semi-supervised min-cut algorithm improves the overall genre classification accuracy.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7929924130439758}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9339959621429443}]}, {"text": "However, it seems that some genre classes benefit more from this graph-based model than others.", "labels": [], "entities": []}], "introductionContent": [{"text": "In Automatic Genre Identification (AGI), documents are classified based on their genres rather than their topics or subjects.", "labels": [], "entities": [{"text": "Automatic Genre Identification (AGI)", "start_pos": 3, "end_pos": 39, "type": "TASK", "confidence": 0.7649129132429758}]}, {"text": "Genre classes such as editorial, interview, news and blog which are recognizable by their distinct purposes, can be on any topic.", "labels": [], "entities": []}, {"text": "The most important application of AGI could be in Information Retrieval.", "labels": [], "entities": [{"text": "AGI", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.7186558842658997}, {"text": "Information Retrieval", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.8147944211959839}]}, {"text": "If a user could use the search engine to retrieve web pages from a specific genre such as news articles, reviews or blogs, search results could be more beneficial.", "labels": [], "entities": []}, {"text": "With the aim of enhancing search engines, AGI has attracted a lot of attention (see.", "labels": [], "entities": []}, {"text": "In this paper, we investigate two important open questions in AGI.", "labels": [], "entities": [{"text": "AGI", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.795659601688385}]}, {"text": "The first question is: what set of features produces the best result in genre classification on the web?", "labels": [], "entities": [{"text": "genre classification", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.7527198791503906}]}, {"text": "The drawbacks of existing genre-annotated web corpora (low inter-coder agreement; false correlations between topic and genre classes) resulted in researchers' doubt on the outcomes of classification models based on these corpora ().", "labels": [], "entities": []}, {"text": "Therefore, in order to answer this question, we perform genre classification with a wide range of features on a reliable and source diverse genre-annotated web corpus.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7957366108894348}]}, {"text": "The second question that we investigate in this paper is: could we exploit the graph structure of the web to increase genre classification accuracy?", "labels": [], "entities": [{"text": "genre classification", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.8348531424999237}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.8465378880500793}]}, {"text": "With the aim of learning from the neighbouring web pages, we investigated the performance of a semi-supervised graph-based model, which is a novel technique in genre classification.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 160, "end_pos": 180, "type": "TASK", "confidence": 0.7937895953655243}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "After reviewing related work in Section 2, we compare different supervised genre classification models based on various lexical, POS-based and text statistics features in Section 3.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.6909928619861603}]}, {"text": "Section 4 describes our semi-supervised graph-based classification experiment, where we use the multi-class min-cut algorithm as a novel technique in genre classification.", "labels": [], "entities": [{"text": "semi-supervised graph-based classification", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.6567092935244242}, {"text": "genre classification", "start_pos": 150, "end_pos": 170, "type": "TASK", "confidence": 0.7705768644809723}]}, {"text": "Section 5 concludes the findings and discusses future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Petrenz and Webber (2010) and emphasize that the impact of topic on genre classification should be eliminated or controlled.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.8034504950046539}]}, {"text": "In order to avoid the influence of topic on genre classification, some researchers (e.g. (Sta-: Statistics for each category illustrate source diversity and reliability of the corpus ().", "labels": [], "entities": [{"text": "genre classification", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8014318346977234}]}, {"text": "To save space, in this paper we use the abbreviation of genre labels which are specified after the genre names.", "labels": [], "entities": []}, {"text": "If we want these models to capture the genre of documents without being influenced by their topics or the style of their authors, we must eliminate the influence of these factors on genre classification by keeping them constant across the genre classes in the training data.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 182, "end_pos": 202, "type": "TASK", "confidence": 0.7399308979511261}]}, {"text": "That means all the documents in the training set should be about the same topic and written by the same person.", "labels": [], "entities": []}, {"text": "However, constructing such a dataset is practically impossible for genre classes on the web.", "labels": [], "entities": []}, {"text": "The other more practical solution to this problem would be to collect data from various topics and sources in order to minimize the impact of these factors on genre classification.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 159, "end_pos": 179, "type": "TASK", "confidence": 0.8629266917705536}]}, {"text": "For that reason, we) created a web genre annotated corpus which is reliable (with Fleiss's kappa equal to 0.874) and source diverse.", "labels": [], "entities": []}, {"text": "We tried to reduce the influence of topic, the writing style of the authors as well as the design of the websites on genre classification by collecting data from various sources and topics.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.7804023623466492}]}, {"text": "The corpus consists of 3964 web pages from 2522 different websites, distributed across 15 genres.", "labels": [], "entities": []}, {"text": "Moreover, we prepared two versions of the corpus: the original text and the main text corpora.", "labels": [], "entities": []}, {"text": "First, we converted web pages to plain text by removing HTML markup using the KrdWrd tool.", "labels": [], "entities": []}, {"text": "This resulted in the original text corpus which contains individual web pages with all the textual elements present on them.", "labels": [], "entities": []}, {"text": "Moreover, in order to investigate the influence of boilerplate parts (e.g. advertisements, headers, footers, template materials, navigation menus and lists of links) of the web pages on genre classification, we removed the boilerplate parts and extracted the main text of each web page using the justext tool . This resulted in the creation of the main text corpus.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 186, "end_pos": 206, "type": "TASK", "confidence": 0.7088605910539627}]}, {"text": "This is the first time that the performance of genre classification models is compared on both the original and the main text of the web pages.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7673555016517639}]}, {"text": "Since the outputs of the justext tool for 518 of the web pages were empty files, the main text corpus has fewer pages.", "labels": [], "entities": []}, {"text": "However, the main text corpus still has a balanced distribution with a relatively large number of web pages per category.", "labels": [], "entities": []}, {"text": "Table 2 compares the number of web pages in the two versions of the corpus.", "labels": [], "entities": []}, {"text": "For all the experiments we use this corpus via 10-fold cross-validation on the web pages.", "labels": [], "entities": []}, {"text": "Also, in order to minimize the effect of factors such as topic, the writing style of the authors and the design of the websites even further, we ensured that all the web pages from the same website are in the same fold.", "labels": [], "entities": []}, {"text": "Many, if not all of the previous studies in automatic genre classification on the web ignored this essential step when dividing the data into folds.", "labels": [], "entities": [{"text": "automatic genre classification", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6240704556306204}]}, {"text": "For machine learning, we) that SVM produces better or at least similar results compared to other machine learning algorithms.", "labels": [], "entities": []}, {"text": "We used the one-versus-one multi-class SVM implemented in Weka 2 with the default setting.", "labels": [], "entities": [{"text": "Weka", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9386988282203674}]}, {"text": "All the experiments are carried out on both the original text and the main text corpora.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for each category illustrate source diversity and reliability of the corpus (", "labels": [], "entities": []}, {"text": " Table 2: Number of web pages in individual genre  classes in both original text and main text corpora.", "labels": [], "entities": []}, {"text": " Table 4: Classification accuracy of different features in genre classification. bin and nf refer to the use of  binary and normalized frequency representation of the features respectively.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9398285746574402}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9244493842124939}, {"text": "genre classification", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7095712125301361}, {"text": "bin", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.9783424139022827}]}, {"text": " Table 5: Number of unlabelled web pages with  different cosine similarity thresholds. The last col- umn shows the average number of neighbours per  labelled page.", "labels": [], "entities": []}, {"text": " Table 6: Recall, Precision and F-measure for multi-", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9968191385269165}, {"text": "Precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9989030361175537}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9986578226089478}]}, {"text": " Table 7: Recall, Precision and F-measure for content-based", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.987798273563385}, {"text": "Precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9985149502754211}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9989381432533264}]}]}