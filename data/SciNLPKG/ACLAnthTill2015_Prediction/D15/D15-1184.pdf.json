{"title": [{"text": "Reading Documents for Bayesian Online Change Point Detection", "labels": [], "entities": [{"text": "Bayesian Online Change Point Detection", "start_pos": 22, "end_pos": 60, "type": "TASK", "confidence": 0.5583411991596222}]}], "abstractContent": [{"text": "Modeling non-stationary time-series data for making predictions is a challenging but important task.", "labels": [], "entities": []}, {"text": "One of the key issues is to identify long-term changes accurately in time-varying data.", "labels": [], "entities": []}, {"text": "Bayesian On-line Change Point Detection (BO-CPD) algorithms efficiently detect long-term changes without assuming the Markov property which is vulnerable to local signal noise.", "labels": [], "entities": [{"text": "Bayesian On-line Change Point Detection (BO-CPD", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.6525663435459137}]}, {"text": "We propose a Document based BO-CPD (DBO-CPD) model which automatically detects long-term temporal changes of continuous variables based on a novel dynamic Bayesian analysis which combines a non-parametric regression, the Gaussian Process (GP), with generative models of texts such as news articles and posts on social networks.", "labels": [], "entities": [{"text": "BO-CPD", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.8803605437278748}]}, {"text": "Since texts often include important clues of signal changes, DBO-CPD enables the accurate prediction of long-term changes accurately.", "labels": [], "entities": []}, {"text": "We show that our algorithm outperforms existing BO-CPDs in two real-world datasets: stock prices and movie revenues.", "labels": [], "entities": []}], "introductionContent": [{"text": "Time series data depends on the latent dependence structure which changes overtime.", "labels": [], "entities": []}, {"text": "Thus, stationary parametric models are not appropriate to represent such dynamic non-stationary processes.", "labels": [], "entities": []}, {"text": "Change point analysis) focuses on formal frameworks to determine whether a change has taken place without assuming the Markov property which is vulnerable to local signal noise.", "labels": [], "entities": [{"text": "Change point analysis", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6611953477064768}]}, {"text": "When change points are identified, each part of the time series is approximated by specified parametric models under the stationary assumptions.", "labels": [], "entities": []}, {"text": "Such change point detection models have successfully been applied to a variety of data, such as stock markets, analyzing bees' behavior, forecasting climates (, and physics experiments).", "labels": [], "entities": [{"text": "change point detection", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.7119618058204651}]}, {"text": "However, offline-based change point analysis suffers from slow retrospective inference which prevents real-time analysis.", "labels": [], "entities": [{"text": "change point analysis", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.6386280357837677}]}, {"text": "Bayesian Online Change Point Detection (BO-CPD) overcomes this restriction by exploiting efficient online inference algorithms.", "labels": [], "entities": [{"text": "Bayesian Online Change Point Detection (BO-CPD", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.566634293113436}]}, {"text": "BO-CPD algorithms efficiently detect long-term changes by analyzing continuous target values with the Gaussian Process (GP), a non-parametric regression method.", "labels": [], "entities": []}, {"text": "The GP-based CPD model is simple and flexible.", "labels": [], "entities": []}, {"text": "However, it is not straightforward to utilize rich external data such as texts in news articles and posts in social networks.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel BO-CPD model that improves the detection of change points in continuous signals by incorporating the rich external information implicitly written in texts on top of the long-term change analysis of the GP.", "labels": [], "entities": [{"text": "BO-CPD", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9621441960334778}]}, {"text": "In particular, our model finds causes of signal changes in news articles which are influential sources of markets of interests.", "labels": [], "entities": []}, {"text": "Given a set of news articles extracted from the Google News service and a sequence of target, continuous values, our new model, Documentbased Bayesian Online Change Point Detection (DBO-CPD), learns a generative model which represents the probability of a news article given the run length (a length of consecutive observations without a change).", "labels": [], "entities": [{"text": "Documentbased Bayesian Online Change Point Detection", "start_pos": 128, "end_pos": 180, "type": "TASK", "confidence": 0.4907010495662689}]}, {"text": "By using the new prior, DBO-CPD models a dynamic hazard rate (h) which determines the rate at which change points occur.", "labels": [], "entities": [{"text": "dynamic hazard rate (h)", "start_pos": 41, "end_pos": 64, "type": "METRIC", "confidence": 0.7898449897766113}]}, {"text": "In the literature, important information is extracted from news articles (a) BO-CPD (b) DBO-CPD (this work): This figures illustrates a graphical representation of BO-CPD and our DBO-CPD model.", "labels": [], "entities": [{"text": "BO-CPD", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.7799700498580933}]}, {"text": "x t , rt , and D t represent a continuous variable of interest, the run length (hidden) variable, and documents, respectively.", "labels": [], "entities": []}, {"text": "Our modeling contribution is to add texts D 1:t for the accurate prediction of the run length r t+1 .;), tweets on Twitter (), online chats (), and blog posts (.", "labels": [], "entities": []}, {"text": "In experiments, we show that DBO-CPD can effectively distinguish whether an abrupt change is a change point or not in real-world datasets (see Section 3.1).", "labels": [], "entities": []}, {"text": "Compared to previous BO-CPD models which explain the changes by human manual mappings, our DBO-CPD automatically explains the reasons why a change point has occurred by connecting the numerical sequence of data and textual features of news articles.", "labels": [], "entities": []}], "datasetContent": [{"text": "Now we explain experiments of DBO-CPD in two real-world datasets, stock prices and movie revenues.", "labels": [], "entities": []}, {"text": "The first case is the historical end-of-day stock prices of five information technology corporations.", "labels": [], "entities": []}, {"text": "In the second dataset, we examine daily film revenues averaged by the number of theaters.", "labels": [], "entities": []}, {"text": "In the stock price dataset, we gather data for five different companies: Apple (AAPL), Google (GOOG), IBM (IBM), Microsoft (MSFT), and Facebook (FB).", "labels": [], "entities": []}, {"text": "These companies were selected because they were the top 5 ranked in market value in 2015.", "labels": [], "entities": []}, {"text": "We chose these technology companies because the announcement of new IT products and features and the interests of public media tend to be higher    News articles are collected from Google News and we use Google search queries to extract specific articles related to each dataset in a specific time period.", "labels": [], "entities": []}, {"text": "During the online article crawling, we store not only the titles of articles, HTML documents, and publication dates, but also the number of related articles.", "labels": [], "entities": []}, {"text": "The number of articles is used to differentiate the weight of news articles during the training of regression.", "labels": [], "entities": []}, {"text": "In the case of stock price data, we use two different queries to decrease noise.", "labels": [], "entities": []}, {"text": "First, we search with the company name such as 'Google'.", "labels": [], "entities": [{"text": "Google", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.9282081723213196}]}, {"text": "Then, we use queries specific to stock 'NASDAQ:' to make the content of articles to be highly relevant to the stock market.", "labels": [], "entities": []}, {"text": "In case of movie data, we search with the movie title with the additional word 'movie' to only collect articles related to the target movie.", "labels": [], "entities": []}, {"text": "With these collected articles, we used two ar-ticle extractors, newspaper (Ou-Yang, 2013) and python-goose, to automate the text extraction of 291,057 HTML documents.", "labels": [], "entities": [{"text": "text extraction of 291,057 HTML documents", "start_pos": 124, "end_pos": 165, "type": "TASK", "confidence": 0.8442243734995524}]}, {"text": "After preprocessing, we could successfully extract texts from 287,389 (98.74%) HTMLs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Negative log likelihood of five stocks  (Apple, Google, IBM, Microsoft, and Facebook)  without and with our model per year from 2010  to 2014. DBO-CPD I represents the experiments  without 'NASDAQ:' as a search query and DBO- CPD II is the result of articles searched with  'NASDAQ:'. Facebook data is not available be- fore the year 2012.", "labels": [], "entities": [{"text": "Negative log likelihood", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.7001026074091593}, {"text": "Facebook data", "start_pos": 295, "end_pos": 308, "type": "DATASET", "confidence": 0.8640981316566467}]}, {"text": " Table 3: Negative log likelihood (NLL) of five  movies (The Dark Knight, Inception, Avengers,  Frozen, and Interstellar) without and with our  model for 1 year from the release date of each  movie.", "labels": [], "entities": [{"text": "Negative log likelihood (NLL)", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.9615204334259033}]}]}