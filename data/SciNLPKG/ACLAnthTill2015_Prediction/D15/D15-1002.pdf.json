{"title": [], "abstractContent": [{"text": "Distributional methods have proven to excel at capturing fuzzy, graded aspects of meaning (Italy is more similar to Spain than to Germany).", "labels": [], "entities": [{"text": "capturing fuzzy, graded aspects of meaning", "start_pos": 47, "end_pos": 89, "type": "TASK", "confidence": 0.7654520698956081}]}, {"text": "In contrast, it is difficult to extract the values of more specific attributes of word referents from distribu-tional representations, attributes of the kind typically found in structured knowledge bases (Italy has 60 million inhabitants).", "labels": [], "entities": []}, {"text": "In this paper, we pursue the hypothesis that distributional vectors also implicitly encode referential attributes.", "labels": [], "entities": []}, {"text": "We show that a standard supervised regression model is in fact sufficient to retrieve such attributes to a reasonable degree of accuracy: When evaluated on the prediction of both categorical and numeric attributes of countries and cities, the model consistently reduces baseline error by 30%, and is not far from the upper bound.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9967923760414124}]}, {"text": "Further analysis suggests that our model is able to \"ob-jectify\" distributional representations for entities, anchoring them more firmly in the external world in measurable ways.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional models induce vector-based semantic representations of words from their contextual distributions in corpora, exploiting the observation that words with related meanings tend to occur in similar linguistic contexts.", "labels": [], "entities": []}, {"text": "Since the approach only requires raw text as input, it can be used to harvest word representations on a very large scale.", "labels": [], "entities": []}, {"text": "By encoding the rich knowledge that is present in text, these representations are able to capture many aspects of word meaning.", "labels": [], "entities": []}, {"text": "Moreover, approximating semantic similarity by graded geometric distance in a vector space is an effective strategy to address the many linguistic phenomena that are better characterized in gradient rather than discrete terms, such as synonymy, selectional preferences, and semantic priming (, among others).", "labels": [], "entities": []}, {"text": "However, not all aspects of human semantic knowledge are satisfactorily captured in terms of fuzzy relations and graded similarity.", "labels": [], "entities": []}, {"text": "In particular, our knowledge of the meaning of words denoting specific entities involves a number of \"hard facts\" about the referents they denote that are best formalized as attribute-value pairs, of the sort that are stored in manually-curated knowledge bases, such as FreeBase or Wikidata.", "labels": [], "entities": [{"text": "knowledge of the meaning of words denoting specific entities", "start_pos": 19, "end_pos": 79, "type": "TASK", "confidence": 0.6932732595337762}, {"text": "FreeBase", "start_pos": 270, "end_pos": 278, "type": "DATASET", "confidence": 0.9539632201194763}]}, {"text": "While distributional vectors can capture the useful fact that, say, Italy is in many ways more similar to Spain than to Germany, as humans we also know (or we can easily look up) a set of objective facts about Italy, such as what is its capital, its area, its official language and GDP, that are difficult to express in the language of vector algebra and geometry.", "labels": [], "entities": []}, {"text": "In this paper, we explore the hypothesis that distributional vectors implicitly encode such attributes of referential entities, which we will call referential attributes.", "labels": [], "entities": []}, {"text": "We show that a simple supervised algorithm applied to vectors can retrieve them so that they can be expressed in the explicit language of structured knowledge bases.", "labels": [], "entities": []}, {"text": "Concretely, we train a logistic regression model to predict the values of both numeric and categorical FreeBase attributes of countries and cities from their distributional vectors.", "labels": [], "entities": []}, {"text": "This model makes predictions that are significantly better than an informed baseline, in-between the latter and an upper-bound method.", "labels": [], "entities": []}, {"text": "Qualitative analysis of the results points both to the inherent difficulty of correctly retrieving certain classes of attributes, and to some intriguing properties of the conceptual nature of the knowledge encoded in distributional data, that bias their predictions about certain objective attributes of geographic entities.", "labels": [], "entities": []}, {"text": "We see our experiment as a first step towards integrating conceptual and referential aspects of meaning in distributional semantics, as we further discuss in the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We design the model using the Countries dataset, and apply it to Cities without further tuning to test its robustness.", "labels": [], "entities": [{"text": "Countries dataset", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.9883052706718445}]}, {"text": "We optimize the parameters with gradient descent, using the Cross Entropy error function.", "labels": [], "entities": [{"text": "Cross Entropy error function", "start_pos": 60, "end_pos": 88, "type": "METRIC", "confidence": 0.6972956135869026}]}, {"text": "We considered L 2 regularization to address possible overfitting, but experiments on validation set showed that the model performs best without any regularization.", "labels": [], "entities": []}, {"text": "As for baselines, for binary features we predict the majority class (0 or 1), and for numeric features we predict the mean value of the feature in the training set.", "labels": [], "entities": []}, {"text": "These are of course strong baselines to beat.", "labels": [], "entities": []}, {"text": "As an upper bound, we train a model that uses the same architecture as described above but uses as input not distributional vectors but the FreeBase attributes themselves.", "labels": [], "entities": []}, {"text": "In other words, this model has to learn \"only\" an identity mapping.", "labels": [], "entities": []}, {"text": "This is not trivial, though, for example due to the presence of strong correlations among attributes, in particular the time series attributes (cf. Section 2.2).", "labels": [], "entities": []}, {"text": "We call this model REF2REF.", "labels": [], "entities": [{"text": "REF2REF", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.856079638004303}]}, {"text": "Since there is no appropriate unified evaluation measure that covers both numeric and binary attributes, we evaluate them separately.", "labels": [], "entities": []}, {"text": "For binary attributes, we report the attributes' mean accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9058688282966614}]}, {"text": "For numeric attributes, we consider attribute prediction a ranking task.", "labels": [], "entities": [{"text": "attribute prediction", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7118254899978638}]}, {"text": "As an example, take the population::2011::number attribute, and imagine that we only have three countries (Germany: 80M; Spain: 36M; and Netherlands: 17M).", "labels": [], "entities": []}, {"text": "If we predict 56M for Spain's population, it is still (correctly) predicted as the second most populous country (rank difference of 0); a prediction of 16M, however, would push Spain to third place (rank difference of 1).", "labels": [], "entities": []}, {"text": "This suggests the use of rank correlation coefficients like Spearman's \u03c1.", "labels": [], "entities": []}, {"text": "However, we want to measure not only how well the model can rank the countries in the test set, but also whether these predictions are consistent with the training set (which makes evaluation both more challenging and more realistic).", "labels": [], "entities": []}, {"text": "One way of achieving this goal would be to use \u03c1 on the union of training and test instances, but this could lead to misleadingly high correlation coefficients since this method would include the labels of the training instances in the evaluation.", "labels": [], "entities": []}, {"text": "Consequently, we define our own evaluation measure, following a rationale similar to evaluation of a zero-shot learning scenario.", "labels": [], "entities": []}, {"text": "What we evaluate, for each attribute, is the rank of the test countries in the whole country list.", "labels": [], "entities": []}, {"text": "Note that this makes our task harder, as there are more confounders: If we only evaluated on the test set, there would be shorter lists and therefore less chances of getting bad rankings.", "labels": [], "entities": []}, {"text": "So, concretely, we first define the prediction quality of each attribute, Q(a), as the median of the rank difference between the prediction and the gold standard in a list that includes both training and test countries (we use the median to give less weight to outlier countries).", "labels": [], "entities": []}, {"text": "We also normalize the rank difference to obtain a number between zero and one.", "labels": [], "entities": []}, {"text": "Ina second step, we define the quality of the complete model, the normalized rank score (NRS), as the mean of all attribute quality scores, in parallel to our evaluation on binary attributes.", "labels": [], "entities": [{"text": "normalized rank score (NRS)", "start_pos": 66, "end_pos": 93, "type": "METRIC", "confidence": 0.7893130630254745}]}, {"text": "Let the set of instances I be partitioned into training instances T rand test instances T s.", "labels": [], "entities": []}, {"text": "Leta \u2208 A: Results for predicting FreeBase attributes from distributional vectors on the test sets.", "labels": [], "entities": [{"text": "predicting FreeBase attributes", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7237815062204996}]}, {"text": "Both evaluation measures range between 0 and 1.", "labels": [], "entities": []}, {"text": "For accuracy, 1 is best.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992495179176331}]}, {"text": "For normalized rank score (NRS), 0 is best.", "labels": [], "entities": [{"text": "normalized rank score (NRS)", "start_pos": 4, "end_pos": 31, "type": "METRIC", "confidence": 0.7723746945460638}]}, {"text": "All pairwise differences between models are significant (p<0.001, bootstrap resampling).", "labels": [], "entities": []}, {"text": "We write pa (i) for the predicted value of attribute a for instance i and g a (i) for the gold standard value.", "labels": [], "entities": []}, {"text": "Finally, let r(v, S) denote the rank of value v in the list resulting when ordering the set S.", "labels": [], "entities": []}, {"text": "Now we can define: This measure can be interpreted similarly to Mean Reciprocal Rank (: It has range [0..1], with smaller numbers indicating better ranking: 0.1, for example, means that, on average, the prediction is 10% of the ranks off (e.g., by four countries in a forty-country list).", "labels": [], "entities": [{"text": "Mean Reciprocal Rank", "start_pos": 64, "end_pos": 84, "type": "METRIC", "confidence": 0.9373711943626404}]}, {"text": "Note that, when evaluating each instance i, we use gold-standard values for all other instances, so that there the baseline is not hampered by ties.", "labels": [], "entities": []}, {"text": "shows the results of our experiments on the two test sets.", "labels": [], "entities": []}, {"text": "For accuracy 1 is best, but for NRS 0 is best.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992415904998779}, {"text": "NRS", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.45333296060562134}]}, {"text": "Recall from Section 2.2 that we perform model selection on the Countries dataset only.", "labels": [], "entities": [{"text": "model selection", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7202863395214081}, {"text": "Countries dataset", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.9863807857036591}]}], "tableCaptions": [{"text": " Table 1: Sample of numeric and binary FreeBase  attributes for Germany.", "labels": [], "entities": []}, {"text": " Table 2: Results for predicting FreeBase attributes from distributional vectors on the test sets. Both  evaluation measures range between 0 and 1. For accuracy, 1 is best. For normalized rank score (NRS), 0  is best. All pairwise differences between models are significant (p<0.001, bootstrap resampling).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9991476535797119}, {"text": "normalized rank score (NRS)", "start_pos": 177, "end_pos": 204, "type": "METRIC", "confidence": 0.76393294831117}]}, {"text": " Table 3: Results for all attribute groups on the Countries test set, in descending order of performance.  DIST2REF, BL: models; #A: number of attributes in group; f(A): median number of countries instantiating  each attribute in the dataset (260 countries); !: attribute group where model performs worse than baseline.", "labels": [], "entities": [{"text": "Countries test set", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.9162243008613586}, {"text": "DIST2REF", "start_pos": 107, "end_pos": 115, "type": "DATASET", "confidence": 0.5517241954803467}, {"text": "BL", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.9701312184333801}]}]}