{"title": [{"text": "Efficient Inner-to-outer Greedy Algorithm for Higher-order Labeled Dependency Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.7527250051498413}]}], "abstractContent": [{"text": "Many NLP systems use dependency parsers as critical components.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7218202948570251}]}, {"text": "Jonit learning parsers usually achieve better parsing accuracies than two-stage methods.", "labels": [], "entities": [{"text": "Jonit learning parsers", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7976775169372559}]}, {"text": "However , classical joint parsing algorithms significantly increase computational complexity , which makes joint learning impractical.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.6375901401042938}]}, {"text": "In this paper, we proposed an efficient dependency parsing algorithm that is capable of capturing multiple edge-label features, while maintaining low computational complexity.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7688209712505341}]}, {"text": "We evaluate our parser on 14 different languages.", "labels": [], "entities": []}, {"text": "Our parser consistently obtains more accurate results than three baseline systems and three popular , off-the-shelf parsers.", "labels": [], "entities": [{"text": "accurate", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9830806851387024}]}], "introductionContent": [{"text": "Natural language processing (NLP) systems, like machine translation), resourcelow languages processing, word sense disambiguation ( , and entity coreference resolution, are becoming more sophisticated, in part because of utilizing syntacitc knowledges such as dependency parsing trees.", "labels": [], "entities": [{"text": "Natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7179436932007471}, {"text": "machine translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7446724772453308}, {"text": "word sense disambiguation", "start_pos": 104, "end_pos": 129, "type": "TASK", "confidence": 0.7414006392161051}, {"text": "entity coreference resolution", "start_pos": 138, "end_pos": 167, "type": "TASK", "confidence": 0.7646579543749491}, {"text": "dependency parsing trees", "start_pos": 260, "end_pos": 284, "type": "TASK", "confidence": 0.8170183897018433}]}, {"text": "Dependency parsers predict dependency structures and dependency type labels on each edge.", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7408537864685059}]}, {"text": "However, most graph-based dependency parsing algorithms only produce unlabeled dependency trees, particularly when higher-order factorizations are used (.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.6991919279098511}]}, {"text": "A two-stage method) is often used because the complexity of some joint learning models is unacceptably high.", "labels": [], "entities": []}, {"text": "On the other hand, joint learning models can benefit from edge-label information that has proven to be important to provide more accurate tree structures and labels.", "labels": [], "entities": []}, {"text": "Previous studies explored the trade-off between computational costs and parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 72, "end_pos": 79, "type": "TASK", "confidence": 0.9638943672180176}]}, {"text": "Some work simplified labeled information to only single label features.", "labels": [], "entities": []}, {"text": "Other work used richer label features but increased systems' complexities significantly, while achieving better parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 112, "end_pos": 119, "type": "TASK", "confidence": 0.9669051766395569}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.8603832125663757}]}, {"text": "Yet, there are no previous work addressing the problem of good balance between parsing accuracy and computational costs for joint parsing models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 79, "end_pos": 86, "type": "TASK", "confidence": 0.977344810962677}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9022849202156067}]}, {"text": "In this paper, we propose anew dependency parsing algorithm that can utilize edge-label information of more than one edge, while simultaneously maintaining low computational complexity.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7191120088100433}]}, {"text": "The component needed to solve this dilemma is an inner-to-outer greedy approximation to avoid an exhaustive search.", "labels": [], "entities": []}, {"text": "The contributions of this work are (i) showing the effectiveness of edge-label information on both UAS and LAS.", "labels": [], "entities": []}, {"text": "(ii) proposing a joint learning parsing model which achieves both effectiveness and efficience.", "labels": [], "entities": [{"text": "joint learning parsing", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.6978195309638977}]}, {"text": "(iii) giving empirical evaluations of this parser on different treebanks over 14 languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "To make a thorough empirical comparison with previous studies, we also evaluate our system on the English Penn Treebanks ( with Stanford Basic Dependencies).", "labels": [], "entities": [{"text": "English Penn Treebanks", "start_pos": 98, "end_pos": 120, "type": "DATASET", "confidence": 0.9436710675557455}]}, {"text": "We compare our parser with three off-the-shelf parsers: MaltParser (: Top 10 dependency labels on which our algorithm achieves most improvements on the F1 score of UAS, together with the corresponding improvements of LAS.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9786080121994019}, {"text": "UAS", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.6506784558296204}, {"text": "LAS", "start_pos": 217, "end_pos": 220, "type": "METRIC", "confidence": 0.955025851726532}]}, {"text": "\"TST\" indicates the two-stage system.", "labels": [], "entities": [{"text": "TST", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.8381159901618958}]}, {"text": "The first column is the label name in the treebank.", "labels": [], "entities": []}, {"text": "The second column is the label's description from.", "labels": [], "entities": []}, {"text": "The results are listed in.", "labels": [], "entities": []}, {"text": "Clearly, our parser is superior in terms of both UAS and LAS.", "labels": [], "entities": [{"text": "UAS", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8370383381843567}, {"text": "LAS", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9635729789733887}]}], "tableCaptions": [{"text": " Table 1: UAS and LAS of non-projective versions of our parsing algorithms on 14 treebanks from  CoNLL shared tasks, together with three baseline systems and the best systems for each language re- ported in CoNLL shared tasks. MD06 is McDonald et al. (2006), RD06 is Riedel et al. (2006), JN08  is Johansson and Nugues (2008), and NV06 is Nivre et al. (2006) Bold indicates the best result for a  language. Red values represent statistically significant improvements over two-stage baseline system  on the corresponding metrics with p < 0.01, using McNemar's test. Blue values indicate statistically  significant improvements with p < 0.05.", "labels": [], "entities": [{"text": "RD06", "start_pos": 259, "end_pos": 263, "type": "METRIC", "confidence": 0.9470607042312622}, {"text": "McNemar's test", "start_pos": 549, "end_pos": 563, "type": "DATASET", "confidence": 0.7766295274098715}]}, {"text": " Table 2: Parsing performance on PTB. The re- sults for MaltParser, MSTParser and DNNParser  are from table 5 of Chen and Manning (2014).", "labels": [], "entities": [{"text": "PTB", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.9026712775230408}, {"text": "MaltParser", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.914768397808075}, {"text": "MSTParser", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.8299011588096619}]}, {"text": " Table 3: Top 10 dependency labels on which our algorithm achieves most improvements on the F1 score  of UAS, together with the corresponding improvements of LAS. \"TST\" indicates the two-stage system.  The first column is the label name in the treebank. The second column is the label's description from", "labels": [], "entities": [{"text": "F1 score", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9701918065547943}, {"text": "UAS", "start_pos": 105, "end_pos": 108, "type": "DATASET", "confidence": 0.7565829753875732}, {"text": "LAS", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.919583797454834}, {"text": "TST", "start_pos": 164, "end_pos": 167, "type": "METRIC", "confidence": 0.7974848747253418}]}]}