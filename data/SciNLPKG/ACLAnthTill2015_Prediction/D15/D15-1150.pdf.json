{"title": [{"text": "Part-of-speech Taggers for Low-resource Languages using CCA Features", "labels": [], "entities": [{"text": "Part-of-speech Taggers", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6810419857501984}]}], "abstractContent": [{"text": "In this paper, we address the challenge of creating accurate and robust part-of-speech taggers for low-resource languages.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7096062302589417}]}, {"text": "We propose a method that leverages existing parallel data between the target language and a large set of resource-rich languages without ancillary resources such as tag dictionaries.", "labels": [], "entities": []}, {"text": "Crucially, we use CCA to induce latent word representations that incorporate cross-genre distri-butional cues, as well as projected tags from a full array of resource-rich languages.", "labels": [], "entities": []}, {"text": "We develop a probability-based confidence model to identify words with highly likely tag projections and use these words to train a multi-class SVM using the CCA features.", "labels": [], "entities": []}, {"text": "Our method yields average performance of 85% accuracy for languages with almost no resources, outperforming a state-of-the-art partially-observed CRF model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9986542463302612}]}], "introductionContent": [{"text": "We address the challenge of creating accurate and robust part-of-speech taggers for low-resource languages.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7089261114597321}]}, {"text": "We aim to apply our methods to the hundreds, and potentially thousands, of languages with meager electronic resources.", "labels": [], "entities": []}, {"text": "We do not assume the existence of a tag dictionary, or any other sort of prior knowledge of the target language.", "labels": [], "entities": []}, {"text": "Instead, we base our methods entirely on the existence of parallel data between the target language and a set of resource-rich languages.", "labels": [], "entities": []}, {"text": "Fortunately, such parallel data exists for just about every written language, in the form of Bible translations.", "labels": [], "entities": []}, {"text": "Around 2,500 languages have at least partial Bible translations, and somewhere between 500 and 1,000 languages have complete translations.", "labels": [], "entities": []}, {"text": "We have collected such electronic Bible translations for 650 languages.", "labels": [], "entities": []}, {"text": "breaks down the number of languages in our collection according to their token count.", "labels": [], "entities": []}, {"text": "The majority of our languages have at least 200,000 tokens of Bible translations.", "labels": [], "entities": []}, {"text": "While previous studies have addressed this general setting, they have typically assumed the existence of a partial tag dictionary as well as large quantities of non-parallel data in the target language.", "labels": [], "entities": []}, {"text": "These assumptions are quite reasonable for the dozen most popular languages in the world, but are inadequate for the creation of a truly worldwide repository of NLP tools and linguistic data.", "labels": [], "entities": []}, {"text": "In fact, we argue that such ancillary sources of information are not really necessary once we take into account the vastly multilingual nature of our parallel data.", "labels": [], "entities": []}, {"text": "Annotations projected from individual resource-rich languages are often noisy and unreliable, due to systematic differences between the languages in question, as well as word alignment errors.", "labels": [], "entities": []}, {"text": "We can thus think of these languages as very lazy and unreliable annotators of our target language.", "labels": [], "entities": []}, {"text": "Despite their incompetence, as the number of such annotators increases, their combined efforts converge upon the truth, as idiosyncratic biases and random noise are washed away.", "labels": [], "entities": []}, {"text": "Our assumption throughout will be that we have in our possession a single multilingual corpus (the Bible) consisting of about 200,000 tokens for several hundred languages languages, as well as reasonably accurate POS taggers for about ten \"resource-rich\" languages.", "labels": [], "entities": []}, {"text": "We will tag the Bible data for the resource-rich languages, word-align them to one another, and also word-align them to the remaining several hundred target languages.", "labels": [], "entities": [{"text": "Bible data", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.8734711408615112}]}, {"text": "Of course, our goal is not to produce a tagger restricted to the Biblical lexicon.", "labels": [], "entities": []}, {"text": "We therefore assume a small unannotated monolingual sample of the target language in an entirely unrelated genre (e.g. newswire).", "labels": [], "entities": []}, {"text": "We use this sample transductively to adapt our learned taggers from the Biblical genre.", "labels": [], "entities": []}, {"text": "In our experiments, we use the CoNLL 2006 and 2007 shared-task test data for this purpose.", "labels": [], "entities": [{"text": "CoNLL 2006 and 2007 shared-task test data", "start_pos": 31, "end_pos": 72, "type": "DATASET", "confidence": 0.9443996718951634}]}, {"text": "Of course tagged data does not exist for truly resource-poor languages, so we evaluate our methodology on the resource-rich languages.", "labels": [], "entities": []}, {"text": "Each such language takes a turn playing the role of the target language for testing purposes.", "labels": [], "entities": []}, {"text": "The goal of the paper is to introduce a general \"recipe\" for successful cross-lingual induction of accurate taggers using meager resources.", "labels": [], "entities": [{"text": "cross-lingual induction of accurate taggers", "start_pos": 72, "end_pos": 115, "type": "TASK", "confidence": 0.7833878993988037}]}, {"text": "We faced three major technical challenges: \u2022 First, word alignments across languages are incomplete, and often do not preserve partof-speech due to language differences.", "labels": [], "entities": [{"text": "word alignments across languages", "start_pos": 52, "end_pos": 84, "type": "TASK", "confidence": 0.7908630594611168}]}, {"text": "\u2022 Second, when using multiple resource-rich languages, we need to resolve conflicting projections.", "labels": [], "entities": []}, {"text": "\u2022 Third, the parallel data at our disposal is of an idiosyncratic genre (the Bible), and we wish to induce a general-purpose tagger.", "labels": [], "entities": []}, {"text": "To address these challenges, we forgo the typical sequence-based learning technique of HMM's and CRF's and instead adopt an instance-learning approach using latent distributional features.", "labels": [], "entities": []}, {"text": "To induce these features, we introduced anew method using Canonical Correlation Analysis (CCA) to generalize the aligned information to new words.", "labels": [], "entities": []}, {"text": "This method views each word position as consisting of three fundamental views: (1) the token view (word context), (2) the type view, and (3) the projected tags in the local vicinity.", "labels": [], "entities": []}, {"text": "We perform a CCA to induce latent continuous vector representations of each view that maximizes their correlations to one another.", "labels": [], "entities": []}, {"text": "On the test data, a simple multi-class classifier then suffices to predict accurate tags, even for novel words.", "labels": [], "entities": []}, {"text": "This approach outperform a state-of-the-art baseline) to achieve average tag accuracy of 85% on newswire text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9238443970680237}]}], "datasetContent": [{"text": "There are more than 4,000 living languages in the world, and one of the most prevalently translated books is the Bible.", "labels": [], "entities": []}, {"text": "We now describe the Bible dataset we collected.", "labels": [], "entities": [{"text": "Bible dataset", "start_pos": 20, "end_pos": 33, "type": "DATASET", "confidence": 0.9417127966880798}]}, {"text": "\u2022 Calculate rank-k SVD\u02c6\u2126SVD\u02c6 SVD\u02c6\u2126.", "labels": [], "entities": []}, {"text": "Let U \u2208 R d\u00d7k (V \u2208 Rd \u00d7k ) be a matrix of the left (right) singular vector corresponding to the largest k singular values.", "labels": [], "entities": []}, {"text": "\u2022  We first collect 893 bible volumes spanning several hundred languages that are freely available from three resources (www.bible.is, www.crosswire.org, www.biblegateway.com) and changed to UTF-8 format.", "labels": [], "entities": []}, {"text": "The distribution of token in each bible in the unit of a language is in.", "labels": [], "entities": []}, {"text": "Note that the Bible scripts are not exactly translated by sentences but by verses.", "labels": [], "entities": []}, {"text": "We thus assume that each verse in a chapter has the same meaning if the number of verses is exactly same in a same chapter.", "labels": [], "entities": []}, {"text": "We also assume that the whole chapters have the same meaning if the number of chapters in a book are exactly the same.", "labels": [], "entities": []}, {"text": "In the same manner, we also assume the volumes that have the same number of chapters are the same.", "labels": [], "entities": []}, {"text": "That is, their volume size should be as similar as possible Input: \u2022 N \"labeled\" tokens in the Bible domain: word w (i) \u2208 V, corresponding context C(w (i) ) \u2282 V and (projected) tag set P (i) \u2282 T for i = 1 . .", "labels": [], "entities": []}, {"text": "N \u2022 N tokens in data in the test domain: word Output: embedding e(w) \u2208 R k 2 for each word w \u2208 V \u222a V 1.", "labels": [], "entities": []}, {"text": "Combine the observed tokens and their context from the Bible and data in the test domain: 2.", "labels": [], "entities": []}, {"text": "Perform rank-k1 CCA-PROJ-SPARSE on (W1, C1) to derive a word projection matrix \u03a6W 1 and a context projection matrix \u03a6C 1 . 3. Project all word examples in the Bible domain using \u03a6W 1 . Denote these projected words and the corresponding projected tag sets from all resource-rich languages by with the respect to the number of verses, chapters, and books.", "labels": [], "entities": []}, {"text": "Based upon these assumptions, we choose the best translation in a language based on a comparison to a reference Bible, the Modern King James Version (MKJV) in English.", "labels": [], "entities": [{"text": "Modern King James Version (MKJV)", "start_pos": 123, "end_pos": 155, "type": "DATASET", "confidence": 0.7598087872777667}]}, {"text": "We choose the translation for each language that best matches this reference version in terms of chapter and verse numbering.", "labels": [], "entities": []}, {"text": "There are other factors considered if there are more than one candidates satisfying this matching.", "labels": [], "entities": []}, {"text": "We focus on the contents of the bible such as the publication time.", "labels": [], "entities": []}, {"text": "For instance, 1599 Geneva Bible in English contains old vocabulary with different spelling systems, causing unexpected errors when tagged by POS annotation tools.", "labels": [], "entities": [{"text": "1599 Geneva Bible", "start_pos": 14, "end_pos": 31, "type": "DATASET", "confidence": 0.7058817346890768}]}, {"text": "Also, some of volumes such as Amplified Bible (AMP) contains extraneous comments on verses themselves, causing errors for word alignments.", "labels": [], "entities": [{"text": "Amplified Bible (AMP)", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.9173562884330749}, {"text": "word alignments", "start_pos": 122, "end_pos": 137, "type": "TASK", "confidence": 0.6900830864906311}]}, {"text": "After the choice of the best volume, we finally select the 10 resource rich languages . The two criteria to select resource rich languages are having i) the matched bible scripts both on the Old and New testament and ii) reliable parts-of-speech annotation tools.", "labels": [], "entities": []}, {"text": "If these two requirements are satisfied, we can freely add more languages as resource rich languages in the future research.", "labels": [], "entities": []}, {"text": "We use Hunpos tagger for CS, DA, DE, EN, and PT, Treetagger for BG, ES, IT, and NL, and Meltparser for FR.", "labels": [], "entities": [{"text": "PT", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9644405245780945}, {"text": "FR", "start_pos": 103, "end_pos": 105, "type": "DATASET", "confidence": 0.7189351916313171}]}], "tableCaptions": [{"text": " Table 2: Baseline model CONLL performance de- pending on criterion for selecting tag projection.", "labels": [], "entities": [{"text": "tag projection", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.7109953016042709}]}, {"text": " Table 3: Performance on multilingual Bible data", "labels": [], "entities": []}, {"text": " Table 4: Accuracy of the PO-CRF models on CoNLL data. A, W, no S/C means: all, word, all but no  suffix and cluster features are used, respectively.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9918850660324097}, {"text": "CoNLL data", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.9602554440498352}]}, {"text": " Table 5: Performances on our test data, CoNLL  document.", "labels": [], "entities": [{"text": "CoNLL  document", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9577566683292389}]}]}