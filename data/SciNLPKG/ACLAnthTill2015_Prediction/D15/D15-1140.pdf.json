{"title": [{"text": "Keyboard Logs as Natural Annotations for Word Segmentation", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7424355149269104}]}], "abstractContent": [{"text": "In this paper we propose a framework to improve word segmentation accuracy using input method logs.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7649155557155609}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.7201946377754211}]}, {"text": "An input method is software used to type sentences in languages which have far more characters than the number of keys on a keyboard.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: 1) an input method server that proposes word candidates which are not included in the vocabulary, 2) a publicly usable input method that logs user behavior (like typing and selection of word candidates), and 3) a method for improving word segmen-tation by using these logs.", "labels": [], "entities": []}, {"text": "We conducted word segmentation experiments on tweets from Twitter, and showed that our method improves accuracy in this domain.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7551701366901398}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9974029660224915}]}, {"text": "Our method itself is domain-independent and only needs logs from the target domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "The first step of almost all natural language processing (NLP) for languages with ambiguous word boundaries (such as Japanese and Chinese) is solving the problem of word identification ambiguity.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.8549020290374756}, {"text": "word identification ambiguity", "start_pos": 165, "end_pos": 194, "type": "TASK", "confidence": 0.8336565891901652}]}, {"text": "This task is called word segmentation (WS) and the accuracy of state-of-the-art methods based on machine learning techniques is more than 98% for Japanese and 95% for Chinese).", "labels": [], "entities": [{"text": "word segmentation (WS)", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.860217422246933}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9993242025375366}]}, {"text": "Compared to languages like English with clear word boundaries, this ambiguity poses an additional problem for NLP tasks in these languages.", "labels": [], "entities": []}, {"text": "To make matters worse, the domains of the available training data often differ from domains where there is a high demand for NLP, which causes a severe degradation in WS performance.", "labels": [], "entities": [{"text": "WS", "start_pos": 167, "end_pos": 169, "type": "TASK", "confidence": 0.9842619895935059}]}, {"text": "Examples include ma-chine translation of patents, text mining of medical texts, and marketing on the micro-blog site Twitter . Some papers have reported low accuracy on WS or the joint task of WS and part-of-speech (POS) tagging of Japanese or Chinese in these domains To cope with this problem, we propose away to collect information from people as they type Japanese or Chinese on computers.", "labels": [], "entities": [{"text": "ma-chine translation of patents", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7914596647024155}, {"text": "text mining of medical texts", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.864095413684845}, {"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.999046266078949}, {"text": "WS", "start_pos": 169, "end_pos": 171, "type": "TASK", "confidence": 0.8842933177947998}, {"text": "part-of-speech (POS) tagging of Japanese or Chinese", "start_pos": 200, "end_pos": 251, "type": "TASK", "confidence": 0.7233218219545152}]}, {"text": "These languages use far more characters than the number of keys on a keyboard, so users use software called an input method (IM) to type text in these languages.", "labels": [], "entities": []}, {"text": "Unlike written texts in these languages, which lack word boundary information, text entered with an IM can provide word boundary information that can used by NLP systems.", "labels": [], "entities": []}, {"text": "As we show in this paper, logs collected from IMs area valuable source of word boundary information.", "labels": [], "entities": []}, {"text": "An IM consists of a client (front-end) and a server (back-end).", "labels": [], "entities": []}, {"text": "The client receives a key sequence typed by the user and sends a phoneme sequence (kana in Japanese or pinyin in Chinese) or some predefined commands to the server.", "labels": [], "entities": []}, {"text": "The server converts the phoneme sequence into normal written text as a word sequence or proposes word candidates for the phoneme sequence in the region specified by the user.", "labels": [], "entities": []}, {"text": "We noticed that the actions performed by people using the IM (such as typing and selecting word candidates) provide information about word boundaries, including context information.", "labels": [], "entities": []}, {"text": "In this paper, we first describe an IM for Japanese which allows us to collect this information.", "labels": [], "entities": [{"text": "IM", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9419169425964355}]}, {"text": "We then propose an automatic word segmenter that uses IM logs as a language resource to improve its performance.", "labels": [], "entities": [{"text": "word segmenter", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.7420549094676971}]}, {"text": "Finally, we report experimental results showing that our method increases the accuracy of a word segmenter on Twitter texts by using logs collected from a browser add-on ver-sion of our IM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9987202882766724}, {"text": "word segmenter on Twitter texts", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.8060734212398529}]}, {"text": "The three main contributions of this paper are: \u2022 an IM server that proposes word candidates which are not included in the vocabulary (Section 3), \u2022 a publicly usable IM that logs user behavior (such as typing and selection of word candidates) (Section 4), \u2022 a method for improving word segmentation by using these logs (Section 5).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 282, "end_pos": 299, "type": "TASK", "confidence": 0.7516137361526489}]}, {"text": "To the best of our knowledge, this is the first paper proposing a method for using IM logs to successfully improve WS.", "labels": [], "entities": [{"text": "WS", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.9856512546539307}]}], "datasetContent": [{"text": "As an evaluation of our methods, we measured the accuracy of WS without using logs (the baseline) and using logs converted by several methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999386191368103}, {"text": "WS", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9444615244865417}]}, {"text": "There are two test corpora: one is the general domain corpus from which we built the baseline WS, and the other is the same domain that the IM logs were collected from, Twitter.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus specifications.  #sent.  #words  #char.  Training  BCCWJ  56,753 1,324,951 1,911,660  Newspaper  8,164  240,097  361,843  Conversation 11,700  147,809  197,941  Test  BCCWJ-test  6,025  148,929  212,261  TWI-test  2,976  37,010  58,316", "labels": [], "entities": [{"text": "BCCWJ  56,753 1,324,951 1,911,660  Newspaper  8,164  240,097  361,843  Conversation 11,700  147,809  197,941  Test  BCCWJ-test  6,025  148,929  212,261  TWI-test", "start_pos": 68, "end_pos": 229, "type": "DATASET", "confidence": 0.8326904111438327}]}, {"text": " Table 3: Language resources derived from logs.  #sentence  fragments #annotations  Log-as-is  32,119  39,708  Log-chunk  8,685  63,144  Log-mconv  4,610  10,852  Log-chunk-mconv  1,218  14,242", "labels": [], "entities": []}, {"text": " Table 4: WS accuracy on the tweets.  Recall [%] Precision [%] F-measure  Baseline  90.31  94.05  92.14  + Log-as-is  90.33  93.77  92.02  + Log-chunk  91.04  94.29  92.64  + Log-mconv  90.62  94.09  92.32  + Log-chunk-mconv  91.40  94.45  92.90", "labels": [], "entities": [{"text": "WS", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8185095191001892}, {"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.979856014251709}, {"text": "Recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9820631742477417}, {"text": "Precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9825795888900757}, {"text": "F-measure  Baseline", "start_pos": 63, "end_pos": 82, "type": "METRIC", "confidence": 0.8398619890213013}]}, {"text": " Table 5: WS accuracy on BCCWJ.  Recall [%] Precision [%] F-measure  Baseline  99.01  98.97  98.99  + Log-as-is  99.02  98.87  98.94  + Log-chunk  99.05  98.88  98.96  + Log-mconv  98.98  98.91  98.95  + Log-chunk-mconv  98.98  98.92  98.95", "labels": [], "entities": [{"text": "WS", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8617619276046753}, {"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9841234087944031}, {"text": "BCCWJ", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.8381346464157104}, {"text": "Recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.995010495185852}, {"text": "Precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9685809016227722}, {"text": "F-measure  Baseline  99.01  98.97", "start_pos": 58, "end_pos": 91, "type": "METRIC", "confidence": 0.8540409207344055}]}, {"text": " Table 6: Ratio of OOV words in error words.", "labels": [], "entities": [{"text": "Ratio", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9528005123138428}]}]}