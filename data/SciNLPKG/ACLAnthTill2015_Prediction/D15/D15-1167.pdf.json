{"title": [{"text": "Document Modeling with Gated Recurrent Neural Network for Sentiment Classification", "labels": [], "entities": [{"text": "Document Modeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8649470806121826}, {"text": "Sentiment Classification", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.9548583030700684}]}], "abstractContent": [{"text": "Document level sentiment classification remains a challenge: encoding the intrinsic relations between sentences in the semantic meaning of a document.", "labels": [], "entities": [{"text": "Document level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8700694292783737}]}, {"text": "To address this, we introduce a neural network model to learn vector-based document representation in a unified, bottom-up fashion.", "labels": [], "entities": []}, {"text": "The model first learns sentence representation with convolutional neural network or long short-term memory.", "labels": [], "entities": [{"text": "sentence representation", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.7389088422060013}]}, {"text": "After-wards, semantics of sentences and their relations are adaptively encoded in document representation with gated recurrent neural network.", "labels": [], "entities": []}, {"text": "We conduct document level sentiment classification on four large-scale review datasets from IMDB and Yelp Dataset Challenge.", "labels": [], "entities": [{"text": "document level sentiment classification", "start_pos": 11, "end_pos": 50, "type": "TASK", "confidence": 0.7352655455470085}, {"text": "IMDB", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.9653456807136536}, {"text": "Yelp Dataset Challenge", "start_pos": 101, "end_pos": 123, "type": "DATASET", "confidence": 0.958336333433787}]}, {"text": "Experimental results show that: (1) our neural model shows superior performances over several state-of-the-art algorithms; (2) gat-ed recurrent neural network dramatically outperforms standard recurrent neural network in document modeling for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 243, "end_pos": 267, "type": "TASK", "confidence": 0.9402182698249817}]}], "introductionContent": [{"text": "Document level sentiment classification is a fundamental task in sentiment analysis, and is crucial to understand user generated content in social networks or product reviews; Liu, 2012).", "labels": [], "entities": [{"text": "Document level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8046077489852905}, {"text": "sentiment analysis", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.913480818271637}]}, {"text": "The task calls for identifying the overall sentiment polarity (e.g. thumbs up or thumbs down, 1-5 stars on review sites) of a document.", "labels": [], "entities": []}, {"text": "In literature, dominant approaches follow () and exploit machine learn-ing algorithm to build sentiment classifier.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.772002100944519}]}, {"text": "Many of them focus on designing hand-crafted features ( or learning discriminate features from data, since the performance of a machine learner is heavily dependent on the choice of data representation.", "labels": [], "entities": []}, {"text": "Document level sentiment classification remains a significant challenge: how to encode the intrinsic (semantic or syntactic) relations between sentences in the semantic meaning of document.", "labels": [], "entities": [{"text": "Document level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8659108132123947}]}, {"text": "This is crucial for sentiment classification because relations like \"contrast\" and \"cause\" have great influences on determining the meaning and the overall polarity of a document.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.9530448615550995}]}, {"text": "However, existing studies typically fail to effectively capture such information.", "labels": [], "entities": []}, {"text": "For example, and represent documents with bag-of-ngrams features and build SVM classifier upon that.", "labels": [], "entities": []}, {"text": "Although such feature-driven SVM is an extremely strong performer and hardly to be transcended, its \"sparse\" and \"discrete\" characteristics make it clumsy in taking into account of side information like relations between sentences.", "labels": [], "entities": []}, {"text": "Recently, exploit neural networks to learn continuous document representation from data.", "labels": [], "entities": []}, {"text": "Essentially, they use local ngram information and do not capture semantic relations between sentences.", "labels": [], "entities": []}, {"text": "Furthermore, a person asked to do this task will naturally carry it out in a sequential, bottom-up fashion, analyze the meanings of sentences before considering semantic relations between them.", "labels": [], "entities": []}, {"text": "This motivates us to develop an end-to-end and bottom-up algorithm to effectively model document representation.", "labels": [], "entities": [{"text": "document representation", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.6677533984184265}]}, {"text": "In this paper, we introduce a neural network approach to learn continuous document representation for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.9441275894641876}]}, {"text": "The method is on the basis of the principle of compositionality, which states that the meaning of a longer expression (e.g. a sentence or a docu-: The neural network model for document level sentiment classification.", "labels": [], "entities": [{"text": "document level sentiment classification", "start_pos": 176, "end_pos": 215, "type": "TASK", "confidence": 0.7253684103488922}]}, {"text": "w n i stands for the i-th word in the n-th sentence, l n is sentence length.", "labels": [], "entities": []}, {"text": "ment) depends on the meanings of its constituents.", "labels": [], "entities": []}, {"text": "Specifically, the approach models document representation in two steps.", "labels": [], "entities": [{"text": "document representation", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.7054589539766312}]}, {"text": "In the first step, it uses convolutional neural network (CNN) or long short-term memory (LSTM) to produce sentence representations from word representations.", "labels": [], "entities": []}, {"text": "Afterwards, gated recurrent neural network is exploited to adaptively encode semantics of sentences and their inherent relations in document representations.", "labels": [], "entities": []}, {"text": "These representations are naturally used as features to classify the sentiment label of each document.", "labels": [], "entities": []}, {"text": "The entire model is trained end-to-end with stochastic gradient descent, where the loss function is the cross-entropy error of supervised sentiment classification 2 . We conduct document level sentiment classification on four large-scale review datasets from IMDB 3 and Yelp Dataset Challenge . We compare to neural network models such as paragraph vector (), convolutional neural network, and baselines such as feature-based SVM (), recommendation algorithm JMARS ().", "labels": [], "entities": [{"text": "supervised sentiment classification", "start_pos": 127, "end_pos": 162, "type": "TASK", "confidence": 0.6893816192944845}, {"text": "document level sentiment classification", "start_pos": 178, "end_pos": 217, "type": "TASK", "confidence": 0.684458926320076}, {"text": "IMDB 3", "start_pos": 259, "end_pos": 265, "type": "DATASET", "confidence": 0.8456560373306274}, {"text": "Yelp Dataset Challenge", "start_pos": 270, "end_pos": 292, "type": "DATASET", "confidence": 0.9306111534436544}]}, {"text": "Experimental results show that: (1) the proposed neural model shows superior performances overall baseline algorithms; (2) gated recurrent neural network dramatically outperforms standard recurrent neural A similar work can be found at: http: //deeplearning.net/tutorial/lstm.html 3 http://www.imdb.com/ 4 http://www.yelp.com/dataset_challenge network in document modeling.", "labels": [], "entities": []}, {"text": "The main contributions of this work are as follows: \u2022 We present a neural network approach to encode relations between sentences in document representation for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.9428849816322327}]}, {"text": "\u2022 We report empirical results on four large-scale datasets, and show that the approach outperforms state-of-the-art methods for document level sentiment classification.", "labels": [], "entities": [{"text": "document level sentiment classification", "start_pos": 128, "end_pos": 167, "type": "TASK", "confidence": 0.7492795363068581}]}, {"text": "\u2022 We report empirical results that traditional recurrent neural network is weak in modeling document composition, while adding neural gates dramatically improves the classification performance.", "labels": [], "entities": [{"text": "modeling document composition", "start_pos": 83, "end_pos": 112, "type": "TASK", "confidence": 0.6953165133794149}]}], "datasetContent": [{"text": "We conduct experiments to empirically evaluate our method by applying it to document level sentiment classification.", "labels": [], "entities": [{"text": "document level sentiment classification", "start_pos": 76, "end_pos": 115, "type": "TASK", "confidence": 0.7388062179088593}]}, {"text": "We describe experimental settings and report empirical results in this section.", "labels": [], "entities": []}, {"text": "We) and M SE ( as evaluation metrics, where accuracy is a standard metric to measure the overall sentiment classification performance.", "labels": [], "entities": [{"text": "SE", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.6976883411407471}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9984304308891296}, {"text": "sentiment classification", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.8947445750236511}]}, {"text": "We use MSE to measure the divergences between predicted sentiment labels and ground truth sentiment labels because review labels reflect sentiment strengths (e.g. one star means strong negative and five star means strong positive).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistical information of Yelp 2013/2014/2015 and IMDB datasets. #docs is the number of  documents, #s/d and #w/d represent average number of sentences and average number of words contained  in per document, |V | is the vocabulary size of words, #class is the number of classes.", "labels": [], "entities": [{"text": "Yelp 2013/2014/2015", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.9554011722405752}, {"text": "IMDB datasets", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.923530638217926}]}, {"text": " Table 2: Sentiment classification on Yelp 2013/2014/2015 and IMDB datasets. Evaluation metrics are  accuracy (higher is better) and MSE (lower is better). The best method in each setting is in bold.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9416662454605103}, {"text": "Yelp 2013/2014/2015", "start_pos": 38, "end_pos": 57, "type": "DATASET", "confidence": 0.9631151556968689}, {"text": "IMDB datasets", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9296139478683472}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9992890357971191}, {"text": "MSE", "start_pos": 133, "end_pos": 136, "type": "METRIC", "confidence": 0.9937537312507629}]}, {"text": " Table 3: Sentiment classification on IMDB, Yelp 2013/2014/2015 datasets. Evaluation metrics are accu- racy (higher is better) and MSE (lower is better). The best method in each setting is in bold.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9471387267112732}, {"text": "IMDB", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.9468451738357544}, {"text": "Yelp 2013/2014/2015 datasets", "start_pos": 44, "end_pos": 72, "type": "DATASET", "confidence": 0.9280361362865993}, {"text": "accu- racy", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9471047520637512}, {"text": "MSE", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.8434754610061646}]}]}