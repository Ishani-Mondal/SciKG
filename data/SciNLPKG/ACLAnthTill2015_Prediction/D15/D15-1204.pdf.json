{"title": [{"text": "CORE: Context-Aware Open Relation Extraction with Factorization Machines", "labels": [], "entities": [{"text": "Context-Aware Open Relation Extraction", "start_pos": 6, "end_pos": 44, "type": "TASK", "confidence": 0.6897689178586006}]}], "abstractContent": [{"text": "We propose CORE, a novel matrix fac-torization model that leverages contextual information for open relation extraction.", "labels": [], "entities": [{"text": "open relation extraction", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.6767724951108297}]}, {"text": "Our model is based on factorization machines and integrates facts from various sources, such as knowledge bases or open information extractors, as well as the context in which these facts have been observed.", "labels": [], "entities": []}, {"text": "We argue that integrating contex-tual information-such as metadata about extraction sources, lexical context, or type information-significantly improves prediction performance.", "labels": [], "entities": []}, {"text": "Open information extractors, for example, may produce extractions that are unspecific or ambiguous when taken out of context.", "labels": [], "entities": [{"text": "Open information extractors", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6752662658691406}]}, {"text": "Our experimental study on a large real-world dataset indicates that CORE has significantly better prediction performance than state-of-the-art approaches when contextual information is available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Open relation extraction (open RE) is the task of extracting new facts fora potentially unbounded set of relations from various sources such as knowledge bases or natural language text.", "labels": [], "entities": [{"text": "Open relation extraction (open RE) is the task of extracting new facts fora potentially unbounded set of relations from various sources such as knowledge bases or natural language text", "start_pos": 0, "end_pos": 184, "type": "Description", "confidence": 0.7490386664867401}]}, {"text": "The task is closely related to targeted information extraction (IE), which aims to populate a knowledge base (KB) with new facts for the KB's relations, such as wasBornIn(Sepp Herberger, Mannheim).", "labels": [], "entities": [{"text": "targeted information extraction (IE)", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.8670683105786642}]}, {"text": "Existing methods either reason within the KB itself ( or leverage large text corpora to learn patterns that are indicative of KB relations ().", "labels": [], "entities": []}, {"text": "In both cases, targeted IE methods are inherently limited to an (often small) set of predefined relations, i.e., they are not \"open\".", "labels": [], "entities": [{"text": "IE", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9732139706611633}]}, {"text": "The open RE task is also related to open information extraction (open IE) (, which extracts large amounts of surface relations and their arguments from natural language text; e.g., \"critizices\"(\"Dante\", \"Catholic Church\").", "labels": [], "entities": [{"text": "open information extraction", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6676080524921417}]}, {"text": "Although open IE is a domain-independent approach, the extracted surface relations are purely syntactic and often ambiguous or noisy.", "labels": [], "entities": []}, {"text": "Moreover, open IE methods usually do not \"predict\" facts that have not been explicitly observed in the input data.", "labels": [], "entities": [{"text": "IE", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9672994017601013}]}, {"text": "Open RE combines the above tasks by predicting new facts for an open set of relations.", "labels": [], "entities": [{"text": "Open RE", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.5337512791156769}]}, {"text": "The key challenge in open RE is to reason jointly over the universal schema consisting of KB relations and surface relations (.", "labels": [], "entities": [{"text": "RE", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.7665076851844788}]}, {"text": "A number of matrix or tensor factorization models have recently been proposed in the context of relation extraction ().", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.8633760809898376}]}, {"text": "These models use the available data to learn latent semantic representations of entities (or entity pairs) and relations in a domain-independent way; the latent representations are subsequently used to predict new facts.", "labels": [], "entities": []}, {"text": "Existing models often focus on either targeted IE or open RE.", "labels": [], "entities": []}, {"text": "Targeted models are used for within-KB reasoning; they rely on the closed-world assumption and often do not scale with the number of relations.", "labels": [], "entities": []}, {"text": "Open RE models use the open-world assumption, which is more suitable for the open RE task because the available data is often highly incomplete.", "labels": [], "entities": []}, {"text": "In this paper, we propose CORE, a novel open RE factorization model that incorporates and exploits contextual information to improve prediction performance.", "labels": [], "entities": [{"text": "CORE", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9032339453697205}]}, {"text": "Consider for example the sentence \"Tom Peloso joined Modest Mouse to record their fifth studio album\".", "labels": [], "entities": []}, {"text": "Open IE systems may extract the surface fact \"join\"(TP, MM) from this sentence.", "labels": [], "entities": []}, {"text": "Note that surface relation \"join\" is unspecific; in this case, it refers to becoming a member of a music band (as opposed to, say, an employee of a company).", "labels": [], "entities": []}, {"text": "Most existing open RE systems use the extracted surface fact for further reasoning, but they ignore the context from which the fact was extracted.", "labels": [], "entities": []}, {"text": "We argue in this paper that exploiting contextual information is beneficial for open RE.", "labels": [], "entities": [{"text": "open RE", "start_pos": 80, "end_pos": 87, "type": "TASK", "confidence": 0.5825905203819275}]}, {"text": "For our example, we may use standard NLP tools like a named entity recognizer to detect that TP is a person and MM an organization.", "labels": [], "entities": []}, {"text": "These coarsegrained types give us hints about the domain and range of the \"join\" relation for the surface fact, although the actual meaning of \"join\" still remains opaque.", "labels": [], "entities": []}, {"text": "Now imagine that the above sentence was extracted from a newspaper article published in the music section.", "labels": [], "entities": []}, {"text": "This information can help to infer that \"join\" indeed refers to joining a band.", "labels": [], "entities": []}, {"text": "Other contextual information, such as the words \"record\" and \"album\" that occur in the sentence, further strengthen this interpretation.", "labels": [], "entities": []}, {"text": "A contextaware open RE system should leverage such information to accurately predict facts like \"is band member of\"(TP, MM) and \"plays with\"(TP, MM).", "labels": [], "entities": []}, {"text": "Note that the prediction of the fact \"is band member of\"(TP, MM) is facilitated if we make use of a KB that knows that TP is a musician and MM is a music band.", "labels": [], "entities": []}, {"text": "If TP and/or MM are not present in the knowledge base, however, such a reasoning does not apply.", "labels": [], "entities": []}, {"text": "In our work, we consider both linked entities (in-KB) and non-linked entity mentions (out of-KB).", "labels": [], "entities": []}, {"text": "Since KB are often incomplete, this open approach to handle named entities allows us to extract facts for all entities, even if they do not appear in the KB.", "labels": [], "entities": []}, {"text": "In this paper, we propose CORE, a flexible open RE model that leverages contextual information.", "labels": [], "entities": []}, {"text": "CORE is inspired by the combined factorization and entity model (FE) of.", "labels": [], "entities": [{"text": "CORE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6943301558494568}, {"text": "FE", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9180647134780884}]}, {"text": "As FE, CORE associates latent semantic representations with entities, relations, and arguments.", "labels": [], "entities": [{"text": "FE", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.9413782954216003}]}, {"text": "In contrast to FE, CORE uses factorization machines as its underlying framework, which allows us to incorporate context in a flexible way.", "labels": [], "entities": [{"text": "FE", "start_pos": 15, "end_pos": 17, "type": "DATASET", "confidence": 0.4594365656375885}]}, {"text": "CORE is able to leverage and integrate arbitrary contextual information associated with the input facts into its open RE factorization model.", "labels": [], "entities": [{"text": "CORE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8541188836097717}]}, {"text": "To support reasoning under the openworld assumption, we propose an efficient method for parameter estimation in factorization machines based on Bayesian personalized ranking.", "labels": [], "entities": []}, {"text": "We conducted an experimental study on a realworld dataset using contextual information along the lines mentioned above.", "labels": [], "entities": []}, {"text": "Our model is extensible, i.e., additional contextual information can be integrated when available.", "labels": [], "entities": []}, {"text": "Even with limited amount of contextual information used in our experiments, our CORE model provided higher prediction performance than previous models.", "labels": [], "entities": []}, {"text": "Our findings validate the usefulness of contextual information for the open RE task.", "labels": [], "entities": [{"text": "RE task", "start_pos": 76, "end_pos": 83, "type": "TASK", "confidence": 0.8892211019992828}]}], "datasetContent": [{"text": "We conducted an experimental study on realworld data to compare our CORE model with other state-of-the-art approaches.", "labels": [], "entities": []}, {"text": "Our experimental study closely follows the one of.", "labels": [], "entities": []}, {"text": "We made use of the dataset of, but extended it with contextual information.", "labels": [], "entities": []}, {"text": "The dataset consisted of 2.5M surface facts extracted from the New York Times corpus, as well as 16k facts from Freebase.", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.8769597262144089}, {"text": "Freebase", "start_pos": 112, "end_pos": 120, "type": "DATASET", "confidence": 0.965451717376709}]}, {"text": "Surface facts have been obtained by using a named-entity recognizer, which additionally labeled each named entity mention with its coarse-grained type (i.e., person, organization, location, miscellaneous).", "labels": [], "entities": []}, {"text": "For each pair of entities found within a sentence, the shortest dependency path between these pairs was taken as surface relation.", "labels": [], "entities": []}, {"text": "The entity mentions in each surface fact were linked to Freebase using a simple string matching: True facts and MAP 100 # (in parentheses) in the top-100 evaluation-set tuples for Freebase relations.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9765489101409912}, {"text": "MAP 100 #", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9377110401789347}]}, {"text": "We consider as context the article metadata (m), the tuple types (t) and the bag-of-words (w).", "labels": [], "entities": []}, {"text": "Best value per relation in bold (unique winner) or italic (multiple winners).", "labels": [], "entities": []}, {"text": "Average weighs are # column values. method.", "labels": [], "entities": []}, {"text": "If no match was found, the entity mention was kept as is.", "labels": [], "entities": []}, {"text": "There were around 2.2M tuples (distinct entity pairs) in this dataset, out of which 580k were fully linked to Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9797596335411072}]}, {"text": "For each of these tuples, the dataset additionally included all of the corresponding facts from Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.9614284038543701}]}, {"text": "Using the metadata 3 of each New York Times article, we enriched each surface fact by the following contextual information: news desk (e.g., sports desk, foreign desk), descriptors (e.g., finances, elections), online section (e.g., sports, business), section (e.g., a, d), publication year, and bag-of-words of the sentence from which the surface fact has been extracted.", "labels": [], "entities": []}, {"text": "From the raw dataset described above, we filtered out all surface relations with less than 10 instances, and all tuples with less than two instances, as in.", "labels": [], "entities": []}, {"text": "1 summarizes statistics of the resulting dataset.", "labels": [], "entities": []}, {"text": "Here we considered a factor tuple as linked if both of its entities were linked to Freebase, as partiallylinked if only one of its entities was linked, and as non-linked otherwise.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.9846653342247009}]}, {"text": "In contrast to previous work (), we retain partially-linked and non-linked facts in our dataset.", "labels": [], "entities": []}, {"text": "3 Further information can be found at htps:// catalog.ldc.upenn.edu/LDC2008T19.", "labels": [], "entities": []}, {"text": "Open RE models produce predictions for all relations and all tuples.", "labels": [], "entities": []}, {"text": "To keep the experimental study feasible and comparable to previous studies, we use the full training data but evaluate each model's predictions on only the subsample of 10k tuples (\u2248 6% of all tuples) of.", "labels": [], "entities": []}, {"text": "The subsample consisted of 20% linked, 40% partially-linked and 40% non-linked tuples.", "labels": [], "entities": []}, {"text": "For each (surface) relation and method, we predicted the top-100 new facts (not in training) for the tuples in the subsample.", "labels": [], "entities": []}, {"text": "We compared various forms of our CORE model with PITF and the matrix factorization model NFE.", "labels": [], "entities": [{"text": "PITF", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.7353801727294922}]}, {"text": "Our study focused on these two factorization models because they outperformed other models (including nonfactorization models) in previous studies ().", "labels": [], "entities": []}, {"text": "All models were trained with the full training data described above.", "labels": [], "entities": []}, {"text": "PITF is a recent tensor factorization method designed for within-KB reasoning.", "labels": [], "entities": [{"text": "PITF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7203078866004944}]}, {"text": "PITF is based on factorization machines so that we used our scalable CORE implementation for training the model.", "labels": [], "entities": [{"text": "PITF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9098764061927795}]}, {"text": "NFE is the full model proposed in the \"universal schema\" work of: True facts and MAP 100 # (in parentheses) in the top-100 evaluation-set tuples for surface relations.", "labels": [], "entities": [{"text": "NFE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8981034755706787}, {"text": "MAP 100 #", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.8410406510035197}]}, {"text": "We consider as context the article metadata (m), the tuple types (t) and the bag-of-words (w).", "labels": [], "entities": []}, {"text": "Best value per relation in bold (unique winner) or italic (multiple winners).", "labels": [], "entities": []}, {"text": "Average weighs are # column values.", "labels": [], "entities": []}, {"text": "model (N), a matrix factorization model (F), and an entity model (E).", "labels": [], "entities": []}, {"text": "The F and E models together are similar (but not equal) to our CORE model without context.", "labels": [], "entities": []}, {"text": "The NFE model outperformed tensor models ( ) as well as clustering methods and distantly supervised methods in the experimental study of for open RE tasks.", "labels": [], "entities": []}, {"text": "We use the original source code of for training.", "labels": [], "entities": []}, {"text": "We include multiple variants of our model in the experimental study, each differing by the amount of context being used.", "labels": [], "entities": []}, {"text": "We consider as context the article metadata (m), the tuple types (t) and the bag-of-words (w).", "labels": [], "entities": []}, {"text": "Each tuple type is a pair of subject-object types of (e.g. (person, location)).", "labels": [], "entities": []}, {"text": "The basic CORE model uses relations, tuples and entities as variables.", "labels": [], "entities": []}, {"text": "We additionally consider the CORE+t, CORE+w, CORE+mt, and CORE+mtw models, where the suffix indicates which contextual information has been included.", "labels": [], "entities": []}, {"text": "The total number of variables in the resulting models varied between 300k (CORE) to 350k (CORE+mtw).", "labels": [], "entities": [{"text": "CORE", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9345893859863281}, {"text": "CORE+mtw", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.8988844354947408}]}, {"text": "We used a modified version of libfm for training.", "labels": [], "entities": []}, {"text": "Our version adds support for BPR and parallelizes the training algorithm.", "labels": [], "entities": [{"text": "BPR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.4421241879463196}]}, {"text": "To evaluate the prediction performance of each method, we followed.", "labels": [], "entities": []}, {"text": "We considered a collection of 19 Freebase relations (Tab. 2) and 10 surface relations (Tab.", "labels": [], "entities": []}, {"text": "3) and restrict predictions to tuples in the evaluation set.", "labels": [], "entities": []}, {"text": "For each relation and method, we computed the top-100 evaluation set predictions and labeled them manually.", "labels": [], "entities": []}, {"text": "We used 4 http://www.libfm.org as evaluation metrics the mean average precision defined as: where indicator I k takes value 1 if the k-th prediction is true and 0 otherwise, and # denotes the number of true tuples for the relation in the top-100 predictions of all models.", "labels": [], "entities": [{"text": "mean average precision", "start_pos": 57, "end_pos": 79, "type": "METRIC", "confidence": 0.696742574373881}]}, {"text": "The denominator is included to account for the fact that the evaluation set may include less than 100 true facts.", "labels": [], "entities": []}, {"text": "MAP 100 # reflects how many true facts are found by each method as well as their ranking.", "labels": [], "entities": [{"text": "MAP 100", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7521568238735199}]}, {"text": "If all # facts are found and ranked top, then MAP 100 # = 1.", "labels": [], "entities": [{"text": "MAP 100 #", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.8237806757291158}]}, {"text": "Note that our definition of MAP 100 # differs slightly from; our metric is more robust because it is based on completely labeled evaluation data.", "labels": [], "entities": []}, {"text": "To compare the prediction performance of each system across multiple relations, we averaged MAP 100 # values, in both an unweighted and a weighted (by #) fashion.", "labels": [], "entities": [{"text": "MAP 100 #", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9376049637794495}]}, {"text": "For all systems, we used d = 100 latent factors, \u03bb = 0.01 for all variables, a constant learning rate of \u03b7 = 0.05, and ran 1000 epochs of stochastic gradient ascent.", "labels": [], "entities": []}, {"text": "These choices correspond to the ones of; no further tuning was performed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: True facts and MAP 100  # (in parentheses) in the top-100 evaluation-set tuples for Freebase rela- tions. We consider as context the article metadata (m), the tuple types (t) and the bag-of-words (w). Best  value per relation in bold (unique winner) or italic (multiple winners). Average weighs are # column  values.", "labels": [], "entities": []}, {"text": " Table 3: True facts and MAP 100  # (in parentheses) in the top-100 evaluation-set tuples for surface relations.  We consider as context the article metadata (m), the tuple types (t) and the bag-of-words (w). Best value  per relation in bold (unique winner) or italic (multiple winners). Average weighs are # column values.", "labels": [], "entities": []}]}