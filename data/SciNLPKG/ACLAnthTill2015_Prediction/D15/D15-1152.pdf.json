{"title": [{"text": "Improving Arabic Diacritization through Syntactic Analysis", "labels": [], "entities": [{"text": "Improving Arabic Diacritization", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9107328255971273}, {"text": "Syntactic Analysis", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.9226875603199005}]}], "abstractContent": [{"text": "We present an approach to Arabic automatic diacritization that integrates syntactic analysis with morphological tagging through improving the prediction of case and state features.", "labels": [], "entities": [{"text": "Arabic automatic diacritization", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.5546494623025259}]}, {"text": "Our best system increases the accuracy of word diacritization by 2.5% absolute on all words, and 5.2% absolute on nominals over a state-of-the-art baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9993658661842346}, {"text": "word diacritization", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.6807377636432648}]}, {"text": "Similar increases are shown on the full morphological analysis choice.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information.", "labels": [], "entities": []}, {"text": "The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics.", "labels": [], "entities": []}, {"text": "Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (), speech synthesis (), and machine translation (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.7915626466274261}, {"text": "speech synthesis", "start_pos": 158, "end_pos": 174, "type": "TASK", "confidence": 0.7666084468364716}, {"text": "machine translation", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.8123289346694946}]}, {"text": "Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms.", "labels": [], "entities": []}, {"text": "observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final).", "labels": [], "entities": []}, {"text": "They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses.", "labels": [], "entities": []}, {"text": "In this paper, we develop an approach for improving the quality of automatic Arabic diacritization through the use of automatic syntactic analysis.", "labels": [], "entities": []}, {"text": "Our approach combines handwritten rules for case assignment and agreement with machine learning of case and state adjustment on the output of a state-of-the-art morphological tagger.", "labels": [], "entities": [{"text": "case assignment", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.8242998123168945}]}, {"text": "Our best system increases the accuracy of word diacrtization by 2.5% absolute overall, and 5.2% absolute on nominals over a state-of-the-art baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9993703961372375}, {"text": "word diacrtization", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.6723014265298843}]}], "datasetContent": [{"text": "We present next our experimental results and compare five case-state prediction techniques.", "labels": [], "entities": [{"text": "case-state prediction", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7673574984073639}]}, {"text": "The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches.", "labels": [], "entities": []}, {"text": "Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) () split into Train, Dev and (blind) Test along the recommendations of which were also used in the baseline system.", "labels": [], "entities": [{"text": "Penn Arabic Treebank (PATB", "start_pos": 17, "end_pos": 43, "type": "DATASET", "confidence": 0.9495690107345581}]}, {"text": "The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems).", "labels": [], "entities": [{"text": "PATB analyses", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.7955658435821533}, {"text": "MADA", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.8052254915237427}]}, {"text": "We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing.", "labels": [], "entities": []}, {"text": "The Test set has 63K words.", "labels": [], "entities": [{"text": "Test set", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9251955449581146}]}, {"text": "Evaluation Metrics We report our accuracy in terms of two metrics: a.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9976953864097595}]}, {"text": "Diac, the percentage of correctly fully diacrtized words; and b.", "labels": [], "entities": []}, {"text": "All, the percentage of words for which a full morphological analysis (lemma, POS, all inflectional and clitic features, and diacritization) is correctly predicted.", "labels": [], "entities": [{"text": "POS", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9386603832244873}]}, {"text": "We report the results on all words (All Words) as well as on nominals with no u casein the gold (henceforth, Nominals).", "labels": [], "entities": []}, {"text": "We do not report on case and state prediction accuracy, nor on the character-level diacritization.", "labels": [], "entities": [{"text": "case and state prediction", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.6040264517068863}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.8743933439254761}]}], "tableCaptions": [{"text": " Table 1: Results on DevTest.", "labels": [], "entities": [{"text": "DevTest", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.8910757899284363}]}, {"text": " Table 2: Results on the blind Test set.", "labels": [], "entities": [{"text": "blind Test set", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7889410952727}]}]}