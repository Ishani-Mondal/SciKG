{"title": [{"text": "Joint Event Trigger Identification and Event Coreference Resolution with Structured Perceptron", "labels": [], "entities": [{"text": "Joint Event Trigger Identification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6762408390641212}, {"text": "Event Coreference Resolution", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.7988324562708536}]}], "abstractContent": [{"text": "Events and their coreference offer useful semantic and discourse resources.", "labels": [], "entities": []}, {"text": "We show that the semantic and discourse aspects of events interact with each other.", "labels": [], "entities": []}, {"text": "However, traditional approaches addressed event extraction and event coref-erence resolution either separately or sequentially , which limits their interactions.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.8143046200275421}, {"text": "event coref-erence resolution", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.609053909778595}]}, {"text": "This paper proposes a document-level structured learning model that simultaneously identifies event triggers and resolves event coreference.", "labels": [], "entities": [{"text": "resolves event coreference", "start_pos": 113, "end_pos": 139, "type": "TASK", "confidence": 0.6029808620611826}]}, {"text": "We demonstrate that the joint model outperforms a pipelined model by 6.9 BLANC F1 and 1.8 CoNLL F1 points in event coreference resolution using a corpus in the biology domain.", "labels": [], "entities": [{"text": "BLANC F1", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9863167405128479}, {"text": "CoNLL F1 points", "start_pos": 90, "end_pos": 105, "type": "METRIC", "confidence": 0.9056849280993143}, {"text": "event coreference resolution", "start_pos": 109, "end_pos": 137, "type": "TASK", "confidence": 0.7834647099177042}]}], "introductionContent": [{"text": "Events convey semantic information such as who did what to whom where and when.", "labels": [], "entities": []}, {"text": "They also corefer to each other, playing a role of discourse connection points to form a coherent story.", "labels": [], "entities": []}, {"text": "These aspects of events have been already utilized in a wide variety of natural language processing (NLP) applications, such as automated population of knowledge bases (Ji and Grishman, 2011), topic detection and tracking, question answering (), text summarization (), and contradiction detection (.", "labels": [], "entities": [{"text": "topic detection and tracking", "start_pos": 193, "end_pos": 221, "type": "TASK", "confidence": 0.8866090476512909}, {"text": "question answering", "start_pos": 223, "end_pos": 241, "type": "TASK", "confidence": 0.8894561529159546}, {"text": "text summarization", "start_pos": 246, "end_pos": 264, "type": "TASK", "confidence": 0.7675703167915344}, {"text": "contradiction detection", "start_pos": 273, "end_pos": 296, "type": "TASK", "confidence": 0.7230017483234406}]}, {"text": "This fact illustrates the importance of event extraction and event coreference resolution.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.8412163555622101}, {"text": "event coreference resolution", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8493304451306661}]}, {"text": "Those semantic and discourse aspects of events are not independent from each other, and in fact often work in interactive manners.", "labels": [], "entities": []}, {"text": "We give two examples of the interactions: (1) British bank Barclays had agreed to buy(E1) Spanish rival Banco Zaragozano for 1.14 billion euros.", "labels": [], "entities": [{"text": "British bank Barclays", "start_pos": 46, "end_pos": 67, "type": "DATASET", "confidence": 0.8796279430389404}]}, {"text": "The combination(E2) of the banking operations of Barclays Spain and Zaragozano will bring together two complementary businesses.", "labels": [], "entities": [{"text": "Barclays Spain", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.8600472807884216}]}, {"text": "(2) The Palestinian Authority condemned the attack(E3), saying it(E4) would divert international sympathy away from the far higher Palestinian civilian death toll.", "labels": [], "entities": []}, {"text": "E1 corefers to E2, and E3 does to E4.", "labels": [], "entities": []}, {"text": "E2 is more abstract than E1, and has less evidence of being an event.", "labels": [], "entities": [{"text": "E2", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8243862986564636}]}, {"text": "E4 is a pronoun, and thus may seem to refer to an entity rather than an event.", "labels": [], "entities": []}, {"text": "Thus, E2 and E4 are relatively difficult to be recognized as events by themselves.", "labels": [], "entities": []}, {"text": "However, event coreference E1-E2, which is supported primarily by E2's participants Barclays and Zaragozano shared with E1, helps determine that E2 is an event.", "labels": [], "entities": [{"text": "Barclays", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.8808865547180176}]}, {"text": "The same logic applies to E3 and E4.", "labels": [], "entities": []}, {"text": "On the other hand, previous works typically rely on a pipelined model that extracts events (e.g., E1 and E3) at the first stage, and then resolves event coreference at the second stage.", "labels": [], "entities": []}, {"text": "Although this modularity is preferable from development perspectives, the pipelined model limits the interactions.", "labels": [], "entities": []}, {"text": "That is, the first stage alone is unlikely to detect E2 and E4 as events due to the difficulties described above.", "labels": [], "entities": []}, {"text": "These missing events make it impossible for the second stage to resolve event coreference E1-E2 and E3-E4.", "labels": [], "entities": []}, {"text": "In this work, we address the problem using the ProcessBank corpus).", "labels": [], "entities": [{"text": "ProcessBank corpus", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.8791216909885406}]}, {"text": "Following the terminology defined in the corpus, we introduce several terms: \u2022 Event: an abstract representation of a change of state, independent from particular texts.", "labels": [], "entities": []}, {"text": "\u2022 Event trigger: main word(s) in text, typically a verb or a noun that most clearly expresses an event.", "labels": [], "entities": []}, {"text": "\u2022 Event arguments: participants or attributes in text, typically nouns, that are involved in an event.", "labels": [], "entities": []}, {"text": "\u2022 Event mention: a clause in text that describes an event, and includes both a trigger and arguments.", "labels": [], "entities": []}, {"text": "\u2022 Event coreference: a linguistic phenomenon that two event mentions refer to the same event.", "labels": [], "entities": [{"text": "Event coreference", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.7231874614953995}]}, {"text": "We aim to explore the interactions between event mentions and event coreference.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.6304107457399368}]}, {"text": "As a first step toward the goal, we focus on the task of identifying event triggers and resolving event coreference, and propose a document-level joint learning model using structured perceptron) that simultaneously predicts them.", "labels": [], "entities": []}, {"text": "Our assumption is that the joint model is able to capture the interactions between event triggers and event coreference adequately, and such comprehensive decision improves the system performance.", "labels": [], "entities": []}, {"text": "For instance, the joint model is likely to extract E2 as well as E1 successfully via their event coreference by simultaneously looking at coreference features.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: 1.", "labels": [], "entities": []}, {"text": "This is the first work that simultaneously predicts event triggers and event coreference using a single joint model.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.6871538907289505}]}, {"text": "At the core of the model is a document-level structured perceptron algorithm that learns event triggers and event coreference jointly.", "labels": [], "entities": []}, {"text": "2. The incremental token-based prediction in joint decoding poses a challenge of synchronizing the assignments of event triggers and coreference.", "labels": [], "entities": []}, {"text": "To avoid this problem, we propose an incremental decoding algorithm that combines the segment-based decoding and best-first clustering algorithm.", "labels": [], "entities": []}, {"text": "3. Our experiments indicate that the joint model achieves a substantial performance gain in event coreference resolution with a corpus in the biology domain, as compared to a pipelined model.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 92, "end_pos": 120, "type": "TASK", "confidence": 0.8348835905392965}]}], "datasetContent": [{"text": "When training our model, we observed that 20-iteration training almost reached convergence, and thus we set the number of iterations to 20.", "labels": [], "entities": [{"text": "convergence", "start_pos": 79, "end_pos": 90, "type": "METRIC", "confidence": 0.9829234480857849}]}, {"text": "We set l max to 6 because we observed that the longest event trigger in the entire ProcessBank corpus has six tokens.", "labels": [], "entities": [{"text": "ProcessBank corpus", "start_pos": 83, "end_pos": 101, "type": "DATASET", "confidence": 0.8792335689067841}]}, {"text": "When tuning beam width k on the development set, large beam width did not give us a significant performance difference.", "labels": [], "entities": []}, {"text": "We attribute this result to the small size of the development data.", "labels": [], "entities": []}, {"text": "In particular, the development data has only 28 event coreferences, which makes it difficult to reveal the effect of beam width.", "labels": [], "entities": []}, {"text": "We thus set k to 1 in our experiments.", "labels": [], "entities": []}, {"text": "We evaluate our system using a reference implementation of coreference scoring algorithms ( ).", "labels": [], "entities": [{"text": "coreference scoring", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.8697068989276886}]}, {"text": "As for event trigger identification, this scorer computes precision (P), recall (R), and the F1 score.", "labels": [], "entities": [{"text": "event trigger identification", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.7128156820933024}, {"text": "precision (P)", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.9594870656728745}, {"text": "recall (R)", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.971043199300766}, {"text": "F1 score", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9872909486293793}]}, {"text": "With respect to event coreference resolution, the scorer computes MUC (", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.8118897875150045}, {"text": "MUC", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9409272074699402}]}], "tableCaptions": [{"text": " Table 1: Statistics of our dataset.", "labels": [], "entities": []}, {"text": " Table 2: Results of event coreference resolution. 'Baseline' refers to the second stage of our baseline.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.7662713726361593}]}, {"text": " Table 2. The joint model  outperforms the baseline by 6.9 BLANC F1 and  1.8 CoNLL F1 points. We observed that this over- all performance gain comes largely from a preci- sion gain, more specifically, substantially reduced  false positives. We explain the superiority of the  joint model as follows. In the baseline, the second  stage uses the output of the first stage. Since event  triggers are fixed at this point, the baseline ex- plores coreference links only between these event  triggers. In contrast, the joint model seeks event  triggers and event coreference simultaneously, and  thus it explores a larger number of false positives  in the search process, thereby learning to penalize  false positives more adequately than the baseline.", "labels": [], "entities": [{"text": "BLANC F1", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9708964824676514}, {"text": "CoNLL F1", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.8721998631954193}]}, {"text": " Table 3: Results of event trigger identification.  'Baseline' refers to the first stage of our baseline.", "labels": [], "entities": [{"text": "event trigger identification", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6208402613798777}]}]}