{"title": [], "abstractContent": [{"text": "ListNet is a well-known listwise learning to rank model and has gained much attention in recent years.", "labels": [], "entities": []}, {"text": "A particular problem of ListNet, however, is the high computation complexity in model training, mainly due to the large number of object permutations involved in computing the gradients.", "labels": [], "entities": []}, {"text": "This paper proposes a stochastic ListNet approach which computes the gradient within a bounded permutation subset.", "labels": [], "entities": []}, {"text": "It significantly reduces the computation complexity of model training and allows extension to Top-k models, which is impossible with the conventional implementation based on full-set permutations.", "labels": [], "entities": []}, {"text": "Meanwhile, the new approach utilizes partial ranking information of human labels , which helps improve model quality.", "labels": [], "entities": []}, {"text": "Our experiments demonstrated that the s-tochastic ListNet method indeed leads to better ranking performance and speeds up the model training remarkably.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning to rank aims to learn a model to rerank a list of objects, e.g., candidate documents in document retrieval.", "labels": [], "entities": []}, {"text": "Recent studies show that listwise learning delivers better performance in general than traditional pairwise learning, partly attributed to its capability of learning human-labelled scores as a full rank list.", "labels": [], "entities": []}, {"text": "A potential disadvantage of listwise learning, however, is the high computation complexity in model training, which is mainly caused by the large number of permutations of the objects to rank.", "labels": [], "entities": []}, {"text": "A typical listwise learning method is the ListNet model proposed by.", "labels": [], "entities": []}, {"text": "This model has been utilized to tackle many ranking problems, e.g. modeling the hiring behavior in online labor markets (, ranking sentences in document summarization (, improving detection of musical concepts ( and ranking the results in video search.", "labels": [], "entities": [{"text": "ranking sentences in document summarization", "start_pos": 123, "end_pos": 166, "type": "TASK", "confidence": 0.5771872520446777}]}, {"text": "Basically, ListNet implements the rank function as a neural network (NN), with the objective function set to be the cross entropy between two probability distributions over the object permutations, one derived from the human-labelled scores and the other derived from the model prediction (network output).", "labels": [], "entities": []}, {"text": "In order to deal with the high computation complexity associated with the large number of permutations, proposed a Top-k approach, which clusters the permutations by the first k objects, so the number of distinct probabilities that need to evaluate in model training reduces from n!", "labels": [], "entities": []}, {"text": "(n\u2212k)!", "labels": [], "entities": []}, {"text": ", where n is the number of objects in the list.", "labels": [], "entities": []}, {"text": "To ensure efficiency, k = 1 was selected in the seminal paper and in the open source implementation of RankLib.", "labels": [], "entities": [{"text": "RankLib", "start_pos": 103, "end_pos": 110, "type": "DATASET", "confidence": 0.9267815947532654}]}, {"text": "This Top-1 approach is a harsh approximation to the full listwise learning and may constrain the power of the ListNet method.", "labels": [], "entities": []}, {"text": "We therefore seek to extend the Top-1 approximation to Top-k ( k > 1) models.", "labels": [], "entities": []}, {"text": "The major obstacle for the Top-k extension is the large number of permutations, or more precisely, permutation classes in the Top-k setting.", "labels": [], "entities": []}, {"text": "A key idea of this paper is that the rank information involved in the permutation classes is highly redundant and so a small number such permutation classes are sufficient to convey the rank information required to train the model.", "labels": [], "entities": []}, {"text": "Meanwhile, the partial rank information associated with the subset of permutation classes may represent more detailed knowledge for model training, leading to better ListNet models.", "labels": [], "entities": []}, {"text": "Based on these two conjectures, we propose a stochastic ListNet method, which samples a subset of the permutation classes (object lists) in model training and based on this subset to train the ListNet model.", "labels": [], "entities": []}, {"text": "Three methods are proposed to conduct the sampling.", "labels": [], "entities": []}, {"text": "In the uniform distribution method, the candidate objects are selected following a uniform distribution; in the fixed distribution method, the candidate objects are selected following a distribution derived from the human-labeled scores; in the adaptive distribution method, the candidates are selected following a distribution defined by the rank function, i.e., the neural network output.", "labels": [], "entities": []}, {"text": "Experimental results demonstrated that the stochastic ListNet method can significantly reduce the computation cost in model training.", "labels": [], "entities": []}, {"text": "In fact, if the size of the permutation subset is fixed, the computation complexity is bounded, which allows training Top-k models where k is large.", "labels": [], "entities": []}, {"text": "Meanwhile, better performance was obtained with the stochastic ListNet approach, probably due to the learning of partial rank information.", "labels": [], "entities": []}, {"text": "The contributions of the paper are three-fold: (1) proposes a stochastic ListNet method that significantly reduces the training complexity and delivers better ranking performance; (2) investigates Top-k models based on the stochastic ListNet, and studies the impact of a large k; (3) provides an open source implementation based on RankLib.", "labels": [], "entities": [{"text": "RankLib", "start_pos": 332, "end_pos": 339, "type": "DATASET", "confidence": 0.9431438446044922}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces some related works, and Section 3 presents the stochastic ListNet method.", "labels": [], "entities": []}, {"text": "Section 4 presents the experiments, and the paper is concluded by Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we consider Top-k models where k = 1, 2, 3, and 4.", "labels": [], "entities": []}, {"text": "Although any k is possible with the proposed stochastic ListNet, we will show that simply increasing the model order k does not improve performance.", "labels": [], "entities": []}, {"text": "The P@1 and P@10 performance is used as the evaluation metric.", "labels": [], "entities": [{"text": "P@1", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9500707387924194}, {"text": "P@10 performance", "start_pos": 12, "end_pos": 28, "type": "METRIC", "confidence": 0.8579908162355423}]}, {"text": "Specially, for all the three distribution sampling methods, the sampling process involves two steps: pre-selection and re-sampling.", "labels": [], "entities": []}, {"text": "The preselection step samples a list of documents following three distributions mentioned above, and in the re-sampling step, document lists including more relevant documents are retained with a higher probability.", "labels": [], "entities": []}, {"text": "For example, denoting the preselected document list by (v 1 ,v 2 ,...,v k ) where k is the length of the list, and denoting the corresponding human-labelled scores by (s 1 , s 2 ,...,s k ), the probability that the list is retained is given by where S is the maximum value of the humanlabelled scores, which is 2 in our case.", "labels": [], "entities": []}, {"text": "The resampling approach is designed to encourage document lists containing more relevant documents, which is the most important for the uniform distribution sampling.", "labels": [], "entities": []}, {"text": "In stochastic Top-k ListNet, the learning rate is set as 10 \u22123 fork = 1, and 10 \u22125 fork > 1.", "labels": [], "entities": []}, {"text": "These values are set to achieve the best performance on the validation set.", "labels": [], "entities": []}, {"text": "Another important parameter of the stochastic Top-k ListNet approach is the number of samples of the document lists (or the size of subset of permutation classes selected), denoted by l.", "labels": [], "entities": []}, {"text": "Various settings of l are experimented within this study.", "labels": [], "entities": []}, {"text": "To eliminate randomness in the results, all the experiments are repeated 20 times and the averaged performance is reported.", "labels": [], "entities": []}, {"text": "The P@1 results on the test dataset with different orders of Top-k ListNet are reported in to.", "labels": [], "entities": [{"text": "P@1", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8540505170822144}]}, {"text": "In each figure, the number of document lists varies from 5 to 500.", "labels": [], "entities": []}, {"text": "For comparison,   the results with the conventional ListNet are also presented.", "labels": [], "entities": [{"text": "ListNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9535092115402222}]}, {"text": "Note that the re-sampling approach was not applied to the Top-1 model as we found it caused performance reduction.", "labels": [], "entities": []}, {"text": "This is perhaps because the sampling space is small with the Top-1 model, and so re-sampling tends to cause overemphasis on relevant documents.", "labels": [], "entities": []}, {"text": "From these results, we first observe that stochastic ListNet with either fixed or adaptive distribution sampling tends to outperform the conventional ListNet approach, particularly with a large k.", "labels": [], "entities": []}, {"text": "This confirms our argument that rank information can be learned from a subset of the permutation classes that are randomly selected, and the partial rank learning can lead to even better performance than the full rank learning, the case of conventional ListNet.", "labels": [], "entities": []}, {"text": "This is an interesting result and demonstrates the stochastic ListNet is both faster and better than the conventional ListNet.", "labels": [], "entities": []}, {"text": "It is also seen that the adaptive distribution sampling performs slightly better than the fixed distribution sampling.", "labels": [], "entities": []}, {"text": "This is not surprising as the adaptive distribution sampling uses a more reasonable relevance score (neural network output) to balance relevant and irrelevant documents.", "labels": [], "entities": []}, {"text": "The uniform distribution sampling performs a little worse than the other two sampling methods, probably caused by the less informative uniform distribution.", "labels": [], "entities": []}, {"text": "Another observation is that in all the four figures, the performance of the stochastic ListNet methods increases with more samples of the object lists.", "labels": [], "entities": []}, {"text": "However if there are too many samples, the performance starts to decrease.", "labels": [], "entities": []}, {"text": "This can be explained by the fact that the sampling prefers relevant documents which are more informative.", "labels": [], "entities": []}, {"text": "A larger sample set often includes more informative documents; however if the set is too large, many irrelevant documents will be selected and the performance is reduced.", "labels": [], "entities": []}, {"text": "In the case that the number of samples is very large (500 for example for Top-1), the stochastic ListNet falls back to the conventional ListNet, and their performance becomes similar.", "labels": [], "entities": []}, {"text": "Comparing the results with different k, it can be seen that a larger k leads to a better performance with stochastic ListNet.", "labels": [], "entities": []}, {"text": "This confirms that high-order Top-k models can learn more ranking information.", "labels": [], "entities": []}, {"text": "However, this is not necessarily the case with the conventional ListNet.", "labels": [], "entities": [{"text": "ListNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9432992339134216}]}, {"text": "For example, the Top-2 model does not offer better performance than the Top-1 model.", "labels": [], "entities": []}, {"text": "This is perhaps because high-order Top-k models consider a large number of document lists and most of them are not informative, which leads to ineffective learning.", "labels": [], "entities": []}, {"text": "Remind that the conventional ListNet is a special case of the stochastic ListNet with a very large sample set, and we have discussed that an overlarge sample set actually reduces performance.", "labels": [], "entities": []}, {"text": "The averaged training time and the performance in precession are presented in.", "labels": [], "entities": [{"text": "precession", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9129028916358948}]}, {"text": "For precession, both P@1 and P@10 results are reported, though we focus on P@1 since it is more concerned for applications such as QA.", "labels": [], "entities": [{"text": "P@1", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9077087044715881}]}, {"text": "Note that for stochastic ListNet, the optimal number of samples (document lists) has been selected according to the P@1 performance on the validate set.", "labels": [], "entities": []}, {"text": "From these results, it can be seen that the conventional Top-1 ListNet is rather fast, however the Top-2 model is thousands of times slower.", "labels": [], "entities": [{"text": "Top-1 ListNet", "start_pos": 57, "end_pos": 70, "type": "DATASET", "confidence": 0.9077287912368774}]}, {"text": "With k > 2, the training time becomes prohibitive and so they are not listed in the Table.", "labels": [], "entities": []}, {"text": "This is expected since the conventional ListNet considers the full set of permutations which is a huge number with a large k.", "labels": [], "entities": []}, {"text": "With the stochastic ListNet, the training time is dramatically reduced.", "labels": [], "entities": []}, {"text": "Even with a large k, the computation cost is still manageable, because the computation is mostly determined by the number of object lists, rather than the value of k.", "labels": [], "entities": []}, {"text": "When comparing the three sampling methods, it can be found the convergence speed of the uniform distribution approach is the slowest, probably due to the ineffective selection for relevant documents.", "labels": [], "entities": [{"text": "convergence", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9439676403999329}]}, {"text": "The adaptive distribution sampling is the fastest, probably attributed to the collaborative update of the model and the distribution.", "labels": [], "entities": []}, {"text": "As for the P@1 performance, the stochastic ListNet method generally outperforms its nonstochastic counterpart, particularly with the adaptive distribution sampling.", "labels": [], "entities": []}, {"text": "For example, the best P@1 results obtained on the test data with the stochastic Top-1 ListNet is 0.4127, which outperforms the conventional Top-1 ListNet (0.4119).", "labels": [], "entities": []}, {"text": "This advantage of stochastic ListNet, as we argued, is largely attributed to its capability of learning partial rank information with samples of partial sequences of the rank list.", "labels": [], "entities": []}, {"text": "Comparing the results with different k values, it can be seen that a larger k tends to offer better P@1 performance on the training set, with either the conventional ListNet or the stochastic ListNet.", "labels": [], "entities": []}, {"text": "For example, with the conventional ListNet, the results are 0.4101 vs. 0.4119 with the Top-1 and Top-2 models respectively.", "labels": [], "entities": [{"text": "ListNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9322909116744995}]}, {"text": "However, the performance gap is rather marginal, and the advantage with the large k does not propagate to the results on the test data (as has been seen in and).", "labels": [], "entities": []}, {"text": "This indicates that for the conventional ListNet, the Top-1 model is not the only choice in the sense of computation complexity, but also the best choice in the sense of P@1 performance.", "labels": [], "entities": []}, {"text": "For stochastic ListNet, the performance improves with k increases.", "labels": [], "entities": []}, {"text": "In contrast to the conventional ListNet, this improvement propagates to the results on the test data.", "labels": [], "entities": [{"text": "ListNet", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.9232771396636963}]}, {"text": "For example, with the adaptive distribution sampling, the P@1 results on the training set are 0.4102 vs. 0.4184 with the Top-1 and Top-3 models respectively, and the results on the test data are 0.4121 vs. 0.4177 respectively.", "labels": [], "entities": [{"text": "P@1", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.8996861378351847}]}, {"text": "Nevertheless, the P@1 performance improvement with a large k is rather marginal, and an overlarge k simply reduces the performance.", "labels": [], "entities": []}, {"text": "To make it clear, we vary the value of k from 1 to 100 and plot the P@1 results in).", "labels": [], "entities": []}, {"text": "It can be seen that larger k (> 4) does not offer any merit but causes performance instability, particu- larly with the adaptive sampling approach.", "labels": [], "entities": []}, {"text": "As we have discussed, with the stochastic ListNet, partial rank information can be learned with simple Top-k models, even the Top-1 model.", "labels": [], "entities": []}, {"text": "This capability of partial rank learning with simple models reduces the necessity of employing complex Top-k models.", "labels": [], "entities": []}, {"text": "This is a highly valuable conclusion, and it suggests that a simple Top-1 or Top-2 model is sufficient for the ListNet method, if the stochastic method is applied.", "labels": [], "entities": []}, {"text": "Considering the trade-off between computation cost and model strength, we recommend stochastic Top-2 ListNet which delivers better P@1 performance than the Top-1 model consistently, with sufficiently fast computing.", "labels": [], "entities": []}, {"text": "If more computation is affordable, stochastic Top-3 ListNet can be used to obtain better performance.", "labels": [], "entities": []}, {"text": "Finally, we highlight that the conclusions ob-  tained from the P@1 results and the P@10 results perfectly match.", "labels": [], "entities": []}, {"text": "In fact, the P@10 results look more consistent between training and test data, and the advantage of the stochastic approach seems more clear, particularly with the adaptive sampling.", "labels": [], "entities": []}, {"text": "This is not surprising as the optimization goal of ListNet is essentially to form a good rank that involves multiple candidates, and so P@10 is apt to measure the superiority of a better rank approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Averaged training time (in seconds), P@1 and P@10 on training, validation (Val.) and test  data with different Top-k methods. 'C-ListNet' stands for conventional ListNet, 'S-ListNet' stands for  stochastic ListNet.", "labels": [], "entities": [{"text": "Averaged training time", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8333714008331299}, {"text": "P@1", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9729504187901815}, {"text": "validation (Val.)", "start_pos": 73, "end_pos": 90, "type": "METRIC", "confidence": 0.661333754658699}]}]}