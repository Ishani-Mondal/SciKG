{"title": [{"text": "A Comparative Study on Regularization Strategies for Embedding-based Neural Networks", "labels": [], "entities": [{"text": "Regularization Strategies", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.9371829926967621}, {"text": "Embedding-based Neural Networks", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.6011301775773367}]}], "abstractContent": [{"text": "This paper aims to compare different reg-ularization strategies to address a common phenomenon, severe overfitting, in embedding-based neural networks for NLP.", "labels": [], "entities": []}, {"text": "We chose two widely studied neu-ral models and tasks as our testbed.", "labels": [], "entities": []}, {"text": "We tried several frequently applied or newly proposed regularization strategies, including penalizing weights (embeddings excluded), penalizing embeddings, re-embedding words, and dropout.", "labels": [], "entities": []}, {"text": "We also emphasized on incremental hyperparame-ter tuning, and combining different regu-larizations.", "labels": [], "entities": []}, {"text": "The results provide a picture on tuning hyperparameters for neural NLP models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural networks have exhibited considerable potential in various fields (.", "labels": [], "entities": []}, {"text": "In early years on neural NLP research, neural networks were used in language modeling (; recently, they have been applied to various supervised tasks, such as named entity recognition, sentiment analysis, relation classification (, etc.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7145290225744247}, {"text": "named entity recognition", "start_pos": 159, "end_pos": 183, "type": "TASK", "confidence": 0.6285873552163442}, {"text": "sentiment analysis", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.9219322502613068}, {"text": "relation classification", "start_pos": 205, "end_pos": 228, "type": "TASK", "confidence": 0.8706109821796417}]}, {"text": "In the field of NLP, neural networks are typically combined with word embeddings, which are usually first pretrained by unsupervised algorithms like; then they are fed forward to standard neural models, fine-tuned during supervised learning.", "labels": [], "entities": []}, {"text": "However, embedding-based neural networks usually suffer from severe overfitting because of the high dimensionality of parameters.", "labels": [], "entities": []}, {"text": "A curious question is whether we can regularize embedding-based NLP neural models to improve generalization.", "labels": [], "entities": []}, {"text": "Although existing and newly proposed regularization methods might alleviate the problem, their inherent performance in neural NLP models is not clear: the use of embeddings is sparse; the behaviors maybe different from those in other scenarios like image recognition.", "labels": [], "entities": [{"text": "image recognition", "start_pos": 249, "end_pos": 266, "type": "TASK", "confidence": 0.7464738488197327}]}, {"text": "Further, selecting hyperparameters to pursue the best performance by validation is extremely timeconsuming, as suggested in.", "labels": [], "entities": []}, {"text": "Therefore, new studies are needed to provide a more complete picture regarding regularization for neural natural language processing.", "labels": [], "entities": [{"text": "neural natural language processing", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.6578604876995087}]}, {"text": "Specifically, we focus on the following research questions in this paper.", "labels": [], "entities": []}, {"text": "RQ 1: How do different regularization strategies typically behave in embedding-based neural networks?", "labels": [], "entities": [{"text": "RQ", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.5479444861412048}]}, {"text": "RQ 2: Can regularization coefficients be tuned incrementally during training so as to ease the burden of hyperparameter tuning?", "labels": [], "entities": []}, {"text": "RQ 3: What is the effect of combining different regularization strategies?", "labels": [], "entities": [{"text": "RQ", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.522544264793396}]}, {"text": "In this paper, we systematically and quantitatively compared four different regularization strategies, namely penalizing weights, penalizing embeddings, newly proposed word re-embedding (, and dropout).", "labels": [], "entities": []}, {"text": "We analyzed these regularization methods by two widely studied models and tasks.", "labels": [], "entities": []}, {"text": "We also emphasized on incremental hyperparameter tuning and the combination of different regularization methods.", "labels": [], "entities": []}, {"text": "Our experiments provide some interesting results: (1) Regularizations do help generalization, but their effect depends largely on the datasets' size.", "labels": [], "entities": [{"text": "generalization", "start_pos": 78, "end_pos": 92, "type": "TASK", "confidence": 0.9787196516990662}]}, {"text": "(2) Penalizing 2 -norm of embeddings helps optimization as well, improving training accuracy unexpectedly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9908084273338318}]}, {"text": "(3) Incremental hyperparameter tuning achieves similar performance, indicat-ing that regularizations mainly serve as a \"local\" effect.", "labels": [], "entities": []}, {"text": "(4) Dropout performs slightly worse than 2 penalty in our experiments; however, provided very small 2 penalty, dropping out hidden units and penalizing 2 -norm are generally complementary.", "labels": [], "entities": []}, {"text": "The newly proposed re-embedding words method is not effective in our experiments.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy in percentage when we com- bine 2 -norm of weights and embeddings (Exper- iment I). Bold numbers are among highest accu- racies (greater than peak performance minus 1.5  times standard deviation, i.e., 1.26 in percentage).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994515776634216}, {"text": "Exper- iment I", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.9271355420351028}, {"text": "accu- racies", "start_pos": 134, "end_pos": 146, "type": "METRIC", "confidence": 0.9658639033635458}]}, {"text": " Table 2: Combining 2 regularization and dropout.  Left: connectional weights. Right: embeddings.  (p refers to the dropout rate.)", "labels": [], "entities": []}]}