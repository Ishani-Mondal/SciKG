{"title": [{"text": "Discourse parsing for multi-party chat dialogues", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7591253221035004}, {"text": "multi-party chat dialogues", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6507876416047415}]}], "abstractContent": [{"text": "In this paper we present the first ever, to the best of our knowledge, discourse parser for multi-party chat dialogues.", "labels": [], "entities": [{"text": "discourse parser", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.728652149438858}]}, {"text": "Discourse in multi-party dialogues dramatically differs from monologues since threaded conversations are commonplace rendering prediction of the discourse structure compelling.", "labels": [], "entities": []}, {"text": "Moreover, the fact that our data come from chats renders the use of syntactic and lexical information useless since people take great liberties in expressing themselves lexically and syntactically.", "labels": [], "entities": []}, {"text": "We use the dependency parsing paradigm as has been done in the past (Muller et al., 2012; Li et al., 2014).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9038437604904175}]}, {"text": "We learn local probability distributions and then use MST for decoding.", "labels": [], "entities": [{"text": "MST", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8044778108596802}]}, {"text": "We achieve 0.680 F 1 on unlabelled structures and 0.516 F 1 on fully labeled structures which is better than many state of the art systems for monologues, despite the inherent difficulties that multi-party chat dialogues have.", "labels": [], "entities": [{"text": "F 1", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9829034507274628}, {"text": "F 1", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9862882196903229}]}], "introductionContent": [{"text": "Discourse parsing is a difficult, multifaceted problem involving the understanding and modeling of various semantic and pragmatic phenomena as well as understanding the structural properties that a discourse graph can have.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8603505194187164}]}, {"text": "Unsurprisingly, most extant theories and computational approaches postulate an extremely simplified version of discourse structure.", "labels": [], "entities": []}, {"text": "One of the most widely cited theories, Rhetorical Structure Theory (RST)), requires that only adjacent discourse units be connected together with a discourse relation.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST))", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.8187490304311117}]}, {"text": "Another widely cited approach, the Penn Discourse Treebank (PDTB), focuses on decisions about the discourse connectives that label the attachment of potentially arbitrary text spans but does not make any claims as to what the overall discourse structure of the resulting annotation looks like.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB)", "start_pos": 35, "end_pos": 65, "type": "DATASET", "confidence": 0.9399230678876241}]}, {"text": "Further, all computational work on the PDTB takes the attachments as given in discourse parsing tasks.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7106496244668961}]}, {"text": "In both cases, the attachment problem, finding which discourse units are attached to which, is vastly simplified, though this has enabled researchers to explore various approaches for discourse parsing).", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 184, "end_pos": 201, "type": "TASK", "confidence": 0.7077722996473312}]}, {"text": "Our paper's main contribution is to provide a discourse parsing model for multi-party chat dialogue (i.e. typed online dialogue), trained on a large corpus we have developed annotated with full discourse structures.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7204217612743378}, {"text": "multi-party chat dialogue (i.e. typed online dialogue)", "start_pos": 74, "end_pos": 128, "type": "TASK", "confidence": 0.6277218129899766}]}, {"text": "We study attachment problem in detail for this genre, without using the simplifying hypotheses mentioned above that we know to be inadequate.", "labels": [], "entities": []}, {"text": "In the following section, we describe the Settlers of Catan game and our corpus in more detail and discuss some problematic structures for discourse parsing from our corpus.", "labels": [], "entities": [{"text": "Settlers of Catan game", "start_pos": 42, "end_pos": 64, "type": "DATASET", "confidence": 0.697828859090805}, {"text": "discourse parsing", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.7131559252738953}]}, {"text": "We motivate our choice of a particular discourse theory, the Segmented Discourse Representation Theory (SDRT), as the underlying theoretical model for our annotations.", "labels": [], "entities": [{"text": "Segmented Discourse Representation Theory (SDRT)", "start_pos": 61, "end_pos": 109, "type": "TASK", "confidence": 0.7806940845080784}]}, {"text": "In section 4 we present our parsing approach, which consists of building a local probability distribution model which serves as input to a series of decoder mechanisms.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9796995520591736}]}, {"text": "We present and discuss the results we obtain in section 5, while related work and conclusions are presented in sections 6 and 7 respectively.", "labels": [], "entities": []}, {"text": "a person might pose a question that concerns all the participants; and once everybody has replied, that same person might reply to all of them with a single comment (e.g. thanking them) or with a single acknowledgment.", "labels": [], "entities": []}, {"text": "provides an example from our corpus.", "labels": [], "entities": []}, {"text": "In turn 234, gotwood4sheep asks a question and makes an underspecified offer to all the players.", "labels": [], "entities": []}, {"text": "He then gets back negative responses to his question from inca, CheshireCatGrin and dmm; and then he broadcasts in 239 an acknowledgment of all the negative responses.", "labels": [], "entities": [{"text": "CheshireCatGrin", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.9566468000411987}]}, {"text": "The presence of such structures makes a powerful case that the general framework guiding the annotation of multi-party dialogues should take non-tree-like graphs as the basic form of discourse structures.", "labels": [], "entities": []}, {"text": "This will require then rethinking the task of discourse parsing when attempting to learn such structures.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7319256514310837}]}, {"text": "In particular, the following questions present themselves: 1) how many non-treelike structures are there?", "labels": [], "entities": []}, {"text": "2) what are the constraints on discourse graphs, if they are not trees?", "labels": [], "entities": []}, {"text": "3) how far can traditional tree-based decoding mechanisms get us in dealing with such data?", "labels": [], "entities": []}, {"text": "Another complicated phenomenon in multiparty chat dialogues is the presence of crossing dependencies.", "labels": [], "entities": []}, {"text": "Many theories of discourse structure like RST, given that they allow attachment only of adjacent spans will perforce not allow structures with crossing dependencies.", "labels": [], "entities": [{"text": "RST", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9542517066001892}]}, {"text": "Also theories that postulate a simple right frontier constraint, according to which only elements on the right frontier of a discourse structure (whether graph or tree) will in general not generate structures with crossing dependencies.", "labels": [], "entities": []}, {"text": "However, crossing dependencies are commonplace in multi-party chat.", "labels": [], "entities": []}, {"text": "Several subgroups of interlocutors can and do momentarily form and carry on a discussion amongst themselves, forming thus multiple concurrent discussion threads.", "labels": [], "entities": []}, {"text": "Since, though, what is being written is publicly available to all involved parties, it can be the case that participants of one thread might reply or comment to something said to another thread.", "labels": [], "entities": []}, {"text": "contains an example from our corpus.", "labels": [], "entities": []}, {"text": "There are at least three threads in this excerpt, and we have given them different fonts to aid the reader.", "labels": [], "entities": []}, {"text": "The intuitive attachments in this excerpt involve the following crossing dependencies:,,,,,, and.", "labels": [], "entities": []}, {"text": "We note also the lack of standard discourse markers such as those found in the PDTB or RST manuals, \"personalized\" orthography, the lack of elaborate syntactic structure and the frequent presence of sentence fragments, all of which means we cannot rely on sentential syntax to aid with discourse parsing (syntax is very useful in monologue discourse parsing, as witnessed by the dramatically higher scores for intra-sentential discourse parsing ().", "labels": [], "entities": [{"text": "PDTB or RST manuals", "start_pos": 79, "end_pos": 98, "type": "DATASET", "confidence": 0.7188649028539658}, {"text": "discourse parsing", "start_pos": 286, "end_pos": 303, "type": "TASK", "confidence": 0.7279928922653198}, {"text": "monologue discourse parsing", "start_pos": 330, "end_pos": 357, "type": "TASK", "confidence": 0.6526851753393809}, {"text": "intra-sentential discourse parsing", "start_pos": 410, "end_pos": 444, "type": "TASK", "confidence": 0.760075310866038}]}, {"text": "Multi-party dialogue presents a discourse parsing problem free of syntactic crutches.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7428179085254669}]}, {"text": "The phenomena we have just described are just some of the complications that appear in the discourse representation of multi-party dialogues, unfortunately rendering discourse theories based on attaching only adjacent units unsuitable for the representation of multi-party dialogues.", "labels": [], "entities": []}, {"text": "In order to be able to capture the discourse phenomena present in our chat corpus, we have decided to use the Segmented Discourse Representation Theory (SDRT)).", "labels": [], "entities": []}, {"text": "This theory not only allows long distance attachments, which (Ginzburg, 2012) finds attested in multilogue, but also has semantics capable of dealing with fragments or non sentential utterances, which are frequent in our corpus.", "labels": [], "entities": []}, {"text": "Also, it can model non-tree like structures, like that shown in, which account for at least 9% of the links in our corpus.", "labels": [], "entities": []}, {"text": "Such structures make theories that model discourse structures with rooted trees, like Rhetorical Structure Theory (RST) or simple dialogue models where attachments are always made to  Clearly, th's two turns combine to form a CDU that is then related by a conditional discourse relation to I do.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 86, "end_pos": 119, "type": "TASK", "confidence": 0.789427787065506}]}, {"text": "That is you give mean ore and or a wood form together the antecedent to the conditional that he expresses.", "labels": [], "entities": []}, {"text": "In order to reflect this semantic dependency, SDRT creates collections of Elementary Discourse Units (EDUs) forming a coherent discourse unit (called Complex Discourse Unit, CDU) and link it to any other discourse unit.", "labels": [], "entities": []}, {"text": "The end result of this process is the creation of a hypergraph or, equivalently, a graph with two types of edges.", "labels": [], "entities": []}, {"text": "Thus, our general conception of a discourse structure fora discourse D = {e 1 , . .", "labels": [], "entities": []}, {"text": ", en }, where where V is a set of nodes or discourse units including {e 1 , . .", "labels": [], "entities": []}, {"text": ", en }, E 1 \u2286 V \u00d7 Va set of edges representing discourse relations and E 2 \u2286 V \u00d7 Va set of edges that represents parthood in the sense that if (x, y) \u2208 E 2 , then x is a discourse unit that is an element of the CDU y.", "labels": [], "entities": []}, {"text": ": E 1 \u2192 Relations is a function that assigns each arc a discourse relation type.", "labels": [], "entities": []}, {"text": "Our corpus contains many instances of CDUs, some of which are quite large, encompassing an entire question answering session like that seen in.", "labels": [], "entities": [{"text": "question answering session", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.8014892935752869}]}], "datasetContent": [{"text": "To train our local models, we extracted features for every pair of EDUs in a given dialogue.", "labels": [], "entities": []}, {"text": "Our features concern the pair of EDUs as well as features related to each EDU specifically.", "labels": [], "entities": []}, {"text": "The feature set, detailed in, can be summarized as follows: \u2022 Positional features: (related to) the nonlinguistic context of the pair; \u2022 Lexical features: single words 3 and punctuation present in the EDUs; \u2022 Parsing features: dependency 4 and dialogue act 5 tagging.", "labels": [], "entities": [{"text": "dialogue act 5 tagging", "start_pos": 244, "end_pos": 266, "type": "TASK", "confidence": 0.5233349204063416}]}, {"text": "shows our results on our unseen test corpus, which contains a randomly selected 10% of dialogues in our corpus.", "labels": [], "entities": []}, {"text": "The best configuration was selected after performing ten-fold cross validation on the training corpus.", "labels": [], "entities": []}, {"text": "The reported results implement the turn-constraint during training for the local models.", "labels": [], "entities": []}, {"text": "In other words, training instances for the local models include only forward links.", "labels": [], "entities": []}, {"text": "The first one, Last, simply attaches every EDU to its previous one.", "labels": [], "entities": []}, {"text": "This is a very strong baseline in discourse parsing, for example).", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.6964491903781891}]}, {"text": "The second baseline is essentially the local classifier without any further decoding; in other words, we simply select the class with the highest probability both for attachment and labeling.", "labels": [], "entities": []}, {"text": "Attaching to last gives us an F-score of 0.584 for attachment and 0.391 when we add the relations as well.", "labels": [], "entities": [{"text": "F-score", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9987485408782959}]}, {"text": "Using only classification from the local probability distribution without decoding gives 0.541 for attachment and 0.446 for attachments and relations.", "labels": [], "entities": []}, {"text": "The best results for the global parsing problem exploited the turn constraint both during learning the local model and during decoding.", "labels": [], "entities": [{"text": "global parsing", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.5735819339752197}]}, {"text": "Within a turn, our discourse structures are simple and largely linear; the best intra-turn results came from using Last.", "labels": [], "entities": []}, {"text": "Most of our interlocutors did not create elaborate discourse structures with long-distance attachments within the same turn.", "labels": [], "entities": []}, {"text": "The inter-turn level was a different story, as the figures show.", "labels": [], "entities": []}, {"text": "For inter-turn and the global problem, MST using the heads of the intra-turn substructures computed with Last, produced the best results.", "labels": [], "entities": [{"text": "MST", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9602988362312317}]}, {"text": "The F1 score for unlabeled structures is at 0.671 while for labelled structures we have 0.516.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9844294190406799}]}, {"text": "To enable a comparison with RST style parsing where exact arguments for discourse relations are not computed, the undirected attachment F1 score = 0.68 for the global parsing problem.", "labels": [], "entities": [{"text": "RST style parsing", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.9079567392667135}, {"text": "undirected attachment F1 score", "start_pos": 114, "end_pos": 144, "type": "METRIC", "confidence": 0.6342598721385002}, {"text": "global parsing", "start_pos": 160, "end_pos": 174, "type": "TASK", "confidence": 0.6593540608882904}]}, {"text": "Despite the inherent difficulty of discourse parsing on multi-party chat dialogues (simultaneous, multiple discussion threads, lack of syntax) our results are close to or better than the current state of the art for discourse parsing on monologue.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.6839434504508972}, {"text": "discourse parsing on monologue", "start_pos": 216, "end_pos": 246, "type": "TASK", "confidence": 0.7994189709424973}]}, {"text": "There are two approaches currently that use dependency parsing strategies for discourse, thoroughly described in the next section.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8285886645317078}]}, {"text": "report an accuracy of 0.7506 for unlabelled structures and 0.4309 for the full labelled structures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995844960212708}]}, {"text": "report 0.662 for unlabelled structure and 0.361 for labelled structures.", "labels": [], "entities": []}, {"text": "We outperform both systems for full labelled structures, and despite our non-tree-like structures beat or are close to these on unlabelled attachments.", "labels": [], "entities": []}, {"text": "Though comparisons across different corpora are difficult, the numbers suggest that our results are more than competitive.", "labels": [], "entities": []}, {"text": "Our results also suggest that one can get quite far with tree-based decoding algorithms, though we know that in principle MST cannot do better than 91% even with a perfect local model (a model in which an arc is giving probability 1 just in case it occurs in the gold standard annotation).", "labels": [], "entities": []}], "tableCaptions": []}