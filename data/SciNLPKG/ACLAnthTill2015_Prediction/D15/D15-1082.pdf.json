{"title": [{"text": "Modeling Relation Paths for Representation Learning of Knowledge Bases", "labels": [], "entities": [{"text": "Modeling Relation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9170421361923218}, {"text": "Representation Learning of Knowledge Bases", "start_pos": 28, "end_pos": 70, "type": "TASK", "confidence": 0.9145105600357055}]}], "abstractContent": [{"text": "Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space.", "labels": [], "entities": [{"text": "Representation learning of knowledge bases", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.9309296250343323}]}, {"text": "Most existing methods only consider direct relations in representation learning.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.931960940361023}]}, {"text": "We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model.", "labels": [], "entities": []}, {"text": "This model considers relation paths as translations between entities for representation learning , and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 73, "end_pos": 96, "type": "TASK", "confidence": 0.9110502898693085}]}, {"text": "(2) We represent relation paths via semantic composition of relation embeddings.", "labels": [], "entities": []}, {"text": "Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 145, "end_pos": 170, "type": "TASK", "confidence": 0.6006012757619222}, {"text": "relation extraction from text", "start_pos": 175, "end_pos": 204, "type": "TASK", "confidence": 0.8558692932128906}]}, {"text": "The source code of this paper can be obtained from https://github.com/mrlyk423/ relation_extraction.", "labels": [], "entities": []}], "introductionContent": [{"text": "People have recently built many large-scale knowledge bases (KBs) such as Freebase, DBpedia and YAGO.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.9692344665527344}, {"text": "DBpedia", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.8880451917648315}, {"text": "YAGO", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.7255120873451233}]}, {"text": "These KBs consist of facts about the real world, mostly in the form of triples, e.g., (Steve Jobs, FounderOf, Apple Inc.).", "labels": [], "entities": []}, {"text": "KBs are important resources for many applications such as question answering and Web search.", "labels": [], "entities": [{"text": "question answering", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9332939386367798}, {"text": "Web search", "start_pos": 81, "end_pos": 91, "type": "TASK", "confidence": 0.7671346962451935}]}, {"text": "Although typical KBs are large in size, usually containing thousands of relation types, millions of entities and billions of facts (triples), they are far from * Corresponding author: Z. complete.", "labels": [], "entities": []}, {"text": "Hence, many efforts have been invested in relation extraction to enrich KBs.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.9220422804355621}]}, {"text": "Recent studies reveal that, neural-based representation learning methods are scalable and effective to encode relational knowledge with lowdimensional representations of both entities and relations, which can be further used to extract unknown relational facts.) is atypical method in the neural-based approach, which learns vectors (i.e., embeddings) for both entities and relations.", "labels": [], "entities": []}, {"text": "The basic idea behind TransE is that, the relationship between two entities corresponds to a translation between the embeddings of the entities, that is, h + r \u2248 t when the triple (h, r, t) holds.", "labels": [], "entities": []}, {"text": "Since TransE has issues when modeling 1-to-N, N-to-1 and N-to-N relations, various methods such as TransH () and TransR ( are proposed to assign an entity with different representations when involved in various relations.", "labels": [], "entities": []}, {"text": "Despite their success in modeling relational facts, TransE and its extensions only take direct relations between entities into consideration.", "labels": [], "entities": []}, {"text": "It is known that there are also substantial multiple-step relation paths between entities indicating their semantic relationships.", "labels": [], "entities": []}, {"text": "The relation paths reflect complicated inference patterns among relations in KBs.", "labels": [], "entities": []}, {"text": "For example, the relation path h Nationality between hand t, i.e.,.", "labels": [], "entities": [{"text": "Nationality", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.9324445724487305}]}, {"text": "In this paper, we aim at extending TransE to model relation paths for representation learning of KBs, and propose path-based TransE (PTransE).", "labels": [], "entities": [{"text": "representation learning of KBs", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.7870796173810959}]}, {"text": "In PTransE, in addition to direct connected relational facts, we also build triples from KBs using entity pairs connected with relation paths.", "labels": [], "entities": [{"text": "PTransE", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.7939313054084778}]}, {"text": "As shown in, TransE only considers direct relations between entities, e.g., hr \u2212 \u2192 t, builds a triple (h, r, t), and optimizes the objec-tive h + r = t.", "labels": [], "entities": []}, {"text": "PTransE generalizes TransE by regarding multiple-step relation paths as connections between entities.", "labels": [], "entities": [{"text": "PTransE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7854689359664917}]}, {"text": "Take the 2-step path hr 1 \u2212 \u2192 e 1 r 2 \u2212 \u2192 t for example as shown in.", "labels": [], "entities": []}, {"text": "Besides building triples (h, r 1 , e 1 ) and (e 1 , r 2 , t) for learning as in TransE, PTransE also builds a triple (h, r 1 \u2022 r 2 , t), and optimizes the objective h + (r 1 \u2022 r 2 ) = t, where \u2022 is an operation to join the relations r 1 and r 2 together into a unified relation path representation.", "labels": [], "entities": [{"text": "PTransE", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.8449997901916504}]}, {"text": "As compared with TransE, PTransE takes rich relation paths in KBs for learning.", "labels": [], "entities": [{"text": "PTransE", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.5384753346443176}]}, {"text": "There are two critical challenges that make PTransE nontrivial to learn from relation paths: Relation Path Reliability.", "labels": [], "entities": []}, {"text": "Not all relation paths are meaningful and reliable for learning.", "labels": [], "entities": []}, {"text": "For example, there is often a relation path h Hence, it is inappropriate to consider all relation paths in our model.", "labels": [], "entities": []}, {"text": "In experiments, we find that those relation paths that lead to lots of possible tail entities are mostly unreliable for the entity pair.", "labels": [], "entities": []}, {"text": "In this paper, we propose a path-constraint resource allocation algorithm to measure the reliability of relation paths.", "labels": [], "entities": []}, {"text": "Afterwards, we select the reliable relation paths for representation learning.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.948430597782135}]}, {"text": "In order to take relation paths into consideration, relation paths should also be represented in a low-dimensional space.", "labels": [], "entities": []}, {"text": "It is straightforward that the semantic meaning of a relation path depends on all relations in this path.", "labels": [], "entities": []}, {"text": "Given a relation path p = (r 1 , . .", "labels": [], "entities": []}, {"text": ", r l ) , we will define and learn a binary operation function (\u2022) to obtain the path embedding p by recursively composing multiple relations, i.e., p = r 1 \u2022 . .", "labels": [], "entities": []}, {"text": "\u2022 r l . With relation path selection and representation, PTransE learns entity and relation embeddings by regarding relation paths as translations between the corresponding entities.", "labels": [], "entities": []}, {"text": "In experiments, we select atypical KB, Freebase, to build datasets and carryout evaluation on three tasks, including entity prediction, relation prediction and relation extraction from text.", "labels": [], "entities": [{"text": "entity prediction", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7281058579683304}, {"text": "relation prediction", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.8072891533374786}, {"text": "relation extraction from text", "start_pos": 160, "end_pos": 189, "type": "TASK", "confidence": 0.8513605296611786}]}, {"text": "Experimental results show that, PTransE significantly outperforms TransE and other baseline methods on all three tasks.", "labels": [], "entities": [{"text": "PTransE", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9442898035049438}]}], "datasetContent": [{"text": "We evaluate our method on atypical large-scale KB Freebase (.", "labels": [], "entities": [{"text": "KB Freebase", "start_pos": 47, "end_pos": 58, "type": "DATASET", "confidence": 0.93918177485466}]}, {"text": "In this paper, we adopt two datasets extracted from Freebase, i.e., FB15K and FB40K.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.9871352314949036}, {"text": "FB15K", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9404897689819336}, {"text": "FB40K", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.9621605277061462}]}, {"text": "The statistics of the datasets are listed in.", "labels": [], "entities": []}, {"text": "We evaluate the performance of PTransE and other baselines by predicting whether testing triples hold.", "labels": [], "entities": [{"text": "PTransE", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.511867344379425}]}, {"text": "We consider two scenarios: (1) Knowledge base completion, aiming to predict the missing entities or relations in given triples only based on existing KBs.", "labels": [], "entities": [{"text": "Knowledge base completion", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6876002351442972}]}, {"text": "(2) Relation extraction from texts, aiming to extract relations between entities based on information from both plain texts and KBs.", "labels": [], "entities": [{"text": "Relation extraction from texts", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.9553952366113663}]}], "tableCaptions": [{"text": " Table 1: Statistics of data sets.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results on entity prediction.", "labels": [], "entities": [{"text": "entity prediction", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.8205926716327667}]}, {"text": " Table 4: Evaluation results on relation prediction.", "labels": [], "entities": [{"text": "relation prediction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.9275695383548737}]}]}