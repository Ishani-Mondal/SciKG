{"title": [], "abstractContent": [{"text": "As conventional word alignment search algorithms usually ignore the consistency constraint in translation rule extraction, improving alignment accuracy does not necessarily increase translation quality.", "labels": [], "entities": [{"text": "word alignment search", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.8418922225634257}, {"text": "translation rule extraction", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.8706827362378439}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9340755939483643}]}, {"text": "We propose to use coverage, which reflects how well extracted phrases can recover the training data, to enable word alignment to model consistency and correlate better with machine translation.", "labels": [], "entities": [{"text": "coverage", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9770828485488892}, {"text": "word alignment", "start_pos": 111, "end_pos": 125, "type": "TASK", "confidence": 0.7677232027053833}, {"text": "machine translation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.716327577829361}]}, {"text": "This can be done by introducing an objective that maximizes both alignment model score and coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9936507344245911}]}, {"text": "We introduce an efficient algorithm to calculate coverage on the fly during search.", "labels": [], "entities": [{"text": "coverage", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9644606709480286}]}, {"text": "Experiments show that our consistency-aware search algorithm significantly outperforms both generative and discriminative alignment approaches across various languages and translation models.", "labels": [], "entities": [{"text": "generative and discriminative alignment", "start_pos": 92, "end_pos": 131, "type": "TASK", "confidence": 0.810542032122612}]}], "introductionContent": [{"text": "Word alignment, which aims to identify the correspondence between words in two languages, plays an important role in statistical machine translation.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.707674965262413}, {"text": "statistical machine translation", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.7364441951115926}]}, {"text": "Word alignment and translation rule extraction often constitute two consecutive steps in the training pipeline.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7573221325874329}, {"text": "translation rule extraction", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.9298995931943258}]}, {"text": "Wordaligned bilingual corpora serve as a fundamental resource for translation rule extraction, not only for phrase-based models (), but also for syntax-based models).", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.9214672247568766}]}, {"text": "Dividing alignment and extraction into two separate steps significantly improves the efficiency and scalability of parameter estimation as compared with directly learning translation models from bilingual * Corresponding author: Yang Liu.", "labels": [], "entities": []}, {"text": "However, separating word alignment from translation rule extraction suffers from a major problem: maximizing the accuracy of word alignment does not necessarily lead to the improvement of translation quality.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7505166232585907}, {"text": "translation rule extraction", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.8129277229309082}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9977832436561584}, {"text": "word alignment", "start_pos": 125, "end_pos": 139, "type": "TASK", "confidence": 0.6484602838754654}]}, {"text": "A number of studies show that alignment error rate (AER) only has a loose correlation with BLEU).", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 30, "end_pos": 56, "type": "METRIC", "confidence": 0.8854586283365885}, {"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9995177984237671}]}, {"text": "find that precision-oriented alignments result in better translation performance than recall-oriented alignments.", "labels": [], "entities": [{"text": "precision-oriented", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9570112824440002}]}, {"text": "show that using AER and balanced F-measure can only partially explain the effect of alignment quality on BLEU for several language pairs.", "labels": [], "entities": [{"text": "AER", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9944652915000916}, {"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9331774115562439}, {"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9956954717636108}]}, {"text": "We believe that the correlation problem arises from the discrepancy between word alignment and translation rule extraction.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.749629944562912}, {"text": "translation rule extraction", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.8718931277592977}]}, {"text": "On one hand, aligners seek to find the alignment with the highest alignment model score, without regard to structural constraints.", "labels": [], "entities": []}, {"text": "Consequently, sensible translation rules may not be extracted because they violate consistency constraints required by translation rule extraction ().", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 119, "end_pos": 146, "type": "TASK", "confidence": 0.7685783902804056}]}, {"text": "find that the standard alignment tools are not optimal for training syntax-based models.", "labels": [], "entities": []}, {"text": "As a result, they have to resort to realigning.", "labels": [], "entities": []}, {"text": "On the other hand, the consistency constraint used inmost translation rule extraction algorithms tolerate wrong links within consistent phrase pairs.", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.7626103361447653}]}, {"text": "uses the union of two unidirectional alignments, which usually has a low precision, for extracting hierarchical phrases.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9956444501876831}, {"text": "extracting hierarchical phrases", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.8401318391164144}]}, {"text": "Therefore, it is important to include both alignment model score and the consistency constraint in the optimization objective of word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 129, "end_pos": 143, "type": "TASK", "confidence": 0.8088697195053101}]}, {"text": "In this work, we propose to use coverage, which measures how well extracted phrases can: (a) An alignment resulting in a set of bilingual phrases (highlighted by shading) that can recover the training example, and (b) an alignment resulting in a set of bilingual phrases that fails to fully recover the training example.", "labels": [], "entities": [{"text": "coverage", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9918577075004578}]}, {"text": "We assume the maximum phrase length w = 3.", "labels": [], "entities": []}, {"text": "Our approach aims to avoid adding links that both have low posterior probabilities and hurt the recovery (e.g., the link between \"huiwu\" and \"hold\").", "labels": [], "entities": []}, {"text": "recover the training data, to bridge word alignment and (hierarchical) phrase-based translation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7636403739452362}, {"text": "phrase-based translation", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.7007168680429459}]}, {"text": "We introduce anew alignment search algorithm with an objective that maximizes both alignment model score and coverage while keeping the training algorithm unchanged.", "labels": [], "entities": [{"text": "alignment search", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.9702526032924652}, {"text": "coverage", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9850613474845886}]}, {"text": "The coverage of an alignment is calculated on the fly during search using a local phrase extraction algorithm.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7500973343849182}]}, {"text": "Experiments show that our approach achieves significant improvements over state-of-the-art baselines across various languages and translation models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our approach in terms of alignment and translation quality on five language pairs: Chinese-English (ZH-EN), Czech-English (CS-EN), German-English (DE-EN), Spanish-English (ES-EN), and French-English (FR-EN).", "labels": [], "entities": []}, {"text": "The evaluation metrics for alignment and translation are alignment error rate (AER) and case-insensitive BLEU (), respectively.", "labels": [], "entities": [{"text": "alignment", "start_pos": 27, "end_pos": 36, "type": "TASK", "confidence": 0.9618212580680847}, {"text": "translation", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.9185194969177246}, {"text": "alignment error rate (AER)", "start_pos": 57, "end_pos": 83, "type": "METRIC", "confidence": 0.9559394419193268}, {"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9666482210159302}]}, {"text": "For Chinese-English, the training data consists of 1.2M pairs of sentences with 30.9M Chinese words and 35.5M English words.", "labels": [], "entities": []}, {"text": "We used the SRILM toolkit) to train a 4-gram language model on the Xinhua portion of the English GIGAWORD corpus, which contains 398.6M words.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 12, "end_pos": 25, "type": "DATASET", "confidence": 0.7955395877361298}, {"text": "Xinhua portion of the English GIGAWORD corpus", "start_pos": 67, "end_pos": 112, "type": "DATASET", "confidence": 0.7254995107650757}]}, {"text": "For alignment evaluation, we used the Tsinghua Chinese-English word alignment evaluation data set (.", "labels": [], "entities": [{"text": "alignment evaluation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9860386550426483}, {"text": "Tsinghua Chinese-English word alignment evaluation data set", "start_pos": 38, "end_pos": 97, "type": "DATASET", "confidence": 0.6777115251336779}]}, {"text": "For translation evaluation, we used the NIST 2006 dataset as the development set and the and 2008 datasets as the test sets.", "labels": [], "entities": [{"text": "translation evaluation", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9693358838558197}, {"text": "NIST 2006 dataset", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.9822637240091959}]}, {"text": "For other languages, the training data is Europarl v7.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9732768535614014}]}, {"text": "The English language model trained on the Xinhua portion of the English GIGA-WORD corpus was also used for translation from European languages to English.", "labels": [], "entities": [{"text": "Xinhua portion of the English GIGA-WORD corpus", "start_pos": 42, "end_pos": 88, "type": "DATASET", "confidence": 0.5883063886846814}]}, {"text": "For translation evaluation, we used the \"news-test2012\" dataset that contains 3,003 sentences as the development set and the \"news-test2013\" dataset that contains 3,000 sentences as the test set.: Comparison of different alignment methods on the Chinese-English dataset.", "labels": [], "entities": [{"text": "translation evaluation", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9377432763576508}, {"text": "news-test2012\" dataset", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.7303829590479533}, {"text": "news-test2013\" dataset", "start_pos": 126, "end_pos": 148, "type": "DATASET", "confidence": 0.7778799136479696}, {"text": "Chinese-English dataset", "start_pos": 246, "end_pos": 269, "type": "DATASET", "confidence": 0.6918308734893799}]}, {"text": "\"GDF\" denotes the grow-diag-final heuristic.", "labels": [], "entities": []}, {"text": "\"phrase count\" denotes optimizing with respect to maximizing the number of extracted tight phrases.", "labels": [], "entities": []}, {"text": "We used Moses to extract loose phrases from word-aligned training data for all methods.", "labels": [], "entities": []}, {"text": "\"# bp\" denotes the number of extracted bilingual phrases, \"# sp\" denotes the number of source phrases, \"# tp\" denotes the number of target phrases, \"# sw\" denotes the source vocabulary size, \"# tw\" denotes the target vocabulary size.: Translation evaluation on different alignment models.", "labels": [], "entities": [{"text": "Translation", "start_pos": 235, "end_pos": 246, "type": "TASK", "confidence": 0.9771392941474915}]}, {"text": "We apply our approach to both generative and discriminative alignment models.", "labels": [], "entities": [{"text": "generative and discriminative alignment", "start_pos": 30, "end_pos": 69, "type": "TASK", "confidence": 0.7529404684901237}]}, {"text": "\"generative\" denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two directions.", "labels": [], "entities": []}, {"text": "\"discriminative\" denotes the log-linear alignment model (.", "labels": [], "entities": []}, {"text": "Adding coverage leads to significant improvements.", "labels": [], "entities": [{"text": "coverage", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9326322078704834}]}, {"text": "We use \"**\" to denote that the difference is statistically significant at p < 0.01 level.", "labels": [], "entities": []}, {"text": "We apply our approach to both generative () and discriminative ( alignment models.", "labels": [], "entities": []}, {"text": "As shown in, we find that adding coverage to the optimization objective significantly improves the BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.999228835105896}]}, {"text": "All differences are statistically significant at p < 0.01 level.", "labels": [], "entities": []}, {"text": "This finding suggests that our approach generalizes well to various alignment models.", "labels": [], "entities": []}, {"text": "We also evaluated our approach on both phrasebased and hierarchical phrase-based models.", "labels": [], "entities": []}, {"text": "As shown in, adding coverage to generative models leads to significant improvements for both models.", "labels": [], "entities": [{"text": "generative", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.97067791223526}]}, {"text": "All the differences are statistically significant at p < 0.01 level.", "labels": [], "entities": []}, {"text": "Although coverage is designed for extracting phrases, using coverage is still beneficial to hierarchical phrase-based models because hierarchical phrases are derived from phrases consistent with word alignment.", "labels": [], "entities": []}, {"text": "4  Finally, we report BLEU scores across five language pairs in: Chinese-English (ZH-EN), Czech-English (CS-EN), German-English (DE-EN), Spanish-English (ES-EN), and FrenchEnglish (FR-EN).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9991797804832458}]}, {"text": "ZH-EN uses four references and other language pairs only use single references.", "labels": [], "entities": [{"text": "ZH-EN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9017362594604492}]}, {"text": "We find that our approach outperforms the baseline statistically significantly at p < 0.01 for four language pairs and p < 0.05 for one language pair.", "labels": [], "entities": []}, {"text": "Therefore, using coverage to bridge word alignment and machine translation can hopefully benefit more languages.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.7671754360198975}, {"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7445019781589508}]}], "tableCaptions": [{"text": " Table 1: Comparison of different settings of  coverage on the Chinese-English dataset using  Moses. \"h\" denotes \"hard\", \"s\" denotes \"soft\",  \"l\" denotes \"loose\", and \"t\" denotes \"tight\". The  BLEU scores were calculated on the development  set. For quick validation, we used a small fraction  of the training data to train the phrase-based  model.", "labels": [], "entities": [{"text": "Chinese-English dataset", "start_pos": 63, "end_pos": 86, "type": "DATASET", "confidence": 0.694736436009407}, {"text": "BLEU", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.9986571073532104}]}, {"text": " Table 2: Comparison of different alignment methods on the Chinese-English dataset. \"GDF\" denotes the  grow-diag-final heuristic. \"phrase count\" denotes optimizing with respect to maximizing the number of  extracted tight phrases. We used Moses to extract loose phrases from word-aligned training data for all  methods. \"# bp\" denotes the number of extracted bilingual phrases, \"# sp\" denotes the number of source  phrases, \"# tp\" denotes the number of target phrases, \"# sw\" denotes the source vocabulary size, \"# tw\"  denotes the target vocabulary size.", "labels": [], "entities": [{"text": "Chinese-English dataset", "start_pos": 59, "end_pos": 82, "type": "DATASET", "confidence": 0.7063017338514328}]}, {"text": " Table 3: Translation evaluation on different alignment models. We apply our approach to both generative  and discriminative alignment models. \"generative\" denotes applying the grow-diag-final heuristic to  the alignments produced by IBM Model 4 in two directions. \"discriminative\" denotes the log-linear  alignment model (", "labels": [], "entities": [{"text": "Translation evaluation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9052278101444244}]}, {"text": " Table 4: Translation evaluation on different translation models. For translation, We used both phrase- based and hierarchical phrase-based models. For alignment, we used the generative model. \"generative\"  denotes applying the grow-diag-final heuristic to the alignments produced by IBM Model 4 in two  directions. Adding coverage leads to significant improvements. We use \"**\" to denote that the difference  is statistically significant at p < 0.01 level.", "labels": [], "entities": [{"text": "Translation evaluation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9177994132041931}, {"text": "translation", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.9724048376083374}]}, {"text": " Table 5: Translation evaluation on five language pairs. \"generative\" denotes applying the grow-diag-final  heuristic to the alignments produced by IBM Model 4 in two directions. We use \"*\" and\"**\" to denote  that the difference is statistically significant at p < 0.05 and p < 0.01, respectively. Note that ZH-EN  uses four references and other language pairs only use single references.", "labels": [], "entities": [{"text": "Translation evaluation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9076610505580902}]}]}