{"title": [{"text": "JEAM: A Novel Model for Cross-Domain Sentiment Classification Based on Emotion Analysis", "labels": [], "entities": [{"text": "Cross-Domain Sentiment Classification", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.7333845694859823}, {"text": "Emotion Analysis", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.802394449710846}]}], "abstractContent": [{"text": "Cross-domain sentiment classification (CSC) aims at learning a sentiment classifier for unlabeled data in the target domain based on the labeled data from a different source domain.", "labels": [], "entities": [{"text": "Cross-domain sentiment classification (CSC)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8502043783664703}]}, {"text": "Due to the differences of data distribution of two domains in terms of the raw features, the CSC problem is difficult and challenging.", "labels": [], "entities": []}, {"text": "Previous researches mainly focused on concepts mining by clustering words across data domains, which ignored the importance of authors' emotion contained in data, or the different representations of the emotion between domains.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel framework to solve the CSC problem, by modelling the emotion across domains.", "labels": [], "entities": [{"text": "CSC problem", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.9106209576129913}]}, {"text": "We first develop a probabilistic model named JEAM to model author's emotion state when writing.", "labels": [], "entities": []}, {"text": "Then, an EM algorithm is introduced to solve the likelihood maximum problem and to obtain the latent emotion distribution of the author.", "labels": [], "entities": []}, {"text": "Finally, a supervised learning method is utilized to assign the sentiment polarity to a given online review.", "labels": [], "entities": []}, {"text": "Experiments show that our approach is effective and outperforms state-of-the-art approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cross-domain sentiment classification (CSC) is the task that learns a sentiment classifier for unlabeled data in the target domain based on the labeled data from the source domain.", "labels": [], "entities": [{"text": "Cross-domain sentiment classification (CSC)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8593028684457144}]}, {"text": "With the increasing amount of opinion information \uf02a Corresponding author available on the Internet, CSC has become a hot spot in recent years.", "labels": [], "entities": []}, {"text": "Traditional machine learning algorithms often train a classifier utilizing the labeled data for CSC.", "labels": [], "entities": []}, {"text": "However, in some practical cases, we may have many labeled data for some domains (source domains) but very few or no labeled data for other domains (target domains).", "labels": [], "entities": []}, {"text": "Due to the differences of the distribution of two domains in terms of raw features, e.g. raw term frequency, the classifier trained from the source domain often performs badly on the target domain.", "labels": [], "entities": []}, {"text": "To overcome this issue, several feature-based studies have been proposed to improve the sentiment classification domain adaptation.", "labels": [], "entities": [{"text": "sentiment classification domain adaptation", "start_pos": 88, "end_pos": 130, "type": "TASK", "confidence": 0.958970382809639}]}, {"text": "Existing studies build various generative models to solve the domain adaptation problems for CSC.", "labels": [], "entities": []}, {"text": "In most cases, the models are trained by using the whole corpora without specifying on the sentiment of the texts.", "labels": [], "entities": []}, {"text": "For example, propose a general framework HIDC to mine high-level concepts (e.g. word clusters) across various domains.", "labels": [], "entities": []}, {"text": "However, their learned concepts contain many topics not restricted to the sentiment.", "labels": [], "entities": []}, {"text": "On the other hand, some researchers focus on the usage of the sentiment in CSC study.] modify JST model by incorporating word polarity priors through adjusting the topic-word Dirichlet priors.", "labels": [], "entities": [{"text": "JST", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.7565756440162659}]}, {"text": "However, they fail to consider the expression differences among various domains.", "labels": [], "entities": []}, {"text": "To overcome the above issues, we employ \"emotion\", for its ubiquity among domains.", "labels": [], "entities": []}, {"text": "The sentiment words in different domains might vary significantly, but the emotion can be effectively transferred.", "labels": [], "entities": []}, {"text": "For example, when expressing the emotion \"happiness\", one uses \"bravo\" in the domain of sport, while \"yummy\" in the domain of food.", "labels": [], "entities": []}, {"text": "Therefore, we propose an EA framework to model the latent emotions which are commonly contained in subjective articles and expressed by \"emotional words\".", "labels": [], "entities": []}, {"text": "We infer the sentiment polarity of a document based on the emotion state.", "labels": [], "entities": []}, {"text": "The hierarchy of EA is composed by four layers: (1) Sentiment Layer Normally, the sentiment of a document is the general opinion towards a certain event or object.", "labels": [], "entities": []}, {"text": "For example, a movie review in IMDB might voice the feeling about the movie by a reviewer.", "labels": [], "entities": []}, {"text": "(2) Emotion Layer Based on the emotion classification theories in psychology, the emotion can be classified into the basic ones influenced by the physiological factors, e.g. happiness, sadness, anger, etc., and dozens of complicated ones formed under some specific social conditions, e.g. shame, guilt, abashment, etc.", "labels": [], "entities": []}, {"text": "Additionally, the emotion can be classified as positive and negative (similar to the sentiment classification) based on dimensional models of emotion.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.7451817989349365}]}, {"text": "Intuitively, we assume that a document tends to contain the emotions of similar polarity.", "labels": [], "entities": []}, {"text": "(3) Lexicon Layer To build the connection between words and the emotion, we introduce emotional words instead of raw word features into our model.", "labels": [], "entities": []}, {"text": "By utilizing the emotional lexicon MPQA, we select groups of strong polar words, which get high scores in the emotional lexicon.", "labels": [], "entities": [{"text": "MPQA", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.8250220417976379}]}, {"text": "These words are considered highly correlated to the certain emotion of the same polarity.", "labels": [], "entities": []}, {"text": "And these strong polar words have invariant polarity across domains.", "labels": [], "entities": []}, {"text": "Therefore, the emotion can be substantialized by a series of emotional words drawn from corresponding probability distribution.", "labels": [], "entities": []}, {"text": "(4) Expression Layer In many practical cases, data come from different domains.", "labels": [], "entities": []}, {"text": "We suppose that the correlation between emotion state and sentiment orientation is stable over domains, but one emotion may have different expressions when domain varies.", "labels": [], "entities": [{"text": "sentiment orientation", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.8366264700889587}]}, {"text": "E.g., \"satisfaction\" maybe expressed as \"interesting\" or \"attractive\" fora book; meanwhile, it maybe expressed \"efficient\" for an electronics device.", "labels": [], "entities": []}, {"text": "Formally, we have \u00ed \u00b5\u00ed\u00b1\u009d(\u00ed \u00b5\u00ed\u00b1\u0092|\u00ed \u00b5\u00ed\u00b1\u00a6, \u00ed \u00b5\u00ed\u00b1\u009f1) = \u00ed \u00b5\u00ed\u00b1\u009d(\u00ed \u00b5\u00ed\u00b1\u0092|\u00ed \u00b5\u00ed\u00b1\u00a6, \u00ed \u00b5\u00ed\u00b1\u009f2) = \u00ed \u00b5\u00ed\u00b1\u009d(\u00ed \u00b5\u00ed\u00b1\u0092|\u00ed \u00b5\u00ed\u00b1\u00a6) (1) \u00ed \u00b5\u00ed\u00b1\u009d(\u00ed \u00b5\u00ed\u00b1\u00a4 \u00ed \u00b5\u00ed\u00b1\u0092 |\u00ed \u00b5\u00ed\u00b1\u0092, \u00ed \u00b5\u00ed\u00b1\u009f1) \u2260 \u00ed \u00b5\u00ed\u00b1\u009d(\u00ed \u00b5\u00ed\u00b1\u00a4 \u00ed \u00b5\u00ed\u00b1\u0092 |\u00ed \u00b5\u00ed\u00b1\u0092, \u00ed \u00b5\u00ed\u00b1\u009f2) where \u00ed \u00b5\u00ed\u00b1\u0092 denotes the emotion, y denotes the author's sentiment orientation, \u00ed \u00b5\u00ed\u00b1\u009f1 and \u00ed \u00b5\u00ed\u00b1\u009f2 denotes two different domains, and \u00ed \u00b5\u00ed\u00b1\u00a4 \u00ed \u00b5\u00ed\u00b1\u0092 denotes the emotional words.", "labels": [], "entities": []}, {"text": "Along this line, we propose the Joint Emotion Analysis Model (named JEAM for abbreviation) utilizing the probabilistic methods.", "labels": [], "entities": [{"text": "Joint Emotion Analysis", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.5440857807795206}, {"text": "JEAM", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.5659700036048889}]}, {"text": "See details in the next section.", "labels": [], "entities": []}], "datasetContent": [{"text": "We demonstrate the effectiveness of JEAM on the Multi-Domain sentiment data set which contains four types (domains) of real-world product documents taken from Amazon.com, which are books, dvd, electronics and kitchen.", "labels": [], "entities": [{"text": "JEAM", "start_pos": 36, "end_pos": 40, "type": "TASK", "confidence": 0.6689247488975525}, {"text": "Multi-Domain sentiment data set", "start_pos": 48, "end_pos": 79, "type": "DATASET", "confidence": 0.6881889849901199}]}, {"text": "We randomly select 1800 documents from the one domain (source domain) and 200 documents from another domain (target domain).", "labels": [], "entities": []}, {"text": "Then, we train a sentiment classifier using documents selected from the source domain and \u00ed \u00b5\u00ed\u00b1\u0092 Emotion \u00ed \u00b5\u00ed\u00b1\u00a4 \u00ed \u00b5\u00ed\u00b1\u0092 Emotional word \u00ed \u00b5\u00ed\u00b1\u009f Domain \u00ed \u00b5\u00ed\u00b1\u0091 Document \u00ed \u00b5\u00ed\u00b1\u00a2 Prior sentiment polarity of the emotional word \u00ed \u00b5\u00ed\u00b1\u00a6 Sentiment polarity of the document \u00ed \u00b5\u00ed\u00b1\u008b All the observed variables \u00ed \u00b5\u00ed\u00bc\u0083 All the model parameters assign labels to documents selected from the target domain, which generates 12 classification tasks.", "labels": [], "entities": []}, {"text": "We preform 10 random selections and report the average results over 10 different runs.", "labels": [], "entities": []}, {"text": "We use MPQA subjective lexicon 1 as the emotional lexicon.", "labels": [], "entities": [{"text": "MPQA subjective lexicon 1", "start_pos": 7, "end_pos": 32, "type": "DATASET", "confidence": 0.7647244781255722}]}, {"text": "In our experiments, only strongly subjective clues are considered as emotional words, consisting of 1717 positive and 3621 negative words.", "labels": [], "entities": []}, {"text": "We rebuild the dataset by cutting out the non-emotional words.", "labels": [], "entities": []}, {"text": "For experiment parameters, we set \u00ed \u00b5\u00ed\u00b1\u009d = 25, \u00ed \u00b5\u00ed\u00b1\u009b = 25, and \u00ed \u00b5\u00ed\u00b1\u0087 = 100 after plenty of experiments.", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed\u00b1\u009d", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.8837893207867941}, {"text": "\u00ed \u00b5\u00ed\u00b1\u0087", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.7486130396525065}]}, {"text": "Considering the data in practice, the sentiment orientation y has only two forms, positive or negative.", "labels": [], "entities": []}, {"text": "Note that we do neither instance selection nor complicated feature selection (only filter the low-frequency words) to our proposed method and other methods in comparison.", "labels": [], "entities": [{"text": "instance selection", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.762883722782135}]}], "tableCaptions": []}