{"title": [{"text": "Feature-Rich Two-Stage Logistic Regression for Monolingual Alignment", "labels": [], "entities": [{"text": "Monolingual Alignment", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7212371230125427}]}], "abstractContent": [{"text": "Monolingual alignment is the task of pair-ing semantically similar units from two pieces of text.", "labels": [], "entities": [{"text": "Monolingual alignment", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8514732718467712}]}, {"text": "We report a top-performing supervised aligner that operates on short text snippets.", "labels": [], "entities": []}, {"text": "We employ a large feature set to (1) encode similarities among semantic units (words and named entities) in context, and (2) address cooperation and competition for alignment among units in the same snippet.", "labels": [], "entities": []}, {"text": "These features are deployed in a two-stage logistic regression framework for alignment.", "labels": [], "entities": [{"text": "alignment", "start_pos": 77, "end_pos": 86, "type": "TASK", "confidence": 0.9630911946296692}]}, {"text": "On two benchmark data sets, our aligner achieves F 1 scores of 92.1% and 88.5%, with statistically significant error reductions of 4.8% and 7.3% over the previous best aligner.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9852021932601929}, {"text": "error", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.7971958518028259}]}, {"text": "It produces top results in extrinsic evaluation as well.", "labels": [], "entities": [{"text": "extrinsic evaluation", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8447737693786621}]}], "introductionContent": [{"text": "Computer applications frequently require semantic comparison between short snippets of natural language text.", "labels": [], "entities": [{"text": "semantic comparison between short snippets of natural language text", "start_pos": 41, "end_pos": 108, "type": "TASK", "confidence": 0.819879886176851}]}, {"text": "Such comparisons are key to paraphrase detection, textual similarity identification () and recognition of textual entailment ().", "labels": [], "entities": [{"text": "paraphrase detection", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.9141483008861542}, {"text": "textual similarity identification", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.714765210946401}, {"text": "recognition of textual entailment", "start_pos": 91, "end_pos": 124, "type": "TASK", "confidence": 0.8673433512449265}]}, {"text": "And they underpin applications such as short answer grading), question answering (, machine translation evaluation, and machine reading.", "labels": [], "entities": [{"text": "question answering", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9208196997642517}, {"text": "machine translation evaluation", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.8744526902834574}, {"text": "machine reading", "start_pos": 120, "end_pos": 135, "type": "TASK", "confidence": 0.8459699749946594}]}, {"text": "A central problem underlying all text comparison tasks is that of alignment: pairing related semantic units (i.e. words and phrases) across the two snippets ().", "labels": [], "entities": [{"text": "text comparison tasks", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.7535233894983927}]}, {"text": "Studies have shown that such tasks can benefit from an explicit alignment component.", "labels": [], "entities": []}, {"text": "However, alignment is still an open research problem.", "labels": [], "entities": [{"text": "alignment", "start_pos": 9, "end_pos": 18, "type": "TASK", "confidence": 0.9878893494606018}]}, {"text": "We present a supervised monolingual aligner that produces top results in several intrinsic and extrinsic evaluation experiments.", "labels": [], "entities": []}, {"text": "We pinpoint a set of key challenges for alignment and design a model with components targeted at each.", "labels": [], "entities": []}, {"text": "Lexical and phrasal alignments can both be represented as pairs of words -in the form of manyto-many mappings among the two phrases' component words in the latter case.", "labels": [], "entities": []}, {"text": "Thus without loss of generality, we formulate alignment as a binary classification task where given all word pairs across two sentences, the goal is to assign each a class label in {aligned, not aligned}.", "labels": [], "entities": [{"text": "formulate alignment", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7219175696372986}]}, {"text": "However, this is not a straightforward classification scenario where each word pair can be treated independently -words in the same snippet can play both mutually cooperating and competing roles in complex ways.", "labels": [], "entities": []}, {"text": "For example, semantically similar words in a snippet can be in competition for alignment with a word in the other snippet, whereas words that constitute a phrase can provide supporting evidence for one another (e.g. in named entity alignments such as Watson \u2194 John Hamish Watson).", "labels": [], "entities": []}, {"text": "To handle such interdependencies, we employ a two-stage logistic regression model -stage 1 computes an alignment probability for each word pair based solely on its own feature values, and stage 2 assigns the eventual alignment labels to all pairs following a comparative assessment of stage 1 probabilities of cooperating and competing pairs.", "labels": [], "entities": []}, {"text": "On two alignment data sets reported in and (, our aligner demonstrates respective F 1 scores of 92.1% and 88.5%, with statistically significant error reductions of 4.8% and 7.3% over the previous best aligner ().", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9900310039520264}, {"text": "error", "start_pos": 144, "end_pos": 149, "type": "METRIC", "confidence": 0.8132789731025696}]}, {"text": "We also present extrinsic evaluation of the aligner within two text comparison tasks, namely sentence similarity identification and paraphrase detection, where it demonstrates state-of-the-art results.", "labels": [], "entities": [{"text": "sentence similarity identification", "start_pos": 93, "end_pos": 127, "type": "TASK", "confidence": 0.7484127481778463}, {"text": "paraphrase detection", "start_pos": 132, "end_pos": 152, "type": "TASK", "confidence": 0.8275663256645203}]}], "datasetContent": [{"text": "We report evaluation on two alignment data sets and extrinsic evaluation on two tasks: sentence similarity identification and paraphrase detection.", "labels": [], "entities": [{"text": "sentence similarity identification", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.7683279712994894}, {"text": "paraphrase detection", "start_pos": 126, "end_pos": 146, "type": "TASK", "confidence": 0.8195514678955078}]}], "tableCaptions": [{"text": " Table 1: Performance on two alignment data sets.  Improvements in F 1 are statistically significant.", "labels": [], "entities": [{"text": "F 1", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9762517511844635}]}, {"text": " Table 2: STS results. Performances of past systems  are reported by Sultan et al. (2014a).", "labels": [], "entities": [{"text": "STS", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.521849513053894}]}, {"text": " Table 3: Paraphrase results. Performances of past  systems are taken from (Sultan et al., 2014a).", "labels": [], "entities": [{"text": "Paraphrase", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8327767848968506}]}, {"text": " Table 4: Performance with and without stage 2.", "labels": [], "entities": []}, {"text": " Table 5: Results without different stage 1 features.", "labels": [], "entities": []}, {"text": " Table 6: Results without different stage 2 features.", "labels": [], "entities": []}, {"text": " Table 7: Performance on different word pair types.", "labels": [], "entities": []}]}