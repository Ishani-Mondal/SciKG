{"title": [{"text": "RELLY: Inferring Hypernym Relationships Between Relational Phrases", "labels": [], "entities": [{"text": "Inferring Hypernym Relationships Between Relational Phrases", "start_pos": 7, "end_pos": 66, "type": "TASK", "confidence": 0.662440021832784}]}], "abstractContent": [{"text": "Relational phrases (e.g., \"got married to\") and their hypernyms (e.g., \"is a relative of\") are central for many tasks including question answering, open information extraction , paraphrasing, and entailment detection.", "labels": [], "entities": [{"text": "question answering", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.9001025557518005}, {"text": "open information extraction", "start_pos": 148, "end_pos": 175, "type": "TASK", "confidence": 0.6788913806279501}, {"text": "entailment detection", "start_pos": 196, "end_pos": 216, "type": "TASK", "confidence": 0.9236205518245697}]}, {"text": "This has motivated the development of several linguistic resources (e.g. DIRT, PATTY, and WiseNet) which systematically collect and organize relational phrases.", "labels": [], "entities": []}, {"text": "These resources have demonstra-ble practical benefits, but are each limited due to noise, sparsity, or size.", "labels": [], "entities": []}, {"text": "We present anew general-purpose method, RELLY, for constructing a large hypernymy graph of relational phrases with high-quality subsumptions using collective probabilistic programming techniques.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9832153916358948}]}, {"text": "Our graph induction approach integrates small high-precision knowledge bases together with large automatically curated resources, and reasons collectively to combine these resources into a consistent graph.", "labels": [], "entities": [{"text": "graph induction", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7576487362384796}]}, {"text": "Using RELLY, we construct a high-coverage, high-precision hypernymy graph consisting of 20K relational phrases and 35K hy-pernymy links.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.8115764856338501}]}, {"text": "Our evaluation indicates a hypernymy link precision of 78%, and demonstrates the value of this resource fora document-relevance ranking task.", "labels": [], "entities": [{"text": "hypernymy link precision", "start_pos": 27, "end_pos": 51, "type": "METRIC", "confidence": 0.712653656800588}]}], "introductionContent": [{"text": "One of the many challenges in natural language understanding is interpreting the multiword phrases that denote relationships between entities.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6727544069290161}]}, {"text": "Semantically organizing the complex relationships between diverse phrases is crucial to applications including question answering, open information extraction, paraphrasing, and entailment detection ().", "labels": [], "entities": [{"text": "question answering", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.9238889217376709}, {"text": "open information extraction", "start_pos": 131, "end_pos": 158, "type": "TASK", "confidence": 0.6777202089627584}, {"text": "entailment detection", "start_pos": 178, "end_pos": 198, "type": "TASK", "confidence": 0.9163563847541809}]}, {"text": "For example, a corpus containing the phrase \"George Burns was married to Gracie Allen\" allows us to answer the query \"Who was the spouse of George Burns?\"", "labels": [], "entities": []}, {"text": "However, \"Jay Z is in a relationship with Beyonc\u00e9\" provides insufficient information to determine whether the couple is married.", "labels": [], "entities": []}, {"text": "To capture the knowledge found in text, relational phrases need to be systematically organized with lexical links like synonymy (\"married to\" and \"spouse of\") and hypernymy (\"in a relationship\" generalizing \"married to\").", "labels": [], "entities": []}, {"text": "Many projects address the challenge of understanding relational phrases, but existing linguistic resources are often limited to synonymy, suffer from low precision, or have low coverage.", "labels": [], "entities": [{"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.994446873664856}]}, {"text": "Systems such as DIRT (), RE-SOLVER (, and WiseNet) have used sophisticated clustering techniques to determine synonymous phrases, but do not provide subsumption information.", "labels": [], "entities": [{"text": "RE-SOLVER", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.8316845893859863}]}, {"text": "The PATTY () project goes beyond clustering and introduces a subsumption hierarchy, but suffers from sparsity and contains few hypernymy links.", "labels": [], "entities": []}, {"text": "The HARPY) project extended PATTY, generating 600K hypernymy links, but with low precision.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.4745933711528778}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9961504936218262}]}, {"text": "introduced entailment graphs that provided a high-quality subsumption hierarchy.", "labels": [], "entities": []}, {"text": "This method required partitioning the graph and the largest component consisted of 120 relations.", "labels": [], "entities": []}, {"text": "A number of manuallycurated relational taxonomies such as WordNet,, and FrameNet () also offer highprecision hierarchies with limited coverage.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9760494232177734}]}, {"text": "In this paper, we introduce RELLY, a method for producing a hypernymy graph that has both high coverage and precision.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9968929290771484}, {"text": "coverage", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9580268859863281}, {"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9960898160934448}]}, {"text": "We build on previous work, integrating the high-precision knowledge in resources such as and WordNet with noisy statistical information from OpenIE projects PATTY and HARPY.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9689942002296448}]}, {"text": "RELLY maintains a consistent graph by including collective global constraints such as transitivity, asymmetry, and acyclicity.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7451345920562744}]}, {"text": "Scalability is often a concern when employing collective reasoning overlarge corpora, but our system can produce graphs with over 100K edges on conventional hardware.", "labels": [], "entities": []}, {"text": "As a result, we produce a large, complete, and high-precision hypernym graph that includes alignments and type information.", "labels": [], "entities": []}, {"text": "RELLY leverages probabilistic soft logic (PSL) (), a popular probabilistic modeling framework, to collectively infer hypernymy links at scale.", "labels": [], "entities": []}, {"text": "PSL uses continuously-valued variables and evidence, allowing easy integration of uncertain statistical information while encoding dependencies between variables using a first-order logic syntax.", "labels": [], "entities": []}, {"text": "We define a PSL model with rules that combine statistical features, semantic information, and structural constraints.", "labels": [], "entities": []}, {"text": "Statistical features, such as argument overlap and alignments to WordNet verbs senses, allow RELLY to learn from large text collections.", "labels": [], "entities": []}, {"text": "Semantic information, such as type information for relation arguments, improves precision of the resulting inferences.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.998229444026947}]}, {"text": "Structural constraints, such as transitivity and acyclicity, enforce a complete and consistent set of edges.", "labels": [], "entities": []}, {"text": "Using this PSL model, we learn rule weights with a small amount of training data and then perform joint inference overall hypernymy links in the graph.", "labels": [], "entities": []}, {"text": "We highlight three major contributions of our work.", "labels": [], "entities": []}, {"text": "First, we introduce RELLY, a scalable method for integrating statistical and semantic signals to produce a hypernymy graph.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.995560884475708}]}, {"text": "RELLY is extensible and can easily incorporate additional information sources and features.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.5268188118934631}]}, {"text": "Second, we generate a complete and precise hypernymy graph over 20K relational phrases and 35K hypernymy links.", "labels": [], "entities": []}, {"text": "We have publicly released this hypernymy graph as a resource for the NLP community.", "labels": [], "entities": []}, {"text": "Third, we present a thorough empirical evaluation to measure the precision of the hypernymy graph as well as demonstrate its usefulness in a real-world document ranking task.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9988590478897095}, {"text": "document ranking task", "start_pos": 152, "end_pos": 173, "type": "TASK", "confidence": 0.7451079984505972}]}, {"text": "Our results show a high precision (0.78) and superior performance in document ranking compared to state-of-the-art models such as word2vec).", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9990886449813843}]}], "datasetContent": [{"text": "In our experiments, we use a large corpus of relational phrases to construct a hypernymy graph using RELLY.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.9349285364151001}]}, {"text": "We evaluate RELLY using both intrinsic and extrinsic evaluation.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.7825061082839966}]}, {"text": "In the intrinsic evaluation, we asked human annotators to judge the relationship between two relational phrases and compared results from several hypernymy graphs.", "labels": [], "entities": []}, {"text": "In the extrinsic evaluation, we used the hypernymy graph fora real-world document ranking task and measured the mean reciprocal rank (MRR) fora number of methods.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 112, "end_pos": 138, "type": "METRIC", "confidence": 0.8609535296758016}]}, {"text": "In both evaluations, the hypernymy graph constructed by RELLY demonstrates significantly better performance than competing algorithms.", "labels": [], "entities": []}, {"text": "We use RELLY to build a hypernymy graph with data from the PATTY and HARPY projects.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.9671816229820251}, {"text": "PATTY", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.4869893193244934}]}, {"text": "The input to our system consists of 20,812 relational phrases and the associated argument types extracted from the English-language Wikipedia website using the PATTY system.", "labels": [], "entities": []}, {"text": "For simplicity, we only include relational phrases that contain exactly one verb (e.g. \"took the throne\"), excluding noun phrases (e.g. \"member of\") and phrases containing multiple verbs (e.g. \"hit and run\").", "labels": [], "entities": []}, {"text": "The verb \"to be\" and modal verbs were not considered in the dataset.", "labels": [], "entities": []}, {"text": "We also include HARPY alignments to the corresponding verb senses in WordNet for each phrase in the corpus.", "labels": [], "entities": [{"text": "HARPY", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9669514298439026}, {"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.971062958240509}]}, {"text": "Additionally, we use a subset of the type-subsumption hierarchy from YAGO consisting of 144 types and 323 subsumption relationships.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.8337807655334473}]}, {"text": "During graph inference, RELLY evaluated 7.9M possible hypernymy links using 9.7M ground logical rules and constraints.", "labels": [], "entities": []}, {"text": "Ultimately, RELLY produced 35,613 hypernymy links between relational phrases with confidence scores above 0.2.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.6727499961853027}]}, {"text": "The hypernymy graph consisted of 3,730 roots.", "labels": [], "entities": []}, {"text": "Running RELLY on a multi-core 2.27GHz server with 64GB of RAM required approximately 20 hours.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.5978173017501831}]}, {"text": "For comparison, PATTY produced 8,162 subsumption links out of 350,569 phrases with approximately 2,300 roots.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.5422224998474121}]}, {"text": "In our intrinsic evaluation, we assess the precision of hypernymy links inferred by RELLY and compare with the precision of hypernymy graphs of PATTY and HARPY.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9988227486610413}, {"text": "RELLY", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.9942540526390076}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9907312989234924}, {"text": "PATTY", "start_pos": 144, "end_pos": 149, "type": "METRIC", "confidence": 0.884660542011261}, {"text": "HARPY", "start_pos": 154, "end_pos": 159, "type": "METRIC", "confidence": 0.8299254179000854}]}, {"text": "In this evaluation, we measure precision for both the most confident hypernymy links in the system (precision@100) and the precision of a random sample of 100 hypernymy links.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9996179342269897}, {"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9982352256774902}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9990642666816711}]}, {"text": "Each set of hypernymy links were presented to several human annotators for labeling.", "labels": [], "entities": []}, {"text": "To measure precision@100, we choose the top 100 hypernymy links using the confidence scores reported by PSL.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9991055130958557}, {"text": "PSL", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.8648326992988586}]}, {"text": "We similarly choose the top 100 links from PATTY using the PATTY subsumption score.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.7841692566871643}, {"text": "PATTY", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.7377320528030396}]}, {"text": "Since HARPY does not provide confidence scores, we were unable to compute precision@100 for HARPY.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9982988238334656}, {"text": "HARPY", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.8853838443756104}]}, {"text": "For each of the three systems, we used the full set of hypernymy links they produce, which consisted of 8K links from PATTY, 600K links from HARPY and 35K links from RELLY.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.6445810198783875}, {"text": "HARPY", "start_pos": 141, "end_pos": 146, "type": "DATASET", "confidence": 0.6928337812423706}, {"text": "RELLY", "start_pos": 166, "end_pos": 171, "type": "DATASET", "confidence": 0.7654012441635132}]}, {"text": "We randomly sampled 100 hypernymy links from each of these systems.", "labels": [], "entities": []}, {"text": "We presented the selected hypernymy links to several human annotators.", "labels": [], "entities": []}, {"text": "The labeling task required the annotator to judge the relationship between two relational phrases in a hypernymy link.", "labels": [], "entities": [{"text": "labeling task", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.8779416382312775}]}, {"text": "For each relational phrase, we provided annotators with type information about the phrase arguments (domain and range) and examples of sentences that use the relational phrase.", "labels": [], "entities": []}, {"text": "Based on this information, annotators could make one of four judgments: (1) the phrases are unrelated; (2) the phrases are synonymous; (3) the first phrase is more specific than the second phrase; (4) the second phrase is more specific than the first phrase.", "labels": [], "entities": []}, {"text": "This evaluation task had good interannotator agreement, with a Cohen's Kappa of 0.624.", "labels": [], "entities": [{"text": "Cohen's Kappa", "start_pos": 63, "end_pos": 76, "type": "METRIC", "confidence": 0.7072099149227142}]}, {"text": "Separately, the precision@100 dataset had Cohen's Kappa of 0.708 and the randomly sampled dataset had Cohen's Kappa of 0.521.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9985176920890808}]}, {"text": "We show the results of the intrinsic evaluation in with 0.9-confidence Wilson score interval ().", "labels": [], "entities": [{"text": "Wilson score interval", "start_pos": 71, "end_pos": 92, "type": "METRIC", "confidence": 0.8073039650917053}]}, {"text": "In comparison to HARPY and PATTY, RELLY has higher precision for both precision@100 and random evaluations.", "labels": [], "entities": [{"text": "HARPY", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9182075262069702}, {"text": "PATTY", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.8753277659416199}, {"text": "RELLY", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.9846305251121521}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.999479353427887}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9972437620162964}]}, {"text": "Precision in RELLY is comparable to PATTY, but RELLY has more than four times as many hypernym links.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9862391352653503}, {"text": "PATTY", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.8790078163146973}]}, {"text": "HARPY has far more hypernymy links, but with a precision of 0.43, we find that many of these links are incorrect.", "labels": [], "entities": [{"text": "HARPY", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9135921597480774}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9963477253913879}]}, {"text": "includes example hypernymy links from RELLY.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.5850390791893005}]}, {"text": "There are examples where PATTY's subsumption is a dominant signal (\"<person> publicly accused <person>\" \u21d2 \"<person> accused <person>\").", "labels": [], "entities": [{"text": "PATTY's subsumption", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.6929403146107992}]}, {"text": "We also observe YAGO type hierarchy influence (\"<athlete> played for <team>\" \u21d2 \"<person> played for <organization>\"), as well as the influence of combined WordNet hierarchy with HARPY alignments (\"<person> marry daughter <person>\" \u21d2 \"<person> joins <per-son>\").", "labels": [], "entities": []}, {"text": "The advantage of RELLY is that it computes the final graph jointly and incorporates transitivity, asymmetry and acyclicity rules.", "labels": [], "entities": [{"text": "RELLY", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9157420992851257}]}, {"text": "It leads to less semantic drift in longer hypernymy chains) compared with PATTY where \"<organization> merged <organization>\" can lead to \"<team> beat <team>\".", "labels": [], "entities": []}, {"text": "The ultimate goal of producing a high-quality hypernymy graph is to deepen our understanding of natural language and improve performance on the many NLP applications.", "labels": [], "entities": []}, {"text": "One such application is document retrieval, where billions of queries are performed each day through search engines.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.796143501996994}]}, {"text": "In our extrinsic evaluation, we demonstrate how a hypernymy graph can improve performance on a document ranking and retrieval task.", "labels": [], "entities": [{"text": "document ranking and retrieval task", "start_pos": 95, "end_pos": 130, "type": "TASK", "confidence": 0.671371978521347}]}, {"text": "We consider a task where an input query document is compared to a corpus of documents with the aim of finding the most relevant related documents.", "labels": [], "entities": []}, {"text": "To isolate the evaluation to relational phrases, we anonymize the documents, by replacing all named entities and noun phrases with placeholders.", "labels": [], "entities": []}, {"text": "For example, the sentence \"The villain has already fled to the Republica de Isthmus\" is anonymized to \" * has already fled to * .\" Anonymized retrieval has potential applications in security and for sensitive documents.", "labels": [], "entities": [{"text": "Republica de Isthmus", "start_pos": 63, "end_pos": 83, "type": "DATASET", "confidence": 0.9568021694819132}]}, {"text": "We collected a dataset consisting of movie plot summaries from two different websites, Wikipedia and the Internet Movie Database (IMDB).", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 87, "end_pos": 96, "type": "DATASET", "confidence": 0.9414540529251099}, {"text": "Internet Movie Database (IMDB)", "start_pos": 105, "end_pos": 135, "type": "DATASET", "confidence": 0.8523443241914114}]}, {"text": "We chose plot synopses from 25 James Bond movies and 23 movies based on the Marvel Comics characters.", "labels": [], "entities": []}, {"text": "For each plot synopsis, we have two plot descriptions: one from Wikipedia and another from IMDB.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.9156026840209961}]}, {"text": "Given a query in the form of an anonymized plot description from one website, the task is to rank the anonymized plot descriptions 977 from the other dataset using relational phrase similarity.", "labels": [], "entities": []}, {"text": "For example, given a query plot description of \"Iron Man\" from Wikipedia, rank plot descriptions from IMDB with the goal of maximizing the ranking of the corresponding \"Iron Man\" plot summary.", "labels": [], "entities": [{"text": "query plot description of \"Iron Man\"", "start_pos": 21, "end_pos": 57, "type": "TASK", "confidence": 0.586748018860817}, {"text": "Iron Man\" plot summary", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.6415905475616455}]}, {"text": "We evaluate the quality of these rankings using the mean reciprocal rank (MRR) score, . Here, Q is the number of documents in the collection (i.e. 2*48 = 96) and rank i is the position of the counterpart document in the ranking of document i.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR) score", "start_pos": 52, "end_pos": 84, "type": "METRIC", "confidence": 0.8668142897742135}]}, {"text": "As baseline algorithms, we use a unigram word2vec model and a bigram model.", "labels": [], "entities": []}, {"text": "In the unigram word2vec model documents are represented by the average of the 300-dimensional word vectors trained on part of Google News dataset (about 100 billion words) ().", "labels": [], "entities": [{"text": "Google News dataset", "start_pos": 126, "end_pos": 145, "type": "DATASET", "confidence": 0.8802527983983358}]}, {"text": "We could not use the bigram word2vec model because of the frequent occurrence of the placeholder symbol.", "labels": [], "entities": []}, {"text": "In the bigram model, documents are represented by vectors in the bag-of-bigrams model with bigram frequency weights.", "labels": [], "entities": []}, {"text": "The similarity measure in both cases is the cosine similarity measure.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 4, "end_pos": 22, "type": "METRIC", "confidence": 0.9594352841377258}, {"text": "cosine similarity measure", "start_pos": 44, "end_pos": 69, "type": "METRIC", "confidence": 0.7633828322092692}]}, {"text": "As the first of our approaches we proposed a solution purely based on relational phrases.", "labels": [], "entities": []}, {"text": "In the relational phrases model we extract relational phrases from a text and we map them to their synsets from PATTY (clusters of synonyms).", "labels": [], "entities": [{"text": "PATTY", "start_pos": 112, "end_pos": 117, "type": "METRIC", "confidence": 0.9876225590705872}]}, {"text": "A phrase is mapped to a synset if the Jaccard similarity between tokens of extracted relation and tokens of one of the phrases in the synset is above a threshold.", "labels": [], "entities": []}, {"text": "Next we represent the document as a vector of the relational phrase synsets weighted by the frequency of the synset in the document (bag-of-relational phrases).", "labels": [], "entities": []}, {"text": "The similarity score between two documents is the cosine similarity between two vectors representing two documents.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9662116169929504}]}, {"text": "The ranking is created based on the similarity scores.", "labels": [], "entities": [{"text": "similarity", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9953041076660156}]}, {"text": "In the relational phrases + hypernyms model we add hypernyms of the extracted relational phrases to the document vector (based on the hypernymy graph).", "labels": [], "entities": []}, {"text": "Hypernyms are additionally weighted by the confidence score produced by the algorithm described in the Section 3.", "labels": [], "entities": []}, {"text": "In the second approach we combine relational phrases models with the best of the baselines.", "labels": [], "entities": []}, {"text": "The similarity score is then equal to \u03bbsim 1 +(1\u2212\u03bb)sim 2 . The \u03bb parameter is trained on a different dataset (2*8 plot descriptions of Harry Potter movies).", "labels": [], "entities": [{"text": "similarity score", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.977027028799057}]}, {"text": "Training was performed by maximization of the MRR The results of the experiment are presented in.", "labels": [], "entities": [{"text": "MRR", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.4453345239162445}]}, {"text": "The best MRR score was obtained by relational phrases + hypernyms + bigrams model.", "labels": [], "entities": [{"text": "MRR", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.6731749176979065}]}, {"text": "The number of samples, 96, was large enough for statistical significance.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6125920116901398}]}, {"text": "We performed a paired ttest for M RR between each of these methods.", "labels": [], "entities": [{"text": "M RR", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.5886365175247192}]}, {"text": "The obtained p-values were below 0.05.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Example RELLY hypernymy links", "labels": [], "entities": [{"text": "RELLY", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9421895742416382}]}, {"text": " Table 5: Results for Entailment graphs induction", "labels": [], "entities": [{"text": "Entailment graphs", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.8985660374164581}]}, {"text": " Table 6: Extrinsic evaluation (Bond & Marvel)", "labels": [], "entities": [{"text": "Extrinsic evaluation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.9046295285224915}, {"text": "Bond & Marvel)", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.8888511508703232}]}, {"text": " Table 6. The best MRR score was obtained by re- lational phrases + hypernyms + bigrams model.  The number of samples, 96, was large enough for  statistical significance. We performed a paired t- test for M RR between each of these methods.  The obtained p-values were below 0.05.", "labels": [], "entities": [{"text": "MRR", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.701450526714325}, {"text": "M RR", "start_pos": 205, "end_pos": 209, "type": "TASK", "confidence": 0.5391036421060562}]}]}