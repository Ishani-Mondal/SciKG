{"title": [], "abstractContent": [{"text": "fast align is a simple, fast, and efficient approach for word alignment based on the IBM model 2.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.7947783470153809}]}, {"text": "fast align performs well for language pairs with relatively similar word orders; however, it does not perform well for language pairs with drastically different word orders.", "labels": [], "entities": []}, {"text": "We propose a segmenting-reversing reordering process to solve this problem by alternately applying fast align and reordering source sentences during training.", "labels": [], "entities": []}, {"text": "Experimental results with Japanese-English translation demonstrate that the proposed approach improves the performance of fast align significantly without the loss of efficiency.", "labels": [], "entities": []}, {"text": "Experiments using other languages are also reported.", "labels": [], "entities": []}], "introductionContent": [{"text": "Aligning words in a parallel corpus is a basic task for almost all state-of-the-art statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "Aligning words in a parallel corpus", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8057688673337301}, {"text": "statistical machine translation (SMT)", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.8066491285959879}]}, {"text": "Word alignment is used to extract translation rules in various way, such as the phrase pairs used in a phrase-based (PB) SMT system (, the hierarchical rules used in a HIERO system, and the sophisticated translation templates used in tree-based SMT systems ().", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6967212557792664}, {"text": "phrase-based (PB) SMT", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.5977813243865967}, {"text": "SMT", "start_pos": 245, "end_pos": 248, "type": "TASK", "confidence": 0.9139342904090881}]}, {"text": "Among different approaches, GIZA++ 1 (Och and, which is based on the IBM translation models, is the most widely used word alignment tool.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 117, "end_pos": 131, "type": "TASK", "confidence": 0.8190445005893707}]}, {"text": "Other well-known tools are the BerkeleyAligner 2 , Nile 3 (, and pialign 4 ().", "labels": [], "entities": [{"text": "BerkeleyAligner 2", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9306660890579224}]}, {"text": "fast align) is a recently proposed word alignment approach based on the reparameterization of the IBM model 2, which is usually referred to as a zero-order alignment model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7846575081348419}]}, {"text": "Taking advantage of the simplicity of the IBM model 2, fast align introduces a \"tension\" parameter to model the overall accordance of word orders and an efficient parameter re-estimation algorithm is devised.", "labels": [], "entities": []}, {"text": "It has been reported that the fast align approach is more than 10 times faster than baseline GIZA++, with comparable results in end-to-end French-, Chinese-, and Arabic-to-English translation experiments.", "labels": [], "entities": []}, {"text": "However, the simplicity of the IBM model 2 also leads to a limitation.", "labels": [], "entities": []}, {"text": "As demonstrated in this study, fast align does not perform well when applied to language pairs with drastically different word orders, e.g., Japanese and English.", "labels": [], "entities": []}, {"text": "The problem is because of the IBM model 2's intrinsic inability to handle complex distortions.", "labels": [], "entities": []}, {"text": "In this study, we propose a simple and efficient reordering approach to improve the fast align's performance in such situations, referred to as segmenting-reversing (seg rev).", "labels": [], "entities": []}, {"text": "Our motivation is to apply a rough but robust reordering to make the source and target sentences have more similar word orders, where fast align can show its power.", "labels": [], "entities": []}, {"text": "Specifically, seg rev first segments a source-target sentence pair into a sequence of minimal monotone chunk pairs 6 based on the automatically generated word alignment.", "labels": [], "entities": []}, {"text": "Within the chunk pairs, source word sequences are examined to determine whether they should be completely reversed or the original order should be retained.", "labels": [], "entities": []}, {"text": "The objective of this step is to convert the source sentence to a roughly target-like word order.", "labels": [], "entities": []}, {"text": "The seg rev process is applied recursively but not deeply (only twice in our ex-the cutting unit 8 is activated by this signal .: Example of seg rev applied to a word-aligned English-Japanese sentence pair.", "labels": [], "entities": []}, {"text": "Based on the word alignment, the source sentence is reordered in a target-like order after applying seg rev twice.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied the proposed approach to JapaneseEnglish translation, a language pair with dramatically different word orders.", "labels": [], "entities": [{"text": "JapaneseEnglish translation", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.7993848919868469}]}, {"text": "In addition, we applied the approach to German-English translation, a language pair with relatively different word orders among European languages.", "labels": [], "entities": [{"text": "German-English translation", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.6700032204389572}]}, {"text": "For Japanese-English translation, we used NTCIR-7 PAT-MT data ().", "labels": [], "entities": [{"text": "Japanese-English translation", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.48789946734905243}, {"text": "NTCIR-7 PAT-MT data", "start_pos": 42, "end_pos": 61, "type": "DATASET", "confidence": 0.7919564843177795}]}, {"text": "For German-English translation, we used the Europarl v7 corpus 10 () for training, the WMT 08 11 / WMT 09 12 test sets for development / testing, respectively.", "labels": [], "entities": [{"text": "Europarl v7 corpus 10", "start_pos": 44, "end_pos": 65, "type": "DATASET", "confidence": 0.9408005326986313}, {"text": "WMT 08 11 / WMT 09 12 test sets", "start_pos": 87, "end_pos": 118, "type": "DATASET", "confidence": 0.8400004439883761}]}, {"text": "Default settings for the PB SMT in MOSES 13 ( were used, except for Japanese-English translations where the distortion-limit was set to 12 to reach a recently reported baseline ().", "labels": [], "entities": [{"text": "PB SMT", "start_pos": 25, "end_pos": 31, "type": "TASK", "confidence": 0.5888847410678864}, {"text": "MOSES 13", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.8825701773166656}]}, {"text": "MERT) was used to tune development set parameter weights and BLEU () was used on test sets to evaluate the translation performance.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8870469927787781}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.998788058757782}]}, {"text": "Bootstrap sampling) was employed to test statistical significance using bleu kit . We compared GIZA++ and fast align with default settings.", "labels": [], "entities": [{"text": "bleu kit", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.8577727675437927}]}, {"text": "GIZA++ was used as a module of MOSES.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.9043960571289062}]}, {"text": "The bi-directional outputs of fast align were symmetrized by atools in cdec 15 (, and further training steps were conducted using MOSES.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 130, "end_pos": 135, "type": "DATASET", "confidence": 0.834116518497467}]}, {"text": "grow-diagfinal-and symmetrization was used consistently in the experiments.", "labels": [], "entities": []}, {"text": "For the the proposed approach, we set \u03b4 = 2 and M = 4 in Algorithm 4.", "labels": [], "entities": [{"text": "\u03b4", "start_pos": 38, "end_pos": 39, "type": "METRIC", "confidence": 0.9406486749649048}, {"text": "M", "start_pos": 48, "end_pos": 49, "type": "METRIC", "confidence": 0.9800674319267273}]}, {"text": "Note that \u03b4 can beset to a larger value and seg rev could be applied repeatedly until no additional reordering is possible.", "labels": [], "entities": []}, {"text": "As mentioned, the word alignment is noisy and our intention is a robust and rough process; therefore, we restricted seg rev to two applications and did not consider the difference in sentence lengths or different languages during training.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7467849850654602}]}, {"text": "Within each iteration, fast align was run with default settings, except initial diagonal-ja-en en-ja de-en en-de: Test set BLEU scores for JapaneseEnglish and German-English translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9815647006034851}]}, {"text": "( \u2021 , statistical significance at p < 0.01; \u2020 , at p < 0.05; boldface, no significance; all compared with GIZA++) tension (\u03bb ini ) was set to 0.1 in the first iteration, to avoid overly strong monotone preference at the beginning of training.", "labels": [], "entities": [{"text": "GIZA++) tension (\u03bb ini )", "start_pos": 106, "end_pos": 130, "type": "METRIC", "confidence": 0.8566435405186245}]}, {"text": "Experimental results for Japanese-English and German-English translations in both directions are listed in.", "labels": [], "entities": []}, {"text": "The first two rows show the baseline performance.", "labels": [], "entities": []}, {"text": "fast align (using a default \u03bb ini = 4.0) performance was statistically significantly lower than GIZA++, particularly for Japanese-English translation.", "labels": [], "entities": []}, {"text": "The following four rows show the results of the proposed approach.", "labels": [], "entities": []}, {"text": "For the first iteration, \u03bb ini was set to 0.1, and the performance did not change significantly.", "labels": [], "entities": []}, {"text": "The translations from English improved (equal to GIZA++) at the second iteration.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9039771556854248}]}, {"text": "However, translations to English improved more slowly.", "labels": [], "entities": []}, {"text": "We attribute the difference in improvement rates between translation to and from English to the relatively fixed word order of English, whereby the reordering process is easier and more consistent.", "labels": [], "entities": [{"text": "translation to and from English", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.8021351337432862}]}, {"text": "Note that once translations from English improved in the second iteration, performance decreased in the following iterations.", "labels": [], "entities": []}, {"text": "The results in were obtained using predictable-seed for tuning, which generated determinate results.", "labels": [], "entities": []}, {"text": "Another attempt using random seeds to tune returned test set BLEU scores of 30.5, 30.4 on en-ja and 12.8, 12.8 on ende, for iterations 3 and 4, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9960935711860657}]}, {"text": "These four scores had no statistical significance against GIZA++.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9035094380378723}]}, {"text": "The instability is largely due to the alignment of function words, which affects translation performance ().", "labels": [], "entities": []}, {"text": "The alignment does not change significantly after the second iteration; however, it is unstable around function words, 16 because seg rev does not process fr-en zh-en GIZA++ 23.3 31.4 FA \u03bb ini =4.0 23.1 31.7 iteration 2 23.1 31.7 unaligned function words between chunks.", "labels": [], "entities": [{"text": "FA \u03bb ini", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9398345947265625}]}, {"text": "Our approach is too rough to handle function words precisely.", "labels": [], "entities": []}, {"text": "We plan to address this in future.", "labels": [], "entities": []}, {"text": "We also tested our approach on French-and Chinese-to-English translations.", "labels": [], "entities": []}, {"text": "The results are listed in.", "labels": [], "entities": []}, {"text": "GIZA++ and fast align showed no statistically significant difference in performance, which is consistent with.", "labels": [], "entities": []}, {"text": "The proposed approach did not affect performance for French-and Chinese-to-English translations.", "labels": [], "entities": []}, {"text": "These results are expected as these language pairs have similar word orders.", "labels": [], "entities": []}, {"text": "With regard to processing time, a na\u00a8\u0131vena\u00a8\u0131ve, singlethread implementation of seg rev in C++ took approximately 60s / 40s in the first / second application on the entire Japanese-English corpus . The recover process took less than 30s in each iteration.", "labels": [], "entities": [{"text": "recover", "start_pos": 201, "end_pos": 208, "type": "METRIC", "confidence": 0.9551224112510681}]}, {"text": "In contrast, fast align, although very fast, took approximately one hour for one round of training (using five iterations for its log-linear model) on the same corpus.", "labels": [], "entities": []}, {"text": "Therefore, the additional time required in our approach is quite small and can be ignored compared with the training time of fast align.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test set BLEU scores for Japanese- English and German-English translations. (  \u2021 , sta- tistical significance at p < 0.01;  \u2020 , at p < 0.05; bold- face, no significance; all compared with GIZA++)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9945055842399597}, {"text": "sta- tistical significance", "start_pos": 93, "end_pos": 119, "type": "METRIC", "confidence": 0.7786899954080582}, {"text": "GIZA++)", "start_pos": 198, "end_pos": 205, "type": "DATASET", "confidence": 0.6464515328407288}]}]}