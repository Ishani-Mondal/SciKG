{"title": [{"text": "Joint Lemmatization and Morphological Tagging with LEMMING", "labels": [], "entities": [{"text": "Morphological Tagging", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.7953573763370514}, {"text": "LEMMING", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9774459004402161}]}], "abstractContent": [{"text": "We present LEMMING, a modular log-linear model that jointly models lemmati-zation and tagging and supports the integration of arbitrary global features.", "labels": [], "entities": [{"text": "LEMMING", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9768307209014893}]}, {"text": "It is trainable on corpora annotated with gold standard tags and lemmata and does not rely on morphological dictionaries or an-alyzers.", "labels": [], "entities": []}, {"text": "LEMMING sets the new state of the art in token-based statistical lemmati-zation on six languages; e.g., for Czech lemmatization, we reduce the error by 60%, from 4.05 to 1.58.", "labels": [], "entities": [{"text": "LEMMING", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.904183566570282}]}, {"text": "We also give empirical evidence that jointly modeling morphological tags and lemmata is mutually beneficial.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lemmatization is important for many NLP tasks, including parsing) and machine translation.", "labels": [], "entities": [{"text": "Lemmatization", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9241841435432434}, {"text": "parsing", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.9757988452911377}, {"text": "machine translation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8157802522182465}]}, {"text": "Lemmata are required whenever we want to map words to lexical resources and establish the relation between inflected forms, particularly critical for morphologically rich languages to address the sparsity of unlemmatized forms.", "labels": [], "entities": []}, {"text": "This strongly motivates work on language-independent tokenbased lemmatization, but until now there has been little work ( ).", "labels": [], "entities": []}, {"text": "Many regular transformations can be described by simple replacement rules, but lemmatization of unknown words requires more than this.", "labels": [], "entities": []}, {"text": "For instance the Spanish paradigms for verbs ending in ir and er share the same 3rd person plural ending en; this makes it hard to decide which paradigm a form belongs to.", "labels": [], "entities": []}, {"text": "1 Solving these kinds of problems requires global features on the lemma.", "labels": [], "entities": []}, {"text": "Global features of this kind were not supported by previous work).", "labels": [], "entities": []}, {"text": "There is a strong mutual dependency between (i) lemmatization of a form in context and (ii) disambiguating its part-of-speech (POS) and morphological attributes.", "labels": [], "entities": []}, {"text": "Attributes often disambiguate the lemma of a form, which explains why many NLP systems () apply a pipeline approach of tagging followed by lemmatization.", "labels": [], "entities": []}, {"text": "Conversely, knowing the lemma of a form is often beneficial for tagging, for instance in the presence of syncretism; e.g., since German plural noun phrases do not mark gender, it is important to know the lemma (singular form) to correctly tag gender on the noun.", "labels": [], "entities": [{"text": "tagging", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.9684439301490784}]}, {"text": "We make the following contributions.", "labels": [], "entities": []}, {"text": "(i) We present the first joint log-linear model of morphological analysis and lemmatization that operates at the token level and is also able to lemmatize unknown forms; and release it as opensource (http://cistern.cis.lmu.de/lemming).", "labels": [], "entities": []}, {"text": "It is trainable on corpora annotated with gold standard tags and lemmata.", "labels": [], "entities": []}, {"text": "Unlike other work (e.g.,)) it does not rely on morphological dictionaries or analyzers.", "labels": [], "entities": []}, {"text": "(ii) We describe a log-linear model for lemmatization that can easily be incorporated into other models and supports arbitrary global features on the lemma.", "labels": [], "entities": []}, {"text": "(iii) We set the new state of the art in token-based statistical lemmatization on six languages (English, German, Czech, Hungarian, Latin and Spanish).", "labels": [], "entities": []}, {"text": "(iv) We experimentally show that jointly modeling morphological tags and lemmata is mutually beneficial and yields significant improvements in joint (tag+lemma) accuracy for four out of six languages; e.g., Czech lemma errors are reduced by >37% and tag+lemma errors by >6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.6418697834014893}]}, {"text": "ge/\u025b \u22a5 t/en umschauen umgeschaut: Edit tree for the inflected form umgeschaut \"looked around\" and its lemma umschauen \"to look around\".", "labels": [], "entities": [{"text": "Edit", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9485962390899658}]}, {"text": "The right tree is the actual edit tree we use in our model, the left tree visualizes what each node corresponds to.", "labels": [], "entities": []}, {"text": "The root node stores the length of the prefix umge (4) and the suffix t (1).", "labels": [], "entities": []}], "datasetContent": [{"text": "We present experiments on the joint task of lemmatization and tagging in six diverse languages: English, German, Czech, Hungarian, Latin and Spanish.", "labels": [], "entities": []}, {"text": "We use the same data sets as in, but do not use the out-of-domain test sets.", "labels": [], "entities": []}, {"text": "The English data is from the Penn Treebank (, Latin from PROIEL (, German and Hungarian from SPMRL 2013, and Spanish and Czech from CoNLL 2009).", "labels": [], "entities": [{"text": "English data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7108182311058044}, {"text": "Penn Treebank", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.991807609796524}, {"text": "CoNLL 2009", "start_pos": 132, "end_pos": 142, "type": "DATASET", "confidence": 0.9236089587211609}]}, {"text": "For German, Hungarian, Spanish and Czech we use the splits from the shared tasks; for English the split from SANCL (Petrov and McDonald, 2012); and for Latina 8/1/1 split into train/dev/test.", "labels": [], "entities": []}, {"text": "For all languages we limit our training data to the first 100,000 tokens.", "labels": [], "entities": []}, {"text": "Dataset statistics can be found in of the appendix.", "labels": [], "entities": []}, {"text": "The lemma of Spanish se is set to be consistent.", "labels": [], "entities": []}, {"text": "We compare our model to three baselines.", "labels": [], "entities": []}, {"text": "(i) MORFETTE (see Section 4).", "labels": [], "entities": [{"text": "MORFETTE", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9945880174636841}]}, {"text": "(ii) SIMPLE, a system that for each form-POS pair, returns the most frequent lemma in the training data or the form if the pair is unknown.", "labels": [], "entities": [{"text": "SIMPLE", "start_pos": 5, "end_pos": 11, "type": "TASK", "confidence": 0.8894961476325989}]}, {"text": "(iii) JCK, our reimplementation of.", "labels": [], "entities": [{"text": "JCK", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.7548547983169556}]}, {"text": "Recall that JCK is TC's lemmatization model and that the full TC model is a type-based model that cannot be applied to our task.", "labels": [], "entities": []}, {"text": "As JCK struggles to memorize irregulars, we only use it for unknown form-POS pairs and use SIMPLE otherwise.", "labels": [], "entities": [{"text": "JCK", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.8281622529029846}]}, {"text": "For aligning the training data we use the edit-tree-based alignment described in the feature section.", "labels": [], "entities": []}, {"text": "We only use output alphabet symbols that are used for \u2265 5 form-lemma pairs and also add a special output symbol that indicates that the aligned input should simply be copied.", "labels": [], "entities": []}, {"text": "We train the model using a structured averaged perceptron and stop after 10 training iterations.", "labels": [], "entities": []}, {"text": "In preliminary experiments we found typebased training to outperform token-based training.", "labels": [], "entities": []}, {"text": "This is understandable as we only apply our model to unseen form-POS pairs.", "labels": [], "entities": []}, {"text": "The feature set is an exact reimplementation of (, it consists of input-output pairs and their character context in a window of 6.", "labels": [], "entities": []}, {"text": "Our candidate selection strategy results in an average number of lemma candidates between 7 (Hungarian) and 91 (Czech) and a coverage of the correct lemma on dev of >99.4 (except 98.4 for Latin).", "labels": [], "entities": [{"text": "coverage", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9910364151000977}]}, {"text": "We first compare the baselines to LEMMING-P, a pipeline based on Section 2, that lemmatizes a word given a predicted tag and is trained using L-BFGS ().", "labels": [], "entities": [{"text": "LEMMING-P", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9710553288459778}]}, {"text": "We use the implementation of MAL-LET: Lemma accuracy on dev for the baselines and the different versions of LEMMING-P.", "labels": [], "entities": [{"text": "MAL-LET", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.5773885250091553}, {"text": "Lemma", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9468240141868591}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.751020610332489}, {"text": "LEMMING-P", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9339566230773926}]}, {"text": "POS and morphological attributes are predicted using MORFETTE.", "labels": [], "entities": [{"text": "MORFETTE", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.7744431495666504}]}, {"text": "The best baseline numbers are underlined, the best numbers are bold.", "labels": [], "entities": []}, {"text": "Models significantly better than the best baseline are marked (+).", "labels": [], "entities": []}, {"text": "which isolates the effects of the different taggers.", "labels": [], "entities": []}, {"text": "Numbers for MARMOT tags are in the appendix).", "labels": [], "entities": [{"text": "MARMOT tags", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.5244571268558502}]}, {"text": "For the initial experiments, we only use POS and ignore additional morphological attributes.", "labels": [], "entities": []}, {"text": "We use different feature sets to illustrate the utility of our templates.", "labels": [], "entities": []}, {"text": "The first model uses the edit tree features (edittree).", "labels": [], "entities": []}, {"text": "shows that this version of LEM-MING outperforms the baselines on half of the languages.", "labels": [], "entities": [{"text": "LEM-MING", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8794454336166382}]}, {"text": "Ina second experiment we add the alignment (+align) and lemma features (+lemma) and show that this consistently outperforms all baselines and edittree.", "labels": [], "entities": [{"text": "alignment", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9673053026199341}]}, {"text": "We then add the dictionary feature (+dict).", "labels": [], "entities": []}, {"text": "The resulting model outperforms all previous models and is significantly better than the best baselines for all languages.", "labels": [], "entities": []}, {"text": "8 These experiments show that LEMMING-P yields state-of-theart results and that all our features are needed to obtain optimal performance.", "labels": [], "entities": [{"text": "LEMMING-P", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9927337169647217}]}, {"text": "The improvements over the baselines are >1 for Czech and Latin and \u2265.5 for German and Hungarian.", "labels": [], "entities": []}, {"text": "The last experiment also uses the additional morphological attributes predicted by MORFETTE (+mrph).", "labels": [], "entities": [{"text": "MORFETTE", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.810673177242279}]}, {"text": "This leads to a drop in lemmatization performance in all languages except Spanish (English has no additional attributes).", "labels": [], "entities": []}, {"text": "However, preliminary experiments showed that correct morphological attributes would substantially improve lemmatization as they help in cases of ambiguity.", "labels": [], "entities": []}, {"text": "As an example, number helps to lemmatize the singular German noun Raps \"canola\", which looks like the plural of Rap \"rap\".", "labels": [], "entities": []}, {"text": "Numbers can be found in of the appendix.", "labels": [], "entities": []}, {"text": "This motivates the necessity of joint tagging and lemmatization.", "labels": [], "entities": [{"text": "joint tagging", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.7725220322608948}]}, {"text": "For the final experiments, we run pipeline models on tags predicted by and compare them to LEMMING-J, the Unknown word accuracies in the appendix.", "labels": [], "entities": [{"text": "LEMMING-J", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9976940751075745}]}, {"text": "We use the randomization test) and p = .05.", "labels": [], "entities": []}, {"text": "joint model described in Section 3.", "labels": [], "entities": []}, {"text": "All LEMMING versions use exactly the same features.", "labels": [], "entities": []}, {"text": "shows that LEMMING-J outperforms LEMMING-P in three measures (see bold tag, lemma & joint (tag+lemma) accuracies) except for English, where we observe a tie in lemma accuracy and a small drop in tag and tag+lemma accuracy.", "labels": [], "entities": [{"text": "LEMMING-J", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9748364686965942}, {"text": "LEMMING-P", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.886063814163208}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9885787963867188}, {"text": "accuracy", "start_pos": 213, "end_pos": 221, "type": "METRIC", "confidence": 0.9779179096221924}]}, {"text": "Coupling morphological attributes and lemmatization (lines 8-10 vs 11-13) improves tag+lemma prediction for five languages.", "labels": [], "entities": [{"text": "tag+lemma prediction", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.6035232916474342}]}, {"text": "Improvements in lemma accuracy of the joint over the best pipeline systems range from .1 (Spanish), over >.3 (German, Hungarian) to \u2265.96 (Czech, Latin).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9699316620826721}]}, {"text": "Lemma accuracy improvements for our best models (lines 4-13) over the best baseline (lines 2-3) are >1 (German, Spanish, Hungarian), >2 (Czech, Latin) and even more pronounced on unknown forms: >1 (English), >5 (German, Spanish, Hungarian) and >12 (Czech, Latin).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9970011115074158}]}], "tableCaptions": [{"text": " Table 2: Test results for LEMMING-J, the joint model, and pipelines (lines 2-7) of MARMOT and (i) JCK and (ii) LEMMING-P.", "labels": [], "entities": [{"text": "MARMOT", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.8335369825363159}, {"text": "JCK", "start_pos": 99, "end_pos": 102, "type": "DATASET", "confidence": 0.886410117149353}]}, {"text": " Table 1: Lemma accuracy on dev for the baselines and the  different versions of LEMMING-P. POS and morphological  attributes are predicted using MORFETTE. The best baseline  numbers are underlined, the best numbers are bold. Models  significantly better than the best baseline are marked (+).", "labels": [], "entities": [{"text": "Lemma", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9531106352806091}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.8932877779006958}, {"text": "LEMMING-P", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9605541825294495}, {"text": "MORFETTE", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.629734218120575}]}]}