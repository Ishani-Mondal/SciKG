{"title": [{"text": "Talking to the crowd: What do people react to in online discussions?", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper addresses the question of how language use affects community reaction to comments in online discussion forums, and the relative importance of the message vs. the messenger.", "labels": [], "entities": []}, {"text": "A new comment ranking task is proposed based on community annotated karma in Reddit discussions , which controls for topic and timing of comments.", "labels": [], "entities": [{"text": "timing", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9446516036987305}]}, {"text": "Experimental work with discussion threads from six subred-dits shows that the importance of different types of language features varies with the community of interest.", "labels": [], "entities": []}], "introductionContent": [{"text": "Online discussion forums area popular platform for people to share their views about current events and learn about issues of concern to them.", "labels": [], "entities": []}, {"text": "Discussion forums tend to specialize on different topics, and people participating in them form communities of interest.", "labels": [], "entities": []}, {"text": "The reaction of people within a community to comments posted provides an indication of community endorsement of opinions and value of information.", "labels": [], "entities": []}, {"text": "In most discussions, the vast majority of comments spawn little reaction.", "labels": [], "entities": []}, {"text": "In this paper, we look at whether (and how) language use affects the reaction, compared to the relative importance of the author and timing of the post.", "labels": [], "entities": [{"text": "timing", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9663514494895935}]}, {"text": "Early work on factors that appear to influence crowd-based judgments of comments in the Slashdot forum () indicate that timing, starting score, length of the comment, and poster anonymity/reputation appear to play a role (where anonymity has a negative effect).", "labels": [], "entities": [{"text": "timing", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9653404951095581}]}, {"text": "Judging by differences in popularity of various discussion forums, topic is clearly important.", "labels": [], "entities": []}, {"text": "Evidence that language use also matters is provided by recent work (Danescu-Niculescu-Mizil et al.,;).", "labels": [], "entities": []}, {"text": "Teasing these different factors apart, however, is a challenge.", "labels": [], "entities": []}, {"text": "The work presented in this paper provides additional insight into this question by controlling for these factors in a different way than previous work and by examining multiple communities of interest.", "labels": [], "entities": []}, {"text": "Specifically, using data from Reddit discussion forums, we look at the role of author reputation as measured in terms of a karma k-index, and control for topic and timing by ranking comments in a constrained window within a discussion.", "labels": [], "entities": []}, {"text": "The primary contributions of this work include findings about the role of author reputation and variation across communities in terms of aspects of language use that matter, as well as the problem formulation, associated data collection, and development of a variety of features for characterizing informativeness, community response, relevance and mood.", "labels": [], "entities": [{"text": "problem formulation", "start_pos": 189, "end_pos": 208, "type": "TASK", "confidence": 0.7428096532821655}]}], "datasetContent": [{"text": "We present three sets of experiments on comment karma ranking, all of which show very different behavior for the different subreddits.", "labels": [], "entities": [{"text": "comment karma ranking", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7604435284932455}]}, {"text": "shows the relative gain in P@1 over the G&T baseline associated with using different feature groups.", "labels": [], "entities": [{"text": "G&T baseline", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.6830555573105812}]}, {"text": "The importance of the different features reflect the nature of the different communities.", "labels": [], "entities": []}, {"text": "The authority/reputation features help most for ASKSCIENCE, consistent with our k-index study.", "labels": [], "entities": [{"text": "ASKSCIENCE", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.5362711548805237}]}, {"text": "Informativeness and relevance help all subreddits except ASKMEN and WORLDNEWS.", "labels": [], "entities": [{"text": "ASKMEN", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.8662991523742676}, {"text": "WORLDNEWS", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.9083254337310791}]}, {"text": "Lexical, mood and community style features are useful in some cases, but hurt others.", "labels": [], "entities": []}, {"text": "The predicted probability of a reply was least useful, possibly because of the low-karma training bias.", "labels": [], "entities": []}, {"text": "summarize the results for the P@1 and NDCG criteria using the greedy selection procedure (which optimizes P@1) compared to a random baseline and the G&T baseline.", "labels": [], "entities": [{"text": "NDCG", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.8942466974258423}, {"text": "G&T baseline", "start_pos": 149, "end_pos": 161, "type": "DATASET", "confidence": 0.8173984736204147}]}, {"text": "The random baseline for P@1 is greater than 10% because of ties.", "labels": [], "entities": []}, {"text": "The G&T baseline results show that the graph and timing features alone obtain 21-32%    they are so rare.", "labels": [], "entities": [{"text": "G&T baseline", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8315454721450806}, {"text": "timing", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9627462029457092}]}, {"text": "Although our feature selection tunes for high rank precision, it is possible that the low-karma data dominate the learning.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9839087128639221}]}, {"text": "Alternatively, it maybe that language cues are mainly useful for identifying distinguishing the negative or mid-level karma comments, and that the very high karma comments area matter of timing.", "labels": [], "entities": []}, {"text": "To better understand the role of language for these different types, we trained classifiers on balanced data for positive vs. negative karma and high vs. mid levels of karma.", "labels": [], "entities": []}, {"text": "For these models, the training pairs could come from different threads, but topic is controlled for in that all topic features are relative (similarity to original post, parent, etc.).", "labels": [], "entities": []}, {"text": "We compared the results to the binary classifier used in ranking, where all pairs are considered.", "labels": [], "entities": []}, {"text": "In all three cases, random chance accuracy is 50%.", "labels": [], "entities": [{"text": "random chance", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.7451527118682861}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.7744288444519043}]}, {"text": "shows the pairwise accuracy of these classifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9910484552383423}]}, {"text": "We find that distinguishing positive from negative classes is fairly easy, with the notable exception of the more information-oriented subreddit ASKSCIENCE.", "labels": [], "entities": []}, {"text": "Averaging across the different subreddits, the high vs. mid task is slightly easier than the general ranking task, but the variation across subreddits is substantial.", "labels": [], "entities": []}, {"text": "The high vs. mid distinction for FITNESS falls below chance (likely overtraining), whereas it seems to bean easier task for the ASKWOMEN, ASKMEN, and WORLDNEWS.", "labels": [], "entities": [{"text": "FITNESS", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.7992876172065735}, {"text": "chance", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9944398403167725}, {"text": "ASKWOMEN", "start_pos": 128, "end_pos": 136, "type": "DATASET", "confidence": 0.8543894290924072}]}], "tableCaptions": [{"text": " Table 2: Percentage of discussions where the top  comment is made by the top k-index person (or top  3 people) in the discussion.", "labels": [], "entities": []}, {"text": " Table 3: Test set precision of top one prediction  (P@1) performance for specific subreddits.", "labels": [], "entities": [{"text": "precision of top one prediction  (P@1)", "start_pos": 19, "end_pos": 57, "type": "METRIC", "confidence": 0.8106000661849976}]}, {"text": " Table 4: Test set ranking NDCG performance for  specific subreddits.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy of binary classifiers trained on  balanced data to distinguish: positive vs. nega- tive karma (Pos/Neg), high vs. mid-level karma  (High/Mid), and ranking between any pair (Rank- ing).", "labels": [], "entities": []}]}