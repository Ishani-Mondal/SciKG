{"title": [{"text": "Topic Identification and Discovery on Text and Speech", "labels": [], "entities": [{"text": "Topic Identification and Discovery", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7862137854099274}]}], "abstractContent": [{"text": "We compare the multinomial i-vector framework from the speech community with LDA, SAGE, and LSA as feature learners for topic ID on multinomial speech and text data.", "labels": [], "entities": [{"text": "topic ID", "start_pos": 120, "end_pos": 128, "type": "TASK", "confidence": 0.7399587333202362}]}, {"text": "We also compare the learned representations in their ability to discover topics, quantified by dis-tributional similarity to gold-standard topics and by human interpretability.", "labels": [], "entities": []}, {"text": "We find that topic ID and topic discovery are competing objectives.", "labels": [], "entities": [{"text": "topic ID", "start_pos": 13, "end_pos": 21, "type": "TASK", "confidence": 0.8545935750007629}, {"text": "topic discovery", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8321938812732697}]}, {"text": "We argue that LSA and i-vectors should be more widely considered by the text processing community as pre-processing steps for downstream tasks, and also speculate about speech processing tasks that could benefit from more interpretable representations like SAGE.", "labels": [], "entities": []}], "introductionContent": [{"text": "The text processing and speech processing research communities have similar problems and goals, but the technical approaches in these two communities develop largely independently.", "labels": [], "entities": [{"text": "text processing and speech processing research", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.7033651868502299}]}, {"text": "In this paper we compare dimensionality reduction techniques on multinomial language data from the text and speech communities.", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7786110043525696}]}, {"text": "We consider a multinomial formulation of the i-vector model (hereafter \"mi-vector\" model) from the speech community), the sparse additive generative (SAGE)) and latent Dirichlet allocation (LDA) () topic models from the text community, and latent semantic analysis (LSA)).", "labels": [], "entities": []}, {"text": "Both the mi-vector model and the SAGE topic model represent a multinomial parameter vector as the softmax of a sum of vectors, one of which is a background vector representing overall word usage in the corpus, and so we might expect mi-vectors and SAGE to produce similar results on real-world data.", "labels": [], "entities": []}, {"text": "We evaluate these two recent models and two more conventional models, LDA and LSA (a term describing a class of methods based on the singular value decomposition, or SVD, which is used broadly in both research communities).", "labels": [], "entities": []}, {"text": "We assess the similarity of mi-vectors and SAGE and expose the strengths and weaknesses of all four learned representations by evaluating them on the supervised task of topic identification (topic ID), depicted in.", "labels": [], "entities": [{"text": "topic identification (topic ID)", "start_pos": 169, "end_pos": 200, "type": "TASK", "confidence": 0.8129979521036148}]}, {"text": "We also evaluate the representations on the unsupervised, less easily-measurable task of topic discovery.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 89, "end_pos": 104, "type": "TASK", "confidence": 0.7921517789363861}]}, {"text": "As a proxy for controlled human annotations, we quantify topic discovery performance by distributional similarity to gold-standard topics.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.7273841202259064}]}, {"text": "We use the bag-of-words multinomial representation of text data, i.e., each document is represented by a vector of counts over the word vocabulary.", "labels": [], "entities": []}, {"text": "For speech data, we use a modern automatic speech recognition (ASR) system to produce frame-wise triphone state cluster posteriors and we take the sum of these posteriors across all frames in a document to obtain a documentlevel vector of triphone state cluster soft counts.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.8182537853717804}]}, {"text": "Modern topic ID systems for speech use ASR output instead of a lower-resource representation like these soft counts to improve performance.", "labels": [], "entities": [{"text": "topic ID", "start_pos": 7, "end_pos": 15, "type": "TASK", "confidence": 0.7816243171691895}]}, {"text": "ASR word counts are high-resource and can be viewed as a noisy version of word counts from text.", "labels": [], "entities": [{"text": "ASR word counts", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8473023374875387}]}, {"text": "We wish to assess the relative performance of our learned representations, not the quality of the data pre-processing scheme, and we desire to strengthen our results by evaluating performance on two distinct views of a corpus.", "labels": [], "entities": []}, {"text": "Hence we break from convention and use triphone state cluster soft counts as speech data.", "labels": [], "entities": []}, {"text": "While previous work has juxtaposed the mivector model against LDA, the current study is the first to provide cross-community evaluations of mi-vectors and a contemporaneous model from the text community on both text and speech data.", "labels": [], "entities": []}, {"text": "This study is also novel in its direct application of the mi-vector model to topic ID and topic discovery, two separate tasks with different motivations and preferring different types of models, and in its use of low-resource triphone state cluster soft counts as speech data for topic ID.", "labels": [], "entities": [{"text": "topic ID", "start_pos": 77, "end_pos": 85, "type": "TASK", "confidence": 0.8515248596668243}, {"text": "topic discovery", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.840346097946167}, {"text": "topic ID", "start_pos": 280, "end_pos": 288, "type": "TASK", "confidence": 0.8374170064926147}]}, {"text": "The lowresource setting reflects constraints often faced in real-world applications, and we report topic ID performance under limited supervision to better illuminate the practical strengths and weaknesses of the learned representations.", "labels": [], "entities": []}, {"text": "Finally, we believe that the centralized comparison herein of several prominent learned representations on two complementary tasks on both text and speech will provide a useful point of reference for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare these four models of learned representations empirically on two distinct tasks, topic ID and topic discovery.", "labels": [], "entities": [{"text": "topic ID", "start_pos": 91, "end_pos": 99, "type": "TASK", "confidence": 0.7494656145572662}, {"text": "topic discovery", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.7851479053497314}]}, {"text": "The essential implementation details of the models are as follows; further details are provided in the supplement.", "labels": [], "entities": []}, {"text": "We learn the mi-vector model in a maximum a posteriori framework as in McCree and.", "labels": [], "entities": []}, {"text": "Our own C++ implementation of SAGE, available online, 4 uses approximate meanfield variational inference, as in.", "labels": [], "entities": []}, {"text": "We learn the LDA model using Gibbs sampling, implemented in MALLET.", "labels": [], "entities": [{"text": "MALLET", "start_pos": 60, "end_pos": 66, "type": "DATASET", "confidence": 0.7185372710227966}]}, {"text": "We perform LSA using centered tf-idfweighted word counts and centered l 2 -normalized triphone state cluster soft counts.", "labels": [], "entities": [{"text": "LSA", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9594631195068359}]}, {"text": "We implement tf-idf by scaling the raw term count by the log inverse document frequency.", "labels": [], "entities": []}, {"text": "We apply l 2 normalization rather than tf-idf weighting to the speech data because it is dense and tf-idf is thus inappropriate.", "labels": [], "entities": []}, {"text": "On both text and speech, mean-centering is performed after the respective normalization, as this pre-processing recipe performed best of all the variants we tried.", "labels": [], "entities": []}, {"text": "For each of the four models, the lowdimensional real vector \u03b8 (d) represents a given document din our experiments.", "labels": [], "entities": []}, {"text": "We also consider two high-dimensional baseline representations: raw (soft) counts on both the text and speech data, and, only on the text data, tf-idfweighted word counts.", "labels": [], "entities": []}, {"text": "These tf-idf weights constitute a high-dimensional learned representation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Selected topic ID error (%) values from", "labels": [], "entities": []}, {"text": " Table 2: Selected V-measure values from", "labels": [], "entities": []}]}