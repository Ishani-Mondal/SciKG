{"title": [{"text": "A Tableau Prover for Natural Logic and Language", "labels": [], "entities": []}], "abstractContent": [{"text": "Modeling the entailment relation over sentences is one of the generic problems of natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.663502037525177}]}, {"text": "In order to account for this problem, we design a theorem prover for Natural Logic, a logic whose terms resemble natural language expressions.", "labels": [], "entities": []}, {"text": "The prover is based on an analytic tableau method and employs syntactically and semantically motivated schematic rules.", "labels": [], "entities": []}, {"text": "Pairing the prover with a preprocessor, which generates formulas of Natural Logic from linguistic expressions, results in a proof system for natural language.", "labels": [], "entities": []}, {"text": "It is shown that the system obtains a comparable accuracy (\u2248 81%) on the unseen SICK data while achieving the state-of-the-art precision (\u2248 98%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9992303848266602}, {"text": "SICK data", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.7495855391025543}, {"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.997944176197052}]}], "introductionContent": [{"text": "A problem of recognizing textual entailments (RTE)-given two text fragments T (for a text) and H (for a hypothesis), determine whether T entails, contradicts or is neutral to H-is considered as a complex and, at the same time, fundamental problem for several NLP tasks).", "labels": [], "entities": [{"text": "recognizing textual entailments (RTE)-", "start_pos": 13, "end_pos": 51, "type": "TASK", "confidence": 0.8214096575975418}]}, {"text": "For more than a decade, RTE challenges have been held, where systems are competing to each other with respect to human annotated RTE test data; but there are few systems that try to solve RTE problems by computing meanings of linguistic expressions and employing inference engines similar to proof procedures of formal logics.", "labels": [], "entities": [{"text": "RTE", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9748591184616089}, {"text": "RTE problems", "start_pos": 188, "end_pos": 200, "type": "TASK", "confidence": 0.9130672216415405}]}, {"text": "Moreover, those few systems are usually used in combination with shallow classifiers since the systems' performances alone are poor.", "labels": [], "entities": []}, {"text": "The current paper advocates that purely deductive inference engines over linguistic representations backed up with a simple lexical knowledge base could be solely and successfully used for the RTE task.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 193, "end_pos": 201, "type": "TASK", "confidence": 0.9448051154613495}]}, {"text": "Our work builds on the theory of an analytic tableau system for Natural Logic (Natural Tableau) introduced by.", "labels": [], "entities": []}, {"text": "The theory offers to employ a tableau method-a proof procedure used for many formal logics-for the version of Natural Logic that employs Lambda Logical Forms (LLFs)-certain terms of simply typed \u03bb-calculus-as Logical Forms (LFs) of linguistic expressions.", "labels": [], "entities": []}, {"text": "The merits of the current approach are several and they can be grouped in two categories: virtues attributed to the tableau prover are (i) the high precision for the RTE task characteristic to proof procedures, (ii) the transparency of the reasoning process, and (iii) ability for solving problems with several premises; and those concerning LLFs are (iv) an evidence for LFs that are reminiscent of Surface Forms but still retaining complex semantics, and (v) an automatized way of obtaining LLFs from wide-coverage texts.", "labels": [], "entities": [{"text": "precision", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.996246874332428}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, Natural Tableau is introduced, and then a method of obtaining LLFs from raw text is described.", "labels": [], "entities": []}, {"text": "We outline the architecture of an implemented theorem prover that is based on the theory of Natural Tableau.", "labels": [], "entities": []}, {"text": "The power of the prover is evaluated against the SICK data; the results are analyzed and compared to related RTE systems.", "labels": [], "entities": [{"text": "SICK data", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.6858220100402832}]}, {"text": "The paper concludes with future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate LangPro on the unseen portion of the SICK data, SICK-test, which was used as a benchmark at RTE14; the data was also held out from the process of designing LLFgen.", "labels": [], "entities": [{"text": "SICK data", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.6944147348403931}, {"text": "RTE14", "start_pos": 104, "end_pos": 109, "type": "DATASET", "confidence": 0.931620180606842}]}, {"text": "The prover classifies each SICK problem as follows: classify as NEUTRAL; CLOSED, CLOSED: classify as ENTAILMENT; report it; else classify as NEUTRAL; report it; The results, in, show evaluation of LangPro on SICK-test using both parsers separately with the efficient and effective rule application upper bounds.", "labels": [], "entities": []}, {"text": "Slightly better results with the C&C parser is explained by employing the parser in the learning phase.", "labels": [], "entities": []}, {"text": "The difference of .5% in X X X X X X X X X X X  accuracy between the C&C-based and EasyCCGbased provers show that LLFgen was not fitted to the C&C parser's output during the learning phase.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9288702011108398}]}, {"text": "In order to eliminate at some extent errors coming from the parsers, hybrid provers are designed that simply combine answers of two systems-if one of the systems proves a relation then it is an answer.", "labels": [], "entities": []}, {"text": "Both hybrid versions of LangPro show more than 80% of accuracy while only 5 systems were able to do so at RTE14, where 77.1% was a median accuracy.", "labels": [], "entities": [{"text": "LangPro", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.9160168170928955}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9979386925697327}, {"text": "RTE14", "start_pos": 106, "end_pos": 111, "type": "DATASET", "confidence": 0.7498741149902344}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9958392381668091}]}, {"text": "The prover turns out to be extremely reliable with its state-of-the-art precision being almost 98%.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9992803931236267}]}, {"text": "A high precision is conditioned by the formal deductive proof nature of LangPro and by the sound rules it employs.", "labels": [], "entities": [{"text": "precision", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9960616230964661}]}, {"text": "In, we compare the best version of hybrid LangPro to the top 5 systems of RTE14 on SICK-test and show the improvement it gives to each system when blindly adopting its positive answers (i.e. entailment and contradiction).", "labels": [], "entities": [{"text": "RTE14", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.8825502395629883}, {"text": "SICK-test", "start_pos": 83, "end_pos": 92, "type": "DATASET", "confidence": 0.7883869409561157}]}, {"text": "The decision procedure of the prover is completely rule-based and easy to comprehend since it follows the intuitive deductive rules.", "labels": [], "entities": []}, {"text": "Tableaux proofs by LangPro for SICK-247 (in and SICK-2895 (in show step by step how T contradicts and entails, respectively, H. 8 Several new rules employed in these tableaux are given in.", "labels": [], "entities": [{"text": "SICK-2895", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.8416193127632141}]}, {"text": "Note that the both problems, SICK-247, 2895, were wrongly classified by all the top 7 systems of the RTE14.", "labels": [], "entities": [{"text": "SICK-247", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.48725706338882446}, {"text": "RTE14", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.9735148549079895}]}, {"text": "Taking into account that solving SICK-247 requires a sort of De Morgan's law for negation and disjunction, this demonstrates where LangPro, a purely logic-based system, outperforms non-logic-based systems.", "labels": [], "entities": [{"text": "SICK-247", "start_pos": 33, "end_pos": 41, "type": "TASK", "confidence": 0.7295213937759399}]}, {"text": "The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be since solving the problem only requires a lexical knowledge barbell \u2264 weight, which is available in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 224, "end_pos": 231, "type": "DATASET", "confidence": 0.9758658409118652}]}], "tableCaptions": [{"text": " Table 1: Problems from SICK-trial and SICK-train with gold and LangPro judgments.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of the versions of LangPro", "labels": [], "entities": [{"text": "LangPro", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.886182963848114}]}, {"text": " Table 3: Comparing LangPro to the top or related  RTE systems and combining their answers 7", "labels": [], "entities": [{"text": "LangPro", "start_pos": 20, "end_pos": 27, "type": "DATASET", "confidence": 0.7333489060401917}]}]}