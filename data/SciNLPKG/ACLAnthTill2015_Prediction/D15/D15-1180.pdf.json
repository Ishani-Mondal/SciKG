{"title": [{"text": "Molding CNNs for text: non-linear, non-consecutive convolutions", "labels": [], "entities": [{"text": "Molding CNNs", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8971244394779205}]}], "abstractContent": [{"text": "The success of deep learning often derives from well-chosen operational building blocks.", "labels": [], "entities": []}, {"text": "In this work, we revise the temporal convolution operation in CNNs to better adapt it to text processing.", "labels": [], "entities": []}, {"text": "Instead of concatenating word representations , we appeal to tensor algebra and use low-rank n-gram tensors to directly exploit interactions between words already at the convolution stage.", "labels": [], "entities": []}, {"text": "Moreover, we extend the n-gram convolution to non-consecutive words to recognize patterns with intervening words.", "labels": [], "entities": []}, {"text": "Through a combination of low-rank tensors, and pattern weighting, we can efficiently evaluate the resulting con-volution operation via dynamic programming.", "labels": [], "entities": []}, {"text": "We test the resulting architecture on standard sentiment classification and news categorization tasks.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.9276826679706573}]}, {"text": "Our model achieves state-of-the-art performance both in terms of accuracy and training speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9995703101158142}]}, {"text": "For instance , we obtain 51.2% accuracy on the fine-grained sentiment classification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9995656609535217}, {"text": "sentiment classification task", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.8191394209861755}]}], "introductionContent": [{"text": "Deep learning methods and convolutional neural networks (CNNs) among them have become de facto top performing techniques across a range of NLP tasks such as sentiment classification, question-answering, and semantic parsing.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 157, "end_pos": 181, "type": "TASK", "confidence": 0.9378257393836975}, {"text": "semantic parsing", "start_pos": 207, "end_pos": 223, "type": "TASK", "confidence": 0.7215144783258438}]}, {"text": "As methods, they require only limited domain knowledge to reach respectable performance with increasing data and computation, yet permit easy architectural and operational variations so as to fine tune them to specific applications to reach top performance.", "labels": [], "entities": []}, {"text": "Indeed, their success is often contingent on specific architectural and operational choices.", "labels": [], "entities": []}, {"text": "CNNs for text applications make use of temporal convolution operators or filters.", "labels": [], "entities": []}, {"text": "Similar to image processing, they are applied at multiple resolutions, interspersed with non-linearities and pooling.", "labels": [], "entities": [{"text": "image processing", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.8706357777118683}]}, {"text": "The convolution operation itself is a linear mapping over \"n-gram vectors\" obtained by concatenating consecutive word (or character) representations.", "labels": [], "entities": []}, {"text": "We argue that this basic building block can be improved in two important respects.", "labels": [], "entities": []}, {"text": "First, the power of n-grams derives precisely from multi-way interactions and these are clearly missed (initially) with linear operations on stacked n-gram vectors.", "labels": [], "entities": []}, {"text": "Non-linear interactions within a local context have been shown to improve empirical performance in various tasks.", "labels": [], "entities": []}, {"text": "Second, many useful patterns are expressed as non-consecutive phrases, such as semantically close multi-word expressions (e.g.,\"not that good\", \"not nearly as good\").", "labels": [], "entities": []}, {"text": "In typical CNNs, such expressions would have to come together and emerge as useful patterns after several layers of processing.", "labels": [], "entities": []}, {"text": "We propose to use a feature mapping operation based on tensor products instead of linear operations on stacked vectors.", "labels": [], "entities": []}, {"text": "This enables us to directly tap into non-linear interactions between adjacent word feature vectors).", "labels": [], "entities": []}, {"text": "To offset the accompanying parametric explosion we maintain a low-rank representation of the tensor parameters.", "labels": [], "entities": []}, {"text": "Moreover, we show that this feature mapping can be applied to all possible non-consecutive n-grams in the sequence with an exponentially decaying weight depending on the length of the span.", "labels": [], "entities": []}, {"text": "Owing to the low rank representation of the tensor, this operation can be performed efficiently in linear time with respect to the sequence length via dynamic programming.", "labels": [], "entities": []}, {"text": "Similar to traditional convolution operations, our non-linear feature mapping can be applied successively at multiple levels.", "labels": [], "entities": []}, {"text": "We evaluate the proposed architecture in the context of sentence sentiment classification and news categorization.", "labels": [], "entities": [{"text": "sentence sentiment classification", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.8296356995900472}]}, {"text": "On the Stanford Sentiment Treebank dataset, our model obtains state-of-theart performance among a variety of neural networks in terms of both accuracy and training cost.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank dataset", "start_pos": 7, "end_pos": 42, "type": "DATASET", "confidence": 0.9053951650857925}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9992247819900513}]}, {"text": "Our model achieves 51.2% accuracy on finegrained classification and 88.6% on binary classification, outperforming the best published numbers obtained by a deep recursive model) and a convolutional model).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995660185813904}, {"text": "finegrained classification", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.7033078670501709}]}, {"text": "On the Chinese news categorization task, our model achieves 80.0% accuracy, while the closest baseline achieves 79.2%.", "labels": [], "entities": [{"text": "Chinese news categorization task", "start_pos": 7, "end_pos": 39, "type": "DATASET", "confidence": 0.7096165865659714}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9987068176269531}]}], "datasetContent": [{"text": "Datasets We evaluate our model on sentence sentiment classification task and news categorization task.", "labels": [], "entities": [{"text": "sentence sentiment classification", "start_pos": 34, "end_pos": 67, "type": "TASK", "confidence": 0.8438782493273417}]}, {"text": "For sentiment classification, we use the Stanford Sentiment Treebank benchmark).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.9765548706054688}, {"text": "Stanford Sentiment Treebank benchmark", "start_pos": 41, "end_pos": 78, "type": "DATASET", "confidence": 0.9082407802343369}]}, {"text": "The dataset consists of 11855 parsed English sentences annotated at both the root (i.e. sentence) level and the phrase level using 5-class fine-grained labels.", "labels": [], "entities": []}, {"text": "We use the standard 8544/1101/2210 split for training, development and testing respectively.", "labels": [], "entities": []}, {"text": "Following previous work, we also evaluate our model on the binary classification variant of this benchmark, ignoring all neutral sentences.", "labels": [], "entities": []}, {"text": "The binary version has 6920/872/1821 sentences for training, development and testing.", "labels": [], "entities": [{"text": "6920/872/1821 sentences", "start_pos": 23, "end_pos": 46, "type": "DATASET", "confidence": 0.8404008547465006}]}, {"text": "For the news categorization task, we evaluate on Sogou Chinese news corpora.", "labels": [], "entities": [{"text": "Sogou Chinese news corpora", "start_pos": 49, "end_pos": 75, "type": "DATASET", "confidence": 0.9676315039396286}]}, {"text": "The dataset contains 10 different news categories in total, including Finance, Sports, Technology and Automobile etc.", "labels": [], "entities": []}, {"text": "We use 79520 documents for training, 9940 for development and 9940 for testing.", "labels": [], "entities": [{"text": "79520 documents", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.9309946596622467}]}, {"text": "To obtain Chinese word boundaries, we use LTP-Cloud , an open-source Chinese NLP platform.", "labels": [], "entities": []}, {"text": "Baselines We implement the standard SVM method and the neural bag-of-words model NBoW as baseline methods in both tasks.", "labels": [], "entities": []}, {"text": "To assess the proposed tensor-based feature map, we also implement a convolutional neural network model CNN by replacing our filter with traditional linear filter.", "labels": [], "entities": []}, {"text": "The rest of the framework (such as feature averaging and concatenation) remains the same.", "labels": [], "entities": [{"text": "feature averaging", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7322990000247955}]}, {"text": "In addition, we compare our model with a wide range of top-performing models on the sentence sentiment classification task.", "labels": [], "entities": [{"text": "sentence sentiment classification task", "start_pos": 84, "end_pos": 122, "type": "TASK", "confidence": 0.8785852193832397}]}, {"text": "Most of these models fall into either the category of recursive neural networks (RNNs) or the category of convolutional neural networks (CNNs) and the most recent recursive model using long-short-term-memory units RLSTM (.", "labels": [], "entities": [{"text": "RLSTM", "start_pos": 214, "end_pos": 219, "type": "DATASET", "confidence": 0.7675418853759766}]}, {"text": "These recursive models assume the input sentences are represented as parse trees.", "labels": [], "entities": []}, {"text": "As a benefit, they can readily utilize annotations at the phrase level.", "labels": [], "entities": []}, {"text": "In contrast, convolutional neural networks are trained on sequence-level, taking the original sequence and its label as training input.", "labels": [], "entities": []}, {"text": "Such convolutional baselines include the dynamic CNN with k-max pooling DCNN () and the convolutional model with multi-channel CNN-MC by.", "labels": [], "entities": []}, {"text": "To leverage the phrase-level annotations in the Stanford Sentiment Treebank, all phrases and the corresponding labels are added as separate instances when training the sequence models.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank", "start_pos": 48, "end_pos": 75, "type": "DATASET", "confidence": 0.8290886680285136}]}, {"text": "We follow this strategy and report results with and without phrase annotations.", "labels": [], "entities": []}, {"text": "Word vectors The word vectors are pre-trained on much larger unannotated corpora to achieve better generalization given limited amount of training data . In particular, for the English sentiment classification task, we use the publicly available 300-dimensional GloVe word vectors trained on the Common Crawl with 840B tokens ().", "labels": [], "entities": [{"text": "English sentiment classification task", "start_pos": 177, "end_pos": 214, "type": "TASK", "confidence": 0.7889483422040939}, {"text": "Common Crawl", "start_pos": 296, "end_pos": 308, "type": "DATASET", "confidence": 0.9402340352535248}]}, {"text": "This choice of word vectors follows most recent work, such as DAN ().", "labels": [], "entities": []}, {"text": "For Chinese news categorization, there is no widely-used publicly available word vectors.", "labels": [], "entities": [{"text": "Chinese news categorization", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.6558999121189117}]}, {"text": "Therefore, we run word2vec () to train 200-dimensional word vectors on the 1.6 million Chinese news articles.", "labels": [], "entities": []}, {"text": "Both word vectors are normalized to unit norm (i.e. w 2 2 = 1) and are fixed in the experiments without fine-tuning.", "labels": [], "entities": []}, {"text": "Hyperparameter setting We perform an extensive search on the hyperparameters of our full model, our implementation of the CNN model (with linear filters), and the SVM baseline.", "labels": [], "entities": []}, {"text": "For our model and the CNN model, the initial learning rate of AdaGrad is fixed to 0.01 for sentiment classification and 0.1 for news categorization, and the L2 regularization weight is fixed to 1e \u2212 5 and 1e \u2212 6 respectively based on preliminary runs.", "labels": [], "entities": [{"text": "initial learning rate", "start_pos": 37, "end_pos": 58, "type": "METRIC", "confidence": 0.847830613454183}, {"text": "AdaGrad", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9148938655853271}, {"text": "sentiment classification", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.9539225697517395}]}, {"text": "The rest of the hyperparameters are randomly chosen as follows: number of feature-mapping layers \u2208 {1, 2, 3}, n-gram order n \u2208 {2, 3}, hidden feature dimension h \u2208 {50, 100, 200}, dropout probability \u2208 {0.0, 0.1, 0.3, 0.5}, and length de-cay \u03bb \u2208 {0.0, 0.3, 0.5}.", "labels": [], "entities": []}, {"text": "We run each configuration 3 times to explore different random initializations.", "labels": [], "entities": []}, {"text": "For the SVM baseline, we tune L2 regularization weight C \u2208 {0.01, 0.1, 1.0, 10.0}, word cut-off frequency \u2208 {1, 2, 3, 5} (i.e. pruning words appearing less than this times) and n-gram feature order n \u2208 {1, 2, 3}.", "labels": [], "entities": []}, {"text": "Implementation details The source code is implemented in Python using the Theano library (), a flexible linear algebra compiler that can optimize userspecified computations (models) with efficient automatic low-level implementations, including (back-propagated) gradient calculation.", "labels": [], "entities": [{"text": "Theano library", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.9256310164928436}]}, {"text": "presents the performance of our model and other baseline methods on Stanford Sentiment Treebank benchmark.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank benchmark", "start_pos": 68, "end_pos": 105, "type": "DATASET", "confidence": 0.9445183277130127}]}, {"text": "Our full model obtains the highest accuracy on both the development and test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9995518326759338}]}, {"text": "Specifically, it achieves 51.2% and 88.6% test accuracies on fine-grained and binary tasks respectively 5 . As shown in, our model performance is relatively stable -it remains high accuracies with around 0.5% standard deviation under different initializations and dropout rates.", "labels": [], "entities": [{"text": "test accuracies", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.6936480402946472}]}, {"text": "Fine-grained Dev 52.5 (\u00b10.5) %   79.2% obtained by the neural bag-of-words model and CNN model.", "labels": [], "entities": []}, {"text": "In contrast, our model obtains 80.0% accuracy on both the development and test sets, outperforming the three baselines by a 0.8% absolute margin.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9996277093887329}]}, {"text": "The best hyperparameter configuration in this task uses less feature layers and lower n-gram order (specifically, 2 layers and n = 2) compared to the sentiment classification task.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 150, "end_pos": 174, "type": "TASK", "confidence": 0.9243091940879822}]}, {"text": "We hypothesize that the difference is due to the nature of the two tasks: the document classification task requires to handle less compositions or context interactions than sentiment analysis.", "labels": [], "entities": [{"text": "document classification", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7694441974163055}, {"text": "sentiment analysis", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.8463905453681946}]}], "tableCaptions": [{"text": " Table 1: Comparison between our model and other baseline methods on Stanford Sentiment Treebank.  The top block lists recursive neural network models, the second block are convolutional network mod- els and the third block contains other baseline methods, including the paragraph-vector model (Le and  Mikolov, 2014), the deep averaging network model (Iyyer et al., 2015) and our implementation of neural  bag-of-words. The training time of baseline methods is taken from (Iyyer et al., 2015) or directly from  the authors. For our implementations, timings were performed on a single core of a 2.6GHz Intel i7  processor.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank", "start_pos": 69, "end_pos": 96, "type": "DATASET", "confidence": 0.9331936637560526}]}, {"text": " Table 2: Analysis of average accuracy and stan- dard deviation of our model on sentiment classifi- cation task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9865357279777527}, {"text": "stan- dard deviation", "start_pos": 43, "end_pos": 63, "type": "METRIC", "confidence": 0.948985293507576}]}, {"text": " Table 3: Performance of various methods on Chi- nese news categorization task. Our model obtains  better results than the SVM, NBoW and traditional  CNN baselines.", "labels": [], "entities": [{"text": "Chi- nese news categorization task", "start_pos": 44, "end_pos": 78, "type": "TASK", "confidence": 0.6002249618371328}, {"text": "NBoW", "start_pos": 128, "end_pos": 132, "type": "DATASET", "confidence": 0.9247605204582214}, {"text": "CNN baselines", "start_pos": 150, "end_pos": 163, "type": "DATASET", "confidence": 0.8971500098705292}]}]}