{"title": [{"text": "Learning Word Meanings and Grammar for Describing Everyday Activities in Smart Environments", "labels": [], "entities": [{"text": "Describing Everyday Activities in Smart Environments", "start_pos": 39, "end_pos": 91, "type": "TASK", "confidence": 0.8547722895940145}]}], "abstractContent": [{"text": "If intelligent systems are to interact with humans in a natural manner, the ability to describe daily life activities is important.", "labels": [], "entities": []}, {"text": "To achieve this, sensing human activities by capturing multimodal information is necessary.", "labels": [], "entities": []}, {"text": "In this study, we consider a smart environment for sensing activities with respect to realistic scenarios.", "labels": [], "entities": []}, {"text": "We next propose a sentence generation system from observed multimodal information in a bottom up manner using mul-tilayered multimodal latent Dirichlet allocation and Bayesian hidden Markov models.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7367465794086456}]}, {"text": "We evaluate the grammar learning and sentence generation as a complete process within a realistic setting.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.749909520149231}]}, {"text": "The experimental result reveals the effectiveness of the proposed method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Describing daily life activities is an important ability of intelligent systems.", "labels": [], "entities": [{"text": "Describing daily life activities", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8980848789215088}]}, {"text": "In fact, we can use this ability to achieve a monitoring system that is able to report on an observed situation, or create an automatic diary of a user.", "labels": [], "entities": []}, {"text": "Recently, several studies have been performed to generate sentences that describe images using Deep Learning (.", "labels": [], "entities": []}, {"text": "Although these results were good, we are interested in unsupervised frameworks.", "labels": [], "entities": []}, {"text": "This is necessary to achieve a system that can adapt to the user, that is, one that can learn a user-unique language and generate it automatically.", "labels": [], "entities": []}, {"text": "Moreover, the use of crowdsourcing should be avoided to respect the privacy of the user.", "labels": [], "entities": []}, {"text": "Regarding this, studies on sentence generation from RGB videos have been discussed in (.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7475272119045258}]}, {"text": "A promising result for language learning has been shown in) and a quite challenging effort to describe cooking activities was made in (.", "labels": [], "entities": []}, {"text": "However, these studies rely only on visual information, while we aim to build a system that is able to describe everyday activities using multimodal information.", "labels": [], "entities": []}, {"text": "To realize such systems, we need to consider two problems.", "labels": [], "entities": []}, {"text": "The first problem is the sensing of daily life activities.", "labels": [], "entities": [{"text": "sensing of daily life", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.8472425788640976}]}, {"text": "In this paper, we utilize a smart house () for sensing human activities.", "labels": [], "entities": []}, {"text": "Thanks to the smart house, multimodal information such as visual, motion, and audio data can be captured.", "labels": [], "entities": []}, {"text": "The second problem to be tackled is verbalization of the observed scenes.", "labels": [], "entities": []}, {"text": "To solve this problem, a multilayered multimodal latent Dirichlet allocation (mMLDA) was proposed in (.", "labels": [], "entities": []}, {"text": "In this paper, we propose a sentence generation system from observed scenes in a bottom up manner using mMLDA and a Bayesian hidden Markov model (BHMM).", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.738866537809372}, {"text": "mMLDA", "start_pos": 104, "end_pos": 109, "type": "DATASET", "confidence": 0.9219952821731567}, {"text": "BHMM", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.785876989364624}]}, {"text": "To generate sentences from scenes, we need to consider the words that represent the scenes and their order.", "labels": [], "entities": []}, {"text": "Here, mMLDA is used to infer words forgiven scenes.", "labels": [], "entities": [{"text": "mMLDA", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.786021888256073}]}, {"text": "To determine the order of words, inspired by), a probabilistic grammar that considers syntactic information is learned using BHMM.", "labels": [], "entities": [{"text": "BHMM", "start_pos": 125, "end_pos": 129, "type": "DATASET", "confidence": 0.6821375489234924}]}, {"text": "In this study, the order of concepts is generated by sampling the learned grammar.", "labels": [], "entities": []}, {"text": "The word selection for each generated concept is then performed using the observed data.", "labels": [], "entities": [{"text": "word selection", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6947486996650696}]}, {"text": "Moreover, a language model that represents the relationship between words is also used to calculate  the transition probability between them.", "labels": [], "entities": []}, {"text": "Considering the transition probability at word level, a lattice of word candidates corresponding to the concept sequence can be generated.", "labels": [], "entities": []}, {"text": "Therefore, sentence generation can bethought of as a problem of finding the word sequence that has the highest probability from the lattice of word candidates, which can be solved by the Viterbi algorithm.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7711359262466431}]}, {"text": "Finally, sampling from grammar is performed multiple times to generate sentence candidates and select the most probable one.", "labels": [], "entities": []}, {"text": "2 Proposed method 2.1 Overview illustrates the overall system of proposed language learning and sentence generation.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7433094829320908}]}, {"text": "In this study, we use a smart environment for sensing multimodal information.", "labels": [], "entities": []}, {"text": "The system shown in is part of a smart house ( that is used to capture multimodal information.", "labels": [], "entities": []}, {"text": "Here, an RFID tag is attached to an object to enable the object information to be read using a wearable tag reader.", "labels": [], "entities": []}, {"text": "To capture motion, five sensors that consist of 3-axis acceleration with 3-axis gyroscope sensors are attached to the upper body, as shown in.", "labels": [], "entities": []}, {"text": "Moreover, a particle filterbased human tracker () applied to four laser range finders is used to estimate the location of a person while performing an action.", "labels": [], "entities": []}, {"text": "This is a setup designed to demonstrate that language can be learned and generated from real human actions.", "labels": [], "entities": []}, {"text": "Ultimately, our goal is sensing based on image recognition.", "labels": [], "entities": [{"text": "image recognition", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7209055125713348}]}, {"text": "The acquired multimodal data is then processed, which results in a bag-of-words model (BoW) and bag-of-features model (BoF) ().", "labels": [], "entities": [{"text": "bag-of-features model (BoF)", "start_pos": 96, "end_pos": 123, "type": "METRIC", "confidence": 0.6846782147884369}]}, {"text": "Using mMLDA (see section 2.2), various concepts can be formed from the multimodal data.", "labels": [], "entities": [{"text": "mMLDA", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.9280140995979309}]}, {"text": "Given teaching sentences, the connection between words and concepts can be learned based on mMLDA and BHMM which is learned with mutual information (MI) as the initial value.", "labels": [], "entities": [{"text": "mMLDA", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.8985949158668518}, {"text": "BHMM", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9602545499801636}, {"text": "mutual information (MI)", "start_pos": 129, "end_pos": 152, "type": "METRIC", "confidence": 0.6564738988876343}]}, {"text": "On the other hand, the bigram model of words is calculated and used as the score when reordering words inferred from multimodal information using grammar.", "labels": [], "entities": []}, {"text": "A morphological analyzer for parsing words in a sentence is also necessary in the proposed system.", "labels": [], "entities": [{"text": "parsing words in a sentence", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.8507344126701355}]}, {"text": "We use publicly available parser MeCab ().", "labels": [], "entities": []}, {"text": "In the future, we plan to use the unsupervised morphological analysis technique proposed in ().", "labels": [], "entities": []}, {"text": "shows the graphical model of mMLDA used in this paper.", "labels": [], "entities": [{"text": "mMLDA", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9321020245552063}]}, {"text": "Here, z represents the integrated category (concept), whereas z O , z M , and z P represent the object, mo-tion, and place concepts, respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "The acquisition system shown in was used to capture multimodal information from human actions.", "labels": [], "entities": []}, {"text": "shows the actions that were performed by three subjects twice, resulting in a total of 195 multimodal data with 1170 sentences.", "labels": [], "entities": []}, {"text": "We then divided the data into training data (99 multimodal data with 594 sentences) and test data (96 multimodal data with 576 sentences).", "labels": [], "entities": []}, {"text": "Some examples of acquired multimodal data are shown in(b).", "labels": [], "entities": []}, {"text": "Using training data, various concepts were formed by mMLDA, and the categorization accuracies for object, motion, and place were respectively 100.00%, 52.53%, and 95.96%.", "labels": [], "entities": [{"text": "mMLDA", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.9358702898025513}]}, {"text": "Motion similarity was responsible for the false cat-  egorization of motion concepts.", "labels": [], "entities": []}, {"text": "Since our goal is to generate sentences from observed scenes, these results are used as reference instead of comparing with the baseline.", "labels": [], "entities": []}, {"text": "To evaluate the concept selection of words, 98 words in teaching sentences were used.", "labels": [], "entities": []}, {"text": "We compared the results of concept selection with handlabeled ones.", "labels": [], "entities": []}, {"text": "shows the accuracy rate of concept selection.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996310472488403}, {"text": "concept selection", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.6627657115459442}]}, {"text": "Here, we excluded the functional words (resulting in 78 words) for fair comparison with the baseline method ().", "labels": [], "entities": []}, {"text": "One can see that, better results can be achieved by the proposed method.", "labels": [], "entities": []}, {"text": "It is clear that concept selection is improved by using the BHMM, indicating that a better grammar can be learned using this model.", "labels": [], "entities": [{"text": "concept selection", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7467055022716522}, {"text": "BHMM", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.8669529557228088}]}, {"text": "Next, the learned grammar was used and sentences were generated.", "labels": [], "entities": []}, {"text": "To reduce randomness of the results, sentence generation was conducted 10 times for each data.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7590816020965576}]}, {"text": "To verify sentence generation quantitatively, we evaluated the sentences automatically using BLEU score ().", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7134175002574921}, {"text": "BLEU score", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9833452701568604}]}, {"text": "depicts the results of 2-to 4-gram of BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.997751772403717}]}, {"text": "Since functional words are not considered in, we used our grammar and performed sentence generation proposed in) as the baseline method.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7383965849876404}]}, {"text": "One can see from the figure that in all cases the BLEU scores of proposed method out performs the baseline method.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9990056157112122}]}, {"text": "It can be said that the sentences generated by the proposed method are of better quality than those generated by the baseline method.", "labels": [], "entities": []}, {"text": "Moreover, we also manually evaluated generated sentences by asking four subjects (i.e., college students who understand Japanese) whether the sentences were: correct both in grammar and meaning (E1), grammatically correct but incorrect in meaning (E2), grammatically incorrect but correct in meaning (E3), or incorrect both in grammar and meaning (E4).", "labels": [], "entities": []}, {"text": "The average rates of E1, E2, E3, and E4 were shown in.", "labels": [], "entities": []}, {"text": "We can see that the proposed method out performs the baseline method by providing high rates of E1 and E2; and low rates of E4.", "labels": [], "entities": []}, {"text": "Because we want to generate sentences that explain actions, incorrect motion in-   ference would lead to incorrect sentence generation.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7551877498626709}]}, {"text": "Examples of E2 are \"Eating the plastic wrap in the dining room\" and \"Opening the dressing in the kitchen.\"", "labels": [], "entities": [{"text": "E2", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.7073047757148743}]}, {"text": "One can see that these sentences are grammatically correct but do not express the scenes correctly because the words that represent the motion are incorrect.", "labels": [], "entities": []}, {"text": "Hence, the misclassification that occurred in the motion concept formation was responsible for the incorrect meaning of the generated sentences.(c) shows the sentences generated from the given scenes).", "labels": [], "entities": []}, {"text": "We can see that meaningful yet natural sentences that explain the observed scenes can be generated using the proposed method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Concepts selection results.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results of generated sentences.", "labels": [], "entities": []}]}