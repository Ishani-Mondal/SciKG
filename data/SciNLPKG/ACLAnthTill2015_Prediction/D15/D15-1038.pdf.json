{"title": [{"text": "Traversing Knowledge Graphs in Vector Space", "labels": [], "entities": [{"text": "Traversing Knowledge Graphs", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8127790292104086}]}], "abstractContent": [{"text": "Path queries on a knowledge graph can be used to answer compositional questions such as \"What languages are spoken by people living in Lisbon?\".", "labels": [], "entities": []}, {"text": "However, knowledge graphs often have missing facts (edges) which disrupts path queries.", "labels": [], "entities": []}, {"text": "Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.6480527520179749}]}, {"text": "We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors.", "labels": [], "entities": []}, {"text": "This motivates anew \"compositional\" training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9966801404953003}]}, {"text": "On a standard knowledge base completion task, we also demonstrate that com-positional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Broad-coverage knowledge bases such as Freebase () support a rich array of reasoning and question answering applications, but they are known to suffer from incomplete coverage ().", "labels": [], "entities": [{"text": "Freebase", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9647130370140076}, {"text": "question answering", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.6889370828866959}]}, {"text": "For example, as of May 2015, Freebase has an entity Tad Lincoln (Abraham Lincoln's son), but does not have his ethnicity.", "labels": [], "entities": []}, {"text": "An elegant solution to incompleteness is using vector space representations: Controlling the dimensionality of the vector space forces generalization to new facts (.", "labels": [], "entities": []}, {"text": "In the example, we would hope to infer Tad's ethnicity from the ethnicity of his parents.", "labels": [], "entities": []}, {"text": "However, what is missing from these vector space models is the original strength of knowledge bases: the ability to support compositional queries.", "labels": [], "entities": []}, {"text": "For example, we might ask what the ethnicity of Abraham Lincoln's daughter would be.", "labels": [], "entities": [{"text": "Abraham Lincoln's daughter", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.7088968679308891}]}, {"text": "This can be formulated as a path query on the knowledge graph, and we would like a method that can answer this efficiently, while generalizing over missing facts and even missing or hypothetical entities (Abraham Lincoln did not in fact have a daughter).", "labels": [], "entities": []}, {"text": "In this paper, we present a scheme to answer path queries on knowledge bases by \"compositionalizing\" abroad class of vector space models that have been used for knowledge base completion (see.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 161, "end_pos": 186, "type": "TASK", "confidence": 0.6273709336916605}]}, {"text": "At a high level, we interpret the base vector space model as implementing a soft edge traversal operator.", "labels": [], "entities": []}, {"text": "This operator can then be recursively applied to predict paths.", "labels": [], "entities": []}, {"text": "Our interpretation suggests anew compositional training objective that encourages better modeling of paths.", "labels": [], "entities": []}, {"text": "Our technique is applicable to abroad class of composable models that includes the bilinear model) and TransE (.", "labels": [], "entities": [{"text": "TransE", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.7928389310836792}]}, {"text": "We have two key empirical findings: First, we show that compositional training enables us to answer path queries up to at least length 5 by substantially reducing cascading errors present in the base vector space model.", "labels": [], "entities": []}, {"text": "Second, we find that somewhat surprisingly, compositional training also improves upon state-of-the-art performance for knowledge base completion, which is a special case of answering unit length path queries.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.6297406355539957}, {"text": "answering unit length path queries", "start_pos": 173, "end_pos": 207, "type": "TASK", "confidence": 0.787209939956665}]}, {"text": "Therefore, compositional training can also be seen as anew form of structural regularization for existing models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In Section 4.1, we describe two standard knowledge base completion datasets.", "labels": [], "entities": []}, {"text": "These consist of single-edge queries, so we call them base datasets.", "labels": [], "entities": []}, {"text": "In Section 4.2, we generate path query datasets from these base datasets.", "labels": [], "entities": []}, {"text": "Our experiments are conducted using the subsets of WordNet and Freebase from.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9817934036254883}]}, {"text": "The statistics of these datasets and their splits are given in.", "labels": [], "entities": []}, {"text": "The WordNet and Freebase subsets exhibit substantial differences that can influence model performance.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9576118588447571}]}, {"text": "The Freebase subset is almost bipartite with most of the edges taking the form (s, r, t) for some person s, relation rand property t.", "labels": [], "entities": [{"text": "Freebase subset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9494206309318542}]}, {"text": "In WordNet, both the source and target entities are arbitrary words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.9475317001342773}]}, {"text": "Both the raw WordNet and Freebase contain many relations that are almost perfectly correlated with an inverse relation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.9610267877578735}, {"text": "Freebase", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.8823795914649963}]}, {"text": "For example, WordNet contains both has part and part of, and Freebase contains both parents and children.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.9635846018791199}]}, {"text": "At test time, a query on an edge (s, r, t) is easy to answer if the inverse triple (t, r \u22121 , s) was observed in the training set.", "labels": [], "entities": []}, {"text": "Following, we account for this by excluding such \"trivial\" queries from the test set.", "labels": [], "entities": []}, {"text": "Given abase knowledge graph, we generate path queries by performing random walks on the graph.", "labels": [], "entities": []}, {"text": "If we view compositional training as a form of regularization, this approach allows us to generate extremely large amounts of auxiliary training data.", "labels": [], "entities": []}, {"text": "The procedure is given below.", "labels": [], "entities": []}, {"text": "Let G train be the training graph, which consists only of the edges in the training set of the base dataset.", "labels": [], "entities": []}, {"text": "We then repeatedly generate training examples with the following procedure: 1.", "labels": [], "entities": []}, {"text": "Uniformly sample a path length L \u2208 {1, . .", "labels": [], "entities": []}, {"text": ", L max }, and uniformly sample a starting entity s \u2208 E.", "labels": [], "entities": []}, {"text": "2. Perform a random walk beginning at entity sand continuing L steps.", "labels": [], "entities": []}, {"text": "(a) At step i of the walk, choose a relation r i uniformly from the set of relations incident on the current entity e.", "labels": [], "entities": []}, {"text": "(b) Choose the next entity uniformly from the set of entities reachable via r i . In practice, we do not sample paths of length 1 and instead directly add all of the edges from G train to the path query dataset.", "labels": [], "entities": []}, {"text": "To generate a path query test set, we repeat the above procedure except using the graph G full , which is G train plus all of the test edges from the base dataset.", "labels": [], "entities": []}, {"text": "Then we remove any queries from the test set that also appeared in the training set.", "labels": [], "entities": []}, {"text": "The statistics for the path query datasets are presented in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: WordNet and Freebase statistics for base  and path query datasets.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.9721401333808899}]}, {"text": " Table 2: Path query answering and knowledge base completion. We compare the performance of  single-edge training (SINGLE) vs compositional training (COMP). MQ: mean quantile, H@10: hits at 10,  %red: percentage reduction in error.", "labels": [], "entities": [{"text": "Path query answering", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8087510267893473}, {"text": "knowledge base completion", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6466214656829834}, {"text": "percentage reduction in error", "start_pos": 201, "end_pos": 230, "type": "METRIC", "confidence": 0.853322371840477}]}, {"text": " Table 4: Path query performance (mean quantile) on a selection of interpretable queries. We compare  Bilinear SINGLE and Bilinear COMP.", "labels": [], "entities": []}, {"text": " Table 3: Deduction and induction. We compare  mean quantile performance of single-edge training  (SINGLE) vs compositional training (COMP). Length  1 queries are excluded.", "labels": [], "entities": []}, {"text": " Table 5: Model performance in terms of accu- racy. EV: entity vectors are separate (initialized  randomly); WV: entity vectors are average of word  vectors (initialized with pretrained word vectors).", "labels": [], "entities": []}]}