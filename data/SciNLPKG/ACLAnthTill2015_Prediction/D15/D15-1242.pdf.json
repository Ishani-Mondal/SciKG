{"title": [{"text": "Specializing Word Embeddings for Similarity or Relatedness", "labels": [], "entities": [{"text": "Similarity or Relatedness", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.8874930938084921}]}], "abstractContent": [{"text": "We demonstrate the advantage of specializing semantic word embeddings for either similarity or relatedness.", "labels": [], "entities": []}, {"text": "We compare two variants of retrofitting and a joint-learning approach, and find that all three yield specialized semantic spaces that capture human intuitions regarding similarity and re-latedness better than unspecialized spaces.", "labels": [], "entities": []}, {"text": "We also show that using specialized spaces in NLP tasks and applications leads to clear improvements, for document classification and synonym selection, which rely on either similarity or relatedness but not both.", "labels": [], "entities": [{"text": "document classification", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.7848821580410004}, {"text": "synonym selection", "start_pos": 134, "end_pos": 151, "type": "TASK", "confidence": 0.9515929222106934}]}], "introductionContent": [{"text": "Most current models of semantic word representation exploit the distributional hypothesis: the idea that words occurring in similar contexts have similar meanings.", "labels": [], "entities": [{"text": "semantic word representation", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6292721430460612}]}, {"text": "Such representations (or embeddings) can reflect human intuitions about similarity and relatedness, and have been applied to a wide variety of NLP tasks, including bilingual lexicon induction (), sentiment analysis () and named entity recognition ().", "labels": [], "entities": [{"text": "bilingual lexicon induction", "start_pos": 164, "end_pos": 191, "type": "TASK", "confidence": 0.6440853675206503}, {"text": "sentiment analysis", "start_pos": 196, "end_pos": 214, "type": "TASK", "confidence": 0.9603135287761688}, {"text": "named entity recognition", "start_pos": 222, "end_pos": 246, "type": "TASK", "confidence": 0.6760244568188986}]}, {"text": "Arguably, one of the reasons behind the popularity of word embeddings is that they are \"general purpose\": they can be used in a variety of tasks without modification.", "labels": [], "entities": []}, {"text": "Although this behavior is sometimes desirable, it may in other cases be detrimental to downstream performance.", "labels": [], "entities": []}, {"text": "For example, when classifying documents by topic, we are particularly interested in related words rather than similar ones: knowing that dog is associated with cat is much more informative of the topic than knowing that it is a synonym of canine.", "labels": [], "entities": []}, {"text": "Conversely, if our embeddings indicate that table is closely related to chair, that does not mean we should translate table into French as chaise.", "labels": [], "entities": []}, {"text": "This distinction between \"genuine\" similarity and associative similarity (i.e., relatedness) is well-known in cognitive science.", "labels": [], "entities": []}, {"text": "In NLP, however, semantic spaces are generally evaluated on how well they capture both similarity and relatedness, even though, for many word combinations (such as car and petrol), these two objectives are mutually incompatible ().", "labels": [], "entities": []}, {"text": "In part, this oversight stems from the distributional hypothesis itself: car and petrol do not have the same, or even very similar, meanings, but these two words may well occur in similar contexts.", "labels": [], "entities": []}, {"text": "Corpus-driven approaches based on the distributional hypothesis therefore generally learn embeddings that capture both similarity and relatedness reasonably well, but neither perfectly.", "labels": [], "entities": []}, {"text": "In this work we demonstrate the advantage of specializing semantic spaces for either similarity or relatedness.", "labels": [], "entities": []}, {"text": "Specializing for similarity is achieved by learning from both a corpus and a thesaurus, and for relatedness by learning from both a corpus and a collection of psychological association norms.", "labels": [], "entities": []}, {"text": "We also compare the recentlyintroduced technique of graph-based retrofitting) with a skip-gram retrofitting and a skip-gram joint-learning approach.", "labels": [], "entities": []}, {"text": "All three methods yield specialized semantic spaces that capture human intuitions regarding similarity and relatedness significantly better than unspecialized spaces, in one case yielding state-of-the-art results for word similarity.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 217, "end_pos": 232, "type": "TASK", "confidence": 0.7405961453914642}]}, {"text": "More importantly, we show clear improvements in downstream tasks and applications: specialized similarity spaces improve synonym detection, while association spaces work better than both general-purpose and similarityspecialized spaces for document classification.", "labels": [], "entities": [{"text": "synonym detection", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.9138487577438354}, {"text": "document classification", "start_pos": 240, "end_pos": 263, "type": "TASK", "confidence": 0.7331861555576324}]}], "datasetContent": [{"text": "For instrinsic comparisons with human judgements, we evaluate on SimLex () (999 pairwise comparisons), which explicitly measures similarity, and MEN () (3000 comparisons), which explicitly measures relatedness.", "labels": [], "entities": []}, {"text": "We also consider two downstream tasks and applications.", "labels": [], "entities": []}, {"text": "In the TOEFL synonym selection task, the objective is to select the correct synonym fora target word from a multiple-choice set of possible answers.", "labels": [], "entities": [{"text": "TOEFL synonym selection task", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.9060618281364441}]}, {"text": "For a more extrinsic evaluation, we use a document classification task based on the Reuters Corpus Volume 1 (RCV1) ().", "labels": [], "entities": [{"text": "document classification", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.7529777586460114}, {"text": "Reuters Corpus Volume 1 (RCV1)", "start_pos": 84, "end_pos": 114, "type": "DATASET", "confidence": 0.9681073597499302}]}, {"text": "This dataset consists of over 800,000 manually categorized news articles.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Spearman \u03c1 on a genuine similarity  (SimLex-999) and relatedness (MEN) dataset.", "labels": [], "entities": [{"text": "Spearman \u03c1", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8313844203948975}, {"text": "SimLex-999) and relatedness (MEN) dataset", "start_pos": 47, "end_pos": 88, "type": "DATASET", "confidence": 0.5894106514751911}]}, {"text": " Table 2: TOEFL synonym selection and docu- ment classification accuracy (percentage of cor- rectly answered questions/correctly classified doc- uments).", "labels": [], "entities": [{"text": "TOEFL synonym selection", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7511386473973592}, {"text": "docu- ment classification", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.5675868913531303}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9444800019264221}]}]}