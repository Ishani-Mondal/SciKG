{"title": [{"text": "Identification and Verification of Simple Claims about Statistical Properties", "labels": [], "entities": [{"text": "Identification", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9702044725418091}]}], "abstractContent": [{"text": "In this paper we study the identification and verification of simple claims about statistical properties, e.g. claims about the population or the inflation rate of a country.", "labels": [], "entities": []}, {"text": "We show that this problem is similar to extracting numerical information from text and following recent work, instead of annotating data for each property of interest in order to learn supervised models, we develop a distantly supervised base-line approach using a knowledge base and raw text.", "labels": [], "entities": []}, {"text": "In experiments on 16 statistical properties about countries from Freebase we show that our approach identifies simple statistical claims about properties with 60% precision, while it is able to verify these claims without requiring any explicit supervision for either tasks.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.9637438058853149}, {"text": "precision", "start_pos": 163, "end_pos": 172, "type": "METRIC", "confidence": 0.9985412359237671}]}, {"text": "Furthermore, we evaluate our approach as a statistical property extractor and we show it achieves 0.11 mean absolute percentage error.", "labels": [], "entities": [{"text": "statistical property extractor", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.6703178584575653}, {"text": "mean absolute percentage error", "start_pos": 103, "end_pos": 133, "type": "METRIC", "confidence": 0.8222848027944565}]}], "introductionContent": [{"text": "Statistical properties are commonly used to describe entities, e.g. population for countries, net value for companies, points scored for athletes, etc.", "labels": [], "entities": []}, {"text": "Claims about such properties are very common in news articles and social media, however they can be erroneous, either due to author error or negligence at the time of writing or because they eventually become out of date.", "labels": [], "entities": []}, {"text": "While manual verification (also referred to as factchecking) is conducted by journalists in news organizations and dedicated websites such as www.", "labels": [], "entities": []}, {"text": "emergent.info, the volume of the claims calls for automated approaches, which is one of the main objectives of computational journalism.", "labels": [], "entities": []}, {"text": "In this paper we develop a baseline approach to identify and verify simple claims about statistical Text: Lesotho, a landlocked enclave of South Africa, has a population of nearly 2 million and covers an area slightly smaller than the U.S. state of Maryland.", "labels": [], "entities": [{"text": "statistical Text", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.5991033613681793}]}, {"text": "Entity: Lesotho Property: population Value claimed in text: 2,000,000 Value in knowledge base: 2,193,843 Absolute percentage error: 0.09 properties against a database.", "labels": [], "entities": [{"text": "Absolute percentage error", "start_pos": 105, "end_pos": 130, "type": "METRIC", "confidence": 0.9665150046348572}]}, {"text": "The task is illustrated in.", "labels": [], "entities": []}, {"text": "Given a sentence, we first identify whether it contains a claim about a property we are interested in (population in the example), which entity it is about and the value claimed (Lesotho and 2,000,000 respectively).", "labels": [], "entities": []}, {"text": "We then proceed to verify the value claimed in text for the property of this entity against the value known in a knowledge base such as Freebase and return a score reflecting the accuracy of the claim (absolute percentage error in the example).", "labels": [], "entities": [{"text": "Freebase", "start_pos": 136, "end_pos": 144, "type": "DATASET", "confidence": 0.9431860446929932}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9989098310470581}, {"text": "absolute percentage error", "start_pos": 202, "end_pos": 227, "type": "METRIC", "confidence": 0.8451699217160543}]}, {"text": "Claim identification is essentially an instance of information extraction.", "labels": [], "entities": [{"text": "Claim identification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8671112954616547}, {"text": "information extraction", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7980834543704987}]}, {"text": "While it would be possible to develop supervised models, this would require expensive manual data annotation for each property of interest.", "labels": [], "entities": []}, {"text": "Instead, we follow the distant supervision paradigm) using supervision obtained by combining triples from a knowledge base and raw text.", "labels": [], "entities": []}, {"text": "However, statistical properties are more challenging in applying the distant supervision assumption than relations between named entities due to the fact that the numerical values are often approximated in text, as in the example of.", "labels": [], "entities": []}, {"text": "Consequently, linking the values mentioned in text with those in the knowledge base is not trivial and thus it is not straightforward to generate training instances for the property of interest.", "labels": [], "entities": []}, {"text": "To address this issue, we propose a distantly supervised claim identification approach that relies on approximate instead of exact matching between values in text and the knowledge base.", "labels": [], "entities": [{"text": "claim identification", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7278811186552048}]}, {"text": "In experiments on 16 statistical properties about countries from Freebase we show that our approach identifies simple statistical claims with 60% precision, while it is able to verify these claims without requiring any explicit supervision for this task.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.9614608287811279}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9985654950141907}]}, {"text": "In developing our approach, we also evaluate it as a statistical property extractor achieving 0.11 mean absolute percentage error.", "labels": [], "entities": [{"text": "statistical property extractor", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.6424295902252197}, {"text": "mean absolute percentage error", "start_pos": 99, "end_pos": 129, "type": "METRIC", "confidence": 0.8673803210258484}]}, {"text": "The code and the datasets developed are publicly available from https://github.com/ uclmr/simpleNumericalFactChecker.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first evaluate our approach as a statistical property extractor for two reasons.", "labels": [], "entities": [{"text": "statistical property extractor", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.664365828037262}]}, {"text": "First, while our main goal is to develop a claim identification approach, there is no data for this task to evaluate, thus making development difficult.", "labels": [], "entities": [{"text": "claim identification", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.8168319165706635}]}, {"text": "On the other hand, we can evaluate statistical property extraction in a straightforward way, thus facilitating development and parameter tuning.", "labels": [], "entities": [{"text": "statistical property extraction", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.7476784785588583}, {"text": "parameter tuning", "start_pos": 127, "end_pos": 143, "type": "TASK", "confidence": 0.7143642902374268}]}, {"text": "Second, the algorithm described learns such an extractor, thus it is of interest to know its performance.", "labels": [], "entities": []}, {"text": "We split the values collected from Freebase into 2/3 for training and 1/3 for testing, ensuring that all regions are present in both datasets.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.9808173179626465}]}, {"text": "The accuracy is evaluated using MAPE.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995614886283875}, {"text": "MAPE", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.5372772812843323}]}, {"text": "When using adjusted MAPE we set the parameter c for each property using 4-fold cross-validation.", "labels": [], "entities": []}, {"text": "The performance of Algorithm 1 using the unadjusted MAPE was 0.72 averaged overall properties.", "labels": [], "entities": []}, {"text": "Using the adjusted version this was greatly improved to 0.49.", "labels": [], "entities": []}, {"text": "We also evaluated the InformedGuess prediction which returns the same value for all regions (it chooses the value that performs best among the mean, the median and 0), and its overall MAPE was 0.79.", "labels": [], "entities": [{"text": "MAPE", "start_pos": 184, "end_pos": 188, "type": "METRIC", "confidence": 0.9991843104362488}]}, {"text": "Recalling that Algorithm 1 returns the InformedGuess in case no pattern is found for an entity, we also evaluate the performance without returning a value for such entities, thus ignoring them in the evaluation.", "labels": [], "entities": [{"text": "InformedGuess", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.9612425565719604}]}, {"text": "In that case the performance with unadjusted MAPE improves to 0.17 but 10% coverage, while with adjusted MAPE it improves to 0.11 with 43% coverage.", "labels": [], "entities": [{"text": "MAPE", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9756796956062317}, {"text": "coverage", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9954207539558411}, {"text": "MAPE", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9531633853912354}]}, {"text": "Best performances were achieved for relations such as population which have a wide range of values that is well separated from the rest, while percentage rates were usually harder for the opposite reason.", "labels": [], "entities": []}, {"text": "Thus we conclude that the algorithm with adjusted MAPE selects better patterns for each property that are encountered more frequently, which is important for the main goal of this paper, claim identification.", "labels": [], "entities": [{"text": "MAPE", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.8034071922302246}, {"text": "claim identification", "start_pos": 187, "end_pos": 207, "type": "TASK", "confidence": 0.7810713052749634}]}], "tableCaptions": [{"text": " Table 1: Property and text patterns associated with entity-value pairs.", "labels": [], "entities": []}, {"text": " Table 2: Claim identification results.", "labels": [], "entities": [{"text": "Claim identification", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8632844388484955}]}]}