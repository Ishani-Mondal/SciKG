{"title": [{"text": "An Entity-centric Approach for Overcoming Knowledge Graph Sparsity", "labels": [], "entities": [{"text": "Overcoming Knowledge Graph Sparsity", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.6935755610466003}]}], "abstractContent": [{"text": "Automatic construction of knowledge graphs (KGs) from unstructured text has received considerable attention in recent research, resulting in the construction of several KGs with millions of entities (nodes) and facts (edges) among them.", "labels": [], "entities": []}, {"text": "Unfortunately, such KGs tend to be severely sparse in terms of number of facts known fora given entity , i.e., have low knowledge density.", "labels": [], "entities": []}, {"text": "For example, the NELL KG consists of only 1.34 facts per entity.", "labels": [], "entities": [{"text": "NELL KG", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.48809076845645905}]}, {"text": "Unfortunately , such low knowledge density makes it challenging to use such KGs in real-world applications.", "labels": [], "entities": []}, {"text": "In contrast to best-effort extraction paradigms followed in the construction of such KGs, in this paper we argue in favor of ENTIty Centric Expansion (ENTICE), an entity-centric KG population framework , to alleviate the low knowledge density problem in existing KGs.", "labels": [], "entities": [{"text": "best-effort extraction", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.7687364220619202}]}, {"text": "By using ENTICE, we are able to increase NELL's knowledge density by a factor of 7.7 at 75.5% accuracy.", "labels": [], "entities": [{"text": "ENTICE", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.91752028465271}, {"text": "NELL", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.9067555665969849}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9973368048667908}]}, {"text": "Additionally, we are also able to extend the ontology discovering new relations and entities.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the last few years, automatic construction of knowledge graphs (KGs) from webscale text data has received considerable attention, resulting in the construction of several large KGs such as NELL (), Google's Knowledge Vault ().", "labels": [], "entities": []}, {"text": "These KGs consist of millions of entities and facts involving them.", "labels": [], "entities": []}, {"text": "While measuring size of the KGs in terms of number of entities and facts is helpful, they don't readily capture the volume of knowledge needed in: Any new fact involving a source entity from a Knowledge Graph (i.e., facts of the form entity1-relation-entity2 where entity1 is already in the KG) can be classified into one of the four extraction classes shown above.", "labels": [], "entities": []}, {"text": "Most KG population techniques tend to focus on extracting facts of the KR-KE class.", "labels": [], "entities": []}, {"text": "ENTICE, the entity-centric approach proposed in this paper, is able to extract facts of all four classes.", "labels": [], "entities": [{"text": "ENTICE", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6708248853683472}]}, {"text": "When such a KG is used in an application, one is often interested in known facts fora given entity, and not necessarily the overall size of the KG.", "labels": [], "entities": []}, {"text": "In particular, knowing the average number of facts per entity is quite informative.", "labels": [], "entities": []}, {"text": "We shall refer to this as the knowledge density of the KG.", "labels": [], "entities": [{"text": "KG", "start_pos": 55, "end_pos": 57, "type": "DATASET", "confidence": 0.8976604342460632}]}, {"text": "Low knowledge density (or high sparsity) in automatically constructed KGs has been recognized in recent research).", "labels": [], "entities": []}, {"text": "For example, NELL KG has a knowledge density of 1.34.", "labels": [], "entities": [{"text": "NELL KG", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.7249316871166229}]}, {"text": "Such low knowledge density puts significant limitations on the utility of these KGs.", "labels": [], "entities": []}, {"text": "Construction of such KGs tend to follow a batch paradigm: the knowledge extraction system makes a full pass over the text corpus extracting whatever knowledge it finds, and finally aggregating all extractions into a graph.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7145077586174011}]}, {"text": "Clearly, such best-effort extraction paradigm has proved to be inadequate to address the low knowledge density issue mentioned above.", "labels": [], "entities": [{"text": "best-effort extraction", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7462716102600098}]}, {"text": "We refer to such paradigm as best-effort since its attention is divided equally among all possible entities.", "labels": [], "entities": []}, {"text": "Recently, a few entity-centric methods have been proposed to increase knowledge density in KGs ().", "labels": [], "entities": []}, {"text": "In contrast to the best-effort approaches mentioned above, these entity-centric approaches aim at increasing knowledge density fora given entity.", "labels": [], "entities": []}, {"text": "A new fact involving the given entity can belong to one of the four types shown in.", "labels": [], "entities": []}, {"text": "Unfortunately, these densifying techniques only aim at identifying instances of known relations among entities already present in the KG, i.e., they fall in the KR-KE type of.", "labels": [], "entities": []}, {"text": "In this paper we propose ENTIty Centric Expansion (ENTICE), an entity-centric knowledge densifying framework which, given an entity, is capable of extracting facts belonging to all the four types shown in.", "labels": [], "entities": [{"text": "ENTIty Centric Expansion (ENTICE)", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.6435725639263788}]}, {"text": "By using ENTICE, we are able to increase NELL's knowledge density by a factor of 7.7 1 , while achieving 75.4% accuracy.", "labels": [], "entities": [{"text": "ENTICE", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9410649538040161}, {"text": "NELL", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.8969692587852478}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9983141422271729}]}, {"text": "Our goal here is to draw attention to the effectiveness of entity-centric approaches with bigger scope (i.e., covering all four extraction classes in) towards improving knowledge density, and that even relatively straightforward techniques can go along way in alleviating low knowledge density in existing state-ofthe-art KGs.", "labels": [], "entities": []}, {"text": "ENTICE code is available at: https://github.com/malllabiisc/entity-centrickb-pop", "labels": [], "entities": [{"text": "ENTICE", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8533174395561218}]}], "datasetContent": [{"text": "In order to evaluate effectiveness of ENTICE, we apply it to increase knowledge density for 100 randomly selected entities from each of the following five NELL categories: Scientist, Universities, Books, Birds, and Cars.", "labels": [], "entities": []}, {"text": "For each category, a random subset of extractions in that category was evaluated using Mechanical Turk.", "labels": [], "entities": []}, {"text": "To get a better accuracy of the evaluation, each fact was evaluated by 3 workers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9993508458137512}]}, {"text": "Workers were made to classify each fact as correct, incorrect or can't say.", "labels": [], "entities": []}, {"text": "Only those facts classified as correct by 2 or more evaluators were considered as correct facts.", "labels": [], "entities": []}, {"text": "Main Result: Experimental results comparing knowledge densities in NELL and after application of ENTICE, along with the accuracy of extractions, are presented in.", "labels": [], "entities": [{"text": "NELL", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.5346065163612366}, {"text": "ENTICE", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.8142879009246826}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.999065101146698}]}, {"text": "From this, we observe that ENTICE is able to improve knowledge density in NELL by a factor of 7.7 while maintaining 75.5% accuracy.", "labels": [], "entities": [{"text": "NELL", "start_pos": 74, "end_pos": 78, "type": "TASK", "confidence": 0.6553248763084412}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9976733326911926}]}, {"text": "Sample extraction examples and accuracy perextraction class are presented in, respectively.", "labels": [], "entities": [{"text": "Sample extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7515794932842255}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9981043338775635}]}, {"text": "Noun and Relation Phrase Normalization: We didn't perform any intrinsic evaluation of the entity and relation normalization step.", "labels": [], "entities": [{"text": "Noun and Relation Phrase Normalization", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6939280390739441}, {"text": "relation normalization", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.7375711798667908}]}, {"text": "However, in this section, we provide a few anecdotal examples to give a sense of the output quality from this step.", "labels": [], "entities": []}, {"text": "We observe that the canopy clustering algorithm for entity and normalization is able to cluster together facts with somewhat different surface representations.", "labels": [], "entities": [{"text": "entity and normalization", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.5973766545454661}]}, {"text": "For example, the algorithm came up with the following cluster with two facts: {(J. Willard Milnor, was awarded, 2011 Abel Prize); (John Milnor, received, Abel Prize)}.", "labels": [], "entities": []}, {"text": "It is encouraging to see that the system is able to put J.", "labels": [], "entities": [{"text": "J", "start_pos": 56, "end_pos": 57, "type": "TASK", "confidence": 0.9406591057777405}]}, {"text": "Willard Milnor and John Milnor together, even though they have somewhat different surface forms (only one word overlap).", "labels": [], "entities": []}, {"text": "Similarly, the relation phrases was awarded and received are also considered to be equivalent in the context of these beliefs.", "labels": [], "entities": []}, {"text": "Integrating with Knowledge Graph: Based on evaluation over a random-sampling, we find that entity linking in ENTICE is 92% accurate, while relation linking is about 70% accurate.", "labels": [], "entities": []}, {"text": "In the entity linking stage, adjectives present in a noun phrase (NP) were ignored while matching the noun phrase to entities in the knowledge graph (NELL KB in this case).", "labels": [], "entities": []}, {"text": "In case the whole NP didn't find any match, part of the NP was used to retrieve its category, if any.", "labels": [], "entities": []}, {"text": "For example, in (Georg Waldemar Cantor, was born in, 1854), the NP Georg Waldemar Cantor was mapped to category person using his last name and 1854 to category date.", "labels": [], "entities": []}, {"text": "The relation phrase \"was born in\" maps to many predicates in NELL relational metadata.", "labels": [], "entities": []}, {"text": "NELL predicate AtDate was selected based on the rule that category signature of the predicate matches the category of the noun phrases present in the triple.", "labels": [], "entities": [{"text": "NELL predicate AtDate", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5564477145671844}]}, {"text": "It also has the highest frequency count for the relational phrase in the metadata.", "labels": [], "entities": [{"text": "frequency count", "start_pos": 24, "end_pos": 39, "type": "METRIC", "confidence": 0.9004282057285309}]}, {"text": "We observed that relation mapping has lesser accuracy due to two reasons.", "labels": [], "entities": [{"text": "relation mapping", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.9473010003566742}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9985060691833496}]}, {"text": "Firstly, error in determining right categories of NPs present in a triple; and secondly, due to higher ambiguity involving relation phrases in general, i.e., a single relation phrase usually matches many relation predicates in the ontology.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1.  In this paper we propose ENTIty Centric  Expansion (ENTICE), an entity-centric  knowledge densifying framework which, given  an entity, is capable of extracting facts be- longing to all the four types shown in", "labels": [], "entities": []}, {"text": " Table 1.  By using ENTICE, we are able to increase  NELL's knowledge density by a factor of 7.7 1 ,  while achieving 75.4% accuracy. Our goal  here is to draw attention to the effectiveness  of entity-centric approaches with bigger scope  (i.e., covering all four extraction classes in", "labels": [], "entities": [{"text": "ENTICE", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9356518387794495}, {"text": "NELL", "start_pos": 53, "end_pos": 57, "type": "TASK", "confidence": 0.8702130913734436}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9985302686691284}]}, {"text": " Table 2: Knowledge densities of five categories in NELL and after application of ENTICE, along  with resulting accuracy. We observe that overall, ENTICE is able to increase knowledge density  by a factor of 7.7 at 75.5% accuracy. This is our main result.", "labels": [], "entities": [{"text": "NELL", "start_pos": 52, "end_pos": 56, "type": "TASK", "confidence": 0.5158174633979797}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.999345600605011}, {"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.9979224801063538}]}, {"text": " Table 3: Facts corresponding to an entity from the scientists domain in NELL as well as those  extracted by ENTICE. While NELL contained only one fact for this entity, ENTICE was able  to extract 15 facts for this entity, only 3 of which are shown above.", "labels": [], "entities": [{"text": "NELL", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.7635722160339355}]}, {"text": " Table 4: Accuracy breakdown over ENTICE extractions for each of the four extraction classes  in", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9986536502838135}, {"text": "ENTICE extractions", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7181892395019531}]}, {"text": " Table 1. For each category, approximately 200 extractions were evaluated using Mechanical  Turk.", "labels": [], "entities": []}]}