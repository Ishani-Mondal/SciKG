{"title": [{"text": "Online Representation Learning in Recurrent Neural Language Models", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate an extension of continuous online learning in recurrent neural network language models.", "labels": [], "entities": []}, {"text": "The model keeps a separate vector representation of the current unit of text being processed and adaptively adjusts it after each prediction.", "labels": [], "entities": []}, {"text": "The initial experiments give promising results, indicating that the method is able to increase language modelling accuracy, while also decreasing the parameters needed to store the model along with the computation required at each step.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7192884683609009}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9499905109405518}]}], "introductionContent": [{"text": "In recent years, neural network models have shown impressive performance on many natural language processing tasks, such as speech recognition (, machine translation (), text classification () and image description generation (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.7518027722835541}, {"text": "machine translation", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.7480663359165192}, {"text": "text classification", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7963500916957855}, {"text": "image description generation", "start_pos": 197, "end_pos": 225, "type": "TASK", "confidence": 0.8038579026858012}]}, {"text": "One of the main advantages of these methods is the ability to learn smooth vector representations for words, thereby reducing the sparsity problem inherent in any natural language dataset.", "labels": [], "entities": []}, {"text": "Language modelling is another task where neural networks have delivered excellent results).", "labels": [], "entities": [{"text": "Language modelling", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7810637354850769}]}, {"text": "have recently benchmarked several well-known language models by training on very large datasets.", "labels": [], "entities": []}, {"text": "They found that a recurrent neural network language model (RNNLM) combined with a 9-gram MaxEnt model was able to give the best results and lowest perplexity.", "labels": [], "entities": []}, {"text": "In this work we investigate a possible extension of RNNLM, by allowing it to continue learning and adapting during testing.", "labels": [], "entities": []}, {"text": "The model keeps a vector representation of the current sentence that is being processed, and continuously modifies it based on an error signal.", "labels": [], "entities": []}, {"text": "We refer to this as aversion of online learning, as gradient descent is used to optimise the vector even during testing.", "labels": [], "entities": []}, {"text": "The technique is inspired by work on representation learning, especially who use a related model to learn representations for text classification.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.9158299267292023}, {"text": "text classification", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7349573373794556}]}, {"text": "We extend the idea to recurrent models and apply it to the task of language modelling.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.7842646539211273}]}, {"text": "Our results indicate that by exchanging some existing model parameters fora component using online learning, the system is able to achieve lower perplexity while also reducing the necessary computation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We constructed a dataset from English Wikipedia to evaluate language modelling performance over individual sentences.", "labels": [], "entities": []}, {"text": "The text was tokenised, sentence split and lowercased.", "labels": [], "entities": []}, {"text": "The sentences were shuffled, in order to minimise any transfer effects between consecutive sentences, and then split into training, development and test sets.", "labels": [], "entities": []}, {"text": "The final sentences were sampled randomly, in order to obtain reasonable training times for the experiments.", "labels": [], "entities": []}, {"text": "The dataset sizes are shown in  Model performance is measured using perplexity, therefore lower values indicate a model which is able to better predict the data.", "labels": [], "entities": []}, {"text": "Special tokens are used to mark the beginning and end of a sentence.", "labels": [], "entities": []}, {"text": "The sentence end token is also included in the evaluation, whereas the sentence start token is only used as context in the input layer.", "labels": [], "entities": []}, {"text": "Any words that occur less than 30 times in the training data were replaced by a special token for unknown words, leaving a vocabulary of 16,514 unique words.", "labels": [], "entities": []}, {"text": "General learning rate was set to 0.1 and decreased during training, whereas the learning rate of the document vector was fixed at 0.1 for both training and testing.", "labels": [], "entities": [{"text": "General learning rate", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.7576716740926107}]}, {"text": "As the baseline, we use the regular RNNLM with 100-dimensional hidden layers and word vectors (M = 100).", "labels": [], "entities": []}, {"text": "In the experiments we increase the capacity of the model and measure how that affects the perplexity on the datasets.", "labels": [], "entities": []}, {"text": "First, we increase the value of M, allowing more information to be stored into word representations, while also increasing the number of hidden-hidden and hidden-output connections.", "labels": [], "entities": []}, {"text": "As can be seen in Table 1, this improves the overall performance of the Next, instead of increasing M , we add a Ddimensional document vector to the model and use this for online learning.", "labels": [], "entities": [{"text": "M", "start_pos": 100, "end_pos": 101, "type": "METRIC", "confidence": 0.9547101259231567}]}, {"text": "When the same number of elements is added to M or D, our results show consistently better performance when using the document vector.", "labels": [], "entities": []}, {"text": "Increasing M by 35 gives perplexity 95.71, whereas using a 35-dimensional document vector gives perplexity 90.29.", "labels": [], "entities": []}, {"text": "We also performed the same experiment using only half of the training data, and the difference was even larger -105.50 and 98.23 correspondingly.", "labels": [], "entities": []}, {"text": "One reason why online learning during model deployment is not commonly used is because it is computationally expensive.", "labels": [], "entities": []}, {"text": "Continuously retraining the model and adjusting parameters can be very time-consuming compared to a simple feedforward process through the network.", "labels": [], "entities": []}, {"text": "However, extra computation is also needed when using a hidden vector of size M , as opposed to using a smaller value.", "labels": [], "entities": []}, {"text": "When increasing the value of M to M + X, the RNNLM will contain additional parameters and needs to perform additional operations at each time step.", "labels": [], "entities": []}, {"text": "2 C is the number of classes, V is vocabulary size, and E is the expected number of words that need to be processed in the output layer during one step.", "labels": [], "entities": []}, {"text": "The corresponding number of additional parameters in a RNNLM model using a D-dimensional document vector for online learning is contains the additional values for the experiments, showing that replacing some hidden vector parameters with the actively learned document vector leads to fewer total parameters and fewer operations, along with lower perplexity.", "labels": [], "entities": []}, {"text": "presents the relationship between perplexity and the number of additional parameters, when increasing either M or D.", "labels": [], "entities": []}, {"text": "The results are averaged over 10 runs with different random initialisations.", "labels": [], "entities": []}, {"text": "As can be seen, using a small document vector lowers the perplexity with fewer parameters, compared to simply increasing the main components of the network.", "labels": [], "entities": []}, {"text": "The graph of perplexity with respect to additional operations in the model also has a very similar shape.", "labels": [], "entities": []}, {"text": "Both Hufnagel and Marston also joined the long-standing technical death metal band Gorguts.", "labels": [], "entities": []}, {"text": "1. The band eventually went onto become the post-hardcore band Adair.", "labels": [], "entities": []}, {"text": "2. The band members originally came from different death metal bands, bonding over a common interest in d-beat.", "labels": [], "entities": []}, {"text": "3. The proceeds went towards a home studio, which enabled him to concentrate on his solo output and songs that were to become his debut mini-album \"Feeding The Wolves\".", "labels": [], "entities": []}, {"text": "The Chiefs reclaimed the title on September 29, 2014 in a Monday Night Football game against the New England Patriots, hitting 142.2 decibels.", "labels": [], "entities": []}, {"text": "1. He played in twenty-four regular season games for the Colts, all off the bench.", "labels": [], "entities": []}, {"text": "2. In May 2009 the Warriors announced they had re-signed him until the end of the 2011 season.", "labels": [], "entities": []}, {"text": "3. The team played inconsistently throughout the campaign from the outset, losing the opening two matches before winning four consecutive games during September 1927.", "labels": [], "entities": []}, {"text": "He was educated at Llandovery College and Jesus College, Oxford, where he obtained an M.A. degree.", "labels": [], "entities": []}, {"text": "1. He studied at the Orthodox High School, then at the Faculty of Mathematics.", "labels": [], "entities": [{"text": "Orthodox High School", "start_pos": 21, "end_pos": 41, "type": "DATASET", "confidence": 0.9568260113398234}]}, {"text": "2. Kaigama studied for the priesthood at St. Augustine's Seminary in Jos with further study in theology in Rome.", "labels": [], "entities": []}, {"text": "3. Under his stewardship, Zahira College became one of the leading schools in the country.: Examples of using the document vectors to find similar sentences in the development data.", "labels": [], "entities": []}, {"text": "In order to further explore the relationship between D and M , we trained a number of smaller models with different values, under the constraint D + M = 100.", "labels": [], "entities": []}, {"text": "To reduce computation time, only half of the training data was used in these experiments.", "labels": [], "entities": []}, {"text": "The lowest perplexity was achieved in the region of D = 23 and M = 77, and making the document vectors much smaller or larger led to a decrease in performance.", "labels": [], "entities": [{"text": "D", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.9638724327087402}, {"text": "M = 77", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9472336967786154}]}, {"text": "This indicates that including the document vector does help increase model accuracy, but as it contains no information about the training data, this vector should be small compared to the main model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9939985275268555}]}, {"text": "Intuitively, this approach works by having the document vector capture the unique aspects of each sentence.", "labels": [], "entities": []}, {"text": "While the general RNNLM is a smooth static representation of the entire training data, the document vector is optimised to represent how each sentence differs from the main language model.", "labels": [], "entities": []}, {"text": "Therefore we performed a qualitative evaluation and found that the learned sentence vectors were also very good predictors of semantic similarity.", "labels": [], "entities": []}, {"text": "The RNN language model was trained on the training set, and then used to process the development set.", "labels": [], "entities": []}, {"text": "The last state of the document vector of each sentence was used to calculate cosine similarity.", "labels": [], "entities": []}, {"text": "contains randomly sampled sentences from the development set, together with corresponding development sentences that have the highest similarity (excluding the original sentence).", "labels": [], "entities": []}, {"text": "Even though there is almost no word overlap, the retrieved sentences are semantically very similar.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Perplexity and additional parameters/operations for different language model configurations", "labels": [], "entities": []}]}