{"title": [{"text": "A Transition-based Model for Joint Segmentation, POS-tagging and Normalization", "labels": [], "entities": [{"text": "Joint Segmentation", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7772807776927948}, {"text": "Normalization", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.9020034074783325}]}], "abstractContent": [{"text": "We propose a transition-based model for joint word segmentation, POS tagging and text normalization.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.6616639494895935}, {"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.8809426724910736}, {"text": "text normalization", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7865979075431824}]}, {"text": "Different from previous methods, the model can be trained on standard text corpora, overcoming the lack of annotated microblog corpora.", "labels": [], "entities": []}, {"text": "To evaluate our model, we develop an annotated corpus based on microblogs.", "labels": [], "entities": []}, {"text": "Experimental results show that our joint model can help improve the performance of word segmentation on microblogs, giving an error reduction in segmentation accuracy of 12.02%, compared to the traditional approach .", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.7679305672645569}, {"text": "error reduction", "start_pos": 126, "end_pos": 141, "type": "METRIC", "confidence": 0.9730813205242157}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.8375025391578674}]}], "introductionContent": [{"text": "Microblogs, such as Twitter, SMS and Weibo, has become an important research topic in NLP.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.9467733502388}]}, {"text": "Previous work has shown that off-the-shelf NLP tools can perform poorly on microblogs).", "labels": [], "entities": []}, {"text": "One of the major challenges for microblog processing is the issue of informal words.", "labels": [], "entities": [{"text": "microblog processing", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8757612109184265}]}, {"text": "For example, \"tmrw\" has been frequently used in tweets for \"tomorrow\", causing OOV problems.", "labels": [], "entities": [{"text": "OOV", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.7931647300720215}]}, {"text": "Text normalization has been introduced as a pre-processing step for microblog processing, which transforms informal words into their standard forms.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7193525284528732}, {"text": "microblog processing", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.7735850214958191}]}, {"text": "Most work in the literature focuses on English microblog normalization, treating it as a noisy channel problem ( or a translation problem (, and training models based on words.", "labels": [], "entities": [{"text": "English microblog normalization", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.5710501174132029}]}, {"text": "Lack of annotated corpora, text normalization is more challenging for Chinese.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7657122910022736}]}, {"text": "Unlike English, Chinese informal words are more difficult * corresponding author to mechanically normalize for two main reasons.", "labels": [], "entities": []}, {"text": "First, Chinese does not have word delimiters.", "labels": [], "entities": []}, {"text": "Second, Chinese informal words manifest diversity, such as abbreviations, neologisms, unconventional spellings and phonetic substitutions.", "labels": [], "entities": []}, {"text": "Intuitively, there is mutual dependency between Chinese word segmentation and normalization, and therefore two tasks should be solved jointly.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.584385871887207}]}, {"text": "proposed a joint model to process word segmentation and informal word detection.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7162332534790039}, {"text": "word detection", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.7256943136453629}]}, {"text": "However, text normalization was not included in the joint model.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.81389120221138}]}, {"text": "proposed a joint model for word segmentation, POS tagging and normalization for Japanese Microblogs, which was trained on a partially annotated microblog corpus.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.795847088098526}, {"text": "POS tagging", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.7522698938846588}, {"text": "Japanese Microblogs", "start_pos": 80, "end_pos": 99, "type": "DATASET", "confidence": 0.9111460447311401}]}, {"text": "Their method requires special annotation for text normalization, which can be expensive.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8185620009899139}]}, {"text": "In this paper, we propose a joint model for Chinese text normalization, word-segmentation and POS tagging, which can be trained using standard segmentation and POS tagging annotation, overcoming the lack of an annotated corpus on Chinese microblogs.", "labels": [], "entities": [{"text": "Chinese text normalization", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.5773289004961649}, {"text": "POS tagging", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.7183015495538712}]}, {"text": "Our model is based on, with an extended set of transition actions to handle joint normalization.", "labels": [], "entities": [{"text": "joint normalization", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.697470024228096}]}, {"text": "In our model, word segmentation and POS tagging are based on normalized text transformed from informal text.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.779836118221283}, {"text": "POS tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.8669924139976501}]}, {"text": "Assuming that the majority of informal words can be normalized into formal equivalents, we seek standard forms of informal words from an automatically constructed normalization dictionary.", "labels": [], "entities": []}, {"text": "To evaluate our model, we developed an annotated corpus of microblog texts.", "labels": [], "entities": []}, {"text": "Results show that our model achieves the best performances on three tasks compared with several baseline systems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Frequency distribution and annotation  agreement on various types of informal words.", "labels": [], "entities": [{"text": "Frequency distribution", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6779612302780151}]}, {"text": " Table 4: Segmentation and normalization results.  S;N denotes the pipeline model. SN denotes the  joint model. lm denotes language model features.", "labels": [], "entities": []}, {"text": " Table 5: Formal and informal word accuracies on  the development test. N-R denotes the recall rate  of formal words, I-R denotes the recall rate of in- formal words, ALL-R denotes the recall rate of all  words.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 88, "end_pos": 99, "type": "METRIC", "confidence": 0.9878231585025787}, {"text": "recall rate", "start_pos": 134, "end_pos": 145, "type": "METRIC", "confidence": 0.9837746322154999}, {"text": "ALL-R", "start_pos": 167, "end_pos": 172, "type": "METRIC", "confidence": 0.9255177974700928}, {"text": "recall rate", "start_pos": 185, "end_pos": 196, "type": "METRIC", "confidence": 0.9842420816421509}]}, {"text": " Table 6: Results on the test set. ST denotes the  joint segmentation and POS tagging model. S;N;T  denotes the pipeline model. SN denotes the joint  segmentation and normalization model. SNT de- notes the joint segmentatin. normalization and  POS tagging model. lm denotes language model  features. Seg-F denotes the F-Score of segmenta- tion. POS-F denotes the F-Score of POS tagging.  Nor-F denotes the F-Score of normalization.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 406, "end_pos": 413, "type": "METRIC", "confidence": 0.9454460144042969}]}, {"text": " Table 7: Results of lexical normalization.", "labels": [], "entities": [{"text": "lexical normalization", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.8786987066268921}]}]}