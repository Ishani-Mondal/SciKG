{"title": [{"text": "Efficient Methods for Incorporating Knowledge into Topic Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Latent Dirichlet allocation (LDA) is a popular topic modeling technique for exploring hidden topics in text corpora.", "labels": [], "entities": [{"text": "Latent Dirichlet allocation (LDA)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6995305170615514}]}, {"text": "Increasingly , topic modeling needs to scale to larger topic spaces and use richer forms of prior knowledge, such as word correlations or document labels.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9100029468536377}]}, {"text": "However, inference is cumbersome for LDA models with prior knowledge.", "labels": [], "entities": []}, {"text": "As a result, LDA models that use prior knowledge only work in small-scale scenarios.", "labels": [], "entities": []}, {"text": "In this work, we propose a factor graph framework, Sparse Constrained LDA (SC-LDA), for efficiently incorporating prior knowledge into LDA.", "labels": [], "entities": []}, {"text": "We evaluate SC-LDA's ability to incorporate word correlation knowledge and document label knowledge on three benchmark datasets.", "labels": [], "entities": [{"text": "word correlation", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7849573493003845}]}, {"text": "Compared to several baseline methods, SC-LDA achieves comparable performance but is significantly faster.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In this section, we demonstrate the effectiveness of our SC-LDA by comparing it with several baseline methods on three benchmark datasets.", "labels": [], "entities": []}, {"text": "We first evaluate the convergence rate of each method and then evaluate the learned model parameter \u03c6-the topic-word distribution-in terms of topic coherence.", "labels": [], "entities": []}, {"text": "We show that SC-LDA can achieve results comparable to the baseline models but is significantly faster.", "labels": [], "entities": []}, {"text": "We setup all experiments on a 8-Core 2.8GHz CPU, 16GB RAM machine.", "labels": [], "entities": []}, {"text": "We use the NIPS and NYT-News datasets from the UCI bag of words data collections.", "labels": [], "entities": [{"text": "NIPS", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.9566097259521484}, {"text": "NYT-News datasets", "start_pos": 20, "end_pos": 37, "type": "DATASET", "confidence": 0.9415338635444641}, {"text": "UCI bag of words data collections", "start_pos": 47, "end_pos": 80, "type": "DATASET", "confidence": 0.9665601948897043}]}, {"text": "3 These two datasets have no document labels, and we use them for word correlation experiments.", "labels": [], "entities": [{"text": "word correlation", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.8098680973052979}]}, {"text": "We also use the 20Newsgroup (20NG) dataset, 4 which has document labels, for document label experiments.", "labels": [], "entities": [{"text": "20Newsgroup (20NG) dataset", "start_pos": 16, "end_pos": 42, "type": "DATASET", "confidence": 0.585431969165802}]}, {"text": "shows the characteristics of each dataset.", "labels": [], "entities": []}, {"text": "Since NIPS and NYT-News have already been preprocessed, to ensure repeatability, we use the data \"as they are\" from the sources.", "labels": [], "entities": [{"text": "NIPS", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.9097349643707275}, {"text": "NYT-News", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.8893283009529114}]}, {"text": "For 20NG, we perform tokenization and stopword removal using Mallet) and remove words that appear fewer than 10 times.", "labels": [], "entities": [{"text": "stopword removal", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7277004420757294}]}], "tableCaptions": [{"text": " Table 1: Characteristics of benchmark datasets.  We use NIPS and NYT for word correlation exper- iments and 20NG for document label experiments.", "labels": [], "entities": [{"text": "NIPS", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.895680844783783}, {"text": "NYT", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8876553773880005}]}, {"text": " Table 2: SC-LDA runtime (in seconds) in the  1st, 50th, 100th, and 200th iteration with different  numbers of correlations.", "labels": [], "entities": []}, {"text": " Table 3: The average running time per iteration  over 100 iterations, averaged over 5 seeds, on  20NG dataset. Experiments begin with 100 top- ics, 1000 labeled documents, and then vary one  dimension: number of topics (top), or number of  labeled documents (bottom).", "labels": [], "entities": [{"text": "20NG dataset", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.750472903251648}]}]}