{"title": [{"text": "Humor Recognition and Humor Anchor Extraction", "labels": [], "entities": [{"text": "Humor Recognition", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8998541235923767}, {"text": "Humor Anchor Extraction", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.8014043966929117}]}], "abstractContent": [{"text": "Humor is an essential component in personal communication.", "labels": [], "entities": [{"text": "Humor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9409881234169006}]}, {"text": "How to create computational models to discover the structures behind humor, recognize humor and even extract humor anchors remains a challenge.", "labels": [], "entities": []}, {"text": "In this work, we first identify several semantic structures behind humor and design sets of features for each structure, and next employ a computational approach to recognize humor.", "labels": [], "entities": []}, {"text": "Furthermore, we develop a simple and effective method to extract anchors that enable humor in a sentence.", "labels": [], "entities": []}, {"text": "Experiments conducted on two datasets demonstrate that our humor recognizer is effective in automatically distinguishing between humorous and non-humorous texts and our extracted humor anchors correlate quite well with human annotations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humor is one of the most interesting and puzzling research areas in the field of natural language understanding.", "labels": [], "entities": [{"text": "Humor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9582620859146118}, {"text": "natural language understanding", "start_pos": 81, "end_pos": 111, "type": "TASK", "confidence": 0.6694038808345795}]}, {"text": "Recently, computers have changed their roles from automatons that can only perform assigned tasks to intelligent agents that dynamically interact with people and learn to understand their users.", "labels": [], "entities": []}, {"text": "When a computer converses with a human being, if it can figure out the humor in human's language, it can better understand the true meaning of human language, and thereby make better decisions that improve the user experience.", "labels": [], "entities": []}, {"text": "Developing techniques that enable computers to understand humor inhuman conversations and adapt behavior accordingly deserves particular attention.", "labels": [], "entities": []}, {"text": "The task of Humor Recognition refers to determining whether a sentence in a given context expresses a certain degree of humor.", "labels": [], "entities": [{"text": "Humor Recognition", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.9921034872531891}]}, {"text": "Humor recognition is a challenging natural language problem.", "labels": [], "entities": [{"text": "Humor recognition", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9733119308948517}]}, {"text": "First, a universal definition of humor is hard to achieve, because different people hold different understandings of even the same sentence.", "labels": [], "entities": []}, {"text": "Second, humor is always situated in a broader context that sometimes requires a lot of external knowledge to fully understand it.", "labels": [], "entities": []}, {"text": "For example, consider the sentence, \"The one who invented the doorknocker got a No Bell prize\" and \"Veni, Vidi, Visa: I came, I saw, I did a little shopping\".", "labels": [], "entities": []}, {"text": "One needs a larger cultural context to figure out the subtle humorous meaning expressed in these two sentences.", "labels": [], "entities": []}, {"text": "Last but not least, there are different types of humor, such as wordplay, irony and sarcasm, but there exist few formal taxonomies of humor characteristics.", "labels": [], "entities": []}, {"text": "Thus it is almost impossible to design a general algorithm that can classify all the different types of humor, since even human cannot perfectly classify all of them.", "labels": [], "entities": []}, {"text": "Although it is impossible to understand universal humor characteristics, one can still capture the possible latent structures behind humor.", "labels": [], "entities": []}, {"text": "In this work, we uncover several latent semantic structures behind humor, in terms of meaning incongruity, ambiguity, phonetic style and personal affect.", "labels": [], "entities": []}, {"text": "In addition to humor recognition, identifying anchors, or which words prompt humor in a sentence, is essential in understanding the phenomenon of humor in language.", "labels": [], "entities": [{"text": "humor recognition", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7350047528743744}]}, {"text": "Here, Anchor Extraction refers to extracting the semantic units (keywords or phrases) that enable the humor in a given sentence.", "labels": [], "entities": [{"text": "Anchor Extraction", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.6675997674465179}]}, {"text": "The presence of such anchors plays an important role in generating humor within a sentence or phrase.", "labels": [], "entities": []}, {"text": "In this work, we formulate humor recognition as a classification task in which we distinguish between humorous and non-humorous instances.", "labels": [], "entities": [{"text": "humor recognition", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7591968178749084}]}, {"text": "Then we explore the semantic structure behind humor from four perspectives: incongruity, am-biguity, interpersonal effect and phonetic style.", "labels": [], "entities": []}, {"text": "For each latent structure, we design a set of features to capture the potential indicators of humor.", "labels": [], "entities": []}, {"text": "With high classification accuracy, we then extract humor anchors in sentences via a simple and effective method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9737507700920105}, {"text": "extract humor anchors in sentences", "start_pos": 43, "end_pos": 77, "type": "TASK", "confidence": 0.737528532743454}]}, {"text": "Both quantitative and qualitative experimental results are provided to validate the classification and anchor extraction performance.", "labels": [], "entities": [{"text": "anchor extraction", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.8709904849529266}]}], "datasetContent": [{"text": "In this section, we validate the performance of different semantic structures we extracted on humor recognition and how the combination of the structures contributes to classification.", "labels": [], "entities": [{"text": "humor recognition", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.8348753750324249}]}, {"text": "In addition, both qualitative and quantitative results regarding humor anchor extraction performance are explored.", "labels": [], "entities": [{"text": "humor anchor extraction", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.8303975065549215}]}, {"text": "The above humor recognition classifier provides us with decent accuracy in identifying humor in the text.", "labels": [], "entities": [{"text": "humor recognition classifier", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7733076612154642}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.998319685459137}]}, {"text": "To better understand which words or semantic units enable humor in sentences, we performed humor anchor extraction as described in Section 5.2.", "labels": [], "entities": [{"text": "humor anchor extraction", "start_pos": 91, "end_pos": 114, "type": "TASK", "confidence": 0.7529791096846262}]}, {"text": "We set the size of the humor anchor set as 3, i.e. t = 3.", "labels": [], "entities": []}, {"text": "The classifier that is used to predict the humor score is trained on all data instances.", "labels": [], "entities": [{"text": "humor score", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.8281252682209015}]}, {"text": "Then all predicted humorous instances are collected and input into the humor anchor extraction component.", "labels": [], "entities": [{"text": "humor anchor extraction", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.6375206410884857}]}, {"text": "Based on the Maximal Decrement method, a set of humor anchors is extracted for each instance.", "labels": [], "entities": [{"text": "Maximal Decrement", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7507390081882477}]}, {"text": "presents selected extracted humor anchor results, including both successful and unsatisfying extractions.", "labels": [], "entities": []}, {"text": "As we can see, extracted humor anchors are quite reasonable in explaining the humor causes or focuses.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"I used to be a watchmaker; it is a great job and I made my own hours\", our method selected 'watchmaker', 'made' and 'hours' as humor anchors.", "labels": [], "entities": []}, {"text": "It makes sense because each word is necessary and essential to enable humor.", "labels": [], "entities": []}, {"text": "Deleting 'watchmaker' will make the combination of 'made' and 'hours' helpless to the comic effect.", "labels": [], "entities": []}, {"text": "To sum up, our extracted anchor extraction works fairly well in identifying the focus and meaning of humor language.", "labels": [], "entities": []}, {"text": "In addition to the above qualitative exploration, we also conducted quantitative evaluations.", "labels": [], "entities": []}, {"text": "For each dataset, we randomly sampled 200 sentences.", "labels": [], "entities": []}, {"text": "Then for each sentence, 3 annotators are asked to annotate and label the possible humor anchors.", "labels": [], "entities": []}, {"text": "To assess the consistency of the labeling in this context, we introduced an Annotation Agreement Ratio (AAR) measurement as follows: Here, N sis the total number of sentences.", "labels": [], "entities": [{"text": "consistency", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.9779340624809265}, {"text": "Annotation Agreement Ratio (AAR) measurement", "start_pos": 76, "end_pos": 120, "type": "METRIC", "confidence": 0.9225817833627973}]}, {"text": "A i and Bi are the humor anchor sets of sentence i provided by annotator A and B respectively.", "labels": [], "entities": []}, {"text": "The AARs on Pun of the Day and 16000 One Liners datasets are 0.618 and 0.433 respectively, computed by averaging the AAR scores between any two different annotators, which indicate relatively reasonable agreement.", "labels": [], "entities": [{"text": "AARs", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9816052317619324}, {"text": "Pun of the Day and 16000 One Liners datasets", "start_pos": 12, "end_pos": 56, "type": "DATASET", "confidence": 0.7013505399227142}, {"text": "AAR", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9870682954788208}]}, {"text": "As a further step to validate the effectiveness of our anchor extraction method, we also introduced two baselines.", "labels": [], "entities": [{"text": "anchor extraction", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.8818359971046448}]}, {"text": "The Random Extraction baseline selects humor anchors by sampling words in a sentence randomly.", "labels": [], "entities": []}, {"text": "Similarly, POS Extraction baseline generates anchors by narrowing down all the words in a sentence to a set of certain POS, e.g. Noun, Verb, Noun Phrase, Verb Phrase, ADVP and ADJP and then sampling words from this set.", "labels": [], "entities": []}, {"text": "To evaluate whether our extracted anchors are consistent with human annotation, we used each annotator's extracted anchor list as the ground truth, and compared with anchor list provided by our method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on Two Datasets", "labels": [], "entities": []}, {"text": " Table 2: Comparison of Different Methods of Humor Recognition", "labels": [], "entities": [{"text": "Humor Recognition", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.9459021091461182}]}, {"text": " Table 3: Representative Extracted Humor Anchors. Highlighted parts are the extracted humor anchors in a sentence.", "labels": [], "entities": []}, {"text": " Table 4: Quantitative Result Comparison of  Humor Anchor Extraction", "labels": [], "entities": [{"text": "Quantitative Result Comparison of  Humor Anchor Extraction", "start_pos": 10, "end_pos": 68, "type": "TASK", "confidence": 0.880290721143995}]}]}