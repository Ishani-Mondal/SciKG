{"title": [{"text": "Mise en Place: Unsupervised Interpretation of Instructional Recipes", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an unsupervised hard EM approach to automatically mapping instructional recipes to action graphs, which define what actions should be performed on which objects and in what order.", "labels": [], "entities": []}, {"text": "Recovering such structures can be challenging, due to unique properties of procedural language where, for example, verbal arguments are commonly elided when they can be inferred from context and disambigua-tion often requires world knowledge.", "labels": [], "entities": []}, {"text": "Our probabilistic model incorporates aspects of procedural semantics and world knowledge , such as likely locations and selec-tional preferences for different actions.", "labels": [], "entities": []}, {"text": "Experiments with cooking recipes demonstrate the ability to recover high quality action graphs, outperforming a strong sequential baseline by 8 points in F1, while also discovering general-purpose knowledge about cooking.", "labels": [], "entities": [{"text": "F1", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.9882035851478577}]}], "introductionContent": [{"text": "Instructional language describes how to achieve a wide variety of goals, from traveling successfully to a desired location to cooking a particular dish for dinner.", "labels": [], "entities": []}, {"text": "Despite the fact that such language is important to our everyday lives, there has been relatively little effort to design algorithms that can automatically convert it into an actionable form.", "labels": [], "entities": []}, {"text": "Existing methods typically assume labeled training data () or access to a physical simulator that can be used to test understanding of the instructions.", "labels": [], "entities": []}, {"text": "In this paper, we present the first approach for unsupervised learning to interpret instructional recipes using text alone, with application to cooking recipes.", "labels": [], "entities": []}, {"text": "Given a recipe, our task is to segment it into text spans that describe individual actions and construct an action graph whose nodes represent actions and edges represent the flow of arguments across actions, for example as seen in.", "labels": [], "entities": []}, {"text": "This task poses unique challenges for semantic analysis.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.9465818107128143}]}, {"text": "First, null arguments and ellipses are extremely common.", "labels": [], "entities": []}, {"text": "For example, sentences such as \"Bake for 50 minutes\" do not explicitly mention what to bake or where.", "labels": [], "entities": []}, {"text": "Second, we must reason about how properties of the physical objects are changed by the described actions, for example to correctly resolve what the phrase \"the wet mixture\" refers to in a baking recipe.", "labels": [], "entities": []}, {"text": "Although linguistic context is important to resolving both of these challenges, more crucial is commonsense knowledge about how the world works, including what types of things are typically baked or what ingredients could be referred to as \"wet.\"", "labels": [], "entities": []}, {"text": "These challenges seemingly present a chicken and egg problem -if we had a high quality semantic analyzer for instructions we could learn commonsense knowledge simply by reading large bodies of text.", "labels": [], "entities": []}, {"text": "However, correctly understanding instructions requires reasoning with exactly this desired knowledge.", "labels": [], "entities": []}, {"text": "We show that this conflict can be resolved with an unsupervised learning approach, where we design models to learn various aspects of procedural knowledge and then fit them to unannotated instructional text.", "labels": [], "entities": []}, {"text": "Cooking recipes are an ideal domain to study these two challenges simultaneously, as vast amounts of recipes are available online today, with significant redundancy in their coverage that can help bootstrap the overall learning process.", "labels": [], "entities": []}, {"text": "For example, there are over 400 variations on \"macaroni and cheese\" recipes on allrecipes.com, from \"chipotle Figure 1: An input recipe (left) and a partial corresponding output action graph (right).", "labels": [], "entities": []}, {"text": "Each rectangle (e i ) represents an action.", "labels": [], "entities": []}, {"text": "The leftmost oval (v i ) in each action is the action's verb and the following ovals (a ij ) represents the verb's arguments.", "labels": [], "entities": []}, {"text": "The yellow ovals represent foods; the grey ovals represent locations.", "labels": [], "entities": []}, {"text": "Argument ovals with dotted boundaries are implicit, i.e., not present in text.", "labels": [], "entities": []}, {"text": "The inner white ovals (s k ij ) are string spans.", "labels": [], "entities": []}, {"text": "The red dashed lines represent connections to string spans from their originating verb or raw ingredient.", "labels": [], "entities": []}, {"text": "The string spans also connect to their associated verb in the action diagram to model the flow of ingredients.", "labels": [], "entities": []}, {"text": "For example, there is a directed path from each raw ingredient to the implicit object of bake, representing that the object being baked is composed of all of the raw ingredients.", "labels": [], "entities": []}, {"text": "macaroni and cheese,\" to \"cheesy salsa mac.\"", "labels": [], "entities": []}, {"text": "We present two models that are learned with hard EM algorithms: (1) a segmentation model to extract the actions from the recipe text, and (2) a graph model that defines a distribution over the connections between the extracted actions.", "labels": [], "entities": []}, {"text": "The commonsense knowledge is encoded in the second model which can, for example, prefer graphs that model implicit verb arguments when they better match the learned selectional preferences.", "labels": [], "entities": []}, {"text": "The final action graph is constructed with a local search algorithm, that allows for global reasoning about ingredients as they flow through the recipe.", "labels": [], "entities": []}, {"text": "Experiments demonstrate the ability to recover high quality action graphs, gaining up to 8 points in F1 over a strong baseline where the ingredients flow sequentially through the verbs.", "labels": [], "entities": [{"text": "F1", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9992117881774902}]}, {"text": "The learned models are also highly interpretable, specifying for example that \"dough\" likely contains \"flour\" and that \"add\" generally requires two food arguments, even if only one is mentioned in the sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data Set We collected 2456 recipes (with over 23,000 sentences) from allrecipes.com by searching for 20 dish names (e.g., including \"banana muffins\", and \"deviled eggs\").", "labels": [], "entities": []}, {"text": "We randomly sampled, removed, and hand labeled 33 recipes fora development set and 100 recipes for test.", "labels": [], "entities": []}, {"text": "All models were trained on the unannotated recipes; the dev set was used to determine the stopping point for training.", "labels": [], "entities": []}, {"text": "Each recipe in the test set has 13 actions on average.", "labels": [], "entities": []}, {"text": "Recipe pre-processing To pre-process each recipe, we first use the segmentation system described in Sec.", "labels": [], "entities": []}, {"text": "6. Then, we use a string classification model to determine the semantic type (e.g., food, location, or other) of an argument based on its spans.", "labels": [], "entities": []}, {"text": "We identify spans as raw ingredients based on string match heuristics (e.g., in, the span \"crushed crackers\" represents the ingredients \"crushed butter-flavored crackers\").", "labels": [], "entities": []}, {"text": "We stem all words and ignore function words.", "labels": [], "entities": []}, {"text": "Sequential Baseline Because most connections are sequential -i.e., argument spans are most often connected to the output of the previous verb -sequential connections make a strong baseline; we connect the output of each predicate to the first available argument span of the following predicate.", "labels": [], "entities": []}, {"text": "If no argument exists, an implicit argument is created.", "labels": [], "entities": []}, {"text": "We run this baseline with and without first identifying raw ingredients in the recipe; if raw ingredient spans are identified, the baseline will not connect the previous event to those spans.", "labels": [], "entities": []}, {"text": "Performance suffers significantly if the raw ingredients are not identified beforehand.", "labels": [], "entities": []}, {"text": "Evaluation metrics We report F-measure by comparing the predicted connections from actions to spans (i.e., where the origin index > 0) against gold standard annotations.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9476152062416077}]}, {"text": "We don't evaluate connections to raw ingredients as we create those connections during pre-processing (see Sec. 7).", "labels": [], "entities": []}, {"text": "Model initialization The verb signature model (Sec. 3.2) is initialized by first identifying food arguments using string overlap with the ingredient list.", "labels": [], "entities": [{"text": "Model initialization", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6843329071998596}]}, {"text": "All other arguments' types are considered unknown, and partial counts were awarded to all verb signatures consistent with the partial information.", "labels": [], "entities": []}, {"text": "The first verb in each recipe was assumed to be the only leaf.", "labels": [], "entities": []}, {"text": "The string classification model for the pre-processing step was initialized by using the initialized verb signature model to identify the types of DOBJ arguments.", "labels": [], "entities": []}, {"text": "The string classification model was estimated using the argument tokens given the types.", "labels": [], "entities": [{"text": "string classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7282599806785583}]}, {"text": "We initialized the partcomposite model (Sec. 3.2.2) so that exact string matches between ingredients and spans are given   high probabilities and those without are given low probabilities.", "labels": [], "entities": []}, {"text": "Given the initialized string classification model, the raw food model (Sec.", "labels": [], "entities": [{"text": "initialized string classification", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.661003053188324}]}, {"text": "3.2.2) is initialized counting whether or not tokens in food arguments occur in the ingredient list.", "labels": [], "entities": []}, {"text": "The probability of an implicit location (Sec. 3.2.2) is initialized to a hand-tuned value using the dev set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of our algorithm against the  sequential baselines.", "labels": [], "entities": []}, {"text": " Table 4: The top verb signatures for example  verbs. The syntactic types identify which argu- ments of the verb are foods and \"leaf\" means no  arguments of the verb connect to previous actions.", "labels": [], "entities": []}]}