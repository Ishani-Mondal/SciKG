{"title": [{"text": "Joint Named Entity Recognition and Disambiguation", "labels": [], "entities": [{"text": "Named Entity Recognition and Disambiguation", "start_pos": 6, "end_pos": 49, "type": "TASK", "confidence": 0.6809720754623413}]}], "abstractContent": [{"text": "Extracting named entities in text and linking extracted names to a given knowledge base are fundamental tasks in applications for text understanding.", "labels": [], "entities": [{"text": "Extracting named entities in text", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8985317707061767}, {"text": "text understanding", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.8156643807888031}]}, {"text": "Existing systems typically run a named entity recognition (NER) model to extract entity names first, then run an entity linking model to link extracted names to a knowledge base.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.8430436352888743}]}, {"text": "NER and linking models are usually trained separately , and the mutual dependency between the two tasks is ignored.", "labels": [], "entities": []}, {"text": "We propose JERL, Joint Entity Recognition and Linking, to jointly model NER and linking tasks and capture the mutual dependency between them.", "labels": [], "entities": [{"text": "JERL", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.8706475496292114}, {"text": "Joint Entity Recognition and Linking", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.7116911888122559}, {"text": "NER", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.971805214881897}]}, {"text": "It allows the information from each task to improve the performance of the other.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, JERL is the first model to jointly optimize NER and linking tasks together completely.", "labels": [], "entities": [{"text": "JERL", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.5381956100463867}, {"text": "NER", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9215118288993835}]}, {"text": "In experiments on the CoNLL'03/AIDA data set, JERL outper-forms state-of-art NER and linking systems , and we find improvements of 0.4% absolute F 1 for NER on CoNLL'03, and 0.36% absolute precision@1 for linking on AIDA.", "labels": [], "entities": [{"text": "CoNLL'03/AIDA data set", "start_pos": 22, "end_pos": 44, "type": "DATASET", "confidence": 0.9177339434623718}, {"text": "absolute F 1", "start_pos": 136, "end_pos": 148, "type": "METRIC", "confidence": 0.7248684565226237}, {"text": "CoNLL'03", "start_pos": 160, "end_pos": 168, "type": "DATASET", "confidence": 0.9392110109329224}, {"text": "precision", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.7172898650169373}, {"text": "AIDA", "start_pos": 216, "end_pos": 220, "type": "DATASET", "confidence": 0.9086698293685913}]}], "introductionContent": [{"text": "In applications of complex Natural Language Processing tasks, such as automatic knowledge base construction, entity summarization, and question answering systems, it is essential to first have high quality systems for lower level tasks, such as partof-speech (POS) tagging, chunking, named entity recognition (NER), entity linking, and parsing among others.", "labels": [], "entities": [{"text": "automatic knowledge base construction", "start_pos": 70, "end_pos": 107, "type": "TASK", "confidence": 0.6399903520941734}, {"text": "entity summarization", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.7159696817398071}, {"text": "question answering", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.7932587563991547}, {"text": "partof-speech (POS) tagging", "start_pos": 245, "end_pos": 272, "type": "TASK", "confidence": 0.60560502409935}, {"text": "named entity recognition (NER)", "start_pos": 284, "end_pos": 314, "type": "TASK", "confidence": 0.7994337181250254}, {"text": "entity linking", "start_pos": 316, "end_pos": 330, "type": "TASK", "confidence": 0.7869748175144196}]}, {"text": "These lower level tasks are usually decoupled and optimized separately to keep the system tractable.", "labels": [], "entities": []}, {"text": "The disadvantage of the decoupled approach is that each lower level task is not aware of other tasks and thus notable to leverage information provided by others to improve performance.", "labels": [], "entities": []}, {"text": "What is more, there is no guarantee that their outputs will be consistent.", "labels": [], "entities": []}, {"text": "This paper addresses the problem by building a joint model for Entity Recognition and Disambiguation (ERD).", "labels": [], "entities": [{"text": "Entity Recognition and Disambiguation (ERD)", "start_pos": 63, "end_pos": 106, "type": "TASK", "confidence": 0.8256623617240361}]}, {"text": "The goal of ERD is to extract named entities in text and link extracted names to a knowledge base, usually Wikipedia or Freebase.", "labels": [], "entities": [{"text": "ERD", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9806241393089294}]}, {"text": "ERD is closely related to NER and linking tasks.", "labels": [], "entities": [{"text": "NER", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9397645592689514}]}, {"text": "NER aims to identify named entities in text and classify mentions into predefined categories such as persons, organizations, locations, etc.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7348126769065857}]}, {"text": "Given a mention and context as input, entity linking connects the mention to a referent entity in a knowledge base.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.701974630355835}]}, {"text": "Existing ERD systems typically run a NER to extract entity mentions first, then run an entity linking model to link mentions to a knowledge base.", "labels": [], "entities": []}, {"text": "Such a decoupled approach makes the system tractable, and both NER and linking models can be optimized separately.", "labels": [], "entities": []}, {"text": "The disadvantages are also obvious: 1) errors caused by NER will be propagated to linking and are not recoverable 2) NER cannot benefit from information available used in entity linking; 3) NER and linking may create inconsistent outputs.", "labels": [], "entities": []}, {"text": "We argue that there is strong mutual dependency between NER and linking tasks.", "labels": [], "entities": []}, {"text": "Consider the following two examples: 1.", "labels": [], "entities": []}, {"text": "The New York Times (NYT) is an American daily newspaper.", "labels": [], "entities": [{"text": "The New York Times (NYT)", "start_pos": 0, "end_pos": 24, "type": "DATASET", "confidence": 0.8302264639309475}]}, {"text": "2. Clinton plans to have more news conferences in 2nd term.", "labels": [], "entities": []}, {"text": "Example 1 is the first sentence from the Wikipedia article about \"The New York Times\".", "labels": [], "entities": [{"text": "The New York Times\"", "start_pos": 66, "end_pos": 85, "type": "DATASET", "confidence": 0.8268143177032471}]}, {"text": "It is reasonable but incorrect for NER to identify \"New York Times\" without \"The\" as a named entity, while entity linking has no trouble connecting \"The New York Times\" to the correct entity.", "labels": [], "entities": [{"text": "NER", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.6822368502616882}, {"text": "New York Times", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.7816971143086752}]}, {"text": "Example 2 is a news title where our NER classifies \"WASHINGTON\" as a location, since a location followed by a date is a frequent pattern in news articles it learned, while the entity linking prefers linking this mention to the U.S. president \"George Washington\" since another president's name \"Clinton\" is mentioned in the context.", "labels": [], "entities": [{"text": "NER classifies \"", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.5316604375839233}, {"text": "WASHINGTON", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.7107798457145691}]}, {"text": "Both the entity boundaries and entity types predicted by NER are correlated to the knowledge of entities linked by entity linking.", "labels": [], "entities": [{"text": "NER", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.8452159762382507}]}, {"text": "Modeling such mutual dependency is helpful in resolving inconsistency and improving performance for both NER and linking.", "labels": [], "entities": [{"text": "NER", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9667667746543884}]}, {"text": "We propose JERL, Joint Entity Recognition and Linking, to jointly model NER and linking tasks and capture the mutual dependency between them.", "labels": [], "entities": [{"text": "JERL", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.8706475496292114}, {"text": "Joint Entity Recognition and Linking", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.7116911888122559}, {"text": "NER", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.971805214881897}]}, {"text": "It allows the information from each task to improve the performance of the other.", "labels": [], "entities": []}, {"text": "If NER is highly confident on its outputs of entity boundaries and types, it will encourage entity linking to link an entity which is consistent with NER's outputs, and vice versa.", "labels": [], "entities": [{"text": "NER", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.8538127541542053}]}, {"text": "In other words, JERL is able to model how consistent NER and linking's outputs are, and predict coherent outputs.", "labels": [], "entities": []}, {"text": "According to our experiments, this approach does improve the end to end performance.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, JERL is the first model to jointly optimize NER and linking tasks together completely . Sil (2013) also proposes jointly conducting NER and linking tasks.", "labels": [], "entities": [{"text": "JERL", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.6326816082000732}]}, {"text": "They leverage existing NER/chunking systems and Freebase to over generate mention candidates and leave the linking algorithm to make final decisions, which is a reranking model.", "labels": [], "entities": []}, {"text": "Their model captures the dependency between entity linking decisions and mention boundary decisions with impressive results.", "labels": [], "entities": []}, {"text": "The difference between our model and theirs is that our model jointly models NER and linking tasks from the training phrase, while their model is a combined one which depends on an existing state-of-art NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9213315844535828}]}, {"text": "Our model is more powerful in capturing mutual dependency by considering entity type and confidences information, while in their model the confidence of outputs is lost in the linking phrase.", "labels": [], "entities": []}, {"text": "Furthermore, in our model NER can naturally benefit from entity linking's decision since both decisions are made together, while in their model, it is not clear how the linking decision can help the NER decision in return.", "labels": [], "entities": []}, {"text": "It increases the problem complexity, is usually inefficient, and requires the careful consideration of features of multiple tasks and mutual dependency, making proper assumptions and approximations to enable tractable training and inference.", "labels": [], "entities": []}, {"text": "However, we believe that joint optimization is a promising direction for improving performance for NLP tasks since it is closer to how human beings process text information.", "labels": [], "entities": [{"text": "joint optimization", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7236161828041077}]}, {"text": "Experiment result indicates that our joint model does a better job at both NER and linking tasks than separate models with the same features, and outperforms state-of-art systems on a widely used data set.", "labels": [], "entities": [{"text": "NER", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.877111554145813}]}, {"text": "We found improvements of 0.4% absolute F 1 for NER on CoNLL'03 and 0.36% absolute precision@1 for linking on AIDA.", "labels": [], "entities": [{"text": "absolute F 1", "start_pos": 30, "end_pos": 42, "type": "METRIC", "confidence": 0.7847386598587036}, {"text": "CoNLL'03", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9246617555618286}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.7062664031982422}, {"text": "AIDA", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.958905816078186}]}, {"text": "NER is a widely studied problem, and we believe our improvement is significant.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9237329959869385}]}, {"text": "The contributions of this paper are as follows: 1.", "labels": [], "entities": []}, {"text": "We identify the mutual dependency between NER and linking tasks, and argue that NER and linking should be conducted together to improve the end to end performance.", "labels": [], "entities": []}, {"text": "2. We propose the first completely joint NER and linking model, JERL, to train and inference the two tasks together.", "labels": [], "entities": [{"text": "NER", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8837296366691589}, {"text": "JERL", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.8305613994598389}]}, {"text": "Efficient training and inference algorithms are also presented.", "labels": [], "entities": []}, {"text": "3. The JERL outperforms the best NER record on the CoNLL'03 data set, which demonstrates how NER could be improved further by leveraging knowledge base and linking techniques.", "labels": [], "entities": [{"text": "JERL", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9073504209518433}, {"text": "CoNLL'03 data set", "start_pos": 51, "end_pos": 68, "type": "DATASET", "confidence": 0.9852720499038696}, {"text": "NER", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.8926072716712952}]}, {"text": "The remainder of this paper is organized as follows: the next section discusses related works on NER, entity linking, and joint optimization; section 3 presents our Joint Entity Recognition and Linking model in detail; section 4 describes experiments, results, and analysis; and section 5 concludes.", "labels": [], "entities": [{"text": "NER", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9569053053855896}, {"text": "entity linking", "start_pos": 102, "end_pos": 116, "type": "TASK", "confidence": 0.7543331980705261}, {"text": "joint optimization", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7204698026180267}, {"text": "Joint Entity Recognition and Linking", "start_pos": 165, "end_pos": 201, "type": "TASK", "confidence": 0.7468491613864898}]}], "datasetContent": [{"text": "In For entity linking, we take Wikipedia as the referent knowledge base.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 7, "end_pos": 21, "type": "TASK", "confidence": 0.7580981254577637}]}, {"text": "We use a Wikipedia snapshot dumped in May 2013, which contains around 4.8 million articles.", "labels": [], "entities": [{"text": "Wikipedia snapshot dumped in May 2013", "start_pos": 9, "end_pos": 46, "type": "DATASET", "confidence": 0.951903889576594}]}, {"text": "We also align our Wikipedia dump with additional knowledge bases, Freebase and Satori (a Microsoft internal knowledge base), to enrich the information of these entities.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.9722505807876587}, {"text": "Satori", "start_pos": 79, "end_pos": 85, "type": "DATASET", "confidence": 0.8395463824272156}]}, {"text": "We follow the CoNLL'03 metrics to evaluate NER performance by precision, recall, and F 1 scores, and follow Hoffart's (2011) experiment setting to evaluate linking performance by micro precision@1.", "labels": [], "entities": [{"text": "NER", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.972564697265625}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9991563558578491}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9887813925743103}, {"text": "F 1 scores", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9809404412905375}]}, {"text": "Since the linking labels of CONLL'03 were annotated in 2011, it is not completely consistent with the Wikipedia dump we used in the case.", "labels": [], "entities": [{"text": "CONLL'03", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.8909285068511963}]}, {"text": "We only consider mention entity pairs where the ground truth are known, and ignore around 20% of NIL mentions in the ground truth.", "labels": [], "entities": []}, {"text": "shows features used in our models.", "labels": [], "entities": []}, {"text": "JERL uses all features in the three categories, while JERL ner and JERL el use only one corresponding category.", "labels": [], "entities": [{"text": "JERL", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9216073155403137}, {"text": "JERL ner", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.6893006861209869}]}, {"text": "All three models are trained on the train and development set, and evaluated on the test set of CoNLL'03/AIDA.", "labels": [], "entities": [{"text": "CoNLL'03/AIDA", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.8273063898086548}]}], "tableCaptions": [{"text": " Table 1: Overview of CoNLL'03/AIDA data set", "labels": [], "entities": [{"text": "CoNLL'03/AIDA data set", "start_pos": 22, "end_pos": 44, "type": "DATASET", "confidence": 0.8852493643760682}]}, {"text": " Table 3: NER evaluation results", "labels": [], "entities": [{"text": "NER evaluation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.90815269947052}]}, {"text": " Table 4: Linking evaluation results", "labels": [], "entities": [{"text": "Linking evaluation", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.90092334151268}]}, {"text": " Table 5: JERL features analysis", "labels": [], "entities": [{"text": "JERL features analysis", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.5488062898317972}]}, {"text": " Table 6: Learned mutual dependency", "labels": [], "entities": [{"text": "Learned mutual dependency", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8657983938852946}]}, {"text": " Table 7: Training time under different settings", "labels": [], "entities": []}]}