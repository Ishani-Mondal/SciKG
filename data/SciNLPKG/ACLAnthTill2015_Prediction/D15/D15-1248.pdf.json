{"title": [{"text": "A Joint Dependency Model of Morphological and Syntactic Structure for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.8570727308591207}]}], "abstractContent": [{"text": "When translating between two languages that differ in their degree of morphological synthesis, syntactic structures in one language maybe realized as morphological structures in the other, and SMT models need a mechanism to learn such translations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 193, "end_pos": 196, "type": "TASK", "confidence": 0.9849928617477417}]}, {"text": "Prior work has used morpheme splitting with flat representations that do not encode the hierarchical structure between morphemes, but this structure is relevant for learning morphosyntactic constraints and selectional preferences.", "labels": [], "entities": [{"text": "morpheme splitting", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7305022180080414}]}, {"text": "We propose to model syntactic and morphological structure jointly in a dependency translation model, allowing the system to generalize to the level of morphemes.", "labels": [], "entities": [{"text": "dependency translation", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.7081338763237}]}, {"text": "We present a dependency representation of German compounds and particle verbs that results in improvements in translation quality of 1.4-1.8 BLEU in the WMT English-German translation task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9980081915855408}, {"text": "WMT English-German translation", "start_pos": 153, "end_pos": 183, "type": "TASK", "confidence": 0.7047734061876932}]}], "introductionContent": [{"text": "When translating between two languages that differ in their degree of morphological synthesis, syntactic structures in one language maybe realized as morphological structures in the other.", "labels": [], "entities": []}, {"text": "Machine Translation models that treat words as atomic units have poor learning capabilities for such translation units, and morphological segmentations are commonly used (.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7966098785400391}]}, {"text": "Like words in a sentence, the morphemes of a word have a hierarchical structure that is relevant in translation.", "labels": [], "entities": []}, {"text": "For instance, compounds in Germanic languages are head-final, and the head is the segment that determines agreement within the noun phrase, and is relevant for selectional preferences of verbs.", "labels": [], "entities": []}, {"text": "they charge a carry-on bag fee.", "labels": [], "entities": []}, {"text": "In example 1, agreement in case, number and gender is enforced between eine 'a' and Geb\u00fchr 'fee', and selectional preference between erheben 'charge' and Geb\u00fchr 'fee'.", "labels": [], "entities": [{"text": "agreement", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9592159390449524}]}, {"text": "A flat representation, as is common in phrase-based SMT, does not encode these relationships, but a dependency representation does so through dependency links.", "labels": [], "entities": [{"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.6717475056648254}]}, {"text": "In this paper, we investigate a dependency representation of morphologically segmented words for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9896678924560547}]}, {"text": "Our representation encodes syntactic and morphological structure jointly, allowing a single model to learn the translation of both.", "labels": [], "entities": []}, {"text": "Specifically, we work with a string-to-tree model with GHKM-style rules (), and a relational dependency language model.", "labels": [], "entities": []}, {"text": "We focus on the representation of German syntax and morphology in an English-to-German system, and two morphologically complex word classes in German that are challenging for translation, compounds and particle verbs.", "labels": [], "entities": [{"text": "translation", "start_pos": 175, "end_pos": 186, "type": "TASK", "confidence": 0.9631102085113525}]}, {"text": "German makes heavy use of compounding, and compounds such as Abwasserbehandlungsanlage 'waste water treatment plant' are translated into complex noun phrases in other languages, such as French station d'\u00e9puration des eaux r\u00e9siduaires.", "labels": [], "entities": []}, {"text": "German particle verbs are difficult to model because their surface realization differs depending on the finiteness of the verb and the type of clause.", "labels": [], "entities": []}, {"text": "Verb particles are separated from the finite verb in main clauses, but prefixed to the verb in subordinated clauses, or when the verb is non-finite.", "labels": [], "entities": []}, {"text": "The infinitive marker zu 'to', which is normally a premodifying particle, appears as an infix in particle verbs.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train English-German string-to-tree SMT systems on the training data of the shared translation task of the Workshop on Statistical Machine Translation (WMT) 2015.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8361236453056335}, {"text": "shared translation task of the Workshop on Statistical Machine Translation (WMT) 2015", "start_pos": 79, "end_pos": 164, "type": "TASK", "confidence": 0.6983623313052314}]}, {"text": "The data set consists of 4.2 million sentence pairs of parallel data, and 160 million sentences of monolingual German data.", "labels": [], "entities": []}, {"text": "We base our systems on that of.", "labels": [], "entities": []}, {"text": "It is a string-to-tree GHKM translation system implemented in Moses (, and using the dependency annotation by.", "labels": [], "entities": [{"text": "GHKM translation", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.6410699337720871}]}, {"text": "Additionally, our baseline system contains a dependency language model (RDLM), trained on the target-side of the parallel training data.", "labels": [], "entities": []}, {"text": "We report case-sensitive BLEU scores on the newstest2014/5 test sets from WMT, averaged over 3 optimization runs of k-batch MIRA (Cherry and Foster, 2012) on a subset of newstest2008-12.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9901633858680725}, {"text": "newstest2014/5 test sets from WMT", "start_pos": 44, "end_pos": 77, "type": "DATASET", "confidence": 0.91293979542596}, {"text": "MIRA", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9658128619194031}]}, {"text": "We split all particle verbs and hyphenated compounds, but other compounds are only split if they are rare (frequency in parallel text < 5).", "labels": [], "entities": []}, {"text": "For comparison with the state-of-the-art, we train a full system on our restructured representation, which incorporates all models and settings of our WMT 2015 submission system (   uses the dependency representation of compounds and tree binarization introduced in this paper; we achieve additional gains over the submission system through particle verb restructuring.", "labels": [], "entities": [{"text": "WMT 2015 submission system", "start_pos": 151, "end_pos": 177, "type": "DATASET", "confidence": 0.6914281845092773}, {"text": "particle verb restructuring", "start_pos": 341, "end_pos": 368, "type": "TASK", "confidence": 0.6500697036584219}]}, {"text": "shows translation quality (BLEU) with different representations of German compounds and particle verbs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9931187629699707}]}, {"text": "Head binarization not only yields improvements over the baseline, but also allows for larger gains from morphological segmentation.", "labels": [], "entities": [{"text": "Head binarization", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7601758241653442}]}, {"text": "We attribute this to the fact that full compounds, and prefixed particle verbs, are not always a constituent in the segmented representation, and that binarization compensates this theoretical drawback.", "labels": [], "entities": []}, {"text": "We perform a synthetic experiment to test our claim that a dependency representation allows for the modelling of agreement between morphemes.", "labels": [], "entities": []}, {"text": "For 200 rare compounds [that would be split by our compound splitter] in the newstest2014/5 references, we artificially introduce agreement errors by changing the gender of the determiner.", "labels": [], "entities": [{"text": "newstest2014/5 references", "start_pos": 77, "end_pos": 102, "type": "DATASET", "confidence": 0.9565411359071732}]}, {"text": "For instance, we create the erroneous sentence sie erheben ein Handgep\u00e4ckgeb\u00fchr as a complement to Example 1.", "labels": [], "entities": []}, {"text": "We measure the ability of language models to prefer (give a higher probability to) the original reference sentence over the erroneous one.", "labels": [], "entities": []}, {"text": "In the original representation, both a Knesersegmented due to its frequency.", "labels": [], "entities": []}, {"text": "Ney 5-gram LM and RDLM perform poorly due to data sparseness, with 70% and 57.5% accuracy, respectively.", "labels": [], "entities": [{"text": "RDLM", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.7892797589302063}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9993687272071838}]}, {"text": "In the split representation, the RDLM reliably prefers the correct agreement (96.5% accuracy), whilst the performance of the 5-gram model even deteriorates (to 60% accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9891352653503418}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9979015588760376}]}, {"text": "This is because the gender of the first segment(s) is irrelevant, or even misleading, for agreement.", "labels": [], "entities": []}, {"text": "For instance, Handgep\u00e4ck is neuter, which could lead a morpheme-level n-gram model to prefer the determiner ein, but Handgep\u00e4ckgeb\u00fchr is feminine and requires eine.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: English-German translation results  (BLEU). Average of three optimization runs.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9639905095100403}]}, {"text": " Table 3: Number of compounds [that would be  split by compound splitter] and particle verbs  (separated, prefixed and with zu-infix) in new- stest2014/5. Average of three optimization runs.", "labels": [], "entities": []}]}