{"title": [], "abstractContent": [{"text": "Performing link prediction in Knowledge Bases (KBs) with embedding-based models , like with the model TransE (Bordes et al., 2013) which represents relationships as translations in the embedding space, have shown promising results in recent years.", "labels": [], "entities": [{"text": "link prediction in Knowledge Bases (KBs)", "start_pos": 11, "end_pos": 51, "type": "TASK", "confidence": 0.8471459671854973}]}, {"text": "Most of these works are focused on modeling single relationships and hence do not take full advantage of the graph structure of KBs.", "labels": [], "entities": []}, {"text": "In this paper, we propose an extension of TransE that learns to explicitly model composition of relationships via the addition of their corresponding translation vectors.", "labels": [], "entities": []}, {"text": "We show empirically that this allows to improve performance for predicting single relationships as well as compositions of pairs of them.", "labels": [], "entities": [{"text": "predicting single relationships", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.8743561307589213}]}], "introductionContent": [{"text": "Performing link prediction on multi-relational data is becoming essential in order to complete the huge amount of missing information of the knowledge bases.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.7925646305084229}]}, {"text": "These knowledge can be formalized as directed multi-relation graphs, whose node correspond to entities connected with edges encoding various kind of relationships.", "labels": [], "entities": []}, {"text": "We denote these connections via triples (head, label, tail).", "labels": [], "entities": []}, {"text": "Link prediction consists in filling in incomplete triples like (head, label, ?) or (?, label, tail).", "labels": [], "entities": [{"text": "Link prediction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9237882792949677}]}, {"text": "In this context, embedding models () that attempt to learn lowdimensional vector or matrix representations of entities and relationships have shown promising performance in recent years.", "labels": [], "entities": []}, {"text": "In particular, the basic model TRANSE () has been proved to be very powerful.", "labels": [], "entities": [{"text": "TRANSE", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.695402204990387}]}, {"text": "This model treats each relationship as a translation vector operating on the embedding representing the entities.", "labels": [], "entities": []}, {"text": "Hence, fora triple (head, label, tail), the vector embeddings of head and tail are learned so that they are connected through a translation parameterized by the vector associated with label.", "labels": [], "entities": []}, {"text": "Many extensions have been proposed to improve the representation power of TRANSE while still keeping its simplicity, by adding some projections steps before the translation (.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9865853786468506}]}, {"text": "In this paper, we propose an extension of TRANSE 1 that focuses on improving its representation of the underlying graph of multi-relational data by trying to learn compositions of relationships as sequences of translations in the embedding space.", "labels": [], "entities": []}, {"text": "The idea is to train the embeddings by learning simple reasonings, such as the relationship people/nationality should give a similar result as the composition people/city of birth and city/country.", "labels": [], "entities": []}, {"text": "In our approach, called RTRANSE, the training set is augmented with relevant examples of such compositions by performing constrained walks in the knowledge graph, and training so that sequences of translations lead to the desired result.", "labels": [], "entities": [{"text": "RTRANSE", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.7597908973693848}]}, {"text": "The idea of compositionality to model multi-relational data was previously introduced in.", "labels": [], "entities": []}, {"text": "That work composes relationships by means of recurrent neural networks (RNN) (one per relationship) with non-linearities.", "labels": [], "entities": []}, {"text": "However, we show that there is a natural way to compose relationships by simply adding translation vectors and not requiring additional parameters, which makes it specially appealing because of its scalability.", "labels": [], "entities": []}, {"text": "We present experimental results that show the superiority of RTRANSE over TRANSE in terms of link prediction.", "labels": [], "entities": [{"text": "RTRANSE", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.7526330351829529}, {"text": "link prediction", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.770194947719574}]}, {"text": "A detailed evaluation, in which test examples are classified as easy or hard depending on their similarity with training data, highlights the improvement of RTRANSE on both categories.", "labels": [], "entities": [{"text": "RTRANSE", "start_pos": 157, "end_pos": 164, "type": "METRIC", "confidence": 0.9238578677177429}]}, {"text": "Our experiments include anew evaluation protocol, in which the model is directly asked to answer questions related to compositions of relations, such as (head, label 1 , label 2 , ?).", "labels": [], "entities": []}, {"text": "RTRANSE also achieves significantly better performances than TRANSE on this new dataset.", "labels": [], "entities": [{"text": "RTRANSE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.5966702103614807}]}, {"text": "We describe RTRANSE in the next section, and present our experiments in Section 3.", "labels": [], "entities": [{"text": "RTRANSE", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.6716862916946411}]}], "datasetContent": [{"text": "This section presents experiments on the benchmark FB15K introduced in ( and on FAMILY, a slightly extended version of the artificial database described in).", "labels": [], "entities": [{"text": "FB15K", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.7449331283569336}, {"text": "FAMILY", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.8616567850112915}]}, {"text": "Data FB15K is a subset of Freebase, a very large database of generic facts gathering more than 1.2 billion triples and 80 million entities.", "labels": [], "entities": [{"text": "Data FB15K", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.769316703081131}, {"text": "Freebase", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.975189208984375}]}, {"text": "Inspired by, FAMILY is a database that contains triples expressing family relationships (cousin of, has ancestor, married to, parent of, related to, sibling of, uncle of) among the members of 5 families along 6 generations.", "labels": [], "entities": [{"text": "FAMILY", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.938724160194397}]}, {"text": "This dataset is artificial and each family is organized in a layered tree structure where each layer refers to a generation.", "labels": [], "entities": []}, {"text": "Families are connected among them by marriage links between two members, randomly sampled from the same layer of different families.", "labels": [], "entities": []}, {"text": "Interestingly on this dataset, there are obvious compositional relationships like uncle of \u2248 sibling of + parent of or parent of \u2248 married to + parent of, among others.", "labels": [], "entities": []}, {"text": "Setting Our main comparison is TRANSE so we followed the same experimental setting as in), using ranking metrics for evaluation.", "labels": [], "entities": [{"text": "TRANSE", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.8963144421577454}]}, {"text": "For each test triple we replaced the head by each of the entities in turn, and then computed the score of each of these candidates and sorted them.", "labels": [], "entities": []}, {"text": "Since other positive candidates (i.e. entities forming true triples) can be ranked higher than the target one, we filtered out all the positive candidates existing in either the training, validation and test set, except the target one, from the ranking and then we kept the rank of the target entity.", "labels": [], "entities": []}, {"text": "The same procedure is repeated but removing the tail instead of the head.", "labels": [], "entities": []}, {"text": "The filtered mean rank (mean rank in the rest) is the average of these ranks, and the filtered Hits@10 (H@10 in the rest) is the proportion of target entities in the top 10 predictions.", "labels": [], "entities": [{"text": "Hits@10 (H@10", "start_pos": 95, "end_pos": 108, "type": "METRIC", "confidence": 0.9008726392473493}]}, {"text": "The embedding dimensions were set to 20 for FAMILY and 100 for FB15K.", "labels": [], "entities": [{"text": "FAMILY", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.5842287540435791}, {"text": "FB15K", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.9788072109222412}]}, {"text": "Training was performed by stochastic gradient descent, stopping after for 500 epochs.", "labels": [], "entities": []}, {"text": "On FB15K, we used the embeddings of TRANSE to initialize RTRANSE, and we set a learning rate of 0.001 to fine-tune RTRANSE.", "labels": [], "entities": [{"text": "FB15K", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9806243777275085}, {"text": "initialize RTRANSE", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.5491996109485626}]}, {"text": "On FAMILY, both algorithms were initialized randomly and used a learning rate of 0.01.", "labels": [], "entities": [{"text": "FAMILY", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.7651705741882324}]}, {"text": "The mean rank was used as a validation criterion, and the values of \u03b3, \u03bb, \u03b1 and \u00b5 were chosen respectively among {0.25, 0.5, 1}, {1e \u22124 , 1e \u22125 , 0}, {0.1, 0.05, 0.1, 0.01, 0.005} and {1e \u22124 , 1e \u22125 , 0}.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the datasets.", "labels": [], "entities": []}, {"text": " Table 2: Detailed performances on FB15k of  TRANSE and RTRANSE. H@10 are in %. W.  COMP. indicates examples for which there exist  quadruplets in train matching their relationship.", "labels": [], "entities": [{"text": "FB15k", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.8872140645980835}, {"text": "TRANSE", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.6460821628570557}, {"text": "COMP", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.47275999188423157}]}]}