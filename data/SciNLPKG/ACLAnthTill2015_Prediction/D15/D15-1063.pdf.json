{"title": [{"text": "A Baseline Temporal Tagger for all Languages", "labels": [], "entities": [{"text": "Baseline Temporal Tagger", "start_pos": 2, "end_pos": 26, "type": "TASK", "confidence": 0.5970062514146169}]}], "abstractContent": [{"text": "Temporal taggers are usually developed fora certain language.", "labels": [], "entities": [{"text": "Temporal taggers", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9517576396465302}]}, {"text": "Besides English, only few languages have been addressed, and only the temporal tagger HeidelTime covers several languages.", "labels": [], "entities": []}, {"text": "While this tool was manually extended to these languages , there have been earlier approaches for automatic extensions to a single target language.", "labels": [], "entities": []}, {"text": "In this paper, we present an approach to extend HeidelTime to all languages in the world.", "labels": [], "entities": []}, {"text": "Our evaluation shows promising results, in particular considering that our approach neither requires language skills nor training data, but results in a baseline tagger for 200+ languages.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "For a subset of languages, temporally annotated corpora exist.", "labels": [], "entities": []}, {"text": "Thus, we can directly evaluate our approach for these languages.", "labels": [], "entities": []}, {"text": "For German, Spanish, Italian, French, Portuguese, Croatian, Arabic, Vietnamese, and Chinese, we compare our automatic approach with HeidelTime's manually developed resources.", "labels": [], "entities": []}, {"text": "In addition, first results are reported for Romanian.", "labels": [], "entities": []}, {"text": "For all other languages, it is obviously difficult to judge the temporal tagging quality of the newly developed resources.", "labels": [], "entities": []}, {"text": "However, for an estimation of the quality for languages without temporally annotated corpora, we provide completeness statistics of the pattern translations.", "labels": [], "entities": []}, {"text": "The fewer translations are available fora language, the more likely it is that the temporal tagging quality is rather low.", "labels": [], "entities": []}, {"text": "Since the task of temporal tagging is two-fold, we report precision, recall, and F1-score for the extraction task, and for the full task (relaxed extraction plus value normalization) value F1.", "labels": [], "entities": [{"text": "temporal tagging", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.6501983106136322}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9995556473731995}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9986745119094849}, {"text": "F1-score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9994639754295349}, {"text": "F1", "start_pos": 189, "end_pos": 191, "type": "METRIC", "confidence": 0.8355920314788818}]}, {"text": "Similar as the TempEval-3 organizers (, we consider value F1 with relaxed matching as most important.", "labels": [], "entities": [{"text": "TempEval-3 organizers", "start_pos": 15, "end_pos": 36, "type": "DATASET", "confidence": 0.8358194530010223}, {"text": "F1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9929388761520386}]}, {"text": "However, when processing large amounts of data, value accuracy becomes also important.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9723656177520752}]}, {"text": "Since it directly shows independent of the recall if extracted expressions are normalized correctly, it is reported, too.", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.997475802898407}]}, {"text": "As shown in, the results of our automatically created resources are worse than those of HeidelTime with manually developed resources.", "labels": [], "entities": []}, {"text": "For Spanish, German, French, and Portuguese, high precision, moderate recall, and good normalization results are achieved.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9995133876800537}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.999751627445221}]}, {"text": "In contrast, recall for Chinese, Croatian, and Romanian are quite low, precision is low for Romanian, and normalization accuracy for Chinese, Vietnamese and Romanian.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9996640682220459}, {"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9996569156646729}, {"text": "normalization", "start_pos": 106, "end_pos": 119, "type": "METRIC", "confidence": 0.9793350696563721}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.8821092844009399}]}, {"text": "Clearly, more work is necessary to achieve temporal tagging quality that can be considered as applicable for other applications.", "labels": [], "entities": [{"text": "temporal tagging", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.698060154914856}]}, {"text": "In particular, issues with morphology-rich languages and those without white-space tokenization have to be addressed.", "labels": [], "entities": []}, {"text": "Nevertheless, the results look promising for several languages taking into account that the resources are developed without any languagespecific information, and that our approach has been the first step towards more sophisticated temporal tagging of all languages in the world.", "labels": [], "entities": [{"text": "temporal tagging", "start_pos": 231, "end_pos": 247, "type": "TASK", "confidence": 0.6686368733644485}]}, {"text": "Note that recall is much worse than precision for all languages and that the normalization of extracted expressions works quite well (value acc.).", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9993539452552795}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9986547231674194}]}], "tableCaptions": [{"text": " Table 1: Evaluation results for several languages on public corpora. HeidelTime 1.9 results as reported  on https://github.com/HeidelTime/heideltime/wiki/Evaluation-Results.", "labels": [], "entities": []}]}