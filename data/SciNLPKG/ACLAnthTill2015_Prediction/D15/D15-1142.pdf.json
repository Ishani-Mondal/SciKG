{"title": [{"text": "Semi-supervised Chinese Word Segmentation based on Bilingual Information", "labels": [], "entities": [{"text": "Semi-supervised Chinese Word Segmentation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5402913093566895}]}], "abstractContent": [{"text": "This paper presents a bilingual semi-supervised Chinese word segmentation (CWS) method that leverages the natural segmenting information of English sentences.", "labels": [], "entities": [{"text": "bilingual semi-supervised Chinese word segmentation (CWS)", "start_pos": 22, "end_pos": 79, "type": "TASK", "confidence": 0.7473587840795517}]}, {"text": "The proposed method involves learning three levels of features, namely, character-level, phrase-level and sentence-level, provided by multiple sub-models.", "labels": [], "entities": []}, {"text": "We use a sub-model of conditional random fields (CRF) to learn mono-lingual grammars, a sub-model based on character-based alignment to obtain explicit segmenting knowledge, and another sub-model based on transliteration similarity to detect out-of-vocabulary (OOV) words.", "labels": [], "entities": []}, {"text": "Moreover, we propose a sub-model leveraging neural network to ensure the proper treatment of the semantic gap and a phrase-based translation sub-model to score the translation probability of the Chi-nese segmentation and its corresponding English sentences.", "labels": [], "entities": []}, {"text": "A cascaded log-linear model is employed to combine these features to segment bilingual unlabeled data, the results of which are used to justify the original supervised CWS model.", "labels": [], "entities": []}, {"text": "The evaluation shows that our method results in superior results compared with those of the state-of-the-art monolingual and bilingual semi-supervised models that have been reported in the literature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Chinese word segmentation (CWS) is generally accepted to be a necessary first step inmost Chinese NLP tasks because Chinese sentences are written in continuous sequences of characters with no explicit delimiters (e.g., the spaces in English).", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.759285181760788}]}, {"text": "Many studies have been conducted in this area, resulting in extensive investigation of the problem of CWS using machine learning techniques in recent years.", "labels": [], "entities": [{"text": "CWS", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9194065928459167}]}, {"text": "However, the reliability of CWS that can be achieved using machine learning techniques relies heavily on the availability of a large amount of high-quality, manually segmented data.", "labels": [], "entities": [{"text": "CWS", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9435986280441284}]}, {"text": "Because hand-labeling individual words and word boundaries is very difficult (), producing segmented Chinese texts is very time-consuming and expensive.", "labels": [], "entities": []}, {"text": "Although a number of manually segmented datasets have been constructed by various organizations, it is not feasible to combine them into a single complete dataset because of their incompatibility due to the use of various segmenting standards.", "labels": [], "entities": []}, {"text": "Thus, it is difficult to build a large-scale manually segmented corpus, and the resulting lack of such a corpus is detrimental to further enhancement of the accuracy of CWS.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9988399147987366}]}, {"text": "To address the scarcity of manually segmented corpora, a number of semi-supervised CWS approaches have been intensively investigated in recent years.", "labels": [], "entities": []}, {"text": "These approaches attempt to either learn the predicted label distribution () or extract mutual information); (Sun and Xu, 2011); () from large-scale monolingual unlabeled data to update the baseline model (from manually segmented corpora).", "labels": [], "entities": []}, {"text": "In addition to these techniques, several co-training approaches () using character-based and word-based models have also been employed.", "labels": [], "entities": []}, {"text": "However, because monolingual unlabeled data contain limited natural segmenting information, inmost semisupervised methods, the objective function tends to be optimized based on the personal experience and knowledge of the researchers.", "labels": [], "entities": []}, {"text": "This practice means that these methods can typically yield high performance in certain specialized domains, but they lack generalizability.", "labels": [], "entities": []}, {"text": "In contrast with these methods, we propose to leverage bilingual unlabeled data, i.e., a Chinese-English corpus with sentence alignment.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.70969457924366}]}, {"text": "Because English sentences are naturally segmented, extracting information from a bilingual corpus is a much more objective task.", "labels": [], "entities": []}, {"text": "As the example presented in, the English sentences that correspond to Chinese text can easily help guide better segmentation, and thus, the learning of segmenting information from bilingual data is a very promising approach.", "labels": [], "entities": []}, {"text": "In this paper, to obtain high-quality segmenting information from bilingual unlabeled data, we leverage multilevel features using the following steps: first, we integrate character-level features calculated using a conditional random field (CRF) model, which is used to capture the monolingual grammars.", "labels": [], "entities": []}, {"text": "Then, we employ a statistical aligner to perform character-based alignment.", "labels": [], "entities": [{"text": "character-based alignment", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.787060022354126}]}, {"text": "Given the results of this character-based alignment, we apply several phrase-level features to extract explicit and implicit segmenting information: (1) we use two types of English-Chinese co-occurrence features (one-to-many and many-to-many) to learn the explicit segmenting information of the English sentences, (2) we use the transliteration similarity feature to detect out-of-vocabulary (OOV) words using a phrase-based translation model, and (3) we employ a neural network to calculate the semantic gap between the Chinese and English words to ensure that the Chinese segmentation follows the semantic meanings of the corresponding English sentences as closely as possible.", "labels": [], "entities": []}, {"text": "Finally, we employ another phrase-based translation model to perform a sentence-level calculation of the translation probability of the Chinese segmentation and its corresponding English sentences.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.5989103764295578}]}, {"text": "After obtaining these multilevel features, we normalize them and combine them into two log-linear models in a cascaded structure, which is illustrated in Finally, we segment the bilingual unlabeled data using the proposed model and use the segmentation of those data to justify the original super-: The structure of cascaded log-linear model with multilevel features vised CWS model, which was trained on a standard manually segmented corpus.", "labels": [], "entities": []}, {"text": "In fact, several semi-supervised CWS methods have previously been proposed that leverage bilingual unlabeled data;;;;).", "labels": [], "entities": []}, {"text": "However, most were developed for statistical machine translation (SMT), causing them to focus on decreasing the perplexity of the bilingual data and the word alignment process rather than on achieving more accurate segmentation.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.8212805340687434}, {"text": "word alignment", "start_pos": 153, "end_pos": 167, "type": "TASK", "confidence": 0.7547798454761505}]}, {"text": "These methods achieve significant improvement in SMT performance but are not very suitable for common NLP tasks because in many situations, they ignore the standard grammars to satisfy the needs of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9965325593948364}, {"text": "SMT", "start_pos": 198, "end_pos": 201, "type": "TASK", "confidence": 0.985822856426239}]}, {"text": "By contrast, we employ various types of features to capture both monolingual standard grammars and bilingual segmenting information, which allows our semi-supervised CWS model to be very efficient at other NLP tasks and endows it with higher generalizability.", "labels": [], "entities": [{"text": "bilingual segmenting information", "start_pos": 99, "end_pos": 131, "type": "TASK", "confidence": 0.7519774933656057}]}, {"text": "Our evaluation also shows that our method significantly outperforms the state-of-the-art monolingual and bilingual semi-supervised approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this paper, we conduct our experiments on the corpus of People's daily of 1998 (from January to June) as the standard (manually segmented) training corpus, the corpus of Bakeoff-2 CWS evaluation as the developing and testing dataset.", "labels": [], "entities": [{"text": "People's daily of 1998", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.9539381623268127}]}, {"text": "As the corpus of Bakeoff-2 is made up of several sets provided by different organizations, we only select two sets whose segmenting standards are similar to the training corpus.", "labels": [], "entities": []}, {"text": "For each set, we take 3000 sentences as the developing dataset and the others as the testing dataset.", "labels": [], "entities": []}, {"text": "The statistics of every set and the standard training corpus are shown in Moreover, the bilingual unlabeled data is formed by a large in-house Chinese-English parallel corpus).", "labels": [], "entities": []}, {"text": "There are in total 2,215,000 Chinese-English sentence pairs crawled from online resources, concentrated in 5 different domains including laws, novels, spoken, news and miscellaneous.", "labels": [], "entities": []}, {"text": "In our evaluation, the F-score was used as the accuracy measure.", "labels": [], "entities": [{"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9982703924179077}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9995750784873962}]}, {"text": "The precision p is defined as the percentage of words in the decoder output that are segmented correctly, and the recall r is the percentage of gold-standard output words that are correctly segmented by the decoder.", "labels": [], "entities": [{"text": "precision p", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9764164090156555}, {"text": "recall r", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9935427606105804}]}, {"text": "The balanced F-score is calculated as 2pr/(p + r).", "labels": [], "entities": [{"text": "F-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9973205924034119}]}, {"text": "We also report the recall of OOV words in our experiments.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9988652467727661}]}, {"text": "In the following, we refer to our methods as \"SLBD\" (segmenter leveraging bilingual data).", "labels": [], "entities": []}, {"text": "Initially, we evaluated state-of-the-art supervised CWS methods, i.e., those of (  segmenting the bilingual unlabeled dataset using character-level features only, the inner log-linear model (which includes character-level and phraselevel features) and the outer log-linear model (the full SLBD approach).", "labels": [], "entities": []}, {"text": "After applying these three segmentations using the different sub-models, we trained the new CRF models on the results of the three segmentations to justify the original CWS model.", "labels": [], "entities": []}, {"text": "The evaluation results for the supervised CWS methods and the sub-models are presented in.", "labels": [], "entities": []}, {"text": "It can be seen that we achieved significant improvement in performance when we combined the character-level and phrase-level features in the inner log-linear model, demonstrating that the proposed phrase-level features can be used to efficiently obtain bilingual segmenting information.", "labels": [], "entities": [{"text": "bilingual segmenting information", "start_pos": 253, "end_pos": 285, "type": "TASK", "confidence": 0.7585726678371429}]}, {"text": "Moreover, the outer log-linear model achieves a further enhancement, thereby demonstrating that the sentence-level features can be used to effectively re-rank the candidate segmentations produced by the inner log-linear model.", "labels": [], "entities": []}, {"text": "Next, we compared the SLBD method with several state-of-the-art monolingual semi-supervised methods, including those of (Sun et al., 2012) (Sun); (Sun and Xu, 2011) (S&X); (Zeng et al., 2013b) (Zeng).", "labels": [], "entities": []}, {"text": "To ensure a fair comparison, we performed the evaluation in two steps.", "labels": [], "entities": []}, {"text": "First, we input the entire bilingual unlabeled dataset into the SLBD method and input only the Chinese sentences from the bilingual unlabeled dataset into the other semi-supervised methods.", "labels": [], "entities": []}, {"text": "Then, because the available monolingual unlabeled dataset was much larger than the bilingual unlabeled dataset in natural, we used the XIN CMN portion of Chinese Gigaword 2.0 as an additional unlabeled dataset for the monolingual semi-supervised methods.", "labels": [], "entities": [{"text": "XIN CMN portion of Chinese Gigaword 2.0", "start_pos": 135, "end_pos": 174, "type": "DATASET", "confidence": 0.7956603680338178}]}, {"text": "which contains 204 million words, more than ten times   the number of words in the bilingual unlabeled dataset.", "labels": [], "entities": []}, {"text": "The testing data was the set of AS only.", "labels": [], "entities": [{"text": "AS", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9965259432792664}]}, {"text": "The evaluation is summarized in.", "labels": [], "entities": []}, {"text": "The results demonstrate that either leveraging the same unlabeled data or providing a much larger unlabeled dataset for the monolingual semisupervised methods, the SLBD method can significantly outperform the evaluated monolingual semi-supervised methods, which indicates that the segmenting information obtained using SLBD is much more efficient at optimizing segmentation.", "labels": [], "entities": []}, {"text": "indicate that SLBD demonstrates much stronger performance, primarily because these other methods were developed with a focus on SMT, which causes them to preferentially decrease the perplexity of the subsequent SMT steps rather than producing a highly accurate segmentation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9884257316589355}, {"text": "SMT", "start_pos": 211, "end_pos": 214, "type": "TASK", "confidence": 0.9713989496231079}]}, {"text": "In contrast to these methods, the SLBD method exhibits greater generalizability.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Word segmentation performance of SLB- D and supervised CWS methods[%]", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7601444125175476}]}, {"text": " Table 3: Word segmentation performance of SLB- D and other monolingual semi-supervised CWS  methods[%]", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7545137107372284}]}, {"text": " Table 4: Word segmentation performance of SLB- D and other bilingual semi-supervised CWS meth- ods[%]", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7289129197597504}]}]}