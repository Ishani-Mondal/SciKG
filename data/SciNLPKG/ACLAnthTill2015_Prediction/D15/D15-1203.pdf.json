{"title": [{"text": "Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks", "labels": [], "entities": [{"text": "Distant Supervision", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9556428790092468}, {"text": "Relation Extraction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9795631766319275}]}], "abstractContent": [{"text": "Two problems arise when using distant supervision for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.921767920255661}]}, {"text": "First, in this method, an already existing knowledge base is heuristically aligned to texts, and the alignment results are treated as labeled data.", "labels": [], "entities": []}, {"text": "However, the heuristic alignment can fail, resulting in wrong label problem.", "labels": [], "entities": []}, {"text": "In addition, in previous approaches , statistical models have typically been applied toad hoc features.", "labels": [], "entities": []}, {"text": "The noise that originates from the feature extraction process can cause poor performance.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7285697311162949}]}, {"text": "In this paper, we propose a novel model dubbed the Piecewise Convolu-tional Neural Networks (PCNNs) with multi-instance learning to address these two problems.", "labels": [], "entities": []}, {"text": "To solve the first problem , distant supervised relation extraction is treated as a multi-instance problem in which the uncertainty of instance labels is taken into account.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.5869473069906235}]}, {"text": "To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.760894238948822}]}, {"text": "Experiments show that our method is effective and outperforms several competitive base-line methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "In relation extraction, one challenge that is faced when building a machine learning system is the generation of training examples.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.957693338394165}]}, {"text": "One common technique for coping with this difficulty is distant supervision () which assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in someway.", "labels": [], "entities": []}, {"text": "shows an example of the auto- matic labeling of data through distant supervision.", "labels": [], "entities": []}, {"text": "In this example, Apple and Steve Jobs are two related entities in Freebase . All sentences that contain these two entities are selected as training instances.", "labels": [], "entities": []}, {"text": "The distant supervision strategy is an effective method of automatically labeling training data.", "labels": [], "entities": []}, {"text": "However, it has two major shortcomings when used for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9250265657901764}]}, {"text": "First, the distant supervision assumption is too strong and causes the wrong label problem.", "labels": [], "entities": []}, {"text": "A sentence that mentions two entities does not necessarily express their relation in a knowledge base.", "labels": [], "entities": []}, {"text": "It is possible that these two entities may simply share the same topic.", "labels": [], "entities": []}, {"text": "For instance, the upper sentence indeed expresses the \"company/founders\" relation in.", "labels": [], "entities": []}, {"text": "The lower sentence, however, does not express this relation but is still selected as a training instance.", "labels": [], "entities": []}, {"text": "This will hinder the performance of a model trained on such noisy data.", "labels": [], "entities": []}, {"text": "Second, previous methods () have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision.", "labels": [], "entities": []}, {"text": "These features are often derived from preexisting Natural Language Processing (NLP) tools.", "labels": [], "entities": []}, {"text": "Since errors inevitably exist in NLP tools, the use of traditional features leads to error propagation or accumulation.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.667043149471283}]}, {"text": "Distant supervised relation extraction generally ad- dresses corpora from the Web, including many informal texts.", "labels": [], "entities": [{"text": "Distant supervised relation extraction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5744242146611214}]}, {"text": "shows the sentence length distribution of a benchmark distant supervision dataset that was developed by.", "labels": [], "entities": []}, {"text": "Approximately half of the sentences are longer than 40 words.", "labels": [], "entities": []}, {"text": "showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9995645880699158}, {"text": "syntactic parsing", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.8084926307201385}]}, {"text": "Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.6730571687221527}]}, {"text": "In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above.", "labels": [], "entities": []}, {"text": "To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies ().", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 30, "end_pos": 68, "type": "TASK", "confidence": 0.5579953715205193}]}, {"text": "In multi-instance problem, the training set consists of many bags, and each contains many instances.", "labels": [], "entities": []}, {"text": "The labels of the bags are known; however, the labels of the instances in the bags are unknown.", "labels": [], "entities": []}, {"text": "We design an objective function at the bag level.", "labels": [], "entities": []}, {"text": "In the learning process, the uncertainty of instance labels can betaken into account; this alleviates the wrong label problem.", "labels": [], "entities": []}, {"text": "To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by.", "labels": [], "entities": []}, {"text": "Our proposal is an extension of, in which a single max pooling operation is utilized to determine the most significant features.", "labels": [], "entities": []}, {"text": "Although this operation has been shown to be effective for textual feature representation, it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities).", "labels": [], "entities": [{"text": "textual feature representation", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.6544800897439321}]}, {"text": "For example, to identify the relation between Steve Jobs and Apple in, we need to specify the entities and extract the structural features between them.", "labels": [], "entities": []}, {"text": "Several approaches have employed manually crafted features that attempt to model such structural information.", "labels": [], "entities": []}, {"text": "These approaches usually consider both internal and external contexts.", "labels": [], "entities": []}, {"text": "A sentence is inherently divided into three segments according to the two given entities.", "labels": [], "entities": []}, {"text": "The internal context includes the characters inside the two entities, and the external context involves the characters around the two entities ( ).", "labels": [], "entities": []}, {"text": "Clearly, single max pooling is not sufficient to capture such structural information.", "labels": [], "entities": []}, {"text": "To capture structural and other latent information, we divide the convolution results into three segments based on the positions of the two given entities and devise a piecewise max pooling layer instead of the single max pooling layer.", "labels": [], "entities": []}, {"text": "The piecewise max pooling procedure returns the maximum value in each segment instead of a single maximum value over the entire sentence.", "labels": [], "entities": []}, {"text": "Thus, it is expected to exhibit superior performance compared with traditional methods.", "labels": [], "entities": []}, {"text": "The contributions of this paper can be summarized as follows.", "labels": [], "entities": []}, {"text": "\u2022 We explore the feasibility of performing distant supervised relation extraction without hand-designed features.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 43, "end_pos": 81, "type": "TASK", "confidence": 0.6473611667752266}]}, {"text": "PCNNS are proposed to automatically learn features without complicated NLP preprocessing.", "labels": [], "entities": [{"text": "PCNNS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8904908299446106}]}, {"text": "\u2022 To address the wrong label problem, we develop innovative solutions that incorporate multi-instance learning into the PCNNS for distant supervised relation extraction.", "labels": [], "entities": [{"text": "PCNNS", "start_pos": 120, "end_pos": 125, "type": "DATASET", "confidence": 0.8891687393188477}, {"text": "distant supervised relation extraction", "start_pos": 130, "end_pos": 168, "type": "TASK", "confidence": 0.568952314555645}]}, {"text": "\u2022 In the proposed network, we devise a piecewise max pooling layer, which aims to capture structural information between two entities.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are intended to provide evidence that supports the following hypothesis: automatically learning features using PCNNs with multiinstance learning can lead to an increase in performance.", "labels": [], "entities": []}, {"text": "To this end, we first introduce the dataset and evaluation metrics used.", "labels": [], "entities": []}, {"text": "Next, we test several variants via cross-validation to determine the parameters to be used in our experiments.", "labels": [], "entities": []}, {"text": "We then compare the performance of our method to those of several traditional methods.", "labels": [], "entities": []}, {"text": "Finally, we evaluate the effects of piecewise max pooling and multiinstance learning 3 .  We evaluate our method on a widely used dataset 4 that was developed by ( and has also been used by.", "labels": [], "entities": []}, {"text": "This dataset was generated by aligning Freebase relations with the NYT corpus, with sentences from the years 2005-2006 used as the training corpus and sentences from 2007 used as the testing corpus.", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.9784200489521027}]}, {"text": "Following previous work), we evaluate our method in two ways: the held-out evaluation and the manual evaluation.", "labels": [], "entities": []}, {"text": "The heldout evaluation only compares the extracted relation instances against Freebase relation data and reports the precision/recall curves of the experiments.", "labels": [], "entities": [{"text": "Freebase relation data", "start_pos": 78, "end_pos": 100, "type": "DATASET", "confidence": 0.8839672406514486}, {"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9991371035575867}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.8704236745834351}]}, {"text": "In the manual evaluation, we manually check the newly discovered relation instances that are not in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 100, "end_pos": 108, "type": "DATASET", "confidence": 0.9763222932815552}]}, {"text": "The held-out evaluation provides an approximate measure of precision without requiring costly human evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9994500279426575}]}, {"text": "Half of the Freebase relations are used for testing.", "labels": [], "entities": [{"text": "Freebase relations", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.9475758671760559}]}, {"text": "The relation instances discovered from the test articles are automatically compared with those in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 98, "end_pos": 106, "type": "DATASET", "confidence": 0.9705407619476318}]}, {"text": "To evaluate the proposed method, we select the following three traditional methods for comparison.", "labels": [], "entities": []}, {"text": "Mintz represents a traditional distantsupervision-based model that was proposed by.", "labels": [], "entities": []}, {"text": "MultiR is a multi-instance learning method that was proposed by).", "labels": [], "entities": []}, {"text": "MIML is a multi-instance multilabel model that was proposed by ().", "labels": [], "entities": []}, {"text": "shows the precision-recall curves for each method, where PCNNs+MIL denotes our method, and demonstrates that PCNNs+MIL achieves higher precision over the entire range of recall.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9963597655296326}, {"text": "MIL", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.8407565355300903}, {"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.996554970741272}, {"text": "recall", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.9686527252197266}]}, {"text": "PCNNs+MIL enhances the recall to ap-: Precision values for the top 100, top 200, and top 500 extracted relation instances upon manual evaluation.", "labels": [], "entities": [{"text": "MIL", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.9287712574005127}, {"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9991074204444885}, {"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.990642249584198}]}, {"text": "proximately 34% without any loss of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9995456337928772}]}, {"text": "In terms of both precision and recall, PCNNs+MIL outperforms all other evaluated approaches.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9994230270385742}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9994688630104065}, {"text": "MIL", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9108391404151917}]}, {"text": "Notably, the results of the methods evaluated for comparison were obtained using manually crafted features.", "labels": [], "entities": []}, {"text": "By contrast, our result is obtained by automatically learning features from original words.", "labels": [], "entities": []}, {"text": "The results demonstrate that the proposed method is an effective technique for distant supervised relation extraction.", "labels": [], "entities": [{"text": "distant supervised relation extraction", "start_pos": 79, "end_pos": 117, "type": "TASK", "confidence": 0.7200845032930374}]}, {"text": "Automatically learning features via PCNNs can alleviate the error propagation that occurs in traditional feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7741148769855499}]}, {"text": "Incorporating multi-instance learning into a convolutional neural network is an effective means of addressing the wrong label problem.", "labels": [], "entities": []}, {"text": "It is worth emphasizing that there is a sharp decline in the held-out precision-recall curves of PCNNs+MIL at very low recall.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 70, "end_pos": 86, "type": "METRIC", "confidence": 0.9922850131988525}, {"text": "MIL", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.8928441405296326}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9976376295089722}]}, {"text": "A manual check of the misclassified examples that were produced with high confidence reveals that the ma-jorities of these examples are false negatives and are actually true relation instances that were misclassified due to the incomplete nature of Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 249, "end_pos": 257, "type": "DATASET", "confidence": 0.9535210132598877}]}, {"text": "Thus, the held-out evaluation suffers from false negatives in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.984458327293396}]}, {"text": "We perform a manual evaluation to eliminate these problems.", "labels": [], "entities": []}, {"text": "For the manual evaluation, we choose the entity pairs for which at least one participating entity is not present in Freebase as a candidate.", "labels": [], "entities": []}, {"text": "This means that there is no overlap between the held-out and manual candidates.", "labels": [], "entities": []}, {"text": "Because the number of relation instances that are expressed in the test data is unknown, we cannot calculate the recall in this case.", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9991762042045593}]}, {"text": "Instead, we calculate the precision of the top N extracted relation instances.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9991242289543152}]}, {"text": "presents the manually evaluated precisions for the top 100, top 200, and top 500 extracted instances.", "labels": [], "entities": [{"text": "precisions", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9894747734069824}]}, {"text": "The results show that PCNNs+MIL achieves the best performance; moreover, the precision is higher than in the held-out evaluation.", "labels": [], "entities": [{"text": "MIL", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9399460554122925}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9997072815895081}]}, {"text": "This finding indicates that many of the false negatives that we predict are, in fact, true relational facts.", "labels": [], "entities": []}, {"text": "The sharp decline observed in the held-out precision-recall curves is therefore reasonable.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 43, "end_pos": 59, "type": "METRIC", "confidence": 0.9319847226142883}]}], "tableCaptions": [{"text": " Table 2: Precision values for the top 100, top 200,  and top 500 extracted relation instances upon man- ual evaluation.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9739211797714233}]}]}