{"title": [{"text": "A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems for Speech Translation", "labels": [], "entities": [{"text": "Speech Translation", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7388956993818283}]}], "abstractContent": [{"text": "Speech translation is conventionally carried out by cascading an automatic speech recognition (ASR) and a statistical machine translation (SMT) system.", "labels": [], "entities": [{"text": "Speech translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8429524004459381}, {"text": "automatic speech recognition (ASR)", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.7567927539348602}, {"text": "statistical machine translation (SMT)", "start_pos": 106, "end_pos": 143, "type": "TASK", "confidence": 0.7967792550722758}]}, {"text": "The hypotheses chosen for translation are based on the ASR system's acoustic and language model scores, and typically optimized for word error rate, ignoring the intended downstream use: automatic translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.9704951643943787}, {"text": "automatic translation", "start_pos": 187, "end_pos": 208, "type": "TASK", "confidence": 0.7302555441856384}]}, {"text": "In this paper, we present a coarse-to-fine model that uses features from the ASR and SMT systems to optimize this coupling.", "labels": [], "entities": [{"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9034889936447144}]}, {"text": "We demonstrate that several standard features utilized by ASR and SMT systems can be used in such a model at the speech-translation interface, and we provide empirical results on the Fisher Spanish-English speech translation corpus .", "labels": [], "entities": [{"text": "ASR", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9688552021980286}, {"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9532651901245117}, {"text": "Fisher Spanish-English speech translation corpus", "start_pos": 183, "end_pos": 231, "type": "DATASET", "confidence": 0.6199531555175781}]}], "introductionContent": [{"text": "Speech translation is the process of translating speech in the source language to text or speech in the target language.", "labels": [], "entities": [{"text": "Speech translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7613968849182129}]}, {"text": "This process is typically structured as a three step pipeline.", "labels": [], "entities": []}, {"text": "Step one involves training an Automatic Speech Recognition (ASR) system to transcribe speech to text in the source language.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 30, "end_pos": 64, "type": "TASK", "confidence": 0.7684956043958664}]}, {"text": "Step two involves extracting an appropriate form of the ASR output to translate.", "labels": [], "entities": [{"text": "ASR", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9415993690490723}, {"text": "translate", "start_pos": 70, "end_pos": 79, "type": "TASK", "confidence": 0.9620843529701233}]}, {"text": "We will refer to this step as the Speech-Translation interface.", "labels": [], "entities": []}, {"text": "In the simplest scenario, the ASR 1-best output can be used as the source text to translate.", "labels": [], "entities": [{"text": "ASR 1-best output", "start_pos": 30, "end_pos": 47, "type": "METRIC", "confidence": 0.5720786650975546}, {"text": "translate", "start_pos": 82, "end_pos": 91, "type": "TASK", "confidence": 0.959945559501648}]}, {"text": "It maybe useful to consider alternative ASR hypotheses and these take the form of an N -best list or a word-lattice.", "labels": [], "entities": [{"text": "ASR hypotheses", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.8916409015655518}]}, {"text": "An N -best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system ().", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 85, "end_pos": 122, "type": "TASK", "confidence": 0.766955574353536}]}, {"text": "Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (; Bangalore and.", "labels": [], "entities": [{"text": "Bangalore", "start_pos": 112, "end_pos": 121, "type": "DATASET", "confidence": 0.939754843711853}]}, {"text": "Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present.", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9616202712059021}]}, {"text": "Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 51, "end_pos": 88, "type": "TASK", "confidence": 0.7981054683526357}]}, {"text": "This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system.", "labels": [], "entities": [{"text": "ASR", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.879002034664154}, {"text": "SMT", "start_pos": 142, "end_pos": 145, "type": "TASK", "confidence": 0.9875682592391968}]}, {"text": "Our motivation is as follows: 1.", "labels": [], "entities": []}, {"text": "Using downstream information : Hypothesis selection for the input to the SMT system should be done jointly by the ASR and the SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9776673913002014}, {"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.8988693356513977}]}, {"text": "That is, there may exist hypotheses that a trained SMT system may find easier to translate and produce better translations for than the ones that are deemed best based on the ASR acoustic and language model scores.", "labels": [], "entities": [{"text": "SMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9928183555603027}, {"text": "ASR acoustic", "start_pos": 175, "end_pos": 187, "type": "TASK", "confidence": 0.7789377570152283}]}, {"text": "Incorporation of knowledge from the downstream process (translation) is vital to selecting translation options, and subsequently producing better translations.", "labels": [], "entities": [{"text": "translation)", "start_pos": 56, "end_pos": 68, "type": "TASK", "confidence": 0.9543308615684509}]}, {"text": "2. Coarse-to-fine grained decoding : An intermediate model which acts as an interface and is a weak (coarse) version of the downstream process maybe able to select better hypotheses.", "labels": [], "entities": []}, {"text": "In effect, a weak translation decoder can be used as the interface to estimate the expected translation quality of an ASR hypothesis.", "labels": [], "entities": [{"text": "ASR hypothesis", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.9212677478790283}]}, {"text": "This method of hypothesis selection should be able to incorporate features from the ASR and the SMT system.", "labels": [], "entities": [{"text": "hypothesis selection", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.8551811873912811}, {"text": "ASR", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.7179532051086426}, {"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9755010008811951}]}, {"text": "3. Phrase units vs. word units : When a phrase based SMT system is used for translation, optimization for hypothesis selection at the Speech-Translation interface should be conducted using phrases as the basic unit instead of words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.8921815156936646}, {"text": "hypothesis selection", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.7022526264190674}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance when using the coarse de- coder interface compared to the the decoding the  human transcripts, the ASR 1-best or the lattice  oracle (the path in the ASR lattice with the least  WER : not available during test time.)", "labels": [], "entities": [{"text": "WER", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9883837103843689}]}]}