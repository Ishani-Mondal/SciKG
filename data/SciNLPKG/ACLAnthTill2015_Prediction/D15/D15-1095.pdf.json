{"title": [], "abstractContent": [{"text": "Wikipedia is the largest collection of ency-clopedic data ever written in the history of humanity.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9286075830459595}]}, {"text": "Thanks to its coverage and its availability in machine-readable format, it has become a primary resource for large-scale research in historical and cultural studies.", "labels": [], "entities": [{"text": "historical and cultural studies", "start_pos": 133, "end_pos": 164, "type": "TASK", "confidence": 0.6381589770317078}]}, {"text": "In this work, we focus on the subset of pages describing persons, and we investigate the task of recognizing biographical sections from them: given a person's page, we identify the list of sections where information about her/his life is present.", "labels": [], "entities": []}, {"text": "We model this as a sequence classification problem, and propose a supervised setting, in which the training data are acquired automatically.", "labels": [], "entities": [{"text": "sequence classification", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.8021228015422821}]}, {"text": "Besides, we show that six simple features extracted only from the section titles are very informative and yield good results well above a strong baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the last years, several projects have started to address the mechanisms behind cultural development, borrowing techniques and algorithms from computer science and natural language processing to serve historical investigation.", "labels": [], "entities": []}, {"text": "Efforts such as BiographyNet 1 , Pantheon 2 or the Austrian Prosopographical Information System 3 prove an increasing interest in automatically extracting biographical descriptions from large amounts of data and combining them in a more general picture, taking advantage of the availability of such descriptions on the web.", "labels": [], "entities": [{"text": "Pantheon", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.9371943473815918}, {"text": "Austrian Prosopographical Information System", "start_pos": 51, "end_pos": 95, "type": "DATASET", "confidence": 0.9200962632894516}]}, {"text": "Wikipedia has been the main source of information for research in this direction despite its many biases, for instance its well-known English, Western and gender bias).", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9138996601104736}]}, {"text": "In fact, Wikipedia coverage both in terms of pages and in terms of languages, as well as the structured information that can be leveraged through DBpedia, has made it the primary resource for large-scale analyses on biographies.", "labels": [], "entities": []}, {"text": "However, the lack of a consistent template for describing persons' lives led to the creation of a plethora of page types, where biographical information is displayed in diverse ways.", "labels": [], "entities": []}, {"text": "Based on a random sample of 100 persons' pages, we noticed that only 20% of them includes a section called Biography or Life, typically containing a set of subsections describing the main periods in a person's life from birth to death (see for instance https://en.wikipedia.org/ wiki/Leonard_Bernstein).", "labels": [], "entities": []}, {"text": "The other pages in our sample do not follow a pre-defined pattern and present the person's biography in one or several sections at the same level of the other ones (see for instance https://en. wikipedia.org/wiki/Judy_Holliday, with the Filmography and Discography sections at the same level of Early Life and Career).", "labels": [], "entities": []}, {"text": "Given this high variability, it is very difficult to extract all and only those sections that describe a biography, and that build all together in sequence the description of a person's life.", "labels": [], "entities": []}, {"text": "This depends also on the different types of non-biographical sections available, which in the case of prominent persons typically include main themes, reception, style, influences, legacy, work titles, etc.", "labels": [], "entities": []}, {"text": "(see for instance Will to power, Eternal return, Perspectivism, Critique on mass culture in https://en.wikipedia.org/wiki/ Friedrich_Nietzsche).", "labels": [], "entities": []}, {"text": "In this work, we present a simple methodology that, given a person's page in Wikipedia, recog-nizes all sections that deal with his/her life even if no Biography section is present.", "labels": [], "entities": []}, {"text": "The problem is modeled as a classification task using Conditional Random Fields, which are particularly suitable for our study because the biographical sections tend to follow a chronological order and present typical sequential patterns (for instance, the section Early Life is often followed by Early Career).", "labels": [], "entities": []}, {"text": "While a simple token-based baseline is very difficult to beat when the task is performed at section level (i.e. deciding whether a section is biographical or not), our method performs best when the evaluation is performed at page level, recognizing all sections that describe a person's life.", "labels": [], "entities": []}, {"text": "This is crucial if the task under investigation is meant as a preliminary step towards the automatic extraction of all events that compose a person's biography.", "labels": [], "entities": [{"text": "automatic extraction of all events that compose a person's biography", "start_pos": 91, "end_pos": 159, "type": "TASK", "confidence": 0.7706180323253978}]}], "datasetContent": [{"text": "We cast the problem as a supervised learning classification task, with the goal to label sequences of Wikipedia sections as describing a person's biography or not.", "labels": [], "entities": []}, {"text": "As discussed in the introduction, we use Conditional Random Fields, since they are particularly suitable for sequence labelling).", "labels": [], "entities": []}, {"text": "We use the implementation provided by CRFsuite 7 (Okazaki, 2007) for both training and classification tasks.", "labels": [], "entities": [{"text": "CRFsuite 7 (Okazaki, 2007)", "start_pos": 38, "end_pos": 64, "type": "DATASET", "confidence": 0.9179364102227348}, {"text": "classification tasks", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.8739816248416901}]}, {"text": "The algorithm parameters are tuned on the development set.", "labels": [], "entities": []}, {"text": "In order to compare our approach with a nonsequential one, we perform the classification task also using Support Vector Machines.", "labels": [], "entities": []}, {"text": "We use YAMCHA 8 , a tool developed for chunking tasks, in which SVMs are easily combined with different context window sizes and dynamic features ().", "labels": [], "entities": []}, {"text": "Since this work is only a preliminary step towards the automatic identification and extraction of biographical information from Wikipedia, we first experiment with the simplest approach.", "labels": [], "entities": [{"text": "automatic identification and extraction of biographical information from Wikipedia", "start_pos": 55, "end_pos": 137, "type": "TASK", "confidence": 0.7987943291664124}]}, {"text": "Therefore, we consider a small set of shallow features extracted only from section titles, and we ignore the content of the sections.", "labels": [], "entities": []}, {"text": "Our six features are: the whole title, the tokens (lowercased), the bigrams, the first token of the section title, the first bigram, the position of the section with respect to the other sections in the same page (first, last, inside).", "labels": [], "entities": []}, {"text": "We also use a sliding window of size 1 (both with CRF and SVM), so that the features extracted from the previous and the next sections are also considered to classify the current one.", "labels": [], "entities": []}, {"text": "We experimented with window sizes > 1 on the development set, but they led to worse results.", "labels": [], "entities": []}, {"text": "Other features we implemented include the last word of the section, and a binary feature indicating whether the section title contains a year which is included between the date of birth and date of death of the person of interest.", "labels": [], "entities": []}, {"text": "However, both pieces of information led to a performance drop on the development set, so we did not include them in the final feature set.", "labels": [], "entities": []}, {"text": "We evaluate our system based on two different metrics, accounting for both exact and partial matches.", "labels": [], "entities": []}, {"text": "\u2022 In the Exact setting, a true positive is scored when all and only those sections with biographical information in a Wikipedia page are extracted.", "labels": [], "entities": [{"text": "Exact", "start_pos": 9, "end_pos": 14, "type": "TASK", "confidence": 0.7689788937568665}]}, {"text": "This measure is useful to understand how often it is possible to extract the complete and exact biographical text concerning a person.", "labels": [], "entities": []}, {"text": "\u2022 The Intersection measure, instead, assigns a score between 0 and 1 for every predicted sequence of sections based on how much it overlaps with the gold standard sequence).", "labels": [], "entities": [{"text": "Intersection measure", "start_pos": 6, "end_pos": 26, "type": "METRIC", "confidence": 0.9149786531925201}]}, {"text": "Evaluation results are reported in.", "labels": [], "entities": []}, {"text": "The CRF-based approach outperforms the baseline in both configurations, with the highest improvement in the exact setting (+0.111 F1).", "labels": [], "entities": [{"text": "CRF-based", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.8318127393722534}, {"text": "F1", "start_pos": 130, "end_pos": 132, "type": "METRIC", "confidence": 0.9740084409713745}]}, {"text": "Compared with the classification performance obtained with SVMs, CRFs yield better results only in the exact setting, while the intersection-based performance does not show substantial differences.", "labels": [], "entities": []}, {"text": "In general, CRFs achieves a better precision but a lower recall than SVMs.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9991928935050964}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9993534684181213}]}, {"text": "If we look at the average length (in sections) of the false positive sequences, it is 3.72 for SVMs and 2.71 for CRFs.", "labels": [], "entities": []}, {"text": "This difference confirms the behaviour of the SVM-based approach, which tends to overestimate the amount of biographical sections that should be tagged in sequence.", "labels": [], "entities": []}, {"text": "The results in show also that a simple baseline relying on the four most frequent tokens in section titles achieves surprisingly good results, especially with the intersection-based metrics.", "labels": [], "entities": []}, {"text": "This means that this basic approach tends to recognize correctly at least some of the sections describing a person's biography, because they present some recurrent patterns in their titles.", "labels": [], "entities": []}, {"text": "In general, we observe that section titles alone are good indicators of their content, also without the need of more complex features.", "labels": [], "entities": []}, {"text": "Although Wikipedia editors are free to name the sections and decide how to arrange them, there are some patterns that can be easily recognized automatically, especially by means of CRF.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification results using the Exact and  Intersection settings", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9833074808120728}]}]}