{"title": [{"text": "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation", "labels": [], "entities": [{"text": "Open Vocabulary Word Representation", "start_pos": 61, "end_pos": 96, "type": "TASK", "confidence": 0.5779261663556099}]}], "abstractContent": [{"text": "We introduce a model for constructing vector representations of words by composing characters using bidirectional LSTMs.", "labels": [], "entities": []}, {"text": "Relative to traditional word representation models that have independent vectors for each word type, our model requires only a single vector per character type and a fixed set of parameters for the compositional model.", "labels": [], "entities": []}, {"text": "Despite the compactness of this model and, more importantly, the arbitrary nature of the form-function relationship in language , our \"composed\" word representations yield state-of-the-art results in language modeling and part-of-speech tagging.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 200, "end_pos": 217, "type": "TASK", "confidence": 0.7092670947313309}, {"text": "part-of-speech tagging", "start_pos": 222, "end_pos": 244, "type": "TASK", "confidence": 0.7992682158946991}]}, {"text": "Benefits over traditional baselines are particularly pronounced in morphologically rich languages (e.g., Turkish).", "labels": [], "entities": []}], "introductionContent": [{"text": "Good representations of words are important for good generalization in natural language processing applications.", "labels": [], "entities": []}, {"text": "Of central importance are vector space models that capture functional (i.e., semantic and syntactic) similarity in terms of geometric locality.", "labels": [], "entities": []}, {"text": "However, when word vectors are learned-a practice that is becoming increasingly common-most models assume that each word type has its own vector representation that can vary independently of other model components.", "labels": [], "entities": []}, {"text": "This paper argues that this independence assumption is inherently problematic, in particular in morphologically rich languages (e.g., Turkish).", "labels": [], "entities": []}, {"text": "In such languages, a more reasonable assumption would be that orthographic (formal) similarity is evidence for functional similarity.", "labels": [], "entities": []}, {"text": "However, it is manifestly clear that similarity inform is neither a necessary nor sufficient condition for similarity in function: small orthographic differences may correspond to large semantic or syntactic differences, and large orthographic differences may obscure nearly perfect functional correspondence (rich vs. affluent).", "labels": [], "entities": []}, {"text": "Thus, any orthographically aware model must be able to capture non-compositional effects in addition to more regular effects due to, e.g., morphological processes.", "labels": [], "entities": []}, {"text": "To model the complex formfunction relationship, we turn to long short-term memories (LSTMs), which are designed to be able to capture complex non-linear and non-local dynamics in sequences (Hochreiter and).", "labels": [], "entities": []}, {"text": "We use bidirectional LSTMs to \"read\" the character sequences that constitute each word and combine them into a vector representation of the word.", "labels": [], "entities": []}, {"text": "This model assumes that each character type is associated with a vector, and the LSTM parameters encode both idiosyncratic lexical and regular morphological knowledge.", "labels": [], "entities": []}, {"text": "To evaluate our model, we use a vectorbased model for part-of-speech (POS) tagging and for language modeling, and we report experiments on these tasks in several languages comparing to baselines that use more traditional, orthographically-unaware parameterizations.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.6741410493850708}, {"text": "language modeling", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7179208099842072}]}, {"text": "These experiments show: (i) our characterbased model is able to generate similar representations for words that are semantically and syntactically similar, even for words are orthographically distant (e.g., October and January); our model achieves improvements over word lookup tables using only a fraction of the number of parameters in two tasks; (iii) our model obtains state-of-theart performance on POS tagging (including establishing anew best performance in English); and (iv) performance improvements are especially dramatic in morphologically rich languages.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 404, "end_pos": 415, "type": "TASK", "confidence": 0.8102864623069763}]}, {"text": "The paper is organized as follows: Section 2 presents our character-based model to generate word embeddings.", "labels": [], "entities": []}, {"text": "Experiments on Language Modeling and POS tagging are described in Sections 4 and 5.", "labels": [], "entities": [{"text": "Language Modeling", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7867141664028168}, {"text": "POS tagging", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.8476009964942932}]}, {"text": "We present related work in Section 6; and we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our proposed model is similar to models used to compute composed representations of sentences from words (.", "labels": [], "entities": []}, {"text": "However, the relationship between the meanings of individual words and the composite meaning of a phrase or sentence is arguably more regular than the relationship of representations of characters and the meaning of a word.", "labels": [], "entities": []}, {"text": "Is our model capable of learning such an irregular relationship?", "labels": [], "entities": []}, {"text": "We now explore this question empirically.", "labels": [], "entities": []}, {"text": "Language modeling is a task with many applications in NLP.", "labels": [], "entities": [{"text": "Language modeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7635610103607178}]}, {"text": "An effective LM requires syntactic aspects of language to be modeled, such as word orderings (e.g., \"John is smart\" vs. \"John smart is\"), but also semantic aspects (e.g., \"John ate fish\" vs. \"fish ate John\").", "labels": [], "entities": [{"text": "LM", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9583280682563782}]}, {"text": "Thus, if our C2W model only captures regular aspects of words, such as, prefixes and suffixes, the model will yield worse results compared to word lookup tables.", "labels": [], "entities": []}, {"text": "Datasets For English, we conduct experiments on the Wall Street Journal of the Penn Treebank dataset (, using the standard splits (sections 1-18 for train, 19-21 for tuning and 22-24 for testing).", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.9670844674110413}, {"text": "Penn Treebank dataset", "start_pos": 79, "end_pos": 100, "type": "DATASET", "confidence": 0.9816476305325826}]}, {"text": "We also perform tests on 4 other languages, which we obtained from the CoNLL shared tasks.", "labels": [], "entities": [{"text": "CoNLL shared tasks", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.8582800428072611}]}, {"text": "While the PTB dataset provides standard train, tuning and test splits, there are no tuning sets in the datasets in other languages, so we withdraw the last 100 sentences from the training dataset and use them for tuning.", "labels": [], "entities": [{"text": "PTB dataset", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.9895656406879425}]}, {"text": "Setup The POS model requires two sets of hyperparameters.", "labels": [], "entities": []}, {"text": "Firstly, words must be converted into continuous representations and the same hyperparametrization as in language modeling (Section 4) is used.", "labels": [], "entities": []}, {"text": "Additionally, we also compare to the convolutional model of, which also requires the dimensionality for characters and the word representation size, which are set to 50 and 150, respectively.", "labels": [], "entities": []}, {"text": "Secondly, words representations are combined to en-code context.", "labels": [], "entities": []}, {"text": "Our POS tagger has three hyperparameters d f W S , db W Sand d W S , which correspond to the sizes of LSTM states, and are all set to 50.", "labels": [], "entities": []}, {"text": "As for the learning algorithm, use the same setup (learning rate, momentum and mini-batch sizes) as used in language modeling.", "labels": [], "entities": []}, {"text": "Once again, we replace OOV words with an unknown token, in the setup that uses word lookup tables, and the same with OOV characters in the C2W model.", "labels": [], "entities": []}, {"text": "In setups using pre-trained word embeddings, we consider a word an OOV if it was not seen in the labelled training data as well as in the unlabeled data used for pre-training.", "labels": [], "entities": [{"text": "OOV", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9363803267478943}]}, {"text": "Compositional Model Comparison A comparison of different recurrent neural networks for the C2W model is presented in.", "labels": [], "entities": []}, {"text": "We used our proposed tagger tagger in all experiments and results are reported for the English Penn Treebank.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 87, "end_pos": 108, "type": "DATASET", "confidence": 0.916084369023641}]}, {"text": "Results on label accuracy test set is shown in the column \"acc\".", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9541704654693604}, {"text": "acc", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9905989766120911}]}, {"text": "The number of parameters in the word composition model is shown in the column \"parameters\".", "labels": [], "entities": []}, {"text": "Finally, the number of words processed attest time per second are shown in column \"words/sec\".", "labels": [], "entities": []}, {"text": "We observe that approaches using RNN yield worse results than their LSTM counterparts with a difference of approximately 2%.", "labels": [], "entities": []}, {"text": "This suggests that while regular RNNs can learn shorter character sequence dependencies, they are not ideal to learn longer dependencies.", "labels": [], "entities": []}, {"text": "LSTMs, on the other hand, seem to effectively obtain relatively higher results, on par with using word lookup tables (row \"Word Lookup\"), even when using forward (row \"Forward LSTM\") and backward (row \"Backward LSTM\") LSTMs individually.", "labels": [], "entities": []}, {"text": "The best results are obtained using the bidirectional LSTM (row \"Bi-LSTM\"), which achieves an accuracy of 97.29% on the test set, surpassing the word lookup table.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9990383386611938}]}, {"text": "The convolution model) obtained slightly lower results (row \"Convolutional (S&Z)\"), we think this is because the convolutional model uses a max-pooling layer over series of window convolutions.", "labels": [], "entities": []}, {"text": "As order is only perserved within windows, longer distance dependences are unobserved.", "labels": [], "entities": []}, {"text": "There are approximately 40k lowercased word types in the training data in the PTB dataset.", "labels": [], "entities": [{"text": "PTB dataset", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.9818952083587646}]}, {"text": "Thus, a word lookup table with 50 dimensions per type contains approximately 2 million parameters.", "labels": [], "entities": []}, {"text": "In the C2W models, the number of characters types (including uppercase and lowercase) is approxi-: POS accuracy results for the English PTB using word representation models.", "labels": [], "entities": [{"text": "POS", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9943459630012512}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.8972344398498535}, {"text": "English PTB", "start_pos": 128, "end_pos": 139, "type": "DATASET", "confidence": 0.6289987862110138}]}, {"text": "Thus, the character lookup table consists of only 4k parameters, which is negligible compared to the number of parameters in the compositional model, which is once again 150k parameters.", "labels": [], "entities": []}, {"text": "One could argue that results in the Bi-LSTM model are higher than those achieved by other models as it contains more parameters, so we set the state size d CS = 50 (row \"Bi-LSTM d CS = 50\") and obtained similar results.", "labels": [], "entities": []}, {"text": "In terms of computational speed, we can observe that there is a more significant slowdown when applying the C2W models compared to language modeling.", "labels": [], "entities": []}, {"text": "This is because there is no longer a softmax over the whole word vocabulary as the main bottleneck of the network.", "labels": [], "entities": []}, {"text": "However, we can observe that while the Bi-LSTM system is 3 times slower, it is does not significantly hurt the performance of the system.", "labels": [], "entities": []}, {"text": "Results on Multiple Languages Results on 5 languages are shown in.", "labels": [], "entities": []}, {"text": "In general, we can observe that the model using word lookup tables (row \"Word\") performs consistently worse than the C2W model (row \"C2W\").", "labels": [], "entities": []}, {"text": "We also compare our results with Stanford's POS tagger, with the default set of features, found in.", "labels": [], "entities": [{"text": "Stanford's POS tagger", "start_pos": 33, "end_pos": 54, "type": "DATASET", "confidence": 0.6805149987339973}]}, {"text": "Results using these tagger are comparable or better than state-of-the-art systems.", "labels": [], "entities": []}, {"text": "We can observe that inmost cases we can slightly outperform the scores obtained using their tagger.", "labels": [], "entities": []}, {"text": "This is a promising result, considering that we use the same training data and do not handcraft any features.", "labels": [], "entities": []}, {"text": "Furthermore, we can observe that for Turkish, our results are significantly higher (>4%).", "labels": [], "entities": []}, {"text": "Comparison with Benchmarks Most state-ofthe-art POS tagging systems are obtained by either learning or handcrafting good lexical features: POS accuracies on different languages ditional raw data to learn features in an unsupervised fashion.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.7791216671466827}]}, {"text": "Generally, optimal results are obtained by performing both.", "labels": [], "entities": []}, {"text": "shows the current Benchmarks in this task for the English PTB.", "labels": [], "entities": [{"text": "Benchmarks", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.6873235702514648}, {"text": "English PTB", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9012815654277802}]}, {"text": "Accuracies on the test set is reported on column \"acc\".", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9956824779510498}, {"text": "acc", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.979730486869812}]}, {"text": "Columns \"+feat\" and \"+data\" define whether hand-crafted features are used and whether additional data was used.", "labels": [], "entities": []}, {"text": "We can see that even without feature engineering or unsupervised pretraining, our C2W model (row \"C2W\") is on par with the current state-of-the-art system (row \"structReg\").", "labels": [], "entities": []}, {"text": "However, if we add hand-crafted features, we can obtain further improvements on this dataset (row \"C2W + features\").", "labels": [], "entities": []}, {"text": "However, there are many words that do not contain morphological cues to their part-of-speech.", "labels": [], "entities": []}, {"text": "For instance, the word snake does not contain any morphological cues that determine its tag.", "labels": [], "entities": []}, {"text": "In these cases, if they are not found labelled in the training data, the model would be dependent on context to determine their tags, which could lead to errors in ambiguous contexts.", "labels": [], "entities": []}, {"text": "Unsupervised training methods such as the Skip-n-gram model can be used to pretrain the word representations on unannotated corpora.", "labels": [], "entities": []}, {"text": "If such pretraining places cat, dog and snake near each other in vector space, and the supervised POS data contains evidence that cat and dog are nouns, our model will be likely to label snake with the same tag.", "labels": [], "entities": [{"text": "POS data", "start_pos": 98, "end_pos": 106, "type": "DATASET", "confidence": 0.6969549506902695}]}, {"text": "We train embeddings using English wikipedia with the dataset used in (, and the Structured Skip-n-gram model.", "labels": [], "entities": []}, {"text": "Results using pre-trained word lookup tables and the C2W with the pre-trained word lookup tables as additional parameters are shown in rows \"word(sskip)\" and \"C2W + word(sskip)\".", "labels": [], "entities": []}, {"text": "We can observe that both systems can obtain improvements over their random initializations (rows \"word\" and (C2W)).", "labels": [], "entities": []}, {"text": "Finally, we also found that when using the C2W model in conjunction pre-trained word embeddings, that adding a non-linearity to the representations extracted from the C2W model e C w improves the results over using a simple linear trans-: POS accuracy result comparison with state-of-the-art systems for the English PTB.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 243, "end_pos": 251, "type": "METRIC", "confidence": 0.7290096879005432}, {"text": "English PTB", "start_pos": 308, "end_pos": 319, "type": "DATASET", "confidence": 0.8349325060844421}]}, {"text": "formation (row \"C2W(tanh)+word (sskip)\").", "labels": [], "entities": []}, {"text": "This setup, obtains 0.28 points over the current state-ofthe-art system(row \"SCCN\").", "labels": [], "entities": []}, {"text": "As a second illustration of the utility of our model, we turn to POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.6943929344415665}]}, {"text": "As morphology is a strong indicator for syntax in many languages, a much effort has been spent engineering features ().", "labels": [], "entities": []}, {"text": "We now show that some of these features can be learnt automatically using our model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Language Modeling Results", "labels": [], "entities": [{"text": "Language Modeling", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7855249643325806}]}, {"text": " Table 3: POS accuracy results for the English PTB  using word representation models.", "labels": [], "entities": [{"text": "POS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8999575972557068}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.8954700231552124}, {"text": "English PTB", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.631786972284317}]}, {"text": " Table 4: POS accuracies on different languages", "labels": [], "entities": []}]}