{"title": [{"text": "Sarcastic or Not: Word Embeddings to Predict the Literal or Sarcastic Meaning of Words", "labels": [], "entities": []}], "abstractContent": [{"text": "Sarcasm is generally characterized as a figure of speech that involves the substitution of a literal by a figurative meaning , which is usually the opposite of the original literal meaning.", "labels": [], "entities": []}, {"text": "We re-frame the sarcasm detection task as a type of word sense disambiguation problem, where the sense of a word is either literal or sarcastic.", "labels": [], "entities": [{"text": "sarcasm detection task", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.8750468095143636}, {"text": "word sense disambiguation", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.7309262752532959}]}, {"text": "We call this the Literal/Sarcastic Sense Disambiguation (LSSD) task.", "labels": [], "entities": [{"text": "Literal/Sarcastic Sense Disambiguation (LSSD) task", "start_pos": 17, "end_pos": 67, "type": "TASK", "confidence": 0.7490356034702725}]}, {"text": "We address two issues: 1) how to collect a set of target words that can have either literal or sarcastic meanings depending on context ; and 2) given an utterance and a target word, how to automatically detect whether the target word is used in the literal or the sarcastic sense.", "labels": [], "entities": []}, {"text": "For the latter, we investigate several distributional semantics methods and show that a Support Vector Machines (SVM) classifier with a modified kernel using word embeddings achieves a 7-10% F1 improvement over a strong lexical baseline.", "labels": [], "entities": [{"text": "F1", "start_pos": 191, "end_pos": 193, "type": "METRIC", "confidence": 0.9995424747467041}]}], "introductionContent": [{"text": "Recognizing sarcasm is important for understanding people's actual sentiments and beliefs.", "labels": [], "entities": [{"text": "Recognizing sarcasm", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8486557602882385}]}, {"text": "For example, failing to recognize the following message as being sarcastic \"I love that I have to go back to the emergency room\", will lead a sentiment and opinion analysis system to infer that the author's sentiment is positive towards the event of \"going to the emergency room\".", "labels": [], "entities": []}, {"text": "Current approaches have framed the sarcasm detection task as predicting whether a full utterance is sarcastic or not (.", "labels": [], "entities": [{"text": "sarcasm detection task", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.8771493832270304}]}, {"text": "We propose a re-framing of sarcasm detection as a type of word sense disambiguation problem: given an utterance and a target word, identify whether the sense of the target word is literal or sarcastic.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.8337317705154419}, {"text": "word sense disambiguation", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.6871129969755808}]}, {"text": "We call this the Literal/Sarcastic Sense Disambiguation (LSSD) task.", "labels": [], "entities": [{"text": "Literal/Sarcastic Sense Disambiguation (LSSD) task", "start_pos": 17, "end_pos": 67, "type": "TASK", "confidence": 0.7490356034702725}]}, {"text": "In the above utterance, the word \"love\" is used in a sarcastic, nonliteral sense (the author's intended meaning being most likely the opposite of the original literal meaning -a negative sentiment, such as \"hate\").", "labels": [], "entities": []}, {"text": "Two key challenges need to be addressed: 1) how to collect a set of target words that can have a literal or a sarcastic sense, depending on context; and 2) given an utterance containing a target word, how can we determine whether the target word is used in its literal sense (e.g., \"I love to take a nice stroll in the park every morning\"), or in a sarcastic sense (e.g., \"I love going to the dentist.\").", "labels": [], "entities": []}, {"text": "To address the first challenge, we need to identify a set of words from sarcastic utterances, which have a figurative/sarcastic sense (e.g., \"love\" in the utterance \"I love going to the dentist\").", "labels": [], "entities": []}, {"text": "We propose a crowdsourcing task where Turkers in Amazon Mechanical Turk (MTurk) platform are given sarcastic utterances (tweets labeled with #sarcasm or #sarcastic hashtags) and are asked to re-phrase those messages so that they convey the author's intended meaning (\"I love going to the dentist\" can be rephrased as \"I hate going to the dentist\" or \"I don't like going to the dentist\").", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (MTurk) platform", "start_pos": 49, "end_pos": 88, "type": "DATASET", "confidence": 0.7722912515912738}]}, {"text": "Given this parallel dataset, we use unsupervised alignment techniques to identify semantically opposite words (e.g., \"love\" \u2194 \"hate\", \"brilliant\" \u2194 \"stupid\", \"never\" \u2194 \"always\").", "labels": [], "entities": []}, {"text": "The words from these pairs that appear in the original sarcastic utterances are then considered as our collection of target words (e.g., \"love\", \"brilliant\", \"never\") that can have both a sarcastic and a literal sense depending on the context (Section 2).", "labels": [], "entities": []}, {"text": "To address the second challenge, we compare several distributional semantics methods generally used in word sense disambiguation tasks (Sec- . We show that using word embeddings in a modified SVM kernel achieves the best results (Section 4).", "labels": [], "entities": [{"text": "word sense disambiguation tasks", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.7491590306162834}]}, {"text": "To collect training and test datasets for each of the target words, we use Twitter messages that contain those words.", "labels": [], "entities": []}, {"text": "For the sarcastic sense (S), we use tweets that contain the target word and are labeled with the #sarcasm or #sar-castic hashtags.", "labels": [], "entities": []}, {"text": "For the literal sense (L), we collect tweets that contain the target word and are not labeled with the #sarcastic or #sarcasm hashtags.", "labels": [], "entities": []}, {"text": "shows examples of two targets words (\"great\" and \"proud\") and their sarcastic sense (S) and literal sense (L).", "labels": [], "entities": [{"text": "literal sense (L)", "start_pos": 92, "end_pos": 109, "type": "METRIC", "confidence": 0.7780335783958435}]}, {"text": "In addition, for the literal sense, we also consider a special case, where the tweets are labeled with either positive or negative hashtags (e.g., #happy, #sad) as proposed by.", "labels": [], "entities": []}, {"text": "We denote these sentiment tweets as L sent.", "labels": [], "entities": []}, {"text": "argue that it is harder to distinguish sarcastic from non-sarcastic messages where the nonsarcastic messages contain sentiment.", "labels": [], "entities": []}, {"text": "Our results support this argument (97% F1 measure for the best result for S vs. L, compared to 84% F1 for the best result for S vs. L sent ; Section 4).", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9810274839401245}, {"text": "F1", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.9988095760345459}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Evaluation of distributional approaches (PMI and word embedding) for LSSD experiments", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of classification approaches (SV M bl and kernel we ) for LSSD experiments", "labels": [], "entities": []}]}