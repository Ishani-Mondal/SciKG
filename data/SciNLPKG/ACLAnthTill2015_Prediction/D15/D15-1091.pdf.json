{"title": [{"text": "TSDPMM: Incorporating Prior Topic Knowledge into Dirichlet Process Mixture Models for Text Clustering", "labels": [], "entities": [{"text": "Dirichlet Process Mixture", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.6876998941103617}]}], "abstractContent": [{"text": "Dirichlet process mixture model (DPM-M) has great potential for detecting the underlying structure of data.", "labels": [], "entities": []}, {"text": "Extensive studies have applied it for text clustering in terms of topics.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8108998835086823}]}, {"text": "However, due to the unsupervised nature, the topic clusters are always less satisfactory.", "labels": [], "entities": []}, {"text": "Considering that people often have some prior knowledge about which potential topics should exist in given data, we aim to incorporate such knowledge into the DPMM to improve text clustering.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 175, "end_pos": 190, "type": "TASK", "confidence": 0.7735127806663513}]}, {"text": "We propose a novel model TSDPMM based on anew seeded P\u00f3lya urn scheme.", "labels": [], "entities": [{"text": "P\u00f3lya urn", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.843571275472641}]}, {"text": "Experimental results on document clustering across three datasets demonstrate our proposed TSDPMM significantly outperforms state-of-the-art DPMM model and can be applied in a lifelong learning framework.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6937903016805649}]}], "introductionContent": [{"text": "Dirichlet process mixture model (DPMM)) has been used in detecting the underlying structure in data.", "labels": [], "entities": []}, {"text": "For example, () applied it to lexicalsemantic verb clustering.", "labels": [], "entities": [{"text": "lexicalsemantic verb clustering", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.6727295319239298}]}, {"text": "() applied it for text clustering in terms of their topics.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.8071622550487518}]}, {"text": "While DPMM achieved some promising results, it can still sometimes produce unsatisfactory topic clusters due to its unsupervised nature.", "labels": [], "entities": []}, {"text": "On the other hand, people often have prior knowledge about what potential topics should exist in a given text corpus.", "labels": [], "entities": []}, {"text": "Take an earthquake event corpus as an example.", "labels": [], "entities": []}, {"text": "The topics, such as \"casualties and damages\", \"rescue\" and \"government reaction\", called prior topics, are expected to occur in the corpus according to our common knowledge (e.g., the topics automatically learned from previous events using topic modeling) or external resources (e.g., table of contents at Wikipedia event pages 1 ).", "labels": [], "entities": [{"text": "\"rescue\"", "start_pos": 46, "end_pos": 54, "type": "TASK", "confidence": 0.8145588040351868}]}, {"text": "Similarly, in academic fields, \"call for papers (CFP)\" of conferences 2 lists main topics that conference organizers would like to focus on.", "labels": [], "entities": []}, {"text": "Clearly, these prior topics can be represented as sets of words, which are available in many real-world applications.", "labels": [], "entities": []}, {"text": "They can serve as weakly supervised information to enhance the unsupervised DPMM for text clustering.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.8026827275753021}]}, {"text": "Standard DPMM) lacks a mechanism for incorporating prior knowledge.", "labels": [], "entities": []}, {"text": "Some existing work) added knowledge of observed instance-level constraints (must-links and cannot-links between documents) to DPMM.", "labels": [], "entities": []}, {"text": "( proposed recurrent Chinese Restaurant Process to incorporate previous documents with known topic clusters.", "labels": [], "entities": []}, {"text": "We focus on incorporating topic-level knowledge, which is more challenging, as seed/prior topics could be latent rather than observable.", "labels": [], "entities": []}, {"text": "Particularly, we construct our novel TSDPM-M (Topic Seeded DPMM) based on a principled seeded P\u00f3lya urn (sPU) scheme.", "labels": [], "entities": [{"text": "TSDPM-M", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.8207051753997803}]}, {"text": "Our model inherits the nonparametric property of DPMM and has additional technical merits.", "labels": [], "entities": [{"text": "DPMM", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.8822038173675537}]}, {"text": "Importantly, our model is encouraged but not forced to find evidences of seed topics.", "labels": [], "entities": []}, {"text": "Therefore, it has freedom to discover new topics beyond prior topics, as well as to detect which prior topics are not covered by current data.", "labels": [], "entities": []}, {"text": "It is thus convenient to observe topic variations between prior topics and newly mined topics.", "labels": [], "entities": []}, {"text": "Experimental results on document clustering across three corpora demonstrate that our model effectively incorporates prior topics, and significantly outperforms state-of-the-art DPMM model.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.630625918507576}]}, {"text": "Particularly, our TSDPMM can be applied in a lifelong learning framework which enables the prior topic knowledge to evolve as more and more data are observed.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our proposed TSDPMM model for document clustering on 3 datasets where each cluster corresponds to a topic.", "labels": [], "entities": []}, {"text": "We implement both DPMM and TSDPMM models -their source codes are available at https://github.com/ newsminer/DPMM_and_TSDPMM.", "labels": [], "entities": []}, {"text": "We collect machine learning conference NIPS datasets composed of paper titles and abstracts from 2012 to 2014 -each year includes 342, 360 and 411 documents respectively.", "labels": [], "entities": [{"text": "NIPS datasets", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.7497761249542236}]}, {"text": "They are named as NIPS-12, NIPS-13 and NIPS-14.", "labels": [], "entities": [{"text": "NIPS-12", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.8944908976554871}, {"text": "NIPS-13", "start_pos": 27, "end_pos": 34, "type": "DATASET", "confidence": 0.8687960505485535}, {"text": "NIPS-14", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9416863322257996}]}, {"text": "We also employ the standard benchmark news datasets, including 20 Newsgroups 3 and Reuters-21578.", "labels": [], "entities": [{"text": "20 Newsgroups 3", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.8051308194796244}, {"text": "Reuters-21578", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.8846755623817444}]}, {"text": "As news is often timely reported, we choose three continuous days with the largest number of documents in 20 Newsgroups (i.e. 11, 12 and 13 May) and Reuters-21578 (i.e. 3, 4 and 5 March) for our experiments.", "labels": [], "entities": [{"text": "Reuters-21578", "start_pos": 149, "end_pos": 162, "type": "DATASET", "confidence": 0.9719262719154358}]}, {"text": "These datasets are denoted and Reu-1, Reu-2,, respectively.", "labels": [], "entities": []}, {"text": "For all the datasets, we conduct the following preprocessing: (1) Convert letters into lowercase; (2) Remove non-Latin characters and stop words; (3) Remove words with document frequency < 2.", "labels": [], "entities": []}, {"text": "We take the standard DPMM as our baseline method and compare it with our proposed TSDP-MM model using different prior knowledge obtained with different manners.", "labels": [], "entities": []}, {"text": "For NIPS datasets, we use two kinds of prior knowledge: one is the topics learned by DPMM from previous year's dataset; the other one is from an external resource \"CFP\" 4 (10 topics, same for each year).", "labels": [], "entities": [{"text": "NIPS datasets", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.8274376392364502}, {"text": "DPMM from previous year's dataset", "start_pos": 85, "end_pos": 118, "type": "DATASET", "confidence": 0.5961145708958308}]}, {"text": "We name them as TSDPMM-P and TSDPMM-E respectively.", "labels": [], "entities": [{"text": "TSDPMM-P", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.4818078577518463}]}, {"text": "As the topic descriptions in \"CFP\" are sparse, we repeat each topic description by ten times and then represent a topic with the words with word frequencies in its description text.", "labels": [], "entities": []}, {"text": "For both 20 Newsgroups and Reuters datasets, we use prior knowledge learned by DPMM from the previous day's dataset.", "labels": [], "entities": [{"text": "Reuters datasets", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.8925403654575348}, {"text": "DPMM from the previous day's dataset", "start_pos": 79, "end_pos": 115, "type": "DATASET", "confidence": 0.6167015263012477}]}, {"text": "Furthermore, to test if we can improve the results continuously by applying TSDPMM, every time when we model anew dataset, we incorporate prior topics learned by TSDPMM from previous day's dataset, similar to lifelong learning.", "labels": [], "entities": []}, {"text": "We call this model as TSDPMM-L.", "labels": [], "entities": [{"text": "TSDPMM-L", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.5437828302383423}]}, {"text": "Following a previous work (, we set the hyper-parameters \u03b1=1, \u20d7 \u03b1 (0) ={1.0}, \u20d7 \u03b2 ={1.0}.", "labels": [], "entities": []}, {"text": "We run Gibbs sampler for 100 iterations and stop the iteration once the log-likelihood of the training data converges.", "labels": [], "entities": []}, {"text": "The widely used NMI (normalized mutual information) measure, has been employed to evaluate document clustering results.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.6455292999744415}]}, {"text": "The higher a value of NMI, the better a clustering result is.", "labels": [], "entities": []}, {"text": "However, NMI needs true class labels for documents, and can only be applied to our benchmark news datasets.", "labels": [], "entities": [{"text": "NMI", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.7906560301780701}]}, {"text": "For NIPS datasets without true labels, we use the measure of perplexity, as defined in (, to test per-word likelihood of the datasets.", "labels": [], "entities": [{"text": "NIPS datasets", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7310758084058762}]}, {"text": "The lower the perplexity, the better a model fits the data.", "labels": [], "entities": []}, {"text": "shows the average perplexity values of five runs of 3 models on NIPS datasets.", "labels": [], "entities": [{"text": "NIPS datasets", "start_pos": 64, "end_pos": 77, "type": "DATASET", "confidence": 0.9703430235385895}]}, {"text": "It shows that both TSDPMM-P and TSDPMM-E, leveraging prior topics from previous learning and \"CFP\" significantly outperform DPMM.", "labels": [], "entities": []}, {"text": "In addition, TSDPMM-E achieves lower performance than TSDPMM-P due to its lower quality of prior topics directly obtained from \"CFP\", compared to higher quality topics from past learning.", "labels": [], "entities": []}, {"text": "We may improve \"CFP\" knowledge by extending it with related texts from search engines or Wikipedia using keywords in \"CFP\" in future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average perplexity of different models on  NIPS.", "labels": [], "entities": [{"text": "NIPS", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.9047987461090088}]}, {"text": " Table 2: Average NMI of different models on news datasets.", "labels": [], "entities": [{"text": "NMI", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.794957160949707}]}]}