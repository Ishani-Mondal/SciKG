{"title": [{"text": "Reversibility reconsidered: finite-state factors for efficient probabilistic sampling in parsing and generation", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.7299143373966217}]}], "abstractContent": [{"text": "We restate the classical logical notion of generation/parsing reversibility in terms of feasible probabilistic sampling, and argue for an implementation based on finite-state factors.", "labels": [], "entities": [{"text": "generation/parsing reversibility", "start_pos": 43, "end_pos": 75, "type": "TASK", "confidence": 0.7475426942110062}]}, {"text": "We propose a modular decomposition that reconciles generation accuracy with parsing robustness and allows the introduction of dynamic contextual factors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9212638139724731}, {"text": "parsing", "start_pos": 76, "end_pos": 83, "type": "TASK", "confidence": 0.9704434275627136}]}], "introductionContent": [{"text": "The objective of Natural Language Understanding (NLU) is to map linguistic utterances to semantic representations, that of Natural Language Generation (NLG) to map semantic representations to linguistic utterances.", "labels": [], "entities": [{"text": "Natural Language Understanding (NLU)", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.7077179650465647}, {"text": "Natural Language Generation (NLG", "start_pos": 123, "end_pos": 155, "type": "TASK", "confidence": 0.7823128461837768}]}, {"text": "In most of NLP practice, these two objectives are handled by different processes, and computational linguists rarely operate at the intersection of the two subdomains.", "labels": [], "entities": []}, {"text": "For a few years around the early nineties, based both on cognitive, linguistic, and engineering considerations, there was a surge of interest in so called reversible grammar approaches to NLP, where one and the same grammatical specification could serve both for parsing utterance x into logical form z, but also for generating x from z (.", "labels": [], "entities": [{"text": "parsing utterance x into logical form z", "start_pos": 263, "end_pos": 302, "type": "TASK", "confidence": 0.786109983921051}]}, {"text": "We start by a brief review of this historical nonprobabilistic notion of reversibility and point out certain of its weaknesses, in particular regarding robustness; we then give in section 3 anew probabilistic definition of reversibility; then, in section 4 we argue fora reversibility model based on modular weighted finite-state transducers.", "labels": [], "entities": []}, {"text": "We end with a discussion of recent related work.", "labels": [], "entities": []}, {"text": "* Work done while at XRCE.", "labels": [], "entities": [{"text": "XRCE", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.8606038093566895}]}], "datasetContent": [], "tableCaptions": []}