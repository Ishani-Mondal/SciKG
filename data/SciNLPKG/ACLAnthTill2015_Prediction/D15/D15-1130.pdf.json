{"title": [], "abstractContent": [{"text": "Language use is known to be influenced by personality traits as well as by socio-demographic characteristics such as age or mother tongue.", "labels": [], "entities": []}, {"text": "As a result, it is possible to automatically identify these traits of the author from her texts.", "labels": [], "entities": []}, {"text": "It has recently been shown that knowledge of such dimensions can improve performance in NLP tasks such as topic and sentiment modeling.", "labels": [], "entities": [{"text": "topic and sentiment modeling", "start_pos": 106, "end_pos": 134, "type": "TASK", "confidence": 0.6866098865866661}]}, {"text": "We posit that machine translation is another application that should be personalized.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.8057441413402557}]}, {"text": "In order to motivate this, we explore whether translation preserves demographic and psychometric traits.", "labels": [], "entities": []}, {"text": "We show that, largely, both translation of the source training data into the target language, and the target test data into the source language has a detrimental effect on the accuracy of predicting author traits.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9977051615715027}, {"text": "predicting author", "start_pos": 188, "end_pos": 205, "type": "TASK", "confidence": 0.8652039468288422}]}, {"text": "We argue that this supports the need for personal and personality-aware machine translation models.", "labels": [], "entities": [{"text": "personality-aware machine translation", "start_pos": 54, "end_pos": 91, "type": "TASK", "confidence": 0.6560010413328806}]}], "introductionContent": [{"text": "Computational personality recognition is garnering increasing interest with a number of recent workshops exploring the topic ().", "labels": [], "entities": [{"text": "Computational personality recognition", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8137081861495972}]}, {"text": "The addition of personality as target traits in the PAN Author Profiling challenge in 2015 () is further evidence.", "labels": [], "entities": [{"text": "PAN Author Profiling challenge in 2015", "start_pos": 52, "end_pos": 90, "type": "DATASET", "confidence": 0.7203263541062673}]}, {"text": "Such user modeling -when performed on text -is built on a long-standing understanding that language use is influenced by sociodemographic characteristics such as age, gender, education level or mother tongue and personality traits like agreeableness or openness.", "labels": [], "entities": []}, {"text": "In this work we explore multilingual user modelling.", "labels": [], "entities": []}, {"text": "The motivation is not only to enable modeling in multiple languages, but also to enable modeling multilingual users who may express different sides of their personality in each language.", "labels": [], "entities": []}, {"text": "One way to address multilinguality in this context is to create models separately in each language, and then fuse the resulting models.", "labels": [], "entities": []}, {"text": "However, labelled data of this nature, particularly in nonEnglish languages, is often not available.", "labels": [], "entities": []}, {"text": "Personality labelling is time consuming, requiring the completion of psychometric questionnaires which maybe considered invasive by many.", "labels": [], "entities": [{"text": "Personality labelling", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8114030063152313}]}, {"text": "An alternative is the use of machine translation (MT) to bootstrap corpora in resource poor languages, and to translate the user's content into a single language before modeling.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.8459014534950257}]}, {"text": "Translated text, either manually or automatically generated, is known to have different characteristics than native text.", "labels": [], "entities": []}, {"text": "Yet, MT was shown to be of use within traditional NLP tasks such as sentiment analysis.", "labels": [], "entities": [{"text": "MT", "start_pos": 5, "end_pos": 7, "type": "TASK", "confidence": 0.9592776894569397}, {"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9636295735836029}]}, {"text": "We explore the utility of MT for classification of demographic and personality traits.", "labels": [], "entities": [{"text": "MT", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9878785014152527}]}, {"text": "MT models, even domain-specific, are user-generic.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9677735567092896}]}, {"text": "Thus, the linguistic signals of user traits which are conveyed in the original language may not be preserved over translation.", "labels": [], "entities": []}, {"text": "In other words, the attributes on which we wish to rely for modelling maybe lost.", "labels": [], "entities": []}, {"text": "This concern is perhaps most observable with gender, a trait of the speaker that is encoded in the morphology of many languages, though not in English.", "labels": [], "entities": []}, {"text": "Gendered translation was the topic of research for many years.", "labels": [], "entities": [{"text": "Gendered translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7896953225135803}]}, {"text": "However, the gender of the author is largely ignored by MT systems, and specifically statistical ones, that would often arbitrarily (or rather statistically-based) translate into one gender form or another.", "labels": [], "entities": [{"text": "MT", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9816557765007019}]}, {"text": "Other demographic and personality traits have not yet been investigated.", "labels": [], "entities": []}, {"text": "One way to address this concern is personalized translation, or author-aware translation.", "labels": [], "entities": [{"text": "personalized translation", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.7667412459850311}, {"text": "author-aware translation", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.6935975104570389}]}, {"text": "The first step toward this goal would be to consider the author traits in the model.", "labels": [], "entities": []}, {"text": "Such an approach has already shown to be useful for several NLP tasks.", "labels": [], "entities": []}, {"text": "However, before embarking on this challenging task, we explore if the above concerns are founded by addressing the research question: does MT has an impact on the classification of demographic and personality traits?", "labels": [], "entities": [{"text": "MT", "start_pos": 139, "end_pos": 141, "type": "TASK", "confidence": 0.9924371838569641}, {"text": "classification of demographic and personality traits", "start_pos": 163, "end_pos": 215, "type": "TASK", "confidence": 0.844620962937673}]}], "datasetContent": [{"text": "To explore our hypothesis, we require data in multiple languages which is labelled with socio-demographic or personality traits.", "labels": [], "entities": []}, {"text": "Using English as the base language (as typically the most resource-rich language in NLP studies), we perform three comparative experiments on several non-English (\"foreign\") corpora.", "labels": [], "entities": []}, {"text": "In these experiments we train a classification model: 1.", "labels": [], "entities": []}, {"text": "Using only foreign language data.", "labels": [], "entities": []}, {"text": "This provides a baseline, as no translated data is used.", "labels": [], "entities": []}, {"text": "2. Augmenting the foreign training data with English data translated into the foreign language.", "labels": [], "entities": [{"text": "Augmenting", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.971974790096283}]}, {"text": "Here, the goal is to assess a scenario where translations from a resource-rich language supplement scarce training data in the foreign language, under the assumption that more training data can be beneficial.", "labels": [], "entities": []}, {"text": "It has been shown that standard approaches to gender classification on English texts can be sub-optimal for non-English language data (.", "labels": [], "entities": [{"text": "gender classification", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.760682076215744}]}, {"text": "However, state-of-the-art classification results are not our focus; rather, our intention is to understand the impact of translation on classification of socio-demographic and personality traits.", "labels": [], "entities": []}, {"text": "Therefore, we fix our models with a set of parameters selected via cross-validation (CV) on the native language: the occurrence threshold is set to 5 and the SVD dimensionality to 500.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of authors and tweets across the four  languages of the PAN dataset.", "labels": [], "entities": [{"text": "PAN dataset", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.925114631652832}]}, {"text": " Table 2: Cross-validation results on PAN15 for the settings as per Section 5.1. Gender is measured in accuracy; the  remaining traits as mean squared error. Bold highlights the best result. English results are included for comparison.", "labels": [], "entities": [{"text": "PAN15", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.8224354386329651}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9993133544921875}]}, {"text": " Table 3: Gender CV accuracy (%) on the English TED  dataset, when translated manually and automatically.", "labels": [], "entities": [{"text": "Gender CV", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8524632155895233}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.5868473052978516}, {"text": "English TED  dataset", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.8810576995213827}]}, {"text": " Table 4: Results when classifying gender on native,  manually translated and machine translated English  texts, from 61 TEDx and TED talks.", "labels": [], "entities": []}, {"text": " Table 4.  Again, signal is lost in automatic translation in com- parison to manual translation. Interestingly, the man- ual translation scores higher than the native English, as  if the translators are adding more gender indications to  the text. Further analysis is required to clarify whether  this is indeed a consequence of the manual translation  or an artifact of the setting.  Author-aware translation may be viewed as a  human-centric domain adaptation task: we can con- sider the two genders as two different domains, and  apply domain adaptation techniques to train a better- suited model for each one. To assess this approach, we  conducted a set of experiments with standard domain  adaptation techniques for en-fr, including: separating  the translation models and the language models by gen- der in various configurations, using only the target gen- der's training data from WIT3 (on top of the Europarl  data), and separating tuning sets by gender. We split", "labels": [], "entities": [{"text": "Author-aware translation", "start_pos": 385, "end_pos": 409, "type": "TASK", "confidence": 0.6786253303289413}, {"text": "WIT3", "start_pos": 890, "end_pos": 894, "type": "DATASET", "confidence": 0.9322906732559204}, {"text": "Europarl  data", "start_pos": 910, "end_pos": 924, "type": "DATASET", "confidence": 0.9926055073738098}]}]}