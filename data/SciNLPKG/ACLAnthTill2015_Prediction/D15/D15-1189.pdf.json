{"title": [{"text": "Event Detection and Factuality Assessment with Non-Expert Supervision", "labels": [], "entities": [{"text": "Event Detection and Factuality Assessment", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6646692514419555}]}], "abstractContent": [{"text": "Events are communicated in natural language with varying degrees of certainty.", "labels": [], "entities": []}, {"text": "For example, if you are \"hoping fora raise,\" it maybe somewhat less likely than if you are \"expecting\" one.", "labels": [], "entities": []}, {"text": "To study these distinctions, we present scalable, high-quality annotation schemes for event detection and fine-grained factuality assessment.", "labels": [], "entities": [{"text": "event detection", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.842641681432724}, {"text": "factuality assessment", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.6664877980947495}]}, {"text": "We find that non-experts, with very little training, can reliably provide judgments about what events are mentioned and the extent to which the author thinks they actually happened.", "labels": [], "entities": []}, {"text": "We also show how such data enables the development of regression models for fine-grained scalar factuality predictions that outper-form strong baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interpretation of events-determining what the author claims did or did not happen-is important for many NLP applications, such as news article summarization or biomedical information extraction.", "labels": [], "entities": [{"text": "Interpretation of events-determining what the author claims", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8538650955472674}, {"text": "news article summarization", "start_pos": 130, "end_pos": 156, "type": "TASK", "confidence": 0.5591525534788767}, {"text": "biomedical information extraction", "start_pos": 160, "end_pos": 193, "type": "TASK", "confidence": 0.651224672794342}]}, {"text": "However, detecting events and assessing their factuality is challenging.", "labels": [], "entities": []}, {"text": "For example, while most non-copular verbs are events, words in general vary with use (e.g. \"trade route\" vs \"trade with Iraq\").", "labels": [], "entities": []}, {"text": "Events also have widely varying, context-dependent factuality cues, such as event interactions (e.g. \"prevent easy access) and cue words (e.g. \"ordered to\" vs. \"expected to\").", "labels": [], "entities": []}, {"text": "As shown in, these are common challenges that a model of event factuality must address.", "labels": [], "entities": []}, {"text": "In this paper, we present new data and models for these tasks, demonstrating that non-experts can provide high-quality annotations which enable fine-grained, scalar judgments of factuality.", "labels": [], "entities": []}, {"text": "Unlike previous work, we do not use a detailed * Work done at the University of Washington.", "labels": [], "entities": []}, {"text": "(1) U.S. embassies and military installations around the world were ordered to set (2.6) up barriers and tighten security to prevent easy access by unauthorized people.", "labels": [], "entities": []}, {"text": "(2) Intel's most powerful computer chip has flaws that could delay (0.8) several computer makers' marketing efforts , but the \"bugs\" aren't expected to hurt (-2.0) Intel.", "labels": [], "entities": []}, {"text": "(3) President Bush on Tuesday said the United States may extend its naval quarantine (2.6) to Jordan's Red Sea port of Aqaba to shutoff Iraq's last unhindered trade route.", "labels": [], "entities": []}, {"text": "(4) He also said (3.0) of trade (-0.8) with Iraq: \"There are no shipments at the moment.\" specification of exactly what events and factuality classes should be.", "labels": [], "entities": []}, {"text": "Instead, we simply ask non-experts to find words describing things that the author claims could have happened, and rate each possibility on a scale of -3 (certainly did not happen) to 3 (certainly did).", "labels": [], "entities": []}, {"text": "shows that non-expert workers-when their judgments are aggregated-consistently find a wide range of events and recognize the subtle differences in implied factuality.", "labels": [], "entities": []}, {"text": "For example, the event set gets a score of 2.6, indicating that it likely but not certainly occurred, since it was ordered, whereas the ordered event, gets a score of 3.0.", "labels": [], "entities": []}, {"text": "We gather data for event detection and factuality, reusing sentences from the TempEval-3 corpus (.", "labels": [], "entities": [{"text": "event detection", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.748520165681839}, {"text": "TempEval-3 corpus", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.9189673662185669}]}, {"text": "Our approach produces high-quality labels with modest costs.", "labels": [], "entities": []}, {"text": "We also introduce simple but highly effective models for both tasks that outperform strong baselines.", "labels": [], "entities": []}, {"text": "In particular, our factuality regression model uses a learning objective that combines the advantages of LASSO and support vector regression, enabling it to effectively consider sparse lexical cues.", "labels": [], "entities": [{"text": "factuality regression", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.8263816833496094}, {"text": "LASSO", "start_pos": 105, "end_pos": 110, "type": "METRIC", "confidence": 0.6877567768096924}]}, {"text": "By providing scalar factuality judgments for events, our models enable more fine-grained reasoning than previously considered.", "labels": [], "entities": []}, {"text": "The corpus and learned models are available online.", "labels": [], "entities": []}], "datasetContent": [{"text": "Baselines For detection, we include a baseline reimplementation of the NAVYTIME) classification detector, one of the top performers in the TempEval-3 event detection task.", "labels": [], "entities": [{"text": "detection", "start_pos": 14, "end_pos": 23, "type": "TASK", "confidence": 0.9639166593551636}, {"text": "NAVYTIME) classification detector", "start_pos": 71, "end_pos": 104, "type": "DATASET", "confidence": 0.6173196136951447}, {"text": "TempEval-3 event detection task", "start_pos": 139, "end_pos": 170, "type": "TASK", "confidence": 0.8126648366451263}]}, {"text": "For factuality, we include three baselines: (1) A one-vs.-rest multi-class classifier (DISCRETE) using our features (Section 4) and labels that are discretized by rounding to the nearest integer, (2) a regression model (SVR) trained with the standard SVR objective using our features, and (3) a regression model (PRABHAKARAN) trained with the standard SVR objective using features from.", "labels": [], "entities": []}, {"text": "These features are highly informative, but their lexical features are restricted to a small set of manually defined words.", "labels": [], "entities": []}], "tableCaptions": []}