{"title": [], "abstractContent": [{"text": "For fine-grained sentiment analysis, we need to go beyond zero-one polarity and find away to compare adjectives that share a common semantic property.", "labels": [], "entities": [{"text": "fine-grained sentiment analysis", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.681179145971934}]}, {"text": "In this paper, we present a semi-supervised approach to assign intensity levels to adjectives , viz.", "labels": [], "entities": []}, {"text": "high, medium and low, where adjectives are compared when they belong to the same semantic category.", "labels": [], "entities": []}, {"text": "For example , in the semantic category of EXPERTISE , expert, experienced and familiar are respectively of level high, medium and low.", "labels": [], "entities": []}, {"text": "We obtain an overall accuracy of 77% for intensity assignment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9995720982551575}, {"text": "intensity assignment", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.8102061450481415}]}, {"text": "We show the significance of considering intensity information of adjectives in predicting star-rating of reviews.", "labels": [], "entities": []}, {"text": "Our intensity based prediction system results in an accuracy of 59% fora 5-star rated movie review corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9995858073234558}]}], "introductionContent": [{"text": "Sentence intensity becomes crucial when we need to compare sentences having the same polarity orientation.", "labels": [], "entities": [{"text": "Sentence intensity", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8140186965465546}]}, {"text": "In such scenarios, we can use intensity of words to judge the intensity of a sentence.", "labels": [], "entities": []}, {"text": "Words that bear the same semantic property can be used interchangeably to upgrade or downgrade the intensity of the expression.", "labels": [], "entities": []}, {"text": "For example, good and outstanding both are positive words from the QUALITY category, but the latter can be used to intensify positive expression in a sentence.", "labels": [], "entities": []}, {"text": "There are several manually or automatically created lexical resources) that assign a fixed positive (+1) or negative (\u22121) polarity to words, making no distinction among them in terms of their intensity.", "labels": [], "entities": []}, {"text": "This paper presents a semi-supervised approach to assign intensity levels to adjectives, viz.", "labels": [], "entities": []}, {"text": "high, medium and low, which share the same semantic property.", "labels": [], "entities": []}, {"text": "We have used the semantic frames of FrameNet-1.) to obtain these semantic categories.", "labels": [], "entities": [{"text": "FrameNet-1.", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.8724634051322937}]}, {"text": "Our approach is based on the idea that the most intense word has higher contextual similarity with high intensity words than with medium or low intensity words.", "labels": [], "entities": []}, {"text": "We use the intensity annotated movie review corpus to obtain the most intense word fora semantic category.", "labels": [], "entities": []}, {"text": "Then, cosine similarity between word vectors of the most intense word and other words of the category is used to assign intensity levels to those words.", "labels": [], "entities": []}, {"text": "Our approach with the used resources is shown in figure 1.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our approach, we consider three measures: accuracy with the goldstandard data, comparison with state of the art and accuracy for the star rating prediction task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9994993209838867}, {"text": "goldstandard data", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.7323290109634399}, {"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9995678067207336}, {"text": "star rating prediction task", "start_pos": 164, "end_pos": 191, "type": "TASK", "confidence": 0.6863037571310997}]}, {"text": "We compute accuracy as the fraction of adjectives for which the predicted intensity level is the same as the gold standard level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9992176294326782}]}, {"text": "We obtained an overall accuracy of 77% across 52 polar categories, containing a total of 697 adjectives.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9990760087966919}]}, {"text": "There have been several successful attempts at sentiment polarity detection in the past).", "labels": [], "entities": [{"text": "sentiment polarity detection", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.9218262632687887}]}, {"text": "However, prediction of star ratings still considered as a challenging task ().", "labels": [], "entities": [{"text": "prediction", "start_pos": 9, "end_pos": 19, "type": "TASK", "confidence": 0.965478241443634}]}, {"text": "We implemented three systems to evaluate the significance of intensity annotated adjectives instar rating prediction task.", "labels": [], "entities": []}, {"text": "System 1: A rule based system based on the concept that negatively high intense words will occur more frequently in the low star reviews and positively high intense words will occur more frequently in the high star reviews.", "labels": [], "entities": []}, {"text": "This system uses the following function Ito assign intensity score to a review r: where C P i and C Ni respectively represent sum of the term-frequencies of positive and negative adjectives with intensity i.", "labels": [], "entities": [{"text": "intensity score", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.980009526014328}]}, {"text": "2 gives us an intensity score between \u22121 and +1 for each review.", "labels": [], "entities": [{"text": "intensity", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9957001209259033}]}, {"text": "We need four breakpoints on these intensity scores to map intensity scores into 5-star ratings.", "labels": [], "entities": []}, {"text": "We learn these breakpoints by maximizing accuracy for the training data 5 overall possible breakpoints.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9992965459823608}]}, {"text": "System 2: In this system, we consider intensity of each adjective as +1 or \u22121 as per its polarity, and then uses eq.", "labels": [], "entities": []}, {"text": "2 to find review intensity.", "labels": [], "entities": [{"text": "review intensity", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8258658647537231}]}, {"text": "System 3: This is an SVM based system which uses four different types of features: (a) unigrams, (b) unigrams with the modification that if adjective belongs to our intensity annotated adjective list, then feature value is intensity of the adjective, (c) and (d) use the scores coming from eq.", "labels": [], "entities": []}, {"text": "2 as an additional feature over those in (a) and shows the results obtained with the above systems.", "labels": [], "entities": []}, {"text": "System 3(d) achieves the maximum accuracy depicting that inclusion of intensity information with the standard features improves the star rating prediction significantly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9995966553688049}]}], "tableCaptions": [{"text": " Table 1: Review ratings with their definitions and  number of reviews.", "labels": [], "entities": []}, {"text": " Table 2: Interpretation of star rating as intensity  scores of reviews for positive and negative words.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of rating prediction systems,  where MSE is the Mean Squared Error and MAE  is the Mean Absolute Error", "labels": [], "entities": [{"text": "Mean Squared Error", "start_pos": 69, "end_pos": 87, "type": "METRIC", "confidence": 0.9112324714660645}, {"text": "MAE", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9912516474723816}, {"text": "Mean Absolute Error", "start_pos": 104, "end_pos": 123, "type": "METRIC", "confidence": 0.8682546218236288}]}]}