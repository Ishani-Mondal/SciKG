{"title": [{"text": "Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Semantically Conditioned LSTM-based Natural Language Generation", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.620713084936142}]}], "abstractContent": [{"text": "Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usabil-ity and perceived quality.", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7683224628369013}]}, {"text": "Most NLG systems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language.", "labels": [], "entities": []}, {"text": "They are also not easily scaled to systems covering multiple domains and languages.", "labels": [], "entities": []}, {"text": "This paper presents a statistical language generator based on a semantically controlled Long Short-term Memory (LSTM) structure.", "labels": [], "entities": []}, {"text": "The LSTM generator can learn from unaligned data by jointly optimising sentence planning and surface realisation using a simple cross entropy training criterion , and language variation can be easily achieved by sampling from output candidates.", "labels": [], "entities": []}, {"text": "With fewer heuristics, an objective evaluation in two differing test domains showed the proposed method improved performance compared to previous methods.", "labels": [], "entities": []}, {"text": "Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "The natural language generation (NLG) component provides much of the persona of a spoken dialogue system (SDS), and it has a significant impact on a user's impression of the system.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.8152974446614584}]}, {"text": "As noted in, a good generator usually depends on several factors: adequacy, fluency, readability, and variation.", "labels": [], "entities": []}, {"text": "Previous approaches attacked the NLG problem in different ways.", "labels": [], "entities": []}, {"text": "The most common and widely adopted today is the rule-based (or template-based) approach).", "labels": [], "entities": []}, {"text": "Despite its robustness and adequacy, the frequent repetition of identical, rather stilted, output forms make talking to a rule-based generator rather tedious.", "labels": [], "entities": []}, {"text": "Furthermore, the approach does not easily scale to large open domain systems().", "labels": [], "entities": []}, {"text": "Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements.", "labels": [], "entities": [{"text": "NLG", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.808558464050293}]}, {"text": "The trainable generator approach exemplified by the HALOGEN ( and SPaRKy system) provides a possible way forward.", "labels": [], "entities": [{"text": "HALOGEN", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.6013805866241455}]}, {"text": "These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (, or reproduce certain style ().", "labels": [], "entities": []}, {"text": "However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation.", "labels": [], "entities": []}, {"text": "The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually.", "labels": [], "entities": []}, {"text": "More recently, corpus-based methods have received attention as access to data becomes increasingly available.", "labels": [], "entities": []}, {"text": "By defining a flexible learning structure, corpus-based methods aim to learn generation directly from data by adopting an over-generation and reranking paradigm), in which final responses are obtained by reranking a set of candidates generated from a stochastic generator.", "labels": [], "entities": []}, {"text": "Learning from data directly enables the system to mimic human responses more naturally, removes the dependency on predefined rules, and makes the system easier to build and extend to other domains.", "labels": [], "entities": []}, {"text": "As detailed in Sections 2 and 3, however, these existing approaches have weaknesses in the areas of training data efficiency, accuracy and naturalness.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9992517828941345}]}, {"text": "This paper presents a statistical NLG based on a semantically controlled Long Short-term Memory (LSTM) recurrent network.", "labels": [], "entities": []}, {"text": "It can learn from unaligned data by jointly optimising its sentence planning and surface realisation components using a simple cross entropy training criterion without any heuristics, and good quality language variation is obtained simply by randomly sampling the network outputs.", "labels": [], "entities": []}, {"text": "We start in Section 3 by defining the framework of the proposed neural language generator.", "labels": [], "entities": []}, {"text": "We introduce the semantically controlled LSTM (SC-LSTM) cell in Section 3.1, then we discuss how to extend it to a deep structure in Section 3.2.", "labels": [], "entities": []}, {"text": "As suggested in, a backward reranker is introduced in Section 3.3 to improve fluency.", "labels": [], "entities": []}, {"text": "Training and decoding details are described in Section 3.4 and 3.5.", "labels": [], "entities": []}, {"text": "Section 4 presents an evaluation of the proposed approach in the context of an application providing information about venues in the San Francisco area.", "labels": [], "entities": []}, {"text": "In Section 4.2, we first show that our generator outperforms several baselines using objective metrics.", "labels": [], "entities": []}, {"text": "We experimented on two different ontologies to show not only that good performance can be achieved across domains, but how easy and quick the development lifecycle is.", "labels": [], "entities": []}, {"text": "In order to assess the subjective performance of our system, a quality test and a pairwise preference test are presented in Section 4.3.", "labels": [], "entities": []}, {"text": "The results show that our approach can produce high quality utterances that are considered to be more natural and are preferred to previous approaches.", "labels": [], "entities": []}, {"text": "We conclude with a brief summary and future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The target application for our generation system is a spoken dialogue system providing information about certain venues in San Francisco.", "labels": [], "entities": []}, {"text": "In order to demonstrate the scalability of the proposed method and its performance in different domains, we tested on two domains that talk about restaurants and hotels respectively.", "labels": [], "entities": []}, {"text": "There are 8 system dialogue act types such as inform to present information about restaurants, confirm to check that a slot value has been recognised correctly, and reject to advise that the user's constraints cannot be met.", "labels": [], "entities": []}, {"text": "Each domain contains 12 attributes (slots), some are common to both domains and the others are domain specific.", "labels": [], "entities": []}, {"text": "The detailed ontologies for the two domains are provided in The system was implemented using the Theano library (, and trained by partitioning each of the collected corpus into a training, validation, and testing set in the ratio 3:1:1.", "labels": [], "entities": [{"text": "Theano library", "start_pos": 97, "end_pos": 111, "type": "DATASET", "confidence": 0.9668711423873901}]}, {"text": "The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform.", "labels": [], "entities": []}, {"text": "Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below 3 were averaged over 5 randomly initialised networks.", "labels": [], "entities": []}, {"text": "For each DA, we overgenerated 20 utterances and selected the top 5 realisations after reranking.", "labels": [], "entities": []}, {"text": "The BLEU-4 metric was used for the objective evaluation ().", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9983079433441162}]}, {"text": "Multiple references for each test DA were obtained by mapping them back to the distinct set of DAs, grouping those delexicalised surface forms that have the same DA specification, and then lexicalising those surface forms back to utterances.", "labels": [], "entities": []}, {"text": "In addition, the slot error rate (ERR) as described in Section 3.5 was computed as an auxiliary metric alongside the BLEU score.", "labels": [], "entities": [{"text": "slot error rate (ERR)", "start_pos": 17, "end_pos": 38, "type": "METRIC", "confidence": 0.9690200289090475}, {"text": "BLEU score", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9666100442409515}]}, {"text": "However, for the experiments it is computed at the corpus level, by averaging slot errors over each of the top 5 realisations in the entire corpus.", "labels": [], "entities": []}, {"text": "The trade-off weights \u03b1 between keyword and key phrase detectors as mentioned in Section 3.1 and 3.2 were set to 0.5.", "labels": [], "entities": [{"text": "keyword and key phrase detectors", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.573177969455719}]}, {"text": "We compared the single layer semantically controlled LSTM (sc-lstm) and a deep version with).", "labels": [], "entities": []}, {"text": "The kNN was implemented by computing the similarity of the test DA 1-hot vector against all of the training DA 1-hot vectors, selecting the nearest and then lexicalising to generate the final surface form.", "labels": [], "entities": []}, {"text": "The objective results are shown in.", "labels": [], "entities": []}, {"text": "As can be seen, none of the baseline systems shown in the first block are comparable to the systems described in this paper (sc-lstm & +deep) if both metrics are considered.", "labels": [], "entities": []}, {"text": "Setting aside the difficulty of scaling to large domains, the handcrafted generator's (hdc) use of predefined rules yields a fixed set of sentence plans, which can differ markedly from the real colloquial human responses collected from AMT, while the class LM approach suffers from inaccurate rendering of information.", "labels": [], "entities": []}, {"text": "Although the kNN method provides reasonable adequacy i.e. low ERR, the BLEU is low, probably because of the errors in the collected corpus which kNN cannot handle but statistical approaches such as LMs can by suppressing unlikely outputs.", "labels": [], "entities": [{"text": "ERR", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9879443645477295}, {"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9997081160545349}]}, {"text": "The last three blocks in compares the proposed method with previous RNN approaches.", "labels": [], "entities": []}, {"text": "LSTM generally works better than vanilla RNN due to its ability to model long range dependencies more efficiently.", "labels": [], "entities": []}, {"text": "We also found that by using gates, whether learned or heuristic, gave much lower slot error rates.", "labels": [], "entities": []}, {"text": "As an aside, the ability of the SC-LSTM to learn gates is also exemplified in.", "labels": [], "entities": []}, {"text": "Finally, by combining the learned gate approach with the deep architecture (+deep), we obtained the best overall performance.", "labels": [], "entities": []}, {"text": "Since automatic metrics may not consistently agree with human perception), human testing is needed to assess subjective quality.", "labels": [], "entities": []}, {"text": "To do this, a set of judges were recruited using AMT.", "labels": [], "entities": [{"text": "AMT", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.8508360385894775}]}, {"text": "For each task, two systems among the four (classlm, rnn w/, sc-lstm, and +deep) were randomly selected to generate utterances from a set of newly sampled dialogues in the restaurant domain.", "labels": [], "entities": []}, {"text": "In order to evaluate system performance in the presence of language variation, each system generated 5 different surface realisations for each input DA and the human judges were asked to score each of them in terms of informativeness and naturalness (rating out of 3), and also asked to state a preference between the two.", "labels": [], "entities": []}, {"text": "Here informativeness is defined as whether the utterance contains all the information specified in the DA, and naturalness is defined as whether the utterance could plausibly have been produced by a human.", "labels": [], "entities": []}, {"text": "In order to decrease the amount of information presented to the judges, utterances that appeared identically in both systems were filtered out.", "labels": [], "entities": []}, {"text": "We tested 1000 DAs in total, and after filtering there were approximately 1300 generated utterances per system.", "labels": [], "entities": []}, {"text": "shows the quality assessments which exhibit the same general trend as the objective results.", "labels": [], "entities": []}, {"text": "The SC-LSTM systems (sc-lstm & +deep) outperform the class-based LMs (classlm) and the RNN with heuristic gates (rnn w/) in both metrics.", "labels": [], "entities": []}, {"text": "The deep SC-LSTM system (+deep) is significantly better than the class LMs (classlm) in terms of informativeness, and better than the RNN with heuristic gates (rnn w/) in terms of naturalness.", "labels": [], "entities": []}, {"text": "The preference test results are shown in.", "labels": [], "entities": []}, {"text": "Again, the SC-LSTM systems were significantly preferred by the judges.", "labels": [], "entities": []}, {"text": "Moreover, the judges recorded a strong preference for the deep approach (+deep) compared to the others, though the preference is not significant when comparing to its shallow counterpart (sc-lstm).", "labels": [], "entities": []}, {"text": "Example dialogue acts and their top-5 realisations are shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Objective evaluation of the top 5 re- alisations. Except for handcrafted (hdc) and k- nearest neighbour (kNN) baselines, all the other  approaches ranked their realisations from 20 over- generated candidates.", "labels": [], "entities": []}, {"text": " Table 3: Real user trial for utterance quality  assessment on two metrics (rating out of 3),  averaging over top 5 realisations. Statistical  significance was computed using a two-tailed  Student's t-test, between deep and all others.", "labels": [], "entities": [{"text": "utterance quality  assessment", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.8037693897883097}]}, {"text": " Table 4: Pairwise preference test among four sys- tems. Statistical significance was computed using  two-tailed binomial test.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 57, "end_pos": 81, "type": "METRIC", "confidence": 0.8414473831653595}]}]}