{"title": [{"text": "Topical Coherence for Graph-based Extractive Summarization", "labels": [], "entities": [{"text": "Graph-based Extractive Summarization", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.7496618032455444}]}], "abstractContent": [{"text": "We present an approach for extractive single-document summarization.", "labels": [], "entities": [{"text": "extractive single-document summarization", "start_pos": 27, "end_pos": 67, "type": "TASK", "confidence": 0.6575761437416077}]}, {"text": "Our approach is based on a weighted graphical representation of documents obtained by topic modeling.", "labels": [], "entities": []}, {"text": "We optimize importance, coherence and non-redundancy simultaneously using ILP.", "labels": [], "entities": []}, {"text": "We compare ROUGE scores of our system with state-of-the-art results on scientific articles from PLOS Medicine and on DUC 2002 data.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9963458180427551}, {"text": "PLOS Medicine", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.8576041162014008}, {"text": "DUC 2002 data", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.9725427428881327}]}, {"text": "Human judges evaluate the coherence of summaries generated by our system in com-parision to two baselines.", "labels": [], "entities": []}, {"text": "Our approach obtains competitive performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Summarization systems take along document as input and generate a concise document as output.", "labels": [], "entities": []}, {"text": "Several summarization variants exist such as generic, query-based, multi-document and single document, but the basic requirements for summarization remain the same.", "labels": [], "entities": [{"text": "summarization", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.9594969153404236}, {"text": "summarization", "start_pos": 134, "end_pos": 147, "type": "TASK", "confidence": 0.970061719417572}]}, {"text": "Summaries should contain salient information so that the reader will not miss anything from the original document.", "labels": [], "entities": []}, {"text": "Also, the reader is not interested in repetitive information, so summaries should not include redundant information.", "labels": [], "entities": [{"text": "summaries", "start_pos": 65, "end_pos": 74, "type": "TASK", "confidence": 0.966933012008667}]}, {"text": "Finally, summaries should be coherent and of high readability.", "labels": [], "entities": []}, {"text": "We introduce a completely unsupervised graphbased summarization using latent drichlet allocation (LDA,).", "labels": [], "entities": []}, {"text": "LDA is a simple model for topic modeling where topic probabilities are assigned words in documents.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.9050501585006714}]}, {"text": "The probabilities can be used to measure the semantic relatedness between words and hence the topical coherence of a document.", "labels": [], "entities": []}, {"text": "We use topical coherence as a means to ensure the coherence of extractive single-document summaries.", "labels": [], "entities": []}, {"text": "Remus and apply LDA to compute lexical chains while also develop a graph-based summarization system which takes coherence into account.", "labels": [], "entities": []}, {"text": "Our work is based on the bipartite entity graph introduced by.", "labels": [], "entities": []}, {"text": "However, in their graph one set of nodes corresponds to entities whereas in our graph it corresponds to topics.", "labels": [], "entities": []}, {"text": "The entity graph has already been used by for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9909372925758362}]}, {"text": "Their graph is unweighted and sparse, whereas our topical graph is weighted and dense.", "labels": [], "entities": []}, {"text": "We apply our topical graph on the dataset introduced by.", "labels": [], "entities": []}, {"text": "This dataset contains scientific articles from the journal PLOS Medicine 1 . Every PLOS Medicine article is accompanied by an editor's summary and an authors' abstract.", "labels": [], "entities": [{"text": "PLOS Medicine 1", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.714807132879893}]}, {"text": "We use both as gold summaries for evaluation.", "labels": [], "entities": []}, {"text": "Results obtained on the PLOS Medicine dataset using the topical graph are as good as using the entity graph and significantly better than several baselines and the graph-based system TextRank ().", "labels": [], "entities": [{"text": "PLOS Medicine dataset", "start_pos": 24, "end_pos": 45, "type": "DATASET", "confidence": 0.927413821220398}]}, {"text": "We use the DUC 2002 dataset to compare our results with state-of-the-art techniques.", "labels": [], "entities": [{"text": "DUC 2002 dataset", "start_pos": 11, "end_pos": 27, "type": "DATASET", "confidence": 0.9841288526852926}]}, {"text": "In contrast to the PLOS Medicine data the DUC 2002 dataset contains very small articles.", "labels": [], "entities": [{"text": "PLOS Medicine data", "start_pos": 19, "end_pos": 37, "type": "DATASET", "confidence": 0.8679261207580566}, {"text": "DUC 2002 dataset", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9383507569630941}]}, {"text": "Still, our technique gives comparable results to the state-of-the-art.", "labels": [], "entities": []}, {"text": "This shows that our technique is flexible and scalable despite being unsupervised.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following, we evaluate on the science genre, i.e. PLOS Medicine articles, and on the news genre, i.e. DUC 2002 data.", "labels": [], "entities": [{"text": "PLOS Medicine articles", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.8791619340578715}, {"text": "DUC 2002 data", "start_pos": 102, "end_pos": 115, "type": "DATASET", "confidence": 0.9630147616068522}]}, {"text": "PLOS Medicine articles are considerably longer than DUC 2002 documents.", "labels": [], "entities": [{"text": "PLOS Medicine articles", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.9218323429425558}, {"text": "DUC 2002 documents", "start_pos": 52, "end_pos": 70, "type": "DATASET", "confidence": 0.9674756129582723}]}, {"text": "The average number of sentences per document is 154 in PLOS Medicine and 25 in DUC 2002.", "labels": [], "entities": [{"text": "PLOS Medicine", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.8154045939445496}, {"text": "DUC 2002", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.9303291141986847}]}, {"text": "Benefits of using PLOS Medicine articles for experiments are: \u2022 They are accompanied by an authors' abstract.", "labels": [], "entities": []}, {"text": "\u2022 They have a summary written by an editor.", "labels": [], "entities": []}, {"text": "\u2022 They are formatted in XML.", "labels": [], "entities": []}, {"text": "\u2022 They contain explicit full forms of abbreviations.", "labels": [], "entities": []}, {"text": "Editor's summaries have a different perspective, writing style and length than authors' abstracts.", "labels": [], "entities": []}, {"text": "We use both as gold summaries for evaluation.", "labels": [], "entities": []}, {"text": "Following Parveen and Strube (2015) we report the results using editor's summaries and author's abstracts independently.", "labels": [], "entities": []}, {"text": "To compare with the state-of-the-art in single-document summarization, we also evaluate on DUC 2002 data.", "labels": [], "entities": [{"text": "DUC 2002 data", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.9780333240826925}]}, {"text": "We use the XML version of PLOS Medicine articles.", "labels": [], "entities": [{"text": "PLOS Medicine articles", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.9071134130160013}]}, {"text": "We extract the contents excluding figures, tables and references.", "labels": [], "entities": []}, {"text": "Editor's summary and authors' abstract are separated from the content for evaluation.", "labels": [], "entities": []}, {"text": "The PLOS Medicine XML provides explicit full forms when abbreviations are introduced.", "labels": [], "entities": [{"text": "PLOS Medicine XML", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9250577290852865}]}, {"text": "We replace abbreviations with their full form in the summary.", "labels": [], "entities": []}, {"text": "We then remove nonalphabetical characters.", "labels": [], "entities": []}, {"text": "After this we parse articles using the Stanford parser).", "labels": [], "entities": []}, {"text": "We perform pronoun resolution using the coreference resolution system by Martschat (2013) 2 . We use gensim to generate the topics.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7630603909492493}, {"text": "coreference resolution", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.9021620750427246}]}, {"text": "For generating topics we use a dataset containing scientific articles from biology, which contains 221,385 documents and about 50 million sentences 3 . We also use Wikipedia to compare with topics from a general domain.", "labels": [], "entities": []}, {"text": "The HITS algorithm is applied on the bipartite graph for computing sentence importance.", "labels": [], "entities": [{"text": "sentence importance", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.664713442325592}]}, {"text": "We calculate the coherence values of sentences on weighted one-mode projection graphs.", "labels": [], "entities": []}, {"text": "The importance and coherence of a sentence is used in the optimization phase 4 which returns a binary value for each sentence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: PLOS Medicine, editor's summaries", "labels": [], "entities": [{"text": "PLOS Medicine", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.7002182006835938}]}, {"text": " Table 2: PLOS Medicine, authors' abstracts", "labels": [], "entities": [{"text": "PLOS Medicine", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.775182843208313}]}, {"text": " Table 3: PLOS Medicine, editor's summ., Bio  topic", "labels": [], "entities": [{"text": "PLOS Medicine", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.7164635360240936}, {"text": "Bio", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.713502824306488}]}, {"text": " Table 4: PLOS Medicine, editor's summ., Wiki  topic", "labels": [], "entities": [{"text": "PLOS Medicine", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.765897274017334}]}, {"text": " Table 5: DUC 2002, single-document summariza- tion", "labels": [], "entities": [{"text": "DUC 2002", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.9334068298339844}]}]}