{"title": [{"text": "What's in an Embedding? Analyzing Word Embeddings through Multilingual Evaluation", "labels": [], "entities": []}], "abstractContent": [{"text": "In the last two years, there has been a surge of word embedding algorithms and research on them.", "labels": [], "entities": []}, {"text": "However, evaluation has mostly been carried out on a narrow set of tasks, mainly word similarity/relatedness and word relation similarity and on a single language, namely English.", "labels": [], "entities": [{"text": "word relation similarity", "start_pos": 113, "end_pos": 137, "type": "TASK", "confidence": 0.647351453701655}]}, {"text": "We propose an approach to evaluate embed-dings on a variety of languages that also yields insights into the structure of the embedding space by investigating how well word embeddings cluster along different syntactic features.", "labels": [], "entities": []}, {"text": "We show that all embedding approaches behave similarly in this task, with dependency-based embeddings performing best.", "labels": [], "entities": []}, {"text": "This effect is even more pronounced when generating low dimensional embed-dings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings map words into a vector space, allowing to reason about words in this space.", "labels": [], "entities": []}, {"text": "They have been shown to be beneficial for several tasks such as machine translation), parsing (, and named entity recognition (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.8198505938053131}, {"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.984001636505127}, {"text": "named entity recognition", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.6954648395379385}]}, {"text": "Recently, word embedding techniques have been studied for their mathematical properties (, yielding a better understanding of the underlying optimization criteria.", "labels": [], "entities": []}, {"text": "However, word embeddings have mostly been studied and evaluated on a single language.", "labels": [], "entities": []}, {"text": "Therefore, validation on languages other than English is lacking and the question whether word embeddings work the same way across languages has not been empirically evaluated.", "labels": [], "entities": []}, {"text": "Evaluations of complex systems -such as parsers -employing word embeddings generally give only little insight into the type of contribution to the result and the structure of word embeddings.", "labels": [], "entities": []}, {"text": "We aim to fill these gaps by evaluating several word embedding algorithms on a set of different languages using tasks that enable additional insight into the learned structures using easily obtainable data.", "labels": [], "entities": []}, {"text": "At the same time, we provide baseline results for using word embeddings in several syntax-based classification tasks.", "labels": [], "entities": [{"text": "syntax-based classification", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.7374951839447021}]}, {"text": "We focus on syntax-related measures because data is available for several languages and we expect a correlation with usefulness of word embeddings for syntax-related tasks such as named entity recognition, parsing, and morphological analysis.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 180, "end_pos": 204, "type": "TASK", "confidence": 0.6161861717700958}, {"text": "parsing", "start_pos": 206, "end_pos": 213, "type": "TASK", "confidence": 0.8150666952133179}, {"text": "morphological analysis", "start_pos": 219, "end_pos": 241, "type": "TASK", "confidence": 0.7119918167591095}]}], "datasetContent": [{"text": "We classify words separately according to several tasks with an L2-regularized linear classifier.", "labels": [], "entities": []}, {"text": "All classification tasks are based on the word embedding of a single word alone, without any other information about the word or its context; in particular, the word's lexicalization is not used as a feature.", "labels": [], "entities": []}, {"text": "By using the continuous features directly instead of clustering them (as e.g. done by), we ensure that no information is lost during preprocessing.", "labels": [], "entities": []}, {"text": "All tasks can be carried out on dependency treebanks with morphological annotation.", "labels": [], "entities": []}, {"text": "From each word in the treebank, we extract a data point (word embedding, class) for training/testing, where class is of one of the following, depending on the task: pos The Part-of-Speech of the word headpos The PoS of the word's head label The label of the word's dependency edge gender* The gender of the word case* The case of the word number* The number of the word tense* The tense of the word Tasks marked with an asterisk are only carried out on words with a corresponding feature.", "labels": [], "entities": [{"text": "PoS", "start_pos": 212, "end_pos": 215, "type": "METRIC", "confidence": 0.9784005880355835}]}, {"text": "Some of these features are absent in some languages, e.g. Basque is mostly genderless and the corpus of English we used is not annotated with morphological information.", "labels": [], "entities": []}, {"text": "These combinations of language and feature have been omitted.", "labels": [], "entities": []}, {"text": "We use a one-versus-all linear classifier for two reasons: First, the feature dimensionality is relatively high.", "labels": [], "entities": []}, {"text": "Second, and more importantly, training a linear classifier yields insights into the structure of the vector space because the classifier also serves as a tool to obtain a supervised clustering of the vector space.", "labels": [], "entities": []}, {"text": "Let C beset set of classes.", "labels": [], "entities": []}, {"text": "A one-versus-all linear classifier learns a linear function f c \u2208 Rn \u2192 R for each class c \u2208 C.", "labels": [], "entities": []}, {"text": "The classifier assigns to a vector X the best matching class based on these functions: Due to the linearity of the functions f c , the vector space is partitioned into convex polytopes, which each represent exactly one class (see Appendix A).", "labels": [], "entities": []}, {"text": "Therefore, the classification accuracies can also be interpreted as supervised clustering accuracies.", "labels": [], "entities": []}, {"text": "This means that if the classifier yields a high accuracy, the members of each class are clustered in a single convex region of the vector space.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9979762434959412}]}, {"text": "We think that this is a fairly strong statement about the structure of the vector space.", "labels": [], "entities": []}, {"text": "To better gauge how well the embeddings are actually clustered, we use a majority baseline which classifies all elements as the one class that occurred most often during training.", "labels": [], "entities": []}, {"text": "This is the accuracy a classifier would yield without any information and therefore the information gain obtainable by using word embeddings as features is the difference between the achieved accuracy and the baseline accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9956318140029907}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.9942597150802612}, {"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.8318758010864258}]}, {"text": "In addition to the lower bound described above, we also provide an approximate upper bound for the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9994206428527832}]}, {"text": "Because no context information is used during classification, the word vector corresponding to a word will always be classified the same, even though the correct classification might depend on the context, e. g. the word put can belong to different tense classes depending on the context.", "labels": [], "entities": []}, {"text": "Therefore, an upper bound for the classification task is to assign each word the most probable class for that word (computed on the training set).", "labels": [], "entities": []}, {"text": "Assuming that no sparsity issues exist, embeddingbased classification can yield at most accuracies as high as this approach.", "labels": [], "entities": [{"text": "embeddingbased classification", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.8407761752605438}]}, {"text": "Note that because in reality data sparsity unfortunately does exist, this is only an approximation of the upper bound.", "labels": [], "entities": []}, {"text": "We call this approximation up-approx and compute it omitting words not seen during training.", "labels": [], "entities": []}, {"text": "Evaluation was carried out on Basque, English, French, German, Hungarian, Polish, and Swedish datasets.", "labels": [], "entities": []}, {"text": "For English, automatically labeled data was obtained by tagging and parsing a subset of the English Wikipedia dump provided by).", "labels": [], "entities": []}, {"text": "The Penn, converted using the LTH converter, was used as the corresponding manually annotated resource.", "labels": [], "entities": [{"text": "Penn", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9894418716430664}, {"text": "LTH converter", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.9385914206504822}]}, {"text": "For all other languages, datasets including both automatically and manually annotated data provided as part of the Shared Task on parsing morphologically rich languages ( were used.", "labels": [], "entities": [{"text": "parsing morphologically rich languages", "start_pos": 130, "end_pos": 168, "type": "TASK", "confidence": 0.8526027202606201}]}, {"text": "For all languages, we trained embeddings on the automatically labeled data using the approaches described in Section 3, with different window sizes (5 and 11, where applicable) and dimensions (10, 100, 200).", "labels": [], "entities": []}, {"text": "The rare word limit was set to five words occurrences.", "labels": [], "entities": []}, {"text": "brown was only trained with 1024 clusters equaling about 10 dimensions, as the number of clusters cannot be increased to generate higher-dimensional embeddings.", "labels": [], "entities": []}, {"text": "dep was not evaluated on French because the French automatically labeled dataset lacks dependency information.", "labels": [], "entities": [{"text": "French", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.922271192073822}]}], "tableCaptions": [{"text": " Table 1: Mean accuracy across tasks for  dimension=200 and window=5, and change in  mean accuracy when deviating, measured in per- centage points. dep has no window parameter.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9826479554176331}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.5539934635162354}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.7094401121139526}]}]}