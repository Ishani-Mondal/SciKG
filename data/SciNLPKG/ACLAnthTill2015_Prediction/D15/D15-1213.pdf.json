{"title": [{"text": "Hierarchical Low-Rank Tensors for Multilingual Transfer Parsing", "labels": [], "entities": [{"text": "Hierarchical Low-Rank Tensors", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.5955845812956492}, {"text": "Multilingual Transfer Parsing", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.70808673898379}]}], "abstractContent": [{"text": "Accurate multilingual transfer parsing typically relies on careful feature engineering.", "labels": [], "entities": [{"text": "multilingual transfer parsing", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.7033445835113525}]}, {"text": "In this paper, we propose a hierarchical tensor-based approach for this task.", "labels": [], "entities": []}, {"text": "This approach induces a compact feature representation by combining atomic features.", "labels": [], "entities": []}, {"text": "However, unlike traditional tensor models, it enables us to incorporate prior knowledge about desired feature interactions , eliminating invalid feature combinations.", "labels": [], "entities": []}, {"text": "To this end, we use a hierarchical structure that uses intermediate em-beddings to capture desired feature combinations.", "labels": [], "entities": []}, {"text": "Algebraically, this hierarchical tensor is equivalent to the sum of traditional tensors with shared components, and thus can be effectively trained with standard online algorithms.", "labels": [], "entities": []}, {"text": "In both unsu-pervised and semi-supervised transfer scenarios , our hierarchical tensor consistently improves UAS and LAS over state-of-the-art multilingual transfer parsers and the traditional tensor model across 10 different languages.", "labels": [], "entities": [{"text": "LAS", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9250010848045349}]}], "introductionContent": [{"text": "The goal of multilingual syntactic transfer is to parse a resource lean target language utilizing annotations available in other languages.", "labels": [], "entities": [{"text": "multilingual syntactic transfer", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.6208470463752747}]}, {"text": "Recent approaches have demonstrated that such transfer is possible, even in the absence of parallel data.", "labels": [], "entities": []}, {"text": "As a main source of guidance, these methods rely on the commonalities in dependency structures across languages.", "labels": [], "entities": []}, {"text": "These commonalities manifest themselves through abroad and diverse set of indicators, ranging from standard arc features used in monolingual parsers to typological properties The source code is available at https://github.", "labels": [], "entities": []}, {"text": "com/yuanzh/TensorTransfer.", "labels": [], "entities": []}, {"text": "Verb-subject: {head POS=VERB} \u2227 {modifier POS=NOUN} \u2227{label=subj} \u2227 {direction=LEFT}\u2227 {82A=SV} Noun-adjective: {head POS=NOUN} \u2227 {modifier POS=ADJ}\u2227 {direction=LEFT} \u2227 {87A=Adj-Noun}: Example verb-subject and noun-adjective typological features.", "labels": [], "entities": []}, {"text": "82A and 87A denote the WALS () feature codes for verbsubject and noun-adjective ordering preferences.", "labels": [], "entities": []}, {"text": "needed to guide cross-lingual sharing (e.g., verbsubject ordering preference).", "labels": [], "entities": []}, {"text": "In fact, careful feature engineering has been shown to play a crucial role in state-of-the-art multilingual transfer parsers.", "labels": [], "entities": [{"text": "multilingual transfer parsers", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.7185261448224386}]}, {"text": "Tensor-based models are an appealing alternative to manual feature design.", "labels": [], "entities": []}, {"text": "These models automatically induce a compact feature representation by factorizing a tensor constructed from atomic features (e.g., the head POS).", "labels": [], "entities": []}, {"text": "No prior knowledge about feature interactions is assumed.", "labels": [], "entities": []}, {"text": "As a result, the model considers all possible combinations of atomic features, and addresses the parameter explosion problem via a low-rank assumption.", "labels": [], "entities": []}, {"text": "In the multilingual transfer setting, however, we have some prior knowledge about legitimate feature combinations.", "labels": [], "entities": []}, {"text": "Consider for instance a typological feature that encodes verb-subject preferences.", "labels": [], "entities": []}, {"text": "As shows, it is expressed as a conjunction of five atomic features.", "labels": [], "entities": []}, {"text": "Ideally, we would like to treat this composition as a single non-decomposable feature.", "labels": [], "entities": []}, {"text": "However, the traditional tensor model decomposes this feature into multiple dimensions, and considers various combinations of these features as well as their individual interactions with other features.", "labels": [], "entities": []}, {"text": "Moreover, we want to avoid invalid combinations that con-join the above feature with unrelated atomic features.", "labels": [], "entities": []}, {"text": "For instance, there is no point to constructing features of the form {head POS=ADJ}\u2227{head POS=VERB} \u2227 \u00b7 \u00b7 \u00b7 \u2227 {82A=SV} as the head POS takes a single value.", "labels": [], "entities": [{"text": "VERB", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.8935914039611816}]}, {"text": "However, the traditional tensor technique still considers these unobserved feature combinations, and assigns them non-zero weights (see Section 7).", "labels": [], "entities": []}, {"text": "This inconsistency between prior knowledge and the low-rank assumption results in a sub-optimal parameter estimation.", "labels": [], "entities": []}, {"text": "To address this issue, we introduce a hierarchical tensor model that constrains parameter representation.", "labels": [], "entities": []}, {"text": "The model encodes prior knowledge by explicitly excluding undesired feature combinations over the same atomic features.", "labels": [], "entities": []}, {"text": "At the bottom level of the hierarchy, the model constructs combinations of atomic features, generating intermediate embeddings that represent the legitimate feature groupings.", "labels": [], "entities": []}, {"text": "For instance, these groupings will not combine the verb-subject ordering feature and the POS head feature.", "labels": [], "entities": []}, {"text": "At higher levels of the hierarchy, the model combines these embeddings as well as the expert-defined typological features over the same atomic features.", "labels": [], "entities": []}, {"text": "The hierarchical tensor is thereby able to capture the interaction between features at various subsets of atomic features.", "labels": [], "entities": []}, {"text": "Algebraically, the hierarchical tensor is equivalent to the sum of traditional tensors with shared components.", "labels": [], "entities": []}, {"text": "Thus, we can use standard online algorithms for optimizing the low-rank hierarchical tensor.", "labels": [], "entities": []}, {"text": "We evaluate our model on labeled dependency transfer parsing using the newly released multilingual universal dependency treebank . We compare our model against the state-of-the-art multilingual transfer dependency parser and the direct transfer model ).", "labels": [], "entities": [{"text": "dependency transfer parsing", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.6880416373411814}, {"text": "multilingual transfer dependency parser", "start_pos": 181, "end_pos": 220, "type": "TASK", "confidence": 0.6345699727535248}]}, {"text": "All the parsers utilize the same training resources but with different feature representations.", "labels": [], "entities": []}, {"text": "When trained on source languages alone, our model outperforms the baselines for 7 out of 10 languages on both unlabeled attachment score (UAS) and labeled attachment score (LAS).", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 110, "end_pos": 142, "type": "METRIC", "confidence": 0.7974800815184911}, {"text": "labeled attachment score (LAS)", "start_pos": 147, "end_pos": 177, "type": "METRIC", "confidence": 0.8593935569127401}]}, {"text": "On average, it achieves 1.1% UAS improvement over's model and 4.8% UAS over the direct transfer.", "labels": [], "entities": [{"text": "UAS", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9978436231613159}, {"text": "UAS", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9993122816085815}]}, {"text": "We also consider a semi-supervised setting where multilingual data is augmented with 50 annotated sentences in the target language.", "labels": [], "entities": []}, {"text": "In this case, our model achieves improvement of 1.7% UAS over's model and 4.5% UAS over the direct transfer.", "labels": [], "entities": [{"text": "UAS", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9787880182266235}, {"text": "UAS", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9977765679359436}]}], "datasetContent": [{"text": "Dataset We evaluate our model on the newly released multilingual universal dependency treebank v2.0 ( ) that consists of 10 languages: English (EN), French (FR), German (DE), Indonesian (ID), Italian (IT), Japanese (JA), Korean (KO), Brazilian-Portuguese (PT), Spanish (ES) and Swedish (SV).", "labels": [], "entities": []}, {"text": "This multilingual treebank is annotated with a universal POS tagset and a universal dependency label set.", "labels": [], "entities": [{"text": "POS tagset", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.7977316081523895}]}, {"text": "Therefore, this dataset is an excellent benchmark for cross-lingual transfer evaluation.", "labels": [], "entities": [{"text": "cross-lingual transfer evaluation", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.8726432124773661}]}, {"text": "For POS tags, the gold universal annotation used the coarse tagset ) that consists of 12 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and a catch-all tag X.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.7858729362487793}]}, {"text": "For dependency labels, the universal annotation developed the Stanford dependencies) into a rich set of 40 labels.", "labels": [], "entities": []}, {"text": "This universal annotation enables labeled dependency parsing in crosslingual transfer.", "labels": [], "entities": [{"text": "labeled dependency parsing", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.591389944156011}]}, {"text": "Evaluation Scenarios We first consider the unsupervised transfer scenario, in which we assume no target language annotations are available.", "labels": [], "entities": []}, {"text": "Following the standard setup, for each target language evaluated, we train our model on the concatenation of the training data in all other source languages.", "labels": [], "entities": []}, {"text": "In addition, we consider the semi-supervised transfer scenario, in which we assume 50 sentences in the target language are available with annotation.", "labels": [], "entities": [{"text": "semi-supervised transfer", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7009690403938293}]}, {"text": "However, we observe that random sentence selection of the supervised sample results in a big performance variance.", "labels": [], "entities": []}, {"text": "Instead, we select sentences that contain patterns that are absent or rare in source language treebanks.", "labels": [], "entities": []}, {"text": "To this end, each time we greedily select the sentence that minimizes the KL divergence between the trigram distribution of the target language and the trigram distribution of the training data after adding this sentence.", "labels": [], "entities": []}, {"text": "The training data includes both the target and the source languages.", "labels": [], "entities": []}, {"text": "The trigrams are based on universal POS tags.", "labels": [], "entities": []}, {"text": "Note that our method does not require any dependency annotations.", "labels": [], "entities": []}, {"text": "To incorporate the new supervision, we simply add the new sentences into the original training set, weighing their impact by a factor of 10.", "labels": [], "entities": []}, {"text": "Baselines We compare against different variants of our model.", "labels": [], "entities": []}, {"text": "\u2022 Direct: a direct transfer baseline ) that uses only delexicalized features in the MSTParser ().", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.9293738007545471}]}, {"text": "\u2022 NT-Select: our model without the tensor component.", "labels": [], "entities": [{"text": "NT-Select", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.7631060481071472}]}, {"text": "This baseline corresponds to the prior feature-based transfer method) with extensions to labeled parsing, lexicalization and semi-supervised parsing.", "labels": [], "entities": []}, {"text": "6 \u2022 Multiway: tensor-based model where typological features are added as an additional component and parameters are factorized in the multiway structure similarly as in.", "labels": [], "entities": []}, {"text": "\u2022 Sup50: our model trained only on the 50 sentences in the target language in the semisupervised scenario.", "labels": [], "entities": []}, {"text": "In all the experiments we incorporate partial lexicalization for all variants of our model and we focus on labeled dependency parsing.", "labels": [], "entities": [{"text": "labeled dependency parsing", "start_pos": 107, "end_pos": 133, "type": "TASK", "confidence": 0.5967151820659637}]}, {"text": "Supervised Upper Bound As a performance upper bound, we train the RBGParser (, the state-of-the-art tensor-based parser, on the full target language training set.", "labels": [], "entities": []}, {"text": "We train the first-order model with default parameter settings, using the current version of the code.", "labels": [], "entities": []}, {"text": "8 Evaluation Measures Following standard practices, we report unlabeled attachment score (UAS) and labeled attachment score (LAS), excluding punctuation.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 62, "end_pos": 94, "type": "METRIC", "confidence": 0.8020455638567606}, {"text": "labeled attachment score (LAS)", "start_pos": 99, "end_pos": 129, "type": "METRIC", "confidence": 0.8800436854362488}]}, {"text": "For all experiments, we report results on the test set and omit the development results because of space.", "labels": [], "entities": []}, {"text": "For all experiments, we use the arc-factored model and use Eisner's algorithm to infer the projective Viterbi parse.", "labels": [], "entities": []}, {"text": "We train our model and the baselines for 10 epochs.", "labels": [], "entities": []}, {"text": "We set a strong regularization C = 0.001 during learning because cross-lingual transfer contains noise and the models can easily overfit.", "labels": [], "entities": []}, {"text": "Other hyper-parameters are set as \u03b3 = 0.3 and r = 200 (rank of the tensor).", "labels": [], "entities": []}, {"text": "For partial lexicalization, we set the embedding dimension to 50.", "labels": [], "entities": []}, {"text": "the baselines in both cases.", "labels": [], "entities": [{"text": "baselines", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9709824919700623}]}, {"text": "Moreover, it achieves best UAS and LAS on 7 out of 10 languages.", "labels": [], "entities": [{"text": "UAS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.8616465926170349}, {"text": "LAS", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9598549008369446}]}, {"text": "The difference is more pronounced in the semisupervised case.", "labels": [], "entities": []}, {"text": "Below, we summarize our findings when comparing the model with the baselines.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Unsupervised: Unlabeled attachment scores (UAS) and Labeled attachment scores (LAS) of  different variants of our model with partial lexicalization in unsupervised scenario. \"Direct\" and \"Multi- way\" indicate the direct transfer and the multiway variants of our model. \"NT-Select\" indicates our model  without tensor component, corresponding to a re-implementation of previous transfer model (T\u00e4ckstr\u00f6m  et al., 2013) with extensions to partial lexicalization and labeled parsing. The last column shows the  results by our hierarchical tensor-based model. Boldface numbers indicate the best UAS or LAS.", "labels": [], "entities": [{"text": "Labeled attachment scores (LAS)", "start_pos": 62, "end_pos": 93, "type": "METRIC", "confidence": 0.7716214060783386}]}, {"text": " Table 6: Examples of weights for feature  combinations between the typological feature  87A=Adj-Noun and different types of arcs. The  first row shows the weight for the valid feature  (conjoined with noun\u2192adjective arcs) and the rest  show weights for the invalid features (conjoined  with other types of arcs).", "labels": [], "entities": []}, {"text": " Table 7: Semi-supervised and Supervised: UAS and LAS of different variants of our model when 50  annotated sentences in the target language are available. \"Sup50\" columns show the results of our model  when only supervised data in the target language is available. We also include in the last two columns  the supervised training results with partial or full lexicalization as the performance upper bound. Other  columns have the same meaning as in", "labels": [], "entities": [{"text": "LAS", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.906662106513977}]}]}