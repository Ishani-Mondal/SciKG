{"title": [{"text": "Inferring Binary Relation Schemas for Open Information Extraction", "labels": [], "entities": [{"text": "Inferring Binary Relation Schemas", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8755691349506378}, {"text": "Open Information Extraction", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.649954617023468}]}], "abstractContent": [{"text": "This paper presents a framework to model the semantic representation of binary relations produced by open information extraction systems.", "labels": [], "entities": [{"text": "open information extraction", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.6837597886721293}]}, {"text": "For each binary relation, we infer a set of preferred types on the two arguments simultaneously, and generate a ranked list of type pairs which we call schemas.", "labels": [], "entities": []}, {"text": "All inferred types are drawn from the Freebase type taxonomy, which are human readable.", "labels": [], "entities": [{"text": "Freebase type taxonomy", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.9197504123051962}]}, {"text": "Our system collects 171,168 binary relations from Re-Verb, and is able to produce top-ranking relation schemas with a mean reciprocal rank of 0.337.", "labels": [], "entities": []}], "introductionContent": [{"text": "Open information extraction (or Open IE) is a task of extracting all sorts of relations between named entities or concepts from open-domain text corpora, without restraining itself to specific relations or patterns.", "labels": [], "entities": [{"text": "Open information extraction (or Open IE)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7797688357532024}, {"text": "extracting all sorts of relations between named entities or concepts from open-domain text corpora", "start_pos": 54, "end_pos": 152, "type": "TASK", "confidence": 0.49255712968962534}]}, {"text": "State-of-the-art Open IE systems () extract millions of binary relations with high precision from the web corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9523363709449768}]}, {"text": "Each extracted relation instance is a triple of the form arg 1 , rel, arg 2 , where the relation rel is a lexical or syntactic pattern, and both arguments are multi-word expressions representing the argument entities or concepts.", "labels": [], "entities": []}, {"text": "Whereas Open IE provides concrete relation instances, we are interested in generalizing these instances into more abstract semantic representations.", "labels": [], "entities": []}, {"text": "In this paper, we focus on inferring the schemas of binary relations.", "labels": [], "entities": []}, {"text": "For example, given the binary relation \"play in\", an Open IE system extracts many triples of the form X, play in, Y . The following relation triples are extracted in ReVerb: Goel Grey, played in, Cabaret Tom Brady, play in, National Football League Informally, the goal of our system is to automatically infer a set of schemas such as t 1 , play in, t 2 , where t 1 and t 2 are two semantic types drawn from a standard knowledge base such as WordNet,,, and Probase (, and each such schema can be used to represent a set of \"play in\" relation instances.", "labels": [], "entities": [{"text": "National Football League", "start_pos": 224, "end_pos": 248, "type": "DATASET", "confidence": 0.8980757395426432}, {"text": "WordNet", "start_pos": 442, "end_pos": 449, "type": "DATASET", "confidence": 0.9689522385597229}, {"text": "Probase", "start_pos": 457, "end_pos": 464, "type": "DATASET", "confidence": 0.9761685729026794}]}, {"text": "For the above example, two possible schemas for \"play in\" are: film actor, play in, film athlete, play in, sports league The schema of a binary relation is useful information in NLP tasks, such as context-oriented entity recognition and open domain question answering.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 214, "end_pos": 232, "type": "TASK", "confidence": 0.6827048063278198}, {"text": "open domain question answering", "start_pos": 237, "end_pos": 267, "type": "TASK", "confidence": 0.5674548968672752}]}, {"text": "Suppose we are to recognize the entities in the sentence \"Granger played in the NBA\".", "labels": [], "entities": []}, {"text": "\"Granger\" is a highly ambiguous term, while \"the NBA\" is probably a sports league.", "labels": [], "entities": [{"text": "Granger\"", "start_pos": 1, "end_pos": 9, "type": "TASK", "confidence": 0.7546639740467072}]}, {"text": "Then with the the above relation schemas for \"play in\", the entity recognizer knows that \"Granger\" is more likely to bean athlete, which results in the correct linking to \"Danny Granger\", who is an NBA player, even though the Open IE has never extracted such fact before.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 226, "end_pos": 233, "type": "DATASET", "confidence": 0.8460085988044739}]}, {"text": "One relevant technique to achieve our goal is selectional preference (SP), which computes the most appropriate types fora specific argument of a predicate.", "labels": [], "entities": [{"text": "selectional preference (SP)", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.602524584531784}]}, {"text": "SP is based on the idea of mutual information, which tends to select types which are unique to the relation.", "labels": [], "entities": [{"text": "SP", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9828388094902039}]}, {"text": "In other words, common types which can be used for many different relations are less preferred.", "labels": [], "entities": []}, {"text": "However, in Open IE, many relations are related or even similar, e.g., play in, take part in and be involved in.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.566724419593811}]}, {"text": "There's no reason for these relations not to share schemas.", "labels": [], "entities": []}, {"text": "Therefore in this paper, our problem is, given a re-lation and its instances, identify the smallest types that can cover as many instances as possible.", "labels": [], "entities": []}, {"text": "Our approach first attempts to link the arguments in the relation instances to a set of possible entities in a knowledge base, hence generate a set of e 1 , e 2 entity pairs.", "labels": [], "entities": []}, {"text": "Then we select a pair of types t 1 , t 2 that covers maximum number of entity pairs.", "labels": [], "entities": []}, {"text": "We resolve ties by selecting the smaller (more specific) types according to a type taxonomy inferred from knowledge base.", "labels": [], "entities": []}, {"text": "This paper makes the following contributions: i) we defined the schema inference problem for binary relations from Open IE; ii) we developed a prototype system based on Freebase and entity linking (, which simultaneously models the type distributions of two arguments for each binary relation; iii) our experiment on ReVerb triples showed that the top inferred schemas receive decent mean reciprocal rank (MRR) of 0.337, with respect to the human labeled ground truth.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 384, "end_pos": 410, "type": "METRIC", "confidence": 0.7687782297531763}]}], "datasetContent": [{"text": "Freebase () is a collaboratively generated knowledge base, which contains more than 40 million entities, and more than 1,700 real types 1 . In our experiment, We use the 16 Feb. 2014 dump of Freebase as the knowledge base.) is an Open IE system which aims to extract verb based relation instances from web corpora.", "labels": [], "entities": []}, {"text": "The release ReVerb dataset contains more than 14 millions of relation tuples with high quality.", "labels": [], "entities": [{"text": "ReVerb dataset", "start_pos": 12, "end_pos": 26, "type": "DATASET", "confidence": 0.9180256128311157}]}, {"text": "We observed that in ReVerb, some argument is unlikely to bean entity in Freebase, for example: M etro Manila, consists of, 12 cities, where the object argument is not an entity but a type.", "labels": [], "entities": []}, {"text": "Since types are usually represented by lowercase common words, we remove the tuple if one argument is lowercase, or if it is made up completely of common words in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 163, "end_pos": 170, "type": "DATASET", "confidence": 0.9692142009735107}]}, {"text": "In addition, because date/time such as \"Jan. 16th, 1981\" often occurs in the object argument while Freebase does not have any such specific dates as entities, we use SUTime () to recognize dates as an virtual entity.", "labels": [], "entities": [{"text": "Jan. 16th, 1981\"", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.8429826617240905}]}, {"text": "After cleaning, the system collects 3,234,208 tuples and 171,168 relation groups.", "labels": [], "entities": []}, {"text": "The following parameters are tuned using a development set: \u03c4 = 0.667, \u01eb = 0.6, \u03bb = 5% and \u03c1 = e \u221250 . For relation grouping, we use Stanford Parser ( to perform POS tagging, lemmatizing and parsing on relations.", "labels": [], "entities": [{"text": "\u01eb", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.9739839434623718}, {"text": "relation grouping", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.8048404157161713}, {"text": "POS tagging", "start_pos": 162, "end_pos": 173, "type": "TASK", "confidence": 0.818804532289505}]}, {"text": "We first evaluate the results of entity linking.", "labels": [], "entities": []}, {"text": "We randomly pick 200 relation instances from ReVerb, and manually labeled arguments with Freebase entities.", "labels": [], "entities": []}, {"text": "For both naive and ensemble strategy, we evaluate the precision, recall, F1 and MRR score on the labeled set.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9997537732124329}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9983643889427185}, {"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9991176724433899}, {"text": "MRR score", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9803084433078766}]}, {"text": "An output entity pair is correct, if and only if both arguments are correctly linked.", "labels": [], "entities": []}, {"text": "Experimental results are listed in.", "labels": [], "entities": []}, {"text": "For the evaluation of relation schema, we first randomly pick 50 binary relations with support larger than 500 from the system.", "labels": [], "entities": []}, {"text": "For each relation, we selected top 100 type pairs with the largest support, as what we evaluated.", "labels": [], "entities": []}, {"text": "We assigned 3 human annotators to label the fitness score of type pair for the relation.", "labels": [], "entities": []}, {"text": "The labeled score ranges from 0 to 3.", "labels": [], "entities": [{"text": "labeled score", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9633733928203583}]}, {"text": "Then we merge these 3 label sets, forming 50 gold standard rankings.", "labels": [], "entities": []}, {"text": "When evaluating a relation schema list from our system, we calculate the MRR score ( by the top schemas in the gold rankings.", "labels": [], "entities": [{"text": "MRR score", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9823552370071411}]}, {"text": "For comparison, we use Pointwise Mutual Information) as our baseline model, which is used in other selectional preference tasks.", "labels": [], "entities": []}, {"text": "We define the association score between relation and type pair as: PM I(r, tp) = p(r, tp) log p(r, tp) p(r, * )p( * , tp) Where p(r, tp) is the joint probability of relation and type pair in the whole linked tuple set, and * stands for any relations or type pairs.", "labels": [], "entities": [{"text": "association score", "start_pos": 14, "end_pos": 31, "type": "METRIC", "confidence": 0.9403381943702698}, {"text": "PM I", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.912689208984375}]}, {"text": "shows the MRR scores by using both baseline model (PMI) and our approach.", "labels": [], "entities": [{"text": "MRR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7030997276306152}]}, {"text": "As the result shows, our approach improves the MRR score by 10.1%.", "labels": [], "entities": [{"text": "MRR score", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.8637268841266632}]}, {"text": "Finally, shows some example binary relations, and their schemas inferred by our system.", "labels": [], "entities": []}, {"text": "We can see that with a well-defined type hierarchy, our system is able to extract both coarse-grained and fine-grained type information from entities, resulting in a informative type lists.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Entity Linking Result", "labels": [], "entities": [{"text": "Entity Linking Result", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8483181993166605}]}, {"text": " Table 2: End-to-end Schema Inference Results", "labels": [], "entities": [{"text": "Schema Inference", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.8721351623535156}]}]}