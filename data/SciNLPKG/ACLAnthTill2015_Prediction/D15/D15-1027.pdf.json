{"title": [{"text": "A Model of Zero-Shot Learning of Spoken Language Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "When building spoken dialogue systems fora new domain, a major bottleneck is developing a spoken language understanding (SLU) module that handles the new domain's terminology and semantic concepts.", "labels": [], "entities": []}, {"text": "We propose a statistical SLU model that generalises to both previously unseen input words and previously unseen output classes by leveraging unlabelled data.", "labels": [], "entities": []}, {"text": "After mapping the utterance into a vector space, the model exploits the structure of the output labels by mapping each label to a hyperplane that separates utterances with and without that label.", "labels": [], "entities": []}, {"text": "Both these mappings are initialised with unsupervised word embeddings, so they can be computed even for words or concepts which were not in the SLU training data.", "labels": [], "entities": [{"text": "SLU training data", "start_pos": 144, "end_pos": 161, "type": "DATASET", "confidence": 0.6601000626881918}]}], "introductionContent": [{"text": "Spoken Language Understanding (SLU) in dialogue systems is the task of taking the utterance output by a speech recognizer and assigning it a semantic label that represents the dialogue actions of that utterance accompanied with their associated attributes and values.", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8610751926898956}]}, {"text": "For example, the utterance \"I would like Chinese food\" is labelled with inform(food=Chinese), in which inform is the dialogue action that provides the value of the attribute food that is Chinese.", "labels": [], "entities": []}, {"text": "Dialogue systems often use hand-crafted grammars for SLU, such as Phoenix (, which are expensive to develop, and expensive to extend or adapt to new attributes and values.", "labels": [], "entities": []}, {"text": "Statistical SLU models are usually trained on the data obtained from a specific domain and location, using a structured output classifier that can be discriminative () or generative ().", "labels": [], "entities": []}, {"text": "Gathering and annotating SLU data is costly and time consuming and therefore SLU datasets are small compare to the number of possible labels.", "labels": [], "entities": [{"text": "SLU datasets", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.7105208486318588}]}, {"text": "Because training sets fora new domain are small, or non-existent, learning is often an instance of Zero-shot or One-shot learning problems (), in which zero or few examples of some output classes are available during the training.", "labels": [], "entities": []}, {"text": "For example, in the restaurant reservation domain, not all possible combinations of foods and dialogue actions maybe included in the training set.", "labels": [], "entities": []}, {"text": "The general idea to solve this type of problems is to map the input and class labels to a semantic space of usually lower dimension in which similar classes are represented by closer points in the space (.", "labels": [], "entities": []}, {"text": "Usually unsupervised knowledge sources are used to form semantic codes of the labels that helps us to generalize to unseen labels.", "labels": [], "entities": []}, {"text": "On the other hand, there are also different ways to express the same meaning, and similarly, most of them cannot be included in the training set.", "labels": [], "entities": []}, {"text": "For instance, the system may have seen \"Please give me the telephone number\" in training, but the user might ask \"Please give me the phone\" attest time.", "labels": [], "entities": []}, {"text": "This problem, feature sparsity, is a common issue in many NLP tasks.", "labels": [], "entities": []}, {"text": "Decomposition of input feature parameters using vector-matrix multiplication ( has addressed this sparsity issue successfully in previous work.", "labels": [], "entities": []}, {"text": "In this way, by sharing the word representations and composition matrices, we can overcome feature sparsity by producing similar representations for similar utterances.", "labels": [], "entities": []}, {"text": "In order to represent words and concepts we use word embeddings, which area form of vector space model.", "labels": [], "entities": []}, {"text": "Word embeddings have proven to be effective models of semantic representation of words in various NLP tasks ().", "labels": [], "entities": []}, {"text": "In addition to parameter sharing, these representations enable us to leverage large scale unlabelled data.", "labels": [], "entities": []}, {"text": "Because word embeddings trained on unlabeled data reflect the similarity between words, they help the model generalize from the words in the original training corpora to the words in the new extended domain, and help generalize from small amounts of data in the extended domain.", "labels": [], "entities": []}, {"text": "The contribution of this paper is to build a representation learning classifier for the SLU task that can generalize to unseen words and labels.", "labels": [], "entities": [{"text": "SLU task", "start_pos": 88, "end_pos": 96, "type": "TASK", "confidence": 0.8636112809181213}]}, {"text": "For every utterance we learn how to compose the word vectors to form the semantics of that utterance for this task of language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.7260429859161377}]}, {"text": "Furthermore, we learn how to compose the semantics of each label from the semantics of the words used to name that label.", "labels": [], "entities": []}, {"text": "This enables us to generalize to unseen labels.", "labels": [], "entities": [{"text": "generalize to unseen labels", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.8416329473257065}]}, {"text": "In this work we use the word2vec software of to induce unsupervised word embeddings that are used to initialize word embedding parameters.", "labels": [], "entities": []}, {"text": "For this, we use an English Wikipedia dump as our unlabelled training corpus, which is a diverse broad-coverage corpus.", "labels": [], "entities": [{"text": "English Wikipedia dump", "start_pos": 20, "end_pos": 42, "type": "DATASET", "confidence": 0.7802333037058512}]}, {"text": "It has been shown () that these embeddings capture lexical similarities even when they are trained on a diverse corpus like Wikipedia.", "labels": [], "entities": []}, {"text": "We test our models on a restaurant booking domain.", "labels": [], "entities": []}, {"text": "We investigate domain adaptation by adding new attribute types (e.g. goodformeal) and new attribute values (e.g. Hayes Valley as a restaurant location).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7335734218358994}, {"text": "Hayes Valley as a restaurant location", "start_pos": 113, "end_pos": 150, "type": "DATASET", "confidence": 0.9075199464956919}]}, {"text": "Our experiments indicate that our model has better performance compared to a hand-crafted system as well as a SVM baseline.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dialogue utterances used to build the SLU dataset were collected during atrial of online dialogue policy adaptation fora restaurant reservation system based in San Francisco.", "labels": [], "entities": [{"text": "SLU dataset", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.7867393493652344}]}, {"text": "The trial began with (area, pricerange and food), and adapted the Interaction Manager online to handle the additional attribute types near, allowedforkids, and goodformeal ().", "labels": [], "entities": []}, {"text": "User utterances from these trials were transcribed and annotated 1 https://code.google.com/p/word2vec/ with dialogue acts by an expert, and afterwards edited by another expert 2 . Each user utterance was annotated with a set of labels, where each label consists of an act type (e.g. inform, request), an attribute type (e.g. foodtype, pricerange), and an attribute value (e.g. Chinese, Cheap).", "labels": [], "entities": []}, {"text": "The dataset is separated into four subsets, SFCore, SF1Ext, SF2Ext and SF3Ext, each with an increasing set of attribute types, as specified in.", "labels": [], "entities": []}, {"text": "This table also gives the total number of utterances in each data set.", "labels": [], "entities": []}, {"text": "For our first experiment, we split each dataset into about 15% for the testing set and 85% for the training set.", "labels": [], "entities": []}, {"text": "For our second experiment we use each extended subset for testing and its preceding subsets for training.", "labels": [], "entities": []}, {"text": "In the first experiment, we measure SLU performance trained on all available data, by building a dataset that is the union of all the above datasets.", "labels": [], "entities": [{"text": "SLU", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9497112035751343}]}, {"text": "This measures the performance of SLU when there is a small amount of data for an extended domain.", "labels": [], "entities": [{"text": "SLU", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.8716982007026672}]}, {"text": "This dataset, similarly to SF3Ext, has 6 main attribute types.", "labels": [], "entities": [{"text": "SF3Ext", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.892025351524353}]}, {"text": "shows the performance of this model.", "labels": [], "entities": []}, {"text": "We report as baselines the performance of the Phoenix system (hand crafted for this domain) and a binary linear SVM trained on the same data.", "labels": [], "entities": []}, {"text": "The hidden layers have size h=d=50.", "labels": [], "entities": []}, {"text": "For this experiment, we split each dataset into about 15% for the testing set and 85% for the training set.", "labels": [], "entities": []}, {"text": "particularly that the recall is almost twice as high as the hand-crafted baseline.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9996310472488403}]}, {"text": "This shows that our SLU can recognise most of the dialogue acts in an utterance, where the rule-based Phoenix system and a classifier without composed output cannot.", "labels": [], "entities": []}, {"text": "Overall there are 1042 dialogue acts in the test set.", "labels": [], "entities": []}, {"text": "SLU recall is very important in the overall dialogue system performance, as the effect of a missed dialogue act is hard to handle for the Interaction Manager.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.8434087038040161}]}, {"text": "Both hand-crafted and our system show relatively high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9982643723487854}]}, {"text": "In the next experiment, we measure how well the new SLU model performs in an extended domain without any training examples from that extended domain.", "labels": [], "entities": []}, {"text": "We train a SLU model on each subset, and test it on each of the more inclusive subsets.", "labels": [], "entities": []}, {"text": "Not surprisingly, the performance is better if SLU is trained on a similar domain to the test domain, and adding more attribute types and values decreases the performance more.", "labels": [], "entities": []}, {"text": "But our SLU can generalise very well to the extended domain, achieving much better generalisation that the SVM model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance on union of data (SF- Core+SF1Ext+SF2Ext+SF3Ext)", "labels": [], "entities": []}, {"text": " Table 3: SLU performance: trained on a smaller domain and tested on more inclusive domains.", "labels": [], "entities": []}]}