{"title": [{"text": "Corpus-level Fine-grained Entity Typing Using Contextual Information", "labels": [], "entities": [{"text": "Corpus-level Fine-grained Entity Typing", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5096642896533012}]}], "abstractContent": [{"text": "This paper addresses the problem of corpus-level entity typing, i.e., inferring from a large corpus that an entity is a member of a class such as \"food\" or \"artist\".", "labels": [], "entities": [{"text": "corpus-level entity typing", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6614722410837809}]}, {"text": "The application of entity typing we are interested in is knowledge base completion, specifically, to learn which classes an entity is a member of.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.6248146593570709}]}, {"text": "We propose FIGMENT to tackle this problem.", "labels": [], "entities": [{"text": "FIGMENT", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.8778998851776123}]}, {"text": "FIGMENT is embedding-based and combines (i) a global model that scores based on aggregated contextual information of an entity and (ii) a context model that first scores the individual occurrences of an entity and then aggregates the scores.", "labels": [], "entities": [{"text": "FIGMENT", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7757052183151245}]}, {"text": "In our evaluation, FIGMENT strongly out-performs an approach to entity typing that relies on relations obtained by an open information extraction system.", "labels": [], "entities": [{"text": "FIGMENT", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.4594283103942871}, {"text": "entity typing", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.7213465571403503}]}], "introductionContent": [{"text": "Natural language understanding (NLU) is not possible without knowledge about the world -partly so because world knowledge is needed for many NLP tasks that must be addressed as part of NLU; e.g., many coreference ambiguities can only be resolved based on world knowledge.", "labels": [], "entities": [{"text": "Natural language understanding (NLU)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7726132770379385}]}, {"text": "It is also true because most NLU applications combine a variety of information sources that include both text sources and knowledge bases; e.g., question answering systems need access to knowledge bases like gazetteers.", "labels": [], "entities": [{"text": "question answering", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.834180474281311}]}, {"text": "Thus, high-quality knowledge bases are critical for successful NLU.", "labels": [], "entities": []}, {"text": "Unfortunately, most knowledge bases are incomplete.", "labels": [], "entities": []}, {"text": "The effort required to create knowledge bases is considerable and since the world changes, it will always continue.", "labels": [], "entities": []}, {"text": "Knowledge bases are therefore always in need of updates and corrections.", "labels": [], "entities": []}, {"text": "To address this problem, we present an information extraction method that can be used for knowledge base completion.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7729472517967224}, {"text": "knowledge base completion", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.7305499712626139}]}, {"text": "In contrast to most other work on knowledge base completion, we focus on fine-grained classification of entities as opposed to relations between entities.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.6301963130633036}]}, {"text": "The goal of knowledge base completion is to acquire knowledge in general as opposed to detailed analysis of an individual context or sentence.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.6245491902033488}]}, {"text": "Therefore, our approach is corpus-level: We infer the types of an entity by considering the set of all of its mentions in the corpus.", "labels": [], "entities": []}, {"text": "In contrast, named entity recognition (NER) is context-level or sentence-level: NER infers the type of an entity in a particular context.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.8175897200902303}]}, {"text": "As will be discussed in more detail in the following sections, the problems of corpus-level entity typing vs. context/sentencelevel entity typing are quite different.", "labels": [], "entities": []}, {"text": "This is partly because the objectives of optimizing accuracy on the context-level vs. optimizing accuracy on the corpus-level are different and partly because evaluation measures for corpus-level and context-level entity typing are different.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9910647869110107}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9609325528144836}]}, {"text": "We define our problem as follows.", "labels": [], "entities": []}, {"text": "Let K be a knowledge base that models a set E of entities, a set T of fine-grained classes or types and a membership function m : E \u00d7 T \u2192 {0, 1} such that m(e, t) = 1 iff entity e has type t.", "labels": [], "entities": []}, {"text": "Let C be a large corpus of text.", "labels": [], "entities": []}, {"text": "Then, the problem we address in this paper is corpus-level entity typing: For a given pair of entity e and type t determine -based on the evidence available in C -whether e is a member of type t (i.e., m(e, t) = 1) or not (i.e., m(e, t) = 0) and update the membership relation m of K with this information.", "labels": [], "entities": []}, {"text": "We investigate two approaches to entity typing: a global model and a context model.", "labels": [], "entities": [{"text": "entity typing", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.7143833339214325}]}, {"text": "The global model aggregates all contextual information about an entity e from the corpus and then based on that, makes a classification decision on a particular type t -i.e., m(e, t) = 0 vs. m(e, t) = 1.", "labels": [], "entities": []}, {"text": "The context model first scores each individual context of e as expressing type tor not.", "labels": [], "entities": []}, {"text": "A final decision on the value of m(e, t) is then made based on the distribution of context scores.", "labels": [], "entities": []}, {"text": "One difficulty in knowledge base completion based on text corpora is that it is too expensive to label large amounts of text for supervised approaches.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.6893816788991293}]}, {"text": "For our context model, we address this problem using distant supervision: we treat all contexts of an entity that can have type t as contexts of type t even though this assumption will in general be only true fora subset of these contexts.", "labels": [], "entities": []}, {"text": "Thus, as is typical for distant supervision, the labels are incorrect in some contexts, but we will show that the labeling is good enough to learn a high-quality context model.", "labels": [], "entities": []}, {"text": "The global model is potentially more robust since it looks at all the available information at once.", "labels": [], "entities": []}, {"text": "In contrast, the context model has the advantage that it can correctly predict types for which there are only a small number of reliable contexts.", "labels": [], "entities": []}, {"text": "For example, in a large corpus we are likely to find a few reliable contexts indicating that \"Barack Obama\" is a bestselling author even though this evidence maybe obscured in the global distribution because the vast majority of mentions of \"Obama\" do not occur in author contexts.", "labels": [], "entities": []}, {"text": "We implement the global model and the context model as well as a simple combination of the two and call the resulting system FIGMENT: FIne-Grained eMbedding-based Entity Typing.", "labels": [], "entities": [{"text": "FIGMENT", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.915463387966156}]}, {"text": "A key feature of FIGMENT is that it makes extensive use of distributed vector representations or embeddings.", "labels": [], "entities": [{"text": "FIGMENT", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.5252374410629272}]}, {"text": "We compute embeddings for words as is standard in a large body of NLP literature, but we also compute embeddings for entities and for types.", "labels": [], "entities": []}, {"text": "The motivation for using embeddings in these cases is (i) better generalization and (ii) more robustness against noise for text types like web pages.", "labels": [], "entities": []}, {"text": "We compare the performance of FIG-MENT with an approach based on Open Information Extraction (OpenIE).", "labels": [], "entities": [{"text": "FIG-MENT", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.5124185681343079}]}, {"text": "The main contributions of this paper can be summarized as follows.", "labels": [], "entities": []}, {"text": "\u2022 We address the problem of corpus-level entity typing in a knowledge base completion setting.", "labels": [], "entities": []}, {"text": "In contrast to other work that has focused on learning relations between entities, we learn types of entities.", "labels": [], "entities": []}, {"text": "\u2022 We show that context and global models for entity typing provide complementary information and combining them gives the best results.", "labels": [], "entities": [{"text": "entity typing", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.7271137237548828}]}, {"text": "\u2022 We use embeddings for words, entities and types to improve generalization and deal with noisy input.", "labels": [], "entities": []}, {"text": "\u2022 We show that our approach outperforms a system based on OpenIE relations when the input corpus consists of noisy web pages.", "labels": [], "entities": []}, {"text": "In the following, we first discuss related work.", "labels": [], "entities": []}, {"text": "Then we motivate our approach and define the problem setting we adopt.", "labels": [], "entities": []}, {"text": "We then introduce our models in detail and report and analyze experimental results.", "labels": [], "entities": []}, {"text": "Finally, we discuss remaining challenges and possible future work and present our conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Type macro average F 1 for all, head and  tail types", "labels": [], "entities": [{"text": "Type macro average F 1", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8052166342735291}]}, {"text": " Table 3: Effect of the context size 2k in CM (2k:  context size, h: number of hidden units in MLP)", "labels": [], "entities": []}, {"text": " Table 1: Ranking and classification results for SE entities. P@1 and BEP are ranking measures. Accuracy  (acc), micro (mic) and macro (mac) are classification measures.", "labels": [], "entities": [{"text": "P@1", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9142307639122009}, {"text": "BEP", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9858232736587524}, {"text": "Accuracy  (acc)", "start_pos": 96, "end_pos": 111, "type": "METRIC", "confidence": 0.9079285711050034}]}]}