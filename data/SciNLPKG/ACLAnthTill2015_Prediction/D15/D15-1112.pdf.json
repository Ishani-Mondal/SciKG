{"title": [{"text": "Semantic Role Labeling with Neural Network Factors", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7797532081604004}]}], "abstractContent": [{"text": "We present anew method for semantic role labeling in which arguments and semantic roles are jointly embedded in a shared vector space fora given predicate.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.6700374682744344}]}, {"text": "These embeddings belong to a neural network, whose output represents the potential functions of a graphical model designed for the SRL task.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 131, "end_pos": 139, "type": "TASK", "confidence": 0.9327073693275452}]}, {"text": "We consider both local and structured learning methods and obtain strong results on standard PropBank and FrameNet corpora with a straightforward product-of-experts model.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 93, "end_pos": 101, "type": "DATASET", "confidence": 0.9568174481391907}]}, {"text": "We further show how the model can learn jointly from PropBank and FrameNet annotations to obtain additional improvements on the smaller FrameNet dataset.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.9550142288208008}, {"text": "FrameNet dataset", "start_pos": 136, "end_pos": 152, "type": "DATASET", "confidence": 0.9401033818721771}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) is the task of identifying the semantic arguments of a predicate and labeling them with their semantic roles.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8433141708374023}]}, {"text": "A key challenge in this task is sparsity of labeled data: a given predicate-role instance may only occur a handful of times in the training set.", "labels": [], "entities": []}, {"text": "Most existing SRL systems model each semantic role as anatomic unit of meaning, ignoring finer-grained semantic similarity between roles that can be leveraged to share context between similar labels, both within and across annotation conventions.", "labels": [], "entities": [{"text": "SRL", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9737327098846436}]}, {"text": "Low-dimensional embedding representations have been shown to be successful in overcoming sparsity and representing label similarity across a wide range of tasks.", "labels": [], "entities": []}, {"text": "In this paper, we present anew model for SRL that embeds candidate arguments and semantic roles (in context of a predicate frame) in a shared vector space.", "labels": [], "entities": [{"text": "SRL", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.991801917552948}]}, {"text": "A feed-forward neural * Work carried out during an internship at network is learned to capture correlations of the respective embedding dimensions to create argument and role representations.", "labels": [], "entities": []}, {"text": "The similarity of these two representations, as measured by their dot product, is used to score possible roles for candidate arguments within a graphical model.", "labels": [], "entities": []}, {"text": "This graphical model jointly models the assignment of semantic roles to all arguments of a predicate, subject to structural linguistic constraints.", "labels": [], "entities": []}, {"text": "Our model has several advantages.", "labels": [], "entities": []}, {"text": "Compared to linear multiclass classifiers used in prior work, vector embeddings of the predictions overcome the assumption of modeling each semantic role as a discrete label, thus capturing fine-grained label similarity.", "labels": [], "entities": []}, {"text": "Moreover, since predictions and inputs are embedded in the same vector space, and features extracted from inputs and outputs are decoupled, our approach is amenable to joint learning of multiple annotation conventions, such as PropBank and FrameNet, in a single model.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 227, "end_pos": 235, "type": "DATASET", "confidence": 0.9271227121353149}]}, {"text": "Finally, as with other neural network approaches, our model obviates the need to manually engineer feature conjunctions.", "labels": [], "entities": []}, {"text": "Our underlying inference algorithm for SRL follows, who presented a dynamic program for structured SRL; it is targeted towards the prediction of full argument spans.", "labels": [], "entities": [{"text": "SRL", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9877678751945496}, {"text": "SRL", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.8941469788551331}]}, {"text": "Hence, we present empirical results on three spanbased SRL datasets: CoNLL 2005 and 2012 data annotated with PropBank conventions, as well as FrameNet 1.5 data.", "labels": [], "entities": [{"text": "SRL datasets", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.7885470688343048}, {"text": "CoNLL 2005 and 2012 data", "start_pos": 69, "end_pos": 93, "type": "DATASET", "confidence": 0.853331470489502}, {"text": "FrameNet 1.5 data", "start_pos": 142, "end_pos": 159, "type": "DATASET", "confidence": 0.8388416369756063}]}, {"text": "We also evaluate our system on the dependency-based CoNLL 2009 shared task by assuming single word argument spans, that represent semantic dependencies, and limit our experiments to English.", "labels": [], "entities": [{"text": "CoNLL 2009 shared task", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.8394481837749481}]}, {"text": "On all datasets, our model performs on par with a strong linear model baseline that uses hand-engineered conjunctive features.", "labels": [], "entities": []}, {"text": "Due to random parameter initialization and stochasticity in the online learning algorithm used to train our models, we observed considerable variance in performance across datasets.", "labels": [], "entities": []}, {"text": "To resolve this variance, we adopt a product-of-experts model that John stole my car .", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the datasets used, the required preprocessing steps, the baselines compared to and the details of our experimental setup.", "labels": [], "entities": []}, {"text": "We evaluate our approach on four standard datasets.", "labels": [], "entities": []}, {"text": "For span-based SRL using PropBank conventions We use the standard evaluation scripts for each task and use a paired bootstrap test to assess the statistical significance of the results.", "labels": [], "entities": [{"text": "SRL", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.8432533740997314}]}, {"text": "For brevity, we only give the p-values for the observed differences between our best and second best models on each of the test sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: PropBank-style SRL results on CoNLL 2005 data. Bold font indicates the best system using a  single or no syntactic parse, while the best scores among all systems are underlined. Results from prior  work are taken from the respective papers, and '-' indicates performance metrics missing in the original  publication. Statistical significance was assessed for F1 and Comp. on the WSJ and Brown test sets with  p < 0.01 ( * ) and p < 0.05 ( *  *", "labels": [], "entities": [{"text": "SRL", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.6247643828392029}, {"text": "CoNLL 2005 data", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9698810776074728}, {"text": "Statistical significance", "start_pos": 327, "end_pos": 351, "type": "METRIC", "confidence": 0.8218248784542084}, {"text": "F1", "start_pos": 369, "end_pos": 371, "type": "METRIC", "confidence": 0.9923248291015625}, {"text": "Comp.", "start_pos": 376, "end_pos": 381, "type": "METRIC", "confidence": 0.9002013206481934}, {"text": "WSJ and Brown test sets", "start_pos": 389, "end_pos": 412, "type": "DATASET", "confidence": 0.9297778964042663}]}, {"text": " Table 3: PropBank-style semantic dependency SRL results (labeled F1) on the CoNLL 2009 data set.  Bold font indicates the best system. Statistical significance was assessed with p < 0.01 ( * ).", "labels": [], "entities": [{"text": "PropBank-style semantic dependency SRL", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.45672472566366196}, {"text": "F1", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9805976748466492}, {"text": "CoNLL 2009 data set", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.9841851145029068}, {"text": "Statistical significance", "start_pos": 136, "end_pos": 160, "type": "METRIC", "confidence": 0.8463467657566071}]}, {"text": " Table 4: PropBank-style SRL results on the  CoNLL 2012 development and test sets. Results  from prior work are taken from the respective pa- pers, and '-' indicates performance metrics miss- ing in the original publication. Significance was  assessed for F1 and Comp. on the test set with  p < 0.01 ( * ).", "labels": [], "entities": [{"text": "SRL", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.6457769274711609}, {"text": "CoNLL 2012 development and test sets", "start_pos": 45, "end_pos": 81, "type": "DATASET", "confidence": 0.932846317688624}, {"text": "Significance", "start_pos": 225, "end_pos": 237, "type": "METRIC", "confidence": 0.9607028961181641}, {"text": "F1", "start_pos": 256, "end_pos": 258, "type": "METRIC", "confidence": 0.9839558005332947}]}, {"text": " Table 5: Joint frame and argument identification  results for FrameNet. Statistical significance was  assessed for F1 and Comp. on the test set with  p < 0.01 ( * ) and p < 0.05 ( *  * ).", "labels": [], "entities": [{"text": "Joint frame and argument identification", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.5868285119533538}, {"text": "FrameNet", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.8176859021186829}, {"text": "Statistical significance", "start_pos": 73, "end_pos": 97, "type": "METRIC", "confidence": 0.906527578830719}, {"text": "F1", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.998428225517273}]}]}