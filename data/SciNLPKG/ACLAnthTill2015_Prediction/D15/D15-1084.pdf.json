{"title": [{"text": "Knowledge Base Unification via Sense Embeddings and Disambiguation", "labels": [], "entities": []}], "abstractContent": [{"text": "We present KB-UNIFY, a novel approach for integrating the output of different Open Information Extraction systems into a single unified and fully disambiguated knowledge repository.", "labels": [], "entities": []}, {"text": "KB-UNIFY consists of three main steps: (1) disambigua-tion of relation argument pairs via a sense-based vector representation and a large unified sense inventory; (2) ranking of semantic relations according to their degree of specificity; (3) cross-resource relation alignment and merging based on the semantic similarity of domains and ranges.", "labels": [], "entities": [{"text": "cross-resource relation alignment", "start_pos": 243, "end_pos": 276, "type": "TASK", "confidence": 0.6859370966752371}]}, {"text": "We tested KB-UNIFY on a set of four heterogeneous knowledge bases, obtaining high-quality results.", "labels": [], "entities": []}, {"text": "We discuss and provide evaluations at each stage, and release output and evaluation data for the use and scrutiny of the community 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "The breakthrough of the Open Information Extraction (OIE) paradigm opened up a research area where Web-scale unconstrained Information Extraction systems are developed to acquire and formalize large quantities of knowledge.", "labels": [], "entities": [{"text": "Open Information Extraction (OIE)", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.7843547761440277}]}, {"text": "However, while successful, to date most state-of-theart OIE systems have been developed with their own type inventories, and no portable ontological structure.", "labels": [], "entities": []}, {"text": "In fact, OIE systems can be very different in nature.", "labels": [], "entities": []}, {"text": "Early approaches () focused on extracting a large number of relations from massive unstructured corpora, mostly relying on dependencies at the level of surface text.", "labels": [], "entities": []}, {"text": "Systems like NELL () combine a hand-crafted taxonomy of entities and relations with self-supervised large-scale extraction http://lcl.uniroma1.it/kb-unify from the Web, but they require additional processing for linking and integration ().", "labels": [], "entities": []}, {"text": "More recent work has focused, instead, on deeper language understanding, especially at the level of syntax and semantics.", "labels": [], "entities": []}, {"text": "By leveraging semantic analysis, knowledge gathered from unstructured text can be adequately integrated and used to enrich existing knowledge bases, such as YAGO (), FREEBASE) and DBPEDIA (.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 157, "end_pos": 161, "type": "METRIC", "confidence": 0.6261928677558899}, {"text": "FREEBASE", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9684794545173645}, {"text": "DBPEDIA", "start_pos": 180, "end_pos": 187, "type": "DATASET", "confidence": 0.772307276725769}]}, {"text": "A large amount of reliable structured knowledge is crucial for OIE approaches based on distant supervision (, even when multi-instance multi-learning algorithms ( or matrix factorization techniques () come into play to deal with noisy extractions.", "labels": [], "entities": [{"text": "OIE", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.856483519077301}]}, {"text": "For this reason a recent trend of research has focused on Knowledge Base (KB) completion (, exploiting the fact that distantly supervised OIE and structured knowledge can complement each other.", "labels": [], "entities": [{"text": "Knowledge Base (KB) completion", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.632476364572843}]}, {"text": "However, the majority of integration approaches nowadays are not designed to deal with many different resources at the same time.", "labels": [], "entities": []}, {"text": "We propose an approach where the key idea is to bring together knowledge drawn from an arbitrary number of OIE systems, regardless of whether these systems provide links to some generalpurpose inventory, come with their own ad-hoc structure, or have no structure at all.", "labels": [], "entities": []}, {"text": "Knowledge from each source, in the form of subject, predicate, object triples, is disambiguated and linked to a single large sense inventory.", "labels": [], "entities": []}, {"text": "This enables us to discover alignments at a semantic level between relations from different KBs, and to generate a unified, fully disambiguated KB of entities and semantic relations.", "labels": [], "entities": []}, {"text": "KB-UNIFY achieves stateof-the-art disambiguation and provides a general, resource-independent representation of semantic relations, suitable for any kind of KB.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: Section 2 reviews relevant related work; Sections 3, 4, 5 and 6 describe in detail each stage of the approach; Sections 7 and 8 describe the experiments carried out and the results obtained; and finally Section 9 summarizes our findings and discusses potential directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The setting for our experimental evaluation was the following: \u2022 We used BabelNet 3.0 3 as our unified sense inventory for the unification procedure as well as the underlying inventory for both BA-BELFY and SENSEMBED.", "labels": [], "entities": [{"text": "BA-BELFY", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.7463667988777161}]}, {"text": "Currently, BabelNet contains around 14M synsets and represents the largest single multilingual repository of entities and concepts; \u2022 We selected PATTY ( and WISENET as linked resources.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 146, "end_pos": 151, "type": "METRIC", "confidence": 0.5466547012329102}]}, {"text": "We used PATTY with FREEBASE types and pattern synsets derived from Wikipedia, and WISENET 2.0 with Wikipedia relational phrases; \u2022 We selected NELL () and REVERB) as unlinked resources.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.7461119294166565}, {"text": "FREEBASE", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9713199138641357}, {"text": "REVERB", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9699020385742188}]}, {"text": "We used KB beliefs updated to November 2014 for the former, and the set of relation instances from ClueWeb09 for the latter.", "labels": [], "entities": [{"text": "KB beliefs", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.7991603016853333}]}], "tableCaptions": [{"text": " Table 1: Statistics on the input KBs", "labels": [], "entities": []}, {"text": " Table 2: Disambiguation precision for all KBs", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9442098736763}, {"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.8005096912384033}]}, {"text": " Table 3: Coverage results (%) for all KBs", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8472645878791809}, {"text": "KBs", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.5352617502212524}]}, {"text": " Table 4: Disambiguation results over NELL gold standard", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8197782635688782}, {"text": "NELL gold", "start_pos": 38, "end_pos": 47, "type": "TASK", "confidence": 0.7700811922550201}]}, {"text": " Table 5: Specificity ranking evaluation", "labels": [], "entities": [{"text": "Specificity ranking", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.9777819514274597}]}, {"text": " Table 7: Cross-resource alignment evaluation", "labels": [], "entities": [{"text": "Cross-resource alignment", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8638399243354797}]}, {"text": " Table 7. Our alignment al- gorithm shows high precision in all pairings where  \u03b4 align = 0.9. Alignment reliability decreases for  lower \u03b4 align , as relation pairs where r i is a gener- alization of r j (or vice versa) tend to have similar  centroids in V S . The same holds for pairs where r i  is the negation of r j (or vice versa). Even though  we could have utilized measures based on rela-tion string similarity (", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9988780617713928}, {"text": "Alignment reliability", "start_pos": 95, "end_pos": 116, "type": "METRIC", "confidence": 0.8626396656036377}]}]}