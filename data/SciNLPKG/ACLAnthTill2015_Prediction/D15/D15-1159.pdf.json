{"title": [{"text": "Improved Transition-Based Parsing and Tagging with Neural Networks", "labels": [], "entities": [{"text": "Improved Transition-Based Parsing and Tagging", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7200149893760681}]}], "abstractContent": [{"text": "We extend and improve upon recent work in struc-tured training for neural network transition-based dependency parsing.", "labels": [], "entities": [{"text": "neural network transition-based dependency parsing", "start_pos": 67, "end_pos": 117, "type": "TASK", "confidence": 0.6527059137821197}]}, {"text": "We do this by experimenting with novel features, additional transition systems and by testing on a wider array of languages.", "labels": [], "entities": []}, {"text": "In particular , we introduce set-valued features to encode the predicted morphological properties and part-of-speech confusion sets of the words being parsed.", "labels": [], "entities": []}, {"text": "We also investigate the use of joint parsing and part-of-speech tagging in the neural paradigm.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.6983675211668015}, {"text": "part-of-speech tagging", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7006130516529083}]}, {"text": "Finally, we conduct a multilingual evaluation that demonstrates the robustness of the overall structured neu-ral approach, as well as the benefits of the extensions proposed in this work.", "labels": [], "entities": []}, {"text": "Our research further demonstrates the breadth of the applicability of neu-ral network methods to dependency parsing, as well as the ease with which new features can be added to neural parsing models.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.85157510638237}, {"text": "neural parsing", "start_pos": 177, "end_pos": 191, "type": "TASK", "confidence": 0.767362505197525}]}], "introductionContent": [{"text": "Transition-based parsers are extremely popular because of their high accuracy and speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9990702271461487}]}, {"text": "Inspired by the greedy neural network transition-based parser of, and concurrently developed structured neural network parsers that use beam search and achieve state-of-the-art accuracies for English dependency parsing.", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 192, "end_pos": 218, "type": "TASK", "confidence": 0.6385876933733622}]}, {"text": "While very successful, these parsers have made use only of a small fraction of the rich options provided inside the transition-based framework: for example, all of these parsers use virtually identical atomic features and the arcstandard transition system.", "labels": [], "entities": []}, {"text": "In this paper we extend this line of work and introduce two new types of features that significantly improve parsing performance: (1) a set-valued (i.e., bag-of-words style) feature for There is of course a much longer tradition of neural network dependency parsing models, going back at least to. each word's morphological attributes, and (2) a weighted set-valued feature for each word's k-best POS tags.", "labels": [], "entities": [{"text": "parsing", "start_pos": 109, "end_pos": 116, "type": "TASK", "confidence": 0.9667876958847046}, {"text": "neural network dependency parsing", "start_pos": 232, "end_pos": 265, "type": "TASK", "confidence": 0.7712368667125702}]}, {"text": "These features can be integrated naturally as atomic inputs to the embedding layer of the network and the model can learn arbitrary conjunctions with all other features through the hidden layers.", "labels": [], "entities": []}, {"text": "In contrast, integrating such features into a model with discrete features requires nontrivial manual tweaking.", "labels": [], "entities": []}, {"text": "For example, Bohnet and Nivre (2012) had to carefully discretize the real-valued POS tag score in order to combine it with the other discrete binary features in their system.", "labels": [], "entities": []}, {"text": "Additionally, we also experiment with different transition systems, most notably the integrated parsing and part-of-speech (POS) tagging system of Bohnet and Nivre (2012) and also the swap system of.", "labels": [], "entities": [{"text": "parsing and part-of-speech (POS) tagging", "start_pos": 96, "end_pos": 136, "type": "TASK", "confidence": 0.65860772558621}]}, {"text": "We evaluate our parser on the CoNLL '09 shared task dependency treebanks, as well as on two English setups, achieving the best published numbers in many cases.", "labels": [], "entities": [{"text": "CoNLL '09 shared task dependency treebanks", "start_pos": 30, "end_pos": 72, "type": "DATASET", "confidence": 0.8876299006598336}]}], "datasetContent": [{"text": "In this section we provide final test set results for our baseline and full models on three standard setups from the literature: CoNLL '09, English WSJ and English Treebank Union.", "labels": [], "entities": [{"text": "CoNLL '09", "start_pos": 129, "end_pos": 138, "type": "DATASET", "confidence": 0.9217624068260193}, {"text": "English WSJ", "start_pos": 140, "end_pos": 151, "type": "DATASET", "confidence": 0.8858695924282074}, {"text": "English Treebank Union", "start_pos": 156, "end_pos": 178, "type": "DATASET", "confidence": 0.9794599016507467}]}], "tableCaptions": [{"text": " Table 1: Ablation study on CoNLL'09 dev set. All scores in  this table are LAS with beam 32. The first three rows use a  pipeline of tagging and then parsing, while the last two rows  use integrated parsing and tagging. Chinese and English have  no morphology features provided in the dataset, so we omit  morphology for those languages.", "labels": [], "entities": [{"text": "CoNLL'09 dev set", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9459274212519327}, {"text": "LAS", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9904460906982422}, {"text": "parsing", "start_pos": 151, "end_pos": 158, "type": "TASK", "confidence": 0.9589175581932068}]}, {"text": " Table 2: POS tagging results on the CoNLL '09 test set for in- tegrated POS tagging and parsing. We compare the accuracy  of our baseline CRF tagger, 'Linear' (our re-implementation  of Bohnet and Nivre (2012, BN'12)), 'Neural' (the neural  parser presented in this work), and results reported by BN'12.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8672262132167816}, {"text": "CoNLL '09 test set", "start_pos": 37, "end_pos": 55, "type": "DATASET", "confidence": 0.9310590267181397}, {"text": "POS tagging and parsing", "start_pos": 73, "end_pos": 96, "type": "TASK", "confidence": 0.6781160682439804}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9986379742622375}, {"text": "BN'12", "start_pos": 211, "end_pos": 216, "type": "DATASET", "confidence": 0.8870135545730591}, {"text": "BN'12", "start_pos": 298, "end_pos": 303, "type": "DATASET", "confidence": 0.9836291670799255}]}, {"text": " Table 3: Final CoNLL '09 test set results. The results not from this work were solicited from the respective authors.", "labels": [], "entities": [{"text": "Final CoNLL '09 test set", "start_pos": 10, "end_pos": 34, "type": "DATASET", "confidence": 0.7790780911842982}]}, {"text": " Table 4: WSJ test set results on Stanford dependencies. Both  the best supervised and semi-supervised results are bolded.", "labels": [], "entities": [{"text": "WSJ test set", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.8234969973564148}]}, {"text": " Table 5: Final English Treebank Union test set results.", "labels": [], "entities": [{"text": "English Treebank Union test set", "start_pos": 16, "end_pos": 47, "type": "DATASET", "confidence": 0.9456775188446045}]}]}