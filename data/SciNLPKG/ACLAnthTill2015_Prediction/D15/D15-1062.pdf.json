{"title": [{"text": "Semantic Relation Classification via Convolutional Neural Networks with Simple Negative Sampling", "labels": [], "entities": [{"text": "Semantic Relation Classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8746419548988342}]}], "abstractContent": [{"text": "Syntactic features play an essential role in identifying relationship in a sentence.", "labels": [], "entities": []}, {"text": "Previous neural network models directly work on raw word sequences or constituent parse trees, thus often suffer from irrelevant information introduced when subjects and objects are in along distance.", "labels": [], "entities": []}, {"text": "In this paper, we propose to learn more robust relation representations from shortest dependency paths through a convolution neu-ral network.", "labels": [], "entities": []}, {"text": "We further take the relation directionality into account and propose a straightforward negative sampling strategy to improve the assignment of subjects and objects.", "labels": [], "entities": [{"text": "relation directionality", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7378571629524231}]}, {"text": "Experimental results show that our method outperforms the state-of-the-art approaches on the SemEval-2010 Task 8 dataset.", "labels": [], "entities": [{"text": "SemEval-2010 Task 8 dataset", "start_pos": 93, "end_pos": 120, "type": "DATASET", "confidence": 0.6349932923913002}]}], "introductionContent": [{"text": "The relation extraction (RE) task can be defined as follows: given a sentence S with a pair of nominals e 1 and e 2 , we aim to identify the relationship between e 1 and e 2 . RE is typically investigated in a classification style, where many features have been proposed, e.g., designed 16 types of features including POS, WordNet, FrameNet, dependency parse features, etc.", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8796980619430542}, {"text": "dependency parse", "start_pos": 342, "end_pos": 358, "type": "TASK", "confidence": 0.7734032273292542}]}, {"text": "Among them, syntactic features are considered to bring significant improvements in extraction accuracy ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9794939756393433}]}, {"text": "Earlier attempts to encode syntactic information are mainly kernel-based methods, such as the convolution tree kernel (, subsequence kernel (, and dependency tree kernel ().", "labels": [], "entities": []}, {"text": "With the recent success of neural networks in natural language processing, different neural network models are proposed to learn syntactic features from raw sequences of words or constituent parse trees (, which have been proved effective, but, often suffer from irrelevant subsequences or clauses, especially when subjects and objects are in a longer distance.", "labels": [], "entities": []}, {"text": "For example, in the sentence, \"The [singer] e1 , who performed three of the nominated songs, also caused a [commotion] e2 on the red carpet\", the who clause is used to modify subject e 1 , but is unrelated to the Cause-Effect relationship between singer and commotion.", "labels": [], "entities": []}, {"text": "Incorporating such information into the model will hurt the extraction performance.", "labels": [], "entities": []}, {"text": "We therefore propose to learn a more robust relation representation from a convolution neural network (CNN) model that works on the simple dependency path between subjects and objects, which naturally characterizes the relationship between two nominals and avoids negative effects from other irrelevant chunks or clauses.", "labels": [], "entities": []}, {"text": "Our second contribution is the introduction of a negative sampling strategy into the CNN models to address the relation directionality, i.e., properly assigning the subject and object within a relationship.", "labels": [], "entities": []}, {"text": "In the above singer example, (singer, commotion) hold the Cause-Effect relation, while (commotion, singer) not.", "labels": [], "entities": []}, {"text": "Previous works () do not fully investigate the differences between subjects and objects in the utterance, and simply transform a (K+1)-relation task into a (2\u00d7K+1) classification task, where 1 is the other relation.", "labels": [], "entities": []}, {"text": "Interestingly, we find that dependency paths naturally offer the relative positions of subjects and objects through the path directions.", "labels": [], "entities": []}, {"text": "In this paper, we propose to model the relation directionality by exploiting the dependency path to learn the assignments of subjects and objects using a straightforward negative sampling method, which adopts the shortest dependency path from the object to the subject as a negative sample.", "labels": [], "entities": [{"text": "relation directionality", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7738334238529205}]}, {"text": "Experimental results show that the negative sampling method significantly improves the performance, and our model outperforms the-state-of-the-art methods on the SemEval-2010 Task 8 dataset.", "labels": [], "entities": [{"text": "SemEval-2010 Task 8 dataset", "start_pos": 162, "end_pos": 189, "type": "DATASET", "confidence": 0.6736776232719421}]}], "datasetContent": [{"text": "We evaluate our model on the, which contains 10,717 annotated examples, including 8,000 instances for training and 2,717 for test.", "labels": [], "entities": []}, {"text": "We randomly sampled 2,182 samples from the training data for validation.", "labels": [], "entities": [{"text": "validation", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.9735365509986877}]}, {"text": "Given a sentence, we first find the shortest dependency path connecting two marked nominals, resulting in two dependency paths corresponding to two opposite subject/object directions, and then make predictions for the two paths, respectively.", "labels": [], "entities": []}, {"text": "We choose the relation other if and only if both predictions are other.", "labels": [], "entities": []}, {"text": "And for the rest cases, we choose the non-other relation with highest confidence as the output, since ideally, fora non-other instance, our model will output the correct label for the right subject/object direction and another label for the wrong direction.", "labels": [], "entities": []}, {"text": "We evaluate our models by macro-averaged F1 using the official evaluation script.", "labels": [], "entities": [{"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9671589732170105}]}, {"text": "We initialized W e with 50-dimensional word vectors trained by.", "labels": [], "entities": []}, {"text": "We tuned the hyper parameters using the development set for each experimental setting.", "labels": [], "entities": []}, {"text": "The hyper parameters include w, n 1 , n 2 , and regularization parameters   for W e , W 1 , W 2 and W 3 . The best setting was obtained with the values: 3, 200, 100, 10 \u22124 , 10 \u22123 , 10 \u22124 and 2 \u00d7 10 \u22123 , respectively.", "labels": [], "entities": []}, {"text": "For fair comparisons, we also add two types of lexical features, WordNet hypernyms and words around nominals, as part of input vector to the final softmax layer.", "labels": [], "entities": []}, {"text": "We can see that our vanilla depLCNN+NS, without extra lexical features, still outperforms, by a large margin, previously reported best systems, MVRNN+ and CNN+, both of which have taken extra lexical features into account, showing that our treatment to dependency path can learn a robust and effective relation representation.", "labels": [], "entities": []}, {"text": "When augmented with similar lexical features, our depLCNN+NS further improves by 1.6%, significantly better than any other systems.", "labels": [], "entities": []}], "tableCaptions": []}