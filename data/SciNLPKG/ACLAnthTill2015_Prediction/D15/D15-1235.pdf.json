{"title": [{"text": "EMNLP versus ACL: Analyzing NLP Research Over Time", "labels": [], "entities": []}], "abstractContent": [{"text": "The conferences ACL (Association for Computational Linguistics) and EMNLP (Empirical Methods in Natural Language Processing) rank among the premier venues that track the research developments in Natural Language Processing and Computational Linguistics.", "labels": [], "entities": [{"text": "EMNLP (Empirical Methods in Natural Language Processing)", "start_pos": 68, "end_pos": 124, "type": "TASK", "confidence": 0.5267930693096585}]}, {"text": "In this paper, we present a study on the research papers of approximately two decades from these two NLP conferences.", "labels": [], "entities": []}, {"text": "We apply keyphrase extraction and corpus analysis tools to the proceedings from these venues and propose probabilistic and vector-based representations to represent the topics published in avenue fora given year.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7540334165096283}]}, {"text": "Next, similarity metrics are studied over pairs of venue representations to capture the progress of the two venues with respect to each other and overtime.", "labels": [], "entities": [{"text": "overtime", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9669370055198669}]}], "introductionContent": [{"text": "Scientific findings in a subject-area are typically published in conferences, journals, patents, and books in that domain.", "labels": [], "entities": []}, {"text": "These research documents constitute valuable resources from the perspective of data mining applications.", "labels": [], "entities": [{"text": "data mining", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.7925720512866974}]}, {"text": "For instance, the citation links among research documents are used in computing bibliometric quantities for authors () whereas topic models on research corpora are used to distinguish between influential and impactful researchers () and to capture temporal topic trends (.", "labels": [], "entities": []}, {"text": "Despite several potential benefits mentioned above and the free availability of most research proceedings in NLP through the ACL Anthology 1 , the topical and temporal aspects of this corpus are yet to be fully studied in current literature.", "labels": [], "entities": [{"text": "ACL Anthology 1", "start_pos": 125, "end_pos": 140, "type": "DATASET", "confidence": 0.9177916248639425}]}, {"text": "In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by.", "labels": [], "entities": [{"text": "ACL", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.927733302116394}, {"text": "EMNLP", "start_pos": 138, "end_pos": 143, "type": "DATASET", "confidence": 0.6706149578094482}]}, {"text": "To the best of our knowledge, we are the first to characterize the developments in the NLP domain using a comparative study of two of its leading publication venues.", "labels": [], "entities": []}, {"text": "Our contributions are summarized below: 1.", "labels": [], "entities": []}, {"text": "We represent the NLP research corpus from approximately two decades as a keyphrasedocument matrix and apply Latent Dirichlet Allocation () to extract coherent topics from it ().", "labels": [], "entities": [{"text": "NLP research corpus", "start_pos": 17, "end_pos": 36, "type": "DATASET", "confidence": 0.8078300356864929}]}, {"text": "2. We propose two novel representations for summarizing the venue proceedings in a given year.", "labels": [], "entities": [{"text": "summarizing", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9640178680419922}]}, {"text": "(1) The probabilistic representation expresses each venue as a probability distribution over topics, whereas (2) the TP-ICP representation captures topics that are the major focus in the venue fora particular year via Topic Proportion (TP) as well as topic importance as measured with inverse corpus proportion (ICP).", "labels": [], "entities": [{"text": "inverse corpus proportion (ICP)", "start_pos": 285, "end_pos": 316, "type": "METRIC", "confidence": 0.9068993131319681}]}, {"text": "3. We apply Jensen-Shannon divergence and cosine similarity on our proposed venue representations to analyze the venues overtime.", "labels": [], "entities": []}, {"text": "Specifically, we ask the following questions: What are the popular topics in ACL and EMNLP in a particular year?", "labels": [], "entities": [{"text": "ACL and EMNLP", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.6506818731625875}]}, {"text": "Is the topical focus in EMNLP different from ACL?", "labels": [], "entities": []}, {"text": "How did the topical focus in each venue changeover time?", "labels": [], "entities": []}, {"text": "Organization: We describe our novel venue representations and the measures used to compare them in Section 2.", "labels": [], "entities": []}, {"text": "The details of our datasets and experiments are presented in Section 3 along with results and observations.", "labels": [], "entities": []}, {"text": "We summarize related research in Section 4 before concluding the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets and setup: We crawled the ACLWeb for research papers from EMNLP and ACL from the year 1996 through 2014 2 using the Java-based crawler, Heritrix 3 . The text from the PDF documents was extracted using the PDFBox software after which simple rules similar to the ones used in CiteSeer () were employed to extract the \"body\" of the research document 5 . The numbers of papers for each year at the end of this process are listed in it appears that the paper \"intake\" in each conference has gone up overall during the last decade although occasionally the increase is due to colocation with related conferences such as IJCNLP and HLT 6 . We construct the keyphrase-document matrix using top-100 keyphrases of each document extracted with ExpandRank.", "labels": [], "entities": [{"text": "EMNLP", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.8817142248153687}, {"text": "IJCNLP", "start_pos": 623, "end_pos": 629, "type": "DATASET", "confidence": 0.9131439924240112}]}, {"text": "The LDA implementation provided in Mallet) was used to extract topics from this matrix.", "labels": [], "entities": [{"text": "Mallet", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.9833797812461853}]}, {"text": "The LDA algorithm was run along with hyperparameter optimization for different numbers of topics between 10 . .", "labels": [], "entities": []}, {"text": "100 in increments of 10.", "labels": [], "entities": []}, {"text": "We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best \"explain\" the corpus.", "labels": [], "entities": []}, {"text": "As indicated by the left plot in this optimum is obtained when the number of topics is 30.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The top words for each topic are shown here after modeling the ACL+EMNLP publications over the years with #topics=30. The topics ranked by their", "labels": [], "entities": [{"text": "ACL+EMNLP publications", "start_pos": 73, "end_pos": 95, "type": "DATASET", "confidence": 0.8762500286102295}]}, {"text": " Table 2: Number of papers for each venue for different years", "labels": [], "entities": []}]}