{"title": [{"text": "SLSA: A Sentiment Lexicon for Standard Arabic", "labels": [], "entities": []}], "abstractContent": [{"text": "Sentiment analysis has been a major area of interest, for which the existence of high-quality resources is crucial.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9733594655990601}]}, {"text": "In Arabic, there is a reasonable number of sentiment lexicons but with major deficiencies.", "labels": [], "entities": []}, {"text": "The paper presents a large-scale Standard Ara-bic Sentiment Lexicon (SLSA) that is publicly available for free and avoids the deficiencies in the current resources.", "labels": [], "entities": [{"text": "Standard Ara-bic Sentiment Lexicon (SLSA)", "start_pos": 33, "end_pos": 74, "type": "TASK", "confidence": 0.6007360390254429}]}, {"text": "SLSA has the highest up-to-date reported coverage.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.691329300403595}, {"text": "coverage", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.6306005716323853}]}, {"text": "The construction of SLSA is based on linking the lexicon of AraMorph with Sen-tiWordNet along with a few heuristics and powerful back-off.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.9397262334823608}]}, {"text": "SLSA shows a relative improvement of 37.8% over a state-of-the-art lexicon when tested for accuracy.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.6373395919799805}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9972851276397705}]}, {"text": "It also outperforms it by an absolute 3.5% of F1-score when tested for sentiment analysis .", "labels": [], "entities": [{"text": "F1-score", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9996097683906555}, {"text": "sentiment analysis", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.963716447353363}]}], "introductionContent": [{"text": "Sentiment analysis is the process of identifying and extracting subjective information using Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9195093810558319}]}, {"text": "It helps identifying opinions and extracting relevant information that lies behind the analyzed data.", "labels": [], "entities": []}, {"text": "Sentiment analysis has received enormous interest in NLP, and in particular in the context of web content.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9454614520072937}]}, {"text": "This includes social media, blogs, discussions, reviews and advertisement.", "labels": [], "entities": []}, {"text": "While there has been extensive work on sentiment analysis in English and other languages of interest, less work has been done for Arabic.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.966727077960968}]}, {"text": "A major concern in Arabic NLP is the morphological complexity of the language along with the limited number of resources, corpora in particular.", "labels": [], "entities": []}, {"text": "The goal of this work is to build a publicly available large-scale Sentiment Lexicon for Standard Arabic (SLSA).", "labels": [], "entities": []}, {"text": "For every lemma and partof-speech (POS) combination that exists in a large Standard Arabic lexicon, SLSA assigns the scores of three sentiment labels: positive, negative and objective, in addition to the English gloss.", "labels": [], "entities": []}, {"text": "The positive and negative scores range between zero and one, while the objective score is defined as 1 -(positive score + negative score).", "labels": [], "entities": []}, {"text": "The existence of SLSA is valuable to the field of Arabic sentiment analysis, which is expected to receive considerable focus during the current decade.", "labels": [], "entities": [{"text": "Arabic sentiment analysis", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.8140219251314799}]}, {"text": "SLSA is the first sentiment lexicon for Arabic to combine the following four strengths.", "labels": [], "entities": []}, {"text": "High coverage SLSA lists the sentiment of about 35,000 lemma and POS combinations, which is the highest coverage reported for Standard Arabic sentiment lexicons.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.4440883696079254}, {"text": "POS", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9627014398574829}]}, {"text": "High quality Unlike many of the current lexicons whose construction is based on semi-supervised learning and heuristic-based approaches, SLSA is not constructed via machine learning models, while the use of heuristics is minimal.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 137, "end_pos": 141, "type": "TASK", "confidence": 0.937402606010437}]}, {"text": "Richness As opposed to sparse surface-based lexicons, SLSA is a lemma-based resource that attaches POS and English gloss information to each lemma, where the information of a lemma is applicable to its inflected forms.", "labels": [], "entities": []}, {"text": "This makes the lexicon more useful when used by other research.", "labels": [], "entities": []}, {"text": "Public Availability SLSA is based on free resources and is publicly available for free.", "labels": [], "entities": [{"text": "Public Availability SLSA", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.4497113029162089}]}], "datasetContent": [{"text": "As mentioned in section 3, no match could be established for 1.2% of AraMorph entries.", "labels": [], "entities": [{"text": "AraMorph", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.9007768630981445}]}, {"text": "We manually investigate these cases more closely.", "labels": [], "entities": []}, {"text": "About 75% of the entries that are not covered in SLSA have lemmas that express Arabic or Islamic subjects that do not have English counterparts such as hamozap (an Arabic name) and kunAfap (an Arabic food).", "labels": [], "entities": []}, {"text": "Another 5% of the cases are countries or nationalities that are not listed in SentiWordNet such as EAjiy (Ivorian).", "labels": [], "entities": [{"text": "EAjiy", "start_pos": 99, "end_pos": 104, "type": "DATASET", "confidence": 0.9005817174911499}]}, {"text": "Additional 2% of the cases are due to misspelled or non-English glosses in AraMorph such as bon appetit.", "labels": [], "entities": [{"text": "AraMorph", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9534959197044373}]}, {"text": "The remaining cases (around 18%) have glosses that do not match any of the synset terms in SentiWordNet.", "labels": [], "entities": []}, {"text": "We then conduct an intrinsic evaluation of SLSA where the performance is compared to that of ArSenL, which is the most similar state-of-theart lexicon (see Section 2).", "labels": [], "entities": [{"text": "SLSA", "start_pos": 43, "end_pos": 47, "type": "TASK", "confidence": 0.8788149952888489}, {"text": "ArSenL", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9167355895042419}]}, {"text": "First, we randomly select 400 (lemma, POS) pairs for the evaluation.", "labels": [], "entities": []}, {"text": "Only four pairs (1%) are not covered in SLSA.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 40, "end_pos": 44, "type": "TASK", "confidence": 0.8335086107254028}]}, {"text": "On the other side, 103 pairs (26%) are absent in ArSenL, which is consistent with the claim of the authors of ArSenL that only 76% of SAMA entries are matched in SentiWordNet.", "labels": [], "entities": [{"text": "ArSenL", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.7934891581535339}]}, {"text": "We then evaluate the random entries that exist in both SLSA and ArSenL (297 entries).", "labels": [], "entities": [{"text": "ArSenL", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.5668625831604004}]}, {"text": "We ask human anno-tators to judge the correctness of the values in the two lexicons.", "labels": [], "entities": []}, {"text": "ArSenL may have several sentiment values for the same entry, each with its own confidence score, so we used the sentiment values with the highest confidence score (averaged in the case of multiple answers).", "labels": [], "entities": [{"text": "ArSenL", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7616792321205139}]}, {"text": "Since judging the values as real numbers is hard for humans, we map the sentiment scores into three classes of intensity (zero, up to 0.55 and above 0.55).", "labels": [], "entities": []}, {"text": "An entry is correct only if the values of the positive and negative polarity classes are both correct.", "labels": [], "entities": []}, {"text": "Each entry was judged by two annotators (without knowing its origin).", "labels": [], "entities": []}, {"text": "They had to discuss and come to an agreement in the cases of disagreement (about 15% of the cases).", "labels": [], "entities": []}, {"text": "SLSA and ArSenL have the exact same scores in 58.2% of the cases, which increases to 83.5% when mapping to the intensity classes.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6511885523796082}, {"text": "ArSenL", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9911094903945923}]}, {"text": "lists the accuracy of a majority baseline (neutral), SLSA and ArSenL for the different POS types 2 . SLSA gives error reductions of 58.7% and 37.8% over the baseline and ArSenL, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995545744895935}, {"text": "ArSenL", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9953847527503967}, {"text": "error reductions", "start_pos": 112, "end_pos": 128, "type": "METRIC", "confidence": 0.9832257032394409}, {"text": "ArSenL", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.9666774868965149}]}, {"text": "About 93% of SLSA errors are cases where the sentiment scores are doubtful in SentiWordNet, while the other errors are due to incorrect glosses in AraMorph.", "labels": [], "entities": [{"text": "AraMorph", "start_pos": 147, "end_pos": 155, "type": "DATASET", "confidence": 0.957214891910553}]}, {"text": "It might happen that an AraMorph entry is incorrectly linked to a SentiWordNet entry causing an error, but we do not see this in any of the manually analyzed data.: Accuracy results of a majority baseline (neutral), SLSA and ArSenL, evaluated on a test set that is covered in both SLSA and ArSenL  We conduct an extrinsic evaluation of SLSA on the task of sentiment analysis where a subjective sentence is classified to be either positive or negative.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9898896217346191}, {"text": "ArSenL", "start_pos": 225, "end_pos": 231, "type": "METRIC", "confidence": 0.9787817597389221}, {"text": "sentiment analysis", "start_pos": 356, "end_pos": 374, "type": "TASK", "confidence": 0.9475781917572021}]}, {"text": "The performance is compared to that of ArSenL.", "labels": [], "entities": [{"text": "ArSenL", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.7821701169013977}]}, {"text": "We use an evaluation setup similar to the one described in () using the corpus developed by.", "labels": [], "entities": []}, {"text": "The corpus involves 400 documents from the Penn Arabic Treebank (part 1 version 3) () where the sentences are tagged as objective, subjective-positive, subjective-negative and subjective-neutral.", "labels": [], "entities": [{"text": "Penn Arabic Treebank (part 1 version", "start_pos": 43, "end_pos": 79, "type": "DATASET", "confidence": 0.9681597181728908}]}, {"text": "The evaluation only involves the sentences tagged as subjective-positive and subjective-negative.", "labels": [], "entities": []}, {"text": "Random 80% of the sentences are used for training, while the rest are left for testing.", "labels": [], "entities": []}, {"text": "We train a Support Vector Machines classifier, through LIBSVM (Chang and Lin, 2011), using sentence vectors of three features representing the averages of the positive scores, negative scores and objective scores of the non-stop words in the sentence divided by the count of the underlying words.", "labels": [], "entities": []}, {"text": "The scores are obtained by querying the lexicon using the lemma and POS information.", "labels": [], "entities": [{"text": "POS", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.8069742321968079}]}, {"text": "We optimize the classification to obtain the best F1-score based on five-fold cross validation on the training set using different SVM kernels and parameters.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9986839890480042}]}, {"text": "Polynomial kernels give the best weighted-average F1-score 3 of 68.6% (using SLSA), which is an absolute 0.2% improvement over linear kernels.", "labels": [], "entities": [{"text": "F1-score 3", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9687788486480713}]}, {"text": "lists the precision, recall and F1-score of a majority baseline (subjective-negative), SLSA and ArSenL.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9996974468231201}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.999351441860199}, {"text": "F1-score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9992559552192688}, {"text": "SLSA", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.92887282371521}, {"text": "ArSenL", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9983099699020386}]}, {"text": "SLSA provides absolute weighted-average F1-score improvements of 22.9% and 3.5% over the baseline and ArSenL, respectively.: Sentiment analysis results of a majority baseline (subjective-negative), SLSA and ArSenL", "labels": [], "entities": [{"text": "SLSA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8009863495826721}, {"text": "F1-score", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9678778648376465}, {"text": "ArSenL", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9853561520576477}, {"text": "ArSenL", "start_pos": 207, "end_pos": 213, "type": "METRIC", "confidence": 0.9510006308555603}]}], "tableCaptions": [{"text": " Table 1: Statistics of SLSA: The counts of the different POS  tags and the percentages of the different sentiment classes.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.9013665914535522}]}, {"text": " Table 2: Examples of SLSA entries; Obj. = Objective. All  scores are rounded for readability.", "labels": [], "entities": [{"text": "SLSA", "start_pos": 22, "end_pos": 26, "type": "TASK", "confidence": 0.9182611107826233}, {"text": "Obj", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9960346817970276}, {"text": "Objective", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.920931875705719}]}, {"text": " Table 3: Accuracy results of a majority baseline (neutral),  SLSA and ArSenL, evaluated on a test set that is covered in  both SLSA and ArSenL", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9929929971694946}, {"text": "ArSenL", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9173535108566284}, {"text": "ArSenL", "start_pos": 137, "end_pos": 143, "type": "DATASET", "confidence": 0.4683123230934143}]}, {"text": " Table 4: Sentiment analysis results of a majority baseline  (subjective-negative), SLSA and ArSenL", "labels": [], "entities": [{"text": "SLSA", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.7158511281013489}, {"text": "ArSenL", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9854971766471863}]}]}