{"title": [{"text": "Conversation Trees: A Grammar Model for Topic Structure in Forums", "labels": [], "entities": []}], "abstractContent": [{"text": "Online forum discussions proceed differently from face-to-face conversations and any single thread on an online forum contains posts on different subtopics.", "labels": [], "entities": []}, {"text": "This work aims to characterize the content of a forum thread as a conversation tree of topics.", "labels": [], "entities": []}, {"text": "We present models that jointly perform two tasks: segment a thread into sub-parts, and assign a topic to each part.", "labels": [], "entities": []}, {"text": "Our core idea is a definition of topic structure using probabilistic grammars.", "labels": [], "entities": [{"text": "definition of topic structure", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.6443189829587936}]}, {"text": "By leveraging the flexibility of two grammar formalisms, Context-Free Grammars and Linear Context-Free Rewriting Systems, our models create desirable structures for forum threads: our topic segmentation is hierarchical, links non-adjacent segments on the same topic, and jointly labels the topic during segmentation.", "labels": [], "entities": []}, {"text": "We show that our models outperform a number of tree generation baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Online forums are commonplace today and used for various purposes: product support and troubleshooting, opining about events and people, and student interaction on online course platforms.", "labels": [], "entities": []}, {"text": "Threads in these forums become long, involve posts from multiple users, and the chronological order of the posts in a thread does not represent a continuous flow of dialog.", "labels": [], "entities": []}, {"text": "Adding structure to these threads is important for tasks such as information extraction, search, and summarization.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8318361639976501}, {"text": "summarization", "start_pos": 101, "end_pos": 114, "type": "TASK", "confidence": 0.9894894957542419}]}, {"text": "One such aspect of structure is topic.", "labels": [], "entities": []}, {"text": "shows a computer-troubleshooting related thread with six posts.", "labels": [], "entities": []}, {"text": "The first post is the troubleshooting question and the remaining posts can be seen as focusing on either of two topics, the driver software (posts p 1 , p 2 , p 5 ) or the speaker hardware p0 Bob: When I play a recorded video on my camera, it looks and sounds fine.", "labels": [], "entities": []}, {"text": "On my computer, it plays at a really fast rate and sounds like Alvin and the Chipmunks!", "labels": [], "entities": []}, {"text": "p1 Kate: I'd find and install the latest audio driver.", "labels": [], "entities": []}, {"text": "p2 Mary: The motherboard supplies the clocks for audio feedback.", "labels": [], "entities": []}, {"text": "So update the audio and motherboard drivers.", "labels": [], "entities": []}, {"text": "p3 Chris: Another fine mess in audio is volume and speaker settings.", "labels": [], "entities": []}, {"text": "p4 Jane: Yes, under speaker settings, look for hardware acceleration.", "labels": [], "entities": []}, {"text": "Turning it off worked for me.", "labels": [], "entities": []}, {"text": "p5 Matt: Audio drivers are at this link.", "labels": [], "entities": []}, {"text": "Rather than just audio drivers, I would also just do all drivers.: Example forum thread conversation (p 3 , p 4 ).", "labels": [], "entities": []}, {"text": "By categorizing posts into such topics, we can provide a useful division of content in a thread and even across multiple threads.", "labels": [], "entities": []}, {"text": "Note that the driver topic is not a contiguous sequence but present in non-adjacent parts, (p 1 , p 2 ) and (p 5 ).", "labels": [], "entities": []}, {"text": "We tackle the problem of joint topic segmentation and topic labeling of forum threads.", "labels": [], "entities": [{"text": "joint topic segmentation", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6677595973014832}, {"text": "topic labeling of forum threads", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.8207494556903839}]}, {"text": "Given a thread's posts in chronological order (the order in which they were posted), we create a phrase structure tree indicating how the posts are grouped hierarchically into subtopics and super-topics.", "labels": [], "entities": []}, {"text": "In these conversation trees, leaves span entire posts.", "labels": [], "entities": []}, {"text": "Each non-terminal identifies the topic characterizing the posts in its span.", "labels": [], "entities": []}, {"text": "Topics are concepts or themes which summarize the content of a group of posts.", "labels": [], "entities": []}, {"text": "Specifically, a topic is a set of words which frequently co-occur in posts which are similar in content and other conversation regularities.", "labels": [], "entities": []}, {"text": "Our key insight in this work is to formalize topic structure using probabilistic grammars.", "labels": [], "entities": [{"text": "formalize topic structure", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6922695438067118}]}, {"text": "We define abase grammar for topic structure of forum threads and refine it to represent finer topics and subtrees.", "labels": [], "entities": []}, {"text": "We learn to predict trees under our grammar based on two formalisms: Probabilistic Context-Free Grammars (PCFG) and Probabilistic Linear Context-Free Rewriting Systems (PLCFRS).", "labels": [], "entities": []}, {"text": "In the PCFG model, a non-terminal spans a contiguous sequence of posts.", "labels": [], "entities": []}, {"text": "In the PLCFRS model, non-terminals are allowed to span discontinuous segments of posts.", "labels": [], "entities": []}, {"text": "We leverage algorithms from probabilistic parsing of natural language sentences and modify them for our domain.", "labels": [], "entities": []}, {"text": "We show that our model performs well and sidesteps a number of limitations of prior topic segmentation approaches.", "labels": [], "entities": []}, {"text": "In particular: \u2022 Our models perform joint topic segmentation and topic labeling while most existing models identify unlabeled segments.", "labels": [], "entities": [{"text": "topic labeling", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.7098356187343597}]}, {"text": "Labeling topics on segments creates richer annotation, and links nonadjacent segments on the same topic.", "labels": [], "entities": []}, {"text": "\u2022 Our grammar-based probabilistic models have two key benefits.", "labels": [], "entities": []}, {"text": "They naturally create tree structures which are considered linguistically suitable for topic segmentation but were difficult to create under previous approaches.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.788445234298706}]}, {"text": "Second, the flexibility of grammars such as PLCFRS allow our models to seamlessly learn to produce trees where nonadjacent segments on the same topic are explicitly linked, an issue that was not addressed before.", "labels": [], "entities": []}, {"text": "We present large-scale experiments on a collection of forum threads from the computertroubleshooting domain.", "labels": [], "entities": []}, {"text": "We show that our grammar models achieve a good balance between identifying when posts should be in the same topic versus a different topic.", "labels": [], "entities": []}, {"text": "These grammar models outperform other tree generation baselines by a significant margin especially on short threads.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the topic segmentation, we develop a node-governance based measure.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7240964472293854}]}, {"text": "Our score compares two conversation trees g and h, where g is the gold-standard tree and h is the hypothesized one.", "labels": [], "entities": []}, {"text": "We assume that g and hare in dependency format, reversing the transformation from \u00a75.1.", "labels": [], "entities": []}, {"text": "We break g (and h) into a set of pairs, for each pair of nodes in the tree (each node is a post in the thread).", "labels": [], "entities": []}, {"text": "For each such pair, p and q, we find their least common ancestor, \u2113(p, q|g) (or \u2113(p, q|h).", "labels": [], "entities": []}, {"text": "If these nodes are in a governing relation (p dominates q or vice versa), then \u2113(p, q) is the dominating node.", "labels": [], "entities": []}, {"text": "We then define the following sets and quantities for \u00b7 \u2208 {g, h}: s 1 (\u00b7) and s 2 (\u00b7) are defined as the size of S 1 (\u00b7) and S 2 (\u00b7), repsectively.", "labels": [], "entities": []}, {"text": "Let g 1 , . .", "labels": [], "entities": []}, {"text": ", g n and h 1 , . .", "labels": [], "entities": []}, {"text": ", h n be a corpus of gold-standard conversation trees and their corresponding hypothesized conversation trees.", "labels": [], "entities": []}, {"text": "Then the evaluation metric we compute is the harmonic mean (Fscore) of the micro-average of the precision for governing (Gp) and non-governing (NG-p) pairs, and recall for governing (G-r) and non-governing (NG-r) pairs.", "labels": [], "entities": [{"text": "harmonic mean (Fscore)", "start_pos": 45, "end_pos": 67, "type": "METRIC", "confidence": 0.7889173865318299}, {"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9953935146331787}, {"text": "recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.9980868101119995}]}, {"text": "For example, G-p is calculated as . Traditional parsing evaluation measures such as constituency bracketting and dependency attachment scores were too local for our purpose.", "labels": [], "entities": [{"text": "parsing evaluation", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.890348494052887}, {"text": "constituency bracketting", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8076397478580475}]}, {"text": "For example, if along chain of posts is placed in a different topic but their local dependencies are maintained, we only penalize one constituent and one node's parent in the constituency and dependency scores respectively.", "labels": [], "entities": []}, {"text": "But the topic segmentation created by this change has several posts placed in the wrong topic branch.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7578608393669128}]}, {"text": "Our scores overcome this problem by considering the relationship between all pairs of posts and also dividing the relationship in the pair as governing or non-governing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on threads with up to 15 posts:  for the grammar models (PCFG and LCFRS) and  comparison systems (See Section 7). 'Ex' is per- centage of fully correct trees and other scores are  from Section 8. Top two Fscores are in bold.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.9253524541854858}, {"text": "Ex'", "start_pos": 133, "end_pos": 136, "type": "METRIC", "confidence": 0.9458369314670563}, {"text": "Fscores", "start_pos": 222, "end_pos": 229, "type": "METRIC", "confidence": 0.9843956232070923}]}, {"text": " Table 3: Results on threads with > 15 posts", "labels": [], "entities": []}]}