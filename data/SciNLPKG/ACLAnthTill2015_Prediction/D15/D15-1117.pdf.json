{"title": [{"text": "Incorporating Trustiness and Collective Synonym/Contrastive Evidence into Taxonomy Construction", "labels": [], "entities": []}], "abstractContent": [{"text": "Taxonomy plays an important role in many applications by organizing domain knowledge into a hierarchy of is-a relations between terms.", "labels": [], "entities": []}, {"text": "Previous works on the taxo-nomic relation identification from text corpora lack in two aspects: 1) They do not consider the trustiness of individual source texts, which is important to filter out incorrect relations from unreliable sources.", "labels": [], "entities": [{"text": "taxo-nomic relation identification from text corpora", "start_pos": 22, "end_pos": 74, "type": "TASK", "confidence": 0.86534317334493}]}, {"text": "2) They also do not consider collective evidence from synonyms and contrastive terms, where synonyms may provide additional supports to taxonomic relations, while contrastive terms may contradict them.", "labels": [], "entities": []}, {"text": "In this paper, we present a method of taxonomic relation identification that incorporates the trustiness of source texts measured with such techniques as PageR-ank and knowledge-based trust, and the collective evidence of synonyms and con-trastive terms identified by linguistic pattern matching and machine learning.", "labels": [], "entities": [{"text": "taxonomic relation identification", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.8093558549880981}, {"text": "linguistic pattern matching", "start_pos": 268, "end_pos": 295, "type": "TASK", "confidence": 0.7001522183418274}]}, {"text": "The experimental results show that the proposed features can consistently improve performance up to 4%-10% of F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.923163115978241}]}], "introductionContent": [{"text": "Taxonomies which serve as backbone of structured knowledge are useful for many applications such as question answering () and document clustering).", "labels": [], "entities": [{"text": "question answering", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.9151815176010132}, {"text": "document clustering", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7428028583526611}]}, {"text": "Even though there are many hand-crafted, well-structured taxonomies publicly available, including WordNet, OpenCyc), and Freebase (, they are incomplete in specific domains, and it is time-consuming to manually extend them or create new ones.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.9704466462135315}, {"text": "Freebase", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.9579700827598572}]}, {"text": "There is thus a need for automatically extracting taxonomic relations from text corpora to construct/extend taxonomies.", "labels": [], "entities": []}, {"text": "Previous works on the task of taxonomy construction capture information about potential taxonomic relations between concepts, rank the candidate relations based on the captured information, and integrate the highly ranked relations into a taxonomic structure.", "labels": [], "entities": [{"text": "taxonomy construction capture information about potential taxonomic relations between concepts", "start_pos": 30, "end_pos": 124, "type": "TASK", "confidence": 0.8399430871009826}]}, {"text": "They utilize such information as hypernym patterns (e.g. A is a B, A such as B) (, syntactic dependency, definition sentences (), co-occurrence (, syntactic contextual similarity (, and sibling relations ().", "labels": [], "entities": []}, {"text": "They, however, lack in the three following aspects: 1) Trustiness: Not all sources are trustworthy (e.g. gossip, forum posts written by non-experts) (.", "labels": [], "entities": []}, {"text": "The trustiness of source texts is important in taxonomic relation identification because evidence from unreliable sources can be incorrect.", "labels": [], "entities": [{"text": "taxonomic relation identification", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.9052608211835226}]}, {"text": "For example, the invalid taxonomic relation between \"American chameleon\" and \"chameleon\" is mistakenly more popular in the Web than the valid taxonomic relation between \"American chameleon\" and \"lizard\", and statistical methods without considering the trustiness may incorrectly extract the invalid relation instead of the latter.", "labels": [], "entities": []}, {"text": "However, to the best of our knowledge, no previous work considered this aspect.", "labels": [], "entities": []}, {"text": "2) Synonyms: A concept maybe expressed in multiple ways, for example with synonyms.", "labels": [], "entities": []}, {"text": "The previous works mostly assumed that a term represents an independent concept, and did not combine information about a concept, which is expressed with multiple synonyms.", "labels": [], "entities": []}, {"text": "The lack of evidence from synonyms may hamper the ranking of candidate taxonomic relations.", "labels": [], "entities": []}, {"text": "combined synonyms into a concept, but only for those from WordNet, called synsets.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9550796747207642}]}, {"text": "3) Contrastive terms: We observe that if two terms are often contrasted (e.g. A but not B, A is different from B) (), they may not have a taxonomic relation.", "labels": [], "entities": []}, {"text": "In this paper, we present a method based on the state-of-the-art method), which incorporates the trustiness of source texts and the collective evidence from synonyms/contrastive terms.", "labels": [], "entities": []}, {"text": "rank candidate taxonomic relations based on such evidence as hypernym patterns, WordNet, and syntactic contextual similarity, where the pattern matches and the syntactic contexts are found from the Web by using a Web search engine.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9170342087745667}]}, {"text": "First, we calculate the trustiness score of each data source with the four following weights: importance (if it is linked by many pages), popularity (if it is visited by many users), authority (if it is from a creditable Web site) and accuracy (if it has many facts).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 235, "end_pos": 243, "type": "METRIC", "confidence": 0.9993771910667419}]}, {"text": "We integrate this score to the work of () so that evidence for taxonomic relations from unreliable sources is discarded.", "labels": [], "entities": []}, {"text": "Second, we identify synonyms of two terms (t 1 , t 2 ), whose taxonomic relation is being scrutinized, by matching such queries as \"t 1 also known as\" against the Web to find t 1 's synonyms next to the query matches (e.g. tin \"t 1 also known as t\").", "labels": [], "entities": []}, {"text": "We then collect the evidence for all taxonomic relations between t 1 and t 2 , where ti is either ti or its synonym (i \u2208 {1, 2}), and combine them to calculate the evidence score of the candidate taxonomic relation between t 1 and t 2 . Similarly, for each pair of two terms (t 1 , t 2 ), we collect their contrastive evidence by matching such queries as \"t 1 is not a type oft 2 \" against the Web, and use them to proportionally decrease the evidence score for taxonomic relation between contrasting terms.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method for taxonomy construction against the following collections of six domains: \u2022 Artificial Intelligence (AI) domain: The corpus consists of 4,976 papers extracted from the IJCAI proceedings from 1969 to 2014 and the ACL archives from year 1979 to 2014.", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.8350016176700592}, {"text": "IJCAI proceedings", "start_pos": 193, "end_pos": 210, "type": "DATASET", "confidence": 0.9104250073432922}, {"text": "ACL archives", "start_pos": 237, "end_pos": 249, "type": "DATASET", "confidence": 0.8170822262763977}]}, {"text": "\u2022 Finance domain: The corpus consists of 1,253 papers extracted from the freely available collection of \"Journal of Financial Economics\" from 1995 to 2012 and from \"Review Of Finance\" from 1997 to 2012.", "labels": [], "entities": []}, {"text": "\u2022 Virus domain: We submit the query \"virus\" to PUBMED search engine and retrieve the first 20,000 abstracts as the corpus of the virus domain.", "labels": [], "entities": [{"text": "PUBMED search engine", "start_pos": 47, "end_pos": 67, "type": "DATASET", "confidence": 0.8838317592938741}]}, {"text": "\u2022 Animals, Plants and Vehicles domains: Collections of Web pages crawled by using the bootstrapping algorithm described by.", "labels": [], "entities": []}, {"text": "We report the results of two experiments in this section: (1) Evaluating the construction of new taxonomies for Finance and AI domains (Section 4.2), and (2) comparing with the curated databases' sub-hierarchies.", "labels": [], "entities": []}, {"text": "We compare our approach with other three state-of-the-art methods in the literature, i.e. (, (Navigli et al., 2011) and () (Section 4.3).", "labels": [], "entities": []}, {"text": "In addition, for Animal domain, we also compare with the reported performance of, a recent work to construct taxonomy using belief propagation.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.7088064700365067}]}, {"text": "We evaluate automatically constructed taxonomies for four domains (i.e. Animal, Plant, Vehicle, Virus) against the corresponding subhierarchies of curated databases.", "labels": [], "entities": []}, {"text": "For Animal, Plant and Vehicle domains, we use WordNet as the gold standards, whereas for Virus domain, we use MeSH sub-hierarchy of virus as the reference.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.9752439856529236}]}, {"text": "Note that in this comparison, to be fair, we change our algorithm to avoid using WordNet in identifying taxonomic relations (i.e. SIWN algorithm), and we only use the exact string-matching comparison without WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9499710202217102}, {"text": "WordNet", "start_pos": 208, "end_pos": 215, "type": "DATASET", "confidence": 0.9654926061630249}]}, {"text": "The evaluation uses the following measures: To understand the individual contribution of the three introduced features (i.e. trustiness, synonym, contrast), we also evaluate our method only with one of the three features each time, as well as with all the three features (denoted as \"Combined\").", "labels": [], "entities": []}, {"text": "Our combined method achieves significantly better performance than the previous state-of-theart methods in terms of F-measure and Recall (ttest, p-value < 0.05) for all the four domains.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9827881455421448}, {"text": "Recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9990535378456116}]}, {"text": "For Animal domain, it also shows higher performance than the reported performance of.", "labels": [], "entities": []}, {"text": "In addition, the proposed method improves the baseline (i.e.) up to 4%-10% of F-measure.", "labels": [], "entities": [{"text": "baseline", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9753608703613281}, {"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9857556223869324}]}, {"text": "Furthermore, we find that the three features have different contribution to the performance improvement.", "labels": [], "entities": []}, {"text": "The trustiness feature contributes to the improvement on both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9996765851974487}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.998828113079071}]}, {"text": "The synonym feature has the tendency of improving the recall further than the trustiness, whereas the contrastive evidence improves the precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9994263648986816}, {"text": "precision", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9985703229904175}]}, {"text": "Note that we discussed these different contributions of the features in the Introduction.", "labels": [], "entities": []}, {"text": "We evaluate the individual methods for trustiness measurement and synonymy identification described in Sections 3.2.1 and 3.3.1.", "labels": [], "entities": [{"text": "trustiness measurement", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.6991824805736542}, {"text": "synonymy identification", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.8356246650218964}]}, {"text": "For this purpose, we evaluate our system only with one of the individual methods at a time (i.e. importance, popularity, authority and accuracy for trustiness measure, and dictionary, pattern matching, and machine learning methods for synonymy identification).", "labels": [], "entities": [{"text": "popularity", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.969871997833252}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9228910207748413}, {"text": "synonymy identification", "start_pos": 235, "end_pos": 258, "type": "TASK", "confidence": 0.8502835035324097}]}, {"text": "As summarized in, the \"Importance\" and \"Accuracy\" methods for trustiness measurement based on PageRank and IE systems, respectively, have more contribution than the others.", "labels": [], "entities": [{"text": "Importance", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9721593856811523}, {"text": "Accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9972035884857178}]}, {"text": "Similarly, the experiment results indicate that the \"Machine learning\" method has the most contribution among the three methods of synonymy identification.", "labels": [], "entities": [{"text": "synonymy identification", "start_pos": 131, "end_pos": 154, "type": "TASK", "confidence": 0.9275044798851013}]}, {"text": "In addition, we also examine the interdependence of the four introduced aspects of trustiness by running the system with the combination of only two aspects, Importance and Accuracy.", "labels": [], "entities": [{"text": "Importance", "start_pos": 158, "end_pos": 168, "type": "METRIC", "confidence": 0.9926909804344177}, {"text": "Accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9801252484321594}]}, {"text": "The results in all domains show that when combining only the Importance and Accuracy, the system almost achieves the same performance to that of the combined system with all four criteria, except for the Plant domain.", "labels": [], "entities": [{"text": "Importance", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9876109957695007}, {"text": "Accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9815888404846191}]}, {"text": "It can be explained as the Importance aspect (which is expressed as the PageRank score) may subsume the Popularity and Authority aspects.", "labels": [], "entities": [{"text": "Importance", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.8745629191398621}]}, {"text": "Another interesting point is that the performance of Accuracy, which is solely based on the local information from the website, when applied individually, is almost the same with that of Importance which is based on the distributed information.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9961734414100647}, {"text": "Importance", "start_pos": 187, "end_pos": 197, "type": "METRIC", "confidence": 0.8797340989112854}]}, {"text": "It shows that the method of ranking of the sites based on the knowledge-based facts can achieve the effectiveness as good as the traditional ranking method using PageRank score.", "labels": [], "entities": []}, {"text": "On the other hand, the true taxonomic relation between 'bat' and 'flying fox' is not identified by the baseline, mainly due to the rare mention of this relation in the Web.", "labels": [], "entities": []}, {"text": "However, our proposed method can recognize this relation because of two reasons: (1) 'flying fox' has many synonyms such as 'fruit bat', 'pteropus', 'kalong', and 'megabat', and there are much evidence that these synonyms are kinds of 'bat' (i.e. using the collective synonym evidence).", "labels": [], "entities": []}, {"text": "(2) The evidence for the taxonomic relation between 'fly-ing fox' and 'bat', though rare, is from trusted sites 9 which are maintained by scientists.", "labels": [], "entities": []}, {"text": "Thus, the trustiness feature helps to boost the evidence score for this relation over the threshold value.", "labels": [], "entities": []}, {"text": "Specifically, the average trustiness score of LSP method (i.e. (AvgT rust(C Web (bat, flying f ox)) + AvgT rust(C Web (f lying fox, bat)))), 2.84, is higher than the average in total, 0.90.", "labels": [], "entities": [{"text": "AvgT", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9537571668624878}]}, {"text": "We further investigate on 256 taxonomic relations that were missed by the baseline but correctly identified by the proposed method.", "labels": [], "entities": []}, {"text": "The average Score LSP and the average Score SCS of the relations by the baseline are 0.35 and 0.60, respectively, while those by the proposed method are 1.17 and 0.82, respectively.", "labels": [], "entities": [{"text": "average Score LSP", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.865303615729014}, {"text": "average Score SCS", "start_pos": 30, "end_pos": 47, "type": "METRIC", "confidence": 0.8478251298268636}]}, {"text": "We thus find that the proposed method is more effective in correctly improving the LSP method than the SCS method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experiment result for finance and AI do- mains. P stands for Precision, and N indicates the  number of extracted relations.", "labels": [], "entities": [{"text": "Precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9913071990013123}]}, {"text": " Table 2: Experiment results for animal and plant  domains. P stands for Precision, R Recall, and F  F-score. The unit is %.", "labels": [], "entities": [{"text": "Precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9981001019477844}, {"text": "R", "start_pos": 84, "end_pos": 85, "type": "METRIC", "confidence": 0.9557086825370789}, {"text": "Recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.564444363117218}, {"text": "F", "start_pos": 98, "end_pos": 99, "type": "METRIC", "confidence": 0.9915701150894165}, {"text": "F-score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.5148103833198547}]}, {"text": " Table 3: Experiment results for vehicle and virus  domains. P stands for Precision, R Recall, and F  F-score. The unit is %.", "labels": [], "entities": [{"text": "Precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9968065023422241}, {"text": "R", "start_pos": 85, "end_pos": 86, "type": "METRIC", "confidence": 0.9465038180351257}, {"text": "Recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.5097895264625549}, {"text": "F", "start_pos": 99, "end_pos": 100, "type": "METRIC", "confidence": 0.9922479391098022}, {"text": "F-score", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.5092235803604126}]}, {"text": " Table 4: Contribution of individual trustiness mea- sures and collective synonym evidence in terms of  F-measure. Imp stands for Important and Accu  stands for Accuracy", "labels": [], "entities": [{"text": "mea- sures", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.6149976849555969}, {"text": "F-measure", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9928787350654602}, {"text": "Imp", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.9592162370681763}, {"text": "Accu  stands for Accuracy", "start_pos": 144, "end_pos": 169, "type": "METRIC", "confidence": 0.8093613237142563}]}]}