{"title": [{"text": "Named entity recognition with document-specific KB tag gazetteers", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6300991376241049}]}], "abstractContent": [{"text": "We consider a novel setting for Named Entity Recognition (NER) where we have access to document-specific knowledge base tags.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.8049387236436208}]}, {"text": "These tags consist of a canonical name from a knowledge base (KB) and entity type, but are not aligned to the text.", "labels": [], "entities": []}, {"text": "We explore how to use KB tags to create document-specific gazetteers at inference time to improve NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9402726888656616}]}, {"text": "We find that this kind of supervision helps recognise organisations more than standard wide-coverage gazetteers.", "labels": [], "entities": []}, {"text": "Moreover, augmenting document-specific gazetteers with KB information lets users specify fewer tags for the same performance, reducing cost.", "labels": [], "entities": []}], "introductionContent": [{"text": "NER is the task of identifying names in text and assigning them a type (e.g. person, location, organisation, miscellaneous).", "labels": [], "entities": [{"text": "NER is the task of identifying names in text and assigning them a type (e.g. person, location, organisation, miscellaneous)", "start_pos": 0, "end_pos": 123, "type": "Description", "confidence": 0.7540011915067831}]}, {"text": "State-of-the-art supervised approaches use models that incorporate a name's form, its linguistic context and its compatibility with known names.", "labels": [], "entities": []}, {"text": "These models rely on large manually-annotated corpora, specifying name spans and types.", "labels": [], "entities": []}, {"text": "These are vital for training models, but it is laborious and expensive to label every occurrence of a name in a document.", "labels": [], "entities": []}, {"text": "We consider a non-standard setting where, for each document, we have metadata in the form of document-specific knowledge base tags.", "labels": [], "entities": []}, {"text": "A KB tag is a canonical name, that is an identifier in a KB (e.g. a Wikipedia title), and an entity type.", "labels": [], "entities": []}, {"text": "While these tags have a correct type assigned for at least one context, they are not aligned to phrases in the text, and may not share the same form as all of their mentions (e.g. we may seethe tag United Nations for the mention UN).", "labels": [], "entities": []}, {"text": "We also assume that each tag matches at least one mention in the document, but do not specify wherein the document the mention is.", "labels": [], "entities": []}, {"text": "There are many sources of KB tags, such as manual entity indexing for news stories or data extracted from personalised knowledge stores.", "labels": [], "entities": [{"text": "manual entity indexing for news stories", "start_pos": 43, "end_pos": 82, "type": "TASK", "confidence": 0.7266894380251566}]}, {"text": "For example, the New York Times Annotated Corpus contains more than 1.5M articles \"manually tagged by library scientists with tags drawn from a normalized indexing vocabulary of people, organizations, locations and topic descriptors\".", "labels": [], "entities": [{"text": "Times Annotated Corpus", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.6939850250879923}]}, {"text": "Names and types are also present in large quantities of financial news stories from Bloomberg (, in the form of linked names of companies and people.", "labels": [], "entities": []}, {"text": "Document-level tags maybe quicker for annotators to apply than the usual method of marking spans in text, and are thus a cheap form of supervision.", "labels": [], "entities": []}, {"text": "It is hard to make strong comparisons to the standard NER task, as KB tags can be considered partial, unaligned gold-standard supervision -so fully supervised models should perform better, the question is by how much and why.", "labels": [], "entities": [{"text": "NER task", "start_pos": 54, "end_pos": 62, "type": "TASK", "confidence": 0.8680771589279175}]}, {"text": "This paper explores effective ways to use KB tags for improving NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9734155535697937}]}, {"text": "We use the CoNLL 2003 English NER dataset, annotated with Wikipedia links.", "labels": [], "entities": [{"text": "CoNLL 2003 English NER dataset", "start_pos": 11, "end_pos": 41, "type": "DATASET", "confidence": 0.949638569355011}]}, {"text": "This allows us to simulate a set of KB tags for each document in the TRAIN, TESTA and TESTB splits of the dataset.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.5595635175704956}, {"text": "TESTA", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.5930984020233154}]}, {"text": "We use a document's KB tags to build a documentspecific gazetteers which we use in addition to standard features fora conditional random field (CRF) model ().", "labels": [], "entities": []}, {"text": "We compare against wide-coverage gazetteers, which score 89.85% F-score on TESTA.", "labels": [], "entities": [{"text": "F-score", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9993240833282471}, {"text": "TESTA", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.7397036552429199}]}, {"text": "Assuming access to all possible KB tags, the upper bound for KB tag models is substantially better at 92.85% F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.9899318218231201}]}, {"text": "KB tags help NER accuracy across all entity types, but provide relatively better supervision for organisation entities than wide-coverage gazetteers.", "labels": [], "entities": [{"text": "NER", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9834989905357361}, {"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.8873887062072754}]}, {"text": "The benefit of KB tags comes from their type information, which is required for good performance.", "labels": [], "entities": []}, {"text": "We also examine how performance degrades as we use fewer KB tags, simulating the use-case where a busy knowledge worker spends less time annotating.", "labels": [], "entities": []}, {"text": "We find that KB augmentation means we require fewer tags to reach the same performance, which reduces the cost of obtaining KB tags.", "labels": [], "entities": [{"text": "KB augmentation", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7782318890094757}]}, {"text": "We show how KB tags can be exploited as a useful complement to traditional NER supervision.", "labels": [], "entities": [{"text": "NER supervision", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.8162021636962891}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for CoNLL 2003 TESTA and TESTB. We report P/R/F for all tags and per-type F-scores.  Methods starting with \"+\" build on the standard CRF by repairing or adding features.", "labels": [], "entities": [{"text": "CoNLL 2003 TESTA", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.8364297747612}, {"text": "TESTB", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.672989547252655}, {"text": "P/R/F", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.8267255902290345}]}]}