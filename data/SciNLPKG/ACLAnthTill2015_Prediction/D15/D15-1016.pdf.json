{"title": [{"text": "Cross-Lingual Sentiment Analysis using modified BRAE", "labels": [], "entities": [{"text": "Cross-Lingual Sentiment Analysis", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7577934265136719}, {"text": "BRAE", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.5387933254241943}]}], "abstractContent": [{"text": "Cross-Lingual Learning provides a mechanism to adapt NLP tools available for label rich languages to achieve similar tasks for label-scarce languages.", "labels": [], "entities": []}, {"text": "An efficient cross-lingual tool significantly reduces the cost and effort required to manually annotate data.", "labels": [], "entities": []}, {"text": "In this paper, we use the Recursive Autoencoder architecture to develop a Cross Lingual Sentiment Analysis (CLSA) tool using sentence aligned corpora between a pair of resource rich (En-glish) and resource poor (Hindi) language.", "labels": [], "entities": [{"text": "Cross Lingual Sentiment Analysis (CLSA)", "start_pos": 74, "end_pos": 113, "type": "TASK", "confidence": 0.7466738734926496}]}, {"text": "The system is based on the assumption that semantic similarity between different phrases also implies sentiment similarity in majority of sentences.", "labels": [], "entities": []}, {"text": "The resulting system is then analyzed on a newly developed Movie Reviews Dataset in Hindi with labels given on a rating scale and compare performance of our system against existing systems.", "labels": [], "entities": [{"text": "Movie Reviews Dataset", "start_pos": 59, "end_pos": 80, "type": "DATASET", "confidence": 0.7254248658816019}]}, {"text": "It is shown that our approach significantly outperforms state of the art systems for Sentiment Analysis, especially when labeled data is scarce.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.9632706046104431}]}], "introductionContent": [{"text": "Sentiment Analysis is a NLP task that deals with extraction of opinion from apiece of text on a topic.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9245418608188629}, {"text": "extraction of opinion from apiece of text on a topic", "start_pos": 49, "end_pos": 101, "type": "TASK", "confidence": 0.8365764796733857}]}, {"text": "This is used by a large number of advertising and media companies to get a sense of public opinion from their reviews.", "labels": [], "entities": []}, {"text": "The ever increasing user generated content has always been motivation for sentiment analysis research, but majority of work has been done for English Language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.9718731343746185}]}, {"text": "However, in recent years, there has been emergence of increasing amount of text in Hindi on electronic sources but NLP Frameworks to process this data is sadly miniscule.", "labels": [], "entities": []}, {"text": "A major cause for this is the lack of annotated datasets in Indian Languages.", "labels": [], "entities": []}, {"text": "One solution is to create cross lingual tools between a resource rich and resource poor language that exploit large amounts of unlabeled data and sentence aligned corpora that are widely available on web through bilingual newspapers, magazines, etc.", "labels": [], "entities": []}, {"text": "Many different approaches have been identified to perform Cross Lingual Tasks but they depend on the presence of MT-System or Bilingual Dictionaries between the source and target language.", "labels": [], "entities": []}, {"text": "In this paper, we use Bilingually Constrained Recursive Auto-encoder (BRAE) given by () to perform Cross Lingual sentiment analysis.", "labels": [], "entities": [{"text": "Bilingually Constrained Recursive Auto-encoder (BRAE)", "start_pos": 22, "end_pos": 75, "type": "METRIC", "confidence": 0.8102443388530186}, {"text": "Cross Lingual sentiment analysis", "start_pos": 99, "end_pos": 131, "type": "TASK", "confidence": 0.8364267945289612}]}, {"text": "Major Contributions of this paper are as follows: First, We develop anew Rating scale based Movie Review Dataset for Hindi.", "labels": [], "entities": [{"text": "Movie Review Dataset", "start_pos": 92, "end_pos": 112, "type": "DATASET", "confidence": 0.7208918333053589}]}, {"text": "Second, a general framework to perform Cross Lingual Classification tasks is developed by modifying the architecture and training procedure for BRAE model.", "labels": [], "entities": [{"text": "Cross Lingual Classification tasks", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.7865947186946869}, {"text": "BRAE", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.46783390641212463}]}, {"text": "This model exploits the fact that phrases in two languages, that share same semantic meaning, can be used to learn language independent semantic vector representations.", "labels": [], "entities": []}, {"text": "These embeddings can further be fine-tuned using labeled dataset in English to capture enough class information regarding Resource poor language.", "labels": [], "entities": []}, {"text": "We train the resultant framework on English-Hindi Language pair and evaluate it against state of the art SA systems on existing and newly developed dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments on two kind of sentiment analysis systems : (1) that gives +ve/-ve polarity to each review and (2) assigns ratings in range 1 -4 to each review.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.9258577823638916}]}, {"text": "For pre-training the word embeddings and RAE Training, we used HindMonoCorp 0.5() with 44.49M sentences (787M Tokens) and English Gigaword Corpus.", "labels": [], "entities": [{"text": "RAE", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.6892709732055664}, {"text": "HindMonoCorp 0.5", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.9339908063411713}, {"text": "English Gigaword Corpus", "start_pos": 122, "end_pos": 145, "type": "DATASET", "confidence": 0.868658443291982}]}, {"text": "For Cross Training, we used the bilingual sentence-aligned data from HindEnCorp) label.", "labels": [], "entities": [{"text": "Cross Training", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8273258209228516}, {"text": "HindEnCorp) label", "start_pos": 69, "end_pos": 86, "type": "DATASET", "confidence": 0.9261787931124369}]}, {"text": "We crawled the Hindi Movie Reviews Website 2 to obtain 2945 movie reviews.", "labels": [], "entities": [{"text": "Hindi Movie Reviews Website 2", "start_pos": 15, "end_pos": 44, "type": "DATASET", "confidence": 0.8411312460899353}]}, {"text": "Each Movie Review on this site is assigned rating in range 1 to 4 by at least three reviewers.", "labels": [], "entities": [{"text": "Movie Review on this site", "start_pos": 5, "end_pos": 30, "type": "DATASET", "confidence": 0.8904815196990967}]}, {"text": "We first discard reviews that whose sum of pairwise difference of ratings is greater than two.", "labels": [], "entities": []}, {"text": "The final rating for each review is calculated by taking the average of the ratings and rounding up to nearest integer.", "labels": [], "entities": []}, {"text": "The fraction of Reviews obtained in ratings 1-4 are respectively.", "labels": [], "entities": [{"text": "Reviews", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.9274725317955017}]}, {"text": "Average length of reviews is 84 words.", "labels": [], "entities": []}, {"text": "For +ve/-ve polarity based system, we group the reviews with ratings {1, 2} as negative and {3, 4} as positive.", "labels": [], "entities": []}, {"text": "We used following Baselines for Sentiment Analysis in Hindi : Majority class: Assign the most frequent class in the training set (Rating:3 / Polarity:+ve) Bag-of-words: Softmax regression on Binary Bag-of-words We also compare our system with state of the art Monolingual and Cross Lingual System for Sentiment Analysis in Hindi as described by) using the same experimental setup.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9269502460956573}, {"text": "Sentiment Analysis", "start_pos": 301, "end_pos": 319, "type": "TASK", "confidence": 0.8713960349559784}]}, {"text": "The best systems in each category given by them are as below: WordNet Based: Using Hindi-SentiWordNet 3 , each word in a review was mapped to corresponding synset identifiers.", "labels": [], "entities": []}, {"text": "These identifiers were used as features for creating sentiment classifiers based on Binary/Multiclass SVM trained on bag of words representation using libSVM library.", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.7993973195552826}]}, {"text": "Cross Lingual (XL) Clustering Based: Here, joint clustering was performed on unlabeled bilingual corpora which maximizes the joint likelihood of monolingual and cross-lingual factors..", "labels": [], "entities": []}, {"text": "For details, please refer the work of.", "labels": [], "entities": []}, {"text": "Each word in a review was then mapped to its cluster identifier and used as features in an SVM.", "labels": [], "entities": []}, {"text": "Our approaches Basic RAE: We use the Semi-Supervised RAE based classification where we first trained a standard RAE using Hindi monolingual corpora, then applied supervised training procedure as described in).", "labels": [], "entities": []}, {"text": "This approach doesn't use bilingual corpora, but is dependent on amount of labeled data in Hindi.", "labels": [], "entities": []}, {"text": "BRAE-U: We neither include penalty term, nor fix the transformations weights in our proposed system.", "labels": [], "entities": [{"text": "BRAE-U", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.972165584564209}]}, {"text": "BRAE-P: We only include the penalty term but allow the transformation weights to be modified in proposed system.", "labels": [], "entities": [{"text": "BRAE-P", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.973218560218811}]}, {"text": "BRAE-F: We add the penalty term and fix the transformation weights during back propagation in proposed system.", "labels": [], "entities": [{"text": "BRAE-F", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9788586497306824}]}, {"text": "We combined the text data from all English Datasets (English Gigaword + HindEnCorp English Portion + IBMD11 + Scale Dataset) described above to train the word embeddings using Word2Vec toolkit and RAE.", "labels": [], "entities": [{"text": "English Datasets", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.8253546953201294}, {"text": "IBMD11 + Scale Dataset", "start_pos": 101, "end_pos": 123, "type": "DATASET", "confidence": 0.664705827832222}]}, {"text": "Similarly, we combined text data from all Hindi Datasets (HindMonoCorp + HindiEnCorp Hindi Portion + RHMR) to train word embeddings and RAE for Hindi.", "labels": [], "entities": [{"text": "Hindi Datasets", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.7055028676986694}, {"text": "HindMonoCorp + HindiEnCorp Hindi Portion + RHMR", "start_pos": 58, "end_pos": 105, "type": "DATASET", "confidence": 0.665099880525044}, {"text": "RAE", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.9461373686790466}]}, {"text": "We used MOSES Toolkit () to obtain high quality bilingual phrase pairs from HindEnCorp to train our BRAE model.", "labels": [], "entities": [{"text": "HindEnCorp", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.9698851108551025}, {"text": "BRAE", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.49634572863578796}]}, {"text": "After removing the duplicates, 364.3k bilingual phrase pairs were obtained with lengths ranging from 1-6, since bigger phrases reduced the performance of the system in terms of Joint Error of BRAE model.", "labels": [], "entities": [{"text": "Joint Error of BRAE", "start_pos": 177, "end_pos": 196, "type": "METRIC", "confidence": 0.5621853768825531}]}, {"text": "We randomly split our RHMR dataset into 10 segments and report the average of 10-fold cross validation accuracies for each setting for both Ratings and Polarity classifiers.", "labels": [], "entities": [{"text": "RHMR dataset", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.8268916606903076}]}, {"text": "We also report 5-fold cross validation accuracy on Standard Movie Reviews Dataset (hereby referred as SMRD) given by ( which contains 125 +ve and 125 -ve reviews in Hindi.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.8592565655708313}, {"text": "Standard Movie Reviews Dataset", "start_pos": 51, "end_pos": 81, "type": "DATASET", "confidence": 0.8296937495470047}]}, {"text": "The dataset can be obtained at http://www.cfilt.iitb.ac.in/Resources.html.", "labels": [], "entities": []}, {"text": "Since this project is about reducing dependence on annotated datasets, we experiment on how accuracy varies with labeled training dataset (RHMR) size.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9986748695373535}]}, {"text": "To perform this, we train our model in 10% increments (150 examples) of training set size (each class sampled in proportion of original set).", "labels": [], "entities": []}, {"text": "For each size, we sample the data 10 times with replacement and trained the model.", "labels": [], "entities": []}, {"text": "For each sample, we calculated 10-fold cross validation accuracy as described above.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9724252820014954}]}, {"text": "Final accuracy for each size was calculated by averaging the accuracies obtained on all 10 samples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9995436072349548}]}, {"text": "Similar kind of evaluation is done for all other Baselines explored.", "labels": [], "entities": []}, {"text": "In subsequent section, the word 'significant' implies that the results were statistically significant (p < 0.05) with paired T-test", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracies obtained for various Exper- imental Settings. Model are trained on complete  labeled training datasets", "labels": [], "entities": []}]}