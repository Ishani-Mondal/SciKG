{"title": [{"text": "Classifying Tweet Level Judgements of Rumours in Social Media", "labels": [], "entities": [{"text": "Classifying Tweet Level Judgements of Rumours in Social Media", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.8063635494973924}]}], "abstractContent": [{"text": "Social media is a rich source of rumours and corresponding community reactions.", "labels": [], "entities": []}, {"text": "Rumours reflect different characteristics, some shared and some individual.", "labels": [], "entities": []}, {"text": "We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task.", "labels": [], "entities": [{"text": "classifying tweet level judgements of rumours", "start_pos": 28, "end_pos": 73, "type": "TASK", "confidence": 0.865768680969874}]}, {"text": "Both supervised and unsupervised domain adaptation are considered , in which tweets from a rumour are classified on the basis of other annotated rumours.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8111386001110077}]}, {"text": "We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.", "labels": [], "entities": [{"text": "England riots", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.7696113884449005}]}], "introductionContent": [{"text": "There is an increasing need to interpret and act upon rumours spreading quickly through social media, especially in circumstances where their veracity is hard to establish.", "labels": [], "entities": [{"text": "interpret and act upon rumours spreading quickly through social media", "start_pos": 31, "end_pos": 100, "type": "TASK", "confidence": 0.5920965254306794}]}, {"text": "For instance, during an earthquake in Chile rumours spread through Twitter that a volcano had become active and that there was a tsunami warning in Valparaiso (.", "labels": [], "entities": []}, {"text": "Other examples, from the riots in England in 2011, were that rioters were going to attack Birmingham's children hospital and that animals had escaped from the zoo (.", "labels": [], "entities": []}, {"text": "Social scientists () analysed manually a sample of tweets expressing different judgements towards rumours and categorised them manually in supporting, denying or questioning.", "labels": [], "entities": []}, {"text": "The goal here is to carryout tweet-level judgement classification automatically, in order to assist in (near) real-time rumour monitoring by journalists and authorities).", "labels": [], "entities": [{"text": "tweet-level judgement classification", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.7557979424794515}]}, {"text": "In addition, information about tweet-level judgements has been used as a first step for early rumour detection by set of other already annotated rumours.", "labels": [], "entities": [{"text": "rumour detection", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.762681782245636}]}, {"text": "Previous work on this problem either considered unrealistic settings ignoring temporal ordering and rumour identities) or proposed regular expressions as a solution (.", "labels": [], "entities": []}, {"text": "We expect posts expressing similar opinions to exhibit many similar characteristics across different rumours.", "labels": [], "entities": []}, {"text": "Based on the assumption of a common underlying linguistic signal, we build a transfer learning system that labels newly emerging rumours for which we have little or no annotated data.", "labels": [], "entities": []}, {"text": "Results demonstrate that Gaussian Processbased multitask learning allows for significantly improved performance.", "labels": [], "entities": []}, {"text": "The novel contributions of this paper are: 1.", "labels": [], "entities": []}, {"text": "Formulating the problem of classifying judgements of rumours in both supervised and unsupervised domain adaptation settings.", "labels": [], "entities": [{"text": "classifying judgements of rumours", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.8953529894351959}]}, {"text": "2. Showing how a multi-task learning approach outperforms singletask methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "We can observe that methods perform on a level similar to majority vote, outperforming it only slightly.", "labels": [], "entities": []}, {"text": "This indicates how difficult the LOO task is, when no annotated target rumour tweets are available.", "labels": [], "entities": [{"text": "LOO task", "start_pos": 33, "end_pos": 41, "type": "TASK", "confidence": 0.6530087888240814}]}, {"text": "shows accuracy fora range of methods as the number of tweets about the target rumour used for training increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9994893074035645}]}, {"text": "Most notably, performance increases from 70% to around 80%, after only 10 annotated tweets from the target rumour become available, as compared to the results on unseen rumours from.", "labels": [], "entities": []}, {"text": "However, as the amount of target rumour increases, performance does not increase further, which suggests that even only 10 human-annotated tweets are enough to achieve significant performance benefits.", "labels": [], "entities": []}, {"text": "Note also how the use of reference rumours is very important, as methods using only the target rumour obtain accuracy similar to the Majority vote classifier (GP Brown and GP BOW).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9988527297973633}, {"text": "GP", "start_pos": 172, "end_pos": 174, "type": "DATASET", "confidence": 0.5163175463676453}, {"text": "BOW", "start_pos": 175, "end_pos": 178, "type": "METRIC", "confidence": 0.721978485584259}]}, {"text": "The top performing methods are GPCIM and GPPooled, where use of Brown clusters consistently improves results for both methods over BOW, irrespective of the number of tweets about the target rumour annotated for training.", "labels": [], "entities": [{"text": "GPCIM", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.9058319330215454}, {"text": "GPPooled", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.9467886686325073}, {"text": "BOW", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.6044616103172302}]}, {"text": "Moreover, GPICM is better than GPPooled both with Brown and BOW features and GPCIM with Brown is ultimately the best performing of all.", "labels": [], "entities": [{"text": "GPICM", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.8577146530151367}, {"text": "GPPooled", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9467946290969849}, {"text": "BOW", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9760079979896545}]}, {"text": "In order to analyse the importance of Brown clusters, Automatic Relevance Determination (ARD) is used) for the best performing GPICM Brown in the LPO scenario.", "labels": [], "entities": [{"text": "Automatic Relevance Determination (ARD)", "start_pos": 54, "end_pos": 93, "type": "METRIC", "confidence": 0.9268325467904409}]}, {"text": "Only the case where the first 10 tweets are used for training is considered, since it already   performs very well.", "labels": [], "entities": []}, {"text": "Using ARD, we learn a separate length-scale for each feature, thus establishing their importance.", "labels": [], "entities": []}, {"text": "The weights learnt for different clusters are averaged over the 7 rumours and the top 5 Brown clusters for each label are shown in.", "labels": [], "entities": []}, {"text": "We can see that clusters around the words fake and bullshit turnout to be important for the denying class, and true for both supporting and questioning classes.", "labels": [], "entities": []}, {"text": "This reinforces our hypothesis that common linguistic cues can be found across multiple rumours.", "labels": [], "entities": []}, {"text": "Note how punctuation proves important as well, since clusters ? and ! are also very prominent.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Counts of tweets with supporting, deny- ing or questioning labels in each rumour collec- tion.", "labels": [], "entities": []}, {"text": " Table 4: Top 5 Brown clusters, each shown  with a representative word.  For further  details please see the cluster definitions  at  http://www.ark.cs.cmu.edu/  TweetNLP/cluster_viewer.html.", "labels": [], "entities": []}]}