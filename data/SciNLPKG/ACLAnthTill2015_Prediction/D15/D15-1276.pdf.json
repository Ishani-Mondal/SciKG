{"title": [{"text": "Morphological Analysis for Unsegmented Languages using Recurrent Neural Network Language Model", "labels": [], "entities": [{"text": "Morphological Analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8142475783824921}]}], "abstractContent": [{"text": "We present anew morphological analysis model that considers semantic plausi-bility of word sequences by using a recurrent neural network language model (RNNLM).", "labels": [], "entities": []}, {"text": "In unsegmented languages, since language models are learned from automatically segmented texts and inevitably contain errors, it is not apparent that conventional language models contribute to morphological analysis.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 193, "end_pos": 215, "type": "TASK", "confidence": 0.7456043064594269}]}, {"text": "To solve this problem, we do not use language models based on raw word sequences but use a semantically generalized language model, RNNLM, in morphological analysis.", "labels": [], "entities": []}, {"text": "In our experiments on two Japanese corpora, our proposed model significantly outper-formed baseline models.", "labels": [], "entities": []}, {"text": "This result indicates the effectiveness of RNNLM in morphological analysis.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.8981398642063141}]}], "introductionContent": [{"text": "In contrast to space-delimited languages like English, word segmentation is the first and most crucial step for natural language processing (NLP) in unsegmented languages like Japanese, Chinese, and Thai ().", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7481004893779755}, {"text": "natural language processing (NLP)", "start_pos": 112, "end_pos": 145, "type": "TASK", "confidence": 0.8189878761768341}]}, {"text": "Word segmentation is usually performed jointly with related analysis: POS tagging for Chinese, and POS tagging and lemmatization (analysis of inflected words) for Japanese.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6864679902791977}, {"text": "POS tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.7575390934944153}, {"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.7166855782270432}]}, {"text": "Morphological analysis including word segmentation has been widely and actively studied, and for example, Japanese word segmentation accuracy is in the high 90s.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9096174240112305}, {"text": "word segmentation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7371387332677841}, {"text": "Japanese word segmentation", "start_pos": 106, "end_pos": 132, "type": "TASK", "confidence": 0.5905901789665222}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.95607990026474}]}, {"text": "However, we often observe that strange outputs of downstream NLP applications such as machine translation and question answering come from incorrect word segmentations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8235511779785156}, {"text": "question answering", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.8648075461387634}]}, {"text": "For example, the state-of-the-art and popular Japanese morphological analyzers, JUMAN) and MeCab () both analyze \" (foreigner's right to vote)\" not into the correct segmentation of (1a), but into the incorrect and awkward segmentation of (1b).", "labels": [], "entities": [{"text": "MeCab", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.9076608419418335}]}, {"text": "JUMAN is a rule-based morphological analyzer, defining word-to-word (including inflection) connectivities and their scores.", "labels": [], "entities": [{"text": "JUMAN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9101792573928833}]}, {"text": "MeCab is a supervised morphological analyzer, learning the probabilities of word/POS/inflection sequence from an annotated corpus of tens of thousands of sentences.", "labels": [], "entities": [{"text": "MeCab", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9317604899406433}]}, {"text": "Both systems, however, cannot realize semantically appropriate analysis, and often produce totally strange outputs like the above.", "labels": [], "entities": []}, {"text": "This paper proposes a semantically appropriate morphological analysis method for unsegmented languages using a language model.", "labels": [], "entities": []}, {"text": "For unsegmented languages, morphological analysis and language modeling form a chicken-and-egg problem.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.7283996194601059}, {"text": "language modeling", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7089950293302536}]}, {"text": "That is, if high-quality morphological analysis is available, we can learn a high-quality language model from a morphologically analyzed large corpus.", "labels": [], "entities": []}, {"text": "On the other hand, if a high-quality language model is available, we can achieve highquality morphological analysis by looking fora segmented word sequence with a large language model score.", "labels": [], "entities": [{"text": "highquality morphological analysis", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.7459579308827718}]}, {"text": "However, even if we learn a language model from a corpus analyzed by a certain level of morphological analyzer, the language model is affected by the analysis errors of the morphological analyzer and it is no practical use for the improvement of the morphological analyzer.", "labels": [], "entities": []}, {"text": "A language model trained by incorrectly segmented \" (foreign)/ (carrot)/ (regime)\" just supports that incorrect segmentation.", "labels": [], "entities": []}, {"text": "The point of the paper is that we have tackled the chicken-and-egg problem, not by using a lan-  guage model of raw word sequences, but by using a semantically generalized language model based on word embeddings, RNNLM (Recurrent Neural Network Language Model) ().", "labels": [], "entities": []}, {"text": "The RNNLM is trained on an automatically analyzed corpus often million sentences, which possibly includes incorrect segmentations such as \" (foreign)/ (carrot)/ (regime).\"", "labels": [], "entities": [{"text": "RNNLM", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.8608759641647339}]}, {"text": "However, on semantically generalized level, it is an unnatural semantic sequence like nation vegetable politics.", "labels": [], "entities": []}, {"text": "Since the state-ofthe-art morphological analyzer achieves the high accuracy, it does not often produce incorrect analyses which support such a semantically strange sequence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9985906481742859}]}, {"text": "This would prefer analysis toward semantically appropriate word sequences.", "labels": [], "entities": []}, {"text": "When a morphological analyzer utilizes such a generalized and reasonable language model, it can penalize strange segmentations like \" (foreign)/ (carrot)/ (regime),\" leading to better accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9952551126480103}]}, {"text": "We furthermore retrain RNNLM using an annotated corpus of manually segmented 45k sentences, which further improves morphological analysis.", "labels": [], "entities": [{"text": "RNNLM", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8232731819152832}]}], "datasetContent": [{"text": "In our experiments, we used the Kyoto University Text Corpus () and Kyoto University Web Document Leads Corpus () as manually tagged corpora.", "labels": [], "entities": [{"text": "Kyoto University Text Corpus", "start_pos": 32, "end_pos": 60, "type": "DATASET", "confidence": 0.9582399427890778}, {"text": "Kyoto University Web Document Leads Corpus", "start_pos": 68, "end_pos": 110, "type": "DATASET", "confidence": 0.941569040218989}]}, {"text": "We randomly chose 2,000 sentences from each corpus for test data, and 500 sentences for development data.", "labels": [], "entities": []}, {"text": "We used the remaining part of the corpora as training data to train our base model and retrain RNNLM.", "labels": [], "entities": [{"text": "RNNLM", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.8593219518661499}]}, {"text": "In total, we used 45,000 sentences for training.", "labels": [], "entities": []}, {"text": "For comparative purposes, we used the following four baselines: the Japanese morphological analyzer JUMAN, the supervised morphological analyzer MeCab, the base model, and a model using a conventional language model.", "labels": [], "entities": [{"text": "Japanese morphological analyzer JUMAN", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.41799773275852203}, {"text": "MeCab", "start_pos": 145, "end_pos": 150, "type": "DATASET", "confidence": 0.825102686882019}]}, {"text": "For this language model, we built a trigram language model with Kneser-Ney smoothing using SRILM) from the same automatically segmented corpus.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.6883270740509033}]}, {"text": "The language model is modified to have an interpolation parameter \u03b1 and length penalty for OOV, L p . We set the beam width to 5 by preliminary experiments.", "labels": [], "entities": [{"text": "length", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9646527767181396}, {"text": "OOV", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9909766912460327}]}, {"text": "We also set a constant penalty for OOV words (C p ) as 5, which is the default value in the implementation of.", "labels": [], "entities": []}, {"text": "We tuned the parameters of our proposed model and the baseline model (\u03b1 and L p ) and the parameters of language models using grid search on the development data.", "labels": [], "entities": []}, {"text": "We set \u03b1 = 0.3, L p =1.5 for the proposed model (\" Base + RNNLM retrain \").", "labels": [], "entities": []}, {"text": "We measured the performance of the baseline models and the proposed model by F-value of word segmentation and F-value of joint evaluation of word segmentation and POS tagging.", "labels": [], "entities": [{"text": "F-value", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9966040849685669}, {"text": "word segmentation", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.6806537359952927}, {"text": "F-value", "start_pos": 110, "end_pos": 117, "type": "METRIC", "confidence": 0.9968234300613403}, {"text": "word segmentation", "start_pos": 141, "end_pos": 158, "type": "TASK", "confidence": 0.6708411425352097}, {"text": "POS tagging", "start_pos": 163, "end_pos": 174, "type": "TASK", "confidence": 0.7126361727714539}]}, {"text": "We calculated F-value for the two corpora (news and web) and the merged corpus (all).", "labels": [], "entities": [{"text": "F-value", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.998663067817688}]}, {"text": "We used the bootstrapping method () to test statistical significance between proposed models and other models.", "labels": [], "entities": []}, {"text": "Suppose we have a test set T that includes N sentences.", "labels": [], "entities": []}, {"text": "The method repeatedly creates M new test sets by resampling N sentences with replacement from T . We calculate the F-value of each model on M + 1 test sets including T , and then we have M + 1 score differences.", "labels": [], "entities": [{"text": "F-value", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9960761666297913}]}, {"text": "From the scores, we calculate the 95% confidence interval.", "labels": [], "entities": [{"text": "95% confidence interval", "start_pos": 34, "end_pos": 57, "type": "METRIC", "confidence": 0.711296871304512}]}, {"text": "If the interval does not overlap with zero, the two models are considered as statistically significantly different.", "labels": [], "entities": []}, {"text": "In our evaluation, M is set to 2,000.", "labels": [], "entities": [{"text": "M", "start_pos": 19, "end_pos": 20, "type": "METRIC", "confidence": 0.9962438344955444}]}, {"text": "lists the results of our proposed model and the baseline models.", "labels": [], "entities": []}, {"text": "Our proposed model (\"Base + RNNLM retrain \") significantly outperforms all the baseline models and \"Base + RNNLM,\" which does not use retraining.", "labels": [], "entities": []}, {"text": "In particular, we achieved a large improvement for segmentation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.9853971600532532}]}, {"text": "This can be attributed to the use of RNNLM that was learned based on lemmatized word sequence without POS tags.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for test datasets.  *  means the score of \"Base + RNNLM retrain \" is significantly improved  from that of all other models.", "labels": [], "entities": [{"text": "Base + RNNLM retrain", "start_pos": 61, "end_pos": 81, "type": "METRIC", "confidence": 0.7405954897403717}]}]}