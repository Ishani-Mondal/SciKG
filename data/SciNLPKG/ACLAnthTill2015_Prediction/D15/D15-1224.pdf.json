{"title": [{"text": "From the Virtual to the Real World: Referring to Objects in Real-World Spatial Scenes", "labels": [], "entities": [{"text": "Referring to Objects in Real-World Spatial Scenes", "start_pos": 36, "end_pos": 85, "type": "TASK", "confidence": 0.7387212514877319}]}], "abstractContent": [{"text": "Predicting the success of referring expressions (RE) is vital for real-world applications such as navigation systems.", "labels": [], "entities": [{"text": "referring expressions (RE)", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.6479836523532867}]}, {"text": "Traditionally , research has focused on studying Referring Expression Generation (REG) in virtual, controlled environments.", "labels": [], "entities": [{"text": "Referring Expression Generation (REG)", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.8597334623336792}]}, {"text": "In this paper, we describe a novel study of spatial references from real scenes rather than virtual.", "labels": [], "entities": []}, {"text": "First, we investigate how humans describe objects in open, uncontrolled scenarios and compare our findings to those reported in virtual environments.", "labels": [], "entities": []}, {"text": "We show that REs in real-world scenarios differ significantly to those in virtual worlds.", "labels": [], "entities": [{"text": "REs", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9372555017471313}]}, {"text": "Second , we propose a novel approach to quantifying image complexity when complete annotations are not present (e.g. due to poor object recognition capabitlities), and third, we present a model for success prediction of REs for objects in real scenes.", "labels": [], "entities": [{"text": "success prediction of REs", "start_pos": 198, "end_pos": 223, "type": "TASK", "confidence": 0.5666913390159607}]}, {"text": "Finally, we discuss implications for Natural Language Generation (NLG) systems and future directions.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.8126582900683085}]}], "introductionContent": [{"text": "REG has attracted considerable interest in the NLG community over the past 20 years).", "labels": [], "entities": [{"text": "REG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8034809827804565}, {"text": "NLG community", "start_pos": 47, "end_pos": 60, "type": "DATASET", "confidence": 0.8495630323886871}]}, {"text": "While initially, the standard evaluation metric for REG was human-likeness, as compared to human corpora similarity as in TUNA (, the field has moved onto evaluating REG effectiveness by measuring task success in virtual interactive environments).", "labels": [], "entities": [{"text": "REG", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9741590023040771}]}, {"text": "Virtual environments however eliminate real-world uncertainty, such object recognition errors or cluttered scenes.", "labels": [], "entities": [{"text": "object recognition", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7670706510543823}]}, {"text": "In this paper, we investigate whether the lessons learnt in virtual environments can be transferred to real-world scenes.", "labels": [], "entities": []}, {"text": "We consider the case where we are uncertain about the scene itself, i.e. we assume that the complexity of the scene is hidden and we are interested in identifying a specific object, and thus our work differs from approaches that generate descriptions for images such as (.", "labels": [], "entities": []}, {"text": "Related work has focused on computer generated objects, crafts (, or small objects in a simple background.", "labels": [], "entities": []}, {"text": "One notable exception is the recent work by, who investigate referring expressions of objects in \"complex photographs of real-world cluttered scenes\".", "labels": [], "entities": []}, {"text": "They report that REs are heavily influenced by the object type.", "labels": [], "entities": []}, {"text": "Here, we are interested in studying REs for visual objects in urban scenes.", "labels": [], "entities": []}, {"text": "As the success of a RE is heavily dependent on the complexity of the scene as well as its linguistic features, we are interested in modelling and thus predicting the success of a RE.", "labels": [], "entities": []}, {"text": "Initially, this paper presents and analyses a novel, real-world corpus REAL (to be released) -\"Referring Expression Anchored Language\" (Section 2), and compares the findings to those reported in virtual worlds (.", "labels": [], "entities": []}, {"text": "We then provide a detailed analysis of how syntactic and semantic features contribute to the success of REs (Sections 4.1, 4.2, 4.3), accounting for unobservable latent variables, such as the complexity of the visual scene (as described in Section 3).", "labels": [], "entities": [{"text": "REs", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.9502889513969421}]}, {"text": "Finally, we summarise our work and discuss the implications of our work for NLG systems (Section 5).", "labels": [], "entities": []}, {"text": "The dataset and models will be released.", "labels": [], "entities": []}], "datasetContent": [{"text": "There were 190 participants recruited (age between 16 to 71).", "labels": [], "entities": []}, {"text": "Each participant was presented with an urban image (, where the target object was outlined by a yellow box, and was asked to describe the target using free text.", "labels": [], "entities": []}, {"text": "After completing a (self-specified) number of tasks, participants were then asked to validate descriptions provided by other participants by clicking on the object using previously unseen images.", "labels": [], "entities": []}, {"text": "Overall, 76.2% of human descriptions provided were successfully identified.", "labels": [], "entities": []}, {"text": "For the experiments reported in following sections, we summarised answers categorised as 'incorrect', 'ambitious' and 'not found' as unsuccessful.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The REAL corpus", "labels": [], "entities": [{"text": "REAL", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.6526436805725098}]}, {"text": " Table 2: Descriptive statistics for GIVE-2 and  REAL", "labels": [], "entities": [{"text": "GIVE-2", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.4589657187461853}, {"text": "REAL", "start_pos": 49, "end_pos": 53, "type": "TASK", "confidence": 0.5286617279052734}]}, {"text": " Table 3: Statistics regarding the linguistic fea- tures in successful vs unsuccessful referring ex- pressions. (* denotes significant difference at p <  0.05).", "labels": [], "entities": []}, {"text": " Table 4: Models and their fit.", "labels": [], "entities": []}, {"text": " Table 5: Frequency of semantic frames in REAL  vs. GIVE-2 (* denotes significant differences at  p < 0.05, \u03c7 2 test).", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9148834943771362}]}]}