{"title": [{"text": "Touch-Based Pre-Post-Editing of Machine Translation Output", "labels": [], "entities": [{"text": "Machine Translation Output", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7383202612400055}]}], "abstractContent": [{"text": "We introduce pre-post-editing, possibly the most basic form of interactive translation , as a touch-based interaction with iteratively improved translation hypotheses prior to classical post-editing.", "labels": [], "entities": []}, {"text": "We report simulated experiments that yield very large improvements on classical evaluation metrics (up to 21 BLEU) as well as on a parameterized variant of the TER metric that takes into account the cost of matching/touching tokens, confirming the promising prospects of the novel translation scenarios offered by our approach.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9985864162445068}, {"text": "TER metric", "start_pos": 160, "end_pos": 170, "type": "METRIC", "confidence": 0.9694169759750366}]}], "introductionContent": [{"text": "As shown by oracle studies (, Statistical Machine Translation (SMT) systems produce results that are of significantly lower quality than what could be produced from their available resources.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.8157738248507181}]}, {"text": "As a pragmatic solution, human intervention is commonly used for improving automatic draft translations, in so-called post-editing (PE), but is also studied earlier in the translation process in a variety of interactive strategies, including e.g. completion assistance and local translation choices (e.g. ().", "labels": [], "entities": [{"text": "draft translations", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.6397823095321655}]}, {"text": "Although interactive machine translation does facilitate the work of the SMT system in certain situations by allowing it to make efficient use of knowledge contributed by the human translator, postediting has been shown to remain a faster alternative ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7397065758705139}, {"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9911803603172302}]}, {"text": "Nevertheless, this activity usually requires complex intervention from an expert translator.", "labels": [], "entities": []}, {"text": "In this work we reduce interaction with an SMT system to its most basic form: similarly to what a human translator is likely to do when first reading a draft translation to post-edit, we require a user to simply spot those segments of a draft translation that can participate in an acceptable translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9833909273147583}]}, {"text": "The corresponding information is then used by a SMT system in a soft way to improve the draft translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9930516481399536}, {"text": "draft translation", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.8873309195041656}]}, {"text": "This process maybe iteratively repeated as long as enough improvements are obtained, and terminates with classical post-editing on the obtained translation, hence we dub it prepost-editing (PPE).", "labels": [], "entities": []}, {"text": "We resort to simulated prepost-editing and post-editing, as in other works), to measure translation performance on some available reference translation using both classical metrics and a variant of the TER metric (), where, essentially, the cost of a token matching operation is a parameterized fraction of the cost of the other token edit operations.", "labels": [], "entities": [{"text": "TER metric", "start_pos": 202, "end_pos": 212, "type": "METRIC", "confidence": 0.9423801600933075}]}, {"text": "With the implementation of appropriate strategies in the SMT system, we show under reasonable assumptions that this approach has the potential to significantly reduce the amount of human effort required to obtain a final translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9919844269752502}]}, {"text": "In the remainder of this article, we describe the technical details of pre-post-editing (Section 2), report experiments conducted on two translation directions and two domains (Section 3), and finally discuss our proposal and introduce our future work (Section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "Classical MT evaluation metrics cannot take into account the interactive cost of PPE, and thus do source c' est la r\u00e9pons\u00e8 a une nouvelle prise de conscience selon laquelle les entreprises chinoises sont indispensables\u00e0 indispensables`indispensables\u00e0 la survi\u00e9 economique de Taiwan PPE#0 this is the answer to anew awareness that Chinese companies are essential to the economic survival of Taiwan PPE#1 it is the response to anew awareness that Chinese firms are essential to Taiwan's economic survival . PPE#2 it is the reply to anew awareness that Chinese enterprises is essential to Taiwan's economic survival . PPE#3 it is responding to anew awareness that Chinese businesses is essential to Taiwan's economic survival . PPE#4 it is responding to anew awareness that Chinese business is essential to Taiwan's economic survival . target ref it is responding to anew awareness that Chinese business is essential to Taiwan's economic survival .: Example of a pre-post-edition trace for French to English translation (using the news task, cf. Section 3) using a given implicit target reference translation for simulating pre-post-editing and postediting.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8859136700630188}]}, {"text": "Each newly touched phrase is indicated with a green background.", "labels": [], "entities": []}, {"text": "Phrases with a gray background indicate previously touched phrases but their tokens remain individually touchable by the user.", "labels": [], "entities": []}, {"text": "for both tasks LM 2.5B -6B: Data used in this work.", "labels": [], "entities": [{"text": "LM 2.5B -6B", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.8245858401060104}]}, {"text": "not allow us to make direct comparisons with PE.", "labels": [], "entities": [{"text": "PE", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.5173762440681458}]}, {"text": "We thus adapt the TER () metric, which typically uses 4 types of token edits: substitution (s), insertion (i), deletion (d) and shift (f ).", "labels": [], "entities": [{"text": "TER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9209491610527039}]}, {"text": "While these edit types all have a (debatable) uniform cost of 1, the operation of matching (m) a correct token is ignored.", "labels": [], "entities": []}, {"text": "We posit that this operation is in fact performed by a human translator during PE (at the minimum, by recognizing and skipping tokens), and that it can be directly compared to our touchbased selection of tokens for PPE.", "labels": [], "entities": [{"text": "PE", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.7440704703330994}]}, {"text": "However, we cannot at this stage of our work provide a realistic cost value for this operation, and so we introduce a match cost parameter \u03b1, and use the following as our PPE-aware metric: where r is the number of tokens in the reference translation.", "labels": [], "entities": [{"text": "match cost parameter \u03b1", "start_pos": 118, "end_pos": 140, "type": "METRIC", "confidence": 0.8963216245174408}]}, {"text": "Note that a null value for \u03b1 makes TER PPE correspond to TER, while a value of 1 would indicate that a token matching/touch (m) is e.g. as costly as a token rewriting (s).", "labels": [], "entities": [{"text": "TER PPE", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.8911744356155396}, {"text": "TER", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9916309714317322}]}, {"text": "We anticipate that a realistic value for \u03b1 given a reasonably skilled user should be rather small, but we will provide TER PPE results for the full range [0, 1].", "labels": [], "entities": [{"text": "TER", "start_pos": 119, "end_pos": 122, "type": "METRIC", "confidence": 0.9989964365959167}, {"text": "PPE", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.632066547870636}]}, {"text": "To validate our approach, we initially used a simulated post-editing paradigm) in which non-post-edited reference translations are used in lieu of human post-editions.", "labels": [], "entities": []}, {"text": "Results on TER () and BLEU (), tuning on both metrics, are provided in Tables 2 (news) and 3 (medical).", "labels": [], "entities": [{"text": "TER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9960089921951294}, {"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9979547262191772}]}, {"text": "First, we observe that whatever the metric and the task, the first iteration of PPE always yields a significant improvement over the Moses initial system (e.g. up to +9.8 BLEU and -8.2 TER for news fr\u2192en).", "labels": [], "entities": [{"text": "PPE", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.5434890389442444}, {"text": "BLEU", "start_pos": 171, "end_pos": 175, "type": "METRIC", "confidence": 0.9967846870422363}, {"text": "TER", "start_pos": 185, "end_pos": 188, "type": "METRIC", "confidence": 0.9716980457305908}]}, {"text": "Unsurprisingly, tuning on a metric yields better results for the same metric for the first iteration; however, we note that this is not always true for the TER metric at later iterations (cf. news en\u2192fr).", "labels": [], "entities": []}, {"text": "More generally, tuning on the TER metric results in lower improvements for news, which are mostly concentrated on the first iterations; as systems tuned on BLEU have been found to produce better translations than systems tuned on TER (, only BLEU tuning was used for medical.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9920828342437744}, {"text": "BLEU", "start_pos": 242, "end_pos": 246, "type": "METRIC", "confidence": 0.9978358149528503}]}, {"text": "Improvements follow an interesting pattern over PPE iterations: for instance, on news fr\u2192en, BLEU scores steadily increase after each new touch-based iteration and reach again of +21.1 BLEU and -12.3 TER over the initial Moses translation after 5 PPE iterations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9995063543319702}, {"text": "BLEU", "start_pos": 185, "end_pos": 189, "type": "METRIC", "confidence": 0.9978129863739014}, {"text": "TER", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9917606115341187}]}, {"text": "Results are very comparable on both language pairs and both domains, e.g. gains of +12.1 BLEU and -9.7 TER are obtained on fr\u2192en medical.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9973541498184204}, {"text": "TER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9831331372261047}]}, {"text": "The lesser amplitude of the gains obtained after 5 iterations maybe attributed to the higher ini-: PPE results on the medical task.", "labels": [], "entities": [{"text": "ini-: PPE", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.6434826403856277}]}, {"text": "Figures 4 and 5 show how our TER PPE metric varies for different values of our \u03b1 parameter (recall that \u03b1 = 0 corresponds to TER).", "labels": [], "entities": [{"text": "TER PPE metric", "start_pos": 29, "end_pos": 43, "type": "METRIC", "confidence": 0.8824291626612345}, {"text": "TER", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.9949648380279541}]}, {"text": "Essentially, whatever the value of \u03b1, we observe that any iteration of PPE dominates PE (Moses 1-best), but with a tendency to become as costly as PE for high, but probably unrealistic values of \u03b1.", "labels": [], "entities": [{"text": "PE", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9695695638656616}]}, {"text": "Tuning with BLEU allows us to bring regular improvements as the number of iteration increases, while tuning with TER makes the amplitude of the gains decrease faster.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9982289671897888}, {"text": "TER", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9976329803466797}]}, {"text": "Furthermore, results shown in point out the complementarity between negative models (negative-lm and negative-pt) and positive models (positive-lm and positive-pt), with a drop of almost 10 BLEU points compared to the corresponding configuration using all models when removing one type of models on both translation directions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 190, "end_pos": 194, "type": "METRIC", "confidence": 0.9990932941436768}]}, {"text": "The language models (negative-lm and positive-lm) seem to play a more important role during PPE than the phrase tables (negative-pt and positive-pt), with a drop of 9.6 BLEU points on news fr\u2192en when removing the language models against a significantly lower drop of 4.4 BLEU points when removing the phrase tables.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9976170063018799}, {"text": "BLEU", "start_pos": 271, "end_pos": 275, "type": "METRIC", "confidence": 0.998384952545166}]}], "tableCaptions": [{"text": " Table 1: Data used in this work.", "labels": [], "entities": []}, {"text": " Table 2: PPE results on the news task.", "labels": [], "entities": [{"text": "PPE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6182703375816345}]}, {"text": " Table 3: PPE results on the medical task.", "labels": [], "entities": [{"text": "PPE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7257153987884521}]}, {"text": " Table 4: PPE results for the news task after 5 iterations using various configurations.", "labels": [], "entities": [{"text": "PPE", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.5211730599403381}]}]}