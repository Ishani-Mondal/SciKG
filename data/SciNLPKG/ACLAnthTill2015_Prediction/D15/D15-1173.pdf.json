{"title": [{"text": "Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction", "labels": [], "entities": [{"text": "Subgraph Feature Extraction", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.652146448691686}]}], "abstractContent": [{"text": "We explore some of the practicalities of using random walk inference methods , such as the Path Ranking Algorithm (PRA), for the task of knowledge base completion.", "labels": [], "entities": [{"text": "Path Ranking Algorithm (PRA)", "start_pos": 91, "end_pos": 119, "type": "METRIC", "confidence": 0.7026699831088384}, {"text": "knowledge base completion", "start_pos": 137, "end_pos": 162, "type": "TASK", "confidence": 0.6639883120854696}]}, {"text": "We show that the random walk probabilities computed (at great expense) by PRA provide no discernible benefit to performance on this task, so they can safely be dropped.", "labels": [], "entities": []}, {"text": "This allows us to define a simpler algorithm for generating feature matrices from graphs, which we call subgraph feature extraction (SFE).", "labels": [], "entities": [{"text": "subgraph feature extraction (SFE", "start_pos": 104, "end_pos": 136, "type": "TASK", "confidence": 0.7153869152069092}]}, {"text": "In addition to being conceptually simpler than PRA, SFE is much more efficient, reducing computation by an order of magnitude , and more expressive, allowing for much richer features than paths between two nodes in a graph.", "labels": [], "entities": [{"text": "PRA", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9364897608757019}, {"text": "SFE", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9200257658958435}]}, {"text": "We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB.", "labels": [], "entities": [{"text": "mean average", "start_pos": 119, "end_pos": 131, "type": "METRIC", "confidence": 0.8879094123840332}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.6749598383903503}, {"text": "NELL KB", "start_pos": 206, "end_pos": 213, "type": "DATASET", "confidence": 0.688262939453125}]}], "introductionContent": [{"text": "Knowledge bases (KBs), such as Freebase (), NELL ( , and DBPedia () contain large collections of facts about things, people, and places in the world.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9707394242286682}]}, {"text": "These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers, and question answering.", "labels": [], "entities": [{"text": "training relation extractors and semantic parsers", "start_pos": 62, "end_pos": 111, "type": "TASK", "confidence": 0.6622166732947031}, {"text": "question answering", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.9173623025417328}]}, {"text": "While these knowledge bases maybe very large, they are still quite incomplete, missing large percentages of facts about common or popular entities.", "labels": [], "entities": []}, {"text": "The task of knowledge base completion-filling in missing facts by examining the facts already in the KB, or by looking in a corpus-is one attempt to mitigate the problems of this knowledge sparsity.", "labels": [], "entities": [{"text": "knowledge base completion-filling in missing facts", "start_pos": 12, "end_pos": 62, "type": "TASK", "confidence": 0.7787267367045084}]}, {"text": "In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA)).", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6199101110299429}]}, {"text": "PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph.", "labels": [], "entities": [{"text": "PRA", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8578224778175354}, {"text": "link prediction", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7601232528686523}]}, {"text": "The method has a strong connection to logical inference (, as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph.", "labels": [], "entities": []}, {"text": "While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (.", "labels": [], "entities": [{"text": "PRA", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9531010389328003}, {"text": "link prediction task", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7958329021930695}, {"text": "KB completion", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.7967316508293152}]}, {"text": "PRA is a two-step process, where the first step finds potential path types between node pairs to use as features in a statistical model, and the second step computes random walk probabilities associated with each path type and node pair (these are the values in a feature matrix).", "labels": [], "entities": [{"text": "PRA", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7729175686836243}]}, {"text": "This second step is very computationally intensive, requiring time proportional to the average out-degree of the graph to the power of the path length for each cell in the computed feature matrix.", "labels": [], "entities": []}, {"text": "In this paper we consider whether this computational effort is wellspent, or whether we might more profitably spend computation in other ways.", "labels": [], "entities": []}, {"text": "We propose anew way of generating feature matrices over node pairs in a graph that aims to improve both the efficiency and the expressivity of the model relative to PRA.", "labels": [], "entities": []}, {"text": "Our technique, which we call subgraph feature extraction (SFE), is similar to only doing the first step of PRA.", "labels": [], "entities": [{"text": "subgraph feature extraction (SFE)", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.7958678603172302}]}, {"text": "Given a set of node pairs in a graph, we first do a local search to characterize the graph around each node.", "labels": [], "entities": []}, {"text": "We then run a set of feature extractors over these local subgraphs to obtain feature vectors for each node pair.", "labels": [], "entities": []}, {"text": "In the simplest case, where the feature extractors only look for paths connecting the two nodes, the feature space is equivalent to PRA's, and this is the same as running PRA and binarizing the resultant feature vectors.", "labels": [], "entities": []}, {"text": "However, because we do not have to compute random walk probabilities associated with each path type in the feature matrix, we can extract much more expressive features, including features which are not representable as paths in the graph at all.", "labels": [], "entities": []}, {"text": "In addition, we can do a more exhaustive search to characterize the local graph, using a breadth-first search instead of random walks.", "labels": [], "entities": []}, {"text": "SFE is a much simpler method than PRA for obtaining feature matrices over node pairs in a graph.", "labels": [], "entities": [{"text": "SFE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5012843012809753}]}, {"text": "Despite its simplicity, however, we show experimentally that it substantially outperforms PRA, both in terms of running time and prediction performance.", "labels": [], "entities": [{"text": "PRA", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.7487706542015076}]}, {"text": "SFE decreases running time over PRA by an order of magnitude, it improves mean average precision from .432 to .528 on the NELL KB, and it improves mean reciprocal rank from .850 to .933.", "labels": [], "entities": [{"text": "SFE", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7386203408241272}, {"text": "mean average", "start_pos": 74, "end_pos": 86, "type": "METRIC", "confidence": 0.9304428696632385}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.5064948201179504}, {"text": "NELL KB", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.876170426607132}, {"text": "mean reciprocal rank", "start_pos": 147, "end_pos": 167, "type": "METRIC", "confidence": 0.8069346149762472}]}, {"text": "In the remainder of this paper, we first describe PRA in more detail.", "labels": [], "entities": [{"text": "PRA", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9792384505271912}]}, {"text": "We then situate our methods in the context of related work, and provide additional experimental motivation for the improvements described in this paper.", "labels": [], "entities": []}, {"text": "We then formally define SFE and the feature extractors we used, and finally we present an experimental comparison between PRA and SFE on the NELL KB.", "labels": [], "entities": [{"text": "NELL KB", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.9655546247959137}]}, {"text": "The code and data used in this paper is available at http://rtw.ml.cmu.edu/emnlp2015 sfe/.", "labels": [], "entities": []}], "datasetContent": [{"text": "Here we present experimental results evaluating the feature extractors we presented, and a comparison between SFE and PRA.", "labels": [], "entities": [{"text": "SFE", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.6375352144241333}]}, {"text": "As we showed in Section 5 that using a breadth-first search to obtain subgraphs is superior to using random walks, all of the experiments presented here use the BFS implementation of SFE.", "labels": [], "entities": [{"text": "SFE", "start_pos": 183, "end_pos": 186, "type": "DATASET", "confidence": 0.6747350692749023}]}], "tableCaptions": [{"text": " Table 1: Using binary feature values instead of  random walk probabilities gives statistically in- distinguishable performance. The p-value on the  Freebase data is .55, while it is .25 for NELL.", "labels": [], "entities": [{"text": "Freebase data", "start_pos": 149, "end_pos": 162, "type": "DATASET", "confidence": 0.9905803203582764}, {"text": "NELL", "start_pos": 191, "end_pos": 195, "type": "DATASET", "confidence": 0.8221957683563232}]}, {"text": " Table 2: Comparison of PRA and SFE on 10  NELL relations. The difference shown is not sta- tistically significant.", "labels": [], "entities": [{"text": "SFE", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.7185614705085754}]}, {"text": " Table 3: Comparison of PRA and SFE (with PRA- style features) on 10 NELL relations. SFE-RW is  not statistically better than PRA, but SFE-BFS is  (p < 0.05).", "labels": [], "entities": []}, {"text": " Table 4: Comparing methods for obtaining nega- tive evidence available at training time. The differ- ence seen is not statistically significant (p = .77).", "labels": [], "entities": [{"text": "differ- ence", "start_pos": 94, "end_pos": 106, "type": "METRIC", "confidence": 0.9683155218760172}]}, {"text": " Table 5: SFE feature ablation study. All rows use  PRA features. PRA + any rel is statistically better  than all other methods except PRA + vec sim, and  most of the other differences are not significant.", "labels": [], "entities": []}, {"text": " Table 6: Results of final comparison between SFE  and PRA, with and without vector space similarity  features. SFE is statistically better than both PRA  methods (p < 0.005).", "labels": [], "entities": []}]}