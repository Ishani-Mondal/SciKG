{"title": [{"text": "Posterior calibration and exploratory analysis for natural language processing models", "labels": [], "entities": []}], "abstractContent": [{"text": "Many models in natural language processing define probabilistic distributions over linguistic structures.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6774863600730896}]}, {"text": "We argue that (1) the quality of a model's posterior distribution can and should be directly evaluated, as to whether probabilities correspond to empirical frequencies; and (2) NLP uncertainty can be projected not only to pipeline components, but also to exploratory data analysis, telling a user when to trust and not trust the NLP analysis.", "labels": [], "entities": []}, {"text": "We present a method to analyze calibration, and apply it to compare the miscalibration of several commonly used models.", "labels": [], "entities": []}, {"text": "We also contribute a coreference sampling algorithm that can create confidence intervals fora political event extraction task.", "labels": [], "entities": [{"text": "coreference sampling", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.850260853767395}, {"text": "political event extraction task", "start_pos": 94, "end_pos": 125, "type": "TASK", "confidence": 0.7194183766841888}]}], "introductionContent": [{"text": "Previous work on Naive Bayes has found its probabilities to have calibration issues, in part due to its incorrect conditional independence assumptions ().", "labels": [], "entities": []}, {"text": "Since logistic regression has the same log-linear representational capacity) but does not suffer from the independence assumptions, we select it for comparison, hypothesizing it may have better calibration.", "labels": [], "entities": []}, {"text": "We analyze a binary classification task of Twitter sentiment analysis from emoticons.", "labels": [], "entities": [{"text": "Twitter sentiment analysis", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.7076558768749237}]}, {"text": "We collect a dataset consisting of tweets identified by the Twitter API as English, collected from 2014 to 2015, with the \"emoticon trick\") to label tweets that contain at least one occurrence of the smiley emoticon \":)\" as \"happy\" (y = 1) and others as y = 0.", "labels": [], "entities": []}, {"text": "The smiley emoticons are deleted in positive examples.", "labels": [], "entities": []}, {"text": "We sampled three sets of tweets (subsampled from the Decahose/Gardenhose stream of public tweets) with Jan-Apr 2014 for training, May-Dec 2014 for development, and Jan-Apr 2015 for testing.", "labels": [], "entities": [{"text": "Decahose/Gardenhose stream of public tweets", "start_pos": 53, "end_pos": 96, "type": "DATASET", "confidence": 0.9106982690947396}]}, {"text": "Each set contains 10 5 tweets, split between an equal number of positive and negative instances.", "labels": [], "entities": []}, {"text": "We use binary features based on unigrams extracted from the twokenize.py 8 tokenization.", "labels": [], "entities": [{"text": "twokenize.py 8 tokenization", "start_pos": 60, "end_pos": 87, "type": "DATASET", "confidence": 0.8271589477856954}]}, {"text": "We use the scikit-learn maximize the F-1 score on the development set.", "labels": [], "entities": [{"text": "F-1 score", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.962274819612503}]}], "datasetContent": [], "tableCaptions": []}