{"title": [{"text": "Recognizing Textual Entailment Using Probabilistic Inference", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8938494920730591}]}], "abstractContent": [{"text": "Recognizing Text Entailment (RTE) plays an important role in NLP applications including question answering, information retrieval, etc.", "labels": [], "entities": [{"text": "Recognizing Text Entailment (RTE)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8511748611927032}, {"text": "question answering", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.911346971988678}, {"text": "information retrieval", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.8152274489402771}]}, {"text": "In recent work, some research explore \"deep\" expressions such as discourse commitments or strict logic for representing the text.", "labels": [], "entities": []}, {"text": "However, these expressions suffer from the limitation of inference inconvenience or translation loss.", "labels": [], "entities": []}, {"text": "To overcome the limitations, in this paper, we propose to use the predicate-argument structures to represent the discourse commitments extracted from text.", "labels": [], "entities": []}, {"text": "At the same time, with the help of the YAGO knowledge , we borrow the distant supervision technique to mine the implicit facts from the text.", "labels": [], "entities": [{"text": "YAGO knowledge", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.8311402201652527}]}, {"text": "We also construct a probabilistic network for all the facts and conduct inference to judge the confidence of each fact for RTE.", "labels": [], "entities": [{"text": "RTE", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.6333092451095581}]}, {"text": "The experimental results show that our proposed method achieves a competitive result compared to the previous work.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the natural language, a common phenomenon is that there exist a lot of ways to express the same or similar meaning.", "labels": [], "entities": []}, {"text": "To discover such different expressions, the Recognising Textual Entailment (RTE) task is proposed to judge whether the meaning of one text (denoted as H) can be inferred (entailed) from the other one (T )().", "labels": [], "entities": [{"text": "Recognising Textual Entailment (RTE)", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.7038689951101939}]}, {"text": "For many natural language processing applications like question answering, information retrieval which involve the diversity of natural language, recognising textual entailments is a critical step.", "labels": [], "entities": [{"text": "question answering", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.9033008813858032}, {"text": "information retrieval", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7267898172140121}]}, {"text": "PASCAL Recognizing Textual Entailment (RTE) Challenges () have witnessed a variety of excellent systems which intend to recognize the textual entailment instances.", "labels": [], "entities": [{"text": "PASCAL Recognizing Textual Entailment (RTE) Challenges", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.7484620101749897}]}, {"text": "These systems mainly employ \"shallow\" techniques, including heuristics, term overlap, syntactic dependencies(; Jijkoun and de).", "labels": [], "entities": []}, {"text": "As Hickl (2008) stated, the shallow approaches do notwork well for long sentences for the missing of underlying information which needs to be mined from the surface level expression.", "labels": [], "entities": []}, {"text": "Recently, some deep techniques are developed to mine the facts latent in the text.", "labels": [], "entities": []}, {"text": "proposed the concept of discourse commitments which can be seen as the set of propositions inferred from the text, and used a series of syntaxlevel and semantic-level rules to extract the commitments from the T -H pairs.", "labels": [], "entities": []}, {"text": "Then the RTE task is reduced to the identification of the commitments from T which are most likely to support the inference of the commitments from H.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 9, "end_pos": 17, "type": "TASK", "confidence": 0.8604618608951569}]}, {"text": "From the work of, we can see that a deep understanding of text is critical to the RTE performance and discourse commitments can serve a good media to understanding text.", "labels": [], "entities": [{"text": "RTE", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.7871986627578735}]}, {"text": "However, the limitation of Hickl (2008)'s work is, the extracted discourse commitments are still from the original text and do not explore the implicit meaning latent behind the text.", "labels": [], "entities": []}, {"text": "Another kind of deep methods involves first transferring natural language to logic representation and then conducting strict logic inference based on the logic representations (;.", "labels": [], "entities": []}, {"text": "Through logic inference, some implicit knowledge behind the text can be mined.", "labels": [], "entities": []}, {"text": "However, it is not easy to translate the natural language text into formal logic expressions and the translation process inevitably suffer from great information loss.", "labels": [], "entities": []}, {"text": "Through analysis above, in our work, we pro-1620  Ayrton Senna was married to a doctor who lives in Austin, the capital of Texas, in 1998.", "labels": [], "entities": []}, {"text": "We translate this example into the predicateargument structures such as bemarried(Senna, doctor), livein(doctor, Austin), captial(Austin, Texas).", "labels": [], "entities": []}, {"text": "Then through distant supervision, we can get some new facts livein(Senna, Austin), livein(Senna, Texas).", "labels": [], "entities": []}, {"text": "To judge the confidence of the new facts, we construct a probabilistic network with all the facts and adopt the Markov Logic Network (MLN) to calculate the probability of each new fact, which can be further used to recognize text entailments.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the performance of our framework for RTE on the PASCAL RTE-2 3 and RTE-3 4 datasets, which has 1600 examples.", "labels": [], "entities": [{"text": "RTE", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9223120808601379}, {"text": "PASCAL RTE-2 3 and RTE-3 4 datasets", "start_pos": 60, "end_pos": 95, "type": "DATASET", "confidence": 0.7429302590233939}]}, {"text": "We use the YAGO2 for aligning predicates and mining inference rules.", "labels": [], "entities": [{"text": "YAGO2", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.6314609050750732}]}, {"text": "YAGO2 contains more than 940K facts and about 470K entities.", "labels": [], "entities": [{"text": "YAGO2", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8303645849227905}]}, {"text": "We run the AMIE system on YAGO2 for only onetime to get all inference rules (about more than 1.8K in total).", "labels": [], "entities": [{"text": "YAGO2", "start_pos": 26, "end_pos": 31, "type": "DATASET", "confidence": 0.8163642287254333}]}, {"text": "For each T -H pair, we only choose a portion of related inference rules to construct MLN.", "labels": [], "entities": []}, {"text": "The chosen rules must contain at least one predicate which occurred in the predicates of T -H pair.", "labels": [], "entities": []}, {"text": "We only use the MLN to infer when the discourse commitment paraphrasing cannot identify a T -H pair as \"Entailment\", which is a back-off method.", "labels": [], "entities": []}, {"text": "We compare our result with 5 baseline systems: (1).", "labels": [], "entities": []}, {"text": "Since we only need to judge \"Yes\" or \"No\" for the 1600 examples, the precision is equal to the recall, so that we only report the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9997146725654602}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9996753931045532}, {"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9988559484481812}]}, {"text": "According to the, the performance of our framework is higher than Hickl (2008)'s baseline, which is significant (Wilcoxon signed-rank test, p < 0.05).", "labels": [], "entities": []}, {"text": "The reason is that we have added the inference portion to's method.", "labels": [], "entities": []}, {"text": "Therefore, some T -H pairs which had to be judged by semantic reasoning can be corrected by our framework.", "labels": [], "entities": []}, {"text": "For instance, T is \"Hughes loved his wife, Gracia, and was absolutely obsessed with his little daughter Elicia.\" and H is \"Gracia's daughter is Elicia.\"", "labels": [], "entities": [{"text": "T", "start_pos": 14, "end_pos": 15, "type": "METRIC", "confidence": 0.9775189161300659}]}, {"text": "It is not easy for the former baselines to recognize this entailment, but our framework can easily recognize it to be \"true\".", "labels": [], "entities": []}, {"text": "In this way, our framework has achieved a higher result.", "labels": [], "entities": []}], "tableCaptions": []}