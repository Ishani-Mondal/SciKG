{"title": [{"text": "Extracting Condition-Opinion Relations Toward Fine-grained Opinion Mining", "labels": [], "entities": []}], "abstractContent": [{"text": "A fundamental issue in opinion mining is to search a corpus for opinion units, each of which typically comprises the evaluation by an author fora target object from an aspect, such as \"This hotel is in a good location\".", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.8507153391838074}]}, {"text": "However, few attempts have been made to address cases where the validity of an evaluation is restricted on a condition in the source text, such as \"for traveling with small kids\".", "labels": [], "entities": [{"text": "validity", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.967700183391571}]}, {"text": "In this paper, we propose a method to extract condition-opinion relations from on-line reviews, which enables fine-grained analysis for the utility of target objects depending the user attribute, purpose, and situation.", "labels": [], "entities": []}, {"text": "Our method uses supervised machine learning to identify sequences of words or phrases that comprise conditions for opinions.", "labels": [], "entities": []}, {"text": "We propose several features associated with lexical and syntactic information , and show their effectiveness experimentally .", "labels": [], "entities": []}], "introductionContent": [{"text": "Reflecting the rapid growth in the use of opinionated texts on the Web, such as comments on news articles and customer reviews, opinion mining has been explored to facilitate utilizing opinions mainly for improving products and decisionmaking purposes.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 128, "end_pos": 142, "type": "TASK", "confidence": 0.7715708613395691}]}, {"text": "While in abroad sense opinion mining refers to a process to discover useful knowledge latent in a corpus of opinionated texts, fundamental issues involve modeling an unit of opinions and searching the corpus for those units, each of which typically comprises the evaluation by an author fora target object from an aspect.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.8055572807788849}]}, {"text": "Other elements, such as when the opinion was submitted, can optionally be included in an opinion unit.", "labels": [], "entities": []}, {"text": "We take the following review sentence as an example opinionated description.", "labels": [], "entities": []}, {"text": "(1) I think hotel A offers a reasonable price if you take a family trip with small kids.", "labels": [], "entities": []}, {"text": "From the above example, existing methods (; Liu and Zhang, 2012;) are intended to extract the following quintuple as an opinion unit.", "labels": [], "entities": []}, {"text": "Target = \"hotel A\", Aspect = \"price\", Evaluation (Polarity) = \"reasonable\" (positive), Holder = \"I (author)\", Time = N/A Depending on the application, \"Evaluation\" can be any of a literal opinion word (e.g., \"reasonable\"), a polarity (positive/negative), or a value for multipoint scale rating.", "labels": [], "entities": [{"text": "Evaluation (Polarity)", "start_pos": 38, "end_pos": 59, "type": "METRIC", "confidence": 0.8846033066511154}, {"text": "Holder", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9985294342041016}, {"text": "Time = N/A", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.829550850391388}]}, {"text": "Given those standardized units extracted from a corpus, it is feasible to overview the distribution of values for each element or a combination of elements.", "labels": [], "entities": []}, {"text": "For example, those who intend to improve the quality of hotel A may investigate representative values for \"Aspect\" in the units satisfying \"Target=hotel A & Polarity=negative\", while those who look for accommodation may collect the opinion units for one or more candidate hotels and investigate the distribution of values for \"Polarity\" on an aspect-by-aspect basis.", "labels": [], "entities": []}, {"text": "However, in the above example (1), the evaluation for hotel A (\"a reasonable price\") is valid for \"if you take a family trip with small kids\", and thus it is not clear whether this evaluation is valid irrespective of the condition.", "labels": [], "entities": []}, {"text": "For example, the price may not be reasonable fora single customer intending for business purposes.", "labels": [], "entities": []}, {"text": "In this paper, we shall call such a condition \"condition for opinion (CFO)\".", "labels": [], "entities": []}, {"text": "We define CFO as a condition for which an opinion unit has a polarity.", "labels": [], "entities": []}, {"text": "The existing methods for opinion mining, which do not consider whether a target opinion is conditional, potentially overestimate or underestimate the utility of hotel A and consequently decrease the quality of opinion mining.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8496524691581726}, {"text": "opinion mining", "start_pos": 210, "end_pos": 224, "type": "TASK", "confidence": 0.7364784479141235}]}, {"text": "We manually analyzed the first 7 000 sentences in the Rakuten Travel data, which consists of 348 564 Japanese reviews for hotels in Japan (see Section 4 for details of this data) and found that 2 272 sentences are opinions, of which 630 opinions are conditional and thus the result for an existing method includes up to 28% (630/2272) errors.", "labels": [], "entities": [{"text": "Rakuten Travel data", "start_pos": 54, "end_pos": 73, "type": "DATASET", "confidence": 0.9642542203267416}]}, {"text": "Motivated by the above discussion, in this paper we propose a method to extract pairs of a CFO and its corresponding opinion unit from online reviews.", "labels": [], "entities": []}, {"text": "This method provides two solutions to the above problem.", "labels": [], "entities": []}, {"text": "First, a passive solution is detecting whether an opinion includes a CFO and, if any, isolating that opinion from the target of opinion mining.", "labels": [], "entities": [{"text": "CFO", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.6136214137077332}, {"text": "opinion mining", "start_pos": 128, "end_pos": 142, "type": "TASK", "confidence": 0.7217911928892136}]}, {"text": "As a result, we can avoid potential errors as much as possible but the coverage is decreased.", "labels": [], "entities": [{"text": "coverage", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9977774024009705}]}, {"text": "Second, an active solution is identifying the span of each CFO in conditional opinions and classify them according to semantic categories, such as purpose, situation, and user attribute so that finer-grained opinion mining can be realized.", "labels": [], "entities": []}, {"text": "For example, the distribution of positive and negative opinions can be available on a category-bycategory basis.", "labels": [], "entities": []}, {"text": "However, in this paper we focus only on the identification for CFOs and leave the semantic classification future work.", "labels": [], "entities": [{"text": "identification for CFOs", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.6002175807952881}, {"text": "semantic classification", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.7806994020938873}]}, {"text": "To produce a practical model for CFOs, it is important to investigate them from a grammar point of view.", "labels": [], "entities": []}, {"text": "It can easily be predicted that atypical grammatical unit for CFOs is a conditional clause as in example (1).", "labels": [], "entities": []}, {"text": "Additionally, restrictive modifiers in general can potentially be CFOs because they restrict the validity of an opinion unit from a specific perspective.", "labels": [], "entities": []}, {"text": "A restrictive modifier comprises a word, phrase, or clause.", "labels": [], "entities": []}, {"text": "The CFO in example (1), which is a dependent clause functioning as a condition, is also a restrictive modifier.", "labels": [], "entities": [{"text": "CFO", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8620029091835022}]}, {"text": "Example, which has the same meaning as example (1), includes a CFO as a prepositional phrase.", "labels": [], "entities": []}, {"text": "(2) Hotel A offers a reasonable price for taking a family trip with small kids.", "labels": [], "entities": []}, {"text": "We denote CFOs and opinion words in bold and italic faces, respectively.", "labels": [], "entities": []}, {"text": "Examples (3) and (4) also include a CFO as a prepositional phrase.", "labels": [], "entities": []}, {"text": "Unlike example (2), the validity of \"reasonable\" is restricted from time and comparison points of view, respectively.", "labels": [], "entities": [{"text": "validity", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9884526133537292}]}, {"text": "(3) Hotel A offers a reasonable price during this holiday season.", "labels": [], "entities": []}, {"text": "(4) Hotel A offers a reasonable price fora four star hotel.", "labels": [], "entities": []}, {"text": "In example (5), which has a similar meaning to example (1), the CFO is a dependent clause functioning as a reason.", "labels": [], "entities": [{"text": "CFO", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.8096924424171448}]}, {"text": "(5) Hotel A offers a reasonable price because we take a family trip with small kids.", "labels": [], "entities": []}, {"text": "Finally, as in example, an opinion holder can also be a CFO because the evaluation is restricted from a perspective of that specific person.", "labels": [], "entities": []}, {"text": "(6) My mother regarded hotel A as a reasonable choice.", "labels": [], "entities": []}, {"text": "If the restriction by a CFO is associated with a user-related perspective, we call such CFOs \"userrestrictive CFOs (U-CFOs)\".", "labels": [], "entities": []}, {"text": "In other words, target users to whom an opinion unit is relevant are restricted by its corresponding U-CFO, although those users may agree or disagree with the opinion.", "labels": [], "entities": []}, {"text": "The CFOs in examples (1), (2), and (5) are U-CFOs because the target users are mainly those who intend to travel with their children.", "labels": [], "entities": []}, {"text": "The CFO in example (3) is also U-CFO because the target users are those who intend to travel during a specific holiday season.", "labels": [], "entities": [{"text": "CFO", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.801416277885437}]}, {"text": "The CFO in example (6) is also U-CFO because the opinion holder (\"my mother\") implies the opinion is relevant mainly to adult females.", "labels": [], "entities": [{"text": "CFO", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8402666449546814}]}, {"text": "However, opinion holders who do not represent user-related perspectives, such as \"I\" without any profile, are not U-CFOs.", "labels": [], "entities": []}, {"text": "The CFO in example is not a U-CFO because the relevance of the opinion is not restricted to specific customers.", "labels": [], "entities": [{"text": "CFO", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9076445698738098}]}, {"text": "It maybe argued that in example (4) the target users are restricted to those who are interested in the price.", "labels": [], "entities": []}, {"text": "However, in example (4) the price restricts the aspect of the opinion unit, and should not be confused with U-CFOs and even CFOs, which restrict the validity of the opinion unit.", "labels": [], "entities": []}, {"text": "If we fully utilize U-CFOs, as discussed for the active solution above, we need to classify U-CFOs into semantic categories so that users can selectively read relevant opinions.", "labels": [], "entities": []}, {"text": "In other words, the identification for U-CFOs facilitates predicting the review helpfulness.", "labels": [], "entities": []}, {"text": "Candidate categories include demographic and psychographic attributes for target users (e.g., age and hobby) and situations of target users (e.g., purpose, time, and place).", "labels": [], "entities": []}, {"text": "However, we leave the classification for U-CFOs future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effectiveness of our method, we used the Rakuten Travel data 1 , which consists of 348 564 Japanese reviews for hotels in Japan.", "labels": [], "entities": [{"text": "Rakuten Travel data 1", "start_pos": 57, "end_pos": 78, "type": "DATASET", "confidence": 0.9376675635576248}]}, {"text": "From this dataset, we selected 580 reviews and manually identified elements for opinion units.", "labels": [], "entities": []}, {"text": "We removed sentences consisting only of opinion unit such as \"The location is good\" from the evaluation.", "labels": [], "entities": []}, {"text": "As a result, 3 155 sentences remained, which comprise our corpus.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness for identifying CFOs, we used the manually annotated opinion elements as output of a pseudo automatic method.", "labels": [], "entities": [{"text": "identifying CFOs", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.6247032582759857}]}, {"text": "Given the above corpus, two annotators independently identified U-CFOs or CFOs, if any, for each opinion unit.", "labels": [], "entities": []}, {"text": "For both annotations of CFOs and U-CFOs, the Kappa value for the interannotator agreement was 0.87, indicating strong agreement.", "labels": [], "entities": [{"text": "Kappa", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.9519721269607544}]}, {"text": "We show the details of our corpus in.", "labels": [], "entities": []}, {"text": "Using this corpus, we performed 10-fold cross-validation and compared different methods from different perspectives.", "labels": [], "entities": []}, {"text": "Also, we determined the threshold for Score (see Eq 2) by a development set for each fold.", "labels": [], "entities": [{"text": "Score", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9979123473167419}]}, {"text": "To evaluate the effectiveness of extracting UCFOs and CFOs independently, we first classified bunsetsu phrases into any of BU, IU, BC, IC, or Other.", "labels": [], "entities": [{"text": "extracting UCFOs and CFOs", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.6679462790489197}, {"text": "BU", "start_pos": 123, "end_pos": 125, "type": "METRIC", "confidence": 0.7580254077911377}]}, {"text": "Then, for the U-CFO extraction we regarded phrases for BU and IU as the Cond-phrases while for the CFO extraction we regarded phrases for BU, IU, BC, and IC as the Cond-phrases.", "labels": [], "entities": [{"text": "CFO extraction", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.6006448566913605}]}, {"text": "We used \"Partial match\" and \"Exact match\", which denote different criteria for the correctness of methods under evaluation.", "labels": [], "entities": [{"text": "Exact match", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9670891761779785}]}, {"text": "While in the partial match each method was requested to only detect whether or not a test sentence includes CFO, in the exact match each method was also requested to identify the span of each CFO.", "labels": [], "entities": [{"text": "CFO", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.7540063858032227}]}, {"text": "Also, we used different evaluation measures, namely precision (P), recall (R), F-measure (F), and accuracy (A).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9399541914463043}, {"text": "recall (R)", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9498360604047775}, {"text": "F-measure (F)", "start_pos": 79, "end_pos": 92, "type": "METRIC", "confidence": 0.95416459441185}, {"text": "accuracy (A)", "start_pos": 98, "end_pos": 110, "type": "METRIC", "confidence": 0.9483048766851425}]}, {"text": "Rule-based method and SVM-based method are used for comparison purposes.", "labels": [], "entities": []}, {"text": "Rule-based method first identifies a bunsetsu phrase whose dependency distance to the opinion word is 1 and including a clue expression (see Section 3), and also identifies a sequence of the phrases from which there is a dependency path to the above phrase as a CFO.", "labels": [], "entities": [{"text": "CFO", "start_pos": 262, "end_pos": 265, "type": "DATASET", "confidence": 0.9061617851257324}]}, {"text": "For example, in because phrase #6 includes a clue expression, a sequence of phrases #3-#6 is extracted as a CFO.", "labels": [], "entities": [{"text": "CFO", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.8344147801399231}]}, {"text": "These rules are based on features F1, F7 and F9.", "labels": [], "entities": [{"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9953646659851074}]}, {"text": "For the U-CFO extraction task, we regarded a sequence of Cond-phrases extracted by the above method as U-CFO if that sequence includes a restrictive word.", "labels": [], "entities": [{"text": "U-CFO extraction task", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.860545019308726}]}, {"text": "For SVM, the thirteen features F1-F13 proposed in Section 3 was used.", "labels": [], "entities": [{"text": "SVM", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.7609264254570007}, {"text": "F1-F13", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9323274493217468}]}, {"text": "We used LIBSVM () to train a classifier.", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 8, "end_pos": 14, "type": "DATASET", "confidence": 0.6451876759529114}]}, {"text": "Our method used CRF to train a classifier with the thirteen features and four patterns for feature functions.", "labels": [], "entities": []}, {"text": "We used CRF++ 2 to train a classifier for each phrase and regularized the parameters using L2-norm.", "labels": [], "entities": []}, {"text": "shows the relationship between values of regularization parameter and F-measure for exact match.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9976882934570312}]}, {"text": "In, \"Rule\", \"SVM\", and \"CRF\" denote a rule-based method, SVM-based method, and our method, respectively.", "labels": [], "entities": []}, {"text": "The Fmeasure for Rule, independent of the regularization parameter, is a constant.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9977229237556458}]}, {"text": "While the F-measure for SVM substantially varied depending on the parameter value, that for CRF did not vary that much.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988718628883362}, {"text": "SVM", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9350879788398743}]}, {"text": "Additionally, the F-measure for CRF was larger than that for SVM irrespective of the parameter value and matching criterion.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9989973902702332}]}, {"text": "shows results obtained with the optimal value for the regularization parameter.", "labels": [], "entities": []}, {"text": "Looking at, one can see that CRF outperformed the other methods in terms of F-measure and accuracy for both partial and exact matches.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9955801367759705}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9995846152305603}]}, {"text": "We used the two-tailed paired t-test for statistical testing and found that the differences of CRF and each of the other methods in F-measure and accuracy were statistically significant at the 1% level irrespective of the configuration.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9148902893066406}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9918498992919922}]}, {"text": "shows the effectiveness of the proposed features for exact match.", "labels": [], "entities": [{"text": "exact", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.8859135508537292}]}, {"text": "The horizontal axis \"w/o X\" denotes a method without feature X.", "labels": [], "entities": []}, {"text": "The vertical axis denotes a ratio of each method to our method.", "labels": [], "entities": []}, {"text": "If a method without feature X takes less than 1 for value of vertical axis, the feature X is effective for extracting CFOs.", "labels": [], "entities": [{"text": "extracting CFOs", "start_pos": 107, "end_pos": 122, "type": "TASK", "confidence": 0.682016134262085}]}, {"text": "Looking at       Thus, we conclude that each of our thirteen features was independently effective for extracting CFO and U-CFO in review sentences and that when used together the improvement was even greater.", "labels": [], "entities": [{"text": "extracting CFO", "start_pos": 102, "end_pos": 116, "type": "TASK", "confidence": 0.7081665992736816}]}, {"text": "For the U-CFO extraction, we analyzed the errors by our method.", "labels": [], "entities": [{"text": "U-CFO extraction", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.8083476722240448}]}, {"text": "The total number of errors was 363 by condition unit.", "labels": [], "entities": [{"text": "errors", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.8847974538803101}]}, {"text": "We describe causes of the errors with example sentences, translated into English by the authors.", "labels": [], "entities": []}, {"text": "In those examples, double and single underlines denote false positive and false negative, respectively.", "labels": [], "entities": []}, {"text": "For each cause, we show the number of errors in parentheses.", "labels": [], "entities": [{"text": "number of errors", "start_pos": 28, "end_pos": 44, "type": "METRIC", "confidence": 0.7479477524757385}]}, {"text": "E1 (124) Errors were due to F11 and F12 with insufficient dictionary for restrictive words.", "labels": [], "entities": [{"text": "E1", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.719560980796814}, {"text": "Errors", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9476838111877441}, {"text": "F11", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9846461415290833}]}, {"text": "Typically, low frequency words (e.g., pilgrimage) and words related to miscellaneous activities during a travel (e.g., charging a battery of a mobile phone) were not included in our dictionary.", "labels": [], "entities": []}, {"text": "While it is important to increase the vocabulary size of our dictionary, identifying synonymous expressions with partial matching (e.g., go to sleep / go to bed) is also important.", "labels": [], "entities": []}, {"text": "E2 (53) Errors were due to dependency analysis, which often mistakenly recognizes sentence boundaries in an informal writing style and dependency relations in a sentence comprising a phrase, such as \"the best location for fully enjoying Asakusa\".", "labels": [], "entities": [{"text": "Errors", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9657473564147949}, {"text": "dependency analysis", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7642840445041656}]}, {"text": "In this example, CaboCha mistakenly associated the adnominal modifier \"for fully enjoying Asakusa\" with \"location (aspect)\" instead of \"best (opinion word)\".", "labels": [], "entities": []}, {"text": "As a result, F1 and F3 did not regard this modifier as a U-CFO.", "labels": [], "entities": [{"text": "F1", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9886749982833862}, {"text": "F3", "start_pos": 20, "end_pos": 22, "type": "DATASET", "confidence": 0.6140275001525879}]}, {"text": "E3 (40) Restrictive modifiers that modify a nonopinion segment were mistakenly extracted as U-CFOs.", "labels": [], "entities": []}, {"text": "For example, in \"I used this hotel for business and the meal was good\", \"for business\" includes the clue expression \"for\" but does not modifies the opinion unit.", "labels": [], "entities": []}, {"text": "E4 (39) Similar to E3 but errors were due to restrictive words instead of clue expressions.", "labels": [], "entities": [{"text": "E4", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.9179059267044067}]}, {"text": "In the example for E3, the restrict word \"business\" caused the error.", "labels": [], "entities": [{"text": "E3", "start_pos": 19, "end_pos": 21, "type": "DATASET", "confidence": 0.9078667759895325}]}, {"text": "E5 (26) U-CFOs that consist of a large number of phrases were often not extracted due to F5, such as \"This hotel is acceptable for one night to take the train at the Chuo station next morning\".", "labels": [], "entities": [{"text": "F5", "start_pos": 89, "end_pos": 91, "type": "METRIC", "confidence": 0.9153011441230774}]}, {"text": "E6 (25) Errors were due to irrelevant entries in our restrictive word dictionary.", "labels": [], "entities": [{"text": "Errors", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9890234470367432}]}, {"text": "E7 (11) Due to the sparseness problem for restrictive words in the training data, U-CFOs and CFOs were not correctly distinguished.", "labels": [], "entities": [{"text": "CFOs", "start_pos": 93, "end_pos": 97, "type": "DATASET", "confidence": 0.8524520993232727}]}, {"text": "E8 (9) Errors were due to part-of-speech tagging.", "labels": [], "entities": [{"text": "E8", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8957456946372986}, {"text": "Errors", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.6442033052444458}, {"text": "part-of-speech tagging", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7022808194160461}]}, {"text": "E9 (6) Errors were due to extracting modifiers consisting of a personal pronoun without additional user-related attributes, such as \"enough for me\" , as U-CFOs.", "labels": [], "entities": [{"text": "E9", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.9346188306808472}]}, {"text": "We need to identify whether an expression fora person is associated with userrelated attributes, such as \"the bed is small fora person who is tall\", which indicates a physical attribute of a user.", "labels": [], "entities": []}, {"text": "Additionally, there are 65 errors for which we have not found a reason.", "labels": [], "entities": [{"text": "errors", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9604105353355408}]}], "tableCaptions": [{"text": " Table 2: Details of our corpus", "labels": [], "entities": []}]}