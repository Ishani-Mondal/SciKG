{"title": [{"text": "Large-Scale Acquisition of Entailment Pattern Pairs by Exploiting Transitivity", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel method for acquiring entailment pairs of binary patterns on a large-scale.", "labels": [], "entities": []}, {"text": "This method exploits the tran-sitivity of entailment and a self-training scheme to improve the performance of an already strong supervised classifier for en-tailment, and unlike previous methods that exploit transitivity, it works on a large-scale.", "labels": [], "entities": []}, {"text": "With it we acquired 138.1 million pattern pairs with 70% precision with such non-trivial lexical substitution as \"use Y to distribute X\"\u2192\"X is available on Y\" whose extraction is considered difficult.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9986193180084229}]}, {"text": "This represents 50.4 million more pattern pairs (a 57.5% increase) than what our supervised baseline extracted at the same precision.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognizing textual entailment) is an important task for many NLP applications, such as relation extraction () or question-answering ().", "labels": [], "entities": [{"text": "Recognizing textual entailment)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8757173717021942}, {"text": "relation extraction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.8868311047554016}]}, {"text": "Text L entails text R if the information written in the latter can be deduced from the information written in the former.", "labels": [], "entities": []}, {"text": "As building blocks to recognize entailment relations between texts, numerous works have focused on recognizing entailment relations between patterns, such as \"grew up in X\"\u2192\"lived in X\" or \"X grew up in Y\"\u2192\"X lived in Y\" ().", "labels": [], "entities": []}, {"text": "We propose in this paper a method for acquiring on a very large-scale, entailment pairs of  such class-dependent binary patterns as \"underwent X exam on Y date \"\u2192\"X exam carried out on Y date \".", "labels": [], "entities": []}, {"text": "Our starting point is a supervised baseline trained with 83,800 manually labeled pattern pairs detailed in.", "labels": [], "entities": []}, {"text": "Its top 205 million output pairs have an estimated 80% precision, but this baseline's performance is saturated.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9992815852165222}]}, {"text": "Table 1 shows the baseline's average precision when varying its amount of hand-labeled training data.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9992154836654663}]}, {"text": "Since the average precision only improves slightly with additional training data, the investment in hand-labeling additional training data is difficult to justify.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.999319314956665}]}, {"text": "To improve our baseline further, we exploit the transitivity property of entailment to automatically generate new features for it.", "labels": [], "entities": []}, {"text": "The entailment is transitive; if we detect that L entails C and C entails R, we can infer an entailment relation between Land R even if no such relation was detected beforehand.", "labels": [], "entities": []}, {"text": "Based on this idea, we propose a self-training scheme that works in the following way.", "labels": [], "entities": []}, {"text": "For pattern pair P ,Q, we use the baselines output to find all the chains of patterns from P to Q that are linked by entailment relations, which we call transitivity paths, and encode the information related to them as new features to judge the validity of pair P ,Q.", "labels": [], "entities": []}, {"text": "Our expectation is that even if our supervised baseline fails to judge P ,Q as an entailment pair, the existence of paths from P to Q that are comprised of pairs judged as entailments by our baseline might strongly suggest that P entails Q; hence, adding our new features to the baseline should help it make better decisions based on the information encoded in the features.", "labels": [], "entities": []}, {"text": "This self-training approach is the first that encodes the information contained in transitivity paths as features fora classifier, and as such it differs from previous state-of-the-art methods that exploit transitivity to extract new pairs using Integer Linear Programming or that autogenerate training data (.", "labels": [], "entities": []}, {"text": "From a corpus of 600 million web pages, we show that our proposed method extracted 217.8 million entailment pairs in Japanese with 80% precision 1 , which is a 6% increase over the 205.3 million pairs output by our baseline with identical precision.", "labels": [], "entities": [{"text": "precision 1", "start_pos": 135, "end_pos": 146, "type": "METRIC", "confidence": 0.9800042808055878}, {"text": "precision", "start_pos": 239, "end_pos": 248, "type": "METRIC", "confidence": 0.9633170366287231}]}, {"text": "It also extracted 138.1 million entailment pairs with 70% precision with non-trivial lexical substitution (generally deemed difficult to extract), which is a 50.4 million pair increase (57.5% size improvement) over the 87.7 million pairs output by our baseline with the same precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9981210827827454}]}, {"text": "These include such pairs as \"use X to distribute Y\"\u2192\"Y is available on X\", \"underwent X on Y\"\u2192\"X carried out on Y\", \"start X at Y\"\u2192\"Y's X\" or \"attach X to Y\"\u2192\"put X on Y\".", "labels": [], "entities": []}, {"text": "Even though we only present results for the Japanese language, we believe that our method should be applicable to other languages as well.", "labels": [], "entities": []}, {"text": "This is because none of the few language dependent features of our classifier are strictly needed by the baseline or our proposed method, and its performance boost is unrelated to these features.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our proposed method in a large-scale setting and compare it to BASE and to state-of-the-art methods based on ILP (Berant et al., 2011) and automatic training data expansion ().", "labels": [], "entities": [{"text": "BASE", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9159289002418518}]}, {"text": "We also indicate that our method shows the best performance gain for pattern pairs with non-trivial lexical substitutions, which are more difficult to acquire.", "labels": [], "entities": []}, {"text": "Evaluation Method For our evaluation, we prepared test set TEST of 15,000 pattern pairs randomly sampled from \u03a3 (our target set of 11 billion pairs).", "labels": [], "entities": [{"text": "TEST", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9977123737335205}]}, {"text": "The pairs were annotated by three humans (not the authors) who voted to settle labeling discrepancies.", "labels": [], "entities": []}, {"text": "We also prepared development set DEV of 5, 000 pattern pairs from \u03a3 for tuning our method.", "labels": [], "entities": []}, {"text": "The Kappa score was 0.55 for the annotation of these two sets.", "labels": [], "entities": [{"text": "Kappa score", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9317219257354736}]}, {"text": "We measured the performance of each method by computing its average precision) on the TEST set.", "labels": [], "entities": [{"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9793893694877625}, {"text": "TEST set", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.7482196688652039}]}, {"text": "We used the average precision instead of the traditional F-value because the latters value greatly varies depending on where the classification boundary is drawn, even for similar rankings.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.7624465227127075}, {"text": "F-value", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9940781593322754}]}, {"text": "We also drew precision curves for each method using the same TEST set.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.97236168384552}, {"text": "TEST", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.8965310454368591}]}, {"text": "Proposed Methods Performance We first show the performance of PROPOSED (our proposed method) and BASE (the baseline classifier).", "labels": [], "entities": [{"text": "BASE", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9986799359321594}]}, {"text": "As another baseline, we consider BASE +DEV where the 5,000 samples of the DEV set were added to the BASE training data.", "labels": [], "entities": [{"text": "BASE +DEV", "start_pos": 33, "end_pos": 42, "type": "DATASET", "confidence": 0.5571651260058085}, {"text": "BASE training data", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.7292966544628143}]}, {"text": "We show the average precision for each of these three classifiers and the: Average precision for similar and nonsimilar pairs number of pairs obtained at 80% precision in Table 2.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9579819440841675}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.7828987240791321}, {"text": "precision", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.981857180595398}]}, {"text": "We also show the performance of these classifiers over similar pattern pairs (both patterns share a content word) and non-similar pairs (they do not share a content word) in.", "labels": [], "entities": []}, {"text": "As mentioned in the introduction, BASE +DEV shows that the addition of 5,000 hand-labeled samples to the training data of BASE (a 6% increase) only improves the average precision performance by 0.17%.", "labels": [], "entities": [{"text": "BASE +DEV", "start_pos": 34, "end_pos": 43, "type": "TASK", "confidence": 0.3659138282140096}, {"text": "BASE", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.4892723560333252}, {"text": "precision", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.998849630355835}]}, {"text": "Our proposed method, on the other hand, exploits the same 5,000 new annotated samples for tuning its parameters and obtains a 1.85% gain of average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9630143642425537}]}, {"text": "Using PROPOSED, we acquired 217.8 million pattern pairs with 80% precision, an improvement of 6.0% over BASE.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9994304776191711}, {"text": "BASE", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.5449882745742798}]}, {"text": "As shown in, BASE s performance is much lower for non-similar pairs like \"use Y to distribute X\"\u2192\"X is available on Y\", which have non-trivial lexical substitutions and are more difficult to acquire than similar pairs.", "labels": [], "entities": [{"text": "BASE", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.6946092247962952}]}, {"text": "This is also where PROPOSED obtains the biggest gain in performance: an average precision of 39.53 compared to 36.98 for BASE.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9986295700073242}, {"text": "BASE", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.7442123293876648}]}, {"text": "We show the precision curves we obtained when ranking the nonsimilar pairs with BASE and PROPOSED in.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9959499835968018}, {"text": "BASE", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9993396401405334}, {"text": "PROPOSED", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9810251593589783}]}, {"text": "PROPOSED acquired 138.1 million nonsimilar pairs at 70% precision, which is an increase of 50.4 million pairs (a 57.5% size improvement) compared to BASE with the same precision.", "labels": [], "entities": [{"text": "PROPOSED", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7876217365264893}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9993069171905518}, {"text": "BASE", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.49460169672966003}, {"text": "precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9826050996780396}]}, {"text": "We believe that the strong performance of BASE for similar entailment pairs helped it discover, through transitivity, the variations of nonsimilar entailment pairs it could already detect.", "labels": [], "entities": [{"text": "BASE", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9430097341537476}]}, {"text": "Comparison to State-of-the-art Methods We also compared PROPOSED with two state-ofthe-art methods that exploit transitivity: the ILPbased method of Berant et al.", "labels": [], "entities": []}, {"text": "(2011) (ILP) and the training data expansion method we proposed in.", "labels": [], "entities": []}, {"text": "The latter, which was initially designed for acquiring contradiction pairs, was adapted to acquire entailment for comparison purposes.", "labels": [], "entities": []}, {"text": "The results of this comparison are summarized in, and the precision curves for these two methods as well over nonsimilar pairs are shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9989933371543884}]}, {"text": "Our proposed method is the only one that provides stable improvement in our large-scale setting; at best, the other two just slightly outperform BASE.", "labels": [], "entities": [{"text": "BASE", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.9026475548744202}]}, {"text": "We believe that our feature encoding provides more information to the classifier than the raw scores in the transitivity paths that are exploited by the other state-of-the-art methods, and as such strengthens the performance.", "labels": [], "entities": []}, {"text": "As for explaining the poor performance of the state-of-the-art methods, ILP is unfortunately not tractable for big problems; our ILP solver failed to solve 82% of the independent problems we fed it due to insufficient memory even on 64-Gb memory machines, making ILP just slightly better than BASE.", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 129, "end_pos": 139, "type": "TASK", "confidence": 0.6476061642169952}, {"text": "BASE", "start_pos": 293, "end_pos": 297, "type": "METRIC", "confidence": 0.48427411913871765}]}, {"text": "Our pattern graph is also sparser than that in, and as such ILP might not be completely efficient.", "labels": [], "entities": []}, {"text": "But we assume that even if we had used the graphs whole closure, the ILP problem instances would have become even less tractable, resulting in performance that only slightly exceeds BASE.", "labels": [], "entities": [{"text": "BASE", "start_pos": 182, "end_pos": 186, "type": "METRIC", "confidence": 0.9980746507644653}]}, {"text": "As for CDP, since our baseline classifier already has more than 80,000 hand-annotated samples as training data, the addition of automatically generated training samples is actually harmful.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average precision for baseline method  with various amounts of training data", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9161977171897888}]}, {"text": " Table 2: Average precision and entailment pairs  obtained (in millions) for proposed method, base- line classifiers, and state-of-the-art methods", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9886426329612732}]}, {"text": " Table 3: Average precision for similar and non- similar pairs", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9733616709709167}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9073372483253479}]}]}