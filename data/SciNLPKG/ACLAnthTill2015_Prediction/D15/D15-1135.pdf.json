{"title": [{"text": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning", "labels": [], "entities": [{"text": "Automatically Solving Number Word Problems", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8159667551517487}, {"text": "Semantic Parsing and Reasoning", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.7100869789719582}]}], "abstractContent": [{"text": "This paper presents a semantic parsing and reasoning approach to automatically solving math word problems.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7374815940856934}, {"text": "automatically solving math word problems", "start_pos": 65, "end_pos": 105, "type": "TASK", "confidence": 0.7490680515766144}]}, {"text": "A new meaning representation language is designed to bridge natural language text and math expressions.", "labels": [], "entities": []}, {"text": "A CFG parser is implemented based on 9,600 semi-automatically created grammar rules.", "labels": [], "entities": []}, {"text": "We conduct experiments on a test set of over 1,500 number word problems (i.e., verbally expressed number problems) and yield 95.4% precision and 60.2% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9994875192642212}, {"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9989812970161438}]}], "introductionContent": [{"text": "Computers, since their creation, have exceeded human beings in (speed and accuracy of) mathematical calculation.", "labels": [], "entities": [{"text": "speed", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9958716034889221}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9934658408164978}]}, {"text": "However, it is still a big challenge nowadays to design algorithms to automatically solve even primary-school-level math word problems (i.e., math problems described in natural language).", "labels": [], "entities": []}, {"text": "Efforts to automatically solve math word problems date back to the 1960s.", "labels": [], "entities": []}, {"text": "Previous work on this topic falls into two categories: symbolic approaches and statistical learning methods.", "labels": [], "entities": []}, {"text": "In symbolic approaches, math problem sentences are transformed to certain structures by pattern matching or verb categorization.", "labels": [], "entities": []}, {"text": "Equations are then derived from the structures.", "labels": [], "entities": [{"text": "Equations", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9330445528030396}]}, {"text": "Statistical learning methods are employed in two recent papers).", "labels": [], "entities": []}, {"text": "Most (if not all) previous symbolic approaches suffer from two major shortcomings.", "labels": [], "entities": []}, {"text": "First, natural language (NL) sentences are processed by simply applying pattern matching and/or transformation rules in an ad-hoc manner (refer to the related work section for more details).", "labels": [], "entities": []}, {"text": "Second, surprisingly, they seldom report evaluation results about the effectiveness of the methods (except for some examples for demonstration purposes).", "labels": [], "entities": []}, {"text": "For the small percentage of work with evaluation results available, it is unclear whether the patterns and rules are specially designed for specific sentences in a test set.", "labels": [], "entities": []}, {"text": "In this paper, we present a computer system called SigmaDolphin which automatically solves math word problems by semantic parsing and reasoning.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.7618425488471985}]}, {"text": "We design a meaning representation language called DOL (abbreviation of dolphin language) as the structured semantic representation of NL text.", "labels": [], "entities": []}, {"text": "A semantic parser is implemented to transform math problem text into DOL trees.", "labels": [], "entities": []}, {"text": "A reasoning module is included to derive math expressions from DOL trees and to calculate final answers.", "labels": [], "entities": []}, {"text": "Our approach falls into the symbolic category, but makes improvements over previous symbolic methods in the following ways, ______________________________________ * Work done while this author was an intern at Microsoft Research 1).", "labels": [], "entities": []}, {"text": "One number is 16 more than another.", "labels": [], "entities": []}, {"text": "If the smaller number is subtracted from 2/3 of the larger, the result is 1/4 of the sum of the two numbers.", "labels": [], "entities": []}, {"text": "Nine plus the sum of an even integer and its square is 3 raised to the power of 4.", "labels": [], "entities": []}, {"text": "The tens digit of a two-digit number is 3 more than the units digit.", "labels": [], "entities": []}, {"text": "If the number is 8 more than 6 times the sum of the digits, find the number.", "labels": [], "entities": []}, {"text": "If the first and third of three consecutive even integers are added, the result is 12 less than three times the second integer.", "labels": [], "entities": []}, {"text": "1) We introduce a systematic way of parsing NL text, based on context-free grammar (CFG).", "labels": [], "entities": [{"text": "parsing NL text", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.8895558714866638}]}, {"text": "2) Evaluation is enhanced in terms of both data set construction and evaluation mechanisms.", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.9534363746643066}]}, {"text": "We split the problem set into a development set (called dev set) and a test set.", "labels": [], "entities": []}, {"text": "Only the dev set is accessible during our algorithm design (especially in designing CFG rules and in implementing the parsing algorithm), which avoids over-tuning towards the test set.", "labels": [], "entities": []}, {"text": "Three metrics (precision, recall, and F1) are employed to measure system performance from multiple perspectives, in contrast to all previous work (including the statistical ones) which only measures accuracy.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9994600415229797}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9977834820747375}, {"text": "F1", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.9998334646224976}, {"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9951730370521545}]}, {"text": "We target, in experiments, a subtype of word problems: number word problems (i.e., verbally expressed number problems, as shown in).", "labels": [], "entities": []}, {"text": "We hope to extend our techniques to handle general math word problems in the future.", "labels": [], "entities": []}, {"text": "We build a test set of over 1,500 problems and make a quantitative comparison with state-of-theart statistical methods.", "labels": [], "entities": []}, {"text": "Evaluation results show that our approach significantly outperforms baseline methods on our test set.", "labels": [], "entities": []}, {"text": "Our system yields an extremely high precision of 95.4% and a reasonable recall of 60.2%, which shows promising application of our system in precision-critical situations.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9988149404525757}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9995653033256531}]}], "datasetContent": [{"text": "Datasets: Our problem collection 5 contains 1,878 math number word problems, collected from two web sites: algebra.com 6 (a website for users to post math problems and get help from tutors) and answers.yahoo.com 7 . Problems on both sites are organized into categories.", "labels": [], "entities": []}, {"text": "For algebra.com, problems are randomly sampled from the number word problems category; for answers.yahoo.com, we first randomly sample an initial set of problems from the math category and then ask human annotators to manually choose number word problems from them.", "labels": [], "entities": []}, {"text": "Math equations 8 and answers to the problems are manually added by human annotators.", "labels": [], "entities": []}, {"text": "We randomly split the dataset into a dev set (for algorithm design and debugging) and a test set.", "labels": [], "entities": []}, {"text": "More subsets are extracted to meet the requirements of the baseline methods (see below).", "labels": [], "entities": []}, {"text": "shows the statistics of the datasets.", "labels": [], "entities": []}, {"text": "Baseline methods: We compare our approach with two baselines: KAZB (  and BasicSim.", "labels": [], "entities": [{"text": "KAZB", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.6882872581481934}, {"text": "BasicSim", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.7640471458435059}]}, {"text": "KAZB is a learning-based statistical method which solves a problem by mapping it to one of the equation templates determined by the annotated equations in the training data.", "labels": [], "entities": [{"text": "KAZB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7911785244941711}]}, {"text": "We run the ALLEQ version of their algorithm since it performs much better than the other two (i.e., 5EQ and 5EQ+ANS).", "labels": [], "entities": [{"text": "ALLEQ", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9135218262672424}, {"text": "ANS", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.5705803632736206}]}, {"text": "Their codes support only linear equations and require that there are at least two problems for each equation template (otherwise an exception will be thrown).", "labels": [], "entities": []}, {"text": "By choosing problems from the collection that meet these requirements, we build a sub-dataset called LinearT2.", "labels": [], "entities": []}, {"text": "In the dataset of KAZB, each equation template corresponds to at least 6 problems.", "labels": [], "entities": [{"text": "KAZB", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.8055272698402405}]}, {"text": "So we form another sub-dataset called LinearT6 by removing from the test set the problems for which the associated equation template appears less than 6 times.", "labels": [], "entities": []}, {"text": "BasicSim is a simple statistical method which works by computing the similarities between a testing problem and those in the training set, and then applying the equations of the most similar problem.", "labels": [], "entities": []}, {"text": "This method has similar performance with KAZB on their dataset, but does not have the two limitations mentioned above.", "labels": [], "entities": []}, {"text": "Therefore we adopt it as the second baseline.", "labels": [], "entities": []}, {"text": "For both baselines, experiments are conducted using 5-fold cross-validation with the dev set always included in the training data.", "labels": [], "entities": []}, {"text": "In other words, we always use the dev set and 4/5 of the test set as training data for each fold.", "labels": [], "entities": []}, {"text": "Evaluation metrics: Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set.", "labels": [], "entities": []}, {"text": "In other words, one has the flexibility of generating answers only when she knows how to solve it or she is confident about her answer.", "labels": [], "entities": []}, {"text": "In this setting, the following three metrics are adopted in reporting evaluation results (assuming, in a test set of size n, a system generates answers form problems, where k of them are correct):  The Overall evaluation results are summarized in, where \"Dolphin\" represents our approach.", "labels": [], "entities": []}, {"text": "The results show that our approach significantly outperforms (with p<<0.01 according to two-tailed t-test) the two baselines on every test set, in terms of precision, recall, and F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9995737671852112}, {"text": "recall", "start_pos": 167, "end_pos": 173, "type": "METRIC", "confidence": 0.9994087219238281}, {"text": "F-measure", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.9978334307670593}]}, {"text": "Our approach achieves a particularly high precision of 95%.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9994831085205078}]}, {"text": "That means once an answer is provided by our approach, it has a very high probability of being correct.", "labels": [], "entities": []}, {"text": "Please note that our grammar rules and parsing algorithm are NOT tuned for the evaluation data.", "labels": [], "entities": [{"text": "NOT", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.918009340763092}]}, {"text": "Only the dev set is referred to in system building.", "labels": [], "entities": []}, {"text": "Since the baselines generate results for all problems, the precision, recall, and F1 are all the same for each dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.999758780002594}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9991148114204407}, {"text": "F1", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9998366832733154}]}, {"text": "The reason for such a high precision is that, by transforming NL text to DOL trees, the system \"understands\" the problem (or has structured and accurate information about quantity relations).", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9981775283813477}]}, {"text": "Therefore it is more likely to generate correct results than statistical methods who simply \"guess\" according to features.", "labels": [], "entities": []}, {"text": "By examining the problems in the dev set that we cannot generate answers, we find that most of them are due to empty parsing results.", "labels": [], "entities": []}, {"text": "On the other hand, statistical approaches have the advantage of generating answers without understanding the semantic meaning of problems (as long as there are similar problems in the training data).", "labels": [], "entities": []}, {"text": "So they are able to handle (with probably low precision) problems that are complex in terms of language and logic.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9934572577476501}]}, {"text": "Please pay attention that our experimental results reported here are on number word problems.", "labels": [], "entities": []}, {"text": "General math word problems are much harder to our approach because the entity types, properties, relations, and actions contained in general word problems are much larger in quantity and more complex in quality.", "labels": [], "entities": []}, {"text": "We are working on extending our approach to general math word problems.", "labels": [], "entities": [{"text": "general math word problems", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.6258072778582573}]}, {"text": "Now our DOL language and CFG grammar already have a good coverage on common entity types, but the coverage on properties, relations, and actions is quite limited.", "labels": [], "entities": []}, {"text": "As a result, our parser fails to parse many sentences in general math word problems because they contain properties, relations or actions that are unknown to our system.", "labels": [], "entities": []}, {"text": "We also observe that sometimes we are able to parse a problem successfully, but cannot derive math expressions in the reasoning stage.", "labels": [], "entities": []}, {"text": "This is often because some relations or actions in the problem are not modeled appropriately.", "labels": [], "entities": []}, {"text": "As future work, we plan to extend our DOL lexicon and grammar to improve the coverage of properties, relations, and actions.", "labels": [], "entities": []}, {"text": "We also plan to study the mechanism of modeling relations and actions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Dataset statistics (Linear: problems with  linear equations; T2: problems corresponding to  template size \u2265 2)", "labels": [], "entities": []}]}