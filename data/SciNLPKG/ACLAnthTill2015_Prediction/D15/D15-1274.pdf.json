{"title": [{"text": "Arabic Diacritization with Recurrent Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Arabic, Hebrew, and similar languages are typically written without diacritics, leading to ambiguity and posing a major challenge for core language processing tasks like speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.7654034495353699}]}, {"text": "Previous approaches to automatic diacritization employed a variety of machine learning techniques.", "labels": [], "entities": [{"text": "automatic diacritization", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.5311847180128098}]}, {"text": "However, they typically rely on existing tools like morphological analyzers and therefore cannot be easily extended to new genres and languages.", "labels": [], "entities": []}, {"text": "We develop a recurrent neural network with long short-term memory layers for predicting diacritics in Arabic text.", "labels": [], "entities": [{"text": "predicting diacritics in Arabic text", "start_pos": 77, "end_pos": 113, "type": "TASK", "confidence": 0.8548670530319213}]}, {"text": "Our language-independent approach is trained solely from diacritized text without relying on external tools.", "labels": [], "entities": []}, {"text": "We show experimentally that our model can rival state-of-the-art methods that have access to additional resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hebrew, Arabic, and other languages based on the Arabic script usually represent only consonants in writing and do not mark vowels.", "labels": [], "entities": []}, {"text": "In such writing systems, diacritics are used for marking short vowels, gemination, and other phonetic units.", "labels": [], "entities": []}, {"text": "In practice, diacritics are usually restricted to specific settings such as language teaching or to religious texts.", "labels": [], "entities": []}, {"text": "Faced with a non-diacritized word, readers infer missing diacritics based on their prior knowledge and the context of the word in order to resolve ambiguities.", "labels": [], "entities": []}, {"text": "In practice, a morphological analyzer like MADA ( produces at least 13 different diacritized forms for this word, a subset of which is shown in.", "labels": [], "entities": []}, {"text": "The ambiguity in Arabic orthography presents a problem for many language processing tasks, including acoustic modeling for speech recognition, language modeling, text-to-speech, and morphological analysis.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.718636691570282}, {"text": "language modeling", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.7750301957130432}, {"text": "morphological analysis", "start_pos": 182, "end_pos": 204, "type": "TASK", "confidence": 0.7683861553668976}]}, {"text": "Automatic methods for diacritization aim to restore diacritics in a non-diacritized text.", "labels": [], "entities": []}, {"text": "While earlier work used rule-based methods, more recent studies attempted to learn a diacritization model from diacritized text.", "labels": [], "entities": []}, {"text": "A variety of methods have been used, including hidden Markov models, finite-state transducers, and maximum entropy -see the review in) -and more recently, deep neural networks).", "labels": [], "entities": []}, {"text": "In addition to learning from diacritized text, these methods typically rely on external resources such as part-of-speech taggers and morphological analyzers like the MADA tool.", "labels": [], "entities": []}, {"text": "However, building such resources is a labor-intensive task and cannot be easily extended to new languages, dialects, and domains.", "labels": [], "entities": []}, {"text": "In this work, we propose a diacritization method based solely on diacritized text.", "labels": [], "entities": []}, {"text": "We treat the problem as a sequence classification task, where each character has a corresponding diacritic label.", "labels": [], "entities": [{"text": "sequence classification task", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.796835700670878}]}, {"text": "The sequence is modeled with a recurrent neural network whose input is a sequence of characters and whose output is a probability distribution over the diacritics.", "labels": [], "entities": []}, {"text": "Any RNN architecture can be used in this framework; here we focus on long short-term memory (LSTM) networks, which have shown recent success in a number of NLP tasks.", "labels": [], "entities": []}, {"text": "We experiment with several architectures and show that we can achieve state-of-the-art results, without relying on external resources.", "labels": [], "entities": []}, {"text": "Error analysis demonstrates the benefit of using LSTM over simpler neural networks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data We extract diacritizied and non-diacritized texts from the Arabic treebank, following the Train/Dev/Test split in (.", "labels": [], "entities": []}, {"text": "provides statistics for the corpus.", "labels": [], "entities": []}, {"text": "Every character in our corpus has a label corresponding to 0, 1, or 2 diacritics, in the case of the gemination marker combining with another diacritic.", "labels": [], "entities": []}, {"text": "Thus the label set almost doubles.", "labels": [], "entities": []}, {"text": "We opted for this formulation due to its simplicity and generalizability to other languages, even though previous work reported improved results by first predicting gemination and then all other diacritics (.", "labels": [], "entities": []}, {"text": "Results shows the results of our models on the Dev set in terms of the diacritic error rate (DER).", "labels": [], "entities": [{"text": "Dev set", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9282855093479156}, {"text": "diacritic error rate (DER)", "start_pos": 71, "end_pos": 97, "type": "METRIC", "confidence": 0.8695819278558096}]}, {"text": "Clearly, LSTM models perform much better than simple feed-forward networks.", "labels": [], "entities": []}, {"text": "To make the comparison fair, we increased the number of parameters in the feed-forward model to match that of the LSTM.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 114, "end_pos": 118, "type": "DATASET", "confidence": 0.7984505891799927}]}, {"text": "In this setting, the LSTM is still much better, indicating that it is far more successful at exploiting the larger parameter set.", "labels": [], "entities": []}, {"text": "Interestingly, the bidirectional LSTM works better than a unidirectional one, despite having less parameters.", "labels": [], "entities": []}, {"text": "Finally, deeper models achieve the best results.", "labels": [], "entities": []}, {"text": "On the Test set, our 3-layer B-LSTM model beats the lexical variant of Zitouni and Sarikaya (2009) by 3.25% DER, a 40% error reduction.", "labels": [], "entities": [{"text": "DER", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9990226030349731}, {"text": "error reduction", "start_pos": 119, "end_pos": 134, "type": "METRIC", "confidence": 0.9612305462360382}]}, {"text": "Moreover, we outperform their best model, which also used a segmenter and part-of- speech tagger.", "labels": [], "entities": []}, {"text": "This shows that our model can effectively learn to diacritize without relying on any resources other than diacritized text.", "labels": [], "entities": []}, {"text": "Finally, some studies report work on a Train/Test data split, without a dedicated Dev set ().", "labels": [], "entities": [{"text": "Train/Test data split", "start_pos": 39, "end_pos": 60, "type": "DATASET", "confidence": 0.6928509473800659}]}, {"text": "We were reluctant to follow this setting so we performed all development on the Dev set of).", "labels": [], "entities": [{"text": "Dev set", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9439451992511749}]}, {"text": "Still, we ran our best model on the Train/Test split and achieved a DER of 5.39% on all diacritics and 8.74% on case endings.", "labels": [], "entities": [{"text": "Train/Test split", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.9040061831474304}, {"text": "DER", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9996821880340576}]}, {"text": "The first result is behind the state-of-theart) by 2% but the second one is better by 3%.", "labels": [], "entities": []}, {"text": "Given that we did not tune the system for this data set, this result is encouraging.", "labels": [], "entities": []}, {"text": "Error Analysis A quantitative analysis of the errors produced by one of our models on the Dev set is shown in.", "labels": [], "entities": [{"text": "Error Analysis", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7077127248048782}, {"text": "Dev set", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.8800461888313293}]}, {"text": "The heat map denotes the number of errors produced.", "labels": [], "entities": []}, {"text": "The major source of errors comes from confusing the short vowels a, i, and u, among themselves and with no diacritic.", "labels": [], "entities": []}, {"text": "This is expected due to the high rate of short vowels in Arabic compared to other diacritics.", "labels": [], "entities": []}, {"text": "It also explains why methods that take the confusion matrix into account in their classification algorithm do quite well).", "labels": [], "entities": []}, {"text": "We also analyzed some errors qualitatively.", "labels": [], "entities": []}, {"text": "shows the errors produced by several of our diacritization models on a sample sentence.", "labels": [], "entities": []}, {"text": "In-  terestingly, the simple feed-forward model fails to predict the correct case ending on the word AlqaDA}iy~ap (\"judicial\"), while both LSTM models succeed.", "labels": [], "entities": []}, {"text": "This may indicate that LSTM indeed captures the kind of long-distance dependencies that are responsible for case marking.", "labels": [], "entities": [{"text": "case marking", "start_pos": 108, "end_pos": 120, "type": "TASK", "confidence": 0.8548457026481628}]}, {"text": "Other errors are more difficult to explain, but note that all models struggle with the proper name tuwayoniy~ (\"Tueini\"), which is difficult to solve without external resources.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Arabic diacritization corpus statistics.", "labels": [], "entities": []}, {"text": " Table 4: Diacrtic error rates (DERs) on the Dev  set, over all diacritics and only at word ending.", "labels": [], "entities": [{"text": "Diacrtic error rates (DERs)", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.8101889789104462}, {"text": "Dev  set", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.8356525599956512}]}, {"text": " Table 5: Results (DER) on the Test set. MaxEnt  results from (Zitouni and Sarikaya, 2009)", "labels": [], "entities": [{"text": "DER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9490659832954407}, {"text": "Test set", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9190652370452881}, {"text": "MaxEnt", "start_pos": 41, "end_pos": 47, "type": "DATASET", "confidence": 0.8177815675735474}]}]}