{"title": [], "abstractContent": [{"text": "We consider the problem of embedding knowledge graphs (KGs) into continuous vector spaces.", "labels": [], "entities": []}, {"text": "Existing methods can only deal with explicit relationships within each triple, i.e., local connectivity patterns , but cannot handle implicit relationships across different triples, i.e., contextual connectivity patterns.", "labels": [], "entities": []}, {"text": "This paper proposes context-dependent KG embedding, a two-stage scheme that takes into account both types of connectivity patterns and obtains more accurate embeddings.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the tasks of link prediction and triple classification, and achieve significant and consistent improvements over state-of-the-art methods.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.8131072521209717}, {"text": "triple classification", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.7937834560871124}]}], "introductionContent": [{"text": "Knowledge Graphs (KGs) like WordNet,, and DBpedia () have become extremely useful resources for many NLP-related applications.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9602377414703369}, {"text": "DBpedia", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.8946686387062073}]}, {"text": "A KG is a directed graph whose nodes correspond to entities and edges to relations.", "labels": [], "entities": []}, {"text": "Each edge is a triple of the form (h, r, t), indicating that entities hand tare connected by relation r.", "labels": [], "entities": []}, {"text": "Although powerful in representing complex data, the symbolic nature makes KGs hard to manipulate.", "labels": [], "entities": []}, {"text": "Recently, knowledge graph embedding has attracted much attention.", "labels": [], "entities": [{"text": "knowledge graph embedding", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6968355377515157}]}, {"text": "It attempts to embed entities and relations in a KG into a continuous vector space, so as to simplify the manipulation while preserving the inherent structure of the original graph.", "labels": [], "entities": []}, {"text": "Most of the existing KG embedding methods model triples individually, ignoring the fact that * Corresponding author: Quan Wang.", "labels": [], "entities": []}, {"text": "entities connected to a same node are usually implicitly related to each other, even if they are not directly connected.", "labels": [], "entities": []}, {"text": "Shaquille O Neal and NBA in the former example and Nevada and Utah in the latter example are implicitly related to each other, through the intermediate nodes Phoenix Suns and USA respectively.", "labels": [], "entities": [{"text": "NBA", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.9002938866615295}, {"text": "USA", "start_pos": 175, "end_pos": 178, "type": "DATASET", "confidence": 0.9557934403419495}]}, {"text": "We refer to such implicit relationships as contextual connectivity patterns (CCPs).", "labels": [], "entities": []}, {"text": "Relationships explicitly represented in triples are referred to as local connectivity patterns (LCPs).", "labels": [], "entities": []}, {"text": "In most of the existing methods, only LCPs are explicitly modeled.", "labels": [], "entities": []}, {"text": "This paper proposes a two-stage embedding scheme that explicitly takes into account both CCPs and LCPs, called context-dependent KG embedding.", "labels": [], "entities": []}, {"text": "In the first stage, each CCP is formalized as a knowledge path, i.e., a sequence of entities and relations occurring in the pattern.", "labels": [], "entities": []}, {"text": "A word embedding model is adopted to learn embeddings of entities and relations, by taking them as pseudowords.", "labels": [], "entities": []}, {"text": "The embeddings are enforced compatible within each knowledge path, and hence can capture CCPs.", "labels": [], "entities": []}, {"text": "In the second stage, the learned embeddings are fine-tuned by an existing KG embedding technique.", "labels": [], "entities": []}, {"text": "Since such a technique requires the embeddings to be compatible on each individual triple, LCPs are also encoded.", "labels": [], "entities": []}, {"text": "The advantages of our approach are three-fold.", "labels": [], "entities": []}, {"text": "1) It fully exploits both CCPs and LCPs, and can obtain more accurate embeddings.", "labels": [], "entities": []}, {"text": "2) It is a general scheme, applicable to a wide variety of word embedding models in the first stage and KG embedding models in the second.", "labels": [], "entities": []}, {"text": "3) No auxiliary data is further required in the two-stage process, except for the original graph.", "labels": [], "entities": []}, {"text": "We evaluate our approach on two publicly available data sets, and achieve significant and consistent improvements over state-of-the-art methods in the link prediction and triple classification tasks.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 151, "end_pos": 166, "type": "TASK", "confidence": 0.7807004451751709}, {"text": "triple classification", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.6604778915643692}]}, {"text": "The learned embeddings are not only more accurate but also more stable.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test our approach on the tasks of link prediction and triple classification.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.7830870449542999}, {"text": "triple classification", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.7798014581203461}]}, {"text": "Two publicly available data sets are used.", "labels": [], "entities": []}, {"text": "The first is WN18 released by . It is a subset of WordNet, consisting of 18 relations and the entities connected by them.", "labels": [], "entities": [{"text": "WN18", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.9138721823692322}, {"text": "WordNet", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9722701907157898}]}, {"text": "The second is NELL186 released by , containing the most frequent 186 relations in NELL ( and the associated entities.", "labels": [], "entities": []}, {"text": "Triples are split into training/validation/test sets, used for model training, parameter tuning, and evaluation respectively.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.7273463904857635}]}, {"text": "Knowledge paths are extracted from training sets.", "labels": [], "entities": []}, {"text": "gives some statistics of the data sets.", "labels": [], "entities": []}, {"text": "To perform context-dependent KG embedding, we use CBOW and Skip-gram in the pre-training stage, and SME, TransE, and SE in the fine-tuning stage.", "labels": [], "entities": [{"text": "SME", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.7303601503372192}, {"text": "SE", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.9966886639595032}]}, {"text": "We take randomly initialized SME, TransE, and SE as baselines, denoted as *-Random.", "labels": [], "entities": [{"text": "SE", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.9973637461662292}]}, {"text": "We do not compare to the setting that employs only CBOW or Skip-gram, since it does not provide an energy function to calculate triple plausibility, which hinders the evaluation of both tasks.", "labels": [], "entities": []}, {"text": "For SE, only entity vectors are initialized by pre-trained embeddings.", "labels": [], "entities": [{"text": "SE", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9791537523269653}]}, {"text": "Relation matrices are randomly initialized.", "labels": [], "entities": []}, {"text": "3 https://everest.hds.utc.fr/doku.php?id=en:smemlj12 4 http://www.aclweb.org/anthology/P/P15/", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Entity/Relation embeddings and energy functions used in KG embedding methods.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of the data sets.", "labels": [], "entities": []}, {"text": " Table 3: Link prediction results on the test sets of WN18 and NELL186.", "labels": [], "entities": [{"text": "WN18", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.9556536078453064}, {"text": "NELL186", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8351014852523804}]}, {"text": " Table 4: Triple classification results on the test sets of WN18 and NELL186.", "labels": [], "entities": [{"text": "Triple classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7855373620986938}, {"text": "WN18", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.9533388614654541}, {"text": "NELL186", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.8481303453445435}]}]}