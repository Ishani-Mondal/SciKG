{"title": [{"text": "An Unsupervised Bayesian Modelling Approach to Storyline Detection from News Articles", "labels": [], "entities": [{"text": "Storyline Detection from News Articles", "start_pos": 47, "end_pos": 85, "type": "TASK", "confidence": 0.8175685405731201}]}], "abstractContent": [{"text": "Storyline detection from news articles aims at summarizing events described under a certain news topic and revealing how those events evolve overtime.", "labels": [], "entities": [{"text": "Storyline detection from news articles", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8745219111442566}, {"text": "summarizing events described under a certain news topic", "start_pos": 47, "end_pos": 102, "type": "TASK", "confidence": 0.8098246306180954}]}, {"text": "It is a difficult task because it requires first the detection of events from news articles published in different time periods and then the construction of storylines by linking events into coherent news stories.", "labels": [], "entities": [{"text": "detection of events from news articles published in different time periods", "start_pos": 53, "end_pos": 127, "type": "TASK", "confidence": 0.8079366846518083}]}, {"text": "Moreover , each storyline has different hierarchical structures which are dependent across epochs.", "labels": [], "entities": []}, {"text": "Existing approaches often ignore the dependency of hierarchical structures in storyline generation.", "labels": [], "entities": [{"text": "storyline generation", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.834190160036087}]}, {"text": "In this paper, we propose an unsupervised Bayesian model, called dynamic storyline detection model, to extract structured representations and evolution patterns of storylines.", "labels": [], "entities": [{"text": "dynamic storyline detection", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.6593897640705109}]}, {"text": "The proposed model is evaluated on a large scale news corpus.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed model outperforms several baseline approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "The rapid development of online news media sites is accompanied by the generation of tremendous news reports.", "labels": [], "entities": []}, {"text": "Facing such massive amount of news articles, it is crucial to develop an automated tool which can provide a temporal summary of events and their evolutions related to a topic from news reports.", "labels": [], "entities": []}, {"text": "Therefore, storyline detection, aiming at summarising the development of certain related events, has been studied in order to help readers quickly understand the major events reported in news articles.", "labels": [], "entities": [{"text": "storyline detection", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.9636444747447968}]}, {"text": "It has attracted great attention recently.", "labels": [], "entities": []}, {"text": "proposed a trend analysis model which used the difference between temporal words and other words in each document to detect topic evolution overtime.", "labels": [], "entities": []}, {"text": "proposed a unified framework to group temporally and topically related news articles into same storylines in order to reveal the temporal evolution of events.", "labels": [], "entities": []}, {"text": "developed a topic-user-trend model, which incorporates user interests into the generative process of web contents.", "labels": [], "entities": [{"text": "generative process of web contents", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.8635435581207276}]}, {"text": "built storylines based on text clustering and entity entropy to predict future events.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.6937400996685028}]}, {"text": "developed a mixture-event-aspect model to model sub-events into local and global aspects and utilize an optimization method to generate storylines.", "labels": [], "entities": []}, {"text": "proposed an evolutionary multi-branch tree clustering method for streaming text data in which the tree construction is casted as an online posterior estimation problem by considering both the current tree and the previous tree simultaneously.", "labels": [], "entities": []}, {"text": "With the fast development of social media platforms, newsworthy events are widely scattered not only on traditional news media but also on social media (.", "labels": [], "entities": []}, {"text": "For example, Twitter, one of the most widely adopted social media platforms, appears to cover nearly all newswire events (.", "labels": [], "entities": []}, {"text": "Therefore, approaches have also been proposed for storyline summarization on social media.", "labels": [], "entities": [{"text": "storyline summarization", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.9458585977554321}]}, {"text": "Given a user input query of an ongoing event, extracted the storyline of an event by first obtaining relevant tweets and then generating storylines via graph optimization.", "labels": [], "entities": []}, {"text": "In (, an evolutionary hierarchical Dirichlet process was proposed to capture the topic evolution pattern in storyline summarization.", "labels": [], "entities": []}, {"text": "However, most of the aforementioned approaches do not represent events in the form of structured representation.", "labels": [], "entities": []}, {"text": "More importantly, they ignore the dependency of the hierarchical structures of events at different epochs in a storyline.", "labels": [], "entities": []}, {"text": "In this paper, we propose a dynamic storyline detection model to overcome the above limitations.", "labels": [], "entities": [{"text": "dynamic storyline detection", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.6757589975992838}]}, {"text": "We assume that each document could belong to one storyline s, which is modelled as a joint distribution over some named entities e and a set of topics z.", "labels": [], "entities": []}, {"text": "Furthermore, to link events at different epochs and detect different types of storylines, the weighted sum of storyline distribution of previous epochs is employed as the prior of the current storyline distribution.", "labels": [], "entities": []}, {"text": "The proposed model is evaluated on a large scale news corpus.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed model outperforms several baseline approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "We crawled and parsed the GDELT Event Database 1 containing news articles published in May 2014.", "labels": [], "entities": [{"text": "GDELT Event Database 1 containing news articles published in May 2014", "start_pos": 26, "end_pos": 95, "type": "DATASET", "confidence": 0.9401344819502397}]}, {"text": "We manually annotated one-week data containing 101,654 documents and identified 77 storylines for evaluation.", "labels": [], "entities": []}, {"text": "We also report the results of our model on the one-month data containing 526,587 documents.", "labels": [], "entities": []}, {"text": "But we only report the precision and not recall of the storylines extracted since it is time consuming to identify all the true storylines in such a large dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9995842576026917}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9990643858909607}]}, {"text": "In our experiments, we used the Stanford Named Entity Recognizer for identifying the named entities.", "labels": [], "entities": [{"text": "Stanford Named Entity Recognizer", "start_pos": 32, "end_pos": 64, "type": "DATASET", "confidence": 0.8022252172231674}]}, {"text": "In addition, we removed common stopwords and only kept tokens which are verbs, nouns, or adjectives in these news articles.", "labels": [], "entities": []}, {"text": "To evaluate the performance of the proposed approach, we use precision, recall and F-score which are commonly used in evaluating information extraction systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9997403025627136}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9994957447052002}, {"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9990398287773132}, {"text": "information extraction", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.7487688064575195}]}, {"text": "The precision is calculated based on the following criteria: 1) The entities and keywords extracted refer to the same storyline.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9993636012077332}]}, {"text": "2) The duration of the storyline is correct.", "labels": [], "entities": [{"text": "duration", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.995867133140564}]}, {"text": "We assume that the start date (or end date) of a storyline is the publication date of the first (or last) news article about it.", "labels": [], "entities": []}, {"text": "The proposed model is compared against the baseline approaches on the annotated one-week data which consist of 77 storylines.", "labels": [], "entities": []}, {"text": "The number of storylines, S, and the number of topics, K, are both set to 100.", "labels": [], "entities": []}, {"text": "The number of historical epochs, M , which is taken into account for setting the Dirichlet priors for the storyline-topicword, the storyline-topic and the storyline-entity distributions, is set to 7.", "labels": [], "entities": []}, {"text": "The evaluation results of our proposed approach in comparison to the three baselines are presented in: Performance comparison of the storyline extraction results in terms of Precision (%), Recall (%) and F-score (%).", "labels": [], "entities": [{"text": "storyline extraction", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.7885187566280365}, {"text": "Precision", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9974675178527832}, {"text": "Recall", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.9969807267189026}, {"text": "F-score", "start_pos": 204, "end_pos": 211, "type": "METRIC", "confidence": 0.9980278611183167}]}, {"text": "It can be observed from that simply using K-means to cluster news articles in each day and linking similar stories across different days in hoping of identifying storylines gives the worst results.", "labels": [], "entities": []}, {"text": "Using LDA to detect stories in each day improves the precision dramatically.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9996633529663086}]}, {"text": "The dynamic LDA model assumes topics (or stories) in the current epoch evolves from the previous epoch and further improves the storyline detection results significantly.", "labels": [], "entities": [{"text": "storyline detection", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7958735227584839}]}, {"text": "Our proposed model aims to capture the long distance dependencies in which the statistics gathered in the past 7 days are taken into account to set the Dirichlet priors of the storyline-topic-word, storyline-topic and storyline-entity distributions in the current epoch.", "labels": [], "entities": [{"text": "Dirichlet priors", "start_pos": 152, "end_pos": 168, "type": "METRIC", "confidence": 0.9364435374736786}]}, {"text": "It gives the best performance and outperforms dynamic LDA by nearly 7% in F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9561508893966675}]}, {"text": "To study the impact of the number of topics on the performance of the proposed model, we conducted experiments on the one-month data with different number of topics varying between 100 and 200.", "labels": [], "entities": []}, {"text": "In all these experiments, the number of storylines, S, is set to 200, based on the speculation that about 40 storylines in the annotated one-week data last for one month and about 40 new storylines occur each week.", "labels": [], "entities": []}, {"text": "Figure 2: Storyline about the patent infringement case between Apple and Samsung was extracted by the proposed Model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance comparison of the storyline  extraction results in terms of Precision (%), Recall  (%) and F-score (%).", "labels": [], "entities": [{"text": "storyline  extraction", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7721372246742249}, {"text": "Precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9986974596977234}, {"text": "Recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9987239241600037}, {"text": "F-score", "start_pos": 113, "end_pos": 120, "type": "METRIC", "confidence": 0.9990366697311401}]}, {"text": " Table 2 shows the precision of the  proposed method under different number of topic- s. It can be observed that the performance of the  proposed approach is quite stable across different  number of topics.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9990352392196655}]}]}