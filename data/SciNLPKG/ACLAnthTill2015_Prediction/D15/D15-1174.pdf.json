{"title": [{"text": "Representing Text for Joint Embedding of Text and Knowledge Bases", "labels": [], "entities": [{"text": "Representing Text", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8837276995182037}]}], "abstractContent": [{"text": "Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9986552000045776}]}, {"text": "In this paper we propose a model that captures the compositional structure of tex-tual relations, and jointly optimizes entity, knowledge base, and textual relation representations.", "labels": [], "entities": []}, {"text": "The proposed model significantly improves performance over a model that does not share parameters among tex-tual relations with common sub-structure.", "labels": [], "entities": []}], "introductionContent": [{"text": "Representing information about real-world entities and their relations in structured knowledge base (KB) form enables numerous applications.", "labels": [], "entities": []}, {"text": "Large, collaboratively created knowledge bases have recently become available e.g.,,, and DBPedia (, but even though they are impressively large, their coverage is far from complete.", "labels": [], "entities": [{"text": "DBPedia", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.9467541575431824}]}, {"text": "This has motivated research in automatically deriving new facts to extend a manually built knowledge base, by using information from the existing knowledge base, textual mentions of entities, and semi-structured data such as tables and web forms (.", "labels": [], "entities": []}, {"text": "In this paper we build upon the work of, which jointly learns continuous representations for knowledge base and textual relations.", "labels": [], "entities": []}, {"text": "This common representation in the same vector space can serve as a kind of \"universal schema\" which admits joint inferences among * This research was conducted during the author's internship at Microsoft Research.", "labels": [], "entities": []}, {"text": "The textual relations represent the relationships between entities expressed in individual sentences (see for an example).", "labels": [], "entities": []}, {"text": "represented each textual mention of an entity pair by the lexicalized dependency path between the two entities (see).", "labels": [], "entities": []}, {"text": "Each such path is treated as a separate relation in a combined knowledge graph including both KB and textual relations.", "labels": [], "entities": []}, {"text": "Following prior work in latent feature models for knowledge base completion, every textual relation receives its own continuous representation, learned from the pattern of its co-occurrences in the knowledge graph.", "labels": [], "entities": [{"text": "knowledge base completion", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6296665966510773}]}, {"text": "However, largely synonymous textual relations often share common sub-structure, and are composed of similar words and dependency arcs.", "labels": [], "entities": []}, {"text": "For example, shows a collection of dependency paths co-occurring with the person/organizations founded relation.", "labels": [], "entities": []}, {"text": "In this paper we model this sub-structure and share parameters among related dependency paths, using a unified loss function learning entity and relation representations to maximize performance on the knowledge base link prediction task.", "labels": [], "entities": [{"text": "knowledge base link prediction task", "start_pos": 201, "end_pos": 236, "type": "TASK", "confidence": 0.6537911474704743}]}, {"text": "We evaluate our approach on the FB15k-237 dataset, a knowledge base derived from the Free-base subset) and filtered to remove highly redundant relations (.", "labels": [], "entities": [{"text": "FB15k-237 dataset", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9934524893760681}]}, {"text": "The knowledge base is paired with textual mentions for all entity pairs derived from ClueWeb12 1 with Freebase entity mention annotations (.", "labels": [], "entities": []}, {"text": "We show that using a convolutional neural network to derive continuous representations for textual relations boosts the overall performance on link prediction, with larger improvement on entity pairs that have textual mentions.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 143, "end_pos": 158, "type": "TASK", "confidence": 0.7548602819442749}]}], "datasetContent": [{"text": "We use the FB15k-237 4 dataset, which is a subset of FB15k ( ) that excludes redundant relations and direct training links for held-out triples, with the goal of making the task more realistic.", "labels": [], "entities": [{"text": "FB15k-237 4 dataset", "start_pos": 11, "end_pos": 30, "type": "DATASET", "confidence": 0.8681961496671041}, {"text": "FB15k", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.9782604575157166}]}, {"text": "The FB15k dataset has been used in multiple studies on knowledge base completion (.", "labels": [], "entities": [{"text": "FB15k dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9726120233535767}, {"text": "knowledge base completion", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.6464615166187286}]}, {"text": "Textual relations for FB15k-237 are extracted from 200 million sentences in the ClueWeb12 corpus coupled with Freebase mention annotations (, and include textual links of all co-occurring entities from the KB set.", "labels": [], "entities": [{"text": "FB15k-237", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.9739306569099426}, {"text": "ClueWeb12 corpus", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.9328730702400208}, {"text": "KB set", "start_pos": 206, "end_pos": 212, "type": "DATASET", "confidence": 0.7820428311824799}]}, {"text": "After pruning 5 , there are 2.7 million unique textual relations that are added to the knowledge graph.", "labels": [], "entities": []}, {"text": "The set of textual relations is larger than the set used in (25,000 versus 2.7 million), leading to improved performance.", "labels": [], "entities": []}, {"text": "The number of relations and triples in the training, validation and test portions of the data are given in.", "labels": [], "entities": []}, {"text": "The two rows list statistics for the KB and text portions of the data separately.", "labels": [], "entities": []}, {"text": "The 2.7 million textual relations occur in 3.9 million text triples.", "labels": [], "entities": []}, {"text": "Almost all entities occur in textual relations (13,937 out of 14,541).", "labels": [], "entities": []}, {"text": "The numbers of triples for textual relations are shown as zero for the validation and test sets because we don't evaluate on prediction of textual relations (all text triples are used in training).", "labels": [], "entities": []}, {"text": "The percentage of KB triples that have textual relations for their pair of entities is 40.5% for the training, 26.6% for the validation, and 28.1% for the test set.", "labels": [], "entities": []}, {"text": "While 26.6% of the validation set triples have textual mentions, the percentage with textual relations that have been seen in the training set is 18.4%.", "labels": [], "entities": []}, {"text": "Having a mention increases the chance that a random entity pair has a relation from 0.1% to 5.0% -a fifty-fold increase.", "labels": [], "entities": []}, {"text": "Given a set of triples in a set disjoint from a training knowledge graph, we test models on predicting the object of each triple, given the subject and relation type.", "labels": [], "entities": []}, {"text": "We rank all entities in the training knowledge base in order of their likelihood of filling the argument position.", "labels": [], "entities": []}, {"text": "We report the mean reciprocal rank (MRR) of the correct entity, as well as HITS@10 -the percentage of test triples for which the correct entity is ranked in the top 10.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 14, "end_pos": 40, "type": "METRIC", "confidence": 0.9003388086954752}, {"text": "HITS@10", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9709934790929159}]}, {"text": "We use filtered measures following the protocol proposed in  -that is, when we rank entities fora given position, we remove all other entities that are known to be part of an existing triple in the training, validation, or test set.", "labels": [], "entities": []}, {"text": "This avoids penalizing the model for ranking other correct fillers higher than the tested entity.", "labels": [], "entities": []}, {"text": "In we show the performance of different models and their combinations 6 , both when using textual mentions (KB+text), and when using only knowledge base relations (KB only).", "labels": [], "entities": []}, {"text": "In the KB+text setting, we evaluate the contribution of the CONV representations of the textual relations.", "labels": [], "entities": []}, {"text": "The upper portion of the were chosen to maximize MRR on the validation set.", "labels": [], "entities": [{"text": "MRR", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8567724823951721}]}, {"text": "The reported numbers were obtained for the test set.", "labels": [], "entities": []}, {"text": "base relations, and are not using any information from textual mentions.", "labels": [], "entities": []}, {"text": "The lower portion of the the performance when textual relations are added to the training knowledge graph and the corresponding training loss function.", "labels": [], "entities": []}, {"text": "Note that all models predict based on the learned knowledge base relation and entity representations, and the textual relations are only used at training time when they can impact these representations.", "labels": [], "entities": []}, {"text": "The performance of all models is shown as an overall MRR (scaled by 100) and HITS@10, as well as performance on the subset of triples that have textual mentions (column With mentions), and ones that do not (column Without mentions).", "labels": [], "entities": [{"text": "MRR", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9987768530845642}, {"text": "HITS", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9990112781524658}]}, {"text": "Around 28% of the test triples have mentions and contribute toward the measures in the With mentions column, and the other 72% of the test triples contribute to the Without mentions column.", "labels": [], "entities": [{"text": "With", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9323734641075134}]}, {"text": "For the KB-only models, we seethe performance of each individual model F, E, and DIST-MULT.", "labels": [], "entities": [{"text": "DIST-MULT", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9740889072418213}]}, {"text": "Model F was the best performing single model from (), but it does not perform well when textual mentions are not used.", "labels": [], "entities": []}, {"text": "In our implementation of model F, we created entity pair parameters only for entity pairs that cooccur in the text data ( also trained pairwise vectors for co-occuring entities only, but all of the training and test tuples in their study were co-occurring) . Without textual information, model F is performing essentially randomly, because entity pairs in the test sets do not occur in training set relations (by construction of the dataset).", "labels": [], "entities": []}, {"text": "Model E is able to do surprisingly well, given that it is making predictions for each object position of a relation without considering the given subject of the relation.", "labels": [], "entities": []}, {"text": "DISTMULT is the best performing single model.", "labels": [], "entities": [{"text": "DISTMULT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7819404602050781}]}, {"text": "Unlike model F, it is able to share parameters among entity pairs with common subject or object entities, and, unlike model E, it captures some dependencies between the subject and object entities of a relation.", "labels": [], "entities": []}, {"text": "The combination of models E+DISTMULT improves performance, but combining model F with the other two is not helpful.", "labels": [], "entities": [{"text": "DISTMULT", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9775620102882385}]}, {"text": "The lower portion of shows results when textual relations are added to the training knowledge graph.", "labels": [], "entities": []}, {"text": "The basic models treat the textual relations as atomic and learn a separate latent feature vector for each textual relation.", "labels": [], "entities": []}, {"text": "The CONV-models use the compositional representations of tex-tual relations learned using the convolutional neural network architecture shown in.", "labels": [], "entities": [{"text": "CONV-models", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8350753784179688}]}, {"text": "We show the performance of each individual model and its corresponding variant with a CONV parameterization.", "labels": [], "entities": []}, {"text": "For each model, we also show the optimal value of \u03c4 , the weight of the textual relations loss.", "labels": [], "entities": []}, {"text": "Model F is able to benefit from textual relations and its performance increases by 2.5 points in MRR, with the gain in performance being particularly large on test triples with textual mentions.", "labels": [], "entities": [{"text": "MRR", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.44545575976371765}]}, {"text": "Model F is essentially limiting its space of considered argument fillers to ones that have cooccurred with the given subject entity.", "labels": [], "entities": []}, {"text": "This gives it an advantage on test triples with textual mentions, but model F still does relatively very poorly overall when taking into account the much more numerous test triples without textual mentions.", "labels": [], "entities": []}, {"text": "The CONV parameterization performs slightly worse in MRR, but slightly better in HITS@10, compared to the atomic parameterization.", "labels": [], "entities": [{"text": "CONV", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.8736987709999084}, {"text": "MRR", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.4051346480846405}]}, {"text": "For model E and its CONV variant, we see that text does not help as its performance using text is the same as that when not using text and the optimal weight of the text is zero.", "labels": [], "entities": []}, {"text": "Model DISTMULT benefits from text, and its convolutional text variant CONV-DISTMULT outperforms the basic model, with the gain being larger on test triples with mentions.", "labels": [], "entities": []}, {"text": "The best model overall, as in the KB-only case, is E+DISTMULT.", "labels": [], "entities": [{"text": "E+DISTMULT", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.8527950445810953}]}, {"text": "The basic model benefits from text slightly and the model with compositional representations of textual patterns CONV-E+CONV-DISTMULT, improves the performance further, by 2.4 MRR overall, and by 5 MRR on triples with textual mentions.", "labels": [], "entities": [{"text": "MRR", "start_pos": 176, "end_pos": 179, "type": "METRIC", "confidence": 0.9977238774299622}, {"text": "MRR", "start_pos": 198, "end_pos": 201, "type": "METRIC", "confidence": 0.99610435962677}]}, {"text": "It is interesting that the text and the compositional representations helped most for this combined model.", "labels": [], "entities": []}, {"text": "One hypothesis is that model E, which provides a prior over relation arguments, is needed in combination with DISTMULT to prevent the prediction of unlikely arguments based on noisy inference from textual patterns and their individual words and dependency links.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The statistics of dataset FB15k-237.", "labels": [], "entities": [{"text": "FB15k-237", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.5816429853439331}]}, {"text": " Table 3: Results on FB15k-237 for KB only and KB+text inference, with basic models versus the pro- posed CONV-augmented models. The values of the hyper-parameter \u03c4 (as shown in the", "labels": [], "entities": [{"text": "FB15k-237", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.9276461601257324}]}]}