{"title": [{"text": "Automatic recognition of habituals: a three-way classification of clausal aspect", "labels": [], "entities": [{"text": "Automatic recognition of habituals", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7275368124246597}]}], "abstractContent": [{"text": "This paper provides the first fully automatic approach for classifying clauses with respect to their aspectual properties as habitual, episodic or static.", "labels": [], "entities": []}, {"text": "We bring together two strands of previous work, which address only the related tasks of the episodic-habitual and stative-dynamic distinctions, respectively.", "labels": [], "entities": []}, {"text": "Our method combines different sources of information found to be useful for these tasks.", "labels": [], "entities": []}, {"text": "We are the first to exhaustively classify all clauses of a text, achieving up to 80% accuracy (baseline 58%) for the three-way classification task, and up to 85% accuracy for related subtasks (baselines 50% and 60%), outperforming previous work.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9991657733917236}, {"text": "three-way classification task", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.6878025730450948}, {"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9983521699905396}]}, {"text": "In addition , we provide anew large corpus of Wikipedia texts labeled according to our linguistically motivated guidelines.", "labels": [], "entities": []}], "introductionContent": [{"text": "In order to understand the function of a clause within a discourse, we need to know the clause's aspectual properties.", "labels": [], "entities": []}, {"text": "The distinction between dynamic and stative lexical aspect, as in examples (1a) and (1b) respectively, is fundamental.", "labels": [], "entities": []}, {"text": "Its automatic prediction has been addressed previously ().", "labels": [], "entities": [{"text": "automatic prediction", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.6093171238899231}]}, {"text": "In this work, we focus on habituality as another fundamental aspectual property.", "labels": [], "entities": []}, {"text": "While example (1a) is an episodic sentence, i.e., a sentence expressing information about a particular event, the same dynamic verb can be used to characterize the default behavior of an individual or of a kind in a certain type of situation (2).", "labels": [], "entities": []}, {"text": "(2) (a) Bill usually drinks coffee after lunch.", "labels": [], "entities": []}, {"text": "(habitual) (b) Italians drink coffee after lunch.", "labels": [], "entities": []}, {"text": "(habitual) The entailment properties of episodic and habitual (or characterizing) sentences differ substantially.", "labels": [], "entities": []}, {"text": "Also, they have different functions in discourse.", "labels": [], "entities": []}, {"text": "The episodic event expressed by (1a) is typically embedded in the temporal structure of a narration.", "labels": [], "entities": []}, {"text": "The habitual sentence (2a) can be used, e.g., as an explanation (why Bill is still sitting at the table), or in a contrastive context (today, he ordered a grappa instead).", "labels": [], "entities": []}, {"text": "Generic sentences with kind-referring subjects (2b) can also be habitual, generalizing at the same time over typical members of this kind and over situations in which they typically carryout some action.", "labels": [], "entities": []}, {"text": "Habitual sentences do not move narrative time, similar to stative clauses such as (1b).", "labels": [], "entities": []}, {"text": "considers habituals to be aspectually stative.", "labels": [], "entities": []}, {"text": "Since there are clear differences between ordinary statives such as (1b) and habituals, we apply a three-way distinction for clausal aspect in this work.", "labels": [], "entities": []}, {"text": "We classify clauses as one of the three categories habitual, episodic and static.", "labels": [], "entities": []}, {"text": "Through its impact on entailment properties and temporal discourse structure, the determination of clausal aspect is relevant to various natural language processing applications requiring text understanding, such as novelty detection), knowledge extraction from text () or question answering (.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.7064554691314697}, {"text": "novelty detection", "start_pos": 216, "end_pos": 233, "type": "TASK", "confidence": 0.7798493504524231}, {"text": "knowledge extraction from text", "start_pos": 236, "end_pos": 266, "type": "TASK", "confidence": 0.8274998217821121}, {"text": "question answering", "start_pos": 273, "end_pos": 291, "type": "TASK", "confidence": 0.8834023773670197}]}, {"text": "Using aspectual information has been shown to improve temporal relation identification.", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.7101032932599386}]}, {"text": "Some languages (e.g., Czech or Swahili) have systematic morphological markers of habituality.", "labels": [], "entities": []}, {"text": "In other languages, there are cues for habituality, such as the simple present in English, and the use of certain adverbials.", "labels": [], "entities": []}, {"text": "The automatic recognition of habitual sentences for the latter languages is non-trivial.", "labels": [], "entities": []}, {"text": "The work in this paper targets the English language; we leave recognition of habituality in other languages to future work.", "labels": [], "entities": []}, {"text": "The only previous work on categorizing sentences as episodic or habitual we know of is by.", "labels": [], "entities": []}, {"text": "They do not attempt to categorize arbitrary sentences in 'free text', however, but work with a corpus of selected sentences and use gold standard parse information for their experiments.", "labels": [], "entities": []}, {"text": "In particular, they consider clauses containing lexically dynamic verbs only.", "labels": [], "entities": []}, {"text": "In this work, we address the task of an exhaustive classification of all clauses of a text into the three aspectual classes habitual, episodic, and static.", "labels": [], "entities": []}, {"text": "Static sentences include lexically stative clauses as well as negated or modalized clauses containing a dynamic main verb.", "labels": [], "entities": []}, {"text": "A computational model for identifying episodic and habitual clauses clearly needs to address this third class as well if it is to be applied in a realistic setting.", "labels": [], "entities": []}, {"text": "Linguistically, the determination of clausal aspect depends on the recognition of the verb's lexical aspectual class (stative or dynamic), and on the recognition of any aspectual markers or transformations, such as use of the perfect tense, negations or modals.", "labels": [], "entities": [{"text": "determination of clausal aspect", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.6674826592206955}]}, {"text": "Our work builds on results for the related subtasks), using both context-based and verbtype based information.", "labels": [], "entities": []}, {"text": "Our major contributions are: (i) We create a corpus of 102 Wikipedia texts whose about 10,000 clauses are annotated as episodic, static or habitual with substantial agreement.", "labels": [], "entities": []}, {"text": "This corpus allows for studying the range of linguistic phenomena related to the clause types as defined above (compared to previous work which uses only a small set of verbs and sentences), and provides a basis for future research.", "labels": [], "entities": []}, {"text": "(ii) We provide the first fully automatic approach for this classification task, combining two classification tasks (lexical aspectual class and habituality) that have been treated separately in previous work.", "labels": [], "entities": []}, {"text": "For an exhaustive classification of clauses of free text, these two classification tasks need to be addressed jointly.", "labels": [], "entities": [{"text": "exhaustive classification of clauses of free text", "start_pos": 7, "end_pos": 56, "type": "TASK", "confidence": 0.7328587174415588}]}, {"text": "We show two different feature sets (verb-type based features and context-based features) to have different impact on the two subtasks, and to be complementary for our full three-way task.", "labels": [], "entities": []}, {"text": "We reach accuracies of nearly 85% for the two subtasks of identifying static clauses and distinguishing episodic and habitual clauses (majority class baselines are 60% and 50% respectively).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.9914781451225281}]}, {"text": "A joint model for the three-way classification task reaches an accuracy of 80% (baseline 60%).", "labels": [], "entities": [{"text": "three-way classification task", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.695128877957662}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9996596574783325}]}, {"text": "In addition, we show that the verb-type based linguistic indicator features generalize well across verb types on our tasks: for verbs unseen in the training data, accuracies drop only by 2-5%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 163, "end_pos": 173, "type": "METRIC", "confidence": 0.9951851963996887}]}], "datasetContent": [{"text": "This section describes our experiments.", "labels": [], "entities": []}, {"text": "First, we reproduce the experiments of, who use manually created syntactic parses, in a purely automatic setting.", "labels": [], "entities": []}, {"text": "The data set and experiments of Mathew and Katz (2009) focus on the episodic-habitual distinction using a set of sentences selected fora small set of verbs, and their feature design focuses on syntactic properties of the clauses found in this annotated data set.", "labels": [], "entities": []}, {"text": "In the further experiments, we turn to the Wikipedia data, which contains annotations for full texts.", "labels": [], "entities": [{"text": "Wikipedia data", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.9754157960414886}]}, {"text": "We expect the Wikipedia data to cover the range of habitual and episodic expressions more fully, and in addition, allows for studying the task of separating static sentences from the other two classes.", "labels": [], "entities": [{"text": "Wikipedia data", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.9468372166156769}]}, {"text": "As we will show, this latter task profits from including features relevant to the stative-dynamic distinction on the lexical level.", "labels": [], "entities": []}, {"text": "We first present experimental results for the two subtasks (described in Section 5.3).", "labels": [], "entities": []}, {"text": "Our CAS-CADED model first identifies static clauses, and then classifies the remaining clauses as episodic or habitual.", "labels": [], "entities": []}, {"text": "For reasons of readability, we first report on our experiments for the episodic-habitual distinction using both the M&K and Wikipedia data sets.", "labels": [], "entities": [{"text": "M&K and Wikipedia data sets", "start_pos": 116, "end_pos": 143, "type": "DATASET", "confidence": 0.8600270577839443}]}, {"text": "Using the Wikipedia data, we then report on the results for the static vs. non-static distinction.", "labels": [], "entities": [{"text": "Wikipedia data", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.9683005511760712}]}, {"text": "Finally, we turn to the full task of the three-ways distinction.", "labels": [], "entities": []}, {"text": "We report results for 10-fold cross validation (CV) with two different settings: In the RANDOM CV setting, we randomly distribute the instances over the folds, putting all instances of one document into the same fold.", "labels": [], "entities": [{"text": "cross validation (CV)", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.7237668752670288}]}, {"text": "In the UNSEEN VERBS CV setting, we simulate the case of not having labeled training data fora particular verb type by putting all instances of one verb type into the same fold.", "labels": [], "entities": [{"text": "UNSEEN VERBS CV setting", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.790991760790348}]}, {"text": "We compute the information retrieval statistics of precision (P), recall (R) and F1-measure per class, where F1 is the harmonic mean of P and R, F 1 = 2 * P * RP +R . Macro-average P is computed as the (unweighted) average of the P scores of the classes, and macro-average R is computed likewise.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9987818598747253}, {"text": "recall (R)", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9332390874624252}, {"text": "F1-measure", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9967483282089233}, {"text": "F1", "start_pos": 109, "end_pos": 111, "type": "METRIC", "confidence": 0.9827316403388977}]}, {"text": "Macro-average F1 is the harmonic mean of macro-average P and macro-average R.", "labels": [], "entities": [{"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.8716870546340942}]}, {"text": "We use McNemar's test with p < 0.01 to compute statistical signficance of differences in accuracies.", "labels": [], "entities": []}, {"text": "In our tables, we indicate that two results differ significantly by marking them with the same symbols (we only show this when scores are close).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Wikipedia data, distribution of labels for  clausal aspect.", "labels": [], "entities": [{"text": "Wikipedia data", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.9558725357055664}]}, {"text": " Table 4: Results for episodic vs. habitual, J48  decision tree, data from", "labels": [], "entities": [{"text": "J48  decision tree", "start_pos": 45, "end_pos": 63, "type": "DATASET", "confidence": 0.8781854112943014}]}, {"text": " Table 5: Wikipedia: Accuracy of episodic vs ha- bitual, 4171 instances, 10-fold cross validation,  * \u2020 \u2021differences statistically significant.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.962319016456604}, {"text": "Accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9944865107536316}]}, {"text": " Table 6: Wikipedia: static vs non-static. All  10355 instances, 10-fold cross validation.* \u2020 \u2021 dif- ferences statistically significant.", "labels": [], "entities": []}, {"text": " Table 7: Wikipedia: static vs. episodic vs. habitual. 10355 instances, 10-fold cross validation. The  CASCADED model uses the best models from", "labels": [], "entities": []}, {"text": " Table 5. * \u2020  \u2021 ** differences statistically  significant.", "labels": [], "entities": []}]}