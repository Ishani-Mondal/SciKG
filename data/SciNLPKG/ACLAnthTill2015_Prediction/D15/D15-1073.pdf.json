{"title": [{"text": "Neural Networks for Open Domain Targeted Sentiment", "labels": [], "entities": [{"text": "Open Domain Targeted Sentiment", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.6141877323389053}]}], "abstractContent": [{"text": "Open domain targeted sentiment is the joint information extraction task that finds target mentions together with the sentiment towards each mention from a text corpus.", "labels": [], "entities": [{"text": "Open domain targeted sentiment", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6353200972080231}, {"text": "information extraction", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7713197469711304}]}, {"text": "The task is typically modeled as a sequence labeling problem, and solved using state-of-the-art labelers such as CRF.", "labels": [], "entities": []}, {"text": "We empirically study the effect of word embeddings and automatic feature combinations on the task by extending a CRF baseline using neural networks, which have demonstrated large potentials for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 194, "end_pos": 212, "type": "TASK", "confidence": 0.9601640403270721}]}, {"text": "Results show that the neural model can give better results by significantly increasing the recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9990094900131226}]}, {"text": "In addition , we propose a novel integration of neural and discrete features, which combines their relative advantages, leading to significantly higher results compared to both baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Targeted sentiment analysis has drawn growing research interests over the past few years.", "labels": [], "entities": [{"text": "Targeted sentiment analysis", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8131394783655802}]}, {"text": "Compared with traditional sentiment analysis tasks, which extract the overall sentiment of a document, a sentence or a tweet, targeted sentiment analysis extracts the sentiment over given targeted entities from a text, and therefore is practically more informative.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8817201256752014}, {"text": "targeted sentiment analysis", "start_pos": 126, "end_pos": 153, "type": "TASK", "confidence": 0.7625061968962351}]}, {"text": "An example is shown in.", "labels": [], "entities": []}, {"text": "There are at least two practical scenarios: (1) Certain entities of concern are specified, and the requirement is to extract the sentiment towards their mentions in a text.", "labels": [], "entities": []}, {"text": "For example, one can be interested in the sentiment towards Google Inc., Microsoft and Facebook in financial news texts, or the sentiment towards Manchester United, Liverpool and Chelsea in tweets.", "labels": [], "entities": []}, {"text": "[AW service] 0 will be back at work . (2) No specified target is given, and the requirement is to find sentiments towards entities in the open domain.", "labels": [], "entities": [{"text": "AW service] 0", "start_pos": 1, "end_pos": 14, "type": "DATASET", "confidence": 0.8632956296205521}]}, {"text": "For example, one might be interested extracting the mentions to all persons and organizations, together with the sentiments towards each mention, from a news archive or a collection of novels.", "labels": [], "entities": [{"text": "extracting the mentions to all persons and organizations", "start_pos": 37, "end_pos": 93, "type": "TASK", "confidence": 0.7868763953447342}]}, {"text": "There are two sub tasks in targeted sentiment analysis, namely entity recognition and sentiment classification for each entity mention which apply to both scenarios above.", "labels": [], "entities": [{"text": "targeted sentiment analysis", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.7499904831250509}, {"text": "entity recognition", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7648608982563019}, {"text": "sentiment classification", "start_pos": 86, "end_pos": 110, "type": "TASK", "confidence": 0.8474531471729279}]}, {"text": "In scenario (1), entity recognition is relatively trivial, and can typically be achieved by pattern matching.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8615352213382721}]}, {"text": "Partly due to this reason, most previous work has addressed targeted sentiment analysis as a pure classification task, assuming that target mentions have been given).", "labels": [], "entities": [{"text": "targeted sentiment analysis", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.806731661160787}]}, {"text": "For scenario (2), a named entity recognition (NER) system can be used to extract targets, before the same targeted sentiment classification algorithms are applied.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.8081694642702738}, {"text": "sentiment classification", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.7915953099727631}]}, {"text": "There has also been work that concentrates on extracting opinion targets ().", "labels": [], "entities": [{"text": "extracting opinion targets", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.8935931126276652}]}, {"text": "In both cases, the data in can be used for training sentiment classifiers.", "labels": [], "entities": [{"text": "training sentiment classifiers", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.6574110190073649}]}, {"text": "took a different approach, extracting named entities and their sentiment classes jointly.", "labels": [], "entities": [{"text": "extracting named entities and their sentiment classes", "start_pos": 27, "end_pos": 80, "type": "TASK", "confidence": 0.7952228529112679}]}, {"text": "They model the joint task as an extension to the NER task, where an extra sentiment label is assigned to each named entity, in addition to the entity label.", "labels": [], "entities": [{"text": "NER task", "start_pos": 49, "end_pos": 57, "type": "TASK", "confidence": 0.7495576739311218}]}, {"text": "As a result, the task can be solved using sequence labeling methods.", "labels": [], "entities": []}, {"text": "As claimed by, the joint task is particularly suitable when no extra resources are available for training separate syntactic analyzers or name entity recognizers.", "labels": [], "entities": [{"text": "syntactic analyzers or name entity recognizers", "start_pos": 115, "end_pos": 161, "type": "TASK", "confidence": 0.6175745477279028}]}, {"text": "Such situations can include tweets and low-resource languages/domains.", "labels": [], "entities": []}, {"text": "Interestingly, because of containing entity information, the annotation in Figure 1 suffices for training joint entity and sentiment labels even if it is the only resource available.", "labels": [], "entities": []}, {"text": "The annotations in can be transformed into label sequences, as shown in. consists of two types of labels, where the B/I/O labels indicate span boundaries, and the +/-/0 labels indicate sentiment classes.", "labels": [], "entities": []}, {"text": "The two types of labels can be assigned in a span\u2192sentiment pipeline, or jointly as a multi-label task.", "labels": [], "entities": []}, {"text": "Alternatively, as shown in(b), the two types of labels can be collapsed into a joint label, such as B+ and I-, indicating the beginning of a positive entity and the middle of a negative entity, respectively.", "labels": [], "entities": []}, {"text": "The collapsed labels allow joint entity recognition and sentiment classification to be achieved using a standard sequence labeler.", "labels": [], "entities": [{"text": "joint entity recognition", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.6173447171847025}, {"text": "sentiment classification", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.9396683573722839}]}, {"text": "compare a pipeline model, a joint model and a collapsed model under the same conditional random field (CRF) framework, finding that the pipeline method outperforms the joint model on a tweet dataset.", "labels": [], "entities": []}, {"text": "Intuitively, the interaction between entity boundaries and sentiment classes might not be as strong as that between more closely-coupled sources of information, such as word boundaries and POS, or named entities and constituents, for which joint models significantly outperform pipeline models.", "labels": [], "entities": []}, {"text": "On the other hand, there do exist cases where entity boundaries and sentiment classes reinforce each other.", "labels": [], "entities": []}, {"text": "For example, in a tweet such as 'I like X.', the contextual pattern indicate both a positive sentiment and an entity in the place of X.", "labels": [], "entities": []}, {"text": "Recently, neural network models have been increasingly used for sentiment analysis, achieving highly competitive results, which show large potentials of neural network models for this task.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.9690232872962952}]}, {"text": "The main advantages of neural networks are two-fold.", "labels": [], "entities": []}, {"text": "First, neural models use real-valued hidden layers to automatically learn feature combinations, which can capture complex semantic information that are difficult to express using traditional discrete manual features.", "labels": [], "entities": []}, {"text": "Second, neural networks take distributed word embeddings as inputs, which can be trained from large-scale raw text, thus alleviating the scarcity of annotated data to some extent.", "labels": [], "entities": []}, {"text": "In this paper, we exploit structured neural models for open targeted sentiment.", "labels": [], "entities": [{"text": "open targeted sentiment", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.6357475717862447}]}, {"text": "We take the CRF model of as the baseline, and explore two research questions.", "labels": [], "entities": []}, {"text": "First, we make an empirical comparison between discrete and neural CRF models, and further combine the strengths of each model via feature integration.", "labels": [], "entities": []}, {"text": "Second, we compare the effects of the pipeline, joint and collapsed models for open targeted sentiment analysis under the neural model settings.", "labels": [], "entities": [{"text": "open targeted sentiment analysis", "start_pos": 79, "end_pos": 111, "type": "TASK", "confidence": 0.7224701792001724}]}, {"text": "Our experiments show that the neural model gives competitive results compared with the discrete baseline, with relatively higher recalls.", "labels": [], "entities": [{"text": "recalls", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.9979230761528015}]}, {"text": "In addition, the integrated model significantly improves over both the discrete and the neural models.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data: We use the data of to conduct all the experiments, which consist of entity and sentiment annotations on both English and Spanish tweets.", "labels": [], "entities": []}, {"text": "Simple normalizations are  conducted to replace all usernames and URLs into the special tokens username and url, respectively.", "labels": [], "entities": []}, {"text": "Following, we report ten-fold cross-validation results.", "labels": [], "entities": []}, {"text": "During training, we split 10% of the training corpus as the development corpus to tune hyper-parameters.", "labels": [], "entities": []}, {"text": "Parameters: For all the neural models, we set the hidden layer size | h| for neural features to 200, the hidden layer size | g| for discrete features to 30, the initial learning rate for adagrad to 0.01 and the regularization parameter \u03bb to 10 \u22128 . English and Spanish word embeddings are trained using the word2vec tool 4 , with respective corpora of 20 minion random tweets crawled by tweet API 5 . The size of word embeddings is 100.", "labels": [], "entities": []}, {"text": "For English, there are 8,061 unique words, for which 25% are out of word embedding vocabulary (OOE) words, while for Spanish, there are 14,648 unique words, for which 15% are OOE words.", "labels": [], "entities": []}, {"text": "Metrics: We take full-span metrics for evaluation, which is different from, who evaluate mainly the beginning of spans.", "labels": [], "entities": []}, {"text": "We measure the precision, recall and F-score of entity recognition (Entity), targeted sentiment analysis (SA) (both entity and sentiment), and targeted subjectivity detection (Subjectivity) (both entity and subjectivity, namely merging the + and -labels as \"1\" label, and performing two-way 0/1 subjectivity classification on entities).", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9997342228889465}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9994613528251648}, {"text": "F-score", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9990276098251343}, {"text": "entity recognition", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7692144513130188}, {"text": "targeted subjectivity detection", "start_pos": 143, "end_pos": 174, "type": "TASK", "confidence": 0.7139193216959635}]}, {"text": "For SA, an entity is taken as correct only when the span and the sentiment are both correctly recognized.", "labels": [], "entities": [{"text": "SA", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.963200569152832}]}, {"text": "Similarly, for Subjectivity, an entity is taken as correct only when both the span and the subjectivity are correctly recognized.", "labels": [], "entities": []}, {"text": "Code: We make the C++ implementations of the discrete, neural and combined models available and GPL, at https://github.com/ SUTDNLP/OpenTargetedSentiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experimental corpus statistics.", "labels": [], "entities": []}, {"text": " Table 4: Results on subjectivity and polarity.", "labels": [], "entities": []}]}