{"title": [{"text": "Abstractive Multi-document Summarization with Semantic Infor- mation Extraction", "labels": [], "entities": [{"text": "Summarization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7085635662078857}]}], "abstractContent": [{"text": "This paper proposes a novel approach to generate abstractive summary for multiple documents by extracting semantic information from texts.", "labels": [], "entities": []}, {"text": "The concept of Basic Semantic Unit (BSU) is defined to describe the semantics of an event or action.", "labels": [], "entities": []}, {"text": "A semantic link network on BSUs is constructed to capture the semantic information of texts.", "labels": [], "entities": []}, {"text": "Summary structure is planned with sentences generated based on the semantic link network.", "labels": [], "entities": [{"text": "Summary structure", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9462443590164185}]}, {"text": "Experiments demonstrate that the approach is effective in generating informative, coherent and compact summary.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most automatic summarization approaches are extractive which leverage only literal or syntactic information in documents.", "labels": [], "entities": [{"text": "summarization", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.7492919564247131}]}, {"text": "Sentences are extracted from the original documents directly by ranking or scoring and only little post-editing is made (.", "labels": [], "entities": []}, {"text": "Pure extraction has intrinsic limits compared to abstraction.", "labels": [], "entities": [{"text": "Pure extraction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7203114181756973}]}, {"text": "Abstractive summarization requires semantic analysis and abstract representation of texts, which need knowledge on and beyond the texts.", "labels": [], "entities": [{"text": "Abstractive summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5527553856372833}, {"text": "semantic analysis", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.702515110373497}]}, {"text": "There are some abstractive approaches in recent years: sentence compression, sentence fusion (, and sentence revision ().", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.778364509344101}, {"text": "sentence fusion", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7915288805961609}, {"text": "sentence revision", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7448765337467194}]}, {"text": "However, these approaches are sentence rewriting techniques based on syntactical analysis without semantic analysis and abstract representation.", "labels": [], "entities": [{"text": "sentence rewriting", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.780919224023819}]}, {"text": "Fully abstractive summarization approach requires a separate process for the analysis of texts that serves as an intermediate step before the generation of sentences).", "labels": [], "entities": []}, {"text": "Statistics of words or phrases and syntactical analysis that have been widely used in existing summarization approaches are all shallow processing of text.", "labels": [], "entities": [{"text": "summarization", "start_pos": 95, "end_pos": 108, "type": "TASK", "confidence": 0.9687201380729675}]}, {"text": "It is necessary to explore summarization methods based on deeper semantic analysis.", "labels": [], "entities": [{"text": "summarization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9803712368011475}]}, {"text": "We define the concept of Basic Semantic Unit (BSU) to express the semantics of texts.", "labels": [], "entities": []}, {"text": "A BSU is an action indicator with its obligatory arguments which contain actor and receiver of the action.", "labels": [], "entities": []}, {"text": "BSU is the most basic element of coherent information in texts, which can describe the semantics of an event or action.", "labels": [], "entities": []}, {"text": "The semantic information of texts is represented by extracting BSUs and constructing BSU semantic link network.", "labels": [], "entities": [{"text": "BSU semantic link network", "start_pos": 85, "end_pos": 110, "type": "DATASET", "confidence": 0.8667051047086716}]}, {"text": "Semantic Link Network consists of semantic nodes, semantic links and reasoning rules.", "labels": [], "entities": []}, {"text": "The semantic nodes can be any resources.", "labels": [], "entities": []}, {"text": "In this work, the semantic nodes are BSUs extracted from texts.", "labels": [], "entities": []}, {"text": "We use semantic relatedness between BSUs as semantic links.", "labels": [], "entities": []}, {"text": "Then summary can be generated based on the semantic link network through summary structure planning.", "labels": [], "entities": []}, {"text": "The characteristics of our approaches are as follows: \uf09f Each BSU describes the semantics of an event or action.", "labels": [], "entities": []}, {"text": "The semantic relatedness between BSUs can capture the context semantic relations of texts.", "labels": [], "entities": []}, {"text": "\uf09f The BSU semantic link network is an abstract representation of texts.", "labels": [], "entities": [{"text": "BSU semantic link network", "start_pos": 6, "end_pos": 31, "type": "DATASET", "confidence": 0.7653212547302246}]}, {"text": "Reduction on the network can obtain important information of texts with no redundancy.", "labels": [], "entities": []}, {"text": "\uf09f Summary is built from sentence to sentence to a coherent body of information based on the BSU semantic link network by summary structure planning.", "labels": [], "entities": [{"text": "\uf09f", "start_pos": 0, "end_pos": 1, "type": "TASK", "confidence": 0.9212725162506104}, {"text": "Summary", "start_pos": 2, "end_pos": 9, "type": "TASK", "confidence": 0.5941727161407471}, {"text": "BSU semantic link network", "start_pos": 92, "end_pos": 117, "type": "DATASET", "confidence": 0.916987955570221}]}], "datasetContent": [{"text": "In order to evaluate the performance of our system, we use two datasets that have been used in recent multi-document summarization shared tasks: DUC2005 and DUC2007.", "labels": [], "entities": [{"text": "multi-document summarization shared tasks", "start_pos": 102, "end_pos": 143, "type": "TASK", "confidence": 0.69941396266222}, {"text": "DUC2005", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.9319857358932495}, {"text": "DUC2007", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.9500477313995361}]}, {"text": "Each task has a gold standard dataset consisting of document clusters and reference summaries.", "labels": [], "entities": []}, {"text": "In our experiments, DUC2005 was used for training and parameter tuning, and DUC2007 was used for testing.", "labels": [], "entities": [{"text": "DUC2005", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.5692538022994995}, {"text": "parameter tuning", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7267427891492844}]}, {"text": "Based on the tuning set, the parameter \u03bb is set as 10 and \u03b4 is set as 0.7 after tuning.", "labels": [], "entities": []}, {"text": "Our system is compared with one state-of-theart graph-based extractive approach MultiMR () and one abstractive approach TTG (Genest and Lapalme, 2011).", "labels": [], "entities": [{"text": "MultiMR", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.8251073360443115}]}, {"text": "In addition, we have implemented another baseline RankBSU which uses the graph-based ranking methods on the BSUs network to rank BSUs and select the top ranked BSUs to generate sentences.", "labels": [], "entities": [{"text": "BSUs network", "start_pos": 108, "end_pos": 120, "type": "DATASET", "confidence": 0.9288347065448761}]}], "tableCaptions": [{"text": " Table 2. Comparison results (F-measure) on  DUC 2007 under ROUGE evaluation.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9953172206878662}, {"text": "DUC 2007", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.9616592824459076}, {"text": "ROUGE evaluation", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.6905198097229004}]}, {"text": " Table 3. Comparison results on DUC 2007 un- der the automated pyramid evaluation with two  threshold value 0.6 and 0.65.", "labels": [], "entities": [{"text": "DUC 2007", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9401138424873352}]}]}