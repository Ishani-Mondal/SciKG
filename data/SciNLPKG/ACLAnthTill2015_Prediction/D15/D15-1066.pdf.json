{"title": [{"text": "LDTM: A Latent Document Type Model for Cumulative Citation Recommendation", "labels": [], "entities": [{"text": "Cumulative Citation Recommendation", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.7255719304084778}]}], "abstractContent": [{"text": "This paper studies Cumulative Citation Recommendation (CCR)-given an entity in Knowledge Bases, how to effectively detect its potential citations from volume text streams.", "labels": [], "entities": [{"text": "Cumulative Citation Recommendation (CCR)-", "start_pos": 19, "end_pos": 60, "type": "TASK", "confidence": 0.7692022323608398}]}, {"text": "Most previous approaches treated all kinds of features indifferently to build a global relevance model, in which the prior knowledge embedded in documents cannot be exploited adequately.", "labels": [], "entities": []}, {"text": "To address this problem, we propose a latent document type discriminative model by introducing a latent layer to capture the correlations between documents and their underlying types.", "labels": [], "entities": []}, {"text": "The model can better adjust to different types of documents and yield flexible performance when dealing with abroad range of document types.", "labels": [], "entities": []}, {"text": "An extensive set of experiments has been conducted on TREC-KBA-2013 dataset, and the results demonstrate that this model can yield a significant performance gain in recommendation quality as compared to the state-of-the-art.", "labels": [], "entities": [{"text": "TREC-KBA-2013 dataset", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.9520307779312134}]}], "introductionContent": [{"text": "Knowledge Bases (KBs), like Wikipedia, are playing increasingly important roles in numerous entity-based information retrieval tasks.", "labels": [], "entities": [{"text": "entity-based information retrieval tasks", "start_pos": 92, "end_pos": 132, "type": "TASK", "confidence": 0.6952629089355469}]}, {"text": "Nevertheless, most KBs are hard to be up-to-date due to their manual maintenances by human editors.", "labels": [], "entities": []}, {"text": "As reported in), there exists a median time lag of 356 days between the day a news article is published and the time that the news is cited in a Wikipedia article dedicated to the entity concerned by the news.", "labels": [], "entities": []}, {"text": "The time lag would be reduced if relevant documents could be automatically detected as soon as they are published online * This work was partially performed when the first author was visiting Purdue University and Microsoft Research Asia.", "labels": [], "entities": []}, {"text": "\u2020 Corresponding Author and then recommended to the editors.", "labels": [], "entities": []}, {"text": "This task is studied as Cumulative Citation Recommendation (CCR).", "labels": [], "entities": [{"text": "Cumulative Citation Recommendation (CCR)", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.5737862984339396}]}, {"text": "Formally, given a set of KB entities, CCR is to filter relevant documents from a stream corpus and evaluate their citation-worthiness to the target entities.", "labels": [], "entities": []}, {"text": "A variety of supervised approaches (e.g., classification, learning to rank) have been employed and achieved promising results (.", "labels": [], "entities": [{"text": "classification", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.9727231860160828}]}, {"text": "Nevertheless, most of them leverage all features indiscriminately to build a global relevance model, which leads to unsatisfactory performance.", "labels": [], "entities": []}, {"text": "The documents can offer some prior knowledge, which is named as type in this paper.", "labels": [], "entities": []}, {"text": "The type is the prior knowledge embedded in the document that impacts on the probability of its being recommended to KBs.", "labels": [], "entities": [{"text": "KBs", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.8190412521362305}]}, {"text": "For instance, when dealing with a document on \"music\" topic, we would like to have less weights put on a politician entity because this document is not likely to related to it, but more often related to musicians or musical bands.", "labels": [], "entities": []}, {"text": "Besides, the source of a document impacts on the recommendation strategies too.", "labels": [], "entities": []}, {"text": "A document from news agencies is more reliable and citable than the one from social websites even if they state an identical story about the target KB entity.", "labels": [], "entities": []}, {"text": "Hence we consider two kinds of document features to model the prior type knowledge: (1) topic-based features, and (2) source-based features.", "labels": [], "entities": []}, {"text": "This paper proposes a latent document type discriminative mixture model for CCR.", "labels": [], "entities": []}, {"text": "We introduce an intermediate latent layer to model latent document types and define a joint distribution over the document-entity pairs and latent document-types on the observation data.", "labels": [], "entities": []}, {"text": "The aim is to achieve a discriminative mixture model that is expected to outperform the global relevance model.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first research work that leverages prior knowledge embedded in documents to improve CCR perfor-mance.", "labels": [], "entities": [{"text": "CCR perfor-mance", "start_pos": 126, "end_pos": 142, "type": "TASK", "confidence": 0.7531063258647919}]}, {"text": "An extensive set of experiments conducted on TREC-KBA-2013 dataset has demonstrated the effectiveness of the proposed mixture model.", "labels": [], "entities": [{"text": "TREC-KBA-2013 dataset", "start_pos": 45, "end_pos": 66, "type": "DATASET", "confidence": 0.9402625858783722}]}], "datasetContent": [{"text": "We utilize TREC-KBA-2013 dataset 2 as our experimental dataset.", "labels": [], "entities": [{"text": "TREC-KBA-2013 dataset 2", "start_pos": 11, "end_pos": 34, "type": "DATASET", "confidence": 0.8503003716468811}]}, {"text": "The dataset is composed of a temporally stream corpus and a target KB entity set.", "labels": [], "entities": []}, {"text": "The stream corpus contains nearly 1 billion documents crawled from 10 sources: news, mainstream news, social, weblog, linking, arxiv, classified, reviews, forum and memetracker . The corpus has been split with documents from October 2011 to February 2012 as training instances and the remainder for evaluation.", "labels": [], "entities": []}, {"text": "We adopt the same training/test range setting in our experiments.", "labels": [], "entities": []}, {"text": "The entity set is composed of 121 Wikipedia entities and 20 Twitter entities.", "labels": [], "entities": []}, {"text": "Each entity-document pair is labeled as one of the 4 relevance levels: (i) Vital, timely information about the entity's current state, actions, or situation.", "labels": [], "entities": [{"text": "Vital", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.9729525446891785}]}, {"text": "This would motivate a change to an already up-to-date KB article.", "labels": [], "entities": [{"text": "KB article", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.9102780818939209}]}, {"text": "(ii) Useful, possibly citable but not timely, e.g., background biography, secondary source information.", "labels": [], "entities": []}, {"text": "(iii) Neural, informative but not citable, e.g., tertiary source like Wikipedia article itself. and (iv) Garbage, no information about the target entity could be learned from the document, e.g., spam.", "labels": [], "entities": []}, {"text": "Annotation details of the dataset are presented in: Annotation details of TREC-KBA-2013 dataset.", "labels": [], "entities": [{"text": "Annotation", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9175973534584045}, {"text": "Annotation", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9598779678344727}, {"text": "TREC-KBA-2013 dataset", "start_pos": 74, "end_pos": 95, "type": "DATASET", "confidence": 0.9523351192474365}]}, {"text": "According to different granularity settings, we evaluate the proposed models in two scenarios:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Annotation details of TREC-KBA-2013  dataset.", "labels": [], "entities": [{"text": "TREC-KBA-2013  dataset", "start_pos": 32, "end_pos": 54, "type": "DATASET", "confidence": 0.8939603865146637}]}, {"text": " Table 2. In comparison to the baselines listed", "labels": [], "entities": []}, {"text": " Table 2: Overall results of evaluated methods.  Best scores are typeset boldface.", "labels": [], "entities": []}, {"text": " Table 3. The optimal number of latent types in  Vital + Useful is more than that in Vital Only.  This reveals that the types of Vital documents for  entities have more restrictions than Useful docu- ments, either by topics or by sources. In addition,  the optimal number of latent topics is more than  that of latent sources, which also follows our in- tuition that topic-based features holding more di- mensions than source-based features. Since we  employ a na\u00a8\u0131vena\u00a8\u0131ve combination strategy for the two  types of features, the number of latent types of  combine LDTM is more close to topic LDTM,  which possesses more features than src LDTM.", "labels": [], "entities": []}, {"text": " Table 3: Number of latent types determined by  AIC.", "labels": [], "entities": [{"text": "AIC", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.5901516675949097}]}]}