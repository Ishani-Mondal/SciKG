{"title": [{"text": "When Are Tree Structures Necessary for Deep Learning of Representations?", "labels": [], "entities": []}], "abstractContent": [{"text": "Recursive neural models, which use syntactic parse trees to recursively generate representations bottom-up, area popular architecture.", "labels": [], "entities": []}, {"text": "However there have not been rigorous evaluations showing for exactly which tasks this syntax-based method is appropriate.", "labels": [], "entities": []}, {"text": "In this paper, we benchmark recursive neural models against sequential recurrent neural models, enforcing apples-to-apples comparison as much as possible.", "labels": [], "entities": []}, {"text": "We investigate 4 tasks: (1) sentiment classification at the sentence level and phrase level; (2) matching questions to answer-phrases; (3) discourse parsing; (4) semantic relation extraction.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.9240372478961945}, {"text": "discourse parsing", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.7265844941139221}, {"text": "semantic relation extraction", "start_pos": 162, "end_pos": 190, "type": "TASK", "confidence": 0.7695019046465555}]}, {"text": "Our goal is to understand better when, and why, recursive models can outperform simpler models.", "labels": [], "entities": []}, {"text": "We find that recursive models help mainly on tasks (like semantic relation extraction) that require long-distance connection modeling, particularly on very long sequences.", "labels": [], "entities": [{"text": "semantic relation extraction", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.6625289718310038}]}, {"text": "We then introduce a method for allowing recurrent models to achieve similar performance: breaking long sentences into clause-like units at punctuation and processing them separately before combining.", "labels": [], "entities": []}, {"text": "Our results thus help understand the limitations of both classes of models, and suggest directions for improving recurrent models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep learning based methods learn lowdimensional, real-valued vectors for word tokens, mostly from large-scale data corpus (e.g.,), successfully capturing syntactic and semantic aspects of text.", "labels": [], "entities": []}, {"text": "For tasks where the inputs are larger text units (e.g., phrases, sentences or documents), a compositional model is first needed to aggregate tokens into a vector with fixed dimensionality that can be used as a feature for other NLP tasks.", "labels": [], "entities": []}, {"text": "Models for achieving this usually fall into two categories: recurrent models and recursive models: Recurrent models (also referred to as sequence models) deal successfully with time-series data) like speech () or handwriting recognition (.", "labels": [], "entities": [{"text": "handwriting recognition", "start_pos": 213, "end_pos": 236, "type": "TASK", "confidence": 0.8583109378814697}]}, {"text": "They were applied early onto NLP, by modeling a sentence as tokens processed sequentially and at each step combining the current token with previously built embeddings.", "labels": [], "entities": []}, {"text": "Recurrent models can be extended to bidirectional ones from both leftto-right and right-to-left.", "labels": [], "entities": []}, {"text": "These models generally consider no linguistic structure aside from word order.", "labels": [], "entities": []}, {"text": "Recursive neural models (also referred to as tree models), by contrast, are structured by syntactic parse trees.", "labels": [], "entities": []}, {"text": "Instead of considering tokens sequentially, recursive models combine neighbors based on the recursive structure of parse trees, starting from the leaves and proceeding recursively in a bottom-up fashion until the root of the parse tree is reached.", "labels": [], "entities": []}, {"text": "For example, for the phrase the food is delicious, following the operation sequence ( (the food) (is delicious) ) rather than the sequential order (((the food) is) delicious).", "labels": [], "entities": []}, {"text": "Many recursive models have been proposed (e.g.,), and applied to various NLP tasks, among them entailment), sentiment analysis (), question-answering (), relation classification (, and discourse ( ).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.9606763422489166}, {"text": "relation classification", "start_pos": 154, "end_pos": 177, "type": "TASK", "confidence": 0.9049047827720642}]}, {"text": "One possible advantage of recursive models is their potential for capturing long-distance dependencies: two tokens maybe structurally close to each other, even though they are faraway in word sequence.", "labels": [], "entities": []}, {"text": "For example, a verb and its corresponding direct object can be faraway in terms of tokens if many adjectives lies in between, but they are adjacent in the parse tree).", "labels": [], "entities": []}, {"text": "However we do not know if this advantage is truly important, and if so for which tasks, or whether other issues are at play.", "labels": [], "entities": []}, {"text": "Indeed, the reliance of recursive models on parsing is also a potential disadvantage, given that parsing is relatively slow, domain-dependent, and can be errorful.", "labels": [], "entities": [{"text": "parsing", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.9717185497283936}, {"text": "parsing", "start_pos": 97, "end_pos": 104, "type": "TASK", "confidence": 0.9696135520935059}]}, {"text": "On the other hand, recent progress in multiple subfields of neural NLP has suggested that recurrent nets maybe sufficient to deal with many of the tasks for which recursive models have been proposed.", "labels": [], "entities": []}, {"text": "Recurrent models without parse structures have shown good results in sequenceto-sequence generation ) for machine translation (e.g.,), parsing ( , and sentiment, where for example recurrent-based paragraph vectors () outperform recursive models) on the Stanford sentimentbank dataset.", "labels": [], "entities": [{"text": "sequenceto-sequence generation", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.7379003763198853}, {"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7987042367458344}, {"text": "parsing", "start_pos": 135, "end_pos": 142, "type": "TASK", "confidence": 0.9813670516014099}, {"text": "Stanford sentimentbank dataset", "start_pos": 253, "end_pos": 283, "type": "DATASET", "confidence": 0.8645756642023722}]}, {"text": "Our goal in this paper is thus to investigate a number of tasks with the goal of understanding for which kinds of problems recurrent models maybe sufficient, and for which kinds recursive models offer specific advantages.", "labels": [], "entities": []}, {"text": "We investigate four tasks with different properties.", "labels": [], "entities": []}, {"text": "\u2022 Binary sentiment classification at the sentence level () and phrase level) that focus on understanding the role of recursive models in dealing with semantic compositionally in various scenarios such as different lengths of inputs and whether or not supervision is comprehensive.", "labels": [], "entities": [{"text": "Binary sentiment classification", "start_pos": 2, "end_pos": 33, "type": "TASK", "confidence": 0.8604415456453959}]}, {"text": "\u2022 Phrase Matching on the UMD-QA dataset) can help seethe difference between outputs from intermediate components from different models, i.e., representations for intermediate parse tree nodes and outputs from recurrent models at different time steps.", "labels": [], "entities": [{"text": "Phrase Matching", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.8126819431781769}, {"text": "UMD-QA dataset", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.9252882599830627}]}, {"text": "It also helps see whether parsing is useful for finding similarities between question sentences and target phrases.", "labels": [], "entities": []}, {"text": "\u2022 Semantic Relation Classification on the) data can help understand whether parsing is helpful in dealing with long-term dependencies, such as relations between two words that are far apart in the sequence.", "labels": [], "entities": [{"text": "Semantic Relation Classification", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.7187602718671163}]}, {"text": "\u2022 Discourse parsing (RST dataset) is useful for measuring the extent to which parsing improves discourse tasks that need to combine meanings of larger text units.", "labels": [], "entities": [{"text": "Discourse parsing (RST", "start_pos": 2, "end_pos": 24, "type": "TASK", "confidence": 0.7438965290784836}]}, {"text": "Discourse parsing treats elementary discourse units (EDUs) as basic units to operate on, which are usually short clauses.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8443719446659088}]}, {"text": "The task also sheds light on the extent to which syntactic structures help acquire shot text representations.", "labels": [], "entities": []}, {"text": "The principal motivation for this paper is to understand better when, and why, recursive models are needed to outperform simpler models by enforcing apples-to-apples comparison as much as possible.", "labels": [], "entities": []}, {"text": "This paper applies existing models to existing tasks, barely offering novel algorithms or tasks.", "labels": [], "entities": []}, {"text": "Our goal is rather an analytic one, to investigate different versions of recursive and recurrent models.", "labels": [], "entities": []}, {"text": "This work helps understand the limitations of both classes of models, and suggest directions for improving recurrent models.", "labels": [], "entities": []}, {"text": "The rest of this paper organized as follows: We detail versions of recursive/recurrent models in Section 2, present the tasks and results in Section 3, and conclude with discussions in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we detail our experimental settings and results.", "labels": [], "entities": []}, {"text": "We consider the following tasks, each representative of a different class of NLP tasks.", "labels": [], "entities": []}, {"text": "\u2022 Binary sentiment classification on the dataset.", "labels": [], "entities": [{"text": "Binary sentiment classification", "start_pos": 2, "end_pos": 33, "type": "TASK", "confidence": 0.9360294342041016}]}, {"text": "This addresses the issues where supervision only appears globally after along sequence of operations.", "labels": [], "entities": []}, {"text": "\u2022 Sentiment Classification on the Stanford Sentiment Treebank (Socher et al., 2013): comprehensive labels are found for words and phrases where local compositionally (such as from negation, mood, or others cued by phrase-structure) is to be learned.", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 2, "end_pos": 26, "type": "TASK", "confidence": 0.8787020742893219}, {"text": "Stanford Sentiment Treebank (Socher et al., 2013)", "start_pos": 34, "end_pos": 83, "type": "DATASET", "confidence": 0.8832514107227325}]}, {"text": "\u2022 Sentence-Target Matching on the UMD-QA dataset): Learns matches between target and components in the source sentences, which are parse tree nodes for recursive models and different time-steps for recurrent models.", "labels": [], "entities": [{"text": "Sentence-Target Matching", "start_pos": 2, "end_pos": 26, "type": "TASK", "confidence": 0.7498309016227722}, {"text": "UMD-QA dataset", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9012596905231476}]}, {"text": "\u2022 Semantic Relation Classification on the SemEval-2010 task ().", "labels": [], "entities": [{"text": "Semantic Relation Classification", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.9069169759750366}, {"text": "SemEval-2010 task", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.782289445400238}]}, {"text": "Learns long-distance relationships between two words that maybe far apart sequentially.", "labels": [], "entities": []}, {"text": "\u2022 Discourse Parsing (: Learns sentence-to-sentence relations based on calculated representations.", "labels": [], "entities": [{"text": "Discourse Parsing", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.7290869355201721}]}, {"text": "In each case we followed the protocols described in the original papers.", "labels": [], "entities": []}, {"text": "We first group the algorithm variants into two groups as follows: \u2022 Standard tree models vs standard sequence models vs standard bi-directional sequence models \u2022 LSTM tree models, LSTM sequence models vs LSTM bi-directional sequence models.", "labels": [], "entities": []}, {"text": "We employed standard training frameworks for neural models: for each task, we used stochastic gradient decent using AdaGrad) with minibatches (Cotter et al., 2011).", "labels": [], "entities": []}, {"text": "Parameters are tuned using the development dataset if available in the original datasets or from crossvalidation if not.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9683676958084106}]}, {"text": "Derivatives are calculated from standard back-propagation.", "labels": [], "entities": []}, {"text": "Parameters to tune include size of mini batches, learning rate, and parameters for L2 penalizations.", "labels": [], "entities": []}, {"text": "The number of running iterations is treated as a parameter to tune and the model achieving best performance on the development set is used as the final model to be evaluated.", "labels": [], "entities": []}, {"text": "For settings where no repeated experiments are performed, the bootstrap testis adopted for statistical significance testing.", "labels": [], "entities": []}, {"text": "Test scores that achieve significance level of 0.05 are marked by an asterisk (*).", "labels": [], "entities": [{"text": "significance level", "start_pos": 25, "end_pos": 43, "type": "METRIC", "confidence": 0.985509991645813}]}], "tableCaptions": [{"text": " Table 1: Test set accuracies on the Stanford Senti- ment Treebank at root level.", "labels": [], "entities": [{"text": "Stanford Senti- ment Treebank", "start_pos": 37, "end_pos": 66, "type": "DATASET", "confidence": 0.9499947309494019}]}, {"text": " Table 2: Test set accuracies on the Stanford Senti- ment Treebank at phrase level.", "labels": [], "entities": [{"text": "Stanford Senti- ment Treebank", "start_pos": 37, "end_pos": 66, "type": "DATASET", "confidence": 0.9476459383964538}]}, {"text": " Table 4: Test set accuracies on the Pang's senti- ment dataset using Standard model settings.", "labels": [], "entities": [{"text": "Pang's senti- ment dataset", "start_pos": 37, "end_pos": 63, "type": "DATASET", "confidence": 0.9454614122708639}]}, {"text": " Table 5: Test set accuracies for UMD-QA dataset.", "labels": [], "entities": [{"text": "UMD-QA dataset", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.831182599067688}]}, {"text": " Table 6: Test set accuracies on the SemEval-2010  Semantic Relationship Classification task.", "labels": [], "entities": [{"text": "SemEval-2010  Semantic Relationship Classification task", "start_pos": 37, "end_pos": 92, "type": "TASK", "confidence": 0.8547897815704346}]}, {"text": " Table 7: Test set accuracies for relation identifica- tion on RST discourse parsing data set.", "labels": [], "entities": [{"text": "RST discourse parsing", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7350016236305237}]}]}