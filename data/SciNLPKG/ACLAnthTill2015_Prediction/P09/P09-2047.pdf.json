{"title": [{"text": "Query Segmentation Based on Eigenspace Similarity School of Applied Math", "labels": [], "entities": [{"text": "Query Segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7241145372390747}, {"text": "Eigenspace Similarity School of Applied Math", "start_pos": 28, "end_pos": 72, "type": "TASK", "confidence": 0.6153989632924398}]}], "abstractContent": [{"text": "Query segmentation is essential to query processing.", "labels": [], "entities": [{"text": "Query segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9076534509658813}, {"text": "query processing", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.879549652338028}]}, {"text": "It aims to tokenize query words into several semantic segments and help the search engine to improve the precision of retrieval.", "labels": [], "entities": [{"text": "tokenize query words into several semantic segments", "start_pos": 11, "end_pos": 62, "type": "TASK", "confidence": 0.8136080077716282}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9982581734657288}]}, {"text": "In this paper, we present a novel unsupervised learning approach to query segmentation based on principal eigenspace similarity of query-word-frequency matrix derived from web statistics.", "labels": [], "entities": [{"text": "query segmentation", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8236067593097687}]}, {"text": "Experimental results show that our approach could achieve superior performance of 35.8% and 17.7% in F-measure over the two baselines respectively , i.e. MI (Mutual Information) approach and EM optimization approach.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9858096241950989}, {"text": "EM optimization", "start_pos": 191, "end_pos": 206, "type": "TASK", "confidence": 0.845194011926651}]}], "introductionContent": [{"text": "People submit concise word-sequences to search engines in order to obtain satisfying feedback.", "labels": [], "entities": []}, {"text": "However, the word sequences are generally ambiguous and often fail to convey the exact information to search engine, thus severely, affecting the performance of the system.", "labels": [], "entities": []}, {"text": "For example, given the query \"free software testing tools download\".", "labels": [], "entities": []}, {"text": "A simple bag-of-words query model cannot analyze \"software testing tools\" accurately.", "labels": [], "entities": []}, {"text": "Instead, it returns \"free software\" or \"free download\" which are high frequency web phrases.", "labels": [], "entities": []}, {"text": "Therefore, how to segment a query into meaningful semantic components for implicit description of user's intention is an important issue both in natural language processing and information retrieval fields.", "labels": [], "entities": []}, {"text": "There are few related studies on query segmentation in spite of its importance and applicability in many query analysis tasks such as query suggestion, query substitution, etc.", "labels": [], "entities": [{"text": "query segmentation", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.7887312471866608}, {"text": "query suggestion", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.7781246304512024}, {"text": "query substitution", "start_pos": 152, "end_pos": 170, "type": "TASK", "confidence": 0.7973186671733856}]}, {"text": "To our knowledge, three approaches have been studied in previous works: MI (Mutual Information) approach;, supervised learning approach and EM optimization approach.", "labels": [], "entities": [{"text": "EM optimization", "start_pos": 140, "end_pos": 155, "type": "TASK", "confidence": 0.7793956995010376}]}, {"text": "However, MI approach calculates MI value just between two adjacent words that cannot handle long entities.", "labels": [], "entities": []}, {"text": "Supervised learning approach requires a sufficiently large number of labeled training data, which is not conducive in real applications.", "labels": [], "entities": []}, {"text": "EM algorithm often converges to a local maximum that depends on the initial conditions.", "labels": [], "entities": []}, {"text": "There are also many relevant research on Chinese word segmentation (.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.5850933492183685}]}, {"text": "However, they cannot be applied directly to query segmentation.", "labels": [], "entities": [{"text": "query segmentation", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8058836758136749}]}, {"text": "Under this scenario, we propose a novel unsupervised approach for query segmentation.", "labels": [], "entities": [{"text": "query segmentation", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8499657809734344}]}, {"text": "Differing from previous work, we first adopt the ngram model to estimate the query term's frequency matrix based on word occurrence statistics on the web.", "labels": [], "entities": []}, {"text": "We then devise anew strategy to select principal eigenvectors of the matrix.", "labels": [], "entities": []}, {"text": "Finally we calculate the similarity of query words for segmentation.", "labels": [], "entities": [{"text": "similarity", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9693295359611511}, {"text": "segmentation", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.9607563614845276}]}, {"text": "Experimental results demonstrate the effectiveness of our approach as compared to two baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two baselines are used in our experiments: one is MI based method (referred to as MI), and the other is EM optimization (referred to as EM).", "labels": [], "entities": [{"text": "EM optimization", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.6607459783554077}]}, {"text": "Since the EM proposed in) is implemented with Yahoo!", "labels": [], "entities": [{"text": "Yahoo!", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.8987621366977692}]}, {"text": "web corpus and only Google Soap Search API is available in our study, we adopt t-test to evaluate the performance of MI with Google data (referred to as MI(G)) and Yahoo!", "labels": [], "entities": []}, {"text": "web corpus (referred to as MI(Y)).", "labels": [], "entities": []}, {"text": "With the values of MI(Y) and MI(G) in we get the p-value (p = 0.316 0.05), which indicates that the performance of MI with different corpuses has no significant difference.", "labels": [], "entities": []}, {"text": "Therefore, we can deduce that, the two corpuses have little influence on the performance of the approaches.", "labels": [], "entities": []}, {"text": "Here, we denote our approach as \"ES\", i.e. Eigenspace Similarity approach.", "labels": [], "entities": []}, {"text": "presents the performance of the three approaches, i.e. MI (MI(Y) and MI(G)), EM and our proposed ES on the five test data sets using the three mentioned metrics.", "labels": [], "entities": [{"text": "MI (MI(Y)", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.8918673694133759}, {"text": "MI(G))", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9177208840847015}, {"text": "EM", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9910282492637634}, {"text": "ES", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9590467214584351}]}, {"text": "From we find that ES achieves significant improvements as compared to the other two methods in any metric and data set we used.", "labels": [], "entities": [{"text": "ES", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.8297274708747864}]}, {"text": "For further analysis, we compute statistical performance on mathematical expectation and standard deviation as shown in.", "labels": [], "entities": []}, {"text": "We observe a consistent trend of the three metrics increasing from left to right as shown in, i.e. EM performs better than MI and ES is the best among the three approaches.", "labels": [], "entities": [{"text": "EM", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.7259661555290222}, {"text": "MI", "start_pos": 123, "end_pos": 125, "type": "METRIC", "confidence": 0.8876266479492188}, {"text": "ES", "start_pos": 130, "end_pos": 132, "type": "METRIC", "confidence": 0.9450473785400391}]}, {"text": "First, we observe that, EM (Prec: 0.609, Recall: 0.613, F-mea: 0.611) performs much better than MI (Prec: 0.549, Recall: 0.513, F-mea: 0.529).", "labels": [], "entities": [{"text": "EM", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.7515402436256409}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9649674892425537}, {"text": "MI", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.8958604335784912}]}, {"text": "This is because EM optimizes the frequencies of query words with EM algorithms.", "labels": [], "entities": []}, {"text": "In addition, it should be noted that, the recall of MI is especially unsatisfactory, which is caused by its shortcoming on handling long entities.", "labels": [], "entities": [{"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9993060827255249}, {"text": "MI", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.8276620507240295}]}], "tableCaptions": [{"text": " Table 1: Performance of different approaches.", "labels": [], "entities": []}]}