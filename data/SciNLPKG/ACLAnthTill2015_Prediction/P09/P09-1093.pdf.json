{"title": [{"text": "A Syntax-Free Approach to Japanese Sentence Compression", "labels": [], "entities": [{"text": "Sentence Compression", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7405378222465515}]}], "abstractContent": [{"text": "Conventional sentence compression methods employ a syntactic parser to compress a sentence without changing its meaning.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7561001479625702}]}, {"text": "However, the reference compressions made by humans do not always retain the syntactic structures of the original sentences.", "labels": [], "entities": []}, {"text": "Moreover, for the goal of on-demand sentence compression, the time spent in the parsing stage is not negligible.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7424086779356003}]}, {"text": "As an alternative to syntactic parsing , we propose a novel term weighting technique based on the positional information within the original sentence and a novel language model that combines statistics from the original sentence and a general corpus.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7683815360069275}, {"text": "term weighting", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.7133838832378387}]}, {"text": "Experiments that involve both human subjective evaluations and automatic evaluations show that our method outperforms Hori's method, a state-of-the-art conventional technique.", "labels": [], "entities": []}, {"text": "Because our method does not use a syntactic parser, it is 4.3 times faster than Hori's method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In order to compress a sentence while retaining its original meaning, the subject-predicate relationship of the original sentence should be preserved after compression.", "labels": [], "entities": []}, {"text": "In accordance with this idea, conventional sentence compression methods employ syntactic parsers.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.7383471578359604}]}, {"text": "English sentences are usually analyzed by a full parser to make parse trees, and the trees are then trimmed).", "labels": [], "entities": []}, {"text": "For Japanese, dependency trees are trimmed instead of full parse trees This parsing approach is reasonable because the compressed output is grammatical if the Hereafter, we refer these compression processes as \"tree trimming.\" input is grammatical, but it offers only moderate compression rates.", "labels": [], "entities": []}, {"text": "An alternative to the tree trimming approach is the sequence-oriented approach.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.7081675380468369}]}, {"text": "It treats a sentence as a sequence of words and structural information, such as a syntactic or dependency tree, is encoded in the sequence as features.", "labels": [], "entities": []}, {"text": "Their methods have the potential to drop arbitrary words from the original sentence without considering the boundary determined by the tree structures.", "labels": [], "entities": []}, {"text": "However, they still rely on syntactic information derived from fully parsed syntactic or dependency trees.", "labels": [], "entities": []}, {"text": "We found that humans usually ignored the syntactic structures when compressing sentences.", "labels": [], "entities": []}, {"text": "For example, in many cases, they compressed the sentence by dropping intermediate nodes of the syntactic tree derived from the source sentence.", "labels": [], "entities": []}, {"text": "We believe that making compression strongly dependent on syntax is not appropriate for reproducing reference compressions.", "labels": [], "entities": []}, {"text": "Moreover, on-demand sentence compression is made problematic by the time spent in the parsing stage.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7252202332019806}]}, {"text": "This paper proposes a syntax-free sequenceoriented sentence compression method.", "labels": [], "entities": [{"text": "syntax-free sequenceoriented sentence compression", "start_pos": 22, "end_pos": 71, "type": "TASK", "confidence": 0.5819011926651001}]}, {"text": "To maintain the subject-predicate relationship in the compressed sentence and retain fluency without using syntactic parsers, we propose two novel features: intra-sentence positional term weighting (IPTW) and the patched language model (PLM).", "labels": [], "entities": [{"text": "intra-sentence positional term weighting", "start_pos": 157, "end_pos": 197, "type": "TASK", "confidence": 0.5877567827701569}]}, {"text": "IPTW is defined by the term's positional information in the original sentence.", "labels": [], "entities": [{"text": "IPTW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7598901391029358}]}, {"text": "PLM is a form of summarization-oriented fluency statistics derived from the original sentence and the general language model.", "labels": [], "entities": []}, {"text": "The weight parameters for these features are optimized within the Minimum Classification Error (MCE) learning framework.", "labels": [], "entities": [{"text": "Minimum Classification Error (MCE) learning", "start_pos": 66, "end_pos": 109, "type": "TASK", "confidence": 0.6950226851872036}]}, {"text": "Experiments that utilize both human subjective and automatic evaluations show that our method is: An example of the dependency relation between an original sentence and its compressed variant.", "labels": [], "entities": []}, {"text": "superior to conventional sequence-oriented methods that employ syntactic parsers while being about 4.3 times faster.", "labels": [], "entities": []}], "datasetContent": [{"text": "We randomly selected 1,000 lead sentences (a lead sentence is the first sentence of an article excluding the headline.) whose length (number of words) was greater than 30 words from the Mainichi Newspaper from 1994 to 2002.", "labels": [], "entities": [{"text": "Mainichi Newspaper from 1994 to 2002", "start_pos": 186, "end_pos": 222, "type": "DATASET", "confidence": 0.9573789238929749}]}, {"text": "There were five different ideal compressions (reference compressions produced by human) for each sentence; all had a 0.6 compression rate.", "labels": [], "entities": []}, {"text": "The average length of the input sentences was about 42 words and that of the reference compressions was about 24 words.", "labels": [], "entities": []}, {"text": "For MCE learning, we selected the reference compression that maximize the BLEU score) (= argmax r\u2208R BLEU(r, R\\r)) from the set of reference compressions and used it as correct data for training.", "labels": [], "entities": [{"text": "MCE learning", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9561736285686493}, {"text": "BLEU score", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9829416275024414}, {"text": "argmax r\u2208R BLEU", "start_pos": 89, "end_pos": 104, "type": "METRIC", "confidence": 0.7618685841560364}]}, {"text": "Note that r is a reference compression and R is the set of reference compressions.", "labels": [], "entities": []}, {"text": "We employed both automatic evaluation and human subjective evaluation.", "labels": [], "entities": []}, {"text": "For automatic evaluation, we employed BLEU () by following ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.999183714389801}]}, {"text": "We utilized 5-fold cross validation, i.e., we broke the whole data set into five blocks and used four of them for training and the remainder for testing and repeated the evaluation on the test data five times changing the test block each time.", "labels": [], "entities": []}, {"text": "We also employed human subjective evaluation, i.e., we presented the compressed sentences to six human subjects and asked them to evaluate the sentence for fluency and importance on a scale 1 (worst) to 5 (best).", "labels": [], "entities": []}, {"text": "For each source sentence, the order in which the compressed sentences were presented was random.", "labels": [], "entities": []}, {"text": "Without introducing dependency probability, both IPTW and PLM worked well.", "labels": [], "entities": []}, {"text": "Our method achieved the highest BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9622547030448914}]}, {"text": "Compared to 'Proposed', 'w/o IPTW' offers significantly worse performance.", "labels": [], "entities": []}, {"text": "The results support the view that our hypothesis, namely that the significance score of a word depends on its position within a sentence, is effective for sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 155, "end_pos": 175, "type": "TASK", "confidence": 0.7465833425521851}]}, {"text": "shows an example of Gaussian mixture with pre- we can see that the positional weights for words have peaks at BOS and EOS.", "labels": [], "entities": [{"text": "BOS", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.9985390901565552}, {"text": "EOS", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.9728044867515564}]}, {"text": "This is because, in many cases, the subject appears at the beginning of Japanese sentences and the predicate at the end.", "labels": [], "entities": []}, {"text": "Replacing PLM with the bigram language model (w/o PLM) degrades the performance significantly.", "labels": [], "entities": []}, {"text": "This result shows that the n-gram language model is improper for sentence compression because the n-gram probability is computed by using a corpus that includes both short and long sentences.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7575725317001343}]}, {"text": "Most bigrams in a compressed sentence followed those in the source sentence.", "labels": [], "entities": []}, {"text": "The dependency probability is very helpful provided either IPTW or PLM is employed.", "labels": [], "entities": []}, {"text": "For example, 'w/o PLM + Dep' achieved the second highest BLEU score.", "labels": [], "entities": [{"text": "PLM + Dep", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.7159316738446554}, {"text": "BLEU score", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9821726679801941}]}, {"text": "The difference of the score between 'Proposed' and 'w/o PLM + Dep' is only 0.01 but there were significant differences as determined by Wilcoxon signed rank test.", "labels": [], "entities": [{"text": "PLM + Dep'", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.759406253695488}, {"text": "Wilcoxon signed rank test", "start_pos": 136, "end_pos": 161, "type": "DATASET", "confidence": 0.7779493927955627}]}, {"text": "Compared to 'Hori\u2212', 'Hori' achieved a significantly higher BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9838728904724121}]}, {"text": "The introduction of both IPTW and PLM makes the use of dependency probability unnecessary.", "labels": [], "entities": []}, {"text": "In fact, the score of 'Proposed + Dep' is not good.", "labels": [], "entities": [{"text": "Proposed + Dep'", "start_pos": 23, "end_pos": 38, "type": "METRIC", "confidence": 0.8733225464820862}]}, {"text": "We believe that this is due to overfitting.", "labels": [], "entities": []}, {"text": "PLM is similar to dependency probability in that both features emphasize word pairs that occurred as bigrams in the source sentence.", "labels": [], "entities": [{"text": "PLM", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7493221759796143}]}, {"text": "Therefore, by introducing dependency probability, the information within the feature vector is not increased even though the number of features is increased.", "labels": [], "entities": []}, {"text": "We used human subjective evaluations to compare our method to human compression, 'w/o PLM + Dep' which achieved the second highest performance in the automatic evaluation, 'Hori\u2212' and 'Hori'.", "labels": [], "entities": []}, {"text": "We randomly selected 100 sentences from the test corpus and evaluated their compressed variants in terms of 'fluency' and 'importance.'", "labels": [], "entities": []}, {"text": "shows the results, mean score of all judgements as well as the standard deviation.", "labels": [], "entities": [{"text": "mean score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9750530123710632}, {"text": "standard", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9591588973999023}]}, {"text": "The results indicate that human compression achieved the best score in both fluency and importance.", "labels": [], "entities": [{"text": "human compression", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.6874909847974777}, {"text": "importance", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.977196216583252}]}, {"text": "Human compression significantly outperformed other compression methods.", "labels": [], "entities": [{"text": "Human compression", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7335262596607208}]}, {"text": "This results supports the idea that humans can easily compress sentences with the compression rate of 0.6.", "labels": [], "entities": []}, {"text": "Of the automatic methods, our method achieved the best score in both fluency and importance while 'Hori\u2212' was the worst performer.", "labels": [], "entities": [{"text": "importance", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.956916868686676}]}, {"text": "Our method significantly outperformed both 'Hori' and 'Hori\u2212' on both metrics.", "labels": [], "entities": []}, {"text": "Moreover, our method outperformed 'w/o PLM + Dep' again.", "labels": [], "entities": []}, {"text": "However, the differences in the scores are not significant.", "labels": [], "entities": []}, {"text": "We believe that this is due to alack of data.", "labels": [], "entities": []}, {"text": "If we use more data for the significant test, significant differences will be found.", "labels": [], "entities": []}, {"text": "Although our method does not employ any explicit syntactic information, its fluency and importance are extremely good.", "labels": [], "entities": []}, {"text": "This confirms the effectiveness of the new features of IPTW and PLM.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Configuration setup  Label  g()  h()  Proposed  IPTW PLM + POS  w/o PLM  IPTW Bigram+POS  w/o IPTW  IDF  PLM+POS  Hori\u2212  IDF  Trigram  Proposed+Dep  IPTW PLM + POS +Dep  w/o PLM+Dep IPTW Bigram+POS+Dep  w/o IPTW+Dep IDF  PLM+POS+Dep  Hori  IDF  Trigram+Dep", "labels": [], "entities": []}, {"text": " Table 2: Results: automatic evaluation  Label  BLEU  Proposed  .679  w/o PLM  .617  w/o IPTW  .635  Hori\u2212  .493  Proposed+Dep  .632  w/o PLM+Dep .669  w/o IPTW+Dep .656  Hori  .600", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9824441075325012}]}]}