{"title": [{"text": "Creating a Gold Standard for Sentence Clustering in Multi-Document Summarization", "labels": [], "entities": [{"text": "Sentence Clustering in Multi-Document Summarization", "start_pos": 29, "end_pos": 80, "type": "TASK", "confidence": 0.7663700699806213}]}], "abstractContent": [{"text": "Sentence Clustering is often used as a first step in Multi-Document Summarization (MDS) to find redundant information.", "labels": [], "entities": [{"text": "Sentence Clustering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8460669219493866}, {"text": "Multi-Document Summarization (MDS)", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.8400631964206695}]}, {"text": "All the same there is no gold standard available.", "labels": [], "entities": []}, {"text": "This paper describes the creation of a gold standard for sentence clustering from DUC document sets.", "labels": [], "entities": [{"text": "sentence clustering", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7239493727684021}]}, {"text": "The procedure of building the gold standard and the guidelines which were given to six human judges are described.", "labels": [], "entities": []}, {"text": "The most widely used and promising evaluation measures are presented and discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "The increasing amount of (online) information and the growing number of news websites lead to a debilitating amount of redundant information.", "labels": [], "entities": []}, {"text": "Different newswires publish different reports about the same event resulting in information overlap.", "labels": [], "entities": []}, {"text": "Multi-Document Summarization (MDS) can help to reduce the amount of documents a user has to read to keep informed.", "labels": [], "entities": [{"text": "Multi-Document Summarization (MDS)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8093437254428864}]}, {"text": "In contrast to single document summarization information overlap is one of the biggest challenges to MDS systems.", "labels": [], "entities": [{"text": "single document summarization information overlap", "start_pos": 15, "end_pos": 64, "type": "TASK", "confidence": 0.6711061894893646}]}, {"text": "While repeated information is a good evidence of importance, this information should be included in a summary only once in order to avoid a repetitive summary.", "labels": [], "entities": []}, {"text": "Sentence clustering has therefore often been used as an early step in MDS; Marcu and Gerber, 2001;).", "labels": [], "entities": [{"text": "Sentence clustering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9282771050930023}, {"text": "MDS", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.88218092918396}]}, {"text": "In sentence clustering semantically similar sentences are grouped together.", "labels": [], "entities": [{"text": "sentence clustering semantically similar sentences", "start_pos": 3, "end_pos": 53, "type": "TASK", "confidence": 0.8302181899547577}]}, {"text": "Sentences within a cluster overlap in information, but they do not have to be identical in meaning.", "labels": [], "entities": []}, {"text": "In contrast to paraphrases sentences in a cluster do not have to cover the same amount of information.", "labels": [], "entities": []}, {"text": "One sentence represents one cluster in the summary.", "labels": [], "entities": []}, {"text": "Either a sentences from the cluster is selected) or anew sentence is regenerated from all/some sentences in a cluster ().", "labels": [], "entities": []}, {"text": "Usually the quality of the sentence clusters are only evaluated indirectly by judging the quality of the generated summary.", "labels": [], "entities": []}, {"text": "There is still no standard evaluation method for summarization and no consensus in the summarization community how to evaluate a summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9894949793815613}, {"text": "summarization", "start_pos": 87, "end_pos": 100, "type": "TASK", "confidence": 0.967480480670929}]}, {"text": "The methods at hand are either superficial or time and resource consuming and not easily repeatable.", "labels": [], "entities": []}, {"text": "Another argument against indirect evaluation of clustering is that troubleshooting becomes more difficult.", "labels": [], "entities": []}, {"text": "If a poor summary was created it is not clear which component e.g. information extraction through clustering or summary generation (using for example language regeneration) is responsible for the lack of quality.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.7199028581380844}, {"text": "summary generation", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7131712138652802}, {"text": "language regeneration", "start_pos": 150, "end_pos": 171, "type": "TASK", "confidence": 0.7247121930122375}]}, {"text": "However there is no gold standard for sentence clustering available to which the output of a clustering systems can be compared.", "labels": [], "entities": [{"text": "sentence clustering", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.728688508272171}]}, {"text": "Another challenge is the evaluation of sentence clusters.", "labels": [], "entities": [{"text": "evaluation of sentence clusters", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.7609373480081558}]}, {"text": "There area lot of evaluation methods available.", "labels": [], "entities": []}, {"text": "Each of them focus on different properties of a set of clusters.", "labels": [], "entities": []}, {"text": "We will discuss and evaluate the most widely used and most promising measures.", "labels": [], "entities": []}, {"text": "In this paper the main focus is on the development of a gold standard for sentence clustering using DUC clusters.", "labels": [], "entities": [{"text": "sentence clustering", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.749196469783783}]}, {"text": "The guidelines and rules that were given to the human annotators are described and the interjudge agreement is evaluated.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation measures will compare a set of clusters to a set of classes.", "labels": [], "entities": []}, {"text": "An ideal evaluation measure should reward a set of clusters if the clusters are pure or homogeneous, so that it only contains sentences from one class.", "labels": [], "entities": []}, {"text": "On the other hand it should also reward the set if all/most of the sentences of a class are in one cluster (completeness).", "labels": [], "entities": []}, {"text": "If sentences that in the gold standard makeup one class are grouped into two clusters, the measure should penalise the clustering less than if a lot of irrelevant sentences were in the same cluster.", "labels": [], "entities": []}, {"text": "Homogeneity is more important to us.", "labels": [], "entities": [{"text": "Homogeneity", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9324607253074646}]}, {"text": "Dis a set of N sentences d a so that D = {d a |a = 1, ..., N }.", "labels": [], "entities": []}, {"text": "A set of clusters L = {l j |j = 1, ..., |L|} is a partition of a data set D into disjoint subsets called clusters, so that l j \u2229 l m = \u2205.", "labels": [], "entities": []}, {"text": "|L| is the number of clusters in L.", "labels": [], "entities": []}, {"text": "A set of clusters that contains only one cluster with all the sentences of D will be called L one . A cluster that contains only one object is called a singleton and a set of clusters that only consists of singletons is called L single . A set of classes C = {c i |i = 1, ..., |C|} is a partition of a data set D into disjoint subsets called classes, so that c i \u2229 cm = \u2205.", "labels": [], "entities": []}, {"text": "|C| is the number of classes in C.", "labels": [], "entities": []}, {"text": "C is also called a gold standard of a clustering of data set D because this set contains the \"ideal\" solution to a clustering task and other clusterings are compared to it.", "labels": [], "entities": []}, {"text": "We used one cluster set to analyse the behaviour and quality of the evaluation measures.", "labels": [], "entities": []}, {"text": "Variations of that cluster set were created by randomly splitting and merging the clusters.", "labels": [], "entities": []}, {"text": "These modified sets were then compared to the original set.", "labels": [], "entities": []}, {"text": "This experiment will help to identify the advantages and disadvantages of the measures, what the values reveal about the quality of a set of clusters and how the measures react to changes in the cluster set.", "labels": [], "entities": []}, {"text": "We used the set of clusters created by Judge A for the Rushdie sentence set.", "labels": [], "entities": []}, {"text": "It contains 70 sentences in 15 clusters.", "labels": [], "entities": []}, {"text": "This cluster set was modified by splitting and merging the clusters randomly until we got L single with 70 clusters and L one with one cluster.", "labels": [], "entities": []}, {"text": "The original set of clusters (C A ) was compared to the modified versions of the set (see).", "labels": [], "entities": []}, {"text": "The evaluation measures reach their best values if CA = 15 clusters is compared to itself.", "labels": [], "entities": [{"text": "CA", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9806899428367615}]}, {"text": "The F -measure is very sensitive to changes.", "labels": [], "entities": [{"text": "F -measure", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9890866676966349}]}, {"text": "It is the only measure which uses its full measurement range.", "labels": [], "entities": []}, {"text": "F = 0 if CA is compared to L A\u2212single , which means that the F -measure considers L A\u2212single to be the opposite of CA . Usually L one and L A\u2212single are considered to be observe and a measure should only reach its worst possible value if these sets are compared.", "labels": [], "entities": [{"text": "F -measure", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9685370127360026}]}, {"text": "In other words the F -measure might be too sensitive for our task.", "labels": [], "entities": [{"text": "F -measure", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.994515041510264}]}, {"text": "The RI stays most of the time in an interval between 0.84 and 1.", "labels": [], "entities": [{"text": "RI", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9927347898483276}]}, {"text": "Even for the comparison between CA and L A\u2212single the RI is 0.91.", "labels": [], "entities": [{"text": "RI", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9979782700538635}]}, {"text": "This behaviour was also described in who observed that the RI concentrates in a small interval near 1.", "labels": [], "entities": []}, {"text": "As described in section 5.5 Purity and Entropy both measure homogeneity.", "labels": [], "entities": []}, {"text": "They both react to changes slowly.", "labels": [], "entities": []}, {"text": "Splitting and merging have almost the same effect on Purity.", "labels": [], "entities": [{"text": "Splitting", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9567448496818542}]}, {"text": "It reaches \u2248 0.6 when the clusters of the set were randomly split or merged four times.", "labels": [], "entities": []}, {"text": "As explained above our ideal evaluation measure should punish a set of clusters which puts sentences of the same class into two clusters less than if sentences are merged with irrelevant ones.", "labels": [], "entities": []}, {"text": "Homogeneity decreases if unrelated clusters are merged whereas a decline in completeness follows from splitting clusters.", "labels": [], "entities": []}, {"text": "In other words for our task a measure should decrease more if two clusters are merged than if a cluster is split.", "labels": [], "entities": []}, {"text": "Entropy for example is more sensitive to merging than splitting.", "labels": [], "entities": []}, {"text": "But Entropy only measures homogeneity and an ideal evaluation measure should also consider completeness.", "labels": [], "entities": []}, {"text": "The remaining measures V beta , V 0.5 and NV I/V I all fulfil our criteria of a good evaluation measure.", "labels": [], "entities": [{"text": "V", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9480050206184387}, {"text": "NV I/V I", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.7460918068885803}]}, {"text": "All of them are more affected by merging than by splitting and use their measuring range appropriately.", "labels": [], "entities": []}, {"text": "V 0.5 favours homogeneity over completeness, but it reacts to changes less than V beta . The V -measure can also be inaccurate if the |L| is considerably different to |C|.", "labels": [], "entities": [{"text": "V -measure", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.8738583127657572}]}, {"text": "normalising VI by dividing it by log N . As Meila (2007) pointed out, this is only convenient if the comparison is limited to one data set.", "labels": [], "entities": []}, {"text": "In this paper V beta , V 0.5 and NV I will be used for evaluation purposes.", "labels": [], "entities": [{"text": "NV I", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.8511085212230682}]}], "tableCaptions": [{"text": " Table 1: Properties of sentence sets", "labels": [], "entities": []}, {"text": " Table 2: Details of manual clusterings: s number of sentences in a set, c number of clusters, s/c average  number of sentences in a cluster", "labels": [], "entities": []}, {"text": " Table 3: Inter-judge agreement for the four sentence set.", "labels": [], "entities": []}]}