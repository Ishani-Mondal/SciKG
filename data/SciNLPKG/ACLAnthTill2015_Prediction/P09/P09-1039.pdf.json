{"title": [{"text": "Concise Integer Linear Programming Formulations for Dependency Parsing", "labels": [], "entities": [{"text": "Integer Linear Programming Formulations", "start_pos": 8, "end_pos": 47, "type": "TASK", "confidence": 0.6040931940078735}, {"text": "Dependency Parsing", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.6527559608221054}]}], "abstractContent": [{"text": "We formulate the problem of non-projective dependency parsing as a polynomial-sized integer linear program.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.7481503287951151}]}, {"text": "Our formulation is able to handle non-local output features in an efficient manner; not only is it compatible with prior knowledge encoded as hard constraints , it can also learn soft constraints from data.", "labels": [], "entities": []}, {"text": "In particular, our model is able to learn correlations among neighboring arcs (siblings and grandparents), word valency, and tendencies toward nearly-projective parses.", "labels": [], "entities": []}, {"text": "The model parameters are learned in a max-margin framework by employing a linear programming relaxation.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our parser on data in several natural languages, achieving improvements over existing state-of-the-art methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much attention has recently been devoted to integer linear programming (ILP) formulations of NLP problems, with interesting results in applications like semantic role labeling), dependency parsing (), word alignment for machine translation), summarization, and coreference resolution, among others.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.6505849758783976}, {"text": "dependency parsing", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.8172713816165924}, {"text": "word alignment for machine translation", "start_pos": 201, "end_pos": 239, "type": "TASK", "confidence": 0.6720616042613983}, {"text": "summarization", "start_pos": 242, "end_pos": 255, "type": "TASK", "confidence": 0.9941496849060059}, {"text": "coreference resolution", "start_pos": 261, "end_pos": 283, "type": "TASK", "confidence": 0.9684759676456451}]}, {"text": "In general, the rationale for the development of ILP formulations is to incorporate non-local features or global constraints, which are often difficult to handle with traditional algorithms.", "labels": [], "entities": [{"text": "ILP formulations", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.9319063127040863}]}, {"text": "ILP formulations focus more on the modeling of problems, rather than algorithm design.", "labels": [], "entities": [{"text": "ILP formulations", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8910252451896667}]}, {"text": "While solving an ILP is NP-hard in general, fast solvers are available today that make it a practical solution for many NLP problems.", "labels": [], "entities": []}, {"text": "This paper presents new, concise ILP formulations for projective and non-projective dependency parsing.", "labels": [], "entities": [{"text": "projective and non-projective dependency parsing", "start_pos": 54, "end_pos": 102, "type": "TASK", "confidence": 0.6603453099727631}]}, {"text": "We believe that our formulations can pave the way for efficient exploitation of global features and constraints in parsing applications, leading to more powerful models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 115, "end_pos": 122, "type": "TASK", "confidence": 0.9634420275688171}]}, {"text": "cast dependency parsing as an ILP, but efficient formulations remain an open problem.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.694900631904602}]}, {"text": "Our formulations offer the following comparative advantages: \u2022 The numbers of variables and constraints are polynomial in the sentence length, as opposed to requiring exponentially many constraints, eliminating the need for incremental procedures like the cutting-plane algorithm; \u2022 LP relaxations permit fast online discriminative training of the constrained model; \u2022 Soft constraints maybe automatically learned from data.", "labels": [], "entities": []}, {"text": "In particular, our formulations handle higher-order arc interactions (like siblings and grandparents), model word valency, and can learn to favor nearly-projective parses.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the new parsers on standard parsing tasks in seven languages.", "labels": [], "entities": []}, {"text": "The techniques that we present are also compatible with scenarios where expert knowledge is available, for example in the form of hard or soft firstorder logic constraints ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We report experiments on seven languages, six (Danish, Dutch, Portuguese, Slovene, Swedish and Turkish) from the CoNLL-X shared task (), and one (English) from the CoNLL-2008 shared task (.", "labels": [], "entities": [{"text": "CoNLL-X shared task", "start_pos": 113, "end_pos": 132, "type": "DATASET", "confidence": 0.7964442372322083}, {"text": "CoNLL-2008 shared task", "start_pos": 164, "end_pos": 186, "type": "DATASET", "confidence": 0.830636183420817}]}, {"text": "8 All experiments are evaluated using the unlabeled attachment score (UAS), using the default settings.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 42, "end_pos": 74, "type": "METRIC", "confidence": 0.79857304195563}]}, {"text": "We used the same arc-factored features as (included in the MSTParser toolkit 10 ); for the higher-order models described in \u00a73.3-3.5, we employed simple higher order features that look at the word, part-of-speech tag, and (if available) morphological information of the words being correlated through the indicator variables.", "labels": [], "entities": [{"text": "MSTParser toolkit 10", "start_pos": 59, "end_pos": 79, "type": "DATASET", "confidence": 0.9448049863179525}]}, {"text": "For scalability (and noting that some of the models require O(|V | \u00b7 |A|) constraints and variables, which, when A = V 2 , grows cubically with the number of words), we first prune the base graph by running a simple algorithm that ranks the k-best candidate parents for each word in the sentence (we set k = 10); this reduces the number of candidate arcs to |A| = kn.", "labels": [], "entities": []}, {"text": "11 This strategy is similar to the one employed by to prune the search space of the actual parser.", "labels": [], "entities": []}, {"text": "The ranker is a local model trained using a max-margin criterion; it is arc-factored and not subject to any structural constraints, so it is very fast.", "labels": [], "entities": []}, {"text": "The actual parser was trained via the online structured passive-aggressive algorithm of; it differs from the 1-best MIRA algorithm of by solving a sequence of loss-augmented inference problems.", "labels": [], "entities": []}, {"text": "The number of iterations was set to 10.", "labels": [], "entities": []}, {"text": "The results are summarized in; for the sake of comparison, we reproduced three strong baselines, all of them state-of-the-art parsers based on non-arc-factored models: the second order model of, the hybrid model of, which combines a (labeled) transition-based and a graphbased parser, and a refinement of the latter, due to, which attempts to approximate non-local features.", "labels": [], "entities": []}, {"text": "We did not reproduce the model of since the latter is tailored for labeled dependency parsing; however, experiments reported in that paper for Dutch (and extended to other languages in the CoNLL-X task) suggest that their model performs worse than our three baselines.", "labels": [], "entities": [{"text": "labeled dependency parsing", "start_pos": 67, "end_pos": 93, "type": "TASK", "confidence": 0.6174933115641276}]}, {"text": "By looking at the middle four columns, we can see that adding non-arc-factored features makes the models more accurate, for all languages.", "labels": [], "entities": []}, {"text": "With the exception of Portuguese, the best results are achieved with the full set of features.", "labels": [], "entities": []}, {"text": "We can also observe that, for some languages, the valency features do not seem to help.", "labels": [], "entities": []}, {"text": "Merely modeling the number of dependents of a word may not be as valuable as knowing what kinds of dependents they are (for example, distinguishing among arguments and adjuncts).", "labels": [], "entities": []}, {"text": "Comparing with the baselines, we observe that our full model outperforms that of, and is inline with the most accurate dependency parsers, obtained by combining transition-based and graph-based parsers.", "labels": [], "entities": []}, {"text": "Notice that our model, compared with these hybrid parsers, has the advantage of not requiring an ensemble configuration (eliminating, for example, the need to tune two parsers).", "labels": [], "entities": []}, {"text": "Unlike the ensembles, it directly handles non-local output features by optimizing a single global objective.", "labels": [], "entities": []}, {"text": "Perhaps more importantly, it makes it possible to exploit expert knowledge through the form of hard global constraints.", "labels": [], "entities": []}, {"text": "Although not pursued here, the same kind of constraints employed by can straightforwardly fit into our model, after extending it to perform labeled dependency parsing.", "labels": [], "entities": [{"text": "labeled dependency parsing", "start_pos": 140, "end_pos": 166, "type": "TASK", "confidence": 0.5949536263942719}]}, {"text": "We believe that a careful design of fea-: Results for nonprojective dependency parsing (unlabeled attachment scores).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7184019982814789}]}, {"text": "The three baselines are the second order model of and the hybrid models of and.", "labels": [], "entities": []}, {"text": "The four middle columns show the performance of our model using exact (ILP) inference attest time, for increasing sets of features (see \u00a73.2- \u00a73.5).", "labels": [], "entities": [{"text": "exact (ILP) inference attest time", "start_pos": 64, "end_pos": 97, "type": "METRIC", "confidence": 0.7853614858218602}]}, {"text": "The rightmost column shows the results obtained with the full set of features using relaxed LP inference followed by projection onto the feasible set.", "labels": [], "entities": []}, {"text": "Differences are with respect to exact inference for the same set of features.", "labels": [], "entities": []}, {"text": "Bold indicates the best result fora language.", "labels": [], "entities": []}, {"text": "As for overall performance, both the exact and relaxed full model outperform the arcfactored model and the second order model of with statistical significance (p < 0.01) according to Dan Bikel's randomized method (http://www.cis.upenn.edu/ \u223c dbikel/software.html).", "labels": [], "entities": []}, {"text": "tures and constraints can lead to further improvements on accuracy.", "labels": [], "entities": [{"text": "tures", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8914322853088379}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9970148801803589}]}, {"text": "We now turn to a different issue: scalability.", "labels": [], "entities": []}, {"text": "In previous work, we showed that training the model via LP-relaxed inference (as we do here) makes it learn to avoid fractional solutions; as a consequence, ILP solvers will converge faster to the optimum (on average).", "labels": [], "entities": [{"text": "ILP solvers", "start_pos": 157, "end_pos": 168, "type": "TASK", "confidence": 0.6781953275203705}]}, {"text": "Yet, it is known from worst case complexity theory that solving a general ILP is NP-hard; hence, these solvers may not scale well with the sentence length.", "labels": [], "entities": []}, {"text": "Merely considering the LP-relaxed version of the problem attest time is unsatisfactory, as it may lead to a fractional solution (i.e., a solution whose components indexed by arcs, \u02dc z = z a a\u2208A , are not all integer), which does not correspond to a valid dependency tree.", "labels": [], "entities": []}, {"text": "We propose the following approximate algorithm to obtain an actual parse: first, solve the LP relaxation (which can be done in polynomial time with interior-point methods); then, if the solution is fractional, project it onto the feasible set Y(x).", "labels": [], "entities": []}, {"text": "Fortunately, the Euclidean projection can be computed in a straightforward way by finding a maximal arborescence in the directed graph whose weights are defined by\u02dczby\u02dc by\u02dcz (we omit the proof for space); as we saw in \u00a72.2, the ChuLiu-Edmonds algorithm can do this in polynomial time.", "labels": [], "entities": []}, {"text": "The overall parsing runtime becomes polynomial with respect to the length of the sentence.", "labels": [], "entities": []}, {"text": "The last column of compares the accuracy of this approximate method with the exact one.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9996310472488403}]}, {"text": "We observe that there is not a substantial drop inaccuracy; on the other hand, we observed a considerable speed-up with respect to exact inference, particularly for long sentences.", "labels": [], "entities": [{"text": "speed-up", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9723018407821655}]}, {"text": "The average runtime (across all languages) is 0.632 seconds per sentence, which is inline with existing higher-order parsers and is much faster than the runtimes reported by.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for nonprojective dependency parsing (unlabeled attachment scores). The three baselines are the second order  model of", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7122098356485367}]}]}