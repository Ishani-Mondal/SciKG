{"title": [], "abstractContent": [{"text": "Binarization of n-ary rules is critical for the efficiency of syntactic machine translation decoding.", "labels": [], "entities": [{"text": "syntactic machine translation decoding", "start_pos": 62, "end_pos": 100, "type": "TASK", "confidence": 0.7608077451586723}]}, {"text": "Because the target side of a rule will generally reorder the source side, it is complex (and sometimes impossible) to find synchronous rule bina-rizations.", "labels": [], "entities": []}, {"text": "However, we show that synchronous binarizations are not necessary in a two-stage de-coder.", "labels": [], "entities": []}, {"text": "Instead, the grammar can be binarized one way for the parsing stage, then rebinarized in a different way for the reranking stage.", "labels": [], "entities": []}, {"text": "Each individual binarization considers only one monolin-gual projection of the grammar, entirely avoiding the constraints of synchronous binarization and allowing binarizations that are separately optimized for each stage.", "labels": [], "entities": []}, {"text": "Compared to n-ary forest reranking, even simple target-side binariza-tion schemes improve overall decoding accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9895528554916382}]}], "introductionContent": [{"text": "Syntactic machine translation decoders search over a space of synchronous derivations, scoring them according to both a weighted synchronous grammar and an n-gram language model.", "labels": [], "entities": [{"text": "machine translation decoders", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8118025660514832}]}, {"text": "The rewrites of the synchronous translation grammar are typically flat, n-ary rules.", "labels": [], "entities": []}, {"text": "Past work has synchronously binarized such rules for efficiency (.", "labels": [], "entities": []}, {"text": "Unfortunately, because source and target orders differ, synchronous binarizations can be highly constrained and sometimes impossible to find.", "labels": [], "entities": []}, {"text": "Recent work has explored two-stage decoding, which explicitly decouples decoding into a source parsing stage and a target language model integration stage.", "labels": [], "entities": []}, {"text": "Because translation grammars continue to increase in size and complexity, both decoding stages require efficient approaches (.", "labels": [], "entities": [{"text": "translation grammars", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.9534140229225159}]}, {"text": "In this paper, we show how two-stage decoding enables independent binarizations for each stage.", "labels": [], "entities": []}, {"text": "The source-side binarization guarantees cubictime construction of a derivation forest, while an entirely different target-side binarization leads to efficient forest reranking with a language model.", "labels": [], "entities": []}, {"text": "Binarizing asynchronous grammar twice independently has two principal advantages over synchronous binarization.", "labels": [], "entities": [{"text": "Binarizing asynchronous grammar", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7983663479487101}]}, {"text": "First, each binarization can be fully tailored to its decoding stage, optimizing the efficiency of both parsing and language model reranking.", "labels": [], "entities": []}, {"text": "Second, the ITG constraint on non-terminal reordering patterns is circumvented, allowing the efficient application of synchronous rules that do not have asynchronous binarization.", "labels": [], "entities": []}, {"text": "The primary contribution of this paper is to establish that binarization of synchronous grammars need not be constrained by cross-lingual reordering patterns.", "labels": [], "entities": []}, {"text": "We also demonstrate that even simple target-side binarization schemes improve the search accuracy of forest reranking with a language model, relative to n-ary forest reranking.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.993120551109314}]}], "datasetContent": [{"text": "The utility of binarization for parsing is well known, and plays an important role in the efficiency of the parsing stage of decoding  model reranking has also been established, both for synchronous binarization () and for target-only binarization.", "labels": [], "entities": [{"text": "parsing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9802019000053406}]}, {"text": "In our experiment, we evaluate the benefit of targetside forest re-binarization in the two-stage decoder of, relative to reranking n-ary forests directly.", "labels": [], "entities": []}, {"text": "We translated 300 NIST 2005 Arabic sentences to English with a large grammar learned from a 220 million word bitext, using rules with up to 6 non-terminals.", "labels": [], "entities": [{"text": "NIST 2005 Arabic sentences", "start_pos": 18, "end_pos": 44, "type": "DATASET", "confidence": 0.8616341054439545}]}, {"text": "We used a trigram language model trained on the English side of this bitext.", "labels": [], "entities": []}, {"text": "Model parameters were tuned with MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.8024049997329712}]}, {"text": "Beam size was limited to 200 derivations per forest node.", "labels": [], "entities": [{"text": "Beam size", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.6627130806446075}]}, {"text": "shows a modest increase in model and BLEU score from left-branching binarization during language model reranking.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9823553562164307}]}, {"text": "We used the same pruned n-ary forest from an identical parsing stage in both conditions.", "labels": [], "entities": []}, {"text": "Binarization did increase reranking time by 25% because more k-best lists are constructed.", "labels": [], "entities": []}, {"text": "However, reusing intermediate edges during reranking binarization reduced binarized reranking time by 37%.", "labels": [], "entities": []}, {"text": "We found that on average, intermediate nodes introduced in the forest are used in 4.5 different rules, which accounts for the speed increase.", "labels": [], "entities": [{"text": "speed", "start_pos": 126, "end_pos": 131, "type": "METRIC", "confidence": 0.9626007080078125}]}], "tableCaptions": [{"text": " Table 1: Reranking a binarized forest improves BLEU by 0.3  and model score by 13 relative to an n-ary forest baseline by  reducing search errors during forest rescoring.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9994385838508606}, {"text": "model score", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9608076214790344}]}]}