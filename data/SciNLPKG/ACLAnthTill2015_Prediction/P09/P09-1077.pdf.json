{"title": [{"text": "Automatic sense prediction for implicit discourse relations in text", "labels": [], "entities": [{"text": "Automatic sense prediction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6605883141358694}]}], "abstractContent": [{"text": "We present a series of experiments on automatically identifying the sense of implicit discourse relations, i.e. relations that are not marked with a discourse connective such as \"but\" or \"because\".", "labels": [], "entities": []}, {"text": "We work with a corpus of implicit relations present in newspaper text and report results on a test set that is representative of the naturally occurring distribution of senses.", "labels": [], "entities": []}, {"text": "We use several linguistically informed features, including polarity tags, Levin verb classes, length of verb phrases, modality, context, and lexical features.", "labels": [], "entities": []}, {"text": "In addition, we revisit past approaches using lexical pairs from unannotated text as features , explain some of their shortcomings and propose modifications.", "labels": [], "entities": []}, {"text": "Our best combination of features outperforms the base-line from data intensive approaches by 4% for comparison and 16% for contingency.", "labels": [], "entities": []}], "introductionContent": [{"text": "Implicit discourse relations abound in text and readers easily recover the sense of such relations during semantic interpretation.", "labels": [], "entities": []}, {"text": "But automatic sense prediction for implicit relations is an outstanding challenge in discourse processing.", "labels": [], "entities": [{"text": "automatic sense prediction", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6364743014176687}]}, {"text": "Discourse relations, such as causal and contrast relations, are often marked by explicit discourse connectives (also called cue words) such as \"because\" or \"but\".", "labels": [], "entities": []}, {"text": "It is not uncommon, though, fora discourse relation to hold between two text spans without an explicit discourse connective, as the example below demonstrates: (1) The 101-year-old magazine has never had to woo advertisers with quite so much fervor before.", "labels": [], "entities": []}, {"text": "[because] It largely rested on its hard-to-fault demographics.", "labels": [], "entities": []}, {"text": "In this paper we address the problem of automatic sense prediction for discourse relations in newspaper text.", "labels": [], "entities": [{"text": "automatic sense prediction", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.6018403371175131}]}, {"text": "For our experiments, we use the Penn Discourse Treebank, the largest existing corpus of discourse annotations for both implicit and explicit relations.", "labels": [], "entities": [{"text": "Penn Discourse Treebank", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.9851067662239075}]}, {"text": "Our work is also informed by the long tradition of data intensive methods that rely on huge amounts of unannotated text rather than on manually tagged corpora (.", "labels": [], "entities": []}, {"text": "In our analysis, we focus only on implicit discourse relations and clearly separate these from explicits.", "labels": [], "entities": []}, {"text": "Explicit relations are easy to identify.", "labels": [], "entities": []}, {"text": "The most general senses (comparison, contingency, temporal and expansion) can be disambiguated in explicit relations with 93% accuracy based solely on the discourse connective used to signal the relation (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9987475872039795}]}, {"text": "So reporting results on explicit and implicit relations separately will allow for clearer tracking of progress.", "labels": [], "entities": []}, {"text": "In this paper we investigate the effectiveness of various features designed to capture lexical and semantic regularities for identifying the sense of implicit relations.", "labels": [], "entities": []}, {"text": "Given two text spans, previous work has used the cross-product of the words in the spans as features.", "labels": [], "entities": []}, {"text": "We examine the most informative word pair features and find that they are not the semantically-related pairs that researchers had hoped.", "labels": [], "entities": []}, {"text": "We then introduce several other methods capturing the semantics of the spans (polarity features, semantic classes, tense, etc.) and evaluate their effectiveness.", "labels": [], "entities": []}, {"text": "This is the first study which reports results on classifying naturally occurring implicit relations in text and uses the natural distribution of the various senses.", "labels": [], "entities": [{"text": "classifying naturally occurring implicit relations in text", "start_pos": 49, "end_pos": 107, "type": "TASK", "confidence": 0.8480889797210693}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: f-score (accuracy) using different features; Naive Bayes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9824275374412537}]}]}