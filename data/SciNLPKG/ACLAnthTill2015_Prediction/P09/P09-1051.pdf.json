{"title": [{"text": "Extracting Lexical Reference Rules from Wikipedia", "labels": [], "entities": [{"text": "Extracting Lexical Reference", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.895122746626536}]}], "abstractContent": [{"text": "This paper describes the extraction from Wikipedia of lexical reference rules, identifying references to term meanings triggered by other terms.", "labels": [], "entities": []}, {"text": "We present extraction methods geared to cover the broad range of the lexical reference relation and analyze them extensively.", "labels": [], "entities": []}, {"text": "Most extraction methods yield high precision levels, and our rule-base is shown to perform better than other automatically constructed baselines in a couple of lexical expansion and matching tasks.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9838485717773438}, {"text": "lexical expansion and matching", "start_pos": 160, "end_pos": 190, "type": "TASK", "confidence": 0.7198489308357239}]}, {"text": "Our rule-base yields comparable performance to Word-Net while providing largely complementary information.", "labels": [], "entities": [{"text": "Word-Net", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.9320883750915527}]}], "introductionContent": [{"text": "A most common need in applied semantic inference is to infer the meaning of a target term from other terms in a text.", "labels": [], "entities": [{"text": "applied semantic inference", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.687409520149231}]}, {"text": "For example, a Question Answering system may infer the answer to a question regarding luxury cars from a text mentioning Bentley, which provides a concrete reference to the sought meaning.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7306346595287323}]}, {"text": "Aiming to capture such lexical inferences we followed ( ), which coined the term lexical reference (LR) to denote references in text to the specific meaning of a target term.", "labels": [], "entities": []}, {"text": "They further analyzed the dataset of the First Recognizing Textual Entailment Challenge (), which includes examples drawn from seven different application scenarios.", "labels": [], "entities": [{"text": "First Recognizing Textual Entailment Challenge", "start_pos": 41, "end_pos": 87, "type": "TASK", "confidence": 0.6143926978111267}]}, {"text": "It was found that an entailing text indeed includes a concrete reference to practically every term in the entailed (inferred) sentence.", "labels": [], "entities": []}, {"text": "The lexical reference relation between two terms maybe viewed as a lexical inference rule, denoted LHS \u21d2 RHS.", "labels": [], "entities": [{"text": "RHS", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.8875870108604431}]}, {"text": "Such rule indicates that the left-hand-side term would generate a reference, in some texts, to a possible meaning of the right hand side term, as the Bentley \u21d2 luxury car example.", "labels": [], "entities": []}, {"text": "In the above example the LHS is a hyponym of the RHS.", "labels": [], "entities": [{"text": "RHS", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.870552659034729}]}, {"text": "Indeed, the commonly used hyponymy, synonymy and some cases of the meronymy relations are special cases of lexical reference.", "labels": [], "entities": []}, {"text": "However, lexical reference is a broader relation.", "labels": [], "entities": []}, {"text": "For instance, the LR rule physician \u21d2 medicine maybe useful to infer the topic medicine in a text categorization setting, while an information extraction system may utilize the rule Margaret Thatcher \u21d2 United Kingdom to infer a UK announcement from the text \"Margaret Thatcher announced\".", "labels": [], "entities": [{"text": "information extraction", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.7259159982204437}]}, {"text": "To perform such inferences, systems need large scale knowledge bases of LR rules.", "labels": [], "entities": []}, {"text": "A prominent available resource is WordNet, from which classical relations such as synonyms, hyponyms and some cases of meronyms maybe used as LR rules.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9566726684570312}]}, {"text": "An extension to WordNet was presented by).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9549544453620911}]}, {"text": "Yet, available resources do not cover the full scope of lexical reference.", "labels": [], "entities": []}, {"text": "This paper presents the extraction of a largescale rule base from Wikipedia designed to cover a wide scope of the lexical reference relation.", "labels": [], "entities": []}, {"text": "As a starting point we examine the potential of definition sentences as a source for LR rules).", "labels": [], "entities": []}, {"text": "When writing a concept definition, one aims to formulate a concise text that includes the most characteristic aspects of the defined concept.", "labels": [], "entities": []}, {"text": "Therefore, a definition is a promising source for LR relations between the defined concept and the definition terms.", "labels": [], "entities": []}, {"text": "In addition, we extract LR rules from Wikipedia redirect and hyperlink relations.", "labels": [], "entities": []}, {"text": "As a guideline, we focused on developing simple extraction methods that maybe applicable for other Web knowledge resources, rather than focusing on Wikipedia-specific attributes.", "labels": [], "entities": []}, {"text": "Overall, our rule base contains about 8 million candidate lexical ref-erence rules.", "labels": [], "entities": []}, {"text": "Extensive analysis estimated that 66% of our rules are correct, while different portions of the rule base provide varying recall-precision tradeoffs.", "labels": [], "entities": [{"text": "recall-precision", "start_pos": 122, "end_pos": 138, "type": "METRIC", "confidence": 0.9947956204414368}]}, {"text": "Following further error analysis we introduce rule filtering which improves inference performance.", "labels": [], "entities": [{"text": "rule filtering", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7999027371406555}]}, {"text": "The rule base utility was evaluated within two lexical expansion applications, yielding better results than other automatically constructed baselines and comparable results to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 176, "end_pos": 183, "type": "DATASET", "confidence": 0.95782870054245}]}, {"text": "A combination with WordNet achieved the best performance, indicating the significant marginal contribution of our rule base.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.9687156677246094}]}], "datasetContent": [{"text": "Our primary application oriented evaluation is within an unsupervised lexical expansion scenario applied to a text categorization data set (Section 6.1).", "labels": [], "entities": []}, {"text": "Additionally, we evaluate the utility of our rule base as a lexical resource for recognizing textual entailment (Section 6.2).", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 81, "end_pos": 111, "type": "TASK", "confidence": 0.7240678071975708}]}, {"text": "Our categorization experiment follows atypical keywords-based text categorization scheme).", "labels": [], "entities": []}, {"text": "Taking a lexical reference perspective, we assume that the characteristic expansion terms fora category should refer to the term (or terms) denoting the category name.", "labels": [], "entities": []}, {"text": "Accordingly, we construct the category's feature vector by taking first the category name itself, and then expanding it with all lefthand sides of lexical reference rules whose righthand side is the category name.", "labels": [], "entities": []}, {"text": "For example, the category \"Cars\" is expanded by rules such as Ferrari F50 \u21d2 car.", "labels": [], "entities": []}, {"text": "During classification cosine similarity is measured between the feature vector of the classified document and the expanded vectors of all categories.", "labels": [], "entities": [{"text": "classification cosine similarity", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.7069796025753021}]}, {"text": "The document is assigned to the category which yields the highest similarity score, following a single-class classification approach ().", "labels": [], "entities": [{"text": "similarity score", "start_pos": 66, "end_pos": 82, "type": "METRIC", "confidence": 0.9639878273010254}]}, {"text": "It should be noted that keyword-based text categorization systems employ various additional steps, such as bootstrapping, which generalize to multi-class settings and further improve performance.", "labels": [], "entities": []}, {"text": "Our basic implementation suffices to evaluate comparatively the direct impact of different expansion resources on the initial classification.", "labels": [], "entities": []}, {"text": "For evaluation we used the test set of the \"bydate\" version of the 20-News Groups collection, 7 which contains 18,846 documents partitioned (nearly) evenly over the 20 categories 8 .", "labels": [], "entities": [{"text": "20-News Groups collection", "start_pos": 67, "end_pos": 92, "type": "DATASET", "confidence": 0.6637899378935496}]}], "tableCaptions": [{"text": " Table 2: Manual analysis: precision and estimated number", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9997265934944153}]}, {"text": " Table 3. Typical re- lations covered by Redirect and Link rules include synonyms (NY State Trooper \u21d2 New York State  Police), morphological derivations (irritate \u21d2 ir- ritation), different spellings or naming (Pytagoras  \u21d2 Pythagoras) and acronyms (AIS \u21d2 Alarm Indi- cation Signal).", "labels": [], "entities": []}, {"text": " Table 4: Splitting All-N extraction method into 3 sub-types.", "labels": [], "entities": [{"text": "Splitting All-N extraction", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8857336044311523}]}, {"text": " Table 5: Results of different rule bases for 20 newsgroups", "labels": [], "entities": []}]}