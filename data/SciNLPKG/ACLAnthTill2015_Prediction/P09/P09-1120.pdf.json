{"title": [{"text": "Language Identification of Search Engine Queries", "labels": [], "entities": [{"text": "Language Identification of Search Engine Queries", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8180777182181677}]}], "abstractContent": [{"text": "We consider the language identification problem for search engine queries.", "labels": [], "entities": [{"text": "language identification", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.7458833456039429}]}, {"text": "First, we propose a method to automatically generate a data set, which uses click-through logs of the Yahoo!", "labels": [], "entities": []}, {"text": "Search Engine to derive the language of a query indirectly from the language of the documents clicked by the users.", "labels": [], "entities": []}, {"text": "Next, we use this data set to train two decision tree classi-fiers; one that only uses linguistic features and is aimed for textual language identification , and one that additionally uses a non-linguistic feature, and is geared towards the identification of the language intended by the users of the search engine.", "labels": [], "entities": [{"text": "textual language identification", "start_pos": 124, "end_pos": 155, "type": "TASK", "confidence": 0.6398431857426962}]}, {"text": "Our results show that our method produces a highly reliable data set very efficiently , and our decision tree classifier outperforms some of the best methods that have been proposed for the task of written language identification on the domain of search engine queries.", "labels": [], "entities": [{"text": "written language identification", "start_pos": 198, "end_pos": 229, "type": "TASK", "confidence": 0.6403942704200745}]}], "introductionContent": [{"text": "The language identification problem refers to the task of deciding in which natural language a given text is written.", "labels": [], "entities": [{"text": "language identification problem", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.7846506138642629}]}, {"text": "Although the problem is heavily studied by the Natural Language Processing community, most of the research carried out to date has been concerned with relatively long texts such as articles or web pages which usually contain enough text for the systems built for this task to reach almost perfect accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 297, "end_pos": 305, "type": "METRIC", "confidence": 0.9776115417480469}]}, {"text": "shows the performance of 6 different language identification methods on written texts of 10 European languages that use the Roman Alphabet.", "labels": [], "entities": [{"text": "language identification", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7637798488140106}]}, {"text": "It can be seen that the methods reach a very high accuracy when the text has 100 or more characters.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9980873465538025}]}, {"text": "However, search engine queries are very short in length; they have about 2 to 3 words on average, which requires a reconsideration of the existing methods built for this problem.", "labels": [], "entities": []}, {"text": "Correct identification of the language of the queries is of critical importance to search engines.", "labels": [], "entities": []}, {"text": "Major search engines such as Yahoo!", "labels": [], "entities": []}, {"text": "Search (www.yahoo.com), or Google (www.google.com) crawl billions of web pages in more than 50 languages, and about a quarter of their queries are in languages other than English.", "labels": [], "entities": []}, {"text": "Therefore a correct identification of the language of a query is needed in order to aid the search engine towards more accurate results.", "labels": [], "entities": []}, {"text": "Moreover, it also helps further processing of the queries, such as stemming or spell checking of the query terms.", "labels": [], "entities": [{"text": "stemming", "start_pos": 67, "end_pos": 75, "type": "TASK", "confidence": 0.9701634049415588}, {"text": "spell checking of the query terms", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.8222905198733012}]}, {"text": "One of the challenges in this problem is the lack of any standard or publicly available data set.", "labels": [], "entities": []}, {"text": "Furthermore, creating such a data set is expensive as it requires an extensive amount of work by human annotators.", "labels": [], "entities": []}, {"text": "In this paper, we introduce anew method to overcome this bottleneck by automatically generating a data set of queries with language annotations.", "labels": [], "entities": []}, {"text": "We show that the data generated this way is highly reliable and can be used to train a machine learning algorithm.", "labels": [], "entities": []}, {"text": "We also distinguish the problem of identifying the textual language vs. the language intended by the users for the search engine queries.", "labels": [], "entities": []}, {"text": "For search engines, there are cases where a correct identifi-cation of the language does not necessarily imply that the user wants to seethe results in the same language.", "labels": [], "entities": []}, {"text": "For example, although the textual identification of the language for the query \"homo sapiens\" is Latin, a user entering this query from Spain, would most probably want to see Spanish web pages, rather than web pages in Latin.", "labels": [], "entities": []}, {"text": "We address this issue by adding a non-linguistic feature to our system.", "labels": [], "entities": []}, {"text": "We organize the rest of the paper as follows: First, we provide an overview of the previous research in this area.", "labels": [], "entities": []}, {"text": "Second, we present our method to automatically generate a data set, and evaluate the effectiveness of this technique.", "labels": [], "entities": []}, {"text": "As a result of this evaluation, we obtain a human-annotated data set which we use to evaluate the systems implemented in the following sections.", "labels": [], "entities": []}, {"text": "In Section 4, we implement some of the existing models and compare their performance on our test set.", "labels": [], "entities": []}, {"text": "We then use the results from these models to build a decision tree system.", "labels": [], "entities": []}, {"text": "Next, we consider identifying the language intended by the user for the results of the query, and describe a system geared towards this task.", "labels": [], "entities": []}, {"text": "Finally, we conclude our study and discuss the future directions for the problem.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Annotation of 500 sample queries drawn  from the automatically generated data.", "labels": [], "entities": [{"text": "Annotation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8579012155532837}]}, {"text": " Table 2: Properties of the test set formed by taking  350 Category-1 queries from each language.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of the models built from the  individual features, and the Rank-Order method  on the test set.", "labels": [], "entities": [{"text": "Rank-Order", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9476444125175476}]}, {"text": " Table 5: Evaluation of the Decision Tree Classifier  with varying sizes of training data.", "labels": [], "entities": []}, {"text": " Table 6: Evaluation of the new feature and the two  decision tree classifiers on the new test set.", "labels": [], "entities": []}]}