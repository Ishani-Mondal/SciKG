{"title": [{"text": "Parsing Speech Repair without Specialized Grammar Symbols *", "labels": [], "entities": [{"text": "Parsing Speech Repair", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8698163231213888}]}], "abstractContent": [{"text": "This paper describes a parsing model for speech with repairs that makes a clear separation between linguistically meaningful symbols in the grammar and operations specific to speech repair in the operation of the parser.", "labels": [], "entities": []}, {"text": "This system builds a model of how unfinished constituents in speech repairs are likely to finish, and finishes them probabilistically with placeholder structure.", "labels": [], "entities": []}, {"text": "These modified repair constituents and the restarted replacement constituent are then recognized together in the same way that two coordinated phrases of the same type are recognized.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speech repair is a phenomenon in spontaneous spoken language in which a speaker decides to interrupt the flow of speech, replace some of the utterance (the \"reparandum\"), and continues on (with the \"alteration\") in away that makes the whole sentence as transcribed grammatical only if the reparandum is ignored.", "labels": [], "entities": [{"text": "Speech repair", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7453939020633698}]}, {"text": "As note, speech repairs 1 are the most disruptive type of disfluency, as they seem to require that a listener first incrementally buildup syntactic and semantic structure, then subsequently remove it and rebuild when the repair is made.", "labels": [], "entities": []}, {"text": "This difficulty combines with their frequent occurrence to make speech repair a pressing problem for machine recognition of spontaneous speech.", "labels": [], "entities": [{"text": "speech repair", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.8200075924396515}, {"text": "machine recognition of spontaneous speech", "start_pos": 101, "end_pos": 142, "type": "TASK", "confidence": 0.7922830820083618}]}, {"text": "This paper introduces a model for dealing with one part of this problem, constructing a syntactic analysis based on a transcript of spontaneous spoken language.", "labels": [], "entities": []}, {"text": "The model introduced here differs from other models attempting to solve the * This research was supported by NSF CAREER award 0447685.", "labels": [], "entities": [{"text": "NSF CAREER award 0447685", "start_pos": 109, "end_pos": 133, "type": "DATASET", "confidence": 0.6491868793964386}]}, {"text": "The views expressed are not necessarily endorsed by the sponsors . same problem, by completely separating the fluent grammar from the operations of the parser.", "labels": [], "entities": []}, {"text": "The grammar thus has no representation of disfluency or speech repair, such as the \"EDITED\" category used to represent a reparandum in the Switchboard corpus, as such categories are seemingly at odds with the typical nature of a linguistic constituent.", "labels": [], "entities": [{"text": "speech repair", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.6932350099086761}, {"text": "Switchboard corpus", "start_pos": 139, "end_pos": 157, "type": "DATASET", "confidence": 0.8062317073345184}]}, {"text": "Rather, the approach presented here uses a grammar that explicitly represents incomplete constituents being processed, and repair is represented by rules which allow incomplete constituents to be prematurely merged with existing structure.", "labels": [], "entities": []}, {"text": "While this model is interesting for its elegance in representation, there is also reason to hypothesize improved performance, since this processing model requires no additional grammar symbols, and only one additional operation to account for speech repair, and thus makes better use of limited data resources.", "labels": [], "entities": [{"text": "speech repair", "start_pos": 243, "end_pos": 256, "type": "TASK", "confidence": 0.7300112992525101}]}], "datasetContent": [{"text": "This model was evaluated on the Switchboard corpus () of conversational telephone speech between two human interlocuters.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.7530263662338257}]}, {"text": "The input to this system is the gold standard word transcriptions, segmented into individual utterances.", "labels": [], "entities": []}, {"text": "For comparison to other similar systems, the system was given the gold standard part of speech for each input word as well.", "labels": [], "entities": []}, {"text": "The standard train/test breakdown was used, with sections 2 and 3 used for training, and subsections 0 and 1 of section 4 used for testing.", "labels": [], "entities": []}, {"text": "Several sentences from the end of section 4 were used during development.", "labels": [], "entities": []}, {"text": "For training, the data set was first standardized by removing punctuation, empty categories, typos, all categories representing repair structure, and partial words -anything that would be difficult or impossible to obtain reliably with a speech recognizer.", "labels": [], "entities": []}, {"text": "The two metrics used here are the standard Parseval F-measure, and Edit-finding F.", "labels": [], "entities": []}, {"text": "The first takes the F-score of labeled precision and recall of the non-terminals in a hypothesized tree relative to the gold standard tree.", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9986218214035034}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9133584499359131}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9993320107460022}]}, {"text": "The second measure marks words in the gold standard as edited if they are dominated by anode labeled EDITED, and measures the F-score of the hypothesized edited words relative to the gold standard.", "labels": [], "entities": [{"text": "F-score", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.9983959794044495}]}, {"text": "Results of the testing can be seen in Table 1.", "labels": [], "entities": []}, {"text": "The first line (\"Baseline CYK\") indicates the results using a standard probabilistic CYK parser, trained on the standardized input trees.", "labels": [], "entities": []}, {"text": "The following two lines are results from reimplementations of the systems from and.", "labels": [], "entities": []}, {"text": "The line marked 'Elided trees' gives current results.", "labels": [], "entities": []}, {"text": "Surprisingly, this result proves to be lower than the previous results.", "labels": [], "entities": []}, {"text": "Two observations in the output of the parser on the development set gave hints as to the reasons for this performance loss.", "labels": [], "entities": []}], "tableCaptions": []}