{"title": [{"text": "Opinion and Generic Question Answering Systems: a Performance Analysis", "labels": [], "entities": [{"text": "Generic Question Answering", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.617251048485438}]}], "abstractContent": [{"text": "The importance of the new textual genres such as blogs or forum entries is growing in parallel with the evolution of the Social Web.", "labels": [], "entities": []}, {"text": "This paper presents two corpora of blog posts in Eng-lish and in Spanish, annotated according to the EmotiBlog annotation scheme.", "labels": [], "entities": [{"text": "EmotiBlog annotation scheme", "start_pos": 101, "end_pos": 128, "type": "DATASET", "confidence": 0.8709145983060201}]}, {"text": "Furthermore, we created 20 factual and opinionated questions for each language and also the Gold Standard for their answers in the corpus.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.8389173150062561}]}, {"text": "The purpose of our work is to study the challenges involved in a mixed fact and opinion question answering setting by comparing the performance of two Question Answering (QA) systems as far as mixed opinion and factual setting is concerned.", "labels": [], "entities": [{"text": "mixed fact and opinion question answering setting", "start_pos": 65, "end_pos": 114, "type": "TASK", "confidence": 0.7671574013573783}, {"text": "Question Answering (QA)", "start_pos": 151, "end_pos": 174, "type": "TASK", "confidence": 0.819431585073471}]}, {"text": "The first one is open domain , while the second one is opinion-oriented.", "labels": [], "entities": []}, {"text": "We evaluate separately the two systems in both languages and propose possible solutions to improve QA systems that have to process mixed questions.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In order to carryout our evaluation, we employed a corpus of blog posts presented in ( . It is a collection of blog entries in English, Spanish and Italian.", "labels": [], "entities": []}, {"text": "However, for this research we used the first two languages.", "labels": [], "entities": []}, {"text": "We annotated it using EmotiBlog (  and we also created a list of 20 questions for each language.", "labels": [], "entities": [{"text": "EmotiBlog", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.9397761225700378}]}, {"text": "Finally, we produced the Gold Standard, by labeling the corpus with the correct answers corresponding to the questions.", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9412764310836792}]}, {"text": "As it can be seen in the table above, we created factoid (F) and opinion (O) queries for English and for Spanish; however, there are some that could be defined between factoid and opinion (F/O) and the system can retrieve multiple answers after having selected, for example, the polarity of the sentences in the corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for English", "labels": [], "entities": [{"text": "English", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.735264241695404}]}, {"text": " Table 3: Results for Spanish", "labels": [], "entities": []}]}