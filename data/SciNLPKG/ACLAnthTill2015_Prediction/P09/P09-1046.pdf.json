{"title": [{"text": "Jointly Identifying Temporal Relations with Markov Logic", "labels": [], "entities": [{"text": "Identifying Temporal Relations", "start_pos": 8, "end_pos": 38, "type": "TASK", "confidence": 0.9166451096534729}]}], "abstractContent": [{"text": "Recent work on temporal relation identification has focused on three types of relations between events: temporal relations between an event and a time expression , between a pair of events and between an event and the document creation time.", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.7021142741044363}]}, {"text": "These types of relations have mostly been identified in isolation by event pairwise comparison.", "labels": [], "entities": []}, {"text": "However, this approach neglects logical constraints between temporal relations of different types that we believe to be helpful.", "labels": [], "entities": []}, {"text": "We therefore propose a Markov Logic model that jointly identifies relations of all three relation types simultaneously.", "labels": [], "entities": []}, {"text": "By evaluating our model on the TempEval data we show that this approach leads to about 2% higher accuracy for all three types of relations-and to the best results for the task when compared to those of other machine learning based systems.", "labels": [], "entities": [{"text": "TempEval data", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.8344355225563049}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9990696310997009}]}], "introductionContent": [{"text": "Temporal relation identification (or temporal ordering) involves the prediction of temporal order between events and/or time expressions mentioned in text, as well as the relation between events in a document and the time at which the document was created.", "labels": [], "entities": [{"text": "Temporal relation identification (or temporal ordering)", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8159901574254036}]}, {"text": "With the introduction of the TimeBank corpus (, a set of documents annotated with temporal information, it became possible to apply machine learning to temporal ordering ().", "labels": [], "entities": [{"text": "TimeBank corpus", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.9345537722110748}]}, {"text": "These tasks have been regarded as essential for complete document understanding and are useful fora wide range of NLP applications such as question answering and machine translation.", "labels": [], "entities": [{"text": "complete document understanding", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.6766064266363779}, {"text": "question answering", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.9384185373783112}, {"text": "machine translation", "start_pos": 162, "end_pos": 181, "type": "TASK", "confidence": 0.8234386742115021}]}, {"text": "Most of these approaches follow a simple schema: they learn classifiers that predict the temporal order of a given event pair based on a set of the pair's of features.", "labels": [], "entities": []}, {"text": "This approach is local in the sense that only a single temporal relation is considered at a time.", "labels": [], "entities": []}, {"text": "Learning to predict temporal relations in this isolated manner has at least two advantages over any approach that considers several temporal relations jointly.", "labels": [], "entities": []}, {"text": "First, it allows us to use off-the-shelf machine learning software that, up until now, has been mostly focused on the case of local classifiers.", "labels": [], "entities": []}, {"text": "Second, it is computationally very efficient both in terms of training and testing.", "labels": [], "entities": []}, {"text": "However, the local approach has a inherent drawback: it can lead to solutions that violate logical constraints we know to hold for any sets of temporal relations.", "labels": [], "entities": []}, {"text": "For example, by classifying temporal relations in isolation we may predict that event A happened before, and event B after, the time of document creation, but also that event A happened after event B-a clear contradiction in terms of temporal logic.", "labels": [], "entities": []}, {"text": "In order to repair the contradictions that the local classifier predicts, proposed a global framework based on Integer Linear Programming (ILP).", "labels": [], "entities": []}, {"text": "They showed that large improvements can be achieved by explicitly incorporating temporal constraints.", "labels": [], "entities": []}, {"text": "The approach we propose in this paper is similar in spirit to that of Chambers and Jurafsky: we seek to improve the accuracy of temporal relation identification by predicting relations in a more global manner.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9970188140869141}, {"text": "temporal relation identification", "start_pos": 128, "end_pos": 160, "type": "TASK", "confidence": 0.6062870224316915}]}, {"text": "However, while they focused only on the temporal relations between events mentioned in a document, we also jointly predict the temporal order between events and time expressions, and between events and the document creation time.", "labels": [], "entities": []}, {"text": "Our work also differs in another important aspect from the approach of Chambers and Jurafsky.", "labels": [], "entities": []}, {"text": "Instead of combining the output of a set of local classifiers using ILP, we approach the problem of joint temporal relation identification using Markov Logic ().", "labels": [], "entities": [{"text": "joint temporal relation identification", "start_pos": 100, "end_pos": 138, "type": "TASK", "confidence": 0.6140598431229591}]}, {"text": "In this framework global correlations can be readily captured through the addition of weighted first order logic formulae.", "labels": [], "entities": []}, {"text": "Using Markov Logic instead of an ILP-based approach has at least two advantages.", "labels": [], "entities": []}, {"text": "First, it allows us to easily capture non-deterministic (soft) rules that tend to hold between temporal relations but do not have to.", "labels": [], "entities": []}, {"text": "1 For example, if event A happens before B, and B overlaps with C, then there is a good chance that A also happens before C, but this is not guaranteed.", "labels": [], "entities": []}, {"text": "Second, the amount of engineering required to build our system is similar to the efforts required for using an off-the-shelf classifier: we only need to define features (in terms of formulae) and provide input data in the correct format.", "labels": [], "entities": []}, {"text": "In particular, we do not need to manually construct ILPs for each document we encounter.", "labels": [], "entities": []}, {"text": "Moreover, we can exploit and compare advanced methods of global inference and learning, as long as they are implemented in our Markov Logic interpreter of choice.", "labels": [], "entities": []}, {"text": "Hence, in our future work we can focus entirely on temporal relations, as opposed to inference or learning techniques for machine learning.", "labels": [], "entities": []}, {"text": "We evaluate our approach using the data of the \"TempEval\" challenge held at the.", "labels": [], "entities": [{"text": "TempEval\" challenge held at the.", "start_pos": 48, "end_pos": 80, "type": "DATASET", "confidence": 0.7114687306540353}]}, {"text": "This challenge involved three tasks corresponding to three types of temporal relations: between events and time expressions in a sentence (Task A), between events of a document and the document creation time, and between events in two consecutive sentences (Task C).", "labels": [], "entities": []}, {"text": "Our findings show that by incorporating global constraints that hold between temporal relations predicted in Tasks A, B and C, the accuracy for all three tasks can be improved significantly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9993630051612854}]}, {"text": "In comparison to other participants of the \"TempEval\" challenge our approach is very competitive: for two out of the three tasks we achieve the best results reported so far, by a margin of at least 2%.", "labels": [], "entities": [{"text": "TempEval\" challenge", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.5900763471921285}]}, {"text": "Only for Task B we were unable to reach the performance of a rule-based entry to the challenge.", "labels": [], "entities": []}, {"text": "However, we do perform better than all pure machine learning-based entries.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: Section 2 describes temporal relation identification including TempEval; Section 3 introduces Markov Logic; Section 4 explains our proposed Markov Logic Network; Section 5 presents the setup of our experiments; Section 6 shows and discusses the results of our experiments; and in Section 7 we conclude and present ideas for future research.", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.6844210624694824}]}], "datasetContent": [{"text": "With our experiments we want to answer two questions: (1) does jointly tackling Tasks A, B, and C help to increase overall accuracy of temporal relation identification?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9981412887573242}, {"text": "temporal relation identification", "start_pos": 135, "end_pos": 167, "type": "TASK", "confidence": 0.6255697111288706}]}, {"text": "(2) How does our approach compare to state-of-the-art results?", "labels": [], "entities": []}, {"text": "In the following we will present the experimental set-up we chose to answer these questions.", "labels": [], "entities": []}, {"text": "In our experiments we use the test and training sets provided by the TempEval shared task.", "labels": [], "entities": [{"text": "TempEval shared task", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.6498891115188599}]}, {"text": "We further split the original training data into a training and a development set, used for optimizing parameters and formulae.", "labels": [], "entities": []}, {"text": "For brevity we will refer to the training, development and test set as TRAIN, DEV and TEST, respectively.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.9977664947509766}, {"text": "DEV", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9814903736114502}, {"text": "TEST", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9943349361419678}]}, {"text": "The numbers of temporal relations in TRAIN, DEV, and TEST are summarized in.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.8419156670570374}, {"text": "DEV", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.6146607398986816}, {"text": "TEST", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.8605571389198303}]}, {"text": "For feature generation we use the following tools.", "labels": [], "entities": [{"text": "feature generation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7527128756046295}]}, {"text": "11 POS tagging is performed with TnT ver2.2; 12 for our dependency-based features we use MaltParser 1.0.0.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.7826014459133148}, {"text": "TnT ver2.2", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.8096936643123627}]}, {"text": "For inference in our models we use Cutting Plane Inference ( with ILP as abase solver.", "labels": [], "entities": []}, {"text": "This type of inference is exact and often very fast because it avoids instantiation of the complete Markov Network.", "labels": [], "entities": []}, {"text": "For learning we apply one-best MIRA with Cutting Plane Inference to find the current model guess.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9917470216751099}]}, {"text": "Both training and inference algorithms are provided by Markov thebeast, a Markov Logic interpreter tailored for NLP applications.", "labels": [], "entities": []}, {"text": "Note that there are several ways to manually optimize the set of formulae to use.", "labels": [], "entities": []}, {"text": "One way is to pick a task and then choose formulae that increase the accuracy for this task on DEV.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9992961883544922}, {"text": "DEV", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.9682832956314087}]}, {"text": "However, our primary goal is to improve the performance of all the tasks together.", "labels": [], "entities": []}, {"text": "Hence we choose formulae with respect to the total score overall three tasks.", "labels": [], "entities": []}, {"text": "We will refer to this type of optimization as \"averaged optimization\".", "labels": [], "entities": []}, {"text": "The total scores of the all three tasks are defined as follows: where Ca , Cb , and C care the number of the correctly identified labels in each task, and Ga , G b , and G care the numbers of gold labels of each task.", "labels": [], "entities": []}, {"text": "Our system necessarily outputs one label to one relational link to identify.", "labels": [], "entities": []}, {"text": "Therefore, for all our re-11 Since the TempEval trial has no restriction on preprocessing such as syntactic parsing, most participants used some sort of parsers.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7279576361179352}]}, {"text": "For evaluation, TempEval proposed the two scoring schemes: \"strict\" and \"relaxed\".", "labels": [], "entities": []}, {"text": "For strict scoring we give full credit if the relations match, and no credit if they do not match.", "labels": [], "entities": []}, {"text": "On the other hand, relaxed scoring gives credit fora relation according to.", "labels": [], "entities": []}, {"text": "For example, if a system picks the relation \"AFTER\" that should have been \"BEFORE\" according to the gold label, it gets neither \"strict\" nor \"relaxed\" credit.", "labels": [], "entities": [{"text": "AFTER", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.9771853089332581}, {"text": "BEFORE", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9919232726097107}]}, {"text": "But if the system assigns \"B-O (BEFORE-OR-OVERLAP)\" to the relation, it gets a 0.5 \"relaxed\" score (and still no \"strict\" score).", "labels": [], "entities": [{"text": "B-O", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9909266233444214}, {"text": "BEFORE-OR-OVERLAP", "start_pos": 32, "end_pos": 49, "type": "METRIC", "confidence": 0.8111495971679688}]}], "tableCaptions": [{"text": " Table 3: Numbers of Labeled Relations for All  Tasks", "labels": [], "entities": []}, {"text": " Table 4: Evaluation Weights for Relaxed Scoring", "labels": [], "entities": [{"text": "Evaluation Weights", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9413261413574219}, {"text": "Scoring", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.6888075470924377}]}, {"text": " Table 5: Results on TEST Set", "labels": [], "entities": []}, {"text": " Table 6: Results with 10-fold Cross Validation", "labels": [], "entities": []}, {"text": " Table 7: Comparison with Other Systems", "labels": [], "entities": []}]}