{"title": [{"text": "Dependency Grammar Induction via Bitext Projection Constraints", "labels": [], "entities": []}], "abstractContent": [{"text": "Broad-coverage annotated treebanks necessary to train parsers do not exist for many resource-poor languages.", "labels": [], "entities": []}, {"text": "The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7098968178033829}]}, {"text": "We consider generative and discriminative models for dependency grammar induction that use word-level alignments and a source language parser (English) to constrain the space of possible target trees.", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.8564444581667582}]}, {"text": "Unlike previous approaches, our framework does not require full projected parses, allowing partial, approximate transfer through linear expectation constraints on the space of distributions over trees.", "labels": [], "entities": []}, {"text": "We consider several types of constraints that range from generic dependency conservation to language-specific annotation rules for auxiliary verb analysis.", "labels": [], "entities": [{"text": "generic dependency conservation", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.7538106242815653}, {"text": "auxiliary verb analysis", "start_pos": 131, "end_pos": 154, "type": "TASK", "confidence": 0.6432627240816752}]}, {"text": "We evaluate our approach on Bulgarian and Spanish CoNLL shared task data and show that we consistently outperform unsupervised methods and can outperform supervised learning for limited training data.", "labels": [], "entities": [{"text": "Bulgarian and Spanish CoNLL shared task data", "start_pos": 28, "end_pos": 72, "type": "DATASET", "confidence": 0.7223275899887085}]}], "introductionContent": [{"text": "For English and a handful of other languages, there are large, well-annotated corpora with a variety of linguistic information ranging from named entity to discourse structure.", "labels": [], "entities": []}, {"text": "Unfortunately, for the vast majority of languages very few linguistic resources are available.", "labels": [], "entities": []}, {"text": "This situation is likely to persist because of the expense of creating annotated corpora that require linguistic expertise.", "labels": [], "entities": []}, {"text": "On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text.", "labels": [], "entities": []}, {"text": "For example, several early works) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models. and explore transfer of deeper syntactic structure: dependency grammars.", "labels": [], "entities": [{"text": "part-of-speech taggers and noun-phrase chunkers", "start_pos": 91, "end_pos": 138, "type": "TASK", "confidence": 0.6530016660690308}]}, {"text": "Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English.", "labels": [], "entities": []}, {"text": "Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches) as well as unsupervised induction ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8687707483768463}, {"text": "constituency parsing", "start_pos": 111, "end_pos": 131, "type": "TASK", "confidence": 0.8760761320590973}]}, {"text": "Dependency representation has been used for language modeling, textual entailment and machine translation (;, to name a few tasks.", "labels": [], "entities": [{"text": "Dependency representation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8607510626316071}, {"text": "language modeling", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7715799510478973}, {"text": "textual entailment", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7534429728984833}, {"text": "machine translation", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.816267192363739}]}, {"text": "Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure).", "labels": [], "entities": [{"text": "transfer", "start_pos": 48, "end_pos": 56, "type": "TASK", "confidence": 0.9632282257080078}]}, {"text": "Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2) errors in word alignments and source language parses, (3) grammatical annotation choices that differ across languages and linguistic theories (e.g., how to analyze auxiliary verbs, conjunctions).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.709996685385704}, {"text": "word alignments", "start_pos": 181, "end_pos": 196, "type": "TASK", "confidence": 0.7047285288572311}]}, {"text": "In this paper, we present a flexible learning framework for transferring dependency grammars via bitext using the posterior regularization framework ().", "labels": [], "entities": []}, {"text": "In particular, we address challenges (1) and (2) by avoiding commitment to an entire projected parse tree in the target language during training.", "labels": [], "entities": []}, {"text": "Instead, we explore formulations of both generative and discriminative probabilistic models where projected syntactic relations are constrained to hold approximately and only in expectation.", "labels": [], "entities": []}, {"text": "Finally, we address challenge (3) by introducing a very small number of language-specific constraints that disambiguate arbitrary annotation choices.", "labels": [], "entities": []}, {"text": "We evaluate our approach by transferring from an English parser trained on the Penn treebank to Bulgarian and Spanish.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9819388389587402}]}, {"text": "We evaluate our results on the Bulgarian and Spanish corpora from the CoNLL X shared task.", "labels": [], "entities": [{"text": "CoNLL X shared task", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.8319475799798965}]}, {"text": "We see that our transfer approach consistently outperforms unsupervised methods and, given just a few (2 to 7) languagespecific constraints, performs comparably to a supervised parser trained on a very limited corpus (30 -140 training sentences).", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on two languages: Bulgarian and Spanish, using each of the parsing models.", "labels": [], "entities": []}, {"text": "The Bulgarian experiments transfer a parser from English to Bulgarian, using the OpenSubtitles corpus.", "labels": [], "entities": [{"text": "OpenSubtitles corpus", "start_pos": 81, "end_pos": 101, "type": "DATASET", "confidence": 0.9110264778137207}]}, {"text": "The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus ().", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.9453887045383453}]}, {"text": "For both corpora, we performed word alignments with the open source PostCAT () toolkit.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7378312051296234}]}, {"text": "We used the Tokyo tagger () to POS tag the English tokens, and generated parses using the first-order model of with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 169, "end_pos": 182, "type": "DATASET", "confidence": 0.9904058575630188}]}, {"text": "In order to evaluate our method, we a baseline inspired by.", "labels": [], "entities": []}, {"text": "The baseline constructs a full parse tree from the incomplete and possibly conflicting transferred edges using a simple random process.", "labels": [], "entities": []}, {"text": "We start with no edges and try to add edges one at a time verifying at each step that it is possible to complete the tree.", "labels": [], "entities": []}, {"text": "We first try to add the transferred edges in random order, then for each orphan node we try all possible parents (both in random order).", "labels": [], "entities": []}, {"text": "We then use this full labeling as supervision fora parser.", "labels": [], "entities": []}, {"text": "Note that this baseline is very similar to the first iteration of our model, since fora large corpus the different random choices made in different sentences tend to smooth each other out.", "labels": [], "entities": []}, {"text": "We also tried to create rules for the adoption of orphans, but the simple rules we tried added bias and performed worse than the baseline we report.", "labels": [], "entities": [{"text": "adoption of orphans", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.863913893699646}]}, {"text": "shows attachment accuracy of our method and the baseline for both language pairs under several conditions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9218868613243103}]}, {"text": "By attachment accuracy we mean the fraction of words assigned the correct parent.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9044610857963562}]}, {"text": "The experimental details are described in this section.", "labels": [], "entities": []}, {"text": "Link-left baselines for these corpora are much lower: 33.8% and 27.9% for Bulgarian and Spanish respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer", "labels": [], "entities": []}, {"text": " Table 3: Top 4 discriminative parser errors by child POS tag and true/guess parent POS tag in the Bulgarian CoNLL train data", "labels": [], "entities": [{"text": "Bulgarian CoNLL train data", "start_pos": 99, "end_pos": 125, "type": "DATASET", "confidence": 0.8794365972280502}]}]}