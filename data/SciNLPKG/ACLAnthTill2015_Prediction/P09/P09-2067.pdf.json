{"title": [{"text": "Automatic Story Segmentation using a Bayesian Decision Framework for Statistical Models of Lexical Chain Features", "labels": [], "entities": [{"text": "Automatic Story Segmentation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6214115917682648}]}], "abstractContent": [{"text": "This paper presents a Bayesian decision framework that performs automatic story segmentation based on statistical model-ing of one or more lexical chain features.", "labels": [], "entities": [{"text": "automatic story segmentation", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.6619237661361694}]}, {"text": "Automatic story segmentation aims to locate the instances in time where a story ends and another begins.", "labels": [], "entities": [{"text": "Automatic story segmentation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6128270427385966}]}, {"text": "A lexical chain is formed by linking coherent lexical items chronologically.", "labels": [], "entities": []}, {"text": "A story boundary is often associated with a significant number of lexical chains ending before it, starting after it, as well as a low count of chains continuing through it.", "labels": [], "entities": []}, {"text": "We devise a Bayesian framework to capture such behavior , using the lexical chain features of start, continuation and end.", "labels": [], "entities": []}, {"text": "In the scoring criteria, lexical chain starts/ends are modeled statistically with the Weibull and uniform distributions at story boundaries and non-boundaries respectively.", "labels": [], "entities": []}, {"text": "The normal distribution is used for lexical chain continuations.", "labels": [], "entities": [{"text": "lexical chain continuations", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6800839602947235}]}, {"text": "Full combination of all lexical chain features gave the best performance (F1=0.6356).", "labels": [], "entities": [{"text": "F1", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9995301961898804}]}, {"text": "We found that modeling chain continuations contributes significantly towards segmentation performance .", "labels": [], "entities": [{"text": "modeling chain continuations", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.643761565287908}, {"text": "segmentation", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.9735342860221863}]}], "introductionContent": [{"text": "Automatic story segmentation is an important precursor in processing audio or video streams in large information repositories.", "labels": [], "entities": [{"text": "Automatic story segmentation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7145918011665344}]}, {"text": "Very often, these continuous streams of data do not come with boundaries that segment them into semantically coherent units, or stories.", "labels": [], "entities": []}, {"text": "The story unit is needed fora wide range of spoken language information retrieval tasks, such as topic tracking, clustering, indexing and retrieval.", "labels": [], "entities": [{"text": "spoken language information retrieval tasks", "start_pos": 44, "end_pos": 87, "type": "TASK", "confidence": 0.7135982036590576}, {"text": "topic tracking", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.853114902973175}]}, {"text": "To perform automatic story segmentation, there are three categories of cues available: lexical cues from transcriptions, prosodic cues from the audio stream and video cues such as anchor face and color histograms.", "labels": [], "entities": [{"text": "automatic story segmentation", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.5951088964939117}]}, {"text": "Among the three types of cues, lexical cues are the most generic since they can work on text and multimedia sources.", "labels": [], "entities": []}, {"text": "Previous approaches include TextTiling) that monitors changes in sentence similarity, use of cue phrases) and Hidden Markov Models).", "labels": [], "entities": []}, {"text": "In addition, the approach based on lexical chaining captures the content coherence by linking coherent lexical items.", "labels": [], "entities": []}, {"text": "discovers boundaries by chaining up terms and locating instances of time where the count of chain starts and ends (boundary strength) achieves local maxima.", "labels": [], "entities": []}, {"text": "enhanced this approach through statistical modeling of lexical chain starts and ends.", "labels": [], "entities": []}, {"text": "We further extend this approach in two aspects: 1) a Bayesian decision framework is used; 2) chain continuations straddling across boundaries are taken into consideration and statistically modeled.", "labels": [], "entities": [{"text": "chain continuations straddling across boundaries", "start_pos": 93, "end_pos": 141, "type": "TASK", "confidence": 0.8033233880996704}]}], "datasetContent": [{"text": "Experiments are conducted using data from the TDT-2 Voice of America Mandarin broadcast.", "labels": [], "entities": [{"text": "TDT-2 Voice of America Mandarin broadcast", "start_pos": 46, "end_pos": 87, "type": "DATASET", "confidence": 0.9729714492956797}]}, {"text": "In particular, we only use the data from the long programs (40 programs, 1458 stories in total), each of which is about one hour in duration.", "labels": [], "entities": []}, {"text": "The average number of words per story is 297.", "labels": [], "entities": []}, {"text": "The news programs are further divided chronologically into training (for parameter estimation of the statistical models), development (for tuning decision thresholds) and test (for performance evaluation) sets, as shown in.", "labels": [], "entities": []}, {"text": "Automatic speech recognition (ASR) outputs that are provided in the TDT-2 corpus are used for lexical chain formation.", "labels": [], "entities": [{"text": "Automatic speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7606758028268814}, {"text": "TDT-2 corpus", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.9295490086078644}, {"text": "lexical chain formation", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.6261617739995321}]}, {"text": "The story segmentation task in this work is to decide whether a hypothesized utterance boundary (provided in the TDT-2 data based on the speech recognition result) is a story boundary.", "labels": [], "entities": [{"text": "story segmentation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7255050241947174}, {"text": "TDT-2 data", "start_pos": 113, "end_pos": 123, "type": "DATASET", "confidence": 0.9468521177768707}]}, {"text": "Segmentation performance is evaluated using the F1-measure.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9953141212463379}]}], "tableCaptions": []}