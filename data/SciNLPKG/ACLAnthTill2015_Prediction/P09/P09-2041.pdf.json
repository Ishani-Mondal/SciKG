{"title": [{"text": "Automatic Satire Detection: Are You Having a Laugh?", "labels": [], "entities": [{"text": "Automatic Satire Detection: Are You Having a Laugh?", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7664540439844132}]}], "abstractContent": [{"text": "We introduce the novel task of determining whether a newswire article is \"true\" or satirical.", "labels": [], "entities": []}, {"text": "We experiment with SVMs, feature scaling, and a number of lexical and semantic feature types, and achieve promising results over the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes a method for filtering satirical news articles from true newswire documents.", "labels": [], "entities": [{"text": "filtering satirical news articles from true newswire documents", "start_pos": 34, "end_pos": 96, "type": "TASK", "confidence": 0.8588686138391495}]}, {"text": "We define a satirical article as one which deliberately exposes real-world individuals, organisations and events to ridicule.", "labels": [], "entities": []}, {"text": "Satirical news articles tend to mimic true newswire articles, incorporating irony and non sequitur in an attempt to provide humorous insight.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results for satire detection (P = preci- sion, R = recall, and F = F-score) for binary un- igram features (BIN) and BNS unigram features  (BNS), optionally using lexical (lex), validity (val)  or combined lexical and validity (all) features", "labels": [], "entities": [{"text": "satire detection", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.729569211602211}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9725064039230347}, {"text": "F-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9467350244522095}, {"text": "validity (val)", "start_pos": 187, "end_pos": 201, "type": "METRIC", "confidence": 0.9183442145586014}]}]}