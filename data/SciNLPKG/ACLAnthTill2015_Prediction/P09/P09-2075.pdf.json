{"title": [{"text": "Multi-Document Summarization using Sentence-based Topic Models", "labels": [], "entities": [{"text": "Multi-Document Summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6290647685527802}]}], "abstractContent": [{"text": "Most of the existing multi-document summarization methods decompose the documents into sentences and work directly in the sentence space using a term-sentence matrix.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.5538961589336395}]}, {"text": "However, the knowledge on the document side, i.e. the topics embedded in the documents, can help the context understanding and guide the sentence selection in the summariza-tion procedure.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.6725859045982361}]}, {"text": "In this paper, we propose anew Bayesian sentence-based topic model for summarization by making use of both the term-document and term-sentence associations.", "labels": [], "entities": [{"text": "summarization", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.9804799556732178}]}, {"text": "An efficient variational Bayesian algorithm is derived for model parameter estimation.", "labels": [], "entities": [{"text": "model parameter estimation", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.6961734096209208}]}, {"text": "Experimental results on benchmark data sets show the effectiveness of the proposed model for the multi-document summarization task.", "labels": [], "entities": [{"text": "multi-document summarization task", "start_pos": 97, "end_pos": 130, "type": "TASK", "confidence": 0.7170316775639852}]}], "introductionContent": [{"text": "With the continuing growth of online text resources, document summarization has found wide-ranging applications in information retrieval and web search.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7210835516452789}, {"text": "information retrieval", "start_pos": 115, "end_pos": 136, "type": "TASK", "confidence": 0.7793952524662018}]}, {"text": "Many multi-document summarization methods have been developed to extract the most important sentences from the documents.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 5, "end_pos": 33, "type": "TASK", "confidence": 0.5930444598197937}]}, {"text": "These methods usually represent the documents as term-sentence matrices (where each row represents a sentence and each column represents a term) or graphs (where each node is a sentence and each edge represents the pairwise relationship among corresponding sentences), and ranks the sentences according to their scores calculated by a set of predefined features, such as term frequencyinverse sentence frequency (TF-ISF) (), sentence or term position (, and number of keywords (.", "labels": [], "entities": [{"text": "term frequencyinverse sentence frequency (TF-ISF)", "start_pos": 371, "end_pos": 420, "type": "METRIC", "confidence": 0.7913440295628139}]}, {"text": "Typical existing summarization methods include centroid-based methods (e.g., MEAD ( )), graph-ranking based methods (e.g.,), non-negative matrix factorization (NMF) based methods (e.g.,), Conditional random field (CRF) based summarization (, and LSA based methods).", "labels": [], "entities": [{"text": "summarization", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.9762507081031799}, {"text": "MEAD", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.8492095470428467}]}, {"text": "There are two limitations with most of the existing multi-document summarization methods: (1) They work directly in the sentence space and many methods treat the sentences as independent of each other.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.5532917678356171}]}, {"text": "Although few work tries to analyze the context or sequence information of the sentences, the document side knowledge, i.e. the topics embedded in the documents are ignored.", "labels": [], "entities": []}, {"text": "(2) Another limitation is that the sentence scores calculated from existing methods usually do not have very clear and rigorous probabilistic interpretations.", "labels": [], "entities": []}, {"text": "Many if not all of the sentence scores are computed using various heuristics as few research efforts have been reported on using generative models for document summarization.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 151, "end_pos": 173, "type": "TASK", "confidence": 0.5368151366710663}]}, {"text": "In this paper, to address the above issues, we propose anew Bayesian sentence-based topic model for multi-document summarization by making use of both the term-document and termsentence associations.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.5987943708896637}]}, {"text": "Our proposal explicitly models the probability distributions of selecting sentences given topics and provides a principled way for the summarization task.", "labels": [], "entities": [{"text": "summarization", "start_pos": 135, "end_pos": 148, "type": "TASK", "confidence": 0.9901968240737915}]}, {"text": "An efficient variational Bayesian algorithm is derived for estimating model parameters.", "labels": [], "entities": []}, {"text": "2 Bayesian Sentence-based Topic Models (BSTM)", "labels": [], "entities": []}], "datasetContent": [{"text": "We use ROUGE toolkit (version 1.5.5) to measure the summarization performance, which is widely applied by DUC for performance evaluation.", "labels": [], "entities": [{"text": "DUC", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.9045127630233765}]}, {"text": "It measures the quality of a summary by counting the unit overlaps between the candidate summary and a set of reference summaries.", "labels": [], "entities": []}, {"text": "The full explanation of the evaluation toolkit can be found in (.", "labels": [], "entities": []}, {"text": "In general, the higher the ROUGE scores, the better summarization performance.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9957137107849121}]}, {"text": "show the comparison results between BSTM and other implemented systems.", "labels": [], "entities": [{"text": "BSTM", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.8425568342208862}]}], "tableCaptions": [{"text": " Table 1: Description of the data sets for multi-document", "labels": [], "entities": []}, {"text": " Table 2: Overall performance comparison on DUC2002", "labels": [], "entities": [{"text": "DUC2002", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9079259037971497}]}, {"text": " Table 3: Overall performance comparison on DUC2004 data using", "labels": [], "entities": [{"text": "DUC2004 data", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9660964608192444}]}]}