{"title": [{"text": "An Error-Driven Word-Character Hybrid Model for Joint Chinese Word Segmentation and POS Tagging", "labels": [], "entities": [{"text": "Joint Chinese Word Segmentation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.5636623799800873}, {"text": "POS Tagging", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.7388478219509125}]}], "abstractContent": [{"text": "In this paper, we present a discriminative word-character hybrid model for joint Chi-nese word segmentation and POS tagging.", "labels": [], "entities": [{"text": "joint Chi-nese word segmentation", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.5882025435566902}, {"text": "POS tagging", "start_pos": 112, "end_pos": 123, "type": "TASK", "confidence": 0.8804626166820526}]}, {"text": "Our word-character hybrid model offers high performance since it can handle both known and unknown words.", "labels": [], "entities": []}, {"text": "We describe our strategies that yield good balance for learning the characteristics of known and unknown words and propose an error-driven policy that delivers such balance by acquiring examples of unknown words from particular errors in a training corpus.", "labels": [], "entities": []}, {"text": "We describe an efficient framework for training our model based on the Margin Infused Relaxed Algorithm (MIRA), evaluate our approach on the Penn Chinese Treebank, and show that it achieves superior performance compared to the state-of-the-art approaches reported in the literature .", "labels": [], "entities": [{"text": "Margin Infused Relaxed Algorithm (MIRA)", "start_pos": 71, "end_pos": 110, "type": "METRIC", "confidence": 0.6624649507658822}, {"text": "Penn Chinese Treebank", "start_pos": 141, "end_pos": 162, "type": "DATASET", "confidence": 0.9876480102539062}]}], "introductionContent": [{"text": "In Chinese, word segmentation and part-of-speech (POS) tagging are indispensable steps for higherlevel NLP tasks.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7450393438339233}, {"text": "part-of-speech (POS) tagging", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.7063315629959106}]}, {"text": "Word segmentation and POS tagging results are required as inputs to other NLP tasks, such as phrase chunking, dependency parsing, and machine translation.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6869028657674789}, {"text": "POS tagging", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.7947887480258942}, {"text": "phrase chunking", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.7924602925777435}, {"text": "dependency parsing", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.8339990079402924}, {"text": "machine translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7976357340812683}]}, {"text": "Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion ().", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.69121353328228}, {"text": "POS tagging", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.8492612242698669}]}, {"text": "In joint word segmentation and the POS tagging process, one serious problem is caused by unknown words, which are defined as words that are not found in a training corpus or in a system's word dictionary . The word boundaries and the POS tags of unknown words, which are very difficult to identify, cause numerous errors.", "labels": [], "entities": [{"text": "joint word segmentation", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.6549723347028097}, {"text": "POS tagging", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.8573141396045685}]}, {"text": "The word-character hybrid model proposed by Nakagawa and Uchimoto shows promising properties for solving this problem.", "labels": [], "entities": []}, {"text": "However, it suffers from structural complexity.", "labels": [], "entities": []}, {"text": "Nakagawa (2004) described a training method based on a word-based Markov model and a character-based maximum entropy model that can be completed in a reasonable time.", "labels": [], "entities": []}, {"text": "However, this training method is limited by the generatively-trained Markov model in which informative features are hard to exploit.", "labels": [], "entities": []}, {"text": "In this paper, we overcome such limitations concerning both efficiency and effectiveness.", "labels": [], "entities": []}, {"text": "We propose anew framework for training the wordcharacter hybrid model based on the Margin Infused Relaxed Algorithm (MIRA)).", "labels": [], "entities": [{"text": "Margin Infused Relaxed Algorithm (MIRA))", "start_pos": 83, "end_pos": 123, "type": "METRIC", "confidence": 0.585823552949088}]}, {"text": "We describe k-best decoding for our hybrid model and design its loss function and the features appropriate for our task.", "labels": [], "entities": []}, {"text": "In our word-character hybrid model, allowing the model to learn the characteristics of both known and unknown words is crucial to achieve optimal performance.", "labels": [], "entities": []}, {"text": "Here, we describe our strategies that yield good balance for learning these two characteristics.", "labels": [], "entities": []}, {"text": "We propose an errordriven policy that delivers this balance by acquiring examples of unknown words from particular errors in a training corpus.", "labels": [], "entities": []}, {"text": "We conducted our experiments on Penn Chinese Treebank () and compared our approach with the best previous approaches reported in the literature.", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 32, "end_pos": 53, "type": "DATASET", "confidence": 0.9632845719655355}]}, {"text": "Experimental results indicate that our approach can achieve state-of-the-art performance.", "labels": [], "entities": []}, {"text": "Beginning character in a multi-character word I Intermediate character in a multi-character word E End character in a multi-character word S Single-character word: Position-of-character (POC) tags.", "labels": [], "entities": []}, {"text": "The paper proceeds as follows: Section 2 gives background on the word-character hybrid model, Section 3 describes our policies for correct path selection, Section 4 presents our training method based on MIRA, Section 5 shows our experimental results, Section 6 discusses related work, and Section 7 concludes the paper.", "labels": [], "entities": [{"text": "correct path selection", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.6124957104523977}, {"text": "MIRA", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.614440381526947}]}], "datasetContent": [{"text": "We evaluated both word segmentation (Seg) and joint word segmentation and POS tagging.", "labels": [], "entities": [{"text": "word segmentation (Seg)", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.755615359544754}, {"text": "word segmentation", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7085579633712769}, {"text": "POS tagging", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.7403681874275208}]}, {"text": "We used recall (R), precision (P ), and F 1 as evaluation metrics.", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9557156711816788}, {"text": "precision (P )", "start_pos": 20, "end_pos": 34, "type": "METRIC", "confidence": 0.9633791595697403}, {"text": "F 1", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9939372837543488}]}, {"text": "Following, we also measured the recall on OOV (R OOV ) tokens and in-vocabulary (R IV ) tokens.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9995325803756714}, {"text": "OOV (R OOV", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.7565088421106339}]}, {"text": "These performance measures can be calculated as follows: Recall (R) = # of correct tokens # of tokens in test data P recision (P ) = # of correct tokens # of tokens in system output # of correct IV tokens # of IV tokens in test data For Seg, a token is considered to be a correct one if the word boundary is correctly identified.", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9315077811479568}, {"text": "Seg", "start_pos": 237, "end_pos": 240, "type": "TASK", "confidence": 0.9512712955474854}]}, {"text": "For Seg & Tag, both the word boundary and its POS tag have to be correctly identified to be counted as a correct token.", "labels": [], "entities": [{"text": "Seg & Tag", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.8491258223851522}]}], "tableCaptions": [{"text": " Table 5: Training, development, and test data  statistics on CTB 5.0 used in our experiments.", "labels": [], "entities": [{"text": "CTB 5.0", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9236289858818054}]}, {"text": " Table 6: Results of our word-character hybrid model using error-driven and baseline policies.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of F 1 results with previous  studies on CTB 5.0.", "labels": [], "entities": [{"text": "F 1", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.983166366815567}, {"text": "CTB 5.0", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9472009539604187}]}, {"text": " Table 8: Comparison of F 1 results of our baseline  model with Nakagawa and Uchimoto (2007) and  Zhang and Clark (2008) on CTB 3.0.", "labels": [], "entities": [{"text": "F 1", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9327126145362854}, {"text": "CTB 3.0", "start_pos": 124, "end_pos": 131, "type": "DATASET", "confidence": 0.952468752861023}]}, {"text": " Table 9: Comparison of averaged F 1 results (by  10-fold cross validation) with previous studies on  CTB 3.0.", "labels": [], "entities": [{"text": "F 1", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9704220294952393}, {"text": "CTB 3.0", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.8899084031581879}]}]}