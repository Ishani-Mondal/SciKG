{"title": [{"text": "Who, What, When, Where, Why? Comparing Multiple Approaches to the Cross-Lingual 5W Task", "labels": [], "entities": []}], "abstractContent": [{"text": "Cross-lingual tasks are especially difficult due to the compounding effect of errors in language processing and errors in machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.8564844489097595}]}, {"text": "In this paper, we present an error analysis of anew cross-lingual task: the 5W task, a sentence-level understanding task which seeks to return the English 5W's (Who, What, When, Where and Why) corresponding to a Chinese sentence.", "labels": [], "entities": []}, {"text": "We analyze systems that we developed, identifying specific problems in language processing and MT that cause errors.", "labels": [], "entities": [{"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.9881195425987244}]}, {"text": "The best cross-lingual 5W system was still 19% worse than the best mono-lingual 5W system, which shows that MT significantly degrades sentence-level understanding.", "labels": [], "entities": [{"text": "MT", "start_pos": 108, "end_pos": 110, "type": "TASK", "confidence": 0.9858936071395874}]}, {"text": "Neither source-language nor target-language analysis was able to circumvent problems in MT, although each approach had advantages relative to the other.", "labels": [], "entities": [{"text": "MT", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.9929488897323608}]}, {"text": "A detailed error analysis across multiple systems suggests directions for future research on the problem.", "labels": [], "entities": []}], "introductionContent": [{"text": "In our increasingly global world, it is evermore likely fora mono-lingual speaker to require information that is only available in a foreign language document.", "labels": [], "entities": []}, {"text": "Cross-lingual applications address this need by presenting information in the speaker's language even when it originally appeared in some other language, using machine translation (MT) in the process.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.8130258202552796}]}, {"text": "In this paper, we present an evaluation and error analysis of a cross-lingual application that we developed fora government-sponsored evaluation, the 5W task.", "labels": [], "entities": [{"text": "error", "start_pos": 44, "end_pos": 49, "type": "METRIC", "confidence": 0.9529099464416504}]}, {"text": "The 5W task seeks to summarize the information in a natural language sentence by distilling it into the answers to the 5W questions: Who, What, When, Where and Why.", "labels": [], "entities": [{"text": "summarize the information in a natural language sentence", "start_pos": 21, "end_pos": 77, "type": "TASK", "confidence": 0.8096743747591972}]}, {"text": "To solve this problem, a number of different problems in NLP must be addressed: predicate identification, argument extraction, attachment disambiguation, location and time expression recognition, and (partial) semantic role labeling.", "labels": [], "entities": [{"text": "predicate identification", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.8557738661766052}, {"text": "argument extraction", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7598044574260712}, {"text": "attachment disambiguation", "start_pos": 127, "end_pos": 152, "type": "TASK", "confidence": 0.7050600349903107}, {"text": "location and time expression recognition", "start_pos": 154, "end_pos": 194, "type": "TASK", "confidence": 0.5897078931331634}, {"text": "semantic role labeling", "start_pos": 210, "end_pos": 232, "type": "TASK", "confidence": 0.656518409649531}]}, {"text": "In this paper, we address the cross-lingual 5W task: given a source-language sentence, return the 5W's translated (comprehensibly) into the target language.", "labels": [], "entities": []}, {"text": "Success in this task requires a synergy of successful MT and answer selection.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9887005686759949}, {"text": "answer selection", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.8576618134975433}]}, {"text": "The questions we address in this paper are: \u2022 How much does machine translation (MT) degrade the performance of cross-lingual 5W systems, as compared to monolingual performance?", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.7930864632129669}]}, {"text": "\u2022 Is it better to do source-language analysis and then translate, or do target-language analysis on MT?", "labels": [], "entities": []}, {"text": "\u2022 Which specific problems in language processing and/or MT cause errors in 5W answers?", "labels": [], "entities": [{"text": "MT", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.967406690120697}]}, {"text": "In this evaluation, we compare several different approaches to the cross-lingual 5W task, two that work on the target language (English) and one that works in the source language (Chinese).", "labels": [], "entities": []}, {"text": "A central question for many cross-lingual applications is whether to process in the source language and then translate the result, or translate documents first and then process the translation.", "labels": [], "entities": []}, {"text": "Depending on how errorful the translation is, results maybe more accurate if models are developed for the source language.", "labels": [], "entities": []}, {"text": "However, if there are more resources in the target language, then the translate-then-process approach maybe more appropriate.", "labels": [], "entities": []}, {"text": "We present a detailed analysis, both quantitative and qualitative, of how the approaches differ in performance.", "labels": [], "entities": []}, {"text": "We also compare system performance on human translation (which we term reference translations) and MT of the same data in order to determine how much MT degrades system performance.", "labels": [], "entities": []}, {"text": "Finally, we do an in-depth analysis of the errors in our 5W approaches, both on the NLP side and the MT side.", "labels": [], "entities": [{"text": "NLP", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9035935997962952}, {"text": "MT side", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.7008363306522369}]}, {"text": "Our results provide explanations for why different approaches succeed, along with indications of where future effort should be spent.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3. Percentages of Who/What errors attributed to  each system error type.", "labels": [], "entities": []}, {"text": " Table 4. Percentages of Who/What errors by each  system attributed to each translation error type.", "labels": [], "entities": []}]}