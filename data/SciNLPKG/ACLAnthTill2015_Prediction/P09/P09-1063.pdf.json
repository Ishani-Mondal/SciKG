{"title": [{"text": "Improving Tree-to-Tree Translation with Packed Forests", "labels": [], "entities": [{"text": "Improving Tree-to-Tree Translation", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.9175021052360535}]}], "abstractContent": [{"text": "Current tree-to-tree models suffer from parsing errors as they usually use only 1-best parses for rule extraction and decoding.", "labels": [], "entities": [{"text": "parsing", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.972266674041748}, {"text": "rule extraction", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.7249576449394226}]}, {"text": "We instead propose a forest-based tree-to-tree model that uses packed forests.", "labels": [], "entities": []}, {"text": "The model is based on a probabilis-tic synchronous tree substitution grammar (STSG), which can be learned from aligned forest pairs automatically.", "labels": [], "entities": [{"text": "probabilis-tic synchronous tree substitution grammar (STSG)", "start_pos": 24, "end_pos": 83, "type": "TASK", "confidence": 0.703370776027441}]}, {"text": "The de-coder finds ways of decomposing trees in the source forest into elementary trees using the source projection of STSG while building target forest in parallel.", "labels": [], "entities": []}, {"text": "Comparable to the state-of-the-art phrase-based system Moses, using packed forests in tree-to-tree translation results in a significant absolute improvement of 3.6 BLEU points over using 1-best trees.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.9993127584457397}]}], "introductionContent": [{"text": "Approaches to syntax-based statistical machine translation make use of parallel data with syntactic annotations, either in the form of phrase structure trees or dependency trees.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6161761581897736}]}, {"text": "They can be roughly divided into three categories: string-to-tree models (e.g., (), tree-to-string models (e.g., ()), and tree-totree models (e.g.,).", "labels": [], "entities": []}, {"text": "By modeling the syntax of both source and target languages, tree-to-tree approaches have the potential benefit of providing rules linguistically better motivated.", "labels": [], "entities": []}, {"text": "However, while string-to-tree and tree-to-string models demonstrate promising results in empirical evaluations, tree-to-tree models have still been underachieving.", "labels": [], "entities": []}, {"text": "We believe that tree-to-tree models face two major challenges.", "labels": [], "entities": []}, {"text": "First, tree-to-tree models are more vulnerable to parsing errors.", "labels": [], "entities": [{"text": "parsing", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.9736068248748779}]}, {"text": "Obtaining syntactic annotations in quantity usually entails running automatic parsers on a parallel corpus.", "labels": [], "entities": []}, {"text": "As the amount and domain of the data used to train parsers are relatively limited, parsers will inevitably output ill-formed trees when handling real-world text.", "labels": [], "entities": []}, {"text": "Guided by such noisy syntactic information, syntax-based models that rely on 1-best parses are prone to learn noisy translation rules in training phase and produce degenerate translations in decoding phase).", "labels": [], "entities": []}, {"text": "This situation aggravates for treeto-tree models that use syntax on both sides.", "labels": [], "entities": []}, {"text": "Second, tree-to-tree rules provide poorer rule coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9282506108283997}]}, {"text": "As a tree-to-tree rule requires that there must be trees on both sides, tree-to-tree models lose a larger amount of linguistically unmotivated mappings.", "labels": [], "entities": []}, {"text": "Studies reveal that the absence of such non-syntactic mappings will impair translation quality dramatically ( ;.", "labels": [], "entities": []}, {"text": "Compactly encoding exponentially many parses, packed forests prove to bean excellent fit for alleviating the above two problems ( . In this paper, we propose a forest-based tree-to-tree model.", "labels": [], "entities": []}, {"text": "To learn STSG rules from aligned forest pairs, we introduce a series of notions for identifying minimal tree-to-tree rules.", "labels": [], "entities": []}, {"text": "Our decoder first converts the source forest to a translation forest and then finds the best derivation that has the source yield of one source tree in the forest.", "labels": [], "entities": []}, {"text": "Comparable to Moses, our forest-based tree-to-tree model achieves an absolute improvement of 3.6 BLEU points over conventional tree-based model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9993355870246887}]}, {"text": "Figure 1: An aligned packed forest pair.", "labels": [], "entities": []}, {"text": "Each node is assigned a unique identity for reference.", "labels": [], "entities": []}, {"text": "The solid lines denote hyperedges and the dashed lines denote word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.687666729092598}]}, {"text": "Shaded nodes are frontier nodes.", "labels": [], "entities": []}, {"text": "shows an aligned forest pair fora Chinese sentence and an English sentence.", "labels": [], "entities": []}, {"text": "The solid lines denote hyperedges and the dashed lines denote word alignments between the two forests.", "labels": [], "entities": []}, {"text": "Each node is assigned a unique identity for reference.", "labels": [], "entities": []}, {"text": "Each hyperedge is associated with a probability, which we omit in for clarity.", "labels": [], "entities": []}, {"text": "Ina forest, anode usually has multiple incoming hyperedges.", "labels": [], "entities": []}, {"text": "We use IN (v) to denote the set of incoming hyperedges of node v.", "labels": [], "entities": [{"text": "IN", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.9946280121803284}]}, {"text": "For example, the source node \"IP 1 \" has following two incoming hyperedges: 1", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Node attributes of the example forest pair.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of BLEU scores for tree- based and forest-based tree-to-tree models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.997819185256958}]}, {"text": " Table 4: Comparison of rule extraction time (sec- onds/1000 sentence pairs) and decoding time (sec- ond/sentence)", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.6855918914079666}]}]}