{"title": [], "abstractContent": [{"text": "The automatic extraction of relations between entities expressed in natural language text is an important problem for IR and text understanding.", "labels": [], "entities": [{"text": "automatic extraction of relations between entities expressed in natural language text", "start_pos": 4, "end_pos": 89, "type": "TASK", "confidence": 0.8604139089584351}, {"text": "IR", "start_pos": 118, "end_pos": 120, "type": "TASK", "confidence": 0.9937210083007812}, {"text": "text understanding", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.7335068583488464}]}, {"text": "In this paper we show how different kernels for parse trees can be combined to improve the relation extraction quality.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.8114172518253326}]}, {"text": "On a public benchmark dataset the combination of a kernel for phrase grammar parse trees and for dependency parse trees outperforms all known tree kernel approaches alone suggesting that both types of trees contain complementary information for relation extraction .", "labels": [], "entities": [{"text": "phrase grammar parse trees", "start_pos": 62, "end_pos": 88, "type": "TASK", "confidence": 0.7686337381601334}, {"text": "relation extraction", "start_pos": 245, "end_pos": 264, "type": "TASK", "confidence": 0.8168193697929382}]}], "introductionContent": [{"text": "The same semantic relation between entities in natural text can be expressed in many ways, e.g. \"Obama was educated at Harvard\", \"Obama is a graduate of Harvard Law School\", or, \"Obama went to Harvard College\".", "labels": [], "entities": []}, {"text": "Relation extraction aims at identifying such semantic relations in an automatic fashion.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9555488228797913}]}, {"text": "As a preprocessing step named entity taggers detect persons, locations, schools, etc.", "labels": [], "entities": []}, {"text": "These techniques have reached a sufficient performance level on many datasets ().", "labels": [], "entities": []}, {"text": "In the next step relations between recognized entities, e.g. person-educatedin-school(Obama,Harvard) are identified.", "labels": [], "entities": []}, {"text": "Parse trees provide extensive information on syntactic structure.", "labels": [], "entities": [{"text": "syntactic structure", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.8165213763713837}]}, {"text": "While feature-based methods may compare only a limited number of structural details, kernel-based methods may explore an often exponential number of characteristics of trees without explicitly representing the features. and proposed kernels for dependency trees (DTs) inspired by string kernels.", "labels": [], "entities": []}, {"text": "suggested a kernel for phrase grammar parse trees.", "labels": [], "entities": [{"text": "phrase grammar parse trees", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.8409838825464249}]}, {"text": "investigated a kernel that computes similarities between nodes on the shortest path of a DT connecting the entities.", "labels": [], "entities": []}, {"text": "presented DT kernels comparing substructures in a more sophisticated way.", "labels": [], "entities": []}, {"text": "Up to now no studies exist on how kernels for different types of parse trees may support each other.", "labels": [], "entities": []}, {"text": "To tackle this we present a study on how those kernels for relation extractions can be combined.", "labels": [], "entities": [{"text": "relation extractions", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7450151741504669}]}, {"text": "We implement four state-of-the-art kernels.", "labels": [], "entities": []}, {"text": "Subsequently we combine pairs of kernels linearly or by polynomial expansion.", "labels": [], "entities": []}, {"text": "On a public benchmark dataset we show that the combined phrase grammar parse tree kernel and dependency parse tree kernel outperforms all others by 5.7% F-Measure reaching an F-Measure of 71.2%.", "labels": [], "entities": [{"text": "phrase grammar parse tree", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.6894419938325882}, {"text": "F-Measure", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9933099746704102}, {"text": "F-Measure", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9897913932800293}]}, {"text": "This result shows that both types of parse trees contain relevant information for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.8276298642158508}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section we describe the investigated tree kernels.", "labels": [], "entities": []}, {"text": "Subsequently we present the method to combine two kernels.", "labels": [], "entities": []}, {"text": "The fourth section details the experiments on a public benchmark dataset.", "labels": [], "entities": [{"text": "public benchmark dataset", "start_pos": 48, "end_pos": 72, "type": "DATASET", "confidence": 0.701305478811264}]}, {"text": "We close with a summary and conclusions.", "labels": [], "entities": [{"text": "summary", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.9265170097351074}]}], "datasetContent": [{"text": "In this section we present the results of the experiments with kernel-based methods for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.8941684067249298}]}, {"text": "Throughout this section we will compare the approaches considering their classification quality on the publicly available benchmark dataset ACE-2003 ().", "labels": [], "entities": [{"text": "benchmark dataset ACE-2003", "start_pos": 122, "end_pos": 148, "type": "DATASET", "confidence": 0.8041902383168539}]}, {"text": "It consists of news documents containing 176825 words splitted in a test and training set.", "labels": [], "entities": []}, {"text": "Entities and the relations between them were manually annotated.", "labels": [], "entities": []}, {"text": "The entities are marked by the types named (e.g. \"Albert Einstein\") , nominal (e.g. \"University\") and pronominal (e.g. \"he\").", "labels": [], "entities": []}, {"text": "There are 5 top level relation types role, part, near, social and at, which are further differentiated into 24 subtypes.", "labels": [], "entities": []}, {"text": "We implemented the tree-kernels for relation extraction in Java and used Joachim's (1999) SVM light with the JNI Kernel Extension using the implementation details from the original papers.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8936223983764648}, {"text": "Joachim's (1999) SVM light", "start_pos": 73, "end_pos": 99, "type": "DATASET", "confidence": 0.6768281204359872}]}, {"text": "For the generation of the parse trees we used the Stanford Parser (.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.9579335451126099}]}, {"text": "We restricted our experiments to relations between named entities, where NER approaches maybe used to extract the arguments.", "labels": [], "entities": []}, {"text": "Without any modification the kernels could also be applied to the all types setting as well.", "labels": [], "entities": []}, {"text": "We conducted classification tests on the five top level relations of the dataset.", "labels": [], "entities": []}, {"text": "For each relation we trained a separate SVM following the one vs. all scheme for multi-class classification.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 81, "end_pos": 107, "type": "TASK", "confidence": 0.7617950737476349}]}, {"text": "We also employed a standard gridsearch on the training set with a 5-times repeated 5-fold cross validation to optimize the parameters of all kernels as well as the SVM-parameter C for the classification runs on the separate test set.", "labels": [], "entities": []}, {"text": "We use the standard evaluation measures for classification accuracy: precision, recall and F-measure.  by at least 5.7% F-Measure on the prespecified test-set and by 3.6% F-Measure on the cross validation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9472358822822571}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9997307658195496}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9994530081748962}, {"text": "F-measure.", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9986024498939514}, {"text": "F-Measure", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9955359697341919}, {"text": "F-Measure", "start_pos": 171, "end_pos": 180, "type": "METRIC", "confidence": 0.9958248138427734}]}, {"text": "shows the F-values of the different combinational kernels on the test set as well as on the cross validation on the training set.", "labels": [], "entities": [{"text": "F-values", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9923715591430664}]}, {"text": "The ZhangPT + Path-DTK performs the best out of all possible combinations.", "labels": [], "entities": []}, {"text": "The difference in F-values between ZhangPT + Path-DTK and ZhangPT is according to corrected resampled t-test) significant at a level of 99.9%.", "labels": [], "entities": [{"text": "F-values", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9986567497253418}, {"text": "ZhangPT", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.8344506621360779}]}, {"text": "These results show that the simultanous consideration of phrase grammar parse trees and dependency parse trees by the combination of the two kernels is meaningful for relation extraction.", "labels": [], "entities": [{"text": "phrase grammar parse trees", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.7572424113750458}, {"text": "relation extraction", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.9172869920730591}]}], "tableCaptions": [{"text": " Table 1: F-values for 3 selected relations and micro-averaged precision, recall and F-score (with standard  error) for all 5 relations on the training (CV) and test set in percent.", "labels": [], "entities": [{"text": "F-values", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9934513568878174}, {"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.8905779719352722}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9997051358222961}, {"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9982407093048096}]}]}