{"title": [], "abstractContent": [{"text": "Paraphrase generation (PG) is important in plenty of NLP applications.", "labels": [], "entities": [{"text": "Paraphrase generation (PG)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8658485293388367}]}, {"text": "However, the research of PG is far from enough.", "labels": [], "entities": [{"text": "PG", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9650796055793762}]}, {"text": "In this paper, we propose a novel method for statistical paraphrase generation (SPG), which can (1) achieve various applications based on a uniform statistical model, and (2) naturally combine multiple resources to enhance the PG performance.", "labels": [], "entities": [{"text": "statistical paraphrase generation (SPG)", "start_pos": 45, "end_pos": 84, "type": "TASK", "confidence": 0.8812731405099233}]}, {"text": "In our experiments, we use the proposed method to generate paraphrases for three different applications.", "labels": [], "entities": []}, {"text": "The results show that the method can be easily transformed from one application to another and generate valuable and interesting paraphrases.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrases are alternative ways that convey the same meaning.", "labels": [], "entities": []}, {"text": "There are two main threads in the research of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG).", "labels": [], "entities": [{"text": "paraphrase recognition", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.8621252477169037}, {"text": "paraphrase generation (PG)", "start_pos": 93, "end_pos": 119, "type": "TASK", "confidence": 0.8054466724395752}]}, {"text": "Paraphrase generation aims to generate a paraphrase fora source sentence in a certain application.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.935375839471817}]}, {"text": "PG shows its importance in many areas, such as question expansion in question answering (QA)), text polishing in natural language generation (NLG) (), text simplification in computer-aided reading (), and sentence similarity computation in the automatic evaluation of machine translation (MT)) and summarization ().", "labels": [], "entities": [{"text": "question expansion in question answering (QA))", "start_pos": 47, "end_pos": 93, "type": "TASK", "confidence": 0.8416749909520149}, {"text": "text polishing in natural language generation (NLG)", "start_pos": 95, "end_pos": 146, "type": "TASK", "confidence": 0.7617438501781888}, {"text": "text simplification", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.7525872886180878}, {"text": "sentence similarity computation", "start_pos": 205, "end_pos": 236, "type": "TASK", "confidence": 0.7462810675303141}, {"text": "evaluation of machine translation (MT))", "start_pos": 254, "end_pos": 293, "type": "TASK", "confidence": 0.719513829265322}, {"text": "summarization", "start_pos": 298, "end_pos": 311, "type": "TASK", "confidence": 0.9834480285644531}]}, {"text": "This paper presents a method for statistical paraphrase generation (SPG).", "labels": [], "entities": [{"text": "statistical paraphrase generation (SPG)", "start_pos": 33, "end_pos": 72, "type": "TASK", "confidence": 0.8738862574100494}]}, {"text": "As far as we know, this is the first statistical model specially designed for paraphrase generation.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.9633729457855225}]}, {"text": "It's distinguishing feature is that it achieves various applications with a uniform model.", "labels": [], "entities": []}, {"text": "In addition, it exploits multiple resources, including paraphrase phrases, patterns, and collocations, to resolve the data shortage problem and generate more varied paraphrases.", "labels": [], "entities": []}, {"text": "We consider three paraphrase applications in our experiments, including sentence compression, sentence simplification, and sentence similarity computation.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.7869638502597809}, {"text": "sentence simplification", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.7927491068840027}, {"text": "sentence similarity computation", "start_pos": 123, "end_pos": 154, "type": "TASK", "confidence": 0.8003942171732584}]}, {"text": "The proposed method generates paraphrases for the input sentences in each application.", "labels": [], "entities": []}, {"text": "The generated paraphrases are then manually scored based on adequacy, fluency, and usability.", "labels": [], "entities": []}, {"text": "The results show that the proposed method is promising, which generates useful paraphrases for the given applications.", "labels": [], "entities": []}, {"text": "In addition, comparison experiments show that our method outperforms a conventional SMT-based PG method.", "labels": [], "entities": [{"text": "SMT-based PG", "start_pos": 84, "end_pos": 96, "type": "TASK", "confidence": 0.8299268484115601}]}], "datasetContent": [{"text": "Our SPG decoder is developed by remodeling Moses that is widely used in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9913273453712463}]}, {"text": "The POS tagger and dependency parser for sentence preprocessing are SVM-Tool () and MSTParser ().", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.7375338971614838}, {"text": "MSTParser", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.871411144733429}]}, {"text": "The language model is trained using a 9 GB English corpus.", "labels": [], "entities": []}, {"text": "Our method is not restricted in domain or sentence style.", "labels": [], "entities": []}, {"text": "Thus any sentence can be used in development and test.", "labels": [], "entities": []}, {"text": "However, for the sentence similarity computation purpose in our experiments, we want to evaluate if the method can enhance the stringlevel similarity between two paraphrase sentences.", "labels": [], "entities": [{"text": "sentence similarity computation", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7441386282444}]}, {"text": "Therefore, for each input sentence s, we need a reference sentence s for similarity computation.", "labels": [], "entities": []}, {"text": "Based on the above consideration, we acquire experiment data from the human references of the MT evaluation, which provide several human translations for each foreign sentence.", "labels": [], "entities": [{"text": "MT", "start_pos": 94, "end_pos": 96, "type": "TASK", "confidence": 0.8789054751396179}]}, {"text": "In detail, we use the first translation of a foreign sentence as the source sand the second translation as the reference s for similarity computation.", "labels": [], "entities": []}, {"text": "In our experiments, the development set contains 200 sentences and the test set contains 500 sentences, both of which are randomly selected from the human translations of 2008 NIST Open Machine Translation Evaluation: Chinese to English Task.", "labels": [], "entities": [{"text": "NIST Open Machine Translation Evaluation: Chinese to English Task", "start_pos": 176, "end_pos": 241, "type": "TASK", "confidence": 0.7118012726306915}]}, {"text": "The evaluation metrics for SPG are similar to the human evaluation for MT.", "labels": [], "entities": [{"text": "SPG", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9819667339324951}, {"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9646594524383545}]}, {"text": "The generated paraphrases are manually evaluated based on three criteria, i.e., adequacy, fluency, and usability, each of which has three scales from 1 to 3.", "labels": [], "entities": []}, {"text": "Here is a brief description of the different scales for the criteria: Adequacy 1: The meaning is evidently changed.", "labels": [], "entities": [{"text": "Adequacy 1", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9568817317485809}]}, {"text": "2: The meaning is generally preserved.", "labels": [], "entities": []}, {"text": "3: The meaning is completely preserved.", "labels": [], "entities": []}, {"text": "We ask two raters to label the paraphrases based on the criteria defined in Section 4.2.", "labels": [], "entities": []}, {"text": "The labeling results are shown in the upper part of.", "labels": [], "entities": []}, {"text": "We can see that for adequacy and fluency, the paraphrases in sentence similarity computation get the highest scores.", "labels": [], "entities": []}, {"text": "About 70% of the paraphrases are labeled \"3\".", "labels": [], "entities": []}, {"text": "This is because in sentence similarity computation, only the target units appearing in the reference sentences are kept in paraphrase planning.", "labels": [], "entities": [{"text": "sentence similarity computation", "start_pos": 19, "end_pos": 50, "type": "TASK", "confidence": 0.7546149591604868}]}, {"text": "This constraint filters most of the noise.", "labels": [], "entities": []}, {"text": "The adequacy and fluency scores of the other two applications are not high.", "labels": [], "entities": []}, {"text": "The percentages of label \"3\" are around 30%.", "labels": [], "entities": []}, {"text": "The main reason is that the average numbers of unit replacements for these two applications are much larger than sentence similarity computation.", "labels": [], "entities": [{"text": "sentence similarity computation", "start_pos": 113, "end_pos": 144, "type": "TASK", "confidence": 0.7769281069437662}]}, {"text": "It is thus more likely to bring in incorrect unit replacements, which influence the quality of the generated paraphrases.", "labels": [], "entities": []}, {"text": "The usability is needed to be manually labeled only for sentence simplification, since it can be automatically labeled in the other two applications.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7526833117008209}]}, {"text": "As shown in, for sentence simplification, most paraphrases are labeled \"2\" in usability, while merely less than 20% are labeled \"3\".", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.7236825525760651}]}, {"text": "We conjecture that it is because the raters are not sensitive to the slight change of the simplification degree.", "labels": [], "entities": [{"text": "raters", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9458813071250916}]}, {"text": "Thus they labeled \"2\" inmost cases.", "labels": [], "entities": []}, {"text": "We compute the kappa statistic between the raters.", "labels": [], "entities": []}, {"text": "Kappa is defined as K = P (A)\u2212P (E) 1\u2212P (E), where P (A) is the proportion of times that the labels agree, and P (E) is the proportion of times that they may agree by chance.", "labels": [], "entities": []}, {"text": "We define P (E) = 1 3 , as the labeling is based on three point scales.", "labels": [], "entities": []}, {"text": "The results show that the kappa statistics for adequacy and fluency are 0.6560 and 0.6500, which indicates a substantial agreement (K: 0.61-0.8) according to.", "labels": [], "entities": [{"text": "K", "start_pos": 132, "end_pos": 133, "type": "METRIC", "confidence": 0.9806450009346008}]}, {"text": "The: The evaluation results of the proposed method and two baseline methods.", "labels": [], "entities": []}, {"text": "kappa statistic for usability is 0.5849, which is only moderate (K: 0.41-0.6).", "labels": [], "entities": [{"text": "K", "start_pos": 65, "end_pos": 66, "type": "METRIC", "confidence": 0.9684696197509766}]}, {"text": "shows an example of the generated paraphrases.", "labels": [], "entities": []}, {"text": "A source sentence sis paraphrased in each application and we can see that: (1) for sentence compression, the paraphrase t is 8 bytes shorter than s; (2) for sentence simplification, the words wealth and part int are easier than their sources asset and proportion, especially for the non-native speakers; (3) for sentence similarity computation, the reference sentence sis listed below t, in which the words appearing int but not in s are highlighted in blue.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7279006242752075}, {"text": "sentence simplification", "start_pos": 157, "end_pos": 180, "type": "TASK", "confidence": 0.7160704433917999}, {"text": "sentence similarity computation", "start_pos": 312, "end_pos": 343, "type": "TASK", "confidence": 0.7716179490089417}]}], "tableCaptions": [{"text": " Table 1: The evaluation results of the proposed method and two baseline methods.", "labels": [], "entities": []}]}