{"title": [{"text": "Bridging Morpho-Syntactic Gap between Source and Target Sentences for English-Korean Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.6539231240749359}]}], "abstractContent": [{"text": "Often, Statistical Machine Translation (SMT) between English and Korean suffers from null alignment.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.8475747505823771}]}, {"text": "Previous studies have attempted to resolve this problem by removing unnecessary function words, or by reordering source sentences.", "labels": [], "entities": []}, {"text": "However, the removal of function words can cause a serious loss in information.", "labels": [], "entities": []}, {"text": "In this paper , we present a possible method of bridging the morpho-syntactic gap for English-Korean SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.7264236807823181}]}, {"text": "In particular, the proposed method tries to transform a source sentence by inserting pseudo words, and by reordering the sentence in such away that both sentences have a similar length and word order.", "labels": [], "entities": []}, {"text": "The proposed method achieves 2.4 increase in BLEU score over baseline phrase-based system.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9754869043827057}]}], "introductionContent": [{"text": "Phrase-based SMT models have performed reasonably well on languages where the syntactic structures are very similar, including languages such as French and English.", "labels": [], "entities": [{"text": "Phrase-based SMT", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6184958219528198}]}, {"text": "However, demonstrated that phrase-based models have limited potential when applied to languages that have a relatively different word order; such is the case between German and English.", "labels": [], "entities": []}, {"text": "They proposed a clause restructuring method for reordering German sentences in order to resemble the order of English sentences.", "labels": [], "entities": [{"text": "clause restructuring", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8089118003845215}]}, {"text": "By modifying the source sentence structure into the target sentence structure, they argued that they could solve the decoding problem by use of completely monotonic translation.", "labels": [], "entities": []}, {"text": "The translation from English to Korean can be more difficult than the translation of other language pairs for the following reasons: First, Korean is language isolate: that is, it has little genealogical relations with other natural languages.", "labels": [], "entities": []}, {"text": "Second, the word order in Korean is relatively free because the functional morphemes, case particles and word endings, play the role as a grammatical information marker.", "labels": [], "entities": []}, {"text": "Thus, the functional morphemes, rather than the word order, determine whether a word is a subject or an object.", "labels": [], "entities": []}, {"text": "Third, Korean is an agglutinative language, in which a word is generally composed of at least one content morpheme and zero or more functional morphemes.", "labels": [], "entities": []}, {"text": "Some Korean words are highly synthetic with complex inflections, and this phenomenon produces a very large vocabulary and causes datasparseness in performing word-based alignment.", "labels": [], "entities": [{"text": "word-based alignment", "start_pos": 158, "end_pos": 178, "type": "TASK", "confidence": 0.6426215320825577}]}, {"text": "To mitigate this problem, many systems tokenize Korean sentences by the morpheme unit before training and decoding the sentences.", "labels": [], "entities": []}, {"text": "When analyzing English-Korean translation with MOSES (, we found high ratio of null alignment.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.6905449628829956}]}, {"text": "In, '\u0093 \u00c9 r(eun)', '_ (eui)', ' (ha)', '(n)', 't (ji)' and '\u008d H (neunda)' are not linked to any word in the English sentence.", "labels": [], "entities": []}, {"text": "In many cases, these words are function words that are attached to preceding content words.", "labels": [], "entities": []}, {"text": "Sometimes they can be linked (incorrectly) to their head's corresponding words, or they can be linked to totally different words with respect to their meaning.", "labels": [], "entities": []}, {"text": "In the preliminary experiment using GIZA++) with grow-diag-final heuristic, we found that about 25% of words in Korean sentences and 21% of English sentences fail to align.", "labels": [], "entities": []}, {"text": "This null alignment ratio is relatively high in comparison to the French-English alignment, in which about 9% of French sentences and 6% of English sentences are not aligned.", "labels": [], "entities": []}, {"text": "Due to this null alignment, the estimation of translation probabilities for Korean function words maybe incomplete; a system would perform mainly based Figure 2: An example of ideal alignment on content-words, which can deteriorate the performance of candidate generation during decoding.", "labels": [], "entities": []}, {"text": "Also, without generating appropriate function words, the quality of the translation will undoubtedly degrade.", "labels": [], "entities": []}, {"text": "In this paper, we present a preprocessing method for both training and decoding in EnglishKorean SMT.", "labels": [], "entities": [{"text": "EnglishKorean SMT", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.6556659191846848}]}, {"text": "In particular, we transform a source language sentence by inserting pseudo words and syntactically reordering it to form a target sentence structure in hopes of reducing the morphosyntactic discrepancies between two languages.", "labels": [], "entities": []}, {"text": "Ultimately, we expect an ideal alignment, as shown in.", "labels": [], "entities": []}, {"text": "Our results show that the combined pseudo word insertion and syntactic reordering method reduces null alignment ratio and makes both sentences have similar length.", "labels": [], "entities": [{"text": "pseudo word insertion", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.6707030932108561}]}, {"text": "We report results showing that the proposed method can improve the translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.9721988439559937}]}, {"text": "find that function words in Korean sentences are not aligned to any English words, and can simply and easily be removed by referring to their POS information.", "labels": [], "entities": []}, {"text": "The unaligned words are case particles, final endings, and auxiliary particles, and they call these words \"untranslatable words\".", "labels": [], "entities": []}], "datasetContent": [{"text": "The baseline of our approach is a statistical phrase-based system which is trained using MOSES (.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.5489171147346497}]}, {"text": "We collect bilingual texts from the Web and combine them with the Sejong parallel corpora 2 . About 300K pair of sentences are collected from the major bilingual news broadcasting sites.", "labels": [], "entities": [{"text": "Sejong parallel corpora 2", "start_pos": 66, "end_pos": 91, "type": "DATASET", "confidence": 0.8785942047834396}]}, {"text": "We also collect around 1M monolingual sentences from the sites to train Korean language models.", "labels": [], "entities": []}, {"text": "The best performing language model is 5-gram order with Kneser-Ney smoothing.", "labels": [], "entities": []}, {"text": "For sentence level alignment, we modified the Champollion toolkit for English-Korean pair).", "labels": [], "entities": [{"text": "sentence level alignment", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6937805612881979}]}, {"text": "We randomly selected 5,000 sentence pairs from Sejong corpora, of which 1,500 were used fora tuning set for minimum error rate training, and another 1,500 for development set for analysis experiment.", "labels": [], "entities": []}, {"text": "We report testing results on the remaining 2,000 sentence pairs for the evaluation.", "labels": [], "entities": []}, {"text": "Korean sentences are tokenized by the morphological analyzer ().", "labels": [], "entities": []}, {"text": "For English sentence preprocessing, we use the Stanford parser with output of typed dependency relations.", "labels": [], "entities": [{"text": "English sentence preprocessing", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.5964832603931427}]}, {"text": "We then applied the pseudo word insertion and four reordering rules described in the previous section to the parse tree of each sentence.: Null alignment ratio (%) for each method (all-null is calculated on the whole training data)  The BLEU scores are reported in.", "labels": [], "entities": [{"text": "pseudo word insertion", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.6443907717863718}, {"text": "Null alignment ratio", "start_pos": 139, "end_pos": 159, "type": "METRIC", "confidence": 0.8627345760663351}, {"text": "BLEU", "start_pos": 237, "end_pos": 241, "type": "METRIC", "confidence": 0.9991056323051453}]}, {"text": "Length ratio indicates the average sentence length ratio between source sentences and target sentences.", "labels": [], "entities": [{"text": "Length ratio", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.9824742376804352}]}, {"text": "The largest gain (+2.39) is achieved when the combined pseudo word insertion (PWI) and word reordering is performed.", "labels": [], "entities": [{"text": "pseudo word insertion (PWI)", "start_pos": 55, "end_pos": 82, "type": "METRIC", "confidence": 0.6026248832543691}]}, {"text": "There could be reasons why the proposed approach is effective over baseline approach.", "labels": [], "entities": []}, {"text": "Presumably, transforming to similar length and word order contributes to lower the distortion and fertility parameter values.", "labels": [], "entities": [{"text": "distortion", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.981676459312439}, {"text": "fertility", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9484686851501465}]}, {"text": "analyzes the effect of individual techniques in terms of the null alignment ratio.", "labels": [], "entities": []}, {"text": "We discover that the alignment ratio can be a good way to measure the relation between the quality of word alignment and the quality of translation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 102, "end_pos": 116, "type": "TASK", "confidence": 0.6986020803451538}]}, {"text": "As shown in, the BLEU score tends to increase as the all-null ratio decreases.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.9831913411617279}]}, {"text": "Interestingly, reordering achieves the smallest null alignment ratio for source language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU score and sentence length ratio for  each method", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9801557064056396}, {"text": "sentence length ratio", "start_pos": 25, "end_pos": 46, "type": "METRIC", "confidence": 0.5554712116718292}]}, {"text": " Table 2: Null alignment ratio (%) for each method  (all-null is calculated on the whole training data)", "labels": [], "entities": [{"text": "Null alignment ratio", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.7285158435503641}]}]}