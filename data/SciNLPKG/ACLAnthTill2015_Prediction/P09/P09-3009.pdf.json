{"title": [], "abstractContent": [{"text": "Parallel corpora are made by human beings.", "labels": [], "entities": []}, {"text": "However, as an MT system is an aggregation of state-of-the-art NLP technologies without any intervention of human beings, it is unavoidable that quite a few sentence pairs are beyond its analysis and that will therefore not contribute to the system.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9725125432014465}]}, {"text": "Furthermore, they in turn may act against our objectives to make the overall performance worse.", "labels": [], "entities": []}, {"text": "Possible unfavorable items are n : m mapping objects, such as paraphrases, non-literal translations , and multiword expressions.", "labels": [], "entities": []}, {"text": "This paper presents a pre-processing method which detects such unfavorable items before supplying them to the word aligner under the assumption that their frequency is low, such as below 5 percent.", "labels": [], "entities": []}, {"text": "We show an improvement of Bleu score from 28.0 to 31.4 in English-Spanish and from 16.9 to 22.1 in German-English.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9632230997085571}]}], "introductionContent": [{"text": "Phrase alignment (Marcu and Wong, 02) has recently attracted researchers in its theory, although it remains in infancy in its practice.", "labels": [], "entities": [{"text": "Phrase alignment", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9681857526302338}]}, {"text": "However, a phrase extraction heuristic such as grow-diag-final (, which is a single difference between word-based SMT () and phrase-based SMT () where we construct word-based SMT by bidirectional word alignment, is nowadays considered to be a key process which leads to an overall improvement of MT systems.", "labels": [], "entities": [{"text": "phrase extraction heuristic", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.8223671714464823}, {"text": "phrase-based SMT", "start_pos": 125, "end_pos": 141, "type": "TASK", "confidence": 0.44247736036777496}, {"text": "MT", "start_pos": 296, "end_pos": 298, "type": "TASK", "confidence": 0.9937303066253662}]}, {"text": "However, technically, this phrase extraction process afterword alignment is known to have at least two limitations: 1) the objectives of uni-directional word alignment is limited only in 1 : n mappings and 2) anatomic unit of phrase pair used by phrase extraction is thus basically restricted in 1 : nor n : 1 with small exceptions.", "labels": [], "entities": [{"text": "phrase extraction process afterword alignment", "start_pos": 27, "end_pos": 72, "type": "TASK", "confidence": 0.8692571520805359}, {"text": "word alignment", "start_pos": 153, "end_pos": 167, "type": "TASK", "confidence": 0.7296003848314285}, {"text": "phrase extraction", "start_pos": 246, "end_pos": 263, "type": "TASK", "confidence": 0.8080269694328308}]}, {"text": "Firstly, the posterior-based approach (Liang, 06) looks at the posterior probability and partially delays the alignment decision.", "labels": [], "entities": []}, {"text": "However, this approach does not have any extension in its 1 : n uni-directional mappings in its word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.6981525421142578}]}, {"text": "Secondly, the aforementioned phrase alignment (Marcu and Wong, 02) considers then : m mapping directly bilingually generated by some concepts without word alignment.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.6976662278175354}]}, {"text": "However, this approach has severe computational complexity problems.", "labels": [], "entities": []}, {"text": "Thirdly, linguistic motivated phrases, such as a tree aligner (Tinsley et al., 06), provides n : m mappings using some information of parsing results.", "labels": [], "entities": []}, {"text": "However, as the approach runs somewhat in a reverse direction to ours, we omit it from the discussion.", "labels": [], "entities": []}, {"text": "Hence, this paper will seek for the methods that are different from those approaches and whose computational cost is cheap.", "labels": [], "entities": []}, {"text": "n : m mappings in our discussion include paraphrases (Callison-Burch, 07; Lin and Pantel, 01), non-literal translations (Imamura et al., 03), multiword expressions (Lambert and Banchs, 05), and some other noise in one side of a translation pair (from now on, we call these 'outliers', meaning that these are not systematic noise).", "labels": [], "entities": []}, {"text": "One common characteristic of these n : m mappings is that they tend to be so flexible that even an exhaustive list by human beings tends to be incomplete (Lin and Pantel, 01).", "labels": [], "entities": []}, {"text": "There are two cases which we should like to distinguish: when we use external resources and when we do not.", "labels": [], "entities": []}, {"text": "For example, Quirk et al. employ external resources by drawing pairs of English sentences from a comparable corpus (Quirk et al., 04), while Bannard and Callison-Burch (Bannard and Callison-Burch, 05) identified English paraphrases by pivoting through phrases in another language.", "labels": [], "entities": []}, {"text": "However, in this paper our interest is rather the case when our resources are limited within our parallel corpus., on the other hand, do not use external resources and present a method based on literalness measure called TCR (Translation Correspondence Rate).", "labels": [], "entities": [{"text": "TCR (Translation Correspondence Rate)", "start_pos": 221, "end_pos": 258, "type": "METRIC", "confidence": 0.6586647778749466}]}, {"text": "Let us define literal translation as a word-to-word translation, and non-literal translation as anon word-toword translation.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7493232786655426}]}, {"text": "Literalness is defined as a degree of literal translation.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7144740521907806}]}, {"text": "Literalness measure of Imamura et al. is trained from a parallel corpus using word aligned results, and then sentences are selected which should either be translated by a 'literal translation' decoder or by a 'non-literal translation' decoder based on this literalness measure.", "labels": [], "entities": []}, {"text": "Apparently, their definition of literalness measure is designed to be high recall since this measure incorporates all the possible correspondence pairs (via realizability of lexical mappings) rather than all the possible true positives (via realizability of sentences).", "labels": [], "entities": [{"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9977465271949768}]}, {"text": "Adding to this, the notion of literal translation maybe broader than this.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.9258252084255219}]}, {"text": "For example, literal translation of \"C'est la vie.\" in French is \"That's life.\" or \"It is the life.\" in English.", "labels": [], "entities": []}, {"text": "If literal translation cannot convey the original meaning correctly, non-literal translation can be applied: \"This is just the way life is.\", \"That's how things happen.\", \"Love story.\", and so forth.", "labels": [], "entities": []}, {"text": "Nonliteral translation preserves the original meaning 1 as much as possible, ignoring the exact word-toword correspondence.", "labels": [], "entities": []}, {"text": "As is indicated by this example, the choice of literal translation or nonliteral translation seems rather a matter of translator preference.", "labels": [], "entities": [{"text": "literal translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7394382059574127}]}, {"text": "This paper presents a pre-processing method using the alternative literalness score aiming for high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.994461715221405}]}, {"text": "We assume that the percentages of these n : m mappings are relatively low.", "labels": [], "entities": []}, {"text": "Finally, it turned out that if we focus on outlier ratio, this method becomes a well-known sentence cleaning approach.", "labels": [], "entities": [{"text": "sentence cleaning", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.797368973493576}]}, {"text": "We refer to this in Section 5.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines the 1 : n characteristics of word alignment by IBM Model 4.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7649911344051361}]}, {"text": "Section 3 reviews anatomic unit of phrase extraction.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8355148136615753}]}, {"text": "Section 4 explains our Good Points Algorithm.", "labels": [], "entities": []}, {"text": "Experimental results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 discusses a sentence cleaning algorithm.", "labels": [], "entities": [{"text": "sentence cleaning", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7984291315078735}]}, {"text": "Section 7 concludes and provides avenues for further research.", "labels": [], "entities": []}, {"text": "Dictionary goes as follows: something that you say when something happens that you do not like but which you have to accept because you cannot change it. shows that in the case of 1:10 alignments, 1/2 of the alignments are considered to be outliers by Algorithm 1, while 100 percent of alignment from 1:11 to 1:13 are considered to be outliers (false negative).", "labels": [], "entities": []}, {"text": "shows that in the case of EN-DE, most of the outlier ratios are less than 20 percent.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Performance of word-based MT system  in different alignment methods. The above is be- tween ENFR and ESEN.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.8613906502723694}, {"text": "ENFR", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.7418200373649597}, {"text": "ESEN", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.8351321816444397}]}, {"text": " Table 4: Performance of word-based MT system  for different language pairs with union alignment  method.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9079487323760986}]}, {"text": " Table 6: Table shows Bleu score for ENES,  DEEN, and ENFR: 0.314, 0.221, and 0.192, re- spectively. All of these are better than baseline.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.9770645499229431}, {"text": "ENES", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.9186081290245056}, {"text": "DEEN", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.5203416347503662}, {"text": "ENFR", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.848813533782959}]}, {"text": " Table 7: This table shows results for the revised  Good Points Algorithm.", "labels": [], "entities": [{"text": "Good Points Algorithm", "start_pos": 52, "end_pos": 73, "type": "DATASET", "confidence": 0.7039251426855723}]}, {"text": " Table 8: Bleu score after cleaning of sen- tences with length greater than X. The row  shows X, while the column shows the language  pair. Parallel corpus is News Commentary par- allel corpus. It is noted that the default set- ting of MAX SENTENCE LENTH ALLOWED  in GIZA++ is 101.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9699270129203796}, {"text": "News Commentary par- allel corpus", "start_pos": 159, "end_pos": 192, "type": "DATASET", "confidence": 0.84063654144605}, {"text": "LENTH ALLOWED", "start_pos": 249, "end_pos": 262, "type": "METRIC", "confidence": 0.6849584877490997}]}]}