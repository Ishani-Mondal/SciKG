{"title": [{"text": "Semi-supervised Learning for Automatic Prosodic Event Detection Using Co-training Algorithm", "labels": [], "entities": [{"text": "Prosodic Event Detection", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.6651581426461538}]}], "abstractContent": [{"text": "Most of previous approaches to automatic prosodic event detection are based on supervised learning, relying on the availability of a corpus that is annotated with the prosodic labels of interest in order to train the classification models.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.7324691216150919}]}, {"text": "However, creating such resources is an expensive and time-consuming task.", "labels": [], "entities": []}, {"text": "In this paper, we exploit semi-supervised learning with the co-training algorithm for automatic detection of coarse level representation of prosodic events such as pitch accents, in-tonational phrase boundaries, and break indices.", "labels": [], "entities": []}, {"text": "We propose a confidence-based method to assign labels to unlabeled data and demonstrate improved results using this method compared to the widely used agreement-based method.", "labels": [], "entities": []}, {"text": "In addition, we examine various informative sample selection methods.", "labels": [], "entities": []}, {"text": "In our experiments on the Boston University radio news corpus, using only a small amount of the labeled data as the initial training set, our proposed labeling method combined with most confidence sample selection can effectively use unlabeled data to improve performance and finally reach performance closer to that of the supervised method using all the training data.", "labels": [], "entities": [{"text": "Boston University radio news corpus", "start_pos": 26, "end_pos": 61, "type": "DATASET", "confidence": 0.9714186906814575}]}], "introductionContent": [{"text": "Prosody represents suprasegmental information in speech since it normally extends over more than one phoneme segment.", "labels": [], "entities": []}, {"text": "Prosodic phenomena manifest themselves in speech in different ways, including changes in relative intensity to emphasize specific words or syllables, variations of the fundamental frequency range and contour, and subtle timing variations, such as syllable lengthening and insertion of pause.", "labels": [], "entities": []}, {"text": "In spoken utterances, speakers use prosody to convey emphasis, intent, attitude, and emotion.", "labels": [], "entities": []}, {"text": "These are important cues to aid the listener for interpretation of speech.", "labels": [], "entities": [{"text": "interpretation of speech", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8964006106058756}]}, {"text": "Prosody also plays an important role in automatic spoken language processing tasks, such as speech act detection and natural speech synthesis, because it includes aspect of higher level information that is not completely revealed by segmental acoustics or lexical information.", "labels": [], "entities": [{"text": "automatic spoken language processing", "start_pos": 40, "end_pos": 76, "type": "TASK", "confidence": 0.6728626638650894}, {"text": "speech act detection", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.6463374098141988}, {"text": "natural speech synthesis", "start_pos": 117, "end_pos": 141, "type": "TASK", "confidence": 0.7265642086664835}]}, {"text": "To represent prosodic events for the categorical annotation schemes, one of the most popular labeling schemes is the Tones and Break Indices (ToBI) framework).", "labels": [], "entities": []}, {"text": "The most important prosodic phenomena captured within this framework include pitch accents (or prominence) and prosodic phrase boundaries.", "labels": [], "entities": [{"text": "prosodic phrase boundaries", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.6159867346286774}]}, {"text": "Within the ToBI framework, prosodic phrasing refers to the perceived grouping of words in an utterance, and accent refers to the greater perceived strength or emphasis of some syllables in a phrase.", "labels": [], "entities": [{"text": "accent", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9664887189865112}]}, {"text": "Corpora annotated with prosody information can be used for speech analysis and to learn the relationship between prosodic events and lexical, syntactic and semantic structure of the utterance.", "labels": [], "entities": [{"text": "speech analysis", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7566997110843658}]}, {"text": "However, it is very expensive and time-consuming to perform prosody labeling manually.", "labels": [], "entities": [{"text": "prosody labeling", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.7972391843795776}]}, {"text": "Therefore, automatic labeling of prosodic events is an attractive alternative that has received attention over the past decades.", "labels": [], "entities": [{"text": "automatic labeling of prosodic events", "start_pos": 11, "end_pos": 48, "type": "TASK", "confidence": 0.7341241657733917}]}, {"text": "In addition, automatically detecting prosodic events also benefits many other speech understanding tasks.", "labels": [], "entities": [{"text": "automatically detecting prosodic events", "start_pos": 13, "end_pos": 52, "type": "TASK", "confidence": 0.6879399567842484}, {"text": "speech understanding", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7367867678403854}]}, {"text": "Many previous efforts on prosodic event detection were supervised learning approaches that used acoustic, lexical, and syntactic cues.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7665927608807882}]}, {"text": "However, the major drawback with these methods is that they require a hand-labeled training corpus and depend on specific corpus used for training.", "labels": [], "entities": []}, {"text": "Limited research has been conducted using unsupervised and semi-supervised methods.", "labels": [], "entities": []}, {"text": "In this paper, we exploit semi-supervised learning with the co-training algorithm for automatic prosodic event labeling.", "labels": [], "entities": [{"text": "prosodic event labeling", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.6215327382087708}]}, {"text": "Two different views according to acoustic and lexicalsyntactic knowledge sources are used in the cotraining framework.", "labels": [], "entities": []}, {"text": "We propose a confidencebased method to assign labels to unlabeled data in training iterations and evaluate its performance combined with different informative sample selection methods.", "labels": [], "entities": []}, {"text": "Our experiments on the Boston Radio News corpus show that the use of unlabeled data can lead to significant improvement of prosodic event detection compared to using the original small training set, and that the semisupervised learning result is comparable with supervised learning with similar amount of training data.", "labels": [], "entities": [{"text": "Boston Radio News corpus", "start_pos": 23, "end_pos": 47, "type": "DATASET", "confidence": 0.9941036850214005}, {"text": "prosodic event detection", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.7551446755727133}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we provide details of the corpus and the prosodic event detection tasks.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.7342831293741862}]}, {"text": "Section 3 reviews previous work briefly.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the classification method for prosodic event detection, including the acoustic and syntactic prosodic models, and the features used.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.7886415123939514}]}, {"text": "Section 5 introduces the co-training algorithm we used.", "labels": [], "entities": []}, {"text": "Section 6 presents our experiments and results.", "labels": [], "entities": []}, {"text": "The final section gives a brief summary along with future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our goal is to determine whether the co-training algorithm described above could successfully use the unlabeled data for prosodic event detection.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 121, "end_pos": 145, "type": "TASK", "confidence": 0.7522748112678528}]}, {"text": "In our experiment, 268 ToBI labeled utterances and 886 unlabeled utterances in BU corpus were used.", "labels": [], "entities": [{"text": "BU corpus", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.9364752769470215}]}, {"text": "Among labeled data, 102 utterances of all f1a and m1b speakers are used for testing, 20 utterances randomly chosen from f2b, f3b, m2b, m3b, and m4b are used as development set to optimize parameters such as \u03bb and confidence level threshold, 5 utterances are used as the initial training set L, and the rest of the data is used as unlabeled set U, which has 1027 unlabeled utterances (we removed the human labels for co-training experiments).", "labels": [], "entities": []}, {"text": "The detailed training and test setting is shown in.", "labels": [], "entities": []}, {"text": "First of all, we compare the learning curves using our proposed confidence-based method to assign possible labels with the simple agreementbased random selection method.", "labels": [], "entities": []}, {"text": "We expect that if self-labeling is accurate, adding new samples randomly drawn from these self-labeled data generally should not make performance worse.", "labels": [], "entities": []}, {"text": "For this experiment, in every iteration, we randomly select the self-labeled samples that have at least 0.1 difference between two classifiers' posterior probabilities.", "labels": [], "entities": []}, {"text": "The number of new samples added to training is 5% of the size of the previous training data.", "labels": [], "entities": []}, {"text": "shows the learning curves for accent detection.", "labels": [], "entities": [{"text": "accent detection", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.9066931009292603}]}, {"text": "The number of samples in the x-axis is the number of syllables.", "labels": [], "entities": []}, {"text": "The F-measure score using the initial training data is 0.69.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9987886548042297}]}, {"text": "The dark solid line in is the learning curve of the supervised method when varying the size of the training data.", "labels": [], "entities": []}, {"text": "Compared with supervised method, our proposed relative confidence-based labeling method shows better performance when there is: Percentage of positive samples, and averaged error rate for positive (P) and negative (N) samples for the first 20 iterations using the agreement-based and our confidence labeling methods.", "labels": [], "entities": [{"text": "error rate", "start_pos": 173, "end_pos": 183, "type": "METRIC", "confidence": 0.842578649520874}]}, {"text": "less data, but after some iteration, the performance is saturated earlier.", "labels": [], "entities": []}, {"text": "However, the agreement-based method does not yield any performance gain, instead, its performance is much worse after some iteration.", "labels": [], "entities": []}, {"text": "The other two prosodic event detection tasks also show similar patterns.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.6709631681442261}]}, {"text": "To analyze the reason for this performance degradation using the agreement-based method, we compare the labels of the newly added samples in random selection with the reference annotation.", "labels": [], "entities": []}, {"text": "shows the percentage of the positive samples added for the first 20 iterations, and the average labeling error rate of those samples for the self-labeled positive and negative classes for two methods.", "labels": [], "entities": []}, {"text": "The agreement-based random selection added more negative samples that also have higher error rate than the positive samples.", "labels": [], "entities": [{"text": "error rate", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9658311307430267}]}, {"text": "Adding these samples has a negative impact on the classifier's performance.", "labels": [], "entities": []}, {"text": "In contrast, our confidence-based approach balances the number of positive and negative samples and significantly reduces the error rates for the negative samples as well, thus leading to performance improvement.", "labels": [], "entities": []}, {"text": "Next we evaluate the efficacy of the three sample selection methods described in Section 5, namely, random, most confident, and most different selections.", "labels": [], "entities": []}, {"text": "shows the learning curves for the three selection methods for accent detection.", "labels": [], "entities": [{"text": "accent detection", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.9098286032676697}]}, {"text": "The same configuration is used as in the previous experiment, i.e., at least 0.1 posterior probability difference between the two classifiers, and adding 5% of new samples in each iteration.", "labels": [], "entities": []}, {"text": "All of these sample selection approaches use the confidence-based labeling.", "labels": [], "entities": []}, {"text": "For comparison, also shows the learning curve for supervised learning when varying the training size.", "labels": [], "entities": []}, {"text": "We can see from the figure that compared to random selection, the most confident selection method shows similar performance in the first few iterations, but its performance continues to increase and the saturation point is much later than random selection.", "labels": [], "entities": []}, {"text": "Unlike the other two sample selection methods, most different selection results in noticeable performance degradation after some iteration.", "labels": [], "entities": []}, {"text": "This difference is caused by the high self-labeling error rate of selected samples.", "labels": [], "entities": []}, {"text": "Both random and most confident selections perform better than supervised learning at the first few iterations.", "labels": [], "entities": []}, {"text": "This is because the new samples added have different posterior probabilities by the two classifiers, and thus one of the classifiers benefits from these samples.", "labels": [], "entities": []}, {"text": "Learning curves for the other two tasks (break index and IPB detection) show similar pattern for the random and most different selection methods, but some differences in the most confident selection results.", "labels": [], "entities": [{"text": "IPB detection", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.6812506169080734}]}, {"text": "For the IPB task, the learning curve of the most confident selection fluctuates somewhat in the middle of the iterations with similar performance to random selection, however, afterward the performance is better than random selection.", "labels": [], "entities": [{"text": "IPB task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.7176178395748138}]}, {"text": "For the break index detection, the learning curve of most different selection increases more slowly than random selection at the beginning, but the saturation point is much later and therefore outperforms the random selection at the later iterations.", "labels": [], "entities": [{"text": "break index detection", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.6663867135842642}]}, {"text": "We also evaluated the effect of the amount of initial labeled training data.", "labels": [], "entities": []}, {"text": "In this experiment, most confident selection is used, and the other configurations are the same as the previous experiment.", "labels": [], "entities": []}, {"text": "The learning curve for accent detection is shown in using different numbers of utterances in the initial training data.", "labels": [], "entities": [{"text": "accent detection", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.9392354190349579}]}, {"text": "The arrow marks indicate the start position of each learning curve.", "labels": [], "entities": []}, {"text": "As we can see, the learning curve when using 20 utterances is slightly better than the others, but there is no significant performance gain according to the size of initial labeled training data.", "labels": [], "entities": []}, {"text": "Finally we compared our co-training performance with supervised learning.", "labels": [], "entities": []}, {"text": "For supervised learning, all labeled utterances except for the test set are used for training.", "labels": [], "entities": []}, {"text": "We used most confident selection with proposed self-labeling method.", "labels": [], "entities": []}, {"text": "The initial training data in co-training is 3% of that used for supervised learning.", "labels": [], "entities": []}, {"text": "After 74 iterations, the size of samples of co-training is similar to that in the supervised method.", "labels": [], "entities": []}, {"text": "presents the results of three prosodic event detection tasks.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.6138683954874674}]}, {"text": "We can see that the performance of co-training for these three tasks is slightly worse than supervised learning using all the labeled data, but is significantly better than the original performance using 3% of hand labeled data.", "labels": [], "entities": []}, {"text": "Most of the previous work for prosodic event detection reported their results using classification accuracy instead of F-measure.", "labels": [], "entities": [{"text": "prosodic event detection", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.879614253838857}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.7121690511703491}, {"text": "F-measure", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9900644421577454}]}, {"text": "Therefore to better compare with previous work, we present below the accuracy results in our approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9994756579399109}]}, {"text": "The cotraining algorithm achieves the accuracy of 85.3%,: The results (F-measure) of prosodic event detection for supervised and co-training approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.999734103679657}, {"text": "F-measure", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9972842931747437}, {"text": "prosodic event detection", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.6927086512247721}]}, {"text": "90.1%, and 86.7% respectively for accent, intonational phrase boundary, and break index detection, compared with 87.6%, 92.3%, and 88.9% in supervised learning.", "labels": [], "entities": [{"text": "break index detection", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7218336264292399}]}, {"text": "Although the test condition is different, our result is significantly better than that of other semi-supervised approaches of previous work and comparable with supervised approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Training and test sets.", "labels": [], "entities": []}, {"text": " Table 2: Percentage of positive samples, and  averaged error rate for positive (P) and nega- tive (N) samples for the first 20 iterations using  the agreement-based and our confidence labeling  methods.", "labels": [], "entities": [{"text": "error rate", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.8607273697853088}]}, {"text": " Table 3: The results (F-measure) of prosodic  event detection for supervised and co-training ap- proaches.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9967204928398132}, {"text": "prosodic  event detection", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.7852928042411804}]}]}