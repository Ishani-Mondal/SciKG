{"title": [{"text": "Cross Language Dependency Parsing using a Bilingual Lexicon *", "labels": [], "entities": [{"text": "Cross Language Dependency Parsing", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7005424350500107}]}], "abstractContent": [{"text": "This paper proposes an approach to enhance dependency parsing in a language by using a translated treebank from another language.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.791122704744339}]}, {"text": "A simple statistical machine translation method, word-byword decoding, where not a parallel corpus but a bilingual lexicon is necessary, is adopted for the treebank translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 9, "end_pos": 40, "type": "TASK", "confidence": 0.6253038346767426}, {"text": "word-byword decoding", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.6936066001653671}]}, {"text": "Using an ensemble method, the key information extracted from word pairs with dependency relations in the translated text is effectively integrated into the parser for the target language.", "labels": [], "entities": []}, {"text": "The proposed method is evaluated in English and Chinese treebanks.", "labels": [], "entities": []}, {"text": "It is shown that a translated English treebank helps a Chinese parser obtain a state-of-the-art result.", "labels": [], "entities": []}], "introductionContent": [{"text": "Although supervised learning methods bring stateof-the-art outcome for dependency parser inferring (, a large enough data set is often required for specific parsing accuracy according to this type of methods.", "labels": [], "entities": [{"text": "dependency parser inferring", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.8481007615725199}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.7814241051673889}]}, {"text": "However, to annotate syntactic structure, either phrase-or dependency-based, is a costly job.", "labels": [], "entities": []}, {"text": "Until now, the largest treebanks 1 in various languages for syntax learning are with around one million words (or some other similar units).", "labels": [], "entities": [{"text": "syntax learning", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.9069911241531372}]}, {"text": "Limited data stand in the way of further performance enhancement.", "labels": [], "entities": []}, {"text": "This is the case for each individual language at least.", "labels": [], "entities": []}, {"text": "But, this is not the case as we observe all treebanks in different languages as a whole.", "labels": [], "entities": []}, {"text": "For example, often treebanks for CoNLL-2007 shared task, none includes more than 500K * The study is partially supported by City University of Hong Kong through the Strategic Research Grant 7002037 and 7002388.", "labels": [], "entities": [{"text": "Strategic Research Grant 7002037", "start_pos": 165, "end_pos": 197, "type": "DATASET", "confidence": 0.6367460861802101}]}, {"text": "The first author is sponsored by a research fellowship from CTL, City University of Hong Kong.", "labels": [], "entities": [{"text": "CTL", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.924733579158783}]}, {"text": "1 It is a tradition to call an annotated syntactic corpus as treebank in parsing community.", "labels": [], "entities": []}, {"text": "tokens, while the sum of tokens from all treebanks is about two million ( . As different human languages or treebanks should share something common, this makes it possible to let dependency parsing in multiple languages be beneficial with each other.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.688725158572197}]}, {"text": "In this paper, we study how to improve dependency parsing by using (automatically) translated texts attached with transformed dependency information.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8600488901138306}]}, {"text": "As a case study, we consider how to enhance a Chinese dependency parser by using a translated English treebank.", "labels": [], "entities": []}, {"text": "What our method relies on is not the close relation of the chosen language pair but the similarity of two treebanks, this is the most different from the previous work.", "labels": [], "entities": []}, {"text": "Two main obstacles are supposed to confront in a cross-language dependency parsing task.", "labels": [], "entities": [{"text": "cross-language dependency parsing task", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.7320449575781822}]}, {"text": "The first is the cost of translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.9771502017974854}]}, {"text": "Machine translation has been shown one of the most expensive language processing tasks, as a great deal of time and space is required to perform this task.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8700326383113861}, {"text": "language processing", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7096219509840012}]}, {"text": "In addition, a standard statistical machine translation method based on a parallel corpus will notwork effectively if it is notable to find a parallel corpus that right covers source and target treebanks.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.634578118721644}]}, {"text": "However, dependency parsing focuses on the relations of word pairs, this allows us to use a dictionarybased translation without assuming a parallel corpus available, and the training stage of translation maybe ignored and the decoding will be quite fast in this case.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8273244500160217}]}, {"text": "The second difficulty is that the outputs of translation are hardly qualified for the parsing purpose.", "labels": [], "entities": [{"text": "translation", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.9602946639060974}, {"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9622229933738708}]}, {"text": "The most challenge in this aspect is morphological preprocessing.", "labels": [], "entities": [{"text": "morphological preprocessing", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.7473165094852448}]}, {"text": "We regard that the morphological issue should be handled aiming at the specific language, our solution here is to use character-level features fora target language like Chinese.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents some related existing work.", "labels": [], "entities": []}, {"text": "Section 3 describes the procedure on tree-bank translation and dependency transformation.", "labels": [], "entities": [{"text": "tree-bank translation", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.6482026875019073}, {"text": "dependency transformation", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.743784487247467}]}, {"text": "Section 4 describes a dependency parser for Chinese as a baseline.", "labels": [], "entities": []}, {"text": "Section 5 describes how a parser can be strengthened from the translated treebank.", "labels": [], "entities": []}, {"text": "The experimental results are reported in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 looks into a few issues concerning the conditions that the proposed approach is suitable for.", "labels": [], "entities": []}, {"text": "Section 8 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The quality of the parser is measured by the parsing accuracy or the unlabeled attachment score (UAS), i.e., the percentage of tokens with correct head.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.8487266302108765}, {"text": "unlabeled attachment score (UAS)", "start_pos": 69, "end_pos": 101, "type": "METRIC", "confidence": 0.8204894264539083}]}, {"text": "Two types of scores are reported for comparison: \"UAS without p\" is the UAS score without all punctuation tokens and \"UAS with p\" is the one with all punctuation tokens.", "labels": [], "entities": []}, {"text": "The results with different feature sets are in Table 4.", "labels": [], "entities": []}, {"text": "As the features preact n are involved, abeam search algorithm with width 5 is used for parsing, otherwise, a simple shift-reduce decoding is used.", "labels": [], "entities": [{"text": "parsing", "start_pos": 87, "end_pos": 94, "type": "TASK", "confidence": 0.9678455591201782}]}, {"text": "It is observed that the features derived from the translated text bring a significant performance improvement as high as 1.3%.", "labels": [], "entities": []}, {"text": "b +T: using features derived from the translated text as in.", "labels": [], "entities": [{"text": "T", "start_pos": 3, "end_pos": 4, "type": "METRIC", "confidence": 0.7247864007949829}]}, {"text": "To compare our parser to the state-of-the-art counterparts, we use the same testing data as () did, selecting the sentences length up to 40.", "labels": [], "entities": []}, {"text": "shows the results achieved by other researchers and ours (UAS with p), which indicates that our parser outperforms any other ones 4 . However, our results is only slightly better than that of) as only sentences whose lengths are less than 40 are considered.", "labels": [], "entities": [{"text": "UAS", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.7225196361541748}]}, {"text": "As our full result is much better than the latter, this comparison indicates that our approach improves the performance for those longer sentences.).", "labels": [], "entities": []}, {"text": "The experimental results in  show a negative impact on the parsing accuracy from too long dependency relation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9808447360992432}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9595515727996826}]}, {"text": "For the proposed method, the improvement relative to dependency length is shown in.", "labels": [], "entities": []}, {"text": "From the figure, it is seen that our method gives observable better performance when dependency lengths are larger than 4.", "labels": [], "entities": []}, {"text": "Although word order is changed, the results here show that the useful information from the translated treebank still help those long distance dependencies.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The results with different feature sets", "labels": [], "entities": []}, {"text": " Table 5: Comparison against the state-of-the-art", "labels": [], "entities": []}]}