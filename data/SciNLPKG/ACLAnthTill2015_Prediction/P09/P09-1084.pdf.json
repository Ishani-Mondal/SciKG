{"title": [{"text": "What lies beneath: Semantic and syntactic analysis of manually reconstructed spontaneous speech", "labels": [], "entities": [{"text": "syntactic analysis of manually reconstructed spontaneous speech", "start_pos": 32, "end_pos": 95, "type": "TASK", "confidence": 0.7342068127223423}]}], "abstractContent": [{"text": "Spontaneously produced speech text often includes disfluencies which make it difficult to analyze underlying structure.", "labels": [], "entities": []}, {"text": "Successful reconstruction of this text would transform these errorful utterances into fluent strings and offer an alternate mechanism for analysis.", "labels": [], "entities": []}, {"text": "Our investigation of naturally-occurring spontaneous speaker errors aligned to corrected text with manual semantico-syntactic analysis yields new insight into the syntactic and structural semantic differences between spoken and reconstructed language.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, natural language processing tasks such as machine translation, information extraction, and question answering have been steadily improving, but relatively little of these systems besides transcription have been applied to the most natural form of language input: spontaneous speech.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7450055480003357}, {"text": "information extraction", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.806195467710495}, {"text": "question answering", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.8516652882099152}]}, {"text": "Moreover, there has historically been little consideration of how to analyze the underlying semantico-syntactic structure of speech.", "labels": [], "entities": []}, {"text": "A system would accomplish reconstruction of its spontaneous speech input if its output were to represent, in flawless, fluent, and contentpreserved English, the message that the speaker intended to convey).", "labels": [], "entities": []}, {"text": "Examples of such reconstructions are seen in the following sentence-like units (SUs).", "labels": [], "entities": []}, {"text": "In EX1, reconstruction requires only the deletion of a simple filled pause and speaker repetition).", "labels": [], "entities": [{"text": "reconstruction", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.9467006921768188}]}, {"text": "The second example shows a restart fragment, where an utterance is aborted by the speaker and then restarted with anew train of thought.", "labels": [], "entities": [{"text": "restart fragment", "start_pos": 27, "end_pos": 43, "type": "METRIC", "confidence": 0.928379237651825}]}, {"text": "Detection of an interruption point (denoted + in the example) between the abandoned thought and its replacement, 2.", "labels": [], "entities": []}, {"text": "Determination that the abandoned portion contains unique and preservable content and should be made anew sentence rather than be deleted (which would alter meaning) 3.", "labels": [], "entities": []}, {"text": "Analysis showing that a required argument must be inserted in order to complete the sentence.", "labels": [], "entities": []}, {"text": "Finally, in the third example EX3, in order to produce one of the reconstructions given, a system must 1.", "labels": [], "entities": [{"text": "EX3", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.9167144298553467}]}, {"text": "Detect the anaphoric relationship between \"they\" and \"some kids\" 2.", "labels": [], "entities": []}, {"text": "Detect the referral of \"do\" to \"like video games\" 3.", "labels": [], "entities": []}, {"text": "Make the necessary word reorderings and deletion of the less informative lexemes.", "labels": [], "entities": []}, {"text": "These examples show varying degrees of difficulty for the task of automatic reconstruction.", "labels": [], "entities": [{"text": "automatic reconstruction", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.6766761988401413}]}, {"text": "In each case, we also see that semantic analysis of the reconstruction is more straightforward than of the original string directly.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7397395968437195}]}, {"text": "Such analysis not only informs us of what the speaker intended to communicate, but also reveals insights into the types of errors speakers make when speaking spontaneously and where these errors occur.", "labels": [], "entities": []}, {"text": "The semantic labeling of reconstructed sentences, when combined with the reconstruction alignments, may yield new quantifiable insights into the structure of disfluent natural speech text.", "labels": [], "entities": []}, {"text": "In this paper, we will investigate this relationship further.", "labels": [], "entities": []}, {"text": "Generally, we seek to answer two questions: \u2022 What generalizations about the underlying structure of errorful and reconstructed speech utterances are possible?", "labels": [], "entities": []}, {"text": "\u2022 Are these generalizations sufficiently robust as to be incorporated into statistical models in automatic systems?", "labels": [], "entities": []}, {"text": "We begin by reviewing previous work in the automatic labeling of structural semantics and motivating the analysis not only in terms of discovery but also regarding its potential application to automatic speech reconstruction research.", "labels": [], "entities": [{"text": "automatic labeling of structural semantics", "start_pos": 43, "end_pos": 85, "type": "TASK", "confidence": 0.8117863476276398}, {"text": "automatic speech reconstruction research", "start_pos": 193, "end_pos": 233, "type": "TASK", "confidence": 0.7169928476214409}]}, {"text": "In Section 2 we describe the Spontaneous Speech Reconstruction (SSR) corpus and the manual semantic role labeling it includes.", "labels": [], "entities": [{"text": "Spontaneous Speech Reconstruction (SSR)", "start_pos": 29, "end_pos": 68, "type": "TASK", "confidence": 0.796289712190628}]}, {"text": "Section 3 analyzes structural differences between verbatim and reconstructed text in the SSR as evaluated by a combination of manual and automatically generated phrasal constituent parses, while Section 4 combines syntactic structure and semantic label annotations to determine the consistency of patterns and their comparison to similar patterns in the Wall Street Journal (WSJ)-based Proposition Bank (PropBank) corpus).", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ)-based Proposition Bank (PropBank) corpus", "start_pos": 354, "end_pos": 420, "type": "DATASET", "confidence": 0.9018166432013879}]}, {"text": "We conclude by offering a high level analysis of discoveries made and suggesting areas for continued analysis in the future.", "labels": [], "entities": []}, {"text": "Expanded analysis of these results is described in).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Frequent P va predicate-argument paths", "labels": [], "entities": []}]}