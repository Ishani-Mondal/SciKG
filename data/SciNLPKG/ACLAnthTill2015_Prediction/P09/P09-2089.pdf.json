{"title": [{"text": "Updating a Name Tagger Using Contemporary Unlabeled Data", "labels": [], "entities": [{"text": "Updating a Name Tagger", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6412238776683807}]}], "abstractContent": [{"text": "For many NLP tasks, including named entity tagging, semi-supervised learning has been proposed as a reasonable alternative to methods that require annotating large amounts of training data.", "labels": [], "entities": [{"text": "named entity tagging", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.6706958214441935}]}, {"text": "In this paper, we address the problem of analyzing new data given a semi-supervised NE tagger trained on data from an earlier time period.", "labels": [], "entities": [{"text": "NE tagger", "start_pos": 84, "end_pos": 93, "type": "TASK", "confidence": 0.7902657091617584}]}, {"text": "We will show that updating the unla-beled data is sufficient to maintain quality overtime, and outperforms updating the labeled data.", "labels": [], "entities": []}, {"text": "Furthermore, we will also show that augmenting the unlabeled data with older data inmost cases does not result in better performance than simply using a smaller amount of current unlabeled data.", "labels": [], "entities": []}], "introductionContent": [{"text": "observed large gains in performance for different NLP tasks solely by increasing the size of unlabeled data, but stressed that for other NLP tasks, such as named entity recognition (NER), we still need to focus on developing tools that help to increase the size of annotated data.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 156, "end_pos": 186, "type": "TASK", "confidence": 0.8118700782457987}]}, {"text": "This problem is particularly crucial when processing languages, such as Portuguese, for which the labeled data is scarce.", "labels": [], "entities": []}, {"text": "For instance, in the first NER evaluation for Portuguese, HAREM, only two out of the nine participants presented systems based on machine learning, and they both argued they could have achieved significantly better results if they had larger training sets.", "labels": [], "entities": [{"text": "NER evaluation for Portuguese, HAREM", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.5700139304002126}]}, {"text": "Semi-supervised methods are commonly chosen as an alternative to overcome the lack of annotated resources, because they present a good trade-off between amount of labeled data needed and performance achieved.", "labels": [], "entities": []}, {"text": "Co-training is one of those methods, and has been extensively studied in NLP.", "labels": [], "entities": []}, {"text": "In particular, we showed that the performance of a name tagger based on co-training decays as the time gap between training data (seeds and unlabeled data) and test data increases).", "labels": [], "entities": []}, {"text": "Compared to the original classifier of that uses seven seeds, we used substantially larger seed sets (more than 1000), which raises the question of which of the parameters (seeds or unlabeled data) are causing the performance deterioration.", "labels": [], "entities": []}, {"text": "In the present study, we investigated two main questions, from the point of view of a developer who wants to analyze anew data set, given an NE tagger trained with older data.", "labels": [], "entities": []}, {"text": "First, we studied whether it was better to update the seeds or the unlabeled data; then, we analyzed whether using a smaller amount of current unlabeled data could be better than increasing the amount of unlabeled data drawn from older sources.", "labels": [], "entities": []}, {"text": "The experiments show that using contemporary unlabeled data is the best choice, outperforming most experiments with larger amounts of older unlabeled data and all experiments with contemporary seeds.", "labels": [], "entities": []}], "datasetContent": [{"text": "We denote by S, U and T , respectively, the seed, unlabeled and test texts, and by (S i , U j , T k ) a training-test configuration, where 91a \u2264 i, j, k \u2264 98b, i.e., epochs i, j and k vary between the first half of 1991 (91a) and the second half of 1998 (98b).", "labels": [], "entities": []}, {"text": "For instance, the training-test configuration (S i=91a...98b , U i=91a...98b , T j=98b ) represents the training-test configuration where the test set was drawn from epoch 98b, and the tagger was trained in turn with seeds and unlabeled data drawn from the same epoch i that varied from 91a to 98b.", "labels": [], "entities": []}], "tableCaptions": []}