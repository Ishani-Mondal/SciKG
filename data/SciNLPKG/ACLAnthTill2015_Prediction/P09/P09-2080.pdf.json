{"title": [], "abstractContent": [{"text": "With the aim to deal with sentiment-transfer problem, we proposed a novel approach, which integrates the sentiment orientations of documents into the graph-ranking algorithm.", "labels": [], "entities": []}, {"text": "We apply the graph-ranking algorithm using the accurate labels of old-domain documents as well as the \"pseudo\" labels of new-domain documents.", "labels": [], "entities": []}, {"text": "Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer.", "labels": [], "entities": [{"text": "sentiment transfer", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.9563137590885162}]}], "introductionContent": [{"text": "With the rapid growth of reviewing pages, sentiment classification is drawing more and more attention (.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.9722285568714142}]}, {"text": "Generally speaking, sentiment classification can be considered as a special kind of traditional text classification ().", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.9726465940475464}, {"text": "traditional text classification", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.7211924393971761}]}, {"text": "In most cases, supervised learning methods can perform well ().", "labels": [], "entities": []}, {"text": "But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results.", "labels": [], "entities": []}, {"text": "This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem).", "labels": [], "entities": [{"text": "cross-domain sentiment classification problem", "start_pos": 18, "end_pos": 63, "type": "TASK", "confidence": 0.7669983357191086}]}, {"text": "Sentiment transfer is anew study field.", "labels": [], "entities": [{"text": "Sentiment transfer", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9626492857933044}]}, {"text": "In recent years, only a few works are conducted on this field.", "labels": [], "entities": []}, {"text": "They are generally divided into two categories.", "labels": [], "entities": []}, {"text": "The first one needs a small amount of labeled training data for the new domain (Aue and).", "labels": [], "entities": [{"text": "Aue", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9746893048286438}]}, {"text": "The second one needs no labeled data for the new domain (.", "labels": [], "entities": []}, {"text": "In this paper, we concentrate on the second category which proves to be used more widely.", "labels": [], "entities": []}, {"text": "Graph-ranking algorithm has been successfully used in many fields (, whose idea is to give anode high score if it is strongly linked with other high-score nodes.", "labels": [], "entities": []}, {"text": "In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm.", "labels": [], "entities": [{"text": "sentiment transfer", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8978486955165863}]}, {"text": "In this algorithm, we assign a score for every unlabelled document to denote its extent to \"negative\" or \"positive\", then we iteratively calculate the score by making use of the accurate labels of old-domain data as well as the \"pseudo\" labels of new-domain data, and the final score for sentiment classification is achieved when the algorithm converges, so we can label the newdomain data based on these scores.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 288, "end_pos": 312, "type": "TASK", "confidence": 0.933264285326004}]}], "datasetContent": [{"text": "Neg  In our experiment, we use prototype classification algorithm) and Support Vector Machine experimenting on the three data sets as our baselines separately.", "labels": [], "entities": []}, {"text": "The Support Vector Machine is a state-of-the-art supervised learning algorithm.", "labels": [], "entities": []}, {"text": "In our experiment, we use LibSVM (www.csie.ntu.edu.tw/~cjlin/libsvm/) with a linear kernel and set all options by default.", "labels": [], "entities": []}, {"text": "We also compare our algorithm to Structural Correspondence Learning (SCL) (.", "labels": [], "entities": [{"text": "Structural Correspondence Learning (SCL)", "start_pos": 33, "end_pos": 73, "type": "TASK", "confidence": 0.6809032658735911}]}, {"text": "SCL is a state-of-the-art sentimenttransfer algorithm which automatically induces correspondences among features from different domains.", "labels": [], "entities": []}, {"text": "It identifies correspondences among features from different domains by modeling their correlations with pivot features, which are features that behave in the same way for discriminative learning in both domains.", "labels": [], "entities": []}, {"text": "In our experiment, we use 100 pivot features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Accuracy comparison of different methods", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9968145489692688}]}]}