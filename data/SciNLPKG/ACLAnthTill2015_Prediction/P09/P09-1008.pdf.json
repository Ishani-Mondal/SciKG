{"title": [], "abstractContent": [{"text": "Freer-word-order languages such as Ger-man exhibit linguistic phenomena that present unique challenges to traditional CFG parsing.", "labels": [], "entities": [{"text": "CFG parsing", "start_pos": 118, "end_pos": 129, "type": "TASK", "confidence": 0.8733544051647186}]}, {"text": "Such phenomena produce discontinuous constituents, which are not naturally modelled by projective phrase structure trees.", "labels": [], "entities": []}, {"text": "In this paper, we examine topological field parsing, a shallow form of parsing which identifies the major sections of a sentence in relation to the clausal main verb and the subordinating heads.", "labels": [], "entities": [{"text": "topological field parsing", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6699028809865316}]}, {"text": "We report the results of topo-logical field parsing of German using the unlexicalized, latent variable-based Berke-ley parser (Petrov et al., 2006) Without any language-or model-dependent adaptation , we achieve state-of-the-art results on the T\u00fcBa-D/Z corpus, and a modified NE-GRA corpus that has been automatically annotated with topological fields (Becker and Frank, 2002).", "labels": [], "entities": [{"text": "topo-logical field parsing of German", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.7458406448364258}, {"text": "T\u00fcBa-D/Z corpus", "start_pos": 244, "end_pos": 259, "type": "DATASET", "confidence": 0.8292945623397827}, {"text": "NE-GRA corpus", "start_pos": 276, "end_pos": 289, "type": "DATASET", "confidence": 0.7758666276931763}]}, {"text": "We also perform a qualitative error analysis of the parser output, and discuss strategies to further improve the parsing results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Freer-word-order languages such as German exhibit linguistic phenomena that present unique challenges to traditional CFG parsing.", "labels": [], "entities": [{"text": "CFG parsing", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.8640887439250946}]}, {"text": "Topic focus ordering and word order constraints that are sensitive to phenomena other than grammatical function produce discontinuous constituents, which are not naturally modelled by projective (i.e., without crossing branches) phrase structure trees.", "labels": [], "entities": [{"text": "Topic focus ordering", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7115514079729716}]}, {"text": "In this paper, we examine topological field parsing, a shallow form of parsing which identifies the major sections of a sentence in relation to the clausal main verb and subordinating heads, when present.", "labels": [], "entities": [{"text": "topological field parsing", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6622509360313416}]}, {"text": "We report the results of parsing German using the unlexicalized, latent variable-based Berkeley parser ().", "labels": [], "entities": [{"text": "parsing German", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8667044043540955}]}, {"text": "Without any languageor model-dependent adaptation, we achieve stateof-the-art results on the T\u00fcBa-D/Z corpus), with a F 1 -measure of 95.15% using gold POS tags.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z corpus", "start_pos": 93, "end_pos": 108, "type": "DATASET", "confidence": 0.8465626984834671}, {"text": "F 1 -measure", "start_pos": 118, "end_pos": 130, "type": "METRIC", "confidence": 0.9886300265789032}]}, {"text": "A further reranking of the parser output based on a constraint involving paired punctuation produces a slight additional performance gain.", "labels": [], "entities": []}, {"text": "To facilitate comparison with previous work, we also conducted experiments on a modified NEGRA corpus that has been automatically annotated with topological fields, and found that the Berkeley parser outperforms the method described in that work.", "labels": [], "entities": [{"text": "NEGRA corpus", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.882363885641098}]}, {"text": "Finally, we perform a qualitative error analysis of the parser output on the T\u00fcBa-D/Z corpus, and discuss strategies to further improve the parsing results.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z corpus", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.8706898093223572}]}, {"text": "German syntax and parsing have been studied using a variety of grammar formalisms. has translated the German TIGER corpus () into a CCG-based treebank to model word order variations in German.", "labels": [], "entities": [{"text": "German TIGER corpus", "start_pos": 102, "end_pos": 121, "type": "DATASET", "confidence": 0.6137250661849976}]}, {"text": "consider aversion of dependency grammars known as weighted constraint dependency grammars for parsing German sentences.", "labels": [], "entities": [{"text": "parsing German sentences", "start_pos": 94, "end_pos": 118, "type": "TASK", "confidence": 0.846816619237264}]}, {"text": "On the NEGRA corpus, they achieve an accuracy of 89.0% on parsing dependency edges.", "labels": [], "entities": [{"text": "NEGRA corpus", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9379332959651947}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9993591904640198}]}, {"text": "In Callmeier (2000), a platform for efficient HPSG parsing is developed.", "labels": [], "entities": [{"text": "Callmeier (2000)", "start_pos": 3, "end_pos": 19, "type": "DATASET", "confidence": 0.8319085091352463}, {"text": "HPSG parsing", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.6798408031463623}]}, {"text": "This parser is later extended by with a topological field parser for more efficient parsing of German.", "labels": [], "entities": []}, {"text": "The system by produces LFG parses using a manually designed grammar and a stochastic parse disambiguation process.", "labels": [], "entities": [{"text": "LFG parses", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.5408143848180771}]}, {"text": "They test on the TIGER corpus and achieve an F 1 -measure of 84.20%.", "labels": [], "entities": [{"text": "TIGER corpus", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.7550841867923737}, {"text": "F 1 -measure", "start_pos": 45, "end_pos": 57, "type": "METRIC", "confidence": 0.9929677397012711}]}, {"text": "In, PCFG parsing of NE-GRA is improved by using sister-head dependencies, which outperforms standard head lexicalization as well as an unlexicalized model.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.6948768794536591}]}, {"text": "The best performing model with gold tags achieve an F 1 of 75.60%.", "labels": [], "entities": [{"text": "F 1", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9671016335487366}]}, {"text": "Sister-head dependencies are useful in this case because of the flat structure of NEGRA's trees.", "labels": [], "entities": [{"text": "NEGRA's trees", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.9032558798789978}]}, {"text": "In contrast to the deeper approaches to parsing described above, topological field parsing identifies the major sections of a sentence in relation to the clausal main verb and subordinating heads, when present.", "labels": [], "entities": [{"text": "topological field parsing", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.645657499631246}]}, {"text": "Like other forms of shallow parsing, topological field parsing is useful as the first stage to further processing and eventual semantic analysis.", "labels": [], "entities": [{"text": "topological field parsing", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.6311140457789103}, {"text": "semantic analysis", "start_pos": 127, "end_pos": 144, "type": "TASK", "confidence": 0.7823843955993652}]}, {"text": "As mentioned above, the output of a topological field parser is used as a guide to the search space of a HPSG parsing algorithm in.", "labels": [], "entities": [{"text": "topological field parser", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7208093206087748}, {"text": "HPSG parsing", "start_pos": 105, "end_pos": 117, "type": "TASK", "confidence": 0.7247253358364105}]}, {"text": "In, topological field parsing is part of a divide-andconquer strategy for shallow analysis of German text with the goal of improving an information extraction system.", "labels": [], "entities": [{"text": "topological field parsing", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6130626300970713}, {"text": "shallow analysis of German text", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.7406233191490174}, {"text": "information extraction", "start_pos": 136, "end_pos": 158, "type": "TASK", "confidence": 0.7379728555679321}]}, {"text": "Existing work in identifying topological fields can be divided into chunkers, which identify the lowest-level non-recursive topological fields, and parsers, which also identify sentence and clausal structure.", "labels": [], "entities": []}, {"text": "compare three approaches to topological field chunking based on finite state transducers, memory-based learning, and PCFGs respectively.", "labels": [], "entities": [{"text": "topological field chunking", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.6344821552435557}]}, {"text": "It is found that the three techniques perform about equally well, with F 1 of 94.1% using POS tags from the TnT tagger, and 98.4% with gold tags.", "labels": [], "entities": [{"text": "F 1", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9964847564697266}]}, {"text": "In Liepert (2003), a topological field chunker is implemented using a multi-class extension to the canonically two-class support vector machine (SVM) machine learning framework.", "labels": [], "entities": []}, {"text": "Parameters to the machine learning algorithm are fine-tuned by a genetic search algorithm, with a resulting F 1 -measure of 92.25%.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 108, "end_pos": 120, "type": "METRIC", "confidence": 0.9882122427225113}]}, {"text": "Training the parameters to SVM does not have a large effect on performance, increasing the F 1 -measure in the test set by only 0.11%.", "labels": [], "entities": [{"text": "SVM", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.6571273803710938}, {"text": "F 1 -measure", "start_pos": 91, "end_pos": 103, "type": "METRIC", "confidence": 0.9904783517122269}]}, {"text": "The corpus-based, stochastic topological field parser of is based on a standard treebank PCFG model, in which rule probabilities are estimated by frequency counts.", "labels": [], "entities": [{"text": "stochastic topological field parser", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.6766467541456223}]}, {"text": "This model includes several enhancements, which are also found in the Berkeley parser.", "labels": [], "entities": []}, {"text": "First, they use parameterized categories, splitting nonterminals according to linguistically based intuitions, such as splitting different clause types (they do not distinguish different clause types as basic categories, unlike T\u00fcBa-D/Z).", "labels": [], "entities": []}, {"text": "Second, they take into account punctuation, which may help identify clause boundaries.", "labels": [], "entities": []}, {"text": "They also binarize the very flat topological tree structures, and prune rules that only occur once.", "labels": [], "entities": []}, {"text": "They test their parser on aversion of the NEGRA corpus, which has been annotated with topological fields using a semiautomatic method.", "labels": [], "entities": [{"text": "NEGRA corpus", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.9573166966438293}]}, {"text": "Ule proposes a process termed Directed Treebank Refinement (DTR).", "labels": [], "entities": [{"text": "Directed Treebank Refinement (DTR)", "start_pos": 30, "end_pos": 64, "type": "TASK", "confidence": 0.6950143525997797}]}, {"text": "The goal of DTR is to refine a corpus to improve parsing performance.", "labels": [], "entities": []}, {"text": "DTR is comparable to the idea of latent variable grammars on which the Berkeley parser is based, in that both consider the observed treebank to be less than ideal and both attempt to refine it by splitting and merging nonterminals.", "labels": [], "entities": []}, {"text": "In this work, splitting and merging nonterminals are done by considering the nonterminals' contexts (i.e., their parent nodes) and the distribution of their productions.", "labels": [], "entities": []}, {"text": "Unlike in the Berkeley parser, splitting and merging are distinct stages, rather than parts of a single iteration.", "labels": [], "entities": []}, {"text": "Multiple splits are found first, then multiple rounds of merging are performed.", "labels": [], "entities": []}, {"text": "As an evaluation, DTR is applied to topological field parsing of the T\u00fcBa-D/Z corpus.", "labels": [], "entities": [{"text": "DTR", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.743259072303772}, {"text": "topological field parsing", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.6307601630687714}, {"text": "T\u00fcBa-D/Z corpus", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.8772406876087189}]}, {"text": "We discuss the performance of these topological field parsers in more detail below.", "labels": [], "entities": []}, {"text": "All of the topological parsing proposals predate the advent of the Berkeley parser.", "labels": [], "entities": [{"text": "topological parsing", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.6779603660106659}]}, {"text": "The experiments of this paper demonstrate that the Berkeley parser outperforms previous methods, many of which are specialized for the task of topological field chunking or parsing.", "labels": [], "entities": [{"text": "topological field chunking or parsing", "start_pos": 143, "end_pos": 180, "type": "TASK", "confidence": 0.6804851293563843}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Parsing results for topological fields and clausal constituents on the T\u00fcBa-D/Z corpus.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z corpus", "start_pos": 81, "end_pos": 96, "type": "DATASET", "confidence": 0.8613304793834686}]}, {"text": " Table 3: BF02 = (", "labels": [], "entities": [{"text": "BF02", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.959769606590271}]}, {"text": " Table 4: Category-specific results using grammar  with no edge labels and passing in gold POS tags.", "labels": [], "entities": []}, {"text": " Table 5: Types and frequency of parser errors in  the fifty worst scoring parses by F 1 -measure, us- ing parameters (+ Gold tags, -Edge labels).", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 85, "end_pos": 97, "type": "METRIC", "confidence": 0.9385322332382202}]}]}