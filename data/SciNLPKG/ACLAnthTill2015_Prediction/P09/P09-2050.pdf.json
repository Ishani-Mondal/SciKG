{"title": [{"text": "Extracting Paraphrases of Technical Terms from Noisy Parallel Software Corpora", "labels": [], "entities": [{"text": "Extracting Paraphrases of Technical Terms from Noisy Parallel Software Corpora", "start_pos": 0, "end_pos": 78, "type": "TASK", "confidence": 0.8481896758079529}]}], "abstractContent": [{"text": "In this paper, we study the problem of extracting technical paraphrases from a parallel software corpus, namely, a collection of duplicate bug reports.", "labels": [], "entities": []}, {"text": "Paraphrase acquisition is a fundamental task in the emerging area of text mining for software engineering.", "labels": [], "entities": [{"text": "Paraphrase acquisition", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9556632041931152}, {"text": "text mining", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.7976232767105103}]}, {"text": "Existing paraphrase extraction methods are not entirely suitable here due to the noisy nature of bug reports.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.8658349215984344}]}, {"text": "We propose a number of techniques to address the noisy data problem.", "labels": [], "entities": []}, {"text": "The empirical evaluation shows that our method significantly improves an existing method by up to 58%.", "labels": [], "entities": []}], "introductionContent": [{"text": "Using natural language processing (NLP) techniques to mine software corpora such as code comments and bug reports to assist software engineering (SE) is an emerging and promising research direction (.", "labels": [], "entities": [{"text": "software engineering (SE)", "start_pos": 124, "end_pos": 149, "type": "TASK", "confidence": 0.7351075172424316}]}, {"text": "Paraphrase extraction is one of the fundamental problems that have not been addressed in this area.", "labels": [], "entities": [{"text": "Paraphrase extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9527953565120697}]}, {"text": "It has many applications including software ontology construction and query expansion for retrieving relevant technical documents.", "labels": [], "entities": [{"text": "software ontology construction", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.7396336595217387}, {"text": "query expansion", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7199072986841202}]}, {"text": "In this paper, we study automatic paraphrase extraction from a large collection of software bug reports.", "labels": [], "entities": [{"text": "automatic paraphrase extraction", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.6753465135892233}]}, {"text": "Most large software projects have bug tracking systems, e.g., Bugzilla 1 , to help global users to describe and report the bugs they encounter when using the software.", "labels": [], "entities": []}, {"text": "However, since the same bug maybe seen by many users, many duplicate bug reports are sent to bug tracking systems.", "labels": [], "entities": []}, {"text": "The duplicate bug reports are manually tagged and associated to the original bug report by either the system manager or software developers.", "labels": [], "entities": []}, {"text": "These families of duplicate bug reports form a semi-parallel http://www.bugzilla.org/ Parallel bug reports with a pair of true paraphrases 1: connector extend with a straight line in full screen mode 2: connector show straight line in presentation mode Non-parallel bug reports referring to the same bug 1: Settle language for part of text and spellchecking part of text 2: Feature requested to improve the management of a multi-language document Context-peculiar paraphrases (shown in italics) 1: status bar appear in the middle of the screen 2: maximizing window create phantom status bar in middle of document: Bug Report Examples corpus and therefore a good candidate for extraction of paraphrases of technical terms.", "labels": [], "entities": [{"text": "Bug Report Examples corpus", "start_pos": 614, "end_pos": 640, "type": "DATASET", "confidence": 0.7836214303970337}]}, {"text": "Hence, bug reports interest us because (1) they are abundant and freely available,(2) they naturally form a semiparallel corpus, and (3) they contain many technical terms.", "labels": [], "entities": []}, {"text": "However, bug reports have characteristics that raise many new challenges.", "labels": [], "entities": []}, {"text": "Different from many other parallel corpora, bug reports are noisy.", "labels": [], "entities": []}, {"text": "We observe at least three types of noise common in bug reports.", "labels": [], "entities": []}, {"text": "First, many bug reports have many spelling, grammatical and sentence structure errors.", "labels": [], "entities": []}, {"text": "To address this we extend a suitable stateof-the-art technique that is robust to such corpora, i.e. ().", "labels": [], "entities": []}, {"text": "Second, many duplicate bug report families contain sentences that are not truly parallel.", "labels": [], "entities": []}, {"text": "An example is shown in (middle).", "labels": [], "entities": []}, {"text": "We handle this by considering lexical similarity between duplicate bug reports.", "labels": [], "entities": []}, {"text": "Third, even if the bug reports are parallel, we find many cases of context-peculiar paraphrases, i.e., a pair of phrases that have the same meaning in a very narrow context.", "labels": [], "entities": []}, {"text": "An example is shown in (bottom).", "labels": [], "entities": []}, {"text": "To address this, we introduce two notions of global context-based score and co-occurrence based score which take into account all good and bad occurrences of the phrases in a candidate paraphrase in the corpus.", "labels": [], "entities": []}, {"text": "These scores are then used to identify and remove context-peculiar paraphrases.", "labels": [], "entities": []}, {"text": "The contributions of our work are twofold.", "labels": [], "entities": []}, {"text": "First, we studied the important problem of paraphrase extraction from a noisy semi-parallel software corpus, which has not been studied either in the NLP or the SE community.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.9631660580635071}]}, {"text": "Second, taking into consideration the special characteristics of our noisy data, we proposed several improvements to an existing general paraphrase extraction method, resulting in a significant performance gain -up to 58% relative improvement in precision.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 137, "end_pos": 158, "type": "TASK", "confidence": 0.77923184633255}, {"text": "precision", "start_pos": 246, "end_pos": 255, "type": "METRIC", "confidence": 0.9982628226280212}]}], "datasetContent": [{"text": "Data Set Our bug report corpus is built from OpenOffice 2 . OpenOffice is a well-known open source software which has similar functionalities as Microsoft Office.", "labels": [], "entities": []}, {"text": "We use the bug reports that are submitted before.", "labels": [], "entities": []}, {"text": "Also, we only use the summary part of the bug reports.", "labels": [], "entities": []}, {"text": "We build our corpus in the following steps.", "labels": [], "entities": []}, {"text": "We collect a total of 13,898 duplicate bug reports from OpenOffice.", "labels": [], "entities": [{"text": "OpenOffice", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.9286926984786987}]}, {"text": "Each duplicate bug report is associated to a master report-there is one master report for each unique bug.", "labels": [], "entities": []}, {"text": "From this information, we create duplicate bug report groups where each member of a group is a duplicate of all other members in the same group.", "labels": [], "entities": []}, {"text": "Finally, we extract duplicate bug report pairs by pairing each two members of each group.", "labels": [], "entities": []}, {"text": "We get in total 53,363 duplicate bug report pairs.", "labels": [], "entities": []}, {"text": "As the first step, we employ parallel sentence selection, described in Sec.", "labels": [], "entities": [{"text": "parallel sentence selection", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6331848204135895}]}, {"text": "3, to remove nonparallel duplicate bug report pairs.", "labels": [], "entities": []}, {"text": "After this step, we find 5,935 parallel duplicate bug report pairs.", "labels": [], "entities": []}, {"text": "Experimental Setup The baseline method we consider is the one in () without sentence alignment -as the bug reports are usually of one sentence long.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7180062532424927}]}, {"text": "2, BL utilizes a threshold to control the number of patterns mined.", "labels": [], "entities": [{"text": "BL", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.9609562754631042}]}, {"text": "These patterns are later used to select paraphrases.", "labels": [], "entities": []}, {"text": "In the experiment, we find that running BL using their default threshold of 0.95 on the 5,935 parallel bug reports only gives us 18 paraphrases.", "labels": [], "entities": []}, {"text": "This number is too small for practical purposes.", "labels": [], "entities": []}, {"text": "Therefore, we reduce the threshold to get more paraphrases.", "labels": [], "entities": []}, {"text": "For each threshold in the range of 0.45-0.95 (step size: 0.05), we extract paraphrases and compute the corresponding precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9942185878753662}]}, {"text": "In our approach, we first form chunk pairs from the 5,935 pairs of parallel sentences and then use the baseline approach at a low threshold to ob-tain patterns.", "labels": [], "entities": []}, {"text": "Using these patterns we compute the global context-based scores S g . We also compute the co-occurrence scores Sc . We rank and extract top-k paraphrases based on these scores.", "labels": [], "entities": []}, {"text": "We consider 4 different methods: We can use either S g or Sc to rank the discovered paraphrases.", "labels": [], "entities": []}, {"text": "We call them Rk-S g and Rk-S c . We also consider using one of the scores for ranking and the other for filtering bad candidate paraphrases.", "labels": [], "entities": []}, {"text": "A threshold of 0.05 is used for filtering.", "labels": [], "entities": [{"text": "filtering", "start_pos": 32, "end_pos": 41, "type": "TASK", "confidence": 0.961498498916626}]}, {"text": "We call these two methods Rk-S c +Ft-S g and Rk-S g +Ft-S c . With ranked lists from these 4 methods, we can compute precision@k for the top-k paraphrases.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9905676245689392}]}, {"text": "Results The comparison among these methods is plotted in.", "labels": [], "entities": []}, {"text": "From the figure we can see that our holistic approach using global-context score to rank and co-occurrence score to filter (i.e., Rk-S g +Ft-S c ) has higher precision than the baseline approach (i.e., BL) in all ks.", "labels": [], "entities": [{"text": "precision", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9959996938705444}, {"text": "BL", "start_pos": 202, "end_pos": 204, "type": "METRIC", "confidence": 0.9814302325248718}]}, {"text": "In general, the other holistic configuration (i.e., Rk-S c +Ft-S g ) also works well for most of the ks considered.", "labels": [], "entities": []}, {"text": "Interestingly, the graph shows that using only one of the scores alone (i.e., Rk-S g and Rk-S c ) does not result in a significantly higher precision than the baseline approach.", "labels": [], "entities": [{"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.998656153678894}]}, {"text": "A holistic approach by merging global-context score and co-occurrence score is needed to yield higher precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9983861446380615}]}, {"text": "In, we show some examples of the paraphrases our algorithm extracted from the bug report corpus.", "labels": [], "entities": []}, {"text": "As we can see, most of the paraphrases are very technical and only make sense in the software domain.", "labels": [], "entities": []}, {"text": "It demonstrates the effectiveness of our method.", "labels": [], "entities": []}], "tableCaptions": []}