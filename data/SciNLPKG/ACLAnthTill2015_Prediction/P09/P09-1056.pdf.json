{"title": [{"text": "Distributional Representations for Handling Sparsity in Supervised Sequence-Labeling", "labels": [], "entities": []}], "abstractContent": [{"text": "Supervised sequence-labeling systems in natural language processing often suffer from data sparsity because they use word types as features in their prediction tasks.", "labels": [], "entities": []}, {"text": "Consequently, they have difficulty estimating parameters for types which appear in the test set, but seldom (or never) appear in the training set.", "labels": [], "entities": []}, {"text": "We demonstrate that distributional representations of word types, trained on unannotated text, can be used to improve performance on rare words.", "labels": [], "entities": []}, {"text": "We incorporate aspects of these representations into the feature space of our sequence-labeling systems.", "labels": [], "entities": []}, {"text": "In an experiment on a standard chunking dataset, our best technique improves a chunker from 0.76 F1 to 0.86 F1 on chunks beginning with rare words.", "labels": [], "entities": [{"text": "F1", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9900714159011841}, {"text": "F1", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9847403168678284}]}, {"text": "On the same dataset, it improves our part-of-speech tagger from 74% to 80% accuracy on rare words.", "labels": [], "entities": [{"text": "part-of-speech tagger", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.6717570424079895}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9979323148727417}]}, {"text": "Furthermore , our system improves significantly over a baseline system when applied to text from a different domain, and it reduces the sample complexity of sequence labeling.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data sparsity and high dimensionality are the twin curses of statistical natural language processing (NLP).", "labels": [], "entities": [{"text": "statistical natural language processing (NLP)", "start_pos": 61, "end_pos": 106, "type": "TASK", "confidence": 0.7363906587873187}]}, {"text": "In many traditional supervised NLP systems, the feature space includes dimensions for each word type in the data, or perhaps even combinations of word types.", "labels": [], "entities": []}, {"text": "Since vocabularies can be extremely large, this leads to an explosion in the number of parameters.", "labels": [], "entities": []}, {"text": "To make matters worse, language is Zipf-distributed, so that a large fraction of any training data set will be hapax legomena, very many word types will appear only a few times, and many word types will be left out of the training set altogether.", "labels": [], "entities": []}, {"text": "As a consequence, for many word types supervised NLP systems have very few, or even zero, labeled examples from which to estimate parameters.", "labels": [], "entities": []}, {"text": "The negative effects of data sparsity have been well-documented in the NLP literature.", "labels": [], "entities": []}, {"text": "The performance of state-of-the-art, supervised NLP systems like part-of-speech (POS) taggers degrades significantly on words that do not appear in the training data, or out-of-vocabulary (OOV) words ().", "labels": [], "entities": [{"text": "part-of-speech (POS) taggers", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6903221487998963}]}, {"text": "Performance also degrades when the domain of the test set differs from the domain of the training set, in part because the test set includes more OOV words and words that appear only a few times in the training set (henceforth, rare words) ().", "labels": [], "entities": []}, {"text": "We investigate the use of distributional representations, which model the probability distribution of a word's context, as techniques for finding smoothed representations of word sequences.", "labels": [], "entities": []}, {"text": "That is, we use the distributional representations to share information across unannotated examples of the same word type.", "labels": [], "entities": []}, {"text": "We then compute features of the distributional representations, and provide them as input to our supervised sequence labelers.", "labels": [], "entities": []}, {"text": "Our technique is particularly well-suited to handling data sparsity because it is possible to improve performance on rare words by supplementing the training data with additional unannotated text containing more examples of the rare words.", "labels": [], "entities": []}, {"text": "We provide empirical evidence that shows how distributional representations improve sequencelabeling in the face of data sparsity.", "labels": [], "entities": []}, {"text": "Specifically, we investigate empirically the effects of our smoothing techniques on two sequence-labeling tasks, POS tagging and chunking, to answer the following: 1.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 113, "end_pos": 124, "type": "TASK", "confidence": 0.8073876798152924}]}, {"text": "What is the effect of smoothing on sequencelabeling accuracy for rare word types?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9668574333190918}]}, {"text": "Our best smoothing technique improves a POS tagger by 11% on OOV words, and a chunker by an impressive 21% on OOV words.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.7459882199764252}]}], "datasetContent": [{"text": "We tested the following hypotheses in our experiments: 1.", "labels": [], "entities": []}, {"text": "Smoothing can improve the performance of a supervised sequence labeling system on words that are rare or nonexistent in the training data.", "labels": [], "entities": []}, {"text": "2. A supervised sequence labeler achieves greater accuracy on new domains with smoothing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9966788291931152}]}, {"text": "3. A supervised sequence labeler has a better sample complexity with smoothing.", "labels": [], "entities": []}, {"text": "We investigate the use of smoothing in two test systems, conditional random field (CRF) models for POS tagging and chunking.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.8583677709102631}]}, {"text": "To incorporate smoothing into our models, we follow the following general procedure: first, we collect a set of unannotated text from the same domain as the test data set.", "labels": [], "entities": []}, {"text": "Second, we train a smoothing model on the text of the training data, the test data, and the additional collection.", "labels": [], "entities": []}, {"text": "We then automatically annotate both the training and test data with features calculated from the distributional representation.", "labels": [], "entities": []}, {"text": "Finally, we train the CRF model on the annotated training set and apply it to the test set.", "labels": [], "entities": []}, {"text": "We use an open source CRF software package designed by Sunita Sajarwal and William W. Cohen to implement our CRF models.", "labels": [], "entities": []}, {"text": "We use a set of boolean features listed in.", "labels": [], "entities": []}, {"text": "Our baseline CRF system for POS tagging follows the model described by.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.8934441208839417}]}, {"text": "We include transition features between pairs of consecutive tag variables, features between tag variables and words, and a set of orthographic features that Lafferty et al. found helpful for performance on OOV words.", "labels": [], "entities": []}, {"text": "Our smoothed models add features computed from the distributional representations, as discussed above.", "labels": [], "entities": []}, {"text": "Our chunker follows the system described by.", "labels": [], "entities": []}, {"text": "In addition to the transition, word-level, and orthographic features, we include features relating automatically-generated POS tags and the chunk labels.", "labels": [], "entities": []}, {"text": "Unlike Sha and  Pereira, we exclude features relating consecutive pairs of words and a chunk label, or features relating consecutive tag labels and a chunk label, in order to expedite our experiments.", "labels": [], "entities": []}, {"text": "We found that including such features does improve chunking F1 by approximately 2%, but it also significantly slows down CRF training.", "labels": [], "entities": [{"text": "chunking", "start_pos": 51, "end_pos": 59, "type": "TASK", "confidence": 0.9812359809875488}, {"text": "F1", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9483361840248108}, {"text": "CRF training", "start_pos": 121, "end_pos": 133, "type": "TASK", "confidence": 0.8444858193397522}]}], "tableCaptions": [{"text": " Table 2: POS tagging accuracy: our HMM-smoothed", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7456294596195221}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9517406821250916}, {"text": "HMM-smoothed", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.44199755787849426}]}, {"text": " Table 3: Chunking F1: our HMM-smoothed chunker", "labels": [], "entities": [{"text": "HMM-smoothed chunker", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.5357485413551331}]}, {"text": " Table 4: On biochemistry journal data from the OANC,", "labels": [], "entities": [{"text": "biochemistry journal data from the OANC", "start_pos": 13, "end_pos": 52, "type": "DATASET", "confidence": 0.7131094088157018}]}, {"text": " Table 5: On biomedical data from the Penn BioIE", "labels": [], "entities": [{"text": "Penn BioIE", "start_pos": 38, "end_pos": 48, "type": "DATASET", "confidence": 0.9544538855552673}]}]}