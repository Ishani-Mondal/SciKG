{"title": [{"text": "Unsupervised Relation Extraction by Mining Wikipedia Texts Using Information from the Web", "labels": [], "entities": [{"text": "Unsupervised Relation Extraction", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7795939346154531}]}], "abstractContent": [{"text": "This paper presents an unsupervised relation extraction method for discovering and enhancing relations in which a specified concept in Wikipedia participates.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7487760484218597}]}, {"text": "Using respective characteristics of Wikipedia articles and Web corpus, we develop a clustering approach based on combinations of patterns: dependency patterns from dependency analysis of texts in Wikipedia, and surface patterns generated from highly redundant information related to the Web.", "labels": [], "entities": []}, {"text": "Evaluations of the proposed approach on two different domains demonstrate the superiority of the pattern combination over existing approaches.", "labels": [], "entities": []}, {"text": "Fundamentally, our method demonstrates how deep linguistic patterns contribute complementarily with Web surface patterns to the generation of various relations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine learning approaches for relation extraction tasks require substantial human effort, particularly when applied to the broad range of documents, entities, and relations existing on the Web.", "labels": [], "entities": [{"text": "relation extraction tasks", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.8749972383181254}]}, {"text": "Even with semi-supervised approaches, which use a large unlabeled corpus, manual construction of a small set of seeds known as true instances of the target entity or relation is susceptible to arbitrary human decisions.", "labels": [], "entities": []}, {"text": "Consequently, a need exists for development of semantic information-retrieval algorithms that can operate in a manner that is as unsupervised as possible.", "labels": [], "entities": []}, {"text": "Currently, the leading methods in unsupervised information extraction collect redundancy information from a local corpus or use the Web as a corpus (); (;:;.", "labels": [], "entities": [{"text": "information extraction collect redundancy information", "start_pos": 47, "end_pos": 100, "type": "TASK", "confidence": 0.8238835811614991}]}, {"text": "The standard process is to scan or search the corpus to collect co-occurrences of word pairs with strings between them, and then to calculate term co-occurrence or generate surface patterns.", "labels": [], "entities": []}, {"text": "The method is used widely.", "labels": [], "entities": []}, {"text": "However, even when patterns are generated from well-written texts, frequent pattern mining is non-trivial because the number of unique patterns is loose, but many patterns are non-discriminative and correlated.", "labels": [], "entities": [{"text": "pattern mining", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.7494127154350281}]}, {"text": "A salient challenge and research interest for frequent pattern mining is abstraction away from different surface realizations of semantic relations to discover discriminative patterns efficiently.", "labels": [], "entities": [{"text": "frequent pattern mining", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.6635224918524424}]}, {"text": "Linguistic analysis is another effective technology for semantic relation extraction, as described in many reports such as;; (;.", "labels": [], "entities": [{"text": "Linguistic analysis", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8033430874347687}, {"text": "semantic relation extraction", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.8266224265098572}]}, {"text": "Currently, linguistic approaches for semantic relation extraction are mostly supervised, relying on pre-specification of the desired relation or initial seed words or patterns from hand-coding.", "labels": [], "entities": [{"text": "semantic relation extraction", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.7984620332717896}]}, {"text": "The common process is to generate linguistic features based on analyses of the syntactic features, dependency, or shallow semantic structure of text.", "labels": [], "entities": []}, {"text": "Then the system is trained to identify entity pairs that assume a relation and to classify them into pre-defined relations.", "labels": [], "entities": []}, {"text": "The advantage of these methods is that they use linguistic technologies to learn semantic information from different surface expressions.", "labels": [], "entities": []}, {"text": "As described herein, we consider integrating linguistic analysis with Web frequency information to improve the performance of unsupervised relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.7694702446460724}]}, {"text": "As ( reported, \"deep\" linguistic technology presents problems when applied to heterogeneous text on the Web.", "labels": [], "entities": []}, {"text": "Therefore, we do not parse information from the Web corpus, but from well written texts.", "labels": [], "entities": [{"text": "Web corpus", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.6967863142490387}]}, {"text": "Particularly, we specifically examine unsupervised relation extraction from existing texts of Wikipedia articles.", "labels": [], "entities": [{"text": "relation extraction from existing texts of Wikipedia articles", "start_pos": 51, "end_pos": 112, "type": "TASK", "confidence": 0.8196350559592247}]}, {"text": "Wikipedia resources of a fun-damental type are of concepts (e.g., represented by Wikipedia articles as a special case) and their mutual relations.", "labels": [], "entities": []}, {"text": "We propose our method, which groups concept pairs into several clusters based on the similarity of their contexts.", "labels": [], "entities": []}, {"text": "Contexts are collected as patterns of two kinds: dependency patterns from dependency analysis of sentences in Wikipedia, and surface patterns generated from highly redundant information from the Web.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are as follows: \u2022 Using characteristics of Wikipedia articles and the Web corpus respectively, our study yields an example of bridging the gap separating \"deep\" linguistic technology and redundant Web information for Information Extraction tasks.", "labels": [], "entities": [{"text": "Information Extraction tasks", "start_pos": 254, "end_pos": 282, "type": "TASK", "confidence": 0.8340596159299215}]}, {"text": "\u2022 Our experimental results reveal that relations are extractable with good precision using linguistic patterns, whereas surface patterns from Web frequency information contribute greatly to the coverage of relation extraction.", "labels": [], "entities": [{"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9952056407928467}, {"text": "relation extraction", "start_pos": 206, "end_pos": 225, "type": "TASK", "confidence": 0.7403256893157959}]}, {"text": "\u2022 The combination of these patterns produces a clustering method to achieve high precision for different Information Extraction applications, especially for bootstrapping a high-recall semi-supervised relation extraction system.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9957083463668823}, {"text": "Information Extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.7579969167709351}, {"text": "relation extraction", "start_pos": 201, "end_pos": 220, "type": "TASK", "confidence": 0.7460795938968658}]}], "datasetContent": [{"text": "We apply our algorithm to two categories in Wikipedia: \"American chief executives\" and \"Companies\".", "labels": [], "entities": []}, {"text": "Both categories are well defined and closed.", "labels": [], "entities": []}, {"text": "We conduct experiments for extracting various relations and for measuring the quality of these relations in terms of precision and coverage.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9994632601737976}]}, {"text": "We use coverage as an evaluation instead of using recall as a measure.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9982907176017761}]}, {"text": "The coverage is used to evaluate all correctly extracted concept pairs.", "labels": [], "entities": [{"text": "coverage", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9611469507217407}]}, {"text": "It is defined as the fraction of all the correctly extracted concept pairs to the whole set of concept pairs.", "labels": [], "entities": []}, {"text": "To balance between precision and coverage of clustering, we integrate two parameters: We downloaded the Wikipedia dump as of December 3, 2008.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9993177652359009}, {"text": "coverage", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9751747250556946}, {"text": "Wikipedia dump", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.944381594657898}]}, {"text": "The performance of the proposed method is evaluated using different pattern types: dependency patterns, surface patterns, and their combination.", "labels": [], "entities": []}, {"text": "We compare our method with's URI method.", "labels": [], "entities": []}, {"text": "Their algorithm outperformed that presented in the earlier work using surface features of two kinds for unsupervised relation extraction: features that test two entities together and features that test only one entity each.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7427271902561188}]}, {"text": "For comparison, we use a k-means clustering algorithm using the same cluster number k.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for the category: \"American chief  executives\"", "labels": [], "entities": [{"text": "American chief  executives\"", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.6661127507686615}]}, {"text": " Table 3: Performance of different pattern types  Pattern type #Instance Precision Coverage  dependency  1127  84.29  13.00%  surface  1510  68.27  14.10%  Combined  2314  75.63  23.94%", "labels": [], "entities": [{"text": "Instance Precision Coverage  dependency", "start_pos": 64, "end_pos": 103, "type": "METRIC", "confidence": 0.6483120322227478}]}, {"text": " Table 4: Results for the category: \"Companies\"", "labels": [], "entities": []}, {"text": " Table 5: Performance of different pattern types  Pattern type #Instance Precision Coverage  dependency  551  82.58  11.17%  surface  685  71.03  11.95%  Combined  1039  76.87  19.61%", "labels": [], "entities": [{"text": "Instance Precision Coverage  dependency", "start_pos": 64, "end_pos": 103, "type": "METRIC", "confidence": 0.6579514443874359}, {"text": "surface", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.9336925745010376}]}]}