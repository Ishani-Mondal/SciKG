{"title": [{"text": "Learning Semantic Correspondences with Less Supervision", "labels": [], "entities": []}], "abstractContent": [{"text": "A central problem in grounded language acquisition is learning the correspondences between a rich world state and a stream of text which references that world state.", "labels": [], "entities": [{"text": "grounded language acquisition", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6291687289873759}]}, {"text": "To deal with the high degree of ambiguity present in this setting, we present a generative model that simultaneously segments the text into utterances and maps each utterance to a meaning representation grounded in the world state.", "labels": [], "entities": []}, {"text": "We show that our model generalizes across three domains of increasing difficulty-Robocup sportscasting, weather forecasts (a new domain), and NFL recaps.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work in learning semantics has focused on mapping sentences to meaning representations (e.g., some logical form) given aligned sentence/meaning pairs as training data.", "labels": [], "entities": []}, {"text": "However, this degree of supervision is unrealistic for modeling human language acquisition and can be costly to obtain for building large-scale, broadcoverage language understanding systems.", "labels": [], "entities": [{"text": "human language acquisition", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.672233114639918}, {"text": "broadcoverage language understanding", "start_pos": 145, "end_pos": 181, "type": "TASK", "confidence": 0.7202328443527222}]}, {"text": "A more flexible direction is grounded language acquisition: learning the meaning of sentences in the context of an observed world state.", "labels": [], "entities": [{"text": "grounded language acquisition", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6867300371328989}]}, {"text": "The grounded approach has gained interest in various disciplines.", "labels": [], "entities": []}, {"text": "Some recent work in the NLP community has also moved in this direction by relaxing the amount of supervision to the setting where each sentence is paired with a small set of candidate meanings.", "labels": [], "entities": []}, {"text": "The goal of this paper is to reduce the amount of supervision even further.", "labels": [], "entities": []}, {"text": "We assume that we are given a world state represented by a set of records along with a text, an unsegmented sequence of words.", "labels": [], "entities": []}, {"text": "For example, in the weather forecast domain (Section 2.2), the text is the weather report, and the records provide a structured representation of the temperature, sky conditions, etc.", "labels": [], "entities": []}, {"text": "In this less restricted data setting, we must resolve multiple ambiguities: (1) the segmentation of the text into utterances; (2) the identification of relevant facts, i.e., the choice of records and aspects of those records; and (3) the alignment of utterances to facts (facts are the meaning representations of the utterances).", "labels": [], "entities": []}, {"text": "Furthermore, in some of our examples, much of the world state is not referenced at all in the text, and, conversely, the text references things which are not represented in our world state.", "labels": [], "entities": []}, {"text": "This increased amount of ambiguity and noise presents serious challenges for learning.", "labels": [], "entities": []}, {"text": "To cope with these challenges, we propose a probabilistic generative model that treats text segmentation, fact identification, and alignment in a single unified framework.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7656773924827576}, {"text": "fact identification", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7461362779140472}]}, {"text": "The parameters of this hierarchical hidden semi-Markov model can be estimated efficiently using EM.", "labels": [], "entities": []}, {"text": "We tested our model on the task of aligning text to records in three different domains.", "labels": [], "entities": []}, {"text": "The first domain is Robocup sportscasting.", "labels": [], "entities": [{"text": "Robocup sportscasting", "start_pos": 20, "end_pos": 41, "type": "DATASET", "confidence": 0.9310495555400848}]}, {"text": "Their best approach (KRISPER) obtains 67% F 1 ; our method achieves 76.5%.", "labels": [], "entities": [{"text": "KRISPER", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.48246365785598755}, {"text": "F 1", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.994747519493103}]}, {"text": "This domain is simplified in that the segmentation is known.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.9522709250450134}]}, {"text": "The second domain is weather forecasts, for which we created anew dataset.", "labels": [], "entities": [{"text": "weather forecasts", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.6988686174154282}]}, {"text": "Here, the full complexity of joint segmentation and alignment arises.", "labels": [], "entities": [{"text": "joint segmentation", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6831528395414352}, {"text": "alignment", "start_pos": 52, "end_pos": 61, "type": "TASK", "confidence": 0.8403303027153015}]}, {"text": "Nonetheless, we were able to obtain reasonable results on this task.", "labels": [], "entities": []}, {"text": "The third domain we considered is NFL recaps (.", "labels": [], "entities": [{"text": "NFL recaps", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.7698248028755188}]}, {"text": "The language used in this domain is richer by orders of magnitude, and much of it does not reference the world state.", "labels": [], "entities": []}, {"text": "Nonetheless, taking the first unsupervised approach to this problem, we were able to make substantial progress: We achieve an F 1 of 53.2%, which closes over half of the gap between a heuristic baseline (26%) and supervised systems (68%-80%).", "labels": [], "entities": [{"text": "F 1", "start_pos": 126, "end_pos": 129, "type": "METRIC", "confidence": 0.9961062371730804}]}], "datasetContent": [{"text": "Our goal is to learn the correspondence between a text wand the world state sit describes.", "labels": [], "entities": []}, {"text": "We use the term scenario to refer to such a (w, s) pair.", "labels": [], "entities": []}, {"text": "The text is simply a sequence of words w = (w 1 , . .", "labels": [], "entities": []}, {"text": ", w |w| ).", "labels": [], "entities": []}, {"text": "We represent the world state s as a set of records, where each record r \u2208 sis described by a record type r.t \u2208 T and a tuple of field values r.v = (r.v 1 , . .", "labels": [], "entities": []}, {"text": "1 For example, temperature is a record type in the weather domain, and it has four fields: time, min, mean, and max.", "labels": [], "entities": []}, {"text": "The record type r.t \u2208 T specifies the field type r.t f \u2208 {INT, STR, CAT} of each field value r.v f , f = 1, . .", "labels": [], "entities": []}, {"text": "There are three possible field types-integer (INT), string (STR), and categorical (CAT)-which are assumed to be known and fixed.", "labels": [], "entities": []}, {"text": "Integer fields represent numeric properties of the world such as temperature, string fields represent surface-level identifiers such as names of people, and categorical fields represent discrete concepts such as score types in football (touchdown, field goal, and safety).", "labels": [], "entities": []}, {"text": "The field type determines the way we expect the field value to be rendered in words: integer fields can be numerically perturbed, string fields can be spliced, and categorical fields are represented by open-ended word distributions, which are to be learned.", "labels": [], "entities": []}, {"text": "See Section 3.3 for details.", "labels": [], "entities": []}, {"text": "Two important aspects of our model are the segmentation of the text and the modeling of the coherence structure at both the record and field levels.", "labels": [], "entities": []}, {"text": "To quantify the benefits of incorporating these two aspects, we compare our full model with two simpler variants.", "labels": [], "entities": []}, {"text": "\u2022 Model 1 (no model of segmentation or coherence): Each record is chosen independently; each record generates one field, and each field generates one word.", "labels": [], "entities": []}, {"text": "This model is similar in spirit to IBM model 1 ().", "labels": [], "entities": []}, {"text": "\u2022 Model 2 (models segmentation but not coherence): Records and fields are still generated independently, but each field can now generate multiple words.", "labels": [], "entities": []}, {"text": "\u2022 Model 3 (our full model of segmentation and coherence): Records and fields are generated according to the Markov chains described in Section 3.", "labels": [], "entities": []}, {"text": "In the annotated data, each text w has been divided into a set of lines.", "labels": [], "entities": []}, {"text": "These lines correspond to clauses in the weather domain and sentences in the Robocup and NFL domains.", "labels": [], "entities": [{"text": "Robocup and NFL domains", "start_pos": 77, "end_pos": 100, "type": "DATASET", "confidence": 0.7571761161088943}]}, {"text": "Each line is annotated with a (possibly empty) set of records.", "labels": [], "entities": []}, {"text": "Let Abe the gold set of these line-record alignment pairs.", "labels": [], "entities": []}, {"text": "To evaluate a learned model, we compute the Viterbi segmentation and alignment (argmax r,f ,c p(r, f , c | w, s)).", "labels": [], "entities": [{"text": "alignment", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.991358757019043}, {"text": "argmax", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9553943872451782}]}, {"text": "We produce a predicted set of line-record pairs A by aligning a line to a record r i if the span of (the utterance corresponding to) r i overlaps the line.", "labels": [], "entities": []}, {"text": "The reason we evaluate indirectly using lines rather than using utterances is that it is difficult to annotate the segmentation of text into utterances in a simple and consistent manner.", "labels": [], "entities": []}, {"text": "We compute standard precision, recall, and F 1 of A with respect to A.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9630592465400696}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9996170997619629}, {"text": "F 1", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9916914105415344}]}, {"text": "Unless otherwise specified, performance is reported on all scenarios, which were also used for training.", "labels": [], "entities": []}, {"text": "However, we did not tune any hyperparameters, but rather used generic values which worked well enough across all three domains.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for the three datasets. We report average  values across all scenarios in the dataset: |w| is the number of  words in the text, |T | is the number of record types, |s| is the  number of records, and |A| is the number of gold alignments.", "labels": [], "entities": [{"text": "A", "start_pos": 221, "end_pos": 222, "type": "METRIC", "confidence": 0.9684188961982727}]}, {"text": " Table 3: Alignment results on the Robocup sportscasting  dataset.", "labels": [], "entities": [{"text": "Robocup sportscasting  dataset", "start_pos": 35, "end_pos": 65, "type": "DATASET", "confidence": 0.9639585018157959}]}, {"text": " Table 4: F1 scores based on the 4-fold cross-validation  scheme in Chen and Mooney (2008).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9992916584014893}]}, {"text": " Table 5: Alignment results on the weather forecast dataset.", "labels": [], "entities": [{"text": "weather forecast dataset", "start_pos": 35, "end_pos": 59, "type": "DATASET", "confidence": 0.6706408858299255}]}, {"text": " Table 6: Alignment results on the NFL dataset. Graph match- ing and multilabel are supervised results reported in Snyder  and Barzilay (2007). 9", "labels": [], "entities": [{"text": "NFL dataset", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9641035795211792}, {"text": "Graph match- ing", "start_pos": 48, "end_pos": 64, "type": "METRIC", "confidence": 0.935027614235878}]}]}