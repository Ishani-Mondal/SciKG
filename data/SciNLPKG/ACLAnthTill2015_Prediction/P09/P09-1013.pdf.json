{"title": [{"text": "Knowing the Unseen: Estimating Vocabulary Size over Unseen Samples", "labels": [], "entities": []}], "abstractContent": [{"text": "Empirical studies on corpora involve making measurements of several quantities for the purpose of comparing corpora, creating language models or to make generalizations about specific linguistic phenomena in a language.", "labels": [], "entities": []}, {"text": "Quantities such as average word length are stable across sample sizes and hence can be reliably estimated from large enough samples.", "labels": [], "entities": []}, {"text": "However , quantities such as vocabulary size change with sample size.", "labels": [], "entities": []}, {"text": "Thus measurements based on a given sample will need to be extrapolated to obtain their estimates over larger unseen samples.", "labels": [], "entities": []}, {"text": "In this work, we propose a novel nonparametric estima-tor of vocabulary size.", "labels": [], "entities": []}, {"text": "Our main result is to show the statistical consistency of the estimator-the first of its kind in the literature.", "labels": [], "entities": [{"text": "consistency", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.8292042016983032}]}, {"text": "Finally, we compare our proposal with the state of the art estimators (both parametric and nonparametric) on large standard corpora; apart from showing the favorable performance of our estimator, we also see that the classical Good-Turing estimator consistently underestimates the vocabulary size.", "labels": [], "entities": []}], "introductionContent": [{"text": "Empirical studies on corpora involve making measurements of several quantities for the purpose of comparing corpora, creating language models or to make generalizations about specific linguistic phenomena in a language.", "labels": [], "entities": []}, {"text": "Quantities such as average word length or average sentence length are stable across sample sizes.", "labels": [], "entities": []}, {"text": "Hence empirical measurements from large enough samples tend to be reliable for even larger sample sizes.", "labels": [], "entities": []}, {"text": "On the other hand, quantities associated with word frequencies, such as the number of hapax legomena or the number of distinct word types changes are strictly sample size dependent.", "labels": [], "entities": []}, {"text": "Given a sample we can obtain the seen vocabulary and the seen number of hapax legomena.", "labels": [], "entities": []}, {"text": "However, for the purpose of comparison of corpora of different sizes or linguistic phenomena based on samples of different sizes it is imperative that these quantities be compared based on similar sample sizes.", "labels": [], "entities": []}, {"text": "We thus need methods to extrapolate empirical measurements of these quantities to arbitrary sample sizes.", "labels": [], "entities": []}, {"text": "Our focus in this study will be estimators of vocabulary size for samples larger than the sample available.", "labels": [], "entities": []}, {"text": "There is an abundance of estimators of population size (in our case, vocabulary size) in existing literature.", "labels": [], "entities": []}, {"text": "Excellent survey articles that summarize the state-of-the-art are available in and).", "labels": [], "entities": []}, {"text": "Of particular interest to us is the set of estimators that have been shown to model word frequency distributions well.", "labels": [], "entities": []}, {"text": "This study proposes a nonparametric estimator of vocabulary size and evaluates its theoretical and empirical performance.", "labels": [], "entities": [{"text": "vocabulary size", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.6967108845710754}]}, {"text": "For comparison we consider some state-of-the-art parametric and nonparametric estimators of vocabulary size.", "labels": [], "entities": []}, {"text": "The proposed non-parametric estimator for the number of unseen elements assumes a regime characterizing word frequency distributions.", "labels": [], "entities": []}, {"text": "This work is motivated by a scaling formulation to address the problem of unlikely events proposed in).", "labels": [], "entities": []}, {"text": "We also demonstrate that the estimator is strongly consistent under the natural scaling formulation.", "labels": [], "entities": []}, {"text": "While compared with other vocabulary size estimates, we see that our estimator performs at least as well as some of the state of the art estimators.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of estimates of vocabulary size for the BNC corpus as percentage errors w.r.t the  true value. A negative value indicates an underestimate. Our estimator outperforms the other estimators  at all sample sizes.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9325036406517029}]}, {"text": " Table 2: Comparison of estimates of vocabulary size for the NYT corpus as percentage errors w.r.t the  true value. A negative value indicates an underestimate. Our estimator compares favorably with ZM and  Chao.", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9634042978286743}]}, {"text": " Table 3: Comparison of estimates of vocabulary size for the Malayalam corpus as percentage errors  w.r.t the true value. A negative value indicates an underestimate. Our estimator compares favorably with  ZM and GS.", "labels": [], "entities": [{"text": "Malayalam corpus", "start_pos": 61, "end_pos": 77, "type": "DATASET", "confidence": 0.9261893332004547}, {"text": "GS", "start_pos": 213, "end_pos": 215, "type": "METRIC", "confidence": 0.5984213948249817}]}]}