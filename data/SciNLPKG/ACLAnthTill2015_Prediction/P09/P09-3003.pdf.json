{"title": [{"text": "Annotating and Recognising Named Entities in Clinical Notes", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents ongoing research in clinical information extraction.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.6717230677604675}]}, {"text": "This work introduces anew genre of text which are not well-written, noise prone, ungrammat-ical and with much cryptic content.", "labels": [], "entities": []}, {"text": "A corpus of clinical progress notes drawn form an Intensive Care Service has been manually annotated with more than 15000 clinical named entities in 11 entity types.", "labels": [], "entities": []}, {"text": "This paper reports on the challenges involved in creating the annotation schema, and recog-nising and annotating clinical named entities.", "labels": [], "entities": []}, {"text": "The information extraction task has initially used two approaches: a rule based system and a machine learning system using Conditional Random Fields (CRF).", "labels": [], "entities": [{"text": "information extraction task", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.8956324855486552}]}, {"text": "Different features are investigated to assess the interaction of feature sets and the supervised learning approaches to establish the combination best suited to this data set.", "labels": [], "entities": []}, {"text": "The rule based and CRF systems achieved an F-score of 64.12% and 81.48% respectively.", "labels": [], "entities": [{"text": "CRF", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.6858056783676147}, {"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9997499585151672}]}], "introductionContent": [{"text": "A substantial amount of clinical data is locked away in a non-standardised form of clinical language, which if standardised could be usefully mined to improve processes in the work of clinical wards, and to gain greater understanding of patient care as well as the progression of diseases.", "labels": [], "entities": []}, {"text": "However in some clinical contexts these clinical notes, as written by a clinicians, are in a less structured and often minimal grammatical form with idiosyncratic and cryptic shorthand.", "labels": [], "entities": []}, {"text": "Whilst there is increasing interest in the automatic extraction of the contents of clinical text, this particular type of notes cause significant difficulties for automatic extraction processes not present for well-written prose notes.", "labels": [], "entities": [{"text": "automatic extraction of the contents of clinical text", "start_pos": 43, "end_pos": 96, "type": "TASK", "confidence": 0.8435094133019447}]}, {"text": "The first step to the extraction of structured information from these clinical notes is to achieve accurate identification of clinical concepts or named entities.", "labels": [], "entities": [{"text": "identification of clinical concepts or named entities", "start_pos": 108, "end_pos": 161, "type": "TASK", "confidence": 0.811951390334538}]}, {"text": "An entity may refer to a concrete object mentioned in the notes.", "labels": [], "entities": []}, {"text": "For example, there are 3 named entities -CT, pituitary macroadenoma and suprasellar cisterns in the sentence: CT revealed pituitary macroadenoma in suprasellar cisterns.", "labels": [], "entities": []}, {"text": "In recent years, the recognition of named entities from biomedical scientific literature has become the focus of much research, a large number of systems have been built to recognise, classify and map biomedical terms to ontologies.", "labels": [], "entities": [{"text": "recognition of named entities from biomedical scientific literature", "start_pos": 21, "end_pos": 88, "type": "TASK", "confidence": 0.7624954506754875}]}, {"text": "However, clinical terms such as findings, procedures and drugs have received less attention.", "labels": [], "entities": []}, {"text": "Although different approaches have been proposed to identify clinical concepts and map them to terminologies), most of the approaches are language pattern based, which suffer from low recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 184, "end_pos": 190, "type": "METRIC", "confidence": 0.9971811771392822}]}, {"text": "The low recall rate is mainly due to the incompleteness of medical lexicon and expressive use of alternative lexicogrammatical structures by the writers.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 8, "end_pos": 19, "type": "METRIC", "confidence": 0.9878182411193848}]}, {"text": "However, only little work has used machine learning approaches, because no training data has been available, or the data are not available for clinical named entity identification.", "labels": [], "entities": [{"text": "clinical named entity identification", "start_pos": 143, "end_pos": 179, "type": "TASK", "confidence": 0.6268332302570343}]}, {"text": "There are semantically annotated corpora that have been developed in biomedical domain in the past few years, for example, the GENIA corpus of Medline abstracts has been annotated with biological entities (; The PennBioIE corpus of 2300 Medline abstracts annotated with biomedical entities, part-of-speech tag and some Penn Treebank style syntactic structures) and LLL05 challenge task corpus).", "labels": [], "entities": [{"text": "GENIA corpus of Medline abstracts", "start_pos": 127, "end_pos": 160, "type": "DATASET", "confidence": 0.9548599720001221}, {"text": "PennBioIE corpus of 2300 Medline abstracts", "start_pos": 212, "end_pos": 254, "type": "DATASET", "confidence": 0.9615345398585001}, {"text": "Penn Treebank", "start_pos": 319, "end_pos": 332, "type": "DATASET", "confidence": 0.979174792766571}, {"text": "LLL05 challenge task corpus", "start_pos": 365, "end_pos": 392, "type": "DATASET", "confidence": 0.642759382724762}]}, {"text": "However only a few corpora are available in the clinical domain.", "labels": [], "entities": []}, {"text": "Many corpora are ad hoc annotations for evaluation, and the size of the corpora are small which is not optimal for machine learning strategies.", "labels": [], "entities": []}, {"text": "The lack of data is due to the difficulty of getting access to clinical text for research purposes and clinical information extraction is still anew area to explore.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.7019335230191549}]}, {"text": "Many of the existing works focused only on clinical conditions or disease).", "labels": [], "entities": []}, {"text": "The only corpus that is annotated with a variety of clinical named entities is the CLEF project () . Most of the works mentioned above are annotated on formal clinical reports and scientific literature abstracts, which generally conform to grammatical conventions of structure and readability.", "labels": [], "entities": [{"text": "CLEF project", "start_pos": 83, "end_pos": 95, "type": "DATASET", "confidence": 0.9034647941589355}]}, {"text": "The CLEF data, annotated on clinical narrative reports, still uses formal clinical reports.", "labels": [], "entities": [{"text": "CLEF data", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.9535010457038879}]}, {"text": "The clinical notes presented in this work, is another genre of text, that is different from clinical reports, because they are not well-written.", "labels": [], "entities": []}, {"text": "Notes written by clinicians and nurses are highly ungrammatical and noise prone, which creates issues in the quality of any text processing.", "labels": [], "entities": []}, {"text": "Examples of problems arising from such texts are: firstly, variance in the representation of core medical concepts, whether unconsciously, such as typographical errors, or consciously, such as abbreviations and personal shorthand; secondly, the occurrences of different notations to signify the same concept.", "labels": [], "entities": []}, {"text": "The clinical notes contain a great deal of formal terminology but used in an informal and unorderly manner, for example, a study of 5000 instances of Glasgow Coma Score (GCS) readings drawn from the corpus showed 321 patterns are used to denote the same concept and over 60% of them are only used once.", "labels": [], "entities": [{"text": "Glasgow Coma Score (GCS) readings drawn from the corpus", "start_pos": 150, "end_pos": 205, "type": "DATASET", "confidence": 0.7112613916397095}]}, {"text": "The clinical information extraction problem is addressed in this work by applying machine learning methods to a corpus annotated for clinical named entities.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.68097651998202}]}, {"text": "The data selection and annotation process is described in Section 3.", "labels": [], "entities": [{"text": "data selection", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7040096819400787}]}, {"text": "The initial approaches to clinical concept identification using both a rule-based approach and machine learning approach are described in Section 4 and Section 5 respectively.", "labels": [], "entities": [{"text": "clinical concept identification", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.631305327018102}]}, {"text": "A Conditional Random Fields based system was used to study and analyse the contribution of various feature types.", "labels": [], "entities": []}, {"text": "The results and discussion are presented in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents experiment results for both the rule-based system and machine learning based system.", "labels": [], "entities": []}, {"text": "Only the 12688 outermost concepts are used in the experiments, because nested terms result in multi-label fora single token.", "labels": [], "entities": []}, {"text": "Since there is no outermost concepts in ABNORMALITY, the classification was done on the remaining 10 categories.", "labels": [], "entities": [{"text": "ABNORMALITY", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.48114779591560364}, {"text": "classification", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.9602816104888916}]}, {"text": "The performances were evaluated in terms of recall, precision and F-score.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9997715353965759}, {"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9997507929801941}, {"text": "F-score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9986299276351929}]}], "tableCaptions": [{"text": " Table 2: Frequencies for nested and outermost  concept.", "labels": [], "entities": []}, {"text": " Table 4: Lexical lookup Performance.", "labels": [], "entities": []}, {"text": " Table 5: Experiment on Feature Contribution for  the ICU corpus.", "labels": [], "entities": [{"text": "ICU corpus", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.7922098934650421}]}, {"text": " Table 6: Detailed Performance of the CRF system.", "labels": [], "entities": [{"text": "Detailed", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.6787559390068054}, {"text": "CRF", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.7949063181877136}]}]}