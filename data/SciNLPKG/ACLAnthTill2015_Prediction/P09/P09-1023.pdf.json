{"title": [], "abstractContent": [{"text": "Wikipedia provides a wealth of knowledge , where the first sentence, infobox (and relevant sentences), and even the entire document of a wiki article could be considered as diverse versions of summaries (definitions) of the target topic.", "labels": [], "entities": []}, {"text": "We explore how to generate a series of summaries with various lengths based on them.", "labels": [], "entities": []}, {"text": "To obtain more reliable associations between sentences, we introduce wiki concepts according to the internal links in Wikipedia.", "labels": [], "entities": []}, {"text": "In addition, we develop an extended document concept lattice model to combine wiki concepts and non-textual features such as the outline and infobox.", "labels": [], "entities": []}, {"text": "The model can concatenate representative sentences from non-overlapping salient local topics for summary generation.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7841461598873138}]}, {"text": "We test our model based on our annotated wiki articles which topics come from TREC-QA 2004-2006 evaluations.", "labels": [], "entities": [{"text": "TREC-QA 2004-2006 evaluations", "start_pos": 78, "end_pos": 107, "type": "DATASET", "confidence": 0.8357182343800863}]}, {"text": "The results show that the model is effective in summariza-tion and definition QA.", "labels": [], "entities": []}], "introductionContent": [{"text": "Nowadays, 'ask Wikipedia' has become as popular as 'Google it' during Internet surfing, as Wikipedia is able to provide reliable information about the concept (entity) that the users want.", "labels": [], "entities": []}, {"text": "As the largest online encyclopedia, Wikipedia assembles immense human knowledge from thousands of volunteer editors, and exhibits significant contributions to NLP problems such as semantic relatedness, word sense disambiguation and question answering (QA).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 202, "end_pos": 227, "type": "TASK", "confidence": 0.6977445681889852}, {"text": "question answering (QA)", "start_pos": 232, "end_pos": 255, "type": "TASK", "confidence": 0.827978390455246}]}, {"text": "For a given definition query, many search engines (e.g., specified by 'define:' in Google) often place the first sentence of the corresponding wiki 1 article at the top of the returned list.", "labels": [], "entities": []}, {"text": "The use of one-sentence snippets provides a brief and concise description of the query.", "labels": [], "entities": []}, {"text": "However, users often need more information beyond such a one-sentence definition, while feeling that the corresponding wiki article is too long.", "labels": [], "entities": []}, {"text": "Thus, there is a strong demand to summarize wiki articles as definitions with various lengths to suite different user needs.", "labels": [], "entities": [{"text": "summarize wiki articles", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8932612737019857}]}, {"text": "The initial motivation of this investigation is to find better definition answer for TREC-QA task using Wikipedia (.", "labels": [], "entities": []}, {"text": "According to past results on TREC-QA), definition queries are usually recognized as being more difficult than factoid and list queries.", "labels": [], "entities": [{"text": "TREC-QA", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.7181746959686279}, {"text": "definition queries", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8639092147350311}]}, {"text": "Wikipedia could help to improve the quality of answer finding and even provide the answers directly.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8976026177406311}, {"text": "answer finding", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8980957865715027}]}, {"text": "Its results are better than other external resources such as WordNet, Gazetteers and Google's define operator, especially for definition QA ().", "labels": [], "entities": [{"text": "WordNet", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.9511191844940186}]}, {"text": "Different from the free text used in QA and summarization, a wiki article usually contains valuable information like infobox and wiki link.", "labels": [], "entities": [{"text": "QA", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9303491115570068}, {"text": "summarization", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.9748537540435791}]}, {"text": "Infobox tabulates the key properties about the target, such as birth place/date and spouse fora person as well as type, founder and products fora company.", "labels": [], "entities": []}, {"text": "Infobox, as a form of thumbnail biography, can be considered as a mini version of a wiki article's summary.", "labels": [], "entities": [{"text": "Infobox", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9204171299934387}]}, {"text": "In addition, the relevant concepts existing in a wiki article usually refer to other wiki pages by wiki internal links, which will form a close set of reference relations.", "labels": [], "entities": []}, {"text": "The current Wikipedia recursively defines over 2 million concepts (in English) via wiki links.", "labels": [], "entities": []}, {"text": "Most of these concepts are multiword terms, whereas WordNet has only 50,000 plus multi-word terms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9711014032363892}]}, {"text": "Any term could appear in the definition of a concept if necessary, while the total vocabulary existing in WordNet's glossary definition is less than 2000.", "labels": [], "entities": [{"text": "WordNet's glossary definition", "start_pos": 106, "end_pos": 135, "type": "DATASET", "confidence": 0.9128320962190628}]}, {"text": "Wikipedia addresses explicit semantics for numerous concepts.", "labels": [], "entities": []}, {"text": "These special knowledge representations will provide additional information for analysis and summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.9778726100921631}]}, {"text": "We thus need to extend existing summarization technologies to take advantage of the knowledge representations in Wikipedia.", "labels": [], "entities": []}, {"text": "The goal of this investigation is to explore summaries with different lengths in Wikipedia.", "labels": [], "entities": []}, {"text": "Our main contribution lies in developing a summarization method that can (i) explore more reliable associations between passages (sentences) in huge feature space represented by wiki concepts; and (ii) effectively combine textual and non-textual features such as infobox and outline in Wikipedia to generate summaries as definition.", "labels": [], "entities": [{"text": "summarization", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.9801822900772095}]}, {"text": "The rest of this paper is organized as follows: In the next section, we discuss the background of summarization using both textual and structural features.", "labels": [], "entities": [{"text": "summarization", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.9890941977500916}]}, {"text": "Section 3 presents the extended document concept lattice model for summarizing wiki articles.", "labels": [], "entities": [{"text": "summarizing wiki articles", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.9149941205978394}]}, {"text": "Section 4 describes corpus construction and experiments are described; while Section 5 concludes the paper.", "labels": [], "entities": [{"text": "corpus construction", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7977405190467834}]}], "datasetContent": [{"text": "The purposes of our experiment are two-fold: (i) evaluate the effects of wiki definition to the TREC-QA task; and (ii) examine the characteristics and summarization performance of EDCL.", "labels": [], "entities": [{"text": "summarization", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.9529679417610168}, {"text": "EDCL", "start_pos": 180, "end_pos": 184, "type": "DATASET", "confidence": 0.8720329999923706}]}], "tableCaptions": [{"text": " Table 1. The correlation co- efficients are listed in", "labels": [], "entities": []}, {"text": " Table 1: Features for correlation measurement", "labels": [], "entities": [{"text": "correlation measurement", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9693508744239807}]}, {"text": " Table 2: Correlation Coefficients between non- textual features in Wiki and TREC/wiki nuggets", "labels": [], "entities": []}, {"text": " Table 4: Average node/concept numbers in DCL  and EDCL", "labels": [], "entities": [{"text": "EDCL", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.800274133682251}]}, {"text": " Table 5: EDCL evaluated by TREC-QA nuggets", "labels": [], "entities": [{"text": "EDCL", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.5847488641738892}, {"text": "TREC-QA nuggets", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.7271344661712646}]}]}