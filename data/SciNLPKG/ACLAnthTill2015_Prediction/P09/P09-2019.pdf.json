{"title": [{"text": "Generalizing over Lexical Features: Selectional Preferences for Semantic Role Classification", "labels": [], "entities": [{"text": "Selectional Preferences", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.8636468350887299}, {"text": "Semantic Role Classification", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.7407323122024536}]}], "abstractContent": [{"text": "This paper explores methods to alleviate the effect of lexical sparseness in the classification of verbal arguments.", "labels": [], "entities": [{"text": "classification of verbal arguments", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.8361145853996277}]}, {"text": "We show how automatically generated selec-tional preferences are able to generalize and perform better than lexical features in a large dataset for semantic role classification.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 148, "end_pos": 176, "type": "TASK", "confidence": 0.6900291442871094}]}, {"text": "The best results are obtained with a novel second-order distributional similarity measure, and the positive effect is specially relevant for out-of-domain data.", "labels": [], "entities": []}, {"text": "Our findings suggest that selectional preferences have potential for improving a full system for Semantic Role Labeling.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.8712459802627563}]}], "introductionContent": [{"text": "Semantic Role Labeling (SRL) systems usually approach the problem as a sequence of two subtasks: argument identification and classification.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8220498859882355}, {"text": "argument identification", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.7182645052671432}]}, {"text": "While the former is mostly a syntactic task, the latter requires semantic knowledge to betaken into account.", "labels": [], "entities": []}, {"text": "Current systems capture semantics through lexicalized features on the predicate and the headword of the argument to be classified.", "labels": [], "entities": []}, {"text": "Since lexical features tend to be sparse (especially when the training corpus is small) SRL systems are prone to overfit the training data and generalize poorly to new corpora.", "labels": [], "entities": [{"text": "SRL", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9712773561477661}]}, {"text": "This work explores the usefulness of selectional preferences to alleviate the lexical dependence of SRL systems.", "labels": [], "entities": [{"text": "SRL", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.9709749817848206}]}, {"text": "Selectional preferences introduce semantic generalizations on the type of arguments preferred by the predicates.", "labels": [], "entities": []}, {"text": "Therefore, they are expected to improve generalization on infrequent and unknown words, and increase the discriminative power of the argument classifiers.", "labels": [], "entities": []}, {"text": "For instance, consider these two sentences: JFK was assassinated (in Dallas) Location JFK was assassinated (in November) T emporal Both share syntactic and argument structure, so the lexical features (i.e., the words 'Dallas' and 'November') represent the most important knowledge to discriminate between the two different adjunct roles.", "labels": [], "entities": []}, {"text": "The problem is that, in new text, one may encounter similar expressions with new words like Texas or Autumn.", "labels": [], "entities": [{"text": "Texas", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.9570811986923218}]}, {"text": "We propose a concrete classification problem as our main evaluation setting for the acquired selectional preferences: given a verb occurrence and a nominal headword of a constituent dependant on that verb, assign the most plausible role to the headword according to the selectional preference model.", "labels": [], "entities": []}, {"text": "This problem is directly connected to argument classification in SRL, but we have isolated the evaluation from the complete SRL task.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.8118945956230164}, {"text": "SRL", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.8354838490486145}, {"text": "SRL task", "start_pos": 124, "end_pos": 132, "type": "TASK", "confidence": 0.8472373783588409}]}, {"text": "This first step allows us to analyze the potential of selectional preferences as a source of semantic knowledge for discriminating among different role labels.", "labels": [], "entities": []}, {"text": "Ongoing work is devoted to the integration of selectional preference-derived features in a complete SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.9847642779350281}]}], "datasetContent": [{"text": "The data used in this work is the benchmark corpus provided by the CoNLL-2005 shared task on SRL ().", "labels": [], "entities": [{"text": "CoNLL-2005 shared task on SRL", "start_pos": 67, "end_pos": 96, "type": "DATASET", "confidence": 0.8037621855735779}]}, {"text": "The dataset, of over 1 million tokens, comprises PropBank sections 02-21 for training, and sections 24 and 23 for development and test, respectively.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8838794231414795}]}, {"text": "In these experiments, NEG, DIS and MOD arguments have been discarded because, apart from not being considered \"pure\" adjunct roles, the selectional preferences implemented in this study are notable to deal with non-nominal argument heads.", "labels": [], "entities": []}, {"text": "The predicate-rol-head (p, r, w) triples for generalizing the selectional preferences are extracted from the arguments of the training set, yielding 71,240 triples, from which 5,587 different predicate-role selectional preferences (p, r) are derived by instantiating the different models in Section 3.", "labels": [], "entities": []}, {"text": "Selectional preferences are then used, to predict the corresponding roles of the (p, w) pairs from the test corpora.", "labels": [], "entities": []}, {"text": "The test set contains 4,134 pairs (covering 505 different predicates) to be classified into the appropriate role label.", "labels": [], "entities": []}, {"text": "In order to study the behavior on out-of-domain data, we also tested on the PropBanked part of the Brown corpus.", "labels": [], "entities": [{"text": "PropBanked part of the Brown corpus", "start_pos": 76, "end_pos": 111, "type": "DATASET", "confidence": 0.942852665980657}]}, {"text": "This corpus contains 2,932 (p, w) pairs covering 491 different predicates.", "labels": [], "entities": []}, {"text": "The performance of each selectional preference model is evaluated by calculating the standard precision, recall and F 1 measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9779725074768066}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9994694590568542}, {"text": "F 1", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.9940900206565857}]}, {"text": "It is worth mentioning that none of the models is able to predict the role when facing an unknown headword.", "labels": [], "entities": []}, {"text": "This happens more often with WordNet based models, which have a lower word coverage compared to distributional similarity-based models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The lexi- cal row corresponds to the baseline lexical match  method. The following row corresponds to the  WordNet-based selectional preference model. The  distributional models follow, including the results  obtained by the three similarity formulas on the", "labels": [], "entities": [{"text": "WordNet-based", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.9081341624259949}]}]}