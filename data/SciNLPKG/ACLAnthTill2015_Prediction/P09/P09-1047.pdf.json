{"title": [{"text": "Profile Based Cross-Document Coreference Using Kernelized Fuzzy Relational Clustering", "labels": [], "entities": []}], "abstractContent": [{"text": "Coreferencing entities across documents in a large corpus enables advanced document understanding tasks such as question answering.", "labels": [], "entities": [{"text": "document understanding", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7331163883209229}, {"text": "question answering", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.8765257000923157}]}, {"text": "This paper presents a novel cross document coreference approach that leverages the profiles of entities which are constructed by using information extraction tools and reconciled by using a within-document coreference module.", "labels": [], "entities": []}, {"text": "We propose to match the profiles by using a learned ensemble distance function comprised of a suite of similarity specialists.", "labels": [], "entities": []}, {"text": "We develop a kernelized soft relational clustering algorithm that makes use of the learned distance function to partition the entities into fuzzy sets of identities.", "labels": [], "entities": [{"text": "kernelized soft relational clustering", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.5840705782175064}]}, {"text": "We compare the kernelized clustering method with a popular fuzzy relation clustering algorithm (FRC) and show 5% improvement in coreference performance.", "labels": [], "entities": [{"text": "fuzzy relation clustering algorithm (FRC)", "start_pos": 59, "end_pos": 100, "type": "TASK", "confidence": 0.693243682384491}]}, {"text": "Evaluation of our proposed methods on a large benchmark disambiguation collection shows that they compare favorably with the top runs in the SemEval evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "A named entity that represents a person, an organization or a geo-location may appear within and across documents in different forms.", "labels": [], "entities": []}, {"text": "Cross document coreference (CDC) is the task of consolidating named entities that appear in multiple documents according to their real referents.", "labels": [], "entities": [{"text": "Cross document coreference (CDC)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7956967751185099}]}, {"text": "CDC is a steppingstone for achieving intelligent information access to vast and heterogeneous text corpora, which includes advanced NLP techniques such as document summarization and question answering.", "labels": [], "entities": [{"text": "CDC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8986982703208923}, {"text": "document summarization", "start_pos": 155, "end_pos": 177, "type": "TASK", "confidence": 0.6291313767433167}, {"text": "question answering", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.8808272480964661}]}, {"text": "A related and well studied task is within document coreference (WDC), which limits the scope of disambiguation to within the boundary of a document.", "labels": [], "entities": [{"text": "document coreference (WDC)", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.7608258366584778}]}, {"text": "When namesakes appear in an article, the author can explicitly help to disambiguate, using titles and suffixes (as in the example, \"George Bush Sr. ... the younger Bush\") besides other means.", "labels": [], "entities": []}, {"text": "Cross document coreference, on the other hand, is a more challenging task because these linguistics cues and sentence structures no longer apply, given the wide variety of context and styles in different documents.", "labels": [], "entities": [{"text": "Cross document coreference", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7040228048960367}]}, {"text": "Cross document coreference research has recently become more popular due to the increasing interests in the web person search task (.", "labels": [], "entities": [{"text": "Cross document coreference", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7208640178044637}]}, {"text": "Here, a search query fora person name is entered into a search engine and the desired outputs are documents clustered according to the identities of the entities in question.", "labels": [], "entities": []}, {"text": "In our work, we propose to drill down to the subdocument mention level and construct an entity profile with the support of information extraction tools and reconciled with WDC methods.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.7081023156642914}]}, {"text": "Hence our IE based approach has access to accurate information such as a person's mentions and geolocations for disambiguation.", "labels": [], "entities": [{"text": "IE", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9445044994354248}]}, {"text": "Simple IR based CDC approaches (e.g. (), on the other hand, may simply use all the terms and this can be detrimental to accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9964601397514343}]}, {"text": "For example, a biography of John F. Kennedy is likely to mention members of his family with related positions, besides references to other political figures.", "labels": [], "entities": []}, {"text": "Even with careful word selection, these textual features can still confuse the disambiguation system about the true identity of the person.", "labels": [], "entities": []}, {"text": "We propose to handle the CDC task using a novel kernelized fuzzy relational clustering algorithm, which allows probabilistic cluster membership assignment.", "labels": [], "entities": [{"text": "cluster membership assignment", "start_pos": 125, "end_pos": 154, "type": "TASK", "confidence": 0.6765816410382589}]}, {"text": "This not only addresses the intrinsic uncertainty nature of the CDC problem, but also yields additional performance improvement.", "labels": [], "entities": []}, {"text": "We propose to use a specialist ensemble learning approach to aggregate the diverse set of similarities in comparing attributes and relationships in entity profiles.", "labels": [], "entities": []}, {"text": "Our approach is first fully described in Section 2.", "labels": [], "entities": []}, {"text": "The effectiveness of the proposed method is demonstrated using real world benchmark test sets in Section 3.", "labels": [], "entities": []}, {"text": "We review related work in cross document coreference and conclude in Section 5.", "labels": [], "entities": [{"text": "cross document coreference", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.682463526725769}]}], "datasetContent": [{"text": "In this section, we first formally define the evaluation metrics, followed by the introduction to the benchmark test sets and the system's performance.", "labels": [], "entities": []}, {"text": "We benchmarked our method using the standard purity and inverse purity clustering metrics as in the WePS evaluation.", "labels": [], "entities": [{"text": "WePS evaluation", "start_pos": 100, "end_pos": 115, "type": "DATASET", "confidence": 0.9358918070793152}]}, {"text": "Leta set of clusters P = {C i } denote the system's partition as aforementioned and a set of categories Q = {D j } be the gold standard.", "labels": [], "entities": []}, {"text": "The precision of a cluster Ci with respect to a category D j is defined as, Purity is in turn defined as the weighted average of the maximum precision achieved by the clusters on one of the categories, where n = |C i |.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9967136383056641}, {"text": "Purity", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9968196153640747}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9876455664634705}]}, {"text": "Hence purity penalizes putting noise chained entities in a cluster.", "labels": [], "entities": []}, {"text": "Trivially, the maximum purity (i.e. 1) can be achieved by making one cluster per chained entity (referred to as the one-in-one baseline).", "labels": [], "entities": []}, {"text": "Reversing the role of clusters and categories, Inverse purity(P, Q) def = Purity(Q, P).", "labels": [], "entities": [{"text": "Inverse purity(P, Q)", "start_pos": 47, "end_pos": 67, "type": "METRIC", "confidence": 0.9170490162713187}]}, {"text": "Inverse Purity penalizes splitting chained entities belonging to the same category into different clusters.", "labels": [], "entities": [{"text": "Inverse Purity penalizes splitting chained entities", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7034638226032257}]}, {"text": "The maximum inverse purity can be similarly achieved by putting all entities into one cluster (all-in-one baseline).", "labels": [], "entities": [{"text": "inverse purity", "start_pos": 12, "end_pos": 26, "type": "METRIC", "confidence": 0.8093608915805817}]}, {"text": "Purity and inverse purity are similar to the precision and recall measures commonly used in IR.", "labels": [], "entities": [{"text": "Purity", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9808127284049988}, {"text": "inverse purity", "start_pos": 11, "end_pos": 25, "type": "METRIC", "confidence": 0.915574461221695}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9993425011634827}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9869117736816406}, {"text": "IR", "start_pos": 92, "end_pos": 94, "type": "TASK", "confidence": 0.9806773066520691}]}, {"text": "The F score, InverseP urity ), is used in performance evaluation.", "labels": [], "entities": [{"text": "F score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9853042662143707}, {"text": "InverseP urity", "start_pos": 13, "end_pos": 27, "type": "METRIC", "confidence": 0.9056730270385742}]}, {"text": "\u03b1 = 0.2 is used to give more weight to inverse purity, with the justification for the web person search mentioned earlier.", "labels": [], "entities": [{"text": "inverse purity", "start_pos": 39, "end_pos": 53, "type": "METRIC", "confidence": 0.6579954624176025}]}, {"text": "We evaluate our methods using the benchmark test collection from the ACL SemEval-2007 web person search task (WePS) ().", "labels": [], "entities": [{"text": "ACL SemEval-2007 web person search task (WePS)", "start_pos": 69, "end_pos": 115, "type": "DATASET", "confidence": 0.7839375601874458}]}, {"text": "The test collection consists of three sets of 10 different names, sampled from ambiguous names from English Wikipedia (famous people), participants of the ACL 2006 conference (computer scientists) and common names from the US Census data, respectively.", "labels": [], "entities": [{"text": "US Census data", "start_pos": 223, "end_pos": 237, "type": "DATASET", "confidence": 0.6801224152247111}]}, {"text": "For each name, the top 100 documents retrieved from the Yahoo!", "labels": [], "entities": []}, {"text": "Search API were annotated, yielding on average 45 real world identities per set and about 3k documents in total.", "labels": [], "entities": []}, {"text": "As we note in the beginning of Section 2, the human markup for the entities corresponding to the search queries is on the document level.", "labels": [], "entities": []}, {"text": "The profile-based CDC approach, however, is to merge the mention-level entities.", "labels": [], "entities": []}, {"text": "In our evaluation, we adopt the document label (and the person search query) to annotate the entity profiles that corresponds to the person name search query.", "labels": [], "entities": []}, {"text": "Despite the difference, the results of the one-in-one and all-in-one baselines are almost identical to those reported in the WePS evaluation (F = 0.52, 0.58 respectively).", "labels": [], "entities": [{"text": "WePS evaluation", "start_pos": 125, "end_pos": 140, "type": "DATASET", "confidence": 0.912776529788971}, {"text": "F", "start_pos": 142, "end_pos": 143, "type": "METRIC", "confidence": 0.9956867098808289}]}, {"text": "Hence the performance reported here is comparable to the official evaluation results (Artiles et al., 2007).", "labels": [], "entities": []}, {"text": "From the WePS training data, we generated a training set of around 32k pairwise instances as previously stated in Section 2.3.", "labels": [], "entities": [{"text": "WePS training data", "start_pos": 9, "end_pos": 27, "type": "DATASET", "confidence": 0.9239524006843567}]}, {"text": "We then used the SEG algorithm to learn the weight distribution model.", "labels": [], "entities": [{"text": "SEG", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.7852646112442017}]}, {"text": "We tuned the parameters in the KARC algorithm using the training set with discrete grid search and chose m = 1.6 and \u03b8 = 0.3.", "labels": [], "entities": []}, {"text": "The RBF kernel (Gaussian) is used with \u03b3 = 0.015.", "labels": [], "entities": [{"text": "RBF kernel", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7381858229637146}]}, {"text": "The macro-averaged cross document coreference on the WePS test sets are reported in.", "labels": [], "entities": [{"text": "cross document coreference", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.5821883082389832}, {"text": "WePS test sets", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.9867362181345621}]}, {"text": "The F score of our CDC system (KARC-S) is 0.740, comparable to the test results of the first tier systems in the official evaluation.", "labels": [], "entities": [{"text": "F score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9895944893360138}, {"text": "CDC system (KARC-S)", "start_pos": 19, "end_pos": 38, "type": "DATASET", "confidence": 0.7188782870769501}]}, {"text": "The two baselines are also included.", "labels": [], "entities": []}, {"text": "Since different feature sets, NLP tools, etc are used in different benchmarked systems, we are also interested in comparing the proposed algorithm with different soft relational clustering variants.", "labels": [], "entities": []}, {"text": "First, we 'harden' the fuzzy partition produced by KARC by allowing an entity to appear in the cluster with highest membership value (KARC-H).", "labels": [], "entities": []}, {"text": "Purity improves because of the removal of noise entities, though at the sacrifice of inverse purity and the We study how the cross document coreference performance changes as we vary the fuzziness in the solution (controlled by m).", "labels": [], "entities": [{"text": "inverse purity", "start_pos": 85, "end_pos": 99, "type": "METRIC", "confidence": 0.824753612279892}]}, {"text": "In, as m increases from 1.4 to 1.9, purity improves by 10% to 0.67, which indicates that more correct coreference decisions (true positives) can be made in a softer configuration.", "labels": [], "entities": [{"text": "purity", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9979776740074158}]}, {"text": "The complimentary is true for inverse purity, though to a lesser extent.", "labels": [], "entities": []}, {"text": "In this case, more false negatives, corresponding to the entities of different coreferents incorrectly linked, are made in a softer partition.", "labels": [], "entities": []}, {"text": "The F score peaks at 0.74 (m = 1.6) and then slightly decreases, as the gain in purity is outweighed by the loss in inverse purity.", "labels": [], "entities": [{"text": "F score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9923677444458008}, {"text": "purity", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9906103014945984}]}, {"text": "evaluates the impact of the different settings of \u03b8 (the threshold of including a chained entity in the fuzzy cluster) on the coreference performance.", "labels": [], "entities": []}, {"text": "We observe that as we increase \u03b8, purity improves indicating less 'noise' entities are included in the solution.", "labels": [], "entities": [{"text": "purity", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9966474175453186}]}, {"text": "On the other hand, inverse purity decreases meaning more coreferent entities are not linked due to the stricter threshold.", "labels": [], "entities": [{"text": "inverse purity", "start_pos": 19, "end_pos": 33, "type": "METRIC", "confidence": 0.6856152415275574}]}, {"text": "Overall, the changes in the two metrics offset each other and the F score is relatively stable across abroad range of \u03b8 settings.", "labels": [], "entities": [{"text": "F score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9876222610473633}]}], "tableCaptions": [{"text": " Table 1: Cross document coreference performance  (I. Purity denotes inverse purity).  Method  Purity I. Purity  F  KARC-S  0.657  0.795 0.740  KARC-H  0.662  0.762 0.710  FRC  0.484  0.840 0.697  One-in-one 1.000  0.482 0.524  All-in-one  0.279  1.000 0.571", "labels": [], "entities": [{"text": "KARC-S  0.657  0.795 0.740  KARC-H  0.662  0.762 0.710  FRC  0.484", "start_pos": 116, "end_pos": 182, "type": "DATASET", "confidence": 0.7795425832271576}]}, {"text": " Table  1. The F score of our CDC system (KARC- S) is 0.740, comparable to the test results of the  first tier systems in the official evaluation. The  two baselines are also included. Since different  feature sets, NLP tools, etc are used in different  benchmarked systems, we are also interested in  comparing the proposed algorithm with differ- ent soft relational clustering variants. First, we  'harden' the fuzzy partition produced by KARC  by allowing an entity to appear in the cluster  with highest membership value (KARC-H). Purity  improves because of the removal of noise entities,  though at the sacrifice of inverse purity and the", "labels": [], "entities": [{"text": "F score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9855371415615082}, {"text": "Purity", "start_pos": 535, "end_pos": 541, "type": "METRIC", "confidence": 0.97808438539505}, {"text": "inverse purity", "start_pos": 622, "end_pos": 636, "type": "METRIC", "confidence": 0.8652611970901489}]}, {"text": " Table 2: Cross document coreference performance  on subsets (I. Purity denotes inverse purity).  Test set  Identity Purity I. Purity  F  Wikipedia  56.5 0.666  0.752 0.717  ACL-06  31.0 0.783  0.771 0.773  US Census  50.3 0.554  0.889 0.754", "labels": [], "entities": [{"text": "F  Wikipedia  56.5 0.666  0.752 0.717", "start_pos": 135, "end_pos": 172, "type": "METRIC", "confidence": 0.890471468369166}, {"text": "ACL-06  31.0 0.783  0.771 0.773  US Census  50.3 0.554  0.889 0.754", "start_pos": 174, "end_pos": 241, "type": "DATASET", "confidence": 0.6820145818320188}]}]}