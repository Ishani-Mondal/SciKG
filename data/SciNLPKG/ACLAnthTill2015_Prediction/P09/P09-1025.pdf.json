{"title": [{"text": "Learning to Tell Tales: A Data-driven Approach to Story Generation", "labels": [], "entities": [{"text": "Learning to Tell Tales", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6773031055927277}, {"text": "Story Generation", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.818161129951477}]}], "abstractContent": [{"text": "Computational storytelling has sparked great interest in artificial intelligence, partly because of its relevance to educational and gaming applications.", "labels": [], "entities": [{"text": "Computational storytelling", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8065553307533264}]}, {"text": "Traditionally , story generators rely on a large repository of background knowledge containing information about the story plot and its characters.", "labels": [], "entities": [{"text": "story generators", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7809573113918304}]}, {"text": "This information is detailed and usually hand crafted.", "labels": [], "entities": []}, {"text": "In this paper we propose a data-driven approach for generating short children's stories that does not require extensive manual involvement.", "labels": [], "entities": []}, {"text": "We create an end-to-end system that realizes the various components of the generation pipeline stochastically.", "labels": [], "entities": []}, {"text": "Our system follows a generate-and-and-rank approach where the space of multiple candidate stories is pruned by considering whether they are plausible, interesting, and coherent.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have witnessed increased interest in the use of interactive language technology in educational and entertainment applications.", "labels": [], "entities": []}, {"text": "Computational storytelling could play a key role in these applications by effectively engaging learners and assisting them in creating a story.", "labels": [], "entities": []}, {"text": "It could also allow teachers to generate stories on demand that suit their classes' needs.", "labels": [], "entities": []}, {"text": "And enhance the entertainment value of role-playing games . The majority of these games come with a set of pre-specified plots that the players must act out.", "labels": [], "entities": []}, {"text": "Ideally, the plot should adapt dynamically in response to the players' actions.", "labels": [], "entities": []}, {"text": "Computational storytelling has a longstanding tradition in the field of artificial intelligence.", "labels": [], "entities": [{"text": "Computational storytelling", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8275129497051239}]}, {"text": "Early work has been largely inspired by typology of narrative structure.", "labels": [], "entities": []}, {"text": "Propp identified in Russian fairy tales a small number of recurring units (e.g., the hero is defeated, the villain causes harm) and rules that could be used to describe their relation (e.g., the hero is pursued and the rescued).", "labels": [], "entities": []}, {"text": "Story grammars were initially used to capture Propp's high-level plot elements and character interactions.", "labels": [], "entities": [{"text": "Propp", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.8748467564582825}]}, {"text": "A large body of more recent work views story generation as a form of agent-based planning ().", "labels": [], "entities": [{"text": "story generation", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.8070513010025024}]}, {"text": "The agents act as characters with a list of goals.", "labels": [], "entities": []}, {"text": "They form plans of action and try to fulfill them.", "labels": [], "entities": []}, {"text": "Interesting stories emerge as agents' plans interact and cause failures and possible replanning.", "labels": [], "entities": []}, {"text": "Perhaps the biggest challenge faced by computational story generators is the amount of world knowledge required to create compelling stories.", "labels": [], "entities": []}, {"text": "A hypothetical system must have information about the characters involved, how they interact, what their goals are, and how they influence their environment.", "labels": [], "entities": []}, {"text": "Furthermore, all this information must be complete and error-free if it is to be used as input to a planning algorithm.", "labels": [], "entities": []}, {"text": "Traditionally, this knowledge is created by hand, and must be recreated for different domains.", "labels": [], "entities": []}, {"text": "Even the simple task of adding anew character requires a whole new set of action descriptions and goals.", "labels": [], "entities": []}, {"text": "A second challenge concerns the generation task itself and the creation of stories characterized by high-quality prose.", "labels": [], "entities": []}, {"text": "Most story generation systems focus on generating plot outlines, without considering the actual linguistic structures found in the stories they are trying to mimic (but see Callaway and Lester 2002 fora notable exception).", "labels": [], "entities": [{"text": "story generation", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.7494560182094574}]}, {"text": "In fact, there seems to belittle common ground between story generation and natural language generation (NLG), despite extensive research in both fields.", "labels": [], "entities": [{"text": "story generation", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.7586438655853271}, {"text": "natural language generation (NLG)", "start_pos": 76, "end_pos": 109, "type": "TASK", "confidence": 0.8110512693723043}]}, {"text": "The NLG process) is often viewed as a pipeline consisting of content planning (selecting and structuring the story's content), microplanning (sentence ag-gregation, generation of referring expressions, lexical choice), and surface realization (agreement, verb-subject ordering).", "labels": [], "entities": [{"text": "surface realization", "start_pos": 223, "end_pos": 242, "type": "TASK", "confidence": 0.7709207534790039}]}, {"text": "However, story generation systems typically operate in two phases: (a) creating a plot for the story and (b) transforming it into text (often by means of template-based NLG).", "labels": [], "entities": [{"text": "story generation", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.791599690914154}]}, {"text": "In this paper we address both challenges facing computational storytelling.", "labels": [], "entities": [{"text": "computational storytelling", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.6986842751502991}]}, {"text": "We propose a data-driven approach to story generation that does not require extensive manual involvement.", "labels": [], "entities": [{"text": "story generation", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.8005301058292389}]}, {"text": "Our goal is to create stories automatically by leveraging knowledge inherent in corpora.", "labels": [], "entities": []}, {"text": "Stories within the same genre (e.g., fairy tales, parables) typically have similar structure, characters, events, and vocabularies.", "labels": [], "entities": []}, {"text": "It is precisely this type of information we wish to extract and quantify.", "labels": [], "entities": []}, {"text": "Of course, building a database of characters and their actions is merely the first step towards creating an automatic story generator.", "labels": [], "entities": []}, {"text": "The latter must be able to select which information to include in the story, in what order to present it, how to convert it into English.", "labels": [], "entities": []}, {"text": "Recent work in natural language generation has seen the development of learning methods for realizing each of these tasks automatically without much hand coding.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6596126953760783}]}, {"text": "For example, and propose to learn a content planner from a parallel corpus.", "labels": [], "entities": []}, {"text": "advocate stochastic search methods for document structuring.", "labels": [], "entities": [{"text": "document structuring", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7192337214946747}]}, {"text": "learn how to combine the syntactic structure of elementary speech acts into one or more sentences from a corpus of good and bad examples.", "labels": [], "entities": []}, {"text": "And use a language model for selecting a fluent sentence among the vast number of surface realizations corresponding to a single semantic representation.", "labels": [], "entities": []}, {"text": "Although successful on their own, these methods have not been yet integrated together into an end-to-end probabilistic system.", "labels": [], "entities": []}, {"text": "Our work attempts to do this for the story generation task, while bridging the gap between story generators and NLG systems.", "labels": [], "entities": [{"text": "story generation", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.8572952151298523}]}, {"text": "Our generator operates over predicate-argument and predicate-predicate co-occurrence statistics gathered from corpora.", "labels": [], "entities": []}, {"text": "These are used to produce a large set of candidate stories which are subsequently ranked based on their interestingness and coherence.", "labels": [], "entities": []}, {"text": "The top-ranked candidate is selected for presentation and verbalized using a language model interfaced with RealPro), a text generation engine.", "labels": [], "entities": [{"text": "RealPro", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.9536206722259521}, {"text": "text generation engine", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7679350972175598}]}, {"text": "This generate-and-rank architecture circumvents the complexity of traditional generation This is a fat hen.", "labels": [], "entities": []}, {"text": "The hen has a nest in the box.", "labels": [], "entities": []}, {"text": "She has eggs in the nest.", "labels": [], "entities": []}, {"text": "A cat sees the nest, and can get the eggs.", "labels": [], "entities": []}, {"text": "The sun will soon set.", "labels": [], "entities": []}, {"text": "The cows are on their way to the barn.", "labels": [], "entities": []}, {"text": "One old cow has a bell on her neck.", "labels": [], "entities": []}, {"text": "She sees the dog, but she will not run.", "labels": [], "entities": []}, {"text": "The dog is kind to the cows.", "labels": [], "entities": []}, {"text": "systems, where numerous, often conflicting constraints, have to be encoded during development in order to produce a single high-quality output.", "labels": [], "entities": []}, {"text": "As a proof of concept we initially focus on children's stories (see for an example).", "labels": [], "entities": []}, {"text": "These stories exhibit several recurrent patterns and are thus amenable to a data-driven approach.", "labels": [], "entities": []}, {"text": "Although they have limited vocabulary and nonelaborate syntax, they nevertheless present challenges at almost all stages of the generation process.", "labels": [], "entities": []}, {"text": "Also from a practical point of view, children's stories have great potential for educational applications.", "labels": [], "entities": []}, {"text": "For instance, the system we describe could serve as an assistant to a person who wants suggestions as to what could happen next in a story.", "labels": [], "entities": []}, {"text": "In the remainder of this paper, we first describe the components of our story generator (Section 2) and explain how these are interfaced with our story ranker (Section 3).", "labels": [], "entities": []}, {"text": "Next, we present the resources and evaluation methodology used in our experiments (Section 4) and discuss our results (Section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our experimental set-up for assessing the performance of our story generator.", "labels": [], "entities": []}, {"text": "We give details on our training corpus, system, parameters (such as the width of the beam), the baselines used for comparison, and explain how our system output was evaluated.", "labels": [], "entities": []}, {"text": "Corpus The generator was trained on 437 stories from the Andrew Lang fairy tale corpus.", "labels": [], "entities": [{"text": "Corpus", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8393191695213318}, {"text": "Andrew Lang fairy tale corpus", "start_pos": 57, "end_pos": 86, "type": "DATASET", "confidence": 0.7347330808639526}]}, {"text": "The stories had an average length of 125.18 sentences.", "labels": [], "entities": []}, {"text": "The corpus contained 15,789 word tokens.", "labels": [], "entities": []}, {"text": "We discarded word tokens that did not appear in the Children's Printed Word Database 7 , a database of printed word frequencies as read by children aged between five and nine.", "labels": [], "entities": [{"text": "Children's Printed Word Database 7", "start_pos": 52, "end_pos": 86, "type": "DATASET", "confidence": 0.7605489492416382}]}, {"text": "Story search When searching the story space, we set the beam width to 500.", "labels": [], "entities": []}, {"text": "This means that we allow only 500 sentences to be considered at a particular depth before generating the next set of sentences in the story.", "labels": [], "entities": []}, {"text": "For each entity we select the five most likely events and event sequences.", "labels": [], "entities": []}, {"text": "Analogously, we consider the five most likely subcategorization templates for each verb.", "labels": [], "entities": []}, {"text": "Considerable latitude is available when applying the ranking functions.", "labels": [], "entities": []}, {"text": "We may use only one of them, or one after the other, or both of them.", "labels": [], "entities": []}, {"text": "To evaluate which system configuration was best, we asked two human evaluators to rate (on a 1-5 scale) stories produced in the following conditions: (a) score the candidate stories using the interest function first and then coherence (and vice versa), (b) score the stories simultaneously using both rankers and select the story with the highest score.", "labels": [], "entities": []}, {"text": "We also examined how best to prune the search space, i.e., by selecting the highest scoring stories, the lowest scoring one, or simply at random.", "labels": [], "entities": []}, {"text": "We created ten stories of length five using the fairy tale corpus for each permutation of the parameters.", "labels": [], "entities": []}, {"text": "The results showed that the evaluators preferred the version of the system that applied both rankers simultaneously and maintained the highest scoring stories in the beam.", "labels": [], "entities": []}, {"text": "Baselines We compared our system against two simpler alternatives.", "labels": [], "entities": []}, {"text": "The first one does not use abeam.", "labels": [], "entities": [{"text": "abeam", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9404132962226868}]}, {"text": "Instead, it decides deterministically how to generate a story on the basis of the most likely predicate-argument and predicate-predicate counts in the knowledge base.", "labels": [], "entities": []}, {"text": "The second one creates a story randomly without taking any cooccurrence frequency into account.", "labels": [], "entities": []}, {"text": "Neither of these systems therefore creates more than one story hypothesis whilst generating.", "labels": [], "entities": []}, {"text": "The system generated stories for 10 input sentences.", "labels": [], "entities": []}, {"text": "These were created using commonly occurring sentences in the fairy tales corpus (e.g., The family has the baby, The monkey climbs the tree, The giant guards the child: Human evaluation results: mean story ratings for three versions of our system; * : significantly different from Rank-based.", "labels": [], "entities": []}, {"text": "stories on a scale of 1 to 5 for fluency (was the sentence grammatical?), coherence (does the story make sense overall?) and interest (how interesting is the story?).", "labels": [], "entities": []}, {"text": "The stories were presented in random order.", "labels": [], "entities": []}, {"text": "Participants were told that all stories were generated by a computer program.", "labels": [], "entities": []}, {"text": "They were instructed to rate more favorably interesting stories, stories that were comprehensible and overall grammatical.", "labels": [], "entities": []}], "tableCaptions": []}