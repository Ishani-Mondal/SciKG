{"title": [{"text": "Word or Phrase? Learning Which Unit to Stress for Information Retrieval *", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.8005044162273407}]}], "abstractContent": [{"text": "The use of phrases in retrieval models has been proven to be helpful in the literature, but no particular research addresses the problem of discriminating phrases that are likely to degrade the retrieval performance from the ones that do not.", "labels": [], "entities": []}, {"text": "In this paper, we present a retrieval framework that utilizes both words and phrases flexibly, followed by a general learning-to-rank method for learning the potential contribution of a phrase in retrieval.", "labels": [], "entities": []}, {"text": "We also present useful features that reflect the compositional-ity and discriminative power of a phrase and its constituent words for optimizing the weights of phrase use in phrase-based retrieval models.", "labels": [], "entities": []}, {"text": "Experimental results on the TREC collections show that our proposed method is effective.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.7888069152832031}]}], "introductionContent": [{"text": "Various researches have improved the quality of information retrieval by relaxing the traditional 'bag-of-words' assumption with the use of phrases.) explore the use n-grams in retrieval models.) use statistically-captured term dependencies within a query.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7391979694366455}]}, {"text": "() study the utility of various kinds of syntactic phrases.", "labels": [], "entities": []}, {"text": "Although use of phrases clearly helps, there still exists a fundamental but unsolved question: Do all phrases contribute an equal amount of increase in the performance of information retrieval models?", "labels": [], "entities": []}, {"text": "Let us consider a search query 'World Bank Criticism', which has the following phrases: 'world bank' and 'bank criticism'.", "labels": [], "entities": [{"text": "World Bank Criticism'", "start_pos": 32, "end_pos": 53, "type": "DATASET", "confidence": 0.8853375613689423}]}, {"text": "Intuitively, the former should be given more importance than its constituents 'world' and 'bank', since the meaning of the original phrase cannot be predicted from the meaning of either constituent.", "labels": [], "entities": []}, {"text": "In contrast, a relatively less attention could be paid to the latter 'bank criticism', because there maybe alternate expressions, of which the meaning is still preserved, that could possibly occur in relevant documents.", "labels": [], "entities": []}, {"text": "However, virtually all the researches ignore the relation between a phrase and its constituent words when combining both words and phrases in a retrieval model.", "labels": [], "entities": []}, {"text": "Our approach to phrase-based retrieval is motivated from the following linguistic intuitions: a) phrases have relatively different degrees of significance, and b) the influence of a phrase should be differentiated based on the phrase's constituents in retrieval models.", "labels": [], "entities": []}, {"text": "In this paper, we start out by presenting a simple language modeling-based retrieval model that utilizes both words and phrases in ranking with use of parameters that differentiate the relative contributions of phrases and words.", "labels": [], "entities": []}, {"text": "Moreover, we propose a general learning-to-rank based framework to optimize the parameters of phrases against their constituent words for retrieval models that utilize both words and phrases.", "labels": [], "entities": []}, {"text": "In order to estimate such parameters, we adapt the use of a cost function together with a gradient descent method that has been proven to be effective for optimizing information retrieval models with multiple parameters.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 166, "end_pos": 187, "type": "TASK", "confidence": 0.7260043919086456}]}, {"text": "We also propose a number of potentially useful features that reflect not only the characteristics of a phrase but also the information of its constituent words for minimizing the cost function.", "labels": [], "entities": []}, {"text": "Our experimental results demonstrate that 1) differentiating the weights of each phrase over words yields statistically significant improvement in retrieval performance, 2) the gradient descent-based parameter optimization is reasonably appropriate to our task, and 3) the proposed features can distinguish good phrases that make contributions to the retrieval performance.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section discusses previous work.", "labels": [], "entities": []}, {"text": "Section 3 presents our learning-based retrieval framework and features.", "labels": [], "entities": []}, {"text": "Section 4 reports the evaluations of our techniques.", "labels": [], "entities": []}, {"text": "Section 5 finally concludes the paper and discusses future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report the retrieval performances of the proposed method with appropriate baselines over a range of training sets.", "labels": [], "entities": []}, {"text": "Retrieval models: We have set two retrieval models, namely the word model and the (phrase-based) one-parameter model, as baselines.", "labels": [], "entities": []}, {"text": "The ranking function of the word model is equivalent to Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9500821828842163}]}, {"text": "2, with \u03bb in Eq.", "labels": [], "entities": []}, {"text": "3 being set to zero (i.e. the phrase probability makes no effect on the ranking).", "labels": [], "entities": []}, {"text": "The ranking function of the one-parameter model is also equivalent to Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9575966596603394}]}, {"text": "2, with \u03bb in Eq.", "labels": [], "entities": []}, {"text": "3 used \"as is\" (i.e. as a constant parameter value optimized using gradient descent method, without being replaced to a logistic function).", "labels": [], "entities": []}, {"text": "Both baseline models cannot differentiate the importance of phrases in a query.", "labels": [], "entities": []}, {"text": "To make a distinction from the baseline models, we will name our proposed method as a multi-parameter model.", "labels": [], "entities": []}, {"text": "In our experiments, all the probabilities in all retrieval models are smoothed with the collection statistics by using dirichlet priors).", "labels": [], "entities": []}, {"text": "Corpus (Training/Test): We have conducted large-scale experiments on three sets of TREC's Ad Hoc Test Collections, namely TREC-6, TREC-7, and TREC-8.", "labels": [], "entities": [{"text": "TREC's Ad Hoc Test Collections", "start_pos": 83, "end_pos": 113, "type": "DATASET", "confidence": 0.8189444243907928}, {"text": "TREC-6", "start_pos": 122, "end_pos": 128, "type": "DATASET", "confidence": 0.751842200756073}, {"text": "TREC-7", "start_pos": 130, "end_pos": 136, "type": "DATASET", "confidence": 0.6935727596282959}, {"text": "TREC-8", "start_pos": 142, "end_pos": 148, "type": "DATASET", "confidence": 0.9098286032676697}]}, {"text": "Three query sets, TREC-6 topics 301-350, TREC-7 topics 351-400, and TREC-8 topics 401-450, along with their relevance judgments have been used.", "labels": [], "entities": []}, {"text": "We only used the title field as query.", "labels": [], "entities": []}, {"text": "When performing experiments on each query set with the one-parameter and the multiparameter models, the other two query sets have been used for learning the optimal parameters.", "labels": [], "entities": []}, {"text": "For each query in the training set, we have generated document pairs for training by the following strategy: first, we have gathered top m ranked documents from retrieval results by using the word model and the one-parameter model (by manually setting \u03bb in Eq. 3 to the fixed constants, 0 and 0.1 respectively).", "labels": [], "entities": []}, {"text": "Then, we have sampled at most r relevant documents and n non-relevant documents from each one and generated document pairs from them.", "labels": [], "entities": []}, {"text": "In our experiments, m, r, and n is set to 100, 10, and 40, respectively.", "labels": [], "entities": []}, {"text": "Phrase extraction and indexing: We evaluate our proposed method on two different types of phrases: syntactic head-modifier pairs (syntactic phrases) and simple bigram phrases (statistical phrases).", "labels": [], "entities": [{"text": "Phrase extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9127936661243439}]}, {"text": "To index the syntactic phrases, we use the method proposed in () with Connexor FDG parser 3 , the syntactic parser based on the functional dependency grammar that occurred less than 10 times in the document collections were not indexed.", "labels": [], "entities": [{"text": "Connexor FDG parser 3", "start_pos": 70, "end_pos": 91, "type": "DATASET", "confidence": 0.7281692177057266}]}, {"text": "shows the experimental results of the three retrieval models on the syntactic phrase (headmodifier pair).", "labels": [], "entities": []}, {"text": "In the table, partial denotes the performance evaluated on queries containing more than one phrase that appeared in the document collection 4 ; this shows the actual performance difference between models.", "labels": [], "entities": []}, {"text": "Note that the ranking results of all retrieval models would be the same as the result of the word model if a query does not contain any phrases in the document collection, because P (q i |q hi , D) would be calculated as zero eventually.", "labels": [], "entities": []}, {"text": "As evaluation measures, we used the mean average precision (MAP), R-precision (RPrec), and precisions at top 10 ranks (P@10).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 36, "end_pos": 64, "type": "METRIC", "confidence": 0.951052318016688}, {"text": "R-precision (RPrec)", "start_pos": 66, "end_pos": 85, "type": "METRIC", "confidence": 0.9653044193983078}, {"text": "precisions", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9799740314483643}]}, {"text": "As shown in, when a syntactic phrase is used for retrieval, one-parameter model trained by gradient-descent method generally performs better than the word model, but the benefits are inconsistent; it achieves approximately 15% and 8% improvements on the partial query set of TREC-6 and 7 over the word model, but it fails to show any improvement on TREC-8 queries.", "labels": [], "entities": []}, {"text": "This maybe a natural result since the one-parameter model is very sensitive to the averaged contribution of phrases used for training.", "labels": [], "entities": []}, {"text": "Compared to the queries in TREC-6 and 7, the TREC-8 queries contain more phrases that are not effective for retrieval (i.e. ones that hurt the retrieval performance when used).", "labels": [], "entities": [{"text": "TREC-6", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.8450042605400085}]}, {"text": "This indicates that without distinguishing effective phrases from ineffective phrases for retrieval, the model trained from one training set for phrase would notwork consistently on other unseen query sets.", "labels": [], "entities": []}, {"text": "Note that the proposed model outperforms all the baselines overall query sets; this shows that differentiating relative contributions of phrases can improve the retrieval performance of the oneparameter model considerably and consistently.", "labels": [], "entities": []}, {"text": "As shown in the table, the multi-parameter model improves by approximately 18% and 12% on the TREC-6 and 7 partial query sets, and it also significantly outperforms both the word model and the one-parameter model on the TREC-8 query set.", "labels": [], "entities": [{"text": "TREC-8 query set", "start_pos": 220, "end_pos": 236, "type": "DATASET", "confidence": 0.8502840995788574}]}, {"text": "Specifically, the improvement on the TREC-8 query set shows one advantage of using our proposed method; by separating potentiallyineffective phrases and effective phrases based on the features, it not only improves the retrieval performance for each query but makes parameter learning less sensitive to the training set.", "labels": [], "entities": [{"text": "TREC-8 query set", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.7531400918960571}]}, {"text": "shows some examples demonstrating the different behaviors of the one-parameter model and the multi-parameters model.", "labels": [], "entities": []}, {"text": "On the figure, the un-dotted lines indicate the variation of average precision scores when \u03bb value in Eq.", "labels": [], "entities": [{"text": "precision scores", "start_pos": 69, "end_pos": 85, "type": "METRIC", "confidence": 0.9235906302928925}]}, {"text": "As \u03bb gets closer to 0, the ranking formula becomes equivalent to the word model.", "labels": [], "entities": []}, {"text": "As shown in the figure, the optimal point of \u03bb is quiet different from query to query.", "labels": [], "entities": []}, {"text": "For example, in cases of the query 'ferry sinking' and industrial  espionage' on the upper side, the optimal point is the value close to 0 and 1 respectively.", "labels": [], "entities": [{"text": "ferry sinking", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.6654471904039383}]}, {"text": "This means that the occurrences of the phrase 'ferry sinking' in a document is better to be less-weighted in retrieval while 'industrial espionage' should be treated as a much more important evidence than its constituent words.", "labels": [], "entities": [{"text": "ferry sinking' in a document", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.8268360396226248}]}, {"text": "Obviously, such differences are not good for one-parameter model assuming relative contributions of phrases uniformly.", "labels": [], "entities": []}, {"text": "For both opposite cases, the multi-parameter model significantly outperforms one-parameter model.", "labels": [], "entities": []}, {"text": "The two examples at the bottom of show the difficulty of optimizing phrase-based retrieval using one uniform parameter.", "labels": [], "entities": []}, {"text": "For example, the query 'declining birth rate' contains two different phrases, 'declining rate' and 'birth rate', which have potentially-different effectiveness in retrieval; the phrase 'declining rate' would not be helpful for retrieval because it is highly compositional, but the phrase 'birth rate' could be a very strong evidence for relevance since it is conventionally used as a phrase.", "labels": [], "entities": []}, {"text": "In this case, we can get only small benefit from the one-parameter model even if we find optimal \u03bb from gradient descent, because it will be just a compromised value between two different, optimized \u03bbs.", "labels": [], "entities": []}, {"text": "For such query, the multi-parameter model could be more effective than the one-parameter model by enabling to set different \u03bbs on phrases according to their predicted contributions.", "labels": [], "entities": []}, {"text": "Note that the multi-parameter model significantly outperforms the one-parameter model and all manually-set \u03bbs for the queries 'declining birth rate' and 'Amazon rain forest', which also has one effective phrase, 'rain forest', and one non-effective phrase, 'Amazon forest'.", "labels": [], "entities": []}, {"text": "Since our method is not limited to a particular type of phrases, we have also conducted experiments on statistical phrases (bigrams) with a reduced set of features directed applicable; RMO, RSO, PD 5 , DF, and CPP; the features requiring linguistic preprocessing (e.g. PPT) are not used, because it is unrealistic to use them under bigrambased retrieval setting.", "labels": [], "entities": []}, {"text": "Moreover, the feature UPD is not used in the experiments because the uncer-.", "labels": [], "entities": [{"text": "UPD", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.6545453667640686}]}, {"text": "The results of experiments using statistical phrases show that multi-parameter model yields additional performance improvement against baselines in many cases, but the benefit is insignificant and inconsistent.", "labels": [], "entities": []}, {"text": "As shown in, according to the MAP score, the multi-parameter model outperforms the one-parameter model on the TREC-7 and 8 query sets, but it performs slightly worse on the TREC-6 query set.", "labels": [], "entities": [{"text": "MAP", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.8156182169914246}, {"text": "TREC-6 query set", "start_pos": 173, "end_pos": 189, "type": "DATASET", "confidence": 0.8579619328180949}]}, {"text": "We suspect that this is because of the lack of features to distinguish an effective statistical phrases from ineffective statistical phrase.", "labels": [], "entities": []}, {"text": "In our observation, the bigram phrases also show a very similar behavior in retrieval; some of them are very effective while others can deteriorate the performance of retrieval models.", "labels": [], "entities": []}, {"text": "However, in case of using statistical phrases, the \u03bb computed by our multi-parameter model would be often similar to the one computed by the one-parameter model, when there is no sufficient evidence to differentiate a phrase.", "labels": [], "entities": []}, {"text": "Moreover, the insufficient amount of features may have caused the multi-parameter model to overfit to the training set easily.", "labels": [], "entities": []}, {"text": "The small size of training corpus could bean another reason.", "labels": [], "entities": []}, {"text": "The number of queries we used for training is less than 80 when removing a query not containing a phrase, which is definitely not a sufficient amount to learn optimal parameters.", "labels": [], "entities": []}, {"text": "However, if we recall that the multi-parameter model worked reasonably in the experiments using syntactic phrases with the same training sets, the lack of features would be a more important reason.", "labels": [], "entities": []}, {"text": "Although we have not mainly focused on features in this paper, it would be strongly necessary to find other useful features, not only for statistical phrases, but also for syntactic phrases.", "labels": [], "entities": []}, {"text": "For example, statistics from query logs and the probability of snippet containing a same phrase in a query is clicked by user could be considered as useful features.", "labels": [], "entities": []}, {"text": "Also, the size of the training data (queries) and the document collection may not be sufficient enough to conclude the effectiveness of our proposed method; our method should be examined in a larger collection with more queries.", "labels": [], "entities": []}, {"text": "Those will be one of our future works.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Retrieval performance of different models on syntactic phrases. Italicized MAP values with  symbols  \u2020 and  \u2021 indicate statistically significant improvements over the word model according to Stu- dent's t-test at p < 0.05 level and p < 0.01 level, respectively. Bold figures indicate the best performed  case for each metric.", "labels": [], "entities": [{"text": "Retrieval", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8162098526954651}, {"text": "MAP", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.7023053169250488}]}, {"text": " Table 2: Retrieval performance of different models, using statistical phrases.", "labels": [], "entities": [{"text": "Retrieval", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9541099071502686}]}]}