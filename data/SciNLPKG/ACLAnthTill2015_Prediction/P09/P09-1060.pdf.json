{"title": [{"text": "Linefeed Insertion into Japanese Spoken Monologue for Captioning", "labels": [], "entities": [{"text": "Linefeed Insertion", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7400481104850769}, {"text": "Captioning", "start_pos": 54, "end_pos": 64, "type": "TASK", "confidence": 0.8411836624145508}]}], "abstractContent": [{"text": "To support the real-time understanding of spoken monologue such as lectures and commentaries, the development of a cap-tioning system is required.", "labels": [], "entities": []}, {"text": "In monologues, since a sentence tends to belong, each sentence is often displayed in multi lines on one screen, it is necessary to insert linefeeds into a text so that the text becomes easy to read.", "labels": [], "entities": []}, {"text": "This paper proposes a technique for inserting linefeeds into a Japanese spoken monologue text as an elemental technique to generate the readable captions.", "labels": [], "entities": []}, {"text": "Our method appropriately inserts linefeeds into a sentence by machine learning, based on the information such as dependencies, clause boundaries, pauses and line length.", "labels": [], "entities": []}, {"text": "An experiment using Japanese speech data has shown the effectiveness of our technique.", "labels": [], "entities": []}], "introductionContent": [{"text": "Real-time captioning is a technique for supporting the speech understanding of deaf persons, elderly persons, or foreigners by displaying transcribed texts of monologue speech such as lectures.", "labels": [], "entities": [{"text": "Real-time captioning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7580975592136383}]}, {"text": "In recent years, there exist a lot of researches about automatic captioning, and the techniques of automatic speech recognition (ASR) aimed for captioning have been developed;;).", "labels": [], "entities": [{"text": "speech recognition (ASR)", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.8095130085945129}]}, {"text": "However, in order to generate captions which is easy to read, it is important not only to recognize speech with high recognition rate but also to properly display the transcribed text on a screen.", "labels": [], "entities": []}, {"text": "Especially, in spoken monologue, since a sentence tends to belong, each sentence is often displayed as a multi-line text on a screen.", "labels": [], "entities": []}, {"text": "Therefore, proper linefeed insertion for the displayed text is desired so that the text becomes easy to read.", "labels": [], "entities": [{"text": "linefeed insertion", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.6680610924959183}]}, {"text": "Until now, there existed few researches about how to display text on a screen in automatic captioning.", "labels": [], "entities": []}, {"text": "As the research about linefeed insertion, Monma et al. proposed a method based on patterns of a sequence of morphemes (.", "labels": [], "entities": [{"text": "linefeed insertion", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.783342033624649}]}, {"text": "However, the target of the research is closed-captions of Japanese TV shows, in which less than or equal to 2 lines text is displayed on a screen and the text all switches to other text at a time.", "labels": [], "entities": []}, {"text": "In the work, the highest priority concept on captioning is that one screen should be filled with as much text as possible.", "labels": [], "entities": []}, {"text": "Therefore, a semantic boundary in a sentence is hardly taken into account in linefeed insertion, and the readability of the caption is hardly improved.", "labels": [], "entities": [{"text": "linefeed insertion", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7047703415155411}]}, {"text": "This paper proposes a technique for inserting linefeeds into transcribed texts of Japanese monologue speech as an elemental technique to generate readable captions.", "labels": [], "entities": []}, {"text": "We assume that a screen for displaying only multi-line caption is placed to provide the caption information to the audience on the site of a lecture.", "labels": [], "entities": []}, {"text": "In our method, the linefeeds are inserted into only the boundaries between bunsetsus 1 , and the linefeeds are appropriately inserted into a sentence by machine learning, based on the information such as morphemes, dependencies 2 , clause boundaries, pauses and line length.", "labels": [], "entities": []}, {"text": "We conducted an experiment on inserting linefeeds by using Japanese spoken monologue data.", "labels": [], "entities": [{"text": "inserting linefeeds", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8718946576118469}]}, {"text": "As the results of inserting linefeeds for 1,714 sentences, the recall and precision of our method were 82.66% and 80.24%, respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9998338222503662}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.999460756778717}]}, {"text": "Our method improved the performance dramatically compared This paper is organized as follows: The next section describes our assumed caption and the preliminary analysis.", "labels": [], "entities": []}, {"text": "Section 3 presents our linefeed insertion technique.", "labels": [], "entities": [{"text": "linefeed insertion", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7930318713188171}]}, {"text": "An experiment and discussion are reported in Sections 4 and 5, respectively.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effectiveness of our method, we conducted an experiment on inserting linefeeds by using discourse speech data.", "labels": [], "entities": []}, {"text": "As the experimental data, we used the transcribed data of Japanese discourse speech in the SIDB ().", "labels": [], "entities": [{"text": "SIDB", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8344740271568298}]}, {"text": "All the data are annotated with information on morphological analysis, clause boundary detection and dependency analysis by hand.", "labels": [], "entities": [{"text": "clause boundary detection", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.7721624573071798}]}, {"text": "We performed a cross-validation experiment by using 16 discourses.", "labels": [], "entities": []}, {"text": "That is, we repeated the experiment, in which we used one discourse from among 16 discourses as the test data and the others as the learning data, 16 times.", "labels": [], "entities": []}, {"text": "However, since we used 2 discourse among 16 discourses as the preliminary analysis data, we evaluated the experimental result for the other 14 discourses.", "labels": [], "entities": []}, {"text": "Here, we used the maximum entropy method tool) with the default options except \"-i 2000.\"", "labels": [], "entities": []}, {"text": "In the evaluation, we obtained recall, precision and the ratio of sentences into which all linefeed points were correctly inserted (hereinafter called sentence accuracy).", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9996020197868347}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9996640682220459}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9425347447395325}]}, {"text": "The recall and precision are respectively defined as follows.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9995629191398621}, {"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9996469020843506}]}, {"text": "For comparison, we established the following four baseline methods.", "labels": [], "entities": []}, {"text": "1. Linefeeds are inserted into the rightmost bunsetsu boundaries among the bunsetsu boundaries into which linefeeds can be inserted so that the length of the line does not exceed the maximum number of characters (Linefeed insertion based on bunsetsu boundaries).", "labels": [], "entities": []}, {"text": "2. Linefeeds are inserted into the all clause boundaries (Linefeed insertion based on clause boundaries).", "labels": [], "entities": [{"text": "Linefeed insertion", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.6614260971546173}]}, {"text": "3. Linefeeds are inserted between adjacent bunsetsus which do not depend on each other (Linefeed insertion based on dependency relations).", "labels": [], "entities": [{"text": "Linefeed insertion", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7048161029815674}]}, {"text": "4. Linefeeds are inserted into the all bunsetsu boundaries in which a pause exists (Linefeed insertion based on pauses).", "labels": [], "entities": []}, {"text": "In the baseline 2, 3 and 4, if each condition is not fulfilled within the maximum number of characters, a linefeed is inserted into the rightmost bunsetsu boundary as well as the baseline 1.", "labels": [], "entities": []}, {"text": "In the experiment, we defined the maximum number of characters per line as 20.", "labels": [], "entities": []}, {"text": "The correct data of linefeed insertion were created by experts who were familiar with displaying captions.", "labels": [], "entities": [{"text": "linefeed insertion", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7013659924268723}]}, {"text": "There existed 5,497 inserted linefeeds in the 14 discourses, which were used in the evaluation.", "labels": [], "entities": []}, {"text": "shows the experimental results of the baselines and our method.", "labels": [], "entities": []}, {"text": "The baseline 1 is very simple method which inserts linefeeds into the bunsetsu boundaries so that the length of the line does not exceed the maximum number of characters per line.", "labels": [], "entities": []}, {"text": "Therefore, the recall and precision were the lowest.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9996380805969238}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9997243285179138}]}, {"text": "In the result of baseline 2, the precision was low.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9998289346694946}]}, {"text": "As described in the Section 3.1, the degree in which linefeeds are inserted varies in different types of clause boundaries.", "labels": [], "entities": []}, {"text": "In the baseline 2, because linefeeds are also inserted into clause boundaries which have the tendency that linefeeds are hardly inserted, the unnecessary linefeeds are considered to have been inserted.", "labels": [], "entities": []}, {"text": "The recall of baseline 3 was very high.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9995212554931641}]}, {"text": "This is because, in the correct data, linefeeds were hardly inserted between two neighboring bunsetsus which are in a dependency relation.", "labels": [], "entities": []}, {"text": "However, the precision was low, because, in the baseline 3, linefeeds are invariably inserted between two neighboring bunsetsus which are not in a dependency relation.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9997395873069763}]}, {"text": "In the baseline 4, both the recall and precision were not good.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9998440742492676}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9997996687889099}]}, {"text": "The possible reason is that the bunsetsu boundaries at which a pause exists do not necessarily correspond to the linefeed points.", "labels": [], "entities": []}, {"text": "On the other hand, the F-measure and the sentence accuracy of our method were 81.43 and 53.15%, respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9991180300712585}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9570368528366089}]}, {"text": "Both of them were highest among those of the four baseline, which showed an effectiveness of our method.", "labels": [], "entities": []}, {"text": "Insertion Result The purpose of our research is to improve the readability of the spoken monologue text by our linefeed insertion.", "labels": [], "entities": [{"text": "Insertion Result", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7261670678853989}]}, {"text": "Therefore, we conducted a subjective evaluation of the texts which were generated by the above-mentioned experiment.", "labels": [], "entities": []}, {"text": "In the subjective evaluation, examinees looked at the two texts placed side-by-side between which the only difference is linefeed points, and then se- Figure 8: Result of subjective evaluation lected the one which was felt more readable.", "labels": [], "entities": []}, {"text": "Here, we compared our method with the baseline 3, of which F-measure was highest among four baselines described in Section 5.1.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.998305082321167}]}, {"text": "Ten examinees evaluated 50 pairs of the results generated from the same 50 randomly selected sentences.", "labels": [], "entities": []}, {"text": "shows the result of subjective evaluation.", "labels": [], "entities": []}, {"text": "This graph shows the number of each method selected by each examinee.", "labels": [], "entities": []}, {"text": "The ratio that our method was selected was 94% in the highest case, and 68% even in the lowest case.", "labels": [], "entities": []}, {"text": "We confirmed the effectiveness of our method for improving the readability of the spoken monologue text.", "labels": [], "entities": []}, {"text": "On the other hand, there existed three sentences for which more than 5 examinees judged that the results of baseline 3 were more readable than those of our method.", "labels": [], "entities": []}, {"text": "From the analysis of the three sentences, we found the following phenomena caused text to be less readable \u2022 Japanese syllabary characters (Hiragana) are successionally displayed across a bunsetsu boundary.", "labels": [], "entities": []}, {"text": "\u2022 The length of anteroposterior lines is extremely different each other.", "labels": [], "entities": []}, {"text": "Each example of the two causes is shown in and 10, respectively.", "labels": [], "entities": []}, {"text": "In, a bunsetsu boundary existed between Japanese syllabary characters \" (I)\" and \" (if truth be told)\" and these characters are successionally displayed in the same line.", "labels": [], "entities": []}, {"text": "In these cases, it becomes more difficult to identify the bunsetsu boundary, therefore, the text is thought to become difficult to read.", "labels": [], "entities": []}, {"text": "In, since the length of the second line is extremely shorter than the first line or third line, the text is thought to become difficult to read.", "labels": [], "entities": []}, {"text": "Compared with, it shows the decreasing rate of the performance of our method was more than those of four baselines which use simply only basic linguistic information.", "labels": [], "entities": []}, {"text": "However, the F-measure of our method was more than 10% higher than those of four baselines.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9988816380500793}]}], "tableCaptions": [{"text": " Table 1: Size of analysis data  sentence  221  bunsetsu  2,891  character  13,899  linefeed  883  character per line  13.2", "labels": [], "entities": []}, {"text": " Table 2: Ratio of linefeed insertion for clause  boundary type", "labels": [], "entities": [{"text": "linefeed insertion", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.6724124699831009}]}, {"text": " Table 5: Experimental results when information of  features are automatically provided", "labels": [], "entities": []}]}