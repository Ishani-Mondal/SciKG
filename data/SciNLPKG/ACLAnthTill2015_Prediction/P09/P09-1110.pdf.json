{"title": [{"text": "Learning Context-Dependent Mappings from Sentences to Logical Form", "labels": [], "entities": [{"text": "Learning Context-Dependent Mappings", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6449941992759705}]}], "abstractContent": [{"text": "We consider the problem of learning context-dependent mappings from sentences to logical form.", "labels": [], "entities": []}, {"text": "The training examples are sequences of sentences annotated with lambda-calculus meaning representations.", "labels": [], "entities": []}, {"text": "We develop an algorithm that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms.", "labels": [], "entities": []}, {"text": "The method uses a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis.", "labels": [], "entities": []}, {"text": "Experiments on context-dependent utterances from the ATIS corpus show that the method recovers fully correct logical forms with 83.7% accuracy.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.9698799848556519}, {"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9974007606506348}]}], "introductionContent": [{"text": "Recently, researchers have developed algorithms that learn to map natural language sentences to representations of their underlying meaning ().", "labels": [], "entities": []}, {"text": "For instance, a training example might be: Here the logical form (LF) is a lambda-calculus expression defining a set of entities that are flights to Boston departing on Friday night.", "labels": [], "entities": []}, {"text": "Most of this work has focused on analyzing sentences in isolation.", "labels": [], "entities": []}, {"text": "In this paper, we consider the problem of learning to interpret sentences whose underlying meanings can depend on the context in which they appear.", "labels": [], "entities": []}, {"text": "For example, consider an interaction where Sent.", "labels": [], "entities": []}, {"text": "1 is followed by the sentence: Sent.", "labels": [], "entities": [{"text": "Sent.", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.9469942450523376}]}, {"text": "2: Show me the flights after 3pm.", "labels": [], "entities": []}, {"text": "LF 2: \u03bbx.f light(x) \u2227 to(x, bos) \u2227day(x, f ri) \u2227 depart(x) > 1500 In this case, the fact that Sent.", "labels": [], "entities": [{"text": "depart", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.961497962474823}]}, {"text": "2 describes flights to Boston on Friday must be determined based on the context established by the first sentence.", "labels": [], "entities": []}, {"text": "We introduce a supervised, hidden-variable approach for learning to interpret sentences in context.", "labels": [], "entities": []}, {"text": "Each training example is a sequence of sentences annotated with logical forms.", "labels": [], "entities": []}, {"text": "shows excerpts from three training examples in the ATIS corpus.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.9300325810909271}]}, {"text": "For context-dependent analysis, we develop an approach that maintains explicit, lambda-calculus representations of salient discourse entities and uses a two-stage pipeline to construct contextdependent logical forms.", "labels": [], "entities": [{"text": "context-dependent analysis", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.7207134962081909}]}, {"text": "The first stage uses a probabilistic Combinatory Categorial Grammar (CCG) parsing algorithm to produce a contextindependent, underspecified meaning representation.", "labels": [], "entities": [{"text": "probabilistic Combinatory Categorial Grammar (CCG) parsing", "start_pos": 23, "end_pos": 81, "type": "TASK", "confidence": 0.7053833976387978}]}, {"text": "The second stage resolves this underspecified meaning representation by making a sequence of modifications to it that depend on the context provided by previous utterances.", "labels": [], "entities": []}, {"text": "In general, there area large number of possible context-dependent analyses for each sentence.", "labels": [], "entities": []}, {"text": "To select the best one, we present a weighted linear model that is used to make a range of parsing and context-resolution decisions.", "labels": [], "entities": [{"text": "parsing", "start_pos": 91, "end_pos": 98, "type": "TASK", "confidence": 0.9645232558250427}]}, {"text": "Since the training data contains only the final logical forms, we model these intermediate decisions as hidden variables that must be estimated without explicit supervision.", "labels": [], "entities": []}, {"text": "We show that this model can be effectively trained with a hidden-variable variant of the perceptron algorithm.", "labels": [], "entities": []}, {"text": "In experiments on the ATIS DEC94 test set, the approach recovers fully correct logical forms with 83.7% accuracy.", "labels": [], "entities": [{"text": "ATIS DEC94 test set", "start_pos": 22, "end_pos": 41, "type": "DATASET", "confidence": 0.9599337428808212}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9979069232940674}]}], "datasetContent": [{"text": "Data In this section, we present experiments in the context-dependent ATIS domain (.", "labels": [], "entities": []}, {"text": "presents statistics for the training, development, and test sets.", "labels": [], "entities": []}, {"text": "To facilitate comparison with previous work, we used the standard DEC94 test set.", "labels": [], "entities": [{"text": "DEC94 test set", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.9905023177464803}]}, {"text": "We randomly split the remaining data to make training and development sets.", "labels": [], "entities": []}, {"text": "We manually converted the original SQL meaning annotations to lambda-calculus expressions.", "labels": [], "entities": []}, {"text": "Evaluation Metrics report accuracy rates for recovering correct SQL annotations on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9991806149482727}]}, {"text": "For comparison, we report exact accuracy rates for recovering completely correct lambda-calculus expressions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9983127117156982}]}, {"text": "We also present precision, recall and F-measure for partial match results that test if individual attributes, such as the from and to cities, are correctly assigned.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9997108578681946}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9996863603591919}, {"text": "F-measure", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.999624490737915}]}, {"text": "See the discussion by for the full details.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the ATIS training, development and", "labels": [], "entities": [{"text": "ATIS training", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.4044322818517685}]}, {"text": " Table 2: Performance on the ATIS DEC94 test set.", "labels": [], "entities": [{"text": "ATIS DEC94 test set", "start_pos": 29, "end_pos": 48, "type": "DATASET", "confidence": 0.9382937848567963}]}, {"text": " Table 3: Performance on the ATIS development set for", "labels": [], "entities": [{"text": "ATIS development set", "start_pos": 29, "end_pos": 49, "type": "DATASET", "confidence": 0.9454289674758911}]}]}