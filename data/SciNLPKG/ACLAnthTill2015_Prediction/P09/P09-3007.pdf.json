{"title": [{"text": "Accurate Learning for Chinese Function Tags from Minimal Features", "labels": [], "entities": [{"text": "Accurate", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.963668704032898}, {"text": "Chinese Function Tags", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.5478643774986267}]}], "abstractContent": [{"text": "Data-driven function tag assignment has been studied for English using Penn Tree-bank data.", "labels": [], "entities": [{"text": "Data-driven function tag assignment", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6412224844098091}, {"text": "Penn Tree-bank data", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.9941737254460653}]}, {"text": "In this paper, we address the question of whether such method can be applied to other languages and Tree-bank resources.", "labels": [], "entities": []}, {"text": "In addition to simply extend previous method from English to Chinese, we also proposed an effective way to recognize function tags directly from lexical information, which is easily scalable for languages that lack sufficient parsing resources or have inherent linguistic challenges for parsing.", "labels": [], "entities": []}, {"text": "We investigated a supervised sequence learning method to automatically recognize function tags, which achieves an F-score of 0.938 on gold-standard POS (Part-of-Speech) tagged Chinese text-a statistically significant improvement over existing Chinese function label assignment systems.", "labels": [], "entities": [{"text": "F-score", "start_pos": 114, "end_pos": 121, "type": "METRIC", "confidence": 0.9991158843040466}]}, {"text": "Results show that a small number of linguistically motivated lexical features are sufficient to achieve comparable performance to systems using sophisticated parse trees.", "labels": [], "entities": []}], "introductionContent": [{"text": "Function tags, such as subject, object, time, location, etc. are conceptually appealing by encoding an event in the format of \"who did what to whom, where, when\", which provides useful semantic information of the sentences.", "labels": [], "entities": []}, {"text": "Lexical semantic resources such as Penn Treebank have been annotated with phrase tree structures and function tags.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.9963280856609344}]}, {"text": "shows the parse tree with function tags fora sample sentence form the Penn Chinese Treebank 5.0 1 () (file 0043.fid).", "labels": [], "entities": [{"text": "Penn Chinese Treebank 5.0 1", "start_pos": 70, "end_pos": 97, "type": "DATASET", "confidence": 0.98774254322052}]}, {"text": "When dealing with the task of function tag assignment (or function labeling thereafter), one basic question that must be addressed is what features can be extracted in practice for distinguishing different function tag types.", "labels": [], "entities": [{"text": "function tag assignment", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7465341289838155}, {"text": "function labeling", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.6928080171346664}]}, {"text": "In answering this question, several pieces of work) have already been proposed.) described a statistical system trained on the data of Penn Treebank to automatically assign function tags for English text.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 135, "end_pos": 148, "type": "DATASET", "confidence": 0.9854300022125244}]}, {"text": "The system first passed sentences through an automatic parser, then extracted features from the parse trees and predicted the most plausible function label of constituent from these features.", "labels": [], "entities": []}, {"text": "Noting that parsing errors are difficult or even impossible to recover at function tag recognition stage, the alternative approaches are obtained by assigning function tags at the same time as producing parse trees), through learning deeper syntactic properties such as finergrained labels, features from the nodes to the left of the current node.", "labels": [], "entities": [{"text": "parsing", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.9771290421485901}, {"text": "function tag recognition", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.6398416459560394}]}, {"text": "Through all that research, however, successfully addressing function labeling requires accurate parsing model and training data, and the re-sults of them show that the performance ceiling of function labeling is limited by the parsers they used.", "labels": [], "entities": [{"text": "function labeling", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7751157283782959}, {"text": "function labeling", "start_pos": 191, "end_pos": 208, "type": "TASK", "confidence": 0.7149096727371216}]}, {"text": "Given the imperfection of existing automatic parsers, which are far from producing gold-standard results, function tags output by such models cannot be satisfactory for practical use.", "labels": [], "entities": []}, {"text": "The limitation is even more pertinent for the languages that do not have sophisticated parsing resources, or languages that have inherent linguistic challenges for parsing (like Chinese).", "labels": [], "entities": [{"text": "parsing", "start_pos": 164, "end_pos": 171, "type": "TASK", "confidence": 0.9673405289649963}]}, {"text": "It is therefore worthwhile to investigate alternatives to function labeling for languages under the parsing bottleneck, both in terms of features used and effective learning algorithms.", "labels": [], "entities": [{"text": "function labeling", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7126173824071884}]}, {"text": "In current study, we focused on the use of parser-independent features for function labeling.", "labels": [], "entities": [{"text": "function labeling", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7012742161750793}]}, {"text": "Specifically, our proposal is to classify function types directly from lexical features like words and their POS tags and the surface sentence information like the word position.", "labels": [], "entities": []}, {"text": "The hypothesis that underlies our proposal is that lexical features are informative for different function types, and capture fundamental properties of the semantics that sometimes cannot be concluded from the glance of parse structure.", "labels": [], "entities": []}, {"text": "Such cases come when distinguishing phrases of the same structure that differ by just one word -for instance, telling \" (in Shanghai)\", which is locative, from \" (in May)\", which is temporal.", "labels": [], "entities": [{"text": "telling \" (in Shanghai)\"", "start_pos": 110, "end_pos": 134, "type": "TASK", "confidence": 0.8123705983161926}]}, {"text": "At a high level, we can say that class-based differences in function labels are reflected in statistics over the lexical features in large-scale annotated corpus, and that such knowledge can be encoded by learning algorithms.", "labels": [], "entities": []}, {"text": "By exploiting lexical information collected from Penn Chinese Treebank (CTB) (), we investigate a supervised sequence learning model to test our core hypothesis -that function tags could be guessed precisely through informative lexical features and effective learning methods.", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB)", "start_pos": 49, "end_pos": 76, "type": "DATASET", "confidence": 0.9784783919652303}]}, {"text": "At the end of this paper, we extend previous function labeling methods from English to Chinese.", "labels": [], "entities": []}, {"text": "The result proves, at least for Chinese language, our proposed method outperforms previous ones that utilize sophisticated parse trees.", "labels": [], "entities": []}, {"text": "In section 2 we will introduce the CTB resources and function tags used in our study.", "labels": [], "entities": []}, {"text": "In section 3, we will describe the sequence learning algorithm in the framework of maximum margin learning, showing how to approximate function tagging by simple lexical statistics.", "labels": [], "entities": [{"text": "sequence learning", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.792276918888092}, {"text": "function tagging", "start_pos": 135, "end_pos": 151, "type": "TASK", "confidence": 0.7231775224208832}]}, {"text": "Section 4 gives a detailed discussion of our experiment and comparison with pieces of related work.", "labels": [], "entities": []}, {"text": "Some final remarks will be given in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we turn to our computational experiments that investigate whether the statistical indicators of lexical properties that we have developed can in fact be used to classify function labels, and demonstrate which kind of feature contributes most in identifying function types, at least for Chinese text.", "labels": [], "entities": []}, {"text": "As in the work of, each word or punctuation mark within a sentence is labeled with \"IOB\" tag together with its function type.", "labels": [], "entities": []}, {"text": "The three tags are sufficient for encoding all constituents since there are no overlaps among different function chunks.", "labels": [], "entities": []}, {"text": "The function tags in this paper are limited to 20 types, resulting in a total of |\u03a3| = 41 different outputs.", "labels": [], "entities": []}, {"text": "We use three measures to evaluate the model performance: precision, which is the percentage of detected chunks that are correct; recall, which is the percentage of chunks in the data that are found by the tagger; and F-score which is equal to 2\u00d7precision\u00d7recall/(precision+recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9994463324546814}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9993799924850464}, {"text": "F-score", "start_pos": 217, "end_pos": 224, "type": "METRIC", "confidence": 0.9989578723907471}, {"text": "precision", "start_pos": 245, "end_pos": 254, "type": "METRIC", "confidence": 0.9596779346466064}, {"text": "recall", "start_pos": 255, "end_pos": 261, "type": "METRIC", "confidence": 0.6296678781509399}, {"text": "precision+recall", "start_pos": 263, "end_pos": 279, "type": "METRIC", "confidence": 0.7425747315088908}]}, {"text": "Under the \"IOB\" tagging scheme, a function chunk is only counted as correct when its boundaries and its type are both identified correctly.", "labels": [], "entities": [{"text": "IOB\" tagging", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.7172411680221558}]}, {"text": "Furthermore, sentence accuracy is used in order to observe the prediction correctness of sentences, which is defined as the percentage of sentences within which all the constituents are assigned with correct tags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.98579341173172}]}, {"text": "As in the work of and), to avoid calculating excessively optimistic values, constituents bearing the \"O\" label are not counted in for computing overall precision, recall and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9937813878059387}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9995998740196228}, {"text": "F-score", "start_pos": 174, "end_pos": 181, "type": "METRIC", "confidence": 0.9975271821022034}]}, {"text": "We derived 18,782 sentences from CTB 5.0 with about 497 thousands of words (including punctuation marks).", "labels": [], "entities": [{"text": "CTB 5.0", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9357280433177948}]}, {"text": "On average, each sentence contains 26.5 words with 2.4 verbs.", "labels": [], "entities": []}, {"text": "We followed 5-fold cross-validation method in our experiment.", "labels": [], "entities": []}, {"text": "The numbers reported are the averages of the results across the five test sets.", "labels": [], "entities": []}, {"text": "In pilot experiments on a subset of the features, we provide a comparison of HM-SVM with other two learning models, maximum entropy (MaxEnt) model and SVM model, to test the effectiveness of HM-SVM on function labeling task, as well as the generality of our hypothesis on different learning In our experiment, SVMs and HM-SVM training are carried outwith SVM struct packages 4 . The multi-class SVMs model is realized by extending binary SVMs using pairwise strategy.", "labels": [], "entities": []}, {"text": "We used a first-order of transition and emission dependency in HM-SVM.", "labels": [], "entities": []}, {"text": "Both SVMs and HM-SVM are trained with the linear kernel function and the soft margin parameter c is set to be 1.", "labels": [], "entities": [{"text": "soft margin parameter c", "start_pos": 73, "end_pos": 96, "type": "METRIC", "confidence": 0.7615523338317871}]}, {"text": "The MaxEnt model is implemented based on Zhang's MaxEnt toolkit and L-BFGS) method to perform parameter estimation.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.6360432505607605}]}, {"text": "We use sentence accuracy to compare performances of three models with different feature combinations shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.954201340675354}]}, {"text": "The learning curves in illustrate feature combination FT7 gains the best results for all three models we considered.", "labels": [], "entities": [{"text": "FT7", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8398296236991882}]}, {"text": "As we have expected, the performance improves as the context window expanded from 2 to 4 (from FT1 to FT3 in).", "labels": [], "entities": [{"text": "FT1", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.8703052997589111}, {"text": "FT3", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.6903841495513916}]}, {"text": "The sentence accuracy increases significantly when the features include verbs and position indicators, giv-ing some indication of the complexity of the structure intervening between focus word and the verb.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9910071492195129}]}, {"text": "However, at a high level, we can simply say that any further information would help for identifying function types, so we believe that the features we deliberated on currently are by no means the solely optimal feature set.", "labels": [], "entities": []}, {"text": "As observed in, the structural sequence model HM-SVM outperforms multi-class SVMs, meanwhile, they both perform slightly better than MaxEnt model, demonstrating the benefit of maximum margin based approach.", "labels": [], "entities": []}, {"text": "In the experiment below, we will use feature FT7 and HM-SVM model to illustrate our method.", "labels": [], "entities": [{"text": "FT7", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.5749742388725281}]}], "tableCaptions": [{"text": " Table 2: Categories of function tags with their rel- ative frequencies and average length.", "labels": [], "entities": []}, {"text": " Table 4: Average performance for individual cat- egories, using HM-SVM model with feature FT7  and gold-standard POS tags.", "labels": [], "entities": [{"text": "FT7", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.5235083699226379}]}, {"text": " Table 5: Performance separated for grammatical  roles and adverbials, of our models GoldPOS (us- ing gold-standard POS tags), GoldPARSE (using  gold-standard parse trees), AutoPOS (using auto- matically labeled POS tags).", "labels": [], "entities": [{"text": "GoldPOS", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.9217523336410522}, {"text": "GoldPARSE", "start_pos": 127, "end_pos": 136, "type": "DATASET", "confidence": 0.8981646299362183}]}]}