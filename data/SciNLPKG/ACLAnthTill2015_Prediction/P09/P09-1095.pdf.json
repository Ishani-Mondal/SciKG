{"title": [{"text": "Semi-Supervised Cause Identification from Aviation Safety Reports", "labels": [], "entities": [{"text": "Cause Identification", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8017261624336243}, {"text": "Aviation Safety Reports", "start_pos": 42, "end_pos": 65, "type": "DATASET", "confidence": 0.6713009476661682}]}], "abstractContent": [{"text": "We introduce cause identification, anew problem involving classification of incident reports in the aviation domain.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7972219288349152}, {"text": "classification of incident reports", "start_pos": 58, "end_pos": 92, "type": "TASK", "confidence": 0.8504678457975388}]}, {"text": "Specifically, given a set of pre-defined causes, a cause identification system seeks to identify all and only those causes that can explain why the aviation incident described in a given report occurred.", "labels": [], "entities": []}, {"text": "The difficulty of cause identification stems in part from the fact that it is a multi-class, multi-label categorization task, and in part from the skewness of the class distributions and the scarcity of annotated reports.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 18, "end_pos": 38, "type": "TASK", "confidence": 0.7108548879623413}]}, {"text": "To improve the performance of a cause identification system for the minority classes, we present a bootstrapping algorithm that automatically augments a training set by learning from a small amount of labeled data and a large amount of unlabeled data.", "labels": [], "entities": []}, {"text": "Experimental results show that our algorithm yields a relative error reduction of 6.3% in F-measure for the minority classes in comparison to a baseline that learns solely from the labeled data.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 54, "end_pos": 78, "type": "METRIC", "confidence": 0.6969793836275736}, {"text": "F-measure", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9972578883171082}]}], "introductionContent": [{"text": "Automatic text classification is one of the most important applications in natural language processing (NLP).", "labels": [], "entities": [{"text": "Automatic text classification", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7337153752644857}, {"text": "natural language processing (NLP)", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.8179597655932108}]}, {"text": "The difficulty of a text classification task depends on various factors, but typically, the task can be difficult if (1) the amount of labeled data available for learning the task is small; (2) it involves multiple classes; (3) it involves multilabel categorization, where more than one label can be assigned to each document; (4) the class distributions are skewed, with some categories significantly outnumbering the others; and (5) the documents belong to the same domain (e.g., movie review classification).", "labels": [], "entities": [{"text": "text classification task", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.796489417552948}, {"text": "movie review classification)", "start_pos": 482, "end_pos": 510, "type": "TASK", "confidence": 0.6960809156298637}]}, {"text": "In particular, when the documents to be classified are from the same domain, they tend to be more similar to each other with respect to word usage, thus making the classes less easily separable.", "labels": [], "entities": []}, {"text": "This is one of the reasons why topic-based classification, even with multiple classes as in the 20 Newsgroups dataset 1 , tends to be easier than review classification, where reviews from the same domain are to be classified according to the sentiment expressed 2 . In this paper, we introduce anew text classification problem involving the Aviation Safety Reporting System (ASRS) that can be viewed as a difficult task along each of the five dimensions discussed above.", "labels": [], "entities": [{"text": "topic-based classification", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.7380799949169159}, {"text": "20 Newsgroups dataset 1", "start_pos": 96, "end_pos": 119, "type": "DATASET", "confidence": 0.7901483923196793}, {"text": "review classification", "start_pos": 146, "end_pos": 167, "type": "TASK", "confidence": 0.7494614124298096}, {"text": "text classification", "start_pos": 299, "end_pos": 318, "type": "TASK", "confidence": 0.7239540815353394}, {"text": "Aviation Safety Reporting System (ASRS)", "start_pos": 341, "end_pos": 380, "type": "TASK", "confidence": 0.6225542511258807}]}, {"text": "Established in 1967, ASRS collects voluntarily submitted reports about aviation safety incidents written by flight crews, attendants, controllers, and other related parties.", "labels": [], "entities": [{"text": "ASRS collects voluntarily submitted reports about aviation safety incidents written by flight crews, attendants, controllers", "start_pos": 21, "end_pos": 145, "type": "TASK", "confidence": 0.8565793949015}]}, {"text": "These incident reports are made publicly available to researchers for automatic analysis, with the ultimate goal of improving the aviation safety situation.", "labels": [], "entities": [{"text": "automatic analysis", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.6122345626354218}]}, {"text": "One central task in the automatic analysis of these reports is cause identification, or the identification of why an incident happened.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.6882553994655609}, {"text": "identification of why an incident", "start_pos": 92, "end_pos": 125, "type": "TASK", "confidence": 0.8199475526809692}]}, {"text": "Aviation safety experts at NASA have identified 14 causes (or shaping factors in NASA terminology) that could explain why an incident occurred.", "labels": [], "entities": []}, {"text": "Hence, cause identification can be naturally recast as a text classification task: given an incident report, determine which of a set of 14 shapers contributed to the occurrence of the incident described in the report.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.9088793098926544}, {"text": "text classification", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7164756953716278}]}, {"text": "As mentioned above, cause identification is considered challenging along each of the five aforementioned dimensions.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.8934045732021332}]}, {"text": "First, there is a scarcity of incident reports labeled with the shapers.", "labels": [], "entities": []}, {"text": "This can be attributed to the fact that there has been very little work on this task.", "labels": [], "entities": []}, {"text": "While the NASA researchers have applied a heuristic method for labeling a report with shapers), the method was evaluated on only 20 manually labeled reports, which are not made publicly available.", "labels": [], "entities": []}, {"text": "Second, the fact that this is a 14-class classification problem makes it more challenging than a binary classification problem.", "labels": [], "entities": [{"text": "14-class classification", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.6493866443634033}]}, {"text": "Third, a report can be labeled with more than one category, as several shapers can contribute to the occurrence of an aviation incident.", "labels": [], "entities": []}, {"text": "Fourth, the class distribution is very skewed: based on an analysis of our 1,333 annotated reports, 10 of the 14 categories can be considered minority classes, which account for only 26% of the total number of labels associated with the reports.", "labels": [], "entities": []}, {"text": "Finally, our cause identification task is domain-specific, involving the classification of documents that all belong to the aviation domain.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8053521513938904}]}, {"text": "This paper focuses on improving the accuracy of minority class prediction for cause identification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9991660118103027}, {"text": "cause identification", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7935625910758972}]}, {"text": "Not surprisingly, when trained on a dataset with a skewed class distribution, most supervised machine learning algorithms will exhibit good performance on the majority classes, but relatively poor performance on the minority classes.", "labels": [], "entities": []}, {"text": "Unfortunately, achieving good accuracies on the minority classes is very important in our task of identifying shapers from aviation safety reports, where 10 out of the 14 shapers are minority classes, as mentioned above.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9728497266769409}, {"text": "identifying shapers from aviation safety", "start_pos": 98, "end_pos": 138, "type": "TASK", "confidence": 0.7567578077316284}]}, {"text": "Minority class prediction has been tackled extensively in the machine learning literature, using methods that typically involve sampling and re-weighting of training instances, with the goal of creating a less skewed class distribution (e.g.,,,).", "labels": [], "entities": [{"text": "Minority class prediction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.71906445423762}]}, {"text": "Such methods, however, are unlikely to perform equally well for our cause identification task given our small labeled set, as the minority class prediction problem is complicated by the scarcity of labeled data.", "labels": [], "entities": [{"text": "cause identification task", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.7899530132611593}, {"text": "minority class prediction", "start_pos": 130, "end_pos": 155, "type": "TASK", "confidence": 0.6254625817139944}]}, {"text": "More specifically, given the scarcity of labeled data, many words that are potentially correlated with a shaper (especially a minority shaper) may not appear in the training set, and the lack of such useful indicators could hamper the acquisition of an accurate classifier via supervised learning techniques.", "labels": [], "entities": []}, {"text": "We propose to address the problem of minority class prediction in the presence of a small training set by means of a bootstrapping approach, where we introduce an iterative algorithm to (1) use a small set of labeled reports and a large set of unlabeled reports to automatically identify words that are most relevant to the minority shaper under consideration, and (2) augment the labeled data by using the resulting words to annotate those unlabeled reports that can be confidently labeled.", "labels": [], "entities": [{"text": "minority class prediction", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.645668645699819}]}, {"text": "We evaluate our approach using cross-validation on 1,333 manually annotated reports.", "labels": [], "entities": []}, {"text": "In comparison to a supervised baseline approach where a classifier is acquired solely based on the training set, our bootstrapping approach yields a relative error reduction of 6.3% in F-measure for the minority classes.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 185, "end_pos": 194, "type": "METRIC", "confidence": 0.9945659637451172}]}, {"text": "In sum, the contributions of our work are threefold.", "labels": [], "entities": []}, {"text": "First, we introduce anew, challenging text classification problem, cause identification from aviation safety reports, to the NLP community.", "labels": [], "entities": [{"text": "text classification", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7313571870326996}]}, {"text": "Second, we created an annotated dataset for cause identification that is made publicly available for stimulating further research on this problem 3 . Third, we introduce a bootstrapping algorithm for improving the prediction of minority classes in the presence of a small training set.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.733643040060997}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the 14 shapers.", "labels": [], "entities": []}, {"text": "Section 3 explains how we preprocess and annotate the reports.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 describe the baseline approaches and our bootstrapping algorithm, respectively.", "labels": [], "entities": []}, {"text": "We present results in Section 6, discuss related work in Section 7, and conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We downloaded our corpus from the ASRS website . The corpus consists of 140,599 incident reports collected during the period from January 1998 to December 2007.", "labels": [], "entities": [{"text": "ASRS website", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9225339293479919}]}, {"text": "Each report is a free text narrative that describes not only why an incident happened, but also what happened, where it happened, how the reporter felt about the incident, the reporter's opinions of other people involved in the incident, and any other comments the reporter cared to include.", "labels": [], "entities": []}, {"text": "In other words, a lot of information in the report is irrelevant to (and thus complicates) the task of cause identification.", "labels": [], "entities": [{"text": "cause identification", "start_pos": 103, "end_pos": 123, "type": "TASK", "confidence": 0.7815408408641815}]}], "tableCaptions": [{"text": " Table 2: Number of occurrences of each shaping  factor in the dataset. The \"Total\" column shows the num-", "labels": [], "entities": []}, {"text": " Table 3: Percentage of documents with x labels.", "labels": [], "entities": []}, {"text": " Table 4: 5-fold cross validation results.", "labels": [], "entities": []}]}