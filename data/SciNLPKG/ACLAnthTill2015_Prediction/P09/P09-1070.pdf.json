{"title": [{"text": "Latent Variable Models of Concept-Attribute Attachment", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a set of Bayesian methods for automatically extending the WORDNET ontology with new concepts and annotating existing concepts with generic property fields, or attributes.", "labels": [], "entities": []}, {"text": "We base our approach on Latent Dirichlet Allocation and evaluate along two dimensions: (1) the precision of the ranked lists of attributes, and (2) the quality of the attribute assignments to WORDNET concepts.", "labels": [], "entities": [{"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9989756345748901}]}, {"text": "In all cases we find that the principled LDA-based approaches outper-form previously proposed heuristic methods , greatly improving the specificity of attributes at each concept.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present a Bayesian approach for simultaneously extending Is-A hierarchies such as those found in WORDNET (WN)) with additional concepts, and annotating the resulting concept graph with attributes, i.e., generic property fields shared by instances of that concept.", "labels": [], "entities": []}, {"text": "Examples of attributes include \"height\" and \"eyecolor\" for the concept Person or \"gdp\" and \"president\" for Country.", "labels": [], "entities": []}, {"text": "Identifying and extracting such attributes relative to a set of flat (i.e., nonhierarchically organized) labeled classes of instances has been extensively studied, using a variety of data, e.g., Web search query logs), Web documents (, and Wikipedia (.", "labels": [], "entities": [{"text": "Identifying and extracting such attributes relative to a set of flat (i.e., nonhierarchically organized) labeled classes of instances", "start_pos": 0, "end_pos": 133, "type": "Description", "confidence": 0.777837648278191}]}, {"text": "Building on the current state of the art in attribute extraction, we propose a model-based approach for mapping flat sets of attributes annotated with class labels into an existing ontology.", "labels": [], "entities": [{"text": "attribute extraction", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.7269788980484009}]}, {"text": "This inference problem is divided into two main components: (1) identifying the appropriate parent concept for each labeled class and (2) learning * Contributions made during an internship at Google.", "labels": [], "entities": []}, {"text": "the correct level of abstraction for each attribute in the extended ontology.", "labels": [], "entities": []}, {"text": "For example, consider the task of annotating WN with the labeled class renaissance painters containing the class instances Pisanello, Hieronymus Bosch, and Jan van Eyck and associated with the attributes \"famous works\" and \"style.\"", "labels": [], "entities": [{"text": "WN", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.6820405721664429}]}, {"text": "Since there is no WN concept for renaissance painters, the latter would need to be mapped into WN under, e.g., Painter.", "labels": [], "entities": [{"text": "Painter", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9489301443099976}]}, {"text": "Furthermore, since \"famous works\" and \"style\" are not specific to renaissance painters (or even the WN concept Painter), they should be placed at the most appropriate level of abstraction, e.g., Artist.", "labels": [], "entities": [{"text": "WN concept Painter", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.7905895113945007}]}, {"text": "In this paper, we show that both of these goals can be realized jointly using a probabilistic topic model, namely hierarchical Latent Dirichlet Allocation (LDA) (.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 127, "end_pos": 160, "type": "METRIC", "confidence": 0.7965859125057856}]}, {"text": "There are three main advantages to using a topic model as the annotation procedure: (1) Unlike hierarchical clustering (), the attribute distribution at a concept node is not composed of the distributions of its children; attributes found specific to the concept Painter would not need to appear in the distribution of attributes for Person, making the internal distributions at each concept more meaningful as attributes specific to that concept; (2) Since LDA is fully Bayesian, its model semantics allow additional prior information to be included, unlike standard models such as Latent Semantic Analysis, improving annotation precision; (3) Attributes with multiple related meanings (i.e., polysemous attributes) are modeled implicitly: if an attribute (e.g., \"style\") occurs in two separate input classes (e.g., poets and car models), then that attribute might attach at two different concepts in the ontology, which is better than attaching it at their most specific common ancestor (Whole) if that ancestor is too general to be useful.", "labels": [], "entities": []}, {"text": "However, there is also a pressure for these two occurrences to attach to a single concept.", "labels": [], "entities": []}, {"text": "We use WORDNET 3.0 as the specific test ontology for our annotation procedure, and evalu-anticancer drugs: mechanism of action, uses, extravasation, solubility, contraindications, side effects, chemistry, molecular weight, history, mode of action bollywood actors: biography, filmography, age, biodata, height, profile, autobiography, new wallpapers, latest photos, family pictures citrus fruits: nutrition, health benefits, nutritional value, nutritional information, calories, nutrition facts, history european countries: population, flag, climate, president, economy, geography, currency, population density, topography, vegetation, religion, natural resources london boroughs: population, taxis, local newspapers, mp, lb, street map, renault connexions, local history microorganisms: cell structure, taxonomy, life cycle, reproduction, colony morphology, scientific name, virulence factors, gram stain, clipart renaissance painters: early life, bibliography, short biography, the david, bio, painting, techniques, homosexuality, birthplace, anatomical drawings, famous paintings: Examples of labeled attribute sets extracted using the method from).", "labels": [], "entities": []}, {"text": "ate three variants: (1) a fixed structure approach where each flat class is attached to WN using a simple string-matching heuristic, and concept nodes are annotated using LDA, (2) an extension of LDA allowing for sense selection in addition to annotation, and (3) an approach employing a nonparametric prior over tree structures capable of inferring arbitrary ontologies.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: \u00a72 describes the full ontology annotation framework, \u00a73 introduces the LDA-based topic models, \u00a74 gives the experimental setup, \u00a75 gives results, \u00a76 gives related work and \u00a77 concludes.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision at n and mean-average preci- sion for all models and data sets. Inset plots show  log-likelihood of each Gibbs sample, indicating  convergence except in the case of nCRP.  \u2020 indi- cates models that do not generate annotated con- cepts corresponding to WN nodes and hence have  no per-node scores.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9975888729095459}]}]}