{"title": [{"text": "Extending a Surface Realizer to Generate Coherent Discourse", "labels": [], "entities": [{"text": "Extending a Surface Realizer", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7848138213157654}]}], "abstractContent": [{"text": "We present a discourse-level Tree Adjoining Grammar which tightly integrates syntax and discourse levels, including a representation for discourse entities.", "labels": [], "entities": []}, {"text": "We show that this technique makes it possible to extend an optimisation algorithm used in natural language generation (polarity filtering) to the discourse level.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.7348708907763163}]}, {"text": "We implemented the grammar in a surface realizer and show that this technique can be used to reduce the search space by filtering out referentially incoherent solutions.", "labels": [], "entities": []}], "introductionContent": [{"text": "A fundamental problem that microplanners and surface realizers face in natural language generation is how to restrict the search space of possible solutions.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.7135801911354065}]}, {"text": "A traditional solution to this computational complexity problem is to divide the generation process into tractable sub-problems, each represented as a module in a pipeline, where every decision made by a module restricts the number of options available to others further down the line.", "labels": [], "entities": []}, {"text": "Though such pipeline architectures are computationally efficient, they severely restrict the flexibility of the system and the quality of the generated output.", "labels": [], "entities": []}, {"text": "Most systems with pipeline architectures generate relatively simple, domain-specific output.", "labels": [], "entities": []}, {"text": "Systems that produce more complex linguistic constructions typically achieve this by adding more modules to the pipeline (e.g. a revision module or aggregation).", "labels": [], "entities": []}, {"text": "Since complex linguistic constructions often require interaction between modules, adding them to the repertoire of pipelined NLG systems becomes an engineering and programming task.", "labels": [], "entities": []}, {"text": "Integrated NLG systems have a simpler architecture because they do not need to model interactions between modules.", "labels": [], "entities": []}, {"text": "However, they still face the problem of computational complexity that was originally solved by the pipeline model.", "labels": [], "entities": []}, {"text": "Strategies that have been introduced to reduce the search space in integrated systems include greedy/incremental search algorithms (, constructing a dependency graph fora flat semantic input and converting it into a derivation tree), using planning algorithms, polarity filtering ( and using underspecified g-derivation trees (G-TAG,).", "labels": [], "entities": [{"text": "polarity filtering", "start_pos": 261, "end_pos": 279, "type": "TASK", "confidence": 0.7914825677871704}]}, {"text": "Despite all these efforts, most systems still don't attempt to go above the sentence level or generate very complex sentences.", "labels": [], "entities": []}, {"text": "In this paper we present anew technique for designing an integrated grammar for natural language generation.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.6606127719084421}]}, {"text": "Using this technique it is possible to use linguistic constraints on referential coherence to automatically reduce the search space -which in turn makes it possible to generate longer and more coherent texts.", "labels": [], "entities": []}, {"text": "First we extend the grammar of a surface realizer to produce complex, multi-sentential output.", "labels": [], "entities": []}, {"text": "Then we add a representation for discourse referents to the grammar, inspired by Centering Theory's notion of a backward looking center and preferred center.", "labels": [], "entities": []}, {"text": "Having done this, we show that by integrating discourse-level representations into a syntactic grammar we can extend an optimization technique -polarity filtering) -from syntactic realization to the discourse level.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}