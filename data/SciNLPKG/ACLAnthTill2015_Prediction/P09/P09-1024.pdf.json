{"title": [{"text": "Automatically Generating Wikipedia Articles: A Structure-Aware Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we investigate an approach for creating a comprehensive tex-tual overview of a subject composed of information drawn from the Internet.", "labels": [], "entities": []}, {"text": "We use the high-level structure of human-authored texts to automatically induce a domain-specific template for the topic structure of anew overview.", "labels": [], "entities": []}, {"text": "The algorithmic innovation of our work is a method to learn topic-specific extractors for content selection jointly for the entire template.", "labels": [], "entities": []}, {"text": "We augment the standard perceptron algorithm with a global integer linear programming formulation to optimize both local fit of information into each topic and global coherence across the entire overview.", "labels": [], "entities": []}, {"text": "The results of our evaluation confirm the benefits of incorporating structural information into the content selection process.", "labels": [], "entities": [{"text": "content selection process", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.7681285838286082}]}], "introductionContent": [{"text": "In this paper, we consider the task of automatically creating a multi-paragraph overview article that provides a comprehensive summary of a subject of interest.", "labels": [], "entities": []}, {"text": "Examples of such overviews include actor biographies from IMDB and disease synopses from Wikipedia.", "labels": [], "entities": []}, {"text": "Producing these texts by hand is a labor-intensive task, especially when relevant information is scattered throughout a wide range of Internet sources.", "labels": [], "entities": []}, {"text": "Our goal is to automate this process.", "labels": [], "entities": []}, {"text": "We aim to create an overview of a subjecte.g., 3-M Syndrome -by intelligently combining relevant excerpts from across the Internet.", "labels": [], "entities": [{"text": "3-M Syndrome", "start_pos": 47, "end_pos": 59, "type": "TASK", "confidence": 0.6326919794082642}]}, {"text": "As a starting point, we can employ methods developed for multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.6228351891040802}]}, {"text": "However, our task poses additional technical challenges with respect to content planning.", "labels": [], "entities": [{"text": "content planning", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.7635275721549988}]}, {"text": "Generating a well-rounded overview article requires proactive strategies to gather relevant material, such as searching the Internet.", "labels": [], "entities": []}, {"text": "Moreover, the challenge of maintaining output readability is magnified when creating a longer document that discusses multiple topics.", "labels": [], "entities": []}, {"text": "In our approach, we explore how the highlevel structure of human-authored documents can be used to produce well-formed comprehensive overview articles.", "labels": [], "entities": []}, {"text": "We select relevant material for an article using a domain-specific automatically generated content template.", "labels": [], "entities": []}, {"text": "For example, a template for articles about diseases might contain diagnosis, causes, symptoms, and treatment.", "labels": [], "entities": []}, {"text": "Our system induces these templates by analyzing patterns in the structure of human-authored documents in the domain of interest.", "labels": [], "entities": []}, {"text": "Then, it produces anew article by selecting content from the Internet for each part of this template.", "labels": [], "entities": []}, {"text": "An example of our system's output 1 is shown in.", "labels": [], "entities": []}, {"text": "The algorithmic innovation of our work is a method for learning topic-specific extractors for content selection jointly across the entire template.", "labels": [], "entities": []}, {"text": "Learning a single topic-specific extractor can be easily achieved in a standard classification framework.", "labels": [], "entities": []}, {"text": "However, the choices for different topics in a template are mutually dependent; for example, in a multi-topic article, there is potential for redundancy across topics.", "labels": [], "entities": []}, {"text": "Simultaneously learning content selection for all topics enables us to explicitly model these inter-topic connections.", "labels": [], "entities": []}, {"text": "We formulate this task as a structured classification problem.", "labels": [], "entities": [{"text": "structured classification", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.6094317734241486}]}, {"text": "We estimate the parameters of our model using the perceptron algorithm augmented with an integer linear programming (ILP) formulation, run over a training set of example articles in the given domain.", "labels": [], "entities": []}, {"text": "The key features of this structure-aware approach are twofold: Diagnosis . .", "labels": [], "entities": []}, {"text": "No laboratories offering molecular genetic testing for prenatal diagnosis of 3-M syndrome are listed in the GeneTests Laboratory Directory.", "labels": [], "entities": [{"text": "prenatal diagnosis of 3-M syndrome", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.6859309196472168}, {"text": "GeneTests Laboratory Directory", "start_pos": 108, "end_pos": 138, "type": "DATASET", "confidence": 0.8421071370442709}]}, {"text": "However, prenatal testing maybe available for families in which the disease-causing mutations have been identified in an affected family member in a research or clinical laboratory.", "labels": [], "entities": []}, {"text": "Causes Three M syndrome is thought to be inherited as an autosomal recessive genetic trait.", "labels": [], "entities": [{"text": "Three M syndrome", "start_pos": 7, "end_pos": 23, "type": "METRIC", "confidence": 0.5409240821997324}]}, {"text": "Human traits, including the classic genetic diseases, are the product of the interaction of two genes, one received from the father and one from the mother.", "labels": [], "entities": []}, {"text": "In recessive disorders, the condition does not occur unless an individual inherits the same defective gene for the same trait from each parent.", "labels": [], "entities": []}, {"text": "Many of the symptoms and physical features associated with the disorder are apparent at birth (congenital).", "labels": [], "entities": []}, {"text": "In some cases, individuals who carry a single copy of the disease gene (heterozygotes) may exhibit mild symptoms associated with Three M syndrome.", "labels": [], "entities": [{"text": "Three M syndrome", "start_pos": 129, "end_pos": 145, "type": "TASK", "confidence": 0.5648458401362101}]}, {"text": "Genetic counseling will be of benefit for affected individuals and their families.", "labels": [], "entities": []}, {"text": "Family members of affected individuals should also receive regular clinical evaluations to detect any symptoms and physical characteristics that maybe potentially associated with Three M syndrome or heterozygosity for the disorder.", "labels": [], "entities": [{"text": "Three M syndrome", "start_pos": 179, "end_pos": 195, "type": "METRIC", "confidence": 0.6157943507035574}]}, {"text": "Other treatment for Three M syndrome is symptomatic and supportive.", "labels": [], "entities": [{"text": "Three M syndrome", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7841522296269735}]}, {"text": "Figure 1: A fragment from the automatically created article for 3-M Syndrome.", "labels": [], "entities": [{"text": "3-M Syndrome", "start_pos": 64, "end_pos": 76, "type": "TASK", "confidence": 0.5782165974378586}]}, {"text": "\u2022 Automatic template creation: Templates are automatically induced from humanauthored documents.", "labels": [], "entities": [{"text": "Automatic template creation", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.5861861109733582}]}, {"text": "This ensures that the overview article will have the breadth expected in a comprehensive summary, with content drawn from a wide variety of Internet sources.", "labels": [], "entities": [{"text": "breadth", "start_pos": 53, "end_pos": 60, "type": "METRIC", "confidence": 0.9818356037139893}]}, {"text": "\u2022 Joint parameter estimation for content selection: Parameters are learned jointly for all topics in the template.", "labels": [], "entities": [{"text": "content selection", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7189127504825592}]}, {"text": "This procedure optimizes both local relevance of information for each topic and global coherence across the entire article.", "labels": [], "entities": []}, {"text": "We evaluate our approach by creating articles in two domains: Actors and Diseases.", "labels": [], "entities": []}, {"text": "For a data set, we use Wikipedia, which contains articles similar to those we wish to produce in terms of length and breadth.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.9513545632362366}, {"text": "breadth", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.9461411833763123}]}, {"text": "An advantage of this data set is that Wikipedia articles explicitly delineate topical sections, facilitating structural analysis.", "labels": [], "entities": [{"text": "structural analysis", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.7043103724718094}]}, {"text": "The results of our evaluation confirm the benefits of structureaware content selection over approaches that do not explicitly model topical structure.", "labels": [], "entities": [{"text": "structureaware content selection", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.64077294866244}]}], "datasetContent": [{"text": "We evaluate our method by observing the quality of automatically created articles in different domains.", "labels": [], "entities": []}, {"text": "We compute the similarity of a large number of articles produced by our system and several baselines to the original human-authored articles using ROUGE, a standard metric for summary quality.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 147, "end_pos": 152, "type": "METRIC", "confidence": 0.994249701499939}]}, {"text": "In addition, we perform an analysis of ediInput: d1 . .", "labels": [], "entities": []}, {"text": "dn: A set of n documents, each containing k sections si1 . .", "labels": [], "entities": []}, {"text": "eijr: Sets of candidate excerpts for each topic tj and document di Define: Rank(eij1 . .", "labels": [], "entities": []}, {"text": "eijr, wj): As described in Section 3.2.1: Calculates scorej(e ijl ) for all excerpts for document di and topic tj, using parameters wj.", "labels": [], "entities": [{"text": "Calculates scorej(e ijl )", "start_pos": 42, "end_pos": 67, "type": "METRIC", "confidence": 0.7417161017656326}]}, {"text": "Orders the list of excerpts by scorej(e ijl ) from highest to lowest.", "labels": [], "entities": [{"text": "scorej(e ijl )", "start_pos": 31, "end_pos": 45, "type": "METRIC", "confidence": 0.7797924518585205}]}, {"text": "e ikr ): As described in Section 3.2.1: Finds the optimal selection of excerpts to form a final article, given ranked lists of excerpts for each topic t1 . .", "labels": [], "entities": []}, {"text": "t k . Returns a list of k excerpts, one for each topic.", "labels": [], "entities": []}, {"text": "\u03c6(e ijl ): Returns the feature vector representing excerpt e ijl Initialization:  tor reaction to system-produced articles submitted to Wikipedia.", "labels": [], "entities": []}, {"text": "Data For evaluation, we consider two domains: American Film Actors and Diseases.", "labels": [], "entities": [{"text": "American Film Actors", "start_pos": 46, "end_pos": 66, "type": "DATASET", "confidence": 0.7675517797470093}]}, {"text": "These domains have been commonly used in prior work on summarization (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.9911325573921204}]}, {"text": "Our text corpus consists of articles drawn from the corresponding categories in Wikipedia.", "labels": [], "entities": []}, {"text": "There are 2,150 articles in American Film Actors and 523 articles in Diseases.", "labels": [], "entities": [{"text": "American Film Actors", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7156760692596436}]}, {"text": "For each domain, we randomly select 90% of articles for training and test on the remaining 10%.", "labels": [], "entities": []}, {"text": "Human-authored articles in both domains contain an average of four topics, and each topic contains an average of 193 words.", "labels": [], "entities": []}, {"text": "In order to model the real-world scenario where Wikipedia articles are not always available (as for new or specialized topics), we specifically exclude Wikipedia sources during our search pro-  cedure (Section 3.1) for evaluation.", "labels": [], "entities": []}, {"text": "Baselines Our first baseline, Search, relies solely on search engine ranking for content selection.", "labels": [], "entities": []}, {"text": "Using the article title as a query -e.g., Bacillary Angiomatosis, this method selects the web page that is ranked first by the search engine.", "labels": [], "entities": []}, {"text": "From this page we select the first k paragraphs where k is defined in the same way as in our full model.", "labels": [], "entities": []}, {"text": "If there are less thank paragraphs on the page, all paragraphs are selected, but no other sources are used.", "labels": [], "entities": []}, {"text": "This yields a document of comparable size with the output of our system.", "labels": [], "entities": []}, {"text": "Despite its simplicity, this baseline is not naive: extracting material from a single document guarantees that the output is coherent, and a page highly ranked by a search engine may readily contain a comprehensive overview of the subject.", "labels": [], "entities": []}, {"text": "Our second baseline, No Template, does not use a template to specify desired topics; therefore, there are no constraints on content selection.", "labels": [], "entities": []}, {"text": "Instead, we follow a simplified form of previous work on biography creation, where a classifier is trained to distinguish biographical text (.", "labels": [], "entities": [{"text": "biography creation", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7737273275852203}]}, {"text": "In this case, we train a classifier to distinguish domain-specific text.", "labels": [], "entities": []}, {"text": "Positive training data is drawn from all topics in the given domain corpus.", "labels": [], "entities": []}, {"text": "To find negative training data, we perform the search procedure as in our full model (see Section 3.1) using only the article titles as search queries.", "labels": [], "entities": []}, {"text": "Any excerpts which have very low similarity to the original articles are used as negative examples.", "labels": [], "entities": []}, {"text": "During the decoding procedure, we use the same search procedure.", "labels": [], "entities": []}, {"text": "We then classify each excerpt as relevant or irrelevant and select the k non-redundant excerpts with the highest relevance confidence scores.", "labels": [], "entities": [{"text": "relevance confidence scores", "start_pos": 113, "end_pos": 140, "type": "METRIC", "confidence": 0.8913505673408508}]}, {"text": "Our third baseline, Disjoint, uses the ranking perceptron framework as in our full system; however, rather than perform an optimization step during training and decoding, we simply select the highest-ranked excerpt for each topic.", "labels": [], "entities": []}, {"text": "This equates to standard linear classification for each section individually.", "labels": [], "entities": []}, {"text": "In addition to these baselines, we compare against an Oracle system.", "labels": [], "entities": []}, {"text": "For each topic present in the human-authored article, the Oracle selects the excerpt from our full model's candidate excerpts with the highest cosine similarity to the human-authored text.", "labels": [], "entities": []}, {"text": "This excerpt is the optimal automatic selection from the results available, and therefore represents an upper bound on our excerpt selection task.", "labels": [], "entities": []}, {"text": "Some articles contain additional topics beyond those in the template; in these cases, the Oracle system produces a longer article than our algorithm.", "labels": [], "entities": []}, {"text": "shows the average number of excerpts selected and sources used in articles created by our full model and each baseline.", "labels": [], "entities": []}, {"text": "Automatic Evaluation To assess the quality of the resulting overview articles, we compare them with the original human-authored articles.", "labels": [], "entities": []}, {"text": "We use ROUGE, an evaluation metric employed at the Document Understanding Conferences (DUC), which assumes that proximity to human-authored text is an indicator of summary quality.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.9931655526161194}, {"text": "Document Understanding Conferences (DUC)", "start_pos": 51, "end_pos": 91, "type": "TASK", "confidence": 0.634418840209643}]}, {"text": "We use the publicly available ROUGE toolkit) to compute recall, precision, and F-score for ROUGE-1.", "labels": [], "entities": [{"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9994321465492249}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9992387294769287}, {"text": "F-score", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.999160647392273}]}, {"text": "We use the Wilcoxon Signed Rank Test to determine statistical significance.", "labels": [], "entities": [{"text": "Wilcoxon Signed Rank Test", "start_pos": 11, "end_pos": 36, "type": "METRIC", "confidence": 0.6546832919120789}, {"text": "significance", "start_pos": 62, "end_pos": 74, "type": "METRIC", "confidence": 0.6598982214927673}]}, {"text": "Analysis of Human Edits In addition to our automatic evaluation, we perform a study of reactions to system-produced articles by the general public.", "labels": [], "entities": [{"text": "Analysis of Human Edits", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.640112966299057}]}, {"text": "To achieve this goal, we insert automatically created articles into Wikipedia itself and examine the feedback of Wikipedia editors.", "labels": [], "entities": []}, {"text": "Selection of specific articles is constrained by the need to find topics which are currently of \"stub\" status that have enough information available on the Internet to construct a valid article.", "labels": [], "entities": []}, {"text": "After a period of time, we analyzed the edits made to the articles to determine the overall editor reaction.", "labels": [], "entities": []}, {"text": "We report results on 15 articles in the Diseases category   Since Wikipedia is a live resource, we do not repeat this procedure for our baseline systems.", "labels": [], "entities": []}, {"text": "Adding articles from systems which have previously demonstrated poor quality would be improper, especially in Diseases.", "labels": [], "entities": []}, {"text": "Therefore, we present this analysis as an additional observation rather than a rigorous technical study.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features employed in the ranking model.", "labels": [], "entities": []}, {"text": " Table 2: Average number of excerpts selected and  sources used in article creation for test articles.", "labels": [], "entities": [{"text": "article creation", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.6744758039712906}]}, {"text": " Table 3: Results of ROUGE-1 evaluation.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.8491736054420471}]}, {"text": " Table 4: Distribution of edits on Wikipedia.", "labels": [], "entities": [{"text": "Distribution of edits", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8760372400283813}, {"text": "Wikipedia", "start_pos": 35, "end_pos": 44, "type": "DATASET", "confidence": 0.6467810869216919}]}]}