{"title": [{"text": "Topological Ordering of Function Words in Hierarchical Phrase-based Translation", "labels": [], "entities": [{"text": "Topological Ordering of Function Words in Hierarchical Phrase-based Translation", "start_pos": 0, "end_pos": 79, "type": "TASK", "confidence": 0.7293787697950999}]}], "abstractContent": [{"text": "Hierarchical phrase-based models are attractive because they provide a consistent framework within which to characterize both local and long-distance reorder-ings, but they also make it difcult to distinguish many implausible reorderings from those that are linguistically plausible.", "labels": [], "entities": []}, {"text": "Rather than appealing to annotation-driven syntactic modeling, we address this problem by observing the innuential role of function words in determining syntactic structure, and introducing soft constraints on function word relationships as part of a standard log-linear hierarchical phrase-based model.", "labels": [], "entities": []}, {"text": "Experimentation on Chinese-English and Arabic-English translation demonstrates that the approach yields signiicant gains in performance.", "labels": [], "entities": []}, {"text": "1 Introduction Hierarchical phrase-based models (Chiang, 2005; Chiang, 2007) offer a number of attractive bene-ts in statistical machine translation (SMT), while maintaining the strengths of phrase-based systems (Koehn et al., 2003).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 117, "end_pos": 154, "type": "TASK", "confidence": 0.8128295143445333}]}, {"text": "The most important of these is the ability to model long-distance reordering ef-ciently.", "labels": [], "entities": []}, {"text": "To model such a reordering, a hierarchical phrase-based system demands no additional parameters, since long and short distance reorder-ings are modeled identically using synchronous context free grammar (SCFG) rules.", "labels": [], "entities": []}, {"text": "The same rule, depending on its topological ordering \u0096 i.e. its position in the hierarchical structure \u0096 can affect both short and long spans of text.", "labels": [], "entities": []}, {"text": "Interestingly , hierarchical phrase-based models provide this beneet without making any linguistic commitments beyond the structure of the model.", "labels": [], "entities": []}, {"text": "However, the system's lack of linguistic commitment is also responsible for one of its greatest drawbacks.", "labels": [], "entities": []}, {"text": "In the absence of linguistic knowledge , the system models linguistic structure using an SCFG that contains only one type of nontermi-nal symbol 1.", "labels": [], "entities": []}, {"text": "As a result, the system is susceptible to the overgeneration problem: the grammar may suggest more reordering choices than appropriate, and many of those choices lead to ungrammatical translations.", "labels": [], "entities": []}, {"text": "Chiang (2005) hypothesized that incorrect reordering choices would often correspond to hierarchical phrases that violate syntactic boundaries in the source language, and he explored the use of a \u0093constituent feature\u0094 intended to reward the application of hierarchical phrases which respect source language syntactic categories.", "labels": [], "entities": []}, {"text": "Although this did not yield signiicant improvements, Mar-ton and Resnik (2008) and Chiang et al.", "labels": [], "entities": []}, {"text": "(2008) extended this approach by introducing soft syntactic constraints similar to the constituent feature, but more ne-grained and sensitive to distinctions among syntactic categories; these led to substantial improvements in performance.", "labels": [], "entities": []}, {"text": "(2006) took a complementary approach, constraining the application of hierarchical rules to respect syntactic boundaries in the target language syntax.", "labels": [], "entities": []}, {"text": "Whether the focus is on constraints from the source language or the target language, the main ingredient in both previous approaches is the idea of constraining the spans of hierarchical phrases to respect syntactic boundaries.", "labels": [], "entities": []}, {"text": "In this paper, we pursue a different approach to improving reordering choices in a hierarchical phrase-based model.", "labels": [], "entities": []}, {"text": "Instead of biasing the model toward hierarchical phrases whose spans respect syntactic boundaries, we focus on the topologi-cal ordering of phrases in the hierarchical structure.", "labels": [], "entities": []}, {"text": "We conjecture that since incorrect reordering choices correspond to incorrect topological or-derings, boosting the probability of correct topo-1 In practice, one additional nonterminal symbol is used in \u0093glue rules\u0094.", "labels": [], "entities": []}, {"text": "This is not relevant in the present discussion.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hierarchical phrase-based models offer a number of attractive benets in statistical machine translation (SMT), while maintaining the strengths of phrase-based systems ().", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 72, "end_pos": 109, "type": "TASK", "confidence": 0.8108200232187907}]}, {"text": "The most important of these is the ability to model long-distance reordering efciently.", "labels": [], "entities": []}, {"text": "To model such a reordering, a hierarchical phrase-based system demands no additional parameters, since long and short distance reorderings are modeled identically using synchronous context free grammar (SCFG) rules.", "labels": [], "entities": []}, {"text": "The same rule, depending on its topological ordering \u0096 i.e. its position in the hierarchical structure \u0096 can affect both short and long spans of text.", "labels": [], "entities": []}, {"text": "Interestingly, hierarchical phrase-based models provide this beneet without making any linguistic commitments beyond the structure of the model.", "labels": [], "entities": []}, {"text": "However, the system's lack of linguistic commitment is also responsible for one of its greatest drawbacks.", "labels": [], "entities": []}, {"text": "In the absence of linguistic knowledge, the system models linguistic structure using an SCFG that contains only one type of nonterminal symbol . As a result, the system is susceptible to the overgeneration problem: the grammar may suggest more reordering choices than appropriate, and many of those choices lead to ungrammatical translations.", "labels": [], "entities": []}, {"text": "Chiang where X is the nonterminal symbol and \u03b3 and \u03b1 are strings that contain the combination of lexical items and nonterminals in the source and target languages, respectively.", "labels": [], "entities": []}, {"text": "The \u223c symbol indicates that nonterminals in \u03b3 and \u03b1 are synchronized through co-indexation; i.e., nonterminals with the same index are aligned.", "labels": [], "entities": []}, {"text": "Nonterminal correspondences are strictly one-to-one, and in practice the number of nonterminals on the right hand side is constrained to at most two, which must be separated by lexical items.", "labels": [], "entities": []}, {"text": "Each rule is associated with a score that is computed via the following log linear formula: where f i is a feature describing one particular aspect of the rule and \u03bb i is the corresponding weight of that feature.", "labels": [], "entities": []}, {"text": "Give\u00f1 e and\u02dcfand\u02dc and\u02dcf as the source and target phrases associated with the rule, typical features used are rule's translation probability P trans ( \u02dc f |\u02dce|\u02dce) and its inverse P trans (\u02dc e|\u02dcfe|\u02dc e|\u02dcf ), the lexical probability P lex ( \u02dc f |\u02dce|\u02dce) and its inverse P lex (\u02dc e|\u02dcfe|\u02dc e|\u02dcf ).", "labels": [], "entities": []}, {"text": "Systems generally also employ a word penalty, a phrase penalty, and target language model feature.", "labels": [], "entities": []}, {"text": "(See () for more detailed discussion.)", "labels": [], "entities": []}, {"text": "Our pairwise dominance model will be expressed as an additional rule-level feature in the model.", "labels": [], "entities": []}, {"text": "Translation of a source sentence e using hierarchical phrase-based models is formulated as a search for the most probable derivation D * whose source side is equal to e: ..|D| is a set of rules following a certain topological ordering, indicated hereby the use of the superscript.", "labels": [], "entities": [{"text": "Translation of a source sentence e", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8251875936985016}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The distribution of the dominance values", "labels": [], "entities": []}, {"text": " Table 2: Experimental results on Chinese-to-", "labels": [], "entities": []}]}