{"title": [{"text": "Automatic Adaptation of Annotation Standards: Chinese Word Segmentation and POS Tagging -A Case Study", "labels": [], "entities": [{"text": "Automatic Adaptation of Annotation Standards", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7865633487701416}, {"text": "Chinese Word Segmentation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6525427003701528}, {"text": "POS Tagging", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.7370588779449463}]}], "abstractContent": [{"text": "Manually annotated corpora are valuable but scarce resources, yet for many annotation tasks such as treebanking and sequence labeling there exist multiple corpora with different and incompatible annotation guidelines or standards.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.6570033878087997}]}, {"text": "This seems to be a great waste of human efforts, and it would be nice to automatically adapt one annotation standard to another.", "labels": [], "entities": []}, {"text": "We present a simple yet effective strategy that transfers knowledge from a differently annotated corpus to the corpus with desired annotation.", "labels": [], "entities": []}, {"text": "We test the efficacy of this method in the context of Chinese word segmentation and part-of-speech tagging, where no segmentation and POS tagging standards are widely accepted due to the lack of morphology in Chinese.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.5932345489660898}, {"text": "part-of-speech tagging", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.7010965049266815}, {"text": "POS tagging", "start_pos": 134, "end_pos": 145, "type": "TASK", "confidence": 0.6416929811239243}]}, {"text": "Experiments show that adaptation from the much larger People's Daily corpus to the smaller but more popular Penn Chinese Treebank results in significant improvements in both segmentation and tagging accuracies (with error reductions of 30.2% and 14%, respectively), which in turn helps improve Chinese parsing accuracy.", "labels": [], "entities": [{"text": "People's Daily corpus", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.9496467858552933}, {"text": "Penn Chinese Treebank", "start_pos": 108, "end_pos": 129, "type": "DATASET", "confidence": 0.9691028396288554}, {"text": "accuracies", "start_pos": 199, "end_pos": 209, "type": "METRIC", "confidence": 0.8265624642372131}, {"text": "error reductions", "start_pos": 216, "end_pos": 232, "type": "METRIC", "confidence": 0.9564380347728729}, {"text": "Chinese parsing", "start_pos": 294, "end_pos": 309, "type": "TASK", "confidence": 0.5715371668338776}, {"text": "accuracy", "start_pos": 310, "end_pos": 318, "type": "METRIC", "confidence": 0.8482036590576172}]}], "introductionContent": [{"text": "Much of statistical NLP research relies on some sort of manually annotated corpora to train their models, but these resources are extremely expensive to build, especially at a large scale, for example in treebanking (.", "labels": [], "entities": []}, {"text": "However the linguistic theories underlying these annotation efforts are often heavily debated, and as a result there often exist multiple corpora for the same task with vastly different and incompatible annotation philosophies.", "labels": [], "entities": []}, {"text": "For example just for English treebanking there have been the Chomskian-style Penn Treebank () the HPSG LinGo Redwoods Treebank (), and a smaller dependency treebank).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.9787548780441284}, {"text": "HPSG LinGo Redwoods Treebank", "start_pos": 98, "end_pos": 126, "type": "DATASET", "confidence": 0.9289460629224777}]}, {"text": "A second, related problem is that the raw texts are also drawn from different domains, which for the above example range from financial news (PTB/WSJ) to transcribed dialog (LinGo).", "labels": [], "entities": [{"text": "PTB/WSJ)", "start_pos": 142, "end_pos": 150, "type": "DATASET", "confidence": 0.8936505913734436}]}, {"text": "These two problems seem be a great waste inhuman efforts, and it would be nice if one could automatically adapt from one annotation standard and/or domain to another in order to exploit much larger datasets for better training.", "labels": [], "entities": []}, {"text": "The second problem, domain adaptation, is very well-studied, e.g. by and Daum\u00e9 III (2007) (and see below for discussions), so in this paper we focus on the less studied, but equally important problem of annotationstyle adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8050912916660309}, {"text": "annotationstyle adaptation", "start_pos": 203, "end_pos": 229, "type": "TASK", "confidence": 0.8175948560237885}]}, {"text": "We present a very simple yet effective strategy that enables us to utilize knowledge from a differently annotated corpora for the training of a model on a corpus with desired annotation.", "labels": [], "entities": []}, {"text": "The basic idea is very simple: we first train on a source corpus, resulting in a source classifier, which is used to label the target corpus and results in a \"sourcestyle\" annotation of the target corpus.", "labels": [], "entities": []}, {"text": "We then train a second model on the target corpus with the first classifier's prediction as additional features for guided learning.", "labels": [], "entities": []}, {"text": "This method is very similar to some ideas in domain adaptation), but we argue that the underlying problems are quite different.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7488937377929688}]}, {"text": "Domain adaptation assumes the labeling guidelines are preserved between the two domains, e.g., an adjective is always labeled as JJ regardless of from Wall Street Journal (WSJ) or Biomedical texts, and only the distributions are different, e.g., the word \"control\" is most likely a verb in WSJ but often a noun in Biomedical texts (as in \"control experiment\").", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7721730768680573}, {"text": "Wall Street Journal (WSJ)", "start_pos": 151, "end_pos": 176, "type": "DATASET", "confidence": 0.9411843518416086}]}, {"text": "Annotation-style adaptation, however, tackles the problem where the guideline itself is changed, for example, one treebank might distinguish between transitive and intransitive verbs, while merging the different noun types (NN, NNS, etc.), and for example one treebank (PTB) might be much flatter than the other (LinGo), not to mention the fundamental disparities between their underlying linguistic representations.", "labels": [], "entities": [{"text": "Annotation-style adaptation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7141438126564026}]}, {"text": "In this sense, the problem we study in this paper seems much harder and more motivated from a linguistic (rather than statistical) point of view.", "labels": [], "entities": []}, {"text": "More interestingly, our method, without any assumption on the distributions, can be simultaneously applied to both domain and annotation standards adaptation problems, which is very appealing in practice because the latter problem often implies the former, as in our case study.", "labels": [], "entities": []}, {"text": "To test the efficacy of our method we choose Chinese word segmentation and part-of-speech tagging, where the problem of incompatible annotation standards is one of the most evident: so far no segmentation standard is widely accepted due to the lack of a clear definition of Chinese words, and the (almost complete) lack of morphology results in much bigger ambiguities and heavy debates in tagging philosophies for Chinese parts-of-speech.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6191872358322144}, {"text": "part-of-speech tagging", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.6771883815526962}]}, {"text": "The two corpora used in this study are the much larger People's Daily (PD) (5.86M words) corpus () and the smaller but more popular Penn Chinese Treebank (CTB) (0.47M words) (.", "labels": [], "entities": [{"text": "People's Daily (PD) (5.86M words) corpus", "start_pos": 55, "end_pos": 95, "type": "DATASET", "confidence": 0.9354309385473077}, {"text": "Penn Chinese Treebank (CTB)", "start_pos": 132, "end_pos": 159, "type": "DATASET", "confidence": 0.9616581499576569}]}, {"text": "They used very different segmentation standards as well as different POS tagsets and tagging guidelines.", "labels": [], "entities": []}, {"text": "For example, in, People's Daily breaks \"Vice-President\" into two words while combines the phrase \"visited-China\" as a compound.", "labels": [], "entities": [{"text": "People's Daily", "start_pos": 17, "end_pos": 31, "type": "DATASET", "confidence": 0.9268489082654318}]}, {"text": "Also CTB has four verbal categories (VV for normal verbs, and VC for copulas, etc.) while PD has only one verbal tag (v).", "labels": [], "entities": [{"text": "CTB", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.8753029108047485}]}, {"text": "It is preferable to transfer knowledge from PD to CTB because the latter also annotates tree structures which is very useful for downstream applications like parsing, summarization, and machine translation, yet it is much smaller in size.", "labels": [], "entities": [{"text": "parsing", "start_pos": 158, "end_pos": 165, "type": "TASK", "confidence": 0.9773234724998474}, {"text": "summarization", "start_pos": 167, "end_pos": 180, "type": "TASK", "confidence": 0.9027619957923889}, {"text": "machine translation", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.8273333311080933}]}, {"text": "Indeed, many recent efforts on Chinese-English translation and Chinese parsing use the CTB as the de facto segmentation and tagging standards, but suffers from the limited size of training data).", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.6528254151344299}, {"text": "Chinese parsing", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.610971137881279}, {"text": "segmentation and tagging", "start_pos": 107, "end_pos": 131, "type": "TASK", "confidence": 0.6033873856067657}]}, {"text": "We believe this is also a reason why stateof-the-art accuracy for Chinese parsing is much lower than that of English (CTB is only half the size of PTB).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9979789853096008}, {"text": "Chinese parsing", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.5880315601825714}]}, {"text": "Our experiments show that adaptation from PD to CTB results in a significant improvement in segmentation and POS tagging, with error reductions of 30.2% and 14%, respectively.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.946092963218689}, {"text": "POS tagging", "start_pos": 109, "end_pos": 120, "type": "TASK", "confidence": 0.7771517038345337}, {"text": "error reductions", "start_pos": 127, "end_pos": 143, "type": "METRIC", "confidence": 0.9826969504356384}]}, {"text": "In addition, the improved accuracies from segmentation and tagging also lead to an improved parsing accuracy on CTB, reducing 38% of the error propagation from word segmentation to parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 92, "end_pos": 99, "type": "TASK", "confidence": 0.9585934281349182}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9061832427978516}, {"text": "word segmentation", "start_pos": 160, "end_pos": 177, "type": "TASK", "confidence": 0.7053666412830353}]}, {"text": "We envision this technique to be general and widely applicable to many other sequence labeling tasks.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.7396712501843771}]}, {"text": "In the rest of the paper we first briefly review the popular classification-based method for word segmentation and tagging (Section 2), and then describe our idea of annotation adaptation (Section 3).", "labels": [], "entities": [{"text": "word segmentation and tagging", "start_pos": 93, "end_pos": 122, "type": "TASK", "confidence": 0.7506322413682938}, {"text": "annotation adaptation", "start_pos": 166, "end_pos": 187, "type": "TASK", "confidence": 0.7066693305969238}]}, {"text": "We then discuss other relevant previous work including co-training and classifier combination (Section 4) before presenting our experimental results (Section 5).", "labels": [], "entities": [{"text": "classifier combination", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.8332445621490479}]}], "datasetContent": [{"text": "Our adaptation experiments are conducted from People's Daily (PD) to Penn Chinese Treebank 5.0 (CTB).", "labels": [], "entities": [{"text": "People's Daily (PD)", "start_pos": 46, "end_pos": 65, "type": "DATASET", "confidence": 0.9517095685005188}, {"text": "Penn Chinese Treebank 5.0 (CTB)", "start_pos": 69, "end_pos": 100, "type": "DATASET", "confidence": 0.9472955550466265}]}, {"text": "These two corpora are segmented following different segmentation standards and labeled with different POS sets (see for example.", "labels": [], "entities": []}, {"text": "PD is much bigger in size, with about 100K sentences, while CTB is much smaller, with only about 18K sentences.", "labels": [], "entities": []}, {"text": "Thus a classifier trained on CTB usually falls behind that trained on PD, but CTB is preferable because it also annotates tree structures, which is very useful for downstream applications like parsing and translation.", "labels": [], "entities": []}, {"text": "For example, currently, most Chinese constituency and dependency parsers are trained on some version of CTB, using its segmentation and POS tagging as the de facto standards.", "labels": [], "entities": [{"text": "Chinese constituency and dependency parsers", "start_pos": 29, "end_pos": 72, "type": "TASK", "confidence": 0.49563907980918886}, {"text": "POS tagging", "start_pos": 136, "end_pos": 147, "type": "TASK", "confidence": 0.6380372494459152}]}, {"text": "Therefore, we expect the knowledge adapted from PD will lead to more precise CTB-style segmenter and POS tagger, which would in turn reduce the error propagation to parsing (and translation).", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 101, "end_pos": 111, "type": "TASK", "confidence": 0.600903257727623}, {"text": "parsing", "start_pos": 165, "end_pos": 172, "type": "TASK", "confidence": 0.9616488218307495}]}, {"text": "Experiments adapting from PD to CTB are conducted for two tasks: word segmentation alone, and joint segmentation and POS tagging (Joint S&T).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.76446932554245}, {"text": "joint segmentation", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.6722684502601624}, {"text": "POS tagging", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.6689145416021347}]}, {"text": "The performance measurement indicators for word segmentation and Joint S&T are balanced F-measure, F = 2P R/(P + R), a function of Precision P and Recall R. For word segmentation, P indicates the percentage of words in segmentation result that are segmented correctly, and R indicates the percentage of correctly segmented words in gold standard words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.8246162235736847}, {"text": "Joint S&T", "start_pos": 65, "end_pos": 74, "type": "TASK", "confidence": 0.7202694118022919}, {"text": "F-measure", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9566627144813538}, {"text": "2P R/(P + R)", "start_pos": 103, "end_pos": 115, "type": "METRIC", "confidence": 0.8125780480248588}, {"text": "Precision P", "start_pos": 131, "end_pos": 142, "type": "METRIC", "confidence": 0.9804444015026093}, {"text": "Recall R.", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9810571372509003}, {"text": "word segmentation", "start_pos": 161, "end_pos": 178, "type": "TASK", "confidence": 0.7570934891700745}]}, {"text": "For Joint S&T, P and R mean nearly the same except that a word is correctly segmented only if its POS is also correctly labelled.", "labels": [], "entities": [{"text": "Joint S&T", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.714533194899559}, {"text": "R", "start_pos": 21, "end_pos": 22, "type": "METRIC", "confidence": 0.9551895260810852}]}], "tableCaptions": [{"text": " Table 3: Experimental results for both baseline  models and final systems with annotation adap- tation. PD \u2192 CTB means annotation adaptation  from PD to CTB. For the upper sub-table, items of  JST F 1 are undefined since only segmentation is  performs. While in the sub-table below, JST F 1  is also undefined since the model trained on PD  gives a POS set different from that of CTB.", "labels": [], "entities": [{"text": "POS set", "start_pos": 350, "end_pos": 357, "type": "METRIC", "confidence": 0.9523945748806}]}, {"text": " Table 4: Error analysis for Joint S&T on the devel- oping set of CTB. #BaseErr and #AdaErr denote  the count of words that can't be recalled by the  baseline model and adapted model, respectively.  ErrDec denotes the error reduction of Recall.", "labels": [], "entities": [{"text": "Joint S&T", "start_pos": 29, "end_pos": 38, "type": "TASK", "confidence": 0.5546917244791985}, {"text": "devel- oping set of CTB", "start_pos": 46, "end_pos": 69, "type": "DATASET", "confidence": 0.6929147044817606}, {"text": "ErrDec", "start_pos": 199, "end_pos": 205, "type": "METRIC", "confidence": 0.9446162581443787}, {"text": "error reduction", "start_pos": 218, "end_pos": 233, "type": "METRIC", "confidence": 0.9328662753105164}, {"text": "Recall", "start_pos": 237, "end_pos": 243, "type": "METRIC", "confidence": 0.4909186065196991}]}]}