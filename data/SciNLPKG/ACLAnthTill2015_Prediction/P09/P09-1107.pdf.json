{"title": [{"text": "Incremental HMM Alignment for MT System Combination", "labels": [], "entities": [{"text": "Incremental HMM Alignment", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7447268962860107}, {"text": "MT System Combination", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8340242902437845}]}], "abstractContent": [{"text": "Inspired by the incremental TER alignment , we redesigned the Indirect HMM (IHMM) alignment, which is one of the best hypothesis alignment methods for conventional MT system combination, in an incremental manner.", "labels": [], "entities": [{"text": "MT", "start_pos": 164, "end_pos": 166, "type": "TASK", "confidence": 0.9810656905174255}]}, {"text": "One crucial problem of incremental alignment is to align a hypothesis to a confusion network (CN).", "labels": [], "entities": []}, {"text": "Our incremental IHMM alignment is implemented in three different ways: 1) treat CN spans as HMM states and define state transition as distortion over covered n-grams between two spans; 2) treat CN spans as HMM states and define state transition as distortion over words in component translations in the CN; and 3) use a consensus decoding algorithm over one hypothesis and multiple IHMMs, each of which corresponds to a component translation in the CN.", "labels": [], "entities": [{"text": "IHMM alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8333708941936493}]}, {"text": "All these three approaches of incremental alignment based on IHMM are shown to be superior to both incremental TER alignment and conventional IHMM alignment in the setting of the Chinese-to-English track of the 2008 NIST Open MT evaluation.", "labels": [], "entities": [{"text": "TER alignment", "start_pos": 111, "end_pos": 124, "type": "METRIC", "confidence": 0.937240868806839}, {"text": "NIST Open MT evaluation", "start_pos": 216, "end_pos": 239, "type": "DATASET", "confidence": 0.7663885205984116}]}], "introductionContent": [{"text": "Word-level combination using confusion network ( and) is a widely adopted approach for combining Machine Translation (MT) systems' output.", "labels": [], "entities": [{"text": "Word-level combination", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.636491596698761}, {"text": "Machine Translation (MT)", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.8485861182212829}]}, {"text": "Word alignment between a backbone (or skeleton) translation and a hypothesis translation is a key problem in this approach.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7026283890008926}]}, {"text": "Translation Edit Rate (TER,) based alignment proposed in is often taken as the baseline, and a couple of other approaches, such as the Indirect Hidden Markov Model (IHMM,) and the ITG-based alignment (), were recently proposed with better results reported.", "labels": [], "entities": [{"text": "Translation Edit Rate (TER", "start_pos": 0, "end_pos": 26, "type": "METRIC", "confidence": 0.7803766250610351}]}, {"text": "With an alignment method, each hypothesis is aligned against the backbone and all the alignments are then used to build a confusion network (CN) for generating a better translation.", "labels": [], "entities": []}, {"text": "However, as pointed out by, such a pair-wise alignment strategy will produce a low-quality CN if there are errors in the alignment of any of the hypotheses, no matter how good the alignments of other hypotheses are.", "labels": [], "entities": []}, {"text": "For example, suppose we have the backbone \"he buys a computer\" and two hypotheses \"he bought a laptop computer\" and \"he buys a laptop\".", "labels": [], "entities": []}, {"text": "It will be natural for most alignment methods to produce the alignments in.", "labels": [], "entities": []}, {"text": "The alignment of hypothesis 2 against the backbone cannot be considered an error if we consider only these two translations; nevertheless, when added with the alignment of another hypothesis, it produces the low-quality CN in, which may generate poor translations like \"he bought a laptop laptop\".", "labels": [], "entities": []}, {"text": "While it could be argued that such poor translations are unlikely to be selected due to language model, this CN does disperse the votes to the word \"laptop\" to two distinct arcs.", "labels": [], "entities": []}, {"text": "showed that this problem can be rectified by incremental alignment.", "labels": [], "entities": []}, {"text": "If hypothesis 1 is first aligned against the backbone, the CN thus produced (depicted in) is then aligned to hypothesis 2, giving rise to the good CN as depicted in.", "labels": [], "entities": []}, {"text": "On the other hand, the: An example bad confusion network due to pair-wise alignment strategy correct result depends on the order of hypotheses.", "labels": [], "entities": []}, {"text": "If hypothesis 2 is aligned before hypothesis 1, the final CN will not be good.", "labels": [], "entities": []}, {"text": "Therefore, the observation in that different order of hypotheses does not affect translation quality is counter-intuitive.", "labels": [], "entities": [{"text": "translation", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.9554397463798523}]}, {"text": "This paper attempts to answer two questions: 1) as incremental TER alignment gives better performance than pair-wise TER alignment, would the incremental strategy still be better than the pairwise strategy if the TER method is replaced by another alignment method?", "labels": [], "entities": []}, {"text": "2) how does translation quality vary for different orders of hypotheses being incrementally added into a CN?", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9524171948432922}]}, {"text": "For question 1, we will focus on the IHMM alignment method and propose three different ways of implementing incremental IHMM alignment.", "labels": [], "entities": [{"text": "IHMM alignment", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.787092924118042}, {"text": "IHMM alignment", "start_pos": 120, "end_pos": 134, "type": "TASK", "confidence": 0.847271740436554}]}, {"text": "Our experiments will also try several orders of hypotheses in response to question 2.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "After setting the notations on CN in section 2, we will first introduce, in section 3, two variations of the basic incremental IHMM model (IncIHMM1 and IncIHMM2).", "labels": [], "entities": []}, {"text": "In section 4, a consensus decoding algorithm (CD-IHMM) is proposed as an alternative way to search for the optimal alignment.", "labels": [], "entities": []}, {"text": "The issues of alignment normalization and the order of hypotheses being added into a CN are discussed in sections 5 and 6 respectively.", "labels": [], "entities": [{"text": "alignment normalization", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.9848092794418335}]}, {"text": "Experiment results and analysis are presented in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following sections, the incremental IHMM approaches using distortion model 1 and 2 are named as IncIHMM1 and IncIHMM2 respectively, and the consensus decoding of multiple IHMMs as CD-IHMM.", "labels": [], "entities": []}, {"text": "The baselines include the TER-based method in, the incremental TER method in, and the IHMM approach in.", "labels": [], "entities": [{"text": "TER-based", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.796683132648468}, {"text": "TER", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9314594268798828}]}, {"text": "The development (dev) set comprises the newswire and newsgroup sections of MT06, whereas the test set is the entire MT08.", "labels": [], "entities": [{"text": "MT06", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.9712225198745728}, {"text": "MT08", "start_pos": 116, "end_pos": 120, "type": "DATASET", "confidence": 0.9777260422706604}]}, {"text": "The 10-best translations for every source sentence in the dev and test sets are collected from eight MT systems.", "labels": [], "entities": []}, {"text": "Case-insensitive BLEU-4, presented in percentage, is used as evaluation metric.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9771193861961365}]}, {"text": "The various parameters in the IHMM model are set as the optimal values found in.", "labels": [], "entities": [{"text": "IHMM", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.7040680646896362}]}, {"text": "The lexical translation probabilities used in the semantic similarity model are estimated from a small portion (FBIS + GALE) of the constrained track training data, using standard HMM alignment model).", "labels": [], "entities": [{"text": "FBIS + GALE)", "start_pos": 112, "end_pos": 124, "type": "METRIC", "confidence": 0.8038467168807983}]}, {"text": "The backbone of CN is selected by MBR.", "labels": [], "entities": [{"text": "MBR", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.9369828701019287}]}, {"text": "The loss function used for TER-based approaches is TER and that for IHMM-based approaches is BLEU.", "labels": [], "entities": [{"text": "TER", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9984068274497986}, {"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9975259900093079}]}, {"text": "As to the incremental systems, the default order of hypotheses is the ascending order of TER score against the backbone, which is the order proposed in.", "labels": [], "entities": [{"text": "TER score", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9808402359485626}]}, {"text": "The default order of hypotheses for our three incremental IHMM approaches is N-best rank order with Bayes Risk system order, which is empirically found to be giving the highest BLEU score.", "labels": [], "entities": [{"text": "Bayes Risk system order", "start_pos": 100, "end_pos": 123, "type": "METRIC", "confidence": 0.5930725783109665}, {"text": "BLEU score", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.9784610867500305}]}, {"text": "Once the CN is built, the final system combination output can be obtained by decoding it with a set of features and decoding parameters.", "labels": [], "entities": []}, {"text": "The features we used include word confidences, language model score, word penalty and empty word penalty.", "labels": [], "entities": []}, {"text": "The decoding parameters are trained by maximum BLEU training on the dev set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9988418221473694}]}, {"text": "The training and decoding processes are the same as described by: Comparison between IncIHMM2 and the three baselines lists the BLEU scores achieved by the three baseline combination methods and IncIHMM2.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9990324974060059}, {"text": "IncIHMM2", "start_pos": 195, "end_pos": 203, "type": "DATASET", "confidence": 0.9088923931121826}]}, {"text": "The comparison between pairwise and incremental TER methods justifies the superiority of the incremental strategy.", "labels": [], "entities": []}, {"text": "However, the benefit of incremental TER over pair-wise TER is smaller than that mentioned in, which maybe because of the difference between test sets and other experimental conditions.", "labels": [], "entities": [{"text": "TER", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9907649755477905}, {"text": "TER", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9539840817451477}]}, {"text": "The comparison between the two pair-wise alignment methods shows that IHMM gives a 0.7 BLEU point gain over TER, which is a bit smaller than the difference reported in.", "labels": [], "entities": [{"text": "IHMM", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.7430928349494934}, {"text": "BLEU point gain", "start_pos": 87, "end_pos": 102, "type": "METRIC", "confidence": 0.9728803237279257}, {"text": "TER", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9976800084114075}]}, {"text": "The possible causes of such discrepancy include the different dev set and the smaller training set for estimating semantic similarity parameters.", "labels": [], "entities": []}, {"text": "Despite that, the pair-wise IHMM method is still a strong baseline.", "labels": [], "entities": [{"text": "IHMM", "start_pos": 28, "end_pos": 32, "type": "TASK", "confidence": 0.6430729627609253}]}, {"text": "Table 2 also shows the performance of IncIHMM2, our best incremental IHMM approach.", "labels": [], "entities": [{"text": "IncIHMM2", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.8863189220428467}]}, {"text": "It is almost one BLEU point higher than the pair-wise IHMM baseline and much higher than the two TER baselines.: Comparison between the three incremental IHMM approaches els is to shift the distortion over spans to the distortion over word sequences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.999302864074707}, {"text": "TER", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9412505030632019}]}, {"text": "In distortion model 2 the word sequences are those sequences available in one of the component translations in the CN.", "labels": [], "entities": []}, {"text": "Distortion model 1 is more encompassing as it also considers the word sequences which are combined from subsequences from various component translations.", "labels": [], "entities": []}, {"text": "However, as mentioned in section 3.1, the number of sequences grows exponentially and there is therefore a limit L to the length of sequences.", "labels": [], "entities": []}, {"text": "In general the limit L \u2265 8 would render the tuning/decoding process intolerably slow.", "labels": [], "entities": []}, {"text": "We tried the values 5 to 8 for Land the variation of performance is less than 0.1 BLEU point.", "labels": [], "entities": [{"text": "variation", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9738885164260864}, {"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9996398687362671}]}, {"text": "That is, distortion model 1 cannot be improved by tuning L.", "labels": [], "entities": []}, {"text": "The similar BLEU scores as shown in Table 3 implies that the incorporation of more word sequences in distortion model 1 does not lead to extra improvement.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9993718266487122}]}, {"text": "Although consensus decoding is conceptually different from both variations of IncIHMM, it can indeed be transformed into a form similar to IncIHMM2.", "labels": [], "entities": [{"text": "IncIHMM", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.938879668712616}, {"text": "IncIHMM2", "start_pos": 139, "end_pos": 147, "type": "DATASET", "confidence": 0.9581833481788635}]}, {"text": "IncIHMM2 calculates the parameters of the IHMM as a weighted sum of various probabilities of the component translations.", "labels": [], "entities": [{"text": "IncIHMM2", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9246574640274048}]}, {"text": "In contrast, the equations in section 4 shows that CD-IHMM calculates the weighted sum of the logarithm of those probabilities of the component translations.", "labels": [], "entities": []}, {"text": "In other words, IncIHMM2 makes use of the sum of probabilities whereas CD-IHMM makes use of the product of probabilities.", "labels": [], "entities": [{"text": "IncIHMM2", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.9287481904029846}]}, {"text": "The experiment results indicate that the interaction between the weights and the probabilities is more fragile in the product case than in the summation case.", "labels": [], "entities": []}, {"text": "lists the BLEU scores on the test set achieved by IncIHMM1 using different orders of hypotheses.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999110758304596}, {"text": "IncIHMM1", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.964292049407959}]}, {"text": "The column 'reversal' shows the impact of deliberately bad order, viz.", "labels": [], "entities": []}, {"text": "more than one BLEU point lower than the best order.", "labels": [], "entities": [{"text": "BLEU point", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9746302366256714}]}, {"text": "The random order is a baseline for not caring about order of hypotheses at all, which is about 0.: Comparison between various orders of hypotheses.", "labels": [], "entities": []}, {"text": "'System' means system-based order; 'Rank' means N-best rank-based order; 'BR' means Bayes Risk order of systems.", "labels": [], "entities": [{"text": "BR", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9935489296913147}]}, {"text": "The numbers are the BLEU scores on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9985219836235046}]}], "tableCaptions": [{"text": " Table 1: The list of order of hypothesis and examples. Note that 'm:n' refers to the n-th translation from  the m-th system.", "labels": [], "entities": []}, {"text": " Table 3: Comparison between the three incremen- tal IHMM approaches", "labels": [], "entities": [{"text": "IHMM", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.8196595907211304}]}, {"text": " Table 4: Comparison between various orders of  hypotheses. 'System' means system-based or- der; 'Rank' means N-best rank-based order; 'BR'  means Bayes Risk order of systems. The numbers  are the BLEU scores on the test set.", "labels": [], "entities": [{"text": "BR", "start_pos": 136, "end_pos": 138, "type": "METRIC", "confidence": 0.9927769899368286}, {"text": "BLEU", "start_pos": 197, "end_pos": 201, "type": "METRIC", "confidence": 0.9986696243286133}]}]}