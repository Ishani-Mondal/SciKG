{"title": [{"text": "Efficient Inference of CRFs for Large-Scale Natural Language Data", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an efficient inference algorithm of conditional random fields (CRFs) for large-scale data.", "labels": [], "entities": []}, {"text": "Our key idea is to decompose the output label state into an active set and an inactive set in which most unsupported transitions become a constant.", "labels": [], "entities": []}, {"text": "Our method unifies two previous methods for efficient inference of CRFs, and also derives a simple but robust special case that performs faster than exact inference when the active sets are sufficiently small.", "labels": [], "entities": []}, {"text": "We demonstrate that our method achieves dramatic speedup on six standard natural language processing problems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conditional random fields (CRFs) are widely used in natural language processing, but extending them to large-scale problems remains a significant challenge.", "labels": [], "entities": [{"text": "Conditional random fields (CRFs)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6754831274350485}]}, {"text": "For simple graphical structures (e.g. linear-chain), an exact inference can be obtained efficiently if the number of output labels is not large.", "labels": [], "entities": []}, {"text": "However, for large number of output labels, the inference is often prohibitively expensive.", "labels": [], "entities": []}, {"text": "To alleviate this problem, researchers have begun to study the methods of increasing inference speeds of CRFs.", "labels": [], "entities": []}, {"text": "proposed a Sparse ForwardBackward (SFB) algorithm, in which marginal distribution is compressed by approximating the true marginals using Kullback-Leibler (KL) divergence.", "labels": [], "entities": [{"text": "ForwardBackward", "start_pos": 18, "end_pos": 33, "type": "METRIC", "confidence": 0.6059531569480896}]}, {"text": "proposed a Tied Potential (TP) algorithm which constrains the labeling considered in each feature function, such that the functions can detect only a relatively small set of labels.", "labels": [], "entities": []}, {"text": "Both of these techniques efficiently compute the marginals with a significantly reduced runtime, resulting in faster training and decoding of CRFs.", "labels": [], "entities": []}, {"text": "This paper presents an efficient inference algorithm of CRFs which unifies the SFB and TP approaches.", "labels": [], "entities": [{"text": "SFB", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.7721460461616516}]}, {"text": "We first decompose output labels states into active and inactive sets.", "labels": [], "entities": []}, {"text": "Then, the active set is selected by feasible heuristics and the parameters of the inactive set are held a constant.", "labels": [], "entities": []}, {"text": "The idea behind our method is that not all of the states contribute to the marginals, that is, only a * Parts of this work were conducted during the author's internship at Microsoft Research Asia.", "labels": [], "entities": [{"text": "Microsoft Research Asia", "start_pos": 172, "end_pos": 195, "type": "DATASET", "confidence": 0.8239565094312032}]}, {"text": "small group of the labeling states has sufficient statistics.", "labels": [], "entities": []}, {"text": "We show that the SFB and the TP are special cases of our method because they derive from our unified algorithm with a different setting of parameters.", "labels": [], "entities": [{"text": "SFB", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.8147162199020386}]}, {"text": "We also present a simple but robust variant algorithm in which CRFs efficiently learn and predict large-scale natural language data.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our method on six large-scale natural language data sets: Penn Treebank 3 for part-of-speech tagging (PTB), phrase chunking data 4 (CoNLL00), named entity recognition data 5 (CoNLL03), grapheme-to-phoneme conversion data 6 (NetTalk), spoken language understanding data (Communicator) (), and finegrained named entity recognition data (Encyclopedia) (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.9884878396987915}, {"text": "part-of-speech tagging (PTB)", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.8177883625030518}, {"text": "phrase chunking", "start_pos": 121, "end_pos": 136, "type": "TASK", "confidence": 0.731328934431076}, {"text": "spoken language understanding", "start_pos": 247, "end_pos": 276, "type": "TASK", "confidence": 0.6265978217124939}]}, {"text": "The active set is sufficiently small in Communicator and Encyclopedia despite their large numbers of output labels.", "labels": [], "entities": [{"text": "Encyclopedia", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.8881956338882446}]}, {"text": "In all data sets, we selected the current word, \u00b12 context words, bigrams, trigrams, and prefix and suffix features as basic feature templates.", "labels": [], "entities": []}, {"text": "A template of part-of-speech tag features was added for CoNLL00, CoNLL03, and Encyclopedia.", "labels": [], "entities": [{"text": "CoNLL00", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9446108341217041}, {"text": "CoNLL03", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.8875832557678223}, {"text": "Encyclopedia", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.9578972458839417}]}, {"text": "In particular, all tasks except PTB and NetTalk require assigning a label to a phrase rather than to a word; hence, we used standard \"BIO\" encoding.", "labels": [], "entities": [{"text": "PTB", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.9382920861244202}]}, {"text": "We used un-normalized loglikelihood, accuracy and training/decoding times as our evaluation measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9991135001182556}]}, {"text": "We did not use cross validation and development set for tuning the parameter because our goal is to evaluate the efficiency of inference algorithms.", "labels": [], "entities": []}, {"text": "Moreover, using the previous state-of-the-art features we expect the achievement of better accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9984329342842102}]}, {"text": "All our models were trained until parameter estimation converged with a Gaussian prior variance of 4.", "labels": [], "entities": [{"text": "Gaussian prior variance", "start_pos": 72, "end_pos": 95, "type": "METRIC", "confidence": 0.832444409529368}]}, {"text": "During training, a pseudo-likelihood parameter estimation ( ) was used as an initial weight (estimated in 30 iterations).", "labels": [], "entities": []}, {"text": "We used complete and dense input/output joint features for dense model (Dense), and only supported features that are used at least once in the training examples for sparse form better, the sparse model performs well in practice without significant loss of accuracy (.: Data sets: number of sentences in the training (#Train) and the test data sets (#Test), and number of output labels (#Label).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 256, "end_pos": 264, "type": "METRIC", "confidence": 0.9955305457115173}]}, {"text": "|A \u03c9=1 avg | denotes the average number of active set when \u03c9 = 1, i.e., the supported transitions that are used at least once in the training set.", "labels": [], "entities": []}, {"text": "We first show that our method is efficient for learning CRFs.", "labels": [], "entities": []}, {"text": "In all learning curves, Dense generally has a higher training log-likelihood than Sparse.", "labels": [], "entities": []}, {"text": "For PTB and Encyclopedia, results for Dense are not available because training in a single machine failed due to out-of-memory errors.", "labels": [], "entities": [{"text": "PTB", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.86700838804245}, {"text": "Encyclopedia", "start_pos": 12, "end_pos": 24, "type": "DATASET", "confidence": 0.9178304672241211}, {"text": "Dense", "start_pos": 38, "end_pos": 43, "type": "TASK", "confidence": 0.8109447360038757}]}, {"text": "For both Dense and Sparse, we executed the exact inference method.", "labels": [], "entities": [{"text": "Sparse", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.7275704145431519}]}, {"text": "Our proposed method (Method 1\u223c4) performs faster than Sparse.", "labels": [], "entities": []}, {"text": "In most results, Method 1 was the fastest, because it was terminated after fewer iterations.", "labels": [], "entities": []}, {"text": "However, Method 1 sometimes failed to converge, for example, in Encyclopedia.", "labels": [], "entities": [{"text": "Encyclopedia", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.8993934988975525}]}, {"text": "Similarly, Method 3 and 4 could not find the optimal solution in the NetTalk data set.", "labels": [], "entities": [{"text": "NetTalk data set", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.9794784386952718}]}, {"text": "Method 2 showed stable results.", "labels": [], "entities": []}, {"text": "Second, we evaluated the accuracy and decoding time of our methods (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995206594467163}]}, {"text": "Most results obtained using our method were as accurate as those of Dense and Sparse.", "labels": [], "entities": [{"text": "Sparse", "start_pos": 78, "end_pos": 84, "type": "DATASET", "confidence": 0.7180646061897278}]}, {"text": "However, some results of Method 1, 3, and 4 were significantly inferior to those of Dense and Sparse for one of two reasons: 1) parameter estimation failed (NetTalk and Encyclopedia), or 2) approximate inference caused search errors (CoNLL00 and Communicator).", "labels": [], "entities": [{"text": "CoNLL00", "start_pos": 234, "end_pos": 241, "type": "DATASET", "confidence": 0.8268627524375916}]}, {"text": "(f) Encyclopedia: Result of training linear-chain CRFs: Un-normalized training log-likelihood and training times are compared.", "labels": [], "entities": []}, {"text": "Dashed lines denote the termination of training step.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data sets: number of sentences in the train- ing (#Train) and the test data sets (#Test), and number  of output labels (#Label). |A \u03c9=1  avg | denotes the average  number of active set when \u03c9 = 1, i.e., the supported  transitions that are used at least once in the training set.", "labels": [], "entities": []}]}