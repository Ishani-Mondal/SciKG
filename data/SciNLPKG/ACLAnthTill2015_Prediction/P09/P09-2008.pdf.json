{"title": [{"text": "A Novel Word Segmentation Approach for Written Languages with Word Boundary Markers", "labels": [], "entities": [{"text": "Word Segmentation Approach", "start_pos": 8, "end_pos": 34, "type": "TASK", "confidence": 0.7585670252641042}]}], "abstractContent": [{"text": "Most NLP applications work under the assumption that a user input is error-free; thus, word segmentation (WS) for written languages that use word boundary markers (WBMs), such as spaces, has been regarded as a trivial issue.", "labels": [], "entities": [{"text": "word segmentation (WS)", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.8456432104110718}]}, {"text": "However, noisy real-world texts, such as blogs, e-mails, and SMS, may contain spacing errors that require correction before further processing may take place.", "labels": [], "entities": []}, {"text": "For the Korean language , many researchers have adopted a traditional WS approach, which eliminates all spaces in the user input and re-inserts proper word boundaries.", "labels": [], "entities": [{"text": "WS", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9747426509857178}]}, {"text": "Unfortunately, such an approach often exacerbates the word spacing quality for user input, which has few or no spacing errors; such is the case, because a perfect WS model does not exist.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel WS method that takes into consideration the initial word spacing information of the user input.", "labels": [], "entities": [{"text": "WS", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9920728802680969}]}, {"text": "Our method generates a better output than the original user input , even if the user input has few spacing errors.", "labels": [], "entities": []}, {"text": "Moreover, the proposed method significantly outperforms a state-of-the-art Korean WS model when the user input initially contains less than 10% spacing errors , and performs comparably for cases containing more spacing errors.", "labels": [], "entities": []}, {"text": "We believe that the proposed method will be a very practical pre-processing module.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word segmentation (WS) has been a fundamental research issue for languages that do not have word boundary markers (WBMs); on the contrary, other languages that do have WBMs have regarded the issue as a trivial task.", "labels": [], "entities": [{"text": "Word segmentation (WS)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8590109050273895}]}, {"text": "Texts segmented with such WBMs, however, could contain a human writer's intentional or un-intentional spacing errors; and even a few spacing errors can cause error-propagation for further NLP stages.", "labels": [], "entities": []}, {"text": "For written languages that have WBMs, such as for the Korean language, the majority of recent research has been based on a traditional WS approach).", "labels": [], "entities": [{"text": "WS", "start_pos": 135, "end_pos": 137, "type": "TASK", "confidence": 0.9285359978675842}]}, {"text": "The first step of the traditional approach is to eliminate all spaces in the user input, and then re-locate the proper places to insert WBMs.", "labels": [], "entities": []}, {"text": "One state-of-the-art Korean WS model () is known to achieve a performance of 90.31% word-unit precision, which is comparable with other WS models for the Chinese or Japanese language.", "labels": [], "entities": [{"text": "WS", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.8123452067375183}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9487947821617126}]}, {"text": "Still, there is a downside to the evaluation method.", "labels": [], "entities": []}, {"text": "If the user input has a few or no spacing errors, traditional WS models may cause more spacing errors than it correct because they produce the same output regardless the word spacing states of the user input.", "labels": [], "entities": [{"text": "WS", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9417480826377869}]}, {"text": "In this paper, we propose anew WS method that takes into account the word spacing information from the user input.", "labels": [], "entities": [{"text": "WS", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9783596396446228}, {"text": "word spacing", "start_pos": 69, "end_pos": 81, "type": "TASK", "confidence": 0.6655916422605515}]}, {"text": "Our proposed method first generates the best word spacing states for the user input by using a traditional WS model; however the method does not immediately apply the output.", "labels": [], "entities": []}, {"text": "Secondly, the method estimates a threshold based on the word spacing quality of the user input.", "labels": [], "entities": []}, {"text": "Finally, the method uses the new word spacing states that have probabilities that are higher than the threshold.", "labels": [], "entities": []}, {"text": "The most important contribution of the proposed method is that, for most cases, the method generates an output that is better than the user input.", "labels": [], "entities": []}, {"text": "The experimental results show that the proposed method produces a better output than the user input even if the user input has less than 1% spacing errors in terms of the character-unit precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.748436689376831}]}, {"text": "Moreover, the proposed method outperforms ( significantly, when the user input initially contains less than 10% spacing errors, and even performs comparably, when the input contains more than 10% errors.", "labels": [], "entities": []}, {"text": "Based on these results, we believe that the proposed method would be a very practical pre-processing module for other NLP applications.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 explains the proposed method.", "labels": [], "entities": []}, {"text": "Section 3 shows the experimental results.", "labels": [], "entities": []}, {"text": "Finally, the last section describes the contributions of the proposed method.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two types of experiments have been performed.", "labels": [], "entities": []}, {"text": "In the first experiment, we investigate the level of performance improvement based on different settings of the user input's word spacing error rate.", "labels": [], "entities": []}, {"text": "Because it is nearly impossible to obtain enough test data for any error rate, we generate pseudo test data in the same way that we generate development data.", "labels": [], "entities": []}, {"text": "In the second experiment, we attempt See Footnote 3.", "labels": [], "entities": [{"text": "See Footnote 3", "start_pos": 37, "end_pos": 51, "type": "METRIC", "confidence": 0.4844416578610738}]}, {"text": "figuring out whether the proposed method really improves the word spacing quality of the user input in a real-world setting.", "labels": [], "entities": [{"text": "word spacing", "start_pos": 61, "end_pos": 73, "type": "TASK", "confidence": 0.6768629848957062}]}], "tableCaptions": [{"text": " Table 1: Performance comparison with Web text", "labels": [], "entities": []}, {"text": " Table 1. The  overall performance of Lee's model, the baseline  WS model and the proposed method decreased  by roughly 18%. We hypothesize that the per- formance degradation probably results from the  spelling errors of the test data, and the inconsis- tencies that exist between the training data and the  test data. However, the proposed method still im- proves the word spacing quality of the user input  by 3%, while the two traditional WS models de- grades the quality. Such a result indicates that  the proposed method is effective for real-world  environments, as we had intended. Furthermore,  we also believe that the performance can be im- proved if a proper training corpus is provided, or  if a spelling correction method is integrated.", "labels": [], "entities": []}]}