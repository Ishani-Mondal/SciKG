{"title": [{"text": "A Non-negative Matrix Tri-factorization Approach to Sentiment Classification with Lexical Prior Knowledge", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.9567360281944275}]}], "abstractContent": [{"text": "Sentiment classification refers to the task of automatically identifying whether a given piece of text expresses positive or negative opinion towards a subject at hand.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9635665118694305}, {"text": "automatically identifying whether a given piece of text expresses positive or negative opinion towards a subject at hand", "start_pos": 47, "end_pos": 167, "type": "TASK", "confidence": 0.5444980843199624}]}, {"text": "The proliferation of user-generated web content such as blogs, discussion forums and online review sites has made it possible to perform large-scale mining of public opinion.", "labels": [], "entities": []}, {"text": "Sentiment modeling is thus becoming a critical component of market intelligence and social media technologies that aim to tap into the collective wisdom of crowds.", "labels": [], "entities": [{"text": "Sentiment modeling", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9398274123668671}]}, {"text": "In this paper, we consider the problem of learning high-quality sentiment models with minimal manual supervision.", "labels": [], "entities": []}, {"text": "We propose a novel approach to learn from lexical prior knowledge in the form of domain-independent sentiment-laden terms, in conjunction with domain-dependent unlabeled data and a few labeled documents.", "labels": [], "entities": []}, {"text": "Our model is based on a constrained non-negative tri-factorization of the term-document matrix which can be implemented using simple update rules.", "labels": [], "entities": []}, {"text": "Extensive experimental studies demonstrate the effectiveness of our approach on a variety of real-world sentiment prediction tasks.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.8534963726997375}]}], "introductionContent": [{"text": "Web 2.0 platforms such as blogs, discussion forums and other such social media have now given a public voice to every consumer.", "labels": [], "entities": []}, {"text": "Recent surveys have estimated that a massive number of internet users turn to such forums to collect recommendations for products and services, guiding their own choices and decisions by the opinions that other consumers have publically expressed.", "labels": [], "entities": []}, {"text": "Gleaning insights by monitoring and analyzing large amounts of such user-generated data is thus becoming a key competitive differentiator for many companies.", "labels": [], "entities": []}, {"text": "While tracking brand perceptions in traditional media is hardly anew challenge, handling the unprecedented scale of unstructured user-generated web content requires new methodologies.", "labels": [], "entities": []}, {"text": "These methodologies are likely to be rooted in natural language processing and machine learning techniques.", "labels": [], "entities": []}, {"text": "Automatically classifying the sentiment expressed in a blog around selected topics of interest is a canonical machine learning task in this discussion.", "labels": [], "entities": [{"text": "classifying the sentiment expressed in a blog around selected topics", "start_pos": 14, "end_pos": 82, "type": "TASK", "confidence": 0.8395560383796692}]}, {"text": "A standard approach would be to manually label documents with their sentiment orientation and then apply off-the-shelf text classification techniques.", "labels": [], "entities": [{"text": "text classification", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7465837001800537}]}, {"text": "However, sentiment is often conveyed with subtle linguistic mechanisms such as the use of sarcasm and highly domain-specific contextual cues.", "labels": [], "entities": []}, {"text": "This makes manual annotation of sentiment time consuming and error-prone, presenting a bottleneck in learning high quality models.", "labels": [], "entities": []}, {"text": "Moreover, products and services of current focus, and associated community of bloggers with their idiosyncratic expressions, may rapidly evolve overtime causing models to potentially lose performance and become stale.", "labels": [], "entities": []}, {"text": "This motivates the problem of learning robust sentiment models from minimal supervision.", "labels": [], "entities": []}, {"text": "In their seminal work, () demonstrated that supervised learning significantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms.", "labels": [], "entities": []}, {"text": "As observed by), most semi-automated dictionary-based approaches yield unsatisfactory lexicons, with either high coverage and low precision or vice versa.", "labels": [], "entities": [{"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9904000163078308}]}, {"text": "However, the treatment of such dictionaries as forms of prior knowledge that can be incorporated in machine learning models is a relatively less explored topic; even lesser so in conjunction with semi-supervised models that attempt to utilize un-labeled data.", "labels": [], "entities": []}, {"text": "This is the focus of the current paper.", "labels": [], "entities": []}, {"text": "Our models are based on a constrained nonnegative tri-factorization of the term-document matrix, which can be implemented using simple update rules.", "labels": [], "entities": []}, {"text": "Treated as a set of labeled features, the sentiment lexicon is incorporated as one set of constraints that enforce domain-independent prior knowledge.", "labels": [], "entities": []}, {"text": "A second set of constraints introduce domain-specific supervision via a few document labels.", "labels": [], "entities": []}, {"text": "Together these constraints enable learning from partial supervision along both dimensions of the term-document matrix, in what maybe viewed more broadly as a framework for incorporating dual-supervision in matrix factorization models.", "labels": [], "entities": []}, {"text": "We provide empirical comparisons with several competing methodologies on four, very different domains -blogs discussing enterprise software products, political blogs discussing US presidential candidates, amazon.com product reviews and IMDB movie reviews.", "labels": [], "entities": []}, {"text": "Results demonstrate the effectiveness and generality of our approach.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We begin by discussing related work in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 gives a quick background on Nonnegative Matrix Tri-factorization models.", "labels": [], "entities": []}, {"text": "In Section 4, we present a constrained model and computational algorithm for incorporating lexical knowledge in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.9546619653701782}]}, {"text": "In Section 5, we enhance this model by introducing document labels as additional constraints.", "labels": [], "entities": []}, {"text": "Section 6 presents an empirical study on four datasets.", "labels": [], "entities": []}, {"text": "Finally, Section 7 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Four different datasets are used in our experiments.", "labels": [], "entities": []}, {"text": "Movies Reviews: This is a popular dataset in sentiment analysis literature).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.9348533749580383}]}, {"text": "It consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB archive of the rec.arts.movies.reviews newsgroups.", "labels": [], "entities": [{"text": "IMDB archive of the rec.arts.movies.reviews newsgroups", "start_pos": 76, "end_pos": 130, "type": "DATASET", "confidence": 0.8858732481797537}]}, {"text": "Lotus blogs: The data set is targeted at detecting sentiment around enterprise software, specifically pertaining to the IBM Lotus brand).", "labels": [], "entities": []}, {"text": "An unlabeled set of blog posts was created by randomly sampling 2000 posts from a universe of 14,258 blogs that discuss issues relevant to Lotus software.", "labels": [], "entities": []}, {"text": "In addition to this unlabeled set, 145 posts were chosen for manual labeling.", "labels": [], "entities": []}, {"text": "These posts came from 14 individual blogs, 4 of which are actively posting negative content on the brand, with the rest tending to write more positive or neutral posts.", "labels": [], "entities": []}, {"text": "For all datasets, we picked 5000 words with highest document-frequency to generate the vocabulary.", "labels": [], "entities": []}, {"text": "Stopwords were removed and a normalized term-frequency representation was used.", "labels": [], "entities": []}, {"text": "Genuinely unlabeled posts for Political and Lotus were used for semi-supervised learning experiments in section 6.3; they were not used in section 6.2 on the effect of lexical prior knowledge.", "labels": [], "entities": []}, {"text": "In the experiments, we set \u03b1, the parameter determining the extent to which to enforce the feature labels, to be 1/2, and \u03b2, the corresponding parameter for enforcing document labels, to be 1.", "labels": [], "entities": []}], "tableCaptions": []}