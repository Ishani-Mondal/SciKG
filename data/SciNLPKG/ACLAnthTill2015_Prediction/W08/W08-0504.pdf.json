{"title": [{"text": "Evaluating the Effects of Treebank Size in a Practical Application for Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.8268077373504639}]}], "abstractContent": [{"text": "Natural language processing modules such as part-of-speech taggers, named-entity recog-nizers and syntactic parsers are commonly evaluated in isolation, under the assumption that artificial evaluation metrics for individual parts are predictive of practical performance of more complex language technology systems that perform practical tasks.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7271727621555328}]}, {"text": "Although this is an important issue in the design and engineering of systems that use natural language input, it is often unclear how the accuracy of an end-user application is affected by parameters that affect individual NLP modules.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9970353841781616}]}, {"text": "We explore this issue in the context of a specific task by examining the relationship between the accuracy of a syntactic parser and the overall performance of an information extraction system for biomedical text that includes the parser as one of its components.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9984806180000305}, {"text": "information extraction", "start_pos": 163, "end_pos": 185, "type": "TASK", "confidence": 0.7383494079113007}]}, {"text": "We present an empirical investigation of the relationship between factors that affect the accuracy of syntactic analysis, and how the difference in parse accuracy affects the overall system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9981299042701721}, {"text": "syntactic analysis", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7675666809082031}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.7706876993179321}]}], "introductionContent": [{"text": "Software systems that perform practical tasks with natural language input often include, in addition to task-specific components, a pipeline of basic natural language processing modules, such as part-ofspeech taggers, named-entity recognizers, syntactic parsers and semantic-role labelers.", "labels": [], "entities": []}, {"text": "Although such building blocks of larger language technology solutions are usually carefully evaluated in isolation using standard test sets, the impact of improvements in each individual module on the overall performance of end-to-end systems is less well understood.", "labels": [], "entities": []}, {"text": "While the effects of the amount of training data, search beam widths and various machine learning frameworks have been explored in detail with respect to speed and accuracy in basic natural language processing tasks, how these tradeoffs in individual modules affect the performance of the larger systems they compose is an issue that has received relatively little attention.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9950544834136963}]}, {"text": "This issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language.", "labels": [], "entities": []}, {"text": "In this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of proteinprotein interactions (PPI) mentioned in papers abstracts from MEDLINE, a large database of biomedical papers.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.8052034676074982}, {"text": "identification of proteinprotein interactions (PPI)", "start_pos": 122, "end_pos": 173, "type": "TASK", "confidence": 0.836054299558912}, {"text": "MEDLINE", "start_pos": 209, "end_pos": 216, "type": "DATASET", "confidence": 0.8820165395736694}]}, {"text": "Due in large part to the creation of biomedical treebanks) and rapid progress of data-driven parsers (, there are now fast, robust and accurate syntactic parsers for text in the biomedical domain.", "labels": [], "entities": []}, {"text": "Recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.9738459587097168}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9808803200721741}]}, {"text": "Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text.", "labels": [], "entities": []}, {"text": "Recent PPI extraction systems have confirmed this intuition ().", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 7, "end_pos": 21, "type": "TASK", "confidence": 0.8199420869350433}]}, {"text": "We attempt to shed some light on these matters by presenting experiments that show the relationship of the accuracy of a dependency parser and the accuracy of the larger PPI system that includes the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9984772801399231}, {"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9983687996864319}]}, {"text": "We investigate the effects of domain-specific treebank size (the amount of available manually annotated training data for syntactic parsers) and final system performance, and obtain results that should be informative to researchers in bioinformatics who rely on existing NLP resources to design information extraction systems, as well as to members of the parsing community who are interested in the practical impact of parsing research.", "labels": [], "entities": [{"text": "parsing community", "start_pos": 356, "end_pos": 373, "type": "TASK", "confidence": 0.9040720462799072}]}, {"text": "In section 2 we discuss our motivation and related efforts.", "labels": [], "entities": []}, {"text": "Section 3 describes the system for identification of protein-protein interactions used in our experiments, and in section 4 describes the syntactic parser that provides the analyses for the PPI system, and the data used to train the parser.", "labels": [], "entities": []}, {"text": "We describe our experiments, results and analysis in section 5, and conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our PPI extraction experiments applying the dependency parsers trained with the different amounts of the GENIA Treebank in our PPI system.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.9105550646781921}, {"text": "GENIA Treebank", "start_pos": 132, "end_pos": 146, "type": "DATASET", "confidence": 0.9809975922107697}]}, {"text": "As we mentioned, the GENIA Treebank is used for training the parser, while the Aimed is used for training and evaluation of PPI extraction.", "labels": [], "entities": [{"text": "GENIA Treebank", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.8530039489269257}, {"text": "Aimed", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.8351361155509949}, {"text": "PPI extraction", "start_pos": 124, "end_pos": 138, "type": "TASK", "confidence": 0.8584141135215759}]}, {"text": "A part-of-speech tagger trained with GENIA and PennBioIE was used.", "labels": [], "entities": [{"text": "part-of-speech tagger", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.7128133475780487}, {"text": "GENIA", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.910857617855072}, {"text": "PennBioIE", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.972719132900238}]}, {"text": "We do not apply automatic protein name detection, and instead use the gold-standard protein annotations in the Aimed corpus.", "labels": [], "entities": [{"text": "protein name detection", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.6798876424630483}, {"text": "Aimed corpus", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.9283851683139801}]}, {"text": "Before running a parser, multiword protein names are concatenated and treated as single words.", "labels": [], "entities": []}, {"text": "As described in Section 3, bag-of-words and syntactic dependency paths are fed as features to the PPI classifier.", "labels": [], "entities": []}, {"text": "The accuracy of PPI extraction is measured by the abstract-wise 10-fold cross validation ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994668364524841}, {"text": "PPI extraction", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.9361907243728638}]}, {"text": "When we use the part-of-speech tagger and the dependency parser trained with WSJ, the accuracy (F-score) of PPI extraction on this data set is 55.2.", "labels": [], "entities": [{"text": "part-of-speech tagger", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7060516774654388}, {"text": "WSJ", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.8755782842636108}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9996167421340942}, {"text": "F-score)", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.865697830915451}, {"text": "PPI extraction", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.8377473652362823}]}, {"text": "The accuracy increases to 56.9 when we train the part-of-speech tagger with GENIA and Penn BioIE, while using the WSJ-trained parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996538162231445}, {"text": "part-of-speech tagger", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7372248470783234}, {"text": "GENIA", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.7706580758094788}, {"text": "Penn BioIE", "start_pos": 86, "end_pos": 96, "type": "DATASET", "confidence": 0.7852763235569}, {"text": "WSJ-trained", "start_pos": 114, "end_pos": 125, "type": "DATASET", "confidence": 0.9171669483184814}]}, {"text": "This confirms the claims by that subsentential lexical analysis alone is helpful in adapting WSJ parsers to the biomedical domain.", "labels": [], "entities": [{"text": "WSJ parsers", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.7438197433948517}]}, {"text": "While Lease and Charniak looked only at parse accuracy, our result shows that the increase in parse accuracy is, as expected, beneficial in practice.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.8926549553871155}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.8508714437484741}]}, {"text": "shows the relationship between the amount of parser training data and the F-score for the PPI extraction.", "labels": [], "entities": [{"text": "F-score", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.9984069466590881}, {"text": "PPI extraction", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.7854777574539185}]}, {"text": "The result shows that the accuracy of PPI extraction increases with the use of more sentences to train the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.999460756778717}, {"text": "PPI extraction", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.9267592132091522}]}, {"text": "The best accuracy was obtained when using 4,000 sentences, where parsing accuracy is around 84.3.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9992653727531433}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9694381952285767}]}, {"text": "Although it may appear that further increasing the training data for the parser may not improve the PPI extraction accuracy (since only small and inconsistent variations in F-score are observed in), when we plot the curves shown in in a single graph, we see that the two curves match each other to a large extent.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.8448970913887024}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.924325704574585}, {"text": "F-score", "start_pos": 173, "end_pos": 180, "type": "METRIC", "confidence": 0.990928590297699}]}, {"text": "This is supported by the strong correlation between parse accuracy and PPI accuracy observed in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.7968205213546753}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.6590937376022339}]}, {"text": "While this suggests that training the parser with a larger treebank may result in improved accuracy in PPI extraction, we observe that a 1% absolute improvement in parser accuracy corresponds roughly to a 0.25 improvement in PPI extraction F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9984979629516602}, {"text": "PPI extraction", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.93905970454216}, {"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9823040962219238}, {"text": "PPI extraction", "start_pos": 225, "end_pos": 239, "type": "TASK", "confidence": 0.8422181904315948}, {"text": "F-score", "start_pos": 240, "end_pos": 247, "type": "METRIC", "confidence": 0.7772808074951172}]}, {"text": "indicates that to obtain even a 1% improvement in parser accuracy by using more training data, the size of the treebank would have to increase significantly.", "labels": [], "entities": [{"text": "parser", "start_pos": 50, "end_pos": 56, "type": "TASK", "confidence": 0.9620648622512817}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9479787349700928}]}, {"text": "Although the results presented so far seem to suggest the need fora large data annotation effort to achieve a meaningful improvement in PPI extraction accuracy, there are other ways to improve the overall accuracy of the system without an improvement in parser accuracy.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 136, "end_pos": 150, "type": "TASK", "confidence": 0.8602559864521027}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.844682514667511}, {"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9920103549957275}, {"text": "accuracy", "start_pos": 261, "end_pos": 269, "type": "METRIC", "confidence": 0.7957367300987244}]}, {"text": "One obvious alternative is to increase the size of the PPI-annotated corpus (which is distinct from the treebank used to train the parser).", "labels": [], "entities": []}, {"text": "As mentioned in section 3, our system is trained using the Aimed corpus, which contains 225 abstracts from biomedical papers with manual annotations indicating interactions between proteins.", "labels": [], "entities": [{"text": "Aimed corpus", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.7264077812433243}]}, {"text": "Pairs of proteins with no interaction described in the text are used as negative examples, and pairs of proteins described as interacting are used as positive examples.", "labels": [], "entities": []}, {"text": "The corpus contains a total of roughly 9,000 examples.", "labels": [], "entities": []}, {"text": "shows how the overall system accuracy varies when different amounts of training data (varying amounts of training examples) are used to train the PPI system (keeping the parse accuracy constant, using all of the available training data in the GENIA treebank to train the parser).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9947381615638733}, {"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.540799081325531}, {"text": "GENIA treebank", "start_pos": 243, "end_pos": 257, "type": "DATASET", "confidence": 0.9833832681179047}]}, {"text": "While indicates that a significant improvement in parse accuracy requires a large increase in the treebank used to train the parser, and shows that improvements in PPI extraction accuracy may require a sizable improvement in parse accuracy, suggests that even a relatively small increase in the PPI corpus may lead to a significant improvement in PPI extraction accuracy.", "labels": [], "entities": [{"text": "parse", "start_pos": 50, "end_pos": 55, "type": "TASK", "confidence": 0.9526199102401733}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.563366174697876}, {"text": "PPI extraction", "start_pos": 164, "end_pos": 178, "type": "TASK", "confidence": 0.8349218964576721}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.573581337928772}, {"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.6405798196792603}, {"text": "PPI extraction", "start_pos": 347, "end_pos": 361, "type": "TASK", "confidence": 0.8925514817237854}, {"text": "accuracy", "start_pos": 362, "end_pos": 370, "type": "METRIC", "confidence": 0.7206186056137085}]}, {"text": "While some of the conclusions that can be drawn from these results maybe somewhat surprising, most are entirely expected.", "labels": [], "entities": []}, {"text": "However, even in these straightforward cases, our experiments provide some empirical evidence and concrete quantitative analysis to complement intuition.", "labels": [], "entities": []}, {"text": "We see that using domain-specific training data for the parsing component for the PPI extraction system produces superior results, compared to using training data from the WSJ Penn Treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.9626791477203369}, {"text": "PPI extraction", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.8302667737007141}, {"text": "WSJ Penn Treebank", "start_pos": 172, "end_pos": 189, "type": "DATASET", "confidence": 0.9347664515177408}]}, {"text": "When the parser trained on WSJ sentences is used, PPI extraction accuracy is about 55, compared to over 57 when sentences from biomedical papers are used.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.7936395108699799}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9486165046691895}]}, {"text": "This corresponds fairly closely to the differences in parser accuracy: the accuracy of the parser trained on 500 sentences from GENIA is about the same as the accuracy of the parser trained on the entire WSJ Penn Treebank, and when these parsers are used in the PPI extraction system, they result in similar overall task accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9581044912338257}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9973331689834595}, {"text": "GENIA", "start_pos": 128, "end_pos": 133, "type": "DATASET", "confidence": 0.917068600654602}, {"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9851090908050537}, {"text": "WSJ Penn Treebank", "start_pos": 204, "end_pos": 221, "type": "DATASET", "confidence": 0.9238050977389017}, {"text": "PPI extraction", "start_pos": 262, "end_pos": 276, "type": "TASK", "confidence": 0.8556651175022125}, {"text": "accuracy", "start_pos": 321, "end_pos": 329, "type": "METRIC", "confidence": 0.9453732371330261}]}, {"text": "However, the results obtained when a domain-specific POS tagger is combined with a parser trained with out-of-domain data, overall PPI results are nearly at the same level as those obtained with domain-specific training data (just below 57 with a domain-specific POS tagger and out-of-domain parser, and just above 57 for domain-specific POS tagger and parser).", "labels": [], "entities": []}, {"text": "At the same time, the argument against annotating domain-specific data for parsers in new domains is not a strong one, since higher accuracy levels (for both the parser and the overall system) can be obtained with a relatively small amount of domainspecific data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9968186616897583}]}, {"text": "Figures 5, 6 and 7 also suggest that additional efforts in improving parser accuracy (through the use of feature engineering, other machine learning techniques, or an increase in the size of its training set) could improve PPI extraction accuracy, but a large improvement in parser accuracy maybe required.", "labels": [], "entities": [{"text": "parser", "start_pos": 69, "end_pos": 75, "type": "TASK", "confidence": 0.9660367369651794}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.8470884561538696}, {"text": "PPI extraction", "start_pos": 223, "end_pos": 237, "type": "TASK", "confidence": 0.9384895265102386}, {"text": "accuracy", "start_pos": 238, "end_pos": 246, "type": "METRIC", "confidence": 0.8896801471710205}, {"text": "accuracy", "start_pos": 282, "end_pos": 290, "type": "METRIC", "confidence": 0.9192903637886047}]}, {"text": "When we combine these results with the findings obtained by, they suggest that a better way to improve the overall system is to spend more effort in designing a specific syntactic representation that addresses the needs of the system, instead of using a generic representation designed for measuring parser accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 307, "end_pos": 315, "type": "METRIC", "confidence": 0.9082302451133728}]}, {"text": "Another potentially fruitful course of action is to design more sophisticated and effective ways for information extraction systems to use NLP tools, rather than simply extracting features that correspond to small fragments of syntactic trees.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.7654938399791718}]}, {"text": "Of course, making proper use of natural language analysis is a considerable challenge, but one that should be kept in mind through the design of practical systems that use NLP components.", "labels": [], "entities": [{"text": "natural language analysis", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.707426110903422}]}], "tableCaptions": []}