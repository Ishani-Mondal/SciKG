{"title": [{"text": "Eliciting Subjectivity and Polarity Judgements on Word Senses", "labels": [], "entities": [{"text": "Polarity Judgements on Word Senses", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.6404491901397705}]}], "abstractContent": [{"text": "There has been extensive work on eliciting human judgements on the sentiment of words and the resulting annotated word lists have frequently been used for opinion mining applications in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 155, "end_pos": 169, "type": "TASK", "confidence": 0.7825663089752197}]}, {"text": "However, this word-based approach does not take different senses of a word into account, which might differ in whether and what kind of sentiment they evoke.", "labels": [], "entities": []}, {"text": "In this paper, we therefore introduce a human annotation scheme for judging both the subjectivity and polarity of word senses.", "labels": [], "entities": []}, {"text": "We show that the scheme is overall reliable, making this a well-defined task for automatic processing.", "labels": [], "entities": []}, {"text": "We also discuss three issues that surfaced during annotation: the role of annotation bias, hierarchical annotation (or un-derspecification) and bias in the sense inventory used.", "labels": [], "entities": []}], "introductionContent": [{"text": "Work in psychology, linguistics and computational linguistics has explored the affective connotations of words via eliciting human judgements (see Section 2 for an in-depth review).", "labels": [], "entities": []}, {"text": "Two important parameters in determining affective meaning that have emerged are subjectivity and polarity.", "labels": [], "entities": []}, {"text": "Subjectivity identification focuses on determining whether a language unit (such as a word, sentence or document) is subjective, i.e. whether it expresses a private state, opinion or attitude, or is factual.", "labels": [], "entities": [{"text": "Subjectivity identification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9231006503105164}]}, {"text": "Polarity identification focuses on whether a language unit has a positive or negative connotation.", "labels": [], "entities": [{"text": "Polarity identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6965337544679642}]}, {"text": "Word lists that result from such studies would, for example tag good or positive as a positive word, bad as negative and table as neither.", "labels": [], "entities": []}, {"text": "Such word lists have frequently been used in natural language processing applications, such as the automatic identification of a review as favourable or unfavourable).", "labels": [], "entities": []}, {"text": "However, the word-based annotation conducted so far is at least partially unreliable.", "labels": [], "entities": []}, {"text": "Thus find only a 78.7% agreement on subjectivity/polarity tags between two widely used word lists.", "labels": [], "entities": []}, {"text": "One problem they identify is that wordbased annotation does not take different senses of a word into account.", "labels": [], "entities": []}, {"text": "Thus, many words are subjectivity-ambiguous or polarity-ambiguous, i.e. have both subjective and objective or both positive and negative senses, such as the words positive and catch with corresponding example senses given below.", "labels": [], "entities": []}, {"text": "(1) positive, electropositive-having a positive electric charge;\"protons are positive\" (objective) (2) plus, positive-involving advantage or good; \"a plus (or positive) factor\" (subjective) Inspired by and, we therefore explore the subjectivity and polarity annotation of word senses instead of words.", "labels": [], "entities": []}, {"text": "We hypothesize that annotation at the sense level might eliminate one possible source of disagreement for subjectivity/polarity annotation and will therefore hopefully lead to higher agreement than at the word level.", "labels": [], "entities": []}, {"text": "An additional advantage for practical purposes is that subjectivity labels for senses add an additional layer of annotation to electronic lexica and can therefore increase their usability.", "labels": [], "entities": []}, {"text": "As an example, prove that subjectivity information for WordNet senses can improve word sense disambiguation tasks for subjectivityambiguous words (such as positive).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.7227611740430196}]}, {"text": "In addition, show that the performance of automatic annotation of subjectivity at the word level can be hurt by the presence of subjectivity-ambiguous words in the training sets they use.", "labels": [], "entities": []}, {"text": "A potential disadvantage for annotation at the sense level is that it is dependent on a lexical resource for sense distinctions and that an annotation scheme might have to take idiosyncracies of specific resources into account or, ideally, abstract away from them.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the reliability of manual subjectivity labeling of word senses.", "labels": [], "entities": []}, {"text": "Specifically, we markup subjectivity/attitude (subjective, objective, and both) of word senses as well as polarity/connotation (positive, negative and no polarity).", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first annotation scheme for judging both subjectivity and polarity of word senses.", "labels": [], "entities": []}, {"text": "We test its reliability on the WordNet sense inventory.", "labels": [], "entities": [{"text": "reliability", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9910815954208374}, {"text": "WordNet sense inventory", "start_pos": 31, "end_pos": 54, "type": "DATASET", "confidence": 0.9714180032412211}]}, {"text": "Overall, the experimental results show high agreement, confirming our hypothesis that agreement at sense level might be higher than at the word level.", "labels": [], "entities": [{"text": "agreement", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9851067066192627}]}, {"text": "The annotated sense inventory will be made publically available to other researchers at http://www.", "labels": [], "entities": []}, {"text": "comp.leeds.ac.uk/markert/data.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses previous related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our human annotation scheme for word sense subjectivity and polarity in detail.", "labels": [], "entities": []}, {"text": "Section 4 presents the experimental results and evaluation.", "labels": [], "entities": []}, {"text": "We also discuss the problems of bias in the annotation scheme, the impact of hierarchical organization or underspecification on agreement as well as problems with bias in WordNet sense descriptions.", "labels": [], "entities": []}, {"text": "Section 5 compares our annotation to the annotation of a different scheme, followed by conclusions and future work in Section 6.", "labels": [], "entities": []}, {"text": "proposed semantic differential to measure the connotative meaning of concepts.", "labels": [], "entities": []}, {"text": "They conducted a factor analysis of large collections of semantic differential scales and pointed out three referring attitudes that people use to evaluate words and phrases-evaluation (goodbad), potency (strong-weak), and activity (activepassive).", "labels": [], "entities": []}, {"text": "Also, they showed that these three dimensions of affective meaning are cross-cultural universals from a study on dozens of cultures.", "labels": [], "entities": []}, {"text": "This work has spawned a considerable amount of linguistic and psychological work in affect analysis on the word level.", "labels": [], "entities": [{"text": "affect analysis", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.7806352078914642}]}, {"text": "In psychology both the Affective Norms for English Words (ANEW) project as well as the Magellan project focus on collecting human judgements on affective meanings of words, roughly following Osgood's scheme.", "labels": [], "entities": []}, {"text": "In the ANEW project they collected numerical ratings of pleasure (equivalent to our term polarity), arousal, and dominance for 1000 English terms) and in Magellan they collected cross-cultural affective meanings (including polarity) in a wide variety of countries such as the USA, China, Japan, and Germany.", "labels": [], "entities": [{"text": "ANEW project", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.811990350484848}, {"text": "dominance", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9672396183013916}]}, {"text": "Both projects concentrate on collecting a large number of ratings on a large variety of words: there is no principled evaluation of agreement.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the experimental setup for our annotation experiments, presents reliability results and discusses the benefits of the use of a hierarchical annotation scheme as well as the problems of bias in the annotation scheme, annotator preferences and bias in the sense inventory.", "labels": [], "entities": []}, {"text": "The dataset used in our annotation scheme is the Micro-WNOp corpus , which contains all senses of 298 words in WordNet 2.0.", "labels": [], "entities": [{"text": "Micro-WNOp corpus", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.9404672086238861}]}, {"text": "We used it as it is representative of WordNet with respect to its partof-speech distribution and includes synsets of relatively frequent words, including a wide variety of subjective senses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.9680450558662415}]}, {"text": "It contains 1105 synsets in total, divided into three groups common (110 synset), group1 (496 synsets) and group2 (499 synsets).", "labels": [], "entities": []}, {"text": "We used common as the training set for the annotators and tested annotation reliability on group1.", "labels": [], "entities": []}, {"text": "Annotation was performed by two annotators.", "labels": [], "entities": [{"text": "Annotation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.49808576703071594}]}, {"text": "Both are fluent English speakers; one is a computational linguist whereas the other is not in linguistics.", "labels": [], "entities": []}, {"text": "All annotation was carried out independently and without discussion during the annotation process.", "labels": [], "entities": []}, {"text": "The annotators were furnished with guideline annotations with examples for each category.", "labels": [], "entities": []}, {"text": "Annotators saw the full synset, including all synonyms, glosses and examples.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Confusion matrix for the training data", "labels": [], "entities": []}, {"text": " Table 2: Confusion matrix on the test set", "labels": [], "entities": []}, {"text": " Table 3: Confusion matrix for Subjectivity", "labels": [], "entities": [{"text": "Subjectivity", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9174649715423584}]}, {"text": " Table 4: Confusion matrix for Polarity", "labels": [], "entities": [{"text": "Polarity", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.7107503414154053}]}, {"text": " Table 5: Reliability of original annotation on  Micro-WNOp", "labels": [], "entities": [{"text": "Micro-WNOp", "start_pos": 49, "end_pos": 59, "type": "DATASET", "confidence": 0.8909205794334412}]}]}