{"title": [{"text": "How Well Do Semantic Relatedness Measures Perform? A Meta-Study", "labels": [], "entities": [{"text": "Semantic Relatedness Measures Perform", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.8375162184238434}]}], "abstractContent": [{"text": "Various semantic relatedness, similarity, and distance measures have been proposed in the past decade and many NLP-applications strongly rely on these semantic measures.", "labels": [], "entities": [{"text": "similarity", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9481419324874878}]}, {"text": "Researchers compete for better algorithms and normally only few percentage points seem to suffice in order to prove anew measure outperforms an older one.", "labels": [], "entities": []}, {"text": "In this paper we present a meta-study comparing various semantic measures and their correlation with human judgments.", "labels": [], "entities": []}, {"text": "We show that the results are rather inconsistent and ask for detailed analyses as well as clarification.", "labels": [], "entities": []}, {"text": "We argue that the definition of a shared task might bring us considerably closer to understanding the concept of semantic relatedness.", "labels": [], "entities": []}], "introductionContent": [{"text": "Various applications in Natural Language Processing, such as Question Answering (), Topic Detection, and Text Summarization (, rely on semantic relatedness (similarity or distance) measures either based on word nets and/or corpus statistics as a resource.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.8390294909477234}, {"text": "Topic Detection", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.8815136551856995}, {"text": "Text Summarization", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.796179324388504}]}, {"text": "In the HyTex project, funded by the German Research Foundation, we develop strategies for the text-to-hypertext conversion using text-grammatical features.", "labels": [], "entities": [{"text": "German Research Foundation", "start_pos": 36, "end_pos": 62, "type": "DATASET", "confidence": 0.9193333188692728}, {"text": "text-to-hypertext conversion", "start_pos": 94, "end_pos": 122, "type": "TASK", "confidence": 0.7078501582145691}]}, {"text": "One strand of research in this project consists of topic-based linking methods using lexical chaining as a resource.", "labels": [], "entities": []}, {"text": "Lexical chaining is a well-known method to calculate partial text representations; it relies on semantic relatedness values as basic input.", "labels": [], "entities": [{"text": "Lexical chaining", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8689577877521515}]}, {"text": "We therefore implemented 2 eight semantic relatedness measures -() -based on GermaNet Lemnitzer and and three based on Google co-occurrence counts.", "labels": [], "entities": [{"text": "GermaNet Lemnitzer", "start_pos": 77, "end_pos": 95, "type": "DATASET", "confidence": 0.9107356369495392}]}, {"text": "In order to evaluate the performance of these measures we conducted two human judgment experiments and computed the correlation between the human judgment and the values of the eleven semantic measures.", "labels": [], "entities": []}, {"text": "We also compared our results with those reported in the literature and found that the correlations between human judgments and semantic measures are extremely scattered.", "labels": [], "entities": []}, {"text": "In this paper we compare the correlation of our own human judgment experiments and the results of three similar studies.", "labels": [], "entities": []}, {"text": "In our opinion this comparison points to the necessity of a thorough analysis of the methods used in these experiments.", "labels": [], "entities": []}, {"text": "We argue that this analysis should aim at answering the following questions: \u2022 How does the setting of the human judgment experiment influence the results?", "labels": [], "entities": []}, {"text": "\u2022 How does the selection of the word-pairs influence the results?", "labels": [], "entities": []}, {"text": "\u2022 Which aspects of semantic relatedness are included inhuman judgments?", "labels": [], "entities": [{"text": "semantic relatedness", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.7139382362365723}]}, {"text": "Thus, what do these experiments actually measure?", "labels": [], "entities": []}, {"text": "\u2022 Are the semantic relatedness measures proposed in the literature able to capture all of these aspects?", "labels": [], "entities": []}, {"text": "In this paper we intend to open the above mentioned analysis and therefore assembled a set of aspects which we consider to be important in order to answer these questions.", "labels": [], "entities": []}, {"text": "Consequently, the remainder of this paper is structured as follows: In Section 2 we The notions of semantic relatedness, similarity, and distance measure are controversially discussed in the literature, e.g..", "labels": [], "entities": [{"text": "similarity", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.9787691831588745}]}, {"text": "However, semantic similarity and relatedness seem to be the predominant terms in this context.", "labels": [], "entities": []}, {"text": "define them as follows: word-pairs are considered to be semantically similar if a synonymy or hypernymy relation holds.", "labels": [], "entities": []}, {"text": "In contrast, word-pairs are considered to be semantically related if a systematic relation, such as synonymy, antonymy, hypernymy, holonymy, or an unsystematic relation holds.", "labels": [], "entities": []}, {"text": "Thus relatedness is the more general (broader) concept since it includes intuitive associations as well as linguistically formalized relations between words (or concepts).", "labels": [], "entities": []}, {"text": "The focus of this paper is on relatedness.", "labels": [], "entities": []}, {"text": "2 Since GermaNet -e.g. in terms of internal structure -slightly differs from Princeton WordNet we could not simply use the measure implementations of the latter and therefore had to reimplement and adapt them for GermaNet.", "labels": [], "entities": [{"text": "Princeton WordNet", "start_pos": 77, "end_pos": 94, "type": "DATASET", "confidence": 0.8916068077087402}]}, {"text": "3 GermaNet is the German counterpart of WordNet present our own human judgment experiments.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9475622177124023}]}, {"text": "In Section 3 we describe three similar studies, two conducted with English data and one with German.", "labels": [], "entities": []}, {"text": "In Section 4 we compare the results of the four studies and discuss (with respect to the experimental setting and goals) potential differences and possible causes for the observed inconsistency of the results.", "labels": [], "entities": []}, {"text": "Finally, we summarize our work and outline some ideas for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the quality of a semantic measure, a set of pre-classified (i.e. judged with respect to their semantic relatedness by subjects) word-pairs is necessary.", "labels": [], "entities": []}, {"text": "In previous work for English data, most researchers used the word-pair list by as well as the list by as an evaluation resource.", "labels": [], "entities": []}, {"text": "For German there are -to our knowledge -two research groups, which compiled lists of word-pairs with respective human judgment: \u2022 Gurevych et al. constructed three lists (a translation of Rubenstein and Goodenough's list), a manually generated set of word-pairs, and a semi-automatically generated one ().", "labels": [], "entities": []}, {"text": "\u2022 While investigating lexical chaining for German corpora, we additionally compiled a total of six lists, each of which consists of 100 word-pairs with respective human judgments.", "labels": [], "entities": []}, {"text": "The goal of our experiments was to cover a wide range of relatedness types, i.e. systematic and unsystematic relations, and relatedness levels, i.e. various degrees of relation strength.", "labels": [], "entities": []}, {"text": "However, we only included nouns in the construction of our sets of word-pairs, since we consider cross-part-of-speech (cross-POS) relations to bean additional challenge , which we intend to address in a continuative experiment.", "labels": [], "entities": []}, {"text": "Furthermore, in order to identify a potential bias of the lists and the impact of this bias on the results, we applied two different methods for the compilation of word-pairs.", "labels": [], "entities": []}, {"text": "For our first human judgment experiment we collected nouns (analytically) 5 of diverse semantic classes, e.g. abstract nouns, such as das Wissen (Engl.", "labels": [], "entities": []}, {"text": "knowledge), and concrete nouns, such as das B\u00fcgeleisen (Engl. flat-iron).", "labels": [], "entities": []}, {"text": "By this means, we constructed a list of approximately 300 word-pairs.", "labels": [], "entities": []}, {"text": "We picked approximately 75 and randomized them.", "labels": [], "entities": []}, {"text": "For the remaining 25 word-pairs, we selected five words and constructed word-pairs such as Sonne-Wind (Engl. sun-wind), Sonne-W\u00e4rme (Engl. sun-warmth), Sonne-Wetter (Engl. sun-weather) etc.", "labels": [], "entities": []}, {"text": "We arranged these 25 pairs into sequences in order to focus our subjects' attention on small semantic relatedness distinctions.", "labels": [], "entities": []}, {"text": "For the five remaining lists (WP2-WP6), we applied a different method: firstly, we again analytically collected word-pairs which are part of collocations, i.e. the two nouns Rat and Tat (mit Rat und Tat helfen, Engl.", "labels": [], "entities": [{"text": "WP2-WP6", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9109064936637878}]}, {"text": "to help with words and deeds) or Qual and Wahl (die Qual der Wahl haben, Engl. to be spoilt for choice).", "labels": [], "entities": []}, {"text": "Secondly, we assembled word-pairs which feature association relations, i.e. Afrika (Engl. Africa) and Tiger (Engl. tiger) or Weihnachten (Engl. Christmas) and Zimt (Engl. cinnamon).", "labels": [], "entities": []}, {"text": "Thirdly, we automatically constructed a list of random word-pairs using the Wacky corpus () as a resource and manually excluded ad-hoc-constructions.", "labels": [], "entities": [{"text": "Wacky corpus", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.9691780805587769}]}, {"text": "Finally, out of these three resources we compiled five sets of 100 randomized word-pairs with no more than 20% of the collocation and association word-pairs.", "labels": [], "entities": []}, {"text": "We asked subjects to rate the word-pairs on a 5-level scale (0 = not related to 4 = strongly related).", "labels": [], "entities": []}, {"text": "The subjects were instructed to base the rating on their intuition about any kind of conceivable relation between the two words.", "labels": [], "entities": []}, {"text": "WP1 was rated by 35 subjects and WP2 to WP6 were each rated by 15 subjects.", "labels": [], "entities": [{"text": "WP1", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9743368625640869}, {"text": "WP2", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.8955733180046082}, {"text": "WP6", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.7639450430870056}]}, {"text": "We then calculated the average judgment per word-pair and ranked the word-pairs accordingly.", "labels": [], "entities": []}, {"text": "The correlation between the human judgments and the eleven semantic measures is shown in.", "labels": [], "entities": []}, {"text": "The difference between the correlation coefficients of WP1 and WP2-WP6 suggests that the method of construction might have an impact on the results of the experiments.", "labels": [], "entities": [{"text": "WP1", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8464139699935913}, {"text": "WP2-WP6", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8882319927215576}]}, {"text": "The manual compilation of word-pairs seems to lead to better correlation coefficients and might therefore cause an overestimation of the performance of the semantic measures.", "labels": [], "entities": []}, {"text": "Furthermore, with respect to the list construction methods, the two resources and respective measures, namely GermaNet (TreePathLin) and Google (GoogleQ-GooglePMI), seem to respond differently: whereas the correlation coefficients of the eight GermaNet based measures drop to a greater or lesser extend: r for WP1 and r for WP2-WP6), the correlation coefficients of the three Google based measures approximately level off.", "labels": [], "entities": [{"text": "list construction", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7479110658168793}, {"text": "Google (GoogleQ-GooglePMI)", "start_pos": 137, "end_pos": 163, "type": "DATASET", "confidence": 0.7627871036529541}]}, {"text": "In any case, since the correlation coefficients are rather low, there is much room for improvement.", "labels": [], "entities": [{"text": "correlation", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.9798172116279602}]}, {"text": "However, as all measures scatter in the same range -independently of the precise algorithm or resource used, as it seems -we argue that the reason for this critical performance might be one of the following two aspects (most probably a combination of both): \u2022 Word nets (and/or corpora) do not cover the (all) types of semantic information required.", "labels": [], "entities": []}, {"text": "\u2022 Human judgment experiments are (without clear and standardized specification of the experimental setup) an inappropriate way to evaluate semantic measures.", "labels": [], "entities": []}, {"text": "Both aspects are discussed in Section 4.", "labels": [], "entities": []}, {"text": "However, we first should have a look at three similar studies, two for English and one for German.", "labels": [], "entities": []}, {"text": "\u2022 Research objective: The goals of the studies differ with respect to several aspects.", "labels": [], "entities": []}, {"text": "Firstly, some studies, e.g., aim at comparing the performance of different semantic (relatedness) measures, whereas BoydGraber et al.", "labels": [], "entities": []}, {"text": "(2006) intend to construct anew relations layer (potentially able to substitute or complement established relatedness measures).", "labels": [], "entities": []}, {"text": "Secondly, in some cases, e.g., relations between words are considered, whereas e.g. Boyd- examine relations between concepts.", "labels": [], "entities": []}, {"text": "Thirdly, it seems to be unclear which types of relations are actually searched for (relatedness, similarity, evocation, distance) and in what aspects these correspond or differ.", "labels": [], "entities": []}, {"text": "Interestingly, in computational linguistics and psycholinguistics there is an additional strand of research investigating the so-called 'association relation', e.g. Schulte im and Roth and Schulte im, which is not yet considered or integrated in the research on semantic relatedness measures.", "labels": [], "entities": []}, {"text": "We argue that such an integration might be fruitful for both research strands.", "labels": [], "entities": []}, {"text": "\u2022 Setting of the human judgment experiment: In all studies summarized above, the subjects are students (mostly of linguistics, computer sciences, and computational linguistics).", "labels": [], "entities": []}, {"text": "In most cases, they are given a short manual explaining the task, which certainly differs in many aspects, e.g. due to the above mentioned fact that the relation type searched for is a still unsettled issue.", "labels": [], "entities": []}, {"text": "Furthermore, no training phase is included inmost of the studies except the one by Boyd-Graber We think that this comparison of the various experiments points to two aspects which probably cause the large statistical spread shown in: the selection of the wordpairs (concept-pairs) and the type of relation (relatedness, similarity, evocation, distance).", "labels": [], "entities": []}, {"text": "We assume that it should be possible to condense the comparison into one (more or less simple) rule: the narrower the relation concept (similarity < relatedness < evocation) and the narrower the data considered (lexical semantic selection rule < any kind of selection rule < random selection) the better the correlation between human judgment and semantic measure . In any case, it seems essential to determine which relation types the subjects (knowingly or unknowingly) bear in mind when they judge word-pairs with respect to semantic relatedness.", "labels": [], "entities": []}, {"text": "In order to achieve this goal and be able to integrate all relevant relations into the resources used for calculating semantic relatedness, the human judgments collected in the above-mentioned studies should be dissected into components (i.e. components for which systematic/unsystematic lexical semantic relations account etc.); such a decomposition certainly also helps render more precisely the definition of semantic relatedness.", "labels": [], "entities": []}, {"text": "Furthermore, it is -in our opinion -an unsettled issue whether the three types of semantic relation at hand, thus the relations 1.", "labels": [], "entities": []}, {"text": "represented in a word net or corpus (both computed via semantic measure), 2.", "labels": [], "entities": []}, {"text": "existing between any given word-pair in a text (which is mostly relevant for NLP-applications), 3. and the one assigned by subjects in a human judgment experiment correspond at all.", "labels": [], "entities": []}, {"text": "In principle, word nets, corpus statistics, and human judgments should be related to (theoretically even represent) the (at least partially) shared knowledge of humans about the underlying 'lexical semantic system', whereas relations between words in a concrete text represent an instantiation of a system.", "labels": [], "entities": []}, {"text": "From this point of view, at least the human judgments should correspond to the semantics encoded in a word net (or corpus statistics).", "labels": [], "entities": []}, {"text": "Instead of using human judgments as an evaluation resource (for e.g. word net based semantic measures), they might as well be directly integrated into the word net as a (preferably dense) layer of (potentially cognitively relevant, weighted but unlabeled) semantic relations, which is best adopted in Boyd-, as summarized in Section 3.", "labels": [], "entities": []}, {"text": "This approach has several advantages: firstly, the calculation of a semantic relatedness value is -given such a layer -trivial, since it merely consists in a look-up procedure.", "labels": [], "entities": []}, {"text": "Secondly, NLP-applications using word nets as a resource would certainly benefit from the thus enhanced density of relations, i.e. cross-POS relations.", "labels": [], "entities": []}, {"text": "Thirdly, an elaborate and standardized experimental setup for human judgment experiments could be used for the construction of such a layer in different languages (and domains) and would also guarantee the modeling quality.", "labels": [], "entities": []}, {"text": "Finally, such anew word net layer would hopefully resolve the above mentioned open issue of the diverging correlation coefficients.", "labels": [], "entities": []}, {"text": "Alternatively, since it is completely unclear if the evocation relation can really act as a substitute for classical semantic relatedness measures in NLP-applications, current word nets should be enhanced by systematically augmenting existing relation types and integrating new ones.", "labels": [], "entities": []}, {"text": "On that condition and given that a common evaluation framework exists, it should be possible to determine which semantic relatedness measure performs best under what conditions.", "labels": [], "entities": []}, {"text": "Last but not least, in order to determine the relation between an underlying semantic system (represented by a semantic measure or as mentioned above the evocation layer) and the instantiation of this system in a concrete text, a study similar to the one reported in should be conducted.", "labels": [], "entities": []}, {"text": "Such a study probably also shows if the evocation relation is able to substitute (or at least complement) semantic relatedness measures typically used in NLP-applications.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Our Correlation Coefficients: Correlation between Average Human Judgment  and Semantic Measure Values", "labels": [], "entities": []}, {"text": " Table 2: Correlation Coefficients by Budantisky and Hirst", "labels": [], "entities": []}, {"text": " Table 3: Correlation Coefficients by Boyd-Graber et al.", "labels": [], "entities": []}, {"text": " Table 4: Correlation Coefficients by Gurevych (with Lesk 1 = Lesk (DWDS); Lesk 2", "labels": [], "entities": []}, {"text": " Table 5: Comparison of the Correlation Coefficients of the Different Experiments  (with B&G: Budanitsky and Hirst / B-G et al.: Boyd-Graber et al. / G et al.: Gurevych  et al. / C&F, C: our results)", "labels": [], "entities": []}]}