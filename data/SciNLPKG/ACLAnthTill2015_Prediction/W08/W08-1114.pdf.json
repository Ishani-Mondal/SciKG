{"title": [{"text": "Simple but effective feedback generation to tutor abstract problem solving", "labels": [], "entities": [{"text": "problem solving", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.8476594090461731}]}], "abstractContent": [{"text": "To generate natural language feedback for an intelligent tutoring system, we developed a simple planning model with a distinguishing feature: its plan operators are derived automatically , on the basis of the association rules mined from our tutorial dialog corpus.", "labels": [], "entities": []}, {"text": "Automatically mined rules are also used for realization.", "labels": [], "entities": [{"text": "realization", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9731289744377136}]}, {"text": "We evaluated 5 different versions of a system that tutors on an abstract sequence learning task.", "labels": [], "entities": []}, {"text": "The version that uses our planning framework is significantly more effective than the other four versions.", "labels": [], "entities": []}, {"text": "We compared this version to the human tutors we employed in our tutorial dialogs, with intriguing results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Intelligent Tutoring Systems (ITSs) are software systems that provide individualized instruction, like human tutors do in one-on-one tutoring sessions.", "labels": [], "entities": []}, {"text": "Whereas ITSs have been shown to be effective in engendering learning gains, they still are not equivalent to human tutors.", "labels": [], "entities": []}, {"text": "Hence, many researchers are exploring Natural Language (NL) as the key to bridging the gap between human tutors and current ITSs.", "labels": [], "entities": []}, {"text": "A few results are now available, that show that ITS with relatively sophisticated language interfaces are more effective than some other competitive condition (;; VanLehn et al.,.", "labels": [], "entities": []}, {"text": "Ascertaining which specific features of the NL interaction are responsible for learning still remains an open research question.", "labels": [], "entities": []}, {"text": "In our experiments, we contrasted the richness with which human tutors respond to student actions with poorer forms of providing feedback, e.g. only graphical.", "labels": [], "entities": []}, {"text": "Our study starts exploring the role that positive feedback plays in tutoring and in ITSs.", "labels": [], "entities": []}, {"text": "While it has long been observed that most tutors tend to avoid direct negative feedback, e.g.), ITSs mostly provide negative feedback, as they react to student errors.", "labels": [], "entities": []}, {"text": "In this paper, we will first briefly describe our tutorial dialog collection.", "labels": [], "entities": []}, {"text": "We will then present the planning architecture that underlies our feedback generator.", "labels": [], "entities": []}, {"text": "Even if our ITS does not currently allow for student input, our generation architecture is inspired by state-of-the art tutorial dialog management).", "labels": [], "entities": []}, {"text": "One limitation of these approaches is that plan operators are difficult to maintain and extend, partly because they are manually defined and tuned.", "labels": [], "entities": []}, {"text": "Crucially, our plan operators are automatically derived via the association rules mined from our corpus.", "labels": [], "entities": []}, {"text": "Finally, we will devote a substantial amount of space to evaluation.", "labels": [], "entities": []}, {"text": "Our work is among the first to show not only that a more sophisticated language interface results in more learning, but that it favorably compares with human tutors.", "labels": [], "entities": []}, {"text": "Full details on our work can be found in.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate the utility of our feedback generator, we developed five different versions of our ITS, named according to how feedback is generated: The ITS only provides the basic interface, so that subjects can practice solving the 13 problems in the curriculum, but does not provide any kind of feedback.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Average Post-test Scores of the ITS", "labels": [], "entities": [{"text": "Average Post-test Scores", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.8725359042485555}, {"text": "ITS", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8202399611473083}]}]}