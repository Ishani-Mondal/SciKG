{"title": [{"text": "Baby SRL: Modeling Early Language Acquisition", "labels": [], "entities": [{"text": "Baby SRL", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8586894273757935}, {"text": "Modeling Early Language Acquisition", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.802329495549202}]}], "abstractContent": [{"text": "A fundamental task in sentence comprehension is to assign semantic roles to sentence constituents.", "labels": [], "entities": []}, {"text": "The structure-mapping account proposes that children start with a shallow structural analysis of sentences: children treat the number of nouns in the sentence as a cue to its semantic predicate-argument structure, and represent language experience in an abstract format that permits rapid generalization to new verbs.", "labels": [], "entities": []}, {"text": "In this paper, we tested the consequences of these representational assumptions via experiments with a system for automatic semantic role labeling (SRL), trained on a sample of child-directed speech.", "labels": [], "entities": [{"text": "automatic semantic role labeling (SRL)", "start_pos": 114, "end_pos": 152, "type": "TASK", "confidence": 0.7546273853097644}]}, {"text": "When the SRL was presented with representations of sentence structure consisting simply of an ordered set of nouns, it mimicked experimental findings with toddlers, including a striking error found in children.", "labels": [], "entities": [{"text": "SRL", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.8787935972213745}]}, {"text": "Adding features representing the position of the verb increased accuracy and eliminated the error.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9992713332176208}, {"text": "error", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.950524091720581}]}, {"text": "We show the SRL system can use incremental knowledge gain to switch from error-prone noun order features to a more accurate representation, demonstrating a possible mechanism for this process in child development.", "labels": [], "entities": [{"text": "SRL", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.7979276776313782}]}], "introductionContent": [{"text": "How does the child get started in learning to interpret sentences?", "labels": [], "entities": []}, {"text": "The structure-mapping view of early verb and syntax acquisition proposes that children start with a shallow structural analysis of sentences: children treat the number of nouns in the sentence as a cue to its semantic predicateargument structure, and represent language experience in an abstract format that permits rapid generalization to new verbs ).", "labels": [], "entities": [{"text": "early verb and syntax acquisition", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.6861936509609222}]}, {"text": "The structure-mapping account makes strong predictions.", "labels": [], "entities": []}, {"text": "First, as soon as children can identify some nouns, they should interpret transitive and intransitive sentences differently, simply by assigning a distinct semantic role to each noun in the sentence.", "labels": [], "entities": []}, {"text": "Second, language-specific syntactic learning should transfer rapidly to new verbs.", "labels": [], "entities": []}, {"text": "Third, some striking errors of interpretation can occur.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.9177104830741882}]}, {"text": "In \"Fred and Ginger danced\", an intransitive verb is presented with two nouns.", "labels": [], "entities": []}, {"text": "If children interpret any two-noun sentence as if it were transitive, they should be fooled into interpreting the order of two nouns in such conjoined-subject intransitive sentences as conveying agent-patient role information.", "labels": [], "entities": []}, {"text": "Experiments with young children support these predictions.", "labels": [], "entities": []}, {"text": "First, 21-month-olds use the number of nouns to understand sentences containing new verbs (.", "labels": [], "entities": []}, {"text": "Second, 21-month-olds generalize what they have learned about English transitive word-order to sentences containing new verbs: Children who heard \"The girl is gorping the boy\" interpreted the girl as an agent and the boy as a patient ).", "labels": [], "entities": []}, {"text": "Third, 21-montholds make the predicted error, treating intransitive sentences containing two nouns as if they were transitive: they interpret the first noun in \"The girl and the boy are gorping\" as an agent and the second as a patient ).", "labels": [], "entities": []}, {"text": "By 25 months, children add new features to their representations of sentences, and interpret conjoined-subject intransitives differ-ently from transitives.", "labels": [], "entities": []}, {"text": "These experimental results shed light on what syntactic information children might have available for early sentence comprehension, but do not rule out the possibility that children's early performance is based on a more complex underlying system.", "labels": [], "entities": []}, {"text": "In this paper, we tested the consequences of our representational assumptions by performing experiments with a system for automatic semantic role labeling (SRL), whose knowledge of sentence structure is under our control.", "labels": [], "entities": [{"text": "automatic semantic role labeling (SRL)", "start_pos": 122, "end_pos": 160, "type": "TASK", "confidence": 0.76999488898686}]}, {"text": "Computational models of semantic role labeling learn to identify, for each verb in a sentence, all constituents that fill a semantic role, and to determine their roles.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.6780419945716858}]}, {"text": "We adopt the architecture proposed by Roth and colleagues), limiting the classifier's features to a set of lexical features and shallow structural features suggested by the structure-mapping account.", "labels": [], "entities": []}, {"text": "Learning ability is measured by the level of SRL accuracy and, more importantly, the types of errors made by the system on sentences containing novel verbs.", "labels": [], "entities": [{"text": "SRL", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.8393802046775818}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9339222311973572}]}, {"text": "Testing these predictions on the automatic SRL provides us with a demonstration that it is possible to learn how to correctly assign semantic roles based only on these very simple cues.", "labels": [], "entities": [{"text": "SRL", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.8530141711235046}]}, {"text": "From an NLP perspective this feature study provides evidence for the efficacy of alternative, simpler syntactic representations in gaining an initial foothold on sentence interpretation.", "labels": [], "entities": [{"text": "sentence interpretation", "start_pos": 162, "end_pos": 185, "type": "TASK", "confidence": 0.7372559607028961}]}, {"text": "It is clear that human learners do not begin interpreting sentences in possession of full part-of-speech tagging, or full parse trees.", "labels": [], "entities": []}, {"text": "By building a model that uses shallow representations of sentences and mimics features of language development in children, we can explore the nature of initial representations of syntactic structure and build more complex features from there, further mimicking child development.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the Baby SRL we tested it with sentences like those used for the experiments with children described above.", "labels": [], "entities": [{"text": "Baby SRL", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.9161827266216278}]}, {"text": "All test sentences contained a novel verb ('gorp').", "labels": [], "entities": []}, {"text": "We constructed two test sentence templates: 'A gorps B' and 'A and B gorp', where A and B were replaced with nouns that appeared more than twice in training.", "labels": [], "entities": []}, {"text": "We filled the A and B slots by sampling nouns that occurred roughly equally as the first and second of two nouns in the training data.", "labels": [], "entities": []}, {"text": "This procedure was adopted to avoid 'building in' the predicted error by choosing A and B nouns biased toward an agent-patient interpretation.", "labels": [], "entities": []}, {"text": "For each test sentence template we built a test set of 100 sentences by randomly sampling nouns in this fashion.", "labels": [], "entities": []}, {"text": "The test sentences with novel verbs ask whether the classifier transfers its learning about argument role assignment to unseen verbs.", "labels": [], "entities": []}, {"text": "Does it assume the first of two nouns in a simple transitive sentence ('A gorps B') is the agent (A0) and the second is the patient (A1)?", "labels": [], "entities": []}, {"text": "Does it overgeneralize this rule to two-noun intransitives ('A and B gorp'), mimicking children's behavior?", "labels": [], "entities": []}, {"text": "We used two measures of success, one to assess classification accuracy, and the other to assess the predicted error.", "labels": [], "entities": [{"text": "classification", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.947716236114502}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9327566623687744}]}, {"text": "We used a per argument F1 for classification accuracy, with F1 based on correct identification of individual nouns rather than full phrases.", "labels": [], "entities": [{"text": "classification", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.9496964812278748}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9449650645256042}, {"text": "F1", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9977349042892456}]}, {"text": "Here precision is defined as the proportion of nouns that were given the correct label based on the argument they belong to, and recall is the proportion of complete arguments for which some noun in that argument was correctly labeled.", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9993093013763428}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.999473512172699}]}, {"text": "The desired labeling for 'A gorps B' is A0 for the first argument and A1 for the second; for 'A and B gorp' both arguments should be A0.", "labels": [], "entities": [{"text": "A0", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9684925675392151}, {"text": "A1", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9474502801895142}]}, {"text": "To measure predicted errors we also report the proportion of test sentences classified with A0 first and A1 second (%A0A1).", "labels": [], "entities": [{"text": "A0 first", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.974036693572998}, {"text": "A1 second", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.908947080373764}, {"text": "A0A1", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.7768961191177368}]}, {"text": "This labeling is a correct generalization for the novel 'A gorps B' sentences, but is an overgeneralization for 'A and B gorp.'", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Testing NPattern features on full SRL task  of heldout section 8 of Eve when trained on sec- tions 9 through 20. Each result column reflects a  per argument F1.", "labels": [], "entities": [{"text": "SRL", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.8991096019744873}, {"text": "F1", "start_pos": 167, "end_pos": 169, "type": "METRIC", "confidence": 0.9865858554840088}]}, {"text": " Table 3: Verb Position vs. Noun Pattern features  alone. Verb position features yield better overall  performance, but do not replicate the error on 'A  and B gorp' sentences seen with children.", "labels": [], "entities": []}]}