{"title": [{"text": "Degrees of Grounding Based on Evidence of Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce the Degrees of Grounding model, which defines the extent to which material being discussed in a dialogue has been grounded.", "labels": [], "entities": []}, {"text": "This model has been developed and evaluated by a corpus analysis, and includes a set of types of evidence of understanding, a set of degrees of groundedness, a set of grounding criteria, and methods for identifying each of these.", "labels": [], "entities": []}, {"text": "We describe how this model can be used for dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8886789679527283}]}], "introductionContent": [{"text": "Dialogue system researchers are active in investigating ways of detecting and recovering from error, including determining when to provide confirmations or rejections, or how to handle cases of complete non-understanding (.", "labels": [], "entities": []}, {"text": "Studying the strategies that humans use when speaking amongst themselves can be helpful ().", "labels": [], "entities": []}, {"text": "One approach to studying how humans manage errors of understanding is to view conversation as a joint activity, in which grounding, or the process of adding material to the common ground between speakers, plays a central role.", "labels": [], "entities": []}, {"text": "From this perspective, conversations are highly coordinated efforts in which participants work together to ensure that knowledge is properly understood by all participants.", "labels": [], "entities": []}, {"text": "There is a wide variety of grounding behavior that is determined by the communication medium, among other things.", "labels": [], "entities": []}, {"text": "This approach is developed computationally by Traum, who presents a model of grounding which adapts Clark and Schaefer's contributions model to make it usable in an online dialogue system.", "labels": [], "entities": []}, {"text": "Other computational approaches to grounding use decision theory or focus on modeling belief.", "labels": [], "entities": []}, {"text": "Grounding models generally consider material to be in one of three states: ungrounded, in the process of becoming sufficiently grounded, or sufficiently grounded.", "labels": [], "entities": []}, {"text": "(An exception is, who use a continuous model of groundedness.)", "labels": [], "entities": []}, {"text": "We are developing a model of grounding that is attentive to a larger set of types of evidence of understanding than is typical, and use this to define a model of Degrees of Grounding, which tracks the extent to which material has become apart of the common ground.", "labels": [], "entities": []}, {"text": "This model includes a set of types of Evidence of Understanding that describes the kinds of cues that the dialogue gives about the state of grounding.", "labels": [], "entities": []}, {"text": "A set of Degrees of Groundedness describes the extent to which material has achieved mutual belief while being discussed.", "labels": [], "entities": []}, {"text": "A set of Grounding Criteria describes the degree to which material needs to be grounded.", "labels": [], "entities": []}, {"text": "Finally, the model provides algorithms to assist dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9053879380226135}]}, {"text": "The next section describes the radio domain which we used to begin developing this model.", "labels": [], "entities": []}, {"text": "The dialogues in this domain contain a large amount of confirmation behavior, which make it a good testbed for the initial development of the model.", "labels": [], "entities": []}, {"text": "However, because these radio dialogues are highly structured we are not yet able to make strong claims about the generality of this model.", "labels": [], "entities": []}, {"text": "In following sections we describe the components of the model, annotation evaluations, and ongoing development of the model.", "labels": [], "entities": []}], "datasetContent": [{"text": "The validity of this model has been evaluated in several corpus tests to measure inter-annotator agreement in identifying evidence, to ensure that identifying evidence can reliably be done by an algorithm, to measure inter-annotator agreement in identifying the increase or decrease of the degree of groundedness, and to ensure that identifying the increase or decrease of a degree of groundedness can reliably be done by an algorithm.", "labels": [], "entities": []}, {"text": "Human transcribers produced transcriptions of several sessions between two sets of humans acting as Forward Observer and Fire Direction Center radio operators in the training simulation.", "labels": [], "entities": [{"text": "Forward Observer and Fire Direction Center radio", "start_pos": 100, "end_pos": 148, "type": "TASK", "confidence": 0.6018201240471431}]}, {"text": "A subset of the corpus was used for close analysis: this subset was made up of 4 training sessions, composed of 17 fire missions, totaling 456 utterances; this provided a total of 1222 possible indicators of evidence of understanding made up of 886 dialogue move parameters and 336 period of silence.", "labels": [], "entities": []}, {"text": "We automatically performed a dialogue act interpretation on the dialogue move parameters, which were then manually corrected.", "labels": [], "entities": [{"text": "dialogue act interpretation", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6862230896949768}]}, {"text": "We then manually annotated the evidence of understanding identified in each dialogue move parameter and period of silence.", "labels": [], "entities": []}, {"text": "An example of the data produced from this process is given in the Appendix.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.5374541878700256}]}], "tableCaptions": [{"text": " Table 9: Example of a Lack of Response", "labels": [], "entities": []}, {"text": " Table 12: Inter-Annotator Agreement -Evidence", "labels": [], "entities": []}, {"text": " Table 13: Algorithm Agreement -Evidence", "labels": [], "entities": [{"text": "Algorithm Agreement -Evidence", "start_pos": 11, "end_pos": 40, "type": "TASK", "confidence": 0.6718696802854538}]}, {"text": " Table 14: Degree Increase/Decrease Agreements", "labels": [], "entities": [{"text": "Degree Increase/Decrease Agreements", "start_pos": 11, "end_pos": 46, "type": "METRIC", "confidence": 0.8391519665718079}]}]}