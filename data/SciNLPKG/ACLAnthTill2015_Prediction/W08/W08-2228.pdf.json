{"title": [{"text": "Textual Entailment as an Evaluation Framework for Metaphor Resolution: A Proposal", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7406632900238037}, {"text": "Metaphor Resolution", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7728718519210815}]}], "abstractContent": [{"text": "We aim to address two complementary deficiencies in Natural Language Processing (NLP) research: (i) Despite the importance and prevalence of metaphor across many discourse genres, and metaphor's many functions, applied NLP has mostly not addressed metaphor understanding.", "labels": [], "entities": [{"text": "metaphor understanding", "start_pos": 248, "end_pos": 270, "type": "TASK", "confidence": 0.773239016532898}]}, {"text": "But, conversely, (ii) difficult issues in metaphor understanding have hindered large-scale application, extensive empirical evaluation, and the handling of the true breadth of metaphor types and interactions with other language phenomena.", "labels": [], "entities": [{"text": "metaphor understanding", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.911184161901474}]}, {"text": "In this paper, abstracted from a recent grant proposal, anew avenue for addressing both deficiencies and for inspiring new basic research on metaphor is investigated: namely, placing metaphor research within the \"Recognizing Textual Entailment\" (RTE) task framework for evaluation of semantic processing systems.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment\" (RTE) task", "start_pos": 213, "end_pos": 255, "type": "TASK", "confidence": 0.7003995627164841}]}, {"text": "357 358 Agerri, Barnden, Lee, and Wallington", "labels": [], "entities": [{"text": "Agerri", "start_pos": 8, "end_pos": 14, "type": "DATASET", "confidence": 0.9721039533615112}, {"text": "Barnden", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.6573789119720459}, {"text": "Wallington", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.7373743653297424}]}], "introductionContent": [{"text": "The RTE task and annual, starting in 2005, have arisen as an evaluation framework for applied semantics in response to the fact that in NLP applications -such as Question Answering (QA), Information Retrieval/Extraction (IR, IE), etc.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.7350290417671204}, {"text": "Question Answering (QA)", "start_pos": 162, "end_pos": 185, "type": "TASK", "confidence": 0.8485201358795166}, {"text": "Information Retrieval/Extraction (IR, IE)", "start_pos": 187, "end_pos": 228, "type": "TASK", "confidence": 0.8549610409471724}]}, {"text": "-the development of semantic algorithms and models have been scattered, or tailored to specific applications, making it difficult to compare and evaluate them within one framework.", "labels": [], "entities": []}, {"text": "RTE is interesting because QA, IE, etc.", "labels": [], "entities": [{"text": "RTE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.4312369227409363}, {"text": "QA", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9546416401863098}, {"text": "IE", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9852988719940186}]}, {"text": "can all be cast as RTE problems.", "labels": [], "entities": []}, {"text": "In RTE, one text fragment, the Text T, is said to entail another one, the Hypothesis H, when humans considering T and H judge that H follows from T (perhaps only plausibly/defeasibly).", "labels": [], "entities": [{"text": "RTE", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.8921408653259277}]}, {"text": "Thus, entailment is a commonsense matter, not a precise logic-based one.", "labels": [], "entities": [{"text": "entailment", "start_pos": 6, "end_pos": 16, "type": "TASK", "confidence": 0.973568856716156}]}, {"text": "An example of a T/H pair is as follows (metaphor in italics): (1) T: Lyon is actually the gastronomic capital of France.", "labels": [], "entities": []}, {"text": "H: Lyon is the capital of France.", "labels": [], "entities": []}, {"text": "Metaphor can roughly be characterized as describing something (the target) as if it were something else (the source) to which it is perceived, or set forth, as being somehow analogous.", "labels": [], "entities": []}, {"text": "Metaphor has long been identified as being ubiquitous in language, including ordinary conversation, newspaper articles, popular novels, popular science writing, classroom dialogue, etc.", "labels": [], "entities": []}, {"text": "Ina study (Tech. Rept. CSRP-03-05 at our School, 2003) we found one metaphorical term per 17.3 words, averaging across various discourses of different genres.", "labels": [], "entities": [{"text": "Tech. Rept. CSRP-03-05 at our School, 2003", "start_pos": 11, "end_pos": 53, "type": "DATASET", "confidence": 0.8911970779299736}]}, {"text": "This is inline with other researchers' studies though counts vary widely because of theory-relativity, researchers' aims, and marked usage differences between genres.", "labels": [], "entities": []}, {"text": "note that 90% of uses of a set of verbs of spatial motion, manipulation, and health in a Wall Street Journal corpus were metaphorical.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 89, "end_pos": 115, "type": "DATASET", "confidence": 0.9361559152603149}]}, {"text": "Some metaphor examples arising in past RTE datasets are the Ts in T/H pairs, with human judgments No, Yes, No and No respectively.", "labels": [], "entities": [{"text": "RTE datasets", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.8155972063541412}]}, {"text": "(2) T: The technological triumph known as GPS was incubated in the mind of Ivan Getting.", "labels": [], "entities": [{"text": "T", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9925089478492737}]}, {"text": "H: Ivan Getting invented the GPS.", "labels": [], "entities": []}, {"text": "(3) T: Convinced that pro-American officials are in the ascendancy in Tokyo, they talk about turning Japan into the Britain of the Far East.", "labels": [], "entities": [{"text": "T", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9906642436981201}]}, {"text": "H: Britain is located in the Far East.", "labels": [], "entities": [{"text": "Britain", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.984987199306488}]}, {"text": "(4) T: Even today, within the deepest recesses of our mind, lies a primordial fear that will not allow us to enter the sea without thinking about the possibility of being attacked by a shark.", "labels": [], "entities": [{"text": "T", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9862698912620544}]}, {"text": "H: A shark attacked a human being.", "labels": [], "entities": []}, {"text": "Importantly, metaphor is often not just a matter of particular terms with particular metaphorical senses that are entrenched (i.e., that are commonly used, default senses; and possibly listed in dictionaries).", "labels": [], "entities": []}, {"text": "Certainly the metaphorical senses of \"capital\" and \"incubate\" used in (1) and (2) are at least moderately entrenched.", "labels": [], "entities": []}, {"text": "For \"incubate,\" some dictionaries list a slow, protective sense of development (in a general, possibly non-physical sense), or for \"capital\" a sense like \"a city [or place more generally] preeminent in some special activity\".", "labels": [], "entities": []}, {"text": "But (3) shows one common type of non-entrenched metaphor, of the general form \"the X of Y\", where X and/or Y are often named entities.", "labels": [], "entities": []}, {"text": "The point of such a metaphor is typically only clear with the help of context.", "labels": [], "entities": []}, {"text": "Reference to recesses of a mind as in is common, and a lexicon could reasonably include a metaphorical sense of \"recess\" that was directly applicable to minds (though WordNet 3.0, e.g, does not), or include \"within the recesses of [X's] mind\" as a stock phrase with a sense of relative inaccessibility or unmodifiability of a thought or feeling.", "labels": [], "entities": []}, {"text": "But the phraseology can be productively varied: e.g., \"deepest\" can be omitted or replaced by \"dim\", \"darkest\", \"foulest\", \"hidden\", etc.", "labels": [], "entities": []}, {"text": "-by any compatible qualifier that emphasizes hiddenness or obstacles to accessibility.", "labels": [], "entities": []}, {"text": "And the fact that such access difficulties are being emphasized is a matter for general semantic reasoning about the qualifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our initiative mainly consists of (A): Create a public, annotated, metaphor-focussed text dataset suitable for RTE evaluation and testing of metaphor processing systems; and (B): Develop a prototype RTE system centred on processing (at least) the types of metaphor arising in (A).", "labels": [], "entities": [{"text": "RTE evaluation", "start_pos": 111, "end_pos": 125, "type": "TASK", "confidence": 0.9154325723648071}]}, {"text": "We will mainly address point (B) in this paper.", "labels": [], "entities": []}, {"text": "As for A, metaphors vary along several dimensions of interest, such as: the target subject matter (e.g., Lyon's food, GPS development, Japanese foreign politics, shark fear in examples 1-4); the source subject matter; what particular, familiar metaphorical views (e.g., Idea as Living Being, in (2)) are used; whether the meaning in context is listed in dictionaries, WordNet, etc; whether the wording is (a variant of) a familiar idiom; the syntax used.", "labels": [], "entities": []}, {"text": "Based on such dimensions, we will analyse the types of metaphor present in past RTE datasets and in the genres of text (e.g., newspapers) they drew from.", "labels": [], "entities": [{"text": "RTE datasets", "start_pos": 80, "end_pos": 92, "type": "DATASET", "confidence": 0.7593125104904175}]}, {"text": "One particular source will be the 242K-word metaphor-orientated corpus that we derived from the British National Corpus.", "labels": [], "entities": [{"text": "242K-word metaphor-orientated corpus", "start_pos": 34, "end_pos": 70, "type": "DATASET", "confidence": 0.7932031353314718}, {"text": "British National Corpus", "start_pos": 96, "end_pos": 119, "type": "DATASET", "confidence": 0.9477885365486145}]}, {"text": "To find metaphor examples elsewhere, we will use known metaphorical phrases and lexical/syntactic templates as seeds for automated search over general corpora or web.", "labels": [], "entities": []}, {"text": "We will also investigate the use or adaptation of other researchers' automated detection/mining techniques (e.g.).", "labels": [], "entities": [{"text": "automated detection/mining", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.8031845688819885}]}], "tableCaptions": []}