{"title": [], "abstractContent": [{"text": "We present a novel unsupervised method for sentence compression which relies on a dependency tree representation and shortens sentences by removing subtrees.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.7556703388690948}]}, {"text": "An automatic evaluation shows that our method obtains result comparable or superior to the state of the art.", "labels": [], "entities": []}, {"text": "We demonstrate that the choice of the parser affects the performance of the system.", "labels": [], "entities": []}, {"text": "We also apply the method to German and report the results of an evaluation with humans.", "labels": [], "entities": []}], "introductionContent": [{"text": "Within the field of text-to-text generation, the sentence compression task can be defined as follows: given a sentence S, consisting of words w 1 w 2 ...w n , what is a subset of the words of S, such that it is grammatical and preserves essential information from S?", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7775272727012634}, {"text": "sentence compression", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7351995557546616}]}, {"text": "There are many applications which would benefit from a robust compression system, such as subtitle generation, compression for mobile devices with a limited screen size, or news digests.", "labels": [], "entities": [{"text": "subtitle generation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7473812699317932}]}, {"text": "Given that to date most text and speech summarization systems are extractive, sentence compression techniques area common way to deal with redundancy in their output.", "labels": [], "entities": [{"text": "text and speech summarization", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.617481641471386}, {"text": "sentence compression", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.80464968085289}]}, {"text": "In recent years, a number of approaches to sentence compression have been developed, inter alia).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.8290207087993622}]}, {"text": "Many explicitly rely on a language model, usually a trigram model, to produce grammatical output.", "labels": [], "entities": []}, {"text": "Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data.", "labels": [], "entities": []}, {"text": "However, compressing sentences in languages with less rigid word order needs a deeper analysis to test grammaticality.", "labels": [], "entities": []}, {"text": "And even for languages with rigid word order the trigram model ignores the structure of the sentence and therefore may significantly distort the meaning of the source sentence.", "labels": [], "entities": []}, {"text": "Approaches going beyond the word level either require a comprehensive lexicon, or manually devised rules) to determine prunable constituents.", "labels": [], "entities": []}, {"text": "A lexicon is not always available, whereas the hand-crafted rules may not coverall cases and are too general to be universally applicable (e.g. PPs can be pruned).", "labels": [], "entities": []}, {"text": "In this paper we present a novel unsupervised approach to sentence compression which is motivated by the belief that the grammaticality of the output can be better ensured by compressing trees.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.7898282110691071}]}, {"text": "In particular, given a dependency tree, we want to prune subtrees which are neither obligatory syntactic arguments, nor contribute important information to the content of the sentence.", "labels": [], "entities": []}, {"text": "A tree pruning approach does not generate new dependencies and is unlikely to produce a compression with a totally different meaning.", "labels": [], "entities": []}, {"text": "Our approach is unsupervised and adaptable to other languages, the main requirement being that there area dependency parser and a corpus available for the languages.", "labels": [], "entities": []}, {"text": "We test our approach on English and German data sets and obtain results comparable or superior to the state of the art.", "labels": [], "entities": [{"text": "English and German data sets", "start_pos": 24, "end_pos": 52, "type": "DATASET", "confidence": 0.6951019525527954}]}], "datasetContent": [{"text": "We evaluate the results automatically as well as with human subjects.", "labels": [], "entities": []}, {"text": "To assess the performance of the method on the English data, we calculate the Fmeasure on grammatical relations.", "labels": [], "entities": [{"text": "English data", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.6783927232027054}, {"text": "Fmeasure", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9981908202171326}]}, {"text": "Following, we calculate average precision and recall as the amount of grammatical relations shared between the output of our system and the gold stan-dard variant divided over the total number of relations in the output and in the human-generated compression respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.8639150261878967}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9995120763778687}]}, {"text": "According to, this measure reliably correlates with human judgements.", "labels": [], "entities": []}, {"text": "The results of our evaluation as well as the state of the art results reported by Clarke & Lapata (2008) (LM+SIG+CONSTR), whose system uses language model scoring (LM), word significance score (SIG), and linguistic constraints (CONSTR), are presented in.", "labels": [], "entities": [{"text": "word significance score (SIG)", "start_pos": 169, "end_pos": 198, "type": "METRIC", "confidence": 0.7119636287291845}]}, {"text": "The F-measure reported by is calculated with RASP which their system builds upon.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9966493248939514}, {"text": "RASP", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9664116501808167}]}, {"text": "For our system we present the results obtained on the data parsed with RASP as well as with the Stanford parser (SP).", "labels": [], "entities": [{"text": "RASP", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.8900999426841736}]}, {"text": "In both cases the F-measure is found with RASP in order to allow fora fair comparison between the three systems.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9979244470596313}, {"text": "RASP", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.6447253823280334}]}, {"text": "We recalculate the compression rate for the gold standard ignoring punctuation.", "labels": [], "entities": [{"text": "compression rate", "start_pos": 19, "end_pos": 35, "type": "METRIC", "confidence": 0.9823252558708191}, {"text": "gold standard", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.8886218667030334}]}, {"text": "On the whole corpus the compression rate turns out to be slightly higher than that reported by  As there are no human-generated compressions for German data, we evaluate the performance of the method in terms of grammaticality and importance by means of an experiment with native speakers.", "labels": [], "entities": []}, {"text": "In the experiment, humans are presented with a source sentence and its compression which they are asked to evaluate on two five-point scales.", "labels": [], "entities": []}, {"text": "Higher grades are given to better sentences.", "labels": [], "entities": []}, {"text": "Importance represents the amount of relevant information from the source sentence retained in the compression.", "labels": [], "entities": [{"text": "Importance", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9890751242637634}]}, {"text": "Since our method does not generate punctuation, the judges are asked to ignore errors due to missing commas.", "labels": [], "entities": []}, {"text": "Five participants took part in the experiment and each rated the total of 25 sentences originating from a randomly chosen newspaper article.", "labels": [], "entities": []}, {"text": "Their ratings as well as the ratings reported by on English corpus are presented in", "labels": [], "entities": [{"text": "English corpus", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.9402526915073395}]}], "tableCaptions": [{"text": " Table 1: Probabilities of subj, d(irect)obj, in, at, after,  with, to given the verb study", "labels": [], "entities": []}, {"text": " Table 2: Probabilities of subj, obja(ccusative), in, at, af- ter, with, to given the verb studieren", "labels": [], "entities": []}, {"text": " Table 3: Average results on the English corpus", "labels": [], "entities": [{"text": "English corpus", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9730726778507233}]}, {"text": " Table 4: Average results for the German data", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9769148826599121}, {"text": "German data", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.9272602796554565}]}]}