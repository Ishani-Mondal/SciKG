{"title": [{"text": "Accurate and Robust LFG-Based Generation for Chinese", "labels": [], "entities": [{"text": "Accurate", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9873008728027344}]}], "abstractContent": [{"text": "We describe three PCFG-based models for Chinese sentence realisation from Lexical-Functional Grammar (LFG) f-structures.", "labels": [], "entities": [{"text": "Chinese sentence realisation", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.6102714339892069}]}, {"text": "Both the lexicalised model and the history-based model improve on the accuracy of a simple wide-coverage PCFG model by adding lexical and contextual information to weaken inappropriate independence assumptions implicit in the PCFG models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9989820122718811}]}, {"text": "In addition, we provide techniques for lexical smoothing and rule smoothing to increase the generation coverage.", "labels": [], "entities": [{"text": "rule smoothing", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.7761256992816925}]}, {"text": "Trained on 15,663 automatically LFG f-structure annotated sentences of the Penn Chi-nese treebank and tested on 500 sentences randomly selected from the treebank test set, the lexicalised model achieves a BLEU score of 0.7265 at 100% coverage, while the history-based model achieves a BLEU score of 0.7245 also at 100% coverage.", "labels": [], "entities": [{"text": "Penn Chi-nese treebank", "start_pos": 75, "end_pos": 97, "type": "DATASET", "confidence": 0.9618067145347595}, {"text": "BLEU score", "start_pos": 205, "end_pos": 215, "type": "METRIC", "confidence": 0.979515016078949}, {"text": "BLEU score", "start_pos": 285, "end_pos": 295, "type": "METRIC", "confidence": 0.9780968725681305}]}], "introductionContent": [{"text": "Sentence generation, or surface realisation can be described as the problem of producing syntactically, morphologically, and orthographically correct sentences from a given abstract semantic / logical representation according to some linguistic theory, e.g. Lexical Functional Grammar (LFG), Head-Driven Phrase Structure Grammar (HPSG), Combinatory Categorial Grammar (CCG), Tree Adjoining Grammar (TAG) etc.", "labels": [], "entities": [{"text": "Sentence generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9191845059394836}, {"text": "surface realisation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7688926756381989}]}, {"text": "Grammars, such as these, are declarative formulations of the correspondences between semantic and syntactic representations.", "labels": [], "entities": []}, {"text": "Traditionally, grammar rules have been carefully handcrafted, such as those used in LinGo), OpenCCG) and XLE (.", "labels": [], "entities": [{"text": "LinGo", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.9473249316215515}, {"text": "OpenCCG", "start_pos": 92, "end_pos": 99, "type": "DATASET", "confidence": 0.8694443702697754}]}, {"text": "As handcrafting grammar rules is time-consuming, language-dependent and domain-specific, recent years have witnessed research on extracting wide-coverage grammars automatically from annotated corpora, for both parsing and generation.", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 210, "end_pos": 232, "type": "TASK", "confidence": 0.6409116188685099}]}, {"text": "FERGUS) took dependency structures as inputs, and produced XTAG derivations by a stochastic tree model automatically acquired from an annotated corpus.", "labels": [], "entities": [{"text": "FERGUS", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7823002338409424}]}, {"text": "presented log-linear models fora chart generator using a HPSG grammar acquired from the Penn-II Treebank.", "labels": [], "entities": [{"text": "HPSG grammar", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9106939733028412}, {"text": "Penn-II Treebank", "start_pos": 88, "end_pos": 104, "type": "DATASET", "confidence": 0.9833278357982635}]}, {"text": "From the same treebank, automatically extracted wide-coverage LFG approximations fora PCFG-based generation model.", "labels": [], "entities": []}, {"text": "In addition to applying statistical techniques to automatically acquire generation grammars, over the last decade, there has been a lot of interest in a generate-and-select paradigm for surface realisation.", "labels": [], "entities": [{"text": "surface realisation", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7704990804195404}]}, {"text": "The paradigm is characterised by a separation between generation and selection, in which symbolic or rule-based methods are used to generate a space of possible paraphrases, and statistical methods are used to select one or more outputs from the space.", "labels": [], "entities": []}, {"text": "Starting from who used a n-gram language model to rank generated output strings, a substantial number of traditional handcrafted surface realisers have been augmented with sophisticated stochastic rankers (.", "labels": [], "entities": []}, {"text": "It is interesting to note that, while the study of how the granularity of context-free grammars (CFG) affects the performance of a parser (e.g. in the form Figure 1: C-and f-structures with \u03c6 links for the sentence \"\u00c4\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\u00c1\u00d3\u00d2\" of grammar transforms and lexicalisation) has attracted substantial attention, to our knowledge, there has been a lot less research on this subject for surface realisation, a process that is generally regarded as the reverse process of parsing.", "labels": [], "entities": [{"text": "surface realisation", "start_pos": 378, "end_pos": 397, "type": "TASK", "confidence": 0.713218167424202}]}, {"text": "Moreover, while most of the research so far has concentrated on English or European languages, we are also interested in generation for other languages with diverse properties, such as Chinese which is currently a focus language in parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 232, "end_pos": 239, "type": "TASK", "confidence": 0.9651663303375244}]}, {"text": "In this paper, we investigate three generative PCFG models for Chinese generation based on wide-coverage LFG grammars automatically extracted from the Penn Chinese Treebank (CTB).", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB)", "start_pos": 151, "end_pos": 178, "type": "DATASET", "confidence": 0.9737021625041962}]}, {"text": "Our work is couched in the framework of Lexical Functional Grammar and is implemented in a chart-style generator.", "labels": [], "entities": [{"text": "Lexical Functional Grammar", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.720110019048055}]}, {"text": "We briefly describe LFG and the basic generation model in Section 2.", "labels": [], "entities": []}, {"text": "We improve the baseline PCFG model by weakening the independence assumptions in two disambiguation models in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes the smoothing algorithms adopted for the chart generator and Section 5 gives the experimental details and results.", "labels": [], "entities": [{"text": "chart generator", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.699214905500412}]}], "datasetContent": [{"text": "Our experiments are carried out on the newly released Penn Chinese treebank version 6.0 (CTB6) (), excluding the portion of ACE broadcast news.", "labels": [], "entities": [{"text": "Penn Chinese treebank version 6.0 (CTB6)", "start_pos": 54, "end_pos": 94, "type": "DATASET", "confidence": 0.9694381430745125}, {"text": "ACE broadcast news", "start_pos": 124, "end_pos": 142, "type": "DATASET", "confidence": 0.9404556751251221}]}, {"text": "We follow the recommended splits (in the list-of-file of CTB6) to divide the data into test set, development set and training set.", "labels": [], "entities": [{"text": "CTB6", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.954285204410553}]}, {"text": "The training set includes 756 files with a total of 15,663 sentences.", "labels": [], "entities": []}, {"text": "The CTB trees of the training set were automatically annotated with LFG f-structure equations following.", "labels": [], "entities": []}, {"text": "shows the number of different grammar rule types extracted from the training set.", "labels": [], "entities": []}, {"text": "From the test files, we randomly select 500 sentences as test data with minimal sentence length 5 words, maximal length 80 words, and average length 28.84 words.", "labels": [], "entities": []}, {"text": "The development set also includes 500 sentences randomly selected from the development files with sentence length between 5 and 80 words.", "labels": [], "entities": []}, {"text": "The c-structure trees of the test and development data were also automatically converted to f-structures as input to the generator.", "labels": [], "entities": []}, {"text": "The generation system is evaluated against the raw text of the test data in terms of accuracy and coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9995057582855225}, {"text": "coverage", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9856553077697754}]}, {"text": "Following) and other work on general-purpose generators, we adopt BLEU score (), average simple string accuracy (SSA) and percentage of exactly matched sentences for accuracy evaluation.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9864882528781891}, {"text": "average simple string accuracy (SSA)", "start_pos": 81, "end_pos": 117, "type": "METRIC", "confidence": 0.9105358038629804}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.983322262763977}]}, {"text": "For coverage evaluation, we measure the percentage of input fstructures that generate a sentence.", "labels": [], "entities": [{"text": "coverage evaluation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9243104159832001}]}, {"text": "reports the initial experiments on the simple PCFG, HB-based PCFG and lexicalised PCFG models.", "labels": [], "entities": [{"text": "HB-based PCFG", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.7752643525600433}]}, {"text": "The results in the left column evaluate all input f-structures, the right column evaluate only those f-structures which yield a complete sentence.", "labels": [], "entities": []}, {"text": "The results show that the lexicalised model outperforms the baseline PCFG model.", "labels": [], "entities": []}, {"text": "The HB model is the most accurate for complete sentences, but with reduced coverage compared to the other two models.", "labels": [], "entities": [{"text": "coverage", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9762094616889954}]}, {"text": "However the low coverage of sentences completely generated due to unknown words and unmatched rules makes the results unusable in prac-: Results with lexical and rule smoothing tice.", "labels": [], "entities": []}, {"text": "gives the results with lexical smoothing.", "labels": [], "entities": []}, {"text": "The coverage for complete sentences increases by nearly 60% absolute for all models.", "labels": [], "entities": [{"text": "coverage", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9976217150688171}]}, {"text": "The increased coverage also improves the overall results evaluated against all sentences.", "labels": [], "entities": [{"text": "coverage", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9947104454040527}]}, {"text": "The HB model performs better than the simple PCFG model in nearly all respects and in turn the lexicalised model comprehensively outperforms the HB model.", "labels": [], "entities": []}, {"text": "The final results with both lexical smoothing and rule smoothing by two different strategies are tabulated in.", "labels": [], "entities": [{"text": "rule smoothing", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.6875544637441635}]}, {"text": "The left column provides the results of smoothing by partial match and the right column the results by reducing conditioning f-structure features.", "labels": [], "entities": []}, {"text": "All results are evaluated for completely generated sentences only.", "labels": [], "entities": []}, {"text": "The feature smoothing results in a full coverage of 100%, while slightly degrading the quality of sentences generated compared with partial match smoothing.", "labels": [], "entities": [{"text": "coverage", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.977592408657074}]}, {"text": "We feel the tradeoff at the cost of a small decrease in quality is still worth the full coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9679178595542908}]}, {"text": "Throughout the experiments, the lexicalised model exhibits consistently better performance than the unlexicalised models, which proves our intuition that successful techniques in parsing also work well in generation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Number of rules in the training set", "labels": [], "entities": []}, {"text": " Table 4: Results without smoothing", "labels": [], "entities": [{"text": "smoothing", "start_pos": 26, "end_pos": 35, "type": "TASK", "confidence": 0.8842953443527222}]}, {"text": " Table 5: Results with lexical smoothing", "labels": [], "entities": [{"text": "lexical smoothing", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7265947461128235}]}]}