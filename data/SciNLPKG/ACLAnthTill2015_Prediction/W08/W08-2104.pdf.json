{"title": [{"text": "Linguistic features in data-driven dependency parsing", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7066777497529984}]}], "abstractContent": [{"text": "This article investigates the effect of a set of linguistically motivated features on argument disambiguation in data-driven dependency parsing of Swedish.", "labels": [], "entities": [{"text": "argument disambiguation", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.7106811702251434}, {"text": "dependency parsing of Swedish", "start_pos": 125, "end_pos": 154, "type": "TASK", "confidence": 0.7846914380788803}]}, {"text": "We present results from experiments with gold standard features, such as animacy, definite-ness and finiteness, as well as corresponding experiments where these features have been acquired automatically and show significant improvements both in overall parse results and in the analysis of specific argument relations, such as subjects, objects and predicatives.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven dependency parsing has recently received extensive attention in the parsing community and impressive results have been obtained fora range of languages (.", "labels": [], "entities": [{"text": "Data-driven dependency parsing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5676394005616506}]}, {"text": "Even with high overall parsing accuracy, however, datadriven parsers often make errors in the assignment of argument relations such as subject and object and the exact influence of data-derived features on the parsing accuracy for specific linguistic constructions is still relatively poorly understood.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.5393232703208923}]}, {"text": "There area number of studies that investigate the influence of different features or representational choices on overall parsing accuracy,.", "labels": [], "entities": [{"text": "parsing", "start_pos": 121, "end_pos": 128, "type": "TASK", "confidence": 0.9583004713058472}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9444721341133118}]}, {"text": "There are also attempts at a more fine-grained analysis of accuracy, targeting specific linguistic constructions or grammatical functions).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9961141347885132}]}, {"text": "But there are few studies that combine the two perspectives and try to tease apart the influence of different features on the analysis of specific constructions, let alone motivated by a thorough linguistic analysis.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the influence of a set of linguistically motivated features on parse results for Swedish, and in particular on the analysis of argument relations such as subjects, objects and subject predicatives.", "labels": [], "entities": []}, {"text": "Motivated by an error analysis of the best performing parser for Swedish in the CoNLL-X shared task, we extend the feature model employed by the parser with a set of linguistically motivated features and goon to show how these features maybe acquired automatically.", "labels": [], "entities": []}, {"text": "We then present results from corresponding parse experiments with automatic features.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2 we present relevant properties of Swedish morphosyntax, as well as the treebank and parser employed in the experiments.", "labels": [], "entities": []}, {"text": "Section 3 presents an error analysis of the baseline parser and we goon to motivate a set of linguistic features in section 4, which are employed in a set of experiments with gold standard features, discussed in section 5.", "labels": [], "entities": []}, {"text": "Section 6 presents the automatic acquisition of these features, with a particular focus on animacy classification and in section 7 we report parse experiments with automatic features.", "labels": [], "entities": [{"text": "animacy classification", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.7826635539531708}]}], "datasetContent": [{"text": "We perform a set of experiments with an extended feature model and added, gold standard information on animacy, definiteness, case, finiteness and voice, where the features were employed individually as well as in combination.", "labels": [], "entities": []}, {"text": "All parsing experiments are performed using 10-fold cross-validation for training and testing on the entire written part of Talbanken05.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9605907201766968}, {"text": "written part of Talbanken05", "start_pos": 108, "end_pos": 135, "type": "DATASET", "confidence": 0.6772526949644089}]}, {"text": "The feature model used throughout is the extended feature model depicted in, including all four columns.", "labels": [], "entities": []}, {"text": "Hence, what is varied in the experiments is only the information contained in the FEATS features (animacy, definiteness, etc.), while the tokens for which these features are defined remains constant.", "labels": [], "entities": [{"text": "FEATS", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.5528115034103394}]}, {"text": "Overall parsing accuracy will be reported using the standard metrics of labeled attachment score (LAS) and unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "parsing", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.9653013944625854}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9714697003364563}, {"text": "labeled attachment score (LAS)", "start_pos": 72, "end_pos": 102, "type": "METRIC", "confidence": 0.822519987821579}, {"text": "unlabeled attachment score (UAS)", "start_pos": 107, "end_pos": 139, "type": "METRIC", "confidence": 0.8048095256090164}]}, {"text": "Statistical significance is checked using Dan Bikel's randomized parsing evaluation We experimented with the use of tense as well as finiteness, a binary feature which was obtained by a mapping from tense to finite/non-finite.", "labels": [], "entities": []}, {"text": "Finiteness gave significantly better results (p<.03) and was therefore employed in the following, see) for details.", "labels": [], "entities": []}, {"text": "6 Preliminary experiments showed that it was better to tie FEATS features to the same tokens as FORM features (rather than POS or DEP features).", "labels": [], "entities": []}, {"text": "Backward selection from this model was tried for several different instantiations of FEATS but with no significant improvement.", "labels": [], "entities": [{"text": "FEATS", "start_pos": 85, "end_pos": 90, "type": "DATASET", "confidence": 0.48201408982276917}]}, {"text": "7 LAS and UAS report the percentage of tokens that are assigned the correct head with (labeled) or without (unlabeled) the correct dependency label, calculated using eval.pl with default settings (http://nextens.uvt.nl/\u223cconll/software.html) comparator.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.8497563600540161}]}, {"text": "Since the main focus of this article is on the disambiguation of grammatical functions, we report accuracy for specific dependency relations, measured as a balanced F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9995124340057373}, {"text": "F-score", "start_pos": 165, "end_pos": 172, "type": "METRIC", "confidence": 0.9867246747016907}]}, {"text": "The experimental methodology is identical to the one described in 5.1 above, the only difference being that the linguistic features are acquired automatically, rather than being gold standard.", "labels": [], "entities": []}, {"text": "In order to enable a direct comparison with the results from the earlier experiments, we employ the gold standard part-of-speech tags, as before.", "labels": [], "entities": []}, {"text": "This means that the set for which the various linguistic features are defined is identical, whereas the feature values may differ.", "labels": [], "entities": []}, {"text": "presents the overall results with automatic features, compared to the gold standard results and p-scores for the difference of the automatic results from the NoFeats baseline.", "labels": [], "entities": [{"text": "NoFeats baseline", "start_pos": 158, "end_pos": 174, "type": "DATASET", "confidence": 0.91887566447258}]}, {"text": "As expected, we find that the effect of the automatic features is generally lower than their gold standard counterparts.", "labels": [], "entities": []}, {"text": "However, all automatic features improve significantly on the NoFeats baseline.", "labels": [], "entities": [{"text": "NoFeats baseline", "start_pos": 61, "end_pos": 77, "type": "DATASET", "confidence": 0.9185851216316223}]}, {"text": "In the error analysis we find the same tendencies in terms of improvement for specific dependency relations.", "labels": [], "entities": []}, {"text": "The morphological argument features from the POS-tagger are reliable, as we saw above, and we observe almost identical results to the gold standard results.", "labels": [], "entities": [{"text": "POS-tagger", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.730766236782074}]}, {"text": "The addition of information on definiteness causes a significant improvement (p<.01), and so does the addition of information on case (p<.0001).", "labels": [], "entities": []}, {"text": "The addition of the automatically acquired animacy information results in a smaller, but significant improvement of overall results even though the annotation is less reliable (p<.03).", "labels": [], "entities": []}, {"text": "An interesting result is that the automatically acquired information on animacy for common nouns actually has a significantly better effect than the gold standard counterparts due to capturing distributional tendencies.", "labels": [], "entities": []}, {"text": "As in the gold standard experiments, we find that the features which have the most notable effect on performance are the verbal features (p<.0001).", "labels": [], "entities": []}, {"text": "In parallel with the results achieved with the combination of gold standard features, we observe improvement of overall results compared to the baseline (p<.0001) and each of the individual features when we combine the features of the arguments (ADC; p<.01) and the argument and verbal features (ADCV; p<.0001).", "labels": [], "entities": [{"text": "ADCV", "start_pos": 296, "end_pos": 300, "type": "DATASET", "confidence": 0.8218854665756226}]}, {"text": "Column 4 in Table 4 shows an overview of performance for the argument relations, compared to the gold standard experiments.", "labels": [], "entities": []}, {"text": "We find overall somewhat lower results in the experiment with automatic features, but find the same tendencies with the automatically acquired features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Overall results in gold standard ex- periments expressed as unlabeled and labeled  attachment scores.", "labels": [], "entities": []}, {"text": " Table 4: F-scores for argument relations with  combined features (ADCV).", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9783306121826172}]}, {"text": " Table 5: Overview of applications employed for  automatic feature acquisition.", "labels": [], "entities": [{"text": "automatic feature acquisition", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.6049847702185313}]}, {"text": " Table 7: Accuracy for automatically acquired linguistic features.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9958763122558594}]}, {"text": " Table 8: Overall results in experiments with auto- matic features compared to gold standard features.", "labels": [], "entities": []}]}