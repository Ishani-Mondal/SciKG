{"title": [], "abstractContent": [{"text": "A common problem for clustering techniques is that clusters overlap, which makes graphing the statistical structure in the data difficult.", "labels": [], "entities": []}, {"text": "A related problem is that we often want to seethe distribution of factors (variables) as well as classes (objects).", "labels": [], "entities": []}, {"text": "Correspondence Analysis (CA) offers a solution to both these problems.", "labels": [], "entities": [{"text": "Correspondence Analysis (CA)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8375366866588593}]}, {"text": "The structure that CA discovers maybe an important step in representing similarity.", "labels": [], "entities": []}, {"text": "We have performed an analysis for Italian verbs and nouns, and confirmed that similar structures are found for English.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the past years, distributional methods have been used to explore the semantic behaviour of verbs, looking at their contexts in corpora.", "labels": [], "entities": []}, {"text": "We follow a general approach suggested already by, to associate distributional similarity with semantic similarity.", "labels": [], "entities": []}, {"text": "One question concerns the syntax-semantics interface.", "labels": [], "entities": []}, {"text": "Results using distributions of verbs in context had an impact on verb classification, automatic verb clustering (Schulte im, and selectional preference acquisition.", "labels": [], "entities": [{"text": "verb classification", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7356907725334167}, {"text": "automatic verb clustering", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.609031081199646}, {"text": "selectional preference acquisition", "start_pos": 129, "end_pos": 163, "type": "TASK", "confidence": 0.6965782841046652}]}, {"text": "In automatic verb clustering, verbs are represented by vectors of a multidimensional space whose dimensions (variables) are identified by some linguistic features, ranging, for example, from subcategorization frames to participation in diathesis alternations and lexical selectional preferences.", "labels": [], "entities": [{"text": "automatic verb clustering", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.6554196178913116}]}, {"text": "The verbs cluster on co-occurrence with the features chosen, and such information provide a generalisation over the verbs with respect to the variables.", "labels": [], "entities": []}, {"text": "In the case of selectional preference acquisition, a verb (or a verb class) is associated to a class of nouns that can be the lexical fillers of a case frame slot for the verb.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.666294107834498}]}, {"text": "This allows us to calculate the association strength between the verb and its filler nouns.", "labels": [], "entities": []}, {"text": "The generalisation step is performed for the case frame instances (observations) and produces more abstract noun classes that can be applied to unseen cases.", "labels": [], "entities": []}, {"text": "This often utilizes hierarchies of existing thesauri or wordnets.", "labels": [], "entities": []}, {"text": "We propose a method that uses Correspondence Analysis (CA) to study the distribution (and associated semantic behaviour) of a list of verbs with nouns occurring in a particular syntactic relation, for example their subjects.", "labels": [], "entities": []}, {"text": "This is collected from a corpus, and reflects usage in that corpus.", "labels": [], "entities": []}, {"text": "Unlike clustering methods, this technique does not imply an exclusive choice between a) classifying verbs on the basis of the noun fillers in their syntactic frame, or b) associating noun classes to verbs (sometimes mediated by a semantic hierarchy).", "labels": [], "entities": []}, {"text": "Instead, this approach yields a geometric representation of the relationships between the nouns and the verbs in a common dual space (biplot).", "labels": [], "entities": []}, {"text": "CA aims to find an overall structure (if any) of the data.", "labels": [], "entities": [{"text": "CA", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8572211861610413}]}, {"text": "The method emphasizes unusual observations, as deviance from the expected is what creates the axes of the analysis.", "labels": [], "entities": []}, {"text": "CA generalizes over the actual occurrences of verb-noun pairs in the corpus, and visualizes the shape of the correspondence space.", "labels": [], "entities": []}, {"text": "When associating verbs with nouns, CA takes as input a contingency table (here rows correspond to the verbs, and columns correspond to their subject fillers).", "labels": [], "entities": []}, {"text": "Each verb is a row point in the multidimensional noun space, and each noun is a column point in the multidimensional verb space.", "labels": [], "entities": []}, {"text": "The CA goals are to reduce the dimension of the dual original space, and to find an optimal subspace that is the closest to this cloud of points in the \u03c7 2 -metric.", "labels": [], "entities": []}, {"text": "The best subspace is determined by finding the smallest number of orthogonal axes that describe the most variance from the original cloud.", "labels": [], "entities": []}, {"text": "Finally the coordinates of both row and column points of the \u03c7 2 contingency table are projected onto this optimal subspace, simultaneously displaying row and column points.", "labels": [], "entities": []}, {"text": "If we consider those points that are well represented, the closer they are in this geometric representation, the more similar their original distributions are.", "labels": [], "entities": []}, {"text": "In this way, we can detect not only that there is a relationship between the verb (e.g. explode) and the noun (e.g. bomb), but also how each word relates to each other word.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}