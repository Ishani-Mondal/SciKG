{"title": [{"text": "Answer Validation by Information Distance Calculation", "labels": [], "entities": [{"text": "Answer Validation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8127303123474121}]}], "abstractContent": [{"text": "In this paper,an information distance based approach is proposed to perform answer validation for question answering system.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.791747510433197}, {"text": "question answering", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.8392757177352905}]}, {"text": "To validate an answer candidate, the approach calculates the conditional information distance between the question focus and the candidate under certain condition pattern set.", "labels": [], "entities": []}, {"text": "Heuristic methods are designed to extract question focus and generate proper condition patterns from question.", "labels": [], "entities": []}, {"text": "General search engines are employed to estimate the Kolmogorov complexity, hence the information distance.", "labels": [], "entities": [{"text": "Kolmogorov complexity", "start_pos": 52, "end_pos": 73, "type": "METRIC", "confidence": 0.7564388811588287}]}, {"text": "Experimental results show that our approach is stable and flexible, and outperforms traditional tfidf methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Question answering(QA) system aims at finding exact answers to a natural language question.", "labels": [], "entities": [{"text": "Question answering(QA)", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9080152750015259}]}, {"text": "In order to correctly answer a question, several components are implemented including question classification, passage retrieval, answer candidates generation, answer validation etc.", "labels": [], "entities": [{"text": "question classification", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.8034942448139191}, {"text": "passage retrieval", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.8716543316841125}, {"text": "answer candidates generation", "start_pos": 130, "end_pos": 158, "type": "TASK", "confidence": 0.6653560400009155}, {"text": "answer validation", "start_pos": 160, "end_pos": 177, "type": "TASK", "confidence": 0.7333401739597321}]}, {"text": "Answer Validation is to decide whether the candidate answers are corrector not, or even to determine the accurate confidence score to them.", "labels": [], "entities": [{"text": "Answer Validation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8195331990718842}, {"text": "accurate confidence score", "start_pos": 105, "end_pos": 130, "type": "METRIC", "confidence": 0.9334527651468912}]}, {"text": "Most of QA systems employ answer validation as the last step to identify the correct answer.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7850503921508789}]}, {"text": "If this component fails, it is impossible to enable the question to be correctly answered.", "labels": [], "entities": []}, {"text": "Automatic techniques for answer validation are of great interest among question answering re- search.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8948375284671783}, {"text": "question answering re- search", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.8915230989456177}]}, {"text": "With automatic answer validation, the system will carryout different refinements of its searching criteria to check the relevance of new candidate answers.", "labels": [], "entities": []}, {"text": "In addition, since most of QA systems rely on complex architectures and the evaluation of their performances requires a huge amount of work, the automatic assessment of candidates with respect to a given question will speedup both algorithm refinement and testing.", "labels": [], "entities": []}, {"text": "Currently, answer validation is mainly viewed as a classification problem or ranking problem.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.956100195646286}]}, {"text": "Different models, such as Support Vector Machine) and Maximum Entropy Model (, are used to integrate sophisticated linguistic features to determine the correctness of candidates.", "labels": [], "entities": []}, {"text": "The answer validation exercise ( aims at developing systems able to decide whether the answer is corrector not.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8746173977851868}]}, {"text": "They formulate answer validation as a text entailment problem.", "labels": [], "entities": [{"text": "formulate answer validation", "start_pos": 5, "end_pos": 32, "type": "TASK", "confidence": 0.7849389016628265}]}, {"text": "These approaches are dependent on sophisticated linguistic analysis of syntactic and semantic relations between question and candidates.", "labels": [], "entities": []}, {"text": "It is quite expensive to use deep analysis for automatic answer validation, especially in large scale data set.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7697039842605591}]}, {"text": "Thus it is appropriate to find an alternative solution to this problem.", "labels": [], "entities": []}, {"text": "Here, we just consider the English answer validation task.", "labels": [], "entities": [{"text": "English answer validation task", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.702244721353054}]}, {"text": "This paper proposes a novel approach based on information retrieval on the Web.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.7513956725597382}]}, {"text": "The answer validation problem is reformulated as distance calculation from an answer candidate to a question.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8535171151161194}]}, {"text": "The hypothesis is that, among all candidates, the correct answer has the smallest distance from question.", "labels": [], "entities": []}, {"text": "We employ conditional normalized min distance, which is based on Kolmogorov Complexity theory, for this task.", "labels": [], "entities": []}, {"text": "The distance measures the relevance between question focus and candidates conditioned on a surface pattern set.", "labels": [], "entities": []}, {"text": "For distance calculation, we first extract the question focus, and then a hierarchical pattern set is automatically constructed as condition.", "labels": [], "entities": [{"text": "distance calculation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9612162113189697}]}, {"text": "Since Kolmogrov Complexity can be approximated through frequency counts.", "labels": [], "entities": []}, {"text": "Two types of search engine \"Google\" and \"Altavista\" are used to approximate the distance.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 describes related work.", "labels": [], "entities": []}, {"text": "The fundamental Kolmogorov Complexity theory is introduced in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 presents our proposed answer validation method based on information retrieval.", "labels": [], "entities": [{"text": "answer validation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.878014087677002}]}, {"text": "In Section 5, we describe the experiments and discussions.", "labels": [], "entities": []}, {"text": "The paper is concluded in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data set: The standard QA test collection () is employed in our experiments.", "labels": [], "entities": [{"text": "QA test collection", "start_pos": 23, "end_pos": 41, "type": "DATASET", "confidence": 0.7207716604073843}]}, {"text": "It consists of 109 factoid questions, covering several domains including history, geography, physics, biology, economics, fashion knowledge, and etc..", "labels": [], "entities": []}, {"text": "20 candidates are prepared for each questions.", "labels": [], "entities": []}, {"text": "All answer candidates are first extracted by the implemented question answering system.", "labels": [], "entities": [{"text": "question answering", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7165737897157669}]}, {"text": "Then we review the candidate set for each question.", "labels": [], "entities": []}, {"text": "If the correct answer is not in this set, it is manually added into the set.", "labels": [], "entities": []}, {"text": "The open source factoid QA system ARANEA (downloaded from Jimmy Lin's website in 2005) is used for comparison, which implements an approximate tf idf algorithm for candidate scoring.", "labels": [], "entities": [{"text": "ARANEA", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.8596189618110657}]}, {"text": "Both ARANEA and our proposed approaches use the internet directly.", "labels": [], "entities": [{"text": "ARANEA", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.847935140132904}]}, {"text": "Google is used as the search engine for ARENEA, and our conditional normalized min distance is calculated with Google and Altavista respectively.", "labels": [], "entities": [{"text": "ARENEA", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9581029415130615}, {"text": "conditional normalized min distance", "start_pos": 56, "end_pos": 91, "type": "METRIC", "confidence": 0.62861068546772}]}, {"text": "The performances of our proposed approach and ARANEA are shown in.", "labels": [], "entities": [{"text": "ARANEA", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9510069489479065}]}, {"text": "For top 1 answer precision, our conditional min distance calculation method through Google achieves 69.7%, and Altavista is 66.1%, which make 56.6% (69.7% v.s.42.2% ) and 50.0% (66.1% v.s 42.2%) improvement compared with ARENEA's tf idf method.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9594149589538574}]}, {"text": "Our proposed methods achieve 0.756 and 0.772 compared with ARENEA's 0.581 for MRR measure.", "labels": [], "entities": [{"text": "ARENEA", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.993615984916687}, {"text": "MRR", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.5097000598907471}]}, {"text": "shows some correct answer validation examples.", "labels": [], "entities": []}, {"text": "the Google Condition(GC) and the Altavista Condition(AC) columns are the employed condition patterns for distance calculation.", "labels": [], "entities": [{"text": "distance calculation", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.9276270866394043}]}, {"text": "For question 1400, the conditional normalized google min distance calculates the distance between question focus \"the telegragh\" and all 20 answer candidates.", "labels": [], "entities": [{"text": "google min distance", "start_pos": 46, "end_pos": 65, "type": "METRIC", "confidence": 0.7440416614214579}]}, {"text": "The minimum distance score is achieved between \"the telegraph\" and \"1837\" with the condition pattern \"f was invented in c\".", "labels": [], "entities": [{"text": "minimum distance score", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.856053372224172}]}, {"text": "Therefore, the candidate \"1837\" is validated as the correct answer.", "labels": [], "entities": []}, {"text": "Meanwhile, the minimum value for conditional normalized altavista min distance is achieved on the same condition.", "labels": [], "entities": []}, {"text": "These results demonstrate that the distance calculation method provides a feasible solution for answer validation.", "labels": [], "entities": [{"text": "distance calculation", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7706765532493591}, {"text": "answer validation", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.9214769303798676}]}, {"text": "In discussion section, we will study three questions: 1.", "labels": [], "entities": []}, {"text": "What is the role of search engine?", "labels": [], "entities": []}, {"text": "2. What is the role of condition pattern?", "labels": [], "entities": []}, {"text": "3. What is the role of question focus?", "labels": [], "entities": [{"text": "question focus", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.7307323813438416}]}, {"text": "\"?x discovered ?y\" \"?x\" \"discovered\" \"?y\" Hernando de Soto the Mississippi River", "labels": [], "entities": [{"text": "Hernando de Soto the Mississippi River", "start_pos": 42, "end_pos": 80, "type": "DATASET", "confidence": 0.524137924114863}]}], "tableCaptions": [{"text": " Table 3. For top 1 an- swer precision, our conditional min distance cal- culation method through Google achieves 69.7%,  and Altavista is 66.1%, which make 56.6%  (69.7% v.s.42.2% ) and 50.0% (66.1% v.s 42.2%)  improvement compared with ARENEA's tf idf  method. Our proposed methods achieve 0.756 and  0.772 compared with ARENEA's 0.581 for MRR  measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9721884727478027}, {"text": "ARENEA", "start_pos": 323, "end_pos": 329, "type": "DATASET", "confidence": 0.7802988886833191}, {"text": "MRR", "start_pos": 342, "end_pos": 345, "type": "METRIC", "confidence": 0.5319287776947021}]}, {"text": " Table 3: Performance comparison, where dmin(G) denotes", "labels": [], "entities": []}]}