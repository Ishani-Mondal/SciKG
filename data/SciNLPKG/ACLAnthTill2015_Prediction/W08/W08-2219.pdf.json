{"title": [{"text": "Open Knowledge Extraction through Compositional Language Processing", "labels": [], "entities": [{"text": "Open Knowledge Extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7496778766314188}]}], "abstractContent": [{"text": "We present results fora system designed to perform Open Knowledge Extraction, based on a tradition of compositional language processing, as applied to a large collection of text derived from the Web.", "labels": [], "entities": [{"text": "Open Knowledge Extraction", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.6332447628180186}]}, {"text": "Evaluation through manual assessment shows that well-formed propositions of reasonable quality, representing general world knowledge, given in a logical form potentially usable for inference, maybe extracted in high volume from arbitrary input sentences.", "labels": [], "entities": []}, {"text": "We compare these results with those obtained in recent work on Open Information Extraction, indicating with some examples the quite different kinds of output obtained by the two approaches.", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.7110151847203573}]}, {"text": "Finally, we observe that portions of the extracted knowledge are comparable to results of recent work on class attribute extraction.", "labels": [], "entities": [{"text": "class attribute extraction", "start_pos": 105, "end_pos": 131, "type": "TASK", "confidence": 0.6359684069951376}]}, {"text": "239 240 Van Durme and Schubert", "labels": [], "entities": []}], "introductionContent": [{"text": "Several early studies in large-scale text processing ( showed that having access to a sentence's syntax enabled credible, automated semantic analysis.", "labels": [], "entities": [{"text": "text processing", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.6933577656745911}, {"text": "semantic analysis", "start_pos": 132, "end_pos": 149, "type": "TASK", "confidence": 0.6939345300197601}]}, {"text": "These studies suggest that the use of increasingly sophisticated linguistic analysis tools could enable an explosion in available symbolic knowledge.", "labels": [], "entities": []}, {"text": "Nonetheless, much of the subsequent work in extraction has remained averse to the use of the linguistic deep structure of text; this decision is typically justified by a desire to keep the extraction system as computationally lightweight as possible.", "labels": [], "entities": []}, {"text": "The acquisition of background knowledge is not an activity that needs to occur online; we argue that as long as the extractor will finish in a reasonable period of time, the speed of such a system is an issue of secondary importance.", "labels": [], "entities": []}, {"text": "Accuracy and usefulness of knowledge should be of paramount concern, especially as the increase in available computational power makes such \"heavy\" processing less of an issue.", "labels": [], "entities": []}, {"text": "The system explored in this paper is designed for Open Knowledge Extraction: the conversion of arbitrary input sentences into general world knowledge represented in a logical form possibly usable for inference.", "labels": [], "entities": [{"text": "Open Knowledge Extraction", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.7217087348302206}]}, {"text": "Results show the feasibility of extraction via the use of sophisticated natural language processing as applied to web texts.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments reported here were aimed at a comparative assessment of linguistically based knowledge extraction (by KNEXT), and pattern-based information extraction (by TextRunner, and by another system, aimed at class attribute discovery).", "labels": [], "entities": [{"text": "linguistically based knowledge extraction", "start_pos": 72, "end_pos": 113, "type": "TASK", "confidence": 0.686724528670311}, {"text": "KNEXT", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.8937366008758545}, {"text": "pattern-based information extraction", "start_pos": 130, "end_pos": 166, "type": "TASK", "confidence": 0.6629970371723175}, {"text": "class attribute discovery", "start_pos": 215, "end_pos": 240, "type": "TASK", "confidence": 0.680216372013092}]}, {"text": "The goal being to show that logically formal results (i.e. knowledge) based on syntactic parsing maybe obtained at a subjective level of accuracy similar to methods aimed exclusively at acquiring correspondences between string pairs based on shallow techniques.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9977186918258667}]}, {"text": "Dataset Experiments were based on sampling 1% of the sentences from each document contained within a corpus of 11,684,774 web pages harvested from 1,354,123 unique top level domains.", "labels": [], "entities": []}, {"text": "The top five contributing domains made up 30% of the documents in the collection.", "labels": [], "entities": []}, {"text": "There were 310,463,012 sentences in all, the sample containing 3,000,736.", "labels": [], "entities": []}, {"text": "Of these, 1,373 were longer than a preset limit of 100 tokens, and were discarded.", "labels": [], "entities": []}, {"text": "5 Sentences containing individual tokens of length greater than 500 characters were similarly removed.", "labels": [], "entities": []}, {"text": "As this corpus derives from the work of, each sentence in the collection is paired with zero or more tuples as extracted by the TextRunner system.", "labels": [], "entities": []}, {"text": "Note that while websites such as Wikipedia.org contain large quantities of (semi-)structured information stored in lists and tables, the focus here is entirely on natural language sentences.", "labels": [], "entities": []}, {"text": "In addition, as the extraction methods discussed in this paper do not make use of intersentential features, the lack of sentence to sentence coherence resulting from random sampling had no effect on the results.", "labels": [], "entities": []}, {"text": "Extraction Sentences were processed using the syntactic parser of Charniak (1999).", "labels": [], "entities": [{"text": "Extraction Sentences", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7622345387935638}]}, {"text": "From the resultant trees, KNEXT extracted 7,406,371 propositions, giving a raw average of 2.47 per sentence.", "labels": [], "entities": []}, {"text": "Of these, 4,151,779 were unique, so that the average extraction frequency per sentence is 1.78 unique propositions.", "labels": [], "entities": []}, {"text": "Post-processing left 3,975,197 items, giving a per sentence expectation of 1.32 unique, filtered propositions.", "labels": [], "entities": []}, {"text": "Selected examples regarding knowledge about people appear in For the same sample, TextRunner extracted 6,053,983 tuples, leading to a raw average of 2.02 tuples per sentence.", "labels": [], "entities": []}, {"text": "As described by its designers, TextRunner is an information extraction system; one would be mistaken in using these results to say that KNEXT \"wins\" in raw extraction volume, as these numbers are not in fact directly comparable (see section on Comparison).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7640508413314819}]}], "tableCaptions": [{"text": " Table 1.  For the same sample, TextRunner extracted 6,053,983 tuples, leading to a raw av- erage of 2.02 tuples per sentence. As described by its designers, TextRunner is an  information extraction system; one would be mistaken in using these results to say  that KNEXT \"wins\" in raw extraction volume, as these numbers are not in fact directly  comparable (see section on Comparison).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 176, "end_pos": 198, "type": "TASK", "confidence": 0.7528849542140961}]}, {"text": " Table 1: Verbalized propositions concerning the class PERSON", "labels": [], "entities": []}, {"text": " Table 2: Percent propositions labeled under the given category(s), paired with Fleiss'  Kappa scores. Results are reported both for the authors (judges one and two), along  with two volunteers  Category % Selected Kappa % Selected Kappa  1  49%  0.4017  50%  0.2822  1, 2, or 3  54%  0.4766  60%  0.3360  judges  judges w/ volunteers", "labels": [], "entities": []}, {"text": " Table 3: Mean judgements (lower is better) on propositions sampled from those sup- ported either exclusively by natural or core sentences, or those supported by both", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.979697048664093}]}, {"text": " Table 5: Mean assessed acceptability for properties occurring for a single class (1),  and more than a single class (2+). Final column contains Pearson correlation scores", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 145, "end_pos": 164, "type": "METRIC", "confidence": 0.8830744624137878}]}]}