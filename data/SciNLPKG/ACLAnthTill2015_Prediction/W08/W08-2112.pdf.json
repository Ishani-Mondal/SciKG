{"title": [{"text": "An Incremental Bayesian Model for Learning Syntactic Categories", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an incremental Bayesian model for the unsupervised learning of syntactic categories from raw text.", "labels": [], "entities": []}, {"text": "The model draws information from the distributional cues of words within an utterance, while explicitly bootstrap-ping its development on its own partially-learned knowledge of syntactic categories.", "labels": [], "entities": []}, {"text": "Testing our model on actual child-directed data, we demonstrate that it is robust to noise, learns reasonable categories, manages lexical ambiguity, and in general shows learning behaviours similar to those observed in children.", "labels": [], "entities": []}], "introductionContent": [{"text": "An important open problem in cognitive science and artificial intelligence is how children successfully learn their native language despite the lack of explicit training.", "labels": [], "entities": []}, {"text": "A key challenge in the early stages of language acquisition is to learn the notion of abstract syntactic categories (e.g., nouns, verbs, or determiners), which is necessary for acquiring the syntactic structure of language.", "labels": [], "entities": []}, {"text": "Indeed, children as young as two years old show evidence of having acquired a good knowledge of some of these abstract categories; by around six years of age, they have learned almost all syntactic categories ().", "labels": [], "entities": []}, {"text": "Computational models help to elucidate the kinds of learning mechanisms that maybe capable of achieving this feat.", "labels": [], "entities": []}, {"text": "Such studies shed light on the possible cognitive mechanisms at work inhuman language acquisition, and also on potential means for unsupervised learning of complex linguistic knowledge in a computational system.", "labels": [], "entities": []}, {"text": "Learning the syntactic categories of words has been suggested to be based on the morphological and phonological properties of individual words, as well as on the distributional information about the contexts in which they appear.", "labels": [], "entities": []}, {"text": "Several computational models have been proposed that draw on one or more of the above-mentioned properties in order to group words into discrete unlabeled categories.", "labels": [], "entities": []}, {"text": "Most existing models only intend to show the relevance of such properties to the acquisition of adult-like syntactic categories such as nouns and verbs; hence, they do not necessarily incorporate the types of learning mechanisms used by children).", "labels": [], "entities": []}, {"text": "For example, in contrast to the above models, children acquire their knowledge of syntactic categories incrementally, processing the utterances they hear one at a time.", "labels": [], "entities": []}, {"text": "Moreover, children appear to be sensitive to the fact that syntactic categories are partially defined in terms of other categories, e.g., nouns tend to follow determiners, and can be modified by adjectives.", "labels": [], "entities": []}, {"text": "We thus argue that a computational model should be incremental, and should use more abstract category knowledge to help better identify syntactic categories.", "labels": [], "entities": []}, {"text": "Incremental processing also allows a model to incorporate its partially-learned knowledge of categories, letting the model bootstrap its development.", "labels": [], "entities": [{"text": "Incremental processing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8220832645893097}]}, {"text": "To our knowledge, the only incremental model of category acquisition that also incorporates bootstrapping is that of.", "labels": [], "entities": [{"text": "category acquisition", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7941312491893768}]}, {"text": "Their template-based model, however, draws on very specific linguistic constraints and rules to learn categories.", "labels": [], "entities": []}, {"text": "Moreover, their model has difficulty with the variability of natural language data.", "labels": [], "entities": []}, {"text": "We address these shortcomings by developing an incremental probabilistic model of syntactic category acquisition that uses a domain-general learning algorithm.", "labels": [], "entities": [{"text": "syntactic category acquisition", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.6712113420168558}]}, {"text": "The model also incorporates a bootstrapping mechanism, and learns syntactic categories by looking only at the general patterns of distributional similarity in the input.", "labels": [], "entities": []}, {"text": "Experiments performed on actual (noisy) child-directed data show that an explicit bootstrapping component improves the model's ability to learn adult-like categories.", "labels": [], "entities": []}, {"text": "The model's learning trajectory resembles some relevant behaviours seen in children, and we also show that the categories that our model learns can be successfully used in a lexical disambiguation task.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test our proposed model, we train it on a sample of language representative of what children would hear, and evaluate its categorization abilities.", "labels": [], "entities": []}, {"text": "We have multiple goals in this evaluation.", "labels": [], "entities": []}, {"text": "First, we determine the model's ability to discover adult-level syntactic categories from the input.", "labels": [], "entities": []}, {"text": "Since this is intended to be a cognitively plausible learning model, we also compare the model's qualitative learning behaviours with those of children.", "labels": [], "entities": []}, {"text": "In the first experiment (Section 4), we compare the model's categorization with a gold standard of adult-level syntactic categories and examine the effect of the bootstrapping component.", "labels": [], "entities": []}, {"text": "The second experiment (Section 5) examines the model's development of three specific parts of speech.", "labels": [], "entities": []}, {"text": "Developmental evidence suggests that children acquire different syntactic categories at different ages, so we compare the model's learning rates of nouns, verbs, and adjectives.", "labels": [], "entities": []}, {"text": "Lastly, we examine our model's ability to handle lexically ambiguous words (Section 6).", "labels": [], "entities": []}, {"text": "English word forms commonly belong to more than one syntactic category, so we show how our model uses context to disambiguate a word's category.", "labels": [], "entities": []}, {"text": "In all experiments, we train and test the model using the Manchester corpus () from the CHILDES database).", "labels": [], "entities": [{"text": "Manchester corpus", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.9877496063709259}, {"text": "CHILDES database", "start_pos": 88, "end_pos": 104, "type": "DATASET", "confidence": 0.9543755054473877}]}, {"text": "The corpus contains transcripts of mothers' conversations with 12 British children between the ages of 1;8 (years;months) and 3;0.", "labels": [], "entities": []}, {"text": "There are 34 one-hour sessions per child over the course of a year.", "labels": [], "entities": []}, {"text": "The age range of the children roughly corresponds with the ages at which children show the first evidence of syntactic categories.", "labels": [], "entities": []}, {"text": "We extract the mothers' speech from each of the transcripts, then concatenate the input of all 12 children (all of Anne's sessions, followed by all of Aran's sessions, and so on).", "labels": [], "entities": [{"text": "Aran's sessions", "start_pos": 151, "end_pos": 166, "type": "TASK", "confidence": 0.8255731066068014}]}, {"text": "We spell out contractions, so that each token in the input corresponds to only one part-of-speech (PoS) label (noun, verb, etc.).", "labels": [], "entities": []}, {"text": "We also remove single-word utterances and utterances with a single repeated word type, since they contain no distributional information.", "labels": [], "entities": []}, {"text": "We randomly split the data into development and evaluation sets, each containing approximately 683,000 tokens.", "labels": [], "entities": []}, {"text": "We use the development set to finetune the model parameters and develop the experiments, then use the evaluation set as a final test of the model.", "labels": [], "entities": []}, {"text": "We further split the development set into about 672,000 tokens (about 8,000 types) for training and 11,000 tokens (1,300 types) for validation.", "labels": [], "entities": []}, {"text": "We split the evaluation set comparably, into training and test subsets.", "labels": [], "entities": []}, {"text": "All reported results are for the evaluation set.", "labels": [], "entities": []}, {"text": "A conservative estimate suggests that children are exposed to at least 1.5 million words of childdirected speech annually (, so this corpus represents only a small portion of a child's available input.", "labels": [], "entities": []}, {"text": "The PoS tags in the Manchester corpus are too finegrained for our evaluation, so for our gold standard we map them to the following 11 tags: noun, verb, auxiliary, adjective, adverb, determiner, conjunction, negation, preposition, infinitive to, and 'other.'", "labels": [], "entities": [{"text": "Manchester corpus", "start_pos": 20, "end_pos": 37, "type": "DATASET", "confidence": 0.8982158005237579}]}, {"text": "When we evaluate the model's categorization performance, we have two different sets of clusters of the words in the test set: one set resulting from the gold standard, and another as a result of the model's categorization.", "labels": [], "entities": []}, {"text": "We compare these two clusterings, using the adjusted Rand index, which measures the overall agreement between two clusterings of a set of data points.", "labels": [], "entities": [{"text": "Rand index", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.949501633644104}]}, {"text": "The measure is 'corrected for chance,' so that a random grouping has an expected score of zero.", "labels": [], "entities": []}, {"text": "This measure tends to be very conservative, giving values much lower than an intuitive percentage score.", "labels": [], "entities": []}, {"text": "However, it offers a useful relative comparison of overall cluster similarity.", "labels": [], "entities": []}, {"text": "gives the adjusted Rand scores of the three model variants, word-based, bootstrap, and combination.", "labels": [], "entities": [{"text": "Rand", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9920469522476196}]}, {"text": "Higher values indicate a better fit with the gold-standard categorization scheme.", "labels": [], "entities": []}, {"text": "The adjusted Rand score is corrected for chance, thus providing a built-in baseline measure.", "labels": [], "entities": [{"text": "Rand score", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9882843196392059}, {"text": "chance", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9885713458061218}]}, {"text": "Since the expected score fora random clustering is zero, all three model variants operate at above-baseline performance.", "labels": [], "entities": []}, {"text": "A common trend observed in children is that different syntactic categories are learned at different rates.", "labels": [], "entities": []}, {"text": "Children appear to have learned the category of nouns by 23 months of age, verbs shortly thereafter, and adjectives relatively late ().", "labels": [], "entities": []}, {"text": "Our goal in this experiment is to look for these specific trends in the behaviour of our model.", "labels": [], "entities": []}, {"text": "We thus simulate an experiment where a child uses a novel word's linguistic context to infer its syntactic category (e.g.,).", "labels": [], "entities": []}, {"text": "For our experiment, we randomly generate input frames with novel head words using contexts associated with nouns, verbs, and adjectives, then examine the model's categorization in each case.", "labels": [], "entities": []}, {"text": "We expect that our model should approximate the developmental trends of children, who tend to learn the category of 'noun' before 'verb,' and both of these before 'adjective.'", "labels": [], "entities": []}, {"text": "The category structure of our model allows a single word type to be a member of multiple categories.", "labels": [], "entities": []}, {"text": "For example, kiss could belong to a category of predominantly noun usages (Can I have a kiss?) and also to a category of verb usages (Kiss me!).", "labels": [], "entities": []}, {"text": "As a result, the model easily represents lexical ambiguity.", "labels": [], "entities": []}, {"text": "In this experiment, inspired by disambiguation work in psycholinguistics (see, e.g., MacDonald, 1993), we examine the model's ability to correctly disambiguate category memberships.", "labels": [], "entities": []}], "tableCaptions": []}