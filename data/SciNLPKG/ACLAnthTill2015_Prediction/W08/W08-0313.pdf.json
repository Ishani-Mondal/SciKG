{"title": [{"text": "First Steps towards a general purpose French/English Statistical Machine Translation System", "labels": [], "entities": [{"text": "French/English Statistical Machine Translation", "start_pos": 38, "end_pos": 84, "type": "TASK", "confidence": 0.6543971995512644}]}], "abstractContent": [{"text": "This paper describes an initial version of a general purpose French/English statistical machine translation system.", "labels": [], "entities": [{"text": "general purpose French/English statistical machine translation", "start_pos": 45, "end_pos": 107, "type": "TASK", "confidence": 0.5839059166610241}]}, {"text": "The main features of this system are the open-source Moses de-coder, the integration of a bilingual dictionary and a continuous space target language model.", "labels": [], "entities": []}, {"text": "We analyze the performance of this system on the test data of the WMT'08 evaluation.", "labels": [], "entities": [{"text": "WMT'08 evaluation", "start_pos": 66, "end_pos": 83, "type": "DATASET", "confidence": 0.8214911818504333}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) is today considered as a serious alternative to rule-based machine translation (RBMT).", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8391865094502767}, {"text": "rule-based machine translation (RBMT)", "start_pos": 86, "end_pos": 123, "type": "TASK", "confidence": 0.8107199668884277}]}, {"text": "While RBMT systems rely on rules and linguistic resources built for that purpose, SMT systems can be developed without the need of any language knowledge and are only based on bilingual sentence-aligned and large monolingual data.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 6, "end_pos": 10, "type": "TASK", "confidence": 0.9374338388442993}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9903833270072937}]}, {"text": "However, while the monolingual data is usually available in large amounts, bilingual texts area sparse resource for most of the language pairs.", "labels": [], "entities": []}, {"text": "The largest SMT systems are currently build for the translation of Mandarin and Arabic to English, using more than 170M words of bitexts that are easily available from the LDC.", "labels": [], "entities": [{"text": "SMT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9771603345870972}, {"text": "translation of Mandarin and Arabic to English", "start_pos": 52, "end_pos": 97, "type": "TASK", "confidence": 0.8698633738926479}]}, {"text": "Recent human evaluations of these systems seem to indicate that they have reached a level of performance allowing a human being to understand the automatic translations and to answer complicated questions on its content.", "labels": [], "entities": []}, {"text": "Ina joint project between the University of Le Mans and the company SYSTRAN, we try to build similar general purpose SMT systems for European languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9059585332870483}]}, {"text": "In the final version, these systems will not only be trained on all available mono-and bilingual data, but also will include additional resources from SYSTRAN like high quality dictionaries, named entity transliteration and rule-based translation of expressions like numbers and dates.", "labels": [], "entities": [{"text": "rule-based translation of expressions like numbers and dates", "start_pos": 224, "end_pos": 284, "type": "TASK", "confidence": 0.7805512920022011}]}, {"text": "Our ultimate goal is to combine the power of datadriven approaches and the concentrated knowledge present in RBMT resources.", "labels": [], "entities": []}, {"text": "In this paper, we describe an initial version of an French/English system and analyze its performance on the test corpora of the WMT'08 workshop.", "labels": [], "entities": [{"text": "WMT'08 workshop", "start_pos": 129, "end_pos": 144, "type": "DATASET", "confidence": 0.7454620599746704}]}], "datasetContent": [{"text": "The shared evaluation task of the third workshop on statistical machine translation features two different test sets: test2008 and newstest2008.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6515271067619324}, {"text": "newstest2008", "start_pos": 131, "end_pos": 143, "type": "DATASET", "confidence": 0.9380837082862854}]}, {"text": "The first one contains data from the European parliament of the same type than the provided training and development data.", "labels": [], "entities": []}, {"text": "Therefore good generalization performance can be expected.", "labels": [], "entities": []}, {"text": "The second test set, however, is news type data from unknown sources.", "labels": [], "entities": []}, {"text": "Scanning some of the sentences after the evaluation seems to indicate that this data is more general than the provided news-commentary training and development data -it contains for instance financial and public health news.", "labels": [], "entities": []}, {"text": "Given the particular jargon of the European parliament, we decided to build two different systems, one rather general system tuned in nc-devtest2007 and an Europarl system tuned on devtest2006.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 156, "end_pos": 164, "type": "DATASET", "confidence": 0.9492444396018982}]}, {"text": "Both systems use the tokenization proposed by the Moses SMT toolkit and the case was preserved in the translation and language model.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.9631341099739075}, {"text": "SMT", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.7881454825401306}]}, {"text": "Therefore, in contrast to the official BLEU scores, we report here case sensitive BLEU scores as calculated by the NIST tool.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9914178848266602}, {"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9522464871406555}, {"text": "NIST tool", "start_pos": 115, "end_pos": 124, "type": "DATASET", "confidence": 0.9572855532169342}]}], "tableCaptions": [{"text": " Table 1: Perplexities on devtest2006 (Europarl) and  nc-devtest2007 (news commentary) for various LMs.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.95485919713974}]}, {"text": " Table 1. We were not able to obtain signifi- cantly better results with 5-gram back-off LMs.", "labels": [], "entities": []}, {"text": " Table 2. The translation model was trained on  the Europarl and the news-commentary data, aug- mented by parts of the dictionary. The LM was  trained on all the data, but the additional out-of- domain data has probably little impact given the  small improvements in perplexity (see", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9777871370315552}, {"text": "Europarl", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.9945916533470154}, {"text": "news-commentary data", "start_pos": 69, "end_pos": 89, "type": "DATASET", "confidence": 0.8469242453575134}]}, {"text": " Table 2: Case sensitive BLEU scores for the Europarl  system (test data)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9636279940605164}, {"text": "Europarl  system", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.9784747958183289}]}, {"text": " Table 3. The translation model  was trained on the news-commentary, Europarl and  Hansard bitexts as well as parts of the dictionary.  The LM was again trained on all data.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9758893251419067}, {"text": "Europarl", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.9697037935256958}, {"text": "Hansard bitexts", "start_pos": 83, "end_pos": 98, "type": "DATASET", "confidence": 0.6976163983345032}]}, {"text": " Table 3: Case sensitive BLEU scores of the news system  (nc-test2007 and newstest2008)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9443161487579346}]}]}