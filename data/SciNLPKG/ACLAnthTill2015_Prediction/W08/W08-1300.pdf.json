{"title": [{"text": "Coling 2008 22nd International Conference on Computational Linguistics Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation Workshop chairs", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "Broad-coverage parsing has come to a point where distinct approaches can offer (seemingly) comparable performance: statistical parsers acquired from the Penn Treebank (PTB); data-driven dependency parsers; 'deep' parsers trained off enriched treebanks (in linguistic frameworks like CCG, HPSG, or LFG); and hybrid 'deep' parsers, employing hand-built grammars in, for example, HPSG, LFG, or LTAG.", "labels": [], "entities": [{"text": "Broad-coverage parsing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6894518136978149}, {"text": "Penn Treebank (PTB)", "start_pos": 153, "end_pos": 172, "type": "DATASET", "confidence": 0.9715781569480896}, {"text": "data-driven dependency parsers", "start_pos": 174, "end_pos": 204, "type": "TASK", "confidence": 0.6613464951515198}, {"text": "HPSG", "start_pos": 377, "end_pos": 381, "type": "DATASET", "confidence": 0.9633592963218689}, {"text": "LTAG", "start_pos": 391, "end_pos": 395, "type": "DATASET", "confidence": 0.9182460904121399}]}, {"text": "Evaluation against trees in the Wall Street Journal (WSJ) section of the PTB has helped advance parsing research over the course of the past decade.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) section of the PTB", "start_pos": 32, "end_pos": 76, "type": "DATASET", "confidence": 0.9531311929225922}, {"text": "parsing", "start_pos": 96, "end_pos": 103, "type": "TASK", "confidence": 0.9839703440666199}]}, {"text": "Despite some scepticism, the crisp and, overtime, stable task of maximizing ParsEval metrics (i.e. constituent labeling precision and recall) over PTB trees has served as a dominating benchmark.", "labels": [], "entities": [{"text": "crisp", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9720021486282349}, {"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.7831048369407654}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9970224499702454}]}, {"text": "However, modern treebank parsers still restrict themselves to only a subset of PTB annotation; there is reason to worry about the idiosyncrasies of this particular corpus; it remains unknown how much the ParsEval metric (or any intrinsic evaluation) can inform NLP application developers; and PTB-style analyses leave a lotto be desired in terms of linguistic information.", "labels": [], "entities": []}, {"text": "The Grammatical Relations (GR) scheme, inspired by Dependency Grammar, offers a level of abstraction over specific syntactic analyses.", "labels": [], "entities": [{"text": "Grammatical Relations (GR)", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6865769386291504}]}, {"text": "It aims to capture the 'gist' of grammatical relations in a fashion that avoids reference to a token linguistic theory.", "labels": [], "entities": []}, {"text": "GR has recently been applied successfully in a series of cross-framework parser evaluation studies.", "labels": [], "entities": [{"text": "GR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.7132735252380371}]}, {"text": "At the same time, rather little GR gold standard data is available, and the GR scheme has been questioned for some of its design decisions.", "labels": [], "entities": [{"text": "GR gold standard data", "start_pos": 32, "end_pos": 53, "type": "DATASET", "confidence": 0.6248602047562599}]}, {"text": "More specifically, GR builds on a combination of syntactic and, albeit very limited, some semantic information.", "labels": [], "entities": [{"text": "GR", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9707995653152466}]}, {"text": "Existing studies suggest that the GR gold standard can be both overly rich and overly shallow in some respects.", "labels": [], "entities": [{"text": "GR gold standard", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.827447235584259}]}, {"text": "Furthermore, the mapping of 'native' parser outputs into GR introduces noise, and it raises a number of theoretical and practical questions.", "labels": [], "entities": []}, {"text": "Gold standard representations at the level of propositional semantics have at times been proposed for cross-framework parser evaluation, specifically where the parsing task is broadly construed as a tool towards 'text understanding', i.e. where the parser is to provide all information that is grammaticalized and contributing to interpretation.", "labels": [], "entities": [{"text": "cross-framework parser evaluation", "start_pos": 102, "end_pos": 135, "type": "TASK", "confidence": 0.7799814939498901}, {"text": "text understanding", "start_pos": 213, "end_pos": 231, "type": "TASK", "confidence": 0.7079508453607559}]}, {"text": "PropBank would seem a candidate gold standard, but to date very few studies exist that report on the use of PropBank for parser evaluation.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9113662838935852}, {"text": "parser evaluation", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.8197344839572906}]}, {"text": "The reasons might be that (at least some) parser developers believe that PropBank goes too far beyond the grammatical level to serve for parser evaluation, and that starting from PTB structures may have led to some questionable annotation decisions.", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 137, "end_pos": 154, "type": "TASK", "confidence": 0.8533201217651367}]}, {"text": "Finally, a complementary topic to cross-framework evaluation is the increasing demand for crossdomain parser evaluation.", "labels": [], "entities": [{"text": "crossdomain parser evaluation", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.7744649251302084}]}, {"text": "At conferences in 2007, concerns were expressed about results that might rely on particular properties of the WSJ PTB, and over idiosyncrasies of this specific sample of natural language.", "labels": [], "entities": [{"text": "WSJ PTB", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.963485836982727}]}, {"text": "For example, it remains a largely open question to what degree progress made in PTB parsing can carryover to other genres and domains; a related question is on the fitness of some specific approach (when measured in parser evaluation metrics) for actual NLP applications.", "labels": [], "entities": [{"text": "PTB parsing", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.7621047794818878}]}, {"text": "In summary, it maybe necessary that the WSJ-and PTB-derived parser benchmarks be complemented by other gold standards, both in terms of the selection of texts and target representations.", "labels": [], "entities": [{"text": "WSJ-and PTB-derived parser benchmarks", "start_pos": 40, "end_pos": 77, "type": "DATASET", "confidence": 0.7726900577545166}]}, {"text": "And to further the adaptation of parser evaluation to more languages, it will be important to carefully distill community experience from ParsEval and GR evaluations.", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8487655222415924}]}, {"text": "iii This workshop aims to bring together developers of broad-coverage parsers who are interested in questions of target representations and cross-framework and cross-domain evaluation and benchmarking.", "labels": [], "entities": []}, {"text": "From informal discussions that the co-organizers had among themselves and with colleagues, it seems evident that there is comparatively broad awareness of current issues in parser evaluation, and a lively interest in detailed exchange of experience (and beliefs).", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 173, "end_pos": 190, "type": "TASK", "confidence": 0.88885098695755}]}, {"text": "Specifically, the organizers have tried to attract representatives from diverse parsing approaches and frameworks, ranging from 'traditional' treebank parsing, over data-driven dependency parsing, to parsing in specific linguistic frameworks.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.7711271345615387}]}, {"text": "For the latter class of parsers, in many frameworks there is a further sub-division into groups pursuing 'classic' grammar engineering vs. ones who rely on grammar acquisition from annotated corpora.", "labels": [], "entities": []}, {"text": "Quite likely for the first time in the history of these approaches, there now exist large, broad-coverage parsing systems representing diverse traditions that can be applied to running text, often producing comparable representations.", "labels": [], "entities": []}, {"text": "In our view, these recent developments present anew opportunity for re-energizing parser evaluation research.", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.9075152575969696}]}, {"text": "We sincerely wish this workshop will provide participants with the opportunity for in-depth and cross-framework exchange of expertise and discussion of future directions in parser evaluation.", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 173, "end_pos": 190, "type": "TASK", "confidence": 0.920756608247757}]}, {"text": "A specific sub-goal of the workshop is to establish an improved shared knowledge among participants of the strengths and weaknesses of extant annotation and evaluation schemes.", "labels": [], "entities": []}, {"text": "In order to create a joint focus for detailed discussion, the workshop preparation included a 'lightweight' shared task.", "labels": [], "entities": []}, {"text": "For a selection of 50 sentences (of which ten were considered obligatory, the rest optional) for which PTB, GR, and PropBank (and other) annotations are available, contributors were invited to scrutinize existing gold-standard representations contrastively, identify perceived deficiencies, and sketch what can be done to address these.", "labels": [], "entities": [{"text": "PTB", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.7267705798149109}, {"text": "GR", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.65765780210495}]}, {"text": "As an optional component, participants in the shared task were welcome to include 'native', framework-specific output representations and actual results fora parsing system of their choice (be it their own or not) in the contrastive study.", "labels": [], "entities": []}, {"text": "In either case, submissions to the shared task reflect on the nature of different representations, highlight which additional distinctions are made in either scheme, and argue why these are useful (for some task) or unmotivated (in general).", "labels": [], "entities": []}, {"text": "Of the eight papers selected for presentation at the workshop, the following three were submissions to the shared task, viz.", "labels": [], "entities": []}, {"text": "those by Flickinger (page 17), Tateisi (page 24), and McConville and Dzikovska (page 51).", "labels": [], "entities": []}, {"text": "For further information on the workshop as a whole, its shared task, and some specific datasets used, please see:", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}