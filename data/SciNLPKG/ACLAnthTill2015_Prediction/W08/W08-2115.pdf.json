{"title": [{"text": "Automatic Chinese Catchword Extraction Based on Time Series Analysis", "labels": [], "entities": [{"text": "Chinese Catchword Extraction", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.5698266128698984}]}], "abstractContent": [{"text": "Catchwords refer to those popular words or phrases in a time period.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach for automatic extraction of Chinese catchwords.", "labels": [], "entities": [{"text": "automatic extraction of Chinese catchwords", "start_pos": 47, "end_pos": 89, "type": "TASK", "confidence": 0.8305631160736084}]}, {"text": "By analyzing features of catchwords, we define three aspects to describe Popular Degree of catchwords.", "labels": [], "entities": []}, {"text": "Then we use curve fitting in Time Series Analysis to build Popular Degree Curves of the extracted terms.", "labels": [], "entities": [{"text": "Popular Degree Curves", "start_pos": 59, "end_pos": 80, "type": "METRIC", "confidence": 0.8913122415542603}]}, {"text": "Finally we give a formula that can calculate Popular Degree values of catchwords and get a ranking list of catchword candidates.", "labels": [], "entities": [{"text": "Popular Degree", "start_pos": 45, "end_pos": 59, "type": "METRIC", "confidence": 0.764251172542572}]}, {"text": "Experiments show that the method is effective.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generally, a catchword is a term which represents a hot social phenomenon or an important incident, and is paid attention by public society within certain time period.", "labels": [], "entities": []}, {"text": "On the one hand, catchwords represent the mass value orientation fora period.", "labels": [], "entities": []}, {"text": "On the other hand, they have a high timeliness.", "labels": [], "entities": [{"text": "timeliness", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.991873562335968}]}, {"text": "Currently, there are quiet a few ranking and evaluations of catchwords every year in various kinds of media.", "labels": [], "entities": []}, {"text": "Only in year 2005, tens of Chinese organizations published their ranking list of Chinese catchwords.", "labels": [], "entities": []}, {"text": "Catchwords contain a great deal of information from any particular area, and such words truly and vividly reflect changes of our lives and our society.", "labels": [], "entities": []}, {"text": "By monitoring and analysis of catchwords, we can learn the change of public attention in time.", "labels": [], "entities": []}, {"text": "In addition, we may detect the potential changes of some linguistic rules, which can help establish and adjust state language policies.", "labels": [], "entities": []}, {"text": "Currently, two kinds of approaches are adopted to evaluate catchwords.", "labels": [], "entities": []}, {"text": "One is by CTR (Click-Through Rate) or retrieval times, but the limitation is that it is just based on frequency, which is only one feature of catchwords.", "labels": [], "entities": [{"text": "CTR (Click-Through Rate)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.7464216649532318}]}, {"text": "The other is by manual evaluation, but it depends on their subjective judgment to a large extent.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach that can automatically analyze and extract Chinese catchwords.", "labels": [], "entities": []}, {"text": "By analyzing sample catchwords and finding out their common features, we provide a method to evaluate the popular degree.", "labels": [], "entities": []}, {"text": "After ranking, terms that have high values are picked out as catchword candidates.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss about the linguistic basis of catchword judgment.", "labels": [], "entities": [{"text": "catchword judgment", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7984629571437836}]}, {"text": "In Section 3, we describe the extraction method in detail.", "labels": [], "entities": []}, {"text": "In Section 4, we present the experimental results as well as some discussions.", "labels": [], "entities": []}, {"text": "Finally, we give the conclusion and future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiment, several parameters should be settled to perform the catchwords extraction.", "labels": [], "entities": [{"text": "catchwords extraction", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7091570645570755}]}, {"text": "\u00b7n A large time granularity may result in low accuracy for conic fitting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9993997812271118}, {"text": "conic fitting", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.7552515268325806}]}, {"text": "In this paper, we select 'day' as the time granularity.", "labels": [], "entities": []}, {"text": "\u00b7m For the interval min formula (2), a proper value should be specified to not only eliminate random fluctuation but also keep accuracy of data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9990357160568237}]}, {"text": "In the experiment we find that the proper interval is between 10 and 20.", "labels": [], "entities": [{"text": "proper interval", "start_pos": 35, "end_pos": 50, "type": "METRIC", "confidence": 0.9744003415107727}]}, {"text": "\u00b7T Sand T E Catchwords have a high timeliness, so we should specify a time domain.", "labels": [], "entities": []}, {"text": "By analysis of sample catchwords, we find that popular time domain for most of them approximately last for not more than 6 months.", "labels": [], "entities": []}, {"text": "So we specify the time domain is n / 2.", "labels": [], "entities": []}, {"text": "Thus the relationship among the starting time T Sand the ending time T E is below: As a proper example, the starting point can be 60 days away from the highest point.", "labels": [], "entities": [{"text": "ending time T E", "start_pos": 57, "end_pos": 72, "type": "METRIC", "confidence": 0.7735083997249603}]}, {"text": "Thus the Popular Trend process and the Popular Keeping process both last for nearly 3 months.", "labels": [], "entities": [{"text": "Popular Trend", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.7136452496051788}, {"text": "Popular Keeping", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.8650522530078888}]}, {"text": "So the relationship can be described as formulas below: shows proper values of parameters as schema 1.", "labels": [], "entities": []}, {"text": "We also give other schemas, which contain different values of parameters, to compare with the schema 1.", "labels": [], "entities": []}, {"text": "In schema 2 to schema 4, default values of parameters are the same with schema 1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Co-occurrence ratio using schema 1", "labels": [], "entities": []}, {"text": " Table 3. Co-occurrence ratio using schema 2", "labels": [], "entities": []}, {"text": " Table 4. Co-occurrence ratio using schema 3", "labels": [], "entities": []}, {"text": " Table 5. Co-occurrence ratio using schema 4", "labels": [], "entities": []}]}