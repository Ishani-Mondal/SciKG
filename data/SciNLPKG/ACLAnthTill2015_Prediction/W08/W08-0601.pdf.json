{"title": [{"text": "A Graph Kernel for Protein-Protein Interaction Extraction", "labels": [], "entities": [{"text": "Protein-Protein Interaction Extraction", "start_pos": 19, "end_pos": 57, "type": "TASK", "confidence": 0.82939346631368}]}], "abstractContent": [{"text": "In this paper, we propose a graph kernel based approach for the automated extraction of protein-protein interactions (PPI) from scientific literature.", "labels": [], "entities": [{"text": "automated extraction of protein-protein interactions (PPI)", "start_pos": 64, "end_pos": 122, "type": "TASK", "confidence": 0.8108256235718727}]}, {"text": "In contrast to earlier approaches to PPI extraction, the introduced all-dependency-paths kernel has the capability to consider full, general dependency graphs.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.9303735196590424}]}, {"text": "We evaluate the proposed method across five publicly available PPI corpora providing the most comprehensive evaluation done fora machine learning based PPI-extraction system.", "labels": [], "entities": []}, {"text": "Our method is shown to achieve state-of-the-art performance with respect to comparable evaluations, achieving 56.4 F-score and 84.8 AUC on the AImed corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9983360171318054}, {"text": "AUC", "start_pos": 132, "end_pos": 135, "type": "METRIC", "confidence": 0.9966468214988708}, {"text": "AImed corpus", "start_pos": 143, "end_pos": 155, "type": "DATASET", "confidence": 0.9074949622154236}]}, {"text": "Further, we identify several pitfalls that can make evaluations of PPI-extraction systems incomparable, or even invalid.", "labels": [], "entities": []}, {"text": "These include incorrect cross-validation strategies and problems related to comparing F-score results achieved on different evaluation resources.", "labels": [], "entities": [{"text": "F-score", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9719352722167969}]}], "introductionContent": [{"text": "Automated protein-protein interaction (PPI) extraction from scientific literature is a task of significant interest in the BioNLP field.", "labels": [], "entities": [{"text": "Automated protein-protein interaction (PPI) extraction from scientific", "start_pos": 0, "end_pos": 70, "type": "TASK", "confidence": 0.7837695313824548}]}, {"text": "The most commonly addressed problem has been the extraction of binary interactions, where the system identifies which protein pairs in a sentence have a biologically relevant relationship between them.", "labels": [], "entities": [{"text": "extraction of binary interactions", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.8360133767127991}]}, {"text": "Proposed solutions include both hand-crafted rule-based systems and machine learning approaches (see e.g. ( ).", "labels": [], "entities": []}, {"text": "A wide range of results have been reported for the systems, but as we will show, differences in evaluation resources, metrics and strategies make direct comparison of these numbers problematic.", "labels": [], "entities": []}, {"text": "Further, the results gained from the BioCreative II evaluation, where the best performing system achieved a 29% F-score (, suggest that the problem of extracting binary protein protein interactions is far from solved.", "labels": [], "entities": [{"text": "BioCreative II", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.43808792531490326}, {"text": "F-score", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9995365142822266}, {"text": "extracting binary protein protein interactions", "start_pos": 151, "end_pos": 197, "type": "TASK", "confidence": 0.8582953572273254}]}, {"text": "The public availability of large annotated PPIcorpora such as AImed ( ), BioInfer () and GENIA (, provides an opportunity for building PPI extraction systems automatically using machine learning.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.9069632887840271}, {"text": "PPI extraction", "start_pos": 135, "end_pos": 149, "type": "TASK", "confidence": 0.8568513989448547}]}, {"text": "A major challenge is how to supply the learner with the contextual and syntactic information needed to distinguish between interactions and non-interactions.", "labels": [], "entities": []}, {"text": "To address the ambiguity and variability of the natural language expressions used to state PPI, several recent studies have focused on the development, adaptation and application of NLP tools for the biomedical domain.", "labels": [], "entities": []}, {"text": "Many high-quality domain-specific tools are now freely available, including full parsers such as that introduced by Charniak and.", "labels": [], "entities": []}, {"text": "Additionally, a number of conversions from phrase structure parses to dependency structures that make the relationships between words more directly accessible have been introduced.", "labels": [], "entities": [{"text": "phrase structure parses", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.6920550366242727}]}, {"text": "These include conversions into representations such as the Stanford dependency scheme (de) that are explicitly designed for information extraction purposes.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.784011572599411}]}, {"text": "However, specialized feature representations and kernels are required to make learning from such structures possible.", "labels": [], "entities": []}, {"text": "Approaches such as subsequence kernels (), tree kernels (Zelenko et al., 2003) and shortest path kernels ( ) have been proposed and successfully used for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.9501389563083649}]}, {"text": "However, these methods lack the expressive power to consider representations derived from general, possibly cyclic, dependency graph structures, such as those generated by the Stanford tools.", "labels": [], "entities": []}, {"text": "The subsequence kernel approach does not consider parses at all, and the shortest path approach is limited to representing only a single path in the full dependency graph, which excludes relevant words even in many simple cases ().", "labels": [], "entities": []}, {"text": "Tree kernels can represent more complex structures, but are still restricted to tree representations.", "labels": [], "entities": []}, {"text": "Lately, in the framework of kernel-based machine learning methods there has been an increased interest in designing kernel functions for graph data.", "labels": [], "entities": []}, {"text": "Building on the work of, graph representations tailored for the task of dependency parse ranking were proposed by.", "labels": [], "entities": [{"text": "dependency parse ranking", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.9022273222605387}]}, {"text": "Though the proposed representations are not directly applicable to the task of PPI extraction, they offer insight in how to learn from dependency graphs.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.9277907311916351}]}, {"text": "We develop a graph kernel approach for PPI extraction based on these ideas.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.9607869982719421}]}, {"text": "We next define a graph representation suitable for describing potential interactions and introduce a kernel which makes efficient learning from a general, unrestricted graph representation possible.", "labels": [], "entities": []}, {"text": "Then we provide a short description of the sparse regularized least squares (sparse RLS) kernel-based machine learning method we use for PPI-extraction.", "labels": [], "entities": []}, {"text": "Further, we rigorously assess our method on five publicly available PPI corpora, providing the first broad cross-corpus evaluation with a machine learning approach to PPI extraction.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 167, "end_pos": 181, "type": "TASK", "confidence": 0.9017155468463898}]}, {"text": "Finally, we discuss the effects that different evaluation strategies, choice of corpus and applied metrics have on measured performance, and conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method using five publicly available corpora that contain PPI interaction annotation:).", "labels": [], "entities": []}, {"text": "All the corpora were processed to a common format using transformations 1 that we have introduced earlier (.", "labels": [], "entities": []}, {"text": "We parse these corpora with the Charniak-Lease parser), which has been found to perform best among a number of parsers tested in recent domain evaluations).", "labels": [], "entities": []}, {"text": "The Charniak-Lease phrase structure parses are transformed into the collapsed Stanford dependency scheme using the Stanford tools (de).", "labels": [], "entities": [{"text": "Charniak-Lease phrase structure parses", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.5612910389900208}]}, {"text": "We cast the PPI extraction task as binary classification, where protein pairs that are stated to interact are positive examples and other co-occuring pairs negative.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.9379552006721497}]}, {"text": "Thus, from each sentence, n 2 examples are generated, where n is the number of occurrences of protein names in the sentence.", "labels": [], "entities": []}, {"text": "Finally, we form the graph representation described earlier for each candidate interaction.", "labels": [], "entities": []}, {"text": "We evaluate the method with 10-fold documentlevel cross-validation on all of the corpora.", "labels": [], "entities": []}, {"text": "This guarantees the maximal use of the available data, and also allows comparison to relevant earlier work.", "labels": [], "entities": []}, {"text": "In particular, on the AImed corpus we apply the exact same 10-fold split that was used by and.", "labels": [], "entities": [{"text": "AImed corpus", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.8599668443202972}]}, {"text": "Performance is measured according to the following criteria: interactions are considered untyped, undirected pairwise relations between specific protein mentions, that is, if the same protein name occurs multiple 1 Available at http://mars.cs.utu.fi/PPICorpora.", "labels": [], "entities": []}, {"text": "times in a sentence, the correct interactions must be extracted for each occurrence.", "labels": [], "entities": []}, {"text": "Further, we do not consider self-interactions as candidates and remove them from the corpora prior to evaluation.", "labels": [], "entities": []}, {"text": "The majority of PPI extraction system evaluations use the balanced F-score measure for quantifying the performance of the systems.", "labels": [], "entities": [{"text": "PPI extraction system evaluations", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.8874741494655609}, {"text": "F-score measure", "start_pos": 67, "end_pos": 82, "type": "METRIC", "confidence": 0.9716236889362335}]}, {"text": "This metric is defined as F = 2pr p+r , where p is precision and r recall.", "labels": [], "entities": [{"text": "F", "start_pos": 26, "end_pos": 27, "type": "METRIC", "confidence": 0.9983112812042236}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9995273351669312}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.8560062646865845}]}, {"text": "Likewise, we provide F-score, precision, and recall values in our evaluation.", "labels": [], "entities": [{"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9989302754402161}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9996077418327332}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9995777010917664}]}, {"text": "It should be noted that F-score is very sensitive to the underlying positive/negative pair distribution of the corpus -a property whose impact on evaluation is discussed in detail below.", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9798803925514221}]}, {"text": "As an alternative to F-score, we also evaluate the performance of our system using the area under the receiver operating characteristics curve (AUC) measure.", "labels": [], "entities": [{"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9968543648719788}, {"text": "receiver operating characteristics curve (AUC) measure", "start_pos": 102, "end_pos": 156, "type": "METRIC", "confidence": 0.8529832772910595}]}, {"text": "AUC has the important property that it is invariant to the class distribution of the used dataset.", "labels": [], "entities": [{"text": "AUC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6522237658500671}]}, {"text": "Due to this and other beneficial properties for comparative evaluation, the usage of AUC for performance evaluation has been recently advocated in the machine learning community (see e.g.).", "labels": [], "entities": []}, {"text": "Formally, AUC can be defined as where m + and m \u2212 are the numbers of positive and negative examples, respectively, and x 1 ,...,x m + are the outputs of the system for the positive, and y 1 ,...,y m \u2212 for the negative examples, and The measure corresponds to the probability that given a randomly chosen positive and negative ex-ample, the system will be able to correctly disinguish which one is which.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Counts of positive and negative examples in the corpora and (P)recision, (R)ecall (F)-score and AUC for the  graph kernel, with standard deviations provided for F and AUC.", "labels": [], "entities": [{"text": "R)ecall (F)-score", "start_pos": 84, "end_pos": 101, "type": "METRIC", "confidence": 0.7798715233802795}, {"text": "AUC", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9894365072250366}, {"text": "F", "start_pos": 171, "end_pos": 172, "type": "METRIC", "confidence": 0.9821872711181641}, {"text": "AUC", "start_pos": 177, "end_pos": 180, "type": "METRIC", "confidence": 0.896550714969635}]}, {"text": " Table 2: (P)recision, (R)ecall and (F)-score results for methods evaluated on AImed with the correct cross-validation  methodology.", "labels": [], "entities": [{"text": "recision", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.8550597429275513}, {"text": "ecall", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.6139123439788818}, {"text": "F)-score", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9081337451934814}]}]}