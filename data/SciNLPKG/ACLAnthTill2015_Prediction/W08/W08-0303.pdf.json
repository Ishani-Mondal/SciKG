{"title": [{"text": "Discriminative Word Alignment via Alignment Matrix Modeling", "labels": [], "entities": [{"text": "Discriminative Word Alignment", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6595367689927419}, {"text": "Alignment Matrix Modeling", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.6543115774790446}]}], "abstractContent": [{"text": "In this paper anew discriminative word alignment method is presented.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.6893169730901718}]}, {"text": "This approach models directly the alignment matrix by a conditional random field (CRF) and so no restrictions to the alignments have to be made.", "labels": [], "entities": []}, {"text": "Furthermore , it is easy to add features and so all available information can be used.", "labels": [], "entities": []}, {"text": "Since the structure of the CRFs can get complex, the inference can only be done approximately and the standard algorithms had to be adapted.", "labels": [], "entities": []}, {"text": "In addition, different methods to train the model have been developed.", "labels": [], "entities": []}, {"text": "Using this approach the alignment quality could be improved by up to 23 percent for 3 different language pairs compared to a combination of both IBM4-alignments.", "labels": [], "entities": []}, {"text": "Furthermore the word alignment was used to generate new phrase tables.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7036385983228683}]}, {"text": "These could improve the translation quality significantly .", "labels": [], "entities": [{"text": "translation", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9786152839660645}]}], "introductionContent": [{"text": "In machine translation parallel corpora are one very important knowledge source.", "labels": [], "entities": [{"text": "machine translation parallel corpora", "start_pos": 3, "end_pos": 39, "type": "TASK", "confidence": 0.8304592818021774}]}, {"text": "These corpora are often aligned at the sentence level, but to use them in the systems inmost cases a word alignment is needed.", "labels": [], "entities": []}, {"text": "Therefore, fora given source sentence f J 1 and a given target sentence e I 1 a set of links (j, i) has to be found, which describes which source word f j is translated into which target word e i . Most SMT systems use the freely available GIZA++-Toolkit to generate the word alignment.", "labels": [], "entities": [{"text": "SMT", "start_pos": 203, "end_pos": 206, "type": "TASK", "confidence": 0.990037202835083}, {"text": "GIZA++-Toolkit", "start_pos": 240, "end_pos": 254, "type": "DATASET", "confidence": 0.8714119593302408}]}, {"text": "This toolkit implements the IBM-and HMMmodels introduced in (.", "labels": [], "entities": [{"text": "IBM-and HMMmodels", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.824767529964447}]}, {"text": "They have the advantage that they are trained unsupervised and are well suited fora noisychannel approach.", "labels": [], "entities": []}, {"text": "But it is difficult to include additional features into these models.", "labels": [], "entities": []}, {"text": "In recent years several authors () proposed discriminative word alignment frameworks and showed that this leads to improved alignment quality.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.7460129261016846}]}, {"text": "In contrast to generative models, these models need a small amount of handaligned data.", "labels": [], "entities": [{"text": "generative", "start_pos": 15, "end_pos": 25, "type": "TASK", "confidence": 0.9632638096809387}]}, {"text": "But it is easy to add features to these models, so all available knowledge sources can be used to find the best alignment.", "labels": [], "entities": []}, {"text": "The discriminative model presented in this paper uses a conditional random field (CRF) to model the alignment matrix.", "labels": [], "entities": []}, {"text": "By modeling the matrix no restrictions to the alignment are required and even n:m alignments can be generated.", "labels": [], "entities": []}, {"text": "Furthermore, this makes the model symmetric, so the model will produce the same alignment no matter which language is selected as source and which as target language.", "labels": [], "entities": []}, {"text": "In contrast, in generative models the alignment is a function where a source word aligns to at most one target word.", "labels": [], "entities": []}, {"text": "So the alignment is asymmetric.", "labels": [], "entities": [{"text": "alignment", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.8708704113960266}]}, {"text": "The training of this discriminative model has to be done on hand-aligned data.", "labels": [], "entities": []}, {"text": "First, the common maximum-likelihood approach was used.", "labels": [], "entities": []}, {"text": "In addition to this, a method to optimize the weights directly towards a word alignment metric was developed.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.7395476400852203}]}, {"text": "The paper is structured as follows: Section 2 and 3 present the model and the training.", "labels": [], "entities": []}, {"text": "In Section 4 the model is evaluated in the word alignment task as well as in the translation task.", "labels": [], "entities": [{"text": "word alignment task", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8331215182940165}, {"text": "translation task", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.8954358696937561}]}, {"text": "The related work and the conclusion are given in Sections 5 and 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The word alignment quality of this approach was tested on three different language pairs.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.765501081943512}]}, {"text": "On the Spanish-English task the hand-aligned data provided by the TALP Research Center () was used.", "labels": [], "entities": [{"text": "TALP Research Center", "start_pos": 66, "end_pos": 86, "type": "DATASET", "confidence": 0.835028608640035}]}, {"text": "As proposed, 100 sentences were used as development data and 400 as test data.", "labels": [], "entities": []}, {"text": "The so called \"Final Text Edition of the European Parliament Proceedings\" consisting of 1.4 million sentences and this hand-aligned data was used as training corpus.", "labels": [], "entities": [{"text": "Final Text Edition of the European Parliament Proceedings\"", "start_pos": 15, "end_pos": 73, "type": "DATASET", "confidence": 0.7753323945734236}]}, {"text": "The POS-tags were generated by the Brill-Tagger and the FreeLing-Tagger () for the English and the Spanish text respectively.", "labels": [], "entities": [{"text": "Brill-Tagger", "start_pos": 35, "end_pos": 47, "type": "METRIC", "confidence": 0.5076356530189514}]}, {"text": "To limit the number of different tags for Spanish we grouped them according to the first 2 characters in the tag names.", "labels": [], "entities": []}, {"text": "A second group of experiments was done on an English-French text.", "labels": [], "entities": []}, {"text": "The data from the 2003 NAACL shared task was used.", "labels": [], "entities": [{"text": "NAACL shared task", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.7131164073944092}]}, {"text": "This data consists of 1.1 million sentences, a validation set of 37 sentences and a test set of 447 sentences, which have been hand-aligned.", "labels": [], "entities": []}, {"text": "For the English POS-tags again the Brill Tagger was used.", "labels": [], "entities": [{"text": "Brill Tagger", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.8737368285655975}]}, {"text": "For the French side, the TreeTagger ( was used.", "labels": [], "entities": [{"text": "TreeTagger (", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9788236916065216}]}, {"text": "Finally, to test our alignment approach with languages that differ more in structure a ChineseEnglish task was selected.", "labels": [], "entities": []}, {"text": "As hand-aligned data 3160 sentences aligned only with sure links were used (LDC2006E93).", "labels": [], "entities": []}, {"text": "This was split up into 2000 sentences of test data and 1160 sentences of development data.", "labels": [], "entities": []}, {"text": "In some experiments only the first 200 sentences of the development data were used to speedup the training process.", "labels": [], "entities": []}, {"text": "The FBIS-corpus was used as training corpus and all Chinese sentences were word segmented with the Stanford Segmenter ().", "labels": [], "entities": [{"text": "FBIS-corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9209600687026978}, {"text": "Stanford Segmenter", "start_pos": 99, "end_pos": 117, "type": "DATASET", "confidence": 0.9346621036529541}]}, {"text": "The POS-tags for both sides were generated with the Stanford Parser ().", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.9383559823036194}]}], "tableCaptions": [{"text": " Table 1: AER-Results on EN-ES task", "labels": [], "entities": [{"text": "AER-Results", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9960057139396667}]}, {"text": " Table 2: AER-Results on EN-FR task", "labels": [], "entities": [{"text": "AER-Results", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9974299073219299}, {"text": "EN-FR", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.7471110820770264}]}, {"text": " Table 3: AER-Results on CH-EN task", "labels": [], "entities": [{"text": "AER-Results", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9982649683952332}]}, {"text": " Table 4: Translation results for EN-ES", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9364930987358093}, {"text": "EN-ES", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.6527498364448547}]}, {"text": " Table 5: Translation results for CH-EN", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8738189935684204}, {"text": "CH-EN", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.6558094024658203}]}]}