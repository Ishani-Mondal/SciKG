{"title": [{"text": "Combining Knowledge-based Methods and Supervised Learning for Effective Italian Word Sense Disambiguation", "labels": [], "entities": [{"text": "Italian Word Sense Disambiguation", "start_pos": 72, "end_pos": 105, "type": "TASK", "confidence": 0.5925881862640381}]}], "abstractContent": [{"text": "This paper presents a WSD strategy which combines a knowledge-based method that exploits sense definitions in a dictionary and relations among senses in a semantic network, with supervised learning methods on annotated corpora.", "labels": [], "entities": [{"text": "WSD", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9687369465827942}]}, {"text": "The idea behind the approach is that the knowledge-based method can cope with the possible lack of training data, while supervised learning can improve the precision of a knowledge-based method when training data are available.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9987536668777466}]}, {"text": "This makes the proposed method suitable for disambiguation of languages for which the available resources are lacking in training data or sense definitions.", "labels": [], "entities": []}, {"text": "In order to evaluate the effectiveness of the proposed approach, experimental sessions were carried out on the dataset used for the WSD task in the EVALITA 2007 initiative, devoted to the evaluation of Natural Language Processing tools for Italian.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 132, "end_pos": 140, "type": "TASK", "confidence": 0.9092987179756165}, {"text": "EVALITA 2007 initiative", "start_pos": 148, "end_pos": 171, "type": "DATASET", "confidence": 0.7381660143534342}]}, {"text": "The most effective hybrid WSD strategy is the one that integrates the knowledge-based approach into the supervised learning method, which outperforms both methods taken singularly.", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9777276515960693}]}], "introductionContent": [], "datasetContent": [{"text": "The main goal of our investigation is to study the behavior of the hybrid algorithm when available training resources are not much reliable, e.g. when a lower number of sense descriptions is available, as for Italian.", "labels": [], "entities": []}, {"text": "The hypothesis we want to evaluate is that corpus-based methods and knowledge-based ones can be combined to improve the accuracy of each single strategy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9981959462165833}]}, {"text": "Experiments have been performed on a standard test collection in the context of the All-Words-Task, in which WSD algorithms attempt to disambiguate all words in a text.", "labels": [], "entities": []}, {"text": "Specifically, we used the EVALITA WSD All-Words-Task dataset , which consists of about 5,000 words labeled with ITALWORDNET synsets.", "labels": [], "entities": [{"text": "EVALITA WSD All-Words-Task dataset", "start_pos": 26, "end_pos": 60, "type": "DATASET", "confidence": 0.653934620320797}]}, {"text": "An important concern for the evaluation of WSD systems is the agreement rate between human annotators on word sense assignment.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9823474884033203}, {"text": "agreement rate", "start_pos": 62, "end_pos": 76, "type": "METRIC", "confidence": 0.9454376995563507}, {"text": "word sense assignment", "start_pos": 105, "end_pos": 126, "type": "TASK", "confidence": 0.6542777419090271}]}, {"text": "While for natural language subtasks like part-of-speech tagging, there are relatively well defined and agreed-upon criteria of what it means to have the \"correct\" part of speech assigned to a word, this is not the case for word sense assignment.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.7319420278072357}, {"text": "word sense assignment", "start_pos": 223, "end_pos": 244, "type": "TASK", "confidence": 0.7023101349671682}]}, {"text": "Two human annotators may genuinely disagree on their sense assignment to a word in a context, since the distinction between the different senses fora commonly used word in a dictionary like WORDNET tend to be rather fine.", "labels": [], "entities": []}, {"text": "What we would like to underline here is that it is important that human agreement on an annotated corpus is carefully measured, in order to set an upper bound to the performance measures: it would be futile to expect computers to agree more with the reference corpus that human annotators among them.", "labels": [], "entities": []}, {"text": "For example, the inter-annotator agreement rate during the preparation of the SENSEVAL-3 WSD English All-WordsTask dataset) was approximately 72.5%.", "labels": [], "entities": [{"text": "SENSEVAL-3 WSD English All-WordsTask dataset", "start_pos": 78, "end_pos": 122, "type": "DATASET", "confidence": 0.5873375236988068}]}, {"text": "Unfortunately, for EVALITA dataset, the inter-annotator agreement has not been measured, one of the reasons why the evaluation for Italian WSD is very hard.", "labels": [], "entities": [{"text": "EVALITA dataset", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9289624392986298}, {"text": "Italian WSD", "start_pos": 131, "end_pos": 142, "type": "DATASET", "confidence": 0.7078182101249695}]}, {"text": "In our experiments, we reasonably selected different baselines to compare the performance of the proposed hybrid algorithm.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Baselines for Italian All-Words-Task  Setting  P  R  F  A", "labels": [], "entities": [{"text": "Italian All-Words-Task  Setting", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.5550166269143423}]}, {"text": " Table 3: Experimental results of K-NN+JIGSAW", "labels": [], "entities": [{"text": "JIGSAW", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.4438052475452423}]}, {"text": " Table 4: Experimental results of JIGSAW+K-NN", "labels": [], "entities": [{"text": "JIGSAW+K-NN", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.6820540229479471}]}]}