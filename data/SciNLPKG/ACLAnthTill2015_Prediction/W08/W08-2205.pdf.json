{"title": [{"text": "Augmenting WordNet for Deep Understanding of Text", "labels": [], "entities": [{"text": "Augmenting WordNet", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6946830153465271}]}], "abstractContent": [{"text": "One of the big challenges in understanding text, i.e., constructing an overall coherent representation of the text, is that much information needed in that representation is unstated (implicit).", "labels": [], "entities": []}, {"text": "Thus, in order to \"fill in the gaps\" and create an overall representation, language processing systems need a large amount of world knowledge, and creating those knowledge resources remains a fundamental challenge.", "labels": [], "entities": []}, {"text": "In our current work, we are seeking to augment WordNet as a knowledge resource for language understanding in several ways: adding informal versions of its word sense definitions (glosses); classifying the morphosemantic links between nouns and verbs; encoding a small number of \"core theories\" about WordNet's most commonly used terms; and adding in simple representations of scripts.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.7552714347839355}]}, {"text": "Although this is still work in progress, we describe our experiences so far with what we hope will be a significantly improved resource for the deep understanding of language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much information that text is intended to convey is not explicitly stated.", "labels": [], "entities": []}, {"text": "Rather, the reader constructs a mental model of the scene described by the text, including many \"obvious\" features that were not explicitly mentioned.", "labels": [], "entities": []}, {"text": "By one estimate, the ratio of explicit to implicit facts is 1:8, making the task of understanding text, i.e., constructing a coherent representation of the scene that the author intended to convey, very difficult, even given the generally reasonable quality of syntactic interpretation that today's systems produce.", "labels": [], "entities": []}, {"text": "For example, given the sentence: A soldier was killed in a gun battle.", "labels": [], "entities": []}, {"text": "a reader will infer that (probably): The soldier was shot; The soldier died; There was a fight; etc.", "labels": [], "entities": []}, {"text": "even though none of these facts are explicitly stated.", "labels": [], "entities": []}, {"text": "A person is able to draw these plausible conclusions because of the large amounts of world knowledge he/she has, and his/her ability to use them to construct an overall mental model of the scene being described.", "labels": [], "entities": []}, {"text": "A key requirement for this task is access to a large body of world knowledge.", "labels": [], "entities": []}, {"text": "However, machines are currently poorly equipped in this regard.", "labels": [], "entities": []}, {"text": "Although a few knowledge encoding projects are underway, e.g.,, developing such resources continues to be a major challenge, and any contribution to this task has significant potential benefit.", "labels": [], "entities": [{"text": "knowledge encoding", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7712275087833405}]}, {"text": "WordNet) presents an unique avenue for making inroads into this problem: It already has broad coverage, multiple lexicosemantic connections, and significant knowledge encoded (albeit informally) in its glosses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9643374085426331}]}, {"text": "It can thus be viewed as on the way to becoming an extensively leveragable, \"lightweight\" knowledge base for reasoning.", "labels": [], "entities": []}, {"text": "In fact, WordNet already plays a central role in many question-answering systems e.g., of the 26 teams in the recent PASCAL RTE3 challenge used WordNet (, and most other large-scale resources already include mappings to it and thus can leverage it easily.", "labels": [], "entities": [{"text": "PASCAL RTE3 challenge", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.6540852189064026}, {"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.8245953917503357}]}, {"text": "In our work we are developing several augmentations to WordNet to improve its utility further, and we report hereon our experiences to date.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.9722791910171509}]}, {"text": "Although we are performing experiments with recognizing textual entailment (RTE) (determining whether a hypothesis sentence H follows from some text T), it is important to note that RTE is not our end-goal.", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE)", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.7513236800829569}]}, {"text": "Many existing RTE systems, e.g.,) largely work by statistically scoring the match between T and H, but this to an extent sidesteps \"deep\" language understanding, namely building a coherent, internal representation of the overall scenario the input text was intended to convey.", "labels": [], "entities": []}, {"text": "RTE is one way of measuring success in this endeavor, but it is also possible to do moderately well in RTE without the system even attempting to \"understand\" the scenario the text is describing.", "labels": [], "entities": []}, {"text": "It is yet to be seen whether very high performance in RTE can be obtained without some kind of deep language understanding of the entire scene that a text conveys.", "labels": [], "entities": [{"text": "RTE", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.909866988658905}]}, {"text": "We are testing our work with BLUE, Boeing's Language Understanding Engine, which we first describe.", "labels": [], "entities": [{"text": "BLUE", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9113978743553162}]}, {"text": "We then present the WordNet augmentations that we are developing, and our experience with these as well as with the DIRT paraphrase database.", "labels": [], "entities": [{"text": "DIRT paraphrase database", "start_pos": 116, "end_pos": 140, "type": "DATASET", "confidence": 0.8686520258585612}]}, {"text": "The contribution of this paper is some preliminary insight into avenues and challenges for creating and leveraging more world knowledge, in the context of WordNet, for deeper language understanding.", "labels": [], "entities": []}], "datasetContent": [{"text": "As an experimental test bed we have developed a publically available RTE-style test suite 2 of 250 pairs (125 entailed, 125 not entailed).", "labels": [], "entities": []}, {"text": "As our goal is deeper semantic processing, the texts are syntactically simpler than the PASCAL RTE sets (at www.", "labels": [], "entities": [{"text": "PASCAL RTE sets", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.6062766214211782}]}, {"text": "pascal-network.org) but semantically challenging to process.", "labels": [], "entities": []}, {"text": "We use examples from this test suite (and others) in this paper.", "labels": [], "entities": []}, {"text": "Although this is work in progress, we have evaluated some of these augmentations using our test suite.", "labels": [], "entities": []}, {"text": "As our ultimate goal is deeper understanding of text, we have deliberately eschewed using statistical similarity measures between T and H, and instead used abductive reasoning to create an axiom-elaborated representation of T, and then seen if it is subsumed by H. Although not using statistical similarity clearly hurts our score, in particular assuming \"no entailment\" when the elaborated representation of T is not subsumed by H, we believe this keeps us appropriately focused on our longerterm goal of deeper understanding of text.", "labels": [], "entities": []}, {"text": "The results on our 250 pairs currently are: Thus our overall score on this test suite is 61.2%.", "labels": [], "entities": []}, {"text": "We have also run our software on the PASCAL RTE3 dataset (, scoring 55.7% (excluding cases where no initial logical representation could be constructed due to parse/LF generation failures).", "labels": [], "entities": [{"text": "PASCAL RTE3 dataset", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.8423883120218912}]}, {"text": "In some cases, other known limitations of WordNet (eg. hypernym errors, fine-grained senses) also caused errors in our tests (outside the scope of this paper).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9463455080986023}]}, {"text": "However, the most significant problem, at least for these tests, was lack of world knowledge.", "labels": [], "entities": []}], "tableCaptions": []}