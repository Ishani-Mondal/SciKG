{"title": [{"text": "Discriminative vs. Generative Approaches in Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.6973809202512106}]}], "abstractContent": [{"text": "This paper describes the two algorithms we developed for the CoNLL 2008 Shared Task \"Joint learning of syntactic and semantic dependencies\".", "labels": [], "entities": [{"text": "CoNLL 2008 Shared Task", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.8218726515769958}]}, {"text": "Both algorithms start parsing the sentence using the same syntactic parser.", "labels": [], "entities": []}, {"text": "The first algorithm uses machine learning methods to identify the semantic dependencies in four stages: identification and labeling of predicates, identification and labeling of arguments.", "labels": [], "entities": [{"text": "identification and labeling of predicates", "start_pos": 104, "end_pos": 145, "type": "TASK", "confidence": 0.7380945265293122}]}, {"text": "The second algorithm uses a generative probabilistic model, choosing the semantic dependencies that maximize the probability with respect to the model.", "labels": [], "entities": []}, {"text": "A hybrid algorithm combining the best stages of the two algorithms attains 86.62% labeled syntactic attachment accuracy, 73.24% labeled semantic dependency F1 and 79.93% labeled macro F1 score for the combined WSJ and Brown test sets 1 .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.5280861854553223}, {"text": "labeled semantic dependency F1", "start_pos": 128, "end_pos": 158, "type": "METRIC", "confidence": 0.4590350389480591}, {"text": "labeled macro F1 score", "start_pos": 170, "end_pos": 192, "type": "METRIC", "confidence": 0.602258212864399}, {"text": "WSJ and Brown test sets", "start_pos": 210, "end_pos": 233, "type": "DATASET", "confidence": 0.8911869883537292}]}], "introductionContent": [{"text": "In this paper we describe the system we developed for the.", "labels": [], "entities": []}, {"text": "Section 2 describes our approach for identifying syntactic dependencies.", "labels": [], "entities": []}, {"text": "For semantic role labeling (SRL), we pursued two independent approaches.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8511041700839996}]}, {"text": "Section 3 describes our first approach, where we treated predicate identification and labeling, and argument identification and labeling as 1 These numbers are slightly higher than the official results due to a small bug in our submission.", "labels": [], "entities": [{"text": "predicate identification and labeling", "start_pos": 57, "end_pos": 94, "type": "TASK", "confidence": 0.7970789149403572}, {"text": "argument identification and labeling", "start_pos": 100, "end_pos": 136, "type": "TASK", "confidence": 0.8128825128078461}]}, {"text": "four separate machine learning problems.", "labels": [], "entities": []}, {"text": "The final program consists of four stages, each stage taking the answers from the previous stage as given and performing its own identification or labeling task based on a model generated from the training set.", "labels": [], "entities": [{"text": "identification or labeling task", "start_pos": 129, "end_pos": 160, "type": "TASK", "confidence": 0.7760554850101471}]}, {"text": "Section 4 describes our second approach where we used a generative model based on the joint distribution of the predicate, the arguments, their labels and the syntactic dependencies connecting them.", "labels": [], "entities": []}, {"text": "Section 5 summarizes our results and suggests possible improvements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Semantic scores for the 4-stage, genera- tive, and hybrid algorithms", "labels": [], "entities": []}]}