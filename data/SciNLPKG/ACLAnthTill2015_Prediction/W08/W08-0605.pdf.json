{"title": [{"text": "Accelerating the Annotation of Sparse Named Entities by Dynamic Sentence Selection", "labels": [], "entities": [{"text": "Annotation of Sparse Named Entities", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.8361368298530578}]}], "abstractContent": [{"text": "This paper presents an active learning-like framework for reducing the human effort for making named entity annotations in a corpus.", "labels": [], "entities": []}, {"text": "In this framework, the annotation work is performed as an iterative and interactive process between the human annotator and a proba-bilistic named entity tagger.", "labels": [], "entities": []}, {"text": "At each iteration , sentences that are most likely to contain named entities of the target category are selected by the probabilistic tagger and presented to the annotator.", "labels": [], "entities": []}, {"text": "This iterative annotation process is repeated until the estimated coverage reaches the desired level.", "labels": [], "entities": []}, {"text": "Unlike active learning approaches, our framework produces a named entity corpus that is free from the sampling bias introduced by the active strategy.", "labels": [], "entities": []}, {"text": "We evaluated our framework by simulating the annotation process using two named entity corpora and show that our approach could drastically reduce the number of sentences to be annotated when applied to sparse named entities.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entities play a central role in conveying important domain specific information in text, and good named entity recognizers are often required in building practical information extraction systems.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 170, "end_pos": 192, "type": "TASK", "confidence": 0.7484970390796661}]}, {"text": "Previous studies have shown that automatic named entity recognition can be performed with a reasonable level of accuracy by using various machine learning models such as support vector machines (SVMs) or conditional random fields (CRFs)).", "labels": [], "entities": [{"text": "automatic named entity recognition", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.609342522919178}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9977501034736633}]}, {"text": "However, the lack of annotated corpora, which are indispensable for training machine learning models, makes it difficult to broaden the scope of text mining applications.", "labels": [], "entities": [{"text": "text mining", "start_pos": 145, "end_pos": 156, "type": "TASK", "confidence": 0.8192163407802582}]}, {"text": "In the biomedical domain, for example, several annotated corpora such as GENIA ( ,), and GENETAG () have been created and made publicly available, but the named entity categories annotated in these corpora are tailored to their specific needs and not always sufficient or suitable for text mining tasks that other researchers need to address.", "labels": [], "entities": [{"text": "GENETAG", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.8209966421127319}, {"text": "text mining tasks", "start_pos": 285, "end_pos": 302, "type": "TASK", "confidence": 0.811966598033905}]}, {"text": "Active learning is a framework which can be used for reducing the amount of human effort required to create a training corpus).", "labels": [], "entities": []}, {"text": "In active learning, samples that need to be annotated by the human annotator are picked up by a machine learning model in an iterative and interactive manner, considering the informativeness of the samples.", "labels": [], "entities": []}, {"text": "Active learning has been shown to be effective in several natural language processing tasks including named entity recognition.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.7070026397705078}]}, {"text": "The problem with active learning is, however, that the resulting annotated data is highly dependent on the machine learning algorithm and the sampling strategy employed, because active learning annotates only a subset of the given corpus.", "labels": [], "entities": []}, {"text": "This sampling bias is not a serious problem if one is to use the annotated corpus only for their own machine learning purpose and with the same machine learning algorithm.", "labels": [], "entities": []}, {"text": "However, the existence of bias is not desirable if one also wants the corpus to be used by other applications or researchers.", "labels": [], "entities": []}, {"text": "For the same reason, ac-tive learning approaches cannot be used to enrich an existing linguistic corpus with anew named entity category.", "labels": [], "entities": []}, {"text": "In this paper, we present a framework that enables one to make named entity annotations fora given corpus with a reduced cost.", "labels": [], "entities": []}, {"text": "Unlike active learning approaches, our framework aims to annotate all named entities of the target category contained in the corpus.", "labels": [], "entities": []}, {"text": "Obviously, if we were to ensure 100% coverage of annotation, there is noway of reducing the annotation cost, i.e. the human annotator has to go through every sentence in the corpus.", "labels": [], "entities": []}, {"text": "However, we show in this paper that it is possible to reduce the cost by slightly relaxing the requirement for the coverage, and the reduction can be drastic when the target named entities are sparse.", "labels": [], "entities": []}, {"text": "We should note here that the purpose of this paper is not to claim that our approach is superior to existing active learning approaches.", "labels": [], "entities": []}, {"text": "The goals are different-while active learning aims at optimizing the performance of the resulting machine learningbased tagger, our framework aims to help develop an unbiased named entity-annotated corpus.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the overall annotation flow in our framework.", "labels": [], "entities": []}, {"text": "Section 3 presents how to select sentences using the output of a probabilistic tagger.", "labels": [], "entities": []}, {"text": "Section 4 describes how to estimate the coverage during the course of annotation.", "labels": [], "entities": [{"text": "coverage", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9860299229621887}]}, {"text": "Experimental results using two named entity corpora are presented in section 5.", "labels": [], "entities": []}, {"text": "Section 6 describes related work and discussions.", "labels": [], "entities": []}, {"text": "Concluding remarks are given in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out experiments to see how our method can improve the efficiency of annotation process for sparse named entities.", "labels": [], "entities": []}, {"text": "We evaluate our method by simulating the annotation process using existing named entity corpora.", "labels": [], "entities": []}, {"text": "In other words, we use the gold-standard annotations in the corpus as the annotations that would be made by the human annotator during the annotation process.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Statistics of named entities.", "labels": [], "entities": []}, {"text": " Table 4: Coverage achieved when the estimated coverage reached 99%.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.6300166249275208}, {"text": "coverage", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9571683406829834}]}]}