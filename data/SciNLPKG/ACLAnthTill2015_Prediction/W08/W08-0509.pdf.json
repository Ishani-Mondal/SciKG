{"title": [{"text": "Parallel Implementations of Word Alignment Tool", "labels": [], "entities": [{"text": "Parallel Implementations of Word Alignment Tool", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7285121728976568}]}], "abstractContent": [{"text": "Training word alignment models on large corpora is a very time-consuming processes.", "labels": [], "entities": [{"text": "Training word alignment models", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7239834442734718}]}, {"text": "This paper describes two parallel implementations of GIZA++ that accelerate this word alignment process.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7518300712108612}]}, {"text": "One of the implementations runs on computer clusters, the other runs on multi-processor system using multi-threading technology.", "labels": [], "entities": []}, {"text": "Results show a near-linear speed-up according to the number of CPUs used, and alignment quality is preserved.", "labels": [], "entities": []}], "introductionContent": [{"text": "Training state-of-the-art phrase-based statistical machine translation (SMT) systems requires several steps.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 26, "end_pos": 76, "type": "TASK", "confidence": 0.7429978251457214}]}, {"text": "First, word alignment models are trained on the bilingual parallel training corpora.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 7, "end_pos": 21, "type": "TASK", "confidence": 0.8040389716625214}]}, {"text": "The most widely used tool to perform this training step is the well-known GIZA++.", "labels": [], "entities": []}, {"text": "The resulting word alignment is then used to extract phrase pairs and perhaps other information to be used in translation systems, such as block reordering models.", "labels": [], "entities": []}, {"text": "Among the procedures, more than 2/3 of the time is consumed byword alignment (.", "labels": [], "entities": []}, {"text": "Speeding up the word alignment step can dramatically reduces the overall training time, and in turn accelerates the development of SMT systems.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8128326833248138}, {"text": "SMT", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.9966104626655579}]}, {"text": "With the rapid development of computing hardware, multi-processor servers and clusters become widely available.", "labels": [], "entities": []}, {"text": "With parallel computing, processing time (wall time) can often be cut down by one or two orders of magnitude.", "labels": [], "entities": []}, {"text": "Tasks, which require several weeks on a single CPU machine may take only a few hours on a cluster.", "labels": [], "entities": []}, {"text": "However, GIZA++ was designed to be single-process and single-thread.", "labels": [], "entities": []}, {"text": "To make more efficient use of available computing resources and thereby speedup the training of our SMT system, we decided to modify GIZA++ so that it can run in parallel on multiple CPUs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.9936834573745728}]}, {"text": "The word alignment models implemented in GIZA++, the so-called IBM ( and HMM alignment models () are typical implementation of the EM algorithm.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7244843244552612}, {"text": "IBM", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.5769557952880859}]}, {"text": "That is to say that each of these models run fora number of iterations.", "labels": [], "entities": []}, {"text": "In each iteration it first calculates the best word alignment for each sentence pairs in the corpus, accumulating various counts, and then normalizes the counts to generate the model parameters for the next iteration.", "labels": [], "entities": []}, {"text": "The word alignment stage is the most time-consuming part, especially when the size of training corpus is large.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8091520071029663}]}, {"text": "During the aligning stage, all sentences can be aligned independently of each other, as model parameters are only updated after all sentence pairs have been aligned.", "labels": [], "entities": []}, {"text": "Making use of this property, the alignment procedure can be parallelized.", "labels": [], "entities": [{"text": "alignment", "start_pos": 33, "end_pos": 42, "type": "TASK", "confidence": 0.942737340927124}]}, {"text": "The basic idea is to have multiple processes or threads aligning portions of corpus independently and then merge the counts and perform normalization.", "labels": [], "entities": []}, {"text": "The paper implements two parallelization methods.", "labels": [], "entities": []}, {"text": "The PGIZA++ implementation, which is based on (), uses multiple aligning processes.", "labels": [], "entities": []}, {"text": "When all the processes finish, a master process starts to collect the counts and normalizes them to produce updated models.", "labels": [], "entities": []}, {"text": "Child processes are then restarted for the new iteration.", "labels": [], "entities": []}, {"text": "The PGIZA++ does not limit the number of CPUs being used, whereas it needs to transfer (in some cases) large amounts of data between processes.", "labels": [], "entities": []}, {"text": "Therefore its performance also depends on the speed of the network infrastructure.", "labels": [], "entities": []}, {"text": "The MGIZA++ implementation, on the other hand, starts multiple threads on a common address space, and uses a mutual locking mechanism to synchronize the access to the memory.", "labels": [], "entities": [{"text": "MGIZA++", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.8633684813976288}]}, {"text": "Although MGIZA++ can only utilize a single multi-processor computer, which limits the number of CPUs it can use, it avoids the overhead of slow network I/O.", "labels": [], "entities": [{"text": "MGIZA++", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.813433438539505}]}, {"text": "That makes it an equally efficient solution for many tasks.", "labels": [], "entities": []}, {"text": "The two versions of alignment tools are available online at http://www.cs.cmu.edu/\u02dc qing/giza.", "labels": [], "entities": [{"text": "alignment", "start_pos": 20, "end_pos": 29, "type": "TASK", "confidence": 0.9795572757720947}]}, {"text": "The paper will be organized as follows, section 2 provides the basic algorithm of GIZA++, and section 3 describes the PGIZA++ implementation.", "labels": [], "entities": []}, {"text": "Section 4 presents the MGIZA++ implementation, followed by the profile and evaluation results of both systems in section 5.", "labels": [], "entities": [{"text": "MGIZA++", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.7926075756549835}]}, {"text": "Finally, conclusion and future work are presented in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "For PGIZA++ we performed training on an ChineseEnglish translation task.", "labels": [], "entities": [{"text": "ChineseEnglish translation task", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.8006634910901388}]}, {"text": "The dataset consists of approximately 10 million sentence pairs with 231 million Chinese words and 258 million English words.", "labels": [], "entities": []}, {"text": "We ran both GIZA++ and PGIZA++ on the same training corpus with the same parameters, then ran Pharaoh phrase extraction on the resulting alignments.", "labels": [], "entities": [{"text": "Pharaoh phrase extraction", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.5270730505386988}]}, {"text": "Finally, we tuned our translation systems on the NIST MT03 test set and evaluate them on NIST MT06 test set.", "labels": [], "entities": [{"text": "NIST MT03 test set", "start_pos": 49, "end_pos": 67, "type": "DATASET", "confidence": 0.8943439871072769}, {"text": "NIST MT06 test set", "start_pos": 89, "end_pos": 107, "type": "DATASET", "confidence": 0.9218419939279556}]}, {"text": "The experiment was performed on a cluster of several Xeon CPUs, the storage of corpora and models are on a central NFS server.", "labels": [], "entities": []}, {"text": "The PGIZA++ uses Condor as its scheduler, splitting the training data into 30 fragments, and ran training in both direction (Ch-En, En-Ch) concurrently.", "labels": [], "entities": [{"text": "PGIZA++", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.8477165400981903}]}, {"text": "The scheduler assigns 11 CPUs on average to the tasks.", "labels": [], "entities": []}, {"text": "We ran 5 iterations of Model 1 training, 5 iteration of HMM, 3 Model 3 iterations and 3 Model 4 iterations.", "labels": [], "entities": [{"text": "HMM", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.7772372961044312}]}, {"text": "To compare the performance of system, we recorded the total training time and the BLEU score, which is a standard automatic measurement of the translation quality().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9808109402656555}]}, {"text": "The training time and BLEU scores are shown in  The results show similar BLEU scores when using GIZA++ and PGIZA++, and a 4 times speedup.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9997679591178894}, {"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9996103644371033}, {"text": "GIZA", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.707720160484314}]}, {"text": "Also, we calculated the time used in normalization.", "labels": [], "entities": [{"text": "normalization", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.9696948528289795}]}, {"text": "The average time of each normalization step is shown in  As we can see, if we rule out the time spent in normalization, the speedup is almost linear.", "labels": [], "entities": []}, {"text": "Higher order models require less time in the normalization step mainly due to the fact that the lexicon becomes smaller and smaller with each models (see.", "labels": [], "entities": []}, {"text": "PGIZA++, in small amount of data,  Because MGIZA++ is more convenient to integrate into other packages, we modified the Moses system to use MGIZA++.", "labels": [], "entities": []}, {"text": "We use the Europal EnglishSpanish dataset as training data, which contains 900 thousand sentence pairs, 20 million English words and 20 million Spanish words.", "labels": [], "entities": [{"text": "Europal EnglishSpanish dataset", "start_pos": 11, "end_pos": 41, "type": "DATASET", "confidence": 0.9654876391092936}]}, {"text": "We trained the English-to-Spanish system, and tuned the system on two datasets, the WSMT 2006 Europal test set (TUNE1) and the WSMT news commentary devtest set 2007 (TUNE2).", "labels": [], "entities": [{"text": "WSMT 2006 Europal test set (TUNE1)", "start_pos": 84, "end_pos": 118, "type": "DATASET", "confidence": 0.9191757664084435}, {"text": "WSMT news commentary devtest set 2007 (TUNE2)", "start_pos": 127, "end_pos": 172, "type": "DATASET", "confidence": 0.934514151679145}]}, {"text": "Then we used the first parameter set to decode WSMT 2006 Europal test set (TEST1) and used the second on WSMT news commentary test set 2007 (TEST2) . shows the comparison of BLEU scores of both systems.", "labels": [], "entities": [{"text": "WSMT 2006 Europal test set (TEST1", "start_pos": 47, "end_pos": 80, "type": "DATASET", "confidence": 0.9051026787076678}, {"text": "WSMT news commentary test set 2007 (TEST2)", "start_pos": 105, "end_pos": 147, "type": "DATASET", "confidence": 0.9504059751828512}, {"text": "BLEU", "start_pos": 174, "end_pos": 178, "type": "METRIC", "confidence": 0.9994319081306458}]}, {"text": "listed in  Note that when decoding using the phrase table resulting from training with MGIZA++, we used the parameter tuned fora phrase table generated from GIZA++ alignment, which maybe the cause of lower BLEU score in the tuning set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 206, "end_pos": 216, "type": "METRIC", "confidence": 0.9820026755332947}]}, {"text": "However, the major difference in the training comes from fixing the HMM bug in GIZA++, as mentioned before.", "labels": [], "entities": [{"text": "GIZA++", "start_pos": 79, "end_pos": 85, "type": "DATASET", "confidence": 0.8674668371677399}]}, {"text": "To profile the speed of the system according to the number of CPUs it use, we ran MGIZA++ on 1, 2 and 4 CPUs of the same speed.", "labels": [], "entities": [{"text": "MGIZA++", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.8520940840244293}]}, {"text": "When it runs on 1 CPU, the speed is the same as for the original GIZA++. and show the running time of each stage:   celeration rate.", "labels": [], "entities": [{"text": "GIZA++.", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.9007889032363892}, {"text": "celeration rate", "start_pos": 116, "end_pos": 131, "type": "METRIC", "confidence": 0.9600363671779633}]}, {"text": "That is mainly because of the required locking mechanism.", "labels": [], "entities": []}, {"text": "However the acceleration is also significant, especially for small training corpora, as we will see in next experiment.", "labels": [], "entities": [{"text": "acceleration", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.9638350009918213}]}], "tableCaptions": [{"text": " Table 1: Model tables created during training", "labels": [], "entities": []}, {"text": " Table 2: Comparison of the size of count tables for the  lexicon probabilities", "labels": [], "entities": []}, {"text": " Table 4: Comparison of GIZA++ and PGIZA++", "labels": [], "entities": []}, {"text": " Table 5: Normalization time in each stage", "labels": [], "entities": []}, {"text": " Table 6: BLEU Score of GIZA++ and MGIZA++", "labels": [], "entities": [{"text": "BLEU Score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9315124154090881}, {"text": "GIZA", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.7556953430175781}, {"text": "MGIZA++", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.7604576647281647}]}, {"text": " Table 7: Speed of MGIZA++", "labels": [], "entities": [{"text": "Speed", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9914509654045105}, {"text": "MGIZA++", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.6774281561374664}]}, {"text": " Table 8: Speed of PGIZA++ on Small Corpus", "labels": [], "entities": [{"text": "Speed", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.982223629951477}, {"text": "Small Corpus", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.8664255738258362}]}, {"text": " Table 9: Normalization time in each stage : small data", "labels": [], "entities": []}, {"text": " Table 10: Difference in Viterbi alignment (GIZA++ with  the bug fixed as reference)", "labels": [], "entities": [{"text": "Viterbi alignment", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.6661860644817352}]}]}