{"title": [{"text": "A Bayesian model of natural language phonology: generating alternations from underlying forms", "labels": [], "entities": []}], "abstractContent": [{"text": "A stochastic approach to learning phonology.", "labels": [], "entities": []}, {"text": "The model presented captures 7-15% more phonologically plausible underlying forms than a simple majority solution, because it prefers \"pure\" alternations.", "labels": [], "entities": []}, {"text": "It could be useful in cases where an approximate solution is needed, or as a seed for more complex models.", "labels": [], "entities": []}, {"text": "A similar process could be involved in some stages of child language acquisition; in particular, early learning of phonotactics.", "labels": [], "entities": [{"text": "child language acquisition", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.7053788701693217}]}], "introductionContent": [{"text": "Sound changes in natural language, such as stem variation in inflected forms, can be described as phonological processes.", "labels": [], "entities": []}, {"text": "These are governed by a constraint hierarchy as in Optimality Theory (OT), or by a set of ordered rules.", "labels": [], "entities": [{"text": "Optimality Theory (OT)", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.827436912059784}]}, {"text": "Both rely on a single lexical representation of each morpheme (i.e., its underlying form), and context-sensitive transformations to surface forms.", "labels": [], "entities": []}, {"text": "Phonological changes often affect segments near morpheme boundaries, but can also apply over an entire prosodic word, as in vowel harmony.", "labels": [], "entities": []}, {"text": "It does not seem straightforward to incorporate context into a Bayesian model of phonology, although a clever solution may yet be found.", "labels": [], "entities": []}, {"text": "A standard way of incorporating conditioning environments is to treat them as factors in a Gibbs model (, but such models require an explicit calculation of the partition function.", "labels": [], "entities": []}, {"text": "Unless the rule contexts possess some kind of locality, we don't know how to compute this partition function efficiently.", "labels": [], "entities": []}, {"text": "Some context could be captured by generating underlying phonemes from an n-gram model, or by annotating surface forms with neighborhood features.", "labels": [], "entities": []}, {"text": "However, the effects of autosegmental phonology and other long-range dependencies (like vowel harmony) cannot be easily Bayesianized.", "labels": [], "entities": []}], "datasetContent": [{"text": "As we describe the model and its implementation in this and subsequent sections, we will refer to a sam-ple dataset (in, consisting of a paradigm 2 of verb stems and person/number suffixes.", "labels": [], "entities": []}, {"text": "The head of each row or column is an /underlying/ form, which in 3rd person singular is a phonologically null segment (represented as /\u00f8/).", "labels": [], "entities": []}, {"text": "In forms, the realization of each morpheme is affected by phonological processes.", "labels": [], "entities": []}, {"text": "For example, in the combination of /tiet\u00e4/ + /vat/, the result is, where the 3rd person plural /a/ becomes [\u00a8 a] due to vowel harmony.", "labels": [], "entities": []}, {"text": "This model provides a language agnostic solution to a subset of phonological problems.", "labels": [], "entities": []}, {"text": "We will first examine performance on the sample Finnish data (from, and then look more closely at the issue of convergence.", "labels": [], "entities": [{"text": "Finnish data", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.7422866076231003}, {"text": "convergence", "start_pos": 111, "end_pos": 122, "type": "METRIC", "confidence": 0.9063180685043335}]}, {"text": "Finally, we present results from larger corpora 3 .", "labels": [], "entities": []}], "tableCaptions": []}