{"title": [{"text": "Invited Talk: Phonological Models in Automatic Speech Recognition", "labels": [], "entities": [{"text": "Automatic Speech Recognition", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.6149582962195078}]}], "abstractContent": [{"text": "The performance of automatic speech recognition systems varies widely across different contexts.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6876130104064941}]}, {"text": "Very good performance can be achieved on single-speaker, large-vocabulary dictation in a clean acoustic environment , as well as on very small vocabulary tasks with much fewer constraints on the speakers and acoustic conditions.", "labels": [], "entities": []}, {"text": "In other domains, speech recognition is still far from usable for real-world applications.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8925483226776123}]}, {"text": "One domain that is still elusive is that of spontaneous conversational speech.", "labels": [], "entities": []}, {"text": "This type of speech poses a number of challenges, such as the presence of disfluencies, a mix of speech and non-speech sounds such as laughter, and extreme variation in pronunciation.", "labels": [], "entities": []}, {"text": "In this talk, I will focus on the challenge of pronunciation variation.", "labels": [], "entities": [{"text": "pronunciation variation", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.9318258166313171}]}, {"text": "A number of analyses suggest that this variability is responsible fora large part of the drop in recognition performance between read (dictated) speech and conversational speech.", "labels": [], "entities": []}, {"text": "I will describe efforts in the speech recognition community to characterize and model pronunciation variation, both for conversational speech and in general.", "labels": [], "entities": [{"text": "speech recognition community", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.7856900791327158}]}, {"text": "The work can be roughly divided into several types of approaches, including: augmentation of a phonetic pronunciation lexicon with phonological rules; the use of large (syllable-or word-sized) units instead of the more traditional phonetic ones; and the use of smaller units, such as distinctive or articulatory features.", "labels": [], "entities": []}, {"text": "Of these, the first is the most thoroughly studied and also the most disappointing: Despite successes in a few domains, it has been difficult to obtain significant recognition improvements by including in the lexicon those phonetic pronunciations that appear to exist in the data.", "labels": [], "entities": []}, {"text": "In part as a reaction to this, many have advocated the use of a \"null pronunciation model,\" i.e. a very limited lexicon including only canonical pronunciations.", "labels": [], "entities": []}, {"text": "The assumption in this approach is that the observation model-the distribution of the acoustics given phonetic units-will better model the \"noise\" introduced by pronunciation variability.", "labels": [], "entities": []}, {"text": "I will advocate an alternative view: that the phone unit may not be the most appropriate for modeling the lexicon.", "labels": [], "entities": []}, {"text": "When considering a variety of pronunciation phenomena, it becomes apparent that phonetic transcription often obscures some of the fundamental processes that are at play.", "labels": [], "entities": [{"text": "phonetic transcription", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.7124808728694916}]}, {"text": "I will describe approaches using both larger and \"smaller\" units.", "labels": [], "entities": []}, {"text": "Larger units are typically syllables or words, and allow greater freedom to model the component states of each unit.", "labels": [], "entities": []}, {"text": "In the class of \"smaller\" unit models, ideas from articulatory and autosegmental phonology motivate multi-tier models in which different features (or groups of features) have semi-independent behavior.", "labels": [], "entities": []}, {"text": "I will present a particular model in which articulatory features are represented as variables in a dynamic Bayesian network.", "labels": [], "entities": []}, {"text": "Non-phonetic pronunciation models can involve significantly different model structures than those typically used in speech recognition, and as a result they may also entail modifications to other components such as the observation model and training algorithms.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.7427698075771332}]}, {"text": "At this point it is not clear what the \"winning\" approach will be.", "labels": [], "entities": []}, {"text": "The success of a given approach may depend on the domain or on the amount and type of training data available.", "labels": [], "entities": []}, {"text": "I will describe some of the current challenges and ongoing work, with a particular focus on the role of phonological theories in statistical models of pronunciation (and vice versa?).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}