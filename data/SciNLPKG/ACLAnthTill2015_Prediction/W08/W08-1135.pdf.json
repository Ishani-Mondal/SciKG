{"title": [{"text": "USP-EACH Frequency-based Greedy Attribute Selection for Referring Expressions Generation", "labels": [], "entities": [{"text": "USP-EACH Frequency-based Greedy Attribute Selection", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.5871070146560669}]}], "abstractContent": [{"text": "Both greedy and domain-oriented REG algorithms have significant strengths but tend to perform poorly according to humanlikeness criteria as measured by, e.g., Dice scores.", "labels": [], "entities": []}, {"text": "In this work we describe an attempt to combine both perspectives into a single attribute selection strategy to be used as part of the Dale & Reiter Incremental algorithm in the REG Challenge 2008, and the results in both Furniture and People domains.", "labels": [], "entities": [{"text": "REG Challenge 2008", "start_pos": 177, "end_pos": 195, "type": "DATASET", "confidence": 0.6330357293287913}]}], "introductionContent": [{"text": "Minimality and Humanlikeness in REG are often conflicting goals.", "labels": [], "entities": [{"text": "REG", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9230468273162842}]}, {"text": "Greedy algorithms tend to favour shorter descriptions, but in doing so their output may look unnatural.", "labels": [], "entities": []}, {"text": "On the other hand, domainoriented algorithms that arguably favour more \"human-like\" strategies (e.g., selecting the most typical attributes first) pay little or no attention to minimality, and as a result the generated descriptions may become overly long or clumsy.", "labels": [], "entities": []}, {"text": "Which strategy might a human speaker favour?", "labels": [], "entities": []}, {"text": "In this work we describe an algorithm that disregards minimality entirely and attempts to select 'typical' attributes based on two simple assumptions: first, when facing a complex context with a large number of objects, an attempt to compute the precise attribute capable of ruling out the largest possible number of distractors is not only hard (from the computational point of view), but also less natural than simply using typical (e.g., frequent) attributes.", "labels": [], "entities": []}, {"text": "On the other hand, as the number of distractors decreases, it may become gradually clearer for the speaker which attributes are most helpful to achieve uniqueness, up to the point in which she may naturally switch to a 'greedy' strategy and finalize the description.", "labels": [], "entities": []}, {"text": "These assumptions are implemented as an attribute selection strategy to be used with the Incremental algorithm) described below.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}