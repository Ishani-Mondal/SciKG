{"title": [{"text": "Transforming Meaning Representation Grammars to Improve Semantic Parsing", "labels": [], "entities": [{"text": "Transforming Meaning Representation Grammars", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.9356384128332138}, {"text": "Improve Semantic Parsing", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.7974022428194681}]}], "abstractContent": [{"text": "A semantic parser learning system learns to map natural language sentences into their domain-specific formal meaning representations , but if the constructs of the meaning representation language do not correspond well with the natural language then the system may not learn a good semantic parser.", "labels": [], "entities": []}, {"text": "This paper presents approaches for automatically transforming a meaning representation grammar (MRG) to conform it better with the natural language semantics.", "labels": [], "entities": [{"text": "automatically transforming a meaning representation grammar (MRG)", "start_pos": 35, "end_pos": 100, "type": "TASK", "confidence": 0.764629430241055}]}, {"text": "It introduces grammar transformation operators and meaning representation macros which are applied in an error-driven manner to transform an MRG while training a semantic parser learning system.", "labels": [], "entities": [{"text": "grammar transformation", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.704551637172699}]}, {"text": "Experimental results show that the automatically transformed MRGs lead to better learned semantic parsers which perform comparable to the semantic parsers learned using manually engineered MRGs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic parsing is the task of converting natural language (NL) sentences into their meaning representations (MRs) which a computer program can execute to perform some domain-specific task, like controlling a robot, answering database queries etc.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8174918293952942}, {"text": "answering database queries", "start_pos": 217, "end_pos": 243, "type": "TASK", "confidence": 0.670628547668457}]}, {"text": "These MRs are expressed in a formal meaning representation language (MRL) unique to the domain to suit the application, like some specific command language to control a robot or some query language to execute database queries.", "labels": [], "entities": []}, {"text": "A machine learning system for semantic parsing takes NL sentences paired with their respective MRs as training data and induces a semantic parser which can then map novel NL sentences into their MRs.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8340131640434265}]}, {"text": "The grammar of an MRL, which we will call meaning representation grammar (MRG), is assumed to be deterministic and context-free which is true for grammars of almost all the computer executable languages.", "labels": [], "entities": [{"text": "meaning representation grammar (MRG)", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.8126063843568166}]}, {"text": "A semantic parsing learning system typically exploits the given MRG of the MRL to learn a semantic parser (;).", "labels": [], "entities": [{"text": "semantic parsing learning", "start_pos": 2, "end_pos": 27, "type": "TASK", "confidence": 0.782626748085022}, {"text": "MRG", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9051518440246582}]}, {"text": "Although in different ways, but the systems presented in these papers learn how the NL phrases relate to the productions of the MRG, and using this information they parse a test sentence to compositionally generate its best MR.", "labels": [], "entities": [{"text": "MRG", "start_pos": 128, "end_pos": 131, "type": "DATASET", "confidence": 0.7002658843994141}]}, {"text": "In order to learn a good semantic parser, it is necessary that the productions of the MRG accurately represent the semantics being expressed by the natural language.", "labels": [], "entities": []}, {"text": "However, an MRL and its MRG are typically designed to best suit the application with little consideration for how well they correspond to the semantics of a natural language.", "labels": [], "entities": []}, {"text": "Some other semantic parser learning systems which need MRL in the form of) or \u03bb-calculus do not use productions of the MRG but instead use predicates of the MRL.", "labels": [], "entities": []}, {"text": "However, in order to learn a good semantic parser, they still require that these predicates correspond well with the semantics of the natural language.", "labels": [], "entities": []}, {"text": "There are also systems which learn semantic parsers from more detailed training data in the form of semantically augmented parse trees of NL sentences in which each internal node has a syntactic and a semantic label (Ge (a) NL: If the ball is in our midfield then player 5 should go to.", "labels": [], "entities": []}, {"text": "MR: (bpos (rec (pt -32 -35)(pt 0 35)) (do (player our {5})(pos (pt -5 0)))) (b) NL: Which is the longest river in Texas?", "labels": [], "entities": []}, {"text": "MR: answer(longest(river(loc_2(stateid('Texas'))))) (c) NL: Which is the longest river in Texas?", "labels": [], "entities": []}, {"text": "MR: select river.name from river where river.traverse='Texas' and river.length= (select max(river.length) from river where river.traverse='Texas'); and).", "labels": [], "entities": []}, {"text": "For these systems to work well, it is also necessary that the semantic labels of the MRL correspond well with natural language semantics.", "labels": [], "entities": []}, {"text": "If the MRG of a domain-specific MRL does not correspond well with natural language semantics then manually re-engineering the MRG to work well for semantic parsing is a tedious task and requires considerable domain expertise.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 147, "end_pos": 163, "type": "TASK", "confidence": 0.7291846722364426}]}, {"text": "In this paper, we present methods to automatically transform a given MRG to make it more suitable for learning semantic parsers.", "labels": [], "entities": [{"text": "learning semantic parsers", "start_pos": 102, "end_pos": 127, "type": "TASK", "confidence": 0.7043129205703735}]}, {"text": "No previous work addresses this issue to our best knowledge.", "labels": [], "entities": []}, {"text": "We introduce grammar transformation operators and meaning representation macros to transform an MRG.", "labels": [], "entities": []}, {"text": "We describe how these are applied in an errordriven manner using the base semantic parsing learning algorithm presented in () resulting in a better learned semantic parser.", "labels": [], "entities": [{"text": "semantic parsing learning", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7933037479718527}]}, {"text": "Our approach, however, is general enough to improve any semantic parser learning system which uses productions of the MRG.", "labels": [], "entities": [{"text": "semantic parser learning", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.7582585612932841}, {"text": "MRG", "start_pos": 118, "end_pos": 121, "type": "DATASET", "confidence": 0.814395010471344}]}, {"text": "We present experimental results with three very different MRLs to show how these grammar transformations improve the semantic parsing performance.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 117, "end_pos": 133, "type": "TASK", "confidence": 0.7716048955917358}]}], "datasetContent": [{"text": "We tested our MRG transformation methods with MRGs of three different MRLs which were described in the Background section.", "labels": [], "entities": [{"text": "MRG transformation", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.952895998954773}]}, {"text": "In each case, we first transformed the given MRG using macros and then using grammar transformation operators.", "labels": [], "entities": []}, {"text": "The training and testing was done using standard 10-fold cross-validation and the performance was measured in terms of precision (the percentage of generated MRs that were correct) and recall (the percentage of all sentences for which correct MRs were obtained).", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9994761347770691}, {"text": "recall", "start_pos": 185, "end_pos": 191, "type": "METRIC", "confidence": 0.9994702935218811}]}, {"text": "Since we wanted to evaluate how the grammar transformation changes the performance on the semantic parsing task, in each of the experiments, we used the same system, KRISP, and compared how it performs when trained using different MRGs for the same MRL.", "labels": [], "entities": [{"text": "semantic parsing task", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.7918543120225271}, {"text": "KRISP", "start_pos": 166, "end_pos": 171, "type": "METRIC", "confidence": 0.5504984259605408}]}, {"text": "Since KRISP assigns confidences to the MRs it generates, an entire range of precision-recall trade-off was plotted by measuring precision and recall values at various confidence levels.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 76, "end_pos": 92, "type": "METRIC", "confidence": 0.9906628131866455}, {"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9972339272499084}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9629083275794983}]}, {"text": "shows the results on the GEOQUERY domain using the functional query language whose corpus contained total 880 NL-MR pairs.", "labels": [], "entities": [{"text": "GEOQUERY domain", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.8842325210571289}]}, {"text": "As can be seen, the performance of the semantic parser that KRISP learns when trained using the initial simple MRG for the MRL is not good.", "labels": [], "entities": []}, {"text": "But when that MRG is transformed, the performance of the semantic parser dramatically improves and is very close to the performance obtained with the manually-engineered grammar.", "labels": [], "entities": []}, {"text": "The macro transformations did not help improve the performance with this MRG, and most of the the performance gain was obtained because of the CreateNT and DeleteProd operators.", "labels": [], "entities": []}, {"text": "We next tested our MRG transformation algorithm on SQL as the MRL for the GEOQUERY domain.", "labels": [], "entities": [{"text": "MRG transformation", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8468746840953827}, {"text": "GEOQUERY domain", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.9462957382202148}]}, {"text": "This corpus contains 700 NL-MR pairs in which the NL sentences were taken from the original 880 examples.", "labels": [], "entities": []}, {"text": "This corpus was previously used to evaluate the PRECISION system (), but since that system is not a machine learning system, its results cannot be directly compared with ours.", "labels": [], "entities": []}, {"text": "The initial MRG we used contained the basic SQL productions.", "labels": [], "entities": [{"text": "MRG", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.8915868401527405}]}, {"text": "shows that results improve by a large amount after MRG transformations.", "labels": [], "entities": [{"text": "MRG transformations", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.8904544115066528}]}, {"text": "We did not have any manuallyengineered MRG for SQL for this domain available to us.", "labels": [], "entities": []}, {"text": "With this MRG, most of the improvement was obtained using the macros and the RemoveDuplNT transformation operator.", "labels": [], "entities": []}, {"text": "Finally, we tested our MRG transformation algorithm on the CLANG domain using its original MRG in which all the chief regions of the soccer field were in the form of numeric MR expressions which do not correspond to their meanings in the natural language.", "labels": [], "entities": [{"text": "MRG transformation", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9414675831794739}, {"text": "CLANG domain", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.9179957211017609}]}, {"text": "Its corpus contains 300 examples of NL-MR pairs.", "labels": [], "entities": []}, {"text": "After applying the MRG transformations the performance improved by a large margin.", "labels": [], "entities": []}, {"text": "The gain was due to transformations obtained us-ing macros while the grammar transformation operators did not help with this MRG.", "labels": [], "entities": [{"text": "MRG", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.6899819374084473}]}, {"text": "Although the precision was lower for low recall values, the recall increased by a large quantity and the best Fmeasure improved from 50% to 63%.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9996284246444702}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9980283379554749}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9996755123138428}, {"text": "Fmeasure", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9791383147239685}]}, {"text": "But the performance still lagged behind that obtained using the manually-engineered MRG.", "labels": [], "entities": [{"text": "MRG", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9150031805038452}]}, {"text": "The main reason for this is that the manual MRG introduced some domain specific expressions, like left, right, left-quarter etc., which correspond directly to their meanings in the natural language.", "labels": [], "entities": [{"text": "MRG", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.4656207859516144}]}, {"text": "On the other hand, the only way to specify \"left\" of a region using the original CLANG MRG is by specifying the coordinates of the left region, like (rec(pt -32 -35)(pt 0 0)) is the left of (rec (pt -32 -35) (pt 0 35)) etc.", "labels": [], "entities": [{"text": "CLANG MRG", "start_pos": 81, "end_pos": 90, "type": "DATASET", "confidence": 0.9222737848758698}]}, {"text": "It is not possible to learn the concept of \"left\" from such expressions even with MRG transformations.", "labels": [], "entities": []}], "tableCaptions": []}