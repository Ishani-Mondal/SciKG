{"title": [{"text": "Collective Semantic Role Labelling with Markov Logic", "labels": [], "entities": [{"text": "Semantic Role Labelling", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.594880481561025}]}], "abstractContent": [{"text": "This paper presents our system for the Open Track of the CoNLL 2008 Shared Task (Surdeanu et al., 2008) in Joint Dependency Parsing 1 and Semantic Role Labelling.", "labels": [], "entities": [{"text": "CoNLL 2008 Shared Task (Surdeanu et al., 2008)", "start_pos": 57, "end_pos": 103, "type": "DATASET", "confidence": 0.7791570208289407}, {"text": "Joint Dependency Parsing 1", "start_pos": 107, "end_pos": 133, "type": "TASK", "confidence": 0.642999604344368}, {"text": "Semantic Role Labelling", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.6677171587944031}]}, {"text": "We use Markov Logic to define a joint SRL model and achieve a semantic F-score of 74.59%, the second best in the Open Track.", "labels": [], "entities": [{"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9528635740280151}, {"text": "F-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.953289806842804}]}], "introductionContent": [{"text": "Many SRL systems use a two-stage pipeline that first extracts possible argument candidates (argument identification) and then assigns argument labels to these candidates (argument classification) ().", "labels": [], "entities": [{"text": "SRL", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9786771535873413}]}, {"text": "If we also consider the necessary previous step of identifying the predicates and their senses (predicate identification) this yields a three-stage pipeline: predicate identification, argument identification and argument classification.", "labels": [], "entities": [{"text": "predicate identification", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.7510965764522552}, {"text": "predicate identification", "start_pos": 158, "end_pos": 182, "type": "TASK", "confidence": 0.7707054018974304}, {"text": "argument identification", "start_pos": 184, "end_pos": 207, "type": "TASK", "confidence": 0.7185718417167664}, {"text": "argument classification", "start_pos": 212, "end_pos": 235, "type": "TASK", "confidence": 0.7413881719112396}]}, {"text": "Our system, on the other hand, follows a joint approach in the spirit of and performs the above steps collectively . We decided to use Markov Logic (ML,), a First Order Probabilistic Language, to develop a global probabilistic model of SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 236, "end_pos": 239, "type": "TASK", "confidence": 0.9753369688987732}]}, {"text": "By using ML we are able to incorporate the dependencies between the decisions of different stages in the pipeline and the well-known global correlations between the arguments of a predicate ().", "labels": [], "entities": []}, {"text": "Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).", "labels": [], "entities": []}, {"text": "Note that in this work we do not consider the parsing task; instead we use the provided dependencies of the open track datatsets. and inference methods were already implemented in the ML software we use, only minimal engineering efforts had to be done.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9767076373100281}]}, {"text": "In contrast to the work of Toutanova et al.", "labels": [], "entities": []}, {"text": "(2005) our system applies online learning to train its parameters and exact inference to predict a collective role labelling.", "labels": [], "entities": []}, {"text": "Moreover, we jointly label the arguments of all predicates in a sentence.", "labels": [], "entities": []}, {"text": "This allows us, for example, to require that certain tokens have to bean argument of some predicates in the sentence.", "labels": [], "entities": []}, {"text": "In this paper we also investigate the impact of different levels of interaction between the layers of the joint SRL model.", "labels": [], "entities": []}, {"text": "We find that a probabilistic model which resembles a traditional bottom-up pipeline (though jointly trained and globally normalised) performs better than the complete joint model on the WSJ test set and worse on the Brown test set.", "labels": [], "entities": [{"text": "WSJ test set", "start_pos": 186, "end_pos": 198, "type": "DATASET", "confidence": 0.9759348630905151}, {"text": "Brown test set", "start_pos": 216, "end_pos": 230, "type": "DATASET", "confidence": 0.9322317043940226}]}, {"text": "The worst performance is observed when no interaction between SRL stages is allowed.", "labels": [], "entities": [{"text": "SRL", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9547650814056396}]}, {"text": "In terms of semantic F-score (74.59%) our submitted results are the second best in the Open Track of the Shared Task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.852000892162323}]}, {"text": "Our error analysis indicates that a) the training regime can be improved and b) nominalizations are difficult to handle for the model as it is.", "labels": [], "entities": []}, {"text": "In the next sections we will first briefly introduce Markov Logic.", "labels": [], "entities": []}, {"text": "Then we present the Markov Logic model we used in our final submission.", "labels": [], "entities": []}, {"text": "We present and analyse our results in section 4 before we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: F-scores for different models.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9952651262283325}]}]}