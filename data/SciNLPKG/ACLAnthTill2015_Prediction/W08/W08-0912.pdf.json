{"title": [{"text": "Towards Automatic Scoring of a Test of Spoken Language with Heterogeneous Task Types", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a system aimed at automatically scoring two task types of high and medium-high linguistic entropy from a spoken English test with a total of six widely differing task types.", "labels": [], "entities": []}, {"text": "We describe the speech recognizer used for this system and its acoustic model and language model adaptation; the speech features computed based on the recognition output; and finally the scoring models based on multiple regression and classification trees.", "labels": [], "entities": []}, {"text": "For both tasks, agreement measures between machine and human scores (correlation, kappa) are close to or reach inter-human agreements.", "labels": [], "entities": [{"text": "correlation", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.9821485280990601}]}], "introductionContent": [{"text": "As demand for spoken language testing and cost of human scoring have increased in recent years, there is a growing interest in building both research and industrial systems for automatically scoring non-native speech).", "labels": [], "entities": []}, {"text": "However, past approaches have focused typically only on one type of spoken language, or on a range of types similar in linguistic entropy.", "labels": [], "entities": []}, {"text": "Entropy in this context can be seen as a measure for how predictable the language in the expected spoken response is: Some tests, such as SET-10 (Bernstein 1999), are focused mostly on the lower entropy aspects of language, using tasks such as \"reading\" or \"repetition\", where the expected sequence of words is highly predictable.", "labels": [], "entities": [{"text": "SET-10", "start_pos": 138, "end_pos": 144, "type": "TASK", "confidence": 0.587439239025116}]}, {"text": "Other assessments, such as the TOEFL\u00ae Practice Online Speaking test, on the other hand, focus on more spontaneous, high-entropy responses.", "labels": [], "entities": [{"text": "TOEFL\u00ae Practice Online Speaking", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.5865365445613862}]}, {"text": "In this paper, we describe a spoken language test with heterogeneous task types, ranging from read speech to tasks that require candidates to give their opinions on an issue, whose goal is to assess communicative competence; we call this test THT (Test with Heterogeneous Tasks).", "labels": [], "entities": []}, {"text": "Communicative competence, in this context, refers to a speaker's ability to use the language for communicative purposes.", "labels": [], "entities": []}, {"text": "The effectiveness of the communication typically consists of a few aspects including comprehensibility, accuracy, clarity, coherence and appropriateness, and is evident in a speaker's pronunciation, fluency, use of grammar and vocabulary, development of ideas, and sensitivity to the context of the communication.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9981315732002258}, {"text": "clarity", "start_pos": 114, "end_pos": 121, "type": "METRIC", "confidence": 0.986801266670227}]}, {"text": "This test has the advantage of being able to assess a wide range of non-native speakers' proficiencies by using tasks of varying difficulty levels to allow even low proficiency speakers some degree of success on easier task types.", "labels": [], "entities": []}, {"text": "We select two tasks from this test, one of higher and one of medium to high entropy, and first adapt a non-native English speech recognizer (trained on TOEFL\u00ae Practice Online data) to transcribed THT task responses, then compute a set of relevant speech features based on the recognition output, and finally build a scoring model using a subset of these features to predict trained human rater scores.", "labels": [], "entities": [{"text": "TOEFL\u00ae Practice Online data", "start_pos": 152, "end_pos": 179, "type": "DATASET", "confidence": 0.8601202726364136}]}, {"text": "In this paper, we will demonstrate that the machine-human score agreements on these two task types come close to or even exceed the level of inter-human agreement.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 discusses related work, Section 3 describes the test and the challenges for automatic scoring involved, Section 4 discusses the speech recognizer and the acoustic and language model adaptations per-formed, and Section 5 describes the speech features selected for use in the scoring model.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 174, "end_pos": 191, "type": "TASK", "confidence": 0.7022067606449127}]}, {"text": "In Section 6, we report the construction of the scoring model and its results, Section 7 contains a general discussion and Section 8 concludes the paper with a brief discussion of future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Word accuracies after each incremental  step of adaptation or optimization and performance  improvement within each step for Picture and Opin- ion task types.", "labels": [], "entities": []}, {"text": " Table 3. Performance of different weighting schemes  on THT scoring model evaluation set for Opinion  tasks (generic model)", "labels": [], "entities": [{"text": "THT scoring model evaluation set", "start_pos": 57, "end_pos": 89, "type": "DATASET", "confidence": 0.6644977807998658}]}, {"text": " Table 4. Performance of CART models on THT  scoring model evaluation set for Picture tasks (ge- neric model vs. task-specific model)", "labels": [], "entities": []}]}