{"title": [{"text": "A Resource-Poor Approach for Linking Ontology Classes to Wikipedia Articles", "labels": [], "entities": [{"text": "Linking Ontology Classes to Wikipedia", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.8704127430915832}]}], "abstractContent": [{"text": "The applicability of ontologies for natural language processing depends on the ability to link ontological concepts and relations to their realisa-tions in texts.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6977883179982504}]}, {"text": "We present a general, resource-poor account to create such a linking automatically by extracting Wikipedia articles corresponding to ontology classes.", "labels": [], "entities": []}, {"text": "We evaluate our approach in an experiment with the Music Ontology.", "labels": [], "entities": []}, {"text": "We consider linking as a promising starting point for subsequent steps of information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.8704056143760681}]}, {"text": "381 382 Reiter, Hartung, and Frank", "labels": [], "entities": []}], "introductionContent": [{"text": "Ontologies are becoming increasingly popular as a means for formal, machine-readable modelling of domain knowledge, in terms of concepts and relations.", "labels": [], "entities": []}, {"text": "Linking ontological concepts and relations to their natural language equivalents is of utmost importance for ontology-based applications in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.6442582905292511}]}, {"text": "Providing larger quantities of text that clearly belongs to a given ontological concept is a prerequisite for further steps towards ontology population with relations and instances.", "labels": [], "entities": []}, {"text": "We thus consider this work as a point of departure for future work on populating and lexicalizing ontologies, and their use in semantic processing.", "labels": [], "entities": []}, {"text": "In this paper we present a method that provides relevant textual sources fora domain ontology by linking ontological classes to the most appropriate Wikipedia articles describing the respective ontological class.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: We discuss related work in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 presents our method for linking ontology classes to Wikipedia articles.", "labels": [], "entities": []}, {"text": "The method is implemented and tested using the music ontology) and a Wikipedia dump of 2007.", "labels": [], "entities": [{"text": "Wikipedia dump of 2007", "start_pos": 69, "end_pos": 91, "type": "DATASET", "confidence": 0.9604644626379013}]}, {"text": "We present this experiment in Section 4 and its evaluation in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes and gives an outlook on directions of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiment is divided into two steps: candidate page selection and classification (see Section 3).", "labels": [], "entities": [{"text": "candidate page selection", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.6375354329744974}, {"text": "classification", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.9075162410736084}]}, {"text": "For candidate selection we extract Wikipedia pages with titles that are near-string identical to the 53 class labels.", "labels": [], "entities": [{"text": "candidate selection", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7869925498962402}]}, {"text": "28 of them are disambiguation pages.", "labels": [], "entities": []}, {"text": "From these pages, we extract the links and use them as candidates.", "labels": [], "entities": []}, {"text": "The remaining 25 are directly linked to a single Wikipedia article.", "labels": [], "entities": []}, {"text": "To test our classification features, we divide the overall set of ontology classes in training and test sets of 43 and 10 classes, respectively, that need to be associated with their most appropriate candidate article.", "labels": [], "entities": []}, {"text": "We restrict the linking to one most appropriate article.", "labels": [], "entities": []}, {"text": "For the classification step, we extract the features discussed in Section 3.", "labels": [], "entities": [{"text": "classification", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.9871869087219238}]}, {"text": "Since the candidate set of pages shows a heavily skewed distribution in favour of negative instances, we generate an additional training set by random oversampling () in order to yield training data with a more uniform distribution of positive and negative instances.", "labels": [], "entities": []}, {"text": "For evaluation, the ambiguous concepts in the ontology have been manually linked to Wikipedia articles.", "labels": [], "entities": []}, {"text": "The linking was carried out independently by three annotators, all of them computational linguists.", "labels": [], "entities": [{"text": "linking", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9666104316711426}]}, {"text": "Each annotator was presented the class label, its comment as provided by the ontology and the super class from which the class inherits.", "labels": [], "entities": []}, {"text": "On the Wikipedia side, all pages found by our candidate extraction method were presented to the annotators.", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.6907815188169479}]}, {"text": "The inter-annotator agreement is \u03ba = 0.68 (Fleiss' Kappa).", "labels": [], "entities": []}, {"text": "For eight concepts, all three annotators agreed that none of the candidate articles is appropriate and for ten all three agreed on the same article.", "labels": [], "entities": []}, {"text": "These figures underline the difficulty of the problem, as the information contained in domain ontologies and Wikipedia varies substantially with respect to granularity and structure.", "labels": [], "entities": []}, {"text": "Candidate selection yields 16 candidate articles per concept on average.", "labels": [], "entities": []}, {"text": "These articles contain 1567 tokens on average.", "labels": [], "entities": []}, {"text": "The minimal and maximal number of articles per concepts are 3 and 38, respectively.", "labels": [], "entities": [{"text": "maximal number", "start_pos": 16, "end_pos": 30, "type": "METRIC", "confidence": 0.9606821835041046}]}, {"text": "We train a decision tree 11 using both the original and the oversampled training sets as explained above.", "labels": [], "entities": []}, {"text": "displays precision, recall and f-score results for positive and negative instances as well as their average.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9996527433395386}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9994248151779175}, {"text": "f-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9903934597969055}]}, {"text": "As the data shows, oversampling can increase the performance considerably.", "labels": [], "entities": []}, {"text": "We suspect this to be caused not only by the larger training set, but primarily by the more uniform distribution.", "labels": [], "entities": []}, {"text": "The table shows further that the negative instances can be classified reliably using the original or oversampled data set.", "labels": [], "entities": []}, {"text": "However, as we intend to select positive appropriate Wikipedia articles rather than to deselect inappropriate ones, we are particularly interested in good performance for the positive instances.", "labels": [], "entities": []}, {"text": "We observe that this approach identifies positive instances (i.e., appropriate Wikipedia articles) with a reasonable performance when using the oversampled training set.", "labels": [], "entities": []}, {"text": "It is noteworthy that not a single feature performs better than with an f-measure of 0.6 when used alone.", "labels": [], "entities": []}, {"text": "The figures shown in are obtained using the combination of all features.", "labels": [], "entities": []}, {"text": "In, we present the results for the best performing features taken together (using oversampling on the training set): nountypes-classlabels (F-measure: 0.6), langlinks (0.5), redirects-classlabels (0.5), nountokens-classlabels (0.44), fulltextclasslabels (0.44).", "labels": [], "entities": []}, {"text": "Recall improves considerably, while there is a small decrease in precision.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9524114727973938}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9990490078926086}]}], "tableCaptions": [{"text": " Table 1: Results after training on original and over-sampled data", "labels": [], "entities": []}, {"text": " Table 2: Results for combination of best features only", "labels": [], "entities": []}]}