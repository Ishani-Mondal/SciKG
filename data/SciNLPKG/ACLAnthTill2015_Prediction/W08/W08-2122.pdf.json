{"title": [{"text": "A Latent Variable Model of Synchronous Parsing for Syntactic and Semantic Dependencies", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a solution to the challenge of the CoNLL 2008 shared task that uses a generative history-based latent variable model to predict the most likely derivation of asynchronous dependency parser for both syntactic and semantic dependencies.", "labels": [], "entities": [{"text": "CoNLL 2008 shared task", "start_pos": 46, "end_pos": 68, "type": "DATASET", "confidence": 0.8375758677721024}]}, {"text": "The submitted model yields 79.1% macro-average F1 performance, for the joint task, 86.9% syntactic dependencies LAS and 71.0% semantic dependencies F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9824525117874146}, {"text": "LAS", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.8826185464859009}, {"text": "F1", "start_pos": 148, "end_pos": 150, "type": "METRIC", "confidence": 0.9499398469924927}]}, {"text": "A larger model trained after the deadline achieves 80.5% macro-average F1, 87.6% syntactic dependencies LAS, and 73.1% semantic dependencies F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.956903874874115}, {"text": "LAS", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.8824805617332458}, {"text": "F1", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.9639766812324524}]}], "introductionContent": [{"text": "Successes in syntactic tasks, such as statistical parsing and tagging, have recently paved the way to statistical learning techniques for levels of semantic representation, such as recovering the logical form of a sentence for information extraction and question-answering applications (e.g. () or jointly learning the syntactic structure of the sentence and the propositional argument-structure of its main predicates (.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8209680616855621}, {"text": "information extraction", "start_pos": 227, "end_pos": 249, "type": "TASK", "confidence": 0.7646972835063934}]}, {"text": "In this vein, the CoNLL 2008 shared task sets the challenge of learning jointly both syntactic dependencies (extracted from the Penn Treebank ) and semantic dependencies (extracted both from PropBank ( and NomBank () under a unified representation.", "labels": [], "entities": [{"text": "CoNLL 2008 shared task", "start_pos": 18, "end_pos": 40, "type": "DATASET", "confidence": 0.753709465265274}, {"text": "Penn Treebank", "start_pos": 128, "end_pos": 141, "type": "DATASET", "confidence": 0.9949065744876862}, {"text": "PropBank", "start_pos": 191, "end_pos": 199, "type": "DATASET", "confidence": 0.960099458694458}]}, {"text": "We propose a solution that uses a generative history-based model to predict the most likely derivation of asynchronous dependency parser for both syntactic and semantic dependencies.", "labels": [], "entities": []}, {"text": "Our probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good behaviour for both constituency) and dependency parsing).", "labels": [], "entities": [{"text": "syntactic structure prediction", "start_pos": 127, "end_pos": 157, "type": "TASK", "confidence": 0.7353605628013611}, {"text": "dependency parsing", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.8140634298324585}]}, {"text": "The ability of ISBNs to induce their features automatically enables us to extend this architecture to learning asynchronous parse of syntax and semantics without modification of the main architecture.", "labels": [], "entities": []}, {"text": "By solving the problem with synchronous parsing, a probabilistic model is learnt which maximises the joint probability of the syntactic and semantic dependencies and thereby guarantees that the output structure is globally coherent, while at the same time building the two structures separately.", "labels": [], "entities": []}, {"text": "This extension of the ISBN architecture is therefore applicable to other problems where two independent, but related, levels of representation are being learnt, such as statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 169, "end_pos": 200, "type": "TASK", "confidence": 0.7007286051909128}]}, {"text": "Currently the largest model we have trained achieves 80.5% macro-average F1 performance for the joint task, 87.6% syntactic dependencies LAS, and 73.1% semantic dependencies F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.973846971988678}, {"text": "LAS", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.8543122410774231}, {"text": "F1", "start_pos": 174, "end_pos": 176, "type": "METRIC", "confidence": 0.9706149697303772}]}], "datasetContent": [{"text": "The experimental set-up common for all the teams is described in the introduction ().", "labels": [], "entities": []}, {"text": "The submitted model has latent variable vectors of 60 units, and a word frequency cut-off of 100, resulting in a small vocabulary of 1083 words.", "labels": [], "entities": []}, {"text": "We used abeam of size 15 to prune derivations after each shift operation to obtain the joint structure, and abeam of size 40 when performing the marginalisation.", "labels": [], "entities": []}, {"text": "Training took approximately 2.5 days on a standard PC with 3.0 GHz Pentium4 CPU.", "labels": [], "entities": []}, {"text": "It took approximately 2 hours to parse the entire testing set (2,824 sentences) and an additional 3 hours to perform syntactic parsing when marginalising out the semantic structures.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7063156366348267}]}, {"text": "Shortly after the submission deadline, we trained a 'large' model with a latent variable vector of size 80, a word frequency cut-off of 20, and additional latent-to-latent connections from semantics to syntax of the same configuration as the last column  To explore the relationship between the two components of the model, we removed the edges between the syntax and the semantics in the submitted model.", "labels": [], "entities": []}, {"text": "This model's performance drops by about 3.5% for semantic role labelling, thereby indicating that the latent annotation of parsing states helps semantic role labelling.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7191330393155416}, {"text": "semantic role labelling", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.7097083926200867}]}, {"text": "However, it also indicates that there is much room for improvement in developing useful semantic-specific features, which was not done for these experiments simply due to constraints on development time.", "labels": [], "entities": []}, {"text": "To test whether joint learning degrades the accuracy of the syntactic parsing model, we trained a syntactic parsing model with the same features and the same pattern of interconnections as used for the syntactic states in our joint model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9991664886474609}, {"text": "syntactic parsing", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.6687804758548737}]}, {"text": "The resulting labelled attachment score was non-significantly lower (0.2%) than the score for the marginalised inference with the joint model.", "labels": [], "entities": [{"text": "labelled attachment score", "start_pos": 14, "end_pos": 39, "type": "METRIC", "confidence": 0.8286125858624777}]}, {"text": "This result suggests that, though the latent variables associated with syntactic states in the joint model were trained to be useful in semantic role labelling, this did not have a negative effect on syntactic parsing accuracy, and may even have helped.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.6626189351081848}, {"text": "syntactic parsing", "start_pos": 200, "end_pos": 217, "type": "TASK", "confidence": 0.8251762688159943}, {"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.9020411968231201}]}, {"text": "Finally, an analysis of the errors on the development set for the submitted model paints a coherent picture.", "labels": [], "entities": []}, {"text": "We find attachment of adjuncts particularly hard.", "labels": [], "entities": []}, {"text": "For dependency labels, we make the most mistakes on modification labels, while for semantic labels, we find TMP, ADV, LOC, and PRN particularly hard.", "labels": [], "entities": []}, {"text": "NomBank arcs are not learnt as well as PropBank arcs: we identify PropBank SRL arguments at F1 70.8% while Nombank arguments reach 58.1%, and predicates at accuracy 87.9% for PropBank and 74.9% for NomBank.", "labels": [], "entities": [{"text": "PropBank SRL", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.7808653712272644}, {"text": "F1", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9955109357833862}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9990369081497192}, {"text": "PropBank", "start_pos": 175, "end_pos": 183, "type": "DATASET", "confidence": 0.9733642935752869}]}], "tableCaptions": [{"text": " Table 3: Scores on the development set and the  final testing sets (percentages). D= development  set; W=WSJ; B=Brown; WB=WSJ+Brown;", "labels": [], "entities": [{"text": "WSJ", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.8607168197631836}, {"text": "Brown", "start_pos": 113, "end_pos": 118, "type": "METRIC", "confidence": 0.7983930706977844}, {"text": "WSJ", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.7668521404266357}]}]}