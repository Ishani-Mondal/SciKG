{"title": [{"text": "Mixture Pruning and Roughening for Scalable Acoustic Models", "labels": [], "entities": []}], "abstractContent": [{"text": "In an automatic speech recognition system using a tied-mixture acoustic model, the main cost in CPU time and memory lies not in the evaluation and storage of Gaussians themselves but rather in evaluating the mixture likelihoods for each state output distribution.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.6706406474113464}]}, {"text": "Using a simple entropy-based technique for pruning the mixture weight distributions, we can achieve a significant speedup in recognition fora 5000-word vocabulary with a negligible increase in word error rate.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 193, "end_pos": 208, "type": "METRIC", "confidence": 0.7803206443786621}]}, {"text": "This allows us to achieve real-time connected-word dictation on an ARM-based mobile device.", "labels": [], "entities": []}], "introductionContent": [{"text": "As transistors shrink and CPUs become faster and more power-efficient, we find ourselves entering anew age of intelligent mobile devices.", "labels": [], "entities": []}, {"text": "We believe that not only will these devices provide access to rich sources of on-line information and entertainment, but they themselves will find new applications as personal knowledge management agents.", "labels": [], "entities": []}, {"text": "Given the constraints of the mobile form factor, natural speech input is crucial to these applications.", "labels": [], "entities": []}, {"text": "However, despite the advances in processor technology, mobile devices are still highly constrained by their memory and storage subsystems.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments in this paper were performed using PocketSphinx).", "labels": [], "entities": [{"text": "PocketSphinx", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.9508172273635864}]}, {"text": "The baseline acoustic model was trained from the combined WSJ0 and WSJ1 \"long\" training sets, fora total of 192 hours of speech.", "labels": [], "entities": [{"text": "WSJ0", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9591483473777771}, {"text": "WSJ1", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.7934001684188843}]}, {"text": "This speech was converted to MFCC features using a bank of 20 mel-scale filters spaced from 0 to 4000Hz, allowing the model to work with audio sampled at 8kHz, as is typical on mobile devices.", "labels": [], "entities": []}, {"text": "We used 5-state Hidden Markov Models for all phones.", "labels": [], "entities": []}, {"text": "Output distributions were modeled by a codebook of 256 Gaussians, shared between 5000 tied states and 220 context-independent states.", "labels": [], "entities": []}, {"text": "Only the first pass of recognition (static lexicon tree search) was performed.", "labels": [], "entities": []}, {"text": "Our test platform is the Nokia N800, a handheld Internet Tablet.", "labels": [], "entities": [{"text": "Nokia N800", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.9286867678165436}]}, {"text": "It uses a Texas Instruments OMAP TM 2420 processor, which combines an ARM11 RISC core and a C55x DSP core on a single chip.", "labels": [], "entities": [{"text": "Texas Instruments OMAP TM 2420 processor", "start_pos": 10, "end_pos": 50, "type": "DATASET", "confidence": 0.8941440482934316}]}, {"text": "The RISC core is clocked at 400MHz while the DSP is clocked at 220MHz.", "labels": [], "entities": []}, {"text": "In these experiments, we used the ARM core for all processing, although we have also ported the MFCC extraction code to the DSP.", "labels": [], "entities": [{"text": "MFCC extraction", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.6772098541259766}, {"text": "DSP", "start_pos": 124, "end_pos": 127, "type": "DATASET", "confidence": 0.9477959275245667}]}, {"text": "The decoder binaries, models and audio files were stored on a high-speed SD flashcard formatted with the ext3 journaling filesystem.", "labels": [], "entities": []}, {"text": "Using the standard bcb05cnp bigram language model, we obtained a baseline word error rate of 9.46% on the si_et_05 test set.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 74, "end_pos": 89, "type": "METRIC", "confidence": 0.6613294978936514}, {"text": "si_et_05 test set", "start_pos": 106, "end_pos": 123, "type": "DATASET", "confidence": 0.7840600439480373}]}, {"text": "The baseline performance of this platform on the test set is 1.40 times real-time, that is, for every second of speech, 1.40 seconds of CPU time are required for recognition.", "labels": [], "entities": []}, {"text": "We used the oprofile utility 1 on the Nokia N800 to collect statistical profiling information fora subset of the test corpus.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We can see that three operations occupy the vast majority of CPU time used in decoding: managing the list of active HMM states, computing the codebook of Gaussians, and computing mixture densities.", "labels": [], "entities": []}, {"text": "The size of the files in the acoustic model is shown in.", "labels": [], "entities": []}, {"text": "While other work on efficient recognition has focused on quantization of the Gaussian parameters  enough that little cost is incurred by storing and calculating them as 32-bit fixed-point numbers.", "labels": [], "entities": [{"text": "efficient recognition", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.8041245937347412}]}, {"text": "Therefore, we focus hereon ways to reduce the amount of storage and computation used by the mixture weight distributions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. The amount of CPU time required to", "labels": [], "entities": []}, {"text": " Table 1: CPU profiling, OMAP platform", "labels": [], "entities": []}, {"text": " Table 2: File sizes, WSJ1 acoustic model", "labels": [], "entities": []}, {"text": " Table 3: Data cache misses (units of 10 7 )", "labels": [], "entities": [{"text": "Data cache misses", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.5553344885508219}]}]}