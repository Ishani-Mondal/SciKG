{"title": [], "abstractContent": [{"text": "Speech-to-text summarization systems usually take as input the output of an automatic speech recognition (ASR) system that is affected by issues like speech recognition errors, disfluencies, or difficulties in the accurate identification of sentence boundaries.", "labels": [], "entities": [{"text": "Speech-to-text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6441241353750229}, {"text": "automatic speech recognition (ASR)", "start_pos": 76, "end_pos": 110, "type": "TASK", "confidence": 0.7927376627922058}]}, {"text": "We propose the inclusion of related, solid background information to cope with the difficulties of summarizing spoken language and the use of multi-document summarization techniques in single document speech-to-text summarization.", "labels": [], "entities": [{"text": "summarizing spoken language", "start_pos": 99, "end_pos": 126, "type": "TASK", "confidence": 0.9144493937492371}, {"text": "multi-document summarization", "start_pos": 142, "end_pos": 170, "type": "TASK", "confidence": 0.5238621383905411}, {"text": "single document speech-to-text summarization", "start_pos": 185, "end_pos": 229, "type": "TASK", "confidence": 0.5783438831567764}]}, {"text": "In this work, we explore the possibilities offered by pho-netic information to select the background information and conduct a perceptual evaluation to better assess the relevance of the inclusion of that information.", "labels": [], "entities": []}, {"text": "Results show that summaries generated using this approach are considerably better than those produced by an up-to-date latent semantic analysis (LSA) summarization method and suggest that humans prefer summaries restricted to the information conveyed in the input source.", "labels": [], "entities": [{"text": "summaries generated", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.8998197019100189}, {"text": "latent semantic analysis (LSA) summarization", "start_pos": 119, "end_pos": 163, "type": "TASK", "confidence": 0.6163973637989589}]}], "introductionContent": [{"text": "News have been the subject of summarization fora longtime, demonstrating the importance of both the subject and the process.", "labels": [], "entities": []}, {"text": "Systems like NewsInEssence (), Newsblaster (), or even Google News substantiate this relevance that is also supported by the spoken language scenario, where most speech summarization systems concentrate on broadcast news).", "labels": [], "entities": [{"text": "Newsblaster", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.9514381885528564}, {"text": "speech summarization", "start_pos": 162, "end_pos": 182, "type": "TASK", "confidence": 0.6790889799594879}]}, {"text": "Nevertheless, although the pioneering efforts on summarization go back to the work of and, it is only after the renaissance of summarization as a research area of great activity-following upon the Dagstuhl Seminar-that the first multi-document news summarization system, SUMMONS, makes its breakthrough (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9896570444107056}, {"text": "summarization", "start_pos": 127, "end_pos": 140, "type": "TASK", "confidence": 0.9758129119873047}, {"text": "Dagstuhl Seminar-that", "start_pos": 197, "end_pos": 218, "type": "DATASET", "confidence": 0.960424393415451}, {"text": "multi-document news summarization", "start_pos": 229, "end_pos": 262, "type": "TASK", "confidence": 0.608473390340805}]}, {"text": "In what concerns speech summarization, the state of affairs is more problematic: news summarization systems appeared later and still focus only on single document summarization).", "labels": [], "entities": [{"text": "speech summarization", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.6822505295276642}, {"text": "news summarization", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.6854885220527649}]}, {"text": "In fact, while text summarization has attained some degree of success) due to the considerable body of work, speech summarization still requires further research, both in speech and text analysis, in order to overcome the specific challenges of the task (.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8141860365867615}, {"text": "speech summarization", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.7275337278842926}, {"text": "text analysis", "start_pos": 182, "end_pos": 195, "type": "TASK", "confidence": 0.6944033950567245}]}, {"text": "Issues like speech recognition errors, disfluencies, and difficulties in accurately identifying sentence boundaries must betaken into account when summarizing spoken language.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.6620007902383804}, {"text": "summarizing spoken language", "start_pos": 147, "end_pos": 174, "type": "TASK", "confidence": 0.9004678130149841}]}, {"text": "However, if on the one hand, recognition errors seem not to have a considerable impact on the summarization task (), on the other hand, spoken language summarization systems often explore ways of minimizing that impact).", "labels": [], "entities": [{"text": "summarization task", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8966029584407806}]}, {"text": "We argue that by including related solid background information from a different source less prone to this kind of errors (e.g., a textual source) in the summarization process, we are able to reduce the influence of recognition errors on the resulting summary.", "labels": [], "entities": []}, {"text": "To support this argument, we developed anew approach to speech-to-text summarization that combines information from multiple information sources to produce a summary driven by the spoken language document to be summarized.", "labels": [], "entities": [{"text": "speech-to-text summarization", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.630253940820694}]}, {"text": "The idea mimics the natural human behavior, in which information acquired from different sources is used to build a better understanding of a given topic (.", "labels": [], "entities": []}, {"text": "Furthermore, we build on the conjecture that this background information is often used by humans to overcome perception difficulties.", "labels": [], "entities": []}, {"text": "In that sense, one of our goals is also to understand what is expected in a summary: a comprehensive, shorter, text that addresses the same subject of the input source to be summarized (possibly introducing new information); or a text restricted to the information conveyed in the input source.", "labels": [], "entities": []}, {"text": "This work explores the use of phonetic domain information to overcome speech recognition errors and disfluencies.", "labels": [], "entities": []}, {"text": "Instead of using the traditional output of the ASR module, we use the phonetic transliteration of the output and compare it to the phonetic transliteration of solid background information.", "labels": [], "entities": [{"text": "ASR", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9588466286659241}]}, {"text": "This enables the use of text, related to the input source, free from the common speech recognition issues, in further processing.", "labels": [], "entities": [{"text": "common speech recognition", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.6705086827278137}]}, {"text": "We use broadcast news as a case study and news stories from online newspapers provide the background information.", "labels": [], "entities": []}, {"text": "Media monitoring systems, used to transcribe and disseminate news, provide an adequate framework to test the proposed method.", "labels": [], "entities": []}, {"text": "This document is organized as follows: section 2 briefly introduces the related work; section 3 presents a characterization of the speech-to-text summarization problem and how we propose to address it; section 4 explicits our use of phonetic domain information, given the previously defined context; the next section describes the case study, including the experimental setup and results; conclusions close the document.", "labels": [], "entities": [{"text": "speech-to-text summarization problem", "start_pos": 131, "end_pos": 167, "type": "TASK", "confidence": 0.6504944860935211}]}], "datasetContent": [{"text": "Our main objective was to understand if it is possible to select relevant information from background information that could improve the quality of speech-to-text summaries.", "labels": [], "entities": []}, {"text": "To assess the validity of this hypothesis, five different processes of generating a summary were considered.", "labels": [], "entities": []}, {"text": "To better analyze the influence of the background information, all automatic summarization methods are based on the up-to-date LSA method previously described: one taking as input only the news story to be summarized (Simple) and used as baseline; other taking as input only the selected background information (Background only); and, the last one, using both the news story and the background information (Background + News).", "labels": [], "entities": []}, {"text": "The other two processes were human: extractive (using only the news story) and abstractive (understanding the news story and condensing it by means of paraphrase).", "labels": [], "entities": []}, {"text": "Since the abstractive summaries had already been created, summary size was determined by their size (which means creating summaries using a compression rate of around 10% of the original size).", "labels": [], "entities": []}, {"text": "As mentioned before, the whole summarization process begins with the selection of the background information.", "labels": [], "entities": [{"text": "summarization", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.977215588092804}]}, {"text": "Using the threshold estimated as described in section 4.2 and the method described in section 4.1 to compute similarity between sentence-like units, no background information was selected for 11 of the 26 news stories of the test corpus.", "labels": [], "entities": []}, {"text": "For the remaining 15 news stories, summaries were generated using the three automatic summarization strategies described before.", "labels": [], "entities": [{"text": "summaries", "start_pos": 35, "end_pos": 44, "type": "TASK", "confidence": 0.9662917852401733}]}, {"text": "In what concerns the evaluation process, although ROUGE) is the most common evaluation metric for the automatic evaluation of summarization, since our approach might introduce in the summary information that it is not present in the original input source, we found that a human evaluation was more adequate to assess the relevance of that additional information.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9907369017601013}, {"text": "summarization", "start_pos": 126, "end_pos": 139, "type": "TASK", "confidence": 0.844612181186676}]}, {"text": "A perceptual evaluation is also adequate to assess the perceive quality of the summaries and a better indicator of the what is expected to be in a summary.", "labels": [], "entities": []}, {"text": "We asked an heterogeneous group of sixteen people to evaluate the summaries created for the 15 news stories for which background information was selected.", "labels": [], "entities": []}, {"text": "Each evaluator was given, for each story, the news story itself (without background information) and five summaries, corresponding to the five different methods presented before.", "labels": [], "entities": []}, {"text": "The evaluation procedure consisted in identifying the best summary and in the classification of each summary (1-5, 5 is better) according to its content and readability (which covers issues like grammaticality, existence of redundant information, or entity references).", "labels": [], "entities": []}, {"text": "Surprisingly enough (see figures 2 and 3), in general, the extractive human summaries were preferred over the abstractive ones.", "labels": [], "entities": []}, {"text": "Moreover, the summaries generated automatically using background information (exclusively or not) were also selected as best summary (over the human created ones) a non-negligible number of times.", "labels": [], "entities": []}, {"text": "The poorest performance was attained, as expected, by the simple LSA summarizer, only preferred on two news stories for which all summaries were very similar.", "labels": [], "entities": [{"text": "LSA summarizer", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.8461036682128906}]}, {"text": "The results of the two approaches using background information were very close, a result that can be explained by the fact the summaries generated by these two approaches were equal for 11 of the 15 news stories (in the remaining 4, the average distribution was 31.25% from the news story versus 68.75% from the background information).", "labels": [], "entities": []}, {"text": "further discriminates the results in terms of content and readability.", "labels": [], "entities": []}, {"text": "Regarding content, the results suggest that the choice of the best summary is highly correlated with its content, as the average content scores mimic the overall ones of.", "labels": [], "entities": []}, {"text": "In what concerns readability, the summaries generated using background information achieved the best results.", "labels": [], "entities": []}, {"text": "The reasons underlying these results are that the newspaper writing is naturally better planned than speech and that speech transcriptions are affected by the several problems described before (and the original motivation for the work), hence the idea of using them as background information.", "labels": [], "entities": []}, {"text": "However, what is odd is that the result obtained by the human abstractive summary creation method is worse than the ones obtained by automatic generation using background information, which could suffer from coherence and cohesion problems.", "labels": [], "entities": [{"text": "human abstractive summary creation", "start_pos": 56, "end_pos": 90, "type": "TASK", "confidence": 0.6423326060175896}]}, {"text": "One possible explanation is that the human abstractive summaries tend to mix both informa-tive and indicative styles of summary.", "labels": [], "entities": []}, {"text": "Figure 5 presents the standard deviation for content and readability scores: concerning content, automatically generated summaries using background information achieved the highest standard deviation scores (see also fora sample story).", "labels": [], "entities": []}, {"text": "That is in part supported by some commentaries made by the human evaluators on whether a summary should contain information that is not present in the input source.", "labels": [], "entities": []}, {"text": "This aspect and the obtained results, suggest that this issue should be further analyzed, possibly using an extrinsic evaluation setup.", "labels": [], "entities": []}, {"text": "On the other hand, readability standard deviation scores show that there is a considerable agreement in what concerns this criterion.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Broadcast news corpus composition.", "labels": [], "entities": [{"text": "Broadcast news corpus composition", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.6214508712291718}]}]}