{"title": [{"text": "From Predicting Predominant Senses to Local Context for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.6961258153120676}]}], "abstractContent": [{"text": "Recent work on automatically predicting the predominant sense of a word has proven to be promising (McCarthy et al., 2004).", "labels": [], "entities": [{"text": "automatically predicting the predominant sense of a word", "start_pos": 15, "end_pos": 71, "type": "TASK", "confidence": 0.7710193209350109}]}, {"text": "It can be applied (as a first sense heuristic) to Word Sense Disambiguation (WSD) tasks, without needing expensive hand-annotated data sets.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD) tasks", "start_pos": 50, "end_pos": 87, "type": "TASK", "confidence": 0.7789917247635978}]}, {"text": "Due to the big skew in the sense distribution of many words (Yarowsky and Florian, 2002), the First Sense heuristic for WSD is often hard to beat.", "labels": [], "entities": [{"text": "WSD", "start_pos": 120, "end_pos": 123, "type": "TASK", "confidence": 0.9550948739051819}]}, {"text": "However, the local context of an ambiguous word can give important clues to which of its senses was intended.", "labels": [], "entities": []}, {"text": "The sense ranking method proposed by McCarthy et al.", "labels": [], "entities": [{"text": "sense ranking", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.875567764043808}]}, {"text": "(2004) uses a distributional similarity thesaurus.", "labels": [], "entities": []}, {"text": "The k nearest neighbours in the thesaurus are used to establish the predominant sense of a word.", "labels": [], "entities": []}, {"text": "In this paper we report on a first investigation on how to use the grammatical relations the target word is involved with, in order to select a subset of the neighbours from the automatically created thesaurus, to take the local context into account.", "labels": [], "entities": []}, {"text": "This unsupervised method is quantitatively evaluated on SemCor.", "labels": [], "entities": [{"text": "SemCor", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.8850388526916504}]}, {"text": "We found a slight improvement in precision over using the predicted first sense.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9995129108428955}]}, {"text": "Finally, we discuss strengths and weaknesses of the method and suggest ways to improve the results in the future.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, a lot of research was done on establishing the predominant sense of ambiguous words automatically using untagged texts (.", "labels": [], "entities": []}, {"text": "The motivation for that work is twofold: on the one hand it builds on the strength of the first sense heuristic in Word Sense Disambiguation (WSD) (i.e. the heuristic of choosing the most commonly used sense of a word, irrespective of the context in which the word occurs) and on the other hand it recognizes that manually created resources for establishing word sense distributions are expensive to create and therefore hard to find.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 115, "end_pos": 146, "type": "TASK", "confidence": 0.7304028371969858}]}, {"text": "The one resource that is used most widely, SemCor, is only available for English and only representative for 'general' (non domain specific) text.", "labels": [], "entities": []}, {"text": "McCarthy et al's method was successfully applied to a corpus of modern English text (the BNC) and the predicted predominant senses compared well with the gold standard given by SemCor.", "labels": [], "entities": [{"text": "BNC)", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.8656973838806152}]}, {"text": "Other experiments showed that the method can successfully be adapted to domain specific text () and other languages (for example, Japanese ().", "labels": [], "entities": []}, {"text": "Even though the first sense heuristic is powerful, it would be preferable to only use it for WSD, when either the sense distribution is so skewed that the most commonly used sense is by far the most dominant, or as a back-off when few other clues are available to decide otherwise.", "labels": [], "entities": [{"text": "WSD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9202748537063599}]}, {"text": "The use of local context is ultimately necessary to find evidence for the intended sense of an ambiguous word.", "labels": [], "entities": []}, {"text": "In this paper we investigate how we can exploit results from intermediate steps taken when calculating the predominant senses to this end.", "labels": [], "entities": []}, {"text": "The work on automatically finding predominant senses 1 was partly inspired by the observation that you can identify word senses by looking at the nearest neighbours of a target word in a distributional thesaurus.", "labels": [], "entities": [{"text": "automatically finding predominant senses 1", "start_pos": 12, "end_pos": 54, "type": "TASK", "confidence": 0.6876810908317565}]}, {"text": "For example, consider the following (simplified) entry for the word plant in such a thesaurus (omitting the scores for distributional similarity): (9) (9) plant : factory, industry, facility, business, company, species, tree, crop, engine, flower, farm, leaf, market, garden, field, seed, shrub...", "labels": [], "entities": [{"text": "9) plant : factory, industry, facility, business, company, species, tree, crop, engine, flower, farm, leaf, market, garden, field, seed, shrub...", "start_pos": 152, "end_pos": 297, "type": "Description", "confidence": 0.824028743725074}]}, {"text": "Just by looking at the neighbours you can identify two main groups of neighbours, each pointing at separate senses of the word.", "labels": [], "entities": []}, {"text": "First there is the set of words consisting of factory, industry, facility, business, company, engine that hint at the 'industrial plant' sense of the word and then there is the set consisting of tree, crop, flower, leaf, species, garden, field, seed, shrub that are more closely related to the 'flora' sense of the word.", "labels": [], "entities": []}, {"text": "A few words, like farm and possibly market could be associated equally strongly with either sense.", "labels": [], "entities": []}, {"text": "The idea behind 'sense ranking' is, that the right mix of 1.", "labels": [], "entities": []}, {"text": "number of neighbours with a strong associations with one or more of the senses, 2.", "labels": [], "entities": []}, {"text": "the strength of the association (semantic similarity) between neighbour and sense and 3.", "labels": [], "entities": []}, {"text": "the strength of the distributional similarity of the contributing neighbour and the target word, will allow us to estimate the relative importance (i.e. frequency of use) of each sense.", "labels": [], "entities": []}, {"text": "What we want to explore here, is how we can use the local context of an occurrence of the target word, to select a subset of these neighbours.", "labels": [], "entities": []}, {"text": "This subset should consist of words that are related more strongly to the sense of the word in the target sentence.", "labels": [], "entities": []}, {"text": "For example, consider the word plant in a sentence like: (10) (10) The gardener grows plants from vegetable seeds.", "labels": [], "entities": []}, {"text": "Plant is used in this sentence as the 'subject of grow'.", "labels": [], "entities": []}, {"text": "A simple way of zooming in on potentially relevant neighbours is by using the most informative contexts shared between neighbours and the word in the target sentence.", "labels": [], "entities": []}, {"text": "This is implemented by selecting just those words that occur in the same grammatical context (i.e. as subject of the verb 'grow') in a reference corpus 2 . If we apply that to the example in 9, we end up with the following subset: business, industry, species, tree, crop, flower, seed, shrub.", "labels": [], "entities": []}, {"text": "Even though the first two words are still associated with the 'industrial plant' sense, we can see that the majority of the words in this subset is strongly associated with the intended sense.", "labels": [], "entities": []}, {"text": "In the next section we first give a quick introduction to the sense ranking algorithm introduced in.", "labels": [], "entities": [{"text": "sense ranking", "start_pos": 62, "end_pos": 75, "type": "TASK", "confidence": 0.7751596570014954}]}, {"text": "Then we explain how we can use the database of grammatical relations that we used for creating the thesaurus, for selecting a subset of neighbours in the thesaurus.", "labels": [], "entities": []}, {"text": "The following section describes an evaluation performed on the SemCor data.", "labels": [], "entities": [{"text": "SemCor data", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.8012682497501373}]}, {"text": "In the last two sections we discuss the results and especially why both recall and precision are lower than we had hoped and what can be done to improve the results.", "labels": [], "entities": [{"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9992519021034241}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9986616373062134}]}], "datasetContent": [{"text": "The example in the last section shows that in certain cases the method performs the way we envisaged.", "labels": [], "entities": []}, {"text": "However, we need a quantitative evaluation to get a proper picture of the method's usefulness.", "labels": [], "entities": []}, {"text": "We performed a full evaluation on SemCor.", "labels": [], "entities": []}, {"text": "In this experiment we limited our attention to nouns only.", "labels": [], "entities": []}, {"text": "We further eliminated Proper Names and multi-word units from the test set.", "labels": [], "entities": []}, {"text": "Since the nouns in both these categories are mostly monosemous, they are less interesting as test material and apart from that, they introduce problems (mostly parser related) that have little to do with the proposed method.", "labels": [], "entities": []}, {"text": "A total of 73,918 words were left to evaluate.", "labels": [], "entities": []}, {"text": "The figure for recall for the 'First Sense' method is not given, because we want to contrast the local context method with the first sense method.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9985771179199219}]}, {"text": "Whilst the first sense method will return an answer inmost cases, the local context method proposed in this paper will not.", "labels": [], "entities": []}, {"text": "Here we want to focus on how we can improve on using the first sense heuristic by taking local context into account, rather than give complete results fora WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 156, "end_pos": 164, "type": "TASK", "confidence": 0.857410728931427}]}, {"text": "There are several things to say about these results.", "labels": [], "entities": []}, {"text": "First of all, even though the results for 'local context' are slightly better than for 'first sense', we expected more from it.", "labels": [], "entities": []}, {"text": "We had identified quite a few cases like 13 and 14 above, where the local context seemed to be able to help to identify the right neigbours in order to make the difference.", "labels": [], "entities": []}, {"text": "Below, we will discuss a few cases where the grammatical relations involved are so general, that the subset of neighbours is large and most importantly, not discriminative enough.", "labels": [], "entities": []}, {"text": "It seems to be reasonable to expect that the latter cases will not influence the precision too much (i.e. a smaller group of neighbours will often give a different result, but some better, some worse).", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9994708895683289}]}, {"text": "The recall is also lower than expected.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9996055960655212}]}, {"text": "The first thought was that data sparseness was the main problem here, but additional experiments showed us that that is unlike to be the case.", "labels": [], "entities": []}, {"text": "In one experiment we took apart of the GigaWord corpus, similar in size to the written part of the BNC (used in our original experiment) and built our grammatical relation database using the combined corpus.", "labels": [], "entities": [{"text": "GigaWord corpus", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9439853131771088}]}, {"text": "The recall went up a little, but at the price of a slightly lower precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9952144622802734}, {"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9984923601150513}]}], "tableCaptions": [{"text": " Table 1: Results of evaluation on the nouns in SemCor  Method  Attempted Correct Wrong Precision Recall  Local Context  23,235  11,904  11,331  0.512  0.161  First sense  23,235  11,795  11,440  0.508  \u2212", "labels": [], "entities": []}]}