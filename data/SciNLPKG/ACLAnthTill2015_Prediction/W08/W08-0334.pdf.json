{"title": [{"text": "Dynamic Model Interpolation for Statistical Machine Translation", "labels": [], "entities": [{"text": "Dynamic Model Interpolation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7235165437062582}, {"text": "Statistical Machine Translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.8308145006497701}]}], "abstractContent": [{"text": "This paper presents a technique for class-dependent decoding for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 65, "end_pos": 102, "type": "TASK", "confidence": 0.8307110965251923}]}, {"text": "The approach differs from previous methods of class-dependent translation in that the class-dependent forms of all models are integrated directly into the decoding process.", "labels": [], "entities": [{"text": "class-dependent translation", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6918387115001678}]}, {"text": "We employ probabilistic mixture weights between models that can change dynamically on a segment-by-segment basis depending on the characteristics of the source segment.", "labels": [], "entities": []}, {"text": "The effectiveness of this approach is demonstrated by evaluating its performance on travel conversation data.", "labels": [], "entities": []}, {"text": "We used the approach to tackle the translation of questions and declarative sentences using class-dependent models.", "labels": [], "entities": [{"text": "translation of questions and declarative sentences", "start_pos": 35, "end_pos": 85, "type": "TASK", "confidence": 0.8633723656336466}]}, {"text": "To achieve this, our system integrated two sets of models specifically built to deal with sentences that fall into one of two classes of dialog sentence: questions and declarations , with a third set of models built to handle the general class.", "labels": [], "entities": []}, {"text": "The technique was thoroughly evaluated on data from 17 language pairs using 6 machine translation evaluation metrics.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 78, "end_pos": 108, "type": "TASK", "confidence": 0.7598944703737894}]}, {"text": "We found the results were corpus-dependent, but inmost cases our system was able to improve translation performance , and for some languages the improvements were substantial.", "labels": [], "entities": [{"text": "translation", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.9646900296211243}]}], "introductionContent": [{"text": "Topic-dependent modeling has proven to bean effective way to improve quality the quality of models in speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7934202551841736}]}, {"text": "Recently, experiments in the field of machine translation have shown that classspecific models are also useful for translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.790849506855011}, {"text": "translation", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.9714592695236206}]}, {"text": "In the method proposed by, topic dependency was implemented by partitioning the data into sets before the decoding process commenced, and subsequently decoding these sets independently using different models that were specific to the class predicted for the source sentence by a classifier that was run over the source sentences in a pre-processing pass.", "labels": [], "entities": []}, {"text": "Our approach is in many ways a generalization of this work.", "labels": [], "entities": []}, {"text": "Our technique allows the use of multiplemodel sets within the decoding process itself.", "labels": [], "entities": []}, {"text": "The contributions of each model set can be controlled dynamically during the decoding through a set of interpolation weights.", "labels": [], "entities": []}, {"text": "These weights can be changed on a sentence-by-sentence basis.", "labels": [], "entities": []}, {"text": "The previous approach is, in essence, the case where the interpolation weights are either 1 (indicating that the source sentence is the same topic as the model) or 0 (the source sentence is a different topic).", "labels": [], "entities": []}, {"text": "One advantage of our proposed technique is that it is a soft approach.", "labels": [], "entities": []}, {"text": "That is, the source sentence can belong to multiple classes to varying degrees.", "labels": [], "entities": []}, {"text": "In this respect our approach is similar to that of, however we used a probabilistic classifier to determine a vector of probabilities representing class-membership, rather than distancebased weights.", "labels": [], "entities": []}, {"text": "These probabilities were used directly as the mixture weights for the respective models in an interpolated model-set.", "labels": [], "entities": []}, {"text": "A second difference between our approach and that of Foster and Kuhn, is that we include a general model built from all of the data along with the set of classspecific models.", "labels": [], "entities": []}, {"text": "Our approach differs from all previous approaches in the models that are class-dependent.", "labels": [], "entities": []}, {"text": "used only a class-dependent language model.", "labels": [], "entities": []}, {"text": "Both and, extended this to include the translation model.", "labels": [], "entities": [{"text": "translation", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.9799461960792542}]}, {"text": "In our approach we combine all of the models, including the distortion and target length models, in the SMT system within a single framework.", "labels": [], "entities": [{"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.9880344271659851}]}, {"text": "The contribution of this paper is two-fold.", "labels": [], "entities": []}, {"text": "The first is the proposal of a technique for combining multiple SMT systems in a weighted manner to allow probabilistic soft weighting between topicdependent models for all models in the system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9895743727684021}]}, {"text": "The second is the application of this technique to improve the quality of dialog systems by building and combing class-based models for interrogative and declarative sentences.", "labels": [], "entities": []}, {"text": "For the purposes of this paper, we wish to make the distinction between interrogative sentences and those which are not.", "labels": [], "entities": []}, {"text": "For the sake of simplicity of expression we will call those sentences which are interrogative, questions and those which are not, declarations for the remainder of this article.", "labels": [], "entities": []}, {"text": "The techniques proposed here were evaluated on a variety of different languages.", "labels": [], "entities": []}, {"text": "We enumerate them below as a key: Arabic (ar), Danish (da), German (de), English (en), Spanish (es), French (fr), Indonesian (Malay) (id), Italian (it), Japanese (ja), Korean (ko), Malaysian (Malay) (ms), Dutch (nl), Portugese (pt), Russian (ru), Thai (th), Vietnamese (vi) and Chinese (zh).", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the proposed technique, we conducted experiments on a travel conversation corpus.", "labels": [], "entities": []}, {"text": "The experimental corpus was the travel arrangement task of the BTEC corpus ( and used English as the target and each of the other languages as source languages.", "labels": [], "entities": [{"text": "BTEC corpus", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.9744581878185272}]}, {"text": "The training, development, and evaluation corpus statistics are shown in shows the overall structure of our system.", "labels": [], "entities": []}, {"text": "We used punctuation (a sentence-final '?' character) on the target-side as the ground truth as to the class of the target sentence.", "labels": [], "entities": []}, {"text": "Neither punctuation nor case information was used for any other purpose in the experiments.", "labels": [], "entities": []}, {"text": "The data were partitioned into classes, and further sub-divided into training and development sets for each class.", "labels": [], "entities": []}, {"text": "1000 sentences were set aside as development data, and the remainder was used for training.", "labels": [], "entities": []}, {"text": "Three complete SMT systems were built: one for each class, and one on the data from both classes.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9943377375602722}]}, {"text": "A probabilistic classifier (described in the next section) was also trained from the full set of training data.", "labels": [], "entities": []}, {"text": "To obtain a balanced view of the merits of our proposed approach, in our experiments we used 6 evaluation techniques to evaluate our systems.", "labels": [], "entities": []}, {"text": "These were: BLEU (Papineni, 2001), NIST), WER (Word Error Rate), PER (Position-independent WER), GTM (General Text Matcher), and METEOR (Banerjee and Lavie, 2005).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9990457892417908}, {"text": "NIST", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.8679393529891968}, {"text": "WER (Word Error Rate)", "start_pos": 42, "end_pos": 63, "type": "METRIC", "confidence": 0.8423396199941635}, {"text": "PER", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9557227492332458}, {"text": "General Text Matcher)", "start_pos": 102, "end_pos": 123, "type": "TASK", "confidence": 0.6503010466694832}, {"text": "METEOR", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9293683767318726}]}], "tableCaptions": [{"text": " Table 1. The corpus statistics of the target language corpus (en). The number of sentences is the same as  these values for all source languaes. The number of words in the source language differs, and depends  on the segmentation granularity.", "labels": [], "entities": []}, {"text": " Table 2. The classifcation accuracy (%) of the  classifier used to predict whether or not an input  sentence either is or should give rise to a question in  the target.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9390117526054382}]}, {"text": " Table 3. Performance results translating from a number of source languages into English. Figures in parentheses are  the percentage improvement in the score relative to the original score. Bold-bordered cells indicate those conditions  where performance degraded. White cells indicate the proposed system's performance is significanly different from  the baseline (using 2000-sample bootstrap resampling with a 95% confidence level)", "labels": [], "entities": []}]}