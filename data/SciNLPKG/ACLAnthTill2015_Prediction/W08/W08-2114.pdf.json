{"title": [{"text": "Acquiring Knowledge from the Web to be used as Selectors for Noun Sense Disambiguation", "labels": [], "entities": [{"text": "Acquiring Knowledge from the Web", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7779133915901184}, {"text": "Noun Sense Disambiguation", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.6203715105851492}]}], "abstractContent": [{"text": "This paper presents a method of acquiring knowledge from the Web for noun sense disambiguation.", "labels": [], "entities": [{"text": "noun sense disambiguation", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.8816054463386536}]}, {"text": "Words, called selectors, are acquired which take the place of an instance of a target word in its local context.", "labels": [], "entities": []}, {"text": "The selectors serve for the system to essentially learn the areas or concepts of WordNet that the sense of a target word should be apart of.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9567216634750366}]}, {"text": "The correct sense is chosen based on a combination of the strength given from similarity and related-ness measures over WordNet and the probability of a selector occurring within the local context.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.9589772820472717}]}, {"text": "Our method is evaluated using the coarse-grained all-words task from Se-mEval 2007.", "labels": [], "entities": []}, {"text": "Experiments reveal that path-based similarity measures perform just as well as information content similarity measures within our system.", "labels": [], "entities": []}, {"text": "Overall, the results show our system is out-performed only by systems utilizing training data or substantially more annotated data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, the Web has become the focus for many word sense disambiguation (WSD) systems.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.8192046880722046}]}, {"text": "Due to the limited amount of sense tagged data available for supervised approaches, systems which are typically referred to as unsupervised, have turned to the use of unannotated corpora including the Web.", "labels": [], "entities": []}, {"text": "The advantage of these systems is that they can disambiguate all words, and not just a set of words for which training data has been provided.", "labels": [], "entities": []}, {"text": "In this paper we present an unsupervised system which uses the Web in a novel fashion to perform sense disambiguation of any noun, incorporating both similarity and relatedness measures.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.7191877663135529}]}, {"text": "As explained in (), there are generally two approaches to unsupervised WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9061515927314758}]}, {"text": "The first is referred to as token based, which compares the relatedness of a target word to other words in its context.", "labels": [], "entities": []}, {"text": "The second approach is type based, which uses or identifies the most commonsense of a word over a discourse or corpus, and annotates all instances of a word with the most commonsense.", "labels": [], "entities": []}, {"text": "Although the type based approach is clearly bound to fail occasionally, it is commonly found to produce the strongest results, rivaling supervised systems).", "labels": [], "entities": []}, {"text": "We identify a third approach through the use of selectors, first introduced by, which help to disambiguate a word by comparing it to other words that may replace it within the same local context.", "labels": [], "entities": []}, {"text": "We approach the problem of word sense disambiguation through a relatively straightforward method that incorporates ideas from the token, type, and selector approaches.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.7173316180706024}]}, {"text": "In particular, we expand the use of selectors in several ways.", "labels": [], "entities": []}, {"text": "First, we revise the method for acquiring selectors to be applicable to the web, a corpus that is, practically speaking, impossible to parse in whole.", "labels": [], "entities": []}, {"text": "Second, we describe a path-based similarity measure that is more suited fora portion of our method than the relatedness measures used by token based systems.", "labels": [], "entities": []}, {"text": "Finally, we expand the use of selectors to help with disambiguating nouns other than the one replaced.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our algorithm using the SemEval 2007 coarse-grained all-words task.", "labels": [], "entities": [{"text": "SemEval 2007 coarse-grained all-words task", "start_pos": 37, "end_pos": 79, "type": "TASK", "confidence": 0.5739240169525146}]}, {"text": "In order to achieve a coarse grained sense inventory WordNet 2.1 senses were manually mapped to the top-level of the Oxford Dictionary of English by an expert lexicographer.", "labels": [], "entities": [{"text": "Oxford Dictionary of English", "start_pos": 117, "end_pos": 145, "type": "DATASET", "confidence": 0.9689365774393082}]}, {"text": "This task avoids the issues of a fine granular sense inventory, which provides senses: Total word instances for which selectors were acquired (insts), and average number of selectors acquired for use in each instance (avgSels). that are difficult even for humans to distinguish.", "labels": [], "entities": []}, {"text": "Additionally, considering how recent the event occurred, there is a lot of up-to-date data about the performance of other disambiguation systems to compare with.", "labels": [], "entities": []}, {"text": "() Out of 2269 noun, verb, adjective, or adverb instances we are concerned with disambiguating the 1108 noun instances from the 245 sentences in the corpus . These noun instances represent 593 different words.", "labels": [], "entities": []}, {"text": "Since we did not use the coarse-grained senses within our algorithm, the predicted senses were correct if they mapped to the correct coarsegrained sense.", "labels": [], "entities": []}, {"text": "The average instance had 2.5 possible coarse-grained senses.", "labels": [], "entities": []}, {"text": "The average number of selectors acquired for each word is given in.", "labels": [], "entities": []}, {"text": "The bottom of shows the random baseline as well as a baseline using the most frequent sense (MFS) heuristic.", "labels": [], "entities": []}, {"text": "As previously mentioned, many supervised systems only perform marginally better than the MFS.", "labels": [], "entities": []}, {"text": "For the SemEval workshop, only 6 of 15 systems performed better than this baseline on the nouns (), all of which used MFS as aback off strategy and an external sense tagged data set.", "labels": [], "entities": []}, {"text": "Baselines: MFS = most frequent sense, random = random choice of sense.", "labels": [], "entities": []}, {"text": "measure of ( gave the best results.", "labels": [], "entities": []}, {"text": "Note that the path-based and information content measures, in general, performed equally.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Total word instances for which selectors  were acquired (insts), and average number of se- lectors acquired for use in each instance (avgSels).", "labels": [], "entities": []}, {"text": " Table  1. The bottom of", "labels": [], "entities": []}, {"text": " Table 3: Number attempted (A), Precision (P),  Recall (R) and F1 values of our method with re- strictions on a minimum number of target selectors  (tMin) and context selectors (cMin).", "labels": [], "entities": [{"text": "Number attempted (A)", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.9475015282630921}, {"text": "Precision (P)", "start_pos": 32, "end_pos": 45, "type": "METRIC", "confidence": 0.9327717870473862}, {"text": "Recall (R)", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9508105218410492}, {"text": "F1", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9666174650192261}]}, {"text": " Table 4: Results of a variety of experiments using  path2 and gloss1 from the previous table. noMFS  = no use of most frequent sense, 1SPD = use of 1  sense per discourse.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of noun F1 values with  various participants in the SemEval2007 coarse- grained all-words task.", "labels": [], "entities": [{"text": "SemEval2007 coarse- grained all-words task", "start_pos": 73, "end_pos": 115, "type": "TASK", "confidence": 0.7672562301158905}]}]}