{"title": [{"text": "Phrase-Based and Deep Syntactic English-to-Czech Statistical Machine Translation *", "labels": [], "entities": [{"text": "Syntactic English-to-Czech Statistical Machine Translation", "start_pos": 22, "end_pos": 80, "type": "TASK", "confidence": 0.5088452100753784}]}], "abstractContent": [{"text": "This paper describes our two contributions to WMT08 shared task: factored phrase-based model using Moses and a probabilistic tree-transfer model at a deep syntactic layer.", "labels": [], "entities": [{"text": "WMT08 shared task", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7160077492396036}]}], "introductionContent": [{"text": "Czech is a Slavic language with very rich morphology and relatively free word order.", "labels": [], "entities": []}, {"text": "The Czech morphological system) defines 4,000 tags in theory and 2,000 were actually seen in a big tagged corpus while the English Penn Treebank tagset contains just about 50 tags.", "labels": [], "entities": [{"text": "English Penn Treebank tagset", "start_pos": 123, "end_pos": 151, "type": "DATASET", "confidence": 0.7952642291784286}]}, {"text": "In our parallel corpus (see below), the English vocabulary size is 148k distinct word forms but more than twice as big in Czech, 343k distinct word forms.", "labels": [], "entities": []}, {"text": "When translating to Czech from an analytic language such as English, target word forms have to be chosen correctly to produce a grammatical sentence and preserve the expressed relations between elements in the sentence, e.g. verbs and their modifiers.", "labels": [], "entities": []}, {"text": "This year, we have taken two radically different approaches to English-to-Czech MT.", "labels": [], "entities": [{"text": "English-to-Czech MT", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.4565567076206207}]}, {"text": "Section 2 describes our setup of the phrase-based system Moses ( and Section 3 focuses on a system with probabilistic tree transfer employed at a deep syntactic layer and the new challenges this approach brings.", "labels": [], "entities": []}, {"text": "describes various experiments with factored translation to Czech aimed at improving target-side morphology.", "labels": [], "entities": []}, {"text": "We use essentially the same setup with some cleanup and significantly larger target-side training data:", "labels": [], "entities": []}], "datasetContent": [{"text": "For WMT08 shared task,, we used a variant of the \"etct factored\" setup with the annotation pipeline as incorporated in TectoMT ( \u02c7 Zabokrtsk\u00b4yZabokrtsk\u00b4y, 2008) environment and using TectoMT internal Treated as atomic, t-node labels have higher entropy (11.54) than lowercase plaintext (10.74).", "labels": [], "entities": [{"text": "WMT08 shared task", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.5098503828048706}]}, {"text": "The t-layer by itself does not bring any reduction in vocabulary.", "labels": [], "entities": []}, {"text": "The idea is that the attributes should be more or less independent and should map easier across languages.", "labels": [], "entities": []}, {"text": "Unlike Moses, \"epcp\" does not permit phrase reordering.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7527987062931061}]}], "tableCaptions": [{"text": " Table 1: English-to-Czech BLEU scores for syntax-based  MT on WMT07 DevTest.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9900279641151428}, {"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9196301698684692}, {"text": "WMT07 DevTest", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.9254887104034424}]}, {"text": " Table 2: WMT08 shared task BLEU scores.", "labels": [], "entities": [{"text": "WMT08 shared task", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.4966733753681183}, {"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9080886840820312}]}]}