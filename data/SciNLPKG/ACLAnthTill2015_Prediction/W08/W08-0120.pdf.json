{"title": [{"text": "A Frame-Based Probabilistic Framework for Spoken Dialog Manage- ment Using Dialog Examples", "labels": [], "entities": [{"text": "Spoken Dialog Manage- ment", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.8123044371604919}]}], "abstractContent": [{"text": "This paper proposes a probabilistic framework for spoken dialog management using dialog examples.", "labels": [], "entities": [{"text": "spoken dialog management", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.7717637221018473}]}, {"text": "To overcome the complexity problems of the classic partially observable Mar-kov decision processes (POMDPs) based dialog manager, we use a frame-based belief state representation that reduces the complexity of belief update.", "labels": [], "entities": []}, {"text": "We also used dialog examples to maintain a reasonable number of system actions to reduce the complexity of the optimizing policy.", "labels": [], "entities": []}, {"text": "We developed weather information and car navigation dialog system that employed a frame-based probabilistic framework.", "labels": [], "entities": [{"text": "car navigation dialog", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.816055436929067}]}, {"text": "This framework enables people to develop a spoken dialog system using a prob-abilistic approach without complexity problem of POMDP.", "labels": [], "entities": []}], "introductionContent": [{"text": "A robust dialog manager is an essential part of spoken dialog systems, because many such systems have failed in practice due to errors in speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7176409065723419}]}, {"text": "Speech recognition errors can be propagated to spoken language understanding (SLU), so the speech input must be considered error-prone from a standpoint of dialog management.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7252545654773712}, {"text": "spoken language understanding (SLU)", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.8423741261164347}]}, {"text": "Therefore robust dialog managers are necessary to develop practical spoken dialog systems.", "labels": [], "entities": []}, {"text": "One approach to dialog management uses the partially observable Markov decision process (POMDP) as a statistical framework, because this approach can model the uncertainty inherent in human-machine dialog.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.9247442483901978}]}, {"text": "The dialog manager uses a probabilistic, rather than deterministic, approach to manage dialog.", "labels": [], "entities": []}, {"text": "As more information becomes available, the dialog manager updates its belief states.", "labels": [], "entities": []}, {"text": "A POMDP-based dialog manager can learn the optimized policy that maximizes expected rewards by reinforcement learning.", "labels": [], "entities": []}, {"text": "But applying classic POMDP to a practical dialog system incurs a scalability problem.", "labels": [], "entities": []}, {"text": "The computational complexity of updating belief states and optimizing the policy increases rapidly with the size of the state space in a slot-filling dialog task.", "labels": [], "entities": []}, {"text": "To solve this scalability problem, the method of compressing states or mapping the original state space to summarized space can be used), but these algorithms tend to approximate the state space excessively.", "labels": [], "entities": []}, {"text": "The complexity problem of POMDP comes from updating beliefs that are out of the user's intention, and from calculating the reward of system actions that do not satisfy user's objective.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew probabilistic framework for spoken dialog management using dialog examples.", "labels": [], "entities": [{"text": "spoken dialog management", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.7608189980189005}]}, {"text": "We adopted a frame-based belief state representation to reduce the complexity of belief update.", "labels": [], "entities": [{"text": "belief update", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.7268121838569641}]}, {"text": "Furthermore, we used an examplebased approach to generate only a reasonable number of system action hypotheses in anew framework.", "labels": [], "entities": []}, {"text": "We developed a dialog system by using our new framework in weather information service and car navigation service.", "labels": [], "entities": [{"text": "car navigation service", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.7708679536978403}]}], "datasetContent": [{"text": "1) Real user evaluation: we measured the user satisfaction with various factors by human.", "labels": [], "entities": []}, {"text": "2) Simulated user evaluation: we implemented user simulator to measure the system performance with a large number of dialogs.", "labels": [], "entities": [{"text": "Simulated user evaluation", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.8530835707982382}]}, {"text": "We built dialog corpora in two domains: weather information service and car navigation.", "labels": [], "entities": [{"text": "car navigation", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.738293930888176}]}, {"text": "We built a dialog corpus in weather information service to measure the performance of the dialog system using our approach by real user evaluation.", "labels": [], "entities": []}, {"text": "This corpus consists of 99 dialogs with 503 user utterances (turns).", "labels": [], "entities": []}, {"text": "User's utterances were annotated with the semantic frame including speech acts, main goal and component slots for training the SLU module and indexing the DEDB.", "labels": [], "entities": [{"text": "DEDB", "start_pos": 155, "end_pos": 159, "type": "DATASET", "confidence": 0.8588008880615234}]}, {"text": "To evaluate the preliminary performance, four test volunteers among computer science people evaluated our dialog system with five different weather information-seeking tasks.", "labels": [], "entities": []}, {"text": "The volunteers typed their utterances with a keyboard rather than using areal ASR because it is hard to control the WER.", "labels": [], "entities": [{"text": "WER", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.6553217768669128}]}, {"text": "We employed a simulated ASR error channel by generating random errors to evaluate the performance of dialog management under various levels of WER.", "labels": [], "entities": [{"text": "ASR error channel", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.8463065425554911}, {"text": "dialog management", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.8370303809642792}]}, {"text": "We will explain the details of our ASR channel simulator in Section 5.2.", "labels": [], "entities": [{"text": "ASR channel simulator", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.9326789776484171}]}, {"text": "The WER is controlled by this ASR channel simulator while the volunteers were interacting with computer.", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.4281606674194336}, {"text": "ASR channel", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.7406422793865204}]}, {"text": "To measure the user perception of task completion rate (TCR), the volunteers evaluated the system's response in each dialog to measure the success turn rate (STR) and decided whether the entire dialog was successful or not.", "labels": [], "entities": [{"text": "user perception of task completion rate (TCR)", "start_pos": 15, "end_pos": 60, "type": "METRIC", "confidence": 0.6921090715461307}, {"text": "success turn rate (STR)", "start_pos": 139, "end_pos": 162, "type": "METRIC", "confidence": 0.9400653739770254}]}, {"text": "We evaluated the performance of our dialog system based on criteria outlined in () by measuring user satisfaction, which is defined with a linear combination of three measures: TCR, Mean Recognition Accuracy (MRA), and STR.", "labels": [], "entities": [{"text": "TCR", "start_pos": 177, "end_pos": 180, "type": "METRIC", "confidence": 0.9934050440788269}, {"text": "Mean Recognition Accuracy (MRA)", "start_pos": 182, "end_pos": 213, "type": "METRIC", "confidence": 0.9485835631688436}, {"text": "STR", "start_pos": 219, "end_pos": 222, "type": "METRIC", "confidence": 0.9339643120765686}]}, {"text": "We built another dialog corpus in car navigation service to measure the performance of the dialog system by simulated user evaluation.", "labels": [], "entities": [{"text": "car navigation", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.7560038864612579}]}, {"text": "This corpus consists of 123 dialogs with 510 user utterances (turns).", "labels": [], "entities": []}, {"text": "The SLU result frame of this corpus has 7 types of speech acts, 8 types of main goals, and 5 different component slots.", "labels": [], "entities": [{"text": "SLU result frame", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.6836678882439932}]}, {"text": "The user simulator and ASR channel simulator has been used for evaluating the proposed dialog management framework.", "labels": [], "entities": [{"text": "ASR channel", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.7505370080471039}, {"text": "dialog management", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.8748049736022949}]}, {"text": "The user simulator has two components: an Intention Simulator and a Surface Simulator.", "labels": [], "entities": []}, {"text": "The Intention Simulator generates the next user intention given current discourse context, and the Surface Simulator generates user sentence to express the generated intention.", "labels": [], "entities": []}, {"text": "ASR channel simulator simulates the speech recognition errors including substitution, deletion, and insertions errors.", "labels": [], "entities": [{"text": "ASR channel", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8294650912284851}, {"text": "speech recognition", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6927160620689392}]}, {"text": "It uses the phoneme confusion matrix to estimate the probability distribution for error simulation.", "labels": [], "entities": [{"text": "error simulation", "start_pos": 82, "end_pos": 98, "type": "TASK", "confidence": 0.6412912607192993}]}, {"text": "ASR channel simulator distorts the generated user utterance from Surface Simulator.", "labels": [], "entities": [{"text": "ASR channel simulator", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6526104807853699}]}, {"text": "By simulating user intentions, surface form of user sentence and ASR channel, we can test the robustness of the proposed dialog system in both speech recognition and speech understanding errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.5355397462844849}, {"text": "speech recognition", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.7425476610660553}]}, {"text": "We defined a final state of dialog to automatically measure TCR of a simulated dialog.", "labels": [], "entities": [{"text": "TCR", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9987044334411621}]}, {"text": "If a dialog flow reaches the final state, the evaluator regards that the dialog was successfully completed.", "labels": [], "entities": []}, {"text": "TCRs and average dialog lengths were measured under various WER conditions that were generated by ASR channel simulator.", "labels": [], "entities": [{"text": "ASR channel simulator", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.8106253743171692}]}, {"text": "Until the SLU result is an actual input of the dialog manager, we also measured the SLU accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9036554098129272}]}, {"text": "If a SLU result is same as a user's intention of the Intention Simulator, then the evaluator considers that the result is correct.", "labels": [], "entities": []}, {"text": "Unlike in the real user evaluation, the dialog system could be evaluated with relatively large amount of simulated dialogs in the simulated user evaluation.", "labels": [], "entities": []}, {"text": "5000 simulated dialogs were generated for each WER condition.", "labels": [], "entities": [{"text": "WER condition", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.6147743761539459}]}, {"text": "We found that the SLU accuracy and TCR linearly decreased with the WER.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9018948674201965}, {"text": "TCR", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9987863898277283}, {"text": "WER", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9263420701026917}]}, {"text": "Similar in the human evaluation, TCR is about 0.9 when WER is zero, and it becomes below 0.7 when WER is higher than 20%.", "labels": [], "entities": [{"text": "TCR", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9996366500854492}, {"text": "WER", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9848545789718628}, {"text": "WER", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.995995283126831}]}, {"text": "Average dialog length, on contrary, increased with WER, and it has similar values when WER is less than 10% although it increased relatively rapidly when WER is higher than 15%.", "labels": [], "entities": [{"text": "length", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.6055501103401184}, {"text": "WER", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8114527463912964}, {"text": "WER", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9769933819770813}, {"text": "WER", "start_pos": 154, "end_pos": 157, "type": "METRIC", "confidence": 0.9422722458839417}]}], "tableCaptions": []}