{"title": [{"text": "Parse selection with a German HPSG grammar", "labels": [], "entities": [{"text": "Parse selection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8414062559604645}, {"text": "German HPSG", "start_pos": 23, "end_pos": 34, "type": "DATASET", "confidence": 0.8453166782855988}]}], "abstractContent": [{"text": "We report on some recent parse selection experiments carried outwith GG, a large-scale HPSG grammar for German.", "labels": [], "entities": []}, {"text": "Using a manually disambiguated treebank derived from the Verbmobil corpus, we achieve over 81% exact match accuracy compared to a 21.4% random baseline, corresponding to an error reduction rate of 3.8.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 57, "end_pos": 73, "type": "DATASET", "confidence": 0.977889746427536}, {"text": "exact match", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.8771317601203918}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.53914475440979}, {"text": "error reduction rate", "start_pos": 173, "end_pos": 193, "type": "METRIC", "confidence": 0.9764430125554403}]}], "introductionContent": [{"text": "The literature on HPSG parsing of German has almost exclusively been concerned with issues of theoretical adequacy and parsing efficiency.", "labels": [], "entities": [{"text": "HPSG parsing of German", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7736559212207794}]}, {"text": "In contrast to LFG parsing of German, or even to HPSG work on English or Japanese, very little effort has been spent on the question of how the intended, or, for that matter a likely parse, can be extracted from the HPSG parse forest of some German sentence.", "labels": [], "entities": [{"text": "LFG parsing of German", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.7509788423776627}, {"text": "HPSG parse forest", "start_pos": 216, "end_pos": 233, "type": "DATASET", "confidence": 0.8174388806025187}]}, {"text": "This issue becomes all the more pressing, as the grammars gain in coverage, inevitably increasing their ambiguity.", "labels": [], "entities": [{"text": "coverage", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9742498397827148}]}, {"text": "In this paper, I shall present preliminary results on probabilistic parse selection fora largescale HPSG of German, building on technology developed in the Lingo Redwoods project).", "labels": [], "entities": [{"text": "parse selection", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7674687802791595}, {"text": "Lingo Redwoods project", "start_pos": 156, "end_pos": 178, "type": "DATASET", "confidence": 0.8601439197858175}]}, {"text": "* The research reported here has been carried out at the German Research Center for Artificial Intelligence (DFKI GmbH) as part of the projects COLLATE, QALL-ME, and Checkpoint, funded by the German Federal Ministery for education and Science (BMBF), the European Union, and the State of Berlin, respectively.", "labels": [], "entities": [{"text": "COLLATE", "start_pos": 144, "end_pos": 151, "type": "METRIC", "confidence": 0.9504678845405579}, {"text": "QALL-ME", "start_pos": 153, "end_pos": 160, "type": "METRIC", "confidence": 0.8562827110290527}]}, {"text": "I am also greatly indepted to my colleagues Bernd Kiefer and G\u00fcnter Neumann, as well as to Stephan Oepen and Dan Flickinger for support and comments relating to the work presented here.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: in section 2, I shall give a brief overview of the grammar.", "labels": [], "entities": []}, {"text": "Section 3 discusses the treebanking effort we have undertaken (3.1), followed by a presentation of the parse selection results we achieve using probabilistic models trained on different feature sets (3.2).", "labels": [], "entities": [{"text": "parse selection", "start_pos": 103, "end_pos": 118, "type": "TASK", "confidence": 0.9358810782432556}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: PCFG model with Grandparenting", "labels": [], "entities": [{"text": "Grandparenting", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.41627511382102966}]}, {"text": " Table 2: PCFG model with Grandparenting & N-grams", "labels": [], "entities": [{"text": "Grandparenting", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.7769027352333069}]}, {"text": " Table 3: Performance of Ruland's probabilistic parser  (with postprocessing) on Verbmobil data", "labels": [], "entities": [{"text": "Verbmobil data", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.9181621372699738}]}]}