{"title": [{"text": "Using LDA to detect semantically incoherent documents", "labels": [], "entities": []}], "abstractContent": [{"text": "Detecting the semantic coherence of a document is a challenging task and has several applications such as in text segmenta-tion and categorization.", "labels": [], "entities": [{"text": "Detecting the semantic coherence of a document", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8674409730093819}]}], "introductionContent": [{"text": "The \"Internet revolution\" has dramatically increased the monetary value of higher ranking on the web search engines index, fostering the expansion of techniques, collectively known as \"Web Spam\", that fraudulently help to do so.", "labels": [], "entities": []}, {"text": "Detecting the consistency of texts or of text chunks has many applications in Natural Language Processing.", "labels": [], "entities": [{"text": "Detecting the consistency of texts or of text chunks", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.78129067685869}]}, {"text": "So far, it has been used mainly in the context of automatic text segmentation, where a change in vocabulary is often the mark of topic change, and, to a lesser extent, in discourse studies (see, e.g.,).", "labels": [], "entities": [{"text": "automatic text segmentation", "start_pos": 50, "end_pos": 77, "type": "TASK", "confidence": 0.6235837837060293}]}, {"text": "It could also serve to devise automatic metrics for text summarization or machine translation tasks.", "labels": [], "entities": [{"text": "text summarization or machine translation", "start_pos": 52, "end_pos": 93, "type": "TASK", "confidence": 0.6736165702342987}]}, {"text": "This paper is an attempt to address the issue of differentiating between 'true' and 'false' documents on the basis of their consistency through topic modeling approach.", "labels": [], "entities": []}, {"text": "We have used Latent Dirichlet allocation (LDA) () model as our main topic modeling tool.", "labels": [], "entities": [{"text": "Latent Dirichlet allocation (LDA)", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.6377928952376047}]}, {"text": "One of the aims of LDA and similar methods, including probabilistic latent semantic analysis (PLSA)), is to produce low dimensionality representations of texts in a \"semantic space\" such that most of their inherent statistical characteristics are preserved.", "labels": [], "entities": [{"text": "probabilistic latent semantic analysis (PLSA))", "start_pos": 54, "end_pos": 100, "type": "TASK", "confidence": 0.7541032092911857}]}, {"text": "A reduction in dimensionality facilitates storage as well as faster retrieval.", "labels": [], "entities": []}, {"text": "Modeling discrete data has many applications in classification, categorization, topic detection, data mining, information retrieval (IR), summarization and collaborative filtering ().", "labels": [], "entities": [{"text": "topic detection", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.7989713847637177}, {"text": "data mining", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.7582769989967346}, {"text": "information retrieval (IR)", "start_pos": 110, "end_pos": 136, "type": "TASK", "confidence": 0.8226524591445923}, {"text": "summarization", "start_pos": 138, "end_pos": 151, "type": "TASK", "confidence": 0.987069845199585}]}, {"text": "The aim of this paper is to test LDA for establishing the semantic coherence of a document based on the premise that areal (coherent) document should discuss only a few number of topics, a property hardly granted for forged documents which are often made up of random assemblage of words or sentences.", "labels": [], "entities": []}, {"text": "As a consequence, the coherence of a document may reflect in the entropy of its posterior topic distribution or in its perplexity for the model.", "labels": [], "entities": []}, {"text": "The entropy of the estimated topic distribution of a true document is expected to be lower than that of a fake document.", "labels": [], "entities": []}, {"text": "Moreover, the length normalized log-likelihood of a true and coherent document maybe higher as compared to that of a false and incoherent document.", "labels": [], "entities": []}, {"text": "In this paper, we compare two methods to estimate the posterior topic distribution of test documents, and this study is also an attempt to investigate the role of different parameters on the efficiency of these methods.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: In Section 2, the basics of the LDA model are set.", "labels": [], "entities": []}, {"text": "We then discuss and contrast several approaches to the problem of inferring the topic distribution of anew document in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the corpus and experimental set-up that are used to produce the results presented in Section 5.", "labels": [], "entities": []}, {"text": "We summarize our main findings and draw perspectives for future research in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Reuters Corpus Volume 1 (RCV1) () is a collection of over 800,000 news items in English from August 1996 to August 1997.", "labels": [], "entities": [{"text": "The Reuters Corpus Volume 1 (RCV1)", "start_pos": 0, "end_pos": 34, "type": "DATASET", "confidence": 0.8911374323070049}]}, {"text": "Out of the entire RCV1 dataset, we selected 27,672 documents (news items) for training (TrainReuters) and 23,326 documents for testing (TestReuters).", "labels": [], "entities": [{"text": "RCV1 dataset", "start_pos": 18, "end_pos": 30, "type": "DATASET", "confidence": 0.9749029576778412}]}, {"text": "The first 4000 documents from the TestReuters dataset were used as true documents (TrueReuters) in the experiments reported in this paper.", "labels": [], "entities": [{"text": "TestReuters dataset", "start_pos": 34, "end_pos": 53, "type": "DATASET", "confidence": 0.9645269215106964}]}, {"text": "The vocabulary size in the train set, after removing the function words, is 93, 214.", "labels": [], "entities": []}, {"text": "Along with these datasets of \"true\" documents, three datasets of fake documents were also created.", "labels": [], "entities": []}, {"text": "Document generation techniques are many: here we consider documents made by mixing short passages from various texts and documents made by assembling randomly chosen words (sometimes called as \"word salads\").", "labels": [], "entities": [{"text": "Document generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8704303503036499}]}, {"text": "In addition, we also consider the case of documents generated with a stochastic language model (LM).", "labels": [], "entities": []}, {"text": "Our \"fake\" test documents are thus composed of: \u2022 (SentenceSalad) obtained by randomly picking sentences from TestReuters.", "labels": [], "entities": []}, {"text": "\u2022 (WordSalad) created by generating random sentences from a conventional unigram LM trained on TrainReuters.", "labels": [], "entities": []}, {"text": "\u2022 (Markovian) created by generating random sentences from a conventional 3-gram LM trained on TrainReuters.", "labels": [], "entities": []}, {"text": "Each of these forged document set contains 4,000 documents.", "labels": [], "entities": []}, {"text": "To assess the performance on out-of-domain data, we replicated the same tests using 2,000 Medline abstracts ().", "labels": [], "entities": [{"text": "Medline abstracts", "start_pos": 90, "end_pos": 107, "type": "DATASET", "confidence": 0.9085308909416199}]}, {"text": "1,500 documents were used either to generate fake documents by picking sentences randomly or to train an LM and then using the LM to generate fake documents.", "labels": [], "entities": []}, {"text": "The remaining 500 abstracts were set aside as \"true\" documents (TrueMedline).", "labels": [], "entities": [{"text": "TrueMedline", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9545478820800781}]}], "tableCaptions": [{"text": " Table 1: Performance of the Multinomial Mixture  and LDA", "labels": [], "entities": [{"text": "Multinomial Mixture", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.5769697278738022}]}, {"text": " Table 2: EER from LLPW and Entropy distribution  for TrueReuters against SentenceSalad.", "labels": [], "entities": [{"text": "EER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9979189038276672}]}, {"text": " Table 3: Performance of LDA on PubMed ab- stracts", "labels": [], "entities": [{"text": "PubMed ab- stracts", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.9437728226184845}]}]}